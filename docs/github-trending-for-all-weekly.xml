<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>GitHub All Languages Weekly Trending</title>
<link>http://mshibanami.github.io/GitHubTrendingRSS</link>


<item>
<title>DiceDB/dice</title>
<link>https://github.com/DiceDB/dice</link>
<guid>https://github.com/DiceDB/dice</guid>
<content:encoded><![CDATA[
<div> 关键词：DiceDB、Redis、SQL、实时数据库、在内存中

总结：
DiceDB是一个基于SQL反应性的在内存实时数据库，专为在现代硬件上构建和扩展真正实时应用而优化。它与Redis高度兼容，可以作为其无缝替代品使用，无需任何代码更改或学习曲线。DiceDB的核心特性包括多线程架构和QWATCH命令，允许用户通过实时监听SQL查询来构建实时应用程序。要开始使用DiceDB，最简单的方法是通过Docker运行容器，或者从源代码安装并设置本地开发环境。此外，DiceDB提供了一个热加载开发服务器，支持快速迭代和实时预览代码变化。为了连接DiceDB，推荐使用DiceDB CLI，但也可以使用任何Redis客户端和SDK。测试功能覆盖了单元测试和集成测试，确保了数据库的功能正确性。对于性能评估，DiceDB支持基准测试以衡量其效率。DiceDB致力于通过持续改进和社区贡献来优化其性能和功能。 <div>
<p>DiceDB is an in-memory real-time database with SQL-based reactivity. It is hyper-optimized for building and scaling truly real-time applications on modern hardware while being a drop-in replacement for Redis.</p><hr /><h1>DiceDB</h1> 
<p>DiceDB is an in-memory real-time database with SQL-based reactivity. It is hyper-optimized for building and scaling truly real-time applications on modern hardware while being a drop-in replacement for Redis.</p> 
<blockquote> 
 <p>Note: DiceDB is still in development and it supports a subset of Redis commands. So, please do not use it in production. But, feel free to go through the <a href="https://github.com/DiceDB/dice/issues">open issues</a> and contribute to help us speed up the development.</p> 
</blockquote> 
<h2>How is it different from Redis?</h2> 
<p>Although DiceDB is a drop-in replacement of Redis, which means almost no learning curve and switching does not require any code change, it still differs in two key aspects and they are</p> 
<ol> 
 <li>DiceDB is multi-threaded and follows <a href="https://en.wikipedia.org/wiki/Shared-nothing_architecture">shared-nothing architecture</a>.</li> 
 <li>DiceDB supports a new command called <code>QWATCH</code> that lets clients listen to a SQL query and get notified in real-time whenever something changes.</li> 
</ol> 
<p>With this, you can build truly real-time applications like <a href="https://github.com/DiceDB/dice/tree/master/examples/leaderboard-go">Leaderboard</a> with simple SQL query.</p> 
<p><img alt="Leaderboard with DiceDB" src="https://github.com/user-attachments/assets/327792c7-d788-47d4-a767-ef2c478d75cb" /></p> 
<h2>Get started</h2> 
<h3>Using Docker</h3> 
<p>The easiest way to get started with DiceDB is using <a href="https://www.docker.com/">Docker</a> by running the following command.</p> 
<pre><code>$ docker run dicedb/dicedb
</code></pre> 
<p>The above command will start the DiceDB server running locally on the port <code>7379</code> and you can connect to it using DiceDB CLI and SDKs, or even Redis CLIs and SDKs.</p> 
<blockquote> 
 <p>Note: Given it is a drop-in replacement of Redis, you can also use any Redis CLI and SDK to connect to DiceDB.</p> 
</blockquote> 
<h3>Setting up DiceDB from source for development and contributions</h3> 
<p>To run DiceDB for local development or running from source, you will need</p> 
<ol> 
 <li><a href="https://go.dev/">Golang</a></li> 
 <li>Any of the below supported platform environment: 
  <ol> 
   <li><a href="https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions">Linux based environment</a></li> 
   <li><a href="https://en.wikipedia.org/wiki/MacOS">OSX (Darwin) based environment</a></li> 
   <li>WSL under Windows</li> 
  </ol> </li> 
</ol> 
<pre><code>$ git clone https://github.com/dicedb/dice
$ cd dice
$ go run main.go
</code></pre> 
<ol start="4"> 
 <li>Install GoLangCI</li> 
</ol> 
<pre><code>$ sudo su
$ curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b /bin v1.60.1
</code></pre> 
<h3>Live Development Server</h3> 
<p>DiceDB provides a hot-reloading development environment, which allows you to instantly view your code changes in a live server. This functionality is supported by <a href="https://github.com/air-verse/air">Air</a></p> 
<p>To Install Air on your system you have following options.</p> 
<ol> 
 <li>If you're on go 1.22+</li> 
</ol> 
<pre><code class="language-sh">go install github.com/air-verse/air@latest
</code></pre> 
<ol start="2"> 
 <li>Install the Air binary</li> 
</ol> 
<pre><code class="language-sh"># binary will be installed at $(go env GOPATH)/bin/air
curl -sSfL https://raw.githubusercontent.com/air-verse/air/master/install.sh | sh -s -- -b $(go env GOPATH)/bin
</code></pre> 
<p>Once <code>air</code> is installed you can verify the installation using the command <code>air -v</code></p> 
<p>To run the live DiceDB server for local development:</p> 
<pre><code class="language-sh">$ git clone https://github.com/dicedb/dice
$ cd dice
$ air
</code></pre> 
<h2>Setting up CLI</h2> 
<p>The best way to connect to DiceDB is using DiceDB CLI and you can install it by running the following command.</p> 
<pre><code>$ pip install dicedb-cli
</code></pre> 
<blockquote> 
 <p>Because DiceDB speaks Redis dialect, you can connect to it with any Redis Client and SDK also. But if you are planning to use the <code>QWATCH</code> feature then you need to use the DiceDB CLI.</p> 
</blockquote> 
<h2>Running Tests</h2> 
<p>Unit tests and integration tests are essential for ensuring correctness and in the case of DiceDB, both types of tests are available to validate its functionality.</p> 
<p>For unit testing, you can execute individual unit tests by specifying the name of the test function using the <code>TEST_FUNC</code> environment variable and running the <code>make unittest-one</code> command. Alternatively, running <code>make unittest</code> will execute all unit tests.</p> 
<h3>Executing one unit test</h3> 
<pre><code>$ TEST_FUNC=&lt;name of the test function&gt; make unittest-one
$ TEST_FUNC=TestByteList make unittest-one
</code></pre> 
<h3>Running all unit tests</h3> 
<pre><code>$ make unittest
</code></pre> 
<p>Integration tests, on the other hand, involve starting up the DiceDB server and running a series of commands to verify the expected end state and output. To execute a single integration test, you can set the <code>TEST_FUNC</code> environment variable to the name of the test function and run <code>make test-one</code>. Running <code>make test</code> will execute all integration tests.</p> 
<h3>Executing a single integration test</h3> 
<pre><code>$ TEST_FUNC=&lt;name of the test function&gt; make test-one
$ TEST_FUNC=TestSet make test-one
</code></pre> 
<h3>Running all integration tests</h3> 
<pre><code>$ make test
</code></pre> 
<blockquote> 
 <p>Work to add more tests in DiceDB is in progress and we will soon port the test <a href="https://github.com/redis/redis/tree/f60370ce28b946c1146dcea77c9c399d39601aaa">Redis suite</a> to this codebase to ensure full compatibility.</p> 
</blockquote> 
<h2>Running Benchmark</h2> 
<pre><code class="language-sh">$ go test -test.bench &lt;pattern&gt;
$ go test -test.bench BenchmarkListRedis -benchmem
</code></pre> 
<h2>Getting Started</h2> 
<p>To get started with building and contributing to DiceDB, please refer to the <a href="https://github.com/DiceDB/dice/issues">issues</a> created in this repository.</p> 
<h2>The story</h2> 
<p>DiceDB started as a re-implementation of Redis in Golang and the idea was to - build a DB from scratch and understand the micro-nuances that come with its implementation. The database does not aim to replace Redis, instead, it will fit in and optimize itself for multi-core computations running on a single-threaded event loop.</p> 
<h2>How to contribute</h2> 
<p>The Code Contribution Guidelines are published at <a href="https://raw.githubusercontent.com/DiceDB/dice/master/CONTRIBUTING.md">CONTRIBUTING.md</a>; please read them before you start making any changes. This would allow us to have a consistent standard of coding practices and developer experience.</p> 
<p>Contributors can join the <a href="https://discord.gg/6r8uXWtXh7">Discord Server</a> for quick collaboration.</p> 
<h2>Contributors</h2> 
<a href="https://github.com/dicedb/dice/graphs/contributors"> <img src="https://contrib.rocks/image?repo=dicedb/dice" /> </a> 
<h2>Troubleshoot</h2> 
<h3>Forcefully killing the process</h3> 
<pre><code>$ sudo netstat -atlpn | grep :7379
$ sudo kill -9 &lt;process_id&gt;
</code></pre>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Freika/dawarich</title>
<link>https://github.com/Freika/dawarich</link>
<guid>https://github.com/Freika/dawarich</guid>
<content:encoded><![CDATA[
<div> 关键词：Dawarich、Google Location History、自托管、位置追踪、隐私保护

总结:
Dawarich是一个自托管的网络应用，旨在替代Google Maps Timeline（即Google Location History），为用户提供了一种自我控制和管理位置历史数据的方式。它允许用户导入来自Google Maps Timeline和Owntracks的位置历史数据，通过地图查看这些数据并获取如访问国家和城市数量、旅行距离等统计信息。

为了进行位置追踪，用户需在手机上安装并配置OwnTracks或Overland应用，将位置更新发送至Dawarich实例。目前，应用仅支持特定版本的OwnTracks。

在数据导入方面，用户可以从Google Maps Timeline、OwnTracks、Strava、Immich等多种来源导入历史数据。同时，Dawarich提供导出功能，支持GeoJSON和GPX格式的数据导出。此外，Dawarich还在不断开发中，提醒用户在导入数据后不要删除原始的Google Maps Timeline数据，并建议保持应用更新以获取最新功能和修复。

Dawarich提供了自托管解决方案，让用户在不依赖于大型科技公司的情况下管理自己的位置历史数据，强调了隐私保护和数据自主权的重要性。 <div>
<p>Self-hosted alternative to Google Location History (Google Maps Timeline)</p><hr /><h1>Dawarich</h1> 
<p><a href="https://discord.gg/pHsBjpt5J8"><img alt="Discord" src="https://dcbadge.limes.pink/api/server/pHsBjpt5J8" /></a> | <a href="https://ko-fi.com/H2H3IDYDD"><img alt="ko-fi" src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" /></a> | <a href="https://www.patreon.com/freika"><img alt="Patreon" src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fshieldsio-patreon.vercel.app%2Fapi%3Fusername%3Dfreika%26type%3Dpatrons&amp;style=for-the-badge" /></a> Donate using crypto: <a href="https://etherscan.io/address/0x6bAd13667692632f1bF926cA9B421bEe7EaEB8D4">0x6bAd13667692632f1bF926cA9B421bEe7EaEB8D4</a></p> 
<p><a href="https://app.circleci.com/pipelines/github/Freika/dawarich"><img alt="CircleCI" src="https://circleci.com/gh/Freika/dawarich.svg?style=svg" /></a></p> 
<h2>Screenshots</h2> 
<p><img alt="Map" src="https://raw.githubusercontent.com/Freika/dawarich/master/screenshots/map.jpeg" /></p> 
<p><img alt="Stats" src="https://raw.githubusercontent.com/Freika/dawarich/master/screenshots/stats.jpeg" /></p> 
<p><img alt="Import" src="https://raw.githubusercontent.com/Freika/dawarich/master/screenshots/imports.jpeg" /></p> 
<p>Dawarich is a self-hosted web application to replace Google Timeline (aka Google Location History). It allows you to import your location history from Google Maps Timeline and Owntracks, view it on a map and see some statistics, such as the number of countries and cities visited, and distance traveled.</p> 
<p>You can find changelog <a href="https://raw.githubusercontent.com/Freika/dawarich/master/CHANGELOG.md">here</a>.</p> 
<h2>Disclaimer</h2> 
<p>⚠️ The project is under very active development.</p> 
<p>⚠️ Expect bugs and breaking changes.</p> 
<p>⚠️ Do not delete your original Google Maps Timeline data after importing it to Dawarich.</p> 
<p>⚠️ Export your data from Dawarich using built-in export functionality before updating to a new version.</p> 
<p>⚠️ Try to keep Dawarich up-to-date to have the latest features and bug fixes.</p> 
<h2>Usage</h2> 
<p>To track your location, install the <a href="https://owntracks.org/booklet/guide/apps/">Owntracks app</a> or <a href="https://overland.p3k.app/">Overland app</a> on your phone and configure it to send location updates to your Dawarich instance.</p> 
<h3>OwnTracks</h3> 
<p>The url to send the location updates to is <code>http://&lt;your-dawarich-instance&gt;/api/v1/owntracks/points?api_key=YOUR_API_KEY</code>.</p> 
<p>Currently, the app only supports <a href="https://owntracks.org/booklet/tech/http/">HTTP mode</a> of OwnTracks.</p> 
<h3>Overland</h3> 
<p>The url to send the location updates to is <code>http://&lt;your-dawarich-instance&gt;/api/v1/overland/batches?api_key=YOUR_API_KEY</code>.</p> 
<p>Your API key can be found and/or generated in the user settings.</p> 
<p>To import your Google Maps Timeline data, download your location history from <a href="https://takeout.google.com/">Google Takeout</a> and upload it to Dawarich.</p> 
<h2>How-to's</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/Freika/dawarich/master/docs/how_to_setup_reverse_proxy.md">How to set up reverse proxy</a></li> 
 <li><a href="https://dawarich.app/docs/tutorials/import-existing-data#sources-of-data">How to import Google Takeout to Dawarich</a></li> 
 <li><a href="https://dawarich.app/docs/tutorials/import-existing-data#semantic-location-history">How to import Google Semantic History to Dawarich</a></li> 
 <li><a href="https://dawarich.app/docs/tutorials/import-existing-data#recordsjson">How to import Google Maps Timeline Data to Dawarich</a></li> 
 <li><a href="https://dawarich.app/docs/tutorials/track-your-location#overland">How to track your location to Dawarich with Overland</a></li> 
 <li><a href="https://dawarich.app/docs/tutorials/track-your-location#owntracks">How to track your location to Dawarich with OwnTracks</a></li> 
 <li><a href="https://dawarich.app/docs/tutorials/export-your-data">How to export your data from Dawarich</a></li> 
</ul> 
<p>More guides can be found in the <a href="https://dawarich.app/docs/intro">Docs</a></p> 
<h2>Features</h2> 
<h3>Location Tracking</h3> 
<p>You can track your location using the Owntracks or Overland app.</p> 
<h3>Location history</h3> 
<p>You can view your location history on a map. On the map you can enable/disable the following layers:</p> 
<ul> 
 <li>Heatmap</li> 
 <li>Points</li> 
 <li>Lines between points</li> 
 <li>Fog of War</li> 
 <li>Areas</li> 
</ul> 
<h3>Visits (beta)</h3> 
<p>Dawarich can suggest places you've visited and allow you to confirm or reject them.</p> 
<h3>Statistics</h3> 
<p>You can see the number of countries and cities visited, the distance traveled, and the time spent in each country, splitted by years and months.</p> 
<h3>Import</h3> 
<p>You can import your existing location history from:</p> 
<ul> 
 <li>Google Maps Timeline</li> 
 <li>OwnTracks</li> 
 <li>Strava</li> 
 <li>Immich</li> 
 <li>Your own GPX files</li> 
 <li>Your own GeoJSON files</li> 
 <li>Your photos' EXIF data</li> 
</ul> 
<h3>Export</h3> 
<p>You can export your data to GeoJSON or GPX format.</p> 
<h2>How to start the app locally</h2> 
<p><code>docker-compose up</code> to start the app. The app will be available at <code>http://localhost:3000</code>.</p> 
<p>Press <code>Ctrl+C</code> to stop the app.</p> 
<h2>How to install the app</h2> 
<p><strong><a href="https://dawarich.app/docs/intro#setup-your-dawarich-instance">Docker</a></strong></p> 
<p><strong><a href="https://dawarich.app/docs/tutorials/platforms/synology">Synology</a></strong></p> 
<h3>Default credentials</h3> 
<ul> 
 <li><strong>Username</strong>: <code>user@domain.com</code></li> 
 <li><strong>Password</strong>: <code>password</code></li> 
</ul> 
<p>Feel free to change them both in the Account section.</p> 
<h2>Environment variables</h2> 
<p>See the docs on the <a href="https://dawarich.app/docs/environment-variables-and-settings">website</a></p> 
<h2>Star History</h2> 
<p>As you could probably guess, I like statistics.</p> 
<a href="https://star-history.com/#Freika/dawarich&amp;Date"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <source media="(prefers-color-scheme: light)" /> 
  <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Freika/dawarich&amp;type=Date" /> 
  </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>shadcn-ui/ui</title>
<link>https://github.com/shadcn-ui/ui</link>
<guid>https://github.com/shadcn-ui/ui</guid>
<content:encoded><![CDATA[
<div> 关键词：设计精良、可复制粘贴、易访问性、可定制化、开源

总结:

这篇文档主要介绍了名为"shadcn/ui"的开源组件库。这个库提供了精心设计的组件，用户可以将这些组件直接复制粘贴到自己的应用中使用。其设计兼顾了易访问性和可定制化，允许开发者根据需要调整和修改组件以适应不同的应用场景。最重要的是，这个组件库是免费且开源的，这意味着任何人都可以在遵守相应的许可协议下使用、修改并贡献给这个项目。

为了帮助用户更好地理解和使用这些组件，文档中包含了详细的使用指南和示例代码。此外，为了鼓励社区参与和改进，文档还提供了关于如何贡献的指导说明。总的来说，shadcn/ui是一个强大的工具，旨在简化开发过程，提升应用的视觉效果和用户体验，同时通过开放源代码的形式促进开发者之间的合作与创新。 <div>
<p>Beautifully designed components that you can copy and paste into your apps. Accessible. Customizable. Open Source.</p><hr /><h1>shadcn/ui</h1> 
<p>Accessible and customizable components that you can copy and paste into your apps. Free. Open Source. <strong>Use this to build your own component library</strong>.</p> 
<p><img alt="hero" src="https://raw.githubusercontent.com/shadcn-ui/ui/main/apps/www/public/og.jpg" /></p> 
<h2>Documentation</h2> 
<p>Visit <a href="http://ui.shadcn.com/docs">http://ui.shadcn.com/docs</a> to view the documentation.</p> 
<h2>Contributing</h2> 
<p>Please read the <a href="https://raw.githubusercontent.com/shadcn-ui/ui/main/CONTRIBUTING.md">contributing guide</a>.</p> 
<h2>License</h2> 
<p>Licensed under the <a href="https://github.com/shadcn/ui/raw/main/LICENSE.md">MIT license</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OpenBMB/MiniCPM</title>
<link>https://github.com/OpenBMB/MiniCPM</link>
<guid>https://github.com/OpenBMB/MiniCPM</guid>
<content:encoded><![CDATA[
<p>MiniCPM3-4B: An edge-side LLM that surpasses GPT-3.5-Turbo.</p><hr /><div align="center"> 
 <img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/minicpm_logo.png" width="500em" /> 
</div> 
<h4 align="center"> <p> <b>中文</b> | <a href="https://github.com/OpenBMB/MiniCPM/raw/main/README-en.md">English</a> </p><p> </p></h4> 
<p align="center"> <a href="https://openbmb.vercel.app/?category=Chinese+Blog" target="_blank">MiniCPM 技术博客</a> | <a href="https://modelbest.feishu.cn/wiki/D2tFw8Pcsi5CIzkaHNacLK64npg" target="_blank">MiniCPM 知识库</a> | <a href="https://arxiv.org/abs/2404.06395" target="_blank">MiniCPM 论文</a> | <a href="https://github.com/OpenBMB/MiniCPM-V/" target="_blank">MiniCPM-V 仓库</a> | 加入我们的 <a href="https://discord.gg/3cGQn9b3YM" target="_blank">discord</a> 和 <a href="https://github.com/OpenBMB/MiniCPM/raw/main/assets/wechat.jpg" target="_blank">微信群</a> </p> 
<h2>更新日志🔥</h2> 
<ul> 
 <li>[2024.09.05] 发布 <a href="https://huggingface.co/openbmb/MiniCPM3-4B"><strong>MiniCPM3-4B</strong></a>！该模型的表现超越 Phi-3.5-mini-instruct 和 GPT-3.5-Turbo-0125，并且能够比肩 Llama3.1-8B-Instruct、Qwen2-7B-Instruct、GLM-4-9B-Chat 等多个 7B-9B 参数量的模型。</li> 
 <li>[2024.07.09] MiniCPM-2B 已经支持使用 <a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#sglang-%E6%8E%A8%E7%90%86">SGLang</a> 推理！</li> 
 <li>[2024.07.05] 发布 <a href="https://huggingface.co/openbmb/MiniCPM-S-1B-sft">MiniCPM-S-1B</a>！该模型在保持下游任务性能无损的前提下，FFN 层实现了 87.89% 的平均稀疏度，将 FFN FLOPs 降低了 84%。</li> 
 <li>[2024.04.11] 发布 <a href="https://huggingface.co/openbmb/MiniCPM-2B-128k">MiniCPM-2B-128k</a>、<a href="https://huggingface.co/openbmb/MiniCPM-MoE-8x2B">MiniCPM-MoE-8x2B</a> 和 <a href="https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16">MiniCPM-1B</a>！点击<a href="https://openbmb.vercel.app/?category=Chinese+Blog">这里</a>查看技术博客。</li> 
 <li>[2024.03.16] MiniCPM-2B 的 30 余个中间检查点开放了！<a href="https://huggingface.co/openbmb/MiniCPM-2B-history">HuggingFace链接</a></li> 
 <li>[2024.02.01] 发布 <a href="https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16"><strong>MiniCPM-2B</strong></a>！该模型在公开评测集上与 Mistral-7B 表现相近（中文、数学、代码能力更优），整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。</li> 
</ul> 
<h2>目录</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD">模型下载</a></li> 
 <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#minicpm-30">MiniCPM 3.0</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C">评测结果</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E7%BB%BC%E5%90%88%E8%AF%84%E6%B5%8B">综合评测</a></li> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%E8%83%BD%E5%8A%9B">工具调用能力</a></li> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E9%95%BF%E6%96%87%E6%9C%AC%E8%83%BD%E5%8A%9B">长文本能力</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">模型推理</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#huggingface">HuggingFace</a></li> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#vllm">vLLM</a></li> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#llamacpp">llama.cpp</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83">模型微调</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#llama-factory">LLaMA-Factory</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E8%BF%9B%E9%98%B6%E5%8A%9F%E8%83%BD">进阶功能</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8">工具调用</a></li> 
     <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8">代码解释器</a></li> 
    </ul> </li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#minicpm-20">MiniCPM 2.0</a></li> 
 <li><a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#minicpm-10">MiniCPM 1.0</a></li> 
</ul> 
<h2>模型下载</h2> 
<table> 
 <thead> 
  <tr> 
   <th>HuggingFace</th> 
   <th>ModelScope</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM3-4B">MiniCPM3-4B</a></td> 
   <td><a href="https://www.modelscope.cn/models/OpenBMB/MiniCPM3-4B">MiniCPM3-4B</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16">MiniCPM-2B-sft</a></td> 
   <td><a href="https://modelscope.cn/models/OpenBMB/miniCPM-bf16">MiniCPM-2B-sft</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16">MiniCPM-2B-dpo</a></td> 
   <td><a href="https://modelscope.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16/summary">MiniCPM-2B-dpo</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM-2B-128k">MiniCPM-2B-128k</a></td> 
   <td><a href="https://modelscope.cn/models/openbmb/MiniCPM-2B-128k/summary">MiniCPM-2B-128k</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM-MoE-8x2B">MiniCPM-MoE-8x2B</a></td> 
   <td><a href="https://modelscope.cn/models/OpenBMB/MiniCPM-MoE-8x2B">MiniCPM-MoE-8x2B</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16">MiniCPM-1B</a></td> 
   <td><a href="https://modelscope.cn/models/OpenBMB/MiniCPM-1B-sft-bf16">MiniCPM-1B</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/openbmb/MiniCPM-S-1B-sft">MiniCPM-S-1B</a></td> 
   <td><a href="https://modelscope.cn/models/OpenBMB/MiniCPM-S-1B-sft">MiniCPM-S-1B</a></td> 
  </tr> 
 </tbody> 
</table> 
<p>注: 更多模型版本见<a href="https://huggingface.co/collections/openbmb/minicpm-2b-65d48bf958302b9fd25b698f">这里</a>。</p> 
<h2>MiniCPM 3.0</h2> 
<p>MiniCPM 3.0 是一个 4B 参数量的语言模型，相比 MiniCPM1.0/2.0，功能更加全面，综合能力大幅提升，多数评测集上的效果比肩甚至超越众多 7B-9B 模型。</p> 
<ul> 
 <li><strong>支持工具调用🛠️（Function Calling）和代码解释器💻（Code Interpreter）</strong>：<a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function Calling Leaderboard (BFCL)</a> 上取得 9B 规模以下 SOTA，超越 GLM-4-9B-Chat、Qwen2-7B-Instruct。</li> 
 <li><strong>超强的推理能力🧮</strong>：数学能力方面，<a href="https://open-compass.github.io/MathBench/">MathBench</a> 上的效果超越 GPT-3.5-Turbo 以及多个 7B-9B 模型。在非常具有挑战性的 <a href="https://livecodebench.github.io/">LiveCodeBench</a> 上，效果超越 Llama3.1-8B-Instruct。</li> 
 <li><strong>出色的中英文指令遵循能力🤖</strong>：英文指令遵循 <a href="https://huggingface.co/datasets/google/IFEval">IFEval</a>、中文指令遵循 <a href="https://huggingface.co/datasets/YuxinJiang/FollowBench">FollowBench-zh</a> 效果超越 GLM-4-9B-Chat、Qwen2-7B-Instruct。</li> 
 <li><strong>长文本能力</strong>：原生支持 32k 上下文长度，32k 长度内大海捞针全绿。提出 <strong>LLM x MapReduce</strong> ，理论可处理的上下文长度达到 +∞。</li> 
 <li><strong>RAG能力</strong>：我们发布了 <a href="https://huggingface.co/collections/openbmb/minicpm-rag-suite-66d976b4204cd0a4f8beaabb">MiniCPM RAG 套件</a>。基于 MiniCPM 系列模型的 <a href="https://huggingface.co/openbmb/MiniCPM-Embedding">MiniCPM-Embedding</a>、<a href="https://huggingface.co/openbmb/MiniCPM-Reranker">MiniCPM-Reranker</a> 在中文、中英跨语言检索测试中取得 SOTA 表现；针对 RAG 场景的 <a href="https://huggingface.co/openbmb/MiniCPM3-RAG-LoRA">MiniCPM3-RAG-LoRA</a> 在开放域问答等多项任务上超越 Llama3-8B、Baichuan2-13B 等模型。</li> 
</ul> 
<h3>评测结果</h3> 
<h4>综合评测</h4> 
<table> 
 <tbody>
  <tr> 
   <td>评测集</td> 
   <td>Qwen2-7B-Instruct</td> 
   <td>GLM-4-9B-Chat</td> 
   <td>Gemma2-9B-it</td> 
   <td>Llama3.1-8B-Instruct</td> 
   <td>GPT-3.5-Turbo-0125</td> 
   <td>Phi-3.5-mini-Instruct(3.8B)</td> 
   <td>MiniCPM3-4B </td> 
  </tr> 
  <tr> 
   <td align="left" colspan="15"><strong>英文能力</strong></td> 
  </tr> 
  <tr> 
   <td>MMLU</td> 
   <td>70.5</td> 
   <td>72.4</td> 
   <td>72.6</td> 
   <td>69.4</td> 
   <td>69.2</td> 
   <td>68.4</td> 
   <td>67.2 </td> 
  </tr> 
  <tr> 
   <td>BBH</td> 
   <td>64.9</td> 
   <td>76.3</td> 
   <td>65.2</td> 
   <td>67.8</td> 
   <td>70.3</td> 
   <td>68.6</td> 
   <td>70.2 </td> 
  </tr> 
  <tr> 
   <td>MT-Bench</td> 
   <td>8.41</td> 
   <td>8.35</td> 
   <td>7.88</td> 
   <td>8.28</td> 
   <td>8.17</td> 
   <td>8.60</td> 
   <td>8.41 </td> 
  </tr> 
  <tr> 
   <td>IFEVAL (Prompt Strict-Acc.)</td> 
   <td>51.0</td> 
   <td>64.5</td> 
   <td>71.9</td> 
   <td>71.5</td> 
   <td>58.8</td> 
   <td>49.4</td> 
   <td>68.4 </td> 
  </tr> 
  <tr> 
   <td align="left" colspan="15"><strong>中文能力</strong></td> 
  </tr> 
  <tr> 
   <td>CMMLU</td> 
   <td>80.9</td> 
   <td>71.5</td> 
   <td>59.5</td> 
   <td>55.8</td> 
   <td>54.5</td> 
   <td>46.9</td> 
   <td>73.3 </td> 
  </tr> 
  <tr> 
   <td>CEVAL</td> 
   <td>77.2</td> 
   <td>75.6</td> 
   <td>56.7</td> 
   <td>55.2</td> 
   <td>52.8</td> 
   <td>46.1</td> 
   <td>73.6 </td> 
  </tr> 
  <tr> 
   <td>AlignBench v1.1</td> 
   <td>7.10</td> 
   <td>6.61</td> 
   <td>7.10</td> 
   <td>5.68</td> 
   <td>5.82</td> 
   <td>5.73</td> 
   <td>6.74 </td> 
  </tr> 
  <tr> 
   <td>FollowBench-zh (SSR)</td> 
   <td>63.0</td> 
   <td>56.4</td> 
   <td>57.0</td> 
   <td>50.6</td> 
   <td>64.6</td> 
   <td>58.1</td> 
   <td>66.8 </td> 
  </tr> 
  <tr> 
   <td align="left" colspan="15"><strong>数学能力</strong></td> 
  </tr> 
  <tr> 
   <td>MATH</td> 
   <td>49.6</td> 
   <td>50.6</td> 
   <td>46.0</td> 
   <td>51.9</td> 
   <td>41.8</td> 
   <td>46.4</td> 
   <td>46.6 </td> 
  </tr> 
  <tr> 
   <td>GSM8K</td> 
   <td>82.3</td> 
   <td>79.6</td> 
   <td>79.7</td> 
   <td>84.5</td> 
   <td>76.4</td> 
   <td>82.7</td> 
   <td>81.1 </td> 
  </tr> 
  <tr> 
   <td>MathBench</td> 
   <td>63.4</td> 
   <td>59.4</td> 
   <td>45.8</td> 
   <td>54.3</td> 
   <td>48.9</td> 
   <td>54.9</td> 
   <td>65.6 </td> 
  </tr> 
  <tr> 
   <td align="left" colspan="15"><strong>代码能力</strong></td> 
  </tr> 
  <tr> 
   <td>HumanEval+</td> 
   <td>70.1</td> 
   <td>67.1</td> 
   <td>61.6</td> 
   <td>62.8</td> 
   <td>66.5</td> 
   <td>68.9</td> 
   <td>68.3 </td> 
  </tr> 
  <tr> 
   <td>MBPP+</td> 
   <td>57.1</td> 
   <td>62.2</td> 
   <td>64.3</td> 
   <td>55.3</td> 
   <td>71.4</td> 
   <td>55.8</td> 
   <td>63.2 </td> 
  </tr> 
  <tr> 
   <td>LiveCodeBench v3</td> 
   <td>22.2</td> 
   <td>20.2</td> 
   <td>19.2</td> 
   <td>20.4</td> 
   <td>24.0</td> 
   <td>19.6</td> 
   <td>22.6 </td> 
  </tr> 
  <tr> 
   <td align="left" colspan="15"><strong>工具调用能力</strong></td> 
  </tr> 
  <tr> 
   <td>BFCL v2</td> 
   <td>71.6</td> 
   <td>70.1</td> 
   <td>19.2</td> 
   <td>73.3</td> 
   <td>75.4</td> 
   <td>48.4</td> 
   <td>76.0 </td> 
  </tr> 
  <tr> 
   <td align="left" colspan="15"><strong>综合能力</strong></td> 
  </tr> 
  <tr> 
   <td>平均分</td> 
   <td>65.3</td> 
   <td>65.0</td> 
   <td>57.9</td> 
   <td>60.8</td> 
   <td>61.0</td> 
   <td>57.2</td> 
   <td><strong>66.3</strong></td> 
  </tr> 
 </tbody>
</table> 
<h4>工具调用能力</h4> 
<p>我们在 <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function Calling Leaderboard (BFCL)</a> 上测试了模型的工具调用能力，MiniCPM3-4B 在该榜单上的表现超越了多个 7B-9B 参数量的模型，优于 GPT-3.5-Turbo-0125。</p> 
<table> 
 <tbody>
  <tr> 
   <td>模型</td> 
   <td>总体准确率</td> 
   <td>AST Summary</td> 
   <td>Exec Summary</td> 
   <td>Irrelevance Detection</td> 
   <td>Relevance Detection </td> 
  </tr> 
  <tr> 
   <td>MiniCPM3-4B</td> 
   <td>76.03%</td> 
   <td>68.55%</td> 
   <td>85.54%</td> 
   <td>53.71%</td> 
   <td>90.24% </td> 
  </tr> 
  <tr> 
   <td>Llama3.1-8B-Instruct</td> 
   <td>73.28%</td> 
   <td>64.61%</td> 
   <td>86.48%</td> 
   <td>43.12%</td> 
   <td>85.37% </td> 
  </tr> 
  <tr> 
   <td>Qwen2-7B-Instruct</td> 
   <td>71.61%</td> 
   <td>65.71%</td> 
   <td>79.57%</td> 
   <td>44.70%</td> 
   <td>90.24% </td> 
  </tr> 
  <tr> 
   <td>GLM-4-9B-Chat</td> 
   <td>70.08%</td> 
   <td>60.69%</td> 
   <td>80.02%</td> 
   <td>55.02%</td> 
   <td>82.93% </td> 
  </tr> 
  <tr> 
   <td>Phi-3.5-mini-instruct</td> 
   <td>48.44%</td> 
   <td>38.89%</td> 
   <td>54.04%</td> 
   <td>46.78%</td> 
   <td>65.85% </td> 
  </tr> 
  <tr> 
   <td>Gemma2-9B-it</td> 
   <td>19.18%</td> 
   <td>5.41%</td> 
   <td>18.50%</td> 
   <td>88.88%</td> 
   <td>7.32%</td> 
  </tr> 
 </tbody>
</table> 
<h4>长文本能力</h4> 
<p>在 32k 的上下文长度进行<a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack">大海捞针</a>测试，结果如下图：</p> 
<p><img alt="needle" src="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/eval_needle.jpeg" /></p> 
<h3>模型推理</h3> 
<h4>Huggingface</h4> 
<pre><code class="language-python">from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
torch.manual_seed(0)

path = 'openbmb/MiniCPM3-4B'
tokenizer = AutoTokenizer.from_pretrained(path)
model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map='cuda', trust_remote_code=True)

responds, history = model.chat(tokenizer, "请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。", temperature=0.7, top_p=0.7)
print(responds)
</code></pre> 
<h4>vLLM</h4> 
<ul> 
 <li>安装 vllm <pre><code class="language-shell">pip install git+https://github.com/OpenBMB/vllm.git@minicpm3
</code></pre> </li> 
 <li>推理 <pre><code class="language-python">from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

model_name = "openbmb/MiniCPM3-4B"
prompt = [{"role": "user", "content": "请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。"}]

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
input_text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)

llm = LLM(model=model_name,
    trust_remote_code=True,
    tensor_parallel_size=1
)
sampling_params = SamplingParams(top_p=0.7, temperature=0.7, max_tokens=1024)

outputs = llm.generate(prompts=input_text, sampling_params=sampling_params)

print(outputs[0].outputs[0].text)
</code></pre> </li> 
</ul> 
<h4>llama.cpp</h4> 
<ul> 
 <li>安装 llama.cpp <pre><code class="language-shell">  git clone https://github.com/OpenBMB/llama.cpp.git
  cd llama.cpp
  git checkout minicpm3    
  make 
</code></pre> </li> 
 <li>创建模型目录 <pre><code class="language-shell">  cd llama.cpp/models
  mkdir Minicpm3
</code></pre> </li> 
 <li>下载 MiniCPM3 模型所有文件到 <code>llama.cpp/models/Minicpm3</code> <pre><code class="language-shell">  cd llama.cpp/models/Minicpm3
  git clone https://huggingface.co/openbmb/MiniCPM3-4B
</code></pre> </li> 
 <li>将模型转换为 gguf 格式，并且量化： <pre><code class="language-python">python3 -m pip install -r requirements.txt
# 将pytorch模型转化为fp16的gguf
python3 convert_hf_to_gguf.py models/Minicpm3/MiniCPM3-4B --outfile ./models/Minicpm3/CPM-4B-F16.gguf
# 完成以上步骤，llama.cpp/models/Minicpm3目录下有一个CPM-4B-F16.gguf的模型文件
./llama-quantize ./models/Minicpm3/CPM-4B-F16.gguf ./models/Minicpm3/ggml-model-Q4_K_M.gguf Q4_K_M
# 使用本行代码执行成功后，./models/Minicpm3下将存在ggml-model-Q4_K_M.gguf的4bit量化文件
</code></pre> </li> 
 <li>推理 <pre><code class="language-shell">./llama-cli -c 1024 -m ./models/Minicpm/ggml-model-Q4_K_M.gguf -n 1024 --top-p 0.7 --temp 0.7 --prompt "&lt;|im_start|&gt;user\n请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n"
</code></pre> </li> 
</ul> 
<h3>模型微调</h3> 
<h4>LLaMA-Factory</h4> 
<p>目前模型微调支持 <a href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factory</a>，使用方法参考 <a href="https://modelbest.feishu.cn/docx/Z7USdW4lloZzkZxQ14icJ3senjb?from=from_copylink">LLaMA-Factory 微调</a>。</p> 
<h3>进阶功能</h3> 
<p>对于以下进阶功能，我们推荐使用 <a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#vllm">vLLM</a>。</p> 
<h4>工具调用</h4> 
<p>我们提供了使用 MiniCPM3 调用工具的示例代码：</p> 
<pre><code class="language-bash">cd demo/minicpm3/function_call
python function_call.py
</code></pre> 
<p>如果你想启动一个能够调用工具的推理服务，使用以下代码：</p> 
<pre><code class="language-bash">cd demo/minicpm3/function_call
pip install -r requirements.txt
python openai_api_server.py \
    --model openbmb/MiniCPM3-4B \
    --served-model-name MiniCPM3-4B \
    --chat-template chatml.jinja \
    --dtype auto \
    --api-key token-abc123 \
    --tensor-parallel-size 1 \
    --trust-remote-code
</code></pre> 
<p>下面是一个调用搜索工具回答问题的演示：</p> 
<p><img alt="function_call" src="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/function_call.gif" /></p> 
<h4>代码解释器</h4> 
<p>我们提供了一个 MiniCPM3 使用代码解释器的示例代码：</p> 
<pre><code class="language-bash">cd demo/minicpm3/code_interpreter
pip install -r requirements.txt
python code_interpreter.py openbmb/MiniCPM3-4B
</code></pre> 
<p>下面是一个使用代码解释器生成二维码的演示：</p> 
<p><img alt="code_interpreter" src="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/code_interpreter.gif" /></p> 
<h2>MiniCPM 2.0</h2> 
<details> 
 查看 MiniCPM 2.0 的详细信息 
 <p>MiniCPM 2.0 系列模型对 MiniCPM 进行了多个维度的升级，包括以下模型版本：</p> 
 <ul> 
  <li>MiniCPM-2B-128k：将 MiniCPM-2B 的上下文长度从 4k 扩展至 128k，在 InfiniteBench 测试集上优于 ChatGLM3-6B-128k、Yi-6B-200k 等更大参数量的模型。</li> 
  <li>MiniCPM-MoE-8x2B：基于 MiniCPM-2B 进行 MoE 扩展，综合表现相比于 MiniCPM-2B 平均提高 4.5 个百分点。</li> 
  <li>MiniCPM-1B：相比于 MiniCPM-2B 成本下降 60%，综合表现仍然优于 LLaMA2-13B。</li> 
  <li>MiniCPM-S-1B：在保持下游任务性能无损的前提下，FFN 层实现了 87.89% 的平均稀疏度，将 FFN FLOPs 降低了 84%。结合 PowerInfer 推理框架，解码速度提升约 2.8 倍。</li> 
 </ul> 
 <h3>评测结果</h3> 
 <h4>MiniCPM-2B-128k 模型评测</h4> 
 <table> 
  <thead> 
   <tr> 
    <th>Model</th> 
    <th>avg</th> 
    <th>avg w/o code&amp;math</th> 
    <th>passkey</th> 
    <th>number_string</th> 
    <th>kv_retrieval</th> 
    <th>longbook_choice_eng</th> 
    <th>longbook_qa_chn</th> 
    <th>longbook_qa_eng</th> 
    <th>longbook_sum_eng</th> 
    <th>longdialogue_qa_eng</th> 
    <th>math_calc</th> 
    <th>math_find</th> 
    <th>code_debug</th> 
    <th>code_run</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>LWM-Text-128k</td> 
    <td>24.45</td> 
    <td>33.62</td> 
    <td>100</td> 
    <td>97.8</td> 
    <td>0.6</td> 
    <td>28.82</td> 
    <td>15.93</td> 
    <td>14.31</td> 
    <td>9.99</td> 
    <td>1.5</td> 
    <td>0</td> 
    <td>3.43</td> 
    <td>20.05</td> 
    <td>1</td> 
   </tr> 
   <tr> 
    <td>Yarn-Mistral-7b-128k</td> 
    <td>19.84</td> 
    <td>27.36</td> 
    <td>92.71</td> 
    <td></td> 
    <td>0</td> 
    <td>27.95</td> 
    <td>15.49</td> 
    <td>9.55</td> 
    <td>9.06</td> 
    <td>7.5</td> 
    <td>0</td> 
    <td>17.14</td> 
    <td>0.76</td> 
    <td>1.25</td> 
   </tr> 
   <tr> 
    <td>Mistral-7B-Instruct-v0.2(ABF 1000w)</td> 
    <td>27.75</td> 
    <td>36.9</td> 
    <td>100</td> 
    <td>78.98</td> 
    <td>3.6</td> 
    <td>37.12</td> 
    <td>11.74</td> 
    <td>17.37</td> 
    <td>21.12</td> 
    <td>9.5</td> 
    <td>0</td> 
    <td>29.43</td> 
    <td>17.51</td> 
    <td>0</td> 
   </tr> 
   <tr> 
    <td>Yi-6B-200k</td> 
    <td>22.15</td> 
    <td>32.54</td> 
    <td>100</td> 
    <td>94.92</td> 
    <td>0</td> 
    <td>36.68</td> 
    <td>15.07</td> 
    <td>9.2</td> 
    <td>0.92</td> 
    <td>3.5</td> 
    <td>0</td> 
    <td>4.29</td> 
    <td>0.51</td> 
    <td>0.75</td> 
   </tr> 
   <tr> 
    <td>chatglm3-6b-128k</td> 
    <td>25.58</td> 
    <td>36.57</td> 
    <td>89.93</td> 
    <td>99.66</td> 
    <td>5.2</td> 
    <td>46.29</td> 
    <td>10.7</td> 
    <td>8.38</td> 
    <td>25.91</td> 
    <td>6.5</td> 
    <td>0</td> 
    <td>8</td> 
    <td>5.33</td> 
    <td>1</td> 
   </tr> 
   <tr> 
    <td>MiniCPM-2.4B-128k</td> 
    <td>27.32</td> 
    <td>37.68</td> 
    <td>98.31</td> 
    <td>99.83</td> 
    <td>9</td> 
    <td>29.69</td> 
    <td>23.06</td> 
    <td>16.33</td> 
    <td>15.73</td> 
    <td>9.5</td> 
    <td>0</td> 
    <td>4.29</td> 
    <td>22.08</td> 
    <td>0</td> 
   </tr> 
  </tbody> 
 </table> 
 <h4>MiniCPM-MoE-8x2B 模型评测</h4> 
 <div align="left"> 
  <table style="margin: 0px auto;"> 
   <thead> 
    <tr> 
     <th align="left">Model</th> 
     <th nowrap="nowrap">BBH</th> 
     <th nowrap="nowrap">MMLU</th> 
     <th nowrap="nowrap">CEval</th> 
     <th nowrap="nowrap">CMMLU</th> 
     <th nowrap="nowrap">HumanEval</th> 
     <th nowrap="nowrap">MBPP†</th> 
     <th nowrap="nowrap">GSM8K</th> 
     <th nowrap="nowrap">MATH</th> 
    </tr>
   </thead> 
   <tbody align="center"> 
    <tr> 
     <td align="left" nowrap="nowrap">Llama2-34B*</td> 
     <td>44.1</td> 
     <td>62.6</td> 
     <td>-</td> 
     <td>-</td> 
     <td>22.6</td> 
     <td>33.0</td> 
     <td>42.2</td> 
     <td>6.24</td> 
    </tr> 
    <tr> 
     <td align="left" nowrap="nowrap">Mistral-7B-Instruct-v0.2</td> 
     <td>39.81</td> 
     <td>60.51</td> 
     <td>42.55</td> 
     <td>41.92</td> 
     <td>36.59</td> 
     <td>39.63</td> 
     <td>40.49</td> 
     <td>4.95</td> 
    </tr> 
    <tr> 
     <td align="left" nowrap="nowrap">Gemma-7B*</td> 
     <td>55.1</td> 
     <td>64.3</td> 
     <td>-</td> 
     <td>-</td> 
     <td>32.3</td> 
     <td>44.4</td> 
     <td>46.4</td> 
     <td>24.3</td> 
    </tr> 
    <tr> 
     <td align="left" nowrap="nowrap">Qwen1.5-7B*</td> 
     <td>40.2</td> 
     <td>61</td> 
     <td>74.1</td> 
     <td>73.1</td> 
     <td>36</td> 
     <td>37.4</td> 
     <td>62.5</td> 
     <td>20.3</td> 
    </tr> 
    <tr> 
     <td align="left" nowrap="nowrap">Deepseek-MoE(16B)*</td> 
     <td>-</td> 
     <td>45.0</td> 
     <td>40.6</td> 
     <td>42.5</td> 
     <td>26.8</td> 
     <td>39.2</td> 
     <td>18.8</td> 
     <td>4.3</td> 
    </tr> 
    <tr> 
     <td align="left" nowrap="nowrap"><b>MiniCPM-2.4B</b></td> 
     <td>36.87</td> 
     <td>53.46</td> 
     <td>51.13</td> 
     <td>51.07</td> 
     <td>50.00</td> 
     <td>35.93</td> 
     <td>53.83</td> 
     <td>10.24</td> 
    </tr> 
    <tr> 
     <td align="left" nowrap="nowrap"><b>MiniCPM-MoE-8x2B</b></td> 
     <td>39.22</td> 
     <td>58.90</td> 
     <td>58.11</td> 
     <td>58.80</td> 
     <td>55.49</td> 
     <td>41.68</td> 
     <td>61.56</td> 
     <td>10.52</td> 
    </tr> 
   </tbody> 
  </table> 
 </div> 
 <p>注：* 表示结果取自技术报告。† 表示评测集为MBPP全集。</p> 
 <h4>MiniCPM-S-1B 评测结果</h4> 
 <ul> 
  <li>代码生成：在 HumanEval（0-shot）和 MBPP（3-shot）上的平均 pass@1 得分。</li> 
  <li>常识推理：在 PIQA、SIQA、HellaSwag、WinoGrande 和 COPA 上的平均 0-shot 准确率。</li> 
  <li>阅读理解：在 BoolQ、LAMBADA 和 TyDi QA 上的平均 0-shot 准确率。</li> 
 </ul> 
 <p>其他测试集：我们报告在GSM8K（8-shot）、MMLU（5-shot）、BBH（3-shot）和 AGI-Eval（0-shot）上的平均准确率。</p> 
 <table> 
  <thead> 
   <tr> 
    <th align="center">Setting</th> 
    <th align="center">Average<br />Sparsity</th> 
    <th align="center">Average<br />Performance</th> 
    <th align="center">Code<br />Generation</th> 
    <th align="center">Commonsense<br />Reasoning</th> 
    <th align="center">Reading<br />Comprehension</th> 
    <th align="center">GSM8K</th> 
    <th align="center">MMLU</th> 
    <th align="center">BBH</th> 
    <th align="center">AGI Eval</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td align="center">LLaMA2-7B</td> 
    <td align="center">-</td> 
    <td align="center">37.96</td> 
    <td align="center">16.37</td> 
    <td align="center">69.59</td> 
    <td align="center">61.87</td> 
    <td align="center">12.96</td> 
    <td align="center">44.45</td> 
    <td align="center">32.96</td> 
    <td align="center">27.53</td> 
   </tr> 
   <tr> 
    <td align="center">ReluLLaMA-7B</td> 
    <td align="center">66.98</td> 
    <td align="center">37.62</td> 
    <td align="center">15.85</td> 
    <td align="center">69.64</td> 
    <td align="center">70.54</td> 
    <td align="center">5.84</td> 
    <td align="center">38.64</td> 
    <td align="center">35.07</td> 
    <td align="center">27.73</td> 
   </tr> 
   <tr> 
    <td align="center"><strong>ProSparse-7B</strong>*</td> 
    <td align="center">88.11</td> 
    <td align="center">38.31</td> 
    <td align="center">19.47</td> 
    <td align="center">66.29</td> 
    <td align="center">63.33</td> 
    <td align="center">12.74</td> 
    <td align="center">45.21</td> 
    <td align="center">33.59</td> 
    <td align="center">27.55</td> 
   </tr> 
   <tr> 
    <td align="center"><strong>ProSparse-7B</strong></td> 
    <td align="center"><strong>89.32</strong></td> 
    <td align="center"><strong>38.46</strong></td> 
    <td align="center">19.42</td> 
    <td align="center">66.27</td> 
    <td align="center">63.50</td> 
    <td align="center">12.13</td> 
    <td align="center">45.48</td> 
    <td align="center">34.99</td> 
    <td align="center">27.46</td> 
   </tr> 
   <tr> 
    <td align="center">LLaMA2-13B</td> 
    <td align="center">-</td> 
    <td align="center">44.06</td> 
    <td align="center">20.19</td> 
    <td align="center">72.58</td> 
    <td align="center">71.55</td> 
    <td align="center">22.21</td> 
    <td align="center">54.69</td> 
    <td align="center">37.89</td> 
    <td align="center">29.33</td> 
   </tr> 
   <tr> 
    <td align="center">ReluLLaMA-13B</td> 
    <td align="center">71.56</td> 
    <td align="center">42.74</td> 
    <td align="center">20.19</td> 
    <td align="center">70.44</td> 
    <td align="center">73.29</td> 
    <td align="center">18.50</td> 
    <td align="center">50.58</td> 
    <td align="center">37.97</td> 
    <td align="center">28.22</td> 
   </tr> 
   <tr> 
    <td align="center"><strong>ProSparse-13B</strong>*</td> 
    <td align="center">87.97</td> 
    <td align="center"><strong>45.07</strong></td> 
    <td align="center">29.03</td> 
    <td align="center">69.75</td> 
    <td align="center">67.54</td> 
    <td align="center">25.40</td> 
    <td align="center">54.78</td> 
    <td align="center">40.20</td> 
    <td align="center">28.76</td> 
   </tr> 
   <tr> 
    <td align="center"><strong>ProSparse-13B</strong></td> 
    <td align="center"><strong>88.80</strong></td> 
    <td align="center">44.90</td> 
    <td align="center">28.42</td> 
    <td align="center">69.76</td> 
    <td align="center">66.91</td> 
    <td align="center">26.31</td> 
    <td align="center">54.35</td> 
    <td align="center">39.90</td> 
    <td align="center">28.67</td> 
   </tr> 
   <tr> 
    <td align="center">MiniCPM-1B</td> 
    <td align="center">-</td> 
    <td align="center">44.44</td> 
    <td align="center">36.85</td> 
    <td align="center">63.67</td> 
    <td align="center">60.90</td> 
    <td align="center">35.48</td> 
    <td align="center">50.44</td> 
    <td align="center">35.03</td> 
    <td align="center">28.71</td> 
   </tr> 
   <tr> 
    <td align="center"><strong>MiniCPM-S-1B</strong>*</td> 
    <td align="center">86.25</td> 
    <td align="center"><strong>44.72</strong></td> 
    <td align="center">41.38</td> 
    <td align="center">64.55</td> 
    <td align="center">60.69</td> 
    <td align="center">34.72</td> 
    <td align="center">49.36</td> 
    <td align="center">34.04</td> 
    <td align="center">28.27</td> 
   </tr> 
   <tr> 
    <td align="center"><strong>MiniCPM-S-1B</strong></td> 
    <td align="center"><strong>87.89</strong></td> 
    <td align="center"><strong>44.72</strong></td> 
    <td align="center">42.04</td> 
    <td align="center">64.37</td> 
    <td align="center">60.73</td> 
    <td align="center">34.57</td> 
    <td align="center">49.51</td> 
    <td align="center">34.08</td> 
    <td align="center">27.77</td> 
   </tr> 
  </tbody> 
 </table> 
 <p>注：</p> 
 <ol> 
  <li>ReluLLaMA-7B 和 ReluLLaMA-13B 的下载链接分别是 <a href="https://huggingface.co/SparseLLM/ReluLLaMA-7B">7B</a> and <a href="https://huggingface.co/SparseLLM/ReluLLaMA-13B">13B</a>。"ProSparse-7B*"、"ProSparse-13B*" 和 "MiniCPM-S-1B*" 代表没有激活阈值偏移的 ProSparse 版本。</li> 
  <li>对于 PIQA、SIQA、HellaSwag、WinoGrande、COPA、BoolQ、LAMBADA、TyDi QA 和 AGI-Eval，我们根据各个选项的 PPL 来进行答案选择。对于 GSM8K、MMLU 和 BBH，我们直接生成答案。</li> 
 </ol> 
 <h3>模型推理</h3> 
 <h4>HuggingFace、vLLM推理</h4> 
 <p>参考 MiniCPM 1.0 中的<a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#huggingface-%E6%8E%A8%E7%90%86">模型推理</a>部分。</p> 
 <h4>Powerinfer 推理</h4> 
 <p>针对 MiniCPM-S-1B 模型，我们可以使用 Powerinfer 进行推理加速，使用方法如下：</p> 
 <ol> 
  <li>保证cmake版本3.17以上，如果已经安装过，则跳过此步骤</li> 
 </ol> 
 <pre><code class="language-bash">  # 下载安装包
  sudo wget https://cmake.org/files/v3.23/cmake-3.23.0.tar.gz
  # 解压安装包
  sudo tar -zxvf cmake-3.23.0.tar.gz
  # 配置安装环境
  sudo ./configure
  sudo make -j8
  # 编译安装
  sudo make install
  # 查看安装后版本
  cmake --version
  # 返回版本号则安装成功
  #cmake version 3.23.0
</code></pre> 
 <ol start="2"> 
  <li>安装powerinfer：</li> 
 </ol> 
 <pre><code class="language-bash">  git clone https://github.com/SJTU-IPADS/PowerInfer
  cd PowerInfer
  pip install -r requirements.txt # install Python helpers' dependencies
</code></pre> 
 <ol start="3"> 
  <li>cpu版本powerinfer编译,如果你的机器只有cpu，或者只想使用cpu进行推理，则运行以下命令：</li> 
 </ol> 
 <pre><code class="language-bash">  cmake -S . -B build
  cmake --build build --config Release
</code></pre> 
 <ol start="4"> 
  <li>gpu版本powerinfer编译,如果你的机器有gpu，则可以运行以下命令：</li> 
 </ol> 
 <pre><code class="language-bash">  cmake -S . -B build -DLLAMA_CUBLAS=ON
  cmake --build build --config Release
</code></pre> 
 <ol start="5"> 
  <li>获取稀疏模型</li> 
 </ol> 
 <pre><code class="language-bash">git clone https://huggingface.co/openbmb/MiniCPM-S-1B-sft-gguf/tree/main
#or
git clone https://modelscope.cn/models/OpenBMB/MiniCPM-S-1B-sft-gguf
</code></pre> 
 <ol start="6"> 
  <li>模型推理：</li> 
 </ol> 
 <pre><code class="language-bash">cd PowerInfer
# 以下是命令模版，output_token_count为最大输出tokens，thread_num 为线程数，prompt为输入prompt字符
#./build/bin/main -m /PATH/TO/MODEL -n $output_token_count -t $thread_num -p $prompt
# 以下是示例
./build/bin/main -m /root/ld/ld_model_pretrain/1b-s-minicpm/MiniCPM-S-1B-sft.gguf -n 2048 -t 8 -p '&lt;用户&gt;hello,tell me a story please.&lt;AI&gt;'
</code></pre> 
</details> 
<h2>MiniCPM 1.0</h2> 
<details> 
 查看 MiniCPM 1.0 的详细信息 
 <p>MiniCPM-2B 语言模型有 24亿（2.4B）的非词嵌入参数量, 总计 2.7B 参数量。</p> 
 <ul> 
  <li>经过 SFT 后，MiniCPM-2B 在公开评测集上与 Mistral-7B 表现相近（中文、数学、代码能力更优），整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。</li> 
  <li>经过 DPO 后，MiniCPM-2B 在 MTBench 上也超越了 Llama2-70B-Chat、Vicuna-33B、Mistral-7B-Instruct-v0.1、Zephyr-7B-alpha 等众多代表性开源大模型。</li> 
 </ul> 
 <p>注意：为了保证在学术研究用途上模型的通用性，我们<strong>未对 MiniCPM-2B 进行任何身份认同训练</strong>。同时由于我们用 ShareGPT 开源语料作为部分训练数据，模型可能会输出类似 GPT 系列模型的身份认同信息。</p> 
 <h3>评测结果</h3> 
 <h4>评测设置</h4> 
 <ul> 
  <li>由于大模型评测难以统一，且大量评测也没有公开的prompt和测试代码，对于具体评测方式，我们只能尽量做到适合各类模型。</li> 
  <li>整体而言，我们测试时采用统一的prompt输入，并按照各模型对应的模板进行输入调整。</li> 
  <li><strong>评测脚本及prompt已开源在我们的Github仓库中，也欢迎更多开发者来不断改进我们的评测方式。</strong> 
   <ul> 
    <li>文本评测部分，采用了我们的开源大模型能力评测框架<a href="https://github.com/OpenBMB/UltraEval">UltraEval</a>。以下为开源模型复现流程： 
     <ul> 
      <li>安装UltraEval <pre><code class="language-shell">git clone https://github.com/OpenBMB/UltraEval.git
cd UltraEval
pip install -e .
</code></pre> </li> 
      <li>下载相关数据并解压处理 <pre><code class="language-shell">wget -O RawData.zip "https://cloud.tsinghua.edu.cn/f/71b5232264ae4833a4d0/?dl=1"
unzip RawData.zip
python data_process.py
</code></pre> </li> 
      <li>执行评测脚本(提供了模板，可自定义) <pre><code class="language-shell">bash run_eval.sh
</code></pre> </li> 
     </ul> </li> 
   </ul> </li> 
 </ul> 
 <h4>部署模式</h4> 
 <ul> 
  <li>因为MiniCPM采用Mup的结构，与现有模型在具体计算上有细微差别，我们是基于vllm=0.2.2版本进行了我们模型的实现。</li> 
  <li><strong>对于非MiniCPM模型，我们采用了vllm=0.2.7的最新版本进行推理。</strong></li> 
 </ul> 
 <h4>评测度量</h4> 
 <ul> 
  <li>对于QA任务（选择题任务），我们选用两种方式进行测试： 
   <ul> 
    <li>PPL：将选项作为题目生成的延续，并根据各个选项的PPL来进行答案选择；</li> 
    <li>第二种是直接生成答案选项。</li> 
   </ul> </li> 
  <li>对于不同模型，这两种方式得到的结果差异较大。MiniCPM两种模式上的结果较为接近，而Mistral-7B-v0.1等模型在PPL上表现较好，直接生成上效果较差。</li> 
  <li>在具体评测时，我们以两种评测方式得分的最高者为最终结果，以此保证对比的公平性(以下表格中*号表示采用PPL)。</li> 
 </ul> 
 <h4>文本模型评测</h4> 
 <p><strong>越级比较:</strong></p> 
 <table> 
  <thead> 
   <tr> 
    <th>模型</th> 
    <th>平均分</th> 
    <th>英文均分</th> 
    <th>中文均分</th> 
    <th>C-Eval</th> 
    <th>CMMLU</th> 
    <th>MMLU</th> 
    <th>HumanEval</th> 
    <th>MBPP</th> 
    <th>GSM8K</th> 
    <th>MATH</th> 
    <th>BBH</th> 
    <th>ARC-E</th> 
    <th>ARC-C</th> 
    <th>HellaSwag</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>Llama2-7B</td> 
    <td>35.40</td> 
    <td>36.21</td> 
    <td>31.765</td> 
    <td>32.42</td> 
    <td>31.11</td> 
    <td>44.32</td> 
    <td>12.2</td> 
    <td>27.17</td> 
    <td>13.57</td> 
    <td>1.8</td> 
    <td>33.23</td> 
    <td>75.25</td> 
    <td>42.75</td> 
    <td>75.62*</td> 
   </tr> 
   <tr> 
    <td>Qwen-7B</td> 
    <td>49.46</td> 
    <td>47.19</td> 
    <td>59.655</td> 
    <td>58.96</td> 
    <td>60.35</td> 
    <td>57.65</td> 
    <td>17.07</td> 
    <td>42.15</td> 
    <td>41.24</td> 
    <td>5.34</td> 
    <td>37.75</td> 
    <td>83.42</td> 
    <td>64.76</td> 
    <td>75.32*</td> 
   </tr> 
   <tr> 
    <td>Deepseek-7B</td> 
    <td>39.96</td> 
    <td>39.15</td> 
    <td>43.64</td> 
    <td>42.82</td> 
    <td>44.45</td> 
    <td>47.82</td> 
    <td>20.12</td> 
    <td>41.45</td> 
    <td>15.85</td> 
    <td>1.53</td> 
    <td>33.38</td> 
    <td>74.58*</td> 
    <td>42.15*</td> 
    <td>75.45*</td> 
   </tr> 
   <tr> 
    <td>Mistral-7B</td> 
    <td>48.97</td> 
    <td>49.96</td> 
    <td>44.54</td> 
    <td>46.12</td> 
    <td>42.96</td> 
    <td>62.69</td> 
    <td>27.44</td> 
    <td>45.2</td> 
    <td>33.13</td> 
    <td>5.0</td> 
    <td>41.06</td> 
    <td>83.92</td> 
    <td>70.73</td> 
    <td>80.43*</td> 
   </tr> 
   <tr> 
    <td>Llama2-13B</td> 
    <td>41.48</td> 
    <td>42.44</td> 
    <td>37.19</td> 
    <td>37.32</td> 
    <td>37.06</td> 
    <td>54.71</td> 
    <td>17.07</td> 
    <td>32.55</td> 
    <td>21.15</td> 
    <td>2.25</td> 
    <td>37.92</td> 
    <td>78.87*</td> 
    <td>58.19</td> 
    <td>79.23*</td> 
   </tr> 
   <tr> 
    <td>MPT-30B</td> 
    <td>38.17</td> 
    <td>39.82</td> 
    <td>30.72</td> 
    <td>29.34</td> 
    <td>32.09</td> 
    <td>46.56</td> 
    <td>21.95</td> 
    <td>35.36</td> 
    <td>10.31</td> 
    <td>1.56</td> 
    <td>38.22</td> 
    <td>78.66*</td> 
    <td>46.08*</td> 
    <td>79.72*</td> 
   </tr> 
   <tr> 
    <td>Falcon-40B</td> 
    <td>43.62</td> 
    <td>44.21</td> 
    <td>40.93</td> 
    <td>40.29</td> 
    <td>41.57</td> 
    <td>53.53</td> 
    <td>24.39</td> 
    <td>36.53</td> 
    <td>22.44</td> 
    <td>1.92</td> 
    <td>36.24</td> 
    <td>81.94*</td> 
    <td>57.68</td> 
    <td>83.26*</td> 
   </tr> 
   <tr> 
    <td>MiniCPM-2B</td> 
    <td>52.33</td> 
    <td>52.6</td> 
    <td>51.1</td> 
    <td>51.13</td> 
    <td>51.07</td> 
    <td>53.46</td> 
    <td>50.00</td> 
    <td>47.31</td> 
    <td>53.83</td> 
    <td>10.24</td> 
    <td>36.87</td> 
    <td>85.44</td> 
    <td>68.00</td> 
    <td>68.25</td> 
   </tr> 
  </tbody> 
 </table> 
 <p><strong>同级比较：</strong></p> 
 <table> 
  <thead> 
   <tr> 
    <th>模型</th> 
    <th>平均分</th> 
    <th>英文均分</th> 
    <th>中文均分</th> 
    <th>C-Eval</th> 
    <th>CMMLU</th> 
    <th>MMLU</th> 
    <th>HumanEval</th> 
    <th>MBPP</th> 
    <th>GSM8K</th> 
    <th>MATH</th> 
    <th>BBH</th> 
    <th>ARC-E</th> 
    <th>ARC-C</th> 
    <th>HellaSwag</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>TinyLlama-1.1B</td> 
    <td>25.36</td> 
    <td>25.55</td> 
    <td>24.525</td> 
    <td>25.02</td> 
    <td>24.03</td> 
    <td>24.3</td> 
    <td>6.71</td> 
    <td>19.91</td> 
    <td>2.27</td> 
    <td>0.74</td> 
    <td>28.78</td> 
    <td>60.77*</td> 
    <td>28.15*</td> 
    <td>58.33*</td> 
   </tr> 
   <tr> 
    <td>Qwen-1.8B</td> 
    <td>34.72</td> 
    <td>31.87</td> 
    <td>47.57</td> 
    <td>49.81</td> 
    <td>45.32</td> 
    <td>43.37</td> 
    <td>7.93</td> 
    <td>17.80</td> 
    <td>19.26</td> 
    <td>2.42</td> 
    <td>29.07</td> 
    <td>63.97*</td> 
    <td>43.69</td> 
    <td>59.28*</td> 
   </tr> 
   <tr> 
    <td>Gemini Nano-3B</td> 
    <td>-</td> 
    <td>-</td> 
    <td>-</td> 
    <td>-</td> 
    <td>-</td> 
    <td>-</td> 
    <td>-</td> 
    <td>27.2(report)</td> 
    <td>22.8(report)</td> 
    <td>-</td> 
    <td>42.4(report)</td> 
    <td>-</td> 
    <td>-</td> 
    <td>-</td> 
   </tr> 
   <tr> 
    <td>StableLM-Zephyr-3B</td> 
    <td>43.46</td> 
    <td>46.31</td> 
    <td>30.62</td> 
    <td>30.34</td> 
    <td>30.89</td> 
    <td>45.9</td> 
    <td>35.37</td> 
    <td>31.85</td> 
    <td>52.54</td> 
    <td>12.49</td> 
    <td>37.68</td> 
    <td>73.78</td> 
    <td>55.38</td> 
    <td>71.87*</td> 
   </tr> 
   <tr> 
    <td>Phi-2-2B</td> 
    <td>48.84</td> 
    <td>54.41</td> 
    <td>23.78</td> 
    <td>23.37</td> 
    <td>24.18</td> 
    <td>52.66</td> 
    <td>47.56</td> 
    <td>55.04</td> 
    <td>57.16</td> 
    <td>3.5</td> 
    <td>43.39</td> 
    <td>86.11</td> 
    <td>71.25</td> 
    <td>73.07*</td> 
   </tr> 
   <tr> 
    <td>MiniCPM-2B</td> 
    <td>52.33</td> 
    <td>52.6</td> 
    <td>51.10</td> 
    <td>51.13</td> 
    <td>51.07</td> 
    <td>53.46</td> 
    <td>50.00</td> 
    <td>47.31</td> 
    <td>53.83</td> 
    <td>10.24</td> 
    <td>36.87</td> 
    <td>85.44</td> 
    <td>68.00</td> 
    <td>68.25</td> 
   </tr> 
  </tbody> 
 </table> 
 <p><strong>Chat模型比较：</strong></p> 
 <table> 
  <thead> 
   <tr> 
    <th>模型</th> 
    <th>平均分</th> 
    <th>英文均分</th> 
    <th>中文均分</th> 
    <th>C-Eval</th> 
    <th>CMMLU</th> 
    <th>MMLU</th> 
    <th>HumanEval</th> 
    <th>MBPP</th> 
    <th>GSM8K</th> 
    <th>MATH</th> 
    <th>BBH</th> 
    <th>ARC-E</th> 
    <th>ARC-C</th> 
    <th>HellaSwag</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>ChatGLM2-6B</td> 
    <td>37.98</td> 
    <td>35.17</td> 
    <td>50.63</td> 
    <td>52.05</td> 
    <td>49.21</td> 
    <td>45.77</td> 
    <td>10.37</td> 
    <td>9.38</td> 
    <td>22.74</td> 
    <td>5.96</td> 
    <td>32.6</td> 
    <td>74.45</td> 
    <td>56.82</td> 
    <td>58.48*</td> 
   </tr> 
   <tr> 
    <td>Mistral-7B-Instruct-v0.1</td> 
    <td>44.36</td> 
    <td>45.89</td> 
    <td>37.51</td> 
    <td>38.06</td> 
    <td>36.96</td> 
    <td>53.56</td> 
    <td>29.27</td> 
    <td>39.34</td> 
    <td>28.73</td> 
    <td>3.48</td> 
    <td>39.52</td> 
    <td>81.61</td> 
    <td>63.99</td> 
    <td>73.47*</td> 
   </tr> 
   <tr> 
    <td>Mistral-7B-Instruct-v0.2</td> 
    <td>50.91</td> 
    <td>52.83</td> 
    <td>42.235</td> 
    <td>42.55</td> 
    <td>41.92</td> 
    <td>60.51</td> 
    <td>36.59</td> 
    <td>48.95</td> 
    <td>40.49</td> 
    <td>4.95</td> 
    <td>39.81</td> 
    <td>86.28</td> 
    <td>73.38</td> 
    <td>84.55*</td> 
   </tr> 
   <tr> 
    <td>Qwen-7B-Chat</td> 
    <td>44.93</td> 
    <td>42.05</td> 
    <td>57.9</td> 
    <td>58.57</td> 
    <td>57.23</td> 
    <td>56.03</td> 
    <td>15.85</td> 
    <td>40.52</td> 
    <td>42.23</td> 
    <td>8.3</td> 
    <td>37.34</td> 
    <td>64.44*</td> 
    <td>39.25*</td> 
    <td>74.52*</td> 
   </tr> 
   <tr> 
    <td>Yi-6B-Chat</td> 
    <td>50.46</td> 
    <td>45.89</td> 
    <td>70.995</td> 
    <td>70.88</td> 
    <td>71.11</td> 
    <td>62.95</td> 
    <td>14.02</td> 
    <td>28.34</td> 
    <td>36.54</td> 
    <td>3.88</td> 
    <td>37.43</td> 
    <td>84.89</td> 
    <td>70.39</td> 
    <td>74.6*</td> 
   </tr> 
   <tr> 
    <td>Baichuan2-7B-Chat</td> 
    <td>44.68</td> 
    <td>42.74</td> 
    <td>53.39</td> 
    <td>53.28</td> 
    <td>53.5</td> 
    <td>53</td> 
    <td>21.34</td> 
    <td>32.32</td> 
    <td>25.25</td> 
    <td>6.32</td> 
    <td>37.46</td> 
    <td>79.63</td> 
    <td>60.15</td> 
    <td>69.23*</td> 
   </tr> 
   <tr> 
    <td>Deepseek-7B-chat</td> 
    <td>49.34</td> 
    <td>49.56</td> 
    <td>48.335</td> 
    <td>46.95</td> 
    <td>49.72</td> 
    <td>51.67</td> 
    <td>40.85</td> 
    <td>48.48</td> 
    <td>48.52</td> 
    <td>4.26</td> 
    <td>35.7</td> 
    <td>76.85</td> 
    <td>63.05</td> 
    <td>76.68*</td> 
   </tr> 
   <tr> 
    <td>Llama2-7B-Chat</td> 
    <td>38.16</td> 
    <td>39.17</td> 
    <td>33.59</td> 
    <td>34.54</td> 
    <td>32.64</td> 
    <td>47.64</td> 
    <td>14.02</td> 
    <td>27.4</td> 
    <td>21.15</td> 
    <td>2.08</td> 
    <td>35.54</td> 
    <td>74.28</td> 
    <td>54.78</td> 
    <td>75.65*</td> 
   </tr> 
   <tr> 
    <td>MiniCPM-2B</td> 
    <td>52.33</td> 
    <td>52.6</td> 
    <td>51.10</td> 
    <td>51.13</td> 
    <td>51.07</td> 
    <td>53.46</td> 
    <td>50.00</td> 
    <td>47.31</td> 
    <td>53.83</td> 
    <td>10.24</td> 
    <td>36.87</td> 
    <td>85.44</td> 
    <td>68.00</td> 
    <td>68.25</td> 
   </tr> 
  </tbody> 
 </table> 
 <p><strong>DPO后模型比较：</strong></p> 
 <table> 
  <thead> 
   <tr> 
    <th>模型</th> 
    <th>MT-bench</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>GPT-4-turbo</td> 
    <td>9.32</td> 
   </tr> 
   <tr> 
    <td>GPT-3.5-turbo</td> 
    <td>8.39</td> 
   </tr> 
   <tr> 
    <td>Mistral-8*7b-Instruct-v0.1</td> 
    <td>8.30</td> 
   </tr> 
   <tr> 
    <td>Claude-2.1</td> 
    <td>8.18</td> 
   </tr> 
   <tr> 
    <td>Zephyr-7B-beta</td> 
    <td>7.34</td> 
   </tr> 
   <tr> 
    <td><strong>MiniCPM-2B</strong></td> 
    <td><strong>7.25</strong></td> 
   </tr> 
   <tr> 
    <td>Vicuna-33B</td> 
    <td>7.12</td> 
   </tr> 
   <tr> 
    <td>Zephyr-7B-alpha</td> 
    <td>6.88</td> 
   </tr> 
   <tr> 
    <td>LLaMA-2-70B-chat</td> 
    <td>6.86</td> 
   </tr> 
   <tr> 
    <td>Mistral-7B-Instruct-v0.1</td> 
    <td>6.84</td> 
   </tr> 
   <tr> 
    <td>MPT-34B-instruct</td> 
    <td>6.39</td> 
   </tr> 
  </tbody> 
 </table> 
 <h3>快速上手</h3> 
 <h4>在线体验</h4> 
 <ul> 
  <li><a href="https://colab.research.google.com/drive/1tJcfPyWGWA5HezO7GKLeyeIso0HyOc0l?usp=sharing">Colab</a></li> 
 </ul> 
 <h4>基于Gradio的网页版Demo</h4> 
 <ul> 
  <li>使用如下命令启动基于Gradio的网页版demo：</li> 
 </ul> 
 <pre><code class="language-shell"># generation powered by vllm
python demo/minicpm/vllm_based_demo.py --model_path &lt;vllmcpm_repo_path&gt;
# generation powered by huggingface
python demo/minicpm/hf_based_demo.py --model_path &lt;hf_repo_path&gt;
</code></pre> 
 <h4>HuggingFace 推理</h4> 
 <h5>MiniCPM-2B</h5> 
 <p>安装<code>transformers&gt;=4.36.0</code>以及<code>accelerate</code>后，运行以下代码：</p> 
 <pre><code class="language-python">from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
torch.manual_seed(0)

path = 'openbmb/MiniCPM-2B-dpo-bf16'
tokenizer = AutoTokenizer.from_pretrained(path)
model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map='cuda', trust_remote_code=True)

responds, history = model.chat(tokenizer, "山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？", temperature=0.5, top_p=0.8, repetition_penalty=1.02)
print(responds)
</code></pre> 
 <h5>MiniCPM-2B （Llama Format）</h5> 
 <p>我们将MiniCPM的模型权重转化成了Llama代码可以直接调用的<a href="https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16-llama-format">格式</a>，以便大家尝试:</p> 
 <pre><code class="language-python">import torch
from transformers import LlamaTokenizerFast, LlamaForCausalLM
model_path = "openbmb/MiniCPM-2B-dpo-bf16-llama-format"
tokenizer = LlamaTokenizerFast.from_pretrained(model_path)
model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map='cuda', trust_remote_code=True)

prompt="Now you act like a terminal situated within a beginner's C++ practice repository folder, please provide the output for the command: `ls -l`"
input_ids = tokenizer.encode("&lt;用户&gt;{}&lt;AI&gt;".format(prompt), return_tensors='pt', add_special_tokens=True).cuda()
responds = model.generate(input_ids, temperature=0.3, top_p=0.8, repetition_penalty=1.02, max_length=1024)
responds = tokenizer.decode(responds[0], skip_special_tokens=True)
print(responds)
</code></pre> 
 <h4>vLLM 推理</h4> 
 <p>安装 <a href="https://github.com/vllm-project/vllm">vLLM</a>。</p> 
 <pre><code class="language-shell">pip install "vllm&gt;=0.4.1"
</code></pre> 
 <p>具体推理代码见<a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#vllm">这里</a>。</p> 
 <h4>SGLang 推理</h4> 
 <p>安装 <a href="https://github.com/sgl-project/sglang">SGLang</a>。</p> 
 <ul> 
  <li>首先需要启动一个服务:</li> 
 </ul> 
 <pre><code class="language-bash">python -m sglang.launch_server --model-path openbmb/MiniCPM-2B-dpo-fp16 --trust-remote-code --port 30000
</code></pre> 
 <ul> 
  <li>下面是一个推理代码的样例:</li> 
 </ul> 
 <pre><code class="language-python">from sglang import function, gen, set_default_backend, RuntimeEndpoint

@function
def text_qa(s, question):
    s += "&lt;用户&gt;" + question + "&lt;AI&gt;"
    s += gen("answer", max_tokens=1024, temperature=0.7, top_p=0.7)

set_default_backend(RuntimeEndpoint("http://localhost:30000"))

state = text_qa.run(
    question="What is the capital of China?",
)

print(state["answer"])
</code></pre> 
 <h4>llama.cpp、Ollama、fastllm、mlx_lm推理</h4> 
 <p>MiniCPM支持<a href="https://github.com/ggerganov/llama.cpp/">llama.cpp</a> 、<a href="https://github.com/ollama/ollama">ollama</a>、<a href="https://github.com/ztxz16/fastllm">fastllm</a>、<a href="https://github.com/ml-explore/mlx-examples">mlx_lm</a>推理。感谢<a href="https://github.com/runfuture">@runfuture</a>对llama.cpp和ollama的适配。</p> 
 <p>请参考 MiniCPM 知识库中的<a href="https://modelbest.feishu.cn/wiki/EatbwdLuvitbbMk2X5wcX6h5n7c">量化指南</a>。</p> 
 <h4>模型微调</h4> 
 <ul> 
  <li>一张 1080/2080 可实现高效参数微调：<a href="https://github.com/OpenBMB/MiniCPM/tree/main/finetune">代码</a></li> 
  <li>mlx 微调：<a href="https://modelbest.feishu.cn/wiki/AIU3wbREcirOm9kkvd7cxujFnMb#share-ASrDdvFAloHtycxfy85cLNhAnd3">教程</a></li> 
  <li><a href="https://github.com/InternLM/xtuner">xtuner</a>: <a href="https://modelbest.feishu.cn/wiki/AIU3wbREcirOm9kkvd7cxujFnMb#AMdXdzz8qoadZhxU4EucELWznzd">MiniCPM高效率微调的不二选择</a></li> 
  <li><a href="https://github.com/hiyouga/LLaMA-Factory.git">LLaMA-Factory</a>：<a href="https://modelbest.feishu.cn/wiki/AIU3wbREcirOm9kkvd7cxujFnMb#BAWrdSjXuoFvX4xuIuzc8Amln5E">MiniCPM微调一键式解决方案</a></li> 
 </ul> 
</details> 
<h2>开源协议</h2> 
<h4>模型协议</h4> 
<ul> 
 <li>本仓库中代码依照 <a href="https://github.com/OpenBMB/MiniCPM/raw/main/LICENSE">Apache-2.0</a> 协议开源</li> 
 <li>MiniCPM 模型权重的使用则需要遵循 <a href="https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%E6%A8%A1%E5%9E%8B%E5%95%86%E7%94%A8%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.md">MiniCPM 模型商用许可协议</a>。</li> 
 <li>MiniCPM 模型权重对学术研究完全开放，在填写<a href="https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g">问卷</a>进行登记后亦允许免费商业使用。</li> 
</ul> 
<h4>声明</h4> 
<ul> 
 <li>作为一个语言模型，MiniCPM 通过学习大量的文本来生成内容，但它无法理解、表达个人观点或价值判断，它所输出的任何内容都不代表模型开发者的观点和立场。</li> 
 <li>因此用户在使用 MiniCPM 生成的内容时，应自行负责对其进行评估和验证。</li> 
 <li>如果由于使用 MiniCPM 开源模型而导致的任何问题，包括但不限于数据安全问题、公共舆论风险，或模型被误导、滥用、传播或不当利用所带来的任何风险和问题，我们将不承担任何责任。</li> 
</ul> 
<h2>开发机构</h2> 
<p>本项目由以下机构共同开发：</p> 
<ul> 
 <li><img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/modelbest.png" width="28px" /> <a href="https://modelbest.cn/">面壁智能</a></li> 
 <li><img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/thunlp.png" width="28px" /> <a href="https://nlp.csai.tsinghua.edu.cn/">清华大学自然语言处理实验室</a></li> 
</ul> 
<h2>工作引用</h2> 
<ul> 
 <li>如果觉得MiniCPM有助于您的工作，请引用我们的<a href="https://arxiv.org/abs/2404.06395">论文</a></li> 
</ul> 
<pre><code>@article{hu2024minicpm,
  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},
  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},
  journal={arXiv preprint arXiv:2404.06395},
  year={2024}
}
</code></pre>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>RSSNext/Follow</title>
<link>https://github.com/RSSNext/Follow</link>
<guid>https://github.com/RSSNext/Follow</guid>
<content:encoded><![CDATA[
<div> 关键词：Next generation information browser、AI、Blockchain、Social、RSSible

总结：

Follow是一款集成了人工智能（AI）、区块链技术、社交功能以及RSS订阅功能的下一代信息浏览器。其核心亮点如下：

1. **AI驱动**：Follow利用高级AI技术提供智能服务，包括翻译、摘要和推荐功能，还每日为用户生成两次AI报告，以突出显示订阅内容的关键信息。此外，它还会根据用户的订阅构建个性化AI知识库。

2. **区块链激励机制**：通过使用区块链技术，Follow为活跃用户和优质创作者提供了奖励机制。持有和使用Power Token的用户可以获得额外的服务和福利，而提供优质内容和服务的创作者则能获得更多的回报。

3. **社交平台功能**：除了信息浏览，Follow还是一款社交平台，用户可以关注其他用户、分享订阅内容，并与他人发现新内容。它还支持订阅列表同步功能，让朋友能够共享订阅信息。

4. **内容适应性**：Follow的社区由超过1000名开发者组成，他们已经适配了近1000个网站，几乎涵盖了所有你需要的内容来源，包括但不限于X、Instagram、PlayStation、Spotify、Telegram、YouTube等。用户还可以编写自己的脚本以适应更多的网站。

5. **定制化与第三方集成**：Follow提供了丰富的自定义选项，以及与第三方应用的集成能力，允许用户根据自己的需求进行调整，并接入更多服务。

此款软件目前仍处于早期开发者预览阶段，仅向受邀用户提供访问权限。有兴趣的用户可以通过加入Discord服务器或关注特定账号等方式获取邀请码。一旦获得访问权限，用户不仅可下载安装适用于不同平台的应用程序，还可以通过参与开源社区共同开发这款软件。 <div>
<p>🧡 Next generation information browser</p><hr /><div align="center"> 
 <a href="https://github.com/PlayCover/PlayCover"> <img alt="Logo" height="80" src="https://github.com/RSSNext/follow/assets/41265413/c6c02ad5-cddc-46f5-8420-a47afe1c82fe" width="80" /> </a> 
 <h3 align="center">Follow</h3> 
 <p align="center"> Next generation information browser. <br /> <br /> <a href="https://discord.gg/xHCVQZ6wmZ">Discord</a> · <a href="https://x.com/intent/follow?screen_name=follow_app_">Twitter</a> · <a href="https://github.com/RSSNext/Follow/releases">Releases</a> </p> 
</div> 
<h2>Introduction</h2> 
<p>Welcome to Follow! This software is all about allowing you to follow your favorite websites, blogs, social media accounts, podcasts and notifications in one place. It is designed as a modern, fast, and convenient all-in-one information center.</p> 
<p>AI: Follow leverages advanced AI to assist your operations. Beyond basic AI translation, summarization, and recommendations, it provides twice-daily AI reports to highlight key information from your subscriptions. Additionally, it offers a personalized AI knowledge base built from your subscriptions.</p> 
<p>Blockchain: Follow uses blockchain technology as an incentive mechanism for active users and outstanding creators. Users can obtain more services and benefits by holding and using Power Token. Creators can obtain more rewards by providing high-quality content and services.</p> 
<p>Social: Follow is also a social platform that allows you to follow other users, share your subscriptions, and discover new content. It also offers a subscription list synchronization feature, enabling your friends to sync with your subscriptions.</p> 
<p>Supported Platforms: Follow Desktop for Windows, macOS, Linux, and Browser; Follow Mobile for Android and iOS (coming soon).</p> 
<h2>Screenshots</h2> 
<p>The project is currently under active development. The following screenshots are for reference only and may differ from the final release version.</p> 
<ul> 
 <li> <p>Use different views for various types of content to offer an experience equal to or better than the original platform - Articles, Social Media, Pictures, Videos, Podcasts, and Notifications <img alt="Screenshot 2024-09-10 at 6 22 18 PM" src="https://github.com/user-attachments/assets/1958ec70-1916-47c5-82d0-3bd8e43f3a26" /> <img alt="Screenshot 2024-09-10 at 6 22 47 PM" src="https://github.com/user-attachments/assets/1d0c3ed7-3da5-45e6-a264-399e8ea4071b" /> <img alt="Screenshot 2024-09-10 at 6 23 07 PM" src="https://github.com/user-attachments/assets/d21d54be-c343-4ac6-99f0-90c1e410245a" /> <img alt="Screenshot 2024-09-10 at 6 23 31 PM" src="https://github.com/user-attachments/assets/1781f368-8375-4b50-a66c-c8d8340f3ffb" /> <img alt="Screenshot 2024-09-10 at 6 23 47 PM" src="https://github.com/user-attachments/assets/6ccfeada-dbc3-4c76-8ca2-5dcac8c06804" /> <img alt="Screenshot 2024-09-10 at 6 24 11 PM" src="https://github.com/user-attachments/assets/f723d62a-1be7-48b1-a42c-83960af133be" /></p> </li> 
 <li> <p>Everything is RSSible. Our <a href="https://github.com/DIYgod/RSSHub">RSSHub</a> community, comprising over 1,000 developers, has spent six years adapting nearly a thousand websites to provide almost all the content you need. This includes platforms like X (Twitter), Instagram, PlayStation, Spotify, Telegram, YouTube, and more. You can also write your own scripts to adapt additional websites. <img alt="Screenshot 2024-09-10 at 8 09 36 PM" src="https://github.com/user-attachments/assets/5bd445f3-e005-4273-b892-7b29212970e2" /> <img alt="Screenshot 2024-09-10 at 8 10 01 PM" src="https://github.com/user-attachments/assets/25fbc9d2-ea10-4477-a4e9-1732f59fcb57" /></p> </li> 
 <li> <p>Actions and AI features. Follow leverages advanced AI to assist your operations. Beyond basic AI translation, summarization, and recommendations, it provides twice-daily AI reports to highlight key information from your subscriptions. Additionally, it offers a personalized AI knowledge base built from your subscriptions.</p> <p><img alt="Screenshot 2024-09-10 at 9 44 23 PM" src="https://github.com/user-attachments/assets/1801f1ba-e57f-4daf-8120-32631b0bdc2c" /> <img alt="Screenshot 2024-09-10 at 6 25 27 PM" src="https://github.com/user-attachments/assets/ddd14398-f735-433c-91cb-a2898ddf2098" /></p> </li> 
 <li> <p>Blockchain features and $Power token. Follow uses blockchain technology as an incentive mechanism for active users and outstanding creators. Users can obtain more services and benefits by holding and using Power Token. Creators can obtain more rewards by providing high-quality content and services. <img alt="Screenshot 2024-09-10 at 6 25 43 PM" src="https://github.com/user-attachments/assets/351ac415-d94e-4d5a-af42-37656c3e535c" /> <img alt="Screenshot 2024-09-10 at 6 27 08 PM" src="https://github.com/user-attachments/assets/82d71c46-c039-41b9-b3cd-5ad078ff14a5" /> <img alt="Screenshot 2024-09-10 at 8 10 56 PM" src="https://github.com/user-attachments/assets/2424dfd4-59a6-4dad-8eb7-8db61a711b45" /></p> </li> 
 <li> <p>Social features. Follow is also a social platform that allows you to follow other users, share your subscriptions, and discover new content. It also offers a subscription list synchronization feature, enabling your friends to sync with your subscriptions. Click <a href="https://app.follow.is/profile/54728159538884608">here</a> to view my automatically generated personal page. <img alt="Screenshot 2024-09-10 at 6 26 37 PM" src="https://github.com/user-attachments/assets/b636fd6d-0fcb-436b-8856-f7a965dba12d" /></p> </li> 
 <li> <p>Extensive customization options <img alt="Screenshot 2024-09-10 at 6 24 38 PM" src="https://github.com/user-attachments/assets/53ff78cd-02d0-4eeb-a10f-40ae21d85912" /> <img alt="Screenshot 2024-09-10 at 6 24 48 PM" src="https://github.com/user-attachments/assets/64bf2e9e-d9fe-4a90-bb3d-975ddb3e6558" /></p> </li> 
 <li> <p>Third-party integrations <img alt="Screenshot 2024-09-10 at 6 25 33 PM" src="https://github.com/user-attachments/assets/ea86fdbd-4b53-47ae-8bc5-d9a382ef07b5" /></p> </li> 
 <li> <p>Shortcuts and gestures <img alt="Screenshot 2024-09-10 at 6 25 38 PM" src="https://github.com/user-attachments/assets/43116bea-47b9-4c17-bc4f-92fb101a37a5" /></p> </li> 
</ul> 
<h2>Releases</h2> 
<p><a href="https://discord.gg/xHCVQZ6wmZ"><img alt="Discord" src="https://img.shields.io/discord/1243823539426033696?logo=discord&amp;label=Discord&amp;style=flat-square&amp;color=5865F2" /></a> <a href="https://x.com/intent/follow?screen_name=follow_app_"><img alt="" src="https://img.shields.io/badge/any_text-Follow-blue?color=2CA5E0&amp;label=_&amp;logo=x&amp;cacheSeconds=3600&amp;style=flat-square" /></a></p> 
<p>Currently, Follow is still in the early developer preview stage (alpha) and is only available to a limited number of users through an invitation system.</p> 
<p>You can get an invitation code in the following ways:</p> 
<ul> 
 <li>Looking for any beta user to invite you.</li> 
 <li>Join our Discord server for occasional giveaways.</li> 
 <li>Follow our X account for occasional giveaways.</li> 
</ul> 
<p>If you have access, you are welcome to use the following methods to download and install it:</p> 
<ul> 
 <li>You can get the installation packages for each platform from the <a href="https://github.com/RSSNext/Follow/releases">Releases page</a>.</li> 
 <li>If you are using Arch linux, you can install package <a href="https://aur.archlinux.org/packages/follow-appimage">follow-appimage</a> that maintained by <a href="https://github.com/ttimochan">timochan</a>.</li> 
</ul> 
<h2>Contributing</h2> 
<p>If you are eligible to use Follow, you are welcome to join the open source community to build together.</p> 
<p>Before you start, you need to install pnpm and then use it to install dependencies:</p> 
<pre><code class="language-sh">pnpm install
</code></pre> 
<h3>Develop in the browser</h3> 
<pre><code class="language-sh">pnpm run dev:web
</code></pre> 
<p>Then the browser opens <code>https://app.follow.is/__debug_proxy</code>，you can access the online API environment to development and debugging.</p> 
<h3>Develop in the electron</h3> 
<p>You need to fill in the required environment variables first.</p> 
<pre><code class="language-sh">cp .env.example .env
</code></pre> 
<p>Then run:</p> 
<pre><code class="language-sh">pnpm run dev
</code></pre> 
<p>Since it is not very convenient to develop in Electron, the first way to develop and contribute is recommended at this stage.</p> 
<h2>License</h2> 
<p>Follow is licensed under the GNU General Public License version 3 with the addition of the following special exception:</p> 
<p>All content in the <code>icons/mgc</code> directory is copyrighted by <a href="https://mgc.mingcute.com/">https://mgc.mingcute.com/</a> and cannot be redistributed.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>bluesky-social/atproto</title>
<link>https://github.com/bluesky-social/atproto</link>
<guid>https://github.com/bluesky-social/atproto</guid>
<content:encoded><![CDATA[
<div> 关键词：Bluesky、AT Protocol、TypeScript、社交网络技术、参考实现

总结：

本文主要介绍了Bluesky开发的AT协议的参考实现，以及基于该协议构建的app.bsky微博客应用服务后端。主要内容包括以下几点：

1. **技术栈**：使用了多种基于TypeScript的软件包和工具，如API客户端、共享代码库、加密库、身份验证、词汇解析、存储结构、语法解析和RPC接口等。

2. **服务架构**：提供了两个核心服务，即“Personal Data Server”（PDS）用于托管atproto账户的内容，以及AppView实现的app.bsky.* API端点运行于主网络上。

3. **规范与测试数据**：提供了一套规范文件，包括JSON格式的lexicons，以及用于跨协议兼容性的测试数据。

4. **开发指南**：推荐使用特定的Node.js管理工具，并提供了一个Makefile来简化开发过程中的常见任务，如依赖安装、构建和测试等。

5. **贡献与社区**：项目鼓励高质量的问题提交和PR，但对大规模重构、新功能添加、工具更改等有明确的限制和指导原则。同时，强调了对安全问题的重视，并提供了专门的邮箱进行报告。

通过这些介绍，可以看出这是一个高度专业化的社交网络技术项目，旨在为开发者提供灵活、去中心化、易于集成的社交平台基础框架。 <div>
<p>Social networking technology created by Bluesky</p><hr /><h1>AT Protocol Reference Implementation (TypeScript)</h1> 
<p>Welcome friends!</p> 
<p>This repository contains Bluesky's reference implementation of AT Protocol, and of the <code>app.bsky</code> microblogging application service backend.</p> 
<h2>What is in here?</h2> 
<p><strong>TypeScript Packages:</strong></p> 
<table> 
 <thead> 
  <tr> 
   <th>Package</th> 
   <th>Docs</th> 
   <th>NPM</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><code>@atproto/api</code>: client library</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/api/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/api"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/api" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/common-web</code>: shared code and helpers which can run in web browsers</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/common-web/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/common-web"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/common-web" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/common</code>: shared code and helpers which doesn't work in web browsers</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/common/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/common"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/common" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/crypto</code>: cryptographic signing and key serialization</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/crypto/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/crypto"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/crypto" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/identity</code>: DID and handle resolution</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/identity/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/identity"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/identity" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/lexicon</code>: schema definition language</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/lexicon/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/lexicon"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/lexicon" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/repo</code>: data storage structure, including MST</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/repo/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/repo"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/repo" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/syntax</code>: string parsers for identifiers</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/syntax/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/syntax"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/syntax" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/xrpc</code>: client-side HTTP API helpers</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/xrpc/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/xrpc"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/xrpc" /></a></td> 
  </tr> 
  <tr> 
   <td><code>@atproto/xrpc-server</code>: server-side HTTP API helpers</td> 
   <td><a href="https://raw.githubusercontent.com/bluesky-social/atproto/main/packages/xrpc-server/README.md">README</a></td> 
   <td><a href="https://www.npmjs.com/package/@atproto/xrpc-server"><img alt="NPM" src="https://img.shields.io/npm/v/@atproto/xrpc-server" /></a></td> 
  </tr> 
 </tbody> 
</table> 
<p><strong>TypeScript Services:</strong></p> 
<ul> 
 <li><code>pds</code>: "Personal Data Server", hosting repo content for atproto accounts. Most implementation code in <code>packages/pds</code>, with runtime wrapper in <code>services/pds</code>. See <a href="https://github.com/bluesky-social/pds">bluesky-social/pds</a> for directions on self-hosting.</li> 
 <li><code>bsky</code>: AppView implementation of the <code>app.bsky.*</code> API endpoints. Running on main network at <code>api.bsky.app</code>. Most implementation code in <code>packages/bsky</code>, with runtime wrapper in <code>services/bsky</code>.</li> 
</ul> 
<p><strong>Lexicons:</strong> for both the <code>com.atproto.*</code> and <code>app.bsky.*</code> are canonically versioned in this repo, for now, under <code>./lexicons/</code>. These are JSON files in the <a href="https://atproto.com/specs/lexicon">Lexicon schema definition language</a>, similar to JSON Schema or OpenAPI.</p> 
<p><strong>Interoperability Test Data:</strong> the language-neutral test files in <code>./interop-test-files/</code> may be useful for other protocol implementations to ensure that they follow the specification correctly</p> 
<p>The source code for the Bluesky Social client app (for web and mobile) can be found at <a href="https://github.com/bluesky-social/social-app">bluesky-social/social-app</a>.</p> 
<p>Go programming language source code is in <a href="https://github.com/bluesky-social/indigo">bluesky-social/indigo</a>, including the BGS implementation.</p> 
<h2>Developer Quickstart</h2> 
<p>We recommend <a href="https://github.com/nvm-sh/nvm"><code>nvm</code></a> for managing Node.js installs. This project requires Node.js version 18. <code>pnpm</code> is used to manage the workspace of multiple packages. You can install it with <code>npm install --global pnpm</code>.</p> 
<p>There is a Makefile which can help with basic development tasks:</p> 
<pre><code class="language-shell"># use existing nvm to install node 18 and pnpm
make nvm-setup

# pull dependencies and build all local packages
make deps
make build

# run the tests, using Docker services as needed
make test

# run a local PDS and AppView with fake test accounts and data
# (this requires a global installation of `jq` and `docker`)
make run-dev-env

# show all other commands
make help
</code></pre> 
<h2>About AT Protocol</h2> 
<p>The Authenticated Transfer Protocol ("ATP" or "atproto") is a decentralized social media protocol, developed by <a href="https://bsky.social">Bluesky PBC</a>. Learn more at:</p> 
<ul> 
 <li><a href="https://atproto.com/guides/overview">Overview and Guides</a> 👈 Best starting point</li> 
 <li><a href="https://github.com/bluesky-social/atproto/discussions">Github Discussions</a> 👈 Great place to ask questions</li> 
 <li><a href="https://atproto.com/specs/atp">Protocol Specifications</a></li> 
 <li><a href="https://bsky.social/about/blog/3-6-2022-a-self-authenticating-social-protocol">Blogpost on self-authenticating data structures</a></li> 
</ul> 
<p>The Bluesky Social application encompasses a set of schemas and APIs built in the overall AT Protocol framework. The namespace for these "Lexicons" is <code>app.bsky.*</code>.</p> 
<h2>Contributions</h2> 
<blockquote> 
 <p>While we do accept contributions, we prioritize high quality issues and pull requests. Adhering to the below guidelines will ensure a more timely review.</p> 
</blockquote> 
<p><strong>Rules:</strong></p> 
<ul> 
 <li>We may not respond to your issue or PR.</li> 
 <li>We may close an issue or PR without much feedback.</li> 
 <li>We may lock discussions or contributions if our attention is getting DDOSed.</li> 
 <li>We do not provide support for build issues.</li> 
</ul> 
<p><strong>Guidelines:</strong></p> 
<ul> 
 <li>Check for existing issues before filing a new one, please.</li> 
 <li>Open an issue and give some time for discussion before submitting a PR.</li> 
 <li>If submitting a PR that includes a lexicon change, please get sign off on the lexicon change <em>before</em> doing the implementation.</li> 
 <li>Issues are for bugs &amp; feature requests related to the TypeScript implementation of atproto and related services. 
  <ul> 
   <li>For high-level discussions, please use the <a href="https://github.com/bluesky-social/atproto/discussions">Discussion Forum</a>.</li> 
   <li>For client issues, please use the relevant <a href="https://github.com/bluesky-social/social-app">social-app</a> repo.</li> 
  </ul> </li> 
 <li>Stay away from PRs that: 
  <ul> 
   <li>Refactor large parts of the codebase</li> 
   <li>Add entirely new features without prior discussion</li> 
   <li>Change the tooling or frameworks used without prior discussion</li> 
   <li>Introduce new unnecessary dependencies</li> 
  </ul> </li> 
</ul> 
<p>Remember, we serve a wide community of users. Our day-to-day involves us constantly asking "which top priority is our top priority." If you submit well-written PRs that solve problems concisely, that's an awesome contribution. Otherwise, as much as we'd love to accept your ideas and contributions, we really don't have the bandwidth.</p> 
<h2>Are you a developer interested in building on atproto?</h2> 
<p>Bluesky is an open social network built on the AT Protocol, a flexible technology that will never lock developers out of the ecosystems that they help build. With atproto, third-party can be as seamless as first-party through custom feeds, federated services, clients, and more.</p> 
<h2>Security disclosures</h2> 
<p>If you discover any security issues, please send an email to <a href="mailto:security@bsky.app">security@bsky.app</a>. The email is automatically CCed to the entire team, and we'll respond promptly. See <a href="https://github.com/bluesky-social/atproto/raw/main/SECURITY.md">SECURITY.md</a> for more info.</p> 
<h2>License</h2> 
<p>This project is dual-licensed under MIT and Apache 2.0 terms:</p> 
<ul> 
 <li>MIT license (<a href="https://github.com/bluesky-social/atproto/raw/main/LICENSE-MIT.txt">LICENSE-MIT.txt</a> or <a href="http://opensource.org/licenses/MIT">http://opensource.org/licenses/MIT</a>)</li> 
 <li>Apache License, Version 2.0, (<a href="https://github.com/bluesky-social/atproto/raw/main/LICENSE-APACHE.txt">LICENSE-APACHE.txt</a> or <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a>)</li> 
</ul> 
<p>Downstream projects and end users may chose either license individually, or both together, at their discretion. The motivation for this dual-licensing is the additional software patent assurance provided by Apache 2.0.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>GoogleCloudPlatform/python-docs-samples</title>
<link>https://github.com/GoogleCloudPlatform/python-docs-samples</link>
<guid>https://github.com/GoogleCloudPlatform/python-docs-samples</guid>
<content:encoded><![CDATA[
<div> 关键词：云平台、Python样本、设置、运行样本、贡献

总结:

本文详细介绍了如何使用Google Cloud Platform中的Python样本。首先，需要确保安装了所需的开发环境，包括Python和可能的其他工具。其次，通过克隆指定的GitHub仓库来获取样本代码，并使用命令行工具完成身份验证过程，以确保能够访问云资源。

在准备就绪后，用户可以切换到特定样本文件夹，如日志管理的客户端示例，创建一个虚拟环境以确保兼容Python 3.6或更高版本的环境。接下来，用户需要安装运行这些样本所需的依赖库。最后，通过执行特定的脚本（例如`snippets.py`）来运行样本代码。

对于想要贡献新功能或改进现有代码的开发者，文档中提供了详细的指导和规则，鼓励大家参与并改进项目。

通过遵循上述步骤，用户可以轻松地利用Google Cloud Platform提供的Python样本进行学习和实践，同时为项目贡献自己的力量。 <div>
<p>Code samples used on cloud.google.com</p><hr /><h1>Google Cloud Platform Python Samples</h1> 
<p>Python samples for <a href="https://cloud.google.com/">Google Cloud Platform products</a>.</p> 
<p><a href="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-2.7.html"><img alt="Build Status" src="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-2.7.svg?sanitize=true" /></a> <a href="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-3.8.html"><img alt="Build Status" src="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-3.8.svg?sanitize=true" /></a> <a href="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-3.9.html"><img alt="Build Status" src="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-3.9.svg?sanitize=true" /></a> <a href="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-3.10.html"><img alt="Build Status" src="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-310.svg?sanitize=true" /></a> <a href="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-3.11.html"><img alt="Build Status" src="https://storage.googleapis.com/cloud-devrel-public/python-docs-samples/badges/py-311.svg?sanitize=true" /></a></p> 
<h2>Google Cloud Samples</h2> 
<p>Check out some of the samples found on this repository on the <a href="https://cloud.google.com/docs/samples?l=python">Google Cloud Samples</a> page.</p> 
<h2>Setup</h2> 
<ol> 
 <li> <p>Install <a href="https://cloud.google.com/python/setup"><code>pip</code> and <code>virtualenv</code></a> if you do not already have them.</p> </li> 
 <li> <p>Clone this repository:</p> <pre><code>git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git
</code></pre> </li> 
 <li> <p>Obtain authentication credentials.</p> <p>Create local credentials by running the following command and following the oauth2 flow (read more about the command <a href="https://cloud.google.com/sdk/gcloud/reference/beta/auth/application-default/login">here</a>):</p> <pre><code>gcloud auth application-default login
</code></pre> <p>Read more about <a href="https://cloud.google.com/docs/authentication#projects_and_resources">Google Cloud Platform Authentication</a>.</p> </li> 
</ol> 
<h2>How to run a sample</h2> 
<ol> 
 <li> <p>Change directory to one of the sample folders, e.g. <code>logging/cloud-client</code>:</p> <pre><code>cd logging/cloud-client/
</code></pre> </li> 
 <li> <p>Create a virtualenv. Samples are compatible with Python 3.6+.</p> <pre><code>python3 -m venv env
source env/bin/activate
</code></pre> </li> 
 <li> <p>Install the dependencies needed to run the samples.</p> <pre><code>pip install -r requirements.txt
</code></pre> </li> 
 <li> <p>Run the sample:</p> <pre><code>python snippets.py
</code></pre> </li> 
</ol> 
<h2>Contributing</h2> 
<p>Contributions welcome! See the <a href="https://raw.githubusercontent.com/GoogleCloudPlatform/python-docs-samples/main/CONTRIBUTING.md">Contributing Guide</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CleverRaven/Cataclysm-DDA</title>
<link>https://github.com/CleverRaven/Cataclysm-DDA</link>
<guid>https://github.com/CleverRaven/Cataclysm-DDA</guid>
<content:encoded><![CDATA[
<div> 关键词：Cataclysm: Dark Days Ahead、生存游戏、程序生成世界、多人对战、自由使用

总结:
《Cataclysm: Dark Days Ahead》是一款设定在后末日世界的回合制生存游戏。游戏不仅包含僵尸元素，还有更多复杂的内容等待玩家探索。玩家需要在这个持久的、程序生成的世界中努力生存，寻找食物和装备，甚至有机会驾驶满油车辆逃离险境。游戏中存在各种强大的怪物，从普通的僵尸到巨型昆虫，甚至是致命机器人和更诡异危险的生物。同时，玩家还需与其他幸存者竞争，因为资源有限。

游戏提供多个版本的下载，包括Ncurses和tiles等，支持多种操作系统如Arch Linux、Fedora、Debian/Ubuntu以及Flathub。玩家可以通过特定命令进行安装。此外，游戏还提供了详细的编译指南和贡献指南，鼓励社区成员参与游戏的开发和改进。游戏遵循Creative Commons Attribution ShareAlike 3.0许可协议，允许用户自由使用、修改和重新分发游戏内容。

对于新玩家，游戏提供教程帮助理解基本操作，通过特殊菜单可以访问。玩家可以自定义快捷键，通过按键组合来执行特定动作。创建新世界的方法是通过主菜单中的“世界”选项。如果玩家遇到问题或有建议，可以通过官方渠道报告错误或提出改进建议。 <div>
<p>Cataclysm - Dark Days Ahead. A turn-based survival game set in a post-apocalyptic world.</p><hr /><h1>Cataclysm: Dark Days Ahead</h1> 
<p>Cataclysm: Dark Days Ahead is a turn-based survival game set in a post-apocalyptic world. While some have described it as a "zombie game", there is far more to Cataclysm than that. Struggle to survive in a harsh, persistent, procedurally generated world. Scavenge the remnants of a dead civilization for food, equipment, or, if you are lucky, a vehicle with a full tank of gas to get you the hell out of Dodge. Fight to defeat or escape from a wide variety of powerful monstrosities, from zombies to giant insects to killer robots and things far stranger and deadlier, and against the others like yourself, who want what you have...</p> 
<p align="center"> <img alt="Tileset: Ultica" src="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/data/screenshots/ultica-showcase-sep-2021.png" /> </p> 
<h2>Downloads</h2> 
<p><strong>Releases</strong> - <a href="https://cataclysmdda.org/releases/">Stable</a> | <a href="https://cataclysmdda.org/experimental/">Experimental</a></p> 
<p><strong>Source</strong> - The source can be downloaded as a <a href="https://github.com/CleverRaven/Cataclysm-DDA/archive/master.zip">.zip archive</a>, or cloned from our <a href="https://github.com/CleverRaven/Cataclysm-DDA/">GitHub repo</a>.</p> 
<a href="https://repology.org/project/cataclysm-dda/versions"> <img align="right" alt="Packaging Status" src="https://repology.org/badge/vertical-allrepos/cataclysm-dda.svg?sanitize=true" /> </a> 
<p><a href="https://github.com/CleverRaven/Cataclysm-DDA/actions/workflows/matrix.yml"><img alt="General build matrix" src="https://github.com/CleverRaven/Cataclysm-DDA/actions/workflows/matrix.yml/badge.svg?sanitize=true" /></a> <a href="https://coveralls.io/github/CleverRaven/Cataclysm-DDA?branch=master"><img alt="Coverage Status" src="https://coveralls.io/repos/github/CleverRaven/Cataclysm-DDA/badge.svg?branch=master" /></a> <a href="https://www.codetriage.com/cleverraven/cataclysm-dda"><img alt="Open Source Helpers" src="https://www.codetriage.com/cleverraven/cataclysm-dda/badges/users.svg?sanitize=true" /></a> <a href="https://github.com/CleverRaven/Cataclysm-DDA/graphs/contributors"><img alt="Commit Activity" src="https://img.shields.io/github/commit-activity/m/CleverRaven/Cataclysm-DDA" /></a> <a href="https://github.com/XAMPPRocky/tokei"><img alt="Lines of Code" src="https://tokei.rs/b1/github/CleverRaven/Cataclysm-DDA?category=code" /></a> <a href="https://www.tickgit.com/browse?repo=github.com/CleverRaven/Cataclysm-DDA"><img alt="TODOs" src="https://badgen.net/https/api.tickgit.com/badgen/github.com/CleverRaven/Cataclysm-DDA" /></a></p> 
<h3>Packaging status</h3> 
<h4>Arch Linux</h4> 
<p>Ncurses and tiles versions are available in the <a href="https://www.archlinux.org/packages/?q=cataclysm-dda">community repo</a>.</p> 
<p><code>sudo pacman -S cataclysm-dda</code></p> 
<h4>Fedora</h4> 
<p>Ncurses and tiles versions are available in the <a href="https://src.fedoraproject.org/rpms/cataclysm-dda">official repos</a>.</p> 
<p><code>sudo dnf install cataclysm-dda</code></p> 
<h4>Debian / Ubuntu</h4> 
<p>Ncurses and tiles versions are available in the <a href="https://tracker.debian.org/pkg/cataclysm-dda">official repos</a>.</p> 
<p><code>sudo apt install cataclysm-dda-curses cataclysm-dda-sdl</code></p> 
<h4>Flathub</h4> 
<p><a href="https://flathub.org/apps/org.cataclysmdda.CataclysmDDA">Download from Flathub</a></p> 
<h2>Compile</h2> 
<p>Please read <a href="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/doc/COMPILING/COMPILING.md">COMPILING.md</a> - it covers general information and more specific recipes for Linux, OS X, Windows and BSD. See <a href="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/doc/COMPILING/COMPILER_SUPPORT.md">COMPILER_SUPPORT.md</a> for details on which compilers we support. And you can always dig for more information in <a href="https://github.com/CleverRaven/Cataclysm-DDA/tree/master/doc">doc/</a>.</p> 
<p>We also have the following build guides:</p> 
<ul> 
 <li>Building on Windows with <code>MSYS2</code> at <a href="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/doc/COMPILING/COMPILING-MSYS.md">COMPILING-MSYS.md</a></li> 
 <li>Building on Windows with <code>vcpkg</code> at <a href="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/doc/COMPILING/COMPILING-VS-VCPKG.md">COMPILING-VS-VCPKG.md</a></li> 
 <li>Building with <code>cmake</code> at <a href="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/doc/COMPILING/COMPILING-CMAKE.md">COMPILING-CMAKE.md</a> (<em>unofficial guide</em>)</li> 
</ul> 
<h2>Contribute</h2> 
<p>Cataclysm: Dark Days Ahead is the result of contributions from over 1000 volunteers under the Creative Commons Attribution ShareAlike 3.0 license. The code and content of the game is free to use, modify, and redistribute for any purpose whatsoever. See <a href="https://creativecommons.org/licenses/by-sa/3.0/">https://creativecommons.org/licenses/by-sa/3.0/</a> for details. Some code distributed with the project is not part of the project and is released under different software licenses; the files covered by different software licenses have their own license notices.</p> 
<p>Please see <a href="https://raw.githubusercontent.com/CleverRaven/Cataclysm-DDA/master/doc/CONTRIBUTING.md">CONTRIBUTING.md</a> for details.</p> 
<p>Special thanks to the contributors, including but not limited to, people below: <a href="https://github.com/cleverraven/cataclysm-dda/graphs/contributors"> <img src="https://contrib.rocks/image?repo=cleverraven/cataclysm-dda" /> </a></p> 
<p>Made with <a href="https://contrib.rocks">contrib.rocks</a>.</p> 
<h2>Community</h2> 
<p>Forums: <a href="https://discourse.cataclysmdda.org">https://discourse.cataclysmdda.org</a></p> 
<p>GitHub repo: <a href="https://github.com/CleverRaven/Cataclysm-DDA">https://github.com/CleverRaven/Cataclysm-DDA</a></p> 
<p>IRC: <code>#CataclysmDDA</code> on <a href="https://libera.chat">Libera Chat</a>, <a href="https://web.libera.chat/#CataclysmDDA">https://web.libera.chat/#CataclysmDDA</a></p> 
<p>Official Discord: <a href="https://discord.gg/jFEc7Yp">https://discord.gg/jFEc7Yp</a></p> 
<h2>Frequently Asked Questions</h2> 
<h4>Is there a tutorial?</h4> 
<p>Yes, you can find the tutorial in the <strong>Special</strong> menu at the main menu (be aware that due to many code changes the tutorial may not function). You can also access documentation in-game via the <code>?</code> key.</p> 
<h4>How can I change the key bindings?</h4> 
<p>Press the <code>?</code> key, followed by the <code>1</code> key to see the full list of key commands. Press the <code>+</code> key to add a key binding, select which action with the corresponding letter key <code>a-w</code>, and then the key you wish to assign to that action.</p> 
<h4>How can I start a new world?</h4> 
<p><strong>World</strong> on the main menu will generate a fresh world for you. Select <strong>Create World</strong>.</p> 
<h4>I've found a bug. What should I do?</h4> 
<p>Please submit an issue on <a href="https://github.com/CleverRaven/Cataclysm-DDA/issues/">our GitHub page</a> using <a href="https://github.com/CleverRaven/Cataclysm-DDA/issues/new?template=bug_report.md">bug report template</a>. If you're not able to, send an email to <code>kevin.granade@gmail.com</code>.</p> 
<h4>I would like to make a suggestion. What should I do?</h4> 
<p>Please submit an issue on <a href="https://github.com/CleverRaven/Cataclysm-DDA/issues/">our GitHub page</a> using <a href="https://github.com/CleverRaven/Cataclysm-DDA/issues/new?template=feature_request.md">feature request template</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>nginx/nginx</title>
<link>https://github.com/nginx/nginx</link>
<guid>https://github.com/nginx/nginx</guid>
<content:encoded><![CDATA[
<div> 关键词：NGINX, 开源仓库, 官方文档, 在线资源, 技术支持

<br />
总结: NGINX官方提供了其开源版本的仓库，为用户提供了一个获取、更新和管理NGINX源代码的平台。同时，为了帮助用户更好地理解和使用NGINX，官方还提供了详细的在线文档，覆盖了从基本概念到高级特性的多个层面。这些文档不仅包含了如何安装和配置NGINX的步骤，还有针对特定应用场景的案例分析和技术指导。此外，NGINX社区活跃，用户可以在这里找到大量的讨论、问题解答以及最佳实践分享，这为寻求技术支持和交流经验的用户提供了一个良好的环境。总的来说，NGINX通过提供丰富的文档资源和活跃的社区支持，为用户的学习和应用提供了全面的帮助。 <div>
<p>The official NGINX Open Source repository.</p><hr /><p>Documentation is available at <a href="http://nginx.org">http://nginx.org</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mintplex-Labs/anything-llm</title>
<link>https://github.com/Mintplex-Labs/anything-llm</link>
<guid>https://github.com/Mintplex-Labs/anything-llm</guid>
<content:encoded><![CDATA[
<div> 关键词：AI应用、多用户管理、容器化、全栈解决方案、本地/远程部署

总结:
这篇文章介绍了名为“AnythingLLM”的全功能AI应用程序，它是一款集成桌面和Docker环境的全能AI应用，具有丰富的RAG（阅读、理解、生成）和AI代理功能。这款应用提供了一个统一平台，让用户可以将任何文档、资源或内容转化为可供大型语言模型（LLM）参考的上下文。用户可以选择使用商业现成的或开源的LLM、向量数据库以及支持多种用户实例与权限管理。

关键特性包括：
1. **多模态支持**：支持闭源和开源的LLM，满足不同需求。
2. **多用户实例**：Docker版本提供多用户实例和权限管理，便于团队协作。
3. **AI代理**：在工作空间内部署AI代理，实现浏览网络、运行代码等功能。
4. **文档类型支持**：支持多种文档格式，如PDF、TXT、DOCX等。
5. **简单易用的聊天界面**：带有拖放功能和清晰引注，提升用户体验。
6. **云端部署**：支持全云部署，兼容各种云服务提供商。
7. **成本节约**：处理大文档时效率高，节省时间与成本。
8. **自定义集成API**：提供开发者API，方便定制集成。
9. **内置向量数据库**：支持特定的向量数据库，提高性能稳定性。
10. **隐私保护**：包含匿名使用信息收集，用户可选择退出，确保隐私安全。

通过这些功能，AnythingLLM为用户提供了一个灵活、高效、安全的AI应用解决方案，适用于个人学习、团队协作、知识管理和企业应用等多个场景。 <div>
<p>The all-in-one Desktop & Docker AI application with full RAG and AI Agent capabilities.</p><hr /><p><a name="readme-top"></a></p> 
<p align="center"> <a href="https://anythingllm.com"><img alt="AnythingLLM logo" src="https://github.com/Mintplex-Labs/anything-llm/raw/master/images/wordmark.png?raw=true" /></a> </p> 
<div align="center"> 
 <a href="https://trendshift.io/repositories/2415" target="_blank"><img alt="Mintplex-Labs%2Fanything-llm | Trendshift" height="55" src="https://trendshift.io/api/badge/repositories/2415" style="width: 250px; height: 55px;" width="250" /></a> 
</div> 
<p align="center"> <b>AnythingLLM:</b> The all-in-one AI app you were looking for.<br /> Chat with your docs, use AI Agents, hyper-configurable, multi-user, &amp; no frustrating set up required. </p> 
<p align="center"> <a href="https://discord.gg/6UyHPeGZAC" target="_blank"> <img alt="Discord" src="https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==" /> </a> | <a href="https://github.com/Mintplex-Labs/anything-llm/raw/master/LICENSE" target="_blank"> <img alt="License" src="https://img.shields.io/static/v1?label=license&amp;message=MIT&amp;color=white" /> </a> | <a href="https://docs.anythingllm.com" target="_blank"> Docs </a> | <a href="https://my.mintplexlabs.com/aio-checkout?product=anythingllm" target="_blank"> Hosted Instance </a> </p> 
<p align="center"> <b>English</b> · <a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/locales/README.zh-CN.md">简体中文</a> · <a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/locales/README.ja-JP.md">日本語</a> </p> 
<p align="center"> 👉 AnythingLLM for desktop (Mac, Windows, &amp; Linux)! <a href="https://anythingllm.com/download" target="_blank"> Download Now</a> </p> 
<p>A full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.</p> 
<p><img alt="Chatting" src="https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859" /></p> 
<details> 
 <kbd>Watch the demo!</kbd> 
 <p><a href="https://youtu.be/f95rGD9trL0"><img alt="Watch the video" src="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/images/youtube.png" /></a></p> 
</details> 
<h3>Product Overview</h3> 
<p>AnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.</p> 
<p>AnythingLLM divides your documents into objects called <code>workspaces</code>. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.</p> 
<h2>Cool features of AnythingLLM</h2> 
<ul> 
 <li>🆕 <strong>Multi-modal support (both closed and open-source LLMs!)</strong></li> 
 <li>👤 Multi-user instance support and permissioning <em>Docker version only</em></li> 
 <li>🦾 Agents inside your workspace (browse the web, run code, etc)</li> 
 <li>💬 <a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/embed/README.md">Custom Embeddable Chat widget for your website</a> <em>Docker version only</em></li> 
 <li>📖 Multiple document type support (PDF, TXT, DOCX, etc)</li> 
 <li>Simple chat UI with Drag-n-Drop funcitonality and clear citations.</li> 
 <li>100% Cloud deployment ready.</li> 
 <li>Works with all popular <a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/#supported-llms-embedder-models-speech-models-and-vector-databases">closed and open-source LLM providers</a>.</li> 
 <li>Built-in cost &amp; time-saving measures for managing very large documents compared to any other chat UI.</li> 
 <li>Full Developer API for custom integrations!</li> 
 <li>Much more...install and find out!</li> 
</ul> 
<h3>Supported LLMs, Embedder Models, Speech models, and Vector Databases</h3> 
<p><strong>Large Language Models (LLMs):</strong></p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/server/storage/models/README.md#text-generation-llm-selection">Any open-source llama.cpp compatible model</a></li> 
 <li><a href="https://openai.com">OpenAI</a></li> 
 <li><a href="https://openai.com">OpenAI (Generic)</a></li> 
 <li><a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service">Azure OpenAI</a></li> 
 <li><a href="https://aws.amazon.com/bedrock/">AWS Bedrock</a></li> 
 <li><a href="https://www.anthropic.com/">Anthropic</a></li> 
 <li><a href="https://ai.google.dev/">Google Gemini Pro</a></li> 
 <li><a href="https://huggingface.co/">Hugging Face (chat models)</a></li> 
 <li><a href="https://ollama.ai/">Ollama (chat models)</a></li> 
 <li><a href="https://lmstudio.ai">LM Studio (all models)</a></li> 
 <li><a href="https://localai.io/">LocalAi (all models)</a></li> 
 <li><a href="https://www.together.ai/">Together AI (chat models)</a></li> 
 <li><a href="https://www.perplexity.ai/">Perplexity (chat models)</a></li> 
 <li><a href="https://openrouter.ai/">OpenRouter (chat models)</a></li> 
 <li><a href="https://mistral.ai/">Mistral</a></li> 
 <li><a href="https://groq.com/">Groq</a></li> 
 <li><a href="https://cohere.com/">Cohere</a></li> 
 <li><a href="https://github.com/LostRuins/koboldcpp">KoboldCPP</a></li> 
 <li><a href="https://github.com/BerriAI/litellm">LiteLLM</a></li> 
 <li><a href="https://github.com/oobabooga/text-generation-webui">Text Generation Web UI</a></li> 
</ul> 
<p><strong>Embedder models:</strong></p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/server/storage/models/README.md">AnythingLLM Native Embedder</a> (default)</li> 
 <li><a href="https://openai.com">OpenAI</a></li> 
 <li><a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service">Azure OpenAI</a></li> 
 <li><a href="https://localai.io/">LocalAi (all)</a></li> 
 <li><a href="https://ollama.ai/">Ollama (all)</a></li> 
 <li><a href="https://lmstudio.ai">LM Studio (all)</a></li> 
 <li><a href="https://cohere.com/">Cohere</a></li> 
</ul> 
<p><strong>Audio Transcription models:</strong></p> 
<ul> 
 <li><a href="https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription">AnythingLLM Built-in</a> (default)</li> 
 <li><a href="https://openai.com/">OpenAI</a></li> 
</ul> 
<p><strong>TTS (text-to-speech) support:</strong></p> 
<ul> 
 <li>Native Browser Built-in (default)</li> 
 <li><a href="https://github.com/rhasspy/piper">PiperTTSLocal - runs in browser</a></li> 
 <li><a href="https://platform.openai.com/docs/guides/text-to-speech/voice-options">OpenAI TTS</a></li> 
 <li><a href="https://elevenlabs.io/">ElevenLabs</a></li> 
</ul> 
<p><strong>STT (speech-to-text) support:</strong></p> 
<ul> 
 <li>Native Browser Built-in (default)</li> 
</ul> 
<p><strong>Vector Databases:</strong></p> 
<ul> 
 <li><a href="https://github.com/lancedb/lancedb">LanceDB</a> (default)</li> 
 <li><a href="https://www.datastax.com/products/datastax-astra">Astra DB</a></li> 
 <li><a href="https://pinecone.io">Pinecone</a></li> 
 <li><a href="https://trychroma.com">Chroma</a></li> 
 <li><a href="https://weaviate.io">Weaviate</a></li> 
 <li><a href="https://qdrant.tech">Qdrant</a></li> 
 <li><a href="https://milvus.io">Milvus</a></li> 
 <li><a href="https://zilliz.com">Zilliz</a></li> 
</ul> 
<h3>Technical Overview</h3> 
<p>This monorepo consists of three main sections:</p> 
<ul> 
 <li><code>frontend</code>: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.</li> 
 <li><code>server</code>: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.</li> 
 <li><code>collector</code>: NodeJS express server that process and parses documents from the UI.</li> 
 <li><code>docker</code>: Docker instructions and build process + information for building from source.</li> 
 <li><code>embed</code>: Submodule for generation &amp; creation of the <a href="https://github.com/Mintplex-Labs/anythingllm-embed">web embed widget</a>.</li> 
 <li><code>browser-extension</code>: Submodule for the <a href="https://github.com/Mintplex-Labs/anythingllm-extension">chrome browser extension</a>.</li> 
</ul> 
<h2>🛳 Self Hosting</h2> 
<p>Mintplex Labs &amp; the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.</p> 
<table> 
 <thead> 
  <tr> 
   <th>Docker</th> 
   <th align="right">AWS</th> 
   <th>GCP</th> 
   <th>Digital Ocean</th> 
   <th>Render.com</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/docker/HOW_TO_USE_DOCKER.md"><img alt="Deploy on Docker" src="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/images/deployBtns/docker.png" /></a></td> 
   <td align="right"><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/cloud-deployments/aws/cloudformation/DEPLOY.md"><img alt="Deploy on AWS" src="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/images/deployBtns/aws.png" /></a></td> 
   <td><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/cloud-deployments/gcp/deployment/DEPLOY.md"><img alt="Deploy on GCP" src="https://deploy.cloud.run/button.svg?sanitize=true" /></a></td> 
   <td><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/cloud-deployments/digitalocean/terraform/DEPLOY.md"><img alt="Deploy on DigitalOcean" src="https://www.deploytodo.com/do-btn-blue.svg?sanitize=true" /></a></td> 
   <td><a href="https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&amp;branch=render"><img alt="Deploy on Render.com" src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" /></a></td> 
  </tr> 
 </tbody> 
</table> 
<table> 
 <thead> 
  <tr> 
   <th>Railway</th> 
   <th>RepoCloud</th> 
   <th>Elestio</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://railway.app/template/HNSCS1?referralCode=WFgJkn"><img alt="Deploy on Railway" src="https://railway.app/button.svg?sanitize=true" /></a></td> 
   <td><a href="https://repocloud.io/details/?app_id=276"><img alt="Deploy on RepoCloud" src="https://d16t0pc4846x52.cloudfront.net/deploylobe.svg?sanitize=true" /></a></td> 
   <td><a href="https://elest.io/open-source/anythingllm"><img alt="Deploy on Elestio" src="https://elest.io/images/logos/deploy-to-elestio-btn.png" /></a></td> 
  </tr> 
 </tbody> 
</table> 
<p><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/BARE_METAL.md">or set up a production AnythingLLM instance without Docker →</a></p> 
<h2>How to setup for development</h2> 
<ul> 
 <li><code>yarn setup</code> To fill in the required <code>.env</code> files you'll need in each of the application sections (from root of repo). 
  <ul> 
   <li>Go fill those out before proceeding. Ensure <code>server/.env.development</code> is filled or else things won't work right.</li> 
  </ul> </li> 
 <li><code>yarn dev:server</code> To boot the server locally (from root of repo).</li> 
 <li><code>yarn dev:frontend</code> To boot the frontend locally (from root of repo).</li> 
 <li><code>yarn dev:collector</code> To then run the document collector (from root of repo).</li> 
</ul> 
<p><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/server/storage/documents/DOCUMENTS.md">Learn about documents</a></p> 
<p><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/server/storage/vector-cache/VECTOR_CACHE.md">Learn about vector caching</a></p> 
<h2>Telemetry &amp; Privacy</h2> 
<p>AnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.</p> 
<details> 
 <kbd>More about Telemetry &amp; Privacy for AnythingLLM</kbd> 
 <h3>Why?</h3> 
 <p>We use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM's performance and stability.</p> 
 <h3>Opting out</h3> 
 <p>Set <code>DISABLE_TELEMETRY</code> in your server or docker .env settings to "true" to opt out of telemetry. You can also do this in-app by going to the sidebar &gt; <code>Privacy</code> and disabling telemetry.</p> 
 <h3>What do you explicitly track?</h3> 
 <p>We will only track usage details that help us make product and roadmap decisions, specifically:</p> 
 <ul> 
  <li>Typ of your installation (Docker or Desktop)</li> 
  <li>When a document is added or removed. No information <em>about</em> the document. Just that the event occurred. This gives us an idea of use.</li> 
  <li>Type of vector database in use. Let's us know which vector database provider is the most used to prioritize changes when updates arrive for that provider.</li> 
  <li>Type of LLM in use. Let's us know the most popular choice and prioritize changes when updates arrive for that provider.</li> 
  <li>Chat is sent. This is the most regular "event" and gives us an idea of the daily-activity of this project across all installations. Again, only the event is sent - we have no information on the nature or content of the chat itself.</li> 
 </ul> 
 <p>You can verify these claims by finding all locations <code>Telemetry.sendTelemetry</code> is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. No IP or other identifying information is collected. The Telemetry provider is <a href="https://posthog.com/">PostHog</a> - an open-source telemetry collection service.</p> 
 <p><a href="https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry(&amp;type=code">View all telemetry events in source code</a></p> 
</details> 
<h2>👋 Contributing</h2> 
<ul> 
 <li>create issue</li> 
 <li>create PR with branch name format of <code>&lt;issue number&gt;-&lt;short name&gt;</code></li> 
 <li>LGTM from core-team</li> 
</ul> 
<h2>🌟 Contributors</h2> 
<p><a href="https://github.com/mintplex-labs/anything-llm/graphs/contributors"><img alt="anythingllm contributors" src="https://contrib.rocks/image?repo=mintplex-labs/anything-llm" /></a></p> 
<p><a href="https://star-history.com/#mintplex-labs/anything-llm&amp;Date"><img alt="Star History Chart" src="https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&amp;type=Timeline" /></a></p> 
<h2>🔗 More Products</h2> 
<ul> 
 <li><strong><a href="https://github.com/mintplex-labs/vector-admin">VectorAdmin</a>:</strong> An all-in-one GUI &amp; tool-suite for managing vector databases.</li> 
 <li><strong><a href="https://github.com/Mintplex-Labs/openai-assistant-swarm">OpenAI Assistant Swarm</a>:</strong> Turn your entire library of OpenAI assistants into one single army commanded from a single agent.</li> 
</ul> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square" /></a></p> 
</div> 
<hr /> 
<p>Copyright © 2024 <a href="https://github.com/mintplex-labs">Mintplex Labs</a>. <br /> This project is <a href="https://raw.githubusercontent.com/Mintplex-Labs/anything-llm/master/LICENSE">MIT</a> licensed.</p> 
<!-- LINK GROUP -->
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>psf/black</title>
<link>https://github.com/psf/black</link>
<guid>https://github.com/psf/black</guid>
<content:encoded><![CDATA[
<div> 关键词：Black、代码格式化、自动化、项目一致性、生产力提升

总结：
Black 是一款强大的 Python 代码自动格式化工具，旨在通过提供一致且高效的方式，帮助开发者节省时间并提高代码质量。其核心优势在于：

1. **速度与确定性**：Black 能够快速地对整个文件进行格式化，且结果高度一致，无需担心因手部操作导致的细微差异。

2. **项目一致性**：在众多项目中，Black 已被广泛采用，确保了代码风格的一致性，无论项目大小，这使得团队协作更为顺畅，代码审查也更加高效。

3. **自动运行**：通过将 Black 作为脚本或命令行工具使用，可以轻松集成到日常开发流程中，自动执行格式化任务，减少人为干预。

4. **配置灵活**：虽然 Black 提供了默认设置以满足大多数需求，但也支持通过 pyproject.toml 文件进行项目特定的自定义配置，以适应不同团队和项目的具体需求。

5. **生产力提升**：正如 Mike Bayer 所言，使用 Black 后，开发者能以更低的成本进行重构和其他代码修改工作，显著提高了编程效率。 <div>
<p>The uncompromising Python code formatter</p><hr /><p><a href="https://black.readthedocs.io/en/stable/"><img alt="Black Logo" src="https://raw.githubusercontent.com/psf/black/main/docs/_static/logo2-readme.png" /></a></p> 
<h2 align="center">The Uncompromising Code Formatter</h2> 
<p align="center"> <a href="https://github.com/psf/black/actions"><img alt="Actions Status" src="https://github.com/psf/black/workflows/Test/badge.svg?sanitize=true" /></a> <a href="https://black.readthedocs.io/en/stable/?badge=stable"><img alt="Documentation Status" src="https://readthedocs.org/projects/black/badge/?version=stable" /></a> <a href="https://coveralls.io/github/psf/black?branch=main"><img alt="Coverage Status" src="https://coveralls.io/repos/github/psf/black/badge.svg?branch=main" /></a> <a href="https://github.com/psf/black/raw/main/LICENSE"><img alt="License: MIT" src="https://black.readthedocs.io/en/stable/_static/license.svg?sanitize=true" /></a> <a href="https://pypi.org/project/black/"><img alt="PyPI" src="https://img.shields.io/pypi/v/black" /></a> <a href="https://pepy.tech/project/black"><img alt="Downloads" src="https://static.pepy.tech/badge/black" /></a> <a href="https://anaconda.org/conda-forge/black/"><img alt="conda-forge" src="https://img.shields.io/conda/dn/conda-forge/black.svg?label=conda-forge" /></a> <a href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" /></a> </p> 
<blockquote> 
 <p>“Any color you like.”</p> 
</blockquote> 
<p><em>Black</em> is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, <em>Black</em> gives you speed, determinism, and freedom from <code>pycodestyle</code> nagging about formatting. You will save time and mental energy for more important matters.</p> 
<p>Blackened code looks the same regardless of the project you're reading. Formatting becomes transparent after a while and you can focus on the content instead.</p> 
<p><em>Black</em> makes code review faster by producing the smallest diffs possible.</p> 
<p>Try it out now using the <a href="https://black.vercel.app">Black Playground</a>. Watch the <a href="https://youtu.be/esZLCuWs_2Y">PyCon 2019 talk</a> to learn more.</p> 
<hr /> 
<p><strong><a href="https://black.readthedocs.io/en/stable">Read the documentation on ReadTheDocs!</a></strong></p> 
<hr /> 
<h2>Installation and usage</h2> 
<h3>Installation</h3> 
<p><em>Black</em> can be installed by running <code>pip install black</code>. It requires Python 3.8+ to run. If you want to format Jupyter Notebooks, install with <code>pip install "black[jupyter]"</code>.</p> 
<p>If you can't wait for the latest <em>hotness</em> and want to install from GitHub, use:</p> 
<p><code>pip install git+https://github.com/psf/black</code></p> 
<h3>Usage</h3> 
<p>To get started right away with sensible defaults:</p> 
<pre><code class="language-sh">black {source_file_or_directory}
</code></pre> 
<p>You can run <em>Black</em> as a package if running it as a script doesn't work:</p> 
<pre><code class="language-sh">python -m black {source_file_or_directory}
</code></pre> 
<p>Further information can be found in our docs:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/stable/usage_and_configuration/index.html">Usage and Configuration</a></li> 
</ul> 
<p><em>Black</em> is already <a href="https://github.com/psf/black#used-by">successfully used</a> by many projects, small and big. <em>Black</em> has a comprehensive test suite, with efficient parallel tests, and our own auto formatting and parallel Continuous Integration runner. Now that we have become stable, you should not expect large formatting changes in the future. Stylistic changes will mostly be responses to bug reports and support for new Python syntax. For more information please refer to <a href="https://black.readthedocs.io/en/stable/the_black_code_style/index.html">The Black Code Style</a>.</p> 
<p>Also, as a safety measure which slows down processing, <em>Black</em> will check that the reformatted code still produces a valid AST that is effectively equivalent to the original (see the <a href="https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#ast-before-and-after-formatting">Pragmatism</a> section for details). If you're feeling confident, use <code>--fast</code>.</p> 
<h2>The <em>Black</em> code style</h2> 
<p><em>Black</em> is a PEP 8 compliant opinionated formatter. <em>Black</em> reformats entire files in place. Style configuration options are deliberately limited and rarely added. It doesn't take previous formatting into account (see <a href="https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#pragmatism">Pragmatism</a> for exceptions).</p> 
<p>Our documentation covers the current <em>Black</em> code style, but planned changes to it are also documented. They're both worth taking a look at:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html">The <em>Black</em> Code Style: Current style</a></li> 
 <li><a href="https://black.readthedocs.io/en/stable/the_black_code_style/future_style.html">The <em>Black</em> Code Style: Future style</a></li> 
</ul> 
<p>Changes to the <em>Black</em> code style are bound by the Stability Policy:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/stable/the_black_code_style/index.html#stability-policy">The <em>Black</em> Code Style: Stability Policy</a></li> 
</ul> 
<p>Please refer to this document before submitting an issue. What seems like a bug might be intended behaviour.</p> 
<h3>Pragmatism</h3> 
<p>Early versions of <em>Black</em> used to be absolutist in some respects. They took after its initial author. This was fine at the time as it made the implementation simpler and there were not many users anyway. Not many edge cases were reported. As a mature tool, <em>Black</em> does make some exceptions to rules it otherwise holds.</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#pragmatism">The <em>Black</em> code style: Pragmatism</a></li> 
</ul> 
<p>Please refer to this document before submitting an issue just like with the document above. What seems like a bug might be intended behaviour.</p> 
<h2>Configuration</h2> 
<p><em>Black</em> is able to read project-specific default values for its command line options from a <code>pyproject.toml</code> file. This is especially useful for specifying custom <code>--include</code> and <code>--exclude</code>/<code>--force-exclude</code>/<code>--extend-exclude</code> patterns for your project.</p> 
<p>You can find more details in our documentation:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/stable/usage_and_configuration/the_basics.html#configuration-via-a-file">The basics: Configuration via a file</a></li> 
</ul> 
<p>And if you're looking for more general configuration documentation:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/stable/usage_and_configuration/index.html">Usage and Configuration</a></li> 
</ul> 
<p><strong>Pro-tip</strong>: If you're asking yourself "Do I need to configure anything?" the answer is "No". <em>Black</em> is all about sensible defaults. Applying those defaults will have your code in compliance with many other <em>Black</em> formatted projects.</p> 
<h2>Used by</h2> 
<p>The following notable open-source projects trust <em>Black</em> with enforcing a consistent code style: pytest, tox, Pyramid, Django, Django Channels, Hypothesis, attrs, SQLAlchemy, Poetry, PyPA applications (Warehouse, Bandersnatch, Pipenv, virtualenv), pandas, Pillow, Twisted, LocalStack, every Datadog Agent Integration, Home Assistant, Zulip, Kedro, OpenOA, FLORIS, ORBIT, WOMBAT, and many more.</p> 
<p>The following organizations use <em>Black</em>: Facebook, Dropbox, KeepTruckin, Lyft, Mozilla, Quora, Duolingo, QuantumBlack, Tesla, Archer Aviation.</p> 
<p>Are we missing anyone? Let us know.</p> 
<h2>Testimonials</h2> 
<p><strong>Mike Bayer</strong>, <a href="https://www.sqlalchemy.org/">author of <code>SQLAlchemy</code></a>:</p> 
<blockquote> 
 <p>I can't think of any single tool in my entire programming career that has given me a bigger productivity increase by its introduction. I can now do refactorings in about 1% of the keystrokes that it would have taken me previously when we had no way for code to format itself.</p> 
</blockquote> 
<p><strong>Dusty Phillips</strong>, <a href="https://smile.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&amp;field-keywords=dusty+phillips">writer</a>:</p> 
<blockquote> 
 <p><em>Black</em> is opinionated so you don't have to be.</p> 
</blockquote> 
<p><strong>Hynek Schlawack</strong>, <a href="https://www.attrs.org/">creator of <code>attrs</code></a>, core developer of Twisted and CPython:</p> 
<blockquote> 
 <p>An auto-formatter that doesn't suck is all I want for Xmas!</p> 
</blockquote> 
<p><strong>Carl Meyer</strong>, <a href="https://www.djangoproject.com/">Django</a> core developer:</p> 
<blockquote> 
 <p>At least the name is good.</p> 
</blockquote> 
<p><strong>Kenneth Reitz</strong>, creator of <a href="https://requests.readthedocs.io/en/latest/"><code>requests</code></a> and <a href="https://readthedocs.org/projects/pipenv/"><code>pipenv</code></a>:</p> 
<blockquote> 
 <p>This vastly improves the formatting of our code. Thanks a ton!</p> 
</blockquote> 
<h2>Show your style</h2> 
<p>Use the badge in your project's README.md:</p> 
<pre><code class="language-md">[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
</code></pre> 
<p>Using the badge in README.rst:</p> 
<pre><code>.. image:: https://img.shields.io/badge/code%20style-black-000000.svg
    :target: https://github.com/psf/black
</code></pre> 
<p>Looks like this: <a href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" /></a></p> 
<h2>License</h2> 
<p>MIT</p> 
<h2>Contributing</h2> 
<p>Welcome! Happy to see you willing to make the project better. You can get started by reading this:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/latest/contributing/the_basics.html">Contributing: The basics</a></li> 
</ul> 
<p>You can also take a look at the rest of the contributing docs or talk with the developers:</p> 
<ul> 
 <li><a href="https://black.readthedocs.io/en/latest/contributing/index.html">Contributing documentation</a></li> 
 <li><a href="https://discord.gg/RtVdv86PrH">Chat on Discord</a></li> 
</ul> 
<h2>Change log</h2> 
<p>The log has become rather long. It moved to its own file.</p> 
<p>See <a href="https://black.readthedocs.io/en/latest/change_log.html">CHANGES</a>.</p> 
<h2>Authors</h2> 
<p>The author list is quite long nowadays, so it lives in its own file.</p> 
<p>See <a href="https://raw.githubusercontent.com/psf/black/main/AUTHORS.md">AUTHORS.md</a></p> 
<h2>Code of Conduct</h2> 
<p>Everyone participating in the <em>Black</em> project, and in particular in the issue tracker, pull requests, and social media activity, is expected to treat other people with respect and more generally to follow the guidelines articulated in the <a href="https://www.python.org/psf/codeofconduct/">Python Community Code of Conduct</a>.</p> 
<p>At the same time, humor is encouraged. In fact, basic familiarity with Monty Python's Flying Circus is expected. We are not savages.</p> 
<p>And if you <em>really</em> need to slap somebody, do it with a fish while dancing.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>aceberg/WatchYourLAN</title>
<link>https://github.com/aceberg/WatchYourLAN</link>
<guid>https://github.com/aceberg/WatchYourLAN</guid>
<content:encoded><![CDATA[
<div> 关键词：WatchYourLAN、轻量级网络IP扫描器、web GUI、InfluxDB2、Grafana

总结：
WatchYourLAN是一款轻量级的网络IP扫描器，具备web图形用户界面。它提供了一些实用的功能，如在发现新主机时发送通知，监控主机的在线和离线历史记录，维护网络中所有主机的列表。同时，它支持将数据发送至InfluxDB2，进而生成Grafana仪表板以进行可视化展示。新版本（2.0）与旧版本（1.0）不兼容，建议使用v2标签的Docker镜像，并且从2.0开始支持VLAN、docker0等复杂的扫描场景。配置可以通过配置文件、GUI或环境变量完成，同时支持多种扫描设置和日志级别，且在Docker容器中持久化历史记录和存储数据。此外，用户还可以选择将数据导出至InfluxDB2，以便于在Grafana中创建更详细的监控图表。 <div>
<p>Lightweight network IP scanner. Can be used to notify about new hosts and monitor host online/offline history</p><hr /><h1><a href="https://github.com/aceberg/WatchYourLAN"> <img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/logo.png" width="20" /> </a>WatchYourLAN</h1> 
<br /> 
<p><a href="https://github.com/aceberg/WatchYourLAN/actions/workflows/main-docker-all.yml"><img alt="Docker" src="https://github.com/aceberg/WatchYourLAN/actions/workflows/main-docker-all.yml/badge.svg?sanitize=true" /></a> <a href="https://goreportcard.com/report/github.com/aceberg/WatchYourLAN"><img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/aceberg/WatchYourLAN" /></a> <a href="https://codeclimate.com/github/aceberg/WatchYourLAN/maintainability"><img alt="Maintainability" src="https://api.codeclimate.com/v1/badges/46b17f99edc1726b5d7d/maintainability" /></a> <a href="https://hub.docker.com/r/aceberg/watchyourlan"><img alt="Docker Image Size (latest semver)" src="https://img.shields.io/docker/image-size/aceberg/watchyourlan" /></a> <a href="https://github.com/aceberg/WatchYourLAN/discussions"><img alt="GitHub Discussions" src="https://img.shields.io/github/discussions/aceberg/WatchYourLAN" /></a></p> 
<p>Lightweight network IP scanner with web GUI. Features:</p> 
<ul> 
 <li>Send notification when new host is found</li> 
 <li>Monitor hosts online/offline history</li> 
 <li>Keep a list of all hosts in the network</li> 
 <li>Send data to <code>InfluxDB2</code> to make a <code>Grafana</code> dashboard</li> 
</ul> 
<blockquote> 
 <p>[!WARNING]<br /> This is version 2.0. Version 1.0 can be found in this branch: <a href="https://github.com/aceberg/WatchYourLAN/tree/v1">v1</a></p> 
</blockquote> 
<blockquote> 
 <p>[!CAUTION]<br /> <strong>BREAKING CHANGES!</strong> Version 2.0 is not compatible with v1.0. For now v2.0 docker images will be released under <code>v2</code> tag. It will be tagged <code>latest</code> in a few weeks (probably, in October).</p> 
</blockquote> 
<blockquote> 
 <p>[!TIP]<br /> WatchYourLAN supports <code>vlan</code>s, <code>docker0</code> and other complicated scans since <code>v2.0.1</code>. How-to <a href="https://github.com/aceberg/WatchYourLAN/raw/main/docs/VLAN_ARP_SCAN.md">here</a>.</p> 
</blockquote> 
<p><img alt="Screenshot_1" src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_1.png" /></p> 
<h2>More screenshots</h2> 
<details> 
 Expand 
 <p><img alt="Screenshot_5" src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_5.png" /><br /> <img alt="Screenshot_2" src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_2.png" /><br /> <img alt="Screenshot_3" src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_3.png" /><br /> <img alt="Screenshot_4" src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_4.png" /></p> 
</details> 
<h2>Quick start</h2> 
<details> 
 Expand 
 <p>Replace <code>$YOURTIMEZONE</code> with correct time zone and <code>$YOURIFACE</code> with network interface you want to scan. Network mode must be <code>host</code>. Set <code>$DOCKERDATAPATH</code> for container to save data:</p> 
 <pre><code class="language-sh">docker run --name wyl \
	-e "IFACES=$YOURIFACE" \
	-e "TZ=$YOURTIMEZONE" \
	--network="host" \
	-v $DOCKERDATAPATH/wyl:/data/WatchYourLAN \
    aceberg/watchyourlan:v2
</code></pre> 
 <p>Web GUI should be at <a href="http://localhost:8840">http://localhost:8840</a></p> 
</details> 
<h2>Config</h2> 
<details> 
 Expand 
 <p>Configuration can be done through config file, GUI or environment variables</p> 
 <h3>Basic config</h3> 
 <table> 
  <thead> 
   <tr> 
    <th>Variable</th> 
    <th>Description</th> 
    <th>Default</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>TZ</td> 
    <td>Set your timezone for correct time</td> 
    <td></td> 
   </tr> 
   <tr> 
    <td>HOST</td> 
    <td>Listen address</td> 
    <td>0.0.0.0</td> 
   </tr> 
   <tr> 
    <td>PORT</td> 
    <td>Port for web GUI</td> 
    <td>8840</td> 
   </tr> 
   <tr> 
    <td>THEME</td> 
    <td>Any theme name from <a href="https://bootswatch.com">https://bootswatch.com</a> in lowcase or <a href="https://github.com/aceberg/aceberg-bootswatch-fork">additional</a></td> 
    <td>sand</td> 
   </tr> 
   <tr> 
    <td>COLOR</td> 
    <td>Background color: light or dark</td> 
    <td>dark</td> 
   </tr> 
   <tr> 
    <td>NODEPATH</td> 
    <td>Path to local node modules</td> 
    <td></td> 
   </tr> 
   <tr> 
    <td>SHOUTRRR_URL</td> 
    <td>Link to any notification service supported by <a href="https://github.com/containrrr/shoutrrr">Shoutrrr</a> (gotify, email, telegram and others) or <a href="https://github.com/containrrr/shoutrrr/raw/main/docs/services/generic.md">Generic Webhook</a></td> 
    <td></td> 
   </tr> 
  </tbody> 
 </table> 
 <h3>Scan settings</h3> 
 <table> 
  <thead> 
   <tr> 
    <th>Variable</th> 
    <th>Description</th> 
    <th>Default</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>IFACES</td> 
    <td>Interfaces to scan. Could be one or more, separated by space. See <a href="https://github.com/aceberg/WatchYourLAN/raw/main/docs/VLAN_ARP_SCAN.md">docs/VLAN_ARP_SCAN.md</a>.</td> 
    <td></td> 
   </tr> 
   <tr> 
    <td>TIMEOUT</td> 
    <td>Time between scans (seconds)</td> 
    <td>120</td> 
   </tr> 
   <tr> 
    <td>ARP_ARGS</td> 
    <td>Arguments for <code>arp-scan</code>. Enable <code>debug</code> log level to see resulting command. (Example: <code>-r 1</code>). See <a href="https://github.com/aceberg/WatchYourLAN/raw/main/docs/VLAN_ARP_SCAN.md">docs/VLAN_ARP_SCAN.md</a>.</td> 
    <td></td> 
   </tr> 
   <tr> 
    <td>ARP_STRS ARP_STRS_JOINED</td> 
    <td>See <a href="https://github.com/aceberg/WatchYourLAN/raw/main/docs/VLAN_ARP_SCAN.md">docs/VLAN_ARP_SCAN.md</a>.</td> 
    <td></td> 
   </tr> 
   <tr> 
    <td>LOG_LEVEL</td> 
    <td>Log level: <code>debug</code>, <code>info</code>, <code>warn</code> or <code>error</code></td> 
    <td>info</td> 
   </tr> 
   <tr> 
    <td>TRIM_HIST</td> 
    <td>Remove history after (hours)</td> 
    <td>48</td> 
   </tr> 
   <tr> 
    <td>HIST_IN_DB</td> 
    <td>Store History in DB - if <code>false</code>, the History will be stored only in memory and will be lost on app restart. Though, it will keep the app DB smaller (and InfluxDB is recommended for long term History storage)</td> 
    <td>false</td> 
   </tr> 
   <tr> 
    <td>USE_DB</td> 
    <td>Either <code>sqlite</code> or <code>postgres</code></td> 
    <td>sqlite</td> 
   </tr> 
   <tr> 
    <td>PG_CONNECT</td> 
    <td>Address to connect to PostgreSQL. (Example: <code>postgres://username:password@192.168.0.1:5432/dbname?sslmode=disable</code>). Full list of URL parameters <a href="https://pkg.go.dev/github.com/lib/pq#hdr-Connection_String_Parameters">here</a></td> 
    <td></td> 
   </tr> 
  </tbody> 
 </table> 
 <h3>InfluxDB2 config</h3> 
 <p>This config matches Grafana's config for InfluxDB data source</p> 
 <table> 
  <thead> 
   <tr> 
    <th>Variable</th> 
    <th>Description</th> 
    <th>Default</th> 
    <th>Example</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>INFLUX_ENABLE</td> 
    <td>Enable export to InfluxDB2</td> 
    <td>false</td> 
    <td>true</td> 
   </tr> 
   <tr> 
    <td>INFLUX_SKIP_TLS</td> 
    <td>Skip TLS Verify</td> 
    <td>false</td> 
    <td>true</td> 
   </tr> 
   <tr> 
    <td>INFLUX_ADDR</td> 
    <td>Address:port of InfluxDB2 server</td> 
    <td></td> 
    <td><a href="https://192.168.2.3:8086/">https://192.168.2.3:8086/</a></td> 
   </tr> 
   <tr> 
    <td>INFLUX_BUCKET</td> 
    <td>InfluxDB2 bucket</td> 
    <td></td> 
    <td>test</td> 
   </tr> 
   <tr> 
    <td>INFLUX_ORG</td> 
    <td>InfluxDB2 org</td> 
    <td></td> 
    <td>home</td> 
   </tr> 
   <tr> 
    <td>INFLUX_TOKEN</td> 
    <td>Secret token, generated by InfluxDB2</td> 
    <td></td> 
    <td></td> 
   </tr> 
  </tbody> 
 </table> 
</details> 
<h2>Config file</h2> 
<details> 
 Expand 
 <p>Config file name is <code>config_v2.yaml</code>. Example:</p> 
 <pre><code class="language-yaml">arp_args: ""
color: dark
hist_in_db: false
host: 0.0.0.0
ifaces: enp4s0
influx_addr: ""
influx_bucket: ""
influx_enable: false
influx_org: ""
influx_skip_tls: false
influx_token: ""
log_level: info
nodepath: ""
pg_connect: ""
port: "8840"
shoutrrr_url: "gotify://192.168.0.1:8083/AwQqpAae.rrl5Ob/?title=Unknown host detected&amp;DisableTLS=yes"
theme: sand
timeout: 60
trim_hist: 48
use_db: sqlite
</code></pre> 
</details> 
<h2>Options</h2> 
<details> 
 Expand 
 <table> 
  <thead> 
   <tr> 
    <th>Key</th> 
    <th>Description</th> 
    <th>Default</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>-d</td> 
    <td>Path to config dir</td> 
    <td>/data/WatchYourLAN</td> 
   </tr> 
   <tr> 
    <td>-n</td> 
    <td>Path to node modules (see below)</td> 
    <td></td> 
   </tr> 
  </tbody> 
 </table> 
</details> 
<h2>Local network only</h2> 
<details> 
 Expand 
 <p>By default, this app pulls themes, icons and fonts from the internet. But, in some cases, it may be useful to have an independent from global network setup. I created a separate <a href="https://github.com/aceberg/my-dockerfiles/tree/main/node-bootstrap">image</a> with all necessary modules and fonts. Run with Docker:</p> 
 <pre><code class="language-sh">docker run --name node-bootstrap          \
    -p 8850:8850                          \
    aceberg/node-bootstrap
</code></pre> 
 <pre><code class="language-sh">docker run --name wyl \
	-e "IFACES=$YOURIFACE" \
	-e "TZ=$YOURTIMEZONE" \
	--network="host" \
	-v $DOCKERDATAPATH/wyl:/data/WatchYourLAN \
    aceberg/watchyourlan:v2 -n "http://$YOUR_IP:8850"
</code></pre> 
 <p>Or use <a href="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/docker-compose-local.yml">docker-compose</a></p> 
</details> 
<h2>API</h2> 
<details> 
 Expand 
 <p>Moved to <a href="https://github.com/aceberg/WatchYourLAN/raw/main/docs/API.md">docs/API.md</a></p> 
</details> 
<h2>Thanks</h2> 
<details> 
 Expand 
 <ul> 
  <li>All go packages listed in <a href="https://github.com/aceberg/WatchYourLAN/network/dependencies">dependencies</a></li> 
  <li>Favicon and logo: <a href="https://www.flaticon.com/free-icons/access-point">Access point icons created by Freepik - Flaticon</a></li> 
  <li><a href="https://getbootstrap.com/">Bootstrap</a></li> 
  <li>Themes: <a href="https://bootswatch.com">Free themes for Bootstrap</a></li> 
 </ul> 
</details>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>novuhq/novu</title>
<link>https://github.com/novuhq/novu</link>
<guid>https://github.com/novuhq/novu</guid>
<content:encoded><![CDATA[
<div> 关键词：Novu、多渠道通知、单个API、嵌入式通知中心、开源平台

总结：

Novu 是一款为开发者打造的统一多渠道通知基础设施，提供了一套全面的 API 解决方案，支持通过多种方式发送通知，包括应用内通知、推送通知、电子邮件、短信和聊天。这款平台的独特之处在于其强大的工作流管理功能，允许用户自定义通知流程并设定条件，确保通知以最有效的方式送达目标受众。

Novu 提供了丰富的特性，包括单个 API 管理所有消息提供商，完全托管的 GitOps 流程，以及使用 Zod 或 JSON Schema 定义工作流和步骤验证的能力。此外，它还支持 React 邮件集成、邮件模板管理和多渠道消息调试分析，以及实时更新的嵌入式通知中心。

Novu 的使用非常简单，只需要在终端中执行命令 `npx novu@latest dev` 即可开始。平台还提供了详细的文档和代码示例，帮助开发者快速上手。Novu 支持多种通知渠道，如电子邮件、短信、推送通知等，并且提供了一套易于集成的组件，允许开发者轻松地将实时通知中心添加到自己的 Web 应用中。通过使用 Novu，开发者可以更高效地管理多渠道通知，提升用户体验。 <div>
<p>Open-Source Notification Platform. Embeddable Notification Center, E-mail, Push and Slack Integrations.</p><hr /><div align="center"> 
 <a href="https://novu.co?utm_source=github" target="_blank"> 
   
   <source media="(prefers-color-scheme: dark)" /> 
   <img alt="Novu Logo" src="https://user-images.githubusercontent.com/2233092/213641043-3bbb3f21-3c53-4e67-afe5-755aeb222159.png" width="280" /> 
   </a> 
</div> 
<br /> 
<p align="center"> <a href="https://www.npmjs.com/package/@novu/node"> <img alt="NPM" src="https://img.shields.io/npm/v/@novu/node" /> </a> <a href="https://www.npmjs.com/package/@novu/node"> <img alt="npm downloads" src="https://img.shields.io/npm/dm/@novu/node" /> </a> <a href="https://github.com/novuhq/novu/raw/main/LICENSE"> <img alt="MIT" src="https://img.shields.io/github/license/novuhq/novu" /> </a> </p> 
<h1 align="center"> The open-source notification infrastructure for developers </h1> 
<div align="center">
  The ultimate service for managing multi-channel notifications with a single API. 
</div> 
<p align="center"> <br /> <a href="https://docs.novu.co" rel="dofollow"><strong>Explore the docs »</strong></a> <br /> <br /> <a href="https://github.com/novuhq/novu/issues/new?assignees=&amp;labels=type%3A+bug&amp;template=bug_report.yml&amp;title=%F0%9F%90%9B+Bug+Report%3A+">Report Bug</a> · <a href="https://github.com/novuhq/novu/issues/new?assignees=&amp;labels=feature&amp;template=feature_request.yml&amp;title=%F0%9F%9A%80+Feature%3A+">Request Feature</a> · <a href="https://discord.novu.co">Join Our Discord</a> · <a href="https://roadmap.novu.co">Roadmap</a> · <a href="https://twitter.com/novuhq">X</a> · <a href="https://notifications.directory">Notifications Directory</a> </p> 
<h2>⭐️ Why Novu?</h2> 
<p>Novu provides a unified API that makes it simple to send notifications through multiple channels, including In-App, Push, Email, SMS, and Chat. With Novu, you can create custom workflows and define conditions for each channel, ensuring that your notifications are delivered in the most effective way possible.</p> 
<h2>✨ Features</h2> 
<ul> 
 <li>🌈 Single API for all messaging providers (In-App, Email, SMS, Push, Chat)</li> 
 <li>💅 Fully managed GitOps Flow, deployed from your CI</li> 
 <li>🔥 Define workflow and step validations with Zod or JSON Schema</li> 
 <li>💌 React Email/Maizzle/MJML integrations</li> 
 <li>🚀 Equipped with a CMS for advanced layouts and design management</li> 
 <li>🛡 Debug and analyze multi-channel messages in a single dashboard</li> 
 <li>📦 Embeddable notification center with real-time updates</li> 
 <li>👨‍💻 Community-driven</li> 
</ul> 
<h2>🚀 Getting Started</h2> 
<p>To get started, type the following command in your Terminal.</p> 
<pre><code class="language-bash">npx novu@latest dev
</code></pre> 
<h2>📚 Table Of Contents</h2> 
<ul> 
 <li><a href="https://github.com/novuhq/novu#-getting-started">Getting Started</a></li> 
 <li><a href="https://github.com/novuhq/novu#-gitops">GitOps &amp; React Email Integration</a></li> 
 <li><a href="https://github.com/novuhq/novu#embeddable-notification-center">Embeddable notification center</a></li> 
 <li><a href="https://github.com/novuhq/novu#providers">Providers</a> 
  <ul> 
   <li><a href="https://github.com/novuhq/novu#-email">Email</a></li> 
   <li><a href="https://github.com/novuhq/novu#-sms">SMS</a></li> 
   <li><a href="https://github.com/novuhq/novu#-push">Push</a></li> 
   <li><a href="https://github.com/novuhq/novu#-chat">Chat</a></li> 
   <li><a href="https://github.com/novuhq/novu#-in-app">In-App</a></li> 
   <li><a href="https://github.com/novuhq/novu#other-coming-soon">Others</a></li> 
  </ul> </li> 
 <li><a href="https://github.com/novuhq/novu#-need-help">Need Help?</a></li> 
 <li><a href="https://github.com/novuhq/novu#-links">Links</a></li> 
 <li><a href="https://github.com/novuhq/novu#%EF%B8%8F-license">License</a></li> 
</ul> 
<h2>Notification Workflows as Code</h2> 
<p>For API documentation and reference, please visit our <a href="https://docs.novu.co/getting-started/introduction?utm_campaign=github-readme">API Reference</a>.</p> 
<pre><code class="language-ts">import { workflow, CronExpression } from '@novu/framework';
import { z } from 'zod';
import { render } from '@react-email/render';

const commentWorkflow = workflow('comment-workflow', async (event) =&gt; {
  const digest = await event.step.digest('digest-comments', (controls) =&gt; ({
    cron: controls.schedule
  }), { controlSchema: z.object({ schedule: z.nativeEnum(CronExpression) }) });

  await event.step.email('digest-email', async (controls) =&gt; ({
    subject: controls.subject,
    body: render(&lt;WeeklyDigestEmail { ...controls } events = { digest.events } /&gt;)
  }), {
    skip: () =&gt; !digest.events.length,
    controlSchema: z.object({
      subject: z.string().default('Hi {{subscriber.firstName}} - Acme Comments'),
      openAiModel: z.enum(['gpt-3.5-turbo', 'gpt-4o']).default('gpt-4o'),
      aiPrompt: z.string().default('Produce a concise comment digest'),
    })
  });
}, { payloadSchema: z.object({ name: z.string(), comment: z.string() }) });

await commentWorkflow.trigger({
  payload: { name: 'John', comment: 'Are you free to give me a call?' },
  to: 'jane@acme.com'
});

</code></pre> 
<h2>Embeddable Notification Center</h2> 
<p>Using the Novu API and admin panel, you can easily add a real-time notification center to your web app without building it yourself. You can use our <a href="https://docs.novu.co/notification-center/client/react/get-started?utm_campaign=github-readme">React</a> / <a href="https://docs.novu.co/notification-center/client/vue?utm_campaign=github-readme">Vue</a> / <a href="https://docs.novu.co/notification-center/client/angular?utm_campaign=github-readme">Angular</a> components or an <a href="https://docs.novu.co/notification-center/client/iframe?utm_campaign=github-readme">iframe embed</a>, as well as a <a href="https://docs.novu.co/notification-center/client/web-component?utm_campaign=github-readme">Web component</a>.</p> 
<div align="center"> 
 <img alt="notification-center-912bb96e009fb3a69bafec23bcde00b0" src="https://user-images.githubusercontent.com/80174214/193887395-f1c95042-b4e6-480e-a89c-a78aa247fa90.gif" width="762" /> 
 <p>Read more about how to add a notification center to your app with the Novu API <a href="https://docs.novu.co/notification-center/getting-started?utm_campaign=github-readme">here</a></p> 
 <p align="center"> <a href="https://docs.novu.co/sdks/react?utm_campaign=github-readme">React Component</a> · <a href="https://docs.novu.co/sdks/vue?utm_campaign=github-readme">Vue Component</a> · <a href="https://docs.novu.co/sdks/angular?utm_campaign=github-readme">Angular Component</a> </p> 
</div> 
<h2>Providers</h2> 
<p>Novu provides a single API to manage providers across multiple channels with a simple-to-use interface.</p> 
<h4>💌 Email</h4> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/sendgrid">Sendgrid</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/netcore">Netcore</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/mailgun">Mailgun</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/ses">SES</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/postmark">Postmark</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/nodemailer">Custom SMTP</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/mailjet">Mailjet</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/mandrill">Mandrill</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/sendinblue">SendinBlue</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/mailersend">MailerSend</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/infobip">Infobip</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/resend">Resend</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/sparkpost">SparkPost</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/outlook365">Outlook 365</a></li> 
</ul> 
<h4>📞 SMS</h4> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/twilio">Twilio</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/plivo">Plivo</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/sns">SNS</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/nexmo">Nexmo - Vonage</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/sms77">Sms77</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/telnyx">Telnyx</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/termii">Termii</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/gupshup">Gupshup</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/sms-central">SMS Central</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/maqsam">Maqsam</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/forty-six-elks">46elks</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/clickatell">Clickatell</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/burst-sms">Burst SMS</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/firetext">Firetext</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/infobip">Infobip</a></li> 
 <li><input disabled="disabled" type="checkbox" /> Bandwidth</li> 
 <li><input disabled="disabled" type="checkbox" /> RingCentral</li> 
</ul> 
<h4>📱 Push</h4> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/fcm">FCM</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/expo">Expo</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/apns">APNS</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/one-signal">OneSignal</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/pushpad">Pushpad</a></li> 
 <li><input disabled="disabled" type="checkbox" /> Pushwoosh</li> 
</ul> 
<h4>👇 Chat</h4> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/slack">Slack</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/discord">Discord</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/ms-teams">MS Teams</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/novuhq/novu/tree/main/providers/mattermost">Mattermost</a></li> 
</ul> 
<h4>📱 In-App</h4> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://docs.novu.co/notification-center/getting-started?utm_campaign=github-readme">Novu</a></li> 
</ul> 
<h4>Other (Coming Soon...)</h4> 
<ul> 
 <li><input disabled="disabled" type="checkbox" /> PagerDuty</li> 
</ul> 
<h2>📋 Read Our Code Of Conduct</h2> 
<p>Before you begin coding and collaborating, please read our <a href="https://github.com/novuhq/novu/raw/main/CODE_OF_CONDUCT.md">Code of Conduct</a> thoroughly to understand the standards (that you are required to adhere to) for community engagement. As part of our open-source community, we hold ourselves and other contributors to a high standard of communication. As a participant and contributor to this project, you agree to abide by our <a href="https://github.com/novuhq/novu/raw/main/CODE_OF_CONDUCT.md">Code of Conduct</a>.</p> 
<h2>💻 Need Help?</h2> 
<p>We are more than happy to help you. If you are getting any errors or facing problems while working on this project, join our <a href="https://discord.novu.co">Discord server</a> and ask for help. We are open to discussing anything related to the project.</p> 
<h2>🔗 Links</h2> 
<ul> 
 <li><a href="https://novu.co?utm_campaign=github-readme">Home page</a></li> 
 <li><a href="https://github.com/novuhq/novu/raw/main/CONTRIBUTING.md">Contribution Guidelines</a></li> 
 <li><a href="https://docs.novu.co/community/run-in-local-machine?utm_campaign=github-readme">Run Novu Locally</a></li> 
</ul> 
<h2>🛡️ License</h2> 
<p>Novu is licensed under the MIT License - see the <a href="https://github.com/novuhq/novu/raw/main/LICENSE">LICENSE</a> file for details.</p> 
<h2>💪 Thanks To All Contributors</h2> 
<p>Thanks a lot for spending your time helping Novu grow. Keep rocking 🥂</p> 
<a href="https://novu.co/contributors?utm_source=github"> <img alt="Contributors" src="https://contributors-img.web.app/image?repo=novuhq/novu" /> </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>processing/p5.js</title>
<link>https://github.com/processing/p5.js</link>
<guid>https://github.com/processing/p5.js</guid>
<content:encoded><![CDATA[
<div> 关键词：p5.js、创意编码、社区、开源、教育

总结：

p5.js是一个面向艺术家、设计师、学生和任何想要学习编程并在线上进行创意表达的人的免费、开源JavaScript库。它基于Processing的核心原则，提供了一套用于绘制的工具，支持创作音频视觉、交互式、实验性和生成性作品。p5.js鼓励迭代和探索式的编程以实现创造性表达，其友好、多元化的社区分享艺术、代码和学习资源，致力于促进所有声音的提升。

该平台提供全面的教程、示例代码和在线编码环境，让初学者也能轻松上手。p5.js的用户可以访问多个语言版本和丰富的示例库，同时社区还提供了大量的扩展库，增强了其功能。此外，p5.js强调了对所有背景人群的开放性和包容性，致力于消除参与创造性的技术障碍。

p5.js由志愿者团队维护，鼓励各种形式的贡献，从代码编写到文档更新，甚至讨论，都是欢迎的。通过参与贡献，开发者不仅能为项目做出贡献，还能在社区中获得支持和灵感。p5.js的领导和管理采取轮换制，确保项目的持续发展和方向的明确性。p5.js不仅是一个工具库，更是一个充满活力的学习和创作平台，为艺术家、设计师、教育者和初学者提供了一个自由创作的空间。 <div>
<p>p5.js is a client-side JS platform that empowers artists, designers, students, and anyone to learn to code and express themselves creatively on the web. It is based on the core principles of Processing. http://twitter.com/p5xjs —</p><hr /><p><a href="https://www.npmjs.com/package/p5"><img alt="npm version" src="https://badge.fury.io/js/p5.svg?sanitize=true" /></a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#contributors"><img alt="All Contributors" src="https://img.shields.io/github/all-contributors/processing/p5.js?color=ee8449&amp;style=flat-square" /></a> <a href="https://www.npmjs.com/package/p5"><img alt="Total Downloads" src="https://img.shields.io/npm/dt/p5" /></a></p> 
<h1><a href="https://p5js.org">p5.js</a></h1> 
<p>Welcome! 👋👋🏿👋🏽👋🏻👋🏾👋🏼</p> 
<p>p5.js is a free and open-source JavaScript library for <a href="https://p5js.org/contribute/access">accessible</a> creative coding. It is a nurturing community, an approachable language, an exploratory tool, an accessible environment, an inclusive platform, welcoming and playful for artists, designers, educators, beginners, and anyone else!</p> 
<table> 
 <tbody>
  <tr> 
   <td> <pre><code class="language-js">function setup() {
&nbsp; createCanvas(400, 400);
&nbsp;&nbsp;background(255);
}

function draw() {
&nbsp; circle(mouseX, mouseY, 80);
}
</code></pre> </td> 
   <td> <img height="200" src="https://raw.githubusercontent.com/processing/p5.js/main/contributor_docs/images/p5-readme-sketch.png" width="200" /> </td> 
  </tr> 
 </tbody>
</table> 
<p><a href="https://p5js.org/tutorials/get-started/">Get Started</a> — <a href="https://p5js.org/reference">Reference</a> — <a href="https://p5js.org/tutorials">Tutorials</a> — <a href="https://p5js.org/examples/">Examples</a> — <a href="https://p5js.org/libraries">Libraries</a> — <a href="https://discourse.processing.org/c/p5js">Forum</a> — <a href="https://discord.gg/SHQ8dH25r9">Discord</a></p> 
<h2>About</h2> 
<p>p5.js is built and organized to prioritize <a href="https://p5js.org/community">accessibility, inclusivity, community, and joy</a>. Similar to sketching, p5.js has a full set of tools to draw. It also supports creating audio-visual, interactive, experimental, and generative works for the web. p5.js enables thinking of a web page as your sketch. p5.js is accessible in multiple languages and has an expansive <a href="https://p5js.org/reference/">documentation</a> with visual examples. You can find <a href="https://p5js.org/learn/">tutorials</a> on the p5.js website and start coding right now in the <a href="https://editor.p5js.org/">p5.js web editor</a>. You can extend p5.js with many community-created <a href="https://p5js.org/libraries/">libraries</a> that bring different capabilities. Its community provides endless inspiration and support for creators.</p> 
<p>p5.js encourages iterative and exploratory code for creative expression. Its friendly, diverse community shares art, code, and learning resources to help elevate all voices. We share our values in open source and access for all, to learn, create, imagine, design, share and code freely.</p> 
<h2>Community</h2> 
<p>The p5.js community shares an interest in exploring the creation of art and design with technology. We are a community of, and in solidarity with, people from every gender identity and expression, sexual orientation, race, ethnicity, language, neuro-type, size, disability, class, caste, religion, culture, subculture, immigration status, age, skill level, occupation, and background. We stand in solidarity with justice and liberation movements. We work to acknowledge, dismantle, and prevent barriers to access p5.js code and the p5.js community.</p> 
<p>Learn more about <a href="https://p5js.org/community/">our community</a> and read our community statement and <a href="https://github.com/processing/p5.js/raw/main/CODE_OF_CONDUCT.md">code of conduct</a>. You can directly support our work with p5.js by donating to <a href="https://processingfoundation.org/support">the Processing Foundation</a>.</p> 
<h2>Issues</h2> 
<p>If you have found a bug in the p5.js library or want to request new features, feel free to file an issue! See our <a href="https://p5js.org/contribute/contributor_guidelines">contributor guidelines</a> for a full reference of our contribution process. A set of templates for reporting issues and requesting features are provided to assist you (and us!). Different parts of p5.js are in different repositories. You can open an issue on each of them through these links:</p> 
<p><a href="https://github.com/processing/p5.js/issues">p5.js</a> — <a href="https://github.com/processing/p5.js-website/issues">p5.js website</a> —- <a href="https://github.com/processing/p5.js-web-editor/issues">p5.js web editor</a></p> 
<p>p5.js is maintained mostly by volunteers, so we thank you for your patience as we try to address your issues as soon as we can.</p> 
<h2>Get Started for Contributors</h2> 
<p>p5.js is a collaborative project with many contributors, mostly volunteers, and you are invited to help. All types of involvement are welcome. See the <a href="https://p5js.org/contribute">contribute</a> for more in-depth details about contributing to different areas of the project, including code, bug fixes, documentation, discussion, and more.</p> 
<p>A quick Getting Started with the Build and setting up the repository could be found <a href="https://p5js.org/contribute/contributor_guidelines/#quick-get-started-for-developers">here</a>.</p> 
<h2>Stewards</h2> 
<p>Stewards are contributors who are particularly involved, familiar, or responsive to certain areas of the project. Their role is to help provide context and guidance to others working on p5.js. If you have a question about contributing to a particular area, you can tag the listed steward in an issue or pull request. They may also weigh in on feature requests and guide the overall direction of their area, with the input of the community. You can read more about the organization of the project in our p5.js <a href="https://p5js.org/contribute/contributor_guidelines">Contributor Guidelines</a> and p5.js <a href="https://p5js.org/contribute/steward_guidelines">Steward Guidelines</a>.</p> 
<p>Anyone interested can volunteer to be a steward! There are no specific requirements for expertise, just an interest in actively learning and participating. If you’re familiar with or interested in actively learning and participating in some of the p5.js areas below, please reply to <a href="https://github.com/processing/p5.js/issues/5719">this issue</a> mentioning which area(s) you are interested in volunteering as a steward! 👋👋👋</p> 
<p>p5.js was created by <a href="https://github.com/lmccart">Lauren Lee McCarthy</a> in 2013 as a new interpretation of Processing for the context of the web. Since then we have allowed ourselves space to deviate and grow, while drawing inspiration from Processing and our shared community. p5.js is sustained by a community of contributors, with support from the Processing Foundation. p5.js follows a rotating leadership model started in 2020, and <a href="https://github.com/qianqianye">Qianqian Ye</a> has been leading p5.js since 2021. Learn more about the <a href="https://p5js.org/people/">people</a> behind p5.js.</p> 
<p>Current Lead/Mentor</p> 
<ul> 
 <li><a href="https://github.com/qianqianye">@qianqianye</a> - p5.js Lead，2021-present</li> 
 <li><a href="https://github.com/limzykenneth">@limzykenneth</a> - p5.js Mentor，2023-present</li> 
</ul> 
<p>Lead/Mentor Alumni</p> 
<ul> 
 <li><a href="https://github.com/lmccart">@lmccart</a>- p5.js Creator</li> 
 <li><a href="https://github.com/outofambit">@outofambit</a> - p5.js Co-Lead 2021-22, Mentor 2022-2023</li> 
 <li><a href="https://github.com/mcturner1995">@mcturner1995</a> - p5.js Lead 2020</li> 
</ul> 
<table> 
 <thead> 
  <tr> 
   <th>Area</th> 
   <th>Steward(s)</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>Overall</td> 
   <td><a href="https://github.com/qianqianye">@qianqianye</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/accessibility">Accessibility</a></td> 
   <td><a href="https://github.com/calebfoss">@calebfoss</a>, <a href="https://github.com/cosmicbhejafry">@cosmicbhejafry</a>, <a href="https://github.com/apoorva-a98">@apoorva-a98</a>, <a href="https://github.com/tedkmburu">@tedkmburu</a>, <a href="https://github.com/Zarkv">@Zarkv</a>, <a href="https://github.com/SkylerW99">@SkylerW99</a>, <a href="https://github.com/itsjoopark">@itsjoopark</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/nhasalajoshi">@nhasalajoshi</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/color">Color</a></td> 
   <td><a href="https://github.com/paulaxisabel">@paulaxisabel</a>, <a href="https://github.com/SoundaryaKoutharapu">@SoundaryaKoutharapu</a>, <a href="https://github.com/mrbrack">@mrbrack</a>, <a href="https://github.com/TJ723">@TJ723</a>, <a href="https://github.com/Zarkv">@Zarkv</a>, <a href="https://github.com/SkylerW99">@SkylerW99</a>, <a href="https://github.com/ramya202000">@ramya202000</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/robin-haxx">@robin-haxx</a>, <a href="https://github.com/hiddenenigma">@hiddenenigma</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/core">Core</a>/Environment/Rendering</td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a>, <a href="https://github.com/davepagurek">@davepagurek</a>, <a href="https://github.com/ChihYungChang">@ChihYungChang</a>, <a href="https://github.com/teragramgius">@teragramgius</a>, <a href="https://github.com/tuminzee">@tuminzee</a>, <a href="https://github.com/Zarkv">@Zarkv</a>, <a href="https://github.com/robin-haxx">@robin-haxx</a>, <a href="https://github.com/Gaurav-1306">@Gaurav-1306</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/data">Data</a></td> 
   <td><a href="https://github.com/angelabelle">@angelabelle</a>, <a href="https://github.com/shahankhatch">@shahankhatch</a>, <a href="https://github.com/TanviKumar">@TanviKumar</a>, <a href="https://github.com/SkylerW99">@SkylerW99</a>, <a href="https://github.com/nhasalajoshi">@nhasalajoshi</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/dom">DOM</a></td> 
   <td><a href="https://github.com/SarveshLimaye">@SarveshLimaye</a>, <a href="https://github.com/SoundaryaKoutharapu">@SoundaryaKoutharapu</a>, <a href="https://github.com/ramya202000">@ramya202000</a>, <a href="https://github.com/BamaCharanChhandogi">@BamaCharanChhandogi</a>, <a href="https://github.com/Obi-Engine10">@Obi-Engine10</a>, <a href="https://github.com/MarceloGoncalves">@MarceloGoncalves</a>, <a href="https://github.com/hiddenenigma">@hiddenenigma</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/events">Events</a></td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a>, <a href="https://github.com/richardegil">@richardegil</a>, <a href="https://github.com/angelabelle">@angelabelle</a>, <a href="https://github.com/littlejacinthe">@littlejacinthe</a>, <a href="https://github.com/TanviKumar">@TanviKumar</a>, <a href="https://github.com/tuminzee">@tuminzee</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/image">Image</a></td> 
   <td><a href="https://github.com/cgusb">@cgusb</a>, <a href="https://github.com/albertomancia">@albertomancia</a>, <a href="https://github.com/ramya202000">@ramya202000</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/robin-haxx">@robin-haxx</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/io">IO</a></td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a>, <a href="https://github.com/Pritam1136">@Pritam1136</a>, <a href="https://github.com/shahankhatch">@shahankhatch</a>, <a href="https://github.com/TanviKumar">@TanviKumar</a>, <a href="https://github.com/jeanetteandrews">@jeanetteandrews</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/math">Math</a></td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a>, <a href="https://github.com/ericnlchen">@ericnlchen</a>, <a href="https://github.com/ChihYungChang">@ChihYungChang</a>, <a href="https://github.com/bsubbaraman">@bsubbaraman</a>, <a href="https://github.com/albertomancia">@albertomancia</a>, <a href="https://github.com/JazerUCSB">@JazerUCSB</a>, <a href="https://github.com/tedkmburu">@tedkmburu</a>, <a href="https://github.com/perminder-17">@perminder-17</a>, <a href="https://github.com/Obi-Engine10">@Obi-Engine10</a>, <a href="https://github.com/jeanetteandrews">@jeanetteandrews</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/typography">Typography</a></td> 
   <td><a href="https://github.com/dhowe">@dhowe</a>, <a href="https://github.com/paulaxisabel">@paulaxisabel</a>, <a href="https://github.com/SarveshLimaye">@SarveshLimaye</a>, <a href="https://github.com/SkylerW99">@SkylerW99</a>, <a href="https://github.com/BamaCharanChhandogi">@BamaCharanChhandogi</a>, <a href="https://github.com/Obi-Engine10">@Obi-Engine10</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/singshris">@singshris</a>, <a href="https://github.com/hiddenenigma">@hiddenenigma</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/utilities">Utilities</a></td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a>, <a href="https://github.com/glopzel">@glopzel</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/webgl">WebGL</a></td> 
   <td><a href="https://github.com/davepagurek">@davepagurek</a>, <a href="https://github.com/aferriss">@aferriss</a>, <a href="https://github.com/aceslowman">@aceslowman</a>, <a href="https://github.com/ShenpaiSharma">@ShenpaiSharma</a>, <a href="https://github.com/ChihYungChang">@ChihYungChang</a>, <a href="https://github.com/teragramgius">@teragramgius</a>, <a href="https://github.com/JazerUCSB">@JazerUCSB</a>, <a href="https://github.com/richardegil">@richardegil</a>, <a href="https://github.com/itsjoopark">@itsjoopark</a>, <a href="https://github.com/Gaurav-1306">@Gaurav-1306</a>, <a href="https://github.com/jeanetteandrews">@jeanetteandrews</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/raw/main/src/core/internationalization.js">Internalization</a></td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/src/core/friendly_errors">Friendly Errors</a></td> 
   <td><a href="https://github.com/richardegil">@richardegil</a>, <a href="https://github.com/itsjoopark">@itsjoopark</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/bisabi-01">@bisabi-01</a>, <a href="https://github.com/singshris">@singshris</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.js/tree/main/contributor_docs">Contributor Docs</a></td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a>, <a href="https://github.com/asukaminato0721">@asukaminato0721</a>, <a href="https://github.com/SoundaryaKoutharapu">@SoundaryaKoutharapu</a>, <a href="https://github.com/richardegil">@richardegil</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/bayomayo">@bayomayo</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/processing/p5.sound.js">p5.sound</a></td> 
   <td><a href="https://github.com/miguellacorte">@miguellacorte</a>, <a href="https://github.com/JazerUCSB">@JazerUCSB</a>, <a href="https://github.com/angelabelle">@angelabelle</a>, <a href="https://github.com/littlejacinthe">@littlejacinthe</a>, <a href="https://github.com/hannahvy">@hannahvy</a>, <a href="https://github.com/glopzel">@glopzel</a>, <a href="https://github.com/singshris">@singshris</a>, <a href="https://github.com/jeanetteandrews">@jeanetteandrews</a></td> 
  </tr> 
  <tr> 
   <td>Build Process/Unit Testing</td> 
   <td><a href="https://github.com/limzykenneth">@limzykenneth</a></td> 
  </tr> 
 </tbody> 
</table> 
<h2>Contributors</h2> 
<p>We recognize all types of contributions. This project follows the <a href="https://github.com/all-contributors/all-contributors">all-contributors specification</a> and the <a href="https://allcontributors.org/docs/en/emoji-key">Emoji Key</a> ✨ for contribution types. Instructions to add yourself or add contribution emojis to your name are <a href="https://github.com/processing/p5.js/issues/2309">here</a>. You can also post an issue or comment on a pull request with the text: <code>@all-contributors please add @YOUR-USERNAME for THINGS</code> (where <code>THINGS</code> is a comma-separated list of entries from the <a href="https://allcontributors.org/docs/en/emoji-key">list of possible contribution types</a>) and our nice bot will add you.</p> 
<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --> 
<!-- prettier-ignore-start --> 
<!-- markdownlint-disable --> 
<table> 
 <tbody> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://lauren-mccarthy.com"><img alt="Lauren McCarthy" src="https://avatars3.githubusercontent.com/u/191056?v=4?s=120" width="120px;" /><br /><sub><b>Lauren McCarthy</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jasonsigal.cc"><img alt="Jason Sigal" src="https://avatars2.githubusercontent.com/u/504124?v=4?s=120" width="120px;" /><br /><sub><b>Jason Sigal</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/KarenPunkPunk"><img alt="Karen" src="https://avatars3.githubusercontent.com/u/1695075?v=4?s=120" width="120px;" /><br /><sub><b>Karen</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.evelyneastmond.com"><img alt="Evelyn Eastmond" src="https://avatars1.githubusercontent.com/u/699840?v=4?s=120" width="120px;" /><br /><sub><b>Evelyn Eastmond</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.shiffman.net"><img alt="Daniel Shiffman" src="https://avatars0.githubusercontent.com/u/191758?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Shiffman</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://reas.com"><img alt="Casey Reas" src="https://avatars2.githubusercontent.com/u/677774?v=4?s=120" width="120px;" /><br /><sub><b>Casey Reas</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://fathom.info"><img alt="Ben Fry" src="https://avatars1.githubusercontent.com/u/1623101?v=4?s=120" width="120px;" /><br /><sub><b>Ben Fry</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://limzykenneth.com"><img alt="Kenneth Lim" src="https://avatars3.githubusercontent.com/u/7543950?v=4?s=120" width="120px;" /><br /><sub><b>Kenneth Lim</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Alimzykenneth" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=limzykenneth" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=limzykenneth" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.katehollenbach.com"><img alt="kate hollenbach" src="https://avatars0.githubusercontent.com/u/78966?v=4?s=120" width="120px;" /><br /><sub><b>kate hollenbach</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mlarghydracept"><img alt="Stalgia Grigg" src="https://avatars2.githubusercontent.com/u/10382506?v=4?s=120" width="120px;" /><br /><sub><b>Stalgia Grigg</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/machinic"><img alt="Jerel Johnson" src="https://avatars3.githubusercontent.com/u/3985997?v=4?s=120" width="120px;" /><br /><sub><b>Jerel Johnson</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sakshamsaxena.in"><img alt="Saksham Saxena" src="https://avatars2.githubusercontent.com/u/8774516?v=4?s=120" width="120px;" /><br /><sub><b>Saksham Saxena</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/ed_saber"><img alt="saber khan" src="https://avatars3.githubusercontent.com/u/11218401?v=4?s=120" width="120px;" /><br /><sub><b>saber khan</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dhowe"><img alt="Daniel Howe" src="https://avatars3.githubusercontent.com/u/737638?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Howe</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://kevinsiwoff.com"><img alt="Kevin Siwoff" src="https://avatars1.githubusercontent.com/u/1585036?v=4?s=120" width="120px;" /><br /><sub><b>Kevin Siwoff</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://portfolio.toolness.org/"><img alt="Atul Varma" src="https://avatars2.githubusercontent.com/u/124687?v=4?s=120" width="120px;" /><br /><sub><b>Atul Varma</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.jessklein.is/"><img alt="Jess Klein" src="https://avatars3.githubusercontent.com/u/535012?v=4?s=120" width="120px;" /><br /><sub><b>Jess Klein</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://unoseistres.com"><img alt="uno seis tres" src="https://avatars1.githubusercontent.com/u/7158943?v=4?s=120" width="120px;" /><br /><sub><b>uno seis tres</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.susanev.com/"><img alt="susan evans" src="https://avatars3.githubusercontent.com/u/5489125?v=4?s=120" width="120px;" /><br /><sub><b>susan evans</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sasj.tumblr.com"><img alt="Saskia Freeke" src="https://avatars3.githubusercontent.com/u/2619912?v=4?s=120" width="120px;" /><br /><sub><b>Saskia Freeke</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.phoenixperry.com"><img alt="Phoenix Perry" src="https://avatars0.githubusercontent.com/u/783625?v=4?s=120" width="120px;" /><br /><sub><b>Phoenix Perry</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://s01e01.xyz/jct"><img alt="jesse cahn-thompson" src="https://avatars1.githubusercontent.com/u/2850174?v=4?s=120" width="120px;" /><br /><sub><b>jesse cahn-thompson</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/lee2sman"><img alt="Lee T" src="https://avatars1.githubusercontent.com/u/7377908?v=4?s=120" width="120px;" /><br /><sub><b>Lee T</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.cargocollective.com/chellyjin"><img alt="Chelly Jin" src="https://avatars0.githubusercontent.com/u/26236471?v=4?s=120" width="120px;" /><br /><sub><b>Chelly Jin</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://L05.is"><img alt="L05" src="https://avatars0.githubusercontent.com/u/3998826?v=4?s=120" width="120px;" /><br /><sub><b>L05</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.diygirls.org"><img alt="DIYgirls" src="https://avatars3.githubusercontent.com/u/1680038?v=4?s=120" width="120px;" /><br /><sub><b>DIYgirls</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/lam802"><img alt="lam802" src="https://avatars3.githubusercontent.com/u/8697852?v=4?s=120" width="120px;" /><br /><sub><b>lam802</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.mayaman.cc"><img alt="Maya Man" src="https://avatars0.githubusercontent.com/u/8224678?v=4?s=120" width="120px;" /><br /><sub><b>Maya Man</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tegacodes"><img alt="Tega Brain" src="https://avatars0.githubusercontent.com/u/5488045?v=4?s=120" width="120px;" /><br /><sub><b>Tega Brain</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/luisaph"><img alt="luisaph" src="https://avatars3.githubusercontent.com/u/295879?v=4?s=120" width="120px;" /><br /><sub><b>luisaph</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/almchung"><img alt="AlM Chng" src="https://avatars2.githubusercontent.com/u/22488500?v=4?s=120" width="120px;" /><br /><sub><b>AlM Chng</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://montoyamoraga.io"><img alt="aarón montoya-moraga" src="https://avatars3.githubusercontent.com/u/3926350?v=4?s=120" width="120px;" /><br /><sub><b>aarón montoya-moraga</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/catarak"><img alt="Cassie Tarakajian" src="https://avatars1.githubusercontent.com/u/6063380?v=4?s=120" width="120px;" /><br /><sub><b>Cassie Tarakajian</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.niklaspeters.com"><img alt="Niklas Peters" src="https://avatars0.githubusercontent.com/u/20650298?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Niklas Peters</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nikfm" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-nikfm" title="Tutorials">✅</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://mathuramg.com"><img alt="Mathura MG" src="https://avatars3.githubusercontent.com/u/5505598?v=4?s=120" width="120px;" /><br /><sub><b>Mathura MG</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://1023.io"><img alt="Yining Shi" src="https://avatars3.githubusercontent.com/u/8662372?v=4?s=120" width="120px;" /><br /><sub><b>Yining Shi</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://kaganjd.github.io/portfolio/"><img alt="Jen Kagan" src="https://avatars0.githubusercontent.com/u/9204835?v=4?s=120" width="120px;" /><br /><sub><b>Jen Kagan</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://fromjia.com/"><img alt="Jiashan Wu" src="https://avatars1.githubusercontent.com/u/6025418?v=4?s=120" width="120px;" /><br /><sub><b>Jiashan Wu</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/futuremarc"><img alt="Marc Abbey" src="https://avatars3.githubusercontent.com/u/8646752?v=4?s=120" width="120px;" /><br /><sub><b>Marc Abbey</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.kadamwhite.com"><img alt="K.Adam White" src="https://avatars1.githubusercontent.com/u/442115?v=4?s=120" width="120px;" /><br /><sub><b>K.Adam White</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://ecridge.com/"><img alt="Eden Cridge" src="https://avatars2.githubusercontent.com/u/11491479?v=4?s=120" width="120px;" /><br /><sub><b>Eden Cridge</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ecridge" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aecridge" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Aecridge" title="Reviewed Pull Requests">👀</a> <a href="https://github.com/processing/p5.js/commits?author=ecridge" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://mikewesthad.com"><img alt="Michael Hadley" src="https://avatars1.githubusercontent.com/u/1131802?v=4?s=120" width="120px;" /><br /><sub><b>Michael Hadley</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://tiller.dog"><img alt="Todd H. Page" src="https://avatars1.githubusercontent.com/u/2047962?v=4?s=120" width="120px;" /><br /><sub><b>Todd H. Page</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jaredsprague.com/"><img alt="Jared Sprague" src="https://avatars1.githubusercontent.com/u/3926730?v=4?s=120" width="120px;" /><br /><sub><b>Jared Sprague</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Jared-Sprague" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=Jared-Sprague" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-Jared-Sprague" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#financial-Jared-Sprague" title="Financial">💵</a> <a href="https://github.com/processing/p5.js/commits?author=Jared-Sprague" title="Tests">⚠️</a> <a href="https://github.com/processing/p5.js/issues?q=author%3AJared-Sprague" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.outofambit.com"><img alt="evelyn masso" src="https://avatars3.githubusercontent.com/u/964912?v=4?s=120" width="120px;" /><br /><sub><b>evelyn masso</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://bomoko.net"><img alt="Blaize Kaye" src="https://avatars1.githubusercontent.com/u/297936?v=4?s=120" width="120px;" /><br /><sub><b>Blaize Kaye</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/DarkPrince304"><img alt="Sanchit Kapoor" src="https://avatars1.githubusercontent.com/u/9005407?v=4?s=120" width="120px;" /><br /><sub><b>Sanchit Kapoor</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://meiamso.me"><img alt="Oliver Wright" src="https://avatars3.githubusercontent.com/u/1187491?v=4?s=120" width="120px;" /><br /><sub><b>Oliver Wright</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mindofmatthew"><img alt="Matthew Kaney" src="https://avatars1.githubusercontent.com/u/911429?v=4?s=120" width="120px;" /><br /><sub><b>Matthew Kaney</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Spongman"><img alt="Spongman" src="https://avatars2.githubusercontent.com/u/1088194?v=4?s=120" width="120px;" /><br /><sub><b>Spongman</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/CleezyITP"><img alt="Claire K-V" src="https://avatars1.githubusercontent.com/u/5375410?v=4?s=120" width="120px;" /><br /><sub><b>Claire K-V</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://lukedubois.com"><img alt="R. Luke DuBois" src="https://avatars0.githubusercontent.com/u/4147978?v=4?s=120" width="120px;" /><br /><sub><b>R. Luke DuBois</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/kevinbarabash"><img alt="Kevin Barabash" src="https://avatars3.githubusercontent.com/u/1044413?v=4?s=120" width="120px;" /><br /><sub><b>Kevin Barabash</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://andrescolubri.net/"><img alt="codeanticode" src="https://avatars2.githubusercontent.com/u/62246?v=4?s=120" width="120px;" /><br /><sub><b>codeanticode</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.bobholtwebdev.com/"><img alt="Bob Holt" src="https://avatars2.githubusercontent.com/u/94167?v=4?s=120" width="120px;" /><br /><sub><b>Bob Holt</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sarahghp.com"><img alt="Sarah Groff Hennigh-Palermo" src="https://avatars1.githubusercontent.com/u/1477362?v=4?s=120" width="120px;" /><br /><sub><b>Sarah Groff Hennigh-Palermo</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jordanshaw.com"><img alt="Jordan Shaw" src="https://avatars1.githubusercontent.com/u/288140?v=4?s=120" width="120px;" /><br /><sub><b>Jordan Shaw</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/brightredchilli"><img alt="brightredchilli" src="https://avatars3.githubusercontent.com/u/751191?v=4?s=120" width="120px;" /><br /><sub><b>brightredchilli</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://derekkinsman.com/"><img alt="Derek J. Kinsman" src="https://avatars0.githubusercontent.com/u/611218?v=4?s=120" width="120px;" /><br /><sub><b>Derek J. Kinsman</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hkirat"><img alt="harkirat singh" src="https://avatars2.githubusercontent.com/u/8079861?v=4?s=120" width="120px;" /><br /><sub><b>harkirat singh</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/GoToLoop"><img alt="GoToLoop" src="https://avatars2.githubusercontent.com/u/6551569?v=4?s=120" width="120px;" /><br /><sub><b>GoToLoop</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://maxgoldste.in/"><img alt="Max Goldstein" src="https://avatars3.githubusercontent.com/u/1191970?v=4?s=120" width="120px;" /><br /><sub><b>Max Goldstein</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://xystudio.cc"><img alt="XY Feng" src="https://avatars2.githubusercontent.com/u/1507265?v=4?s=120" width="120px;" /><br /><sub><b>XY Feng</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/PaliwalSparsh"><img alt="Sparsh Paliwal" src="https://avatars1.githubusercontent.com/u/6324861?v=4?s=120" width="120px;" /><br /><sub><b>Sparsh Paliwal</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://austince.me"><img alt="Austin Cawley-Edwards" src="https://avatars3.githubusercontent.com/u/4655775?v=4?s=120" width="120px;" /><br /><sub><b>Austin Cawley-Edwards</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=austince" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-austince" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.estebanalmiron.com"><img alt="taseenb" src="https://avatars1.githubusercontent.com/u/1040718?v=4?s=120" width="120px;" /><br /><sub><b>taseenb</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tafsiri"><img alt="Yannick Assogba" src="https://avatars1.githubusercontent.com/u/26408?v=4?s=120" width="120px;" /><br /><sub><b>Yannick Assogba</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/johnpasquarello"><img alt="John Pasquarello" src="https://avatars3.githubusercontent.com/u/2349625?v=4?s=120" width="120px;" /><br /><sub><b>John Pasquarello</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=johnpasquarello" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://HappyCoding.io"><img alt="Kevin Workman" src="https://avatars1.githubusercontent.com/u/6930986?v=4?s=120" width="120px;" /><br /><sub><b>Kevin Workman</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=KevinWorkman" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/gauini"><img alt="gauini" src="https://avatars1.githubusercontent.com/u/4229215?v=4?s=120" width="120px;" /><br /><sub><b>gauini</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sansumbrella.com/"><img alt="David Wicks" src="https://avatars0.githubusercontent.com/u/81553?v=4?s=120" width="120px;" /><br /><sub><b>David Wicks</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/guillemontecinos"><img alt="Guillermo Montecinos" src="https://avatars1.githubusercontent.com/u/19594257?v=4?s=120" width="120px;" /><br /><sub><b>Guillermo Montecinos</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.walking-productions.com/notslop/"><img alt="Shawn Van Every" src="https://avatars0.githubusercontent.com/u/431774?v=4?s=120" width="120px;" /><br /><sub><b>Shawn Van Every</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.wiredpieces.com"><img alt="Sinan Ascioglu" src="https://avatars3.githubusercontent.com/u/579033?v=4?s=120" width="120px;" /><br /><sub><b>Sinan Ascioglu</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://hamoid.com"><img alt="Abe Pazos" src="https://avatars0.githubusercontent.com/u/108264?v=4?s=120" width="120px;" /><br /><sub><b>Abe Pazos</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://charstiles.com/"><img alt="Char" src="https://avatars1.githubusercontent.com/u/10173517?v=4?s=120" width="120px;" /><br /><sub><b>Char</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://genekogan.com"><img alt="Gene Kogan" src="https://avatars3.githubusercontent.com/u/1335251?v=4?s=120" width="120px;" /><br /><sub><b>Gene Kogan</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jay-manday"><img alt="Jason Mandel" src="https://avatars2.githubusercontent.com/u/13109165?v=4?s=120" width="120px;" /><br /><sub><b>Jason Mandel</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/russomf"><img alt="Mark Russo" src="https://avatars1.githubusercontent.com/u/11917158?v=4?s=120" width="120px;" /><br /><sub><b>Mark Russo</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jedahan.com"><img alt="Jonathan Dahan" src="https://avatars1.githubusercontent.com/u/32407?v=4?s=120" width="120px;" /><br /><sub><b>Jonathan Dahan</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://nok.onl"><img alt="Darius Morawiec" src="https://avatars1.githubusercontent.com/u/670641?v=4?s=120" width="120px;" /><br /><sub><b>Darius Morawiec</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/darbicus"><img alt="Darby Rathbone" src="https://avatars3.githubusercontent.com/u/3231573?v=4?s=120" width="120px;" /><br /><sub><b>Darby Rathbone</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hrishit"><img alt="hrishit" src="https://avatars1.githubusercontent.com/u/2214025?v=4?s=120" width="120px;" /><br /><sub><b>hrishit</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/chiunhauyou"><img alt="Chiun Hau You" src="https://avatars1.githubusercontent.com/u/6561433?v=4?s=120" width="120px;" /><br /><sub><b>Chiun Hau You</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://zaerl.com"><img alt="Francesco Bigiarini" src="https://avatars1.githubusercontent.com/u/167611?v=4?s=120" width="120px;" /><br /><sub><b>Francesco Bigiarini</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://fabianmoronzirfas.me"><img alt="Fabian Morón Zirfas" src="https://avatars3.githubusercontent.com/u/315106?v=4?s=120" width="120px;" /><br /><sub><b>Fabian Morón Zirfas</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://cambridgemike.com"><img alt="Mike Anderson" src="https://avatars1.githubusercontent.com/u/163429?v=4?s=120" width="120px;" /><br /><sub><b>Mike Anderson</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://linkedin.com/in/limikael"><img alt="Mikael Lindqvist" src="https://avatars2.githubusercontent.com/u/902911?v=4?s=120" width="120px;" /><br /><sub><b>Mikael Lindqvist</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ctlusto"><img alt="Chris" src="https://avatars0.githubusercontent.com/u/3980953?v=4?s=120" width="120px;" /><br /><sub><b>Chris</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/max0410"><img alt="Max Segal" src="https://avatars2.githubusercontent.com/u/16921177?v=4?s=120" width="120px;" /><br /><sub><b>Max Segal</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tstefanich"><img alt="Tyler Stefanich" src="https://avatars1.githubusercontent.com/u/810727?v=4?s=120" width="120px;" /><br /><sub><b>Tyler Stefanich</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.sixhat.net/"><img alt="Dave" src="https://avatars3.githubusercontent.com/u/614881?v=4?s=120" width="120px;" /><br /><sub><b>Dave</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://wxs.ca"><img alt="Xavier Snelgrove" src="https://avatars0.githubusercontent.com/u/326559?v=4?s=120" width="120px;" /><br /><sub><b>Xavier Snelgrove</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/DoubleJump"><img alt="Gareth Battensby" src="https://avatars2.githubusercontent.com/u/1791943?v=4?s=120" width="120px;" /><br /><sub><b>Gareth Battensby</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://taeyoonchoi.com"><img alt="Taeyoon Choi" src="https://avatars3.githubusercontent.com/u/683107?v=4?s=120" width="120px;" /><br /><sub><b>Taeyoon Choi</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/akashraj9828"><img alt="AKASH RAJ" src="https://avatars0.githubusercontent.com/u/29796785?v=4?s=120" width="120px;" /><br /><sub><b>AKASH RAJ</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/keho98"><img alt="Kevin Ho" src="https://avatars3.githubusercontent.com/u/1147122?v=4?s=120" width="120px;" /><br /><sub><b>Kevin Ho</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://dexter1691.github.io"><img alt="Harsh Agrawal" src="https://avatars0.githubusercontent.com/u/2039548?v=4?s=120" width="120px;" /><br /><sub><b>Harsh Agrawal</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Luxapodular"><img alt="Luca Damasco" src="https://avatars1.githubusercontent.com/u/8699557?v=4?s=120" width="120px;" /><br /><sub><b>Luca Damasco</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://lav.io"><img alt="Sam Lavigne" src="https://avatars0.githubusercontent.com/u/344861?v=4?s=120" width="120px;" /><br /><sub><b>Sam Lavigne</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://epicjefferson.com"><img alt="Epic Jefferson" src="https://avatars1.githubusercontent.com/u/658242?v=4?s=120" width="120px;" /><br /><sub><b>Epic Jefferson</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.carolinerecord.com/"><img alt="Caroline Record" src="https://avatars0.githubusercontent.com/u/3160465?v=4?s=120" width="120px;" /><br /><sub><b>Caroline Record</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://cjdecarteret.com"><img alt="Christine de Carteret" src="https://avatars2.githubusercontent.com/u/7853707?v=4?s=120" width="120px;" /><br /><sub><b>Christine de Carteret</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://crhallberg.com"><img alt="Chris Hallberg" src="https://avatars0.githubusercontent.com/u/451107?v=4?s=120" width="120px;" /><br /><sub><b>Chris Hallberg</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.workergnome.com"><img alt="David Newbury" src="https://avatars0.githubusercontent.com/u/34536?v=4?s=120" width="120px;" /><br /><sub><b>David Newbury</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/piinthecloud"><img alt="piinthecloud" src="https://avatars3.githubusercontent.com/u/6187313?v=4?s=120" width="120px;" /><br /><sub><b>piinthecloud</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.molleindustria.org"><img alt="Paolo Pedercini" src="https://avatars1.githubusercontent.com/u/12369651?v=4?s=120" width="120px;" /><br /><sub><b>Paolo Pedercini</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://huah.net/jason/"><img alt="Jason Alderman" src="https://avatars0.githubusercontent.com/u/3819772?v=4?s=120" width="120px;" /><br /><sub><b>Jason Alderman</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://media.mit.edu/~jacobsj"><img alt="Jennifer Jacobs" src="https://avatars1.githubusercontent.com/u/295733?v=4?s=120" width="120px;" /><br /><sub><b>Jennifer Jacobs</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sepans.com"><img alt="Sepand Ansari" src="https://avatars3.githubusercontent.com/u/687513?v=4?s=120" width="120px;" /><br /><sub><b>Sepand Ansari</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://valhead.com"><img alt="Val Head" src="https://avatars2.githubusercontent.com/u/1289596?v=4?s=120" width="120px;" /><br /><sub><b>Val Head</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/six5532one"><img alt="Emily Chen" src="https://avatars1.githubusercontent.com/u/1435725?v=4?s=120" width="120px;" /><br /><sub><b>Emily Chen</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://benmoren.com"><img alt="Ben Moren" src="https://avatars3.githubusercontent.com/u/1385996?v=4?s=120" width="120px;" /><br /><sub><b>Ben Moren</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.runemadsen.com"><img alt="Rune Skjoldborg Madsen" src="https://avatars0.githubusercontent.com/u/192021?v=4?s=120" width="120px;" /><br /><sub><b>Rune Skjoldborg Madsen</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://alignedleft.com"><img alt="Scott Murray" src="https://avatars0.githubusercontent.com/u/1034002?v=4?s=120" width="120px;" /><br /><sub><b>Scott Murray</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.scottmadethis.net/"><img alt="Scott Garner" src="https://avatars0.githubusercontent.com/u/786436?v=4?s=120" width="120px;" /><br /><sub><b>Scott Garner</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://b2renger.github.io/"><img alt="b2renger" src="https://avatars2.githubusercontent.com/u/1818874?v=4?s=120" width="120px;" /><br /><sub><b>b2renger</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://craigpickard.net/"><img alt="Craig Pickard" src="https://avatars2.githubusercontent.com/u/4640172?v=4?s=120" width="120px;" /><br /><sub><b>Craig Pickard</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mxchelle"><img alt="mxchelle" src="https://avatars3.githubusercontent.com/u/4912796?v=4?s=120" width="120px;" /><br /><sub><b>mxchelle</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.wickeditor.com"><img alt="Zach Rispoli" src="https://avatars0.githubusercontent.com/u/4970417?v=4?s=120" width="120px;" /><br /><sub><b>Zach Rispoli</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.liuchang.work"><img alt="Liu Chang" src="https://avatars1.githubusercontent.com/u/7039783?v=4?s=120" width="120px;" /><br /><sub><b>Liu Chang</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://cvalenzuelab.com/"><img alt="Cristóbal Valenzuela" src="https://avatars0.githubusercontent.com/u/10605821?v=4?s=120" width="120px;" /><br /><sub><b>Cristóbal Valenzuela</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.milespeyton.info"><img alt="Miles Peyton" src="https://avatars2.githubusercontent.com/u/1015606?v=4?s=120" width="120px;" /><br /><sub><b>Miles Peyton</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.flong.com"><img alt="Golan Levin" src="https://avatars2.githubusercontent.com/u/290053?v=4?s=120" width="120px;" /><br /><sub><b>Golan Levin</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/feedzh"><img alt="feedzh" src="https://avatars3.githubusercontent.com/u/378124?v=4?s=120" width="120px;" /><br /><sub><b>feedzh</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/rubayet170746"><img alt="Shahriar Rahman Rubayet" src="https://avatars0.githubusercontent.com/u/35176093?s=40&amp;v=4?s=120" width="120px;" /><br /><sub><b>Shahriar Rahman Rubayet</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://nicusor.org/"><img alt="Chiciuc Nicușor" src="https://avatars0.githubusercontent.com/u/4076804?v=4?s=120" width="120px;" /><br /><sub><b>Chiciuc Nicușor</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.videoventure.org"><img alt="Ken Miller" src="https://avatars3.githubusercontent.com/u/1566844?v=4?s=120" width="120px;" /><br /><sub><b>Ken Miller</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://brysonian.com"><img alt="Chandler McWilliams" src="https://avatars2.githubusercontent.com/u/69087?v=4?s=120" width="120px;" /><br /><sub><b>Chandler McWilliams</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://wxactly.com/"><img alt="Jaymz Rhime" src="https://avatars1.githubusercontent.com/u/1130929?v=4?s=120" width="120px;" /><br /><sub><b>Jaymz Rhime</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://njoubert.com"><img alt="Niels Joubert" src="https://avatars1.githubusercontent.com/u/181043?v=4?s=120" width="120px;" /><br /><sub><b>Niels Joubert</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/iamutkarshtiwari"><img alt="Utkarsh Tiwari" src="https://avatars1.githubusercontent.com/u/6258810?v=4?s=120" width="120px;" /><br /><sub><b>Utkarsh Tiwari</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/parsoyaarihant"><img alt="Arihant Parsoya" src="https://avatars0.githubusercontent.com/u/15258498?v=4?s=120" width="120px;" /><br /><sub><b>Arihant Parsoya</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://bradleycbuchanan.com"><img alt="Brad Buchanan" src="https://avatars0.githubusercontent.com/u/1615761?v=4?s=120" width="120px;" /><br /><sub><b>Brad Buchanan</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/DonKarlssonSan"><img alt="Johan Karlsson" src="https://avatars0.githubusercontent.com/u/3482016?v=4?s=120" width="120px;" /><br /><sub><b>Johan Karlsson</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://andrewjtimmons.github.io"><img alt="Andy Timmons" src="https://avatars1.githubusercontent.com/u/1569764?v=4?s=120" width="120px;" /><br /><sub><b>Andy Timmons</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/zacharystenger"><img alt="zacharystenger" src="https://avatars3.githubusercontent.com/u/7537243?v=4?s=120" width="120px;" /><br /><sub><b>zacharystenger</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://boucheron.org/brian"><img alt="Brian Boucheron" src="https://avatars3.githubusercontent.com/u/170997?v=4?s=120" width="120px;" /><br /><sub><b>Brian Boucheron</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sortasleepy"><img alt="sortasleepy" src="https://avatars2.githubusercontent.com/u/22330511?v=4?s=120" width="120px;" /><br /><sub><b>sortasleepy</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://kylemcdonald.net/"><img alt="Kyle McDonald" src="https://avatars3.githubusercontent.com/u/157106?v=4?s=120" width="120px;" /><br /><sub><b>Kyle McDonald</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://spadial.com"><img alt="Antonio Jesús Sánchez Padial" src="https://avatars1.githubusercontent.com/u/710282?v=4?s=120" width="120px;" /><br /><sub><b>Antonio Jesús Sánchez Padial</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ajspadial" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.geekdome.net"><img alt="Brad Smith" src="https://avatars2.githubusercontent.com/u/188349?v=4?s=120" width="120px;" /><br /><sub><b>Brad Smith</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://vitorgalvao.com/"><img alt="Vítor Galvão" src="https://avatars1.githubusercontent.com/u/1699443?v=4?s=120" width="120px;" /><br /><sub><b>Vítor Galvão</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/drifkin"><img alt="Devon Rifkin" src="https://avatars1.githubusercontent.com/u/175530?v=4?s=120" width="120px;" /><br /><sub><b>Devon Rifkin</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://xie-emily.com"><img alt="Emily Xie" src="https://avatars0.githubusercontent.com/u/5360525?v=4?s=120" width="120px;" /><br /><sub><b>Emily Xie</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://twitter.com/borisbucha"><img alt="Boris Bucha" src="https://avatars2.githubusercontent.com/u/150448?v=4?s=120" width="120px;" /><br /><sub><b>Boris Bucha</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://avocode.com"><img alt="Petr Brzek" src="https://avatars3.githubusercontent.com/u/879564?v=4?s=120" width="120px;" /><br /><sub><b>Petr Brzek</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/transfluxus"><img alt="Ramin" src="https://avatars1.githubusercontent.com/u/1574219?v=4?s=120" width="120px;" /><br /><sub><b>Ramin</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/arsenijesavic"><img alt="Arsenije Savic" src="https://avatars0.githubusercontent.com/u/7712798?v=4?s=120" width="120px;" /><br /><sub><b>Arsenije Savic</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.linkedin.com/in/lukeburgessyeo"><img alt="Luke Burgess-Yeo" src="https://avatars1.githubusercontent.com/u/15360369?v=4?s=120" width="120px;" /><br /><sub><b>Luke Burgess-Yeo</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/slfmessi"><img alt="Sun Lifei" src="https://avatars3.githubusercontent.com/u/3071467?v=4?s=120" width="120px;" /><br /><sub><b>Sun Lifei</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://himo.boy.jp/"><img alt="naoyashiga" src="https://avatars3.githubusercontent.com/u/1988660?v=4?s=120" width="120px;" /><br /><sub><b>naoyashiga</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://facebook.com/Jimish.Fotariya"><img alt="Jimish Fotariya" src="https://avatars0.githubusercontent.com/u/8057628?v=4?s=120" width="120px;" /><br /><sub><b>Jimish Fotariya</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.moro.es"><img alt="Jorge Moreno" src="https://avatars1.githubusercontent.com/u/703744?v=4?s=120" width="120px;" /><br /><sub><b>Jorge Moreno</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aalterebro" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=alterebro" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=alterebro" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://stevengreens10.github.io"><img alt="Steven Green" src="https://avatars3.githubusercontent.com/u/26755396?v=4?s=120" width="120px;" /><br /><sub><b>Steven Green</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.marcusparsons.com"><img alt="Marcus Parsons" src="https://avatars2.githubusercontent.com/u/10608765?v=4?s=120" width="120px;" /><br /><sub><b>Marcus Parsons</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nthitz"><img alt="Nick Yahnke" src="https://avatars1.githubusercontent.com/u/1482377?v=4?s=120" width="120px;" /><br /><sub><b>Nick Yahnke</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.radialglo.com"><img alt="Anthony Su" src="https://avatars3.githubusercontent.com/u/1859451?v=4?s=120" width="120px;" /><br /><sub><b>Anthony Su</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.kroko.me/"><img alt="kroko / Reinis Adovičs" src="https://avatars3.githubusercontent.com/u/720976?v=4?s=120" width="120px;" /><br /><sub><b>kroko / Reinis Adovičs</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/robynitp"><img alt="Robyn Overstreet" src="https://avatars2.githubusercontent.com/u/5854770?v=4?s=120" width="120px;" /><br /><sub><b>Robyn Overstreet</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/benhinchley"><img alt="Ben Hinchley" src="https://avatars1.githubusercontent.com/u/7188324?v=4?s=120" width="120px;" /><br /><sub><b>Ben Hinchley</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://ello.co/maxkolyanov"><img alt="Max Kolyanov" src="https://avatars1.githubusercontent.com/u/3266989?v=4?s=120" width="120px;" /><br /><sub><b>Max Kolyanov</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://zenozeng.com"><img alt="Zeno Zeng" src="https://avatars3.githubusercontent.com/u/2544489?v=4?s=120" width="120px;" /><br /><sub><b>Zeno Zeng</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.sethkranzler.com"><img alt="Seth" src="https://avatars0.githubusercontent.com/u/8644048?v=4?s=120" width="120px;" /><br /><sub><b>Seth</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/plural"><img alt="plural" src="https://avatars2.githubusercontent.com/u/396562?v=4?s=120" width="120px;" /><br /><sub><b>plural</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://ucodia.space"><img alt="Lionel Ringenbach" src="https://avatars3.githubusercontent.com/u/1795860?v=4?s=120" width="120px;" /><br /><sub><b>Lionel Ringenbach</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/darkcoderrises"><img alt="Harshil Goel" src="https://avatars3.githubusercontent.com/u/9111606?v=4?s=120" width="120px;" /><br /><sub><b>Harshil Goel</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://becker.codes"><img alt="Joshua Storm Becker" src="https://avatars0.githubusercontent.com/u/12414183?v=4?s=120" width="120px;" /><br /><sub><b>Joshua Storm Becker</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://twitter.com/maxdevjs"><img alt="maxdevjs" src="https://avatars2.githubusercontent.com/u/22229196?v=4?s=120" width="120px;" /><br /><sub><b>maxdevjs</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://timorychert.de/"><img alt="trych" src="https://avatars2.githubusercontent.com/u/9803905?v=4?s=120" width="120px;" /><br /><sub><b>trych</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.alejandratrejo.com/"><img alt="Alejandra Trejo" src="https://avatars1.githubusercontent.com/u/15284993?v=4?s=120" width="120px;" /><br /><sub><b>Alejandra Trejo</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.pgupta.com"><img alt="Prashant Gupta" src="https://avatars0.githubusercontent.com/u/9909241?v=4?s=120" width="120px;" /><br /><sub><b>Prashant Gupta</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/rasca0027"><img alt="Kai-han Chang" src="https://avatars2.githubusercontent.com/u/5270022?v=4?s=120" width="120px;" /><br /><sub><b>Kai-han Chang</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/kjav"><img alt="kjav" src="https://avatars0.githubusercontent.com/u/9029686?v=4?s=120" width="120px;" /><br /><sub><b>kjav</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://maddy.zone"><img alt="maddy" src="https://avatars0.githubusercontent.com/u/1965049?v=4?s=120" width="120px;" /><br /><sub><b>maddy</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://digitalcoleman.com"><img alt="Christopher Coleman" src="https://avatars3.githubusercontent.com/u/2354476?v=4?s=120" width="120px;" /><br /><sub><b>Christopher Coleman</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://boazsender.com"><img alt="Boaz" src="https://avatars3.githubusercontent.com/u/122117?v=4?s=120" width="120px;" /><br /><sub><b>Boaz</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/wangyasai"><img alt="Yasai" src="https://avatars1.githubusercontent.com/u/13515645?v=4?s=120" width="120px;" /><br /><sub><b>Yasai</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#blog-wangyasai" title="Blogposts">📝</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hackertron"><img alt="Jay Gupta" src="https://avatars3.githubusercontent.com/u/7667514?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Jay Gupta</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/bansalnitish"><img alt="Nitish Bansal" src="https://avatars1.githubusercontent.com/u/22434689?v=4?s=120" width="120px;" /><br /><sub><b>Nitish Bansal</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://caro.io/"><img alt="Caroline Hermans" src="https://avatars0.githubusercontent.com/u/8083973?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Caroline Hermans</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-carolinehermans" title="Examples">💡</a> <a href="https://github.com/processing/p5.js/commits?author=carolinehermans" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/faithwyu"><img alt="Faith Wuyue Yu" src="https://avatars3.githubusercontent.com/u/19146133?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Faith Wuyue Yu</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://aatishb.com"><img alt="Aatish Bhatia" src="https://avatars2.githubusercontent.com/u/1878638?s=400&amp;v=4?s=120" width="120px;" /><br /><sub><b>Aatish Bhatia</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aatishb" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aaatishb" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dekmm"><img alt="Mislav Milicevic" src="https://avatars3.githubusercontent.com/u/7628664?v=4?s=120" width="120px;" /><br /><sub><b>Mislav Milicevic</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dekmm" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Adekmm" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/yutinglu413"><img alt="Yuting Lu" src="https://avatars1.githubusercontent.com/u/25344311?v=4?s=120" width="120px;" /><br /><sub><b>Yuting Lu</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=yutinglu413" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/adilrabbani"><img alt="Adil Rabbani" src="https://avatars2.githubusercontent.com/u/15272015?v=4?s=120" width="120px;" /><br /><sub><b>Adil Rabbani</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=adilrabbani" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aadilrabbani" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-adilrabbani" title="Examples">💡</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://zalastax.github.io/"><img alt="Pierre Krafft" src="https://avatars3.githubusercontent.com/u/908496?v=4?s=120" width="120px;" /><br /><sub><b>Pierre Krafft</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AZalastax" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=Zalastax" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=Zalastax" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-Zalastax" title="Examples">💡</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3AZalastax" title="Reviewed Pull Requests">👀</a> <a href="https://github.com/processing/p5.js/commits?author=Zalastax" title="Tests">⚠️</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-Zalastax" title="Tools">🔧</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/zoeingram"><img alt="Zoë Ingram" src="https://avatars2.githubusercontent.com/u/12074409?v=4?s=120" width="120px;" /><br /><sub><b>Zoë Ingram</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=zoeingram" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AidanNelson"><img alt="Aidan Nelson" src="https://avatars1.githubusercontent.com/u/6486359?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Aidan Nelson</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aaidannelson" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=aidannelson" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=aidannelson" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hydrosquall"><img alt="Cameron Yick" src="https://avatars2.githubusercontent.com/u/9020979?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Cameron Yick</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=hydrosquall" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/TanviKumar"><img alt="Tanvi Kumar" src="https://avatars3.githubusercontent.com/u/18724229?v=4?s=120" width="120px;" /><br /><sub><b>Tanvi Kumar</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3ATanviKumar" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=TanviKumar" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=TanviKumar" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-TanviKumar" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://enkatsu.org"><img alt="Katsuya Endoh" src="https://avatars0.githubusercontent.com/u/7820411?v=4?s=120" width="120px;" /><br /><sub><b>Katsuya Endoh</b></sub></a><br /></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/OsakaStarbux"><img alt="Kevin Bradley" src="https://avatars1.githubusercontent.com/u/7752014?v=4?s=120" width="120px;" /><br /><sub><b>Kevin Bradley</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=OsakaStarbux" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://justinsunho.com/"><img alt="Justin Kim" src="https://avatars3.githubusercontent.com/u/31749430?v=4?s=120" width="120px;" /><br /><sub><b>Justin Kim</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=justinsunho" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/EndBug"><img alt="Federico Grandi" src="https://avatars3.githubusercontent.com/u/26386270?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Federico Grandi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=EndBug" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=EndBug" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://freddierawlins.wixsite.com/site"><img alt="Freddie Rawlins" src="https://discourse-cdn-sjc2.com/standard10/user_avatar/discourse.processing.org/freddiera/120/4078_2.png?s=120" width="120px;" /><br /><sub><b>Freddie Rawlins</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=FreddieRa" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=FreddieRa" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/justlucdewit"><img alt="Luc de wit" src="https://media.discordapp.net/attachments/499488127245615135/499488260435869696/normal_luke.png?s=120" width="120px;" /><br /><sub><b>Luc de wit</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Luke_" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3ALuke_" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mcuz"><img alt="Mark Nikora" src="https://avatars3.githubusercontent.com/u/44824130?s=40&amp;v=4?s=120" width="120px;" /><br /><sub><b>Mark Nikora</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mcuz" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Nekzuris"><img alt="Louis Demange" src="https://avatars3.githubusercontent.com/u/48560751?s=400&amp;u=652ea1a1720b1986c3ea5b96028bdcb5f4f18f96&amp;v=4?s=120" width="120px;" /><br /><sub><b>Louis Demange</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3ANekzuris" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/sanket24singh"><img alt="Sanket Singh" src="https://avatars3.githubusercontent.com/u/24548786?v=4?s=120" width="120px;" /><br /><sub><b>Sanket Singh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sanketsingh24" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Asanketsingh24" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=sanketsingh24" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-sanketsingh24" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://orenshoham.com"><img alt="Oren Shoham" src="https://avatars0.githubusercontent.com/u/2325893?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Oren Shoham</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=oshoham" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/abhinavsagar"><img alt="Abhinav Sagar" src="https://avatars0.githubusercontent.com/u/40603139?v=4?s=120" width="120px;" /><br /><sub><b>Abhinav Sagar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=abhinavsagar" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jonnytest1"><img alt="Jonathan Heindl" src="https://avatars2.githubusercontent.com/u/13507796?s=40&amp;v=4?s=120" width="120px;" /><br /><sub><b>Jonathan Heindl</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jonnytest1" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-jonnytest1" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-jonnytest1" title="Ideas, Planning, &amp; Feedback">🤔</a> <a href="https://github.com/processing/p5.js/commits?author=jonnytest1" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://hiradsab.com"><img alt="Hirad Sab" src="https://avatars2.githubusercontent.com/u/11205091?s=120" width="120px;" /><br /><sub><b>Hirad Sab</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=hsab" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Ahsab" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=hsab" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-hsab" title="Examples">💡</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/singhvisha"><img alt="Vishal Singh" src="https://avatars0.githubusercontent.com/u/38842688?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Vishal Singh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=singhvisha" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=singhvisha" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.coreygo.com"><img alt="Corey Gouker" src="https://avatars1.githubusercontent.com/u/649879?v=4?s=120" width="120px;" /><br /><sub><b>Corey Gouker</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=coreygo" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=coreygo" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Acoreygo" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.lisamabley.codes"><img alt="Lisa Mabley" src="https://avatars3.githubusercontent.com/u/6124489?v=4?s=120" width="120px;" /><br /><sub><b>Lisa Mabley</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=LisaMabley" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-LisaMabley" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.amf.fyi"><img alt="Adam Ferriss" src="https://avatars3.githubusercontent.com/u/3698659?v=4?s=120" width="120px;" /><br /><sub><b>Adam Ferriss</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aferriss" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=aferriss" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aaferriss" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-aferriss" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://joshuaalm.github.io"><img alt="Joshua Marris" src="https://avatars1.githubusercontent.com/u/6978629?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Joshua Marris</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=joshuaalm" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=joshuaalm" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-joshuaalm" title="Talks">📢</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-joshuaalm" title="Tutorials">✅</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/thumbsupep"><img alt="Erica Pramer" src="https://avatars3.githubusercontent.com/u/5598732?v=4?s=120" width="120px;" /><br /><sub><b>Erica Pramer</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=thumbsupep" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/CrypticGuy"><img alt="Vasu Goel" src="https://avatars3.githubusercontent.com/u/13849789?v=4?s=120" width="120px;" /><br /><sub><b>Vasu Goel</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=CrypticGuy" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=CrypticGuy" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tokinifubara"><img alt="Tokini Irene Fubara" src="https://avatars2.githubusercontent.com/u/10986281?v=4?s=120" width="120px;" /><br /><sub><b>Tokini Irene Fubara</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=tokinifubara" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dhruvs009"><img alt="Dhruv Sahnan" src="https://avatars1.githubusercontent.com/u/39025961?v=4?s=120" width="120px;" /><br /><sub><b>Dhruv Sahnan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dhruvs009" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=dhruvs009" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jjkaufman"><img alt="Jon Kaufman" src="https://avatars0.githubusercontent.com/u/1706950?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Jon Kaufman</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jjkaufman" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://gruselhaus.com"><img alt="Nico Finkernagel" src="https://avatars2.githubusercontent.com/u/33380107?v=4?s=120" width="120px;" /><br /><sub><b>Nico Finkernagel</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#infra-gruselhaus" title="Infrastructure (Hosting, Build-Tools, etc)">🚇</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Agruselhaus" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ashu8912"><img alt="ashu8912" src="https://avatars1.githubusercontent.com/u/30126128?v=4?s=120" width="120px;" /><br /><sub><b>ashu8912</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ashu8912" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://teddavis.org"><img alt="ffd8" src="https://avatars2.githubusercontent.com/u/570957?v=4?s=120" width="120px;" /><br /><sub><b>ffd8</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ffd8" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://about.sonalee.me"><img alt="Sona Lee" src="https://avatars0.githubusercontent.com/u/4694139?v=4?s=120" width="120px;" /><br /><sub><b>Sona Lee</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mojosoeun" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://raw.githubusercontent.com/processing/p5.js/main/rdslade.github.io"><img alt="Ryan Slade" src="https://avatars2.githubusercontent.com/u/8525152?v=4?s=120" width="120px;" /><br /><sub><b>Ryan Slade</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=rdslade" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mann27"><img alt="Mann Shah" src="https://avatars2.githubusercontent.com/u/33790390?v=4?s=120" width="120px;" /><br /><sub><b>Mann Shah</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nthe"><img alt="Juraj Onuska" src="https://avatars1.githubusercontent.com/u/6535424?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Juraj Onuska</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AnuragGupta93"><img alt="ANURAG GUPTA" src="https://avatars1.githubusercontent.com/u/35900375?v=4?s=120" width="120px;" /><br /><sub><b>ANURAG GUPTA</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AnuragGupta93" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://zoyron.github.io/"><img alt="Sagar Arora" src="https://avatars3.githubusercontent.com/u/24233321?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Sagar Arora</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://iamrajiv.github.io/"><img alt="Rajiv Ranjan Singh" src="https://avatars0.githubusercontent.com/u/42106787?s=460&amp;v=4?s=120" width="120px;" /><br /><sub><b>Rajiv Ranjan Singh</b></sub></a><br /></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://fenilgandhi.tech"><img alt="Fenil Gandhi" src="https://avatars0.githubusercontent.com/u/9128903?v=4?s=120" width="120px;" /><br /><sub><b>Fenil Gandhi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=fenilgandhi" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-fenilgandhi" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/akshay-99"><img alt="Akshay Padte" src="https://avatars0.githubusercontent.com/u/38867671?v=4?s=120" width="120px;" /><br /><sub><b>Akshay Padte</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=akshay-99" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aakshay-99" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=akshay-99" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sk1122"><img alt="Satyam Kulkarni" src="https://avatars3.githubusercontent.com/u/40713709?v=4?s=120" width="120px;" /><br /><sub><b>Satyam Kulkarni</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sk1122" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/DivyamAhuja"><img alt="Shirou" src="https://avatars0.githubusercontent.com/u/39771050?v=4?s=120" width="120px;" /><br /><sub><b>Shirou</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=DivyamAhuja" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3ADivyamAhuja" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/pcgamer1"><img alt="Sarthak Saxena" src="https://avatars2.githubusercontent.com/u/30899040?v=4?s=120" width="120px;" /><br /><sub><b>Sarthak Saxena</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=pcgamer1" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nickmcintyre"><img alt="Nick McIntyre" src="https://avatars2.githubusercontent.com/u/3719176?s=460&amp;u=aa8165c80ab91fb1d85537f199d9871b5cb2e5e0&amp;v=4?s=120" width="120px;" /><br /><sub><b>Nick McIntyre</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-nickmcintyre" title="Plugin/utility libraries">🔌</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Anickmcintyre" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-nickmcintyre" title="Tutorials">✅</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ameybhavsar24"><img alt="Amey Bhavsar" src="https://avatars1.githubusercontent.com/u/28699912?s=400&amp;u=c039ff6ac7be37e3a9a8a434ffdac81b35c6d2ae&amp;v=4?s=120" width="120px;" /><br /><sub><b>Amey Bhavsar</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aameybhavsar24" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-ameybhavsar24" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mjaything"><img alt="Minjun Kim" src="https://avatars1.githubusercontent.com/u/13192500?v=4?s=120" width="120px;" /><br /><sub><b>Minjun Kim</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Amjaything" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-mjaything" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/fisherdiede"><img alt="Fisher Diede" src="https://avatars2.githubusercontent.com/u/11671032?s=400&amp;u=212a5392a3a1d3c68a5c41527529fed19cb72e23&amp;v=4?s=120" width="120px;" /><br /><sub><b>Fisher Diede</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=fisherdiede" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/karinaxlpz"><img alt="karinaxlpz" src="https://avatars2.githubusercontent.com/u/64159159?v=4?s=120" width="120px;" /><br /><sub><b>karinaxlpz</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-karinaxlpz" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/SamuelAl"><img alt="Samuel Alarco Cantos" src="https://avatars3.githubusercontent.com/u/33717014?v=4?s=120" width="120px;" /><br /><sub><b>Samuel Alarco Cantos</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-SamuelAl" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://divyanshuraj.co"><img alt="DIVYANSHU RAJ" src="https://avatars1.githubusercontent.com/u/43696525?v=4?s=120" width="120px;" /><br /><sub><b>DIVYANSHU RAJ</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=endurance21" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aendurance21" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=endurance21" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sm7515"><img alt="sm7515" src="https://avatars1.githubusercontent.com/u/36653440?v=4?s=120" width="120px;" /><br /><sub><b>sm7515</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sm7515" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://adityarp.com"><img alt="Aditya Rachman Putra" src="https://avatars3.githubusercontent.com/u/5263688?v=4?s=120" width="120px;" /><br /><sub><b>Aditya Rachman Putra</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=banditelol" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shaharyar-shamshi"><img alt="shaharyarshamshi" src="https://avatars3.githubusercontent.com/u/17377195?v=4?s=120" width="120px;" /><br /><sub><b>shaharyarshamshi</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-shaharyar-shamshi" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://ayushj.me"><img alt="Ayush Jain" src="https://avatars3.githubusercontent.com/u/33171576?v=4?s=120" width="120px;" /><br /><sub><b>Ayush Jain</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-ayushjainrksh" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://dev.to/rizz0s"><img alt="Summer Rizzo" src="https://avatars1.githubusercontent.com/u/39225869?v=4?s=120" width="120px;" /><br /><sub><b>Summer Rizzo</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Rizz0S" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Aierie"><img alt="Aierie" src="https://avatars3.githubusercontent.com/u/39579264?v=4?s=120" width="120px;" /><br /><sub><b>Aierie</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Aierie" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3AAierie" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/matvs"><img alt="Mateusz Swiatkowski" src="https://avatars3.githubusercontent.com/u/6883643?v=4?s=120" width="120px;" /><br /><sub><b>Mateusz Swiatkowski</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=matvs" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Amatvs" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/SketchySketch"><img alt="XingZiLong" src="https://avatars0.githubusercontent.com/u/41220208?v=4?s=120" width="120px;" /><br /><sub><b>XingZiLong</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-SketchySketch" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/oruburos"><img alt="ov" src="https://avatars2.githubusercontent.com/u/718254?v=4?s=120" width="120px;" /><br /><sub><b>ov</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-oruburos" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/kyle1james"><img alt="Kyle James" src="https://avatars3.githubusercontent.com/u/13423696?v=4?s=120" width="120px;" /><br /><sub><b>Kyle James</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=kyle1james" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AbhiGulati"><img alt="Abhi Gulati" src="https://avatars1.githubusercontent.com/u/8756983?v=4?s=120" width="120px;" /><br /><sub><b>Abhi Gulati</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AbhiGulati" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://jtp.io"><img alt="Jeremy Tuloup" src="https://avatars2.githubusercontent.com/u/591645?v=4?s=120" width="120px;" /><br /><sub><b>Jeremy Tuloup</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jtpio" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://lm-n.com"><img alt="Luis Morales-Navarro" src="https://avatars0.githubusercontent.com/u/16418450?v=4?s=120" width="120px;" /><br /><sub><b>Luis Morales-Navarro</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#a11y-lm-n" title="Accessibility">️️️️♿️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/yukie-nomiya/"><img alt="Yuki" src="https://avatars3.githubusercontent.com/u/49163604?v=4?s=120" width="120px;" /><br /><sub><b>Yuki</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-yukienomiya" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/cedarfall"><img alt="cedarfall" src="https://avatars2.githubusercontent.com/u/50991099?v=4?s=120" width="120px;" /><br /><sub><b>cedarfall</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=cedarfall" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://dribbble.com/isaacdurazo"><img alt="Isaac Durazo " src="https://avatars1.githubusercontent.com/u/1379244?v=4?s=120" width="120px;" /><br /><sub><b>Isaac Durazo </b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-isaacdurazo" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ismailnamdar"><img alt="İsmail Namdar" src="https://avatars1.githubusercontent.com/u/31315754?v=4?s=120" width="120px;" /><br /><sub><b>İsmail Namdar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ismailnamdar" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=ismailnamdar" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://skyperx.github.io"><img alt="skyperx" src="https://avatars1.githubusercontent.com/u/64559807?v=4?s=120" width="120px;" /><br /><sub><b>skyperx</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=skyperx" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://josepharonson.com/"><img alt="Joseph Aronson" src="https://avatars0.githubusercontent.com/u/32691229?v=4?s=120" width="120px;" /><br /><sub><b>Joseph Aronson</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=joeyaronson" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Ajoeyaronson" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://haideralipunjabi.com"><img alt="Haider Ali Punjabi" src="https://avatars1.githubusercontent.com/u/11888687?v=4?s=120" width="120px;" /><br /><sub><b>Haider Ali Punjabi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=haideralipunjabi" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Swapnil-2001"><img alt="Swapnil-2001" src="https://avatars0.githubusercontent.com/u/53232360?v=4?s=120" width="120px;" /><br /><sub><b>Swapnil-2001</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Swapnil-2001" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/TakumaKira"><img alt="Takuma Kira" src="https://avatars1.githubusercontent.com/u/50410641?v=4?s=120" width="120px;" /><br /><sub><b>Takuma Kira</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3ATakumaKira" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=TakumaKira" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=TakumaKira" title="Tests">⚠️</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/NagariaHussain"><img alt="Mohammad Hussain Nagaria" src="https://avatars1.githubusercontent.com/u/34810212?v=4?s=120" width="120px;" /><br /><sub><b>Mohammad Hussain Nagaria</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3ANagariaHussain" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://tush.xyz"><img alt="Tushar Choudhari" src="https://avatars1.githubusercontent.com/u/33191895?v=4?s=120" width="120px;" /><br /><sub><b>Tushar Choudhari</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=chtushar" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=chtushar" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://nakulshahdadpuri3141@gmail.com"><img alt="Nakul Shahdadpuri" src="https://avatars2.githubusercontent.com/u/43999912?v=4?s=120" width="120px;" /><br /><sub><b>Nakul Shahdadpuri</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nakul-shahdadpuri" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jpdutoit"><img alt="Jacques P. du Toit" src="https://avatars3.githubusercontent.com/u/160440?v=4?s=120" width="120px;" /><br /><sub><b>Jacques P. du Toit</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jpdutoit" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/surajsurajsuraj"><img alt="surajsurajsuraj" src="https://avatars1.githubusercontent.com/u/45002201?v=4?s=120" width="120px;" /><br /><sub><b>surajsurajsuraj</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Asurajsurajsuraj" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://connieliu0.github.io"><img alt="Connie Liu" src="https://avatars3.githubusercontent.com/u/50529223?v=4?s=120" width="120px;" /><br /><sub><b>Connie Liu</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=connieliu0" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-connieliu0" title="Design">🎨</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://zeke.sikelianos.com"><img alt="Zeke Sikelianos" src="https://avatars1.githubusercontent.com/u/2289?v=4?s=120" width="120px;" /><br /><sub><b>Zeke Sikelianos</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=zeke" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/dryniguez"><img alt="Ramon Jr. Yniguez" src="https://avatars3.githubusercontent.com/u/5209194?v=4?s=120" width="120px;" /><br /><sub><b>Ramon Jr. Yniguez</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=TheoNeUpKid88" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/Benoit_Boure"><img alt="Benoît Bouré" src="https://avatars0.githubusercontent.com/u/7089997?v=4?s=120" width="120px;" /><br /><sub><b>Benoît Bouré</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=bboure" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.linkedin.com/in/heroichitesh"><img alt="Hitesh Kumar" src="https://avatars3.githubusercontent.com/u/37622734?v=4?s=120" width="120px;" /><br /><sub><b>Hitesh Kumar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=HeroicHitesh" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://samporapeli.fi"><img alt="Sampo Rapeli" src="https://avatars0.githubusercontent.com/u/35733458?v=4?s=120" width="120px;" /><br /><sub><b>Sampo Rapeli</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-samporapeli" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Milchreis"><img alt="Nick Müller" src="https://avatars1.githubusercontent.com/u/544436?v=4?s=120" width="120px;" /><br /><sub><b>Nick Müller</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-milchreis" title="Plugin/utility libraries">🔌</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tankeith"><img alt="Keith Tan" src="https://avatars0.githubusercontent.com/u/24620742?v=4?s=120" width="120px;" /><br /><sub><b>Keith Tan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=tankeith" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://berkeozgen.me/"><img alt="Berke Özgen" src="https://avatars1.githubusercontent.com/u/56646605?v=4?s=120" width="120px;" /><br /><sub><b>Berke Özgen</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aberkeozgen08" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://musab.me"><img alt="Musab Kılıç" src="https://avatars3.githubusercontent.com/u/30195912?v=4?s=120" width="120px;" /><br /><sub><b>Musab Kılıç</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=musabkilic" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=musabkilic" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://nmarino.dev"><img alt="Nicholas Marino" src="https://avatars2.githubusercontent.com/u/56003967?v=4?s=120" width="120px;" /><br /><sub><b>Nicholas Marino</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nsmarino" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://greg.technology/"><img alt="Greg Sadetsky" src="https://avatars0.githubusercontent.com/u/1017304?v=4?s=120" width="120px;" /><br /><sub><b>Greg Sadetsky</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=gregsadetsky" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Priya-Pathak"><img alt="Priya-Pathak" src="https://avatars1.githubusercontent.com/u/39853633?v=4?s=120" width="120px;" /><br /><sub><b>Priya-Pathak</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-Priya-Pathak" title="Examples">💡</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/daniel-michel"><img alt="Daniel Michel" src="https://avatars1.githubusercontent.com/u/65034538?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Michel</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=daniel-michel" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://nisar.dev"><img alt="Nisar Hassan Naqvi" src="https://avatars3.githubusercontent.com/u/46004116?v=4?s=120" width="120px;" /><br /><sub><b>Nisar Hassan Naqvi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nisarhassan12" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shocknoble"><img alt="Joshua Noble" src="https://avatars2.githubusercontent.com/u/36461802?v=4?s=120" width="120px;" /><br /><sub><b>Joshua Noble</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=shocknoble" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://liamp.uk"><img alt="Liam Piesley" src="https://avatars1.githubusercontent.com/u/17195367?v=4?s=120" width="120px;" /><br /><sub><b>Liam Piesley</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=liampuk" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/rt1301"><img alt="Rishabh Taparia" src="https://avatars0.githubusercontent.com/u/63252510?v=4?s=120" width="120px;" /><br /><sub><b>Rishabh Taparia</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=rt1301" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=rt1301" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dansarno"><img alt="Daniel Sarno" src="https://avatars0.githubusercontent.com/u/48413743?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Sarno</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-dansarno" title="Examples">💡</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://kkvanonymous.github.io/"><img alt="Kunal Kumar Verma" src="https://avatars3.githubusercontent.com/u/58628586?v=4?s=120" width="120px;" /><br /><sub><b>Kunal Kumar Verma</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=KKVANONYMOUS" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3AKKVANONYMOUS" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=KKVANONYMOUS" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://bharathkumarravichandran.github.io"><img alt="Bharath Kumar R" src="https://avatars2.githubusercontent.com/u/16106573?v=4?s=120" width="120px;" /><br /><sub><b>Bharath Kumar R</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=BharathKumarRavichandran" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/aditya-mohan-b1ba7a182/"><img alt="Aditya Mohan" src="https://avatars2.githubusercontent.com/u/54040096?v=4?s=120" width="120px;" /><br /><sub><b>Aditya Mohan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=TraXIcoN" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/arijit-kundu/"><img alt="Arijit Kundu" src="https://avatars1.githubusercontent.com/u/53327173?v=4?s=120" width="120px;" /><br /><sub><b>Arijit Kundu</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Acovalentbond" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=covalentbond" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=covalentbond" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://tannerdolby.com"><img alt="Tanner Dolby" src="https://avatars3.githubusercontent.com/u/48612525?v=4?s=120" width="120px;" /><br /><sub><b>Tanner Dolby</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=tannerdolby" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://samdelong.com"><img alt="sam delong" src="https://avatars0.githubusercontent.com/u/20839292?v=4?s=120" width="120px;" /><br /><sub><b>sam delong</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=samdelong" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.haoohaoo.com"><img alt="Zhao Xin" src="https://avatars0.githubusercontent.com/u/1265068?v=4?s=120" width="120px;" /><br /><sub><b>Zhao Xin</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=archtaurus" title="Code">💻</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Aarchtaurus" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/siv2r"><img alt="Sivaram D" src="https://avatars3.githubusercontent.com/u/56887198?v=4?s=120" width="120px;" /><br /><sub><b>Sivaram D</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=siv2r" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=siv2r" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/frappelatte28"><img alt="Pragya" src="https://avatars0.githubusercontent.com/u/64382399?v=4?s=120" width="120px;" /><br /><sub><b>Pragya</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=frappelatte28" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/myselfhimself"><img alt="Jonathan-David Schröder" src="https://avatars.githubusercontent.com/u/1265346?v=4?s=120" width="120px;" /><br /><sub><b>Jonathan-David Schröder</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-myselfhimself" title="Ideas, Planning, &amp; Feedback">🤔</a> <a href="https://github.com/processing/p5.js/commits?author=myselfhimself" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ShenpaiSharma"><img alt="Shubham Kumar" src="https://avatars.githubusercontent.com/u/47415702?v=4?s=120" width="120px;" /><br /><sub><b>Shubham Kumar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ShenpaiSharma" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nakednous"><img alt="Jean Pierre Charalambos" src="https://avatars.githubusercontent.com/u/645599?&amp;v=4?s=120" width="120px;" /><br /><sub><b>Jean Pierre Charalambos</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nakednous" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-nakednous" title="Tools">🔧</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/satyasaibhushan"><img alt="Sai Bhushan" src="https://avatars.githubusercontent.com/u/40578313?v=4?s=120" width="120px;" /><br /><sub><b>Sai Bhushan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=satyasaibhushan" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=satyasaibhushan" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/vulongphan"><img alt="Long Phan" src="https://avatars.githubusercontent.com/u/46087559?v=4?s=120" width="120px;" /><br /><sub><b>Long Phan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=vulongphan" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://jcelerier.name"><img alt="Jean-Michaël Celerier" src="https://avatars.githubusercontent.com/u/2772730?v=4?s=120" width="120px;" /><br /><sub><b>Jean-Michaël Celerier</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Ajcelerier" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://sosunnyproject.github.io"><img alt="So Sun Park" src="https://avatars.githubusercontent.com/u/17012862?v=4?s=120" width="120px;" /><br /><sub><b>So Sun Park</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sosunnyproject" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://msub2.com"><img alt="Daniel Adams" src="https://avatars.githubusercontent.com/u/70986246?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Adams</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=msub2" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=msub2" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://shantanu-kaushik.herokuapp.com/"><img alt="Aloneduckling" src="https://avatars.githubusercontent.com/u/54030684?v=4?s=120" width="120px;" /><br /><sub><b>Aloneduckling</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Aloneduckling" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://msundaram.me"><img alt="Mohana Sundaram S" src="https://avatars.githubusercontent.com/u/60923158?v=4?s=120" width="120px;" /><br /><sub><b>Mohana Sundaram S</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=highonweb" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/two-ticks"><img alt="TwoTicks" src="https://avatars.githubusercontent.com/u/68433541?v=4?s=120" width="120px;" /><br /><sub><b>TwoTicks</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=two-ticks" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=two-ticks" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-two-ticks" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://kathrynisabelle.com"><img alt="Kathryn Isabelle Lawrence" src="https://avatars.githubusercontent.com/u/15334958?v=4?s=120" width="120px;" /><br /><sub><b>Kathryn Isabelle Lawrence</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=lawreka" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-lawreka" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.joonasjokinen.fi"><img alt="Joonas Jokinen" src="https://avatars.githubusercontent.com/u/46967273?v=4?s=120" width="120px;" /><br /><sub><b>Joonas Jokinen</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-jnsjknn" title="Design">🎨</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Ajaya1000"><img alt="Ajaya Mati" src="https://avatars.githubusercontent.com/u/43005088?v=4?s=120" width="120px;" /><br /><sub><b>Ajaya Mati</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Ajaya1000" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/suhascv"><img alt="Suhas CV" src="https://avatars.githubusercontent.com/u/43292181?v=4?s=120" width="120px;" /><br /><sub><b>Suhas CV</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=suhascv" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://sanjaysinghrajpoot.me"><img alt="Sanjay Singh Rajpoot" src="https://avatars.githubusercontent.com/u/67458417?v=4?s=120" width="120px;" /><br /><sub><b>Sanjay Singh Rajpoot</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=SanjaySinghRajpoot" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://chrispilcher.me"><img alt="Chris P." src="https://avatars.githubusercontent.com/u/5150833?v=4?s=120" width="120px;" /><br /><sub><b>Chris P.</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=b4ux1t3" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/maxthomax"><img alt="Thomas Herlea" src="https://avatars.githubusercontent.com/u/888491?v=4?s=120" width="120px;" /><br /><sub><b>Thomas Herlea</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Amaxthomax" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=maxthomax" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=maxthomax" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://smrnjeet222.github.io"><img alt="Simranjeet Singh" src="https://avatars.githubusercontent.com/u/48654626?v=4?s=120" width="120px;" /><br /><sub><b>Simranjeet Singh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=smrnjeet222" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-smrnjeet222" title="Talks">📢</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-smrnjeet222" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Asmrnjeet222" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://rahulm2310.github.io/Portfolio"><img alt="Rahul Mohata" src="https://avatars.githubusercontent.com/u/54268438?v=4?s=120" width="120px;" /><br /><sub><b>Rahul Mohata</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Rahulm2310" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.davepagurek.com"><img alt="Dave Pagurek" src="https://avatars.githubusercontent.com/u/5315059?v=4?s=120" width="120px;" /><br /><sub><b>Dave Pagurek</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=davepagurek" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=davepagurek" title="Tests">⚠️</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://fb.com/leo.kamwathi"><img alt="Leo Kamwathi" src="https://avatars.githubusercontent.com/u/9960539?v=4?s=120" width="120px;" /><br /><sub><b>Leo Kamwathi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=leokamwathi" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/DavidWeiss2"><img alt="David Weiss" src="https://avatars.githubusercontent.com/u/12801099?v=4?s=120" width="120px;" /><br /><sub><b>David Weiss</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=DavidWeiss2" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-DavidWeiss2" title="Talks">📢</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3ADavidWeiss2" title="Reviewed Pull Requests">👀</a> <a href="https://github.com/processing/p5.js/commits?author=DavidWeiss2" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/christhomson"><img alt="Chris Thomson" src="https://avatars.githubusercontent.com/u/22621?v=4?s=120" width="120px;" /><br /><sub><b>Chris Thomson</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=christhomson" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Achristhomson" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://olusegunsamson.me"><img alt="mainstreamdev" src="https://avatars.githubusercontent.com/u/40327060?v=4?s=120" width="120px;" /><br /><sub><b>mainstreamdev</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Acryptochap" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ageonic"><img alt="Aaron George" src="https://avatars.githubusercontent.com/u/79060613?v=4?s=120" width="120px;" /><br /><sub><b>Aaron George</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aageonic" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/aLyonsGH"><img alt="Alex Lyons" src="https://avatars.githubusercontent.com/u/52976155?s=400&amp;u=e1dde38fbd983995c459ec3d1f999193bd1e132e&amp;v=4?s=120" width="120px;" /><br /><sub><b>Alex Lyons</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aLyonsGH" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/TylersGit"><img alt="Tyler Jordan" src="https://avatars.githubusercontent.com/u/71571453?v=4?s=120" width="120px;" /><br /><sub><b>Tyler Jordan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=TylersGit" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://ghales.top"><img alt="Ghales" src="https://avatars.githubusercontent.com/u/37638655?v=4?s=120" width="120px;" /><br /><sub><b>Ghales</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-ghalestrilo" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=ghalestrilo" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-ghalestrilo" title="Tools">🔧</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/JetStarBlues"><img alt="JetStarBlues" src="https://avatars.githubusercontent.com/u/4354703?v=4?s=120" width="120px;" /><br /><sub><b>JetStarBlues</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JetStarBlues" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=JetStarBlues" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/code4humanity"><img alt="Avelar" src="https://avatars.githubusercontent.com/u/66260854?v=4?s=120" width="120px;" /><br /><sub><b>Avelar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=code4humanity" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://code.osteele.com/"><img alt="Oliver Steele" src="https://avatars.githubusercontent.com/u/674?v=4?s=120" width="120px;" /><br /><sub><b>Oliver Steele</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=osteele" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/pearmini"><img alt="MiniPear" src="https://avatars.githubusercontent.com/u/49330279?v=4?s=120" width="120px;" /><br /><sub><b>MiniPear</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=pearmini" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.paulwheeler.us/"><img alt="Paul Wheeler" src="https://avatars.githubusercontent.com/u/940246?v=4?s=120" width="120px;" /><br /><sub><b>Paul Wheeler</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sflanker" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://nitin-rana.github.io/nitinrana.github.io/"><img alt="Nitin Rana" src="https://avatars.githubusercontent.com/u/58933197?v=4?s=120" width="120px;" /><br /><sub><b>Nitin Rana</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Nitin-Rana" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.anniemckinnon.com/"><img alt="Annie McKinnon" src="https://avatars.githubusercontent.com/u/35992537?v=4?s=120" width="120px;" /><br /><sub><b>Annie McKinnon</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aanniemckinnon" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=anniemckinnon" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jiwon.me"><img alt="Jiwon Park (hanpanic)" src="https://avatars.githubusercontent.com/u/53327429?v=4?s=120" width="120px;" /><br /><sub><b>Jiwon Park (hanpanic)</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jiwonme" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://truemaxdh.github.io/"><img alt="truemaxdh" src="https://avatars.githubusercontent.com/u/12081386?v=4?s=120" width="120px;" /><br /><sub><b>truemaxdh</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Atruemaxdh" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=truemaxdh" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/katiejliu"><img alt="Katie" src="https://avatars.githubusercontent.com/u/78124298?v=4?s=120" width="120px;" /><br /><sub><b>Katie</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=katiejliu" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.alura.com.br"><img alt="Guilherme Silveira" src="https://avatars.githubusercontent.com/u/51391?v=4?s=120" width="120px;" /><br /><sub><b>Guilherme Silveira</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=guilhermesilveira" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.camilleroux.com/"><img alt="Camille Roux" src="https://avatars.githubusercontent.com/u/25977?v=4?s=120" width="120px;" /><br /><sub><b>Camille Roux</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=camilleroux" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/reejuBhattacharya"><img alt="reejuBhattacharya" src="https://avatars.githubusercontent.com/u/40564575?v=4?s=120" width="120px;" /><br /><sub><b>reejuBhattacharya</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=reejuBhattacharya" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=reejuBhattacharya" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/akshatnema"><img alt="Akshat Nema" src="https://avatars.githubusercontent.com/u/76521428?v=4?s=120" width="120px;" /><br /><sub><b>Akshat Nema</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=akshatnema" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/IamEzio"><img alt="Anshuman Maurya" src="https://avatars.githubusercontent.com/u/89375125?v=4?s=120" width="120px;" /><br /><sub><b>Anshuman Maurya</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AIamEzio" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Himanshu664"><img alt="Himanshu Malviya" src="https://avatars.githubusercontent.com/u/76220055?v=4?s=120" width="120px;" /><br /><sub><b>Himanshu Malviya</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AHimanshu664" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/chosamuel"><img alt="Samuel Cho" src="https://avatars.githubusercontent.com/u/26333602?v=4?s=120" width="120px;" /><br /><sub><b>Samuel Cho</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Achosamuel" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/TOrfevres"><img alt="Théodore Orfèvres" src="https://avatars.githubusercontent.com/u/23334809?v=4?s=120" width="120px;" /><br /><sub><b>Théodore Orfèvres</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3ATOrfevres" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/JaPatGitHub"><img alt="Jyotiraditya Pradhan" src="https://avatars.githubusercontent.com/u/73636668?v=4?s=120" width="120px;" /><br /><sub><b>Jyotiraditya Pradhan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JaPatGitHub" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Zearin"><img alt="Zearin" src="https://avatars.githubusercontent.com/u/630124?v=4?s=120" width="120px;" /><br /><sub><b>Zearin</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Zearin" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/pifragile"><img alt="pifragile" src="https://avatars.githubusercontent.com/u/14249275?v=4?s=120" width="120px;" /><br /><sub><b>pifragile</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Apifragile" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/j-stodd"><img alt="Jstodd" src="https://avatars.githubusercontent.com/u/65479705?v=4?s=120" width="120px;" /><br /><sub><b>Jstodd</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aj-stodd" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://racket-stories.com"><img alt="Jens Axel Søgaard" src="https://avatars.githubusercontent.com/u/461765?v=4?s=120" width="120px;" /><br /><sub><b>Jens Axel Søgaard</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=soegaard" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Asoegaard" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/oleboleskole3"><img alt="oleboleskole3" src="https://avatars.githubusercontent.com/u/43952813?v=4?s=120" width="120px;" /><br /><sub><b>oleboleskole3</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aoleboleskole3" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/awelles"><img alt="A Welles" src="https://avatars.githubusercontent.com/u/115194?v=4?s=120" width="120px;" /><br /><sub><b>A Welles</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aawelles" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://superblob.studio/"><img alt="andrei antonescu" src="https://avatars.githubusercontent.com/u/5208182?v=4?s=120" width="120px;" /><br /><sub><b>andrei antonescu</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aandreiantonescu" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dipamsen"><img alt="Fun Planet" src="https://avatars.githubusercontent.com/u/59444569?v=4?s=120" width="120px;" /><br /><sub><b>Fun Planet</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Adipamsen" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/stigmollerhansen"><img alt="Stig Møller Hansen" src="https://avatars.githubusercontent.com/u/6607966?v=4?s=120" width="120px;" /><br /><sub><b>Stig Møller Hansen</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Astigmollerhansen" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://derekenlow.com"><img alt="Derek Enlow" src="https://avatars.githubusercontent.com/u/28745080?v=4?s=120" width="120px;" /><br /><sub><b>Derek Enlow</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=frigorific44" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://willmartian.com"><img alt="Will Martin" src="https://avatars.githubusercontent.com/u/17113462?v=4?s=120" width="120px;" /><br /><sub><b>Will Martin</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-willmartian" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/beaumu"><img alt="Beau Muylle" src="https://avatars.githubusercontent.com/u/25036955?v=4?s=120" width="120px;" /><br /><sub><b>Beau Muylle</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=beaumu" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/unjust"><img alt="Ivy Feraco" src="https://avatars.githubusercontent.com/u/92090?v=4?s=120" width="120px;" /><br /><sub><b>Ivy Feraco</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aunjust" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://RandomSyntax.Net"><img alt="Gareth Williams" src="https://avatars.githubusercontent.com/u/6419944?v=4?s=120" width="120px;" /><br /><sub><b>Gareth Williams</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Gaweph" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://bandism.net/"><img alt="Ikko Ashimine" src="https://avatars.githubusercontent.com/u/22633385?v=4?s=120" width="120px;" /><br /><sub><b>Ikko Ashimine</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=eltociear" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/0xJonas"><img alt="Jonas Rinke" src="https://avatars.githubusercontent.com/u/24874041?v=4?s=120" width="120px;" /><br /><sub><b>Jonas Rinke</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3A0xJonas" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.gakuin.otsuma.ac.jp/english/"><img alt="MATSUDA, Kouichi" src="https://avatars.githubusercontent.com/u/14014568?v=4?s=120" width="120px;" /><br /><sub><b>MATSUDA, Kouichi</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AKouichiMatsuda" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/stampyzfanz"><img alt="stampyzfanz" src="https://avatars.githubusercontent.com/u/34364128?v=4?s=120" width="120px;" /><br /><sub><b>stampyzfanz</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=stampyzfanz" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/taejs"><img alt="tae" src="https://avatars.githubusercontent.com/u/41318449?v=4?s=120" width="120px;" /><br /><sub><b>tae</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Ataejs" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Divyansh013"><img alt="Divyansh013" src="https://avatars.githubusercontent.com/u/85135469?v=4?s=120" width="120px;" /><br /><sub><b>Divyansh013</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Divyansh013" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/rinkydevi"><img alt="rinkydevi" src="https://avatars.githubusercontent.com/u/82359874?v=4?s=120" width="120px;" /><br /><sub><b>rinkydevi</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-rinkydevi" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.zhdk.ch/weiterbildung/weiterbildung-design/cas-coding-for-the-arts"><img alt="Coding for the Arts" src="https://avatars.githubusercontent.com/u/88927553?v=4?s=120" width="120px;" /><br /><sub><b>Coding for the Arts</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Acas-c4ta" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://danieljamesross.github.io"><img alt="Dan" src="https://avatars.githubusercontent.com/u/28922296?v=4?s=120" width="120px;" /><br /><sub><b>Dan</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Adanieljamesross" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://sparshg.github.io"><img alt="sparshg" src="https://avatars.githubusercontent.com/u/43041139?v=4?s=120" width="120px;" /><br /><sub><b>sparshg</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Asparshg" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/liz-peng"><img alt="Liz Peng" src="https://avatars.githubusercontent.com/u/8376256?v=4?s=120" width="120px;" /><br /><sub><b>Liz Peng</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-liz-peng" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=liz-peng" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-liz-peng" title="Tools">🔧</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/koolaidkrusade"><img alt="koolaidkrusade" src="https://avatars.githubusercontent.com/u/95722198?v=4?s=120" width="120px;" /><br /><sub><b>koolaidkrusade</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=koolaidkrusade" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/smilee"><img alt="smilee" src="https://avatars.githubusercontent.com/u/5793796?v=4?s=120" width="120px;" /><br /><sub><b>smilee</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=smilee" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/CommanderRoot"><img alt="CommanderRoot" src="https://avatars.githubusercontent.com/u/4395417?v=4?s=120" width="120px;" /><br /><sub><b>CommanderRoot</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=CommanderRoot" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://philipbell.org"><img alt="Philip Bell" src="https://avatars.githubusercontent.com/u/3860311?v=4?s=120" width="120px;" /><br /><sub><b>Philip Bell</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=processprocess" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tapioca24"><img alt="tapioca24" src="https://avatars.githubusercontent.com/u/12683107?v=4?s=120" width="120px;" /><br /><sub><b>tapioca24</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-tapioca24" title="Plugin/utility libraries">🔌</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://qianqian-ye.com"><img alt="Qianqian Ye" src="https://avatars.githubusercontent.com/u/18587130?v=4?s=120" width="120px;" /><br /><sub><b>Qianqian Ye</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Qianqianye" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-Qianqianye" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=Qianqianye" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-Qianqianye" title="Event Organizing">📋</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3AQianqianye" title="Reviewed Pull Requests">👀</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Qianqianye" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/adarrssh"><img alt="Adarsh" src="https://avatars.githubusercontent.com/u/85433137?v=4?s=120" width="120px;" /><br /><sub><b>Adarsh</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-adarrssh" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/kaabe1"><img alt="kaabe1" src="https://avatars.githubusercontent.com/u/78185255?v=4?s=120" width="120px;" /><br /><sub><b>kaabe1</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-kaabe1" title="Design">🎨</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-kaabe1" title="Event Organizing">📋</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.guirdo.xyz/"><img alt="Seb Méndez" src="https://avatars.githubusercontent.com/u/21044700?v=4?s=120" width="120px;" /><br /><sub><b>Seb Méndez</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Guirdo" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/3ru"><img alt="Ryuya" src="https://avatars.githubusercontent.com/u/69892552?v=4?s=120" width="120px;" /><br /><sub><b>Ryuya</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3A3ru" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3A3ru" title="Reviewed Pull Requests">👀</a> <a href="https://github.com/processing/p5.js/commits?author=3ru" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/LEMIBANDDEXARI"><img alt="LEMIBANDDEXARI" src="https://avatars.githubusercontent.com/u/70129787?v=4?s=120" width="120px;" /><br /><sub><b>LEMIBANDDEXARI</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-LEMIBANDDEXARI" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://linktr.ee/probablyvivek"><img alt="Vivek Tiwari" src="https://avatars.githubusercontent.com/u/25459353?v=4?s=120" width="120px;" /><br /><sub><b>Vivek Tiwari</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-probablyvivek" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/KevinGrajeda"><img alt="Kevin Grajeda" src="https://avatars.githubusercontent.com/u/60023139?v=4?s=120" width="120px;" /><br /><sub><b>Kevin Grajeda</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=KevinGrajeda" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/anniezhengg"><img alt="anniezhengg" src="https://avatars.githubusercontent.com/u/78184655?v=4?s=120" width="120px;" /><br /><sub><b>anniezhengg</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=anniezhengg" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-anniezhengg" title="Design">🎨</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/SNP0301"><img alt="Seung-Gi Kim(David)" src="https://avatars.githubusercontent.com/u/68281918?v=4?s=120" width="120px;" /><br /><sub><b>Seung-Gi Kim(David)</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-SNP0301" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://ikebot108.weebly.com/"><img alt="Ike Bischof" src="https://avatars.githubusercontent.com/u/56776763?v=4?s=120" width="120px;" /><br /><sub><b>Ike Bischof</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=IkeB108" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://ongzz.ml"><img alt="Ong Zhi Zheng" src="https://avatars.githubusercontent.com/u/47311100?v=4?s=120" width="120px;" /><br /><sub><b>Ong Zhi Zheng</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-ongzzzzzz" title="Plugin/utility libraries">🔌</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/bsubbaraman"><img alt="bsubbaraman" src="https://avatars.githubusercontent.com/u/11969085?v=4?s=120" width="120px;" /><br /><sub><b>bsubbaraman</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-bsubbaraman" title="Plugin/utility libraries">🔌</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jdeboi.com"><img alt="Jenna deBoisblanc" src="https://avatars.githubusercontent.com/u/1548679?v=4?s=120" width="120px;" /><br /><sub><b>Jenna deBoisblanc</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-jdeboi" title="Plugin/utility libraries">🔌</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Manpreet-Singh001"><img alt="manpreet" src="https://avatars.githubusercontent.com/u/93985396?v=4?s=120" width="120px;" /><br /><sub><b>manpreet</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Manpreet-Singh001" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=Manpreet-Singh001" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=Manpreet-Singh001" title="Tests">⚠️</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/TetroGem"><img alt="TetroGem" src="https://avatars.githubusercontent.com/u/19498453?v=4?s=120" width="120px;" /><br /><sub><b>TetroGem</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-TetroGem" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://ggorlen.github.io/"><img alt="ggorlen" src="https://avatars.githubusercontent.com/u/17895165?v=4?s=120" width="120px;" /><br /><sub><b>ggorlen</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ggorlen" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/raclim"><img alt="raclim" src="https://avatars.githubusercontent.com/u/43053081?v=4?s=120" width="120px;" /><br /><sub><b>raclim</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=raclim" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dwight9339"><img alt="David White" src="https://avatars.githubusercontent.com/u/25517492?v=4?s=120" width="120px;" /><br /><sub><b>David White</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dwight9339" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://lf32.github.io/Blog"><img alt="Akhil Raj" src="https://avatars.githubusercontent.com/u/96695352?v=4?s=120" width="120px;" /><br /><sub><b>Akhil Raj</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Alf32" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=lf32" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-lf32" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-lf32" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=lf32" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://brahvim.github.io"><img alt="Brahvim" src="https://avatars.githubusercontent.com/u/69293652?v=4?s=120" width="120px;" /><br /><sub><b>Brahvim</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Brahvim" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/UnityOfFairfax"><img alt="UnityOfFairfax" src="https://avatars.githubusercontent.com/u/46071997?v=4?s=120" width="120px;" /><br /><sub><b>UnityOfFairfax</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=UnityOfFairfax" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/inaridarkfox4231"><img alt="INARI_DARKFOX" src="https://avatars.githubusercontent.com/u/39549290?v=4?s=120" width="120px;" /><br /><sub><b>INARI_DARKFOX</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=inaridarkfox4231" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jwilliamdunn.com"><img alt="James Dunn" src="https://avatars.githubusercontent.com/u/4262131?v=4?s=120" width="120px;" /><br /><sub><b>James Dunn</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Ajwdunn1" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=jwdunn1" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Malayvasa"><img alt="Malay Vasa" src="https://avatars.githubusercontent.com/u/22751053?v=4?s=120" width="120px;" /><br /><sub><b>Malay Vasa</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-Malayvasa" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=Malayvasa" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/wagedu"><img alt="wagedu" src="https://avatars.githubusercontent.com/u/1332848?v=4?s=120" width="120px;" /><br /><sub><b>wagedu</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Awagedu" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://weslord.com"><img alt="Wes Lord" src="https://avatars.githubusercontent.com/u/1022948?v=4?s=120" width="120px;" /><br /><sub><b>Wes Lord</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=weslord" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=weslord" title="Tests">⚠️</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/pinky-pig"><img alt="pinky-pig" src="https://avatars.githubusercontent.com/u/42307398?v=4?s=120" width="120px;" /><br /><sub><b>pinky-pig</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-pinky-pig" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ChinmayKadam172"><img alt="Chinmay Kadam" src="https://avatars.githubusercontent.com/u/57569079?v=4?s=120" width="120px;" /><br /><sub><b>Chinmay Kadam</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ChinmayKadam172" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Prateek462003"><img alt="Prateekgit" src="https://avatars.githubusercontent.com/u/90177794?v=4?s=120" width="120px;" /><br /><sub><b>Prateekgit</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Prateek462003" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://adityashrivastav.tech"><img alt="Aditya Shrivastav" src="https://avatars.githubusercontent.com/u/81470938?v=4?s=120" width="120px;" /><br /><sub><b>Aditya Shrivastav</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aaditya-shrivastavv" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=aditya-shrivastavv" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=aditya-shrivastavv" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/davidbmx"><img alt="David" src="https://avatars.githubusercontent.com/u/12814631?v=4?s=120" width="120px;" /><br /><sub><b>David</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Adavidbmx" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=davidbmx" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AryanKoundal"><img alt="Aryan Koundal" src="https://avatars.githubusercontent.com/u/77334487?v=4?s=120" width="120px;" /><br /><sub><b>Aryan Koundal</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AryanKoundal" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://alptugan.com"><img alt="alp tuğan" src="https://avatars.githubusercontent.com/u/315287?v=4?s=120" width="120px;" /><br /><sub><b>alp tuğan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=alptugan" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-alptugan" title="Plugin/utility libraries">🔌</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-alptugan" title="Tools">🔧</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-alptugan" title="Tutorials">✅</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-alptugan" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ltciro"><img alt="Laura Ciro" src="https://avatars.githubusercontent.com/u/26748227?v=4?s=120" width="120px;" /><br /><sub><b>Laura Ciro</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-ltciro" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/kate-grant-dev/"><img alt="Kate Grant" src="https://avatars.githubusercontent.com/u/61399166?v=4?s=120" width="120px;" /><br /><sub><b>Kate Grant</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Akate-grant" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=kate-grant" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=kate-grant" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/yogitheboss"><img alt="Yograj Rajput" src="https://avatars.githubusercontent.com/u/91418287?v=4?s=120" width="120px;" /><br /><sub><b>Yograj Rajput</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-yogitheboss" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.holomorfo.com"><img alt="Dr. Holomorfo" src="https://avatars.githubusercontent.com/u/9595617?v=4?s=120" width="120px;" /><br /><sub><b>Dr. Holomorfo</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-holomorfo" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://p5play.org"><img alt="Quinton Ashley" src="https://avatars.githubusercontent.com/u/20031683?v=4?s=120" width="120px;" /><br /><sub><b>Quinton Ashley</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=quinton-ashley" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aquinton-ashley" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-quinton-ashley" title="Plugin/utility libraries">🔌</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ninioArtillero"><img alt="Xavier Góngora" src="https://avatars.githubusercontent.com/u/64996634?v=4?s=120" width="120px;" /><br /><sub><b>Xavier Góngora</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-ninioArtillero" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.hernanivillasenor.com"><img alt="hvillase" src="https://avatars.githubusercontent.com/u/8923320?v=4?s=120" width="120px;" /><br /><sub><b>hvillase</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-hvillase" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://shivanshsharma13.github.io/"><img alt="Shivansh Sharma" src="https://avatars.githubusercontent.com/u/68982304?v=4?s=120" width="120px;" /><br /><sub><b>Shivansh Sharma</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-shivanshsharma13" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Elliot-Hernandez"><img alt="Elliot-Hernandez" src="https://avatars.githubusercontent.com/u/86040553?v=4?s=120" width="120px;" /><br /><sub><b>Elliot-Hernandez</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Elliot-Hernandez" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hunahpu18"><img alt="hunahpu18" src="https://avatars.githubusercontent.com/u/101674270?v=4?s=120" width="120px;" /><br /><sub><b>hunahpu18</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-hunahpu18" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://dewanshthakur.vercel.app"><img alt="Dewansh Thakur" src="https://avatars.githubusercontent.com/u/71703033?v=4?s=120" width="120px;" /><br /><sub><b>Dewansh Thakur</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AdewanshDT" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/konstantinstanmeyer"><img alt="konstantinstanmeyer" src="https://avatars.githubusercontent.com/u/78387837?v=4?s=120" width="120px;" /><br /><sub><b>konstantinstanmeyer</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=konstantinstanmeyer" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/al6862"><img alt="al6862" src="https://avatars.githubusercontent.com/u/120232244?v=4?s=120" width="120px;" /><br /><sub><b>al6862</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aal6862" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=al6862" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/monmon2003"><img alt="Monalisa Maity" src="https://avatars.githubusercontent.com/u/122162780?v=4?s=120" width="120px;" /><br /><sub><b>Monalisa Maity</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=monmon2003" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/kr-2003"><img alt="Abhinav Kumar" src="https://avatars.githubusercontent.com/u/96587705?v=4?s=120" width="120px;" /><br /><sub><b>Abhinav Kumar</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Akr-2003" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://nownine.vercel.app"><img alt="Abhinav Srinivas" src="https://avatars.githubusercontent.com/u/25835195?v=4?s=120" width="120px;" /><br /><sub><b>Abhinav Srinivas</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Anown1ne" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=nown1ne" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sawaisinghh"><img alt="Sawai Singh Rajpurohit" src="https://avatars.githubusercontent.com/u/49401909?v=4?s=120" width="120px;" /><br /><sub><b>Sawai Singh Rajpurohit</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sawaisinghh" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Asawaisinghh" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=sawaisinghh" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/anpanring"><img alt="Jack Dempsey" src="https://avatars.githubusercontent.com/u/48136223?v=4?s=120" width="120px;" /><br /><sub><b>Jack Dempsey</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aanpanring" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Aryan1982"><img alt="Aryan Thakor" src="https://avatars.githubusercontent.com/u/62349184?v=4?s=120" width="120px;" /><br /><sub><b>Aryan Thakor</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Aryan1982" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/MostafaEwis"><img alt="Mostafa Ewis" src="https://avatars.githubusercontent.com/u/64862002?v=4?s=120" width="120px;" /><br /><sub><b>Mostafa Ewis</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-MostafaEwis" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nabilhassein"><img alt="Nabil Hassein" src="https://avatars.githubusercontent.com/u/693744?v=4?s=120" width="120px;" /><br /><sub><b>Nabil Hassein</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-nabilhassein" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://asukaminato.notion.site/Blog-3c0df75d3d8b471ab67e97ecc82e10a4"><img alt="AsukaMinato" src="https://avatars.githubusercontent.com/u/30024051?v=4?s=120" width="120px;" /><br /><sub><b>AsukaMinato</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-wuyudi" title="Translation">🌍</a> <a href="https://github.com/processing/p5.js/commits?author=wuyudi" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/agrshch"><img alt="agrshch" src="https://avatars.githubusercontent.com/u/98658900?v=4?s=120" width="120px;" /><br /><sub><b>agrshch</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=agrshch" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://shibomb.xyz"><img alt="SHIBAHARA Hiroki" src="https://avatars.githubusercontent.com/u/958471?v=4?s=120" width="120px;" /><br /><sub><b>SHIBAHARA Hiroki</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=shibomb" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-shibomb" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://twitter.com/CallMeSiddhant"><img alt="siddhant" src="https://avatars.githubusercontent.com/u/30566406?v=4?s=120" width="120px;" /><br /><sub><b>siddhant</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Asiddhant1" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=siddhant1" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://calebfoss.com"><img alt="Caleb Foss" src="https://avatars.githubusercontent.com/u/16294664?v=4?s=120" width="120px;" /><br /><sub><b>Caleb Foss</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-calebfoss" title="Ideas, Planning, &amp; Feedback">🤔</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Acalebfoss" title="Reviewed Pull Requests">👀</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-calebfoss" title="Plugin/utility libraries">🔌</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/chechenxu"><img alt="chechenxu" src="https://avatars.githubusercontent.com/u/111816575?v=4?s=120" width="120px;" /><br /><sub><b>chechenxu</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=chechenxu" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/pmarsh-scottlogic"><img alt="Peter Marsh" src="https://avatars.githubusercontent.com/u/118171430?v=4?s=120" width="120px;" /><br /><sub><b>Peter Marsh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=pmarsh-scottlogic" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/neondev27"><img alt="Ahmet Kaya" src="https://avatars.githubusercontent.com/u/88967833?v=4?s=120" width="120px;" /><br /><sub><b>Ahmet Kaya</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-neondev27" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://oz.super.site/"><img alt="oz" src="https://avatars.githubusercontent.com/u/69949201?v=4?s=120" width="120px;" /><br /><sub><b>oz</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ozramos" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://munusshih.com"><img alt="Munus Shih" src="https://avatars.githubusercontent.com/u/34775424?v=4?s=120" width="120px;" /><br /><sub><b>Munus Shih</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=munusshih" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/peilingjiang"><img alt="Peiling Jiang" src="https://avatars.githubusercontent.com/u/25191575?v=4?s=120" width="120px;" /><br /><sub><b>Peiling Jiang</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=peilingjiang" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-peilingjiang" title="Design">🎨</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-peilingjiang" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Decoy4ever"><img alt="Decoy4ever" src="https://avatars.githubusercontent.com/u/50310148?v=4?s=120" width="120px;" /><br /><sub><b>Decoy4ever</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Decoy4ever" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://lindapaiste.com"><img alt="Linda Paiste" src="https://avatars.githubusercontent.com/u/28965286?v=4?s=120" width="120px;" /><br /><sub><b>Linda Paiste</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Alindapaiste" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=lindapaiste" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-lindapaiste" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=lindapaiste" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shujuuu"><img alt="shujulin" src="https://avatars.githubusercontent.com/u/43021463?v=4?s=120" width="120px;" /><br /><sub><b>shujulin</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Ashujuuu" title="Bug reports">🐛</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-shujuuu" title="Ideas, Planning, &amp; Feedback">🤔</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-shujuuu" title="Design">🎨</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://wonger.dev"><img alt="J Wong" src="https://avatars.githubusercontent.com/u/28441593?v=4?s=120" width="120px;" /><br /><sub><b>J Wong</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=wong-justin" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=wong-justin" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://aceslowman.com"><img alt="Austin Lee Slominski" src="https://avatars.githubusercontent.com/u/6826702?v=4?s=120" width="120px;" /><br /><sub><b>Austin Lee Slominski</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aceslowman" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=aceslowman" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://nickbriz.com"><img alt="Nick Briz" src="https://avatars.githubusercontent.com/u/2506806?v=4?s=120" width="120px;" /><br /><sub><b>Nick Briz</b></sub></a><br /><a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Anbriz" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://ayush23dash.github.io"><img alt="Ayush Shankar" src="https://avatars.githubusercontent.com/u/40827680?v=4?s=120" width="120px;" /><br /><sub><b>Ayush Shankar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Ayush23Dash" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/zelf0"><img alt="zelf0" src="https://avatars.githubusercontent.com/u/84274405?v=4?s=120" width="120px;" /><br /><sub><b>zelf0</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=zelf0" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jtn.im"><img alt="JT Nimoy" src="https://avatars.githubusercontent.com/u/183796?v=4?s=120" width="120px;" /><br /><sub><b>JT Nimoy</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jtnimoy" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#plugin-jtnimoy" title="Plugin/utility libraries">🔌</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/SilasVM"><img alt="Victor Morgan" src="https://avatars.githubusercontent.com/u/124199231?v=4?s=120" width="120px;" /><br /><sub><b>Victor Morgan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=SilasVM" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/snwarner22"><img alt="Sekani Warner" src="https://avatars.githubusercontent.com/u/137221902?v=4?s=120" width="120px;" /><br /><sub><b>Sekani Warner</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=snwarner22" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/e-coucou"><img alt="e-Coucou" src="https://avatars.githubusercontent.com/u/4691474?v=4?s=120" width="120px;" /><br /><sub><b>e-Coucou</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Ae-coucou" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/thatguyseven"><img alt="Aaron Ni" src="https://avatars.githubusercontent.com/u/137221692?v=4?s=120" width="120px;" /><br /><sub><b>Aaron Ni</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=thatguyseven" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/OnexiMedina"><img alt="Onexi" src="https://avatars.githubusercontent.com/u/112675769?v=4?s=120" width="120px;" /><br /><sub><b>Onexi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=OnexiMedina" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.vijithassar.com"><img alt="Vijith Assar" src="https://avatars.githubusercontent.com/u/3488572?v=4?s=120" width="120px;" /><br /><sub><b>Vijith Assar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=vijithassar" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=vijithassar" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://processingfoundation.org/"><img alt="Dorothy R. Santos" src="https://avatars.githubusercontent.com/u/66838497?v=4?s=120" width="120px;" /><br /><sub><b>Dorothy R. Santos</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=drsantos8791" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-drsantos8791" title="Event Organizing">📋</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#fundingFinding-drsantos8791" title="Funding Finding">🔍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-drsantos8791" title="Talks">📢</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tonipizza"><img alt="tonipizza" src="https://avatars.githubusercontent.com/u/3420966?v=4?s=120" width="120px;" /><br /><sub><b>tonipizza</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#fundingFinding-tonipizza" title="Funding Finding">🔍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#financial-tonipizza" title="Financial">💵</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.annacarreras.com"><img alt="Anna Carreras" src="https://avatars.githubusercontent.com/u/2182422?v=4?s=120" width="120px;" /><br /><sub><b>Anna Carreras</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-acarreras" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-acarreras" title="Talks">📢</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://cenkhor.org"><img alt="takawo" src="https://avatars.githubusercontent.com/u/39242?v=4?s=120" width="120px;" /><br /><sub><b>takawo</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-takawo" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-takawo" title="Event Organizing">📋</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#blog-takawo" title="Blogposts">📝</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/13sfaith"><img alt="Spencer Faith" src="https://avatars.githubusercontent.com/u/45831293?v=4?s=120" width="120px;" /><br /><sub><b>Spencer Faith</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=13sfaith" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/a-y-u-s-h"><img alt="Ayush Sharma" src="https://avatars.githubusercontent.com/u/19586719?v=4?s=120" width="120px;" /><br /><sub><b>Ayush Sharma</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=a-y-u-s-h" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/aaronccasanova"><img alt="Aaron Casanova" src="https://avatars.githubusercontent.com/u/32409546?v=4?s=120" width="120px;" /><br /><sub><b>Aaron Casanova</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aaronccasanova" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/acasmith"><img alt="Adam Smith" src="https://avatars.githubusercontent.com/u/30869791?v=4?s=120" width="120px;" /><br /><sub><b>Adam Smith</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=acasmith" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Acha0203"><img alt="Acha" src="https://avatars.githubusercontent.com/u/74553433?v=4?s=120" width="120px;" /><br /><sub><b>Acha</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Acha0203" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/aditya-siddheshwar"><img alt="Aditya Siddheshwar" src="https://avatars.githubusercontent.com/u/46048299?v=4?s=120" width="120px;" /><br /><sub><b>Aditya Siddheshwar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aditya-siddheshwar" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/adwaith007"><img alt="Adwaith D" src="https://avatars.githubusercontent.com/u/37845277?v=4?s=120" width="120px;" /><br /><sub><b>Adwaith D</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=adwaith007" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/aemonm"><img alt="æmon" src="https://avatars.githubusercontent.com/u/1058915?v=4?s=120" width="120px;" /><br /><sub><b>æmon</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aemonm" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Ajayneethikannan"><img alt="ajayTDM" src="https://avatars.githubusercontent.com/u/35770004?v=4?s=120" width="120px;" /><br /><sub><b>ajayTDM</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Ajayneethikannan" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://akashgutha.github.io/"><img alt="Akash" src="https://avatars.githubusercontent.com/u/10159531?v=4?s=120" width="120px;" /><br /><sub><b>Akash</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AkashGutha" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AliLordLoss"><img alt="AliLordLoss" src="https://avatars.githubusercontent.com/u/45513491?v=4?s=120" width="120px;" /><br /><sub><b>AliLordLoss</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AliLordLoss" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://amethyst.codes/"><img alt="Lauren" src="https://avatars.githubusercontent.com/u/16910219?v=4?s=120" width="120px;" /><br /><sub><b>Lauren</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Amethystix" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/anagondesign"><img alt="anagondesign" src="https://avatars.githubusercontent.com/u/83731139?v=4?s=120" width="120px;" /><br /><sub><b>anagondesign</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=anagondesign" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AndrasGardos"><img alt="András Gárdos" src="https://avatars.githubusercontent.com/u/53218984?v=4?s=120" width="120px;" /><br /><sub><b>András Gárdos</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AndrasGardos" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AndrasGG"><img alt="AndrasGG" src="https://avatars.githubusercontent.com/u/36957076?v=4?s=120" width="120px;" /><br /><sub><b>AndrasGG</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AndrasGG" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Aqmalp99"><img alt="Aqmalp99" src="https://avatars.githubusercontent.com/u/64822387?v=4?s=120" width="120px;" /><br /><sub><b>Aqmalp99</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Aqmalp99" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://arbaaz.io/"><img alt="Arbaaz" src="https://avatars.githubusercontent.com/u/5406232?v=4?s=120" width="120px;" /><br /><sub><b>Arbaaz</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=arbaaz" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/arihantparsoya"><img alt="Arihant Parsoya" src="https://avatars.githubusercontent.com/u/15258498?v=4?s=120" width="120px;" /><br /><sub><b>Arihant Parsoya</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=arihantparsoya" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ArshM17"><img alt="ArshM17" src="https://avatars.githubusercontent.com/u/107296445?v=4?s=120" width="120px;" /><br /><sub><b>ArshM17</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ArshM17" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://asukaminato.eu.org/"><img alt="AsukaMinato" src="https://avatars.githubusercontent.com/u/30024051?v=4?s=120" width="120px;" /><br /><sub><b>AsukaMinato</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=asukaminato0721" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://jareddonovan.com/"><img alt="Jared Donovan" src="https://avatars.githubusercontent.com/u/92529?v=4?s=120" width="120px;" /><br /><sub><b>Jared Donovan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=awarua" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/beau-muylle"><img alt="beau-muylle" src="https://avatars.githubusercontent.com/u/95020280?v=4?s=120" width="120px;" /><br /><sub><b>beau-muylle</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=beau-muylle" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://bekicot.github.io/"><img alt="Yana Agun Siswanto" src="https://avatars.githubusercontent.com/u/1826884?v=4?s=120" width="120px;" /><br /><sub><b>Yana Agun Siswanto</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=bekicot" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Benjamin-Davies"><img alt="Benjamin Davies" src="https://avatars.githubusercontent.com/u/25046874?v=4?s=120" width="120px;" /><br /><sub><b>Benjamin Davies</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Benjamin-Davies" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/BerfinA"><img alt="BerfinA" src="https://avatars.githubusercontent.com/u/50386960?v=4?s=120" width="120px;" /><br /><sub><b>BerfinA</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=BerfinA" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Bernice55231"><img alt="Bernice Wu" src="https://avatars.githubusercontent.com/u/78245731?v=4?s=120" width="120px;" /><br /><sub><b>Bernice Wu</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Bernice55231" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://subculturecreations.com/"><img alt="Ben Scheiner" src="https://avatars.githubusercontent.com/u/9775178?v=4?s=120" width="120px;" /><br /><sub><b>Ben Scheiner</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=brmscheiner" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.bryanleister.com/"><img alt="Bryan" src="https://avatars.githubusercontent.com/u/3446093?v=4?s=120" width="120px;" /><br /><sub><b>Bryan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=bryanrtboy" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://bulkan-evcimen.com/"><img alt="Bulkan Evcimen" src="https://avatars.githubusercontent.com/u/13985?v=4?s=120" width="120px;" /><br /><sub><b>Bulkan Evcimen</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=bulkan" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://notes.variogram.com/"><img alt="Brian Whitman" src="https://avatars.githubusercontent.com/u/76612?v=4?s=120" width="120px;" /><br /><sub><b>Brian Whitman</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=bwhitman" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/cacoollib"><img alt="cacoollib" src="https://avatars.githubusercontent.com/u/53848442?v=4?s=120" width="120px;" /><br /><sub><b>cacoollib</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=cacoollib" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://caitelatte.com/"><img alt="Caitlin" src="https://avatars.githubusercontent.com/u/4994062?v=4?s=120" width="120px;" /><br /><sub><b>Caitlin</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=caitelatte" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/calebegg"><img alt="Caleb Eggensperger" src="https://avatars.githubusercontent.com/u/782920?v=4?s=120" width="120px;" /><br /><sub><b>Caleb Eggensperger</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=calebegg" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/cdfuller"><img alt="Cody Fuller" src="https://avatars.githubusercontent.com/u/2310581?v=4?s=120" width="120px;" /><br /><sub><b>Cody Fuller</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=cdfuller" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ChrisJohnRyan"><img alt="Christopher John Ryan" src="https://avatars.githubusercontent.com/u/8646106?v=4?s=120" width="120px;" /><br /><sub><b>Christopher John Ryan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ChrisJohnRyan" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/constanceyu"><img alt="Constance Yu" src="https://avatars.githubusercontent.com/u/19146133?v=4?s=120" width="120px;" /><br /><sub><b>Constance Yu</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=constanceyu" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://cosme.dev/"><img alt="Cosme Escobedo" src="https://avatars.githubusercontent.com/u/24755643?v=4?s=120" width="120px;" /><br /><sub><b>Cosme Escobedo</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=cosmeoes" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://cotsog.wordpress.com/"><img alt="Dominic Jodoin" src="https://avatars.githubusercontent.com/u/149366?v=4?s=120" width="120px;" /><br /><sub><b>Dominic Jodoin</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=cotsog" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dabe"><img alt="Dabe Andre Enajada" src="https://avatars.githubusercontent.com/u/32162370?v=4?s=120" width="120px;" /><br /><sub><b>Dabe Andre Enajada</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dabe" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/danarmulder"><img alt="Dana Mulder" src="https://avatars.githubusercontent.com/u/9340817?v=4?s=120" width="120px;" /><br /><sub><b>Dana Mulder</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=danarmulder" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/demc"><img alt="Derrick McMillen" src="https://avatars.githubusercontent.com/u/3744617?v=4?s=120" width="120px;" /><br /><sub><b>Derrick McMillen</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=demc" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dhoizner"><img alt="Dan Hoizner" src="https://avatars.githubusercontent.com/u/419620?v=4?s=120" width="120px;" /><br /><sub><b>Dan Hoizner</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dhoizner" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://twitter.com/digitalfrost"><img alt="digitalfrost" src="https://avatars.githubusercontent.com/u/286763?v=4?s=120" width="120px;" /><br /><sub><b>digitalfrost</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=digitalfrost" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://thomasdiewald.com/"><img alt="Thomas Diewald" src="https://avatars.githubusercontent.com/u/743399?v=4?s=120" width="120px;" /><br /><sub><b>Thomas Diewald</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=diwi" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dummyAccount22"><img alt="dummyAccount22" src="https://avatars.githubusercontent.com/u/115959622?v=4?s=120" width="120px;" /><br /><sub><b>dummyAccount22</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dummyAccount22" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://duskvirkus.com/links"><img alt="Dusk" src="https://avatars.githubusercontent.com/u/43045568?v=4?s=120" width="120px;" /><br /><sub><b>Dusk</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=duskvirkus" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://edbrannin.com/"><img alt="Ed Brannin" src="https://avatars.githubusercontent.com/u/121909?v=4?s=120" width="120px;" /><br /><sub><b>Ed Brannin</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=edbrannin" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/drewanjohnstone/"><img alt="Ewan Johnstone" src="https://avatars.githubusercontent.com/u/30697825?v=4?s=120" width="120px;" /><br /><sub><b>Ewan Johnstone</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=eJohnstonePhd1991" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/emclaren"><img alt="elgin mclaren" src="https://avatars.githubusercontent.com/u/6835324?v=4?s=120" width="120px;" /><br /><sub><b>elgin mclaren</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=emclaren" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/epramer-godaddy"><img alt="epramer-godaddy" src="https://avatars.githubusercontent.com/u/63809970?v=4?s=120" width="120px;" /><br /><sub><b>epramer-godaddy</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=epramer-godaddy" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://bob.ippoli.to/"><img alt="Bob Ippolito" src="https://avatars.githubusercontent.com/u/26596?v=4?s=120" width="120px;" /><br /><sub><b>Bob Ippolito</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=etrepum" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.fal-works.com/"><img alt="FAL" src="https://avatars.githubusercontent.com/u/33595446?v=4?s=120" width="120px;" /><br /><sub><b>FAL</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=fal-works" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://rwell.org/"><img alt="Corey Farwell" src="https://avatars.githubusercontent.com/u/416575?v=4?s=120" width="120px;" /><br /><sub><b>Corey Farwell</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=frewsxcv" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://rathoresaab.wordpress.com/"><img alt="Shubham Rathore" src="https://avatars.githubusercontent.com/u/9786291?v=4?s=120" width="120px;" /><br /><sub><b>Shubham Rathore</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=GABBAR1947" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/glneto"><img alt="Geraldo Neto" src="https://avatars.githubusercontent.com/u/7269097?v=4?s=120" width="120px;" /><br /><sub><b>Geraldo Neto</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=glneto" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://dev.to/gr2m"><img alt="Gregor Martynus" src="https://avatars.githubusercontent.com/u/39992?v=4?s=120" width="120px;" /><br /><sub><b>Gregor Martynus</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=gr2m" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Gracia-zhang"><img alt="Gracia-zhang" src="https://avatars.githubusercontent.com/u/70793865?v=4?s=120" width="120px;" /><br /><sub><b>Gracia-zhang</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Gracia-zhang" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hellonearthis"><img alt="Brett Cooper" src="https://avatars.githubusercontent.com/u/121805?v=4?s=120" width="120px;" /><br /><sub><b>Brett Cooper</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=hellonearthis" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/hscdl"><img alt="Half Scheidl" src="https://avatars.githubusercontent.com/u/46812590?v=4?s=120" width="120px;" /><br /><sub><b>Half Scheidl</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=hscdl" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://iashris.com/"><img alt="Ashris" src="https://avatars.githubusercontent.com/u/7142235?v=4?s=120" width="120px;" /><br /><sub><b>Ashris</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=iashris" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/idontknowjs"><img alt="Arijit" src="https://avatars.githubusercontent.com/u/53327173?v=4?s=120" width="120px;" /><br /><sub><b>Arijit</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=idontknowjs" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ihsavru"><img alt="Urvashi" src="https://avatars.githubusercontent.com/u/22816171?v=4?s=120" width="120px;" /><br /><sub><b>Urvashi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ihsavru" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://jtajuelo.com/"><img alt="José Miguel Tajuelo Garrigós" src="https://avatars.githubusercontent.com/u/11405820?v=4?s=120" width="120px;" /><br /><sub><b>José Miguel Tajuelo Garrigós</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=J-888" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/jai-kotia/"><img alt="Jai Kotia" src="https://avatars.githubusercontent.com/u/32239054?v=4?s=120" width="120px;" /><br /><sub><b>Jai Kotia</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JaiKotia" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jatin33"><img alt="Jatin Panjwani" src="https://avatars.githubusercontent.com/u/13780467?v=4?s=120" width="120px;" /><br /><sub><b>Jatin Panjwani</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jatin33" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jeong"><img alt="jeong" src="https://avatars.githubusercontent.com/u/749767?v=4?s=120" width="120px;" /><br /><sub><b>jeong</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jeong" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jesi-rgb"><img alt="Jesús Enrique Rascón" src="https://avatars.githubusercontent.com/u/50735312?v=4?s=120" width="120px;" /><br /><sub><b>Jesús Enrique Rascón</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jesi-rgb" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jhongover9000"><img alt="Joseph Hong" src="https://avatars.githubusercontent.com/u/57396665?v=4?s=120" width="120px;" /><br /><sub><b>Joseph Hong</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jhongover9000" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://jithinks.netlify.app/"><img alt="Jithin KS" src="https://avatars.githubusercontent.com/u/19987520?v=4?s=120" width="120px;" /><br /><sub><b>Jithin KS</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JithinKS97" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jmandel1027"><img alt="Jason Mandel" src="https://avatars.githubusercontent.com/u/13109165?v=4?s=120" width="120px;" /><br /><sub><b>Jason Mandel</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jmandel1027" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/JoeCastor"><img alt="JoeCastor" src="https://avatars.githubusercontent.com/u/79670830?v=4?s=120" width="120px;" /><br /><sub><b>JoeCastor</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JoeCastor" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://prototyping.barcelona/"><img alt="Juan Irache" src="https://avatars.githubusercontent.com/u/5341183?v=4?s=120" width="120px;" /><br /><sub><b>Juan Irache</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JuanIrache" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://junagao.com/"><img alt="juliane nagao" src="https://avatars.githubusercontent.com/u/615616?v=4?s=120" width="120px;" /><br /><sub><b>juliane nagao</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=junagao" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://junshern.github.io/"><img alt="Chan Jun Shern" src="https://avatars.githubusercontent.com/u/7796965?v=4?s=120" width="120px;" /><br /><sub><b>Chan Jun Shern</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JunShern" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://ashleykang.dev/"><img alt="Ashley Kang" src="https://avatars.githubusercontent.com/u/12789512?v=4?s=120" width="120px;" /><br /><sub><b>Ashley Kang</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=kangashley" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/kant"><img alt="Darío Hereñú" src="https://avatars.githubusercontent.com/u/32717?v=4?s=120" width="120px;" /><br /><sub><b>Darío Hereñú</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=kant" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/LadySith"><img alt="Sithe Ncube" src="https://avatars.githubusercontent.com/u/9806760?v=4?s=120" width="120px;" /><br /><sub><b>Sithe Ncube</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=LadySith" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/LakshSingla"><img alt="Laksh Singla" src="https://avatars.githubusercontent.com/u/30999375?v=4?s=120" width="120px;" /><br /><sub><b>Laksh Singla</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=LakshSingla" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/leslieyip02"><img alt="Leslie Yip" src="https://avatars.githubusercontent.com/u/90888680?v=4?s=120" width="120px;" /><br /><sub><b>Leslie Yip</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=leslieyip02" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/linnhallonqvist"><img alt="linnhallonqvist" src="https://avatars.githubusercontent.com/u/24587690?v=4?s=120" width="120px;" /><br /><sub><b>linnhallonqvist</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=linnhallonqvist" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.frederikring.com/"><img alt="Frederik Ring" src="https://avatars.githubusercontent.com/u/1662740?v=4?s=120" width="120px;" /><br /><sub><b>Frederik Ring</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=m90" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/maddyfisher"><img alt="maddyfisher" src="https://avatars.githubusercontent.com/u/50155810?v=4?s=120" width="120px;" /><br /><sub><b>maddyfisher</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=maddyfisher" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Maikuolan/"><img alt="Caleb Mazalevskis" src="https://avatars.githubusercontent.com/u/12571108?v=4?s=120" width="120px;" /><br /><sub><b>Caleb Mazalevskis</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Maikuolan" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/manpreeeeeet"><img alt="manpreet" src="https://avatars.githubusercontent.com/u/93985396?v=4?s=120" width="120px;" /><br /><sub><b>manpreet</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=manpreeeeeet" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://bento.me/meodai"><img alt="David Aerne" src="https://avatars.githubusercontent.com/u/608386?v=4?s=120" width="120px;" /><br /><sub><b>David Aerne</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=meodai" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://naotohieda.com/"><img alt="Naoto Hieda" src="https://avatars.githubusercontent.com/u/1835081?v=4?s=120" width="120px;" /><br /><sub><b>Naoto Hieda</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=micuat" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/min-kim42"><img alt="min-kim42" src="https://avatars.githubusercontent.com/u/13192500?v=4?s=120" width="120px;" /><br /><sub><b>min-kim42</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=min-kim42" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/minortext"><img alt="M" src="https://avatars.githubusercontent.com/u/62758084?v=4?s=120" width="120px;" /><br /><sub><b>M</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=minortext" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/N4M3L355"><img alt="Adam Král" src="https://avatars.githubusercontent.com/u/16424778?v=4?s=120" width="120px;" /><br /><sub><b>Adam Král</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=N4M3L355" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nebbles"><img alt="Ben Greenberg" src="https://avatars.githubusercontent.com/u/12599555?v=4?s=120" width="120px;" /><br /><sub><b>Ben Greenberg</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nebbles" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Neilblaze"><img alt="Pratyay Banerjee" src="https://avatars.githubusercontent.com/u/48355572?v=4?s=120" width="120px;" /><br /><sub><b>Pratyay Banerjee</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Neilblaze" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nikhilhvr"><img alt="Nikhil" src="https://avatars.githubusercontent.com/u/97503662?v=4?s=120" width="120px;" /><br /><sub><b>Nikhil</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nikhilhvr" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.behance.net/nikiartito2d54"><img alt="Niki Ito" src="https://avatars.githubusercontent.com/u/85363556?v=4?s=120" width="120px;" /><br /><sub><b>Niki Ito</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=niki-ito" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://nikolas.us.to/"><img alt="Nik Nyby" src="https://avatars.githubusercontent.com/u/59292?v=4?s=120" width="120px;" /><br /><sub><b>Nik Nyby</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nikolas" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nully0x"><img alt="nully0x" src="https://avatars.githubusercontent.com/u/40327060?v=4?s=120" width="120px;" /><br /><sub><b>nully0x</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=nully0x" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://whatoscarhasmade.com/blog/mise"><img alt="odm275" src="https://avatars.githubusercontent.com/u/20306697?v=4?s=120" width="120px;" /><br /><sub><b>odm275</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=odm275" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/OleksiiBulba"><img alt="Oleksii Bulba" src="https://avatars.githubusercontent.com/u/41155673?v=4?s=120" width="120px;" /><br /><sub><b>Oleksii Bulba</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=OleksiiBulba" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/paollabd"><img alt="paollabd" src="https://avatars.githubusercontent.com/u/31938051?v=4?s=120" width="120px;" /><br /><sub><b>paollabd</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=paollabd" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://prateek93a.medium.com/"><img alt="Prateek Jain" src="https://avatars.githubusercontent.com/u/44807945?v=4?s=120" width="120px;" /><br /><sub><b>Prateek Jain</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Prateek93a" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/quinox"><img alt="Ceesjan Luiten" src="https://avatars.githubusercontent.com/u/739770?v=4?s=120" width="120px;" /><br /><sub><b>Ceesjan Luiten</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=quinox" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://niinomi.art/"><img alt="NIINOMI" src="https://avatars.githubusercontent.com/u/3589344?v=4?s=120" width="120px;" /><br /><sub><b>NIINOMI</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=r21nomi" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://benwendt.ca/"><img alt="Ben Wendt" src="https://avatars.githubusercontent.com/u/11400743?v=4?s=120" width="120px;" /><br /><sub><b>Ben Wendt</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=rbwendt" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/reijovosu"><img alt="Reijo Vosu" src="https://avatars.githubusercontent.com/u/378124?v=4?s=120" width="120px;" /><br /><sub><b>Reijo Vosu</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=reijovosu" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/risingBirdSong"><img alt="peter" src="https://avatars.githubusercontent.com/u/52929863?v=4?s=120" width="120px;" /><br /><sub><b>peter</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=risingBirdSong" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://sachinvarghese.github.io/"><img alt="Sachin Varghese" src="https://avatars.githubusercontent.com/u/24502613?v=4?s=120" width="120px;" /><br /><sub><b>Sachin Varghese</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=SachinVarghese" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://art.sarahghp.com/"><img alt="Sarah Groff Hennigh-Palermo" src="https://avatars.githubusercontent.com/u/1477362?v=4?s=120" width="120px;" /><br /><sub><b>Sarah Groff Hennigh-Palermo</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sarahghp" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/seagalputra"><img alt="Dwiferdio Seagal Putra" src="https://avatars.githubusercontent.com/u/15377132?v=4?s=120" width="120px;" /><br /><sub><b>Dwiferdio Seagal Putra</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=seagalputra" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shakeabi"><img alt="Abishake" src="https://avatars.githubusercontent.com/u/36559835?v=4?s=120" width="120px;" /><br /><sub><b>Abishake</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=shakeabi" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sheamus.dev/"><img alt="sheamus" src="https://avatars.githubusercontent.com/u/8462408?v=4?s=120" width="120px;" /><br /><sub><b>sheamus</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sheamusburns" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shinytang6"><img alt="Liang Tang" src="https://avatars.githubusercontent.com/u/22241503?v=4?s=120" width="120px;" /><br /><sub><b>Liang Tang</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=shinytang6" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Siphonophora"><img alt="Michael J Conrad" src="https://avatars.githubusercontent.com/u/32316111?v=4?s=120" width="120px;" /><br /><sub><b>Michael J Conrad</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Siphonophora" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/smrghsh"><img alt="Samir Ghosh" src="https://avatars.githubusercontent.com/u/22751315?v=4?s=120" width="120px;" /><br /><sub><b>Samir Ghosh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=smrghsh" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/stalgiag"><img alt="Stalgia Grigg" src="https://avatars.githubusercontent.com/u/10382506?v=4?s=120" width="120px;" /><br /><sub><b>Stalgia Grigg</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=stalgiag" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://steftervel.de/"><img alt="Stef Tervelde" src="https://avatars.githubusercontent.com/u/4988953?v=4?s=120" width="120px;" /><br /><sub><b>Stef Tervelde</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Stefterv" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/stormCup"><img alt="stormCup" src="https://avatars.githubusercontent.com/u/52805485?v=4?s=120" width="120px;" /><br /><sub><b>stormCup</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=stormCup" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.cliffsu.me/"><img alt="Cliff Su" src="https://avatars.githubusercontent.com/u/22230889?v=4?s=120" width="120px;" /><br /><sub><b>Cliff Su</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=stu01509" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sz245"><img alt="sz245" src="https://avatars.githubusercontent.com/u/25470283?v=4?s=120" width="120px;" /><br /><sub><b>sz245</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sz245" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tau-"><img alt="Alex Troesch" src="https://avatars.githubusercontent.com/u/1418502?v=4?s=120" width="120px;" /><br /><sub><b>Alex Troesch</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=tau-" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/tawez"><img alt="Maciej Stankiewicz" src="https://avatars.githubusercontent.com/u/177306?v=4?s=120" width="120px;" /><br /><sub><b>Maciej Stankiewicz</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=tawez" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://tito21.github.io/"><img alt="Alberto Di Biase" src="https://avatars.githubusercontent.com/u/1232343?v=4?s=120" width="120px;" /><br /><sub><b>Alberto Di Biase</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=tito21" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/vedhant"><img alt="Vedhant Agarwal" src="https://avatars.githubusercontent.com/u/32607479?v=4?s=120" width="120px;" /><br /><sub><b>Vedhant Agarwal</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=vedhant" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://verma-varsha.github.io/"><img alt="Varsha Verma" src="https://avatars.githubusercontent.com/u/20443665?v=4?s=120" width="120px;" /><br /><sub><b>Varsha Verma</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=verma-varsha" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/vipulrawat"><img alt="vipulrawat" src="https://avatars.githubusercontent.com/u/26515826?v=4?s=120" width="120px;" /><br /><sub><b>vipulrawat</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=vipulrawat" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/with-a-k"><img alt="Erik Butcher" src="https://avatars.githubusercontent.com/u/6319591?v=4?s=120" width="120px;" /><br /><sub><b>Erik Butcher</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=with-a-k" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/wmmnola"><img alt="Wade Marshall" src="https://avatars.githubusercontent.com/u/13511578?v=4?s=120" width="120px;" /><br /><sub><b>Wade Marshall</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=wmmnola" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.orangutan.or.id/"><img alt="XTY" src="https://avatars.githubusercontent.com/u/11317451?v=4?s=120" width="120px;" /><br /><sub><b>XTY</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=xty" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.xujenna.com/"><img alt="Jenna" src="https://avatars.githubusercontent.com/u/13280722?v=4?s=120" width="120px;" /><br /><sub><b>Jenna</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=xujenna" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/yifanmai"><img alt="Yifan Mai" src="https://avatars.githubusercontent.com/u/185227?v=4?s=120" width="120px;" /><br /><sub><b>Yifan Mai</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=yifanmai" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://yinhwa.art/"><img alt="Inhwa" src="https://avatars.githubusercontent.com/u/51147158?v=4?s=120" width="120px;" /><br /><sub><b>Inhwa</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=yinhwa" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ykabusalah"><img alt="Yousef Abu-Salah" src="https://avatars.githubusercontent.com/u/42948521?v=4?s=120" width="120px;" /><br /><sub><b>Yousef Abu-Salah</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ykabusalah" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://harvestplugins.com/"><img alt="Zoe Stenger" src="https://avatars.githubusercontent.com/u/7537243?v=4?s=120" width="120px;" /><br /><sub><b>Zoe Stenger</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=zoalst" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mcturner1995"><img alt="mcturner1995" src="https://avatars.githubusercontent.com/u/36084197?v=4?s=120" width="120px;" /><br /><sub><b>mcturner1995</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mcturner1995" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/okdalto"><img alt="Seonghyeon Kim" src="https://avatars.githubusercontent.com/u/22714667?v=4?s=120" width="120px;" /><br /><sub><b>Seonghyeon Kim</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=okdalto" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-okdalto" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/cgusb"><img alt="Gus Becker" src="https://avatars.githubusercontent.com/u/60982210?v=4?s=120" width="120px;" /><br /><sub><b>Gus Becker</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#maintenance-cgusb" title="Maintenance">🚧</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-cgusb" title="Ideas, Planning, &amp; Feedback">🤔</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#question-cgusb" title="Answering Questions">💬</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://holoshow.senbaku.info/"><img alt="senbaku" src="https://avatars.githubusercontent.com/u/10251300?v=4?s=120" width="120px;" /><br /><sub><b>senbaku</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-senbaku" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#blog-senbaku" title="Blogposts">📝</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-senbaku" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-senbaku" title="Tutorials">✅</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://reona396.com/"><img alt="reona396" src="https://avatars.githubusercontent.com/u/10163980?v=4?s=120" width="120px;" /><br /><sub><b>reona396</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-reona396" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-reona396" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://maveme.github.com/"><img alt="Mauricio Verano Merino" src="https://avatars.githubusercontent.com/u/3525794?v=4?s=120" width="120px;" /><br /><sub><b>Mauricio Verano Merino</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-maveme" title="Event Organizing">📋</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#research-maveme" title="Research">🔬</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#mentoring-maveme" title="Mentoring">🧑‍🏫</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/RandomGamingDev"><img alt="RandomGamingDev" src="https://avatars.githubusercontent.com/u/83996185?v=4?s=120" width="120px;" /><br /><sub><b>RandomGamingDev</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=RandomGamingDev" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3ARandomGamingDev" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://cheyuwu.com/"><img alt="Wu Che Yu" src="https://avatars.githubusercontent.com/u/4727572?v=4?s=120" width="120px;" /><br /><sub><b>Wu Che Yu</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-frank890417" title="Event Organizing">📋</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#blog-frank890417" title="Blogposts">📝</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-frank890417" title="Tutorials">✅</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#video-frank890417" title="Videos">📹</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sarahciston.com"><img alt="Sarah Ciston" src="https://avatars.githubusercontent.com/u/31395144?v=4?s=120" width="120px;" /><br /><sub><b>Sarah Ciston</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#mentoring-sarahciston" title="Mentoring">🧑‍🏫</a> <a href="https://github.com/processing/p5.js/commits?author=sarahciston" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-sarahciston" title="Event Organizing">📋</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://tiagohermano.dev"><img alt="Tiago Hermano" src="https://avatars.githubusercontent.com/u/5157960?v=4?s=120" width="120px;" /><br /><sub><b>Tiago Hermano</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-tiagohermano" title="Translation">🌍</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3Atiagohermano" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://unicar9.github.io/weijia/"><img alt="Unicar" src="https://avatars.githubusercontent.com/u/27838326?v=4?s=120" width="120px;" /><br /><sub><b>Unicar</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-unicar9" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-unicar9" title="Tutorials">✅</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-unicar9" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/yulicai"><img alt="Yolonanido" src="https://avatars.githubusercontent.com/u/14118438?v=4?s=120" width="120px;" /><br /><sub><b>Yolonanido</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-yulicai" title="Event Organizing">📋</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/SableRaf"><img alt="Raphaël de Courville" src="https://avatars.githubusercontent.com/u/290261?v=4?s=120" width="120px;" /><br /><sub><b>Raphaël de Courville</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-SableRaf" title="Event Organizing">📋</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#video-SableRaf" title="Videos">📹</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-SableRaf" title="Ideas, Planning, &amp; Feedback">🤔</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#promotion-SableRaf" title="Promotion">📣</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mykongee"><img alt="Mike " src="https://avatars.githubusercontent.com/u/10676303?v=4?s=120" width="120px;" /><br /><sub><b>Mike </b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mykongee" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Amykongee" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://my-portfolio-ankush263.vercel.app/"><img alt="Ankush Banik" src="https://avatars.githubusercontent.com/u/86042508?v=4?s=120" width="120px;" /><br /><sub><b>Ankush Banik</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AAnkush263" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=Ankush263" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-Ankush263" title="Talks">📢</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#question-Ankush263" title="Answering Questions">💬</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://qiita.com/tetunori_lego"><img alt="tetunori" src="https://avatars.githubusercontent.com/u/14086390?v=4?s=120" width="120px;" /><br /><sub><b>tetunori</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#blog-tetunori" title="Blogposts">📝</a> <a href="https://github.com/processing/p5.js/commits?author=tetunori" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-tetunori" title="Examples">💡</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-tetunori" title="Tools">🔧</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/KeyboardSounds"><img alt="Emma Krantz" src="https://avatars.githubusercontent.com/u/3796838?v=4?s=120" width="120px;" /><br /><sub><b>Emma Krantz</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AKeyboardSounds" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=KeyboardSounds" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://zactolle.notion.site"><img alt="Zac Tolle" src="https://avatars.githubusercontent.com/u/139601580?v=4?s=120" width="120px;" /><br /><sub><b>Zac Tolle</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#a11y-ZacTolle" title="Accessibility">️️️️♿️</a> <a href="https://github.com/processing/p5.js/commits?author=ZacTolle" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#tool-ZacTolle" title="Tools">🔧</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-ZacTolle" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/capGoblin"><img alt="Dharshan" src="https://avatars.githubusercontent.com/u/78524377?v=4?s=120" width="120px;" /><br /><sub><b>Dharshan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=capGoblin" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/skbhagat0502"><img alt="Sandeep Kumar Bhagat" src="https://avatars.githubusercontent.com/u/109683163?v=4?s=120" width="120px;" /><br /><sub><b>Sandeep Kumar Bhagat</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-skbhagat0502" title="Design">🎨</a> <a href="https://github.com/processing/p5.js/commits?author=skbhagat0502" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://gaurav-personal-portfolio.netlify.app/"><img alt="Gaurav Tiwary" src="https://avatars.githubusercontent.com/u/97665755?v=4?s=120" width="120px;" /><br /><sub><b>Gaurav Tiwary</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Gaurav-1306" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Garima3110"><img alt="Garima" src="https://avatars.githubusercontent.com/u/110815240?v=4?s=120" width="120px;" /><br /><sub><b>Garima</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Garima3110" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/lakshay451"><img alt="Lakshay Joshi" src="https://avatars.githubusercontent.com/u/89472581?v=4?s=120" width="120px;" /><br /><sub><b>Lakshay Joshi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=lakshay451" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/perminder-17"><img alt="perminder-17" src="https://avatars.githubusercontent.com/u/127239756?v=4?s=120" width="120px;" /><br /><sub><b>perminder-17</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=perminder-17" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://yash-portfolio-bice.vercel.app/"><img alt="Yash Pandey" src="https://avatars.githubusercontent.com/u/97700473?v=4?s=120" width="120px;" /><br /><sub><b>Yash Pandey</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Ayashpandey06" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=yashpandey06" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/adityadeshpande09"><img alt="Aditya Deshpande" src="https://avatars.githubusercontent.com/u/98452243?v=4?s=120" width="120px;" /><br /><sub><b>Aditya Deshpande</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aadityadeshpande09" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=adityadeshpande09" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://art.arqtistic.com"><img alt="Alejandro" src="https://avatars.githubusercontent.com/u/121937906?v=4?s=120" width="120px;" /><br /><sub><b>Alejandro</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aacamposuribe" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=acamposuribe" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/diyaayay"><img alt="Diya Solanki" src="https://avatars.githubusercontent.com/u/110971977?v=4?s=120" width="120px;" /><br /><sub><b>Diya Solanki</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=diyaayay" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mhsh312"><img alt="mhsh312" src="https://avatars.githubusercontent.com/u/135870090?v=4?s=120" width="120px;" /><br /><sub><b>mhsh312</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mhsh312" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Amhsh312" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/wackbyte"><img alt="wackbyte" src="https://avatars.githubusercontent.com/u/29505620?v=4?s=120" width="120px;" /><br /><sub><b>wackbyte</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=wackbyte" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/apsinghdev"><img alt="Ajeet Pratap Singh" src="https://avatars.githubusercontent.com/u/109718740?v=4?s=120" width="120px;" /><br /><sub><b>Ajeet Pratap Singh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=apsinghdev" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aapsinghdev" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Jaivignesh-afk"><img alt="Jai Vignesh J" src="https://avatars.githubusercontent.com/u/108923524?v=4?s=120" width="120px;" /><br /><sub><b>Jai Vignesh J</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Jaivignesh-afk" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://kyabe.net"><img alt="cab_kyabe" src="https://avatars.githubusercontent.com/u/7237868?v=4?s=120" width="120px;" /><br /><sub><b>cab_kyabe</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Acabbage63" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=cabbage63" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/vishwassrivastava"><img alt="Vishwas Srivastava" src="https://avatars.githubusercontent.com/u/84739867?v=4?s=120" width="120px;" /><br /><sub><b>Vishwas Srivastava</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=vishwassrivastava" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/suhani6904"><img alt="suhani6904" src="https://avatars.githubusercontent.com/u/113185177?v=4?s=120" width="120px;" /><br /><sub><b>suhani6904</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-suhani6904" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dexterco"><img alt="Nabeel (Dexter)" src="https://avatars.githubusercontent.com/u/63152089?v=4?s=120" width="120px;" /><br /><sub><b>Nabeel (Dexter)</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dexterco" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/umangutkarsh"><img alt="Umang Utkarsh" src="https://avatars.githubusercontent.com/u/95426993?v=4?s=120" width="120px;" /><br /><sub><b>Umang Utkarsh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=umangutkarsh" title="Documentation">📖</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-umangutkarsh" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/aditya123473892"><img alt="aditya123473892" src="https://avatars.githubusercontent.com/u/117269123?v=4?s=120" width="120px;" /><br /><sub><b>aditya123473892</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aditya123473892" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aaditya123473892" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=aditya123473892" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/haarsh157"><img alt="Harsh Range" src="https://avatars.githubusercontent.com/u/115213858?v=4?s=120" width="120px;" /><br /><sub><b>Harsh Range</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=haarsh157" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Ahaarsh157" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sudhanshuv1"><img alt="Sudhanshu Tiwari" src="https://avatars.githubusercontent.com/u/148856416?v=4?s=120" width="120px;" /><br /><sub><b>Sudhanshu Tiwari</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sudhanshuv1" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mohamedalisaifudeen"><img alt="mohamedalisaifudeen" src="https://avatars.githubusercontent.com/u/107266503?v=4?s=120" width="120px;" /><br /><sub><b>mohamedalisaifudeen</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Amohamedalisaifudeen" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/aryanas159"><img alt="Aryan Singh" src="https://avatars.githubusercontent.com/u/114330931?v=4?s=120" width="120px;" /><br /><sub><b>Aryan Singh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aryanas159" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/nikhilkalburgi"><img alt="nikhilkalburgi" src="https://avatars.githubusercontent.com/u/70331875?v=4?s=120" width="120px;" /><br /><sub><b>nikhilkalburgi</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Anikhilkalburgi" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=nikhilkalburgi" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/samrudh3125"><img alt="Samrudh Shetty" src="https://avatars.githubusercontent.com/u/69446481?v=4?s=120" width="120px;" /><br /><sub><b>Samrudh Shetty</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#a11y-samrudh3125" title="Accessibility">️️️️♿️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Bumblebee00"><img alt="Mattia Micheletta Merlin" src="https://avatars.githubusercontent.com/u/54026028?v=4?s=120" width="120px;" /><br /><sub><b>Mattia Micheletta Merlin</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-Bumblebee00" title="Examples">💡</a> <a href="https://github.com/processing/p5.js/commits?author=Bumblebee00" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=Bumblebee00" title="Tests">⚠️</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://rmncafe.in"><img alt="Armaan Gupta" src="https://avatars.githubusercontent.com/u/119604454?v=4?s=120" width="120px;" /><br /><sub><b>Armaan Gupta</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ohayouarmaan" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://harmanbatheja15.github.io/harmanbatheja/"><img alt="Harman Batheja" src="https://avatars.githubusercontent.com/u/66913564?v=4?s=120" width="120px;" /><br /><sub><b>Harman Batheja</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-harmanbatheja15" title="Translation">🌍</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Aharmanbatheja15" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/PracDuckling"><img alt="PracDuckling" src="https://avatars.githubusercontent.com/u/68885144?v=4?s=120" width="120px;" /><br /><sub><b>PracDuckling</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3APracDuckling" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=PracDuckling" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/PoulavBhowmick03"><img alt="Poulav Bhowmick" src="https://avatars.githubusercontent.com/u/133862694?v=4?s=120" width="120px;" /><br /><sub><b>Poulav Bhowmick</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3APoulavBhowmick03" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=PoulavBhowmick03" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://keshav-malik99.netlify.app/"><img alt="Keshav Malik" src="https://avatars.githubusercontent.com/u/91189139?v=4?s=120" width="120px;" /><br /><sub><b>Keshav Malik</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=keshav-0907" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=keshav-0907" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Akeshav-0907" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/deveshidwivedi"><img alt="Deveshi Dwivedi" src="https://avatars.githubusercontent.com/u/120312681?v=4?s=120" width="120px;" /><br /><sub><b>Deveshi Dwivedi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=deveshidwivedi" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mohitbalwani"><img alt="Mohit Balwani" src="https://avatars.githubusercontent.com/u/73066030?v=4?s=120" width="120px;" /><br /><sub><b>Mohit Balwani</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mohitbalwani" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/rahulrangers"><img alt="rahulrangers" src="https://avatars.githubusercontent.com/u/127782777?v=4?s=120" width="120px;" /><br /><sub><b>rahulrangers</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=rahulrangers" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sudhanshuv3"><img alt="Sudhanshu Tiwari" src="https://avatars.githubusercontent.com/u/148856416?v=4?s=120" width="120px;" /><br /><sub><b>Sudhanshu Tiwari</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Asudhanshuv3" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=sudhanshuv3" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://meezwhite.xyz"><img alt="meezwhite" src="https://avatars.githubusercontent.com/u/112010422?v=4?s=120" width="120px;" /><br /><sub><b>meezwhite</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=meezwhite" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/pie999"><img alt="pie999" src="https://avatars.githubusercontent.com/u/105122549?v=4?s=120" width="120px;" /><br /><sub><b>pie999</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=pie999" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/haroon10725"><img alt="Muhammad Haroon" src="https://avatars.githubusercontent.com/u/104259212?v=4?s=120" width="120px;" /><br /><sub><b>Muhammad Haroon</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=haroon10725" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/commits?author=haroon10725" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/natdecker"><img alt="Nat Decker" src="https://avatars.githubusercontent.com/u/76665013?v=4?s=120" width="120px;" /><br /><sub><b>Nat Decker</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#a11y-natdecker" title="Accessibility">️️️️♿️</a> <a href="https://github.com/processing/p5.js/commits?author=natdecker" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sproutleaf"><img alt="Miaoye Que" src="https://avatars.githubusercontent.com/u/116130954?v=4?s=120" width="120px;" /><br /><sub><b>Miaoye Que</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-sproutleaf" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#maintenance-sproutleaf" title="Maintenance">🚧</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sphantom-code"><img alt="sphantom-code" src="https://avatars.githubusercontent.com/u/74479963?v=4?s=120" width="120px;" /><br /><sub><b>sphantom-code</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sphantom-code" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://parkminwook.com"><img alt="Minwook Park" src="https://avatars.githubusercontent.com/u/23724801?v=4?s=120" width="120px;" /><br /><sub><b>Minwook Park</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-wooknick" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Harrycheng233"><img alt="Harrycheng233" src="https://avatars.githubusercontent.com/u/129256087?v=4?s=120" width="120px;" /><br /><sub><b>Harrycheng233</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Harrycheng233" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/DianaMGalindo"><img alt="Diana Galindo" src="https://avatars.githubusercontent.com/u/95235340?v=4?s=120" width="120px;" /><br /><sub><b>Diana Galindo</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-DianaMGalindo" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/douMax"><img alt="Lingxiao Wang" src="https://avatars.githubusercontent.com/u/28494194?v=4?s=120" width="120px;" /><br /><sub><b>Lingxiao Wang</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-douMax" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ml008008"><img alt="ml.008" src="https://avatars.githubusercontent.com/u/141788009?v=4?s=120" width="120px;" /><br /><sub><b>ml.008</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-ml008008" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://ocelotl.cc"><img alt="EmilioOcelotl" src="https://avatars.githubusercontent.com/u/8987515?v=4?s=120" width="120px;" /><br /><sub><b>EmilioOcelotl</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-EmilioOcelotl" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://marianneteixido.github.io/"><img alt="Teixido" src="https://avatars.githubusercontent.com/u/32370294?v=4?s=120" width="120px;" /><br /><sub><b>Teixido</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-MarianneTeixido" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.ien.zone"><img alt="IENGROUND" src="https://avatars.githubusercontent.com/u/32572338?v=4?s=120" width="120px;" /><br /><sub><b>IENGROUND</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-ienground" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.behance.net/orwiss"><img alt="Orwiss" src="https://avatars.githubusercontent.com/u/7181108?v=4?s=120" width="120px;" /><br /><sub><b>Orwiss</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Orwiss" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://ranaa.tech"><img alt="Aditya Rana" src="https://avatars.githubusercontent.com/u/42575044?v=4?s=120" width="120px;" /><br /><sub><b>Aditya Rana</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-ranaaditya" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://eshaanagg.netlify.app/"><img alt="Eshaan Aggarwal" src="https://avatars.githubusercontent.com/u/96648934?v=4?s=120" width="120px;" /><br /><sub><b>Eshaan Aggarwal</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-EshaanAgg" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/yunyoungJang"><img alt="everything became blue" src="https://avatars.githubusercontent.com/u/39682540?v=4?s=120" width="120px;" /><br /><sub><b>everything became blue</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-yunyoungJang" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/YewonCALLI"><img alt="YewonCALLI" src="https://avatars.githubusercontent.com/u/96384200?v=4?s=120" width="120px;" /><br /><sub><b>YewonCALLI</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-YewonCALLI" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://sejinoh.live"><img alt="SejinOH" src="https://avatars.githubusercontent.com/u/39869184?v=4?s=120" width="120px;" /><br /><sub><b>SejinOH</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-designerSejinOH" title="Translation">🌍</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3AdesignerSejinOH" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Surbhi-Pittie"><img alt="Surbhi Pittie" src="https://avatars.githubusercontent.com/u/101015196?v=4?s=120" width="120px;" /><br /><sub><b>Surbhi Pittie</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Surbhi-Pittie" title="Translation">🌍</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Tmicrd"><img alt="nancy" src="https://avatars.githubusercontent.com/u/53132820?v=4?s=120" width="120px;" /><br /><sub><b>nancy</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-Tmicrd" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/jaiakash"><img alt="Akash Jaiswal" src="https://avatars.githubusercontent.com/u/33419526?v=4?s=120" width="120px;" /><br /><sub><b>Akash Jaiswal</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-jaiakash" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://jackbdu.com/about"><img alt="Jack B. Du" src="https://avatars.githubusercontent.com/u/8614803?v=4?s=120" width="120px;" /><br /><sub><b>Jack B. Du</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#tutorial-jackbdu" title="Tutorials">✅</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-jackbdu" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/togekisse"><img alt="togekisse" src="https://avatars.githubusercontent.com/u/78539685?v=4?s=120" width="120px;" /><br /><sub><b>togekisse</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-togekisse" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://tuan-h.com"><img alt="tuan" src="https://avatars.githubusercontent.com/u/90000947?v=4?s=120" width="120px;" /><br /><sub><b>tuan</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-tuantinghuang" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-tuantinghuang" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/janisepulveda"><img alt="Janis Sepúlveda" src="https://avatars.githubusercontent.com/u/144460794?v=4?s=120" width="120px;" /><br /><sub><b>Janis Sepúlveda</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-janisepulveda" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-janisepulveda" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="http://violand.xyz"><img alt="viola " src="https://avatars.githubusercontent.com/u/65051338?v=4?s=120" width="120px;" /><br /><sub><b>viola </b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-sandpills" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-sandpills" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://yuyuy.cargo.site/"><img alt="yu" src="https://avatars.githubusercontent.com/u/43624848?v=4?s=120" width="120px;" /><br /><sub><b>yu</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-leey611" title="Translation">🌍</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#ideas-leey611" title="Ideas, Planning, &amp; Feedback">🤔</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/LKL2017"><img alt="李坤霖" src="https://avatars.githubusercontent.com/u/31305299?v=4?s=120" width="120px;" /><br /><sub><b>李坤霖</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3ALKL2017" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/wwwld1"><img alt="Leo Wang" src="https://avatars.githubusercontent.com/u/116049361?v=4?s=120" width="120px;" /><br /><sub><b>Leo Wang</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-wwwld1" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Papershine"><img alt="Hilary Lau" src="https://avatars.githubusercontent.com/u/30367398?v=4?s=120" width="120px;" /><br /><sub><b>Hilary Lau</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Papershine" title="Code">💻</a> <a href="https://github.com/processing/p5.js/commits?author=Papershine" title="Tests">⚠️</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://bobbykaz.com"><img alt="Bobby Kazimiroff" src="https://avatars.githubusercontent.com/u/1424679?v=4?s=120" width="120px;" /><br /><sub><b>Bobby Kazimiroff</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=bobbykaz" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/PalumboN"><img alt="Nahuel Palumbo" src="https://avatars.githubusercontent.com/u/4098184?v=4?s=120" width="120px;" /><br /><sub><b>Nahuel Palumbo</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3APalumboN" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=PalumboN" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/lottihill"><img alt="lottihill" src="https://avatars.githubusercontent.com/u/76125564?v=4?s=120" width="120px;" /><br /><sub><b>lottihill</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=lottihill" title="Documentation">📖</a> <a href="https://github.com/processing/p5.js/issues?q=author%3Alottihill" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/JulioGitLab"><img alt="Julio Lab" src="https://avatars.githubusercontent.com/u/156870555?v=4?s=120" width="120px;" /><br /><sub><b>Julio Lab</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=JulioGitLab" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/JordanSucher"><img alt="Jordan Sucher" src="https://avatars.githubusercontent.com/u/9809109?v=4?s=120" width="120px;" /><br /><sub><b>Jordan Sucher</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AJordanSucher" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=JordanSucher" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/iambiancafonseca"><img alt="iambiancafonseca" src="https://avatars.githubusercontent.com/u/102000079?v=4?s=120" width="120px;" /><br /><sub><b>iambiancafonseca</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=iambiancafonseca" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Vishal2002"><img alt="Vishal Sharma" src="https://avatars.githubusercontent.com/u/35897449?v=4?s=120" width="120px;" /><br /><sub><b>Vishal Sharma</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Vishal2002" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://piyushs-folio-c8b8.onrender.com/"><img alt="PiyushChandra17" src="https://avatars.githubusercontent.com/u/47579287?v=4?s=120" width="120px;" /><br /><sub><b>PiyushChandra17</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=PiyushChandra17" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3APiyushChandra17" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/pulls?q=is%3Apr+reviewed-by%3APiyushChandra17" title="Reviewed Pull Requests">👀</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/dgrantham01"><img alt="Daniel Grantham" src="https://avatars.githubusercontent.com/u/71230430?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Grantham</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=dgrantham01" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://aboutmonica.com"><img alt="Monica Powell" src="https://avatars.githubusercontent.com/u/6998954?v=4?s=120" width="120px;" /><br /><sub><b>Monica Powell</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#talk-m0nica" title="Talks">📢</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-m0nica" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/rohanjulka19"><img alt="Rohan Julka" src="https://avatars.githubusercontent.com/u/19673968?v=4?s=120" width="120px;" /><br /><sub><b>Rohan Julka</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=rohanjulka19" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ravixalgorithm"><img alt="Mr. Algorithm" src="https://avatars.githubusercontent.com/u/148683640?v=4?s=120" width="120px;" /><br /><sub><b>Mr. Algorithm</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ravixalgorithm" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/sambensim"><img alt="sambensim" src="https://avatars.githubusercontent.com/u/28797947?v=4?s=120" width="120px;" /><br /><sub><b>sambensim</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=sambensim" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/NicholasGillen"><img alt="NicholasGillen" src="https://avatars.githubusercontent.com/u/80383027?v=4?s=120" width="120px;" /><br /><sub><b>NicholasGillen</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=NicholasGillen" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://abhinavcode13.github.io"><img alt="Abhinav kumar" src="https://avatars.githubusercontent.com/u/126642111?v=4?s=120" width="120px;" /><br /><sub><b>Abhinav kumar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Abhinavcode13" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/chhaski"><img alt="chaski" src="https://avatars.githubusercontent.com/u/71788879?v=4?s=120" width="120px;" /><br /><sub><b>chaski</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#research-chhaski" title="Research">🔬</a> <a href="https://github.com/processing/p5.js/commits?author=chhaski" title="Code">💻</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-chhaski" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Evorage0"><img alt="Evorage" src="https://avatars.githubusercontent.com/u/68397475?v=4?s=120" width="120px;" /><br /><sub><b>Evorage</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AEvorage0" title="Bug reports">🐛</a> <a href="https://github.com/processing/p5.js/commits?author=Evorage0" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://iamdanielmarino.com"><img alt="Daniel Marino" src="https://avatars.githubusercontent.com/u/171375?v=4?s=120" width="120px;" /><br /><sub><b>Daniel Marino</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=starzonmyarmz" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shahmaz0/"><img alt="Shahma Ansari" src="https://avatars.githubusercontent.com/Shahmaz0?s=120" width="120px;" /><br /><sub><b>Shahma Ansari</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AShahmaz0" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Manancode"><img alt="Manan Arora" src="https://avatars.githubusercontent.com/u/144525586?v=4?s=120" width="120px;" /><br /><sub><b>Manan Arora</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Manancode" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Serena20003"><img alt="Serena20003" src="https://avatars.githubusercontent.com/u/54823659?v=4?s=120" width="120px;" /><br /><sub><b>Serena20003</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Serena20003" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Souvik-Cyclic"><img alt="Souvik Kumar" src="https://avatars.githubusercontent.com/u/145324128?v=4?s=120" width="120px;" /><br /><sub><b>Souvik Kumar</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Souvik-Cyclic" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/PaperPrototype"><img alt="Abdiel Lopez" src="https://avatars.githubusercontent.com/u/48071553?v=4?s=120" width="120px;" /><br /><sub><b>Abdiel Lopez</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#mentoring-PaperPrototype" title="Mentoring">🧑‍🏫</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/PimTournaye"><img alt="Pim Tournaye" src="https://avatars.githubusercontent.com/u/56040665?v=4?s=120" width="120px;" /><br /><sub><b>Pim Tournaye</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=PimTournaye" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/Martin-Lorentzon"><img alt="Martin Lorentzon" src="https://avatars.githubusercontent.com/u/106841201?v=4?s=120" width="120px;" /><br /><sub><b>Martin Lorentzon</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3AMartin-Lorentzon" title="Bug reports">🐛</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://denisovichdev.github.io/link-tree"><img alt="Rishi" src="https://avatars.githubusercontent.com/u/66998096?v=4?s=120" width="120px;" /><br /><sub><b>Rishi</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=DenisovichDev" title="Code">💻</a> <a href="https://github.com/processing/p5.js/issues?q=author%3ADenisovichDev" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://www.linkedin.com/in/forcha-pearl/"><img alt="FORCHA PEARL" src="https://avatars.githubusercontent.com/u/24577149?v=4?s=120" width="120px;" /><br /><sub><b>FORCHA PEARL</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=Forchapeatl" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/c-dacanay"><img alt="c-dacanay" src="https://avatars.githubusercontent.com/u/54914834?v=4?s=120" width="120px;" /><br /><sub><b>c-dacanay</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#design-c-dacanay" title="Design">🎨</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#eventOrganizing-c-dacanay" title="Event Organizing">📋</a> <a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-c-dacanay" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/mathewpan2"><img alt="mathewpan2" src="https://avatars.githubusercontent.com/u/112679001?v=4?s=120" width="120px;" /><br /><sub><b>mathewpan2</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mathewpan2" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/cog25"><img alt="cog25" src="https://avatars.githubusercontent.com/u/74242561?v=4?s=120" width="120px;" /><br /><sub><b>cog25</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#translation-cog25" title="Translation">🌍</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/AaratiAkkapeddi"><img alt="Aarati Akkapeddi " src="https://avatars.githubusercontent.com/u/7389189?v=4?s=120" width="120px;" /><br /><sub><b>Aarati Akkapeddi </b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=AaratiAkkapeddi" title="Code">💻</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://mayaarguelles.com/"><img alt="Maya Arguelles" src="https://avatars.githubusercontent.com/u/29130029?v=4?s=120" width="120px;" /><br /><sub><b>Maya Arguelles</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=mayaarguelles" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/shourysingh07"><img alt="Shoury Singh" src="https://avatars.githubusercontent.com/u/105987613?v=4?s=120" width="120px;" /><br /><sub><b>Shoury Singh</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=shourysingh07" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/valkyriedimension"><img alt="Melody Sharp" src="https://avatars.githubusercontent.com/u/139258864?v=4?s=120" width="120px;" /><br /><sub><b>Melody Sharp</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Avalkyriedimension" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://tiborudvari.com"><img alt="Tibor Udvari" src="https://avatars.githubusercontent.com/u/1434442?v=4?s=120" width="120px;" /><br /><sub><b>Tibor Udvari</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=TiborUdvari" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://willallstetter.com"><img alt="willallstet" src="https://avatars.githubusercontent.com/u/67874779?v=4?s=120" width="120px;" /><br /><sub><b>willallstet</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=willallstet" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ashwanidey"><img alt="Ashwani Dey" src="https://avatars.githubusercontent.com/u/110251931?v=4?s=120" width="120px;" /><br /><sub><b>Ashwani Dey</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=ashwanidey" title="Documentation">📖</a></td> 
  </tr> 
  <tr> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/ibrand"><img alt="Ilona Brand" src="https://avatars.githubusercontent.com/u/3953117?v=4?s=120" width="120px;" /><br /><sub><b>Ilona Brand</b></sub></a><br /><a href="https://github.com/processing/p5.js/issues?q=author%3Aibrand" title="Bug reports">🐛</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://www.antoinettecreates.com"><img alt="Antoinette Bumatay-Chan" src="https://avatars.githubusercontent.com/u/342223?v=4?s=120" width="120px;" /><br /><sub><b>Antoinette Bumatay-Chan</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=aleannab" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/benpalevsky"><img alt="benpalevsky" src="https://avatars.githubusercontent.com/u/25121735?v=4?s=120" width="120px;" /><br /><sub><b>benpalevsky</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=benpalevsky" title="Documentation">📖</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="http://jeanetteandre.ws"><img alt="jeanette" src="https://avatars.githubusercontent.com/u/12685889?v=4?s=120" width="120px;" /><br /><sub><b>jeanette</b></sub></a><br /><a href="https://github.com/processing/p5.js/commits?author=jeanetteandrews" title="Code">💻</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/williamthazard"><img alt="William Hazard" src="https://avatars.githubusercontent.com/u/105560469?v=4?s=120" width="120px;" /><br /><sub><b>William Hazard</b></sub></a><br /><a href="https://raw.githubusercontent.com/processing/p5.js/main/#example-williamthazard" title="Examples">💡</a></td> 
   <td align="center" valign="top" width="16.66%"><a href="https://github.com/visheshrwl"><img alt="Vishesh Rawal" src="https://avatars.githubusercontent.com/u/92795514?v=4" width="120px;" /><br /><sub><b>Vishesh Rawal</b></sub></a><br /><a href="https://visheshrwl.vercel.app" title="Vishesh Rawal">💡</a></td> 
  </tr> 
 </tbody> 
</table> 
<!-- markdownlint-restore --> 
<!-- prettier-ignore-end --> 
<!-- ALL-CONTRIBUTORS-LIST:END --> 
<p>Thanks to all the wonderful contributors! 💓</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>graviraja/MLOps-Basics</title>
<link>https://github.com/graviraja/MLOps-Basics</link>
<guid>https://github.com/graviraja/MLOps-Basics</guid>
<content:encoded><![CDATA[
<div> 关键词：MLOps、模型监控、配置管理、数据版本控制、模型打包

总结:

本文详细介绍了MLOps的基础概念和实践流程，旨在帮助读者构建完整的机器学习操作流程。首先，通过项目设置阶段，了解了获取数据、数据预处理、数据加载、模型定义、模型训练以及模型推理的基本步骤，使用了特定技术栈进行操作。

接着，进入模型监控阶段，利用Weights & Biases工具对实验进行跟踪，包括调整超参数、测试不同模型性能以及分析模型与输入数据之间的关系，以优化模型。

配置管理部分引入了Hydra框架，用于解决复杂软件系统中配置管理的问题，通过配置文件的组织和参数的覆盖机制，实现灵活且高效的配置管理。

数据版本控制则是通过DVC（Data Version Control）实现，它解决了传统代码版本控制系统在处理大型文件时的局限性，确保模型历史版本的可追溯性和复用性。

最后，模型打包环节采用了ONNX和Docker技术，ONNX格式化模型便于跨框架部署，而Docker容器化技术则实现了应用的便携性和跨平台运行能力，简化了模型部署过程中的环境配置问题。

整体而言，MLOps通过整合数据处理、模型训练、监控、配置管理和打包等关键步骤，为机器学习项目的全生命周期提供了高效、自动化和可重复的操作流程，旨在提高模型开发和部署的效率与质量。 <div>
<p></p><hr /><h1>MLOps-Basics</h1> 
<blockquote> 
 <p>There is nothing magic about magic. The magician merely understands something simple which doesn’t appear to be simple or natural to the untrained audience. Once you learn how to hold a card while making your hand look empty, you only need practice before you, too, can “do magic.” – Jeffrey Friedl in the book Mastering Regular Expressions</p> 
</blockquote> 
<p><strong>Note: Please raise an issue for any suggestions, corrections, and feedback.</strong></p> 
<p>The goal of the series is to understand the basics of MLOps like model building, monitoring, configurations, testing, packaging, deployment, cicd, etc.</p> 
<p><img alt="pl" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/summary.png" /></p> 
<h2>Week 0: Project Setup</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=easy&amp;color=green" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-project-setup-part1">Blog Post here</a></p> 
<p>The project I have implemented is a simple classification problem. The scope of this week is to understand the following topics:</p> 
<ul> 
 <li><code>How to get the data?</code></li> 
 <li><code>How to process the data?</code></li> 
 <li><code>How to define dataloaders?</code></li> 
 <li><code>How to declare the model?</code></li> 
 <li><code>How to train the model?</code></li> 
 <li><code>How to do the inference?</code></li> 
</ul> 
<p><img alt="pl" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/pl.jpeg" /></p> 
<p>Following tech stack is used:</p> 
<ul> 
 <li><a href="https://github.com/huggingface/datasets">Huggingface Datasets</a></li> 
 <li><a href="https://github.com/huggingface/transformers">Huggingface Transformers</a></li> 
 <li><a href="https://pytorch-lightning.readthedocs.io/">Pytorch Lightning</a></li> 
</ul> 
<h2>Week 1: Model monitoring - Weights and Biases</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=easy&amp;color=green" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-wandb-integration">Blog Post here</a></p> 
<p>Tracking all the experiments like tweaking hyper-parameters, trying different models to test their performance and seeing the connection between model and the input data will help in developing a better model.</p> 
<p>The scope of this week is to understand the following topics:</p> 
<ul> 
 <li><code>How to configure basic logging with W&amp;B?</code></li> 
 <li><code>How to compute metrics and log them in W&amp;B?</code></li> 
 <li><code>How to add plots in W&amp;B?</code></li> 
 <li><code>How to add data samples to W&amp;B?</code></li> 
</ul> 
<p><img alt="wannb" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/wandb.png" /></p> 
<p>Following tech stack is used:</p> 
<ul> 
 <li><a href="https://wandb.ai/site">Weights and Biases</a></li> 
 <li><a href="https://torchmetrics.readthedocs.io/">torchmetrics</a></li> 
</ul> 
<p>References:</p> 
<ul> 
 <li> <p><a href="https://www.youtube.com/watch?v=hUXQm46TAKc">Tutorial on Pytorch Lightning + Weights &amp; Bias</a></p> </li> 
 <li> <p><a href="https://docs.wandb.ai/">WandB Documentation</a></p> </li> 
</ul> 
<h2>Week 2: Configurations - Hydra</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=easy&amp;color=green" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-hydra-config">Blog Post here</a></p> 
<p>Configuration management is a necessary for managing complex software systems. Lack of configuration management can cause serious problems with reliability, uptime, and the ability to scale a system.</p> 
<p>The scope of this week is to understand the following topics:</p> 
<ul> 
 <li><code>Basics of Hydra</code></li> 
 <li><code>Overridding configurations</code></li> 
 <li><code>Splitting configuration across multiple files</code></li> 
 <li><code>Variable Interpolation</code></li> 
 <li><code>How to run model with different parameter combinations?</code></li> 
</ul> 
<p><img alt="hydra" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/hydra.png" /></p> 
<p>Following tech stack is used:</p> 
<ul> 
 <li><a href="https://hydra.cc/">Hydra</a></li> 
</ul> 
<p>References</p> 
<ul> 
 <li> <p><a href="https://hydra.cc/docs/intro">Hydra Documentation</a></p> </li> 
 <li> <p><a href="https://www.sscardapane.it/tutorials/hydra-tutorial/#executing-multiple-runs">Simone Tutorial on Hydra</a></p> </li> 
</ul> 
<h2>Week 3: Data Version Control - DVC</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=easy&amp;color=green" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-dvc">Blog Post here</a></p> 
<p>Classical code version control systems are not designed to handle large files, which make cloning and storing the history impractical. Which are very common in Machine Learning.</p> 
<p>The scope of this week is to understand the following topics:</p> 
<ul> 
 <li><code>Basics of DVC</code></li> 
 <li><code>Initialising DVC</code></li> 
 <li><code>Configuring Remote Storage</code></li> 
 <li><code>Saving Model to the Remote Storage</code></li> 
 <li><code>Versioning the models</code></li> 
</ul> 
<p><img alt="dvc" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/dvc.png" /></p> 
<p>Following tech stack is used:</p> 
<ul> 
 <li><a href="https://dvc.org/">DVC</a></li> 
</ul> 
<p>References</p> 
<ul> 
 <li> <p><a href="https://dvc.org/doc">DVC Documentation</a></p> </li> 
 <li> <p><a href="https://www.youtube.com/watch?v=kLKBcPonMYw">DVC Tutorial on Versioning data</a></p> </li> 
</ul> 
<h2>Week 4: Model Packaging - ONNX</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=medium&amp;color=orange" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-onnx">Blog Post here</a></p> 
<p>Why do we need model packaging? Models can be built using any machine learning framework available out there (sklearn, tensorflow, pytorch, etc.). We might want to deploy models in different environments like (mobile, web, raspberry pi) or want to run in a different framework (trained in pytorch, inference in tensorflow). A common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers will help a lot.</p> 
<p>This is acheived by a community project <code>ONNX</code>.</p> 
<p>The scope of this week is to understand the following topics:</p> 
<ul> 
 <li> <p><code>What is ONNX?</code></p> </li> 
 <li> <p><code>How to convert a trained model to ONNX format?</code></p> </li> 
 <li> <p><code>What is ONNX Runtime?</code></p> </li> 
 <li> <p><code>How to run ONNX converted model in ONNX Runtime?</code></p> </li> 
 <li> <p><code>Comparisions</code></p> </li> 
</ul> 
<p><img alt="ONNX" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/onnx.jpeg" /></p> 
<p>Following tech stack is used:</p> 
<ul> 
 <li><a href="https://onnx.ai/">ONNX</a></li> 
 <li><a href="https://www.onnxruntime.ai/">ONNXRuntime</a></li> 
</ul> 
<p>References</p> 
<ul> 
 <li><a href="https://www.youtube.com/watch?v=7nutT3Aacyw">Abhishek Thakur tutorial on onnx model conversion</a></li> 
 <li><a href="https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html">Pytorch Lightning documentation on onnx conversion</a></li> 
 <li><a href="https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333">Huggingface Blog on ONNXRuntime</a></li> 
 <li><a href="https://tugot17.github.io/data-science-blog/onnx/tutorial/2020/09/21/Exporting-lightning-model-to-onnx.html">Piotr Blog on onnx conversion</a></li> 
</ul> 
<h2>Week 5: Model Packaging - Docker</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=easy&amp;color=green" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-docker">Blog Post here</a></p> 
<p>Why do we need packaging? We might have to share our application with others, and when they try to run the application most of the time it doesn’t run due to dependencies issues / OS related issues and for that, we say (famous quote across engineers) that <code>It works on my laptop/system</code>.</p> 
<p>So for others to run the applications they have to set up the same environment as it was run on the host side which means a lot of manual configuration and installation of components.</p> 
<p>The solution to these limitations is a technology called Containers.</p> 
<p>By containerizing/packaging the application, we can run the application on any cloud platform to get advantages of managed services and autoscaling and reliability, and many more.</p> 
<p>The most prominent tool to do the packaging of application is Docker 🛳</p> 
<p>The scope of this week is to understand the following topics:</p> 
<ul> 
 <li><code>FastAPI wrapper</code></li> 
 <li><code>Basics of Docker</code></li> 
 <li><code>Building Docker Container</code></li> 
 <li><code>Docker Compose</code></li> 
</ul> 
<p><img alt="Docker" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/docker_flow.png" /></p> 
<p>References</p> 
<ul> 
 <li><a href="https://www.analyticsvidhya.com/blog/2021/06/a-hands-on-guide-to-containerized-your-machine-learning-workflow-with-docker/">Analytics vidhya blog</a></li> 
</ul> 
<h2>Week 6: CI/CD - GitHub Actions</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=medium&amp;color=orange" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-github-actions">Blog Post here</a></p> 
<p>CI/CD is a coding philosophy and set of practices with which you can continuously build, test, and deploy iterative code changes.</p> 
<p>This iterative process helps reduce the chance that you develop new code based on a buggy or failed previous versions. With this method, you strive to have less human intervention or even no intervention at all, from the development of new code until its deployment.</p> 
<p>In this post, I will be going through the following topics:</p> 
<ul> 
 <li>Basics of GitHub Actions</li> 
 <li>First GitHub Action</li> 
 <li>Creating Google Service Account</li> 
 <li>Giving access to Service account</li> 
 <li>Configuring DVC to use Google Service account</li> 
 <li>Configuring Github Action</li> 
</ul> 
<p><img alt="Docker" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/basic_flow.png" /></p> 
<p>References</p> 
<ul> 
 <li> <p><a href="https://dvc.org/doc/user-guide/setup-google-drive-remote">Configuring service account</a></p> </li> 
 <li> <p><a href="https://docs.github.com/en/actions/quickstart">Github actions</a></p> </li> 
</ul> 
<h2>Week 7: Container Registry - AWS ECR</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=medium&amp;color=orange" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-container-registry">Blog Post here</a></p> 
<p>A container registry is a place to store container images. A container image is a file comprised of multiple layers which can execute applications in a single instance. Hosting all the images in one stored location allows users to commit, identify and pull images when needed.</p> 
<p>Amazon Simple Storage Service (S3) is a storage for the internet. It is designed for large-capacity, low-cost storage provision across multiple geographical regions.</p> 
<p>In this week, I will be going through the following topics:</p> 
<ul> 
 <li> <p><code>Basics of S3</code></p> </li> 
 <li> <p><code>Programmatic access to S3</code></p> </li> 
 <li> <p><code>Configuring AWS S3 as remote storage in DVC</code></p> </li> 
 <li> <p><code>Basics of ECR</code></p> </li> 
 <li> <p><code>Configuring GitHub Actions to use S3, ECR</code></p> </li> 
</ul> 
<p><img alt="Docker" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/ecr_flow.png" /></p> 
<h2>Week 8: Serverless Deployment - AWS Lambda</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=medium&amp;color=orange" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-serverless">Blog Post here</a></p> 
<p>A serverless architecture is a way to build and run applications and services without having to manage infrastructure. The application still runs on servers, but all the server management is done by third party service (AWS). We no longer have to provision, scale, and maintain servers to run the applications. By using a serverless architecture, developers can focus on their core product instead of worrying about managing and operating servers or runtimes, either in the cloud or on-premises.</p> 
<p>In this week, I will be going through the following topics:</p> 
<ul> 
 <li> <p><code>Basics of Serverless</code></p> </li> 
 <li> <p><code>Basics of AWS Lambda</code></p> </li> 
 <li> <p><code>Triggering Lambda with API Gateway</code></p> </li> 
 <li> <p><code>Deploying Container using Lambda</code></p> </li> 
 <li> <p><code>Automating deployment to Lambda using Github Actions</code></p> </li> 
</ul> 
<p><img alt="Docker" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/lambda_flow.png" /></p> 
<h2>Week 9: Prediction Monitoring - Kibana</h2> 
<img src="https://img.shields.io/static/v1.svg?style=for-the-badge&amp;label=difficulty&amp;message=medium&amp;color=orange" /> 
<p>Refer to the <a href="https://www.ravirajag.dev/blog/mlops-monitoring">Blog Post here</a></p> 
<p>Monitoring systems can help give us confidence that our systems are running smoothly and, in the event of a system failure, can quickly provide appropriate context when diagnosing the root cause.</p> 
<p>Things we want to monitor during and training and inference are different. During training we are concered about whether the loss is decreasing or not, whether the model is overfitting, etc.</p> 
<p>But, during inference, We like to have confidence that our model is making correct predictions.</p> 
<p>There are many reasons why a model can fail to make useful predictions:</p> 
<ul> 
 <li> <p>The underlying data distribution has shifted over time and the model has gone stale. i.e inference data characteristics is different from the data characteristics used to train the model.</p> </li> 
 <li> <p>The inference data stream contains edge cases (not seen during model training). In this scenarios model might perform poorly or can lead to errors.</p> </li> 
 <li> <p>The model was misconfigured in its production deployment. (Configuration issues are common)</p> </li> 
</ul> 
<p>In all of these scenarios, the model could still make a <code>successful</code> prediction from a service perspective, but the predictions will likely not be useful. Monitoring machine learning models can help us detect such scenarios and intervene (e.g. trigger a model retraining/deployment pipeline).</p> 
<p>In this week, I will be going through the following topics:</p> 
<ul> 
 <li> <p><code>Basics of Cloudwatch Logs</code></p> </li> 
 <li> <p><code>Creating Elastic Search Cluster</code></p> </li> 
 <li> <p><code>Configuring Cloudwatch Logs with Elastic Search</code></p> </li> 
 <li> <p><code>Creating Index Patterns in Kibana</code></p> </li> 
 <li> <p><code>Creating Kibana Visualisations</code></p> </li> 
 <li> <p><code>Creating Kibana Dashboard</code></p> </li> 
</ul> 
<p><img alt="Docker" src="https://raw.githubusercontent.com/graviraja/MLOps-Basics/main/images/kibana_flow.png" /></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>getcursor/cursor</title>
<link>https://github.com/getcursor/cursor</link>
<guid>https://github.com/getcursor/cursor</guid>
<content:encoded><![CDATA[
<div> 关键词：AI Code EditorCursor、bug报告、功能请求、反馈、下载尝试

总结:
本文为Cursor代码编辑器的问题报告库，旨在收集用户关于软件的bug报告和功能需求。鼓励用户根据自身使用体验对优先级进行排序，以帮助开发团队更好地优化Cursor。Cursor提供了一个智能代码编辑环境，支持多种编程语言，具有强大的代码补全、实时语法检查等功能。为了开始使用，用户需访问指定链接下载并尝试Cursor编辑器。用户的反馈对于提升Cursor的性能至关重要，因此，提出问题或建议时应详细描述遇到的具体情况或期望的功能实现方式，以便开发团队能够准确理解并及时解决。 <div>
<p>The AI Code Editor</p><hr /><h1>Cursor</h1> 
<p>This is an issues-only repo for <a href="https://cursor.com">Cursor</a>.</p> 
<p>Creating new tickets for bugs or feature requests is much appreciated 🙂 Feel free to react to the ones you'd like us to prioritize. Our goal is to make Cursor work great for you, and your feedback is super helpful.</p> 
<h2>Getting Started</h2> 
<p>Head over to <a href="https://cursor.com/">our website</a> to download and try out the editor.</p> 
<h2>Features</h2> 
<p><a href="https://cursor.com/features">See here</a> for more info on Cursor's features.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>librespot-org/librespot</title>
<link>https://github.com/librespot-org/librespot</link>
<guid>https://github.com/librespot-org/librespot</guid>
<content:encoded><![CDATA[
<div> 关键词：librespot、open source、Spotify client、audio playback、development

总结:

librespot 是一款开源的 Spotify 客户端库，允许应用程序通过多种后端控制和播放音乐，同时作为 Spotify Connect 接收器。它提供了官方封闭源代码的 libspotify 所不具备的额外功能。需要注意的是，librespot 只适用于 Spotify 高级版用户，不支持免费账户的有限功能，如有限次数的跳过和广告。

安装 librespot 非常简单，只需运行 `cargo install librespot` 命令即可。使用命令行界面（CLI）创建一个名为“Librespot Speaker”并以 160 kbps 的音频流播放的扬声器是一个示例。

此仓库是由原项目维护者不再活跃维护后建立的，旨在为未来提供维护和升级途径。librespot 的文档正在不断完善中，欢迎贡献。开发者可以通过阅读代码或在 Gitter 上提问来了解更多关于 librespot 的工作原理。

在遇到问题时，请首先检查现有问题，避免重复提交。报告崩溃时，提供 librespot 生成的堆栈跟踪和复现问题所需的信息非常重要。librespot 提供了构建过程的概述，并且支持多种音频后端，包括但不限于 Rodio、ALSA、GStreamer 等。

librespot 通过官方包系统在多个操作系统上可用，例如 Linux、FreeBSD 和 NetBSD。为了构建 librespot，需要安装相应的依赖项，具体取决于操作系统。librespot 还提供了实现无头 Spotify Connect 接收器的示例程序。 <div>
<p>Open Source Spotify client library</p><hr /><p><a href="https://github.com/librespot-org/librespot/actions"><img alt="Build Status" src="https://github.com/librespot-org/librespot/workflows/test/badge.svg?sanitize=true" /></a> <a href="https://gitter.im/librespot-org/spotify-connect-resources"><img alt="Gitter chat" src="https://badges.gitter.im/librespot-org/librespot.png" /></a> <a href="https://crates.io/crates/librespot"><img alt="Crates.io" src="https://img.shields.io/crates/v/librespot.svg?sanitize=true" /></a></p> 
<p>Current maintainers are <a href="https://github.com/orgs/librespot-org/people">listed on GitHub</a>.</p> 
<h1>librespot</h1> 
<p><em>librespot</em> is an open source client library for Spotify. It enables applications to use Spotify's service to control and play music via various backends, and to act as a Spotify Connect receiver. It is an alternative to the official and <a href="https://pyspotify.mopidy.com/en/latest/#libspotify-s-deprecation">now deprecated</a> closed-source <code>libspotify</code>. Additionally, it will provide extra features which are not available in the official library.</p> 
<p><em>Note: librespot only works with Spotify Premium. This will remain the case. We will not support any features to make librespot compatible with free accounts, such as limited skips and adverts.</em></p> 
<h2>Quick start</h2> 
<p>We're available on <a href="https://crates.io/crates/librespot">crates.io</a> as the <em>librespot</em> package. Simply run <code>cargo install librespot</code> to install librespot on your system. Check the wiki for more info and possible <a href="https://github.com/librespot-org/librespot/wiki/Options">usage options</a>.</p> 
<p>After installation, you can run librespot from the CLI using a command such as <code>librespot -n "Librespot Speaker" -b 160</code> to create a speaker called <em>Librespot Speaker</em> serving 160 kbps audio.</p> 
<h2>This fork</h2> 
<p>As the origin by <a href="https://github.com/plietar/">plietar</a> is no longer actively maintained, this organisation and repository have been set up so that the project may be maintained and upgraded in the future.</p> 
<h1>Documentation</h1> 
<p>Documentation is currently a work in progress, contributions are welcome!</p> 
<p>There is some brief documentation on how the protocol works in the <a href="https://github.com/librespot-org/librespot/tree/master/docs">docs</a> folder.</p> 
<p><a href="https://github.com/librespot-org/librespot/raw/master/COMPILING.md">COMPILING.md</a> contains detailed instructions on setting up a development environment, and compiling librespot. More general usage and compilation information is available on the <a href="https://github.com/librespot-org/librespot/wiki">wiki</a>. <a href="https://github.com/librespot-org/librespot/raw/master/CONTRIBUTING.md">CONTRIBUTING.md</a> also contains our contributing guidelines.</p> 
<p>If you wish to learn more about how librespot works overall, the best way is to simply read the code, and ask any questions you have in our <a href="https://gitter.im/librespot-org/spotify-connect-resources">Gitter Room</a>.</p> 
<h1>Issues &amp; Discussions</h1> 
<p><strong>We have recently started using Github discussions for general questions and feature requests, as they are a more natural medium for such cases, and allow for upvoting to prioritize feature development. Check them out <a href="https://github.com/librespot-org/librespot/discussions">here</a>. Bugs and issues with the underlying library should still be reported as issues.</strong></p> 
<p>If you run into a bug when using librespot, please search the existing issues before opening a new one. Chances are, we've encountered it before, and have provided a resolution. If not, please open a new one, and where possible, include the backtrace librespot generates on crashing, along with anything we can use to reproduce the issue, e.g. the Spotify URI of the song that caused the crash.</p> 
<h1>Building</h1> 
<p>A quick walkthrough of the build process is outlined below, while a detailed compilation guide can be found <a href="https://github.com/librespot-org/librespot/raw/master/COMPILING.md">here</a>.</p> 
<h2>Additional Dependencies</h2> 
<p>We recently switched to using <a href="https://github.com/tomaka/rodio">Rodio</a> for audio playback by default, hence for macOS and Windows, you should just be able to clone and build librespot (with the command below). For Linux, you will need to run the additional commands below, depending on your distro.</p> 
<p>On Debian/Ubuntu, the following command will install these dependencies:</p> 
<pre><code class="language-shell">sudo apt-get install build-essential libasound2-dev
</code></pre> 
<p>On Fedora systems, the following command will install these dependencies:</p> 
<pre><code class="language-shell">sudo dnf install alsa-lib-devel make gcc
</code></pre> 
<p>librespot currently offers the following selection of <a href="https://github.com/librespot-org/librespot/wiki/Audio-Backends">audio backends</a>:</p> 
<pre><code>Rodio (default)
ALSA
GStreamer
PortAudio
PulseAudio
JACK
JACK over Rodio
SDL
Pipe
Subprocess
</code></pre> 
<p>Please check the corresponding <a href="https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies">Compiling</a> entry on the wiki for backend specific dependencies.</p> 
<p>Once you've installed the dependencies and cloned this repository you can build <em>librespot</em> with the default backend using Cargo.</p> 
<pre><code class="language-shell">cargo build --release
</code></pre> 
<h1>Packages</h1> 
<p>librespot is also available via official package system on various operating systems such as Linux, FreeBSD, NetBSD. <a href="https://repology.org/project/librespot/versions">Repology</a> offers a good overview.</p> 
<p><a href="https://repology.org/project/librespot/versions"><img alt="Packaging status" src="https://repology.org/badge/vertical-allrepos/librespot.svg?sanitize=true" /></a></p> 
<h2>Usage</h2> 
<p>A sample program implementing a headless Spotify Connect receiver is provided. Once you've built <em>librespot</em>, run it using :</p> 
<pre><code class="language-shell">target/release/librespot --name DEVICENAME
</code></pre> 
<p>The above is a minimal example. Here is a more fully fledged one:</p> 
<pre><code class="language-shell">target/release/librespot -n "Librespot" -b 320 -c ./cache --enable-volume-normalisation --initial-volume 75 --device-type avr
</code></pre> 
<p>The above command will create a receiver named <code>Librespot</code>, with bitrate set to 320 kbps, initial volume at 75%, with volume normalisation enabled, and the device displayed in the app as an Audio/Video Receiver. A folder named <code>cache</code> will be created/used in the current directory, and be used to cache audio data and credentials.</p> 
<p>A full list of runtime options is available <a href="https://github.com/librespot-org/librespot/wiki/Options">here</a>.</p> 
<p><em>Please Note: When using the cache feature, an authentication blob is stored for your account in the cache directory. For security purposes, we recommend that you set directory permissions on the cache directory to <code>700</code>.</em></p> 
<h2>Contact</h2> 
<p>Come and hang out on gitter if you need help or want to offer some: <a href="https://gitter.im/librespot-org/spotify-connect-resources">https://gitter.im/librespot-org/spotify-connect-resources</a></p> 
<h2>Disclaimer</h2> 
<p>Using this code to connect to Spotify's API is probably forbidden by them. Use at your own risk.</p> 
<h2>License</h2> 
<p>Everything in this repository is licensed under the MIT license.</p> 
<h2>Related Projects</h2> 
<p>This is a non exhaustive list of projects that either use or have modified librespot. If you'd like to include yours, submit a PR.</p> 
<ul> 
 <li><a href="https://github.com/librespot-org/librespot-golang">librespot-golang</a> - A golang port of librespot.</li> 
 <li><a href="https://github.com/marcelveldt/plugin.audio.spotify">plugin.audio.spotify</a> - A Kodi plugin for Spotify.</li> 
 <li><a href="https://github.com/dtcooper/raspotify">raspotify</a> - A Spotify Connect client that mostly Just Works™</li> 
 <li><a href="https://github.com/Spotifyd/spotifyd">Spotifyd</a> - A stripped down librespot UNIX daemon.</li> 
 <li><a href="https://github.com/nicokaiser/rpi-audio-receiver">rpi-audio-receiver</a> - easy Raspbian install scripts for Spotifyd, Bluetooth, Shairport and other audio receivers</li> 
 <li><a href="https://github.com/badfortrains/spotcontrol">Spotcontrol</a> - A golang implementation of a Spotify Connect controller. No playback functionality.</li> 
 <li><a href="https://github.com/devgianlu/librespot-java">librespot-java</a> - A Java port of librespot.</li> 
 <li><a href="https://github.com/hrkfdn/ncspot">ncspot</a> - Cross-platform ncurses Spotify client.</li> 
 <li><a href="https://github.com/xMordax/ansible-role-librespot/tree/master">ansible-role-librespot</a> - Ansible role that will build, install and configure Librespot.</li> 
 <li><a href="https://github.com/xou816/spot">Spot</a> - Gtk/Rust native Spotify client for the GNOME desktop.</li> 
 <li><a href="https://github.com/badaix/snapcast">Snapcast</a> - synchronised multi-room audio player that uses librespot as its source for Spotify content</li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>gitroomhq/postiz-app</title>
<link>https://github.com/gitroomhq/postiz-app</link>
<guid>https://github.com/gitroomhq/postiz-app</guid>
<content:encoded><![CDATA[
<div> 关键词：AI、社交媒体管理、Postiz、团队协作、自动化

文章总结：

Postiz是一款专为社交媒体管理设计的AI工具，它提供了全面的功能来帮助用户规划、发布、分析和优化社交媒体内容。与Buffer.com、Hypefury、Twitter Hunter等竞品相比，Postiz通过AI技术增强了内容创建和发布的效率。

该平台允许用户自动化地安排多平台的社交媒体帖子，同时提供详尽的分析报告，帮助用户了解哪些内容最吸引受众，从而优化未来的发布策略。此外，Postiz支持团队协作功能，允许用户邀请同事加入项目，共同讨论、评论并调度内容。这不仅促进了团队内的沟通，还提高了内容生产的效率和质量。

Postiz采用现代技术栈开发，包括NX（Monorepo）、NextJS（React）和NestJS等，确保了高性能和可扩展性。它还集成了Prisma（默认使用PostgreSQL）、Redis（BullMQ）和Resend（邮件通知）等服务，以增强数据管理和通信功能。

总之，Postiz是一个全面的解决方案，旨在通过AI驱动的自动化功能、深入的数据分析和高效的团队协作，帮助用户更有效地管理他们的社交媒体存在，实现业务增长。 <div>
<p>📨 Schedule social media posts, measure them, exchange with other members and get a lot of help from AI 🚀</p><hr /><p align="center"> <a href="https://x.com/intent/follow?screen_name=nevodavid" target="_blank"> <img alt="Follow me" src="https://github.com/user-attachments/assets/1562c93f-95c6-4307-8a85-e62003e26348" /> </a> <br /><br /> </p> 
<p align="center"> <a href="https://postiz.com" target="_blank"> 
   
   <source media="(prefers-color-scheme: dark)" /> 
   <img alt="Novu Logo" src="https://github.com/user-attachments/assets/f0d30d70-dddb-4142-8876-e9aa6ed1cb99" width="280" /> 
   </a> </p> 
<p align="center"> <a href="https://opensource.org/licenses/Apache-2.0"> <img alt="License" src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" /> </a> </p> 
<div align="center"> 
 <strong> <h2>Your ultimate AI social media scheduling tool</h2><br /> <a href="https://postiz.com">Postiz</a>: An alternative to: Buffer.com, Hypefury, Twitter Hunter, Etc...<br /><br /> </strong> Postiz offers everything you need to manage your social media posts,
 <br />build an audience, capture leads, and grow your business. 
</div> 
<div align="center" class="flex"> 
 <br /> 
 <img alt="Instagram" src="https://postiz.com/svgs/socials/Instagram.svg?sanitize=true" width="32" /> 
 <img alt="Youtube" src="https://postiz.com/svgs/socials/Youtube.svg?sanitize=true" width="32" /> 
 <img alt="Dribbble" src="https://postiz.com/svgs/socials/Dribbble.svg?sanitize=true" width="32" /> 
 <img alt="Linkedin" src="https://postiz.com/svgs/socials/Linkedin.svg?sanitize=true" width="32" /> 
 <img alt="Reddit" src="https://postiz.com/svgs/socials/Reddit.svg?sanitize=true" width="32" /> 
 <img alt="TikTok" src="https://postiz.com/svgs/socials/TikTok.svg?sanitize=true" width="32" /> 
 <img alt="Facebook" src="https://postiz.com/svgs/socials/Facebook.svg?sanitize=true" width="32" /> 
 <img alt="Pinterest" src="https://postiz.com/svgs/socials/Pinterest.svg?sanitize=true" width="32" /> 
 <img alt="Threads" src="https://postiz.com/svgs/socials/Threads.svg?sanitize=true" width="32" /> 
</div> 
<p align="center"> <br /> <a href="https://docs.postiz.com" rel="dofollow"><strong>Explore the docs »</strong></a> <br /> <br /> <a href="https://platform.postiz.com">Register</a> · <a href="https://discord.postiz.com">Join Our Discord</a> · <a href="https://twitter.com/nevodavid">X</a> · <a href="https://gitroom.com">Gitroom</a> </p> 
<br /> 
<p align="center"> 
 <video src="https://github.com/user-attachments/assets/05436a01-19c8-4827-b57f-05a5e7637a67" width="100%"></video> </p> 
<h2>✨ Features</h2> 
<table> 
 <thead> 
  <tr> 
   <th><img alt="Image 1" src="https://github.com/user-attachments/assets/a27ee220-beb7-4c7e-8c1b-2c44301f82ef" /></th> 
   <th><img alt="Image 2" src="https://github.com/user-attachments/assets/eb5f5f15-ed90-47fc-811c-03ccba6fa8a2" /></th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><img alt="Image 3" src="https://github.com/user-attachments/assets/d51786ee-ddd8-4ef8-8138-5192e9cfe7c3" /></td> 
   <td><img alt="Image 4" src="https://github.com/user-attachments/assets/91f83c89-22f6-43d6-b7aa-d2d3378289fb" /></td> 
  </tr> 
 </tbody> 
</table> 
<h1>Intro</h1> 
<ul> 
 <li>Schedule all your social media posts (many AI features)</li> 
 <li>Measure your work with analytics.</li> 
 <li>Collaborate with other team members to exchange or buy posts.</li> 
 <li>Invite your team members to collaborate, comment, and schedule posts.</li> 
 <li>At the moment there is no difference between the hosted version to the self-hosted version</li> 
</ul> 
<h2>Tech Stack</h2> 
<ul> 
 <li>NX (Monorepo)</li> 
 <li>NextJS (React)</li> 
 <li>NestJS</li> 
 <li>Prisma (Default to PostgreSQL)</li> 
 <li>Redis (BullMQ)</li> 
 <li>Resend (email notifications)</li> 
</ul> 
<h2>Quick Start</h2> 
<p>To have the project up and running, please follow the <a href="https://docs.postiz.com/quickstart">Quick Start Guide</a></p> 
<h2></h2> 
<h1>License</h1> 
<p>This repository's source code is available under the <a href="https://raw.githubusercontent.com/gitroomhq/postiz-app/main/LICENSE">Apache 2.0 License</a>.</p> 
<p><br /><br /><br /></p> 
<p align="center"> <a href="https://www.g2.com/products/postiz/take_survey" target="blank"><img alt="g2" src="https://github.com/user-attachments/assets/892cb74c-0b49-4589-b2f5-fbdbf7a98f66" /></a> </p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>continuedev/continue</title>
<link>https://github.com/continuedev/continue</link>
<guid>https://github.com/continuedev/continue</guid>
<content:encoded><![CDATA[
<div> 关键词：Continue, AI代码助手, VS Code, JetBrains, 开源

总结:
本文介绍了“Continue”作为领先的开源AI代码助手，它允许用户连接任何模型和上下文，构建自定义的代码补全和聊天体验，直接在VS Code和JetBrains中使用。文章提供了多种快捷键，如在VS Code中使用cmd+L或ctrl+L在MacOS和Windows上定位代码，使用tab键进行代码补全，以及在JetBrains中使用相同的快捷键实现相同功能。同时，文章强调了如何轻松理解代码段落、重命名函数、询问关于代码库的问题和利用文档作为上下文。

为了开始使用，用户可以下载并安装到VS Code和JetBrains中，通过免费试用模型来熟悉其功能，然后再进行个性化设置。文章还鼓励用户探索提供的模型和提供商信息，并提供了参与贡献的途径。最后，强调了Continue的开源性质，邀请用户查阅相关文档、参与社区讨论和合作，以及了解其许可证条款。 <div>
<p>⏩ Continue is the leading open-source AI code assistant. You can connect any models and any context to build custom autocomplete and chat experiences inside VS Code and JetBrains</p><hr /><div align="center"> 
 <p><img alt="Continue logo" src="https://raw.githubusercontent.com/continuedev/continue/main/media/readme.png" /></p> 
</div> 
<h1 align="center">Continue</h1> 
<div align="center"> 
 <p><strong><a href="https://docs.continue.dev">Continue</a> is the leading open-source AI code assistant. You can connect any models and any context to build custom autocomplete and chat experiences inside <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code</a> and <a href="https://plugins.jetbrains.com/plugin/22707-continue-extension">JetBrains</a></strong></p> 
</div> 
<div align="center"> 
 <a href="https://opensource.org/licenses/Apache-2.0" style="background: none;" target="_blank"> <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" style="height: 22px;" /> </a> 
 <a href="https://docs.continue.dev" style="background: none;" target="_blank"> <img src="https://img.shields.io/badge/continue_docs-%23BE1B55" style="height: 22px;" /> </a> 
 <a href="https://discord.gg/vapESyrFmJ" style="background: none;" target="_blank"> <img src="https://img.shields.io/badge/discord-join-continue.svg?labelColor=191937&amp;color=6F6FF7&amp;logo=discord" style="height: 22px;" /> </a> 
 <p></p> 
 <h2>Easily understand code sections</h2> 
 <p><img alt="understand" src="https://raw.githubusercontent.com/continuedev/continue/main/docs/static/img/understand.gif" /></p> 
 <p>VS Code: <code>cmd+L</code> (MacOS) / <code>ctrl+L</code> (Windows)</p> 
 <p>JetBrains: <code>cmd+J</code> (MacOS) / <code>ctrl+J</code> (Windows)</p> 
 <h2>Tab to autocomplete code suggestions</h2> 
 <p><img alt="autocomplete" src="https://raw.githubusercontent.com/continuedev/continue/main/docs/static/img/autocomplete.gif" /></p> 
 <p>VS Code: <code>tab</code> (MacOS) / <code>tab</code> (Windows)</p> 
 <p>JetBrains: <code>tab</code> (MacOS) / <code>tab</code> (Windows)</p> 
 <h2>Refactor functions where you are coding</h2> 
 <p><img alt="inline" src="https://raw.githubusercontent.com/continuedev/continue/main/docs/static/img/inline.gif" /></p> 
 <p>VS Code: <code>cmd+I</code> (MacOS) / <code>ctrl+I</code> (Windows)</p> 
 <p>JetBrains: <code>cmd+I</code> (MacOS) / <code>ctrl+I</code> (Windows)</p> 
 <h2>Ask questions about your codebase</h2> 
 <p><img alt="codebase" src="https://raw.githubusercontent.com/continuedev/continue/main/docs/static/img/codebase.gif" /></p> 
 <p>VS Code: <code>cmd+enter</code> (MacOS) / <code>ctrl+enter</code> (Windows)</p> 
 <p>JetBrains: <code>cmd+enter</code> (MacOS) / <code>ctrl+enter</code> (Windows)</p> 
 <h2>Quickly use documentation as context</h2> 
 <p><img alt="docs" src="https://raw.githubusercontent.com/continuedev/continue/main/docs/static/img/docs.gif" /></p> 
 <p>VS Code: <code>@docs</code> (MacOS) / <code>@docs</code> (Windows)</p> 
 <p>JetBrains: <code>@docs</code> (MacOS) / <code>@docs</code> (Windows)</p> 
</div> 
<h2>Getting Started</h2> 
<h3>Download for <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code</a> and <a href="https://plugins.jetbrains.com/plugin/22707-continue-extension">JetBrains</a></h3> 
<p>You can try out Continue with our free trial models before configuring your setup.</p> 
<p>Learn more about the models and providers <a href="https://continue.dev/docs/setup/overview">here</a>.</p> 
<h2>Contributing</h2> 
<p>Check out the <a href="https://github.com/orgs/continuedev/projects/2">contribution ideas board</a>, read the <a href="https://github.com/continuedev/continue/raw/main/CONTRIBUTING.md">contributing guide</a>, and join <a href="https://discord.gg/vapESyrFmJ">#contribute on Discord</a></p> 
<h2>License</h2> 
<p><a href="https://raw.githubusercontent.com/continuedev/continue/main/LICENSE">Apache 2.0 © 2023 Continue Dev, Inc.</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>bitcoin/bitcoin</title>
<link>https://github.com/bitcoin/bitcoin</link>
<guid>https://github.com/bitcoin/bitcoin</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin Core、集成/暂存树、二进制版本、MIT许可、开发过程

总结:
这篇文章主要介绍了比特币核心(Bitcoin Core)的集成/暂存树的相关信息。比特币核心是一个用于连接到比特币点对点网络以下载和完全验证区块及交易的软件，它还包括了钱包和图形用户界面。开发者可以通过遵循文档中的构建说明来构建并测试主分支，尽管该分支可能并非完全稳定。定期从发布分支创建的提交用于指示新发布的稳定版本。GUI的开发仅在单独的存储库中进行，其主分支与所有monotree仓库保持一致，不存在发布分支或标签。为了确保项目的安全性和质量，开发团队鼓励编写单元测试，并要求其他开发人员帮助测试拉取请求。此外，文章还强调了翻译工作的重要性以及如何通过Transifex进行协作。最后，文章提醒开发者，翻译变更不应作为GitHub拉取请求提交，以防下次从Transifex同步时被覆盖。 <div>
<p>Bitcoin Core integration/staging tree</p><hr /><h1>Bitcoin Core integration/staging tree</h1> 
<p><a href="https://bitcoincore.org">https://bitcoincore.org</a></p> 
<p>For an immediately usable, binary version of the Bitcoin Core software, see <a href="https://bitcoincore.org/en/download/">https://bitcoincore.org/en/download/</a>.</p> 
<h2>What is Bitcoin Core?</h2> 
<p>Bitcoin Core connects to the Bitcoin peer-to-peer network to download and fully validate blocks and transactions. It also includes a wallet and graphical user interface, which can be optionally built.</p> 
<p>Further information about Bitcoin Core is available in the <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/doc">doc folder</a>.</p> 
<h2>License</h2> 
<p>Bitcoin Core is released under the terms of the MIT license. See <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/COPYING">COPYING</a> for more information or see <a href="https://opensource.org/licenses/MIT">https://opensource.org/licenses/MIT</a>.</p> 
<h2>Development Process</h2> 
<p>The <code>master</code> branch is regularly built (see <code>doc/build-*.md</code> for instructions) and tested, but it is not guaranteed to be completely stable. <a href="https://github.com/bitcoin/bitcoin/tags">Tags</a> are created regularly from release branches to indicate new official, stable release versions of Bitcoin Core.</p> 
<p>The <a href="https://github.com/bitcoin-core/gui">https://github.com/bitcoin-core/gui</a> repository is used exclusively for the development of the GUI. Its master branch is identical in all monotree repositories. Release branches and tags do not exist, so please do not fork that repository unless it is for development reasons.</p> 
<p>The contribution workflow is described in <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/CONTRIBUTING.md">CONTRIBUTING.md</a> and useful hints for developers can be found in <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/doc/developer-notes.md">doc/developer-notes.md</a>.</p> 
<h2>Testing</h2> 
<p>Testing and code review is the bottleneck for development; we get more pull requests than we can review and test on short notice. Please be patient and help out by testing other people's pull requests, and remember this is a security-critical project where any mistake might cost people lots of money.</p> 
<h3>Automated Testing</h3> 
<p>Developers are strongly encouraged to write <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/src/test/README.md">unit tests</a> for new code, and to submit new unit tests for old code. Unit tests can be compiled and run (assuming they weren't disabled during the generation of the build system) with: <code>ctest</code>. Further details on running and extending unit tests can be found in <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/src/test/README.md">/src/test/README.md</a>.</p> 
<p>There are also <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/test">regression and integration tests</a>, written in Python. These tests can be run (if the <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/test">test dependencies</a> are installed) with: <code>test/functional/test_runner.py</code></p> 
<p>The CI (Continuous Integration) systems make sure that every pull request is built for Windows, Linux, and macOS, and that unit/sanity tests are run automatically.</p> 
<h3>Manual Quality Assurance (QA) Testing</h3> 
<p>Changes should be tested by somebody other than the developer who wrote the code. This is especially important for large or high-risk changes. It is useful to add a test plan to the pull request description if testing the changes is not straightforward.</p> 
<h2>Translations</h2> 
<p>Changes to translations as well as new translations can be submitted to <a href="https://www.transifex.com/bitcoin/bitcoin/">Bitcoin Core's Transifex page</a>.</p> 
<p>Translations are periodically pulled from Transifex and merged into the git repository. See the <a href="https://raw.githubusercontent.com/bitcoin/bitcoin/master/doc/translation_process.md">translation process</a> for details on how this works.</p> 
<p><strong>Important</strong>: We do not accept translation changes as GitHub pull requests because the next pull from Transifex would automatically overwrite them again.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>mattermost/mattermost</title>
<link>https://github.com/mattermost/mattermost</link>
<guid>https://github.com/mattermost/mattermost</guid>
<content:encoded><![CDATA[
<div> 关键词：Mattermost, 开源平台, 安全协作, 软件开发生命周期, Linux

总结：

Mattermost 是一款开源平台，专为安全协作设计，贯穿整个软件开发流程。它以 Go 和 React 语言编写，运行于单一的 Linux 二进制文件上，支持 MySQL 或 PostgreSQL 数据库。每月底都会发布一次基于 MIT 许可证的新编译版本。

使用 Mattermost 的主要优势在于提供了一个全面的协作环境，从代码审查到项目管理，再到团队沟通，覆盖了软件开发的所有阶段。用户可以通过多种方式安装和配置 Mattermost，包括 Docker、Ubuntu 以及 tar 文件。此外，还提供了原生的移动和桌面应用版本，使得跨设备协作成为可能。

为了确保安全，Mattermost 提供了订阅安全公告的服务，帮助用户及时了解关键的安全更新。社区参与也是 Mattermost 的重要组成部分，用户可以在此平台上进行代码贡献，构建集成，甚至参与讨论和发展方向。

最后，Mattermost 保持开放的社区文化，通过多种渠道如社交媒体、邮件列表、论坛和 IRC 频道与用户保持联系。对于想要参与贡献的开发者，官方文档提供了详细的指南。 <div>
<p>Mattermost is an open source platform for secure collaboration across the entire software development lifecycle..</p><hr /><h1><a href="https://mattermost.com"><img alt="Mattermost logo" src="https://user-images.githubusercontent.com/7205829/137170381-fe86eef0-bccc-4fdd-8e92-b258884ebdd7.png" /></a></h1> 
<p><a href="https://mattermost.com">Mattermost</a> is an open source platform for secure collaboration across the entire software development lifecycle. This repo is the primary source for core development on the Mattermost platform; it's written in Go and React and runs as a single Linux binary with MySQL or PostgreSQL. A new compiled version is released under an MIT license every month on the 16th.</p> 
<p><a href="https://mattermost.com/deploy/?utm_source=github-mattermost-server-readme">Deploy Mattermost on-premises</a>, or <a href="https://mattermost.com/sign-up/?utm_source=github-mattermost-server-readme">try it for free in the cloud</a>.</p> 
<img alt="mattermost user interface" src="https://user-images.githubusercontent.com/7205829/136107976-7a894c9e-290a-490d-8501-e5fdbfc3785a.png" width="1006" /> 
<p>Learn more about the following use cases with Mattermost:</p> 
<ul> 
 <li><a href="https://mattermost.com/solutions/use-cases/devops/?utm_source=github-mattermost-server-readme">DevSecOps</a></li> 
 <li><a href="https://mattermost.com/solutions/use-cases/incident-resolution/?utm_source=github-mattermost-server-readme">Incident Resolution</a></li> 
 <li><a href="https://mattermost.com/solutions/use-cases/it-service-desk/?utm_source=github-mattermost-server-readme">IT Service Desk</a></li> 
</ul> 
<p>Other useful resources:</p> 
<ul> 
 <li><a href="https://docs.mattermost.com/guides/deployment.html">Download and Install Mattermost</a> - Install, setup, and configure your own Mattermost instance.</li> 
 <li><a href="https://docs.mattermost.com/">Product documentation</a> - Learn how to run a Mattermost instance and take advantage of all the features.</li> 
 <li><a href="https://developers.mattermost.com/">Developer documentation</a> - Contribute code to Mattermost or build an integration via APIs, Webhooks, slash commands, Apps, and plugins.</li> 
</ul> 
<h1>Table of contents</h1> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#install-mattermost">Install Mattermost</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#native-mobile-and-desktop-apps">Native mobile and desktop apps</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#get-security-bulletins">Get security bulletins</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#get-involved">Get involved</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#learn-more">Learn more</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#license">License</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#get-the-latest-news">Get the latest news</a></li> 
 <li><a href="https://raw.githubusercontent.com/mattermost/mattermost/master/#contributing">Contributing</a></li> 
</ul> 
<h2>Install Mattermost</h2> 
<ul> 
 <li><a href="https://docs.mattermost.com/guides/deployment.html">Download and Install Mattermost Self-Hosted</a> - Deploy a Mattermost Self-hosted instance in minutes via Docker, Ubuntu, or tar.</li> 
 <li><a href="https://mattermost.com/sign-up/?utm_source=github-mattermost-server-readme">Get started in the cloud</a> to try Mattermost today.</li> 
 <li><a href="https://developers.mattermost.com/contribute/server/developer-setup">Developer machine setup</a> - Follow this guide if you want to write code for Mattermost.</li> 
</ul> 
<p>Other install guides:</p> 
<ul> 
 <li><a href="https://docs.mattermost.com/install/install-docker.html">Deploy Mattermost on Docker</a></li> 
 <li><a href="https://docs.mattermost.com/install/installing-mattermost-omnibus.html">Mattermost Omnibus</a></li> 
 <li><a href="https://docs.mattermost.com/install/install-tar.html">Install Mattermost from Tar</a></li> 
 <li><a href="https://docs.mattermost.com/install/installing-ubuntu-2004-LTS.html">Ubuntu 20.04 LTS</a></li> 
 <li><a href="https://docs.mattermost.com/install/install-kubernetes.html">Kubernetes</a></li> 
 <li><a href="https://docs.mattermost.com/install/install-kubernetes.html#installing-the-operators-via-helm">Helm</a></li> 
 <li><a href="https://docs.mattermost.com/install/install-debian.html">Debian Buster</a></li> 
 <li><a href="https://docs.mattermost.com/install/install-rhel-8.html">RHEL 8</a></li> 
 <li><a href="https://docs.mattermost.com/guides/deployment.html">More server install guides</a></li> 
</ul> 
<h2>Native mobile and desktop apps</h2> 
<p>In addition to the web interface, you can also download Mattermost clients for <a href="https://mattermost.com/pl/android-app/">Android</a>, <a href="https://mattermost.com/pl/ios-app/">iOS</a>, <a href="https://docs.mattermost.com/install/desktop-app-install.html#windows-10-windows-8-1">Windows PC</a>, <a href="https://docs.mattermost.com/install/desktop-app-install.html#macos-10-9">macOS</a>, and <a href="https://docs.mattermost.com/install/desktop-app-install.html#linux">Linux</a>.</p> 
<p><a href="https://mattermost.com/pl/android-app/"><img alt="Get Mattermost on Google Play" height="50px" src="https://user-images.githubusercontent.com/30978331/272826427-6200c98f-7319-42c3-86d4-0b33ae99e01a.png" /></a> <a href="https://itunes.apple.com/us/app/mattermost/id1257222717?mt=8"><img alt="Get Mattermost on the App Store" height="50px" src="https://developer.apple.com/assets/elements/badges/download-on-the-app-store.svg?sanitize=true" /></a> <a href="https://docs.mattermost.com/install/desktop.html#windows-10-windows-8-1-windows-7"><img alt="Get Mattermost on Windows PC" src="https://user-images.githubusercontent.com/33878967/33095357-39cab8d2-ceb8-11e7-89a6-67dccc571ca3.png" /></a> <a href="https://docs.mattermost.com/install/desktop.html#macos-10-9"><img alt="Get Mattermost on Mac OSX" src="https://user-images.githubusercontent.com/33878967/33095355-39a36f2a-ceb8-11e7-9b33-73d4f6d5d6c1.png" /></a> <a href="https://docs.mattermost.com/install/desktop.html#linux"><img alt="Get Mattermost on Linux" src="https://user-images.githubusercontent.com/33878967/33095354-3990e256-ceb8-11e7-965d-b00a16e578de.png" /></a></p> 
<h2>Get security bulletins</h2> 
<p>Receive notifications of critical security updates. The sophistication of online attackers is perpetually increasing. If you're deploying Mattermost it's highly recommended you subscribe to the Mattermost Security Bulletin mailing list for updates on critical security releases.</p> 
<p><a href="https://mattermost.com/security-updates/#sign-up">Subscribe here</a></p> 
<h2>Get involved</h2> 
<ul> 
 <li><a href="https://handbook.mattermost.com/contributors/contributors/ways-to-contribute">Contribute to Mattermost</a></li> 
 <li><a href="https://github.com/mattermost/mattermost-server/issues?page=1&amp;q=is%3Aissue+is%3Aopen+%22Help+Wanted%22&amp;utf8=%E2%9C%93">Find "Help Wanted" projects</a></li> 
 <li><a href="https://community.mattermost.com/signup_user_complete/?id=f1924a8db44ff3bb41c96424cdc20676">Join Developer Discussion on a Mattermost server for contributors</a></li> 
 <li><a href="https://docs.mattermost.com/guides/get-help.html">Get Help With Mattermost</a></li> 
</ul> 
<h2>Learn more</h2> 
<ul> 
 <li><a href="https://api.mattermost.com/">API options - webhooks, slash commands, drivers, and web service</a></li> 
 <li><a href="https://mattermost.com/customers/">See who's using Mattermost</a></li> 
 <li><a href="https://mattermost.com/marketplace/">Browse over 700 Mattermost integrations</a></li> 
</ul> 
<h2>License</h2> 
<p>See the <a href="https://raw.githubusercontent.com/mattermost/mattermost/master/LICENSE.txt">LICENSE file</a> for license rights and limitations.</p> 
<h2>Get the latest news</h2> 
<ul> 
 <li><strong>X</strong> - Follow <a href="https://twitter.com/mattermost">Mattermost on X, formerly Twitter</a>.</li> 
 <li><strong>Blog</strong> - Get the latest updates from the <a href="https://mattermost.com/blog/">Mattermost blog</a>.</li> 
 <li><strong>Facebook</strong> - Follow <a href="https://www.facebook.com/MattermostHQ">Mattermost on Facebook</a>.</li> 
 <li><strong>LinkedIn</strong> - Follow <a href="https://www.linkedin.com/company/mattermost/">Mattermost on LinkedIn</a>.</li> 
 <li><strong>Email</strong> - Subscribe to our <a href="https://mattermost.us11.list-manage.com/subscribe?u=6cdba22349ae374e188e7ab8e&amp;id=2add1c8034">newsletter</a> (1 or 2 per month).</li> 
 <li><strong>Mattermost</strong> - Join the ~contributors channel on <a href="https://community.mattermost.com">the Mattermost Community Server</a>.</li> 
 <li><strong>IRC</strong> - Join the #matterbridge channel on <a href="https://freenode.net/">Freenode</a> (thanks to <a href="https://github.com/42wim/matterircd">matterircd</a>).</li> 
 <li><strong>YouTube</strong> - Subscribe to <a href="https://www.youtube.com/@MattermostHQ">Mattermost</a>.</li> 
</ul> 
<h2>Contributing</h2> 
<p><a href="https://gitpod.io/#https://github.com/mattermost/mattermost"><img alt="Small Image" src="https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod" /></a></p> 
<p>Please see <a href="https://raw.githubusercontent.com/mattermost/mattermost/master/CONTRIBUTING.md">CONTRIBUTING.md</a>. <a href="https://community.mattermost.com/signup_user_complete/?id=codoy5s743rq5mk18i7u5ksz7e">Join the Mattermost Contributors server</a> to join community discussions about contributions, development, and more.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>microsoft/PowerToys</title>
<link>https://github.com/microsoft/PowerToys</link>
<guid>https://github.com/microsoft/PowerToys</guid>
<content:encoded><![CDATA[
<div> 关键词：Microsoft PowerToys、Windows系统、生产力、安装方法、功能更新

总结：

Microsoft PowerToys 是一套专为 Windows 系统的高级用户设计的实用工具，旨在通过自定义和优化工作流程来提升生产力。该工具集包括多种实用程序，如快捷键管理、图像处理、系统监控等，满足不同用户的个性化需求。

在安装方面，PowerToys 支持多种方法，包括通过 GitHub 的 EXE 安装程序、Microsoft Store 和 WinGet 命令行工具进行安装。每种方法都有其推荐的使用场景，确保用户能够根据自己的硬件架构（x64 或 ARM64）和安装偏好（用户级或系统级）选择最适合的安装方式。

在功能更新方面，PowerToys 不断迭代和添加新功能。例如，新增了 PowerToys Workspaces 工具，允许用户自定义应用程序布局并保存为工作空间，便于快速切换工作环境。此外，还引入了高级粘贴功能，支持自定义操作提示和搜索功能，增强了用户体验。同时，团队也在持续优化稳定性，修复已知问题，如应用以管理员权限运行时的位置调整问题等。

Microsoft PowerToys 团队非常重视社区反馈，鼓励用户参与开发过程，无论是提交 bug 报告、更新文档、设计指导还是编写新功能，每位贡献者都对 PowerToys 的发展起到了关键作用。团队遵循 Code of Conduct，致力于营造一个友好、包容的开发环境，并承诺保护用户的隐私，仅收集基本的使用数据以持续改进产品。 <div>
<p>Windows system utilities to maximize productivity</p><hr /><h1>Microsoft PowerToys</h1> 
<p><img alt="Hero image for Microsoft PowerToys" src="https://raw.githubusercontent.com/microsoft/PowerToys/main/doc/images/overview/PT_hero_image.png" /></p> 
<p><a href="https://aka.ms/powertoys-docs">How to use PowerToys</a> | <a href="https://aka.ms/installPowerToys">Downloads &amp; Release notes</a> | <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/#contributing">Contributing to PowerToys</a> | <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/#whats-happening">What's Happening</a> | <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/#powertoys-roadmap">Roadmap</a></p> 
<h2>Build status</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Architecture</th> 
   <th>Solution (Main)</th> 
   <th>Solution (Stable)</th> 
   <th>Installer (Main)</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>x64</td> 
   <td><a href="https://dev.azure.com/shine-oss/PowerToys/_build/latest?definitionId=3&amp;branchName=main"><img alt="Build Status for Main" src="https://dev.azure.com/shine-oss/PowerToys/_apis/build/status%2FPowerToys%20CI?branchName=main&amp;jobName=Build%20x64%20Release" /></a></td> 
   <td><a href="https://dev.azure.com/shine-oss/PowerToys/_build/latest?definitionId=3&amp;branchName=stable"><img alt="Build Status for Stable" src="https://dev.azure.com/shine-oss/PowerToys/_apis/build/status%2FPowerToys%20CI?branchName=stable&amp;jobName=Build%20x64%20Release" /></a></td> 
   <td><a href="https://dev.azure.com/microsoft/Dart/_build/latest?definitionId=76541&amp;branchName=main"><img alt="Build Status Installer pipeline" src="https://dev.azure.com/microsoft/Dart/_apis/build/status/PowerToys/PowerToys%20Signed%20YAML%20Release%20Build?branchName=main&amp;jobName=Build&amp;configuration=Build%20Release_x64" /></a></td> 
  </tr> 
  <tr> 
   <td>ARM64</td> 
   <td><a href="https://dev.azure.com/shine-oss/PowerToys/_build/latest?definitionId=3&amp;branchName=main"><img alt="Build Status for Main" src="https://dev.azure.com/shine-oss/PowerToys/_apis/build/status%2FPowerToys%20CI?branchName=main&amp;jobName=Build%20arm64%20Release" /></a></td> 
   <td><a href="https://dev.azure.com/shine-oss/PowerToys/_build/latest?definitionId=3&amp;branchName=main"><img alt="Build Status for Stable" src="https://dev.azure.com/shine-oss/PowerToys/_apis/build/status%2FPowerToys%20CI?branchName=main&amp;jobName=Build%20arm64%20Release" /></a></td> 
   <td><a href="https://dev.azure.com/microsoft/Dart/_build/latest?definitionId=76541&amp;branchName=main"><img alt="Build Status Installer pipeline" src="https://dev.azure.com/microsoft/Dart/_apis/build/status/PowerToys/PowerToys%20Signed%20YAML%20Release%20Build?branchName=main&amp;jobName=Build&amp;configuration=Build%20Release_arm64" /></a></td> 
  </tr> 
 </tbody> 
</table> 
<h2>About</h2> 
<p>Microsoft PowerToys is a set of utilities for power users to tune and streamline their Windows experience for greater productivity. For more info on <a href="https://aka.ms/powertoys-docs">PowerToys overviews and how to use the utilities</a>, or any other tools and resources for <a href="https://learn.microsoft.com/windows/dev-environment/overview">Windows development environments</a>, head over to <a href="https://aka.ms/powertoys-docs">learn.microsoft.com</a>!</p> 
<table> 
 <thead> 
  <tr> 
   <th></th> 
   <th>Current utilities:</th> 
   <th></th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_AdvancedPaste">Advanced Paste</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_AoT">Always on Top</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_Awake">PowerToys Awake</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_CmdNotFound">Command Not Found</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_ColorPicker">Color Picker</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_CropAndLock">Crop And Lock</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_EnvironmentVariables">Environment Variables</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_FancyZones">FancyZones</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_FileExplorerAddOns">File Explorer Add-ons</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_FileLocksmith">File Locksmith</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_HostsFileEditor">Hosts File Editor</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_ImageResizer">Image Resizer</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_KeyboardManager">Keyboard Manager</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_MouseUtilities">Mouse utilities</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_MouseWithoutBorders">Mouse Without Borders</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_Peek">Peek</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_PastePlain">Paste as Plain Text</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_PowerRename">PowerRename</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_PowerToysRun">PowerToys Run</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_QuickAccent">Quick Accent</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_RegistryPreview">Registry Preview</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_ScreenRuler">Screen Ruler</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_ShortcutGuide">Shortcut Guide</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_TextExtractor">Text Extractor</a></td> 
  </tr> 
  <tr> 
   <td><a href="https://aka.ms/PowerToysOverview_VideoConference">Video Conference Mute</a></td> 
   <td><a href="https://aka.ms/PowerToysOverview_Workspaces">Workspaces</a></td> 
   <td></td> 
  </tr> 
 </tbody> 
</table> 
<h2>Installing and running Microsoft PowerToys</h2> 
<h3>Requirements</h3> 
<ul> 
 <li>Windows 11 or Windows 10 version 2004 (code name 20H1 / build number 19041) or newer.</li> 
 <li>x64 or ARM64 processor</li> 
 <li>Our installer will install the following items: 
  <ul> 
   <li><a href="https://go.microsoft.com/fwlink/p/?LinkId=2124703">Microsoft Edge WebView2 Runtime</a> bootstrapper. This will install the latest version.</li> 
  </ul> </li> 
</ul> 
<h3>Via GitHub with EXE [Recommended]</h3> 
<p>Go to the <a href="https://aka.ms/installPowerToys">Microsoft PowerToys GitHub releases page</a> and click on <code>Assets</code> at the bottom to show the files available in the release. Please use the appropriate PowerToys installer that matches your machine's architecture and install scope. For most, it is <code>x64</code> and per-user.</p> 
<!-- items that need to be updated release to release --> 
<table> 
 <thead> 
  <tr> 
   <th>Description</th> 
   <th>Filename</th> 
   <th>sha256 hash</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>Per user - x64</td> 
   <td><a href="https://github.com/microsoft/PowerToys/releases/download/v0.84.0/PowerToysUserSetup-0.84.0-x64.exe">PowerToysUserSetup-0.84.0-x64.exe</a></td> 
   <td>6792180D697ED9FDF9AA7B3F0AB92767CF4C79B526715C802F545E2DCB201BE3</td> 
  </tr> 
  <tr> 
   <td>Per user - ARM64</td> 
   <td><a href="https://github.com/microsoft/PowerToys/releases/download/v0.84.0/PowerToysUserSetup-0.84.0-arm64.exe">PowerToysUserSetup-0.84.0-arm64.exe</a></td> 
   <td>3D071F009B5E3DBAD21D7450ADB53CBC85CAFB21016E44F414E2A03C188D2FAF</td> 
  </tr> 
  <tr> 
   <td>Machine wide - x64</td> 
   <td><a href="https://github.com/microsoft/PowerToys/releases/download/v0.84.0/PowerToysSetup-0.84.0-x64.exe">PowerToysSetup-0.84.0-x64.exe</a></td> 
   <td>67B7E685AAF635803A87D8EE96CA1AF5024910B0BF00A9277CD77C810D049446</td> 
  </tr> 
  <tr> 
   <td>Machine wide - ARM64</td> 
   <td><a href="https://github.com/microsoft/PowerToys/releases/download/v0.84.0/PowerToysSetup-0.84.0-arm64.exe">PowerToysSetup-0.84.0-arm64.exe</a></td> 
   <td>259DA1EFB33A616CF64840B8D8AB84F86A43F61687578B43849D5DE11F77AF82</td> 
  </tr> 
 </tbody> 
</table> 
<p>This is our preferred method.</p> 
<h3>Via Microsoft Store</h3> 
<p>Install from the <a href="https://aka.ms/getPowertoys">Microsoft Store's PowerToys page</a>. You must be using the <a href="https://blogs.windows.com/windowsExperience/2021/06/24/building-a-new-open-microsoft-store-on-windows-11/">new Microsoft Store</a> which is available for both Windows 11 and Windows 10.</p> 
<h3>Via WinGet</h3> 
<p>Download PowerToys from <a href="https://github.com/microsoft/winget-cli#installing-the-client">WinGet</a>. Updating PowerToys via winget will respect current PowerToys installation scope. To install PowerToys, run the following command from the command line / PowerShell:</p> 
<h4>User scope installer [default]</h4> 
<pre><code class="language-powershell">winget install Microsoft.PowerToys -s winget
</code></pre> 
<h4>Machine-wide scope installer</h4> 
<pre><code class="language-powershell">winget install --scope machine Microsoft.PowerToys -s winget
</code></pre> 
<h3>Other install methods</h3> 
<p>There are <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/doc/unofficialInstallMethods.md">community driven install methods</a> such as Chocolatey and Scoop. If these are your preferred install solutions, you can find the install instructions there.</p> 
<h2>Third-Party Run Plugins</h2> 
<p>There is a collection of <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/doc/thirdPartyRunPlugins.md">third-party plugins</a> created by the community that aren't distributed with PowerToys.</p> 
<h2>Contributing</h2> 
<p>This project welcomes contributions of all types. Besides coding features / bug fixes, other ways to assist include spec writing, design, documentation, and finding bugs. We are excited to work with the power user community to build a set of tools for helping you get the most out of Windows.</p> 
<p>We ask that <strong>before you start work on a feature that you would like to contribute</strong>, please read our <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/CONTRIBUTING.md">Contributor's Guide</a>. We would be happy to work with you to figure out the best approach, provide guidance and mentorship throughout feature development, and help avoid any wasted or duplicate effort.</p> 
<p>Most contributions require you to agree to a <a href="https://cla.opensource.microsoft.com">Contributor License Agreement (CLA)</a> declaring that you grant us the rights to use your contribution and that you have permission to do so.</p> 
<p>For guidance on developing for PowerToys, please read the <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/doc/devdocs">developer docs</a> for a detailed breakdown. This includes how to setup your computer to compile.</p> 
<h2>What's Happening</h2> 
<h3>PowerToys Roadmap</h3> 
<p>Our <a href="https://github.com/microsoft/PowerToys/wiki/Roadmap">prioritized roadmap</a> of features and utilities that the core team is focusing on.</p> 
<h3>0.84 - August 2024 Update</h3> 
<p>In this release, we focused on adding a new utility (PowerToys Workspaces), Advanced paste custom actions feature, stability, and improvements.</p> 
<p><strong>Highlights</strong></p> 
<ul> 
 <li>New utility: PowerToys Workspaces - this utility can launch a set of applications to a custom layout and configuration on the desktop. App arrangements can be saved as a workspace and then relaunched with one click from the Workspaces Editor or from a desktop shortcut. In the editor, app configuration can be customized using CLI arguments and "launch as admin" modifiers, and app window sizes and positions can be updated as desired. This is our first public version of Workspaces and we are excited for you to try it out for yourself! Make sure to file issues you encounter on our GitHub so the team can continue to improve the utility. 
  <ul> 
   <li>Known issues - the team is actively working on fixing these: 
    <ul> 
     <li>Apps that launch as admin are unable to be repositioned to the desired layout.</li> 
     <li>Border of "Remove" / "Add Back" app button in editor is not clearly visible on light themes.</li> 
    </ul> </li> 
  </ul> </li> 
 <li>Added Awake --use-parent-pid CLI argument to attach to parent process. Thanks <a href="https://github.com/dend">@dend</a>!</li> 
 <li>Added custom actions - user-specified pre-defined prompts for the AI model. Additionally, actions (both standard and custom) are now searchable from prompt box and Ctrl + number in-app shortcuts are now applicable for first 9 search results.</li> 
 <li>Ported all C++/CX code to C++/WinRT as part of a refactor and upgrade series aimed at enabling AOT (Ahead of Time) compilation for enhanced performance and reduced disk footprint.</li> 
</ul> 
<h3>General</h3> 
<ul> 
 <li>Added DSC support for ImageResizer resize sizes property.</li> 
</ul> 
<h3>Advanced Paste</h3> 
<ul> 
 <li>Added custom actions - user-specified pre-defined prompts for the AI model. Additionally, actions (both standard and custom) are now searchable from prompt box and Ctrl + number in-app shortcuts are now applicable for first 9 search results.</li> 
</ul> 
<h3>Awake</h3> 
<ul> 
 <li>Added --use-parent-pid CLI argument to attach to parent process and fixed issue causing tray icon to disappear. Thanks <a href="https://github.com/dend">@dend</a>!</li> 
</ul> 
<h3>Hosts File Editor</h3> 
<ul> 
 <li>Fixed save failure when the hosts file is hidden. Thanks <a href="https://github.com/davidegiacometti">@davidegiacometti</a>!</li> 
</ul> 
<h3>File Explorer add-ons</h3> 
<ul> 
 <li>Fixed multiple preview form positioning issues causing floating, detached windows, CoreWebView2 related exception and process leak. Thanks <a href="https://github.com/davidegiacometti">@davidegiacometti</a>!</li> 
</ul> 
<h3>Keyboard Manager</h3> 
<ul> 
 <li>Convert RemapBufferRow to a struct with descriptive field names. Thanks <a href="https://github.com/masaru-iritani">@masaru-iritani</a>!</li> 
 <li>Fixed issue causing stuck Ctrl key when shortcuts contain AltGr key.</li> 
</ul> 
<h3>Peek</h3> 
<ul> 
 <li>Added long paths support. Thanks <a href="https://github.com/davidegiacometti">@davidegiacometti</a>!</li> 
</ul> 
<h3>Quick Accent</h3> 
<ul> 
 <li>Moved number superscripts and subscripts from Portuguese to all languages definition. Thanks <a href="https://github.com/octastylos-pseudodipteros">@octastylos-pseudodipteros</a>!</li> 
</ul> 
<h3>PowerRename</h3> 
<ul> 
 <li>Updated the tooltip text of the replace box info button. Thanks <a href="https://github.com/Agnibaan">@Agnibaan</a>!</li> 
</ul> 
<h3>PowerToys Run</h3> 
<ul> 
 <li>Fixed window positioning on start-up introduced in 0.83.</li> 
 <li>Improved default web browser detection. Thanks <a href="https://github.com/davidegiacometti">@davidegiacometti</a>!</li> 
 <li>Fixed volume ounces conversion to support both imperial and metric. Thanks <a href="https://github.com/GhostVaibhav">@GhostVaibhav</a>!</li> 
 <li>Fixed thread-safety issue causing results not to be shown on first launch.</li> 
</ul> 
<h3>Screen Ruler</h3> 
<ul> 
 <li>Added multiple measurements support for all measuring tools.</li> 
</ul> 
<h3>Settings</h3> 
<ul> 
 <li>Improved disabled animations InfoBar in Find My Mouse page. Thanks <a href="https://github.com/davidegiacometti">@davidegiacometti</a>!</li> 
</ul> 
<h3>Workspaces</h3> 
<ul> 
 <li>New utility: PowerToys Workspaces - this utility can launch a set of applications to a custom layout and configuration on the desktop. App arrangements can be saved as a workspace and then relaunched with one click from the Workspaces Editor or from a desktop shortcut. In the editor, app configuration can be customized using CLI arguments and "launch as admin" modifiers, and app window sizes and positions can be updated as desired. This is our first public version of Workspaces and we are excited for you to try it out for yourself! Make sure to file issues you encounter on our GitHub so the team can continue to improve the utility.</li> 
</ul> 
<h3>Documentation</h3> 
<ul> 
 <li>Added ChatGPTPowerToys plugin mention to thirdPartyRunPlugins.md. Thanks <a href="https://github.com/ferraridavide">@ferraridavide</a>!</li> 
</ul> 
<h3>Development</h3> 
<ul> 
 <li>Ported all C++/CX code to C++/WinRT.</li> 
 <li>Moved Version.props import to Directory.Build.props.</li> 
 <li>Extracted self-containment related .csproj properties to src/Common.SelfContained.props.</li> 
 <li>Unused and obsolete dependencies cleanup. Thanks <a href="https://github.com/davidegiacometti">@davidegiacometti</a>!</li> 
 <li>Extracted CSWinRT related .csproj properties to src/Common.Dotnet.CsWinRT.props.</li> 
 <li>Upgraded Microsoft.Windows.CsWinRT to 2.0.8 and updated verifyDepsJsonLibraryVersions.ps1 to unblock PRs.</li> 
 <li>Explicitly Set NuGet Audit Mode to Direct in Directory.Build.props to revert changes made with VS 17.12 update. Thanks <a href="https://github.com/snickler">@snickler</a>!</li> 
 <li>Upgraded UnitsNet to 5.56.0.</li> 
</ul> 
<h4>What is being planned for version 0.84</h4> 
<p>For <a href="https://github.com/microsoft/PowerToys/issues?q=is%3Aissue+milestone%3A%22PowerToys+0.85%22">v0.85</a>, we'll work on the items below:</p> 
<ul> 
 <li>Stability / bug fixes</li> 
 <li>Language selection</li> 
 <li>New module: File Actions Menu</li> 
 <li>New module: New+</li> 
</ul> 
<h2>PowerToys Community</h2> 
<p>The PowerToys team is extremely grateful to have the <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/COMMUNITY.md">support of an amazing active community</a>. The work you do is incredibly important. PowerToys wouldn’t be nearly what it is today without your help filing bugs, updating documentation, guiding the design, or writing features. We want to say thank you and take time to recognize your work. Month by month, you directly help make PowerToys a better piece of software.</p> 
<h2>Code of Conduct</h2> 
<p>This project has adopted the <a href="https://raw.githubusercontent.com/microsoft/PowerToys/main/CODE_OF_CONDUCT.md">Microsoft Open Source Code of Conduct</a>.</p> 
<h2>Privacy Statement</h2> 
<p>The application logs basic telemetry. Our Telemetry Data page (Coming Soon) has the trends from the telemetry. Please read the <a href="http://go.microsoft.com/fwlink/?LinkId=521839">Microsoft privacy statement</a> for more information.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>bluesky-social/social-app</title>
<link>https://github.com/bluesky-social/social-app</link>
<guid>https://github.com/bluesky-social/social-app</guid>
<content:encoded><![CDATA[
<div> 关键词：Bluesky Social、Web、iOS、Android、贡献

总结：
Bluesky Social 是一个跨平台的社交应用，支持 Web、iOS 和 Android 设备。它基于 TypeScript 编写，构建在 atproto 协议之上，该协议是一个去中心化的社交媒体协议。开发者可以访问 Web 服务源代码，通过 React Native Web 技术构建应用界面。项目提供了一套名为“Lexicons”的命名空间，用于描述应用程序的结构和交互方式。

为了参与项目的开发和贡献，开发者需遵循一定的规则和指南。这些包括不响应或快速关闭无反馈的问题与拉取请求，以及限制对代码库的大规模重构或未经讨论的新功能添加。鼓励提交简洁且解决具体问题的高质量拉取请求，以提高审查效率。如果开发者希望为项目做出贡献，被鼓励fork项目，但需明确告知用户其版本与原版的区别，并更改所有品牌标识、支持链接和分析系统，确保与原版保持清晰区分。

对于发现的安全问题，应直接联系安全团队进行报告，确保问题得到及时处理。Bluesky 社区欢迎开发者利用 atproto 协议构建在 Bluesky 社交网络之上的应用和服务，同时强调了开发者社区在构建开放社交生态系统中的重要性。项目采用 MIT 许可证，允许自由使用和修改。最后，社区对所有参与者的贡献表示感谢。 <div>
<p>The Bluesky Social application for Web, iOS, and Android</p><hr /><h1>Bluesky Social App</h1> 
<p>Welcome friends! This is the codebase for the Bluesky Social app.</p> 
<p>Get the app itself:</p> 
<ul> 
 <li><strong>Web: <a href="https://bsky.app">bsky.app</a></strong></li> 
 <li><strong>iOS: <a href="https://apps.apple.com/us/app/bluesky-social/id6444370199">App Store</a></strong></li> 
 <li><strong>Android: <a href="https://play.google.com/store/apps/details?id=xyz.blueskyweb.app">Play Store</a></strong></li> 
</ul> 
<h2>Development Resources</h2> 
<p>This is a <a href="https://reactnative.dev/">React Native</a> application, written in the TypeScript programming language. It builds on the <code>atproto</code> TypeScript packages (like <a href="https://www.npmjs.com/package/@atproto/api"><code>@atproto/api</code></a>), code for which is also open source, but in <a href="https://github.com/bluesky-social/atproto">a different git repository</a>.</p> 
<p>There is a small amount of Go language source code (in <code>./bskyweb/</code>), for a web service that returns the React Native Web application.</p> 
<p>The <a href="https://raw.githubusercontent.com/bluesky-social/social-app/main/docs/build.md">Build Instructions</a> are a good place to get started with the app itself.</p> 
<p>The Authenticated Transfer Protocol ("AT Protocol" or "atproto") is a decentralized social media protocol. You don't <em>need</em> to understand AT Protocol to work with this application, but it can help. Learn more at:</p> 
<ul> 
 <li><a href="https://atproto.com/guides/overview">Overview and Guides</a></li> 
 <li><a href="https://github.com/bluesky-social/atproto/discussions">Github Discussions</a> 👈 Great place to ask questions</li> 
 <li><a href="https://atproto.com/specs/atp">Protocol Specifications</a></li> 
 <li><a href="https://bsky.social/about/blog/3-6-2022-a-self-authenticating-social-protocol">Blogpost on self-authenticating data structures</a></li> 
</ul> 
<p>The Bluesky Social application encompasses a set of schemas and APIs built in the overall AT Protocol framework. The namespace for these "Lexicons" is <code>app.bsky.*</code>.</p> 
<h2>Contributions</h2> 
<blockquote> 
 <p>While we do accept contributions, we prioritize high quality issues and pull requests. Adhering to the below guidelines will ensure a more timely review.</p> 
</blockquote> 
<p><strong>Rules:</strong></p> 
<ul> 
 <li>We may not respond to your issue or PR.</li> 
 <li>We may close an issue or PR without much feedback.</li> 
 <li>We may lock discussions or contributions if our attention is getting DDOSed.</li> 
 <li>We're not going to provide support for build issues.</li> 
</ul> 
<p><strong>Guidelines:</strong></p> 
<ul> 
 <li>Check for existing issues before filing a new one please.</li> 
 <li>Open an issue and give some time for discussion before submitting a PR.</li> 
 <li>Stay away from PRs like... 
  <ul> 
   <li>Changing "Post" to "Skeet."</li> 
   <li>Refactoring the codebase, e.g., to replace MobX with Redux or something.</li> 
   <li>Adding entirely new features without prior discussion.</li> 
  </ul> </li> 
</ul> 
<p>Remember, we serve a wide community of users. Our day-to-day involves us constantly asking "which top priority is our top priority." If you submit well-written PRs that solve problems concisely, that's an awesome contribution. Otherwise, as much as we'd love to accept your ideas and contributions, we really don't have the bandwidth. That's what forking is for!</p> 
<h2>Forking guidelines</h2> 
<p>You have our blessing 🪄✨ to fork this application! However, it's very important to be clear to users when you're giving them a fork.</p> 
<p>Please be sure to:</p> 
<ul> 
 <li>Change all branding in the repository and UI to clearly differentiate from Bluesky.</li> 
 <li>Change any support links (feedback, email, terms of service, etc) to your own systems.</li> 
 <li>Replace any analytics or error-collection systems with your own so we don't get super confused.</li> 
</ul> 
<h2>Security disclosures</h2> 
<p>If you discover any security issues, please send an email to <a href="mailto:security@bsky.app">security@bsky.app</a>. The email is automatically CCed to the entire team and we'll respond promptly.</p> 
<h2>Are you a developer interested in building on atproto?</h2> 
<p>Bluesky is an open social network built on the AT Protocol, a flexible technology that will never lock developers out of the ecosystems that they help build. With atproto, third-party integration can be as seamless as first-party through custom feeds, federated services, clients, and more.</p> 
<h2>License (MIT)</h2> 
<p>See <a href="https://raw.githubusercontent.com/bluesky-social/social-app/main/LICENSE">./LICENSE</a> for the full license.</p> 
<h2>P.S.</h2> 
<p>We ❤️ you and all of the ways you support us. Thank you for making Bluesky a great place!</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Zeyi-Lin/HivisionIDPhotos</title>
<link>https://github.com/Zeyi-Lin/HivisionIDPhotos</link>
<guid>https://github.com/Zeyi-Lin/HivisionIDPhotos</guid>
<content:encoded><![CDATA[
<div> 关键词：HivisionIDPhotos, AI, 证件照, 扣图, API

总结:
HivisionIDPhotos是一个专注于开发轻量级AI证件照制作算法的项目。其核心功能包括人像抠图、根据不同尺寸生成标准证件照及六寸排版照，支持离线或端云推理模式。项目通过集成多种AI模型，实现了高效的人脸检测、抠图与照片处理，满足了用户对于快速制作高质量证件照的需求。此外，HivisionIDPhotos还提供了API接口，方便开发者和企业集成到自己的应用中，进一步扩展了其应用场景。通过不断更新和优化模型，项目持续提升用户体验和效果，为用户提供更加便捷和专业的证件照制作解决方案。 <div>
<p>⚡️HivisionIDPhotos: a lightweight and efficient AI ID photos tools. 一个轻量级的AI证件照制作算法。</p><hr /><div align="center"> 
 <img alt="hivision_logo" height="120" src="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/assets/hivision_logo.png" width="120" /> 
 <h1>HivisionIDPhoto</h1> 
 <p><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/README_EN.md">English</a> / 中文 / <a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/README_JP.md">日本語</a> / <a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/README_KO.md">한국어</a></p> 
 <p><a href="https://github.com/zeyi-lin/hivisionidphotos/releases"><img alt="" src="https://img.shields.io/github/v/release/zeyi-lin/hivisionidphotos?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square" /></a> <a href="https://hub.docker.com/r/linzeyi/hivision_idphotos/tags"><img alt="" src="https://img.shields.io/docker/v/linzeyi/hivision_idphotos?color=369eff&amp;label=docker&amp;labelColor=black&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://github.com/zeyi-lin/hivisionidphotos/stargazers"><img alt="" src="https://img.shields.io/github/stars/zeyi-lin/hivisionidphotos?color=ffcb47&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/zeyi-lin/hivisionidphotos/issues"><img alt="" src="https://img.shields.io/github/issues/zeyi-lin/hivisionidphotos?color=ff80eb&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/zeyi-lin/hivisionidphotos/graphs/contributors"><img alt="" src="https://img.shields.io/github/contributors/zeyi-lin/hivisionidphotos?color=c4f042&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/zeyi-lin/hivisionidphotos/network/members"><img alt="" src="https://img.shields.io/github/forks/zeyi-lin/hivisionidphotos?color=8ae8ff&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/raw/master/LICENSE"><img alt="" src="https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&amp;style=flat-square" /></a><br /> <a href="https://docs.qq.com/doc/DUkpBdk90eWZFS2JW"><img alt="" src="https://img.shields.io/badge/WeChat-%E5%BE%AE%E4%BF%A1-4cb55e" /></a> <a href="https://huggingface.co/spaces/TheEeeeLin/HivisionIDPhotos"><img alt="" src="https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue" /></a> <a href="https://swanhub.co/ZeYiLin/HivisionIDPhotos/demo"><img alt="" src="https://swanhub.co/git/repo/SwanHub%2FAuto-README/file/preview?ref=main&amp;path=swanhub.svg?sanitize=true" /></a></p> 
 <p><a href="https://trendshift.io/repositories/11622"><img alt="" src="https://trendshift.io/api/badge/repositories/11622" /></a> <a href="https://hellogithub.com/repository/8ea1457289fb4062ba661e5299e733d6"><img alt="" src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=8ea1457289fb4062ba661e5299e733d6&amp;claim_uid=Oh5UaGjfrblg0yZ" /></a></p> 
 <img src="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/assets/demoImage.png" width="900" /> 
</div> 
<br /> 
<blockquote> 
 <p><strong>相关项目</strong>：</p> 
 <ul> 
  <li><a href="https://github.com/SwanHubX/SwanLab">SwanLab</a>：训练人像抠图模型全程用它来分析和监控，以及和实验室同学协作交流，大幅提升了训练效率。</li> 
 </ul> 
</blockquote> 
<br /> 
<h1>目录</h1> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-%E9%A1%B9%E7%9B%AE%E6%9B%B4%E6%96%B0">项目更新</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#overview">Overview</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">准备工作</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-%E8%BF%90%E8%A1%8C-gradio-demo">Demo启动</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-python-%E6%8E%A8%E7%90%86">Python推理</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#%EF%B8%8F-%E9%83%A8%E7%BD%B2-api-%E6%9C%8D%E5%8A%A1">API服务部署</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-docker-%E9%83%A8%E7%BD%B2">Docker部署</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5">友情链接</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#-%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">联系我们</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/#%E8%B4%A1%E7%8C%AE%E8%80%85">贡献者</a></li> 
</ul> 
<br /> 
<h1>🤩 项目更新</h1> 
<ul> 
 <li> <p>在线体验： <a href="https://swanhub.co/ZeYiLin/HivisionIDPhotos/demo"><img alt="SwanHub Demo" src="https://img.shields.io/static/v1?label=Demo&amp;message=SwanHub%20Demo&amp;color=blue" /></a>、<a href="https://huggingface.co/spaces/TheEeeeLin/HivisionIDPhotos"><img alt="Spaces" src="https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue" /></a></p> </li> 
 <li> <p>2024.09.08: 增加新的抠图模型 <a href="https://huggingface.co/briaai/RMBG-1.4">RMBG-1.4</a></p> </li> 
 <li> <p>2024.09.07: 增加<strong>人脸检测API选项</strong> <a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/face++_CN.md">Face++</a>，实现更高精度的人脸检测</p> </li> 
 <li> <p>2024.09.06: 增加新的抠图模型 <a href="https://github.com/ZHKKKe/MODNet">modnet_photographic_portrait_matting.onnx</a></p> </li> 
 <li> <p>2024.09.05: 更新 <a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/api_CN.md">Restful API 文档</a></p> </li> 
 <li> <p>2024.09.02: 更新<strong>调整照片 KB 大小</strong>，<a href="https://hub.docker.com/r/linzeyi/hivision_idphotos/tags">DockerHub</a></p> </li> 
 <li> <p>2023.12.01: 更新<strong>API 部署（基于 fastapi）</strong></p> </li> 
 <li> <p>2023.06.20: 更新<strong>预设尺寸菜单</strong></p> </li> 
</ul> 
<h1>Overview</h1> 
<blockquote> 
 <p>🚀 谢谢你对我们的工作感兴趣。您可能还想查看我们在图像领域的其他成果，欢迎来信:<a href="mailto:zeyi.lin@swanhub.co">zeyi.lin@swanhub.co</a>.</p> 
</blockquote> 
<p>HivisionIDPhoto 旨在开发一种实用、系统性的证件照智能制作算法。</p> 
<p>它利用一套完善的AI模型工作流程，实现对多种用户拍照场景的识别、抠图与证件照生成。</p> 
<p><strong>HivisionIDPhoto 可以做到：</strong></p> 
<ol> 
 <li>轻量级抠图（纯离线，仅需 <strong>CPU</strong> 即可快速推理）</li> 
 <li>根据不同尺寸规格生成不同的标准证件照、六寸排版照</li> 
 <li>支持 纯离线 或 端云 推理</li> 
 <li>美颜（waiting）</li> 
 <li>智能换正装（waiting）</li> 
</ol> 
<div align="center"> 
 <img src="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/assets/harry.png" width="900" /> 
</div> 
<!-- <div align="center">
<img src="assets/gradio-image.jpeg" width=900>
</div> --> 
<hr /> 
<p>如果 HivisionIDPhoto 对你有帮助，请 star 这个 repo 或推荐给你的朋友，解决证件照应急制作问题！</p> 
<br /> 
<h1>🔧 准备工作</h1> 
<p>环境安装与依赖：</p> 
<ul> 
 <li>Python &gt;= 3.7（项目主要测试在 python 3.10）</li> 
 <li>OS: Linux, Windows, MacOS</li> 
</ul> 
<h2>1. 克隆项目</h2> 
<pre><code class="language-bash">git clone https://github.com/Zeyi-Lin/HivisionIDPhotos.git
cd  HivisionIDPhotos
</code></pre> 
<h2>2. 安装依赖环境</h2> 
<blockquote> 
 <p>建议 conda 创建一个 python3.10 虚拟环境后，执行以下命令</p> 
</blockquote> 
<pre><code class="language-bash">pip install -r requirements.txt
pip install -r requirements-app.txt
</code></pre> 
<h2>3. 下载权重文件</h2> 
<p><strong>方式一：脚本下载</strong></p> 
<pre><code class="language-bash">python scripts/download_model.py
</code></pre> 
<p><strong>方式二：直接下载</strong></p> 
<p>存到项目的<code>hivision/creator/weights</code>目录下：</p> 
<ul> 
 <li><code>modnet_photographic_portrait_matting.onnx</code> (24.7MB): <a href="https://github.com/ZHKKKe/MODNet">MODNet</a>官方权重，<a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/modnet_photographic_portrait_matting.onnx">下载</a></li> 
 <li><code>hivision_modnet.onnx</code> (24.7MB): 对纯色换底适配性更好的抠图模型，<a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/hivision_modnet.onnx">下载</a></li> 
 <li><code>mnn_hivision_modnet.mnn</code> (24.7MB): mnn转换后的抠图模型 by <a href="https://github.com/zjkhahah">zjkhahah</a>，<a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/mnn_hivision_modnet.mnn">下载</a></li> 
 <li><code>rmbg-1.4.onnx</code> (176.2MB): <a href="https://huggingface.co/briaai/RMBG-1.4">BRIA AI</a> 开源的抠图模型，<a href="https://huggingface.co/briaai/RMBG-1.4/resolve/main/model.pth?download=true">下载</a>后重命名为<code>rmbg-1.4.onnx</code></li> 
</ul> 
<h2>4. 人脸检测模型配置</h2> 
<blockquote> 
 <p>这是一个可选项</p> 
</blockquote> 
<table> 
 <thead> 
  <tr> 
   <th>拓展人脸检测模型</th> 
   <th>介绍</th> 
   <th>使用文档</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>MTCNN</td> 
   <td><strong>离线</strong>人脸检测模型，高性能CPU推理，为默认模型，检测精度较低</td> 
   <td>Clone此项目后直接使用</td> 
  </tr> 
  <tr> 
   <td>Face++</td> 
   <td>旷视推出的在线人脸检测API，检测精度较高，<a href="https://console.faceplusplus.com.cn/documents/4888373">官方文档</a></td> 
   <td><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/face++_CN.md">使用文档</a></td> 
  </tr> 
 </tbody> 
</table> 
<br /> 
<h1>🚀 运行 Gradio Demo</h1> 
<pre><code class="language-bash">python app.py
</code></pre> 
<p>运行程序将生成一个本地 Web 页面，在页面中可完成证件照的操作与交互。</p> 
<br /> 
<h1>🚀 Python 推理</h1> 
<p>核心参数：</p> 
<ul> 
 <li><code>-i</code>: 输入图像路径</li> 
 <li><code>-o</code>: 保存图像路径</li> 
 <li><code>-t</code>: 推理类型，有idphoto、human_matting、add_background、generate_layout_photos可选</li> 
 <li><code>--matting_model</code>: 人像抠图模型权重选择，可选<code>hivision_modnet</code>、<code>modnet_photographic_portrait_matting</code></li> 
 <li><code>--face_detect_model</code>: 人脸检测模型选择，可选<code>mtcnn</code>、<code>face_plusplus</code></li> 
</ul> 
<p>更多参数可通过<code>python inference.py --help</code>查看</p> 
<h2>1. 证件照制作</h2> 
<p>输入 1 张照片，获得 1 张标准证件照和 1 张高清证件照的 4 通道透明 png</p> 
<pre><code class="language-python">python inference.py -i demo/images/test.jpg -o ./idphoto.png --height 413 --width 295
</code></pre> 
<h2>2. 人像抠图</h2> 
<pre><code class="language-python">python inference.py -t human_matting -i demo/images/test.jpg -o ./idphoto_matting.png --matting_model hivision_modnet
</code></pre> 
<h2>3. 透明图增加底色</h2> 
<p>输入 1 张 4 通道透明 png，获得 1 张增加了底色的图像）</p> 
<pre><code class="language-python">python inference.py -t add_background -i ./idphoto.png -o ./idphoto_ab.jpg  -c 4f83ce -k 30 -r 1
</code></pre> 
<h2>4. 得到六寸排版照</h2> 
<p>输入 1 张 3 通道照片，获得 1 张六寸排版照</p> 
<pre><code class="language-python">python inference.py -t generate_layout_photos -i ./idphoto_ab.jpg -o ./idphoto_layout.jpg  --height 413 --width 295 -k 200
</code></pre> 
<br /> 
<h1>⚡️ 部署 API 服务</h1> 
<h2>启动后端</h2> 
<pre><code>python deploy_api.py
</code></pre> 
<h2>请求 API 服务</h2> 
<p>详细请求方式请参考 <a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/api_CN.md">API 文档</a>，包含以下请求示例：</p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/api_CN.md#curl-%E8%AF%B7%E6%B1%82%E7%A4%BA%E4%BE%8B">cURL</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/api_CN.md#python-%E8%AF%B7%E6%B1%82%E7%A4%BA%E4%BE%8B">Python</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/api_CN.md#java-%E8%AF%B7%E6%B1%82%E7%A4%BA%E4%BE%8B">Java</a></li> 
 <li><a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/docs/api_CN.md#javascript-%E8%AF%B7%E6%B1%82%E7%A4%BA%E4%BE%8B">Javascript</a></li> 
</ul> 
<br /> 
<h1>🐳 Docker 部署</h1> 
<h2>1. 拉取或构建镜像</h2> 
<blockquote> 
 <p>以下方式三选一</p> 
</blockquote> 
<p><strong>方式一：拉取最新镜像：</strong></p> 
<pre><code class="language-bash">docker pull linzeyi/hivision_idphotos
</code></pre> 
<p><strong>方式二：Dockrfile 直接构建镜像：</strong></p> 
<p>在确保将模型权重文件<a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/tag/pretrained-model">hivision_modnet.onnx</a>放到<code>hivision/creator/weights</code>下后，在项目根目录执行：</p> 
<pre><code class="language-bash">docker build -t linzeyi/hivision_idphotos .
</code></pre> 
<p><strong>方式三：Docker compose 构建：</strong></p> 
<p>确保将模型权重文件 <a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/tag/pretrained-model">hivision_modnet.onnx</a> 放在<code>hivision/creator/weights</code>下后，在项目根目录下执行：</p> 
<pre><code class="language-bash">docker compose build
</code></pre> 
<h2>2. 运行服务</h2> 
<p><strong>启动 Gradio Demo 服务</strong></p> 
<p>运行下面的命令，在你的本地访问 <a href="http://127.0.0.1:7860/">http://127.0.0.1:7860</a> 即可使用。</p> 
<pre><code class="language-bash">docker run -d -p 7860:7860 linzeyi/hivision_idphotos
</code></pre> 
<p><strong>启动 API 后端服务</strong></p> 
<pre><code class="language-bash">docker run -d -p 8080:8080 linzeyi/hivision_idphotos python3 deploy_api.py
</code></pre> 
<p><strong>两个服务同时启动</strong></p> 
<pre><code class="language-bash">docker compose up -d
</code></pre> 
<h2>环境变量</h2> 
<p>本项目提供了一些额外的配置项，使用环境变量进行设置：</p> 
<table> 
 <thead> 
  <tr> 
   <th>环境变量</th> 
   <th>类型</th> 
   <th>描述</th> 
   <th>示例</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>FACE_PLUS_API_KEY</td> 
   <td>可选</td> 
   <td>这是你在 Face++ 控制台申请的 API 密钥</td> 
   <td><code>7-fZStDJ····</code></td> 
  </tr> 
  <tr> 
   <td>FACE_PLUS_API_SECRET</td> 
   <td>可选</td> 
   <td>Face++ API密钥对应的Secret</td> 
   <td><code>VTee824E····</code></td> 
  </tr> 
 </tbody> 
</table> 
<p>docker使用环境变量示例：</p> 
<pre><code class="language-bash">docker run  -d -p 7860:7860 \
    -e FACE_PLUS_API_KEY=7-fZStDJ···· \
    -e FACE_PLUS_API_SECRET=VTee824E···· \
    linzeyi/hivision_idphotos 
</code></pre> 
<br /> 
<h1>🌲 友情链接</h1> 
<ul> 
 <li><a href="https://github.com/zhaoyun0071/HivisionIDPhotos-windows-GUI">HivisionIDPhotos-windows-GUI</a></li> 
</ul> 
<br /> 
<h1>📖 引用项目</h1> 
<ol> 
 <li>MTCNN:</li> 
</ol> 
<pre><code class="language-bibtex">@software{ipazc_mtcnn_2021,
    author = {ipazc},
    title = {{MTCNN}},
    url = {https://github.com/ipazc/mtcnn},
    year = {2021},
    publisher = {GitHub}
}
</code></pre> 
<ol start="2"> 
 <li>ModNet:</li> 
</ol> 
<pre><code class="language-bibtex">@software{zhkkke_modnet_2021,
    author = {ZHKKKe},
    title = {{ModNet}},
    url = {https://github.com/ZHKKKe/MODNet},
    year = {2021},
    publisher = {GitHub}
}
</code></pre> 
<br /> 
<h1>💻 开发小贴士</h1> 
<p><strong>1. 如何修改预设尺寸？</strong></p> 
<p>修改<a href="https://raw.githubusercontent.com/Zeyi-Lin/HivisionIDPhotos/master/demo/size_list_CN.csv">size_list_CN.csv</a>后再次运行 <code>app.py</code> 即可，其中第一列为尺寸名，第二列为高度，第三列为宽度。</p> 
<br /> 
<h1>📧 联系我们</h1> 
<p>如果您有任何问题，请发邮件至 <a href="mailto:zeyi.lin@swanhub.co">zeyi.lin@swanhub.co</a></p> 
<br /> 
<h1>贡献者</h1> 
<a href="https://github.com/Zeyi-Lin/HivisionIDPhotos/graphs/contributors"> <img src="https://contrib.rocks/image?repo=Zeyi-Lin/HivisionIDPhotos" /> </a> 
<p><a href="https://github.com/Zeyi-Lin">Zeyi-Lin</a>、<a href="https://github.com/SAKURA-CAT">SAKURA-CAT</a>、<a href="https://github.com/Feudalman">Feudalman</a>、<a href="https://github.com/swpfY">swpfY</a>、<a href="https://github.com/Kaikaikaifang">Kaikaikaifang</a>、<a href="https://github.com/ShaohonChen">ShaohonChen</a>、<a href="https://github.com/KashiwaByte">KashiwaByte</a></p> 
<br /> 
<h1>StarHistory</h1> 
<p><a href="https://star-history.com/#Zeyi-Lin/HivisionIDPhotos&amp;Date"><img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Zeyi-Lin/HivisionIDPhotos&amp;type=Date" /></a></p> 
<!-- 微信群链接 --> 
<!-- Github Release -->
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>alan2207/bulletproof-react</title>
<link>https://github.com/alan2207/bulletproof-react</link>
<guid>https://github.com/alan2207/bulletproof-react</guid>
<content:encoded><![CDATA[
<div> 关键词：生产级、React、架构、安全性、性能

总结：

本文介绍了一种构建生产级React应用的简单、可扩展且强大的架构。其核心目标是在遵循一系列基本原则的前提下，提供一个易于上手、易于理解和维护的项目结构。这种架构强调使用最适合任务的工具，确保代码边界清晰，团队成员在执行流程上保持一致性，并且重视安全、性能和可扩展性。

1. **易用性**：设计简洁，便于开发者快速启动并理解项目。
2. **工具选择**：基于当前生态系统中的最佳实践和工具，确保功能覆盖全面。
3. **代码组织**：通过合理的代码划分和边界设定，实现模块化，提高代码复用性和可维护性。
4. **团队协作**：确保团队成员在开发过程中遵循统一的标准和流程，提高协作效率。
5. **关注关键特性**：着重于安全性、性能优化和可扩展性，以适应不同规模的项目需求。

本文鼓励开发者根据自身项目需求灵活调整技术栈，但应始终围绕上述原则进行决策，以构建出高质量的React应用。 <div>
<p>🛡️ ⚛️ A simple, scalable, and powerful architecture for building production ready React applications.</p><hr /><h1>Bulletproof React 🛡️ ⚛️</h1> 
<p><a href="https://github.com/alan2207/bulletproof-react/raw/master/LICENSE"><img alt="MIT License" src="https://img.shields.io/github/license/alan2207/bulletproof-react" /></a> <a href="https://github.com/alan2207/bulletproof-react/actions/workflows/ci.yml"><img alt="CI" src="https://github.com/alan2207/bulletproof-react/actions/workflows/ci.yml/badge.svg?sanitize=true" /></a></p> 
<p>A simple, scalable, and powerful architecture for building production ready React applications.</p> 
<h2>Introduction</h2> 
<p>React is an excellent tool for building front-end applications. It has a diverse ecosystem with hundreds of great libraries for literally anything you might need. However, being forced to make so many choices can be overwhelming. It is also very flexible, you can write React applications in any way you like, but that flexibility comes with a cost. Since there is no pre-defined architecture that developers can follow, it often leads to a messy, inconsistent, and over-complicated codebase.</p> 
<p>This repo attempts to present a way of creating React applications using some of the best tools in the ecosystem with a good project structure that scales very well. Based on my experience working with a lot of different codebases, this architecture turns out to be the most effective.</p> 
<p>The goal here is to serve as a collection of resources and best practices when developing React applications. It is supposed to showcase solving most of the real-world problems of an application in a practical way and help developers write better applications.</p> 
<p>Feel free to explore the sample app codebase to get the most value out of the repo.</p> 
<h2>What makes a React application "bulletproof"?</h2> 
<p>This repo doesn't aim to be a silver bullet for all React applications as there are many different use cases, but it tries to provide a solid foundation for building applications based on the following principles:</p> 
<ul> 
 <li>Easy to get started with</li> 
 <li>Simple to understand and maintain</li> 
 <li>Uses the right tools for the job</li> 
 <li>Clean boundaries between different parts of the application</li> 
 <li>Everyone on the team is on the same page when it comes to how things are done</li> 
 <li>Secure</li> 
 <li>Performant</li> 
 <li>Scalable in terms of codebase and team size</li> 
 <li>Issues detectable as early as possible</li> 
</ul> 
<h4>Disclaimer:</h4> 
<p>This is not supposed to be a template, boilerplate or a framework. It is an opinionated guide that shows how to do some things in a certain way. You are not forced to do everything exactly as it is shown here, decide what works best for you and your team and stay consistent with your style.</p> 
<p>To get most out of it, do not get limited by the technologies used in this sample app, but rather focus on the principles and the concepts that are being presented here. The tools and libraries used here are just a suggestion, you can always replace them with something that fits your needs better. Sometimes, your project might require a slightly different approach, and that's totally fine.</p> 
<h2>Table Of Contents:</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/application-overview.md">💻 Application Overview</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/project-standards.md">⚙️ Project Standards</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/project-structure.md">🗄️ Project Structure</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/components-and-styling.md">🧱 Components And Styling</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/api-layer.md">📡 API Layer</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/state-management.md">🗃️ State Management</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/testing.md">🧪 Testing</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/error-handling.md">⚠️ Error Handling</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/security.md">🔐 Security</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/performance.md">🚄 Performance</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/deployment.md">🌐 Deployment</a></li> 
 <li><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/docs/additional-resources.md">📚 Additional Resources</a></li> 
</ul> 
<h2>Contributing</h2> 
<p>Contributions are always welcome! If you have any ideas, suggestions, fixes, feel free to contribute. You can do that by going through the following steps:</p> 
<ol> 
 <li>Clone this repo</li> 
 <li>Create a branch: <code>git checkout -b your-feature</code></li> 
 <li>Execute the <code>yarn prepare</code> script.</li> 
 <li>Make some changes</li> 
 <li>Test your changes</li> 
 <li>Push your branch and open a Pull Request</li> 
</ol> 
<h2>License</h2> 
<p><a href="https://raw.githubusercontent.com/alan2207/bulletproof-react/master/LICENSE">MIT</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ChrisTitusTech/linutil</title>
<link>https://github.com/ChrisTitusTech/linutil</link>
<guid>https://github.com/ChrisTitusTech/linutil</guid>
<content:encoded><![CDATA[
<div> 关键词：Chris Titus Tech、Linutil、Rust、Distro-agnostic、Toolbox

总结:

Chris Titus Tech的Linutil是一个跨发行版的工具箱，旨在简化Linux日常任务。它由活跃开发的Rust语言编写，确保了高性能和可靠性。用户可以通过选择不同的分支并在终端中运行特定命令来开始使用Linutil。

对于稳定版本，推荐使用curl命令获取脚本并执行：
```bash
curl -fsSL https://christitus.com/linux | sh
```

对于开发者版本，可以使用以下命令：
```bash
curl -fsSL https://christitus.com/linuxdev | sh
```

如果用户觉得Linutil有用，可以给予支持，例如通过给项目打星标。为了更好地了解如何使用Linutil，用户可以访问其官方文档。

项目鼓励社区成员贡献，但在开始前需要阅读贡献指南，以确保贡献的有效性和效率。

最后，感谢所有为Linutil发展做出贡献的人们。他们的努力使得这个工具能够不断改进，服务于更多用户。

Linutil是由一位开发者使用Rust语言构建的跨发行版Linux工具集，旨在简化日常操作。用户可以选择稳定的或开发者版本进行安装，项目持续接受社区的反馈与贡献。通过给予项目支持和访问官方文档，用户可以更深入地了解如何利用Linutil提高Linux系统的使用体验。 <div>
<p>Chris Titus Tech's Linux Toolbox - Linutil is a distro-agnostic toolbox designed to simplify everyday Linux tasks.</p><hr /><h1>Chris Titus Tech's Linux Utility</h1> 
<p><a href="https://github.com/ChrisTitusTech/linutil/releases/latest"><img alt="Version" src="https://img.shields.io/github/v/release/ChrisTitusTech/linutil?color=%230567ff&amp;label=Latest%20Release&amp;style=for-the-badge" /></a> <img alt="GitHub Downloads (specific asset, all releases)" src="https://img.shields.io/github/downloads/ChrisTitusTech/linutil/linutil?label=Total%20Downloads&amp;style=for-the-badge" /></p> 
<p><img alt="Preview" src="https://raw.githubusercontent.com/ChrisTitusTech/linutil/main/docs/assets/preview.png" /></p> 
<p><strong>Linutil</strong> is a distro-agnostic toolbox designed to simplify everyday Linux tasks. It helps you set up applications and optimize your system for specific use cases. The utility is actively developed in Rust 🦀, providing performance and reliability.</p> 
<blockquote> 
 <p>[!NOTE] Since the project is still in active development, you may encounter some issues. Please consider <a href="https://github.com/ChrisTitusTech/linutil/issues">submitting feedback</a> if you do.</p> 
</blockquote> 
<h2>💡 Usage</h2> 
<p>To get started, pick which branch you would like to use, then run the command in your terminal:</p> 
<h3>Stable Branch (Recommended)</h3> 
<pre><code class="language-bash">curl -fsSL https://christitus.com/linux | sh
</code></pre> 
<h3>Dev branch</h3> 
<pre><code class="language-bash">curl -fsSL https://christitus.com/linuxdev | sh
</code></pre> 
<h2>💖 Support</h2> 
<p>If you find Linutil helpful, please consider giving it a ⭐️ to show your support!</p> 
<h2>🎓 Documentation</h2> 
<p>For comprehensive information on how to use Linutil, visit the <a href="https://christitustech.github.io/linutil/">Linutil Official Documentation</a>.</p> 
<h2>🛠 Contributing</h2> 
<p>We welcome contributions from the community! Before you start, please review our <a href="https://raw.githubusercontent.com/ChrisTitusTech/linutil/main/CONTRIBUTING.md">Contributing Guidelines</a> to understand how to make the most effective and efficient contributions.</p> 
<h2>🏅 Thanks to All Contributors</h2> 
<p>Thank you to everyone who has contributed to the development of Linutil. Your efforts are greatly appreciated, and you’re helping make this tool better for everyone!</p> 
<p><a href="https://github.com/ChrisTitusTech/linutil/graphs/contributors"><img alt="Contributors" src="https://contrib.rocks/image?repo=ChrisTitusTech/linutil" /></a></p> 
<h2>📜 Credits</h2> 
<p>Linutil’s Rust shell was developed by <a href="https://github.com/JustLinuxUser">@JustLinuxUser</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>grafana/mimir</title>
<link>https://github.com/grafana/mimir</link>
<guid>https://github.com/grafana/mimir</guid>
<content:encoded><![CDATA[
<div> 关键词：Grafana Mimir、Prometheus、长时存储、大规模可扩展性、多租户支持

总结:
Grafana Mimir 是一个针对 Prometheus 提供的开源软件项目，它为 Prometheus 提供了水平可扩展、高可用、多租户和长期存储解决方案。其核心优势包括：
1. **易安装与维护**：Grafana Mimir 提供详细的文档、教程和部署工具，使其快速上手。使用其单体模式，只需一个二进制文件即可启动，无需额外依赖。预装的监控面板、警报和运行指南简化了系统的健康监控。
2. **大规模扩展能力**：Grafana Mimir 的分布式架构允许在多台机器上水平扩展，处理比单个 Prometheus 实例多得多的时间序列数据。内部测试显示它能够处理高达1亿条活跃时间序列。
3. **全局指标视图**：通过聚合来自多个 Prometheus 实例的数据，Grafana Mimir 提供了系统级的指标视图。其查询引擎高度并行化执行查询，即使是最复杂的查询也能以惊人的速度完成。
4. **经济实惠的持久存储**：利用对象存储进行长期数据存储，Grafana Mimir 能够利用这种通用、成本效益高、耐用性高的技术。它兼容多种对象存储实现，包括AWS S3、Google Cloud Storage、Azure Blob Storage、OpenStack Swift以及任何S3兼容的对象存储。
5. **高可用性**：Grafana Mimir 通过复制入站指标来防止数据丢失，即使在机器故障的情况下也能确保数据安全。其分布式架构还允许零中断地重启、升级或降级系统，不影响指标收集或查询。
6. **多租户支持**：Grafana Mimir 的多租户架构允许隔离不同团队或业务部门的数据和查询，使得这些组能够共享同一集群。高级限制和服务质量控制确保容量公平分配给租户。

通过上述特性，Grafana Mimir 成为了一种强大的工具，用于管理和分析大规模时间序列数据，同时提供了高可用性和多租户功能，适用于各种规模的生产环境。 <div>
<p>Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.</p><hr /><h1>Grafana Mimir</h1> 
<p align="center"><img alt="Grafana Mimir logo" src="https://raw.githubusercontent.com/grafana/mimir/main/images/logo.png" width="400" /></p> 
<p>Grafana Mimir is an open source software project that provides a scalable long-term storage for <a href="https://prometheus.io">Prometheus</a>. Some of the core strengths of Grafana Mimir include:</p> 
<ul> 
 <li><strong>Easy to install and maintain:</strong> Grafana Mimir’s extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system.</li> 
 <li><strong>Massive scalability:</strong> You can run Grafana Mimir's horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series.</li> 
 <li><strong>Global view of metrics:</strong> Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed.</li> 
 <li><strong>Cheap, durable metric storage:</strong> Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage.</li> 
 <li><strong>High availability:</strong> Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying.</li> 
 <li><strong>Natively multi-tenant:</strong> Grafana Mimir’s multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants.</li> 
</ul> 
<h2>Migrating to Grafana Mimir</h2> 
<p>If you're migrating to Grafana Mimir, refer to the following documents:</p> 
<ul> 
 <li><a href="https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-thanos-or-prometheus/">Migrating from Thanos or Prometheus to Grafana Mimir</a>.</li> 
 <li><a href="https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-cortex/">Migrating from Cortex to Grafana Mimir</a></li> 
</ul> 
<h2>Deploying Grafana Mimir</h2> 
<p>For information about how to deploy Grafana Mimir, refer to <a href="https://grafana.com/docs/mimir/latest/operators-guide/deploy-grafana-mimir/">Deploy Grafana Mimir</a>.</p> 
<h2>Getting started</h2> 
<p>If you’re new to Grafana Mimir, read the <a href="https://grafana.com/docs/mimir/latest/get-started/">Get started guide</a>.</p> 
<p>Before deploying Grafana Mimir in a production environment, read:</p> 
<ol> 
 <li><a href="https://grafana.com/docs/mimir/latest/operators-guide/architecture/">An overview of Grafana Mimir’s architecture</a></li> 
 <li><a href="https://grafana.com/docs/mimir/latest/operators-guide/configure/">Configure Grafana Mimir</a></li> 
 <li><a href="https://grafana.com/docs/mimir/latest/operators-guide/run-production-environment/">Run Grafana Mimir in production</a></li> 
</ol> 
<h2>Documentation</h2> 
<p>Refer to the following links to access Grafana Mimir documentation:</p> 
<ul> 
 <li><a href="https://grafana.com/docs/mimir/latest/">Latest release</a></li> 
 <li><a href="https://grafana.com/docs/mimir/next/">Upcoming release</a>, at the tip of the <code>main</code> branch</li> 
</ul> 
<h2>Contributing</h2> 
<p>To contribute to Grafana Mimir, refer to <a href="https://github.com/grafana/mimir/tree/main/docs/internal/contributing">Contributing to Grafana Mimir</a>.</p> 
<h2>Join the Grafana Mimir discussion</h2> 
<p>If you have any questions or feedback regarding Grafana Mimir, join the <a href="https://github.com/grafana/mimir/discussions">Grafana Mimir Discussion</a>. Alternatively, consider joining the monthly <a href="https://docs.google.com/document/d/1E4jJcGicvLTyMEY6cUFFZUg_I8ytrBuW8r5yt1LyMv4">Grafana Mimir Community Call</a>.</p> 
<p>Your feedback is always welcome, and you can also share it via the <a href="https://slack.grafana.com/"><code>#mimir</code> Slack channel</a>.</p> 
<h2>License</h2> 
<p>Grafana Mimir is distributed under <a href="https://raw.githubusercontent.com/grafana/mimir/main/LICENSE">AGPL-3.0-only</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ruanyf/weekly</title>
<link>https://github.com/ruanyf/weekly</link>
<guid>https://github.com/ruanyf/weekly</guid>
<content:encoded><![CDATA[
<div> 关键词: 科技爱好者周刊、每周五发布、内容分享、投稿邀请、免费程序员招聘帖

总结:

科技爱好者周刊是一份定期于每周五发布的科技内容汇总刊物。它旨在记录并分享一周内值得关注的科技新闻、创新软件、资源等。这份刊物鼓励读者投稿或自荐文章、软件或资源，以丰富其内容。同时，还提供了一个免费的程序员招聘平台，帮助程序员找到工作或实习机会。

这份周刊通过多种方式供用户进行内容搜索，包括GitHub网页搜索、特定搜索引擎和本地仓库搜索。用户可以根据需要回顾往期内容，从第288期到2024年九月的第316期，涵盖了一年的科技动态。

通过订阅和参与，科技爱好者不仅能够获取最新的科技资讯，还能成为内容贡献者，与社区共享知识和经验。免费的程序员招聘帖为用户提供了一个直接寻找就业机会的渠道，强化了社区的实用性和互动性。 <div>
<p>科技爱好者周刊，每周五发布</p><hr /><h1>科技爱好者周刊</h1> 
<p>记录每周值得分享的科技内容，周五发布。</p> 
<p>欢迎投稿，推荐或自荐文章/软件/资源，请<a href="https://github.com/ruanyf/weekly/issues">提交 issue</a> 。</p> 
<blockquote> 
 <p>P.S. 讨论区的<a href="https://github.com/ruanyf/weekly/issues/5090">《谁在招人》</a>，是一个免费的程序员招聘帖，提供大量就业信息，欢迎访问或发布工作/实习岗位。</p> 
</blockquote> 
<h2>如何搜索</h2> 
<p>周刊已经沉淀了大量内容，可以使用下面的几种方法进行搜索。</p> 
<p>1、使用 GitHub 自带的网页搜索。</p> 
<p>2、使用 <a href="https://sourcegraph.com/github.com/ruanyf/weekly">Sourcegraph.com</a> 进行搜索。</p> 
<p>3、将这个仓库克隆到本地，然后在仓库目录使用下面的命令。</p> 
<pre><code class="language-bash">$ grep -nri [搜索词] docs | cat --number
</code></pre> 
<p>比如，搜索 CSS 相关内容。</p> 
<pre><code class="language-bash">$ grep -nri css docs | cat --number
</code></pre> 
<h2>2024</h2> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 316 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-316.md">你一生的故事</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 315 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-315.md">一份谷歌离职报告</a></li> 
 <li>第 314 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-314.md">《黑神话：悟空》可以产业化吗？</a></li> 
 <li>第 313 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-313.md">如果新加坡没有空调</a></li> 
 <li>第 312 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-312.md">从英特尔看“美国制造”</a></li> 
 <li>第 311 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-311.md">低利率与长期项目</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 310 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-310.md">内容农场的 AI 赚钱术</a></li> 
 <li>第 309 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-309.md">无人驾驶出租车的双面刃</a></li> 
 <li>第 308 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-308.md">工作找不到，博士能读吗？</a></li> 
 <li>第 307 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-307.md">不要看重 Product Hunt</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 306 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-306.md">信息就像糖一样上瘾</a></li> 
 <li>第 305 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-305.md">随机数，这是一个问题</a></li> 
 <li>第 304 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-304.md">最受欢迎的颜色</a></li> 
 <li>第 303 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-303.md">技术封建主义</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 302 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-302.md">创业虽然好，不敢推荐了</a></li> 
 <li>第 301 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-301.md">OpenAI 的图书馆工位</a></li> 
 <li>第 300 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-300.md">三十年，解决人生三大问题</a></li> 
 <li>第 299 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-299.md">AI 的关键是语料</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 298 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-298.md">轮到硬件工程师吃香了</a></li> 
 <li>第 297 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-297.md">饮水鸟玩具</a></li> 
 <li>第 296 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-296.md">xz 后门的作者 Jia Tan 是谁？</a></li> 
</ul> 
<p><strong>三月</strong></p> 
<ul> 
 <li>第 295 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-295.md">巧妙的灯泡钟</a></li> 
 <li>第 294 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-294.md">崖门海战的感想</a></li> 
 <li>第 293 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-293.md">一周是一年的2%</a></li> 
 <li>第 292 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-292.md">所有代码都是技术债</a></li> 
 <li>第 291 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-291.md">AI 没有护城河</a></li> 
</ul> 
<p><strong>二月</strong></p> 
<ul> 
 <li>第 290 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-290.md">苹果头盔的最大问题</a></li> 
 <li>第 289 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-289.md">宽容从何而来</a></li> 
</ul> 
<p><strong>一月</strong></p> 
<ul> 
 <li>第 288 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-288.md">技术写作的首要诀窍</a></li> 
 <li>第 287 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-287.md">禄丰恐龙谷记行</a></li> 
 <li>第 286 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-286.md">蓝色指示灯的解决方案</a></li> 
 <li>第 285 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-285.md">为什么 PPT 不如备忘录</a></li> 
</ul> 
<h2>2023</h2> 
<p><strong>十二月</strong></p> 
<ul> 
 <li>第 284 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-284.md">YouTube 有多少个视频？</a></li> 
 <li>第 283 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-283.md">[年终感想] 没有目的地，向前走</a></li> 
 <li>第 282 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-282.md">电动皮卡 Cybertruck 的 48V 供电</a></li> 
 <li>第 281 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-281.md">新基建的政策选择</a></li> 
 <li>第 280 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-280.md">机器点餐与宅文化</a></li> 
</ul> 
<p><strong>十一月</strong></p> 
<ul> 
 <li>第 279 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-279.md">网络社区的悲剧</a></li> 
 <li>第 278 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-278.md">棘手的 AI 版权</a></li> 
 <li>第 277 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-277.md">工作台副屏的最佳选择</a></li> 
 <li>第 276 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-276.md">内容行业的衰落</a></li> 
</ul> 
<p><strong>十月</strong></p> 
<ul> 
 <li>第 275 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-275.md">彼得·蒂尔的实验</a></li> 
 <li>第 274 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-274.md">加密通信的最后一块拼图</a></li> 
 <li>第 273 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-273.md">任正非的三篇最新谈话</a></li> 
</ul> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 272 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-272.md">Unity 的安装费，游戏业的缩影</a></li> 
 <li>第 271 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-271.md">非线性的世界，线性的你</a></li> 
 <li>第 270 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-270.md">“精益开发”的精益是什么？</a></li> 
 <li>第 269 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-269.md">为什么英雄不使用炸药</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 268 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-268.md">生产力是形容机器，不是形容人</a></li> 
 <li>第 267 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-267.md">5G 的春天要来了</a></li> 
 <li>第 266 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-266.md">自己做双语 EPUB 电子书</a></li> 
 <li>第 265 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-265.md">WiFi 的后面是 LiFi</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 264 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-264.md">Elasticsearch 的启示</a></li> 
 <li>第 263 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-263.md">开源软件如何赚钱？</a></li> 
 <li>第 262 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-262.md">告别密码</a></li> 
 <li>第 261 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-261.md">黑客马拉松的正确方式</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 260 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-260.md">你的旅程不会停在 Day 1</a></li> 
 <li>第 259 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-259.md">如何免费使用 ChatGPT</a></li> 
 <li>第 258 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-258.md">卡马克的猫</a></li> 
 <li>第 257 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-257.md">黄仁勋的 Nvidia 故事</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 256 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-256.md">最酷的乐高作品</a></li> 
 <li>第 255 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-255.md">对待 AI 的正确态度</a></li> 
 <li>第 254 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-254.md">人生是一个长板问题</a></li> 
 <li>第 253 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-253.md">训练材料用完之日</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 252 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-252.md">互联网创业变难了</a></li> 
 <li>第 251 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-251.md">国产单板机值得推荐</a></li> 
 <li>第 250 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-250.md">新技术的最大风险</a></li> 
 <li>第 249 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-249.md">最成功的软件企业家</a></li> 
</ul> 
<p><strong>三月</strong></p> 
<ul> 
 <li>第 248 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-248.md">不要夸大 ChatGPT</a></li> 
 <li>第 247 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-247.md">扎克伯克的裁员信</a></li> 
 <li>第 246 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-246.md">永不丢失的网络身份</a></li> 
 <li>第 245 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-245.md">摩天大楼是反人类的</a></li> 
 <li>第 244 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-244.md">大数据已死</a></li> 
</ul> 
<p><strong>二月</strong></p> 
<ul> 
 <li>第 243 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-243.md">与孔子 AI 聊天</a></li> 
 <li>第 242 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-242.md">一次尴尬的服务器被黑</a></li> 
 <li>第 241 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-241.md">中国的增长动力在内陆</a></li> 
 <li>第 240 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-240.md">教育年限可以缩短吗？</a></li> 
</ul> 
<p><strong>一月</strong></p> 
<ul> 
 <li>第 239 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-239.md">未来两种人会增加</a></li> 
 <li>第 238 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-238.md">停止寻找的最佳时间</a></li> 
</ul> 
<h2>2022</h2> 
<p><strong>十二月</strong></p> 
<ul> 
 <li>第 237 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-237.md">真实方位是如何暴露的？</a></li> 
 <li>第 236 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-236.md">中国的阳光地带</a></li> 
 <li>第 235 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-235.md">青年失业率与选择创业</a></li> 
 <li>第 234 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-234.md">AI 聊天有多强</a></li> 
 <li>第 233 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-233.md">生活就像一个鱼缸</a></li> 
</ul> 
<p><strong>十一月</strong></p> 
<ul> 
 <li>第 232 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-232.md">好用的平面设计软件</a></li> 
 <li>第 231 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-231.md">互联网公司需要多少员工？</a></li> 
 <li>第 230 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-230.md">电子产品的用电量</a></li> 
 <li>第 229 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-229.md">手机充电问题的解决</a></li> 
</ul> 
<p><strong>十月</strong></p> 
<ul> 
 <li>第 228 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-228.md">人类和人生的意义</a></li> 
 <li>第 227 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-227.md">脸书的公司入职教育</a></li> 
 <li>第 226 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-226.md">谷歌出了什么问题？</a></li> 
</ul> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 225 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-225.md">游戏 NPC 也是一种职业</a></li> 
 <li>第 224 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-224.md">Figma 为什么赢了 Sketch</a></li> 
 <li>第 223 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-223.md">程序员需要担心裁员吗？</a></li> 
 <li>第 222 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-222.md">四十年编程感想</a></li> 
 <li>第 221 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-221.md">全世界最繁荣的行业</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 220 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-220.md">人工智能的机会在哪里</a></li> 
 <li>第 219 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-219.md">如何防止帐号被黑</a></li> 
 <li>第 218 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-218.md">葡萄酒，樱花，全球变暖</a></li> 
 <li>第 217 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-217.md">沙特的新未来城</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 216 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-216.md">极简主义的胜利</a></li> 
 <li>第 215 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-215.md">互联网最喜欢的行为模式</a></li> 
 <li>第 214 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-214.md">你的地图是错的</a></li> 
 <li>第 213 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-213.md">知识孤岛，知识软件</a></li> 
 <li>第 212 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-212.md">人生不短</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 211 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-211.md">虚拟商品可以拉动 GDP</a></li> 
 <li>第 210 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-210.md">为什么软件变得复杂</a></li> 
 <li>第 209 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-209.md">程序员是怎样的人</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 208 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-208.md">晋升制度的问题</a></li> 
 <li>第 207 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-207.md">汽车行业的顶峰可能过去了</a></li> 
 <li>第 206 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-206.md">如何走出失望和怀疑</a></li> 
 <li>第 205 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-205.md">互联网风口过去了吗？</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 204 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-204.md">如何度过疫情、裁员、还有战争</a></li> 
 <li>第 203 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-203.md">英国的名校签证，伯克利的计算机教育</a></li> 
 <li>第 202 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-202.md">三个有启发的学习方法</a></li> 
 <li>第 201 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-201.md">中国需要成立半导体部</a></li> 
</ul> 
<p><strong>三月</strong></p> 
<ul> 
 <li>第 200 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-200.md">低期望，多尝试</a></li> 
 <li>第 199 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-199.md">俄罗斯的 HTTPS 证书问题</a></li> 
 <li>第 198 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-198.md">美国制造是否可能</a></li> 
 <li>第 197 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-197.md">如果这个世界有快乐机</a></li> 
</ul> 
<p><strong>二月</strong></p> 
<ul> 
 <li>第 196 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-196.md">掌机的未来</a></li> 
 <li>第 195 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-195.md">你做过不在乎结果的项目吗？</a></li> 
 <li>第 194 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-194.md">悲观者正确，乐观者成功</a></li> 
</ul> 
<p><strong>一月</strong></p> 
<ul> 
 <li>第 193 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-193.md">前端与后端，谁更难？</a></li> 
 <li>第 192 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-192.md">最大的机会来自新技术</a></li> 
 <li>第 191 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-191.md">一个程序员的财务独立之路</a></li> 
</ul> 
<h2>2021</h2> 
<p><strong>十二月</strong></p> 
<ul> 
 <li>第 190 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-190.md">产品化思维</a></li> 
 <li>第 189 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-189.md">下一个内卷的行业</a></li> 
 <li>第 188 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-188.md">音乐是反社交</a></li> 
 <li>第 187 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-187.md">元宇宙会成功吗</a></li> 
 <li>第 186 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-186.md">低纬度，高海拔，气候优势</a></li> 
</ul> 
<p><strong>十一月</strong></p> 
<ul> 
 <li>第 185 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-185.md">美国宪法拍卖，一个区块链案例</a></li> 
 <li>第 184 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-184.md">政府的存储需求有多大？</a></li> 
 <li>第 183 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-183.md">腾讯的员工退休福利</a></li> 
 <li>第 182 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-182.md">新人优惠的风险</a></li> 
</ul> 
<p><strong>十月</strong></p> 
<ul> 
 <li>第 181 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-181.md">移动支付应该怎么设计？</a></li> 
 <li>第 180 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-180.md">你想住在中国哪里？</a></li> 
 <li>第 179 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-179.md">AR 技术的打开方式</a></li> 
 <li>第 178 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-178.md">家庭太阳能发电的春天</a></li> 
</ul> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 177 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-177.md">iPad 的真正用途</a></li> 
 <li>第 176 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-176.md">中国法院承认 GPL 吗？</a></li> 
 <li>第 175 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-175.md">知识广度 vs 知识深度</a></li> 
 <li>第 174 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-174.md">全能程序员 vs 特长程序员</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 173 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-173.md">网络收音机的设计</a></li> 
 <li>第 172 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-172.md">我们会死于气候灾难吗？</a></li> 
 <li>第 171 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-171.md">云服务流量有多贵？</a></li> 
 <li>第 170 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-170.md">软件订阅制的胜利</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 169 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-169.md">五菱汽车的产品设计</a></li> 
 <li>第 168 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-168.md">游戏《底特律：变人》</a></li> 
 <li>第 167 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-167.md">广告拦截器太过分了</a></li> 
 <li>第 166 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-166.md">视频学习胜过读书吗？</a></li> 
 <li>第 165 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-165.md">全端 App 的时代</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 164 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-164.md">培训班 vs 大学，求职成功率比较</a></li> 
 <li>第 163 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-163.md">你的城市有多少张病床？</a></li> 
 <li>第 162 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-162.md">生活就像《吃豆人》游戏</a></li> 
 <li>第 161 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-161.md">再见了，学术硕士</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 160 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-160.md">中年码农的危机</a></li> 
 <li>第 159 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-159.md">游戏开发者的年薪</a></li> 
 <li>第 158 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-158.md">内容渠道的贬值</a></li> 
 <li>第 157 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-157.md">KK 给年轻人的建议</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 156 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-156.md">显卡缺货与异业竞争</a></li> 
 <li>第 155 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-155.md">数字货币是打破美元霸权的武器吗？</a></li> 
 <li>第 154 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-154.md">1982年的信息社会预言</a></li> 
 <li>第 153 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-153.md">机器翻译是对译者的侮辱吗？</a></li> 
 <li>第 152 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-152.md">从北大到技校</a></li> 
</ul> 
<p><strong>三月</strong></p> 
<ul> 
 <li>第 151 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-151.md">NFT 是什么，听说能赚钱</a></li> 
 <li>第 150 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-150.md">当音乐还是稀缺的时候</a></li> 
 <li>第 149 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-149.md">新能源汽车，谁会是赢家？</a></li> 
 <li>第 148 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-148.md">微增长时代</a></li> 
</ul> 
<p><strong>二月</strong></p> 
<ul> 
 <li>第 147 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-147.md">寻找你愿意忍受的痛苦</a></li> 
 <li>第 146 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-146.md">网课应该怎么上？</a></li> 
 <li>第 145 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-145.md">大家不出门，经济怎么办？</a></li> 
</ul> 
<p><strong>一月</strong></p> 
<ul> 
 <li>第 144 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-144.md">提高收入的根本途径</a></li> 
 <li>第 143 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-143.md">世界尽头与冷酷仙境</a></li> 
 <li>第 142 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-142.md">2020年才是21世纪元年</a></li> 
 <li>第 141 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-141.md">封闭系统的胜利</a></li> 
</ul> 
<h2>2020</h2> 
<p><strong>十二月</strong></p> 
<ul> 
 <li>第 140 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-140.md">印度人的工资是多少？</a></li> 
 <li>第 139 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-139.md">生物学的可怕进展</a></li> 
 <li>第 138 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-138.md">失业难以避免，重构人生规划</a></li> 
 <li>第 137 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-137.md">Slack 被收购，以及企业的技术选型</a></li> 
 <li>第 136 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-136.md">利特伍德奇迹定律</a></li> 
</ul> 
<p><strong>十一月</strong></p> 
<ul> 
 <li>第 135 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-135.md">什么行业适合创业？</a></li> 
 <li>第 134 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-134.md">未来的游戏业比现在大100倍</a></li> 
 <li>第 133 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-133.md">贵州变瑞士，有没有可能？</a></li> 
 <li>第 132 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-132.md">快能力和慢能力</a></li> 
</ul> 
<p><strong>十月</strong></p> 
<ul> 
 <li>第 131 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-131.md">你的头脑是二值逻辑，还是三值逻辑？</a></li> 
 <li>第 130 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-130.md">低龄化的互联网</a></li> 
 <li>第 129 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-129.md">创业的凸函数与凹函数</a></li> 
 <li>第 128 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-128.md">这个社会是否正在变成“赛博朋克”？</a></li> 
</ul> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 127 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-127.md">未来人人开发软件，几乎没人编码</a></li> 
 <li>第 126 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-126.md">内卷化是什么？</a></li> 
 <li>第 125 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-125.md">数字人民币要取代谁</a></li> 
 <li>第 124 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-124.md">华为如何考核员工</a></li> 
 <li>第 123 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-123.md">互联网公司与湘军的军制</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 122 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-122.md">谈谈互联网公司的高估值</a></li> 
 <li>第 121 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-121.md">为什么人类没有越来越闲？</a></li> 
 <li>第 120 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-120.md">只有开放才能打败封锁</a></li> 
 <li>第 119 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-119.md">降雨量和保险博弈</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 118 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-118.md">高考志愿怎么填</a></li> 
 <li>第 117 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-117.md">我不想让你记住我的脸</a></li> 
 <li>第 116 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-116.md">世界的未来就是一个火药桶</a></li> 
 <li>第 115 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-115.md">保护你的 DNA，不要泄漏</a></li> 
 <li>第 114 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-114.md">U 盘化生存和 Uber-job</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 113 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-113.md">暴力犯罪为什么越来越少？</a></li> 
 <li>第 112 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-112.md">如何培养领导力</a></li> 
 <li>第 111 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-111.md">智能电视的误区</a></li> 
 <li>第 110 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-110.md">如果不能去美国上市</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 109 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-109.md">播客的价值</a></li> 
 <li>第 108 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-108.md">阵地战与奇袭战</a></li> 
 <li>第 107 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-107.md">致富与杠杆</a></li> 
 <li>第 106 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-106.md">数字游民</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 105 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-105.md">线上行业会赢</a></li> 
 <li>第 104 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-104.md">语音合成的用途</a></li> 
 <li>第 103 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-103.md">信息的半衰期</a></li> 
 <li>第 102 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-102.md">工作热情从何而来？</a></li> 
 <li>第 101 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-101.md">互联网不再稀缺</a></li> 
</ul> 
<p><strong>三月</strong></p> 
<ul> 
 <li>第 100 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-100.md">零利率时代</a></li> 
 <li>第 99 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-99.md">疫情导致的研究生扩招</a></li> 
 <li>第 98 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-98.md">怎样清晰地表达自己的观点？</a></li> 
 <li>第 97 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-97.md">那些为了考试拼搏的年轻人</a></li> 
</ul> 
<p><strong>二月</strong></p> 
<ul> 
 <li>第 96 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-96.md">在线教育不等于录制视频</a></li> 
 <li>第 95 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-95.md">远程办公暴露冗余岗位</a></li> 
 <li>第 94 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-94.md">既懂得制造，又懂得销售</a></li> 
 <li>第 93 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-93.md">漫游类的游戏，将会越来越多</a></li> 
</ul> 
<p><strong>一月</strong></p> 
<ul> 
 <li>第 92 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-92.md">听觉暂留</a></li> 
 <li>第 91 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-91.md">印度孟买的房价，为什么跟北京一样高？</a></li> 
 <li>第 90 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-90.md">管人和技术是两种不同的能力</a></li> 
 <li>第 89 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-89.md">不下雨的地方，不要去卖伞</a></li> 
</ul> 
<h2>2019</h2> 
<p><strong>十二月</strong></p> 
<ul> 
 <li>第 88 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-88.md">如果你遇到一条蛇</a></li> 
 <li>第 87 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-87.md">新人要为团队写文档</a></li> 
 <li>第 86 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-86.md">千万不要当完美主义者</a></li> 
 <li>第 85 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-85.md">美国为什么不是乱哄哄？</a></li> 
</ul> 
<p><strong>十一月</strong></p> 
<ul> 
 <li>第 84 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-84.md">一次性工作招聘，用完你就丢</a></li> 
 <li>第 83 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-83.md">技术解决不了人类的对立</a></li> 
 <li>第 82 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-82.md">就业要选发展最快的行业</a></li> 
 <li>第 81 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-81.md">子辈能大幅超越父辈吗？</a></li> 
 <li>第 80 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-80.md">企业软件创业，为什么在中国不容易成功？</a></li> 
</ul> 
<p><strong>十月</strong></p> 
<ul> 
 <li>第 79 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-79.md">我们的生活越来越依赖机器</a></li> 
 <li>第 78 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-78.md">下一个风口是什么行业？</a></li> 
 <li>第 77 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-77.md">韩剧《阿尔布拉罕宫的回忆》</a></li> 
 <li>第 76 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-76.md">任何爱好都能变成职业，只要你会拍视频</a></li> 
</ul> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 75 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-75.md">电子取代机械，对就业有何影响？</a></li> 
 <li>第 74 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-74.md">信息的商业模式为什么不是收费</a></li> 
 <li>第 73 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-73.md">数据统计的威力</a></li> 
 <li>第 72 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-72.md">当代人不再有手稿</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 71 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-71.md">名校毕业，不容易创业</a></li> 
 <li>第 70 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-70.md">世界进入负利率时代，这意味什么</a></li> 
 <li>第 69 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-69.md">做得好 vs 做得快</a></li> 
 <li>第 68 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-68.md">关注能力的成长，胜于关注待遇</a></li> 
 <li>第 67 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-67.md">复杂系统无法维护，侏罗纪公园必定失败</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 66 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-66.md">创业不是零和游戏</a></li> 
 <li>第 65 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-65.md">周刊开设“谁在招人”的招聘服务</a></li> 
 <li>第 64 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-64.md">新人如何进入互联网行业？</a></li> 
 <li>第 63 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-63.md">互联网市场的集中化趋势</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 62 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-62.md">日本电影《编舟记》</a></li> 
 <li>第 61 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-61.md">转行前端越来越难</a></li> 
 <li>第 60 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-60.md">一本介绍人类起源的学术自传</a></li> 
 <li>第 59 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-59.md">互联网时代很难交朋友</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 58 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-58.md">软件推广可以像化妆品那样吗？</a></li> 
 <li>第 57 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-57.md">分享知识是否违反人性？</a></li> 
 <li>第 56 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-56.md">文科生为什么不容易就业？</a></li> 
 <li>第 55 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-55.md">不是反对 996，而要提倡远程办公</a></li> 
 <li>第 54 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-54.md">可扩展性最好的活动</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 53 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-53.md">DNA 相亲会</a></li> 
 <li>第 52 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-52.md">人脸识别与课堂监控</a></li> 
 <li>第 51 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-51.md">为什么过去10年，笔记本硬件发展缓慢？</a></li> 
 <li>第 50 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-50.md">"时间换收入"是一个陷阱</a></li> 
</ul> 
<p><strong>三月</strong></p> 
<ul> 
 <li>第 49 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-49.md">学会有所不为</a></li> 
 <li>第 48 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-48.md">著名程序员 Bill Joy 的人生启示</a></li> 
 <li>第 47 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-47.md">吃播算不算正式工作？</a></li> 
 <li>第 46 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-46.md">推荐算法的副作用</a></li> 
 <li>第 45 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-45.md">阿西莫夫回忆录《人生舞台》</a></li> 
</ul> 
<p><strong>二月</strong></p> 
<ul> 
 <li>第 44 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-44.md">高校“唯论文”导向的后果</a></li> 
 <li>第 43 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-43.md">一篇好玩的论文</a></li> 
 <li>第 42 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-42.md">什么领域，你可以做到出类拔萃？</a></li> 
</ul> 
<p><strong>一月</strong></p> 
<ul> 
 <li>第 41 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-41.md">如何看待互联网公司裁员？</a></li> 
 <li>第 40 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-40.md">手动咖啡不属于电子时代</a></li> 
 <li>第 39 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-39.md">苹果公司的两封公开信</a></li> 
 <li>第 38 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-38.md">使用越方便，技术实现越复杂</a></li> 
</ul> 
<h2>2018</h2> 
<p><strong>十二月</strong></p> 
<ul> 
 <li>第 37 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-37.md">小说家的时代，永远地过去了</a></li> 
 <li>第 36 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-36.md">程序员将来会不会过剩？</a></li> 
 <li>第 35 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-35.md">“一人份”的服务越来越多</a></li> 
 <li>第 34 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-34.md">身份证的最终解决方案：人体植入芯片</a></li> 
</ul> 
<p><strong>十一月</strong></p> 
<ul> 
 <li>第 33 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-33.md">现场投票不如网络投票</a></li> 
 <li>第 32 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-32.md">砌砖头的三种角度</a></li> 
 <li>第 31 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-31.md">程序员的退休信号</a></li> 
 <li>第 30 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-30.md">为什么谷歌做不好社交软件？</a></li> 
 <li>第 29 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-29.md">公司的组织架构，决定了软件的复杂性</a></li> 
</ul> 
<p><strong>十月</strong></p> 
<ul> 
 <li>第 28 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-28.md">软件开发是真正的知识吗？</a></li> 
 <li>第 27 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-27.md">乔布斯的“热情假设”对不对？</a></li> 
 <li>第 26 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-26.md">DHH 的新书《工作何必疯狂》</a></li> 
 <li>第 25 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-25.md">安卓手机十周年的感想</a></li> 
</ul> 
<p><strong>九月</strong></p> 
<ul> 
 <li>第 24 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-24.md">新人进入软件行业的建议</a></li> 
 <li>第 23 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-23.md">统计学上的人生最大决定因素</a></li> 
 <li>第 22 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-22.md">猴子自拍，版权归谁</a></li> 
 <li>第 21 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-21.md">人生的水平运动和垂直运动</a></li> 
</ul> 
<p><strong>八月</strong></p> 
<ul> 
 <li>第 20 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-20.md">不读大学的替代方案</a></li> 
 <li>第 19 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-19.md">电影《头号玩家》描绘未来的虚拟世界</a></li> 
 <li>第 18 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-18.md">无人机攻击，难以防范</a></li> 
 <li>第 17 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-17.md">全球变暖，在劫难逃</a></li> 
 <li>第 16 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-16.md">科技改变死亡的模式</a></li> 
</ul> 
<p><strong>七月</strong></p> 
<ul> 
 <li>第 15 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-15.md">周刊的内容从何而来？</a></li> 
 <li>第 14 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-14.md">马斯克的人生才是梦想家的人生</a></li> 
 <li>第 13 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-13.md">周刊为什么只谈技术？</a></li> 
 <li>第 12 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-12.md">人口老龄化，养老金不够</a></li> 
</ul> 
<p><strong>六月</strong></p> 
<ul> 
 <li>第 11 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-11.md">编程语言越发复杂</a></li> 
 <li>第 10 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-10.md">30岁以后谨慎转行前端</a></li> 
 <li>第 9 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-9.md">身份证可以植入人体</a></li> 
 <li>第 8 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-8.md">实验室会生产人吗？</a></li> 
 <li>第 7 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-7.md">垃圾填埋不是解决办法</a></li> 
</ul> 
<p><strong>五月</strong></p> 
<ul> 
 <li>第 6 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-6.md">未来还需要苦学外语吗？</a></li> 
 <li>第 5 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-5.md">互联网时代，做一个好人是划算的</a></li> 
 <li>第 4 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-4.md">马克思研究的问题</a></li> 
 <li>第 3 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-3.md">周刊的风格</a></li> 
</ul> 
<p><strong>四月</strong></p> 
<ul> 
 <li>第 2 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-2.md">为什么写周刊？</a></li> 
 <li>第 1 期：<a href="https://raw.githubusercontent.com/ruanyf/weekly/master/docs/issue-1.md">创刊号</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>lobehub/lobe-chat</title>
<link>https://github.com/lobehub/lobe-chat</link>
<guid>https://github.com/lobehub/lobe-chat</guid>
<content:encoded><![CDATA[
<div> 关键词：LobeChat、开源、现代设计、AI聊天框架、一键免费部署

总结：

LobeChat 是一款开源的现代设计 AI 聊天框架，支持多 AI 提供商（包括 OpenAI、Claude、Gemini、Ollama、Azure、DeepSeek 等）、知识库（文件上传、知识管理、RAG）、多模态（视觉/TTS）和插件系统。用户无需安装或注册，即可通过访问官方网站体验其功能。此外，LobeChat 提供了一个社区平台，用户可以在此交流并参与产品的迭代优化。它还支持多种模型服务提供商，以满足不同用户的需求。LobeChat 还具备文件上传与知识管理功能、支持多语言环境、提供主题模式选择、以及 PWA 技术以实现跨平台的无缝体验。用户可以通过 Vercel 或 Docker 快速部署自己的聊天机器人服务。同时，LobeChat 支持自定义域名绑定，确保用户数据的安全性和隐私性。最后，LobeChat 的生态系统包括 UI 组件库、AI 模型品牌 SVG 图标集合、高质量的语音合成与识别组件、以及用于配置 ESLint、Stylelint、Commitlint、Prettier、Remark 和 Semantic Release 的工具集。 <div>
<p>🤯 Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Azure / DeepSeek), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Vision/TTS) and plugin system. One-click FREE deployment of your private ChatGPT/ Claude application.</p><hr /><div align="center">
 <a name="readme-top"></a> 
 <p><a href="https://chat-preview.lobehub.com"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/28616219/9f155dff-4737-429f-9cad-a70a1a860c5f" /></a></p> 
 <h1>Lobe Chat</h1> 
 <p>An open-source, modern-design ChatGPT/LLMs UI/Framework.<br /> Supports speech-synthesis, multi-modal, and extensible (<a href="https://lobehub.com/blog/openai-function-call">function call</a>) plugin system.<br /> One-click <strong>FREE</strong> deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.</p> 
 <p><strong>English</strong> · <a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/README.zh-CN.md">简体中文</a> · <a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/README.ja-JP.md">日本語</a> · <a href="https://lobehub.com">Official Site</a> · <a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/CHANGELOG.md">Changelog</a> · <a href="https://lobehub.com/docs/usage/start">Documents</a> · <a href="https://lobehub.com/blog">Blog</a> · <a href="https://github.com/lobehub/lobe-chat/issues">Feedback</a></p> 
 <!-- SHIELD GROUP --> 
 <p><a href="https://github.com/lobehub/lobe-chat/releases"><img alt="" src="https://img.shields.io/github/v/release/lobehub/lobe-chat?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square" /></a> <a href="https://hub.docker.com/r/lobehub/lobe-chat"><img alt="" src="https://img.shields.io/docker/v/lobehub/lobe-chat?color=369eff&amp;label=docker&amp;labelColor=black&amp;logo=docker&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://chat-preview.lobehub.com"><img alt="" src="https://img.shields.io/badge/vercel-online-55b467?labelColor=black&amp;logo=vercel&amp;style=flat-square" /></a> <a href="https://discord.gg/AYFPHvv2jT"><img alt="" src="https://img.shields.io/discord/1127171173982154893?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square" /></a><br /> <a href="https://codecov.io/gh/lobehub/lobe-chat"><img alt="" src="https://img.shields.io/codecov/c/github/lobehub/lobe-chat?labelColor=black&amp;style=flat-square&amp;logo=codecov&amp;logoColor=white" /></a> <a href="https://github.com/actions/workflows/lobehub/lobe-chat/test.yml"><img alt="" src="https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/test.yml?label=test&amp;labelColor=black&amp;logo=githubactions&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://github.com/actions/workflows/lobehub/lobe-chat/release.yml"><img alt="" src="https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/release.yml?label=release&amp;labelColor=black&amp;logo=githubactions&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://github.com/lobehub/lobe-chat/releases"><img alt="" src="https://img.shields.io/github/release-date/lobehub/lobe-chat?labelColor=black&amp;style=flat-square" /></a><br /> <a href="https://github.com/lobehub/lobe-chat/graphs/contributors"><img alt="" src="https://img.shields.io/github/contributors/lobehub/lobe-chat?color=c4f042&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/lobehub/lobe-chat/network/members"><img alt="" src="https://img.shields.io/github/forks/lobehub/lobe-chat?color=8ae8ff&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/lobehub/lobe-chat/network/stargazers"><img alt="" src="https://img.shields.io/github/stars/lobehub/lobe-chat?color=ffcb47&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/lobehub/lobe-chat/issues"><img alt="" src="https://img.shields.io/github/issues/lobehub/lobe-chat?color=ff80eb&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://github.com/lobehub/lobe-chat/raw/main/LICENSE"><img alt="" src="https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&amp;style=flat-square" /></a><br /> <a href="https://opencollective.com/lobehub" title="Become ❤️ LobeHub Sponsor"><img alt="" src="https://img.shields.io/badge/-Sponsor%20LobeHub-f04f88?logo=opencollective&amp;logoColor=white&amp;style=flat-square" /></a></p> 
 <p><strong>Share LobeChat Repository</strong></p> 
 <p><a href="https://x.com/intent/tweet?hashtags=chatbot%2CchatGPT%2CopenAI&amp;text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.&amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"><img alt="" src="https://img.shields.io/badge/-share%20on%20x-black?labelColor=black&amp;logo=x&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://t.me/share/url%22?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"><img alt="" src="https://img.shields.io/badge/-share%20on%20telegram-black?labelColor=black&amp;logo=telegram&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://api.whatsapp.com/send?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat%20%23chatbot%20%23chatGPT%20%23openAI"><img alt="" src="https://img.shields.io/badge/-share%20on%20whatsapp-black?labelColor=black&amp;logo=whatsapp&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://www.reddit.com/submit?title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"><img alt="" src="https://img.shields.io/badge/-share%20on%20reddit-black?labelColor=black&amp;logo=reddit&amp;logoColor=white&amp;style=flat-square" /></a> <a href="http://service.weibo.com/share/share.php?sharesource=weibo&amp;title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"><img alt="" src="https://img.shields.io/badge/-share%20on%20weibo-black?labelColor=black&amp;logo=sinaweibo&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://mastodon.social/share?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source,%20extensible%20(Function%20Calling),%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT/LLM%20web%20application.%20https://github.com/lobehub/lobe-chat%20#chatbot%2520%23chatGPT%2520%23openAI"><img alt="" src="https://img.shields.io/badge/-share%20on%20mastodon-black?labelColor=black&amp;logo=mastodon&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://linkedin.com/feed"><img alt="" src="https://img.shields.io/badge/-share%20on%20linkedin-black?labelColor=black&amp;logo=linkedin&amp;logoColor=white&amp;style=flat-square" /></a></p> 
 <p><sup>Pioneering the new age of thinking and creating. Built for you, the Super Individual.</sup></p> 
 <p><a href="https://trendshift.io/repositories/2256"><img alt="" src="https://trendshift.io/api/badge/repositories/2256" /></a></p> 
 <p><a href="https://chat-preview.lobehub.com"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/17870709/56b95d48-f573-41cd-8b38-387bf88bc4bf" /></a></p> 
</div> 
<details> 
 <kbd>Table of contents</kbd> 
 <h4>TOC</h4> 
 <ul> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-getting-started--join-our-community">👋🏻 Getting Started &amp; Join Our Community</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-features">✨ Features</a> 
   <ul> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#1-file-uploadknowledge-base"><code>1</code> File Upload/Knowledge Base</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#2-multi-model-service-provider-support"><code>2</code> Multi-Model Service Provider Support</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#3-local-large-language-model-llm-support"><code>3</code> Local Large Language Model (LLM) Support</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#4-model-visual-recognition"><code>4</code> Model Visual Recognition</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#5-tts--stt-voice-conversation"><code>5</code> TTS &amp; STT Voice Conversation</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#6-text-to-image-generation"><code>6</code> Text to Image Generation</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#7-plugin-system-function-calling"><code>7</code> Plugin System (Function Calling)</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#8-agent-market-gpts"><code>8</code> Agent Market (GPTs)</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#9-support-local--remote-database"><code>9</code> Support Local / Remote Database</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#10-support-multi-user-management"><code>10</code> Support Multi-User Management</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#11-progressive-web-app-pwa"><code>11</code> Progressive Web App (PWA)</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#12-mobile-device-adaptation"><code>12</code> Mobile Device Adaptation</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#13-custom-themes"><code>13</code> Custom Themes</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-whats-more"><code>*</code> What's more</a></li> 
   </ul> </li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-performance">⚡️ Performance</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-self-hosting">🛳 Self Hosting</a> 
   <ul> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#a-deploying-with-vercel-zeabur-or-sealos"><code>A</code> Deploying with Vercel, Zeabur or Sealos</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#b-deploying-with-docker"><code>B</code> Deploying with Docker</a></li> 
    <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#environment-variable">Environment Variable</a></li> 
   </ul> </li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-ecosystem">📦 Ecosystem</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-plugins">🧩 Plugins</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-local-development">⌨️ Local Development</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-contributing">🤝 Contributing</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-sponsor">❤️ Sponsor</a></li> 
  <li><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-more-products">🔗 More Products</a></li> 
 </ul> 
 <h4></h4> 
 <br /> 
</details> 
<h2>👋🏻 Getting Started &amp; Join Our Community</h2> 
<p>We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC. By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.</p> 
<p>Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any <a href="https://img.shields.io/github/issues/lobehub/lobe-chat.svg?style=flat">issues</a> encountered.</p> 
<table> 
 <thead> 
  <tr> 
   <th align="left"><a href="https://chat-preview.lobehub.com"><img alt="" src="https://img.shields.io/badge/TRY%20LOBECHAT-ONLINE-55b467?labelColor=black&amp;logo=vercel&amp;style=for-the-badge" /></a></th> 
   <th align="left">No installation or registration necessary! Visit our website to experience it firsthand.</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td align="left"><a href="https://discord.gg/AYFPHvv2jT"><img alt="" src="https://img.shields.io/discord/1127171173982154893?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=for-the-badge" /></a></td> 
   <td align="left">Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub.</td> 
  </tr> 
 </tbody> 
</table> 
<blockquote> 
 <p>[!IMPORTANT]</p> 
 <p><strong>Star Us</strong>, You will receive all release notifications from GitHub without any delay ~ ⭐️</p> 
</blockquote> 
<p><a href="https://github.com/lobehub/lobe-chat/network/stargazers"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/17870709/cb06b748-513f-47c2-8740-d876858d7855" /></a></p> 
<details> 
 <kbd>Star History</kbd> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <img src="https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date" width="100%" /> 
  
</details> 
<h2>✨ Features</h2> 
<p><a href="https://lobehub.com/blog/knowledge-base"><img alt="" src="https://github.com/user-attachments/assets/77e58e1c-c82f-4341-b159-f4eeede9967f" /></a></p> 
<h3><code>1</code> <a href="https://lobehub.com/blog/knowledge-base">File Upload/Knowledge Base</a></h3> 
<p>LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.</p> 
<p><a href="https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175">https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175</a></p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>Learn more on <a href="https://lobehub.com/blog/knowledge-base">📘 LobeChat Knowledge Base Launch — From Now On, Every Step Counts</a></p> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/multi-ai-providers"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/28616219/b164bc54-8ba2-4c1e-b2f2-f4d7f7e7a551" /></a></p> 
<h3><code>2</code> <a href="https://lobehub.com/docs/usage/features/multi-ai-providers">Multi-Model Service Provider Support</a></h3> 
<p>In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.</p> 
<p>In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.</p> 
<h4>Supported Model Service Providers</h4> 
<p>We have implemented support for the following model service providers:</p> 
<ul> 
 <li><strong>AWS Bedrock</strong>: Integrated with AWS Bedrock service, supporting models such as <strong>Claude / LLama2</strong>, providing powerful natural language processing capabilities. <a href="https://aws.amazon.com/cn/bedrock">Learn more</a></li> 
 <li><strong>Anthropic (Claude)</strong>: Accessed Anthropic's <strong>Claude</strong> series models, including Claude 3 and Claude 2, with breakthroughs in multi-modal capabilities and extended context, setting a new industry benchmark. <a href="https://www.anthropic.com/claude">Learn more</a></li> 
 <li><strong>Google AI (Gemini Pro, Gemini Vision)</strong>: Access to Google's <strong>Gemini</strong> series models, including Gemini and Gemini Pro, to support advanced language understanding and generation. <a href="https://deepmind.google/technologies/gemini/">Learn more</a></li> 
 <li><strong>Groq</strong>: Accessed Groq's AI models, efficiently processing message sequences and generating responses, capable of multi-turn dialogues and single-interaction tasks. <a href="https://groq.com/">Learn more</a></li> 
 <li><strong>OpenRouter</strong>: Supports routing of models including <strong>Claude 3</strong>, <strong>Gemma</strong>, <strong>Mistral</strong>, <strong>Llama2</strong> and <strong>Cohere</strong>, with intelligent routing optimization to improve usage efficiency, open and flexible. <a href="https://openrouter.ai/">Learn more</a></li> 
 <li><strong>01.AI (Yi Model)</strong>: Integrated the 01.AI models, with series of APIs featuring fast inference speed, which not only shortened the processing time, but also maintained excellent model performance. <a href="https://01.ai/">Learn more</a></li> 
 <li><strong>Together.ai</strong>: Over 100 leading open-source Chat, Language, Image, Code, and Embedding models are available through the Together Inference API. For these models you pay just for what you use. <a href="https://www.together.ai/">Learn more</a></li> 
 <li><strong>ChatGLM</strong>: Added the <strong>ChatGLM</strong> series models from Zhipuai (GLM-4/GLM-4-vision/GLM-3-turbo), providing users with another efficient conversation model choice. <a href="https://www.zhipuai.cn/">Learn more</a></li> 
 <li><strong>Moonshot AI (Dark Side of the Moon)</strong>: Integrated with the Moonshot series models, an innovative AI startup from China, aiming to provide deeper conversation understanding. <a href="https://www.moonshot.cn/">Learn more</a></li> 
 <li><strong>Minimax</strong>: Integrated the Minimax models, including the MoE model <strong>abab6</strong>, offers a broader range of choices. <a href="https://www.minimaxi.com/">Learn more</a></li> 
 <li><strong>DeepSeek</strong>: Integrated with the DeepSeek series models, an innovative AI startup from China, The product has been designed to provide a model that balances performance with price. <a href="https://www.deepseek.com/">Learn more</a></li> 
 <li><strong>Qwen</strong>: Integrated the Qwen series models, including the latest <strong>qwen-turbo</strong>, <strong>qwen-plus</strong> and <strong>qwen-max</strong>. <a href="https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction">Lean more</a></li> 
 <li><strong>Novita AI</strong>: Access <strong>Llama</strong>, <strong>Mistral</strong>, and other leading open-source models at cheapest prices. Engage in uncensored role-play, spark creative discussions, and foster unrestricted innovation. <strong>Pay For What You Use.</strong> <a href="https://novita.ai/llm-api?utm_source=lobechat&amp;utm_medium=ch&amp;utm_campaign=api">Learn more</a></li> 
</ul> 
<p>At the same time, we are also planning to support more model service providers, such as Replicate and Perplexity, to further enrich our service provider library. If you would like LobeChat to support your favorite service provider, feel free to join our <a href="https://github.com/lobehub/lobe-chat/discussions/1284">community discussion</a>.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/local-llm"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/28616219/ca9a21bc-ea6c-4c90-bf4a-fa53b4fb2b5c" /></a></p> 
<h3><code>3</code> <a href="https://lobehub.com/docs/usage/features/local-llm">Local Large Language Model (LLM) Support</a></h3> 
<p>To meet the specific needs of users, LobeChat also supports the use of local models based on <a href="https://ollama.ai">Ollama</a>, allowing users to flexibly use their own or third-party models.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>Learn more about <a href="https://lobehub.com/docs/usage/providers/ollama">📘 Using Ollama in LobeChat</a> by checking it out.</p> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/vision"><img alt="" src="https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/284072129-382bdf30-e3d6-4411-b5a0-249710b8ba08.png" /></a></p> 
<h3><code>4</code> <a href="https://lobehub.com/docs/usage/features/vision">Model Visual Recognition</a></h3> 
<p>LobeChat now supports OpenAI's latest <a href="https://platform.openai.com/docs/guides/vision"><code>gpt-4-vision</code></a> model with visual recognition capabilities, a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box, and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this, creating smarter and more diversified chat scenarios.</p> 
<p>This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements. Whether it's sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/tts"><img alt="" src="https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/284072124-c9853d8d-f1b5-44a8-a305-45ebc0f6d19a.png" /></a></p> 
<h3><code>5</code> <a href="https://lobehub.com/docs/usage/features/tts">TTS &amp; STT Voice Conversation</a></h3> 
<p>LobeChat supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs, allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.</p> 
<p>Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy. In LobeChat, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds. Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/text-to-image"><img alt="" src="https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/297746445-0ff762b9-aa08-4337-afb7-12f932b6efbb.png" /></a></p> 
<h3><code>6</code> <a href="https://lobehub.com/docs/usage/features/text-to-image">Text to Image Generation</a></h3> 
<p>With support for the latest text-to-image generation technology, LobeChat now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as <a href="https://openai.com/dall-e-3"><code>DALL-E 3</code></a>, <a href="https://www.midjourney.com/"><code>MidJourney</code></a>, and <a href="https://pollinations.ai/"><code>Pollinations</code></a>, the agents are now equipped to transform your ideas into images.</p> 
<p>This enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/plugin-system"><img alt="" src="https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/268670883-33c43a5c-a512-467e-855c-fa299548cce5.png" /></a></p> 
<h3><code>7</code> <a href="https://lobehub.com/docs/usage/features/plugin-system">Plugin System (Function Calling)</a></h3> 
<p>The plugin ecosystem of LobeChat is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeChat assistant.</p> 
<p>
 <video controls="controls" src="https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2"></video></p> 
<p>By utilizing plugins, LobeChat assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.</p> 
<p>In addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>Learn more about <a href="https://lobehub.com/docs/usage/plugins/basic">📘 Plugin Usage</a> by checking it out.</p> 
</blockquote> 
<!-- PLUGIN LIST --> 
<table> 
 <thead> 
  <tr> 
   <th>Recent Submits</th> 
   <th>Description</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/settings/agent">Tongyi wanxiang Image Generator</a><br /><sup>By <strong>YoungTx</strong> on <strong>2024-08-09</strong></sup></td> 
   <td>This plugin uses Alibaba's Tongyi Wanxiang model to generate images based on text prompts.<br /><code>image</code> <code>tongyi</code> <code>wanxiang</code></td> 
  </tr> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/settings/agent">Shopping tools</a><br /><sup>By <strong>shoppingtools</strong> on <strong>2024-07-19</strong></sup></td> 
   <td>Search for products on eBay &amp; AliExpress, find eBay events &amp; coupons. Get prompt examples.<br /><code>shopping</code> <code>e-bay</code> <code>ali-express</code> <code>coupons</code></td> 
  </tr> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/settings/agent">Savvy Trader AI</a><br /><sup>By <strong>savvytrader</strong> on <strong>2024-06-27</strong></sup></td> 
   <td>Realtime stock, crypto and other investment data.<br /><code>stock</code> <code>analyze</code></td> 
  </tr> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/settings/agent">Social Search</a><br /><sup>By <strong>say-apps</strong> on <strong>2024-06-02</strong></sup></td> 
   <td>The Social Search provides access to tweets, users, followers, images, media and more.<br /><code>social</code> <code>twitter</code> <code>x</code> <code>search</code></td> 
  </tr> 
 </tbody> 
</table> 
<blockquote> 
 <p>📊 Total plugins: <a href="https://github.com/lobehub/lobe-chat-plugins"><kbd><strong>51</strong></kbd></a></p> 
</blockquote> 
<!-- PLUGIN LIST --> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/agent-market"><img alt="" src="https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/268670869-f1ffbf66-42b6-42cf-a937-9ce1f8328514.png" /></a></p> 
<h3><code>8</code> <a href="https://lobehub.com/docs/usage/features/agent-market">Agent Market (GPTs)</a></h3> 
<p>In LobeChat Agent Marketplace, creators can discover a vibrant and innovative community that brings together a multitude of well-designed agents, which not only play an important role in work scenarios but also offer great convenience in learning processes. Our marketplace is not just a showcase platform but also a collaborative space. Here, everyone can contribute their wisdom and share the agents they have developed.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>By <a href="https://github.com/lobehub/lobe-chat-agents">🤖/🏪 Submit Agents</a>, you can easily submit your agent creations to our platform. Importantly, LobeChat has established a sophisticated automated internationalization (i18n) workflow, capable of seamlessly translating your agent into multiple language versions. This means that no matter what language your users speak, they can experience your agent without barriers.</p> 
</blockquote> 
<blockquote> 
 <p>[!IMPORTANT]</p> 
 <p>We welcome all users to join this growing ecosystem and participate in the iteration and optimization of agents. Together, we can create more interesting, practical, and innovative agents, further enriching the diversity and practicality of the agent offerings.</p> 
</blockquote> 
<!-- AGENT LIST --> 
<table> 
 <thead> 
  <tr> 
   <th>Recent Submits</th> 
   <th>Description</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/market?agent=nuxt-vue-developer">Nuxt 3/Vue.js Master Developer</a><br /><sup>By <strong><a href="https://github.com/Kadreev">Kadreev</a></strong> on <strong>2024-09-03</strong></sup></td> 
   <td>Specialized in full-stack development with Nuxt 3 expertise.<br /><code>nuxt-3</code> <code>vue-js</code> <code>full-stack-development</code> <code>java-script</code> <code>web-applications</code></td> 
  </tr> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/market?agent=letrista-internacional">International Lyricist</a><br /><sup>By <strong><a href="https://github.com/mnector">mnector</a></strong> on <strong>2024-08-29</strong></sup></td> 
   <td>Specialized in writing lyrics for songs in Spanish, English, and French, with a focus on storytelling and the emotions of the provided content.<br /><code>lyricism</code> <code>translation</code> <code>music</code></td> 
  </tr> 
  <tr> 
   <td><a href="https://chat-preview.lobehub.com/market?agent=step-back-expert">Backtracking Question Expert</a><br /><sup>By <strong><a href="https://github.com/tiny656">tiny656</a></strong> on <strong>2024-08-27</strong></sup></td> 
   <td>Hello! I am an expert in world knowledge, skilled in using backtracking questioning strategies to help you gain a deeper understanding and analysis of issues. Please enter a question, and I will respond to it according to the following process:</td> 
  </tr> 
 </tbody> 
</table> 
<ol> 
 <li>Provide at least 3 optional backtracking questions that align with the strategy.</li> 
 <li>Answer each of these backtracking questions.</li> 
 <li>Use the above answers as evidence to logically and coherently provide a final answer to your question, assisted by visual charts.</li> 
</ol> 
<p>Please tell me what issue you would like to explore?<br /><code>backtracking-questions</code> <code>thinking-strategies</code> <code>problem-analysis</code> | | <a href="https://chat-preview.lobehub.com/market?agent=unreal-engine-master">Unreal Engine Master</a><br /><sup>By <strong><a href="https://github.com/thedivergentai">thedivergentai</a></strong> on <strong>2024-08-27</strong></sup> | Unreal Game Development Companion<br /><code>game-development</code> <code>unreal-engine</code> <code>software-engineering</code> |</p> 
<blockquote> 
 <p>📊 Total agents: <a href="https://github.com/lobehub/lobe-chat-agents"><kbd><strong>322</strong></kbd> </a></p> 
</blockquote> 
<!-- AGENT LIST --> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/database"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/17870709/c27a0234-a4e9-40e5-8bcb-42d5ce7e40f9" /></a></p> 
<h3><code>9</code> <a href="https://lobehub.com/docs/usage/features/database">Support Local / Remote Database</a></h3> 
<p>LobeChat supports the use of both server-side and local databases. Depending on your needs, you can choose the appropriate deployment solution:</p> 
<ul> 
 <li><strong>Local database</strong>: suitable for users who want more control over their data and privacy protection. LobeChat uses CRDT (Conflict-Free Replicated Data Type) technology to achieve multi-device synchronization. This is an experimental feature aimed at providing a seamless data synchronization experience.</li> 
 <li><strong>Server-side database</strong>: suitable for users who want a more convenient user experience. LobeChat supports PostgreSQL as a server-side database. For detailed documentation on how to configure the server-side database, please visit <a href="https://lobehub.com/docs/self-hosting/advanced/server-database">Configure Server-side Database</a>.</li> 
</ul> 
<p>Regardless of which database you choose, LobeChat can provide you with an excellent user experience.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/auth"><img alt="" src="https://github.com/lobehub/lobe-chat/assets/17870709/8ce70e15-40df-451e-b700-66090fe5b8c2" /></a></p> 
<h3><code>10</code> <a href="https://lobehub.com/docs/usage/features/auth">Support Multi-User Management</a></h3> 
<p>LobeChat supports multi-user management and provides two main user authentication and management solutions to meet different needs:</p> 
<ul> 
 <li> <p><strong>next-auth</strong>: LobeChat integrates <code>next-auth</code>, a flexible and powerful identity verification library that supports multiple authentication methods, including OAuth, email login, credential login, etc. With <code>next-auth</code>, you can easily implement user registration, login, session management, social login, and other functions to ensure the security and privacy of user data.</p> </li> 
 <li> <p><a href="https://go.clerk.com/exgqLG0"><strong>Clerk</strong></a>: For users who need more advanced user management features, LobeChat also supports <code>Clerk</code>, a modern user management platform. <code>Clerk</code> provides richer functions, such as multi-factor authentication (MFA), user profile management, login activity monitoring, etc. With <code>Clerk</code>, you can get higher security and flexibility, and easily cope with complex user management needs.</p> </li> 
</ul> 
<p>Regardless of which user management solution you choose, LobeChat can provide you with an excellent user experience and powerful functional support.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/pwa"><img alt="" src="https://gw.alipayobjects.com/zos/kitchen/69x6bllkX3/pwa.webp" /></a></p> 
<h3><code>11</code> <a href="https://lobehub.com/docs/usage/features/pwa">Progressive Web App (PWA)</a></h3> 
<p>We deeply understand the importance of providing a seamless experience for users in today's multi-device environment. Therefore, we have adopted Progressive Web Application (<a href="https://support.google.com/chrome/answer/9658361">PWA</a>) technology, a modern web technology that elevates web applications to an experience close to that of native apps.</p> 
<p>Through PWA, LobeChat can offer a highly optimized user experience on both desktop and mobile devices while maintaining its lightweight and high-performance characteristics. Visually and in terms of feel, we have also meticulously designed the interface to ensure it is indistinguishable from native apps, providing smooth animations, responsive layouts, and adapting to different device screen resolutions.</p> 
<blockquote> 
 <p>[!NOTE]</p> 
 <p>If you are unfamiliar with the installation process of PWA, you can add LobeChat as your desktop application (also applicable to mobile devices) by following these steps:</p> 
 <ul> 
  <li>Launch the Chrome or Edge browser on your computer.</li> 
  <li>Visit the LobeChat webpage.</li> 
  <li>In the upper right corner of the address bar, click on the <kbd>Install</kbd> icon.</li> 
  <li>Follow the instructions on the screen to complete the PWA Installation.</li> 
 </ul> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/mobile"><img alt="" src="https://gw.alipayobjects.com/zos/kitchen/R441AuFS4W/mobile.webp" /></a></p> 
<h3><code>12</code> <a href="https://lobehub.com/docs/usage/features/mobile">Mobile Device Adaptation</a></h3> 
<p>We have carried out a series of optimization designs for mobile devices to enhance the user's mobile experience. Currently, we are iterating on the mobile user experience to achieve smoother and more intuitive interactions. If you have any suggestions or ideas, we welcome you to provide feedback through GitHub Issues or Pull Requests.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<p><a href="https://lobehub.com/docs/usage/features/theme"><img alt="" src="https://gw.alipayobjects.com/zos/kitchen/pvus1lo%26Z7/darkmode.webp" /></a></p> 
<h3><code>13</code> <a href="https://lobehub.com/docs/usage/features/theme">Custom Themes</a></h3> 
<p>As a design-engineering-oriented application, LobeChat places great emphasis on users' personalized experiences, hence introducing flexible and diverse theme modes, including a light mode for daytime and a dark mode for nighttime. Beyond switching theme modes, a range of color customization options allow users to adjust the application's theme colors according to their preferences. Whether it's a desire for a sober dark blue, a lively peach pink, or a professional gray-white, users can find their style of color choices in LobeChat.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>The default configuration can intelligently recognize the user's system color mode and automatically switch themes to ensure a consistent visual experience with the operating system. For users who like to manually control details, LobeChat also offers intuitive setting options and a choice between chat bubble mode and document mode for conversation scenarios.</p> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h3><code>*</code> What's more</h3> 
<p>Beside these features, LobeChat also have much better basic technique underground:</p> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> 💨 <strong>Quick Deployment</strong>: Using the Vercel platform or docker image, you can deploy with just one click and complete the process within 1 minute without any complex configuration.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> 🌐 <strong>Custom Domain</strong>: If users have their own domain, they can bind it to the platform for quick access to the dialogue agent from anywhere.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> 🔒 <strong>Privacy Protection</strong>: All data is stored locally in the user's browser, ensuring user privacy.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> 💎 <strong>Exquisite UI Design</strong>: With a carefully designed interface, it offers an elegant appearance and smooth interaction. It supports light and dark themes and is mobile-friendly. PWA support provides a more native-like experience.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> 🗣️ <strong>Smooth Conversation Experience</strong>: Fluid responses ensure a smooth conversation experience. It fully supports Markdown rendering, including code highlighting, LaTex formulas, Mermaid flowcharts, and more.</li> 
</ul> 
<blockquote> 
 <p>✨ more features will be added when LobeChat evolve.</p> 
</blockquote> 
<hr /> 
<blockquote> 
 <p>[!NOTE]</p> 
 <p>You can find our upcoming <a href="https://github.com/lobehub/lobe-chat/projects">Roadmap</a> plans in the Projects section.</p> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>⚡️ Performance</h2> 
<blockquote> 
 <p>[!NOTE]</p> 
 <p>The complete list of reports can be found in the <a href="https://github.com/lobehub/lobe-chat/wiki/Lighthouse">📘 Lighthouse Reports</a></p> 
</blockquote> 
<table> 
 <thead> 
  <tr> 
   <th align="center">Desktop</th> 
   <th align="center">Mobile</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td align="center"><img alt="" src="https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/desktop/pagespeed.svg?sanitize=true" /></td> 
   <td align="center"><img alt="" src="https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/mobile/pagespeed.svg?sanitize=true" /></td> 
  </tr> 
  <tr> 
   <td align="center"><a href="https://lobehub.github.io/lobe-chat/lighthouse/chat/desktop/chat_preview_lobehub_com_chat.html">📑 Lighthouse Report</a></td> 
   <td align="center"><a href="https://lobehub.github.io/lobe-chat/lighthouse/chat/mobile/chat_preview_lobehub_com_chat.html">📑 Lighthouse Report</a></td> 
  </tr> 
 </tbody> 
</table> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>🛳 Self Hosting</h2> 
<p>LobeChat provides Self-Hosted Version with Vercel and <a href="https://hub.docker.com/r/lobehub/lobe-chat">Docker Image</a>. This allows you to deploy your own chatbot within a few minutes without any prior knowledge.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>Learn more about <a href="https://lobehub.com/docs/self-hosting/start">📘 Build your own LobeChat</a> by checking it out.</p> 
</blockquote> 
<h3><code>A</code> Deploying with Vercel, Zeabur or Sealos</h3> 
<p>If you want to deploy this service yourself on either Vercel or Zeabur, you can follow these steps:</p> 
<ul> 
 <li>Prepare your <a href="https://platform.openai.com/account/api-keys">OpenAI API Key</a>.</li> 
 <li>Click the button below to start deployment: Log in directly with your GitHub account, and remember to fill in the <code>OPENAI_API_KEY</code>(required) and <code>ACCESS_CODE</code> (recommended) on the environment variable section.</li> 
 <li>After deployment, you can start using it.</li> 
 <li>Bind a custom domain (optional): The DNS of the domain assigned by Vercel is polluted in some areas; binding a custom domain can connect directly.</li> 
</ul> 
<div align="center"> 
 <table> 
  <thead> 
   <tr> 
    <th align="center">Deploy with Vercel</th> 
    <th align="center">Deploy with Zeabur</th> 
    <th align="center">Deploy with Sealos</th> 
    <th align="center">Deploy with RepoCloud</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td align="center"><a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&amp;env=OPENAI_API_KEY,ACCESS_CODE&amp;envDescription=Find%20your%20OpenAI%20API%20Key%20by%20click%20the%20right%20Learn%20More%20button.%20%7C%20Access%20Code%20can%20protect%20your%20website&amp;envLink=https%3A%2F%2Fplatform.openai.com%2Faccount%2Fapi-keys&amp;project-name=lobe-chat&amp;repository-name=lobe-chat"><img alt="" src="https://vercel.com/button" /></a></td> 
    <td align="center"><a href="https://zeabur.com/templates/VZGGTI"><img alt="" src="https://zeabur.com/button.svg?sanitize=true" /></a></td> 
    <td align="center"><a href="https://cloud.sealos.io/?openapp=system-template%3FtemplateName%3Dlobe-chat"><img alt="" src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg?sanitize=true" /></a></td> 
    <td align="center"><a href="https://repocloud.io/details/?app_id=248"><img alt="" src="https://d16t0pc4846x52.cloudfront.net/deploylobe.svg?sanitize=true" /></a></td> 
   </tr> 
  </tbody> 
 </table> 
</div> 
<h4>After Fork</h4> 
<p>After fork, only retain the upstream sync action and disable other actions in your repository on GitHub.</p> 
<h4>Keep Updated</h4> 
<p>If you have deployed your own project following the one-click deployment steps in the README, you might encounter constant prompts indicating "updates available." This is because Vercel defaults to creating a new project instead of forking this one, resulting in an inability to detect updates accurately.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>We suggest you redeploy using the following steps, <a href="https://lobehub.com/docs/self-hosting/advanced/upstream-sync">📘 Auto Sync With Latest</a></p> 
</blockquote> 
<br /> 
<h3><code>B</code> Deploying with Docker</h3> 
<p><a href="https://hub.docker.com/r/lobehub/lobe-chat"><img alt="" src="https://img.shields.io/docker/v/lobehub/lobe-chat?color=369eff&amp;label=docker&amp;labelColor=black&amp;logo=docker&amp;logoColor=white&amp;style=flat-square" /></a> <a href="https://hub.docker.com/r/lobehub/lobe-chat"><img alt="" src="https://img.shields.io/docker/image-size/lobehub/lobe-chat?color=369eff&amp;labelColor=black&amp;style=flat-square" /></a> <a href="https://hub.docker.com/r/lobehub/lobe-chat"><img alt="" src="https://img.shields.io/docker/pulls/lobehub/lobe-chat?color=45cc11&amp;labelColor=black&amp;style=flat-square" /></a></p> 
<p>We provide a Docker image for deploying the LobeChat service on your own private device. Use the following command to start the LobeChat service:</p> 
<pre><code class="language-fish">$ docker run -d -p 3210:3210 \
  -e OPENAI_API_KEY=sk-xxxx \
  -e ACCESS_CODE=lobe66 \
  --name lobe-chat \
  lobehub/lobe-chat
</code></pre> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>If you need to use the OpenAI service through a proxy, you can configure the proxy address using the <code>OPENAI_PROXY_URL</code> environment variable:</p> 
</blockquote> 
<pre><code class="language-fish">$ docker run -d -p 3210:3210 \
  -e OPENAI_API_KEY=sk-xxxx \
  -e OPENAI_PROXY_URL=https://api-proxy.com/v1 \
  -e ACCESS_CODE=lobe66 \
  --name lobe-chat \
  lobehub/lobe-chat
</code></pre> 
<blockquote> 
 <p>[!NOTE]</p> 
 <p>For detailed instructions on deploying with Docker, please refer to the <a href="https://lobehub.com/docs/self-hosting/platform/docker">📘 Docker Deployment Guide</a></p> 
</blockquote> 
<br /> 
<h3>Environment Variable</h3> 
<p>This project provides some additional configuration items set with environment variables:</p> 
<table> 
 <thead> 
  <tr> 
   <th>Environment Variable</th> 
   <th>Required</th> 
   <th>Description</th> 
   <th>Example</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><code>OPENAI_API_KEY</code></td> 
   <td>Yes</td> 
   <td>This is the API key you apply on the OpenAI account page</td> 
   <td><code>sk-xxxxxx...xxxxxx</code></td> 
  </tr> 
  <tr> 
   <td><code>OPENAI_PROXY_URL</code></td> 
   <td>No</td> 
   <td>If you manually configure the OpenAI interface proxy, you can use this configuration item to override the default OpenAI API request base URL</td> 
   <td><code>https://api.chatanywhere.cn</code> or <code>https://aihubmix.com/v1</code> <br />The default value is<br /><code>https://api.openai.com/v1</code></td> 
  </tr> 
  <tr> 
   <td><code>ACCESS_CODE</code></td> 
   <td>No</td> 
   <td>Add a password to access this service; you can set a long password to avoid leaking. If this value contains a comma, it is a password array.</td> 
   <td><code>awCTe)re_r74</code> or <code>rtrt_ewee3@09!</code> or <code>code1,code2,code3</code></td> 
  </tr> 
  <tr> 
   <td><code>OPENAI_MODEL_LIST</code></td> 
   <td>No</td> 
   <td>Used to control the model list. Use <code>+</code> to add a model, <code>-</code> to hide a model, and <code>model_name=display_name</code> to customize the display name of a model, separated by commas.</td> 
   <td><code>qwen-7b-chat,+glm-6b,-gpt-3.5-turbo</code></td> 
  </tr> 
 </tbody> 
</table> 
<blockquote> 
 <p>[!NOTE]</p> 
 <p>The complete list of environment variables can be found in the <a href="https://lobehub.com/docs/self-hosting/environment-variables">📘 Environment Variables</a></p> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>📦 Ecosystem</h2> 
<table> 
 <thead> 
  <tr> 
   <th>NPM</th> 
   <th>Repository</th> 
   <th>Description</th> 
   <th>Version</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://www.npmjs.com/package/@lobehub/ui">@lobehub/ui</a></td> 
   <td><a href="https://github.com/lobehub/lobe-ui">lobehub/lobe-ui</a></td> 
   <td>Open-source UI component library dedicated to building AIGC web applications.</td> 
   <td><a href="https://www.npmjs.com/package/@lobehub/ui"><img alt="" src="https://img.shields.io/npm/v/@lobehub/ui?color=369eff&amp;labelColor=black&amp;logo=npm&amp;logoColor=white&amp;style=flat-square" /></a></td> 
  </tr> 
  <tr> 
   <td><a href="https://www.npmjs.com/package/@lobehub/icons">@lobehub/icons</a></td> 
   <td><a href="https://github.com/lobehub/lobe-icons">lobehub/lobe-icons</a></td> 
   <td>Popular AI / LLM Model Brand SVG Logo and Icon Collection.</td> 
   <td><a href="https://www.npmjs.com/package/@lobehub/icons"><img alt="" src="https://img.shields.io/npm/v/@lobehub/icons?color=369eff&amp;labelColor=black&amp;logo=npm&amp;logoColor=white&amp;style=flat-square" /></a></td> 
  </tr> 
  <tr> 
   <td><a href="https://www.npmjs.com/package/@lobehub/tts">@lobehub/tts</a></td> 
   <td><a href="https://github.com/lobehub/lobe-tts">lobehub/lobe-tts</a></td> 
   <td>High-quality &amp; reliable TTS/STT React Hooks library</td> 
   <td><a href="https://www.npmjs.com/package/@lobehub/tts"><img alt="" src="https://img.shields.io/npm/v/@lobehub/tts?color=369eff&amp;labelColor=black&amp;logo=npm&amp;logoColor=white&amp;style=flat-square" /></a></td> 
  </tr> 
  <tr> 
   <td><a href="https://www.npmjs.com/package/@lobehub/lint">@lobehub/lint</a></td> 
   <td><a href="https://github.com/lobehub/lobe-lint">lobehub/lobe-lint</a></td> 
   <td>Configurations for ESlint, Stylelint, Commitlint, Prettier, Remark, and Semantic Release for LobeHub.</td> 
   <td><a href="https://www.npmjs.com/package/@lobehub/lint"><img alt="" src="https://img.shields.io/npm/v/@lobehub/lint?color=369eff&amp;labelColor=black&amp;logo=npm&amp;logoColor=white&amp;style=flat-square" /></a></td> 
  </tr> 
 </tbody> 
</table> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>🧩 Plugins</h2> 
<p>Plugins provide a means to extend the <a href="https://lobehub.com/blog/openai-function-call">Function Calling</a> capabilities of LobeChat. They can be used to introduce new function calls and even new ways to render message results. If you are interested in plugin development, please refer to our <a href="https://lobehub.com/docs/usage/plugins/development">📘 Plugin Development Guide</a> in the Wiki.</p> 
<ul> 
 <li><a href="https://github.com/lobehub/lobe-chat-plugins">lobe-chat-plugins</a>: This is the plugin index for LobeChat. It accesses index.json from this repository to display a list of available plugins for LobeChat to the user.</li> 
 <li><a href="https://github.com/lobehub/chat-plugin-template">chat-plugin-template</a>: This is the plugin template for LobeChat plugin development.</li> 
 <li><a href="https://github.com/lobehub/chat-plugin-sdk">@lobehub/chat-plugin-sdk</a>: The LobeChat Plugin SDK assists you in creating exceptional chat plugins for Lobe Chat.</li> 
 <li><a href="https://github.com/lobehub/chat-plugins-gateway">@lobehub/chat-plugins-gateway</a>: The LobeChat Plugins Gateway is a backend service that provides a gateway for LobeChat plugins. We deploy this service using Vercel. The primary API POST /api/v1/runner is deployed as an Edge Function.</li> 
</ul> 
<blockquote> 
 <p>[!NOTE]</p> 
 <p>The plugin system is currently undergoing major development. You can learn more in the following issues:</p> 
 <ul> 
  <li>[x] <a href="https://github.com/lobehub/lobe-chat/issues/73"><strong>Plugin Phase 1</strong></a>: Implement separation of the plugin from the main body, split the plugin into an independent repository for maintenance, and realize dynamic loading of the plugin.</li> 
  <li>[x] <a href="https://github.com/lobehub/lobe-chat/issues/97"><strong>Plugin Phase 2</strong></a>: The security and stability of the plugin's use, more accurately presenting abnormal states, the maintainability of the plugin architecture, and developer-friendly.</li> 
  <li>[x] <a href="https://github.com/lobehub/lobe-chat/issues/149"><strong>Plugin Phase 3</strong></a>: Higher-level and more comprehensive customization capabilities, support for plugin authentication, and examples.</li> 
 </ul> 
</blockquote> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>⌨️ Local Development</h2> 
<p>You can use GitHub Codespaces for online development:</p> 
<p><a href="https://codespaces.new/lobehub/lobe-chat"><img alt="" src="https://github.com/codespaces/badge.svg?sanitize=true" /></a></p> 
<p>Or clone it for local development:</p> 
<pre><code class="language-fish">$ git clone https://github.com/lobehub/lobe-chat.git
$ cd lobe-chat
$ pnpm install
$ pnpm dev
</code></pre> 
<p>If you would like to learn more details, please feel free to look at our <a href="https://github.com/lobehub/lobe-chat/wiki/index">📘 Development Guide</a>.</p> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>🤝 Contributing</h2> 
<p>Contributions of all types are more than welcome; if you are interested in contributing code, feel free to check out our GitHub <a href="https://github.com/lobehub/lobe-chat/issues">Issues</a> and <a href="https://github.com/lobehub/lobe-chat/projects">Projects</a> to get stuck in to show us what you’re made of.</p> 
<blockquote> 
 <p>[!TIP]</p> 
 <p>We are creating a technology-driven forum, fostering knowledge interaction and the exchange of ideas that may culminate in mutual inspiration and collaborative innovation.</p> 
 <p>Help us make LobeChat better. Welcome to provide product design feedback, user experience discussions directly to us.</p> 
 <p><strong>Principal Maintainers:</strong> <a href="https://github.com/arvinxx">@arvinxx</a> <a href="https://github.com/canisminor1990">@canisminor1990</a></p> 
</blockquote> 
<p><a href="https://github.com/lobehub/lobe-chat/pulls"><img alt="" src="https://img.shields.io/badge/%F0%9F%A4%AF_pr_welcome-%E2%86%92-ffcb47?labelColor=black&amp;style=for-the-badge" /></a> <a href="https://github.com/lobehub/lobe-chat-agents"><img alt="" src="https://img.shields.io/badge/%F0%9F%A4%96/%F0%9F%8F%AA_submit_agent-%E2%86%92-c4f042?labelColor=black&amp;style=for-the-badge" /></a> <a href="https://github.com/lobehub/lobe-chat-plugins"><img alt="" src="https://img.shields.io/badge/%F0%9F%A7%A9/%F0%9F%8F%AA_submit_plugin-%E2%86%92-95f3d9?labelColor=black&amp;style=for-the-badge" /></a></p> 
<a href="https://github.com/lobehub/lobe-chat/graphs/contributors" target="_blank"> 
 <table> 
  <tbody>
   <tr> 
    <th colspan="2"> <br /><img src="https://contrib.rocks/image?repo=lobehub/lobe-chat" /><br /><br /> </th> 
   </tr> 
   <tr> 
    <td> 
      
      <source media="(prefers-color-scheme: dark)" /> 
      <img src="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;period=past_28_days&amp;owner_id=131470832&amp;repo_ids=643445235&amp;image_size=2x3&amp;color_scheme=light" /> 
      </td> 
    <td rowspan="2"> 
      
      <source media="(prefers-color-scheme: dark)" /> 
      <img src="https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&amp;period=past_28_days&amp;owner_id=131470832&amp;repo_ids=643445235&amp;image_size=4x7&amp;color_scheme=light" /> 
      </td> 
   </tr> 
   <tr> 
    <td> 
      
      <source media="(prefers-color-scheme: dark)" /> 
      <img src="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=131470832&amp;repo_ids=643445235&amp;image_size=2x3&amp;color_scheme=light" /> 
      </td> 
   </tr> 
  </tbody>
 </table> </a> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>❤️ Sponsor</h2> 
<p>Every bit counts and your one-time donation sparkles in our galaxy of support! You're a shooting star, making a swift and bright impact on our journey. Thank you for believing in us – your generosity guides us toward our mission, one brilliant flash at a time.</p> 
<a href="https://opencollective.com/lobehub" target="_blank"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <img src="https://github.com/lobehub/.github/raw/main/static/sponsor-light.png?raw=true" /> 
  </a> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<h2>🔗 More Products</h2> 
<ul> 
 <li><strong><a href="https://github.com/lobehub/sd-webui-lobe-theme">🅰️ Lobe SD Theme</a>:</strong> Modern theme for Stable Diffusion WebUI, exquisite interface design, highly customizable UI, and efficiency-boosting features.</li> 
 <li><strong><a href="https://github.com/lobehub/lobe-midjourney-webui">⛵️ Lobe Midjourney WebUI</a>:</strong> WebUI for Midjourney, leverages AI to quickly generate a wide array of rich and diverse images from text prompts, sparking creativity and enhancing conversations.</li> 
 <li><strong><a href="https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-i18n">🌏 Lobe i18n</a> :</strong> Lobe i18n is an automation tool for the i18n (internationalization) translation process, powered by ChatGPT. It supports features such as automatic splitting of large files, incremental updates, and customization options for the OpenAI model, API proxy, and temperature.</li> 
 <li><strong><a href="https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-commit">💌 Lobe Commit</a>:</strong> Lobe Commit is a CLI tool that leverages Langchain/ChatGPT to generate Gitmoji-based commit messages.</li> 
</ul> 
<div align="right"> 
 <p><a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"><img alt="" src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" /></a></p> 
</div> 
<hr /> 
<details>
 <h4>📝 License</h4> 
 <p><a href="https://app.fossa.com/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat"><img alt="" src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat.svg?type=large" /></a></p> 
</details> 
<p>Copyright © 2024 <a href="https://github.com/lobehub">LobeHub</a>. <br /> This project is <a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/LICENSE">Apache 2.0</a> licensed.</p> 
<!-- LINK GROUP -->
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>anthropics/anthropic-cookbook</title>
<link>https://github.com/anthropics/anthropic-cookbook</link>
<guid>https://github.com/anthropics/anthropic-cookbook</guid>
<content:encoded><![CDATA[
<div> 关键词：Anthropic API, Claude, 开发者, Python, 文本生成

总结:
本文介绍了《Anthropic 食谱》这一资源，旨在帮助开发者利用 Claude 建设项目。为了充分利用食谱中的示例，您需要一个免费的 Anthropic API 密钥。尽管示例主要以 Python 编写，但其概念适用于任何支持与 Anthropic API 交互的编程语言。初学者建议从官方指南开始学习。

探索进一步的内容包括更多增强与 Claude 和 AI 助手体验的资源链接。《Anthropic 食谱》通过贡献机制持续发展，鼓励开发者提交想法、修正错误、添加新指南或改进现有内容，以提升资源价值。通过检查现有问题和拉取请求来避免重复努力。

食谱分为几个部分，包括技能、工具使用和集成、第三方集成、多模态能力、高级技术以及额外资源。这些部分涵盖了从基本到高级的使用案例，如让 Claude 引用来源、文本分类、知识增强、文本摘要、与外部工具集成、补充知识、图像生成等。此外，还包括了在 AWS 基础设施中使用 Claude 的示例和代码样本。

《Anthropic 食谱》是一个动态资源库，旨在为开发者提供丰富的灵感和实用技巧，以充分发挥 Claude 的潜力，并促进其在各种场景下的应用。 <div>
<p>A collection of notebooks/recipes showcasing some fun and effective ways of using Claude.</p><hr /><h1>Anthropic Cookbook</h1> 
<p>The Anthropic Cookbook provides code and guides designed to help developers build with Claude, offering copy-able code snippets that you can easily integrate into your own projects.</p> 
<h2>Prerequisites</h2> 
<p>To make the most of the examples in this cookbook, you'll need an Anthropic API key (sign up for free <a href="https://www.anthropic.com">here</a>).</p> 
<p>While the code examples are primarily written in Python, the concepts can be adapted to any programming language that supports interaction with the Anthropic API.</p> 
<p>If you're new to working with the Anthropic API, we recommend starting with our <a href="https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals">Anthropic API Fundamentals course</a> to get a solid foundation.</p> 
<h2>Explore Further</h2> 
<p>Looking for more resources to enhance your experience with Claude and AI assistants? Check out these helpful links:</p> 
<ul> 
 <li><a href="https://docs.anthropic.com/claude/docs/guide-to-anthropics-prompt-engineering-resources">Anthropic developer documentation</a></li> 
 <li><a href="https://support.anthropic.com">Anthropic support docs</a></li> 
 <li><a href="https://www.anthropic.com/discord">Anthropic Discord community</a></li> 
</ul> 
<h2>Contributing</h2> 
<p>The Anthropic Cookbook thrives on the contributions of the developer community. We value your input, whether it's submitting an idea, fixing a typo, adding a new guide, or improving an existing one. By contributing, you help make this resource even more valuable for everyone.</p> 
<p>To avoid duplication of efforts, please review the existing issues and pull requests before contributing.</p> 
<p>If you have ideas for new examples or guides, share them on the <a href="https://github.com/anthropics/anthropic-cookbook/issues">issues page</a>.</p> 
<h2>Table of recipes</h2> 
<h3>Skills</h3> 
<ul> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/citations">Citations</a>: Learn how to prompt Claude to cite sources in its responses.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/classification">Classification</a>: Explore techniques for text and data classification using Claude.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/retrieval_augmented_generation">Retrieval Augmented Generation</a>: Learn how to enhance Claude's responses with external knowledge.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/summarization">Summarization</a>: Discover techniques for effective text summarization with Claude.</li> 
</ul> 
<h3>Tool Use and Integration</h3> 
<ul> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/tool_use">Tool use</a>: Learn how to integrate Claude with external tools and functions to extend its capabilities. 
  <ul> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/tool_use/customer_service_agent.ipynb">Customer service agent</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/tool_use/calculator_tool.ipynb">Calculator integration</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/how_to_make_sql_queries.ipynb">SQL queries</a></li> 
  </ul> </li> 
</ul> 
<h3>Third-Party Integrations</h3> 
<ul> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/third_party">Retrieval augmented generation</a>: Supplement Claude's knowledge with external data sources. 
  <ul> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/Pinecone/rag_using_pinecone.ipynb">Vector databases (Pinecone)</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/Wikipedia/wikipedia-search-cookbook.ipynb/">Wikipedia</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/read_web_pages_with_haiku.ipynb">Web pages</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/Brave/web_search_using_brave.ipynb">Internet search (Brave)</a></li> 
  </ul> </li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/VoyageAI/how_to_create_embeddings.md">Embeddings with Voyage AI</a></li> 
</ul> 
<h3>Multimodal Capabilities</h3> 
<ul> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/tree/main/multimodal">Vision with Claude</a>: 
  <ul> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/getting_started_with_vision.ipynb">Getting started with images</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/best_practices_for_vision.ipynb">Best practices for vision</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/reading_charts_graphs_powerpoints.ipynb">Interpreting charts and graphs</a></li> 
   <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/how_to_transcribe_text.ipynb">Extracting content from forms</a></li> 
  </ul> </li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/illustrated_responses.ipynb">Generate images with Claude</a>: Use Claude with Stable Diffusion for image generation.</li> 
</ul> 
<h3>Advanced Techniques</h3> 
<ul> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/using_sub_agents.ipynb">Sub-agents</a>: Learn how to use Haiku as a sub-agent in combination with Opus.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/pdf_upload_summarization.ipynb">Upload PDFs to Claude</a>: Parse and pass PDFs as text to Claude.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/building_evals.ipynb">Automated evaluations</a>: Use Claude to automate the prompt evaluation process.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/how_to_enable_json_mode.ipynb">Enable JSON mode</a>: Ensure consistent JSON output from Claude.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/building_moderation_filter.ipynb">Create a moderation filter</a>: Use Claude to create a content moderation filter for your application.</li> 
 <li><a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/prompt_caching.ipynb">Prompt caching</a>: Learn techniques for efficient prompt caching with Claude.</li> 
</ul> 
<h2>Additional Resources</h2> 
<ul> 
 <li><a href="https://github.com/aws-samples/anthropic-on-aws">Anthropic on AWS</a>: Explore examples and solutions for using Claude on AWS infrastructure.</li> 
 <li><a href="https://github.com/aws-samples/">AWS Samples</a>: A collection of code samples from AWS which can be adapted for use with Claude. Note that some samples may require modification to work optimally with Claude.</li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>deepfakes/faceswap</title>
<link>https://github.com/deepfakes/faceswap</link>
<guid>https://github.com/deepfakes/faceswap</guid>
<content:encoded><![CDATA[
<div> 关键词：FaceSwap、AI技术、伦理使用、学习机会、开源项目

总结：
FaceSwap是一个基于深度学习的工具，用于在图片和视频中识别并替换人脸。最初，这项技术的发布和应用代表了人工智能领域的一个重要进步，但它也很快被用于不当内容的创建，这主要归因于代码的复杂性和对技术的不正确理解。然而，开发者们强调，FaceSwap的初衷是为了提供一个易于获取、运行和实验的AI平台，无需深厚的数学、计算机理论、心理学等专业知识。他们坚持使用FaceSwap进行道德和合理的用途，如实验、社会或政治评论、电影制作等。

为了设置和运行项目，用户需要遵循详细的安装说明，确保系统兼容性，并使用Python脚本执行关键步骤，包括从原始文件中提取人脸、训练模型以及将新面孔应用到原始图像上。开发人员还提供了一个图形界面（GUI）作为替代方案，并建议用户在遇到问题时加入支持社区以获取帮助。

开发者们呼吁关注伦理使用，承诺对任何不道德的用途采取零容忍政策，并鼓励通过捐赠来支持项目的持续发展。此外，社区成员可以通过参与开源项目、贡献代码、报告问题或提供反馈来为FaceSwap的发展做出贡献。对于希望深入了解AI工作原理的人，推荐了一些教程资源。

最后，FaceSwap的命名虽与“深伪造”一词相似，但其并非针对该特定应用，而是为了纪念原作者，同时便于吸引更多贡献者和用户。 <div>
<p>Deepfakes Software For All</p><hr /><h1>deepfakes_faceswap</h1> 
<p align="center"> <a href="https://faceswap.dev"><img src="https://i.imgur.com/zHvjHnb.png" /></a> <br />FaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos. </p> 
<p align="center"> <img src="https://i.imgur.com/nWHFLDf.jpg" /> </p> 
<p align="center"> <a href="https://www.patreon.com/bePatron?u=23238350"><img src="https://c5.patreon.com/external/logo/become_a_patron_button.png" /></a> &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://discord.gg/FC54sYg"><img src="https://i.imgur.com/gIpztkv.png" /></a></p> 
<p align="center"> <a href="https://www.dailymotion.com/video/x810mot"><img src="https://user-images.githubusercontent.com/36920800/178301720-b69841bb-a1ca-4c20-91db-a2a10f5692ca.png" /></a> <br />Emma Stone/Scarlett Johansson FaceSwap using the Phaze-A model </p> 
<p align="center"> <a href="https://www.youtube.com/watch?v=r1jng79a5xc"><img src="https://img.youtube.com/vi/r1jng79a5xc/0.jpg" /></a> <br />Jennifer Lawrence/Steve Buscemi FaceSwap using the Villain model </p> 
<p><img alt="Build Status" src="https://github.com/deepfakes/faceswap/actions/workflows/pytest.yml/badge.svg?sanitize=true" /> <a href="https://faceswap.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation Status" src="https://readthedocs.org/projects/faceswap/badge/?version=latest" /></a></p> 
<p>Make sure you check out <a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/INSTALL.md">INSTALL.md</a> before getting started.</p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#deepfakes_faceswap">deepfakes_faceswap</a></li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#manifesto">Manifesto</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#faceswap-has-ethical-uses">FaceSwap has ethical uses.</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#how-to-setup-and-run-the-project">How To setup and run the project</a></li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#overview">Overview</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#extract">Extract</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#train">Train</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#convert">Convert</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#gui">GUI</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#general-notes">General notes:</a></li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#help-i-need-support">Help I need support!</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#discord-server">Discord Server</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#faceswap-forum">FaceSwap Forum</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#donate">Donate</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#patreon">Patreon</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#one-time-donations">One time Donations</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#torzdf">@torzdf</a></li> 
     <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#andenixa">@andenixa</a></li> 
    </ul> </li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#how-to-contribute">How to contribute</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-people-interested-in-the-generative-models">For people interested in the generative models</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-devs">For devs</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-non-dev-advanced-users">For non-dev advanced users</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-end-users">For end-users</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-haters">For haters</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#about-githubcomdeepfakes">About github.com/deepfakes</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#what-is-this-repo">What is this repo?</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#why-this-repo">Why this repo?</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#why-is-it-named-deepfakes-if-it-is-not-udeepfakes">Why is it named 'deepfakes' if it is not /u/deepfakes?</a></li> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#what-if-udeepfakes-feels-bad-about-that">What if /u/deepfakes feels bad about that?</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#about-machine-learning">About machine learning</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network">How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?</a></li> 
  </ul> </li> 
</ul> 
<h1>Manifesto</h1> 
<h2>FaceSwap has ethical uses.</h2> 
<p>When faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before "deepfakes" these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.</p> 
<p>"Deepfakes" changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.</p> 
<p>Are there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don't even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.</p> 
<p>We are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this software is and isn't as far as us developers are concerned.</p> 
<ul> 
 <li>FaceSwap is not for creating inappropriate content.</li> 
 <li>FaceSwap is not for changing faces without consent or with the intent of hiding its use.</li> 
 <li>FaceSwap is not for any illicit, unethical, or questionable purposes.</li> 
 <li>FaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.</li> 
</ul> 
<p>We are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.</p> 
<h1>How To setup and run the project</h1> 
<p>FaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.</p> 
<p>See <a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/INSTALL.md">INSTALL.md</a> for full installation instructions. You will need a modern GPU with CUDA support for best performance. Many AMD GPUs are supported through DirectML (Windows) and ROCm (Linux).</p> 
<h1>Overview</h1> 
<p>The project has multiple entry points. You will have to:</p> 
<ul> 
 <li>Gather photos and/or videos</li> 
 <li><strong>Extract</strong> faces from your raw photos</li> 
 <li><strong>Train</strong> a model on the faces extracted from the photos/videos</li> 
 <li><strong>Convert</strong> your sources with the model</li> 
</ul> 
<p>Check out <a href="https://raw.githubusercontent.com/deepfakes/faceswap/master/USAGE.md">USAGE.md</a> for more detailed instructions.</p> 
<h2>Extract</h2> 
<p>From your setup folder, run <code>python faceswap.py extract</code>. This will take photos from <code>src</code> folder and extract faces into <code>extract</code> folder.</p> 
<h2>Train</h2> 
<p>From your setup folder, run <code>python faceswap.py train</code>. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the <code>models</code> folder.</p> 
<h2>Convert</h2> 
<p>From your setup folder, run <code>python faceswap.py convert</code>. This will take photos from <code>original</code> folder and apply new faces into <code>modified</code> folder.</p> 
<h2>GUI</h2> 
<p>Alternatively, you can run the GUI by running <code>python faceswap.py gui</code></p> 
<h1>General notes:</h1> 
<ul> 
 <li>All of the scripts mentioned have <code>-h</code>/<code>--help</code> options with arguments that they will accept. You're smart, you can figure out how this works, right?!</li> 
</ul> 
<p>NB: there is a conversion tool for video. This can be accessed by running <code>python tools.py effmpeg -h</code>. Alternatively, you can use <a href="https://www.ffmpeg.org">ffmpeg</a> to convert video into photos, process images, and convert images back to the video.</p> 
<p><strong>Some tips:</strong></p> 
<p>Reusing existing models will train much faster than starting from nothing. If there is not enough training data, start with someone who looks similar, then switch the data.</p> 
<h1>Help I need support!</h1> 
<h2>Discord Server</h2> 
<p>Your best bet is to join the <a href="https://discord.gg/FC54sYg">FaceSwap Discord server</a> where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!</p> 
<h2>FaceSwap Forum</h2> 
<p>Alternatively, you can post questions in the <a href="https://faceswap.dev/forum">FaceSwap Forum</a>. Please do not post general support questions in this repo as they are liable to be deleted without response.</p> 
<h1>Donate</h1> 
<p>The developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.</p> 
<h2>Patreon</h2> 
<p>The best way to support us is through our Patreon page:</p> 
<p><a href="https://www.patreon.com/bePatron?u=23238350"><img alt="become-a-patron" src="https://c5.patreon.com/external/logo/become_a_patron_button.png" /></a></p> 
<h2>One time Donations</h2> 
<p>Alternatively you can give a one off donation to any of our Devs:</p> 
<h3>@torzdf</h3> 
<p>There is very little FaceSwap code that hasn't been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.</p> 
<p><strong>Bitcoin:</strong> bc1qpm22suz59ylzk0j7qk5e4c7cnkjmve2rmtrnc6</p> 
<p><strong>Ethereum:</strong> 0xd3e954dC241B87C4E8E1A801ada485DC1d530F01</p> 
<p><strong>Monero:</strong> 45dLrtQZ2pkHizBpt3P3yyJKkhcFHnhfNYPMSnz3yVEbdWm3Hj6Kr5TgmGAn3Far8LVaQf1th2n3DJVTRkfeB5ZkHxWozSX</p> 
<p><strong>Paypal:</strong> <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=JZ8PP3YE9J62L"><img alt="torzdf" src="https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif" /></a></p> 
<h3>@andenixa</h3> 
<p>Creator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.</p> 
<p><strong>Paypal:</strong> <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=NRVLQYGS6NWTU"><img alt="andenixa" src="https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif" /></a></p> 
<h1>How to contribute</h1> 
<h2>For people interested in the generative models</h2> 
<ul> 
 <li>Go to the 'faceswap-model' to discuss/suggest/commit alternatives to the current algorithm.</li> 
</ul> 
<h2>For devs</h2> 
<ul> 
 <li>Read this README entirely</li> 
 <li>Fork the repo</li> 
 <li>Play with it</li> 
 <li>Check issues with the 'dev' tag</li> 
 <li>For devs more interested in computer vision and openCV, look at issues with the 'opencv' tag. Also feel free to add your own alternatives/improvements</li> 
</ul> 
<h2>For non-dev advanced users</h2> 
<ul> 
 <li>Read this README entirely</li> 
 <li>Clone the repo</li> 
 <li>Play with it</li> 
 <li>Check issues with the 'advuser' tag</li> 
 <li>Also go to the '<a href="https://faceswap.dev/forum">faceswap Forum</a>' and help others.</li> 
</ul> 
<h2>For end-users</h2> 
<ul> 
 <li>Get the code here and play with it if you can</li> 
 <li>You can also go to the <a href="https://faceswap.dev/forum">faceswap Forum</a> and help or get help from others.</li> 
 <li>Be patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!</li> 
 <li><strong>Notice</strong> Any issue related to running the code has to be opened in the <a href="https://faceswap.dev/forum">faceswap Forum</a>!</li> 
</ul> 
<h2>For haters</h2> 
<p>Sorry, no time for that.</p> 
<h1>About github.com/deepfakes</h1> 
<h2>What is this repo?</h2> 
<p>It is a community repository for active users.</p> 
<h2>Why this repo?</h2> 
<p>The joshua-wu repo seems not active. Simple bugs like missing <em>http://</em> in front of urls have not been solved since days.</p> 
<h2>Why is it named 'deepfakes' if it is not /u/deepfakes?</h2> 
<ol> 
 <li>Because a typosquat would have happened sooner or later as project grows</li> 
 <li>Because we wanted to recognize the original author</li> 
 <li>Because it will better federate contributors and users</li> 
</ol> 
<h2>What if /u/deepfakes feels bad about that?</h2> 
<p>This is a friendly typosquat, and it is fully dedicated to the project. If /u/deepfakes wants to take over this repo/user and drive the project, he is welcomed to do so (Raise an issue, and he will be contacted on Reddit). Please do not send /u/deepfakes messages for help with the code you find here.</p> 
<h1>About machine learning</h1> 
<h2>How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?</h2> 
<p>It's complicated. Here's a good video that makes the process understandable: <a href="https://www.youtube.com/watch?v=R9OHn5ZF4Uo"><img alt="How Machines Learn" src="https://img.youtube.com/vi/R9OHn5ZF4Uo/0.jpg" /></a></p> 
<p>Here's a slightly more in depth video that tries to explain the basic functioning of a neural network: <a href="https://www.youtube.com/watch?v=aircAruvnKk"><img alt="How Machines Learn" src="https://img.youtube.com/vi/aircAruvnKk/0.jpg" /></a></p> 
<p>tl;dr: training data + trial and error</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cinnamon/kotaemon</title>
<link>https://github.com/Cinnamon/kotaemon</link>
<guid>https://github.com/Cinnamon/kotaemon</guid>
<content:encoded><![CDATA[
<div> 关键词：kotaemon、RAG、QA、文档聊天、开放源码

总结：

kotaemon是一个基于RAG（Read, Annotate, Generate）技术的开源工具，旨在为用户提供一个简洁明了的界面来对文档进行质询和验证。它支持多种LLM API供应商（如OpenAI、AzureOpenAI、Cohere等）以及本地LLM（通过ollama和llama-cpp-python实现），提供一键安装脚本，使得用户能够轻松地在其应用中集成文档聊天功能。

对于开发者而言，kotaemon提供了一个构建自定义RAG文档质询流程的框架，允许他们利用预设的UI来展示和测试自己的RAG管道。此外，该框架还支持多用户登录、文档分类、协作共享等功能，并提供了丰富的配置选项，包括模型选择、提示调整等。

在安装方面，kotaemon提供了两种方式：通过Docker快速启动或在无Docker环境下的本地安装。为了充分利用应用功能，用户需要在.env文件中设置必要的API密钥、端点等信息，并可能需要下载并解压PDF预览所需的资源。

对于希望定制应用体验的用户，kotaemon提供了灵活的数据存储目录，并允许通过修改.flowsettings.py和.env文件来自定义应用行为，包括文档存储、向量检索、推理策略等。开发者还可以扩展应用功能，例如添加自定义推理或索引策略，以满足特定需求。

通过kotaemon，无论是普通用户还是开发者都能便捷地将文档聊天功能集成到其应用中，提升内容质量和用户体验。 <div>
<p>An open-source RAG-based tool for chatting with your documents.</p><hr /><h1>kotaemon</h1> 
<p>An open-source clean &amp; customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.</p> 
<p><img alt="Preview" src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview-graph.png" /></p> 
<p><a href="https://huggingface.co/spaces/cin-model/kotaemon-demo">Live Demo</a> | <a href="https://github.com/Cinnamon/kotaemon">Source Code</a></p> 
<p><a href="https://cinnamon.github.io/kotaemon/">User Guide</a> | <a href="https://cinnamon.github.io/kotaemon/development/">Developer Guide</a> | <a href="https://github.com/Cinnamon/kotaemon/issues">Feedback</a></p> 
<p><a href="https://www.python.org/downloads/release/python-31013/"><img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true" /></a> <a href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" /></a> <a href="https://hub.docker.com/r/taprosoft/kotaemon" target="_blank"> <img alt="docker pull taprosoft/kotaemon:v1.0" src="https://img.shields.io/badge/docker_pull-kotaemon:v1.0-brightgreen" /></a> <a href="https://codeium.com"><img alt="built with Codeium" src="https://codeium.com/badges/main" /></a> <a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" /></a></p> 
<h2>Introduction</h2> 
<p>This project serves as a functional RAG UI for both end users who want to do QA on their documents and developers who want to build their own RAG pipeline.</p> 
<ul> 
 <li>For end users: 
  <ul> 
   <li>A clean &amp; minimalistic UI for RAG-based QA.</li> 
   <li>Supports LLM API providers (OpenAI, AzureOpenAI, Cohere, etc) and local LLMs (via <code>ollama</code> and <code>llama-cpp-python</code>).</li> 
   <li>Easy installation scripts.</li> 
  </ul> </li> 
 <li>For developers: 
  <ul> 
   <li>A framework for building your own RAG-based document QA pipeline.</li> 
   <li>Customize and see your RAG pipeline in action with the provided UI (built with <a href="https://github.com/gradio-app/gradio">Gradio <img src="https://img.shields.io/github/stars/gradio-app/gradio" /></a>).</li> 
  </ul> </li> 
</ul> 
<pre><code class="language-yml">+----------------------------------------------------------------------------+
| End users: Those who use apps built with `kotaemon`.                       |
| (You use an app like the one in the demo above)                            |
|     +----------------------------------------------------------------+     |
|     | Developers: Those who built with `kotaemon`.                   |     |
|     | (You have `import kotaemon` somewhere in your project)         |     |
|     |     +----------------------------------------------------+     |     |
|     |     | Contributors: Those who make `kotaemon` better.    |     |     |
|     |     | (You make PR to this repo)                         |     |     |
|     |     +----------------------------------------------------+     |     |
|     +----------------------------------------------------------------+     |
+----------------------------------------------------------------------------+
</code></pre> 
<p>This repository is under active development. Feedback, issues, and PRs are highly appreciated.</p> 
<h2>Key Features</h2> 
<ul> 
 <li> <p><strong>Host your own document QA (RAG) web-UI</strong>. Support multi-user login, organize your files in private / public collections, collaborate and share your favorite chat with others.</p> </li> 
 <li> <p><strong>Organize your LLM &amp; Embedding models</strong>. Support both local LLMs &amp; popular API providers (OpenAI, Azure, Ollama, Groq).</p> </li> 
 <li> <p><strong>Hybrid RAG pipeline</strong>. Sane default RAG pipeline with hybrid (full-text &amp; vector) retriever + re-ranking to ensure best retrieval quality.</p> </li> 
 <li> <p><strong>Multi-modal QA support</strong>. Perform Question Answering on multiple documents with figures &amp; tables support. Support multi-modal document parsing (selectable options on UI).</p> </li> 
 <li> <p><strong>Advance citations with document preview</strong>. By default the system will provide detailed citations to ensure the correctness of LLM answers. View your citations (incl. relevant score) directly in the <em>in-browser PDF viewer</em> with highlights. Warning when retrieval pipeline return low relevant articles.</p> </li> 
 <li> <p><strong>Support complex reasoning methods</strong>. Use question decomposition to answer your complex / multi-hop question. Support agent-based reasoning with ReAct, ReWOO and other agents.</p> </li> 
 <li> <p><strong>Configurable settings UI</strong>. You can adjust most important aspects of retrieval &amp; generation process on the UI (incl. prompts).</p> </li> 
 <li> <p><strong>Extensible</strong>. Being built on Gradio, you are free to customize / add any UI elements as you like. Also, we aim to support multiple strategies for document indexing &amp; retrieval. <code>GraphRAG</code> indexing pipeline is provided as an example.</p> </li> 
</ul> 
<p><img alt="Preview" src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview.png" /></p> 
<h2>Installation</h2> 
<h3>For end users</h3> 
<p>This document is intended for developers. If you just want to install and use the app as it is, please follow the non-technical <a href="https://cinnamon.github.io/kotaemon/">User Guide</a> (WIP).</p> 
<h3>For developers</h3> 
<h4>With Docker (recommended)</h4> 
<ul> 
 <li>Use this command to launch the server</li> 
</ul> 
<pre><code>docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-p 7860:7860 -it --rm \
taprosoft/kotaemon:v1.0
</code></pre> 
<p>Navigate to <code>http://localhost:7860/</code> to access the web UI.</p> 
<h4>Without Docker</h4> 
<ul> 
 <li>Clone and install required packages on a fresh python environment.</li> 
</ul> 
<pre><code class="language-shell"># optional (setup env)
conda create -n kotaemon python=3.10
conda activate kotaemon

# clone this repo
git clone https://github.com/Cinnamon/kotaemon
cd kotaemon

pip install -e "libs/kotaemon[all]"
pip install -e "libs/ktem"
</code></pre> 
<ul> 
 <li> <p>View and edit your environment variables (API keys, end-points) in <code>.env</code>.</p> </li> 
 <li> <p>(Optional) To enable in-browser PDF_JS viewer, download <a href="https://github.com/mozilla/pdf.js/releases/download/v4.0.379/pdfjs-4.0.379-dist.zip">PDF_JS_DIST</a> and extract it to <code>libs/ktem/ktem/assets/prebuilt</code></p> </li> 
</ul> 
<img alt="pdf-setup" src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/pdf-viewer-setup.png" width="300" /> 
<ul> 
 <li>Start the web server:</li> 
</ul> 
<pre><code class="language-shell">python app.py
</code></pre> 
<p>The app will be automatically launched in your browser.</p> 
<p>Default username / password are: <code>admin</code> / <code>admin</code>. You can setup additional users directly on the UI.</p> 
<p><img alt="Chat tab" src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/chat-tab.png" /></p> 
<h2>Setup local models (for local / private RAG)</h2> 
<p>See <a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/local_model.md">Local model setup</a>.</p> 
<h2>Customize your application</h2> 
<p>By default, all application data are stored in <code>./ktem_app_data</code> folder. You can backup or copy this folder to move your installation to a new machine.</p> 
<p>For advance users or specific use-cases, you can customize those files:</p> 
<ul> 
 <li><code>flowsettings.py</code></li> 
 <li><code>.env</code></li> 
</ul> 
<h3><code>flowsettings.py</code></h3> 
<p>This file contains the configuration of your application. You can use the example <a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/flowsettings.py">here</a> as the starting point.</p> 
<details> 
 Notable settings 
 <pre><code># setup your preferred document store (with full-text search capabilities)
KH_DOCSTORE=(Elasticsearch | LanceDB | SimpleFileDocumentStore)

# setup your preferred vectorstore (for vector-based search)
KH_VECTORSTORE=(ChromaDB | LanceDB | InMemory)

# Enable / disable multimodal QA
KH_REASONINGS_USE_MULTIMODAL=True

# Setup your new reasoning pipeline or modify existing one.
KH_REASONINGS = [
    "ktem.reasoning.simple.FullQAPipeline",
    "ktem.reasoning.simple.FullDecomposeQAPipeline",
    "ktem.reasoning.react.ReactAgentPipeline",
    "ktem.reasoning.rewoo.RewooAgentPipeline",
]
)
</code></pre> 
</details> 
<h3><code>.env</code></h3> 
<p>This file provides another way to configure your models and credentials.</p> 
<details> 
 Configure model via the .env file 
 <p>Alternatively, you can configure the models via the <code>.env</code> file with the information needed to connect to the LLMs. This file is located in the folder of the application. If you don't see it, you can create one.</p> 
 <p>Currently, the following providers are supported:</p> 
 <h4>OpenAI</h4> 
 <p>In the <code>.env</code> file, set the <code>OPENAI_API_KEY</code> variable with your OpenAI API key in order to enable access to OpenAI's models. There are other variables that can be modified, please feel free to edit them to fit your case. Otherwise, the default parameter should work for most people.</p> 
 <pre><code class="language-shell">OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=&lt;your OpenAI API key here&gt;
OPENAI_CHAT_MODEL=gpt-3.5-turbo
OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002
</code></pre> 
 <h4>Azure OpenAI</h4> 
 <p>For OpenAI models via Azure platform, you need to provide your Azure endpoint and API key. Your might also need to provide your developments' name for the chat model and the embedding model depending on how you set up Azure development.</p> 
 <pre><code class="language-shell">AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002
</code></pre> 
 <h4>Local models</h4> 
 <h5>Using ollama OpenAI compatible server</h5> 
 <p>Install <a href="https://github.com/ollama/ollama">ollama</a> and start the application.</p> 
 <p>Pull your model (e.g):</p> 
 <pre><code>ollama pull llama3.1:8b
ollama pull nomic-embed-text
</code></pre> 
 <p>Set the model names on web UI and make it as default.</p> 
 <p><img alt="Models" src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/models.png" /></p> 
 <h5>Using GGUF with llama-cpp-python</h5> 
 <p>You can search and download a LLM to be ran locally from the <a href="https://huggingface.co/models">Hugging Face Hub</a>. Currently, these model formats are supported:</p> 
 <ul> 
  <li>GGUF</li> 
 </ul> 
 <p>You should choose a model whose size is less than your device's memory and should leave about 2 GB. For example, if you have 16 GB of RAM in total, of which 12 GB is available, then you should choose a model that takes up at most 10 GB of RAM. Bigger models tend to give better generation but also take more processing time.</p> 
 <p>Here are some recommendations and their size in memory:</p> 
 <ul> 
  <li><a href="https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true">Qwen1.5-1.8B-Chat-GGUF</a>: around 2 GB</li> 
 </ul> 
 <p>Add a new LlamaCpp model with the provided model name on the web uI.</p> 
</details> 
<h2>Adding your own RAG pipeline</h2> 
<h4>Custom reasoning pipeline</h4> 
<p>First, check the default pipeline implementation in <a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/libs/ktem/ktem/reasoning/simple.py">here</a>. You can make quick adjustment to how the default QA pipeline work.</p> 
<p>Next, if you feel comfortable adding new pipeline, add new <code>.py</code> implementation in <code>libs/ktem/ktem/reasoning/</code> and later include it in <code>flowssettings</code> to enable it on the UI.</p> 
<h4>Custom indexing pipeline</h4> 
<p>Check sample implementation in <code>libs/ktem/ktem/index/file/graph</code></p> 
<p>(more instruction WIP).</p> 
<h2>Developer guide</h2> 
<p>Please refer to the <a href="https://cinnamon.github.io/kotaemon/development/">Developer Guide</a> for more details.</p> 
<h2>Star History</h2> 
<a href="https://star-history.com/#Cinnamon/kotaemon&amp;Date"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <source media="(prefers-color-scheme: light)" /> 
  <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;type=Date" /> 
  </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>dokku/dokku</title>
<link>https://github.com/dokku/dokku</link>
<guid>https://github.com/dokku/dokku</guid>
<content:encoded><![CDATA[
<div> 关键词：Dokku、PaaS、Docker、Heroku、安装

文章总结：

Dokku 是一款基于 Docker 的 PaaS（平台即服务）工具，它旨在帮助开发者构建和管理应用程序的整个生命周期。Dokku 被比喻为“迷你版 Heroku”，提供了最小的 PaaS 实现。为了支持其持续运营和发展，Dokku 接受赞助和月度捐赠。它支持多种操作系统，如 Ubuntu 20.04/22.04、Debian 10 及以上版本和 Arch Linux（实验性）。安装 Dokku 需要用户具备 sudo 权限，并通过特定命令下载并执行安装脚本。

为了升级到最新版本，用户可以遵循特定的升级指南。Dokku 提供了详细的在线文档，包括进阶安装指南，以及用于获取支持的论坛、FAQ 和 Discord 社区。社区鼓励贡献者通过 Fork 项目并提交 Pull Requests 来参与改进，即使这些贡献可能需要进一步的调整以适应更广泛的用户需求。Dokku 的使用许可归 Jeff Lindsay 所有。

总之，Dokku 是一个轻量级的 Docker 基于的 PaaS 解决方案，适合开发者构建、部署和管理应用。它通过社区支持、文档和贡献机制维持其发展。 <div>
<p>A docker-powered PaaS that helps you build and manage the lifecycle of applications</p><hr /><h1>Dokku</h1> 
<p><a href="https://github.com/dokku/dokku/actions?query=branch%3Amaster"><img alt="Build Status" src="https://github.com/dokku/dokku/actions/workflows/ci.yml/badge.svg?branch=master" /></a> <a href="https://packagecloud.io/dokku/dokku"><img alt="Ubuntu Package" src="https://img.shields.io/badge/package-ubuntu-brightgreen.svg?style=flat-square" title="Ubuntu Package" /></a> <a href="https://aur.archlinux.org/packages/dokku/"><img alt="Arch Package" src="https://img.shields.io/badge/package-arch-brightgreen.svg?style=flat-square" title="Arch Package" /></a> <a href="https://slack.dokku.com/"><img alt="Slack Group" src="https://img.shields.io/badge/irc-slack-blue.svg?style=flat-square" title="Slack Group" /></a> <a href="https://dokku.com/docs/getting-started/installation/"><img alt="Documentation" src="https://img.shields.io/badge/docs-site-blue.svg?style=flat-square" title="Site" /></a> <a href="https://raw.githubusercontent.com/dokku/dokku/master/#sponsors"><img alt="OpenCollective" src="https://opencollective.com/dokku/sponsors/badge.svg?style=flat-square" /></a> <a href="https://raw.githubusercontent.com/dokku/dokku/master/#backers"><img alt="OpenCollective" src="https://opencollective.com/dokku/backers/badge.svg?style=flat-square" /></a> <a href="https://www.patreon.com/dokku/"><img alt="Patreon" src="https://img.shields.io/badge/patreon-donate-green.svg?style=flat-square" /></a></p> 
<p>Docker powered mini-Heroku. The smallest PaaS implementation you've ever seen.</p> 
<h2>Sponsors</h2> 
<p>Become a sponsor and get your logo on our README on GitHub with a link to your site. [<a href="https://opencollective.com/dokku#sponsor">Become a sponsor</a>]</p> 
<p><a href="https://opencollective.com/dokku/sponsor/0/website"><img alt="OpenCollective Sponsor 0" src="https://opencollective.com/dokku/sponsor/0/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/1/website"><img alt="OpenCollective Sponsor 1" src="https://opencollective.com/dokku/sponsor/1/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/2/website"><img alt="OpenCollective Sponsor 2" src="https://opencollective.com/dokku/sponsor/2/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/3/website"><img alt="OpenCollective Sponsor 3" src="https://opencollective.com/dokku/sponsor/3/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/4/website"><img alt="OpenCollective Sponsor 4" src="https://opencollective.com/dokku/sponsor/4/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/5/website"><img alt="OpenCollective Sponsor 5" src="https://opencollective.com/dokku/sponsor/5/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/6/website"><img alt="OpenCollective Sponsor 6" src="https://opencollective.com/dokku/sponsor/6/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/7/website"><img alt="OpenCollective Sponsor 7" src="https://opencollective.com/dokku/sponsor/7/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/8/website"><img alt="OpenCollective Sponsor 8" src="https://opencollective.com/dokku/sponsor/8/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/9/website"><img alt="OpenCollective Sponsor 9" src="https://opencollective.com/dokku/sponsor/9/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/10/website"><img alt="OpenCollective Sponsor 10" src="https://opencollective.com/dokku/sponsor/10/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/11/website"><img alt="OpenCollective Sponsor 11" src="https://opencollective.com/dokku/sponsor/11/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/12/website"><img alt="OpenCollective Sponsor 12" src="https://opencollective.com/dokku/sponsor/12/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/13/website"><img alt="OpenCollective Sponsor 13" src="https://opencollective.com/dokku/sponsor/13/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/14/website"><img alt="OpenCollective Sponsor 14" src="https://opencollective.com/dokku/sponsor/14/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/5/website"><img alt="OpenCollective Sponsor 15" src="https://opencollective.com/dokku/sponsor/15/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/16/website"><img alt="OpenCollective Sponsor 6" src="https://opencollective.com/dokku/sponsor/16/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/17/website"><img alt="OpenCollective Sponsor 17" src="https://opencollective.com/dokku/sponsor/17/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/sponsor/18/website"><img alt="OpenCollective Sponsor 18" src="https://opencollective.com/dokku/sponsor/18/avatar.svg?sanitize=true" /></a></p> 
<h2>Backers</h2> 
<p>Support us with a monthly donation and help us continue our activities. [<a href="https://opencollective.com/dokku#backer">Become a backer</a>]</p> 
<p><a href="https://opencollective.com/dokku/backer/0/website"><img alt="OpenCollective Backer 0" src="https://opencollective.com/dokku/backer/0/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/1/website"><img alt="OpenCollective Backer 1" src="https://opencollective.com/dokku/backer/1/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/2/website"><img alt="OpenCollective Backer 2" src="https://opencollective.com/dokku/backer/2/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/3/website"><img alt="OpenCollective Backer 3" src="https://opencollective.com/dokku/backer/3/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/4/website"><img alt="OpenCollective Backer 4" src="https://opencollective.com/dokku/backer/4/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/5/website"><img alt="OpenCollective Backer 5" src="https://opencollective.com/dokku/backer/5/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/6/website"><img alt="OpenCollective Backer 6" src="https://opencollective.com/dokku/backer/6/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/7/website"><img alt="OpenCollective Backer 7" src="https://opencollective.com/dokku/backer/7/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/8/website"><img alt="OpenCollective Backer 8" src="https://opencollective.com/dokku/backer/8/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/9/website"><img alt="OpenCollective Backer 9" src="https://opencollective.com/dokku/backer/9/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/10/website"><img alt="OpenCollective Backer 10" src="https://opencollective.com/dokku/backer/10/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/11/website"><img alt="OpenCollective Backer 11" src="https://opencollective.com/dokku/backer/11/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/12/website"><img alt="OpenCollective Backer 12" src="https://opencollective.com/dokku/backer/12/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/13/website"><img alt="OpenCollective Backer 13" src="https://opencollective.com/dokku/backer/13/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/14/website"><img alt="OpenCollective Backer 14" src="https://opencollective.com/dokku/backer/14/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/15/website"><img alt="OpenCollective Backer 15" src="https://opencollective.com/dokku/backer/15/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/16/website"><img alt="OpenCollective Backer 16" src="https://opencollective.com/dokku/backer/16/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/17/website"><img alt="OpenCollective Backer 17" src="https://opencollective.com/dokku/backer/17/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/18/website"><img alt="OpenCollective Backer 18" src="https://opencollective.com/dokku/backer/18/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/19/website"><img alt="OpenCollective Backer 19" src="https://opencollective.com/dokku/backer/19/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/20/website"><img alt="OpenCollective Backer 20" src="https://opencollective.com/dokku/backer/20/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/21/website"><img alt="OpenCollective Backer 21" src="https://opencollective.com/dokku/backer/21/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/22/website"><img alt="OpenCollective Backer 22" src="https://opencollective.com/dokku/backer/22/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/23/website"><img alt="OpenCollective Backer 23" src="https://opencollective.com/dokku/backer/23/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/24/website"><img alt="OpenCollective Backer 24" src="https://opencollective.com/dokku/backer/24/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/25/website"><img alt="OpenCollective Backer 25" src="https://opencollective.com/dokku/backer/25/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/26/website"><img alt="OpenCollective Backer 26" src="https://opencollective.com/dokku/backer/26/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/27/website"><img alt="OpenCollective Backer 27" src="https://opencollective.com/dokku/backer/27/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/28/website"><img alt="OpenCollective Backer 28" src="https://opencollective.com/dokku/backer/28/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/dokku/backer/29/website"><img alt="OpenCollective Backer 29" src="https://opencollective.com/dokku/backer/29/avatar.svg?sanitize=true" /></a></p> 
<h2>Requirements</h2> 
<p>A fresh VM running any of the following operating systems:</p> 
<ul> 
 <li>Ubuntu 20.04 / 22.04 x64 - Any currently supported release</li> 
 <li>Debian 10+ x64</li> 
 <li>Arch Linux x64 <em>(experimental)</em></li> 
</ul> 
<p>An SSH keypair that can be used for application deployment. If this exists before installation, it will be automatically imported into dokku. Otherwise, you will need to import the keypair manually after installation using <code>dokku ssh-keys:add</code>.</p> 
<h2>Installation</h2> 
<p>To install the latest stable release, run the following commands as a user who has access to <code>sudo</code>:</p> 
<pre><code class="language-shell">wget -NP . https://dokku.com/install/v0.34.9/bootstrap.sh
sudo DOKKU_TAG=v0.34.9 bash bootstrap.sh
</code></pre> 
<p>You can then proceed to configure your server domain (via <code>dokku domains:set-global</code>) and user access (via <code>dokku ssh-keys:add</code>) to complete the installation.</p> 
<p>If you wish for a more unattended installation method, see <a href="https://dokku.com/docs/getting-started/install/debian/#unattended-installation">these</a> docs.</p> 
<h3>Upgrade</h3> 
<p><a href="https://dokku.com/docs/getting-started/upgrading/">View the docs</a> for upgrading from an older version of Dokku.</p> 
<h2>Documentation</h2> 
<p>Full documentation - including advanced installation docs - are available online at <a href="https://dokku.com/docs/getting-started/installation/">https://dokku.com/docs/getting-started/installation/</a>.</p> 
<h2>Support</h2> 
<p>You can use <a href="https://github.com/dokku/dokku/issues">GitHub Issues</a>, check <a href="https://dokku.com/docs/getting-started/troubleshooting/">Troubleshooting</a> in the documentation, or join us on <a href="https://slack.dokku.com/">Gliderlabs Slack in the #dokku channel</a>.</p> 
<h2>Contribution</h2> 
<p>After checking <a href="https://github.com/dokku/dokku/issues">GitHub Issues</a>, the <a href="https://dokku.com/docs/getting-started/troubleshooting/">Troubleshooting Guide</a> or having a chat with us on <a href="https://slack.dokku.com/">Gliderlabs Slack in the #dokku channel</a>, feel free to fork and create a Pull Request.</p> 
<p>While we may not merge your PR as is, they serve to start conversations and improve the general Dokku experience for all users.</p> 
<h2>License</h2> 
<p><a href="https://github.com/dokku/dokku/raw/master/LICENSE">MIT License</a> © Jeff Lindsay</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ComposioHQ/composio</title>
<link>https://github.com/ComposioHQ/composio</link>
<guid>https://github.com/ComposioHQ/composio</guid>
<content:encoded><![CDATA[
<div> 关键词：Composio、AI 剂、工具集、集成、Python

总结:

Composio 是一款专为 AI 剂提供高质工具与集成的平台。它支持超过100种不同类别的工具，包括软件操作（如GitHub、Notion、Linear、Gmail、Slack、Hubspot、Salesforce等）、操作系统功能（点击、输入、复制粘贴）、浏览器扩展（智能搜索、截图、多窗口操作、下载、上传等）、搜索引擎（Google搜索、Perplexity搜索、Tavily、Exa等）以及软件工程（Ngrok、数据库、Redis、Vercel、Git等）。此外，Composio 提供了 Agentic RAG 功能，能够即时处理任何类型的数据。

Composio 的核心功能包括：
1. **集成工具**：提供100多种高质量工具的集成，无需考虑认证、准确性和可靠性问题。
2. **AI框架支持**：与OpenAI、Claude、LlamaIndex、Langchain、CrewAI、Autogen、Gemini、Julep、Lyzr等AI框架兼容。
3. **授权管理**：支持六种不同的认证协议，包括访问令牌、刷新令牌、OAuth、API密钥、JWT等，以便用户专注于构建AI剂而非处理技术细节。
4. **准确性优化**：通过优化工具设计，使AI剂的准确性提高40%。
5. **可定制性**：易于扩展额外的工具、框架和认证协议，以及在后端应用中嵌入白标集成，以维护一致的用户体验。

为了开始使用，开发者可以选择使用Python或JavaScript。在Python中，可以通过安装`composio-core`和`composio-openai`包来快速集成并创建AI剂，执行特定任务，如在GitHub上星标仓库。在JavaScript中，需要先安装`composio-core`，然后设置OpenAI客户端和工具集，接着执行AI剂以完成指定任务，例如在GitHub上创建问题。 <div>
<p>Composio equip's your AI agents & LLMs with 100+ high-quality integrations via function calling</p><hr /><p align="center"> <a href="https://x.com/GanatraSoham/?utm_campaign=github-readme" target="_blank"> <img alt="Follow me" src="https://raw.githubusercontent.com/ComposioHQ/composio/master/python/docs/imgs/follow_x.png" width="100%" /> </a> <br /> <br /> </p> 
<p align="center"> <a href="https://app.composio.dev/?utm_campaign=github-readme" target="_blank"> <img alt="Sign up" src="https://raw.githubusercontent.com/ComposioHQ/composio/master/python/docs/imgs/try_hosted.png" width="100%" /> </a> </p>
<p><br /> <br /></p> 
<p></p> 
<p> <a href="https://github.com/composiohq/composio/raw/master/README.md">EN</a> | <a href="https://github.com/composiohq/composio/raw/master/README-CN.md">CN</a> | <a href="https://github.com/composiohq/composio/raw/master/README-JP.md">JP</a> </p> 
<p align="center"> <a href="https://composio.dev//#gh-dark-mode-only"> <img alt="Composio logo" src="https://raw.githubusercontent.com/ComposioHQ/composio/master/python/docs/imgs/composio_white_font.svg?sanitize=true" width="318px" /> </a> <a href="https://composio.dev//#gh-light-mode-only"> <img alt="Composio Logo" src="https://raw.githubusercontent.com/ComposioHQ/composio/master/python/docs/imgs/composio_black_font.svg?sanitize=true" width="318px" /> </a> </p> 
<p align="center"> <a href="https://github.com/composiodev/composio/actions/workflows/common.yml"> <img alt="Tests" src="https://img.shields.io/github/actions/workflow/status/composiodev/composio/common.yml?label=Tests&amp;style=plastic&amp;logo=github&amp;color=blue&amp;cacheSeconds=60" /> </a> <a href="https://pypi.org/project/composio-core/"> <img alt="PyPI" src="https://img.shields.io/pypi/v/composio_core?label=Latest&amp;style=plastic&amp;logo=pypi&amp;color=blue&amp;cacheSeconds=60&amp;logoColor=white" /> </a> <a href="https://www.npmjs.com/package/composio-core"> <img alt="NPM" src="https://img.shields.io/npm/v/composio-core?style=plastic&amp;logo=npm&amp;logoColor=white&amp;label=latest&amp;color=blue&amp;cacheSeconds=60" /> </a> <a href="https://pypi.org/project/composio-core/"> <img alt="Downloads" src="https://img.shields.io/pypi/dm/composio-core?label=Downloads&amp;style=plastic&amp;logo=github&amp;color=blue&amp;cacheSeconds=60" /> </a> </p> 
<h2 align="center"><i> Production Ready Toolset for AI Agents </i></h2> 
<h4 align="center">Equip your agent with high-quality tools &amp; integrations without worrying about authentication, accuracy, and reliability in a single line of code! </h4> 
<div align="center"> 
 <p> <a href="https://docs.composio.dev" rel="dofollow"><strong>Explore the Docs »</strong></a> </p> 
 <p> <a href="https://app.composio.dev">Try on Dashboard</a> <b>|</b> <a href="https://www.composio.dev">Homepage</a> <b>|</b> 
  <!-- <a href="https://docs.composio.dev/guides/examples">Examples</a> |
<a href="https://docs.composio.dev/chat-with-docs">Chat with Docs</a> | --> <a href="https://docs.composio.dev/sdk">SDK</a> <b>|</b> <a href="https://docs.composio.dev/api-reference/">APIs</a> </p> 
</div> 
<hr /> 
<div align="center"> 
 <p> <b>✨ Socials &gt;&gt;</b> <a href="https://dub.composio.dev/JoinHQ">Discord</a> <b>|</b> <a href="https://www.youtube.com/@Composio">Youtube</a> <b>|</b> <a href="https://twitter.com/composiohq">Twitter</a> <b>|</b> <a href="https://www.linkedin.com/company/composio-dev"> Linkedin </a> </p> 
 <p align="center"> <b>⛏️ Contribute &gt;&gt;</b> <a href="https://github.com/composiodev/composio/issues/new?assignees=&amp;labels=type%3A+bug&amp;template=bug_report.yml&amp;title=%F0%9F%90%9B+Bug+Report%3A+">Report Bugs</a> <b>|</b> <a href="https://github.com/composiodev/composio/issues/new?assignees=&amp;labels=feature&amp;template=feature_request.yml&amp;title=%F0%9F%9A%80+Feature%3A+">Request Feature</a> <b>|</b> <a href="https://github.com/composiodev/composio/raw/master/CONTRIBUTING.md">Contribute</a> </p> 
</div> 
<h2>📋 Table of contents</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-table-of-contents">📋 Table of contents</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-why-composio">🤔 Why Composio?</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-key-features">🔥 Key Features</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-getting-started-with-python">🚀 Getting Started with Python</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#1-installation">1. Installation</a></li> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#2-testing-composio-in-action">2. Testing Composio in Action</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-getting-started-with-javascript">🚀 Getting Started with Javascript</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#1-install-the-composio-sdk">1. <strong>Install the Composio SDK</strong>:</a></li> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#2-setup-the-openai-and-composio-tool-set">2. <strong>Setup the OpenAI and Composio Tool Set</strong>:</a></li> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#3-run-your-script">3. <strong>Run your script</strong>:</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-examples">💡 Examples</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#python-examples">Python Examples</a></li> 
   <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#javascript-examples">Javascript Examples</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#star-history">Star History</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-read-our-code-of-conduct">📋 Read Our Code Of Conduct</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-contributions">🤗 Contributions</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-links">🔗 Links</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#%EF%B8%8F-license">🛡️ License</a></li> 
 <li><a href="https://raw.githubusercontent.com/ComposioHQ/composio/master/#-thanks-to-all-contributors">💪 Thanks To All Contributors</a></li> 
</ul> 
<h2>🤔 Why Composio?</h2> 
<p>We believe AI Based Agents/Workflows are the future. Composio is the best toolset to integrate AI Agents to best Agentic Tools and use them to accomplish tasks.</p> 
<img alt="Illustration" src="https://raw.githubusercontent.com/ComposioHQ/composio/master/docs/imgs/banner.gif" style="border-radius: 5px;" /> 
<h2>🔥 Key Features</h2> 
<ul> 
 <li> <p><strong>100+ Tools</strong>: Support for a range of different categories</p> 
  <ul> 
   <li><strong>Software</strong>: Do anything on GitHub, Notion, Linear, Gmail, Slack, Hubspot, Salesforce, &amp; 90 more.</li> 
   <li><strong>OS</strong>: Click anywhere, Type anything, Copy to Clipboard, &amp; more.</li> 
   <li><strong>Browser</strong>: Smart Search, Take a screenshot, MultiOn, Download, Upload, &amp; more.</li> 
   <li><strong>Search</strong>: Google Search, Perplexity Search, Tavily, Exa &amp; more.</li> 
   <li><strong>SWE</strong>: Ngrok, Database, Redis, Vercel, Git, etc.</li> 
   <li><strong>RAG</strong>: Agentic RAG for any type of data on the fly!</li> 
  </ul> </li> 
 <li> <p><strong>Frameworks</strong>: Use tools with agent frameworks like <strong>OpenAI, Claude, LlamaIndex, Langchain, CrewAI, Autogen, Gemini, Julep, Lyzr</strong>, and more in a single line of code.</p> </li> 
 <li> <p><strong>Managed Authorisation</strong>: Supports six different auth protocols. <em>Access Token, Refresh token, OAuth, API Keys, JWT, and more</em> abstracted out so you can focus on the building agents.</p> </li> 
 <li> <p><strong>Accuracy</strong>: Get <em>up to 40% better agentic accuracy</em> in your tool calls due to better tool designs.</p> </li> 
 <li> <p><strong>Embeddable</strong>: Whitelabel in the backend of your applications managing Auth &amp; Integrations for all your users &amp; agents and maintain a consistent experience.</p> </li> 
 <li> <p><strong>Pluggable</strong>: Designed to be extended with additional Tools, Frameworks and Authorisation Protocols very easily.</p> </li> 
</ul> 
<h2>🚀 Getting Started with Python</h2> 
<h3>1. Installation</h3> 
<p>To get started, type the following command in your Terminal.</p> 
<pre><code class="language-bash">pip install composio-core
</code></pre> 
<p>If you want to install the 'composio' package along with its openai plugin: <code>pip install composio-openai</code>.</p> 
<h3>2. Testing Composio in Action</h3> 
<p>Let's use Composio to create an AI Agent that can star a Github Repo.</p> 
<pre><code class="language-bash">composio add github # Connect your Github - Run this in terminal
</code></pre> 
<pre><code class="language-python">
from openai import OpenAI
from composio_openai import ComposioToolSet, App, Action

openai_client = OpenAI(
    api_key="{{OPENAIKEY}}"
)

# Initialise the Composio Tool Set

composio_tool_set = ComposioToolSet()

# Get GitHub tools that are pre-configured
actions = composio_tool_set.get_actions(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)

my_task = "Star a repo composiodev/composio on GitHub"

# Setup openai assistant
assistant_instruction = "You are a super intelligent personal assistant"

assistant = openai_client.beta.assistants.create(
    name="Personal Assistant",
    instructions=assistant_instruction,
    model="gpt-4-turbo",
    tools=actions,
)

# create a thread
thread = openai_client.beta.threads.create()

message = openai_client.beta.threads.messages.create(
    thread_id=thread.id,
    role="user",
    content=my_task
)

# Execute Agent with integrations
run = openai_client.beta.threads.runs.create(
    thread_id=thread.id,
    assistant_id=assistant.id
)


# Execute Function calls
response_after_tool_calls = composio_tool_set.wait_and_handle_assistant_tool_calls(
    client=openai_client,
    run=run,
    thread=thread,
)

print(response_after_tool_calls)
</code></pre> 
<h2>🚀 Getting Started with Javascript</h2> 
<p>To get started with the Composio SDK in Javascript, follow these steps:</p> 
<h3>1. <strong>Install the Composio SDK</strong>:</h3> 
<pre><code class="language-bash">npm install composio-core
</code></pre> 
<h3>2. <strong>Setup the OpenAI and Composio Tool Set</strong>:</h3> 
<pre><code class="language-javascript">import { OpenAI } from "openai";
import { OpenAIToolSet } from "composio-core";

const toolset = new OpenAIToolSet({
    apiKey: process.env.COMPOSIO_API_KEY,
});

async function setupUserConnectionIfNotExists(entityId) {
    const entity = await toolset.client.getEntity(entityId);
    const connection = await entity.getConnection('github');

    if (!connection) {
        // If this entity/user hasn't already connected the account
        const connection = await entity.initiateConnection(appName);
        console.log("Log in via: ", connection.redirectUrl);
        return connection.waitUntilActive(60);
    }

    return connection;
}

async function executeAgent(entityName) {
    const entity = await toolset.client.getEntity(entityName)
    await setupUserConnectionIfNotExists(entity.id);

    const tools = await toolset.get_actions({ actions: ["github_issues_create"] }, entity.id);
    const instruction = "Make an issue with sample title in the repo - himanshu-dixit/custom-repo-breaking"

    const client = new OpenAI({ apiKey: process.env.OPEN_AI_API_KEY })
    const response = await client.chat.completions.create({
        model: "gpt-4-turbo",
        messages: [{
            role: "user",
            content: instruction,
        }],
        tools: tools,
        tool_choice: "auto",
    })

    console.log(response.choices[0].message.tool_calls);
    await toolset.handle_tool_call(response, entity.id);
}

executeAgent("your-entity-name");
</code></pre> 
<h3>3. <strong>Run your script</strong>:</h3> 
<pre><code class="language-bash">node your_script.js
</code></pre> 
<p>This will set up the Composio SDK and execute an agent that creates a GitHub issue using the provided instructions.</p> 
<p>For more details, refer to the <a href="https://docs.composio.dev/">Composio SDK Documentation</a>.</p> 
<h2>💡 Examples</h2> 
<h3><a href="https://docs.composio.dev/guides/python/">Python Examples</a></h3> 
<h3><a href="https://docs.composio.dev/guides/javascript/">Javascript Examples</a></h3> 
<h2>Star History</h2> 
<p><a href="https://star-history.com/#composiohq/composio&amp;Date"><img alt="Star History Chart" src="https://api.star-history.com/svg?repos=composiohq/composio&amp;type=Date" /></a></p> 
<h2>📋 Read Our Code Of Conduct</h2> 
<p>As part of our open-source community, we hold ourselves and other contributors to a high standard of communication. As a participant and contributor to this project, you agree to abide by our <a href="https://github.com/composiodev/composio/raw/master/CODE_OF_CONDUCT.md">Code of Conduct</a>.</p> 
<h2>🤗 Contributions</h2> 
<p>Composio is open-source and we welcome contributions. Please fork the repository, create a new branch for your feature, add your feature or improvement, and send a pull request.</p> 
<p>Also go through our <a href="https://github.com/composiodev/composio/raw/master/CONTRIBUTING.md">Contribution Guidelines</a> and <a href="https://github.com/composiodev/composio/raw/master/CODE_OF_CONDUCT.md">Code of Conduct</a> before you start.</p> 
<h2>🔗 Links</h2> 
<ul> 
 <li><a href="https://composio.dev?utm_campaign=github-readme">Home page</a></li> 
 <li><a href="https://github.com/composiodev/composio/raw/master/CONTRIBUTING.md">Contribution Guidelines</a></li> 
 <li><a href="https://docs.composio.dev/?utm_campaign=github-readme">Docs</a></li> 
</ul> 
<h2>🛡️ License</h2> 
<p>Composio is licensed under the Elastic License - see the <a href="https://github.com/composiodev/composio/raw/master/LICENSE">LICENSE</a> file for details.</p> 
<h2>💪 Thanks To All Contributors</h2> 
<a href="https://github.com/composiohq/composio/graphs/contributors"> <img alt="List of Contributors" src="https://contributors-img.web.app/image?repo=composiodev/composio" /> </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>facebook/folly</title>
<link>https://github.com/facebook/folly</link>
<guid>https://github.com/facebook/folly</guid>
<content:encoded><![CDATA[
<div> 关键词：Folly、GitHub、C++、Facebook、Open-source

总结：

Folly 是 Facebook 开源的一个 C++17 组件库，旨在提供高效和实用的功能。它包含了 Facebook 内部广泛使用的各种核心库组件，同时也与 Boost 和 C++ 标准库等其他库相补充而非竞争。Folly 的设计围绕着性能这一主题，有时导致一些非标准的设计决策以实现高性能。

Folly 的结构相对扁平，其目录与命名空间结构一致，不设复杂的目录层次。它分为标准库组件和实验性组件两部分，后者可能因 API 可能频繁变化而不适合外部使用。Folly 使用类似于 Boost 的“重复”方案组织文件和头文件。

Folly 通过 GitHub 发布，并支持多种编译器和操作系统。为了确保依赖库的兼容性和版本一致性，推荐使用 getdeps.py 脚本下载并构建所有依赖库。这脚本支持 Python 3.6 或更高版本，可以在多个平台上运行。用户可以自定义安装路径和构建选项，但考虑到 Folly 的不兼容性保证，通常建议将库安装到临时目录，并通过环境变量配置项目构建时查找此目录。

Folly 需要依赖于 Boost、gtest 等库，这些库可以通过 getdeps.py 自动管理。对于 Linux 或 macOS 用户，可以使用预构建的系统依赖包来加速构建过程。Folly 提供了自动化构建脚本（如 build.sh 和 build.bat）以及与 CMake 集成的选项，允许用户根据需求进行定制化构建。此外，Folly 还提供了测试功能，确保库的正确性和稳定性。 <div>
<p>An open-source C++ library developed and used at Facebook.</p><hr /><h1>Folly: Facebook Open-source Library</h1> 
<a href="https://opensource.facebook.com/support-ukraine"> <img alt="Support Ukraine - Help Provide Humanitarian Aid to Ukraine." src="https://img.shields.io/badge/Support-Ukraine-FFD500?style=flat&amp;labelColor=005BBB" /> </a> 
<h1>What is <code>folly</code>?</h1> 
<img align="right" alt="Logo Folly" src="https://raw.githubusercontent.com/facebook/folly/main/static/logo.svg?sanitize=true" width="15%" /> 
<p>Folly (acronymed loosely after Facebook Open Source Library) is a library of C++17 components designed with practicality and efficiency in mind. <strong>Folly contains a variety of core library components used extensively at Facebook</strong>. In particular, it's often a dependency of Facebook's other open source C++ efforts and place where those projects can share code.</p> 
<p>It complements (as opposed to competing against) offerings such as Boost and of course <code>std</code>. In fact, we embark on defining our own component only when something we need is either not available, or does not meet the needed performance profile. We endeavor to remove things from folly if or when <code>std</code> or Boost obsoletes them.</p> 
<p>Performance concerns permeate much of Folly, sometimes leading to designs that are more idiosyncratic than they would otherwise be (see e.g. <code>PackedSyncPtr.h</code>, <code>SmallLocks.h</code>). Good performance at large scale is a unifying theme in all of Folly.</p> 
<h2>Check it out in the intro video</h2> 
<p><a href="https://www.youtube.com/watch?v=Wr_IfOICYSs"><img alt="Explain Like I’m 5: Folly" src="https://img.youtube.com/vi/Wr_IfOICYSs/0.jpg" /></a></p> 
<h1>Logical Design</h1> 
<p>Folly is a collection of relatively independent components, some as simple as a few symbols. There is no restriction on internal dependencies, meaning that a given folly module may use any other folly components.</p> 
<p>All symbols are defined in the top-level namespace <code>folly</code>, except of course macros. Macro names are ALL_UPPERCASE and should be prefixed with <code>FOLLY_</code>. Namespace <code>folly</code> defines other internal namespaces such as <code>internal</code> or <code>detail</code>. User code should not depend on symbols in those namespaces.</p> 
<p>Folly has an <code>experimental</code> directory as well. This designation connotes primarily that we feel the API may change heavily over time. This code, typically, is still in heavy use and is well tested.</p> 
<h1>Physical Design</h1> 
<p>At the top level Folly uses the classic "stuttering" scheme <code>folly/folly</code> used by Boost and others. The first directory serves as an installation root of the library (with possible versioning a la <code>folly-1.0/</code>), and the second is to distinguish the library when including files, e.g. <code>#include &lt;folly/FBString.h&gt;</code>.</p> 
<p>The directory structure is flat (mimicking the namespace structure), i.e. we don't have an elaborate directory hierarchy (it is possible this will change in future versions). The subdirectory <code>experimental</code> contains files that are used inside folly and possibly at Facebook but not considered stable enough for client use. Your code should not use files in <code>folly/experimental</code> lest it may break when you update Folly.</p> 
<p>The <code>folly/folly/test</code> subdirectory includes the unittests for all components, usually named <code>ComponentXyzTest.cpp</code> for each <code>ComponentXyz.*</code>. The <code>folly/folly/docs</code> directory contains documentation.</p> 
<h1>What's in it?</h1> 
<p>Because of folly's fairly flat structure, the best way to see what's in it is to look at the headers in <a href="https://github.com/facebook/folly/tree/main/folly">top level <code>folly/</code> directory</a>. You can also check the <a href="https://raw.githubusercontent.com/facebook/folly/main/folly/docs"><code>docs</code> folder</a> for documentation, starting with the <a href="https://raw.githubusercontent.com/facebook/folly/main/folly/docs/Overview.md">overview</a>.</p> 
<p>Folly is published on GitHub at <a href="https://github.com/facebook/folly">https://github.com/facebook/folly</a>.</p> 
<h1>Build Notes</h1> 
<p>Because folly does not provide any ABI compatibility guarantees from commit to commit, we generally recommend building folly as a static library.</p> 
<p>folly supports gcc (5.1+), clang, or MSVC. It should run on Linux (x86-32, x86-64, and ARM), iOS, macOS, and Windows (x86-64). The CMake build is only tested on some of these platforms; at a minimum, we aim to support macOS and Linux (on the latest Ubuntu LTS release or newer.)</p> 
<h2><code>getdeps.py</code></h2> 
<p>This script is used by many of Meta's OSS tools. It will download and build all of the necessary dependencies first, and will then invoke cmake etc to build folly. This will help ensure that you build with relevant versions of all of the dependent libraries, taking into account what versions are installed locally on your system.</p> 
<p>It's written in python so you'll need python3.6 or later on your PATH. It works on Linux, macOS and Windows.</p> 
<p>The settings for folly's cmake build are held in its getdeps manifest <code>build/fbcode_builder/manifests/folly</code>, which you can edit locally if desired.</p> 
<h3>Dependencies</h3> 
<p>If on Linux or MacOS (with homebrew installed) you can install system dependencies to save building them:</p> 
<pre><code># Clone the repo
git clone https://github.com/facebook/folly
# Install dependencies
cd folly
sudo ./build/fbcode_builder/getdeps.py install-system-deps --recursive
</code></pre> 
<p>If you'd like to see the packages before installing them:</p> 
<pre><code>./build/fbcode_builder/getdeps.py install-system-deps --dry-run --recursive
</code></pre> 
<p>On other platforms or if on Linux and without system dependencies <code>getdeps.py</code> will mostly download and build them for you during the build step.</p> 
<p>Some of the dependencies <code>getdeps.py</code> uses and installs are:</p> 
<ul> 
 <li>a version of boost compiled with C++14 support.</li> 
 <li>googletest is required to build and run folly's tests.</li> 
</ul> 
<h3>Build</h3> 
<p>This script will download and build all of the necessary dependencies first, and will then invoke cmake etc to build folly. This will help ensure that you build with relevant versions of all of the dependent libraries, taking into account what versions are installed locally on your system.</p> 
<p><code>getdeps.py</code> currently requires python 3.6+ to be on your path.</p> 
<p><code>getdeps.py</code> will invoke cmake etc.</p> 
<pre><code># Clone the repo
git clone https://github.com/facebook/folly
cd folly
# Build, using system dependencies if available
python3 ./build/fbcode_builder/getdeps.py --allow-system-packages build
</code></pre> 
<p>It puts output in its scratch area:</p> 
<ul> 
 <li><code>installed/folly/lib/libfolly.a</code>: Library</li> 
</ul> 
<p>You can also specify a <code>--scratch-path</code> argument to control the location of the scratch directory used for the build. You can find the default scratch install location from logs or with <code>python3 ./build/fbcode_builder/getdeps.py show-inst-dir</code>.</p> 
<p>There are also <code>--install-dir</code> and <code>--install-prefix</code> arguments to provide some more fine-grained control of the installation directories. However, given that folly provides no compatibility guarantees between commits we generally recommend building and installing the libraries to a temporary location, and then pointing your project's build at this temporary location, rather than installing folly in the traditional system installation directories. e.g., if you are building with CMake you can use the <code>CMAKE_PREFIX_PATH</code> variable to allow CMake to find folly in this temporary installation directory when building your project.</p> 
<p>If you want to invoke <code>cmake</code> again to iterate, there is a helpful <code>run_cmake.py</code> script output in the scratch build directory. You can find the scratch build directory from logs or with <code>python3 ./build/fbcode_builder/getdeps.py show-build-dir</code>.</p> 
<h3>Run tests</h3> 
<p>By default <code>getdeps.py</code> will build the tests for folly. To run them:</p> 
<pre><code>cd folly
python3 ./build/fbcode_builder/getdeps.py --allow-system-packages test
</code></pre> 
<h3><code>build.sh</code>/<code>build.bat</code> wrapper</h3> 
<p><code>build.sh</code> can be used on Linux and MacOS, on Windows use the <code>build.bat</code> script instead. Its a wrapper around <code>getdeps.py</code>.</p> 
<h2>Build with cmake directly</h2> 
<p>If you don't want to let getdeps invoke cmake for you then by default, building the tests is disabled as part of the CMake <code>all</code> target. To build the tests, specify <code>-DBUILD_TESTS=ON</code> to CMake at configure time.</p> 
<p>NB if you want to invoke <code>cmake</code> again to iterate on a <code>getdeps.py</code> build, there is a helpful <code>run_cmake.py</code> script output in the scratch-path build directory. You can find the scratch build directory from logs or with <code>python3 ./build/fbcode_builder/getdeps.py show-build-dir</code>.</p> 
<p>Running tests with ctests also works if you cd to the build dir, e.g. <code>(cd $(python3 ./build/fbcode_builder/getdeps.py show-build-dir) &amp;&amp; ctest)</code></p> 
<h3>Finding dependencies in non-default locations</h3> 
<p>If you have boost, gtest, or other dependencies installed in a non-default location, you can use the <code>CMAKE_INCLUDE_PATH</code> and <code>CMAKE_LIBRARY_PATH</code> variables to make CMAKE look also look for header files and libraries in non-standard locations. For example, to also search the directories <code>/alt/include/path1</code> and <code>/alt/include/path2</code> for header files and the directories <code>/alt/lib/path1</code> and <code>/alt/lib/path2</code> for libraries, you can invoke <code>cmake</code> as follows:</p> 
<pre><code>cmake \
  -DCMAKE_INCLUDE_PATH=/alt/include/path1:/alt/include/path2 \
  -DCMAKE_LIBRARY_PATH=/alt/lib/path1:/alt/lib/path2 ...
</code></pre> 
<h2>Ubuntu LTS, CentOS Stream, Fedora</h2> 
<p>Use the <code>getdeps.py</code> approach above. We test in CI on Ubuntu LTS, and occasionally on other distros.</p> 
<p>If you find the set of system packages is not quite right for your chosen distro, you can specify distro version specific overrides in the dependency manifests (e.g. <a href="https://github.com/facebook/folly/raw/main/build/fbcode_builder/manifests/boost">https://github.com/facebook/folly/blob/main/build/fbcode_builder/manifests/boost</a> ). You could probably make it work on most recent Ubuntu/Debian or Fedora/Redhat derived distributions.</p> 
<p>At time of writing (Dec 2021) there is a build break on GCC 11.x based systems in lang_badge_test. If you don't need badge functionality you can work around by commenting it out from CMakeLists.txt (unfortunately fbthrift does need it)</p> 
<h2>Windows (Vcpkg)</h2> 
<p>Note that many tests are disabled for folly Windows builds, you can see them in the log from the cmake configure step, or by looking for WINDOWS_DISABLED in <code>CMakeLists.txt</code></p> 
<p>That said, <code>getdeps.py</code> builds work on Windows and are tested in CI.</p> 
<p>If you prefer, you can try Vcpkg. folly is available in <a href="https://github.com/Microsoft/vcpkg#vcpkg">Vcpkg</a> and releases may be built via <code>vcpkg install folly:x64-windows</code>.</p> 
<p>You may also use <code>vcpkg install folly:x64-windows --head</code> to build against <code>main</code>.</p> 
<h2>macOS</h2> 
<p><code>getdeps.py</code> builds work on macOS and are tested in CI, however if you prefer, you can try one of the macOS package managers</p> 
<h3>Homebrew</h3> 
<p>folly is available as a Formula and releases may be built via <code>brew install folly</code>.</p> 
<p>You may also use <code>folly/build/bootstrap-osx-homebrew.sh</code> to build against <code>main</code>:</p> 
<pre><code>  ./folly/build/bootstrap-osx-homebrew.sh
</code></pre> 
<p>This will create a build directory <code>_build</code> in the top-level.</p> 
<h3>MacPorts</h3> 
<p>Install the required packages from MacPorts:</p> 
<pre><code>  sudo port install \
    boost \
    cmake \
    gflags \
    git \
    google-glog \
    libevent \
    libtool \
    lz4 \
    lzma \
    openssl \
    snappy \
    xz \
    zlib
</code></pre> 
<p>Download and install double-conversion:</p> 
<pre><code>  git clone https://github.com/google/double-conversion.git
  cd double-conversion
  cmake -DBUILD_SHARED_LIBS=ON .
  make
  sudo make install
</code></pre> 
<p>Download and install folly with the parameters listed below:</p> 
<pre><code>  git clone https://github.com/facebook/folly.git
  cd folly
  mkdir _build
  cd _build
  cmake ..
  make
  sudo make install
</code></pre>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>EbookFoundation/free-programming-books</title>
<link>https://github.com/EbookFoundation/free-programming-books</link>
<guid>https://github.com/EbookFoundation/free-programming-books</guid>
<content:encoded><![CDATA[
<div> 关键词：免费资源、编程书籍、GitHub、协作更新、Free Ebook Foundation

总结：
本文是一篇关于免费编程学习资源的综述。主要关键词包括“免费资源”、“编程书籍”、“GitHub”、“协作更新”和“Free Ebook Foundation”。文章指出，该列表最初源自其他资源，通过GitHub进行共享和维护，成为了一个广泛收集编程相关书籍和其他学习资料的集合。GitHub平台允许用户通过阅读贡献指南进行协作更新，而Free Ebook Foundation是一个非营利组织，致力于推广免费电子书的创造、分发、存档和可持续发展，其捐赠在美国可以免税。此外，文章还强调了如何通过各种方式贡献，如翻译文档或创建内容，以及提供了如何分享这些资源的指导。最后，提到项目中包含多种类型的学习资源，如书籍、在线课程、编程工具等，旨在帮助编程爱好者和学习者获取所需的知识和技能。 <div>
<p>📚 Freely available programming books</p><hr /><h1>List of Free Learning Resources In Many Languages</h1> 
<div align="center"> 
 <p><a href="https://github.com/sindresorhus/awesome"><img alt="Awesome" src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" /></a>&nbsp; <a href="https://creativecommons.org/licenses/by/4.0/"><img alt="License: CC BY 4.0" src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg?sanitize=true" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2023-10-01..2023-10-31"><img alt="Hacktoberfest 2023 stats" src="https://img.shields.io/github/hacktoberfest/2023/EbookFoundation/free-programming-books?label=Hacktoberfest+2023" /></a></p> 
</div> 
<p>Search the list at <a href="https://ebookfoundation.github.io/free-programming-books-search/">https://ebookfoundation.github.io/free-programming-books-search/</a> <a href="https://ebookfoundation.github.io/free-programming-books-search/"><img alt="https://ebookfoundation.github.io/free-programming-books-search/" src="https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Dynamic%20search%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F" /></a>.</p> 
<p>This page is available as an easy-to-read website. Access it by clicking on <a href="https://ebookfoundation.github.io/free-programming-books/"><img alt="https://ebookfoundation.github.io/free-programming-books/" src="https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Static%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F" /></a>.</p> 
<div align="center"> 
 <form action="https://ebookfoundation.github.io/free-programming-books-search"> 
  <input id="fpbSearch" name="search" required="required" type="text" /> 
  <label for="submit"> </label> 
  <input id="submit" name="submit" type="submit" value="Search" /> 
 </form> 
</div> 
<h2>Intro</h2> 
<p>This list was originally a clone of <a href="https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926">StackOverflow - List of Freely Available Programming Books</a> with contributions from Karan Bhangui and George Stocker.</p> 
<p>The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of <a href="https://octoverse.github.com/">GitHub's most popular repositories</a>.</p> 
<div align="center"> 
 <p><a href="https://github.com/EbookFoundation/free-programming-books/network"><img alt="GitHub repo forks" src="https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Forks" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/stargazers"><img alt="GitHub repo stars" src="https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Stars" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/graphs/contributors"><img alt="GitHub repo contributors" src="https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Contributors" /></a><br /> <a href="https://github.com/sponsors/EbookFoundation"><img alt="GitHub org sponsors" src="https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Sponsors" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/watchers"><img alt="GitHub repo watchers" src="https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Watchers" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip"><img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Repo%20Size" /></a></p> 
</div> 
<p>The <a href="https://ebookfoundation.org">Free Ebook Foundation</a> now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. <a href="https://ebookfoundation.org/contributions.html">Donations</a> to the Free Ebook Foundation are tax-deductible in the US.</p> 
<h2>How To Contribute</h2> 
<p>Please read <a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md">CONTRIBUTING</a>. If you're new to GitHub, <a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md">welcome</a>! Remember to abide by our adapted from <img alt="Contributor Covenant 1.3" src="https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg?sanitize=true" /> <a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md">Code of Conduct</a> too (<a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/#translations">translations</a> also available).</p> 
<p>Click on these badges to see how you might be able to help:</p> 
<div align="center"> 
 <p><a href="https://github.com/EbookFoundation/free-programming-books/issues"><img alt="GitHub repo Issues" src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=red&amp;label=Issues" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"><img alt="GitHub repo Good Issues for newbies" src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Good%20First%20issues" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"><img alt="GitHub Help Wanted issues" src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20issues" /></a><br /> <a href="https://github.com/EbookFoundation/free-programming-books/pulls"><img alt="GitHub repo PRs" src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=orange&amp;label=PRs" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged"><img alt="GitHub repo Merged PRs" src="https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Merged%20PRs&amp;query=is%3Amerged" /></a>&nbsp; <a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"><img alt="GitHub Help Wanted PRs" src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20PRs" /></a></p> 
</div> 
<h2>How To Share</h2> 
<div align="left"> 
 <a href="https://www.facebook.com/share.php?u=https%253A%252F%252Fgithub.com%252FEbookFoundation%252Ffree-programming-books&amp;p%5Bimages%5D%5B0%5D=&amp;p%5Btitle%5D=Free%2520Programming%2520Books&amp;p%5Bsummary%5D=">Share on Facebook</a>
 <br /> 
 <a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=">Share on LinkedIn</a>
 <br /> 
 <a href="https://toot.kytta.dev/?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=">Share on Mastodon/Fediverse</a>
 <br /> 
 <a href="https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books">Share on Telegram</a>
 <br /> 
 <a href="https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books">Share on 𝕏 (Twitter)</a>
 <br /> 
</div> 
<h2>Resources</h2> 
<p>This project lists books and other resources grouped by genres:</p> 
<h3>Books</h3> 
<p><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-langs.md">English, By Programming Language</a></p> 
<p><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-subjects.md">English, By Subject</a></p> 
<h4>Other Languages</h4> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ar.md">Arabic / al arabiya / العربية</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hy.md">Armenian / Հայերեն</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-az.md">Azerbaijani / Азәрбајҹан дили / آذربايجانجا ديلي</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bn.md">Bengali / বাংলা</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bg.md">Bulgarian / български</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-my.md">Burmese / မြန်မာဘာသာ</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-zh.md">Chinese / 中文</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-cs.md">Czech / čeština / český jazyk</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ca.md">Catalan / catalan/ català</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-da.md">Danish / dansk</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-nl.md">Dutch / Nederlands</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-et.md">Estonian / eesti keel</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fi.md">Finnish / suomi / suomen kieli</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fr.md">French / français</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-de.md">German / Deutsch</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-el.md">Greek / ελληνικά</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-he.md">Hebrew / עברית</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hi.md">Hindi / हिन्दी</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hu.md">Hungarian / magyar / magyar nyelv</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-id.md">Indonesian / Bahasa Indonesia</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-it.md">Italian / italiano</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ja.md">Japanese / 日本語</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ko.md">Korean / 한국어</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-lv.md">Latvian / Latviešu</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ml.md">Malayalam / മലയാളം</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-no.md">Norwegian / Norsk</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fa_IR.md">Persian / Farsi (Iran) / فارسى</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pl.md">Polish / polski / język polski / polszczyzna</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_BR.md">Portuguese (Brazil)</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_PT.md">Portuguese (Portugal)</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ro.md">Romanian (Romania) / limba română / român</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ru.md">Russian / Русский язык</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sr.md">Serbian / српски језик / srpski jezik</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sk.md">Slovak / slovenčina</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-es.md">Spanish / español / castellano</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sv.md">Swedish / Svenska</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ta.md">Tamil / தமிழ்</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-te.md">Telugu / తెలుగు</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-th.md">Thai / ไทย</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-tr.md">Turkish / Türkçe</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-uk.md">Ukrainian / Українська</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-vi.md">Vietnamese / Tiếng Việt</a></li> 
</ul> 
<h3>Cheat Sheets</h3> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-cheatsheets.md">All Languages</a></li> 
</ul> 
<h3>Free Online Courses</h3> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ar.md">Arabic / al arabiya / العربية</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bn.md">Bengali / বাংলা</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bg.md">Bulgarian / български</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-my.md">Burmese / မြန်မာဘာသာ</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-zh.md">Chinese / 中文</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-en.md">English</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fi.md">Finnish / suomi / suomen kieli</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fr.md">French / français</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-de.md">German / Deutsch</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-el.md">Greek / ελληνικά</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-he.md">Hebrew / עברית</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-hi.md">Hindi / हिंदी</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-id.md">Indonesian / Bahasa Indonesia</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-it.md">Italian / italiano</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ja.md">Japanese / 日本語</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kn.md">Kannada/ಕನ್ನಡ</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kk.md">Kazakh / қазақша</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-km.md">Khmer / ភាសាខ្មែរ</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ko.md">Korean / 한국어</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ml.md">Malayalam / മലയാളം</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-mr.md">Marathi / मराठी</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ne.md">Nepali / नेपाली</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-no.md">Norwegian / Norsk</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fa_IR.md">Persian / Farsi (Iran) / فارسى</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pl.md">Polish / polski / język polski / polszczyzna</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_BR.md">Portuguese (Brazil)</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_PT.md">Portuguese (Portugal)</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ru.md">Russian / Русский язык</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-si.md">Sinhala / සිංහල</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-es.md">Spanish / español / castellano</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-sv.md">Swedish / svenska</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ta.md">Tamil / தமிழ்</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-te.md">Telugu / తెలుగు</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-th.md">Thai / ภาษาไทย</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-tr.md">Turkish / Türkçe</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-uk.md">Ukrainian / Українська</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ur.md">Urdu / اردو</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-vi.md">Vietnamese / Tiếng Việt</a></li> 
</ul> 
<h3>Interactive Programming Resources</h3> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-zh.md">Chinese / 中文</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-en.md">English</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-de.md">German / Deutsch</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ja.md">Japanese / 日本語</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ru.md">Russian / Русский язык</a></li> 
</ul> 
<h3>Problem Sets and Competitive Programming</h3> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/problem-sets-competitive-programming.md">Problem Sets</a></li> 
</ul> 
<h3>Podcast - Screencast</h3> 
<p>Free Podcasts and Screencasts:</p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ar.md">Arabic / al Arabiya / العربية</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-my.md">Burmese / မြန်မာဘာသာ</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-zh.md">Chinese / 中文</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-cs.md">Czech / čeština / český jazyk</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-nl.md">Dutch / Nederlands</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-en.md">English</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fi.md">Finnish / Suomi</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fr.md">French / français</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-de.md">German / Deutsch</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-he.md">Hebrew / עברית</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-id.md">Indonesian / Bahasa Indonesia</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fa_IR.md">Persian / Farsi (Iran) / فارسى</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pl.md">Polish / polski / język polski / polszczyzna</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_BR.md">Portuguese (Brazil)</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_PT.md">Portuguese (Portugal)</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ru.md">Russian / Русский язык</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-si.md">Sinhala / සිංහල</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-es.md">Spanish / español / castellano</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-sv.md">Swedish / Svenska</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-tr.md">Turkish / Türkçe</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-uk.md">Ukrainian / Українська</a></li> 
</ul> 
<h3>Programming Playgrounds</h3> 
<p>Write, compile, and run your code within a browser. Try it out!</p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-zh.md">Chinese / 中文</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds.md">English</a></li> 
 <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-de.md">German / Deutsch</a></li> 
</ul> 
<h2>Translations</h2> 
<p>Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.</p> 
<ul> 
 <li>English 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md">Code of Conduct</a></li> 
   <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md">Contributing</a></li> 
   <li><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md">How-to</a></li> 
  </ul> </li> 
 <li>... <em><a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations">More languages</a></em> ...</li> 
</ul> 
<p>You might notice that there are <a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations">some missing translations here</a> - perhaps you would like to help out by <a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md#help-out-by-contributing-a-translation">contributing a translation</a>?</p> 
<h2>License</h2> 
<p>Each file included in this repository is licensed under the <a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/LICENSE">CC BY License</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>signalapp/libsignal</title>
<link>https://github.com/signalapp/libsignal</link>
<guid>https://github.com/signalapp/libsignal</guid>
<content:encoded><![CDATA[
<div> 关键词：Signal Protocol、libsignal、Rust、Java/Swift/TypeScript、Android/Native Libraries

总结:

这篇文章详细介绍了Signal的内部技术栈和构建流程。核心在于libsignal库，它包含用于官方Signal客户端和服务器的平台中立API，提供Java、Swift、TypeScript等语言的封装。libsignal底层使用Rust实现，包含了Signal协议、加密算法、设备间传输功能、零知识证明、安全值恢复系统、用户名管理等模块。

对于Android开发，需要额外安装JDK、Android NDK/SDK，以及设置Rust编译目标。构建流程包括使用cargo编译并测试基本协议库。对于Java/Android应用，需要构建Java/Android jar和aar文件，并通过Gradle或Docker进行构建。Maven Central提供了Signal客户端和服务器的Java包，包含针对不同平台的本地库。Swift和Node的构建流程也有详细的指导文档。NPM提供了一个用于Node的特定包，包括Windows、macOS和Linux的本地库。

对于外部贡献者，Signal接受贡献，但需遵守特定的流程和标准，包括开立问题讨论、确保贡献与项目目标一致、签署开源许可协议等。此外，该软件涉及加密功能，其出口可能受到国家法律限制，需谨慎使用。最后，所有内容均遵循GNU AGPLv3许可证条款。 <div>
<p>Home to the Signal Protocol as well as other cryptographic primitives which make Signal possible.</p><hr /><h1>Overview</h1> 
<p>libsignal contains platform-agnostic APIs used by the official Signal clients and servers, exposed as a Java, Swift, or TypeScript library. The underlying implementations are written in Rust:</p> 
<ul> 
 <li>libsignal-protocol: Implements the Signal protocol, including the <a href="https://signal.org/docs/">Double Ratchet algorithm</a>. A replacement for <a href="https://github.com/signalapp/libsignal-protocol-java">libsignal-protocol-java</a> and <a href="https://github.com/signalapp/libsignal-metadata-java">libsignal-metadata-java</a>.</li> 
 <li>signal-crypto: Cryptographic primitives such as AES-GCM. We use <a href="https://github.com/RustCrypto">RustCrypto</a>'s where we can but sometimes have differing needs.</li> 
 <li>device-transfer: Support logic for Signal's device-to-device transfer feature.</li> 
 <li>attest: Functionality for remote attestation of <a href="https://www.intel.com/content/www/us/en/architecture-and-technology/software-guard-extensions.html">SGX enclaves</a> and server-side <a href="https://en.wikipedia.org/wiki/Hardware_security_module">HSMs</a>.</li> 
 <li>zkgroup: Functionality for <a href="https://signal.org/blog/signal-private-group-system/">zero-knowledge groups</a> and related features available in Signal.</li> 
 <li>zkcredential: An abstraction for the sort of zero-knowledge credentials used by zkgroup, based on the paper "<a href="https://eprint.iacr.org/2019/1416.pdf">The Signal Private Group System</a>" by Chase, Perrin, and Zaverucha.</li> 
 <li>poksho: Utilities for implementing zero-knowledge proofs (such as those used by zkgroup); stands for "proof-of-knowledge, stateful-hash-object".</li> 
 <li>pin: Functionality for consistently using <a href="https://signal.org/blog/signal-pins/">PINs</a> as passwords in Signal's Secure Value Recovery system.</li> 
 <li>usernames: Functionality for username generation, hashing, and proofs.</li> 
 <li>media: Utilities for manipulating media.</li> 
</ul> 
<p>This repository is used by the Signal client apps (<a href="https://github.com/signalapp/Signal-Android">Android</a>, <a href="https://github.com/signalapp/Signal-iOS">iOS</a>, and <a href="https://github.com/signalapp/Signal-Desktop">Desktop</a>) as well as server-side. Use outside of Signal is unsupported. In particular, the products of this repository are the Java, Swift, and TypeScript libraries that wrap the underlying Rust implementations. All APIs and implementations are subject to change without notice, as are the JNI, C, and Node add-on "bridge" layers. However, backwards-incompatible changes to the Java, Swift, TypeScript, and non-bridge Rust APIs will be reflected in the version number on a best-effort basis, including increases to the minimum supported tools versions.</p> 
<h1>Building</h1> 
<p>To build anything in this repository you must have <a href="https://rust-lang.org">Rust</a> installed, as well as Clang, libclang, <a href="https://cmake.org">CMake</a>, Make, protoc, and git. On a Debian-like system, you can get these extra dependencies through <code>apt</code>:</p> 
<pre><code class="language-shell">$ apt-get install clang libclang-dev cmake make protobuf-compiler git
</code></pre> 
<p>Additionally, some of the tests in this repository rely on submodules being checked out:</p> 
<pre><code class="language-shell">$ git submodule update --init
</code></pre> 
<p>The build currently uses a specific version of the Rust nightly compiler, which will be downloaded automatically by cargo. To build and test the basic protocol libraries:</p> 
<pre><code class="language-shell">$ cargo build
...
$ cargo test
...
</code></pre> 
<h2>Java/Android</h2> 
<p>To build for Android you must install several additional packages including a JDK, the Android NDK/SDK, and add the Android targets to the Rust compiler, using</p> 
<p><code>rustup target add armv7-linux-androideabi aarch64-linux-android i686-linux-android x86_64-linux-android</code></p> 
<p>To build the Java/Android <code>jar</code> and <code>aar</code>, and run the tests:</p> 
<pre><code class="language-shell">$ cd java
$ ./gradlew test
$ ./gradlew build # if you need AAR outputs
</code></pre> 
<p>You can pass <code>-P debugLevelLogs</code> to Gradle to build without filtering out debug- and verbose-level logs from Rust.</p> 
<p>Alternately, a build system using Docker is available:</p> 
<pre><code class="language-shell">$ cd java
$ make
</code></pre> 
<p>When exposing new APIs to Java, you will need to run <code>rust/bridge/jni/bin/gen_java_decl.py</code> in addition to rebuilding.</p> 
<h3>Maven Central</h3> 
<p>Signal publishes Java packages on <a href="https://central.sonatype.org">Maven Central</a> for its own use, under the names org.signal:libsignal-server, org.signal:libsignal-client, and org.signal:libsignal-android. libsignal-client and libsignal-server contain native libraries for Debian-flavored x86_64 Linux as well as Windows (x86_64) and macOS (x86_64 and arm64). libsignal-android contains native libraries for armeabi-v7a, arm64-v8a, x86, and x86_64 Android.</p> 
<p>When building for Android you need <em>both</em> libsignal-android and libsignal-client, but the Windows and macOS libraries in libsignal-client won't automatically be excluded from your final app. You can explicitly exclude them using <code>packagingOptions</code>:</p> 
<pre><code>android {
  // ...
  packagingOptions {
    resources {
      excludes += setOf("libsignal_jni*.dylib", "signal_jni*.dll")
    }
  }
  // ...
}
</code></pre> 
<p>You can additionally exclude <code>libsignal_jni_testing.so</code> if you do not plan to use any of the APIs intended for client testing.</p> 
<h2>Swift</h2> 
<p>To learn about the Swift build process see <a href="https://raw.githubusercontent.com/signalapp/libsignal/main/swift/"><code>swift/README.md</code></a></p> 
<h2>Node</h2> 
<p>You'll need Node installed to build. If you have <a href="https://github.com/nvm-sh/nvm">nvm</a>, you can run <code>nvm use</code> to select an appropriate version automatically.</p> 
<p>We use <a href="https://classic.yarnpkg.com/"><code>yarn</code></a> as our package manager, and <code>node-gyp</code> to control building the Rust library.</p> 
<pre><code class="language-shell">$ cd node
$ nvm use
$ yarn install
$ yarn node-gyp rebuild  # clean-&gt;configure-&gt;build
$ yarn tsc
$ yarn test
</code></pre> 
<p>When testing changes locally, you can use <code>yarn build</code> to do an incremental rebuild of the Rust library. Alternately, <code>yarn build-with-debug-level-logs</code> will rebuild without filtering out debug- and verbose-level logs.</p> 
<p>When exposing new APIs to Node, you will need to run <code>rust/bridge/node/bin/gen_ts_decl.py</code> in addition to rebuilding.</p> 
<h3>NPM</h3> 
<p>Signal publishes the NPM package <code>@signalapp/libsignal-client</code> for its own use, including native libraries for Windows, macOS, and Debian-flavored Linux. Both x64 and arm64 builds are included for all three platforms, but the arm64 builds for Windows and Linux are considered experimental, since there are no official builds of Signal for those architectures.</p> 
<h1>Contributions</h1> 
<p>Signal does accept external contributions to this project. However unless the change is simple and easily understood, for example fixing a bug or portability issue, adding a new test, or improving performance, first open an issue to discuss your intended change as not all changes can be accepted.</p> 
<p>Contributions that will not be used directly by one of Signal's official client apps may still be considered, but only if they do not pose an undue maintenance burden or conflict with the goals of the project.</p> 
<p>Signing a <a href="https://signal.org/cla/">CLA (Contributor License Agreement)</a> is required for all contributions.</p> 
<h1>Legal things</h1> 
<h2>Cryptography Notice</h2> 
<p>This distribution includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software. BEFORE using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted. See <a href="http://www.wassenaar.org/">http://www.wassenaar.org/</a> for more information.</p> 
<p>The U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this software as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software using or performing cryptographic functions with asymmetric algorithms. The form and manner of this distribution makes it eligible for export under the License Exception ENC Technology Software Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for both object code and source code.</p> 
<h2>License</h2> 
<p>Copyright 2020-2024 Signal Messenger, LLC</p> 
<p>Licensed under the GNU AGPLv3: <a href="https://www.gnu.org/licenses/agpl-3.0.html">https://www.gnu.org/licenses/agpl-3.0.html</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>TheAlgorithms/Java</title>
<link>https://github.com/TheAlgorithms/Java</link>
<guid>https://github.com/TheAlgorithms/Java</guid>
<content:encoded><![CDATA[
<div> 关键词：Java、算法、Gitpod.io、学习、贡献

总结:
本文主要介绍了一个在线平台，允许用户通过单击操作在Gitpod.io上运行、编辑和贡献各种算法的Java实现。这些算法都用Java语言编写，旨在帮助学习者理解并实践算法逻辑。值得注意的是，虽然这些实现可能在效率上不如Java标准库提供的解决方案，但它们对于教育目的非常有帮助。平台鼓励贡献，要求潜在贡献者先阅读特定的指南以了解如何参与。

通过这个平台，学习者能够直接与算法交互，通过实际操作加深对算法的理解。同时，它也为那些希望改进或添加新算法的开发者提供了机会，通过贡献代码，共同丰富这个资源库。整体而言，这是一个结合了在线编程环境、教育价值和社区合作的项目，为Java算法学习和实践提供了一种创新的方式。 <div>
<p>All Algorithms implemented in Java</p><hr /><h1>The Algorithms - Java</h1> 
<p><a href="https://github.com/TheAlgorithms/Java/actions/workflows/build.yml"><img alt="Build" src="https://github.com/TheAlgorithms/Java/actions/workflows/build.yml/badge.svg?branch=master" /></a> <a href="https://codecov.io/gh/TheAlgorithms/Java"><img alt="codecov" src="https://codecov.io/gh/TheAlgorithms/Java/graph/badge.svg?token=XAdPyqTIqR" /></a> <a href="https://discord.gg/c7MnfGFGa6"><img alt="Discord chat" src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;colorB=7289DA&amp;style=flat-square" /></a> <a href="https://gitpod.io/#https://github.com/TheAlgorithms/Java"><img alt="Gitpod ready-to-code" src="https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod" /></a></p> 
<p>You can run and edit the algorithms, or contribute to them using Gitpod.io (a free online development environment) with a single click.</p> 
<p><a href="https://gitpod.io/#https://github.com/TheAlgorithms/Java"><img alt="Open in Gitpod" src="https://gitpod.io/button/open-in-gitpod.svg?sanitize=true" /></a></p> 
<h3>All algorithms are implemented in Java (for educational purposes)</h3> 
<p>These implementations are intended for learning purposes. As such, they may be less efficient than the Java standard library.</p> 
<h2>Contribution Guidelines</h2> 
<p>Please read our <a href="https://raw.githubusercontent.com/TheAlgorithms/Java/master/CONTRIBUTING.md">Contribution Guidelines</a> before you contribute to this project.</p> 
<h2>Algorithms</h2> 
<p>Our <a href="https://raw.githubusercontent.com/TheAlgorithms/Java/master/DIRECTORY.md">directory</a> has the full list of applications.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Lightning-AI/LitServe</title>
<link>https://github.com/Lightning-AI/LitServe</link>
<guid>https://github.com/Lightning-AI/LitServe</guid>
<content:encoded><![CDATA[
<div> 关键词：LitServe、FastAPI、AI模型服务、GPU自动缩放、企业级规模

总结:

LitServe 是一款基于 FastAPI 的高性能 AI 模型服务引擎，专为加速 AI 应用设计。它提供了多种增强功能，如批量处理、流式传输和 GPU 自动缩放，以简化模型部署过程，无需每次构建新的 FastAPI 服务器。相较于标准的 FastAPI 服务，LitServe 至少能提供两倍以上的性能提升，特别适用于 AI 相关的多模型复合系统。

LitServe 可以轻松定义并启动服务，支持自定义模型和多种框架（如 PyTorch、JAX、TensorFlow 等），并通过其灵活的架构支持 AI 复合系统的构建。例如，可以同时使用两个模型进行计算，实现复杂逻辑处理。LitServe 还提供了一键自托管和完全管理的云部署选项，满足不同开发者的需求。

此外，LitServe 支持各种 AI 模型服务，从自然语言处理（NLP）、生成式 AI 到多模态系统、音频和视觉应用等，提供了一站式的 AI 服务解决方案。它还支持 GPU 自动缩放、批量处理和流式传输等高级特性，确保了高并发场景下的高效运行。通过 LitServe，用户可以构建和部署高度复杂的 AI 系统，同时享受到企业级的服务支持，包括负载均衡、自动扩展、零部署能力以及与 AWS 和 GCP 等云平台的兼容性。社区参与也是 LitServe 发展的关键，鼓励开发者共同构建更强大的 AI 推理引擎。 <div>
<p>Lightning-fast serving engine for AI models. Flexible. Easy. Enterprise-scale.</p><hr /><div align="center"> 
 <h1>Easily serve AI models Lightning fast ⚡</h1> 
 <img alt="Lightning" src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/ls_banner2.png" width="800px" /> 
 <p>&nbsp;</p> 
 <p><strong>Lightning-fast serving engine for AI models.</strong><br /> Easy. Flexible. Enterprise-scale.</p> 
</div> 
<hr /> 
<p><strong>LitServe</strong> is an easy-to-use, flexible serving engine for AI models built on FastAPI. Features like batching, streaming, and GPU autoscaling eliminate the need to rebuild a FastAPI server per model.</p> 
<p>LitServe is at least <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#performance">2x faster</a> than plain FastAPI due to AI-specific multi-worker handling.</p> 
<div align="center"> 
 <pre>
✅ (2x)+ faster serving  ✅ Easy to use          ✅ LLMs, non LLMs and more
✅ Bring your own model  ✅ PyTorch/JAX/TF/...   ✅ Built on FastAPI       
✅ GPU autoscaling       ✅ Batching, Streaming  ✅ Self-host or ⚡️ managed 
</pre> 
 <div align="center"> 
  <p><a href="https://discord.gg/VptPCZkGNa"><img alt="Discord" src="https://img.shields.io/discord/1077906959069626439?label=Get%20help%20on%20Discord" /></a> <img alt="cpu-tests" src="https://github.com/Lightning-AI/litserve/actions/workflows/ci-testing.yml/badge.svg?sanitize=true" /> <a href="https://codecov.io/gh/Lightning-AI/litserve"><img alt="codecov" src="https://codecov.io/gh/Lightning-AI/litserve/graph/badge.svg?token=SmzX8mnKlA" /></a> <a href="https://github.com/Lightning-AI/litserve/raw/main/LICENSE"><img alt="license" src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" /></a></p> 
 </div> 
</div> 
<div align="center"> 
 <div style="text-align: center;"> 
  <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#quick-start" style="margin: 0 10px;" target="_blank">Quick start</a> • 
  <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#featured-examples" style="margin: 0 10px;" target="_blank">Examples</a> • 
  <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#features" style="margin: 0 10px;" target="_blank">Features</a> • 
  <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#performance" style="margin: 0 10px;" target="_blank">Performance</a> • 
  <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#hosting-options" style="margin: 0 10px;" target="_blank">Hosting</a> • 
  <a href="https://lightning.ai/docs/litserve" style="margin: 0 10px;" target="_blank">Docs</a> 
 </div> 
</div> 
<p>&nbsp;</p> 
<div align="center"> 
 <a href="https://lightning.ai/docs/litserve/home/get-started" target="_blank"> <img alt="Get started" height="36px" src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/get-started-badge.svg?sanitize=true" /> </a> 
</div> 
<p>&nbsp;</p> 
<h1>Quick start</h1> 
<p>Install LitServe via pip (<a href="https://lightning.ai/docs/litserve/home/install">more options</a>):</p> 
<pre><code class="language-bash">pip install litserve
</code></pre> 
<h3>Define a server</h3> 
<p>This toy example with 2 models (AI compound system) shows LitServe's flexibility (<a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#examples">see real examples</a>):</p> 
<pre><code class="language-python"># server.py
import litserve as ls

# (STEP 1) - DEFINE THE API (compound AI system)
class SimpleLitAPI(ls.LitAPI):
    def setup(self, device):
        # setup is called once at startup. Build a compound AI system (1+ models), connect DBs, load data, etc...
        self.model1 = lambda x: x**2
        self.model2 = lambda x: x**3

    def decode_request(self, request):
        # Convert the request payload to model input.
        return request["input"] 

    def predict(self, x):
        # Easily build compound systems. Run inference and return the output.
        squared = self.model1(x)
        cubed = self.model2(x)
        output = squared + cubed
        return {"output": output}

    def encode_response(self, output):
        # Convert the model output to a response payload.
        return {"output": output} 

# (STEP 2) - START THE SERVER
if __name__ == "__main__":
    # scale with advanced features (batching, GPUs, etc...)
    server = ls.LitServer(SimpleLitAPI(), accelerator="auto", max_batch_size=1)
    server.run(port=8000)
</code></pre> 
<p>Now run the server via the command-line</p> 
<pre><code class="language-bash">python server.py
</code></pre> 
<h3>Test the server</h3> 
<p>Run the auto-generated test client:</p> 
<pre><code class="language-bash">python client.py    
</code></pre> 
<p>Or use this terminal command:</p> 
<pre><code class="language-bash">curl -X POST http://127.0.0.1:8000/predict -H "Content-Type: application/json" -d '{"input": 4.0}'
</code></pre> 
<h3>LLM serving</h3> 
<p>LitServe isn’t <em>just</em> for LLMs like vLLM or Ollama; it serves any AI model with full control over internals (<a href="https://lightning.ai/docs/litserve/features/serve-llms">learn more</a>).<br /> For easy LLM serving, use <a href="https://github.com/Lightning-AI/litgpt?tab=readme-ov-file#deploy-an-llm">LitGPT</a> (built on LitServe).</p> 
<pre><code>litgpt serve microsoft/phi-2
</code></pre> 
<h3>Summary</h3> 
<ul> 
 <li>LitAPI lets you easily build complex AI systems with one or more models (<a href="https://lightning.ai/docs/litserve/api-reference/litapi">docs</a>).</li> 
 <li>Use the setup method for one-time tasks like connecting models, DBs, and loading data (<a href="https://lightning.ai/docs/litserve/api-reference/litapi#setup">docs</a>).</li> 
 <li>LitServer handles optimizations like batching, GPU autoscaling, streaming, etc... (<a href="https://lightning.ai/docs/litserve/api-reference/litserver">docs</a>).</li> 
 <li>Self host on your own machines or use Lightning Studios for a fully managed deployment (<a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#hosting-options">learn more</a>).</li> 
</ul> 
<p><a href="https://lightning.ai/docs/litserve/home/speed-up-serving-by-200x">Learn how to make this server 200x faster</a>.</p> 
<p>&nbsp;</p> 
<h1>Featured examples</h1> 
<p>Use LitServe to deploy any model or AI service: (Gen AI, classical ML, embedding servers, LLMs, vision, audio, multi-modal systems, etc...)</p> 
<div align="center"> 
 <div width="200px"> 
  <video controls="controls" src="https://github.com/user-attachments/assets/5e73549a-bc0f-47a9-9d9c-5b54389be5de" width="200px"></video> 
 </div> 
</div> 
<h2>Examples</h2> 
<pre>
<strong>Toy model:</strong>      <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#define-a-server" target="_blank">Hello world</a>
<strong>LLMs:</strong>           <a href="https://lightning.ai/lightning-ai/studios/deploy-a-private-llama-3-8b-api" target="_blank">Llama 3 (8B)</a>, <a href="https://lightning.ai/lightning-ai/studios/openai-fault-tolerant-proxy-server" target="_blank">LLM Proxy server</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-ai-agent-with-tool-use" target="_blank">Agent with tool use</a>
<strong>RAG:</strong>            <a href="https://lightning.ai/lightning-ai/studios/deploy-a-private-llama-3-1-rag-api" target="_blank">RAG API (LlamaIndex)</a>
<strong>NLP:</strong>            <a href="https://lightning.ai/lightning-ai/studios/deploy-any-hugging-face-model-instantly" target="_blank">Hugging face</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-a-hugging-face-bert-model" target="_blank">BERT</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-text-embedding-api-with-litserve" target="_blank">Text embedding API</a>
<strong>Multimodal:</strong>     <a href="https://lightning.ai/lightning-ai/studios/deploy-open-ai-clip-with-litserve" target="_blank">OpenAI Clip</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-a-multi-modal-llm-with-minicpm" target="_blank">MiniCPM</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-phi3-5-vision-api-with-litserve" target="_blank">Phi-3.5 Vision Instruct</a>, <a href="https://lightning.ai/bhimrajyadav/studios/deploy-and-chat-with-qwen2-vl-using-litserve" target="_blank">Qwen2-VL</a>
<strong>Audio:</strong>          <a href="https://lightning.ai/lightning-ai/studios/deploy-open-ai-s-whisper-model" target="_blank">Whisper</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-an-music-generation-api-with-meta-s-audio-craft" target="_blank">AudioCraft</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-an-audio-generation-api" target="_blank">StableAudio</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-a-noise-cancellation-api-with-deepfilternet" target="_blank">Noise cancellation (DeepFilterNet)</a>
<strong>Vision:</strong>         <a href="https://lightning.ai/lightning-ai/studios/deploy-a-private-api-for-stable-diffusion-2" target="_blank">Stable diffusion 2</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-an-image-generation-api-with-auraflow" target="_blank">AuraFlow</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-an-image-generation-api-with-flux" target="_blank">Flux</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-a-super-resolution-image-api-with-aura-sr" target="_blank">Image Super Resolution (Aura SR)</a>,
                <a href="https://lightning.ai/bhimrajyadav/studios/deploy-background-removal-api-with-litserve" target="_blank">Background Removal</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-a-controlled-image-generation-api-controlnet" target="_blank">Control Stable Diffusion (ControlNet)</a>
<strong>Speech:</strong>         <a href="https://lightning.ai/lightning-ai/studios/deploy-a-voice-clone-api-coqui-xtts-v2-model" target="_blank">Text-speech (XTTS V2)</a>
<strong>Classical ML:</strong>   <a href="https://lightning.ai/lightning-ai/studios/deploy-random-forest-with-litserve" target="_blank">Random forest</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-xgboost-with-litserve" target="_blank">XGBoost</a>
<strong>Miscellaneous:</strong>  <a href="https://lightning.ai/lightning-ai/studios/deploy-an-media-conversion-api-with-ffmpeg" target="_blank">Media conversion API (ffmpeg)</a>, <a href="https://lightning.ai/lightning-ai/studios/deploy-both-pytorch-and-tensorflow-in-a-single-api" target="_blank">PyTorch + TensorFlow in one API</a>
</pre>  
<p><a href="https://lightning.ai/studios?section=serving">Browse 100+ community-built templates</a></p> 
<p>&nbsp;</p> 
<h1>Features</h1> 
<p>State-of-the-art features:</p> 
<p>✅ <a href="https://raw.githubusercontent.com/Lightning-AI/LitServe/main/#performance">(2x)+ faster than plain FastAPI</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/full-control">Bring your own model</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/compound-ai-systems">Build compound systems (1+ models)</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/gpu-inference">GPU autoscaling</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/batching">Batching</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/streaming">Streaming</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/autoscaling">Worker autoscaling</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/hosting-methods#host-on-your-own">Self-host on your machines</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/hosting-methods#host-on-lightning-studios">Host fully managed on Lightning AI</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/examples">Serve all models: (LLMs, vision, etc.)</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/streaming">Scale to zero (serverless)</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/full-control">Supports PyTorch, JAX, TF, etc...</a><br /> ✅ <a href="https://www.openapis.org/">OpenAPI compliant</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/open-ai-spec">Open AI compatibility</a><br /> ✅ <a href="https://lightning.ai/docs/litserve/features/authentication">Authentication</a></p> 
<p><a href="https://lightning.ai/docs/litserve/features">10+ features...</a></p> 
<p><strong>Note:</strong> We prioritize scalable, enterprise-level features over hype.</p> 
<p>&nbsp;</p> 
<h1>Performance</h1> 
<p>LitServe is designed for AI workloads. Specialized multi-worker handling delivers a minimum <strong>2x speedup over FastAPI</strong>.</p> 
<p>Additional features like batching and GPU autoscaling can drive performance well beyond 2x, scaling efficiently to handle more simultaneous requests than FastAPI and TorchServe.</p> 
<p>Reproduce the full benchmarks <a href="https://lightning.ai/docs/litserve/home/benchmarks">here</a> (higher is better).</p> 
<div align="center"> 
 <img alt="LitServe" src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/ls_charts_v6.png" width="1000px" /> 
</div> 
<p>These results are for image and text classification ML tasks. The performance relationships hold for other ML tasks (embedding, LLM serving, audio, segmentation, object detection, summarization etc...).</p> 
<p><em><strong>💡 Note on LLM serving:</strong></em> For high-performance LLM serving (like Ollama/VLLM), use <a href="https://github.com/Lightning-AI/litgpt?tab=readme-ov-file#deploy-an-llm">LitGPT</a> or build your custom VLLM-like server with LitServe. Optimizations like kv-caching, which can be done with LitServe, are needed to maximize LLM performance.</p> 
<p>&nbsp;</p> 
<h1>Hosting options</h1> 
<p>LitServe can be hosted independently on your own machines or fully managed via Lightning Studios.</p> 
<p>Self-hosting is ideal for hackers, students, and DIY developers, while fully managed hosting is ideal for enterprise developers needing easy autoscaling, security, release management, and 99.995% uptime and observability.</p> 
<p>&nbsp;</p> 
<div align="center"> 
 <a href="https://lightning.ai/lightning-ai/studios/litserve-hello-world" target="_blank"> <img alt="Host on Lightning" src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/host-on-lightning.svg?sanitize=true" /> </a> 
</div> 
<p>&nbsp;</p> 
<div align="center"> 
 <table> 
  <thead> 
   <tr> 
    <th>Feature</th> 
    <th>Self Managed</th> 
    <th>Fully Managed on Studios</th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>Deployment</td> 
    <td>✅ Do it yourself deployment</td> 
    <td>✅ One-button cloud deploy</td> 
   </tr> 
   <tr> 
    <td>Load balancing</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>Autoscaling</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>Scale to zero</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>Multi-machine inference</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>Authentication</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>Own VPC</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>AWS, GCP</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
   <tr> 
    <td>Use your own cloud commits</td> 
    <td>❌</td> 
    <td>✅</td> 
   </tr> 
  </tbody> 
 </table> 
</div> 
<p>&nbsp;</p> 
<h1>Community</h1> 
<p>LitServe is a <a href="https://lightning.ai/docs/litserve/community">community project accepting contributions</a> - Let's make the world's most advanced AI inference engine.</p> 
<p>💬 <a href="https://discord.com/invite/XncpTy7DSt">Get help on Discord</a><br /> 📋 <a href="https://github.com/Lightning-AI/litserve/raw/main/LICENSE">License: Apache 2.0</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>sickcodes/Docker-OSX</title>
<link>https://github.com/sickcodes/Docker-OSX</link>
<guid>https://github.com/sickcodes/Docker-OSX</guid>
<content:encoded><![CDATA[
<p>Run macOS VM in a Docker! Run near native OSX-KVM in Docker! X11 Forwarding! CI/CD for OS X Security Research! Docker mac Containers.</p><hr /><h1>Docker-OSX · <a href="https://twitter.com/sickcodes">Follow @sickcodes on Twitter</a></h1> 
<p><img alt="Running Mac OS X in a Docker container" src="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/running-mac-inside-docker-qemu.png?raw=true" title="OSX KVM DOCKER" /></p> 
<p>Run Mac OS X in Docker with near-native performance! X11 Forwarding! iMessage security research! iPhone USB working! macOS in a Docker container!</p> 
<p>Conduct Security Research on macOS using both Linux &amp; Windows!</p> 
<h1>Docker-OSX now has a Discord server &amp; Telegram!</h1> 
<p>The Discord is active on #docker-osx and anyone is welcome to come and ask questions, ideas, etc.</p> 
<p align="center"> <a href="https://hub.docker.com/r/sickcodes/docker-osx"><img src="https://dockeri.co/image/sickcodes/docker-osx" /></a><a href="https://discord.gg/sickchat"></a><a href="https://discord.gg/sickchat" target="_blank"><img src="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/discord-logo.svg?sanitize=true" /></a> </p> 
<h3>Click to join the Discord server <a href="https://discord.gg/sickchat">https://discord.gg/sickchat</a></h3> 
<h3>Click to join the Telegram server <a href="https://t.me/sickcodeschat">https://t.me/sickcodeschat</a></h3> 
<p>Or reach out via Linkedin if it's private: <a href="https://www.linkedin.com/in/sickcodes">https://www.linkedin.com/in/sickcodes</a></p> 
<p>Or via <a href="https://sick.codes/contact/">https://sick.codes/contact/</a></p> 
<h2>Author</h2> 
<p>This project is maintained by <a href="https://sick.codes/">Sick.Codes</a>. <a href="https://twitter.com/sickcodes">(Twitter)</a></p> 
<p>Additional credits can be found here: <a href="https://github.com/sickcodes/Docker-OSX/raw/master/CREDITS.md">https://github.com/sickcodes/Docker-OSX/blob/master/CREDITS.md</a></p> 
<p>Additionally, comprehensive list of all contributors can be found here: <a href="https://github.com/sickcodes/Docker-OSX/graphs/contributors">https://github.com/sickcodes/Docker-OSX/graphs/contributors</a></p> 
<p>Big thanks to <a href="https://twitter.com/kholia">@kholia</a> for maintaining the upstream project, which Docker-OSX is built on top of: <a href="https://github.com/kholia/OSX-KVM">OSX-KVM</a>.</p> 
<p>Also special thanks to <a href="https://github.com/thenickdude">@thenickdude</a> who maintains the valuable fork <a href="https://github.com/thenickdude/KVM-Opencore">KVM-OpenCore</a>, which was started by <a href="https://github.com/Leoyzen/">@Leoyzen</a>!</p> 
<p>Extra special thanks to the OpenCore team over at: <a href="https://github.com/acidanthera/OpenCorePkg">https://github.com/acidanthera/OpenCorePkg</a>. Their well-maintained bootloader provides much of the great functionality that Docker-OSX users enjoy :)</p> 
<p>If you like this project, consider contributing here or upstream!</p> 
<h2>Quick Start Docker-OSX</h2> 
<p>Video setup tutorial is also available here: <a href="https://www.youtube.com/watch?v=wLezYl77Ll8">https://www.youtube.com/watch?v=wLezYl77Ll8</a></p> 
<p><strong>Windows users:</strong> <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#id-like-to-run-docker-osx-on-windows">click here to see the notes below</a>!</p> 
<p align="center"> <a href="https://www.youtube.com/watch?v=wLezYl77Ll8" target="_blank"><img src="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/Youtube-Screenshot-Docker-OSX-Setup.png" /></a> </p> 
<p>First time here? try <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#initial-setup">initial setup</a>, otherwise try the instructions below to use either Catalina or Big Sur.</p> 
<h2>Any questions, ideas, or just want to hang out?</h2> 
<h1><a href="https://discord.gg/sickchat">https://discord.gg/sickchat</a></h1> 
<h3>Catalina <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/latest?label=sickcodes%2Fdocker-osx%3Alatest" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/latest?label=sickcodes%2Fdocker-osx%3Alatest" /></a></h3> 
<pre><code class="language-bash">docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:latest

# docker build -t docker-osx .
</code></pre> 
<h3>Big Sur <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/big-sur?label=sickcodes%2Fdocker-osx%3Abig-sur" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/big-sur?label=sickcodes%2Fdocker-osx%3Abig-sur" /></a></h3> 
<pre><code class="language-bash">docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:big-sur

# docker build -t docker-osx --build-arg SHORTNAME=big-sur .
</code></pre> 
<h3>Monterey <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/monterey?label=sickcodes%2Fdocker-osx%3Amonterey" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/monterey?label=sickcodes%2Fdocker-osx%3Amonterey" /></a></h3> 
<pre><code class="language-bash">
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_UNIQUE=true \
    -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist' \
    sickcodes/docker-osx:monterey

# docker build -t docker-osx --build-arg SHORTNAME=monterey .
</code></pre> 
<h3>Ventura <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/ventura?label=sickcodes%2Fdocker-osx%3Aventura" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/ventura?label=sickcodes%2Fdocker-osx%3Aventura" /></a></h3> 
<pre><code class="language-bash">
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_UNIQUE=true \
    -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist' \
    sickcodes/docker-osx:ventura

# docker build -t docker-osx --build-arg SHORTNAME=ventura .
</code></pre> 
<h3>Sonoma <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/sonoma?label=sickcodes%2Fdocker-osx%3Asonoma" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/sonoma?label=sickcodes%2Fdocker-osx%3Asonoma" /></a></h3> 
<pre><code class="language-bash">
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_UNIQUE=true \
    -e CPU='Haswell-noTSX' \
    -e CPUID_FLAGS='kvm=on,vendor=GenuineIntel,+invtsc,vmware-cpuid-freq=on' \
    -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom-sonoma.plist' \
    sickcodes/docker-osx:sonoma

# docker build -t docker-osx --build-arg SHORTNAME=sonoma .
</code></pre> 
<h4>Run Catalina Pre-Installed <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/auto?label=sickcodes%2Fdocker-osx%3Aauto" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/auto?label=sickcodes%2Fdocker-osx%3Aauto" /></a></h4> 
<pre><code class="language-bash"># 40GB disk space required: 20GB original image 20GB your container.
docker pull sickcodes/docker-osx:auto

# boot directly into a real OS X shell with a visual display [NOT HEADLESS]
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_UNIQUE=true \
    sickcodes/docker-osx:auto

# username is user
# passsword is alpine
</code></pre> 
<h3>Older Systems</h3> 
<h3>High Sierra <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/high-sierra?label=sickcodes%2Fdocker-osx%3Ahigh-sierra" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/high-sierra?label=sickcodes%2Fdocker-osx%3Ahigh-sierra" /></a></h3> 
<pre><code class="language-bash">
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:high-sierra

# docker build -t docker-osx --build-arg SHORTNAME=high-sierra .
</code></pre> 
<h3>Mojave <a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/mojave?label=sickcodes%2Fdocker-osx%3Amojave" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/mojave?label=sickcodes%2Fdocker-osx%3Amojave" /></a></h3> 
<pre><code class="language-bash">
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:mojave

# docker build -t docker-osx --build-arg SHORTNAME=mojave .
</code></pre> 
<h4>Download the image manually and use it in Docker</h4> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked?label=sickcodes%2Fdocker-osx%3Anaked" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked?label=sickcodes%2Fdocker-osx%3Anaked" /></a></p> 
<p>This is a particularly good way for downloading the container, in case Docker's CDN (or your connection) happens to be slow.</p> 
<pre><code class="language-bash">wget https://images2.sick.codes/mac_hdd_ng_auto.img

docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v "${PWD}/mac_hdd_ng_auto.img:/image" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_UNIQUE=true \
    -e MASTER_PLIST_URL=https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/custom/config-nopicker-custom.plist \
    sickcodes/docker-osx:naked
</code></pre> 
<h4>Use your own image and manually and automatically log into a shell</h4> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked-auto?label=sickcodes%2Fdocker-osx%3Anaked-auto" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked-auto?label=sickcodes%2Fdocker-osx%3Anaked-auto" /></a></p> 
<p>Enable SSH in network sharing inside the guest first. Change <code>-e "USERNAME=user"</code> and <code>-e "PASSWORD=password"</code> to your credentials. The container will add itself to <code>~/.ssh/authorized_keys</code></p> 
<p>Since you can't see the screen, use the PLIST with nopicker, for example:</p> 
<pre><code class="language-bash"># Catalina
# wget https://images2.sick.codes/mac_hdd_ng_auto.img
# Monterey
wget https://images.sick.codes/mac_hdd_ng_auto_monterey.img

docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v "${PWD}/mac_hdd_ng_auto_monterey.img:/image" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e "USERNAME=user" \
    -e "PASSWORD=alpine" \
    -e GENERATE_UNIQUE=true \
    -e MASTER_PLIST_URL=https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/custom/config-nopicker-custom.plist \
    sickcodes/docker-osx:naked-auto
</code></pre> 
<h1>Share directories, sharing files, shared folder, mount folder</h1> 
<p>The easiest and most secure way is <code>sshfs</code></p> 
<pre><code class="language-bash"># on Linux/Windows
mkdir ~/mnt/osx
sshfs user@localhost:/ -p 50922 ~/mnt/osx
# wait a few seconds, and ~/mnt/osx will have full rootfs mounted over ssh, and in userspace
# automated: sshpass -p &lt;password&gt; sshfs user@localhost:/ -p 50922 ~/mnt/osx
</code></pre> 
<h1>(VFIO) iPhone USB passthrough (VFIO)</h1> 
<p>If you have a laptop see the next usbfluxd section.</p> 
<p>If you have a desktop PC, you can use <a href="https://github.com/Silfalion">@Silfalion</a>'s instructions: <a href="https://github.com/Silfalion/Iphone_docker_osx_passthrough">https://github.com/Silfalion/Iphone_docker_osx_passthrough</a></p> 
<h1>(USBFLUXD) iPhone USB -&gt; Network style passthrough OSX-KVM Docker-OSX</h1> 
<p>Video setup tutorial for usbfluxd is also available here: <a href="https://www.youtube.com/watch?v=kTk5fGjK_PM">https://www.youtube.com/watch?v=kTk5fGjK_PM</a></p> 
<p align="center"> <a href="https://www.youtube.com/watch?v=kTk5fGjK_PM" target="_blank"><img alt="iPhone USB passthrough on macOS virtual machine Linux &amp; Windows" src="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/Youtube-USBFLUXD-Screenshot-Docker-OSX.png" /></a> </p> 
<p>This method WORKS on laptop, PC, anything!</p> 
<p>Thank you <a href="https://github.com/nikias">@nikias</a> for <a href="https://github.com/corellium/usbfluxd">usbfluxd</a> via <a href="https://github.com/corellium">https://github.com/corellium</a>!</p> 
<p><strong>This is done inside Linux.</strong></p> 
<p>Open 3 terminals on Linux</p> 
<p>Connecting your device over USB on Linux allows you to expose <code>usbmuxd</code> on port <code>5000</code> using <a href="https://github.com/corellium/usbfluxd">https://github.com/corellium/usbfluxd</a> to another system on the same network.</p> 
<p>Ensure <code>usbmuxd</code>, <code>socat</code> and <code>usbfluxd</code> are installed.</p> 
<p><code>sudo pacman -S libusbmuxd usbmuxd avahi socat</code></p> 
<p>Available on the AUR: <a href="https://aur.archlinux.org/packages/usbfluxd/">https://aur.archlinux.org/packages/usbfluxd/</a></p> 
<p><code>yay usbfluxd</code></p> 
<p>Plug in your iPhone or iPad.</p> 
<p>Terminal 1</p> 
<pre><code class="language-bash">sudo systemctl start usbmuxd
sudo avahi-daemon
</code></pre> 
<p>Terminal 2:</p> 
<pre><code class="language-bash"># on host
sudo systemctl restart usbmuxd
sudo socat tcp-listen:5000,fork unix-connect:/var/run/usbmuxd
</code></pre> 
<p>Terminal 3:</p> 
<pre><code class="language-bash">sudo usbfluxd -f -n
</code></pre> 
<h3>Connect to a host running usbfluxd</h3> 
<p><strong>This is done inside macOS.</strong></p> 
<p>Install homebrew.</p> 
<p><code>172.17.0.1</code> is usually the Docker bridge IP, which is your PC, but you can use any IP from <code>ip addr</code>...</p> 
<p>macOS Terminal:</p> 
<pre><code class="language-zsh"># on the guest
brew install make automake autoconf libtool pkg-config gcc libimobiledevice usbmuxd

git clone https://github.com/corellium/usbfluxd.git
cd usbfluxd

./autogen.sh
make
sudo make install
</code></pre> 
<p>Accept the USB over TCP connection, and appear as local:</p> 
<p>(you may need to change <code>172.17.0.1</code> to the IP address of the host. e.g. check <code>ip addr</code>)</p> 
<pre><code class="language-bash"># on the guest
sudo launchctl start usbmuxd
export PATH=/usr/local/sbin:${PATH}
sudo usbfluxd -f -r 172.17.0.1:5000
</code></pre> 
<p>Close apps such as Xcode and reopen them and your device should appear!</p> 
<p><em>If you need to start again on Linux, wipe the current usbfluxd, usbmuxd, and socat:</em></p> 
<pre><code class="language-bash">sudo killall usbfluxd
sudo systemctl restart usbmuxd
sudo killall socat
</code></pre> 
<h2>Make container FASTER using <a href="https://github.com/sickcodes/osx-optimizer">https://github.com/sickcodes/osx-optimizer</a></h2> 
<p>SEE commands in <a href="https://github.com/sickcodes/osx-optimizer">https://github.com/sickcodes/osx-optimizer</a>!</p> 
<ul> 
 <li>Skip the GUI login screen (at your own risk!)</li> 
 <li>Disable spotlight indexing on macOS to heavily speed up Virtual Instances.</li> 
 <li>Disable heavy login screen wallpaper</li> 
 <li>Disable updates (at your own risk!)</li> 
</ul> 
<h2>Increase disk space by moving /var/lib/docker to external drive, block storage, NFS, or any other location conceivable.</h2> 
<p>Move /var/lib/docker, following the tutorial below</p> 
<ul> 
 <li>Cheap large physical disk storage instead using your server's disk, or SSD.</li> 
 <li>Block Storage, NFS, etc.</li> 
</ul> 
<p>Tutorial here: <a href="https://sick.codes/how-to-run-docker-from-block-storage/">https://sick.codes/how-to-run-docker-from-block-storage/</a></p> 
<p>Only follow the above tutorial if you are happy with wiping all your current Docker images/layers.</p> 
<p>Safe mode: Disable docker temporarily so you can move the Docker folder temporarily.</p> 
<ul> 
 <li>Do NOT do this until you have moved your image out already <a href="https://github.com/dulatello08/Docker-OSX/#quick-start-your-own-image-naked-container-image">https://github.com/dulatello08/Docker-OSX/#quick-start-your-own-image-naked-container-image</a></li> 
</ul> 
<pre><code class="language-bash">killall dockerd
systemctl disable --now docker
systemctl disable --now docker.socket
systemctl stop docker
systemctl stop docker.socket
</code></pre> 
<p>Now, that Docker daemon is off, move /var/lib/docker somewhere</p> 
<p>Then, symbolicly link /var/lib/docker somewhere:</p> 
<pre><code class="language-bash">mv /var/lib/docker /run/media/user/some_drive/docker
ln -s /run/media/user/some_drive/docker /var/lib/docker

# now check if /var/lib/docker is working still
ls /var/lib/docker
</code></pre> 
<p>If you see folders, then it worked. You can restart Docker, or just reboot if you want to be sure.</p> 
<h2>Important notices:</h2> 
<p><strong>2021-11-14</strong> - Added High Sierra, Mojave</p> 
<p>Pick one of these while <strong>building</strong>, irrelevant when using docker pull:</p> 
<pre><code>--build-arg SHORTNAME=high-sierra 
--build-arg SHORTNAME=mojave
--build-arg SHORTNAME=catalina
--build-arg SHORTNAME=big-sur
--build-arg SHORTNAME=monterey
--build-arg SHORTNAME=ventura
--build-arg SHORTNAME=sonoma
</code></pre> 
<h2>Technical details</h2> 
<p>There are currently multiple images, each with different use cases (explained <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#container-images">below</a>):</p> 
<ul> 
 <li>High Sierra</li> 
 <li>Mojave</li> 
 <li>Catalina</li> 
 <li>Big Sur</li> 
 <li>Monterey</li> 
 <li>Ventura</li> 
 <li>Sonoma</li> 
 <li>Auto (pre-made Catalina)</li> 
 <li>Naked (use your own .img)</li> 
 <li>Naked-Auto (user your own .img and SSH in)</li> 
</ul> 
<p>High Sierra:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/high-sierra?label=sickcodes%2Fdocker-osx%3Ahigh-sierra" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/high-sierra?label=sickcodes%2Fdocker-osx%3Ahigh-sierra" /></a></p> 
<p>Mojave:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/mojave?label=sickcodes%2Fdocker-osx%3Amojave" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/mojave?label=sickcodes%2Fdocker-osx%3Amojave" /></a></p> 
<p>Catalina:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/latest?label=sickcodes%2Fdocker-osx%3Alatest" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/latest?label=sickcodes%2Fdocker-osx%3Alatest" /></a></p> 
<p>Big-Sur:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/big-sur?label=sickcodes%2Fdocker-osx%3Abig-sur" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/big-sur?label=sickcodes%2Fdocker-osx%3Abig-sur" /></a></p> 
<p>Monterey make your own image:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/monterey?label=sickcodes%2Fdocker-osx%3Amonterey" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/monterey?label=sickcodes%2Fdocker-osx%3Amonterey" /></a></p> 
<p>Ventura make your own image:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/ventura?label=sickcodes%2Fdocker-osx%3Aventura" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/ventura?label=sickcodes%2Fdocker-osx%3Aventura" /></a></p> 
<p>Sonoma make your own image:</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/sonoma?label=sickcodes%2Fdocker-osx%3Asonoma" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/sonoma?label=sickcodes%2Fdocker-osx%3Asonoma" /></a></p> 
<p>Pre-made <strong>Catalina</strong> system by <a href="https://sick.codes">Sick.Codes</a>: username: <code>user</code>, password: <code>alpine</code></p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/auto?label=sickcodes%2Fdocker-osx%3Aauto" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/auto?label=sickcodes%2Fdocker-osx%3Aauto" /></a></p> 
<p>Naked: Bring-your-own-image setup (use any of the above first):</p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked?label=sickcodes%2Fdocker-osx%3Anaked" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked?label=sickcodes%2Fdocker-osx%3Anaked" /></a></p> 
<p>Naked Auto: same as above but with <code>-e USERNAME</code> &amp; <code>-e PASSWORD</code> and <code>-e OSX_COMMANDS="put your commands here"</code></p> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked-auto?label=sickcodes%2Fdocker-osx%3Anaked-auto" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked-auto?label=sickcodes%2Fdocker-osx%3Anaked-auto" /></a></p> 
<h2>Capabilities</h2> 
<ul> 
 <li>use iPhone OSX KVM on Linux using <a href="https://github.com/corellium/usbfluxd">usbfluxd</a>!</li> 
 <li>macOS Monterey VM on Linux!</li> 
 <li>Folder sharing-</li> 
 <li>USB passthrough (hotplug too)</li> 
 <li>SSH enabled (<code>localhost:50922</code>)</li> 
 <li>VNC enabled (<code>localhost:8888</code>) if using ./vnc version</li> 
 <li>iMessage security research via <a href="https://github.com/sickcodes/osx-serial-generator">serial number generator!</a></li> 
 <li>X11 forwarding is enabled</li> 
 <li>runs on top of QEMU + KVM</li> 
 <li>supports Big Sur, custom images, Xvfb headless mode</li> 
 <li>you can clone your container with <code>docker commit</code></li> 
</ul> 
<h3>Requirements</h3> 
<ul> 
 <li>20GB+++ disk space for bare minimum installation (50GB if using Xcode)</li> 
 <li>virtualization should be enabled in your BIOS settings</li> 
 <li>a x86_64 kvm-capable host</li> 
 <li>at least 50 GBs for <code>:auto</code> (half for the base image, half for your runtime image</li> 
</ul> 
<h3>TODO</h3> 
<ul> 
 <li>documentation for security researchers</li> 
 <li>gpu acceleration</li> 
 <li>support for virt-manager</li> 
</ul> 
<h2>Docker</h2> 
<p>Images built on top of the contents of this repository are also available on <strong>Docker Hub</strong> for convenience: <a href="https://hub.docker.com/r/sickcodes/docker-osx">https://hub.docker.com/r/sickcodes/docker-osx</a></p> 
<p>A comprehensive list of the available Docker images and their intended purpose can be found in the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#instructions">Instructions</a>.</p> 
<h2>Kubernetes</h2> 
<p>Docker-OSX supports Kubernetes.</p> 
<p>Kubernetes Helm Chart &amp; Documentation can be found under the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/helm/README.md">helm directory</a>.</p> 
<p>Thanks <a href="https://github.com/cephasara">cephasara</a> for contributing this major contribution.</p> 
<p><a href="https://artifacthub.io/packages/search?repo=docker-osx"><img alt="Artifact HUB" src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/docker-osx" /></a></p> 
<h2>Support</h2> 
<h3>Small questions &amp; issues</h3> 
<p>Feel free to open an <a href="https://github.com/sickcodes/Docker-OSX/issues/new/choose">issue</a>, should you come across minor issues with running Docker-OSX or have any questions.</p> 
<h4>Resolved issues</h4> 
<p>Before you open an issue, however, please check the <a href="https://github.com/sickcodes/Docker-OSX/issues?q=is%3Aissue+is%3Aclosed">closed issues</a> and confirm that you're using the latest version of this repository — your issues may have already been resolved! You might also see your answer in our questions and answers section <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#more-questions-and-answers">below</a>.</p> 
<h3>Feature requests and updates</h3> 
<p>Follow <a href="https://twitter.com/sickcodes">@sickcodes</a>!</p> 
<h3>Professional support</h3> 
<p>For more sophisticated endeavours, we offer the following support services:</p> 
<ul> 
 <li>Enterprise support, business support, or casual support.</li> 
 <li>Custom images, custom scripts, consulting (per hour available!)</li> 
 <li>One-on-one conversations with you or your development team.</li> 
</ul> 
<p>In case you're interested, contact <a href="https://twitter.com/sickcodes">@sickcodes on Twitter</a> or click <a href="https://sick.codes/contact">here</a>.</p> 
<h2>License/Contributing</h2> 
<p>Docker-OSX is licensed under the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/LICENSE">GPL v3+</a>. Contributions are welcomed and immensely appreciated. You are in fact permitted to use Docker-OSX as a tool to create proprietary software.</p> 
<h3>Other cool Docker/QEMU based projects</h3> 
<ul> 
 <li><a href="https://github.com/sickcodes/dock-droid">Run Android in a Docker Container with Dock Droid</a></li> 
 <li><a href="https://github.com/sickcodes/droid-native">Run Android fully native on the host!</a></li> 
 <li><a href="https://github.com/sickcodes/Docker-eyeOS">Run iOS 12 in a Docker container with Docker-eyeOS</a> - <a href="https://github.com/sickcodes/Docker-eyeOS">https://github.com/sickcodes/Docker-eyeOS</a></li> 
 <li><a href="https://bluebubbles.app/">Run iMessage relayer in Docker with Bluebubbles.app</a> - <a href="https://github.com/BlueBubblesApp/BlueBubbles-Server/wiki/Running-via-Docker">Getting started wiki</a></li> 
</ul> 
<h2>Disclaimer</h2> 
<p>If you are serious about Apple Security, and possibly finding 6-figure bug bounties within the Apple Bug Bounty Program, then you're in the right place! Further notes: <a href="https://sick.codes/is-hackintosh-osx-kvm-or-docker-osx-legal/">Is Hackintosh, OSX-KVM, or Docker-OSX legal?</a></p> 
<p>Product names, logos, brands and other trademarks referred to within this project are the property of their respective trademark holders. These trademark holders are not affiliated with our repository in any capacity. They do not sponsor or endorse this project in any way.</p> 
<h1>Instructions</h1> 
<h2>Container images</h2> 
<h3>Already set up or just looking to make a container quickly? Check out our <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-docker-osx">quick start</a> or see a bunch more use cases under our <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#container-creation-examples">container creation examples</a> section.</h3> 
<p>There are several different Docker-OSX images available that are suitable for different purposes.</p> 
<ul> 
 <li><code>sickcodes/docker-osx:latest</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-docker-osx">I just want to try it out.</a></li> 
 <li><code>sickcodes/docker-osx:latest</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-your-own-image-naked-container-image">I want to use Docker-OSX to develop/secure apps in Xcode (sign into Xcode, Transporter)</a></li> 
 <li><code>sickcodes/docker-osx:naked</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#building-a-headless-container-from-a-custom-image">I want to use Docker-OSX for CI/CD-related purposes (sign into Xcode, Transporter)</a></li> 
</ul> 
<p>Create your personal image using <code>:latest</code> or <code>big-sur</code>. Then, pull the image out the image. Afterwards, you will be able to duplicate that image and import it to the <code>:naked</code> container, in order to revert the container to a previous state repeatedly.</p> 
<ul> 
 <li> <p><code>sickcodes/docker-osx:auto</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#prebuilt-image-with-arbitrary-command-line-arguments">I'm only interested in using the command line (useful for compiling software or using Homebrew headlessly).</a></p> </li> 
 <li> <p><code>sickcodes/docker-osx:naked</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#generating-serial-numbers">I need iMessage/iCloud for security research.</a></p> </li> 
 <li> <p><code>sickcodes/docker-osx:big-sur</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-docker-osx">I want to run Big Sur.</a></p> </li> 
 <li> <p><code>sickcodes/docker-osx:monterey</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-docker-osx">I want to run Monterey.</a></p> </li> 
 <li> <p><code>sickcodes/docker-osx:ventura</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-docker-osx">I want to run Ventura.</a></p> </li> 
 <li> <p><code>sickcodes/docker-osx:sonoma</code> - <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#quick-start-docker-osx">I want to run Sonoma.</a></p> </li> 
 <li> <p><code>sickcodes/docker-osx:high-sierra</code> - I want to run High Sierra.</p> </li> 
 <li> <p><code>sickcodes/docker-osx:mojave</code> - I want to run Mojave.</p> </li> 
</ul> 
<h2>Initial setup</h2> 
<p>Before you do anything else, you will need to turn on hardware virtualization in your BIOS. Precisely how will depend on your particular machine (and BIOS), but it should be straightforward.</p> 
<p>Then, you'll need QEMU and some other dependencies on your host:</p> 
<pre><code class="language-bash"># ARCH
sudo pacman -S qemu libvirt dnsmasq virt-manager bridge-utils flex bison iptables-nft edk2-ovmf

# UBUNTU DEBIAN
sudo apt install qemu qemu-kvm libvirt-clients libvirt-daemon-system bridge-utils virt-manager libguestfs-tools

# CENTOS RHEL FEDORA
sudo yum install libvirt qemu-kvm
</code></pre> 
<p>Then, enable libvirt and load the KVM kernel module:</p> 
<pre><code class="language-bash">sudo systemctl enable --now libvirtd
sudo systemctl enable --now virtlogd

echo 1 | sudo tee /sys/module/kvm/parameters/ignore_msrs

sudo modprobe kvm
</code></pre> 
<h3>I'd like to run Docker-OSX on Windows</h3> 
<p>Running Docker-OSX on Windows is possible using WSL2 (Windows 11 + Windows Subsystem for Linux).</p> 
<p>You must have Windows 11 installed with build 22000+ (21H2 or higher).</p> 
<p>First, install WSL on your computer by running this command in an administrator powershell. For more info, look <a href="https://docs.microsoft.com/en-us/windows/wsl/install">here</a>.</p> 
<p>This will install Ubuntu by default.</p> 
<pre><code>wsl --install
</code></pre> 
<p>You can confirm WSL2 is enabled using <code>wsl -l -v</code> in PowerShell. To see other distributions that are available, use <code>wsl -l -o</code>.</p> 
<p>If you have previously installed WSL1, upgrade to WSL 2. Check <a href="https://docs.microsoft.com/en-us/windows/wsl/install#upgrade-version-from-wsl-1-to-wsl-2">this link to upgrade from WSL1 to WSL2</a>.</p> 
<p>After WSL installation, go to <code>C:/Users/&lt;Your_Name&gt;/.wslconfig</code> and add <code>nestedVirtualization=true</code> to the end of the file (If the file doesn't exist, create it). For more information about the <code>.wslconfig</code> file check <a href="https://docs.microsoft.com/en-us/windows/wsl/wsl-config#wslconfig">this link</a>. Verify that you have selected "Show Hidden Files" and "Show File Extensions" in File Explorer options. The result should be like this:</p> 
<pre><code>[wsl2]
nestedVirtualization=true
</code></pre> 
<p>Go into your WSL distro (Run <code>wsl</code> in powershell) and check if KVM is enabled by using the <code>kvm-ok</code> command. The output should look like this:</p> 
<pre><code>INFO: /dev/kvm exists
KVM acceleration can be used
</code></pre> 
<p>Use the command <code>sudo apt -y install bridge-utils cpu-checker libvirt-clients libvirt-daemon qemu qemu-kvm</code> to install it if it isn't.</p> 
<p>Now download and install <a href="https://docs.docker.com/desktop/windows/install/">Docker for Windows</a> if it is not already installed.</p> 
<p>After installation, go into Settings and check these 2 boxes:</p> 
<pre><code>General -&gt; "Use the WSL2 based engine";
Resources -&gt; WSL Integration -&gt; "Enable integration with my default WSL distro", 
</code></pre> 
<p>Ensure <code>x11-apps</code> is installed. Use the command <code>sudo apt install x11-apps -y</code> to install it if it isn't.</p> 
<p>Finally, there are 3 ways to get video output:</p> 
<ul> 
 <li>WSLg: This is the simplest and easiest option to use. There may be some issues such as the keyboard not being fully passed through or seeing a second mouse on the desktop - <a href="https://github.com/microsoft/wslg/issues/376">Issue on WSLg</a> - but this option is recommended.</li> 
</ul> 
<p>To use WSLg's built-in X-11 server, change these two lines in the docker run command to point Docker-OSX to WSLg.</p> 
<pre><code>-e "DISPLAY=${DISPLAY:-:0.0}" \
-v /mnt/wslg/.X11-unix:/tmp/.X11-unix \
</code></pre> 
<p>Or try:</p> 
<pre><code>-e "DISPLAY=${DISPLAY:-:0}" \
-v /mnt/wslg/.X11-unix:/tmp/.X11-unix \
</code></pre> 
<p>For Ubuntu 20.x on Windows, see <a href="https://github.com/sickcodes/Docker-OSX/discussions/458">https://github.com/sickcodes/Docker-OSX/discussions/458</a></p> 
<ul> 
 <li>VNC: See the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#building-a-headless-container-which-allows-insecure-vnc-on-localhost-for-local-use-only">VNC section</a> for more information. You could also add -vnc argument to qemu. Connect to your mac VM via a VNC Client. <a href="https://wiki.archlinux.org/title/QEMU#VNC">Here is a how to</a></li> 
 <li>Desktop Environment: This will give you a full desktop linux experience but it will use a bit more of the computer's resources. Here is an example guide, but there are other guides that help set up a desktop environment. <a href="https://www.makeuseof.com/tag/linux-desktop-windows-subsystem/">DE Example</a></li> 
</ul> 
<h2>Additional boot instructions for when you are <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#container-creation-examples">creating your container</a></h2> 
<ul> 
 <li> <p>Boot the macOS Base System (Press Enter)</p> </li> 
 <li> <p>Click <code>Disk Utility</code></p> </li> 
 <li> <p>Erase the BIGGEST disk (around 200gb default), DO NOT MODIFY THE SMALLER DISKS. -- if you can't click <code>erase</code>, you may need to reduce the disk size by 1kb</p> </li> 
 <li> <p>(optional) Create a partition using the unused space to house the OS and your files if you want to limit the capacity. (For Xcode 12 partition at least 60gb.)</p> </li> 
 <li> <p>Click <code>Reinstall macOS</code></p> </li> 
 <li> <p>The system may require multiple reboots during installation</p> </li> 
</ul> 
<h2>Troubleshooting</h2> 
<h3>Routine checks</h3> 
<p>This is a great place to start if you are having trouble getting going, especially if you're not that familiar with Docker just yet.</p> 
<p>Just looking to make a container quickly? Check out our <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#container-creation-examples">container creation examples</a> section.</p> 
<p>More specific/advanced troubleshooting questions and answers may be found in <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#more-questions-and-answers">More Questions and Answers</a>. You should also check out the <a href="https://github.com/sickcodes/Docker-OSX/issues?q=is%3Aissue+is%3Aclosed">closed issues</a>. Someone else might have gotten a question like yours answered already even if you can't find it in this document!</p> 
<h4>Confirm that your CPU supports virtualization</h4> 
<p>See <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#initial-setup">initial setup</a>.</p> 
<h4>Docker Unknown Server OS error</h4> 
<pre><code class="language-console">docker: unknown server OS: .
See 'docker run --help'.
</code></pre> 
<p>This means your docker daemon is not running.</p> 
<p><code>pgrep dockerd</code> should return nothing</p> 
<p>Therefore, you have a few choices.</p> 
<p><code>sudo dockerd</code> for foreground Docker usage. I use this.</p> 
<p>Or</p> 
<p><code>sudo systemctl --start dockerd</code> to start dockerd this now.</p> 
<p>Or</p> 
<p><code>sudo systemctl --enable --now dockerd</code> for start dockerd on every reboot, and now.</p> 
<h4>Use more CPU Cores/SMP</h4> 
<p>Examples:</p> 
<p><code>-e EXTRA='-smp 6,sockets=3,cores=2'</code></p> 
<p><code>-e EXTRA='-smp 8,sockets=4,cores=2'</code></p> 
<p><code>-e EXTRA='-smp 16,sockets=8,cores=2'</code></p> 
<p>Note, unlike memory, CPU usage is shared. so you can allocate all of your CPU's to the container.</p> 
<h3>Confirm your user is part of the Docker group, KVM group, libvirt group</h3> 
<h4>Add yourself to the Docker group</h4> 
<p>If you use <code>sudo dockerd</code> or dockerd is controlled by systemd/systemctl, then you must be in the Docker group. If you are not in the Docker group:</p> 
<pre><code class="language-bash">sudo usermod -aG docker "${USER}"
</code></pre> 
<p>and also add yourself to the kvm and libvirt groups if needed:</p> 
<pre><code class="language-bash">sudo usermod -aG libvirt "${USER}"
sudo usermod -aG kvm "${USER}"
</code></pre> 
<p>See also: <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#initial-setup">initial setup</a>.</p> 
<h4>Is the docker daemon enabled?</h4> 
<pre><code class="language-bash"># run ad hoc
sudo dockerd

# or daemonize it
sudo nohup dockerd &amp;

# enable it in systemd (it will persist across reboots this way)
sudo systemctl enable --now docker

# or just start it as your user with systemd instead of enabling it
systemctl start docker
</code></pre> 
<h2>More Questions and Answers</h2> 
<p>Big thank you to our contributors who have worked out almost every conceivable issue so far!</p> 
<p><a href="https://github.com/sickcodes/Docker-OSX/raw/master/CREDITS.md">https://github.com/sickcodes/Docker-OSX/blob/master/CREDITS.md</a></p> 
<h3>Start the same container later (persistent disk)</h3> 
<p>Created a container with <code>docker run</code> and want to reuse the underlying image again later?</p> 
<p>NB: see <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#container-creation-examples">container creation examples</a> first for how to get to the point where this is applicable.</p> 
<p>This is for when you want to run the SAME container again later. You may need to use <code>docker commit</code> to save your container before you can reuse it. Check if your container is persisted with <code>docker ps --all</code>.</p> 
<p>If you don't run this you will have a new image every time.</p> 
<pre><code class="language-bash"># look at your recent containers and copy the CONTAINER ID
docker ps --all

# docker start the container ID
docker start -ai abc123xyz567

# if you have many containers, you can try automate it with filters like this
# docker ps --all --filter "ancestor=sickcodes/docker-osx"
# for locally tagged/built containers
# docker ps --all --filter "ancestor=docker-osx"

</code></pre> 
<p>You can also pull the <code>.img</code> file out of the container, which is stored in <code>/var/lib/docker</code>, and supply it as a runtime argument to the <code>:naked</code> Docker image.</p> 
<p>See also: <a href="https://github.com/sickcodes/Docker-OSX/issues/197">here</a>.</p> 
<h3>I have used Docker-OSX before and want to restart a container that starts automatically</h3> 
<p>Containers that use <code>sickcodes/docker-osx:auto</code> can be stopped while being started.</p> 
<pre><code class="language-bash"># find last container
docker ps -a

# docker start old container with -i for interactive, -a for attach STDIN/STDOUT
docker start -ai -i &lt;Replace this with your ID&gt;
</code></pre> 
<h3>LibGTK errors "connection refused"</h3> 
<p>You may see one or more libgtk-related errors if you do not have everything set up for hardware virtualisation yet. If you have not yet done so, check out the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#initial-setup">initial setup</a> section and the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#routine-checks">routine checks</a> section as you may have missed a setup step or may not have all the needed Docker dependencies ready to go.</p> 
<p>See also: <a href="https://github.com/sickcodes/Docker-OSX/issues/174">here</a>.</p> 
<h4>Permissions denied error</h4> 
<p>If you have not yet set up xhost, try the following:</p> 
<pre><code class="language-bash">echo $DISPLAY

# ARCH
sudo pacman -S xorg-xhost

# UBUNTU DEBIAN
sudo apt install x11-xserver-utils

# CENTOS RHEL FEDORA
sudo yum install xorg-x11-server-utils

# then run
xhost +

</code></pre> 
<h3>RAM over-allocation</h3> 
<p>You cannot allocate more RAM than your machine has. The default is 3 Gigabytes: <code>-e RAM=3</code>.</p> 
<p>If you are trying to allocate more RAM to the container than you currently have available, you may see an error like the following: <code>cannot set up guest memory 'pc.ram': Cannot allocate memory</code>. See also: <a href="https://github.com/sickcodes/Docker-OSX/issues/188">here</a>, <a href="https://github.com/sickcodes/Docker-OSX/pull/189">here</a>.</p> 
<p>For example (below) the <code>buff/cache</code> already contains 20 Gigabytes of allocated RAM:</p> 
<pre><code class="language-console">[user@hostname ~]$ free -mh
               total        used        free      shared  buff/cache   available
Mem:            30Gi       3.5Gi       7.0Gi       728Mi        20Gi        26Gi
Swap:           11Gi          0B        11Gi
</code></pre> 
<p>Clear the buffer and the cache:</p> 
<pre><code class="language-bash">sudo tee /proc/sys/vm/drop_caches &lt;&lt;&lt; 3
</code></pre> 
<p>Now check the RAM again:</p> 
<pre><code class="language-console">[user@hostname ~]$ free -mh
               total        used        free      shared  buff/cache   available
Mem:            30Gi       3.3Gi        26Gi       697Mi       1.5Gi        26Gi
Swap:           11Gi          0B        11Gi
</code></pre> 
<h3>PulseAudio</h3> 
<h4>Use PulseAudio for sound</h4> 
<p>Note: <a href="https://github.com/acidanthera/AppleALC">AppleALC</a>, <a href="https://dortania.github.io/OpenCore-Post-Install/universal/audio.html"><code>alcid</code></a> and <a href="https://github.com/chris1111/VoodooHDA-OC">VoodooHDA-OC</a> do not have <a href="https://osy.gitbook.io/hac-mini-guide/details/hda-fix#hda-codec">codec support</a>. However, <a href="https://github.com/vulgo/IORegistryExplorer">IORegistryExplorer</a> does show the controller component working.</p> 
<pre><code class="language-bash">docker run \
    --device /dev/kvm \
    -e AUDIO_DRIVER=pa,server=unix:/tmp/pulseaudio.socket \
    -v "/run/user/$(id -u)/pulse/native:/tmp/pulseaudio.socket" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    sickcodes/docker-osx
</code></pre> 
<h4>PulseAudio debugging</h4> 
<pre><code class="language-bash">docker run \
    --device /dev/kvm \
    -e AUDIO_DRIVER=pa,server=unix:/tmp/pulseaudio.socket \
    -v "/run/user/$(id -u)/pulse/native:/tmp/pulseaudio.socket" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e PULSE_SERVER=unix:/tmp/pulseaudio.socket \
    sickcodes/docker-osx pactl list
</code></pre> 
<h4>PulseAudio with WSLg</h4> 
<pre><code class="language-bash">docker run \
    --device /dev/kvm \
    -e AUDIO_DRIVER=pa,server=unix:/tmp/pulseaudio.socket \
    -v /mnt/wslg/runtime-dir/pulse/native:/tmp/pulseaudio.socket \
    -v /mnt/wslg/.X11-unix:/tmp/.X11-unix \
    sickcodes/docker-osx
</code></pre> 
<h3>Forward additional ports (nginx hosting example)</h3> 
<p>It's possible to forward additional ports depending on your needs. In this example, we'll use Mac OSX to host nginx:</p> 
<pre><code>host:10023 &lt;-&gt; 10023:container:10023 &lt;-&gt; 80:guest
</code></pre> 
<p>On the host machine, run:</p> 
<pre><code class="language-bash">docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -e ADDITIONAL_PORTS='hostfwd=tcp::10023-:80,' \
    -p 10023:10023 \
    sickcodes/docker-osx:auto
</code></pre> 
<p>In a Terminal session running the container, run:</p> 
<pre><code class="language-bash">/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

brew install nginx
sudo sed -i -e 's/8080/80/' /usr/local/etc/nginx/nginx.confcd
# sudo nginx -s stop
sudo nginx
</code></pre> 
<p><strong>nginx should now be reachable on port 10023.</strong></p> 
<p>Additionally, you can string multiple statements together, for example:</p> 
<pre><code class="language-bash">    -e ADDITIONAL_PORTS='hostfwd=tcp::10023-:80,hostfwd=tcp::10043-:443,'
    -p 10023:10023 \
    -p 10043:10043 \
</code></pre> 
<h3>Bridged networking</h3> 
<p>You might not need to do anything with the default setup to enable internet connectivity from inside the container. Additionally, <code>curl</code> may work even if <code>ping</code> doesn't.</p> 
<p>See discussion <a href="https://github.com/sickcodes/Docker-OSX/issues/177">here</a> and <a href="https://github.com/sickcodes/Docker-OSX/issues/72">here</a> and <a href="https://github.com/sickcodes/Docker-OSX/issues/88">here</a>.</p> 
<h3>Enable IPv4 forwarding for bridged network connections for remote installations</h3> 
<p>This is not required for LOCAL installations.</p> 
<p>Additionally note it may <a href="https://sick.codes/cve-2020-15590/">cause the host to leak your IP, even if you're using a VPN in the container</a>.</p> 
<p>However, if you're trying to connect to an instance of Docker-OSX remotely (e.g. an instance of Docker-OSX hosted in a datacenter), this may improve your performance:</p> 
<pre><code class="language-bash"># enable for current session
sudo sysctl -w net.ipv4.ip_forward=1

# OR
# sudo tee /proc/sys/net/ipv4/ip_forward &lt;&lt;&lt; 1

# enable permanently
sudo touch /etc/sysctl.conf
sudo tee -a /etc/sysctl.conf &lt;&lt;EOF
net.ipv4.ip_forward = 1
EOF

# or edit manually with the editor of your choice
nano /etc/sysctl.conf || vi /etc/sysctl.conf || vim /etc/sysctl.conf

# now reboot
</code></pre> 
<h2>Share folder with Docker-OSX QEMU macOS</h2> 
<p>Sharing a folder with guest is quite simple.</p> 
<p>Your folder, will go to /mnt/hostshare inside the Arch container which is then passed over QEMU.</p> 
<p>Then mount using <code>sudo -S mount_9p hostshare</code> from inside the mac.</p> 
<p>For example,</p> 
<pre><code class="language-bash">FOLDER=~/somefolder
</code></pre> 
<pre><code class="language-bash">    -v "${FOLDER}:/mnt/hostshare" \
    -e EXTRA="-virtfs local,path=/mnt/hostshare,mount_tag=hostshare,security_model=passthrough,id=hostshare" \
</code></pre> 
<p>Full example:</p> 
<pre><code class="language-bash"># stat mac_hdd_ng.img
SHARE=~/somefolder

docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -v "${PWD}/mac_hdd_ng.img:/home/arch/OSX-KVM/mac_hdd_ng.img" \
    -v "${SHARE}:/mnt/hostshare" \
    -e EXTRA="-virtfs local,path=/mnt/hostshare,mount_tag=hostshare,security_model=passthrough,id=hostshare" \
    sickcodes/docker-osx:latest

# !!! Open Terminal inside macOS and run the following command to mount the virtual file system
# sudo -S mount_9p hostshare

</code></pre> 
<h3>Share Linux NFS Drive into macOS</h3> 
<p>To share a folder using NFS, setup a folder for on the host machine, for example, <code>/srv/nfs/share</code> and then append to <code>/etc/exports</code>:</p> 
<pre><code class="language-bash">/srv/nfs/share      127.0.0.1/0(insecure,rw,all_squash,anonuid=1000,anongid=985,no_subtree_check)
</code></pre> 
<p>You may need to reload exports now, which will begin sharing that directory.</p> 
<pre><code class="language-bash"># reload shared folders
sudo exportfs -arv
</code></pre> 
<p><a href="https://serverfault.com/questions/716350/mount-nfs-volume-on-ubuntu-linux-server-from-macos-client">Source &amp; Explanation</a></p> 
<p>Give permissions on the shared folder for the <code>anonuid</code> and <code>anongid</code>, where <code>anonuid</code> and <code>anongid</code> matches that of your linux user; <code>id -u</code></p> 
<p><code>id -u ; id -g</code> will print <code>userid:groupid</code></p> 
<pre><code>chown 1000:985 /srv/nfs/share
chmod u+rwx /srv/nfs/share
</code></pre> 
<p>Start the Docker-OSX container with the additional flag <code>--network host</code></p> 
<p>Create and mount the nfs folder from the mac terminal:</p> 
<pre><code>mkdir -p ~/mnt
sudo mount_nfs -o locallocks 10.0.2.2:/srv/nfs/share ~/mnt
</code></pre> 
<h3>Share USB Drive into macOS over QEMU</h3> 
<h2>Mount USB Drive (Hotplug/Hot Plug USB)</h2> 
<p>Start your container.</p> 
<p>Pick a port, for example, <code>7700</code>.</p> 
<p><code>lsusb</code> to get <code>vid:pid</code></p> 
<p>On Linux: <code>sudo usbredirserver -p 7700 1e3d:2096</code></p> 
<p>Now, in the Docker window hit Enter to see the <code>(qemu)</code> console.</p> 
<p>You can add/remove the disk using commands like this, even once the machine is started:</p> 
<p><code>chardev-add socket,id=usbredirchardev1,port=7700,host=172.17.0.1</code></p> 
<p><code>device_add usb-redir,chardev=usbredirchardev1,id=usbredirdev1,debug=4</code></p> 
<h2>Mount USB Drive inside macOS at boot Docker OSX</h2> 
<pre><code class="language-bash">PORT=7700
IP_ADDRESS=172.17.0.1

-e EXTRA="-chardev socket,id=usbredirchardev1,port=${PORT},host=${IP_ADDRESS} -device usb-redir,chardev=usbredirchardev1,id=usbredirdev1,debug=4" \`
</code></pre> 
<h3>Fedora: enable internet connectivity with a bridged network</h3> 
<p>Fedora's default firewall settings may prevent Docker's network interface from reaching the internet. In order to resolve this, you will need to whitelist the interface in your firewall:</p> 
<pre><code class="language-bash"># Set the docker0 bridge to the trusted zone
sudo firewall-cmd --permanent --zone=trusted --add-interface=docker0
sudo firewall-cmd --reload
</code></pre> 
<h3>Nested Hardware Virtualization</h3> 
<p>Check if your machine has hardware virtualization enabled:</p> 
<pre><code class="language-bash">sudo tee /sys/module/kvm/parameters/ignore_msrs &lt;&lt;&lt; 1

egrep -c '(svm|vmx)' /proc/cpuinfo
</code></pre> 
<h3>Virtual network adapters</h3> 
<h4>Fast internet connectivity</h4> 
<p><code>-e NETWORKING=vmxnet3</code></p> 
<h4>Slow internet connectivity</h4> 
<p><code>-e NETWORKING=e1000-82545em</code></p> 
<h3>CI/CD Related Improvements</h3> 
<h4>Tips for reducing the size of the image</h4> 
<ul> 
 <li>Start the container as usual, and remove unnecessary files. A useful way to do this is to use <code>du -sh *</code> starting from the <code>/</code> directory, and find large directories where files can be removed. E.g. unnecessary cached files, Xcode platforms, etc.</li> 
 <li>Once you are satisfied with the amount of free space, enable trim with <code>sudo trimforce enable</code>, and reboot.</li> 
 <li>Zero out the empty space on the disk with <code>dd if=/dev/zero of=./empty &amp;&amp; rm -f empty</code></li> 
 <li>Shut down the VM and copy out the qcow image with <code>docker cp stoppedcontainer:/home/arch/OSX-KVM/mac_hdd_ng.img .</code></li> 
 <li>Run <code>qemu-img check -r all mac_hdd_ng.img</code> to fix any errors.</li> 
 <li>Run <code>qemu-img convert -O qcow2 mac_hdd_ng.img deduped.img</code> and check for errors again</li> 
 <li><strong>OPTIONAL:</strong> Run <code>qemu-img convert -c -O qcow2 deduped.img compressed.img</code> to further compress the image. This may reduce the runtime speed though, but it should reduce the size by roughly 25%.</li> 
 <li>Check for errors again, and build a fresh docker image. E.g. with this Dockerfile</li> 
</ul> 
<pre><code>FROM sickcodes/docker-osx
USER arch
COPY --chown=arch ./deduped.img /home/arch/OSX-KVM/mac_hdd_ng.img
</code></pre> 
<h3>Run Docker-OSX headlessly with Telnet</h3> 
<p>First make sure <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#autoboot-into-osx-after-youve-installed-everything">autoboot is enabled</a></p> 
<p>Next, you will want to set up SSH to be automatically started.</p> 
<pre><code class="language-bash">sudo systemsetup -setremotelogin on
</code></pre> 
<p>Make sure to commit the new docker image and save it, or rebuild as described in the <a href="https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/#how-to-reduce-the-size-of-the-image">section on reducing disk space</a>.</p> 
<p>Then run it with these arguments.</p> 
<pre><code class="language-bash"># Run with the -nographic flag, and enable a telnet interface
  docker run \
    --device /dev/kvm \
    -p 50922:10022 \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e EXTRA="-monitor telnet::45454,server,nowait -nographic -serial null" \
    mycustomimage
</code></pre> 
<h3>What mirrors are appropriate to use to build Docker-OSX locally?</h3> 
<p>If you are building Docker-OSX locally, you'll probably want to use Arch Linux's mirrors.</p> 
<p>Mirror locations can be found here (uses two-letter country codes): <a href="https://archlinux.org/mirrorlist/all/">https://archlinux.org/mirrorlist/all/</a></p> 
<pre><code class="language-bash">docker build -t docker-osx:latest \
    --build-arg RANKMIRRORS=true \
    --build-arg MIRROR_COUNTRY=US \
    --build-arg MIRROR_COUNT=10 \
    --build-arg SHORTNAME=catalina \
    --build-arg SIZE=200G .
</code></pre> 
<h3>Custom QEMU Arguments (passthrough devices)</h3> 
<p>Pass any devices/directories to the Docker container &amp; the QEMU arguments using the handy runtime argument provider option <code>-e EXTRA=</code>.</p> 
<pre><code class="language-bash"># example customizations
docker run \
    -e RAM=4 \
    -e SMP=4 \
    -e CORES=4 \
    -e EXTRA='-usb -device usb-host,hostbus=1,hostaddr=8' \
    -e INTERNAL_SSH_PORT=23 \
    -e MAC_ADDRESS="$(xxd -c1 -p -l 6 /dev/urandom | tr '\n' ':' | cut -c1-17)" \
    -e AUDIO_DRIVER=alsa \
    -e IMAGE_PATH=/image \
    -e SCREEN_SHARE_PORT=5900 \
    -e DISPLAY=:0 \
    -e NETWORKING=vmxnet3 \
    --device /dev/kvm \
    --device /dev/snd \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    docker-osx:latest
</code></pre> 
<h3>Generating serial numbers</h3> 
<p>Generate serial numbers in <code>./custom</code> OR make docker generate them at runtime (see below).</p> 
<p>At any time, verify your serial number before logging into iCloud, etc.</p> 
<pre><code class="language-bash"># this is a quick way to check your serial number via cli inside OSX
ioreg -l | grep IOPlatformSerialNumber

# test some commands
sshpass -p 'alpine' ssh user@localhost -p 50922 'ping google.com'

# check your serial number
sshpass -p 'alpine' ssh user@localhost -p 50922 'ioreg -l | grep IOPlatformSerialNumber'
</code></pre> 
<h4>Getting started with serial numbers</h4> 
<pre><code class="language-bash"># ARCH
pacman -S libguestfs

# UBUNTU DEBIAN
apt install libguestfs -y

# RHEL FEDORA CENTOS
yum install libguestfs -y
</code></pre> 
<p>Inside the <code>./custom</code> folder you will find <code>4</code> scripts.</p> 
<ul> 
 <li><code>config-nopicker-custom.plist</code></li> 
 <li><code>opencore-image-ng.sh</code></li> 
</ul> 
<p>These two files are from OSX-KVM.</p> 
<p>You don't need to touch these two files.</p> 
<p>The config.plist has 5 values replaced with placeholders. <a href="https://github.com/sickcodes/Docker-OSX/raw/master/custom/config-nopicker-custom.plist#L705">Click here to see those values for no reason.</a></p> 
<ul> 
 <li><code>generate-unique-machine-values.sh</code> This script will generate serial numbers, with Mac Addresses, plus output to CSV/TSV, plus make a <code>bootdisk image</code>.</li> 
</ul> 
<p>You can create hundreds, <code>./custom/generate-unique-machine-values.sh --help</code></p> 
<pre><code class="language-bash">./custom/generate-unique-machine-values.sh \
    --count 1 \
    --tsv ./serial.tsv \
    --bootdisks \
    --output-bootdisk OpenCore.qcow2 \
    --output-env source.env.sh
</code></pre> 
<p>Or if you have some specific serial numbers...</p> 
<ul> 
 <li><code>generate-specific-bootdisk.sh</code></li> 
</ul> 
<pre><code class="language-bash">generate-specific-bootdisk.sh \
    --model "${DEVICE_MODEL}" \
    --serial "${SERIAL}" \
    --board-serial "${BOARD_SERIAL}" \
    --uuid "${UUID}" \
    --mac-address "${MAC_ADDRESS}" \
    --output-bootdisk OpenCore-nopicker.qcow2
</code></pre> 
<h4>This example generates a random set of serial numbers at runtime, headlessly</h4> 
<pre><code class="language-bash"># proof of concept only, generates random serial numbers, headlessly, and quits right after.
docker run --rm -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -e NOPICKER=true \
    -e GENERATE_UNIQUE=true \
    -e DEVICE_MODEL="iMacPro1,1" \
    sickcodes/docker-osx:auto

# -e OSX_COMMANDS='ioreg -l | grep IOPlatformSerialNumber' \
</code></pre> 
<h4>This example generates a specific set of serial numbers at runtime</h4> 
<pre><code class="language-bash"># run the same as above 17gb auto image, with SSH, with nopicker, and save the bootdisk for later.
# you don't need to save the bootdisk IF you supply specific serial numbers!

docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -e NOPICKER=true \
    -e GENERATE_SPECIFIC=true \
    -e DEVICE_MODEL="iMacPro1,1" \
    -e SERIAL="C02TW0WAHX87" \
    -e BOARD_SERIAL="C027251024NJG36UE" \
    -e UUID="5CCB366D-9118-4C61-A00A-E5BAF3BED451" \
    -e MAC_ADDRESS="A8:5C:2C:9A:46:2F" \
    -e OSX_COMMANDS='ioreg -l | grep IOPlatformSerialNumber' \
    sickcodes/docker-osx:auto
</code></pre> 
<h4>This example generates a specific set of serial numbers at runtime, with your existing image, at 1000x1000 display resolution</h4> 
<pre><code class="language-bash"># run an existing image in current directory, with a screen, with SSH, with nopicker.

stat mac_hdd_ng.img # make sure you have an image if you're using :naked

docker run -it \
    -v "${PWD}/mac_hdd_ng.img:/image" \
    --device /dev/kvm \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -p 50922:10022 \
    -e NOPICKER=true \
    -e GENERATE_SPECIFIC=true \
    -e DEVICE_MODEL="iMacPro1,1" \
    -e SERIAL="C02TW0WAHX87" \
    -e BOARD_SERIAL="C027251024NJG36UE" \
    -e UUID="5CCB366D-9118-4C61-A00A-E5BAF3BED451" \
    -e MAC_ADDRESS="A8:5C:2C:9A:46:2F" \
    -e WIDTH=1000 \
    -e HEIGHT=1000 \
    sickcodes/docker-osx:naked
</code></pre> 
<p>If you want to generate serial numbers, either make them at runtime using <code> -e GENERATE_UNIQUE=true \</code></p> 
<p>Or you can generate them inside the <code>./custom</code> folder. And then use:</p> 
<pre><code class="language-bash">    -e GENERATE_SPECIFIC=true \
    -e SERIAL="" \
    -e BOARD_SERIAL="" \
    -e UUID="" \
    -e MAC_ADDRESS="" \
</code></pre> 
<h4>Making serial numbers persist across reboots</h4> 
<pre><code class="language-bash">
stat mac_hdd_ng_testing.img
touch ./output.env

# generate fresh random serial numbers, with a screen, using your own image, and save env file with your new serial numbers for later.

docker run -it \
    --device /dev/kvm \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -p 50922:10022 \
    -e NOPICKER=true \
    -e GENERATE_UNIQUE=true \
    -e GENERATE_SPECIFIC=true \
    -e DEVICE_MODEL="iMacPro1,1" \
    -v "${PWD}/output.env:/env" \
    -v "${PWD}/mac_hdd_ng_testing.img:/image" \
    sickcodes/docker-osx:naked
</code></pre> 
<p>To use iMessage or iCloud you need to change <code>5</code> values.</p> 
<ul> 
 <li><code>SERIAL</code></li> 
 <li><code>BOARD_SERIAL</code></li> 
 <li><code>UUID</code></li> 
 <li><code>MAC_ADDRESS</code></li> 
</ul> 
<p><em><code>ROM</code> is just the lowercased mac address, without <code>:</code> between each word.</em></p> 
<p>You can tell the container to generate them for you using <code>-e GENERATE_UNIQUE=true</code></p> 
<p>Or tell the container to use specific ones using <code>-e GENERATE_SPECIFIC=true</code></p> 
<pre><code class="language-bash">    -e GENERATE_SPECIFIC=true \
    -e DEVICE_MODEL="iMacPro1,1" \
    -e SERIAL="C02TW0WAHX87" \
    -e BOARD_SERIAL="C027251024NJG36UE" \
    -e UUID="5CCB366D-9118-4C61-A00A-E5BAF3BED451" \
    -e MAC_ADDRESS="A8:5C:2C:9A:46:2F" \
</code></pre> 
<h3>Changing display resolution</h3> 
<p>The display resolution is controlled by this line:</p> 
<p><a href="https://github.com/sickcodes/Docker-OSX/raw/master/custom/config-nopicker-custom.plist#L819">https://github.com/sickcodes/Docker-OSX/blob/master/custom/config-nopicker-custom.plist#L819</a></p> 
<p>Instead of mounting that disk, Docker-OSX will generate a new <code>OpenCore.qcow2</code> by using this one cool trick:</p> 
<pre><code class="language-bash">-e GENERATE_UNIQUE=true \
-e WIDTH=800 \
-e HEIGHT=600 \
</code></pre> 
<p>To use <code>WIDTH</code>/<code>HEIGHT</code>, you must use with either <code>-e GENERATE_UNIQUE=true</code> or <code>-e GENERATE_SPECIFIC=true</code>.</p> 
<p>It will take around 30 seconds longer to boot because it needs to make a new boot partition using <code>libguestfs</code>.</p> 
<pre><code class="language-bash">-e GENERATE_SPECIFIC=true \
-e WIDTH=1920 \
-e HEIGHT=1080 \
-e SERIAL="" \
-e BOARD_SERIAL="" \
-e UUID="" \
-e MAC_ADDRESS="" \
</code></pre> 
<h4>Change Docker-OSX Resolution Examples</h4> 
<pre><code class="language-bash"># using an image in your current directory
stat mac_hdd_ng.img

docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v "${PWD}/mac_hdd_ng.img:/image" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_SPECIFIC=true \
    -e DEVICE_MODEL="iMacPro1,1" \
    -e SERIAL="C02TW0WAHX87" \
    -e BOARD_SERIAL="C027251024NJG36UE" \
    -e UUID="5CCB366D-9118-4C61-A00A-E5BAF3BED451" \
    -e MAC_ADDRESS="A8:5C:2C:9A:46:2F" \
    -e MASTER_PLIST_URL=https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/custom/config-nopicker-custom.plist \
    -e WIDTH=1600 \
    -e HEIGHT=900 \
    sickcodes/docker-osx:naked
</code></pre> 
<pre><code class="language-bash"># generating random serial numbers, using the DIY installer, along with the screen resolution changes.
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e GENERATE_UNIQUE=true \
    -e WIDTH=800 \
    -e HEIGHT=600 \
    sickcodes/docker-osx:latest
</code></pre> 
<p>Here's a few other resolutions! If your resolution is invalid, it will default to 800x600.</p> 
<pre><code>    -e WIDTH=800 \
    -e HEIGHT=600 \
</code></pre> 
<pre><code>    -e WIDTH=1280 \
    -e HEIGHT=768 \
</code></pre> 
<pre><code>    -e WIDTH=1600 \
    -e HEIGHT=900 \
</code></pre> 
<pre><code>    -e WIDTH=1920 \
    -e HEIGHT=1080 \
</code></pre> 
<pre><code>    -e WIDTH=2560 \
    -e HEIGHT=1600 \
</code></pre> 
<h4>This example shows how to change resolution after the container is created.</h4> 
<p>First step is to stop the docker daemon</p> 
<pre><code>sudo systemctl stop docker
</code></pre> 
<p>The second step is to change container config in</p> 
<pre><code>/var/lib/docker/containers/[container-id]/config.v2.json
</code></pre> 
<p>(Suppose your original WIDTH is 1024 and HEIGHT is 768, you can search 1024 and replace it with the new value. Same for 768.)</p> 
<p>The last step is to restart the docker daemon</p> 
<pre><code>sudo systemctl restart docker
</code></pre> 
<h3>Mounting physical disks in Mac OSX</h3> 
<p>Pass the disk into the container as a volume and then pass the disk again into QEMU command line extras with.</p> 
<p>Use the <code>config-custom.plist</code> because you probably want to see the boot menu, otherwise omit the first line:</p> 
<pre><code class="language-bash">DISK_TWO="${PWD}/mount_me.img"
</code></pre> 
<pre><code class="language-dockerfile">-e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist' \
-v "${DISK_TWO}:/disktwo" \
-e EXTRA='-device ide-hd,bus=sata.5,drive=DISK-TWO -drive id=DISK-TWO,if=none,file=/disktwo,format=qcow2' \
</code></pre> 
<h4>Physical disk mounting example</h4> 
<pre><code class="language-bash">OSX_IMAGE="${PWD}/mac_hdd_ng_xcode_bigsur.img"
DISK_TWO="${PWD}/mount_me.img"

docker run -it \
    --device /dev/kvm \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist' \
    -v "${OSX_IMAGE}":/image \
    -v "${DISK_TWO}":/disktwo \
    -e EXTRA='-device ide-hd,bus=sata.5,drive=DISK-TWO -drive id=DISK-TWO,if=none,file=/disktwo,format=qcow2' \
    sickcodes/docker-osx:naked
</code></pre> 
<p>See also: <a href="https://github.com/sickcodes/Docker-OSX/issues/222">here</a>.</p> 
<h4>Extracting the APFS disk on Linux</h4> 
<p>In Docker-OSX, we are using <code>qcow2</code> images.</p> 
<p>This means the image grows as you use it, but the guest OS thinks you have 200GB available.</p> 
<p><strong>READ ONLY</strong></p> 
<pre><code class="language-bash"># mount the qemu image like a real disk
sudo modprobe nbd max_part=8
sudo qemu-nbd --connect=/dev/nbd0 ./image.img
sudo fdisk /dev/nbd0 -l

mkdir -p ./mnt
sudo mount /dev/nbd0p1 ./mnt

# inspect partitions (2 partitions)
sudo fdisk /dev/nbd0 -l

# mount using apfs-linux-rw OR apfs-fuse
mkdir -p ./part

sudo mount /dev/nbd0p2 ./part
sudo apfs-fuse -o allow_other /dev/nbd0p2 ./part

</code></pre> 
<p>When you are finishing looking at your disk, you can unmount the partition, the disk, and remove the loopback device:</p> 
<pre><code class="language-bash">sudo umount ./part
sudo umount ./mnt
sudo qemu-nbd --disconnect /dev/nbd0
sudo rmmod nbd
</code></pre> 
<h3>USB Passthrough</h3> 
<p>Firstly, QEMU must be started as root.</p> 
<p>It is also potentially possible to accomplish USB passthrough by changing the permissions of the device in the container. See <a href="https://www.linuxquestions.org/questions/slackware-14/qemu-usb-permissions-744557/#post3628691">here</a>.</p> 
<p>For example, create a new Dockerfile with the following</p> 
<pre><code class="language-bash">FROM sickcodes/docker-osx
USER arch
RUN sed -i -e s/exec\ qemu/exec\ sudo\ qemu/ ./Launch.sh
COPY --chown=arch ./new_image.img /home/arch/OSX-KVM/mac_hdd_ng.img
</code></pre> 
<p>Where <code>new_image.img</code> is the qcow2 image you extracted. Then rebuild with <code>docker build .</code></p> 
<p>Next we need to find out the bus and port numbers of the USB device we want to pass through to the VM:</p> 
<pre><code class="language-bash">lsusb -t
/:  Bus 02.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/6p, 5000M
/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/12p, 480M
    |__ Port 2: Dev 5, If 0, Class=Human Interface Device, Driver=usbhid, 12M
    |__ Port 2: Dev 5, If 1, Class=Chip/SmartCard, Driver=, 12M
    |__ Port 3: Dev 2, If 0, Class=Wireless, Driver=, 12M
    |__ Port 3: Dev 2, If 1, Class=Wireless, Driver=, 12M
    |__ Port 5: Dev 3, If 0, Class=Video, Driver=uvcvideo, 480M
    |__ Port 5: Dev 3, If 1, Class=Video, Driver=uvcvideo, 480M
</code></pre> 
<p>In this example, we want to pass through a smartcard device. The device we want is on bus 1 and port 2.</p> 
<p>There may also be differences if your device is usb 2.0 (ehci) vs usb 3.0 (xhci). See <a href="https://unix.stackexchange.com/a/452946/101044">here</a> for more details.</p> 
<pre><code class="language-bash"># hostbus and hostport correspond to the numbers from lsusb
# runs in privileged mode to enable access to the usb devices.
docker run \
  --privileged \
  --device /dev/kvm \
  -e RAM=4 \
  -p 50922:10022 \
  -e "DISPLAY=${DISPLAY:-:0.0}" \
  -e EXTRA="-device virtio-serial-pci -device usb-host,hostbus=1,hostport=2" \
  mycustomimage
</code></pre> 
<p>You should see the device show up when you do <code>system_profiler SPUSBDataType</code> in the MacOS shell.</p> 
<p>Important Note: this will cause the host system to lose access to the USB device while the VM is running!</p> 
<h2>Container creation examples</h2> 
<h4>Quick Start your own image (naked container image)</h4> 
<p>This is my favourite container. You can supply an existing disk image as a Docker command line argument.</p> 
<ul> 
 <li> <p>Pull images out using <code>sudo find /var/lib/docker -name mac_hdd_ng.img -size +10G</code></p> </li> 
 <li> <p>Supply your own local image with the command argument <code>-v "${PWD}/mac_hdd_ng.img:/image"</code> and use <code>sickcodes/docker-osx:naked</code> when instructing Docker to create your container.</p> 
  <ul> 
   <li> <p>Naked image is for booting any existing .img file, e.g in the current working directory (<code>$PWD</code>)</p> </li> 
   <li> <p>By default, this image has a variable called <code>NOPICKER</code> which is <code>"true"</code>. This skips the disk selection menu. Use <code>-e NOPICKER=false</code> or any other string than the word <code>true</code> to enter the boot menu.</p> <p>This lets you use other disks instead of skipping the boot menu, e.g. recovery disk or disk utility.</p> </li> 
  </ul> </li> 
</ul> 
<pre><code class="language-bash">docker pull sickcodes/docker-osx:naked

# run your own image + SSH
# change mac_hdd_ng.img
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v "${PWD}/mac_hdd_ng.img:/image" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:naked

# run local copy of the auto image + SSH + Boot menu
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v "${PWD}/mac_hdd_ng_auto.img:/image" \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e "NOPICKER=false" \
    sickcodes/docker-osx:naked
</code></pre> 
<h3>Building an OSX container with video output</h3> 
<p>The Quick Start command should work out of the box, provided that you keep the following lines. Works in <code>auto</code> &amp; <code>naked</code> machines:</p> 
<pre><code>    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
</code></pre> 
<h4>Prebuilt image with arbitrary command line arguments</h4> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/auto?label=sickcodes%2Fdocker-osx%3Aauto" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/auto?label=sickcodes%2Fdocker-osx%3Aauto" /></a></p> 
<p><code>-e OSX_COMMANDS</code> lets you run any commands inside the container</p> 
<pre><code class="language-bash">docker pull sickcodes/docker-osx:auto

# boot to OS X shell + display + specify commands to run inside OS X!
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e "OSX_COMMANDS=/bin/bash -c \"put your commands here\"" \
    sickcodes/docker-osx:auto

# Boots in a minute or two!
</code></pre> 
<p>OR if you have an image already and just want to log in and execute arbitrary commands:</p> 
<pre><code class="language-bash">docker pull sickcodes/docker-osx:naked-auto

# boot to OS X shell + display + specify commands to run inside OS X!
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e USERNAME=yourusername \
    -e PASSWORD=yourpassword \
    -e "OSX_COMMANDS=/bin/bash -c \"put your commands here\"" \
    sickcodes/docker-osx:naked-auto

# Boots in a minute or two!

</code></pre> 
<h3>Further examples</h3> 
<p>There's a myriad of other potential use cases that can work perfectly with Docker-OSX, some of which you'll see below!</p> 
<h3>Building a headless OSX container</h3> 
<p>For a headless container, <strong>remove</strong> the following two lines from your <code>docker run</code> command:</p> 
<pre><code>    # -v /tmp/.X11-unix:/tmp/.X11-unix \
    # -e "DISPLAY=${DISPLAY:-:0.0}" \
</code></pre> 
<h4>Building a headless container from a custom image</h4> 
<p><a href="https://hub.docker.com/r/sickcodes/docker-osx/tags?page=1&amp;ordering=last_updated"><img alt="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked?label=sickcodes%2Fdocker-osx%3Anaked" src="https://img.shields.io/docker/image-size/sickcodes/docker-osx/naked?label=sickcodes%2Fdocker-osx%3Anaked" /></a></p> 
<p>This is particularly helpful for CI/CD pipelines.</p> 
<pre><code class="language-bash"># run your own image headless + SSH
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    -v "${PWD}/mac_hdd_ng.img:/image" \
    sickcodes/docker-osx:naked
</code></pre> 
<h3>Building a headless container that allows insecure VNC on localhost (!for local use only!)</h3> 
<p><strong>Must change -it to -i to be able to interact with the QEMU console</strong></p> 
<p><strong>To exit a container using -i you must <code>docker kill &lt;containerid&gt;</code>. For example, to kill everything, <code>docker ps | xargs docker kill</code>.</strong></p> 
<p>Native QEMU VNC example</p> 
<pre><code class="language-bash">docker run -i \
    --device /dev/kvm \
    -p 50922:10022 \
    -p 5999:5999 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e EXTRA="-display none -vnc 0.0.0.0:99,password=on" \
    sickcodes/docker-osx:big-sur

# type `change vnc password myvncusername` into the docker terminal and set a password
# connect to localhost:5999 using VNC
# qemu 6 seems to require a username for vnc now
</code></pre> 
<p><strong>NOT TLS/HTTPS Encrypted at all!</strong></p> 
<p>Or <code>ssh -N root@1.1.1.1 -L 5999:127.0.0.1:5999</code>, where <code>1.1.1.1</code> is your remote server IP.</p> 
<p>(Note: if you close port 5999 and use the SSH tunnel, this becomes secure.)</p> 
<h3>Building a headless container to run remotely with secure VNC</h3> 
<p>Add the following line:</p> 
<p><code>-e EXTRA="-display none -vnc 0.0.0.0:99,password=on"</code></p> 
<p>In the Docker terminal, press <code>enter</code> until you see <code>(qemu)</code>.</p> 
<p>Type <code>change vnc password someusername</code></p> 
<p>Enter a password for your new vnc username^.</p> 
<p>You also need the container IP: <code>docker inspect &lt;containerid&gt; | jq -r '.[0].NetworkSettings.IPAddress'</code></p> 
<p>Or <code>ip n</code> will usually show the container IP first.</p> 
<p>Now VNC connects using the Docker container IP, for example <code>172.17.0.2:5999</code></p> 
<p>Remote VNC over SSH: <code>ssh -N root@1.1.1.1 -L 5999:172.17.0.2:5999</code>, where <code>1.1.1.1</code> is your remote server IP and <code>172.17.0.2</code> is your LAN container IP.</p> 
<p>Now you can direct connect VNC to any container built with this command!</p> 
<h3>I'd like to use SPICE instead of VNC</h3> 
<p>Optionally, you can enable the SPICE protocol, which allows use of <code>remote-viewer</code> to access your OSX container rather than VNC.</p> 
<p>Note: <code>-disable-ticketing</code> will allow unauthenticated access to the VM. See the <a href="https://www.spice-space.org/spice-user-manual.html">spice manual</a> for help setting up authenticated access ("Ticketing").</p> 
<pre><code class="language-bash">  docker run \
    --device /dev/kvm \
    -p 3001:3001 \
    -p 50922:10022 \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    -e EXTRA="-monitor telnet::45454,server,nowait -nographic -serial null -spice disable-ticketing,port=3001" \
    mycustomimage
</code></pre> 
<p>Then simply do <code>remote-viewer spice://localhost:3001</code> and add <code>--spice-debug</code> for debugging.</p> 
<h4>Creating images based on an already configured and set up container</h4> 
<pre><code class="language-bash"># You can create an image of an already configured and setup container.
# This allows you to effectively duplicate a system.
# To do this, run the following commands

# make note of your container id
docker ps --all
docker commit containerid newImageName

# To run this image do the following
docker run \
    --device /dev/kvm \
    --device /dev/snd \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    newImageName
</code></pre> 
<pre><code class="language-bash">docker pull sickcodes/docker-osx:auto

# boot directly into a real OS X shell with no display (Xvfb) [HEADLESS]
docker run -it \
    --device /dev/kvm \
    -p 50922:10022 \
    sickcodes/docker-osx:auto

# username is user
# passsword is alpine
# Wait 2-3 minutes until you drop into the shell.
</code></pre> 
<h4>Run the original version of Docker-OSX</h4> 
<pre><code class="language-bash">
docker pull sickcodes/docker-osx:latest

docker run -it \
    --device /dev/kvm \
    --device /dev/snd \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:latest

# press CTRL + G if your mouse gets stuck
# scroll down to troubleshooting if you have problems
# need more RAM and SSH on localhost -p 50922?
</code></pre> 
<h4>Run but enable SSH in OS X (Original Version)!</h4> 
<pre><code class="language-bash">docker run -it \
    --device /dev/kvm \
    --device /dev/snd \
    -p 50922:10022 \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e "DISPLAY=${DISPLAY:-:0.0}" \
    sickcodes/docker-osx:latest

# turn on SSH after you've installed OS X in the "Sharing" settings.
ssh user@localhost -p 50922
</code></pre> 
<h4>Autoboot into OS X after you've installed everything</h4> 
<p>Add the extra option <code>-e NOPICKER=true</code>.</p> 
<p>Old machines:</p> 
<pre><code class="language-bash"># find your containerID
docker ps

# move the no picker script on top of the Launch script
# NEW CONTAINERS
docker exec containerID mv ./Launch-nopicker.sh ./Launch.sh

# VNC-VERSION-CONTAINER
docker exec containerID mv ./Launch-nopicker.sh ./Launch_custom.sh

# LEGACY CONTAINERS
docker exec containerID bash -c "grep -v InstallMedia ./Launch.sh &gt; ./Launch-nopicker.sh
chmod +x ./Launch-nopicker.sh
sed -i -e s/OpenCore\.qcow2/OpenCore\-nopicker\.qcow2/ ./Launch-nopicker.sh
"
</code></pre> 
<h3>The big-sur image starts slowly after installation. Is this expected?</h3> 
<p>Automatic updates are still on in the container's settings. You may wish to turn them off. <a href="https://github.com/sickcodes/Docker-OSX/issues/227">We have future plans for development around this.</a></p> 
<h3>What is <code>${DISPLAY:-:0.0}</code>?</h3> 
<p><code>$DISPLAY</code> is the shell variable that refers to your X11 display server.</p> 
<p><code>${DISPLAY}</code> is the same, but allows you to join variables like this:</p> 
<ul> 
 <li>e.g. <code>${DISPLAY}_${DISPLAY}</code> would print <code>:0.0_:0.0</code></li> 
 <li>e.g. <code>$DISPLAY_$DISPLAY</code> would print <code>:0.0</code></li> 
</ul> 
<p>...because <code>$DISPLAY_</code> is not <code>$DISPLAY</code></p> 
<p><code>${variable:-fallback}</code> allows you to set a "fallback" variable to be substituted if <code>$variable</code> is not set.</p> 
<p>You can also use <code>${variable:=fallback}</code> to set that variable (in your current terminal).</p> 
<p>In Docker-OSX, we assume, <code>:0.0</code> is your default <code>$DISPLAY</code> variable.</p> 
<p>You can see what yours is</p> 
<pre><code class="language-bash">echo $DISPLAY
</code></pre> 
<p>That way, <code>${DISPLAY:-:0.0}</code> will use whatever variable your X11 server has set for you, else <code>:0.0</code></p> 
<h3>What is <code>-v /tmp/.X11-unix:/tmp/.X11-unix</code>?</h3> 
<p><code>-v</code> is a Docker command-line option that lets you pass a volume to the container.</p> 
<p>The directory that we are letting the Docker container use is a X server display socket.</p> 
<p><code>/tmp/.X11-unix</code></p> 
<p>If we let the Docker container use the same display socket as our own environment, then any applications you run inside the Docker container will show up on your screen too! <a href="https://www.x.org/archive/X11R6.8.0/doc/RELNOTES5.html">https://www.x.org/archive/X11R6.8.0/doc/RELNOTES5.html</a></p> 
<h3>ALSA errors on startup or container creation</h3> 
<p>You may when initialising or booting into a container see errors from the <code>(qemu)</code> console of the following form: <code>ALSA lib blahblahblah: (function name) returned error: no such file or directory</code>. These are more or less expected. As long as you are able to boot into the container and everything is working, no reason to worry about these.</p> 
<p>See also: <a href="https://github.com/sickcodes/Docker-OSX/issues/174">here</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>mendableai/firecrawl</title>
<link>https://github.com/mendableai/firecrawl</link>
<guid>https://github.com/mendableai/firecrawl</guid>
<content:encoded><![CDATA[
<div> 关键词：Firecrawl、API服务、数据爬取、数据转换、自托管

总结：

Firecrawl是一个API服务，专门用于从URL中爬取并转换网站数据为易于LLM处理的Markdown或结构化数据。它能自动抓取网站上的所有可访问子页面，无需提供sitemap。用户可以通过其官方文档和演示页面来使用此服务，或者选择自托管后端。

关键功能包括：
1. **爬取与转换**：通过提交URL请求，Firecrawl会爬取指定网站及其所有可访问子页面，并将获取的数据转换为Markdown或HTML格式。
2. **状态检查**：提供API接口供用户检查爬取任务的状态以及获取结果数据。
3. **内容提取**：除了基本的转换外，还支持从页面中提取特定结构化信息，如使用预定义的模式或自定义提示进行数据提取。
4. **自托管选项**：用户可以选择自行部署后端服务，以适应特定的环境需求或隐私要求。
5. **API密钥管理**：为了安全地使用服务，用户需要注册并获取API密钥。

通过上述功能，Firecrawl为开发者和数据挖掘者提供了一种高效、自动化的方式来收集和准备网页数据，以便于后续的自然语言处理（NLP）任务或其他应用。 <div>
<p>🔥 Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.</p><hr /><h3 align="center"> <img height="200" src="https://raw.githubusercontent.com/mendableai/firecrawl/main/img/firecrawl_logo.png" /> </h3> 
<div align="center"> 
 <a href="https://github.com/mendableai/firecrawl/raw/main/LICENSE"> <img alt="License" src="https://img.shields.io/github/license/mendableai/firecrawl" /> </a> 
 <a href="https://pepy.tech/project/firecrawl-py"> <img alt="Downloads" src="https://static.pepy.tech/badge/firecrawl-py" /> </a> 
 <a href="https://GitHub.com/mendableai/firecrawl/graphs/contributors"> <img alt="GitHub Contributors" src="https://img.shields.io/github/contributors/mendableai/firecrawl.svg?sanitize=true" /> </a> 
 <a href="https://github.com/mendableai/firecrawl"> <img alt="Open Source" src="https://badgen.net/badge/Open%20Source%20%3F/Yes%21/blue?icon=github" /> </a> 
</div> 
<div> 
 <p align="center"> <a href="https://twitter.com/firecrawl_dev"> <img alt="Follow on X" src="https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white" /> </a> <a href="https://www.linkedin.com/company/104100957"> <img alt="Follow on LinkedIn" src="https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white" /> </a> <a href="https://discord.com/invite/gSmWdAkdwd"> <img alt="Join our Discord" src="https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white" /> </a> </p> 
</div> 
<h1>🔥 Firecrawl</h1> 
<p>Crawl and convert any website into LLM-ready markdown or structured data. Built by <a href="https://mendable.ai?ref=gfirecrawl">Mendable.ai</a> and the Firecrawl community. Includes powerful scraping, crawling and data extraction capabilities.</p> 
<p><em>This repository is in its early development stages. We are still merging custom modules in the mono repo. It's not completely yet ready for full self-host deployment, but you can already run it locally.</em></p> 
<h2>What is Firecrawl?</h2> 
<p><a href="https://firecrawl.dev?ref=github">Firecrawl</a> is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our <a href="https://docs.firecrawl.dev">documentation</a>.</p> 
<p><em>Pst. hey, you, join our stargazers :)</em></p> 
<a href="https://github.com/mendableai/firecrawl"> <img alt="GitHub stars" src="https://img.shields.io/github/stars/mendableai/firecrawl.svg?style=social&amp;label=Star&amp;maxAge=2592000" /> </a> 
<h2>How to use it?</h2> 
<p>We provide an easy to use API with our hosted version. You can find the playground and documentation <a href="https://firecrawl.dev/playground">here</a>. You can also self host the backend if you'd like.</p> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://firecrawl.dev/playground">API</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/mendableai/firecrawl/tree/main/apps/python-sdk">Python SDK</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://github.com/mendableai/firecrawl/tree/main/apps/js-sdk">Node SDK</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://python.langchain.com/docs/integrations/document_loaders/firecrawl/">Langchain Integration 🦜🔗</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl">Langchain JS Integration 🦜🔗</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader">Llama Index Integration 🦙</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl">Dify Integration</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://docs.langflow.org/">Langflow Integration</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://docs.crewai.com/">Crew.ai Integration</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl">Flowise AI Integration</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://docs.praison.ai/firecrawl/">PraisonAI Integration</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <a href="https://zapier.com/apps/firecrawl/integrations">Zapier Integration</a></li> 
 <li><input disabled="disabled" type="checkbox" /> Want an SDK or Integration? Let us know by opening an issue.</li> 
</ul> 
<p>To run locally, refer to guide <a href="https://github.com/mendableai/firecrawl/raw/main/CONTRIBUTING.md">here</a>.</p> 
<h3>API Key</h3> 
<p>To use the API, you need to sign up on <a href="https://firecrawl.dev">Firecrawl</a> and get an API key.</p> 
<h3>Crawling</h3> 
<p>Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "limit": 100,
      "scrapeOptions": {
        "formats": ["markdown", "html"]
      }
    }'
</code></pre> 
<p>Returns a crawl job id and the url to check the status of the crawl.</p> 
<pre><code class="language-json">{
  "success": true,
  "id": "123-456-789",
  "url": "https://api.firecrawl.dev/v1/crawl/123-456-789"
}
</code></pre> 
<h3>Check Crawl Job</h3> 
<p>Used to check the status of a crawl job and get its result.</p> 
<pre><code class="language-bash">curl -X GET https://api.firecrawl.dev/v1/crawl/123-456-789 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
</code></pre> 
<pre><code class="language-json">{
  "status": "completed",
  "total": 36,
  "creditsUsed": 36,
  "expiresAt": "2024-00-00T00:00:00.000Z",
  "data": [
    {
      "markdown": "[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...",
      "html": "&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" class=\"js-focus-visible lg:[--scroll-mt:9.5rem]\" data-js-focus-visible=\"\"&gt;...",
      "metadata": {
        "title": "Build a 'Chat with website' using Groq Llama 3 | Firecrawl",
        "language": "en",
        "sourceURL": "https://docs.firecrawl.dev/learn/rag-llama3",
        "description": "Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a 'Chat with your website' bot.",
        "ogLocaleAlternate": [],
        "statusCode": 200
      }
    }
  ]
}
</code></pre> 
<h3>Scraping</h3> 
<p>Used to scrape a URL and get its content in the specified formats.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats" : ["markdown", "html"]
    }'
</code></pre> 
<p>Response:</p> 
<pre><code class="language-json">{
  "success": true,
  "data": {
    "markdown": "Launch Week I is here! [See our Day 2 Release 🚀](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[💥 Get 2 months free...",
    "html": "&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" class=\"light\" style=\"color-scheme: light;\"&gt;&lt;body class=\"__variable_36bd41 __variable_d7dc5d font-inter ...",
    "metadata": {
      "title": "Home - Firecrawl",
      "description": "Firecrawl crawls and converts any website into clean markdown.",
      "language": "en",
      "keywords": "Firecrawl,Markdown,Data,Mendable,Langchain",
      "robots": "follow, index",
      "ogTitle": "Firecrawl",
      "ogDescription": "Turn any website into LLM-ready data.",
      "ogUrl": "https://www.firecrawl.dev/",
      "ogImage": "https://www.firecrawl.dev/og.png?123",
      "ogLocaleAlternate": [],
      "ogSiteName": "Firecrawl",
      "sourceURL": "https://firecrawl.dev",
      "statusCode": 200
    }
  }
}
</code></pre> 
<h3>Map (Alpha)</h3> 
<p>Used to map a URL and get urls of the website. This returns most links present on the website.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev"
    }'
</code></pre> 
<p>Response:</p> 
<pre><code class="language-json">{
  "status": "success",
  "links": [
    "https://firecrawl.dev",
    "https://www.firecrawl.dev/pricing",
    "https://www.firecrawl.dev/blog",
    "https://www.firecrawl.dev/playground",
    "https://www.firecrawl.dev/smart-crawl",
  ]
}
</code></pre> 
<h4>Map with search</h4> 
<p>Map with <code>search</code> param allows you to search for specific urls inside a website.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev",
      "search": "docs"
    }'
</code></pre> 
<p>Response will be an ordered list from the most relevant to the least relevant.</p> 
<pre><code class="language-json">{
  "status": "success",
  "links": [
    "https://docs.firecrawl.dev",
    "https://docs.firecrawl.dev/sdks/python",
    "https://docs.firecrawl.dev/learn/rag-llama3",
  ]
}
</code></pre> 
<h3>LLM Extraction (Beta)</h3> 
<p>Used to extract structured data from scraped pages.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://www.mendable.ai/",
      "formats": ["extract"],
      "extract": {
        "schema": {
          "type": "object",
          "properties": {
            "company_mission": {
                      "type": "string"
            },
            "supports_sso": {
                      "type": "boolean"
            },
            "is_open_source": {
                      "type": "boolean"
            },
            "is_in_yc": {
                      "type": "boolean"
            }
          },
          "required": [
            "company_mission",
            "supports_sso",
            "is_open_source",
            "is_in_yc"
          ]
        }
      }
    }'
</code></pre> 
<pre><code class="language-json">{
  "success": true,
  "data": {
    "content": "Raw Content",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "robots": "follow, index",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "ogUrl": "https://mendable.ai/",
      "ogImage": "https://mendable.ai/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://mendable.ai/"
    },
    "llm_extraction": {
      "company_mission": "Train a secure AI on your technical resources that answers customer and employee questions so your team doesn't have to",
      "supports_sso": true,
      "is_open_source": false,
      "is_in_yc": true
    }
  }
}
</code></pre> 
<h3>Extracting without a schema (New)</h3> 
<p>You can now extract without a schema by just passing a <code>prompt</code> to the endpoint. The llm chooses the structure of the data.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "formats": ["extract"],
      "extract": {
        "prompt": "Extract the company mission from the page."
      }
    }'
</code></pre> 
<h3>Search (v0) (Beta)</h3> 
<p>Used to search the web, get the most relevant results, scrape each page and return the markdown.</p> 
<pre><code class="language-bash">curl -X POST https://api.firecrawl.dev/v0/search \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "query": "firecrawl",
      "pageOptions": {
        "fetchPageContent": true // false for a fast serp api
      }
    }'
</code></pre> 
<pre><code class="language-json">{
  "success": true,
  "data": [
    {
      "url": "https://mendable.ai",
      "markdown": "# Markdown Content",
      "provider": "web-scraper",
      "metadata": {
        "title": "Mendable | AI for CX and Sales",
        "description": "AI for CX and Sales",
        "language": null,
        "sourceURL": "https://www.mendable.ai/"
      }
    }
  ]
}
</code></pre> 
<h2>Using Python SDK</h2> 
<h3>Installing Python SDK</h3> 
<pre><code class="language-bash">pip install firecrawl-py
</code></pre> 
<h3>Crawl a website</h3> 
<pre><code class="language-python">from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Scrape a website:
scrape_status = app.scrape_url(
  'https://firecrawl.dev', 
  params={'formats': ['markdown', 'html']}
)
print(scrape_status)

# Crawl a website:
crawl_status = app.crawl_url(
  'https://firecrawl.dev', 
  params={
    'limit': 100, 
    'scrapeOptions': {'formats': ['markdown', 'html']}
  }, 
  wait_until_done=True, 
  poll_interval=30
)
print(crawl_status)
</code></pre> 
<h3>Extracting structured data from a URL</h3> 
<p>With LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:</p> 
<pre><code class="language-python">
from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY", version="v0")

class ArticleSchema(BaseModel):
    title: str
    points: int
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description="Top 5 stories")

data = app.scrape_url('https://news.ycombinator.com', {
    'extractorOptions': {
        'extractionSchema': TopArticlesSchema.model_json_schema(),
        'mode': 'llm-extraction'
    },
    'pageOptions':{
        'onlyMainContent': True
    }
})
print(data["llm_extraction"])
</code></pre> 
<h2>Using the Node SDK</h2> 
<h3>Installation</h3> 
<p>To install the Firecrawl Node SDK, you can use npm:</p> 
<pre><code class="language-bash">npm install @mendable/firecrawl-js
</code></pre> 
<h3>Usage</h3> 
<ol> 
 <li>Get an API key from <a href="https://firecrawl.dev">firecrawl.dev</a></li> 
 <li>Set the API key as an environment variable named <code>FIRECRAWL_API_KEY</code> or pass it as a parameter to the <code>FirecrawlApp</code> class.</li> 
</ol> 
<pre><code class="language-js">import FirecrawlApp, { CrawlParams, CrawlStatusResponse } from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Scrape a website
const scrapeResponse = await app.scrapeUrl('https://firecrawl.dev', {
  formats: ['markdown', 'html'],
});

if (scrapeResponse) {
  console.log(scrapeResponse)
}

// Crawl a website
const crawlResponse = await app.crawlUrl('https://firecrawl.dev', {
  limit: 100,
  scrapeOptions: {
    formats: ['markdown', 'html'],
  }
} as CrawlParams, true, 30) as CrawlStatusResponse;

if (crawlResponse) {
  console.log(crawlResponse)
}
</code></pre> 
<h3>Extracting structured data from a URL</h3> 
<p>With LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how you to use it:</p> 
<pre><code class="language-js">import FirecrawlApp from "@mendable/firecrawl-js";
import { z } from "zod";

const app = new FirecrawlApp({
  apiKey: "fc-YOUR_API_KEY",
  version: "v0"
});

// Define schema to extract contents into
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe("Top 5 stories on Hacker News"),
});

const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
  extractorOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data["llm_extraction"]);
</code></pre> 
<h2>Contributing</h2> 
<p>We love contributions! Please read our <a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/CONTRIBUTING.md">contributing guide</a> before submitting a pull request.</p> 
<p><em>It is the sole responsibility of the end users to respect websites' policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites' robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions.</em></p> 
<h2>License Disclaimer</h2> 
<p>This project is primarily licensed under the GNU Affero General Public License v3.0 (AGPL-3.0), as specified in the LICENSE file in the root directory of this repository. However, certain components of this project are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.</p> 
<p>Please note:</p> 
<ul> 
 <li>The AGPL-3.0 license applies to all parts of the project unless otherwise specified.</li> 
 <li>The SDKs and some UI components are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.</li> 
 <li>When using or contributing to this project, ensure you comply with the appropriate license terms for the specific component you are working with.</li> 
</ul> 
<p>For more details on the licensing of specific components, please refer to the LICENSE files in the respective directories or contact the project maintainers.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>coollabsio/coolify</title>
<link>https://github.com/coollabsio/coolify</link>
<guid>https://github.com/coollabsio/coolify</guid>
<content:encoded><![CDATA[
<div> 关键词：Coolify、自托管、Heroku替代、开源、免费

总结:
Coolify是一个开源的、自托管的平台，作为Heroku、Netlify和Vercel等云服务的替代方案。它允许用户在自己的硬件上管理服务器、应用程序和数据库，只需要通过SSH连接即可操作。这种模式提供了对云服务的自由度，避免了供应商锁定，因为所有应用和数据库配置都保存在本地服务器上，方便用户在停止使用Coolify后继续管理资源。

Coolify的安装过程简单快捷，只需通过命令行运行安装脚本。对于寻求专业支持和高可用性功能的用户，Coolify提供了一个付费的云版本，包括自动通知、更好的技术支持和更少的维护工作。此外，Coolify还接受了来自不同组织和个人的资金赞助，以确保其持续发展为完全免费和开源的项目。

最后，Coolify致力于提供高质量的服务，并获得了行业内的认可。其活跃的社区和不断增长的星标数量体现了项目的价值和受欢迎程度。 <div>
<p>An open-source & self-hostable Heroku / Netlify / Vercel alternative.</p><hr /><p><img alt="Latest Release Version" src="https://img.shields.io/badge/dynamic/json?labelColor=grey&amp;color=6366f1&amp;label=Latest_released_version&amp;url=https%3A%2F%2Fcdn.coollabs.io%2Fcoolify%2Fversions.json&amp;query=coolify.v4.version&amp;style=for-the-badge" /></p> 
<p><a href="https://console.algora.io/org/coollabsio/bounties/new"><img alt="Bounty Issues" src="https://img.shields.io/static/v1?labelColor=grey&amp;color=6366f1&amp;label=Algora&amp;message=%F0%9F%92%8E+Bounty+issues&amp;style=for-the-badge" /></a></p> 
<h1>About the Project</h1> 
<p>Coolify is an open-source &amp; self-hostable alternative to Heroku / Netlify / Vercel / etc.</p> 
<p>It helps you manage your servers, applications, and databases on your own hardware; you only need an SSH connection. You can manage VPS, Bare Metal, Raspberry PIs, and anything else.</p> 
<p>Imagine having the ease of a cloud but with your own servers. That is <strong>Coolify</strong>.</p> 
<p>No vendor lock-in, which means that all the configurations for your applications/databases/etc are saved to your server. So, if you decide to stop using Coolify (oh nooo), you could still manage your running resources. You lose the automations and all the magic. 🪄️</p> 
<p>For more information, take a look at our landing page at <a href="https://coolify.io">coolify.io</a>.</p> 
<h1>Installation</h1> 
<pre><code class="language-bash">curl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash
</code></pre> 
<p>You can find the installation script source <a href="https://raw.githubusercontent.com/coollabsio/coolify/main/scripts/install.sh">here</a>.</p> 
<h1>Support</h1> 
<p>Contact us at <a href="https://coolify.io/docs/contact">coolify.io/docs/contact</a>.</p> 
<h1>Donations</h1> 
<p>To stay completely free and open-source, with no feature behind the paywall and evolve the project, we need your help. If you like Coolify, please consider donating to help us fund the project's future development.</p> 
<p><a href="https://coolify.io/sponsorships">coolify.io/sponsorships</a></p> 
<p>Thank you so much!</p> 
<p>Special thanks to our biggest sponsors!</p> 
<p><a href="https://cccareers.org/" target="_blank"><img alt="cccareers logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/ccc-logo.webp" width="200" /></a> <a href="http://htznr.li/CoolifyXHetzner" target="_blank"><img alt="hetzner logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/hetzner.jpg" width="150" /></a> <a href="https://logto.io/?ref=coolify" target="_blank"><img alt="logto logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/logto.webp" width="150" /></a> <a href="https://bc.direct/?ref=coolify.io" target="_blank"><img alt="bc direct logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/bc.png" width="200" /></a> <a href="https://www.quantcdn.io/?ref=coolify.io" target="_blank"><img alt="quantcdn logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/quant.svg?sanitize=true" width="150" /></a> <a href="https://arcjet.com/?ref=coolify.io" target="_blank"><img alt="arcjet logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/arcjet.svg?sanitize=true" width="200" /></a> <a href="https://supa.guide/?ref=coolify.io" target="_blank"><img alt="supaguide logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/supaguide.png" width="200" /></a> <a href="https://tigrisdata.com/?ref=coolify.io" target="_blank"><img alt="tigris logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/tigris.svg?sanitize=true" width="140" /></a> <a href="https://fractalnetworks.co/?ref=coolify.io" target="_blank"><img alt="fractal logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/fractal.svg?sanitize=true" width="180" /></a> <a href="https://coolify.ad.vin/?ref=coolify.io" target="_blank"><img alt="advin logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/advin.png" width="250" /></a> <a href="https://trieve.ai/?ref=coolify.io" target="_blank"><img alt="trieve logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/trieve_bg.png" width="180" /></a> <a href="https://blacksmith.sh/?ref=coolify.io" target="_blank"><img alt="blacksmith logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/blacksmith.svg?sanitize=true" width="200" /></a> <a href="https://latitude.sh/?ref=coolify.io" target="_blank"><img alt="latitude logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/latitude.svg?sanitize=true" width="200" /></a> <a href="https://brand.dev/?ref=coolify.io" target="_blank"><img alt="branddev logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/branddev.png" width="200" /></a> <a href="https://jobscollider.com/remote-jobs?ref=coolify.io" target="_blank"><img alt="jobscollider logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/jobscollider.svg?sanitize=true" width="200" /></a> <a href="https://hostinger.com?ref=coolify.io" target="_blank"><img alt="hostinger logo" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/hostinger.svg?sanitize=true" width="200" /></a></p> 
<h2>Github Sponsors ($40+)</h2> 
<p><a href="https://serpapi.com/?ref=coolify.io"><img alt="SerpAPI" src="https://github.com/serpapi.png" width="60px" /></a> <a href="https://typebot.io/?ref=coolify.io"><img alt="typebot" src="https://pbs.twimg.com/profile_images/1509194008366657543/9I-C7uWT_400x400.jpg" width="60px" /></a> <a href="https://www.runpod.io/?ref=coolify.io"> 
  <svg version="1.0" viewBox="0 0 200 200" xmlns="http://www.w3.org/2000/svg">
   <g>
    <path d="M74.5 51.1c-25.4 14.9-27 16-29.6 20.2-1.8 3-1.9 5.3-1.9 32.3 0 21.7.3 29.4 1.3 30.6 1.9 2.5 46.7 27.9 48.5 27.6 1.5-.3 1.7-3.1 2-27.7.2-21.9 0-27.8-1.1-29.5-.8-1.2-9.9-6.8-20.2-12.6-10.3-5.8-19.4-11.5-20.2-12.7-1.8-2.6-.9-5.9 1.8-7.4 1.6-.8 6.3 0 21.8 4C87.8 78.7 98 81 99.6 81c4.4 0 49.9-25.9 49.9-28.4 0-1.6-3.4-2.8-24-8.2-13.2-3.5-25.1-6.3-26.5-6.3-1.4.1-12.4 5.9-24.5 13z"></path>
    <path d="m137.2 68.1-3.3 2.1 6.3 3.7c3.5 2 6.3 4.3 6.3 5.1 0 .9-8 6.1-19.4 12.6-10.6 6-20 11.9-20.7 12.9-1.2 1.6-1.4 7.2-1.2 29.4.3 24.8.5 27.6 2 27.9 1.8.3 46.6-25.1 48.6-27.6.9-1.2 1.2-8.8 1.2-30.2s-.3-29-1.2-30.2c-1.6-1.9-12.1-7.8-13.9-7.8-.8 0-2.9 1-4.7 2.1z"></path>
   </g>
  </svg></a> <a href="https://lightspeed.run/?ref=coolify.io"><img alt="Lightspeed.run" src="https://github.com/lightspeedrun.png" width="60px" /></a> <a href="https://www.flint.sh/en/home?ref=coolify.io"> <img alt="FlintCompany" src="https://github.com/Flint-company.png" width="60px" /></a> <a href="https://americancloud.com/?ref=coolify.io"><img alt="American Cloud" src="https://github.com/American-Cloud.png" width="60px" /></a> <a href="https://cryptojobslist.com/?ref=coolify.io"><img alt="CryptoJobsList" src="https://github.com/cryptojobslist.png" width="60px" /></a> <a href="https://codext.link/coolify-io?ref=coolify.io"><img alt="Codext" src="https://raw.githubusercontent.com/coollabsio/coolify/main/other/logos/codext.jpg" width="60px" /></a> <a href="https://x.com/mrsmith9ja?ref=coolify.io"><img alt="Thompson Edolo" src="https://github.com/verygreenboi.png" width="60px" /></a> <a href="https://www.uxwizz.com/?ref=coolify.io"><img alt="UXWizz" src="https://github.com/UXWizz.png" width="60px" /></a> <a href="https://github.com/Flowko"><img alt="Younes Barrad" src="https://barrad.me/_ipx/f_webp&amp;s_300x300/younes.jpg" width="60px" /></a> <a href="https://github.com/automazeio"><img alt="Automaze" src="https://github.com/automazeio.png" width="60px" /></a> <a href="https://github.com/corentinclichy"><img alt="Corentin Clichy" src="https://github.com/corentinclichy.png" width="60px" /></a> <a href="https://github.com/Niki2k1"><img alt="Niklas Lausch" src="https://github.com/Niki2k1.png" width="60px" /></a> <a href="https://github.com/pixelinfinito"><img alt="Pixel Infinito" src="https://github.com/pixelinfinito.png" width="60px" /></a> <a href="https://github.com/whitesidest"><img alt="Tyler Whitesides" src="https://avatars.githubusercontent.com/u/12365916?s=52&amp;v=4" width="60px" /></a> <a href="https://github.com/aniftyco"><img alt="NiftyCo" src="https://github.com/aniftyco.png" width="60px" /></a> <a href="https://github.com/iujlaki"><img alt="Imre Ujlaki" src="https://github.com/iujlaki.png" width="60px" /></a> <a href="https://il.ly"><img alt="Ilias Ism" src="https://github.com/Illyism.png" width="60px" /></a> <a href="https://www.breakcold.com/?utm_source=coolify.io"><img alt="Breakcold" src="https://github.com/breakcold.png" width="60px" /></a> <a href="https://github.com/urtho"><img alt="Paweł Pierścionek" src="https://github.com/urtho.png" width="60px" /></a> <a href="https://github.com/monocursive"><img alt="Michael Mazurczak" src="https://github.com/monocursive.png" width="60px" /></a> <a href="https://formbricks.com/?utm_source=coolify.io"><img alt="Formbricks" src="https://github.com/formbricks.png" width="60px" /></a></p> 
<h2>Organizations</h2> 
<p><a href="https://opencollective.com/coollabsio/organization/0/website"><img src="https://opencollective.com/coollabsio/organization/0/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/1/website"><img src="https://opencollective.com/coollabsio/organization/1/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/2/website"><img src="https://opencollective.com/coollabsio/organization/2/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/3/website"><img src="https://opencollective.com/coollabsio/organization/3/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/4/website"><img src="https://opencollective.com/coollabsio/organization/4/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/5/website"><img src="https://opencollective.com/coollabsio/organization/5/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/6/website"><img src="https://opencollective.com/coollabsio/organization/6/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/7/website"><img src="https://opencollective.com/coollabsio/organization/7/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/8/website"><img src="https://opencollective.com/coollabsio/organization/8/avatar.svg?sanitize=true" /></a> <a href="https://opencollective.com/coollabsio/organization/9/website"><img src="https://opencollective.com/coollabsio/organization/9/avatar.svg?sanitize=true" /></a></p> 
<h2>Individuals</h2> 
<p><a href="https://opencollective.com/coollabsio"><img src="https://opencollective.com/coollabsio/individuals.svg?width=890" /></a></p> 
<h1>Cloud</h1> 
<p>If you do not want to self-host Coolify, there is a paid cloud version available: <a href="https://app.coolify.io">app.coolify.io</a></p> 
<p>For more information &amp; pricing, take a look at our landing page <a href="https://coolify.io">coolify.io</a>.</p> 
<h2>Why should I use the Cloud version?</h2> 
<p>The recommended way to use Coolify is to have one server for Coolify and one (or more) for the resources you are deploying. A server is around 4-5$/month.</p> 
<p>By subscribing to the cloud version, you get the Coolify server for the same price, but with:</p> 
<ul> 
 <li>High-availability</li> 
 <li>Free email notifications</li> 
 <li>Better support</li> 
 <li>Less maintenance for you</li> 
</ul> 
<h1>Recognitions</h1> 
<p> <a href="https://news.ycombinator.com/item?id=26624341"> <img alt="Featured on Hacker News" height="54" src="https://hackernews-badge.vercel.app/api?id=26624341" style="width: 250px; height: 54px;" width="250" /> </a> </p> 
<p><a href="https://www.producthunt.com/posts/coolify?ref=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-coolify" target="_blank"><img alt="Coolify - An open-source &amp; self-hostable Heroku, Netlify alternative | Product Hunt" height="54" src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=338273&amp;theme=light" style="width: 250px; height: 54px;" width="250" /></a></p> 
<p><a href="https://trendshift.io/repositories/634" target="_blank"><img alt="coollabsio%2Fcoolify | Trendshift" height="55" src="https://trendshift.io/api/badge/repositories/634" style="width: 250px; height: 55px;" width="250" /></a></p> 
<h1>Repo Activity</h1> 
<p><img alt="Alt" src="https://repobeats.axiom.co/api/embed/eab1c8066f9c59d0ad37b76c23ebb5ccac4278ae.svg?sanitize=true" title="Repobeats analytics image" /></p> 
<h1>Star History</h1> 
<p><a href="https://star-history.com/#coollabsio/coolify&amp;Date"><img alt="Star History Chart" src="https://api.star-history.com/svg?repos=coollabsio/coolify&amp;type=Date" /></a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>openobserve/openobserve</title>
<link>https://github.com/openobserve/openobserve</link>
<guid>https://github.com/openobserve/openobserve</guid>
<content:encoded><![CDATA[
<div> 关键词：OpenObserve、日志、指标、跟踪、性能监控

总结：
OpenObserve 是一款专为日志、指标、跟踪和 RUM（实时用户监控）设计的云原生可观测性平台，适用于 PB 级数据量。与 Elasticsearch 相比，它提供更简单易用的操作体验，启动速度快，只需 2 分钟即可完成部署。OpenObserve 的界面自成一体，无需额外安装。通过使用 Fluent Bit 推送生产 Kubernetes 集群的日志到 OpenObserve，可实现高达 140 倍的存储成本降低。

OpenObserve 支持全面的数据类型，包括日志、指标和跟踪，并兼容 OpenTelemetry 标准。其功能覆盖性能监控、错误记录和会话重放，配备丰富的图表类型以供数据可视化。平台还具备高级数据处理功能，如红黑化敏感信息、合规性检查等。此外，它提供 SQL 和 Prometheus Query Language (PromQL) 的支持，便于查询日志和跟踪数据。对于安全需求，内置认证系统确保数据安全。安装方式灵活多样，支持 Docker、Docker Compose 等多种部署方式。 <div>
<p>🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces, RUM, Error tracking, Session replay).</p><hr /><p align="center"> <a href="https://openobserve.ai"><img alt="OpenObserve" src="https://openobserve.ai/img/logo/logo_horizontal.svg?sanitize=true" /></a> </p> 
<p align="center"> <em>🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces).</em> </p> 
<p align="center"> <a href="https://github.com/openobserve/openobserve" target="_blank"> <img alt="Last Commit" src="https://img.shields.io/github/last-commit/openobserve/openobserve" /> </a> <a href="https://github.com/openobserve/openobserve/stargazers" target="_blank"> <img alt="GitHub Stars" src="https://img.shields.io/github/stars/openobserve/openobserve" /> </a> <a href="https://github.com/openobserve/openobserve/issues" target="_blank"> <img alt="GitHub Issues" src="https://img.shields.io/github/issues/openobserve/openobserve" /> </a> <a href="https://github.com/openobserve/openobserve/graphs/contributors" target="_blank"> <img alt="Contributors" src="https://img.shields.io/github/contributors/openobserve/openobserve" /> </a> <a href="https://github.com/openobserve/openobserve/releases" target="_blank"> <img alt="GitHub Release" src="https://img.shields.io/github/v/release/openobserve/openobserve" /> </a> </p> 
<p>OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, RUM (Real User Monitoring - Performance, Errors, Session Replay) designed to work at petabyte scale.</p> 
<p>It is straightforward and easy to operate, in contrast to Elasticsearch, which requires understanding and tuning numerous settings. Get OpenObserve up and running in under 2 minutes.</p> 
<p>OpenObserve serves as a seamless replacement for Elasticsearch for users who ingest data using APIs and perform searches. OpenObserve comes with its own user interface, eliminating the need for separate installation.</p> 
<p>You can reduce your log storage costs by ~140x compared to Elasticsearch by using OpenObserve. Below, we present the results from pushing logs from our production Kubernetes cluster to both Elasticsearch and OpenObserve using Fluent Bit.</p> 
<p><img alt="OpenObserve Vs Elasticsearch" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_vs_es.png" /></p> 
<h2>🎥 Introduction Video</h2> 
<p><a href="https://github.com/openobserve/openobserve/assets/4242188/77c71e8c-23f6-4123-b42a-7113b464f7a6">https://github.com/openobserve/openobserve/assets/4242188/77c71e8c-23f6-4123-b42a-7113b464f7a6</a></p> 
<h2>🌟 Features:</h2> 
<ul> 
 <li><strong>Logs, Metrics, Traces</strong>: Comprehensive support for various data types.</li> 
 <li><strong>OpenTelemetry Support</strong>: Full compatibility with OTLP for logs, metrics, and traces.</li> 
 <li><strong>Real User Monitoring (RUM)</strong>: Includes performance tracking, error logging, and session replay.</li> 
 <li><strong>Alerts &amp; Dashboards</strong>: Features over 14 different chart types for comprehensive data visualization.</li> 
 <li><strong>Advanced Ingest and Query Functions</strong>: Aid in enrichment, redaction, log reduction, and compliance, like redacting sensitive data from logs.</li> 
 <li><strong>Advanced Embedded GUI</strong>: Intuitive and user-friendly interface.</li> 
 <li><strong>SQL and PromQL Support</strong>: Query logs and traces with SQL, and metrics with SQL and PromQL.</li> 
 <li><strong>Single Binary Installation</strong>: Easy installation and running, with binaries available for multiple platforms under <a href="https://github.com/openobserve/openobserve/releases">releases</a>.</li> 
 <li><strong>Versatile Storage Options</strong>: Supports local disk, S3, MinIO, GCS, Azure Blob Storage.</li> 
 <li><strong>High Availability and Clustering</strong>: Ensures reliable and scalable performance.</li> 
 <li><strong>Dynamic Schema</strong>: Adapts to your data structure seamlessly.</li> 
 <li><strong>Built-in Authentication</strong>: Secure and ready to use.</li> 
 <li><strong>Ease of Operation</strong>: Designed for simplicity and efficiency.</li> 
 <li><strong>Seamless Upgrades</strong>: Hassle-free updates.</li> 
 <li><strong>Multilingual UI</strong>: Supports 11 languages, including English, Spanish, German, French, Chinese, and more.</li> 
</ul> 
<p>For a full list of features, check the <a href="https://openobserve.ai/docs/#project-status-features-and-roadmap">documentation</a>.</p> 
<h2>⚡️ Quick start</h2> 
<h3>🐳 Docker:</h3> 
<pre><code class="language-bash">docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL="root@example.com" \
      -e ZO_ROOT_USER_PASSWORD="Complexpass#123" \
      public.ecr.aws/zinclabs/openobserve:latest
</code></pre> 
<h3>🐙 Docker Compose:</h3> 
<pre><code class="language-yaml">services:
  openobserve:
    image: public.ecr.aws/zinclabs/openobserve:latest
    restart: unless-stopped
    environment:
      ZO_ROOT_USER_EMAIL: "root@example.com"
      ZO_ROOT_USER_PASSWORD: "Complexpass#123"
    ports:
      - "5080:5080"
    volumes:
      - data:/data
volumes:
  data:
</code></pre> 
<p>For other ways to quickly install OpenObserve or use OpenObserve cloud, check <a href="https://openobserve.ai/docs/quickstart">quickstart documentation</a>.</p> 
<p>For installing OpenObserve in HA mode, check <a href="https://openobserve.ai/docs/ha_deployment/">HA deployment documentation</a>.</p> 
<h2>Enterprise Vs Open source Vs Cloud edition</h2> 
<p>OpenObserve is available in three different editions:</p> 
<table> 
 <thead> 
  <tr> 
   <th>Feature</th> 
   <th>Open Source (Self hosted)</th> 
   <th>Enterprise (Self hosted)</th> 
   <th>Cloud</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>Logs</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Metrics</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Traces</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>RUM</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Alerts</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Dashboards</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Reports</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>VRL functions</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Pipelines</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>High Availability</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Multitenancy (Organizations)</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Dynamic schema and schema evolution</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Advanced multilingual GUI</td> 
   <td>✅</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Single Sign On</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Role Based Access Control (RBAC)</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>✅</td> 
  </tr> 
  <tr> 
   <td>Federated search / Super cluster</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>❌</td> 
  </tr> 
  <tr> 
   <td>Query management</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>❌</td> 
  </tr> 
  <tr> 
   <td>Workload management (QoS)</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>❌</td> 
  </tr> 
  <tr> 
   <td>Audit trail</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>❌</td> 
  </tr> 
  <tr> 
   <td>Ability to influence roadmap</td> 
   <td>❌</td> 
   <td>✅</td> 
   <td>✅ on enterprise plan</td> 
  </tr> 
  <tr> 
   <td>License</td> 
   <td>AGPL</td> 
   <td>Enterprise</td> 
   <td>Cloud</td> 
  </tr> 
  <tr> 
   <td>Support</td> 
   <td>Community</td> 
   <td>Enterprise</td> 
   <td>Cloud</td> 
  </tr> 
  <tr> 
   <td>Cost</td> 
   <td>Free</td> 
   <td>If self hosted, free for up to 200 GB/Day data ingested <br /> Paid thereafter</td> 
   <td>Free 200 GB/Month data ingested <br /> Paid thereafter</td> 
  </tr> 
 </tbody> 
</table> 
<h2>📷 Screenshots</h2> 
<h3>Home</h3> 
<p><img alt="Home" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_home.png" /></p> 
<h3>Logs</h3> 
<p><img alt="Logs" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/logs.png" /></p> 
<h3>Traces (OpenTelemetry)</h3> 
<p>Trace details page <img alt="Traces using OpenTelemetry" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces.png" /></p> 
<p>Golden metrics based on traces <img alt="Traces golden metrics" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces-overall.png" /></p> 
<h3>Visualizations and Dashboards</h3> 
<p><img alt="Dashboard" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard.png" /> <img alt="Dashboard" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard2.png" /> <img alt="Create panel" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/create-panel.png" /> <img alt="Map" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/map.png" /></p> 
<h3>Front end monitoring</h3> 
<p>Performance analytics <img alt="Performance" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/performance.png" /></p> 
<p>Session replay <img alt="Session replay" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/session-replay.png" /></p> 
<p>Error tracking <img alt="Error tracking" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/error-tracking.png" /></p> 
<h3>Alerts</h3> 
<p><img alt="Alerts" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/alerts.png" /></p> 
<h3>Streams</h3> 
<p><img alt="Streams" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/streams.png" /></p> 
<h3>Ingestion</h3> 
<p><img alt="Ingestion" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/ingestion1.png" /></p> 
<p><img alt="Ingestion" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/ingestion2.png" /></p> 
<h3>SBOM</h3> 
<p>Software Bill of Materials for OpenObserve</p> 
<h4>Rust</h4> 
<p>SBOM can be found <a href="https://raw.githubusercontent.com/openobserve/openobserve/main/openobserve.cdx.xml">here</a>. You can analyze it using <a href="https://dependencytrack.org/">dependency track</a>.</p> 
<p>In order to generate the SBOM, you can use the following commands:</p> 
<p>Install cargo-cyclonedx:</p> 
<pre><code class="language-bash">cargo install cargo-cyclonedx
</code></pre> 
<p>Generate the SBOM:</p> 
<pre><code class="language-bash">cargo-cyclonedx cyclonedx
</code></pre> 
<h4>JavaScript</h4> 
<p>SBOM can be found <a href="https://raw.githubusercontent.com/openobserve/openobserve/main/web/sbom.json">here</a>. You can analyze it using <a href="https://dependencytrack.org/">dependency track</a>.</p> 
<p>In order to generate the SBOM, you can use the following commands:</p> 
<p>Install cyclonedx-npm:</p> 
<pre><code class="language-bash">npm install --global @cyclonedx/cyclonedx-npm
</code></pre> 
<p>Generate the SBOM:</p> 
<pre><code class="language-bash">cd web
cyclonedx-npm &gt; sbom.json         
</code></pre> 
<h2>⚖️ License</h2> 
<p>OpenObserve is licensed under the AGPL-3.0 license. For more details, see the <a href="https://github.com/openobserve/openobserve/raw/main/LICENSE">LICENSE</a>.</p> 
<h2>🌍 Community</h2> 
<h3>🔗 Join our Slack Channel</h3> 
<p><a href="https://short.openobserve.ai/community"><img alt="Slack" src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/slack.png" /></a></p> 
<p>Easiest way to get support is to join the <a href="https://short.openobserve.ai/community">Slack channel</a>.</p> 
<h3>📱 Join our WeChat Group</h3> 
<img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/wechat_qr.jpg" width="300" />
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>nocodb/nocodb</title>
<link>https://github.com/nocodb/nocodb</link>
<guid>https://github.com/nocodb/nocodb</guid>
<content:encoded><![CDATA[
<div> 关键词：开源、替代品、NoSQL数据库、GUI界面、API集成

总结:
本文介绍了一款名为NocoDB的开源Airtable替代品，它允许用户将MySQL、PostgreSQL、SQL Server、SQLite和MariaDB等关系型数据库转变为智能表格。NocoDB提供了一个丰富的表格界面，支持基本操作（创建、读取、更新和删除表、列和行）、字段操作（排序、筛选、隐藏/显示列）以及多种视图类型（网格、画廊、表单视图和看板视图）。此外，它还支持角色访问控制、自定义单元格类型、工作流自动化集成、程序化访问（REST API和SDK）以及数据同步功能。NocoDB旨在为每个互联网业务提供一个开放源代码的、强大的无代码数据库接口，以实现更民主的数据访问和创新。

NocoDB通过Docker容器提供了快速试用方法，同时也提供了适用于不同操作系统的二进制文件下载链接。为了便于部署，还提供了Docker Compose配置文件。NocoDB还支持与第三方服务（如Slack、Discord、Mattermost、AWS SES、SMTP、MailerSend等）的集成，以实现流程自动化。对于开发者，NocoDB提供了REST API和SDK，允许通过API进行操作。同时，NocoDB还支持从外部系统同步表结构更改，并记录用户操作日志，以便于审计和管理。为了满足生产环境的需求，NocoDB允许用户指定自己的数据库连接参数，确保数据安全性和灵活性。 <div>
<p>🔥 🔥 🔥 Open Source Airtable Alternative</p><hr /><h1 align="center" style="border-bottom: none;"> 
 <div> 
  <a href="https://www.nocodb.com"> <img src="https://raw.githubusercontent.com/nocodb/nocodb/develop/packages/nc-gui/assets/img/icons/512x512.png" width="80" /> <br /> NocoDB </a> 
 </div> The Open Source Airtable Alternative <br /> </h1> 
<p align="center"> Turns any MySQL, PostgreSQL, SQL Server, SQLite &amp; MariaDB into a smart spreadsheet. </p> 
<div align="center"> 
 <p><a href="http://nodejs.org/download/"><img alt="Node version" src="https://img.shields.io/badge/node-%3E%3D%2018.19.1-brightgreen" /></a> <a href="https://conventionalcommits.org"><img alt="Conventional Commits" src="https://img.shields.io/badge/Conventional%20Commits-1.0.0-green.svg?sanitize=true" /></a></p> 
</div> 
<p align="center"> <a href="http://www.nocodb.com"><b>Website</b></a> • <a href="https://discord.gg/5RgZmkW"><b>Discord</b></a> • <a href="https://community.nocodb.com/"><b>Community</b></a> • <a href="https://twitter.com/nocodb"><b>Twitter</b></a> • <a href="https://www.reddit.com/r/NocoDB/"><b>Reddit</b></a> • <a href="https://docs.nocodb.com/"><b>Documentation</b></a> </p> 
<p><img alt="video avi" src="https://github.com/nocodb/nocodb/assets/86527202/e2fad786-f211-4dcb-9bd3-aaece83a6783" /></p> 
<div align="center"> 
 <p><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/chinese.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263434-75fe793d-42af-49e4-b964-d70920e41655.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/french.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263474-787d71e7-3a87-42a8-92a8-be1d1f55413d.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/german.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263531-fae58600-6616-4b43-95a0-5891019dd35d.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/spanish.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263589-3dbeda9a-0d2e-4bbd-b1fc-691404bb74fb.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/portuguese.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263669-f567196a-d4e8-4143-a80a-93d3be32ba90.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/italian.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263707-ba4e04a4-268a-4626-91b8-048e572fd9f6.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/japanese.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263770-38e3e79d-11d4-472e-ac27-ae0f17cf65c4.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/korean.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263822-28fce9de-915a-44dc-962d-7a61d340e91d.png" /></a> <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/russian.md"><img height="38" src="https://user-images.githubusercontent.com/61551451/135263888-151d4ad1-7084-4943-97c9-56f28cd40b80.png" /></a></p> 
</div> 
<p align="center"><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/README.md"><b>See other languages »</b></a></p> 
<img src="https://static.scarf.sh/a.png?x-pxid=c12a77cc-855e-4602-8a0f-614b2d0da56a" /> 
<h1>Join Our Team</h1> 
<p align=""><a href="http://careers.nocodb.com" target="_blank"><img src="https://user-images.githubusercontent.com/61551451/169663818-45643495-e95b-48e2-be13-01d6a77dc2fd.png" width="250" /></a></p> 
<h1>Join Our Community</h1> 
<a href="https://discord.gg/5RgZmkW" target="_blank"> <img alt="" src="https://discordapp.com/api/guilds/661905455894888490/widget.png?style=banner3" /> </a> 
<p><a href="https://github.com/nocodb/nocodb/stargazers"><img alt="Stargazers repo roster for @nocodb/nocodb" src="http://reporoster.com/stars/nocodb/nocodb" /></a></p> 
<h1>Quick try</h1> 
<h2>Docker</h2> 
<pre><code class="language-bash"># with PostgreSQL
docker run -d --name nocodb-postgres \
-v "$(pwd)"/nocodb:/usr/app/data/ \
-p 8080:8080 \
-e NC_DB="pg://host.docker.internal:5432?u=root&amp;p=password&amp;d=d1" \
-e NC_AUTH_JWT_SECRET="569a1821-0a93-45e8-87ab-eb857f20a010" \
nocodb/nocodb:latest

# with SQLite : mounting volume `/usr/app/data/` is crucial to avoid data loss.
docker run -d --name nocodb \
-v "$(pwd)"/nocodb:/usr/app/data/ \
-p 8080:8080 \
nocodb/nocodb:latest
</code></pre> 
<h2>Binaries</h2> 
<p>🚥 Binaries are intended for ONLY quick trials or testing purposes and are not recommended for production use.</p> 
<table> 
 <thead> 
  <tr> 
   <th>OS</th> 
   <th>Architecture</th> 
   <th>Command</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>macOS</td> 
   <td>arm64</td> 
   <td><code>curl http://get.nocodb.com/macos-arm64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td> 
  </tr> 
  <tr> 
   <td>macOS</td> 
   <td>x64</td> 
   <td><code>curl http://get.nocodb.com/macos-x64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td> 
  </tr> 
  <tr> 
   <td>Linux</td> 
   <td>x64</td> 
   <td><code>curl http://get.nocodb.com/linux-x64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td> 
  </tr> 
  <tr> 
   <td>Linux</td> 
   <td>arm64</td> 
   <td><code>curl http://get.nocodb.com/linux-arm64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td> 
  </tr> 
  <tr> 
   <td>Windows</td> 
   <td>x64</td> 
   <td><code>iwr http://get.nocodb.com/win-x64.exe -o Noco-win-x64.exe &amp;&amp;.\Noco-win-x64.exe</code></td> 
  </tr> 
  <tr> 
   <td>Windows</td> 
   <td>arm64</td> 
   <td><code>iwr http://get.nocodb.com/win-arm64.exe -o Noco-win-arm64.exe &amp;&amp; .\Noco-win-arm64.exe</code></td> 
  </tr> 
 </tbody> 
</table> 
<h2>Docker Compose</h2> 
<p>We provide different docker-compose.yml files under <a href="https://github.com/nocodb/nocodb/tree/master/docker-compose">this directory</a>. Here are some examples.</p> 
<pre><code class="language-bash">git clone https://github.com/nocodb/nocodb
cd nocodb/docker-compose/pg
</code></pre> 
<h1>GUI</h1> 
<p>Access Dashboard using: <a href="http://localhost:8080/dashboard">http://localhost:8080/dashboard</a></p> 
<h1>Screenshots</h1> 
<p><img alt="2" src="https://github.com/nocodb/nocodb/assets/86527202/a127c05e-2121-4af2-a342-128e0e2d0291" /> <img alt="3" src="https://github.com/nocodb/nocodb/assets/86527202/674da952-8a06-4848-a0e8-a7b02d5f5c88" /> <img alt="4" src="https://github.com/nocodb/nocodb/assets/86527202/cbc5152a-9caf-4f77-a8f7-92a9d06d025b" /> <img alt="5" src="https://github.com/nocodb/nocodb/assets/86527202/dc75dfdc-c486-4f5a-a853-2a8f9e6b569a" /></p> 
<p><img alt="5" src="https://user-images.githubusercontent.com/35857179/194844886-a17006e0-979d-493f-83c4-0e72f5a9b716.png" /> <img alt="7" src="https://github.com/nocodb/nocodb/assets/86527202/be64e619-7295-43e2-aa95-cace4462b17f" /> <img alt="8" src="https://github.com/nocodb/nocodb/assets/86527202/4538bf5a-371f-4ec1-a867-8197e5824286" /></p> 
<p><img alt="8" src="https://user-images.githubusercontent.com/35857179/194844893-82d5e21b-ae61-41bd-9990-31ad659bf490.png" /> <img alt="9" src="https://user-images.githubusercontent.com/35857179/194844897-cfd79946-e413-4c97-b16d-eb4d7678bb79.png" /> <img alt="10" src="https://user-images.githubusercontent.com/35857179/194844902-c0122570-0dd5-41cf-a26f-6f8d71fefc99.png" /> <img alt="11" src="https://user-images.githubusercontent.com/35857179/194844903-c1e47f40-e782-4f5d-8dce-6449cc70b181.png" /> <img alt="12" src="https://user-images.githubusercontent.com/35857179/194844907-09277d3e-cbbf-465c-9165-6afc4161e279.png" /></p> 
<h1>Table of Contents</h1> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#quick-try">Quick try</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#docker">Docker</a></li> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#docker-compose">Docker Compose</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#gui">GUI</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#join-our-community">Join Our Community</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#screenshots">Screenshots</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#table-of-contents">Table of Contents</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#features">Features</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#rich-spreadsheet-interface">Rich Spreadsheet Interface</a></li> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#app-store-for-workflow-automations">App Store for Workflow Automations</a></li> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#programmatic-access">Programmatic Access</a></li> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#sync-schema">Sync Schema</a></li> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#audit">Audit</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#production-setup">Production Setup</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#environment-variables">Environment variables</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#development-setup">Development Setup</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#contributing">Contributing</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#why-are-we-building-this">Why are we building this?</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#our-mission">Our Mission</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#license">License</a></li> 
 <li><a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/#contributors">Contributors</a></li> 
</ul> 
<h1>Features</h1> 
<h3>Rich Spreadsheet Interface</h3> 
<ul> 
 <li>⚡ &nbsp;Basic Operations: Create, Read, Update and Delete Tables, Columns, and Rows</li> 
 <li>⚡ &nbsp;Fields Operations: Sort, Filter, Hide / Unhide Columns</li> 
 <li>⚡ &nbsp;Multiple Views Types: Grid (By default), Gallery, Form View and Kanban View</li> 
 <li>⚡ &nbsp;View Permissions Types: Collaborative Views, &amp; Locked Views</li> 
 <li>⚡ &nbsp;Share Bases / Views: either Public or Private (with Password Protected)</li> 
 <li>⚡ &nbsp;Variant Cell Types: ID, LinkToAnotherRecord, Lookup, Rollup, SingleLineText, Attachment, Currency, Formula, etc</li> 
 <li>⚡ &nbsp;Access Control with Roles: Fine-grained Access Control at different levels</li> 
 <li>⚡ &nbsp;and more ...</li> 
</ul> 
<h3>App Store for Workflow Automations</h3> 
<p>We provide different integrations in three main categories. See <a href="https://docs.nocodb.com/account-settings/oss-specific-details/#app-store" target="_blank">App Store</a> for details.</p> 
<ul> 
 <li>⚡ &nbsp;Chat: Slack, Discord, Mattermost, and etc</li> 
 <li>⚡ &nbsp;Email: AWS SES, SMTP, MailerSend, and etc</li> 
 <li>⚡ &nbsp;Storage: AWS S3, Google Cloud Storage, Minio, and etc</li> 
</ul> 
<h3>Programmatic Access</h3> 
<p>We provide the following ways to let users programmatically invoke actions. You can use a token (either JWT or Social Auth) to sign your requests for authorization to NocoDB.</p> 
<ul> 
 <li>⚡ &nbsp;REST APIs</li> 
 <li>⚡ &nbsp;NocoDB SDK</li> 
</ul> 
<h3>Sync Schema</h3> 
<p>We allow you to sync schema changes if you have made changes outside NocoDB GUI. However, it has to be noted then you will have to bring your own schema migrations for moving from one environment to another. See <a href="https://docs.nocodb.com/data-sources/sync-with-data-source" target="_blank">Sync Schema</a> for details.</p> 
<h3>Audit</h3> 
<p>We are keeping all the user operation logs in one place. See <a href="https://docs.nocodb.com/data-sources/actions-on-data-sources/#audit-logs" target="_blank">Audit</a> for details.</p> 
<h1>Production Setup</h1> 
<p>By default, SQLite is used for storing metadata. However, you can specify your database. The connection parameters for this database can be specified in <code>NC_DB</code> environment variable. Moreover, we also provide the below environment variables for configuration.</p> 
<h2>Environment variables</h2> 
<p>Please refer to the <a href="https://docs.nocodb.com/getting-started/self-hosted/environment-variables">Environment variables</a></p> 
<h1>Development Setup</h1> 
<p>Please refer to <a href="https://docs.nocodb.com/engineering/development-setup">Development Setup</a></p> 
<h1>Contributing</h1> 
<p>Please refer to <a href="https://github.com/nocodb/nocodb/raw/master/.github/CONTRIBUTING.md">Contribution Guide</a>.</p> 
<h1>Why are we building this?</h1> 
<p>Most internet businesses equip themselves with either spreadsheet or a database to solve their business needs. Spreadsheets are used by Billion+ humans collaboratively every single day. However, we are way off working at similar speeds on databases which are way more powerful tools when it comes to computing. Attempts to solve this with SaaS offerings have meant horrible access controls, vendor lock-in, data lock-in, abrupt price changes &amp; most importantly a glass ceiling on what's possible in the future.</p> 
<h1>Our Mission</h1> 
<p>Our mission is to provide the most powerful no-code interface for databases that is open source to every single internet business in the world. This would not only democratise access to a powerful computing tool but also bring forth a billion+ people who will have radical tinkering-and-building abilities on the internet.</p> 
<h1>License</h1> 
<p> This project is licensed under <a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/LICENSE">AGPLv3</a>. </p> 
<h1>Contributors</h1> 
<p>Thank you for your contributions! We appreciate all the contributions from the community.</p> 
<a href="https://github.com/nocodb/nocodb/graphs/contributors"> <img src="https://contrib.rocks/image?repo=nocodb/nocodb" /> </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>toeverything/AFFiNE</title>
<link>https://github.com/toeverything/AFFiNE</link>
<guid>https://github.com/toeverything/AFFiNE</guid>
<content:encoded><![CDATA[
<div> 关键词：AFFiNE、Notion、Miro、开源、自托管

总结：
AFFiNE是一款集文档、画布和表格于一体的新型知识库平台，旨在提供一个全面、个性化的工作空间，替代Notion和Miro等现有工具。其核心特性包括：

1. **全能融合**：AFFiNE将文档和白板功能完美融合在一个无边界的画布上，支持多种构建块形式，如富文本、便签、嵌入网页、多视图数据库、链接页面、形状和幻灯片等。

2. **AI助手**：内置AI伴侣，能够生成专业报告、转换大纲为展示文稿、总结文章为思维导图、整理任务计划或直接在提示下绘制和编码应用程序原型。

3. **本地优先与实时协作**：注重数据所有权，允许用户在本地设备上存储数据，同时支持跨平台的实时同步和协作。

4. **自托管与定制化**：用户可以自定义和管理AFFiNE，未来将引入插件市场和社区贡献，允许开发者和用户定制和扩展功能。

5. **开放源代码**：AFFiNE采用开源模式，鼓励社区参与开发、反馈和贡献，支持用户根据需要调整和优化平台。 <div>
<p>There can be more than Notion and Miro. AFFiNE(pronounced [ə‘fain]) is a next-gen knowledge base that brings planning, sorting and creating all together. Privacy first, open-source, customizable and ready to use.</p><hr /><div align="center"> 
 <h1 style="border-bottom: none;"> <b><a href="https://affine.pro">AFFiNE.PRO</a></b><br /> Write, Draw and Plan All at Once <br /> </h1> 
 <a href="https://affine.pro/download"> <img alt="affine logo" src="https://cdn.affine.pro/Github_hero_image1.png" style="width: 100%;" /> </a> 
 <br /> 
 <p align="center"> A privacy-focused, local-first, open-source, and ready-to-use alternative for Notion &amp; Miro. <br /> One hyper-fused platform for wildly creative minds. </p> 
 <br /> 
 <br /> 
 <a href="https://www.producthunt.com/posts/affine-3?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-affine-3" target="_blank"><img alt="AFFiNE - One app for all - Where Notion meets Miro | Product Hunt" height="54" src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=440671&amp;theme=light" style="width: 250px; height: 54px;" width="250" /></a> 
 <br /> 
 <br /> 
 <div align="center"> 
  <a href="https://affine.pro">Home Page</a> | 
  <a href="https://discord.gg/whd5mjYqVw">Discord</a> | 
  <a href="https://app.affine.pro">Live Demo</a> | 
  <a href="https://affine.pro/blog/">Blog</a> | 
  <a href="https://docs.affine.pro/docs/">Documentation</a> 
 </div> 
 <br /> 
 <p><a href="https://github.com/toeverything/AFFiNE/releases/latest"><img alt="Releases" src="https://img.shields.io/github/downloads/toeverything/AFFiNE/total" /></a> <a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/#contributors"><img alt="All Contributors" src="https://img.shields.io/github/contributors/toeverything/AFFiNE" /></a> <a href="https://www.typescriptlang.org/"><img alt="TypeScript-version-icon" src="https://img.shields.io/github/package-json/dependency-version/toeverything/affine/dev/typescript" /></a> <a href="https://www.rust-lang.org/"><img alt="Rust-version-icon" src="https://img.shields.io/badge/Rust-1.79.0-dea584" /></a></p> 
</div> 
<br /> 
<div align="center"> 
 <em>Docs, canvas and tables are hyper-merged with AFFiNE - just like the word affine (əˈfʌɪn | a-fine).</em> 
</div> 
<br /> 
<div align="center"> 
 <img src="https://github.com/toeverything/AFFiNE/assets/79301703/49a426bb-8d2b-4216-891a-fa5993642253" style="width: 100%;" /> 
</div> 
<h2>Getting started &amp; staying tuned with us.</h2> 
<p>Star us, and you will receive all release notifications from GitHub without any delay!</p> 
<img src="https://user-images.githubusercontent.com/79301703/230891830-0110681e-8c7e-483b-b6d9-9e42b291b9ef.gif" style="width: 100%;" /> 
<h2>What is AFFiNE</h2> 
<p>AFFiNE is an open-source, all-in-one workspace and an operating system for all the building blocks that assemble your knowledge base and much more -- wiki, knowledge management, presentation and digital assets. It's a better alternative to Notion and Miro.</p> 
<h2>Features</h2> 
<p><strong>A true canvas for blocks in any form. Docs and whiteboard are now fully merged.</strong></p> 
<ul> 
 <li>Many editor apps claim to be a canvas for productivity, but AFFiNE is one of the very few which allows you to put any building block on an edgeless canvas -- rich text, sticky notes, any embedded web pages, multi-view databases, linked pages, shapes and even slides. We have it all.</li> 
</ul> 
<p><strong>Multimodal AI partner ready to kick in any work</strong></p> 
<ul> 
 <li>Write up professional work report? Turn an outline into expressive and presentable slides? Summary an article into a well-structured mindmap? Sorting your job plan and backlog for tasks? Or... draw and code prototype apps and web pages directly all with one prompt? With you, AFFiNE AI pushes your creativity to the edge of your imagination.</li> 
</ul> 
<p><strong>Local-first &amp; Real-time collaborative</strong></p> 
<ul> 
 <li>We love the idea of local-first that you always own your data on your disk, in spite of the cloud. Furthermore, AFFiNE supports real-time sync and collaborations on web and cross-platform clients.</li> 
</ul> 
<p><strong>Self-host &amp; Shape your own AFFiNE</strong></p> 
<ul> 
 <li>You have the freedom to manage, self-host, fork and build your own AFFiNE. Plugin community and third-party blocks are coming soon. More tractions on <a href="https://blocksuite.io">Blocksuite</a>. Check there to learn how to <a href="https://docs.affine.pro/docs/self-host-affine">self-host AFFiNE</a>.</li> 
</ul> 
<h2>Acknowledgement</h2> 
<p>“We shape our tools and thereafter our tools shape us”. A lot of pioneers have inspired us along the way, e.g.:</p> 
<ul> 
 <li>Quip &amp; Notion with their great concept of “everything is a block”</li> 
 <li>Trello with their Kanban</li> 
 <li>Airtable &amp; Miro with their no-code programmable datasheets</li> 
 <li>Miro &amp; Whimiscal with their edgeless visual whiteboard</li> 
 <li>Remote &amp; Capacities with their object-based tag system</li> 
</ul> 
<p>There is a large overlap of their atomic “building blocks” between these apps. They are not open source, nor do they have a plugin system like Vscode for contributors to customize. We want to have something that contains all the features we love and also goes one step even further.</p> 
<p>Thanks for checking us out, we appreciate your interest and sincerely hope that AFFiNE resonates with you! 🎵 Checking <a href="https://affine.pro/">https://affine.pro/</a> for more details ions.</p> 
<h2>Contributing</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Bug Reports</th> 
   <th>Feature Requests</th> 
   <th>Questions/Discussions</th> 
   <th>AFFiNE Community</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://github.com/toeverything/AFFiNE/issues/new?assignees=&amp;labels=bug%2Cproduct-review&amp;template=BUG-REPORT.yml&amp;title=TITLE">Create a bug report</a></td> 
   <td><a href="https://github.com/toeverything/AFFiNE/issues/new?assignees=&amp;labels=feat%2Cproduct-review&amp;template=FEATURE-REQUEST.yml&amp;title=TITLE">Submit a feature request</a></td> 
   <td><a href="https://github.com/toeverything/AFFiNE/discussions">Check GitHub Discussion</a></td> 
   <td><a href="https://community.affine.pro">Vist the AFFiNE Community</a></td> 
  </tr> 
  <tr> 
   <td>Something isn't working as expected</td> 
   <td>An idea for a new feature, or improvements</td> 
   <td>Discuss and ask questions</td> 
   <td>A place to ask, learn and engage with others</td> 
  </tr> 
 </tbody> 
</table> 
<p>Calling all developers, testers, tech writers and more! Contributions of all types are more than welcome, you can read more in <a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/docs/types-of-contributions.md">docs/types-of-contributions.md</a>. If you are interested in contributing code, read our <a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/docs/CONTRIBUTING.md">docs/CONTRIBUTING.md</a> and feel free to check out our GitHub issues to get stuck in to show us what you’re made of.</p> 
<p><strong>Before you start contributing, please make sure you have read and accepted our <a href="https://github.com/toeverything/affine/edit/canary/.github/CLA.md">Contributor License Agreement</a>. To indicate your agreement, simply edit this file and submit a pull request.</strong></p> 
<p>For <strong>bug reports</strong>, <strong>feature requests</strong> and other <strong>suggestions</strong> you can also <a href="https://github.com/toeverything/AFFiNE/issues/new/choose">create a new issue</a> and choose the most appropriate template for your feedback.</p> 
<p>For <strong>translation</strong> and <strong>language support</strong> you can visit our <a href="https://community.affine.pro/c/i18n-general">i18n General Space</a>.</p> 
<p>Looking for <strong>other ways to contribute</strong> and wondering where to start? Check out the <a href="https://community.affine.pro/c/start-here/affine-ambassador">AFFiNE Ambassador program</a>, we work closely with passionate community members and provide them with a wide range of support and resources.</p> 
<p>If you have questions, you are welcome to contact us. One of the best places to get more info and learn more is in the <a href="https://community.affine.pro">AFFiNE Community</a> where you can engage with other like-minded individuals.</p> 
<h2>Ecosystem</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Name</th> 
   <th></th> 
   <th></th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/packages/frontend/component">@affine/component</a></td> 
   <td>AFFiNE Component Resources</td> 
   <td><img alt="" src="https://img.shields.io/codecov/c/github/toeverything/affine?style=flat-square" /></td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/packages/common/theme">@toeverything/theme</a></td> 
   <td>AFFiNE theme</td> 
   <td><a href="https://www.npmjs.com/package/@toeverything/theme"><img alt="" src="https://img.shields.io/npm/dm/@toeverything/theme?style=flat-square&amp;color=eee" /></a></td> 
  </tr> 
 </tbody> 
</table> 
<h2>Upstreams</h2> 
<p>We would also like to give thanks to open-source projects that make AFFiNE possible:</p> 
<ul> 
 <li><a href="https://github.com/toeverything/BlockSuite">Blocksuite</a> - 💠 BlockSuite is the open-source collaborative editor project behind AFFiNE.</li> 
 <li><a href="https://github.com/toeverything/OctoBase">OctoBase</a> - 🐙 OctoBase is the open-source database behind AFFiNE, local-first, yet collaborative. A light-weight, scalable, data engine written in Rust.</li> 
 <li><a href="https://github.com/yjs/yjs">yjs</a> - Fundamental support of CRDTs for our implementation on state management and data sync.</li> 
 <li><a href="https://github.com/electron/electron">electron</a> - Build cross-platform desktop apps with JavaScript, HTML, and CSS.</li> 
 <li><a href="https://github.com/facebook/react">React</a> - The library for web and native user interfaces.</li> 
 <li><a href="https://github.com/napi-rs/napi-rs">napi-rs</a> - A framework for building compiled Node.js add-ons in Rust via Node-API.</li> 
 <li><a href="https://github.com/pmndrs/jotai">Jotai</a> - Primitive and flexible state management for React.</li> 
 <li><a href="https://github.com/Jack-Works/async-call-rpc">async-call-rpc</a> - A lightweight JSON RPC client &amp; server.</li> 
 <li><a href="https://github.com/vitejs/vite">Vite</a> - Next generation frontend tooling.</li> 
 <li>Other upstream <a href="https://github.com/toeverything/AFFiNE/network/dependencies">dependencies</a>.</li> 
</ul> 
<p>Thanks a lot to the community for providing such powerful and simple libraries, so that we can focus more on the implementation of the product logic, and we hope that in the future our projects will also provide a more easy-to-use knowledge base for everyone.</p> 
<h2>Contributors</h2> 
<p>We would like to express our gratitude to all the individuals who have already contributed to AFFiNE! If you have any AFFiNE-related project, documentation, tool or template, please feel free to contribute it by submitting a pull request to our curated list on GitHub: <a href="https://github.com/toeverything/awesome-affine">awesome-affine</a>.</p> 
<a href="https://github.com/toeverything/affine/graphs/contributors"> <img alt="contributors" src="https://opencollective.com/affine/contributors.svg?width=890&amp;button=false" /> </a> 
<h2>Self-Host</h2> 
<p>Begin with Docker to deploy your own feature-rich, unrestricted version of AFFiNE. Our team is diligently updating to the latest version. For more information on how to self-host AFFiNE, please refer to our <a href="https://docs.affine.pro/docs/self-host-affine">documentation</a>.</p> 
<h2>Hiring</h2> 
<p>Some amazing companies, including AFFiNE, are looking for developers! Are you interested in joining AFFiNE or its partners? Check out our Discord channel for some of the latest jobs available.</p> 
<h2>Feature Request</h2> 
<p>For feature requests, please see <a href="https://community.affine.pro/c/feature-requests/">community.affine.pro</a>.</p> 
<h2>Building</h2> 
<h3>Codespaces</h3> 
<p>From the GitHub repo main page, click the green "Code" button and select "Create codespace on master". This will open a new Codespace with the (supposedly auto-forked AFFiNE repo cloned, built, and ready to go.</p> 
<h3>Local</h3> 
<p>See <a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/docs/BUILDING.md">BUILDING.md</a> for instructions on how to build AFFiNE from source code.</p> 
<h2>Contributing</h2> 
<p>We welcome contributions from everyone. See <a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/docs/contributing/tutorial.md">docs/contributing/tutorial.md</a> for details.</p> 
<h2>Thanks</h2> 
<p><a href="https://www.chromatic.com/"><img alt="Chromatic" height="30" src="https://user-images.githubusercontent.com/321738/84662277-e3db4f80-af1b-11ea-88f5-91d67a5e59f6.png" width="153" /></a></p> 
<p>Thanks to <a href="https://www.chromatic.com/">Chromatic</a> for providing the visual testing platform that helps us review UI changes and catch visual regressions.</p> 
<h2>License</h2> 
<h3>Editions</h3> 
<ul> 
 <li> <p>AFFiNE Community Edition (CE) is the current available version, it's free for self-host under the MIT license.</p> </li> 
 <li> <p>AFFiNE Enterprise Edition (EE) is yet to be published, it will have more advanced features and enterprise-oriented offerings, including but not exclusive to rebranding and SSO, advanced admin and audit, etc., you may refer to <a href="https://affine.pro/pricing">https://affine.pro/pricing</a> for more information</p> </li> 
</ul> 
<p>See <a href="https://raw.githubusercontent.com/toeverything/AFFiNE/canary/LICENSE">LICENSE</a> for details.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Permify/permify</title>
<link>https://github.com/Permify/permify</link>
<guid>https://github.com/Permify/permify</guid>
<content:encoded><![CDATA[
<div> 关键词：Permify、开放源代码、细粒度授权、快速部署、全球一致性

总结：

Permify 是一个基于开源的授权即服务系统，灵感源自 Google 的 Zanzibar 系统，旨在帮助开发者轻松构建和管理细粒度、可扩展且灵活的访问控制策略。它允许在几分钟到数天内实现这一目标，而无需花费数月时间来搭建完整的基础设施。通过 Permify，用户可以集中化并标准化其授权逻辑，创建针对特定资源、层次结构、上下文等的精细权限和策略，为不同的租户设置默认的授权，并随需调整。

Permify 提供了强大的功能，如实时响应访问控制检查，支持 RBAC、ReBAC 和 ABAC 等标准模型，并且能够以毫秒级速度处理大量请求。它提供了易于使用的工具和文档，包括快速入门指南、API 文档、示例和教程，以及本地运行的 Docker 命令，使得部署过程变得简单快捷。此外，Permify 社区活跃，提供技术支持和产品更新信息，鼓励用户参与贡献，包括代码提交、文档改进和功能开发，以及参与解决已知问题以获得奖励。 <div>
<p>An open-source authorization as a service inspired by Google Zanzibar, designed to build and manage fine-grained and scalable authorization systems for any application.</p><hr /><h1 align="center"> <img alt="Permify logo" src="https://raw.githubusercontent.com/Permify/permify/master/assets/permify-logo.svg?sanitize=true" width="336px" /><br /> Permify - Open Source Fine-Grained Authorization </h1> 
<p align="center"> Implement fine-grained, scalable and extensible access controls within minutes to days instead of months. <br /> Inspired by Google’s consistent, global authorization system, <a href="https://permify.co/post/google-zanzibar-in-a-nutshell/" target="_blank">Zanzibar</a> </p> 
<p align="center"> <a href="https://github.com/Permify/permify" target="_blank"><img alt="Permify Go Version" src="https://img.shields.io/github/go-mod/go-version/Permify/permify?style=for-the-badge&amp;logo=go" /></a>&nbsp; <a href="https://goreportcard.com/report/github.com/Permify/permify" target="_blank"><img alt="Permify Go Report Card" src="https://goreportcard.com/badge/github.com/Permify/permify?style=for-the-badge&amp;logo=go" /></a>&nbsp; <a href="https://github.com/Permify/permify" target="_blank"><img alt="Permify Licence" src="https://img.shields.io/github/license/Permify/permify?style=for-the-badge" /></a>&nbsp; <a href="https://discord.gg/n6KfzYxhPp" target="_blank"><img alt="Permify Discord Channel" src="https://img.shields.io/discord/950799928047833088?style=for-the-badge&amp;logo=discord&amp;label=DISCORD" /></a>&nbsp; <a href="https://github.com/Permify/permify/pkgs/container/permify" target="_blank"><img alt="Permify Release" src="https://img.shields.io/github/v/release/permify/permify?include_prereleases&amp;style=for-the-badge" /></a>&nbsp; <a href="https://img.shields.io/github/commit-activity/m/Permify/permify?style=for-the-badge" target="_blank"><img alt="Permify Commit Activity" src="https://img.shields.io/github/commit-activity/m/Permify/permify?style=for-the-badge" /></a>&nbsp; <a href="https://img.shields.io/github/actions/workflow/status/Permify/permify/release.yml?style=for-the-badge" target="_blank"><img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/Permify/permify/release.yml?style=for-the-badge" /></a>&nbsp; <a href="https://scrutinizer-ci.com/g/Permify/permify/?branch=master" target="_blank"><img alt="Scrutinizer code quality (GitHub/Bitbucket)" src="https://img.shields.io/scrutinizer/quality/g/Permify/permify/master?style=for-the-badge" /></a>&nbsp; <a href="https://coveralls.io/github/Permify/permify?branch=master"><img alt="Coveralls" src="https://img.shields.io/coverallsCoverage/github/Permify/permify?style=for-the-badge" /></a> </p> 
<p><img alt="permify-centralized" src="https://github.com/user-attachments/assets/e1c22244-1fa4-4bc3-8b7a-bdfb97610c5f" /></p> 
<h2>What is Permify?</h2> 
<p><a href="https://github.com/Permify/permify">Permify</a> is an open-source authorization service for easily building and managing fine-grained, scalable, and extensible access controls for your applications and services. Inspired by Google’s consistent, global authorization system, <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/41f08f03da59f5518802898f68730e247e23c331.pdf">Google Zanzibar</a></p> 
<p>Our service makes authorization more secure and adaptable to changing needs, allowing you to get it up and running in just a few minutes to a couple of days—no need to spend months building out entire piece of infrastructure.</p> 
<p>It works in run time and can respond to any type of access control checks (can user X view document Y?, which posts can members of team Y edit?, etc.) from any of your apps and services in tens of milliseconds.</p> 
<h3>With Permify, you can:</h3> 
<p>🧪 <strong>Centralize &amp; Standardize Your Authorization</strong>: Abstract your authorization logic from your codebase and application logic to easily reason, test, and debug your authorization. Behave your authorization as a sole entity and move faster with in your core development.</p> 
<p>🔮 <strong>Build Granular Permissions For Any Case You Have:</strong> You can create granular (resource-specific, hierarchical, context aware, etc) permissions and policies using Permify's domain specific language that is compatible with RBAC, ReBAC and ABAC.</p> 
<p>🔐 <strong>Set Authorization For Your Tenants By Default</strong>: Set up isolated authorization logic and custom permissions for your vendors/organizations (tenants) and manage them in a single place.</p> 
<p>🚀 <strong>Scale Your Authorization As You Wish:</strong> Achieve lightning-fast response times down to 10ms for access checks with a proven infrastructure inspired by Google Zanzibar.</p> 
<h2>Getting Started</h2> 
<ul> 
 <li>Follow a guide to model your authorization using <a href="https://docs.permify.co/getting-started/modeling">Permify's Authorization Language</a>.</li> 
 <li>See our <a href="https://play.permify.co/">Playground</a>, build your authorization logic and test it with sample data.</li> 
 <li>Explore overview of <a href="https://docs.permify.co/api-reference">Permify API</a> and learn how to interact with it.</li> 
 <li>See <a href="https://permify.co/post/google-zanzibar-in-a-nutshell">our article</a> to examine <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/41f08f03da59f5518802898f68730e247e23c331.pdf">Google Zanzibar</a> in a nutshell.</li> 
 <li>Explore our <a href="https://github.com/Permify/permify/tree/master/sdk">SDK samples</a> for hands-on examples.</li> 
</ul> 
<h3>QuickStart</h3> 
<p>You can quickly start Permify on your local with running the docker command below:</p> 
<pre><code class="language-shell">docker run -p 3476:3476 -p 3478:3478  ghcr.io/permify/permify
</code></pre> 
<p>This will start Permify with the default configuration options:</p> 
<ul> 
 <li>Port 3476 is used to serve the REST API.</li> 
 <li>Port 3478 is used to serve the GRPC Service.</li> 
 <li>Authorization data stored in memory.</li> 
</ul> 
<p>See <a href="https://docs.permify.co/setting-up">all of the options</a> that you can use to set up and deploy Permify in your servers.</p> 
<h4>Test your connection</h4> 
<p>You can test your connection with creating a GET request,</p> 
<pre><code class="language-shell">localhost:3476/healthz
</code></pre> 
<h2>Community ♥️</h2> 
<p>We would love to hear from you!</p> 
<p>Get the latest product updates, receive immediate assistance from our team members, and feel free to ask any questions about Permify or authorization in a broader context by joining our conversation on Discord!</p> 
<p><a href="https://discord.gg/n6KfzYxhPp" target="_blank"><img alt="Join Our Discord" src="https://img.shields.io/badge/Join%20Our%20Discord!-blueviolet?style=for-the-badge" /></a>&nbsp;</p> 
<h2>Contributing</h2> 
<p>The open source community thrives on contributions, offering an incredible space for learning, inspiration, and creation. Your contributions are immensely valued and appreciated!</p> 
<p>Here are the ways to contribute to Permify:</p> 
<ul> 
 <li><strong>Contribute to codebase:</strong> We're collaboratively working with our community to make Permify the best it can be! You can develop new features, fix existing issues or make third-party integrations/packages.</li> 
 <li><strong>Improve documentation:</strong> Alongside our codebase, documentation one of the most significant part in our open-source journey. We're trying to give the best DX possible to explain ourselves and Permify. And you can help on that with importing resources or adding new ones.</li> 
 <li><strong>Contribute to playground:</strong> Permify playground allows you to visualize and test your authorization logic. You can contribute to our playground by improving its user interface, fixing glitches, or adding new features.</li> 
</ul> 
<h3>Bounties</h3> 
<p><a href="https://console.algora.io/org/permify/bounties?status=open"><img alt="Open Bounties" src="https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fpermify%2Fbounties%3Fstatus%3Dopen&amp;style=for-the-badge" /></a></p> 
<p>We have a list of <a href="https://github.com/Permify/permify/labels/%F0%9F%92%8E%20Bounty">issues</a> where you can contribute and gain bounty award! Bounties will be awarded for fixing issues via accepted Pull Requests (PR).</p> 
<p>Before start please see our <a href="https://github.com/Permify/permify/raw/master/CONTRIBUTING.md">contributing guide</a>.</p> 
<h2>Roadmap</h2> 
<p>You can find Permify's Public Roadmap <a href="https://permify.featurebase.app/roadmap">here</a>!</p> 
<h2>Contributors ♥️</h2> 
<a href="https://github.com/permify/Permify/graphs/contributors"> <img src="https://contrib.rocks/image?repo=permify/Permify&amp;anon=1" /> </a> 
<h2>Communication Channels</h2> 
<p>If you like Permify, please consider giving us a <span>⭐</span></p> 
<p align="left"> <a href="https://discord.gg/n6KfzYxhPp"> <img alt="permify | Discord" height="70px" src="https://user-images.githubusercontent.com/39353278/187209316-3d01a799-c51b-4eaa-8f52-168047078a14.png" width="70px" /> </a> <a href="https://twitter.com/GetPermify"> <img alt="permify | Twitter" height="70px" src="https://user-images.githubusercontent.com/39353278/187209323-23f14261-d406-420d-80eb-1aa707a71043.png" width="70px" /> </a> <a href="https://www.linkedin.com/company/permifyco"> <img alt="permify | Linkedin" height="70px" src="https://user-images.githubusercontent.com/39353278/187209321-03293a24-6f63-4321-b362-b0fc89fdd879.png" width="70px" /> </a> </p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AppFlowy-IO/AppFlowy</title>
<link>https://github.com/AppFlowy-IO/AppFlowy</link>
<guid>https://github.com/AppFlowy-IO/AppFlowy</guid>
<content:encoded><![CDATA[
<div> 关键词：AppFlowy、开源、数据安全、协作工作空间、Notion替代品

总结:
AppFlowy是一款基于AI的开放源代码协作工作空间，旨在为用户提供与Notion类似的功能和体验，但强调用户对数据和自定义的控制权。它提供了一个集项目管理、wiki和团队合作于一体的平台，允许用户在不牺牲数据隐私的情况下实现更多目标。AppFlowy的目标是为个人和企业打造一个既具备Notion功能和设计美感，同时又注重数据安全和跨平台原生体验的工具。通过坚持数据隐私优先、提供可靠原生体验以及促进社区驱动的可扩展性，AppFlowy旨在成为构建个性化协作工具的首选平台。其开源性质鼓励社区参与开发，共同推动复杂工作管理工具的民主化，并为个人和企业提供构建自己理想应用所需的基础组件和服务。 <div>
<p>Bring projects, wikis, and teams together with AI. AppFlowy is an AI collaborative workspace where you achieve more without losing control of your data. The best open source alternative to Notion.</p><hr /><h1 align="center" style="border-bottom: none;"> <b> <a href="https://www.appflowy.io">AppFlowy.IO</a><br /> </b> ⭐️ The Open Source Alternative To Notion ⭐️ <br /> </h1> 
<p align="center"> You are in charge of your data and customizations. </p> 
<p align="center"> <a href="https://discord.gg/9Q2xaN37tV"><img src="https://img.shields.io/badge/AppFlowy.IO-discord-orange" /></a> <a href="https://github.com/AppFlowy-IO/appflowy"><img src="https://img.shields.io/github/stars/AppFlowy-IO/appflowy.svg?style=flat&amp;logo=github&amp;colorB=deeppink&amp;label=stars" /></a> <a href="https://github.com/AppFlowy-IO/appflowy"><img src="https://img.shields.io/github/forks/AppFlowy-IO/appflowy.svg?sanitize=true" /></a> <a href="https://opensource.org/licenses/AGPL-3.0"><img alt="License: AGPL" src="https://img.shields.io/badge/license-AGPL-purple.svg?sanitize=true" /></a> </p> 
<p align="center"> <a href="https://www.appflowy.io"><b>Website</b></a> • <a href="https://discord.gg/9Q2xaN37tV"><b>Discord</b></a> • <a href="https://twitter.com/appflowy"><b>Twitter</b></a> </p> 
<p align="center"><img alt="AppFlowy Docs &amp; Notes &amp; Wikis" src="https://user-images.githubusercontent.com/12026239/236664610-fc209a97-815e-4716-af07-d94a859d1907.png" width="1000px" /></p> 
<p align="center"><img alt="AppFlowy Databases for Tasks and Projects" src="https://user-images.githubusercontent.com/12026239/236664628-5def2450-914a-4b2d-b907-92b7476b9863.png" width="1000px" /></p> 
<p align="center"><img alt="AppFlowy Kanban Board for To-Dos" src="https://user-images.githubusercontent.com/12026239/236664642-22e26c1b-5eae-4635-9aa6-b12ecf1c3c46.png" width="1000px" /></p> 
<p align="center"><img alt="AppFlowy Calendars for Plan and Manage Content" src="https://github.com/AppFlowy-IO/AppFlowy/assets/12026239/6be93d2b-a5c5-48a9-b7cf-c599d5f5140c" width="1000px" /></p> 
<p align="center"><img alt="AppFlowy OpenAI GPT Writers" src="https://user-images.githubusercontent.com/12026239/236664657-dc5291f3-67b0-4a43-a818-640e92735deb.png" width="1000px" /></p> 
<h2>User Installation</h2> 
<ul> 
 <li><a href="https://docs.appflowy.io/docs/appflowy/install-appflowy/installation-methods/mac-windows-linux-packages">Windows/Mac/Linux</a></li> 
 <li><a href="https://docs.appflowy.io/docs/appflowy/install-appflowy/installation-methods/installing-with-docker">Docker</a></li> 
 <li><a href="https://docs.appflowy.io/docs/documentation/appflowy/from-source">Source</a></li> 
</ul> 
<h2>Built With</h2> 
<ul> 
 <li> <p><a href="https://flutter.dev/">Flutter</a></p> </li> 
 <li> <p><a href="https://www.rust-lang.org/">Rust</a></p> </li> 
</ul> 
<h2>Stay Up-to-Date</h2> 
<p align="center"><img alt="AppFlowy Github - how to star the repo" src="https://github.com/AppFlowy-IO/appflowy/raw/main/doc/imgs/howtostar.gif" width="100%" /></p> 
<h2>Getting Started with development</h2> 
<p>Please view the <a href="https://docs.appflowy.io/docs/documentation/appflowy/from-source">documentation</a> for OS specific development instructions</p> 
<h2>Roadmap</h2> 
<ul> 
 <li><a href="https://docs.appflowy.io/docs/appflowy/roadmap">AppFlowy Roadmap ReadMe</a></li> 
 <li><a href="https://github.com/orgs/AppFlowy-IO/projects/5/views/12">AppFlowy Public Roadmap</a></li> 
</ul> 
<p>If you'd like to propose a feature, submit a feature request <a href="https://github.com/AppFlowy-IO/AppFlowy/issues/new?assignees=&amp;labels=&amp;template=feature_request.yaml&amp;title=%5BFR%5D+">here</a> <br /> If you'd like to report a bug, submit a bug report <a href="https://github.com/AppFlowy-IO/AppFlowy/issues/new?assignees=&amp;labels=&amp;template=bug_report.yaml&amp;title=%5BBug%5D+">here</a></p> 
<h2><strong>Releases</strong></h2> 
<p>Please see the <a href="https://www.appflowy.io/whatsnew">changelog</a> for more details about a given release.</p> 
<h2>Contributing</h2> 
<p>Contributions make the open-source community a fantastic place to learn, inspire, and create. Any contributions you make are <strong>greatly appreciated</strong>. Please look at <a href="https://docs.appflowy.io/docs/documentation/software-contributions/contributing-to-appflowy">Contributing to AppFlowy</a> for details.</p> 
<p>If your Pull Request is accepted as it fixes a bug, adds functionality, or makes AppFlowy's codebase significantly easier to use or understand, <strong>Congratulations!</strong> If your administrative and managerial work behind the scenes sustains the community, <strong>Congratulations!</strong> You are now an official contributor to AppFlowy. Get in touch with us (<a href="https://tally.so/r/mKP5z3">link</a>) to receive the very special Contributor T-shirt! Proudly wear your T-shirt and show it to us by tagging <a href="https://twitter.com/appflowy">@appflowy</a> on Twitter.</p> 
<h2>Translations 🌎🗺</h2> 
<p><a href="https://inlang.com/editor/github.com/AppFlowy-IO/AppFlowy?ref=badge"><img alt="translation badge" src="https://inlang.com/badge?url=github.com/AppFlowy-IO/AppFlowy" /></a></p> 
<p>To add translations, you can manually edit the JSON translation files in <code>/frontend/resources/translations</code>, use the <a href="https://inlang.com/editor/github.com/AppFlowy-IO/AppFlowy">inlang online editor</a>, or run <code>npx inlang machine translate</code> to add missing translations.</p> 
<h2>Join the community to build AppFlowy together</h2> 
<a href="https://github.com/AppFlowy-IO/AppFlowy/graphs/contributors"> <img src="https://contrib.rocks/image?repo=AppFlowy-IO/AppFlowy" /> </a> 
<h2>Why Are We Building This?</h2> 
<p>Notion has been our favourite project and knowledge management tool in recent years because of its aesthetic appeal and functionality. Our team uses it daily, and we are on its paid plan. However, as we all know, Notion has its limitations. These include weak data security and poor compatibility with mobile devices. Likewise, alternative collaborative workplace management tools also have their constraints.</p> 
<p>The limitations we encountered using these tools and our past work experience with collaborative productivity tools have led to our firm belief that there is a glass ceiling on what's possible for these tools in the future. This emanates from the fact that these tools will probably struggle to scale horizontally at some point and be forced to prioritize a proportion of customers whose needs differ from the rest. While decision-makers want a workplace OS, it is impossible to come up with a one-size fits all solution in such a fragmented market.</p> 
<p>When a customer's evolving core needs are not satisfied, they either switch to another or build one from the ground up, in-house. Consequently, they either go under another ceiling or buy an expensive ticket to learn a hard lesson. This is a requirement for many resources and expertise, building a reliable and easy-to-use collaborative tool, not to mention the speed and native experience. The same may apply to individual users as well.</p> 
<p>All these restrictions necessitate our mission - to make it possible for anyone to create apps that suit their needs well.</p> 
<ul> 
 <li>To individuals, we would like to offer Notion's functionality, data security, and cross-platform native experience.</li> 
 <li>To enterprises and hackers, AppFlowy is dedicated to offering building blocks and collaboration infra services to enable you to make apps on your own. Moreover, you have 100% control of your data. You can design and modify AppFlowy your way, with a single codebase written in Flutter and Rust supporting multiple platforms armed with long-term maintainability.</li> 
</ul> 
<p>We decided to achieve this mission by upholding the three most fundamental values:</p> 
<ul> 
 <li>Data privacy first</li> 
 <li>Reliable native experience</li> 
 <li>Community-driven extensibility</li> 
</ul> 
<p>We do not claim to outperform Notion in terms of functionality and design, at least for now. Besides, our priority doesn't lie in more functionality at the moment. Instead, we would like to cultivate a community to democratize the knowledge and wheels of making complex workplace management tools while enabling people and businesses to create beautiful things on their own by equipping them with a versatile toolbox of building blocks.</p> 
<h2>License</h2> 
<p>Distributed under the AGPLv3 License. See <a href="https://github.com/AppFlowy-IO/AppFlowy/raw/main/LICENSE"><code>LICENSE.md</code></a> for more information.</p> 
<h2>Acknowledgements</h2> 
<p>Special thanks to these amazing projects which help power AppFlowy.IO:</p> 
<ul> 
 <li><a href="https://github.com/singerdmx/flutter-quill">flutter-quill</a></li> 
 <li><a href="https://github.com/sagiegurari/cargo-make">cargo-make</a></li> 
 <li><a href="https://contrib.rocks">contrib.rocks</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DrKLO/Telegram</title>
<link>https://github.com/DrKLO/Telegram</link>
<guid>https://github.com/DrKLO/Telegram</guid>
<content:encoded><![CDATA[
<div> 关键词：Telegram、Android源代码、应用开发、API、编译指南

总结:

本文详细介绍了如何获取和使用Telegram的Android源代码进行应用开发的过程。开发者首先需要了解并遵守一系列要求，包括应用命名规则、logo使用规范、数据隐私保护、以及代码开源等。为了支持自定义发布，文中提供了一个包含示例配置的编译指南。

为了开始，开发者需要下载Telegram的源代码，将个人的release.keystore文件放置在指定位置，并在gradle.properties中设置相关的安全参数。接下来，创建两个Android应用项目，确保它们拥有正确的应用ID，并启用Firebase消息服务以下载google-services.json文件。

编译前，需要在TMessagesProj/src/main/java/org/telegram/messenger/BuildVars.java文件中填写必要的变量信息，这些信息通常可以从官方文档中获得。最后，通过Android Studio打开项目，即可准备进行编译。

对于本地化需求，所有翻译工作已转移到特定的资源文件中，开发者需遵循官方指南完成相应翻译工作。

整个流程旨在为开发者提供一个清晰的路径，从获取源代码到完成应用编译，同时强调了数据安全和用户隐私的重要性。 <div>
<p>Telegram for Android source</p><hr /><h2>Telegram messenger for Android</h2> 
<p><a href="https://telegram.org">Telegram</a> is a messaging app with a focus on speed and security. It’s superfast, simple and free. This repo contains the official source code for <a href="https://play.google.com/store/apps/details?id=org.telegram.messenger">Telegram App for Android</a>.</p> 
<h2>Creating your Telegram Application</h2> 
<p>We welcome all developers to use our API and source code to create applications on our platform. There are several things we require from <strong>all developers</strong> for the moment.</p> 
<ol> 
 <li><a href="https://core.telegram.org/api/obtaining_api_id"><strong>Obtain your own api_id</strong></a> for your application.</li> 
 <li>Please <strong>do not</strong> use the name Telegram for your app — or make sure your users understand that it is unofficial.</li> 
 <li>Kindly <strong>do not</strong> use our standard logo (white paper plane in a blue circle) as your app's logo.</li> 
 <li>Please study our <a href="https://core.telegram.org/mtproto/security_guidelines"><strong>security guidelines</strong></a> and take good care of your users' data and privacy.</li> 
 <li>Please remember to publish <strong>your</strong> code too in order to comply with the licences.</li> 
</ol> 
<h3>API, Protocol documentation</h3> 
<p>Telegram API manuals: <a href="https://core.telegram.org/api">https://core.telegram.org/api</a></p> 
<p>MTproto protocol manuals: <a href="https://core.telegram.org/mtproto">https://core.telegram.org/mtproto</a></p> 
<h3>Compilation Guide</h3> 
<p><strong>Note</strong>: In order to support <a href="https://core.telegram.org/reproducible-builds">reproducible builds</a>, this repo contains dummy release.keystore, google-services.json and filled variables inside BuildVars.java. Before publishing your own APKs please make sure to replace all these files with your own.</p> 
<p>You will require Android Studio 3.4, Android NDK rev. 20 and Android SDK 8.1</p> 
<ol> 
 <li>Download the Telegram source code from <a href="https://github.com/DrKLO/Telegram">https://github.com/DrKLO/Telegram</a> ( git clone <a href="https://github.com/DrKLO/Telegram.git">https://github.com/DrKLO/Telegram.git</a> )</li> 
 <li>Copy your release.keystore into TMessagesProj/config</li> 
 <li>Fill out RELEASE_KEY_PASSWORD, RELEASE_KEY_ALIAS, RELEASE_STORE_PASSWORD in gradle.properties to access your release.keystore</li> 
 <li>Go to <a href="https://console.firebase.google.com/">https://console.firebase.google.com/</a>, create two android apps with application IDs org.telegram.messenger and org.telegram.messenger.beta, turn on firebase messaging and download google-services.json, which should be copied to the same folder as TMessagesProj.</li> 
 <li>Open the project in the Studio (note that it should be opened, NOT imported).</li> 
 <li>Fill out values in TMessagesProj/src/main/java/org/telegram/messenger/BuildVars.java – there’s a link for each of the variables showing where and which data to obtain.</li> 
 <li>You are ready to compile Telegram.</li> 
</ol> 
<h3>Localization</h3> 
<p>We moved all translations to <a href="https://translations.telegram.org/en/android/">https://translations.telegram.org/en/android/</a>. Please use it.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>anthropics/courses</title>
<link>https://github.com/anthropics/courses</link>
<guid>https://github.com/anthropics/courses</guid>
<content:encoded><![CDATA[
<div> 关键词：Anthropic、教育课程、Claude SDK、提示技术、工具使用

文章总结：

Anthropic提供了四个教育课程，旨在帮助用户全面掌握与Claude SDK的交互。首先，用户需完成"Claude SDK入门"课程，该课程教授了获取API密钥、模型参数使用、多模态提示撰写、流式响应等基本技能。接下来，“全面提示技巧指南”提供了一个逐步教程，深入讲解关键的提示策略。

接着，“复杂场景提示应用”课程则进一步指导用户如何将这些提示技巧融入到复杂的、实际世界的应用场景中。最后，“Claude工作流程中的工具使用”课程则全面覆盖了如何成功地在工作流程中集成工具，以实现高效操作。

通过这四个课程的学习，用户将能够全面掌握从基础到高级的Claude SDK应用技能，包括获取和利用API、编写有效提示、解决实际问题以及自动化工作流程。这不仅有助于提升个人或团队的工作效率，还能加深对AI语言模型的理解和应用。 <div>
<p>Anthropic's educational courses</p><hr /><h1>Anthropic courses</h1> 
<p>Welcome to Anthropic's educational courses. This repository currently contains four courses. We suggest completing the courses in the following order:</p> 
<ol> 
 <li><a href="https://raw.githubusercontent.com/anthropics/courses/master/anthropic_api_fundamentals/README.md">Anthropic API fundamentals course</a> - teaches the essentials of working with the Claude SDK: getting an API key, working with model parameters, writing multimodal prompts, streaming responses, etc.</li> 
 <li><a href="https://raw.githubusercontent.com/anthropics/courses/master/prompt_engineering_interactive_tutorial/README.md">Prompt engineering interactive tutorial</a> - a comprehensive step-by-step guide to key prompting techniques</li> 
</ol> 
<ul> 
 <li><a href="https://github.com/anthropics/courses/tree/vertex/real_world_prompting">Google Vertex version</a></li> 
</ul> 
<ol start="3"> 
 <li><a href="https://raw.githubusercontent.com/anthropics/courses/master/real_world_prompting/README.md">Real world prompting course</a> - learn how to incorporate prompting techniques into complex, real world prompts</li> 
 <li><a href="https://raw.githubusercontent.com/anthropics/courses/master/tool_use/README.md">Tool use course</a> - teaches everything you need to know to implement tool use successfully in your workflows with Claude.</li> 
</ol>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>wazuh/wazuh</title>
<link>https://github.com/wazuh/wazuh</link>
<guid>https://github.com/wazuh/wazuh</guid>
<content:encoded><![CDATA[
<div> 关键词：Wazuh、安全平台、XDR、SIEM、多平台支持

总结:

Wazuh是一个免费开源的安全平台，专为威胁预防、检测和响应而设计。它提供了一种统一的端点到云工作负载的跨域检测与事件响应（XDR）和安全信息与事件管理（SIEM）解决方案，支持从本地、虚拟化、容器化到云环境的各种工作负载。

1. **入侵检测**：通过扫描监控系统以检测恶意软件、后门和可疑异常，Wazuh能够发现隐藏文件、隐蔽进程或未注册的网络监听器，以及系统调用响应不一致的情况。此外，通过服务器组件的签名基方法，结合正则表达式引擎分析收集的日志数据，以识别被破坏的指标。

2. **日志数据分析**：Wazuh的代理程序读取操作系统和应用程序日志，并将这些日志安全地转发至中央管理器进行基于规则的分析和存储。当没有部署代理程序时，服务器还可以接收来自网络设备或应用的syslog数据。Wazuh规则有助于识别应用或系统错误、配置错误、恶意活动尝试或成功、策略违规和其他安全和操作问题。

3. **文件完整性监控**：Wazuh监控文件系统，识别文件内容、权限、所有权和属性的变化，以及用户和应用程序创建或修改文件的情况。结合威胁情报使用，可以帮助识别威胁或受感染的主机。同时，该功能符合PCI DSS等合规标准的要求。

4. **漏洞检测**：Wazuh的代理程序收集软件清单数据并将其发送至服务器，与不断更新的CVE数据库相关联，以识别已知的脆弱软件。自动化漏洞评估帮助识别关键资产中的弱点，并在攻击者利用它们破坏业务或窃取敏感数据之前采取纠正措施。

5. **合规性**：Wazuh提供了实现行业标准和法规所需的一些安全控制。其Web用户界面提供的报告和仪表板有助于满足如PCI DSS、GPG13或GDPR等法规的要求。

Wazuh通过提供全面的监控和响应能力，支持多平台环境的安全性和合规性要求，为组织提供了一个强大的安全防护体系。 <div>
<p>Wazuh - The Open Source Security Platform. Unified XDR and SIEM protection for endpoints and cloud workloads.</p><hr /><h1>Wazuh</h1> 
<p><a href="https://wazuh.com/community/join-us-on-slack/"><img alt="Slack" src="https://img.shields.io/badge/slack-join-blue.svg?sanitize=true" /></a> <a href="https://groups.google.com/forum/#!forum/wazuh"><img alt="Email" src="https://img.shields.io/badge/email-join-blue.svg?sanitize=true" /></a> <a href="https://documentation.wazuh.com"><img alt="Documentation" src="https://img.shields.io/badge/docs-view-green.svg?sanitize=true" /></a> <a href="https://wazuh.com"><img alt="Documentation" src="https://img.shields.io/badge/web-view-green.svg?sanitize=true" /></a> <a href="https://scan.coverity.com/projects/wazuh-wazuh"><img alt="Coverity" src="https://scan.coverity.com/projects/10992/badge.svg?sanitize=true" /></a> <a href="https://twitter.com/wazuh"><img alt="Twitter" src="https://img.shields.io/twitter/follow/wazuh?style=social" /></a> <a href="https://www.youtube.com/watch?v=peTSzcAueEc"><img alt="YouTube" src="https://img.shields.io/youtube/views/peTSzcAueEc?style=social" /></a></p> 
<p>Wazuh is a free and open source platform used for threat prevention, detection, and response. It is capable of protecting workloads across on-premises, virtualized, containerized, and cloud-based environments.</p> 
<p>Wazuh solution consists of an endpoint security agent, deployed to the monitored systems, and a management server, which collects and analyzes data gathered by the agents. Besides, Wazuh has been fully integrated with the Elastic Stack, providing a search engine and data visualization tool that allows users to navigate through their security alerts.</p> 
<h2>Wazuh capabilities</h2> 
<p>A brief presentation of some of the more common use cases of the Wazuh solution.</p> 
<p><strong>Intrusion detection</strong></p> 
<p>Wazuh agents scan the monitored systems looking for malware, rootkits and suspicious anomalies. They can detect hidden files, cloaked processes or unregistered network listeners, as well as inconsistencies in system call responses.</p> 
<p>In addition to agent capabilities, the server component uses a signature-based approach to intrusion detection, using its regular expression engine to analyze collected log data and look for indicators of compromise.</p> 
<p><strong>Log data analysis</strong></p> 
<p>Wazuh agents read operating system and application logs, and securely forward them to a central manager for rule-based analysis and storage. When no agent is deployed, the server can also receive data via syslog from network devices or applications.</p> 
<p>The Wazuh rules help make you aware of application or system errors, misconfigurations, attempted and/or successful malicious activities, policy violations and a variety of other security and operational issues.</p> 
<p><strong>File integrity monitoring</strong></p> 
<p>Wazuh monitors the file system, identifying changes in content, permissions, ownership, and attributes of files that you need to keep an eye on. In addition, it natively identifies users and applications used to create or modify files.</p> 
<p>File integrity monitoring capabilities can be used in combination with threat intelligence to identify threats or compromised hosts. In addition, several regulatory compliance standards, such as PCI DSS, require it.</p> 
<p><strong>Vulnerability detection</strong></p> 
<p>Wazuh agents pull software inventory data and send this information to the server, where it is correlated with continuously updated CVE (Common Vulnerabilities and Exposure) databases, in order to identify well-known vulnerable software.</p> 
<p>Automated vulnerability assessment helps you find the weak spots in your critical assets and take corrective action before attackers exploit them to sabotage your business or steal confidential data.</p> 
<p><strong>Configuration assessment</strong></p> 
<p>Wazuh monitors system and application configuration settings to ensure they are compliant with your security policies, standards and/or hardening guides. Agents perform periodic scans to detect applications that are known to be vulnerable, unpatched, or insecurely configured.</p> 
<p>Additionally, configuration checks can be customized, tailoring them to properly align with your organization. Alerts include recommendations for better configuration, references and mapping with regulatory compliance.</p> 
<p><strong>Incident response</strong></p> 
<p>Wazuh provides out-of-the-box active responses to perform various countermeasures to address active threats, such as blocking access to a system from the threat source when certain criteria are met.</p> 
<p>In addition, Wazuh can be used to remotely run commands or system queries, identifying indicators of compromise (IOCs) and helping perform other live forensics or incident response tasks.</p> 
<p><strong>Regulatory compliance</strong></p> 
<p>Wazuh provides some of the necessary security controls to become compliant with industry standards and regulations. These features, combined with its scalability and multi-platform support help organizations meet technical compliance requirements.</p> 
<p>Wazuh is widely used by payment processing companies and financial institutions to meet PCI DSS (Payment Card Industry Data Security Standard) requirements. Its web user interface provides reports and dashboards that can help with this and other regulations (e.g. GPG13 or GDPR).</p> 
<p><strong>Cloud security</strong></p> 
<p>Wazuh helps monitoring cloud infrastructure at an API level, using integration modules that are able to pull security data from well known cloud providers, such as Amazon AWS, Azure or Google Cloud. In addition, Wazuh provides rules to assess the configuration of your cloud environment, easily spotting weaknesses.</p> 
<p>In addition, Wazuh light-weight and multi-platform agents are commonly used to monitor cloud environments at the instance level.</p> 
<p><strong>Containers security</strong></p> 
<p>Wazuh provides security visibility into your Docker hosts and containers, monitoring their behavior and detecting threats, vulnerabilities and anomalies. The Wazuh agent has native integration with the Docker engine allowing users to monitor images, volumes, network settings, and running containers.</p> 
<p>Wazuh continuously collects and analyzes detailed runtime information. For example, alerting for containers running in privileged mode, vulnerable applications, a shell running in a container, changes to persistent volumes or images, and other possible threats.</p> 
<h2>WUI</h2> 
<p>The Wazuh WUI provides a powerful user interface for data visualization and analysis. This interface can also be used to manage Wazuh configuration and to monitor its status.</p> 
<p><strong>Modules overview</strong></p> 
<p><img alt="Modules overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app.png" /></p> 
<p><strong>Security events</strong></p> 
<p><img alt="Overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app2.png" /></p> 
<p><strong>Integrity monitoring</strong></p> 
<p><img alt="Overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app3.png" /></p> 
<p><strong>Vulnerability detection</strong></p> 
<p><img alt="Overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app4.png" /></p> 
<p><strong>Regulatory compliance</strong></p> 
<p><img alt="Overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app5.png" /></p> 
<p><strong>Agents overview</strong></p> 
<p><img alt="Overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app6.png" /></p> 
<p><strong>Agent summary</strong></p> 
<p><img alt="Overview" src="https://github.com/wazuh/wazuh-dashboard-plugins/raw/master/screenshots/app7.png" /></p> 
<h2>Orchestration</h2> 
<p>Here you can find all the automation tools maintained by the Wazuh team.</p> 
<ul> 
 <li> <p><a href="https://github.com/wazuh/wazuh-cloudformation">Wazuh AWS CloudFormation</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-docker">Docker containers</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-ansible">Wazuh Ansible</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-chef">Wazuh Chef</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-puppet">Wazuh Puppet</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-kubernetes">Wazuh Kubernetes</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-bosh">Wazuh Bosh</a></p> </li> 
 <li> <p><a href="https://github.com/wazuh/wazuh-salt">Wazuh Salt</a></p> </li> 
</ul> 
<h2>Branches</h2> 
<ul> 
 <li><code>master</code> branch contains the latest code, be aware of possible bugs on this branch.</li> 
 <li><code>stable</code> branch on correspond to the last Wazuh stable version.</li> 
</ul> 
<h2>Software and libraries used</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Software</th> 
   <th>Version</th> 
   <th>Author</th> 
   <th>License</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://github.com/libarchive/bzip2">bzip2</a></td> 
   <td>1.0.8</td> 
   <td>Julian Seward</td> 
   <td>BSD License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/DaveGamble/cJSON">cJSON</a></td> 
   <td>1.7.12</td> 
   <td>Dave Gamble</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/python/cpython">cPython</a></td> 
   <td>3.10.13</td> 
   <td>Guido van Rossum</td> 
   <td>Python Software Foundation License version 2</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/curl/curl">cURL</a></td> 
   <td>8.5.0</td> 
   <td>Daniel Stenberg</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/google/flatbuffers/">Flatbuffers</a></td> 
   <td>23.5.26</td> 
   <td>Google Inc.</td> 
   <td>Apache 2.0 License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/google/googletest">GoogleTest</a></td> 
   <td>1.11.0</td> 
   <td>Google Inc.</td> 
   <td>3-Clause "New" BSD License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/jemalloc/jemalloc">jemalloc</a></td> 
   <td>5.2.1</td> 
   <td>Jason Evans</td> 
   <td>2-Clause "Simplified" BSD License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/lua/lua">Lua</a></td> 
   <td>5.3.6</td> 
   <td>PUC-Rio</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/libarchive/libarchive">libarchive</a></td> 
   <td>3.7.2</td> 
   <td>Tim Kientzle</td> 
   <td>3-Clause "New" BSD License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/yasuhirokimura/db18">libdb</a></td> 
   <td>18.1.40</td> 
   <td>Oracle Corporation</td> 
   <td>Affero GPL v3</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/libffi/libffi">libffi</a></td> 
   <td>3.2.1</td> 
   <td>Anthony Green</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/PCRE2Project/pcre2">libpcre2</a></td> 
   <td>10.42.0</td> 
   <td>Philip Hazel</td> 
   <td>BSD License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/libimobiledevice/libplist">libplist</a></td> 
   <td>2.2.0</td> 
   <td>Aaron Burghardt et al.</td> 
   <td>GNU Lesser General Public License version 2.1</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/yaml/libyaml">libYAML</a></td> 
   <td>0.1.7</td> 
   <td>Kirill Simonov</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/tukaani-project/xz">liblzma</a></td> 
   <td>5.4.2</td> 
   <td>Lasse Collin, Jia Tan et al.</td> 
   <td>GNU Public License version 3</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/linux-audit/audit-userspace">Linux Audit userspace</a></td> 
   <td>2.8.4</td> 
   <td>Rik Faith</td> 
   <td>LGPL (copyleft)</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/msgpack/msgpack-c">msgpack</a></td> 
   <td>3.1.1</td> 
   <td>Sadayuki Furuhashi</td> 
   <td>Boost Software License version 1.0</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/nlohmann/json">nlohmann</a></td> 
   <td>3.7.3</td> 
   <td>Niels Lohmann</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/openssl/openssl">OpenSSL</a></td> 
   <td>3.0.12</td> 
   <td>OpenSSL Software Foundation</td> 
   <td>Apache 2.0 License</td> 
  </tr> 
  <tr> 
   <td><a href="https://gitlab.archlinux.org/pacman/pacman">pacman</a></td> 
   <td>5.2.2</td> 
   <td>Judd Vinet</td> 
   <td>GNU Public License version 2 (copyleft)</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/rpm-software-management/popt">popt</a></td> 
   <td>1.16</td> 
   <td>Jeff Johnson &amp; Erik Troan</td> 
   <td>MIT License</td> 
  </tr> 
  <tr> 
   <td><a href="https://gitlab.com/procps-ng/procps">procps</a></td> 
   <td>2.8.3</td> 
   <td>Brian Edmonds et al.</td> 
   <td>LGPL (copyleft)</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/facebook/rocksdb/">RocksDB</a></td> 
   <td>8.3.2</td> 
   <td>Facebook Inc.</td> 
   <td>Apache 2.0 License</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/rpm-software-management/rpm">rpm</a></td> 
   <td>4.18.2</td> 
   <td>Marc Ewing &amp; Erik Troan</td> 
   <td>GNU Public License version 2 (copyleft)</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/sqlite/sqlite">sqlite</a></td> 
   <td>3.45.0</td> 
   <td>D. Richard Hipp</td> 
   <td>Public Domain (no restrictions)</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/madler/zlib">zlib</a></td> 
   <td>1.3.1</td> 
   <td>Jean-loup Gailly &amp; Mark Adler</td> 
   <td>zlib/libpng License</td> 
  </tr> 
 </tbody> 
</table> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/wazuh/wazuh/master/framework/requirements.txt">PyPi packages</a></li> 
</ul> 
<h2>Documentation</h2> 
<ul> 
 <li><a href="http://documentation.wazuh.com">Full documentation</a></li> 
 <li><a href="https://documentation.wazuh.com/current/installation-guide/index.html">Wazuh installation guide</a></li> 
</ul> 
<h2>Get involved</h2> 
<p>Become part of the <a href="https://wazuh.com/community/">Wazuh's community</a> to learn from other users, participate in discussions, talk to our developers and contribute to the project.</p> 
<p>If you want to contribute to our project please don’t hesitate to make pull-requests, submit issues or send commits, we will review all your questions.</p> 
<p>You can also join our <a href="https://wazuh.com/community/join-us-on-slack/">Slack community channel</a> and <a href="https://groups.google.com/d/forum/wazuh">mailing list</a> by sending an email to <a href="mailto:wazuh+subscribe@googlegroups.com">wazuh+subscribe@googlegroups.com</a>, to ask questions and participate in discussions.</p> 
<p>Stay up to date on news, releases, engineering articles and more.</p> 
<ul> 
 <li><a href="http://wazuh.com">Wazuh website</a></li> 
 <li><a href="https://www.linkedin.com/company/wazuh">Linkedin</a></li> 
 <li><a href="https://www.youtube.com/c/wazuhsecurity">YouTube</a></li> 
 <li><a href="https://twitter.com/wazuh">Twitter</a></li> 
 <li><a href="https://wazuh.com/blog/">Wazuh blog</a></li> 
 <li><a href="https://wazuh.com/community/join-us-on-slack/">Slack announcements channel</a></li> 
</ul> 
<h2>Authors</h2> 
<p>Wazuh Copyright (C) 2015-2023 Wazuh Inc. (License GPLv2)</p> 
<p>Based on the OSSEC project started by Daniel Cid.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>frappe/erpnext</title>
<link>https://github.com/frappe/erpnext</link>
<guid>https://github.com/frappe/erpnext</guid>
<content:encoded><![CDATA[
<div> 关键词：ERPNext、安装、学习与社区、贡献、许可证

文章总结：

ERPNext是一个基于Python和JavaScript的全栈Web应用框架构建的免费开源企业资源规划（ERP）系统。它为管理业务提供了各种功能区域，包括销售、采购、库存、生产、项目、客户服务等。

对于部署，提供了多种方式供选择。一种是容器化安装，通过Docker进行生产或开发应用。另一种是手动安装，使用我们的安装脚本Bench来安装所有依赖项，如MariaDB数据库。新生成的管理员密码和其他重要用户密码将显示并保存到~/frappe_passwords.txt文件中。

在学习和社区部分，提供了多种途径帮助用户了解和掌握Frappe框架和ERPNext。文档提供了详细的指导，社区支持活跃，用户可以在这里获取即时帮助。此外，鼓励用户参与贡献，遵守GNU/General Public License和商标政策。

最后，需要强调的是，ERPNext的代码和文档分别遵循GNU General Public License (v3)和Creative Commons Attribution-ShareAlike 3.0许可。任何贡献者都同意其贡献将遵循此许可证。同时，需要遵守Logo和商标政策。 <div>
<p>Free and Open Source Enterprise Resource Planning (ERP)</p><hr /><div align="center"> 
 <a href="https://erpnext.com"> <img height="128" src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/erpnext-logo.png" /> </a> 
 <h2>ERPNext</h2> 
 <p align="center"> </p>
 <p>ERP made simple</p> 
 <p></p> 
 <p><a href="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml"><img alt="CI" src="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml/badge.svg?event=schedule" /></a> <a href="https://www.codetriage.com/frappe/erpnext"><img alt="Open Source Helpers" src="https://www.codetriage.com/frappe/erpnext/badges/users.svg?sanitize=true" /></a> <a href="https://codecov.io/gh/frappe/erpnext"><img alt="codecov" src="https://codecov.io/gh/frappe/erpnext/branch/develop/graph/badge.svg?token=0TwvyUg3I5" /></a> <a href="https://hub.docker.com/r/frappe/erpnext-worker"><img alt="docker pulls" src="https://img.shields.io/docker/pulls/frappe/erpnext-worker.svg?sanitize=true" /></a></p> 
 <p><a href="https://erpnext.com">https://erpnext.com</a></p> 
</div> 
<p>ERPNext as a monolith includes the following areas for managing businesses:</p> 
<ol> 
 <li><a href="https://erpnext.com/open-source-accounting">Accounting</a></li> 
 <li><a href="https://erpnext.com/distribution/warehouse-management-system">Warehouse Management</a></li> 
 <li><a href="https://erpnext.com/open-source-crm">CRM</a></li> 
 <li><a href="https://erpnext.com/open-source-sales-purchase">Sales</a></li> 
 <li><a href="https://erpnext.com/open-source-sales-purchase">Purchase</a></li> 
 <li><a href="https://erpnext.com/open-source-hrms">HRMS</a></li> 
 <li><a href="https://erpnext.com/open-source-projects">Project Management</a></li> 
 <li><a href="https://erpnext.com/open-source-help-desk-software">Support</a></li> 
 <li><a href="https://erpnext.com/open-source-asset-management-software">Asset Management</a></li> 
 <li><a href="https://erpnext.com/docs/user/manual/en/quality-management">Quality Management</a></li> 
 <li><a href="https://erpnext.com/open-source-manufacturing-erp-software">Manufacturing</a></li> 
 <li><a href="https://erpnext.com/open-source-website-builder-software">Website Management</a></li> 
 <li><a href="https://erpnext.com/docs/user/manual/en/customize-erpnext">Customize ERPNext</a></li> 
 <li><a href="https://erpnext.com/docs/user/manual/en/">And More</a></li> 
</ol> 
<p>ERPNext is built on the <a href="https://github.com/frappe/frappe">Frappe Framework</a>, a full-stack web app framework built with Python &amp; JavaScript.</p> 
<h2>Installation</h2> 
<div align="center"> 
 <a href="https://frappecloud.com/erpnext/signup"> <img height="40" src="https://raw.githubusercontent.com/frappe/erpnext/develop/.github/try-on-f-cloud-button.svg?sanitize=true" /> </a> 
 <a href="https://labs.play-with-docker.com/?stack=https://raw.githubusercontent.com/frappe/frappe_docker/main/pwd.yml"> <img alt="Try in PWD" height="37" src="https://raw.githubusercontent.com/play-with-docker/stacks/master/assets/images/button.png" /> </a> 
</div> 
<blockquote> 
 <p>Login for the PWD site: (username: Administrator, password: admin)</p> 
</blockquote> 
<h3>Containerized Installation</h3> 
<p>Use docker to deploy ERPNext in production or for development of <a href="https://github.com/frappe/frappe">Frappe</a> apps. See <a href="https://github.com/frappe/frappe_docker">https://github.com/frappe/frappe_docker</a> for more details.</p> 
<h3>Manual Install</h3> 
<p>The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See <a href="https://github.com/frappe/bench">https://github.com/frappe/bench</a> for more details.</p> 
<p>New passwords will be created for the ERPNext "Administrator" user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).</p> 
<h2>Learning and community</h2> 
<ol> 
 <li><a href="https://frappe.school">Frappe School</a> - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.</li> 
 <li><a href="https://docs.erpnext.com/">Official documentation</a> - Extensive documentation for ERPNext.</li> 
 <li><a href="https://discuss.erpnext.com/">Discussion Forum</a> - Engage with community of ERPNext users and service providers.</li> 
 <li><a href="https://erpnext_public.t.me">Telegram Group</a> - Get instant help from huge community of users.</li> 
</ol> 
<h2>Contributing</h2> 
<ol> 
 <li><a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines">Issue Guidelines</a></li> 
 <li><a href="https://erpnext.com/security">Report Security Vulnerabilities</a></li> 
 <li><a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines">Pull Request Requirements</a></li> 
</ol> 
<h2>License</h2> 
<p>GNU/General Public License (see <a href="https://raw.githubusercontent.com/frappe/erpnext/develop/license.txt">license.txt</a>)</p> 
<p>The ERPNext code is licensed as GNU General Public License (v3) and the Documentation is licensed as Creative Commons (CC-BY-SA-3.0) and the copyright is owned by Frappe Technologies Pvt Ltd (Frappe) and Contributors.</p> 
<p>By contributing to ERPNext, you agree that your contributions will be licensed under its GNU General Public License (v3).</p> 
<h2>Logo and Trademark Policy</h2> 
<p>Please read our <a href="https://raw.githubusercontent.com/frappe/erpnext/develop/TRADEMARK_POLICY.md">Logo and Trademark Policy</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Z4nzu/hackingtool</title>
<link>https://github.com/Z4nzu/hackingtool</link>
<guid>https://github.com/Z4nzu/hackingtool</guid>
<content:encoded><![CDATA[
<div> 关键词：Kali Linux, Docker, Hacking Tool, 更新, 社交媒体分享

总结:

本文主要介绍了名为“Hacking Tool”的集成黑客工具包，旨在为黑客提供一系列实用工具。以下是文章的主要要点：

1. **安装选项**：文章提供了在Windows 10上不使用虚拟机（如VirtualBox）或Docker安装Kali Linux的方法。用户可以选择通过Git克隆项目、给予执行权限、移动到项目目录并运行安装脚本来完成安装。

2. **更新内容**：新版本（V1.2.0）修复了安装错误，并添加了多个新功能，包括反向工程、RAT工具、网页爬虫、载荷注入器等，以及多工器工具、WiFi干扰、SQL注入工具、钓鱼攻击工具和网络攻击工具等。

3. **匿名隐藏工具**：文章提到了一些用于匿名操作的工具，强调了隐私保护的重要性。

4. **社交分享**：鼓励用户分享新版本的更新，以保持社区的活跃度和资源的传播。

5. **使用方式与贡献**：提供了一步式指导如何使用Hacking Tool，同时也欢迎用户提出建议、分享喜爱的工具或报告非法用途，强调了对工具使用的道德责任。

通过这些要点，可以概括出“Hacking Tool”是一个全面的黑客工具集，支持多种操作系统安装方式，持续更新以满足不同需求，并鼓励用户参与社区建设和遵守使用规范。 <div>
<p>ALL IN ONE Hacking Tool For Hackers</p><hr /><h3>All in One Hacking tool For Hackers🥇</h3> 
<p><img alt="" src="https://img.shields.io/github/license/Z4nzu/hackingtool" /> <img alt="" src="https://img.shields.io/github/issues/Z4nzu/hackingtool" /> <img alt="" src="https://img.shields.io/github/issues-closed/Z4nzu/hackingtool" /> <img alt="" src="https://img.shields.io/badge/Python-3-blue" /> <img alt="" src="https://img.shields.io/github/forks/Z4nzu/hackingtool" /> <img alt="" src="https://img.shields.io/github/stars/Z4nzu/hackingtool" /> <img alt="" src="https://img.shields.io/github/last-commit/Z4nzu/hackingtool" /> <a href="http://hits.dwyl.com/Z4nzu/hackingtool"><img alt="HitCount" src="http://hits.dwyl.com/Z4nzu/hackingtool.svg?sanitize=true" /></a> <img alt="" src="https://img.shields.io/badge/platform-Linux%20%7C%20KaliLinux%20%7C%20ParrotOs-blue" /></p> 
<h4>Install Kali Linux in WIndows10 Without VirtualBox <a href="https://youtu.be/BsFhpIDcd9I">YOUTUBE</a> or use Docker</h4> 
<h2>Update Available V1.2.0 🚀</h2> 
<ul> 
 <li>[✔] Installation Bug Fixed</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> Added New Tools 
  <ul> 
   <li><input checked="checked" disabled="disabled" type="checkbox" /> Reverse Engineering</li> 
   <li><input checked="checked" disabled="disabled" type="checkbox" /> RAT Tools</li> 
   <li><input checked="checked" disabled="disabled" type="checkbox" /> Web Crawling</li> 
   <li><input checked="checked" disabled="disabled" type="checkbox" /> Payload Injector</li> 
  </ul> </li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> Multitor Tools update</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> Added Tool in wifijamming</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> Added Tool in steganography</li> 
</ul> 
<h1>Hackingtool Menu 🧰</h1> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#anonymously-hiding-tools">Anonymously Hiding Tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#information-gathering-tools">Information gathering tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#wordlist-generator">Wordlist Generator</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#wireless-attack-tools">Wireless attack tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#sql-injection-tools">SQL Injection Tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#phishing-attack-tools">Phishing attack tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#web-attack-tools">Web Attack tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#post-exploitation-tools">Post exploitation tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#forensic-tools">Forensic tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#payload-creation-tools">Payload creation tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#exploit-framework">Exploit framework</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#reverse-engineering-tools">Reverse engineering tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#ddos-attack-tools">DDOS Attack Tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#remote-administrator-tools--rat-">Remote Administrator Tools (RAT)</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#xss-attack-tools">XSS Attack Tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#steganograhy-tools">Steganograhy tools</a></li> 
 <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#other-tools">Other tools</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#socialmedia-bruteforce">SocialMedia Bruteforce</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#android-hacking-tools">Android Hacking tools</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#idn-homograph-attack">IDN Homograph Attack</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#email-verify-tools">Email Verify tools</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#hash-cracking-tools">Hash cracking tools</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#wifi-deauthenticate">Wifi Deauthenticate</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#socialmedia-finder">SocialMedia Finder</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#payload-injector">Payload Injector</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#web-crawling">Web crawling</a></li> 
   <li><a href="https://raw.githubusercontent.com/Z4nzu/hackingtool/master/#mix-tools">Mix tools</a></li> 
  </ul> </li> 
</ul> 
<h3>Anonymously Hiding Tools</h3> 
<ul> 
 <li><a href="https://github.com/Und3rf10w/kali-anonsurf">Anonmously Surf</a></li> 
 <li><a href="https://github.com/trimstray/multitor">Multitor</a></li> 
</ul> 
<h3>Information gathering tools</h3> 
<ul> 
 <li><a href="https://github.com/nmap/nmap">Network Map (nmap)</a></li> 
 <li><a href="https://github.com/Screetsec/Dracnmap">Dracnmap</a></li> 
 <li>Port scanning</li> 
 <li>Host to IP</li> 
 <li><a href="https://github.com/LionSec/xerosploit">Xerosploit</a></li> 
 <li><a href="https://github.com/Tuhinshubhra/RED_HAWK">RED HAWK (All In One Scanning)</a></li> 
 <li><a href="https://github.com/bhavsec/reconspider">ReconSpider(For All Scanning)</a></li> 
 <li>IsItDown (Check Website Down/Up)</li> 
 <li><a href="https://github.com/m4ll0k/Infoga">Infoga - Email OSINT</a></li> 
 <li><a href="https://github.com/s0md3v/ReconDog">ReconDog</a></li> 
 <li><a href="https://github.com/s0md3v/Striker">Striker</a></li> 
 <li><a href="https://github.com/m4ll0k/SecretFinder">SecretFinder (like API &amp; etc)</a></li> 
 <li><a href="https://github.com/m4ll0k/Shodanfy.py">Find Info Using Shodan</a></li> 
 <li><a href="https://github.com/floriankunushevci/rang3r">Port Scanner - rang3r (Python 2.7)</a></li> 
 <li><a href="https://github.com/joeyagreco/ranger-reloaded">Port Scanner - Ranger Reloaded (Python 3+)</a></li> 
 <li><a href="https://github.com/s0md3v/Breacher">Breacher</a></li> 
</ul> 
<h3>Wordlist Generator</h3> 
<ul> 
 <li><a href="https://github.com/Mebus/cupp.git">Cupp</a></li> 
 <li><a href="https://github.com/Z4nzu/wlcreator">WordlistCreator</a></li> 
 <li><a href="https://github.com/UndeadSec/GoblinWordGenerator.git">Goblin WordGenerator</a></li> 
 <li><a href="https://github.com/Viralmaniar/SMWYG-Show-Me-What-You-Got">Password list (1.4 Billion Clear Text Password)</a></li> 
</ul> 
<h3>Wireless attack tools</h3> 
<ul> 
 <li><a href="https://github.com/P0cL4bs/wifipumpkin3">WiFi-Pumpkin</a></li> 
 <li><a href="https://github.com/wiire/pixiewps">pixiewps</a></li> 
 <li><a href="https://github.com/andrewmichaelsmith/bluepot">Bluetooth Honeypot GUI Framework</a></li> 
 <li><a href="https://github.com/thehackingsage/Fluxion">Fluxion</a></li> 
 <li><a href="https://github.com/wifiphisher/wifiphisher">Wifiphisher</a></li> 
 <li><a href="https://github.com/derv82/wifite2">Wifite</a></li> 
 <li><a href="https://github.com/Z4nzu/fakeap">EvilTwin</a></li> 
 <li><a href="https://github.com/Z4nzu/fastssh">Fastssh</a></li> 
 <li>Howmanypeople</li> 
</ul> 
<h3>SQL Injection Tools</h3> 
<ul> 
 <li><a href="https://github.com/sqlmapproject/sqlmap">Sqlmap tool</a></li> 
 <li><a href="https://github.com/codingo/NoSQLMap">NoSqlMap</a></li> 
 <li><a href="https://github.com/stamparm/DSSS">Damn Small SQLi Scanner</a></li> 
 <li><a href="https://github.com/dtag-dev-sec/explo">Explo</a></li> 
 <li><a href="https://github.com/JohnTroony/Blisqy">Blisqy - Exploit Time-based blind-SQL injection</a></li> 
 <li><a href="https://github.com/leviathan-framework/leviathan">Leviathan - Wide Range Mass Audit Toolkit</a></li> 
 <li><a href="https://github.com/Cvar1984/sqlscan">SQLScan</a></li> 
</ul> 
<h3>Phishing attack tools</h3> 
<ul> 
 <li><a href="https://github.com/trustedsec/social-engineer-toolkit">Setoolkit</a></li> 
 <li><a href="https://github.com/UndeadSec/SocialFish">SocialFish</a></li> 
 <li><a href="https://github.com/DarkSecDevelopers/HiddenEye">HiddenEye</a></li> 
 <li><a href="https://github.com/kgretzky/evilginx2">Evilginx2</a></li> 
 <li><a href="https://github.com/Viralmaniar/I-See-You">I-See_You(Get Location using phishing attack)</a></li> 
 <li><a href="https://github.com/hangetzzu/saycheese">SayCheese (Grab target's Webcam Shots)</a></li> 
 <li><a href="https://github.com/cryptedwolf/ohmyqr">QR Code Jacking</a></li> 
 <li><a href="https://github.com/An0nUD4Y/shellphish">ShellPhish</a></li> 
 <li><a href="https://github.com/iinc0gnit0/BlackPhish">BlackPhish</a></li> 
</ul> 
<h3>Web Attack tools</h3> 
<ul> 
 <li><a href="https://github.com/santatic/web2attack">Web2Attack</a></li> 
 <li>Skipfish</li> 
 <li><a href="https://github.com/aboul3la/Sublist3r">SubDomain Finder</a></li> 
 <li><a href="https://github.com/UndeadSec/checkURL">CheckURL</a></li> 
 <li><a href="https://github.com/UltimateHackers/Blazy">Blazy(Also Find ClickJacking)</a></li> 
 <li><a href="https://github.com/m4ll0k/takeover">Sub-Domain TakeOver</a></li> 
 <li><a href="https://gitlab.com/kalilinux/packages/dirb">Dirb</a></li> 
</ul> 
<h3>Post exploitation tools</h3> 
<ul> 
 <li><a href="https://github.com/Screetsec/Vegile">Vegile - Ghost In The Shell</a></li> 
 <li><a href="https://github.com/UndeadSec/HeraKeylogger">Chrome Keylogger</a></li> 
</ul> 
<h3>Forensic tools</h3> 
<ul> 
 <li>Autopsy</li> 
 <li>Wireshark</li> 
 <li><a href="https://github.com/simsong/bulk_extractor">Bulk extractor</a></li> 
 <li><a href="https://guymager.sourceforge.io/">Disk Clone and ISO Image Acquire</a></li> 
 <li><a href="https://www.toolsley.com/">Toolsley</a></li> 
 <li><a href="https://github.com/volatilityfoundation/volatility3/">Volatility3</a></li> 
</ul> 
<h3>Payload creation tools</h3> 
<ul> 
 <li><a href="https://github.com/Screetsec/TheFatRat">The FatRat</a></li> 
 <li><a href="https://github.com/Screetsec/Brutal">Brutal</a></li> 
 <li><a href="https://nathanlopez.github.io/Stitch">Stitch</a></li> 
 <li><a href="https://github.com/g0tmi1k/msfpc">MSFvenom Payload Creator</a></li> 
 <li><a href="https://github.com/r00t-3xp10it/venom">Venom Shellcode Generator</a></li> 
 <li><a href="https://github.com/indexnotfound404/spycam">Spycam</a></li> 
 <li><a href="https://github.com/kinghacker0/Mob-Droid">Mob-Droid</a></li> 
 <li><a href="https://github.com/UndeadSec/Enigma">Enigma</a></li> 
</ul> 
<h3>Exploit framework</h3> 
<ul> 
 <li><a href="https://github.com/threat9/routersploit">RouterSploit</a></li> 
 <li><a href="https://github.com/The404Hacking/websploit">WebSploit</a></li> 
 <li><a href="https://github.com/commixproject/commix">Commix</a></li> 
 <li><a href="https://github.com/santatic/web2attack">Web2Attack</a></li> 
</ul> 
<h3>Reverse engineering tools</h3> 
<ul> 
 <li><a href="https://github.com/androguard/androguard">Androguard</a></li> 
 <li><a href="https://github.com/lxdvs/apk2gold">Apk2Gold</a></li> 
 <li><a href="https://github.com/skylot/jadx">JadX</a></li> 
</ul> 
<h3>DDOS Attack Tools</h3> 
<ul> 
 <li>SlowLoris</li> 
 <li><a href="https://github.com/fatihsnsy/aSYNcrone">Asyncrone | Multifunction SYN Flood DDoS Weapon</a></li> 
 <li><a href="https://github.com/epsylon/ufonet">UFOnet</a></li> 
 <li><a href="https://github.com/jseidl/GoldenEye">GoldenEye</a></li> 
</ul> 
<h3>Remote Administrator Tools (RAT)</h3> 
<ul> 
 <li><a href="https://github.com/nathanlopez/Stitch">Stitch</a></li> 
 <li><a href="https://github.com/knassar702/pyshell">Pyshell</a></li> 
</ul> 
<h3>XSS Attack Tools</h3> 
<ul> 
 <li><a href="https://github.com/hahwul/dalfox">DalFox(Finder of XSS)</a></li> 
 <li><a href="https://github.com/capture0x/XSS-LOADER.git">XSS Payload Generator</a></li> 
 <li><a href="https://github.com/Damian89/extended-xss-search">Extended XSS Searcher and Finder</a></li> 
 <li><a href="https://github.com/PR0PH3CY33/XSS-Freak">XSS-Freak</a></li> 
 <li><a href="https://github.com/hahwul/XSpear">XSpear</a></li> 
 <li><a href="https://github.com/menkrep1337/XSSCon">XSSCon</a></li> 
 <li><a href="https://github.com/Ekultek/XanXSS">XanXSS</a></li> 
 <li><a href="https://github.com/UltimateHackers/XSStrike">Advanced XSS Detection Suite</a></li> 
 <li><a href="https://github.com/iinc0gnit0/RVuln">RVuln</a></li> 
 <li><a href="https://github.com/v8blink/Chromium-based-XSS-Taint-Tracking">Cyclops</a></li> 
</ul> 
<h3>Steganograhy tools</h3> 
<ul> 
 <li>SteganoHide</li> 
 <li>StegnoCracker</li> 
 <li><a href="https://github.com/W1LDN16H7/StegoCracker">StegoCracker</a></li> 
 <li><a href="https://github.com/beardog108/snow10">Whitespace</a></li> 
</ul> 
<h3>Other tools</h3> 
<h4>SocialMedia Bruteforce</h4> 
<ul> 
 <li><a href="https://github.com/chinoogawa/instaBrute">Instagram Attack</a></li> 
 <li><a href="https://github.com/Matrix07ksa/Brute_Force">AllinOne SocialMedia Attack</a></li> 
 <li><a href="https://github.com/Matrix07ksa/Brute_Force">Facebook Attack</a></li> 
 <li><a href="https://github.com/jakuta-tech/underhanded">Application Checker</a></li> 
</ul> 
<h4>Android Hacking tools</h4> 
<ul> 
 <li><a href="https://github.com/F4dl0/keydroid">Keydroid</a></li> 
 <li><a href="https://github.com/papusingh2sms/mysms">MySMS</a></li> 
 <li><a href="https://github.com/JasonJerry/lockphish">Lockphish (Grab target LOCK PIN)</a></li> 
 <li><a href="https://github.com/kinghacker0/WishFish">DroidCam (Capture Image)</a></li> 
 <li><a href="https://github.com/crypticterminal/EvilApp">EvilApp (Hijack Session)</a></li> 
 <li><a href="https://github.com/HatBashBR/HatCloud">HatCloud(Bypass CloudFlare for IP)</a></li> 
</ul> 
<h4>IDN Homograph Attack</h4> 
<ul> 
 <li><a href="https://github.com/UndeadSec/EvilURL">EvilURL</a></li> 
</ul> 
<h4>Email Verify tools</h4> 
<ul> 
 <li><a href="https://github.com/4w4k3/KnockMail">Knockmail</a></li> 
</ul> 
<h4>Hash cracking tools</h4> 
<ul> 
 <li><a href="https://github.com/s0md3v/Hash-Buster">Hash Buster</a></li> 
</ul> 
<h4>Wifi Deauthenticate</h4> 
<ul> 
 <li><a href="https://github.com/MisterBianco/wifijammer-ng">WifiJammer-NG</a></li> 
 <li><a href="https://github.com/aryanrtm/KawaiiDeauther">KawaiiDeauther</a></li> 
</ul> 
<h4>SocialMedia Finder</h4> 
<ul> 
 <li><a href="https://github.com/Greenwolf/social_mapper">Find SocialMedia By Facial Recognation System</a></li> 
 <li><a href="https://github.com/xHak9x/finduser">Find SocialMedia By UserName</a></li> 
 <li><a href="https://github.com/sherlock-project/sherlock">Sherlock</a></li> 
 <li><a href="https://github.com/iojw/socialscan">SocialScan | Username or Email</a></li> 
</ul> 
<h4>Payload Injector</h4> 
<ul> 
 <li><a href="https://github.com/UndeadSec/Debinject">Debinject</a></li> 
 <li><a href="https://github.com/chinarulezzz/pixload">Pixload</a></li> 
</ul> 
<h4>Web crawling</h4> 
<ul> 
 <li><a href="https://github.com/jaeles-project/gospider">Gospider</a></li> 
</ul> 
<h4>Mix tools</h4> 
<ul> 
 <li>Terminal Multiplexer</li> 
</ul> 
<p><img alt="" src="https://github.com/Z4nzu/hackingtool/raw/master/images/A00.png" /> <img alt="" src="https://github.com/Z4nzu/hackingtool/raw/master/images/A0.png" /> <img alt="" src="https://github.com/Z4nzu/hackingtool/raw/master/images/A1.png" /> <img alt="" src="https://github.com/Z4nzu/hackingtool/raw/master/images/A2.png" /> <img alt="" src="https://github.com/Z4nzu/hackingtool/raw/master/images/A4.png" /></p> 
<h2>Installation For Linux <img alt="linux" height="25" src="https://konpa.github.io/devicon/devicon.git/icons/linux/linux-original.svg?sanitize=true" width="25" /><p></p><p align="center"></p></h2> 
<h3>!! RUN HACKINGTOOL AS ROOT !!</h3> 
<h2>Steps are given below :</h2> 
<h2>Step : 1 Download hackingtool</h2> 
<pre><code>git clone https://github.com/Z4nzu/hackingtool.git
</code></pre> 
<h2>Step : 2 Give Permission to hackingtool</h2> 
<pre><code>chmod -R 755 hackingtool  
</code></pre> 
<h2>Step : 3 Move to hackingtool directory</h2> 
<pre><code>cd hackingtool
</code></pre> 
<h2>Step : 4 Run hackingtool</h2> 
<pre><code>sudo bash install.sh
</code></pre> 
<h2>Step : 5 For installing tools in directory</h2> 
<pre><code>sudo hackingtool
</code></pre> 
<h2>Use image with Docker</h2> 
<h3>Create Docker Image</h3> 
<ul> 
 <li>Create the docker image</li> 
</ul> 
<pre><code class="language-bash">docker buitl -t vgpastor/hackingtool .
</code></pre> 
<h3>Run as container</h3> 
<pre><code class="language-bash">docker-compose up -d
</code></pre> 
<h3>Interact with terminal</h3> 
<ul> 
 <li>Get into the container</li> 
</ul> 
<pre><code class="language-bash">docker exec -it hackingtool bash
</code></pre> 
<p><strong>OUTPUT:</strong></p> 
<pre><code class="language-bash">Select Best Option : 

              [1] Kali Linux / Parrot-Os (apt)
              [2] Arch Linux (pacman)
              [0] Exit 
</code></pre> 
<p>Enter the options and continue.</p> 
<ul> 
 <li>If need open other ports you can edit the docker-compose.yml file</li> 
 <li>Volumes are mounted in the container to persist data and can share files between the host and the container</li> 
</ul> 
<h4>Thanks to original Author of the tools used in hackingtool</h4> 
<img src="https://img.shields.io/badge/Important-notice-red" /> 
<h4>Please Don't Use for illegal Activity</h4> 
<h3>To do</h3> 
<ul> 
 <li><input disabled="disabled" type="checkbox" /> Release Tool</li> 
 <li><input disabled="disabled" type="checkbox" /> Add Tools for CTF</li> 
 <li><input disabled="disabled" type="checkbox" /> Want to do automatic</li> 
</ul> 
<h2>Social Media <span>📭</span></h2> 
<p><a href="https://twitter.com/_Zinzu07"><img alt="Twitter" src="https://img.shields.io/twitter/url?color=%231DA1F2&amp;label=follow&amp;logo=twitter&amp;logoColor=%231DA1F2&amp;style=flat-square&amp;url=https%3A%2F%2Fwww.reddit.com%2Fuser%2FFatChicken277" /></a> <a href="https://github.com/Z4nzu/"><img alt="GitHub" src="https://img.shields.io/badge/-GitHub-181717?style=flat-square&amp;logo=github&amp;link=https://github.com/Z4nzu/" /></a></p> 
<h5>Your Favourite Tool is not in hackingtool or Suggestions Please <a href="https://forms.gle/b235JoCKyUq5iM3t8">CLICK HERE</a></h5> 
<p><img alt="Z4nzu's github stats" src="https://github-readme-stats.vercel.app/api?username=Z4nzu&amp;show_icons=true&amp;title_color=fff&amp;icon_color=79ff97&amp;text_color=9f9f9f&amp;bg_color=151515" /></p> 
<h4>Don't Forgot to share with Your Friends</h4> 
<h3>The new Update get will soon stay updated</h3> 
<h4>Thank you..!!</h4>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>fmtlib/fmt</title>
<link>https://github.com/fmtlib/fmt</link>
<guid>https://github.com/fmtlib/fmt</guid>
<content:encoded><![CDATA[
<div> 关键词：fmt库、快速安全、C/C++、国际化支持、头文件驱动

总结：

fmt库是一个为现代C和C++程序设计的开放源代码格式化库。它提供了一个快速、安全的替代方案，用于替换C标准输入输出库（stdio）和C++输入输出流（iostreams）。fmt库的特点包括：

1. **简单性与国际化**：支持基于位置参数的局部化字符串格式化，实现类似Python的格式化字符串功能。
2. **高性能**：提供IEEE 754浮点数格式化功能，具有正确的舍入、最短长度和反向转换保证，使用Kahan算法。
3. **Unicode支持**：具有跨平台的Unicode支持，确保安全的字符串格式化操作。
4. **类型安全性**：实现头文件驱动型编程，包括POSIX扩展的参数位置支持，避免缓冲区溢出错误。
5. **可扩展性与可靠性**：易于扩展，拥有广泛的单元测试套件，确保其稳定性和健壮性。

通过fmt库，开发者可以实现高效、安全的字符串格式化，同时享受跨平台兼容性、高性能以及简洁的API设计。 <div>
<p>A modern formatting library</p><hr /><img alt="{fmt}" src="https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png" width="25%" /> 
<p><a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux"><img alt="image" src="https://github.com/fmtlib/fmt/workflows/linux/badge.svg?sanitize=true" /></a> <a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos"><img alt="image" src="https://github.com/fmtlib/fmt/workflows/macos/badge.svg?sanitize=true" /></a> <a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows"><img alt="image" src="https://github.com/fmtlib/fmt/workflows/windows/badge.svg?sanitize=true" /></a> <a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20%0ASummary&amp;q=proj%3Dfmt&amp;can=1"><img alt="fmt is continuously fuzzed at oss-fuzz" src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg?sanitize=true" /></a> <a href="https://stackoverflow.com/questions/tagged/fmt"><img alt="Ask questions at StackOverflow with the tag fmt" src="https://img.shields.io/badge/stackoverflow-fmt-blue.svg?sanitize=true" /></a> <a href="https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt"><img alt="image" src="https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge" /></a></p> 
<p><strong>{fmt}</strong> is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams.</p> 
<p>If you like this project, please consider donating to one of the funds that help victims of the war in Ukraine: <a href="https://www.stopputin.net/">https://www.stopputin.net/</a>.</p> 
<p><a href="https://fmt.dev">Documentation</a></p> 
<p><a href="https://hackingcpp.com/cpp/libs/fmt.html">Cheat Sheets</a></p> 
<p>Q&amp;A: ask questions on <a href="https://stackoverflow.com/questions/tagged/fmt">StackOverflow with the tag fmt</a>.</p> 
<p>Try {fmt} in <a href="https://godbolt.org/z/8Mx1EW73v">Compiler Explorer</a>.</p> 
<h1>Features</h1> 
<ul> 
 <li>Simple <a href="https://fmt.dev/latest/api/">format API</a> with positional arguments for localization</li> 
 <li>Implementation of <a href="https://en.cppreference.com/w/cpp/utility/format">C++20 std::format</a> and <a href="https://en.cppreference.com/w/cpp/io/print">C++23 std::print</a></li> 
 <li><a href="https://fmt.dev/latest/syntax/">Format string syntax</a> similar to Python's <a href="https://docs.python.org/3/library/stdtypes.html#str.format">format</a></li> 
 <li>Fast IEEE 754 floating-point formatter with correct rounding, shortness and round-trip guarantees using the <a href="https://github.com/jk-jeon/dragonbox">Dragonbox</a> algorithm</li> 
 <li>Portable Unicode support</li> 
 <li>Safe <a href="https://fmt.dev/latest/api/#printf-formatting">printf implementation</a> including the POSIX extension for positional arguments</li> 
 <li>Extensibility: <a href="https://fmt.dev/latest/api/#formatting-user-defined-types">support for user-defined types</a></li> 
 <li>High performance: faster than common standard library implementations of <code>(s)printf</code>, iostreams, <code>to_string</code> and <code>to_chars</code>, see <a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#speed-tests">Speed tests</a> and <a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html">Converting a hundred million integers to strings per second</a></li> 
 <li>Small code size both in terms of source code with the minimum configuration consisting of just three files, <code>core.h</code>, <code>format.h</code> and <code>format-inl.h</code>, and compiled code; see <a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#compile-time-and-code-bloat">Compile time and code bloat</a></li> 
 <li>Reliability: the library has an extensive set of <a href="https://github.com/fmtlib/fmt/tree/master/test">tests</a> and is <a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&amp;q=proj%3Dfmt&amp;can=1">continuously fuzzed</a></li> 
 <li>Safety: the library is fully type-safe, errors in format strings can be reported at compile time, automatic memory management prevents buffer overflow errors</li> 
 <li>Ease of use: small self-contained code base, no external dependencies, permissive MIT <a href="https://github.com/fmtlib/fmt/raw/master/LICENSE">license</a></li> 
 <li><a href="https://fmt.dev/latest/#portability">Portability</a> with consistent output across platforms and support for older compilers</li> 
 <li>Clean warning-free codebase even on high warning levels such as <code>-Wall -Wextra -pedantic</code></li> 
 <li>Locale independence by default</li> 
 <li>Optional header-only configuration enabled with the <code>FMT_HEADER_ONLY</code> macro</li> 
</ul> 
<p>See the <a href="https://fmt.dev">documentation</a> for more details.</p> 
<h1>Examples</h1> 
<p><strong>Print to stdout</strong> (<a href="https://godbolt.org/z/Tevcjh">run</a>)</p> 
<pre><code class="language-c++">#include &lt;fmt/core.h&gt;

int main() {
  fmt::print("Hello, world!\n");
}
</code></pre> 
<p><strong>Format a string</strong> (<a href="https://godbolt.org/z/oK8h33">run</a>)</p> 
<pre><code class="language-c++">std::string s = fmt::format("The answer is {}.", 42);
// s == "The answer is 42."
</code></pre> 
<p><strong>Format a string using positional arguments</strong> (<a href="https://godbolt.org/z/Yn7Txe">run</a>)</p> 
<pre><code class="language-c++">std::string s = fmt::format("I'd rather be {1} than {0}.", "right", "happy");
// s == "I'd rather be happy than right."
</code></pre> 
<p><strong>Print dates and times</strong> (<a href="https://godbolt.org/z/c31ExdY3W">run</a>)</p> 
<pre><code class="language-c++">#include &lt;fmt/chrono.h&gt;

int main() {
  auto now = std::chrono::system_clock::now();
  fmt::print("Date and time: {}\n", now);
  fmt::print("Time: {:%H:%M}\n", now);
}
</code></pre> 
<p>Output:</p> 
<pre><code>Date and time: 2023-12-26 19:10:31.557195597
Time: 19:10
</code></pre> 
<p><strong>Print a container</strong> (<a href="https://godbolt.org/z/MxM1YqjE7">run</a>)</p> 
<pre><code class="language-c++">#include &lt;vector&gt;
#include &lt;fmt/ranges.h&gt;

int main() {
  std::vector&lt;int&gt; v = {1, 2, 3};
  fmt::print("{}\n", v);
}
</code></pre> 
<p>Output:</p> 
<pre><code>[1, 2, 3]
</code></pre> 
<p><strong>Check a format string at compile time</strong></p> 
<pre><code class="language-c++">std::string s = fmt::format("{:d}", "I am not a number");
</code></pre> 
<p>This gives a compile-time error in C++20 because <code>d</code> is an invalid format specifier for a string.</p> 
<p><strong>Write a file from a single thread</strong></p> 
<pre><code class="language-c++">#include &lt;fmt/os.h&gt;

int main() {
  auto out = fmt::output_file("guide.txt");
  out.print("Don't {}", "Panic");
}
</code></pre> 
<p>This can be <a href="http://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html">5 to 9 times faster than fprintf</a>.</p> 
<p><strong>Print with colors and text styles</strong></p> 
<pre><code class="language-c++">#include &lt;fmt/color.h&gt;

int main() {
  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,
             "Hello, {}!\n", "world");
  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |
             fmt::emphasis::underline, "Olá, {}!\n", "Mundo");
  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,
             "你好{}！\n", "世界");
}
</code></pre> 
<p>Output on a modern terminal with Unicode support:</p> 
<p><img alt="image" src="https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7" /></p> 
<h1>Benchmarks</h1> 
<h2>Speed tests</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Library</th> 
   <th>Method</th> 
   <th>Run Time, s</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>libc</td> 
   <td>printf</td> 
   <td>0.91</td> 
  </tr> 
  <tr> 
   <td>libc++</td> 
   <td>std::ostream</td> 
   <td>2.49</td> 
  </tr> 
  <tr> 
   <td>{fmt} 9.1</td> 
   <td>fmt::print</td> 
   <td>0.74</td> 
  </tr> 
  <tr> 
   <td>Boost Format 1.80</td> 
   <td>boost::format</td> 
   <td>6.26</td> 
  </tr> 
  <tr> 
   <td>Folly Format</td> 
   <td>folly::format</td> 
   <td>1.87</td> 
  </tr> 
 </tbody> 
</table> 
<p>{fmt} is the fastest of the benchmarked methods, ~20% faster than <code>printf</code>.</p> 
<p>The above results were generated by building <code>tinyformat_test.cpp</code> on macOS 12.6.1 with <code>clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT</code>, and taking the best of three runs. In the test, the format string <code>"%0.10f:%04d:%+g:%s:%p:%c:%%\n"</code> or equivalent is filled 2,000,000 times with output sent to <code>/dev/null</code>; for further details refer to the <a href="https://github.com/fmtlib/format-benchmark/raw/master/src/tinyformat-test.cc">source</a>.</p> 
<p>{fmt} is up to 20-30x faster than <code>std::ostringstream</code> and <code>sprintf</code> on IEEE754 <code>float</code> and <code>double</code> formatting (<a href="https://github.com/fmtlib/dtoa-benchmark">dtoa-benchmark</a>) and faster than <a href="https://github.com/google/double-conversion">double-conversion</a> and <a href="https://github.com/ulfjack/ryu">ryu</a>:</p> 
<p><a href="https://fmt.dev/unknown_mac64_clang12.0.html"><img alt="image" src="https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png" /></a></p> 
<h2>Compile time and code bloat</h2> 
<p>The script <a href="https://github.com/fmtlib/format-benchmark/raw/master/bloat-test.py">bloat-test.py</a> from <a href="https://github.com/fmtlib/format-benchmark">format-benchmark</a> tests compile time and code bloat for nontrivial projects. It generates 100 translation units and uses <code>printf()</code> or its alternative five times in each to simulate a medium-sized project. The resulting executable size and compile time (Apple clang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown in the following tables.</p> 
<p><strong>Optimized build (-O3)</strong></p> 
<table> 
 <thead> 
  <tr> 
   <th>Method</th> 
   <th>Compile Time, s</th> 
   <th>Executable size, KiB</th> 
   <th>Stripped size, KiB</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>printf</td> 
   <td>1.6</td> 
   <td>54</td> 
   <td>50</td> 
  </tr> 
  <tr> 
   <td>IOStreams</td> 
   <td>25.9</td> 
   <td>98</td> 
   <td>84</td> 
  </tr> 
  <tr> 
   <td>fmt 83652df</td> 
   <td>4.8</td> 
   <td>54</td> 
   <td>50</td> 
  </tr> 
  <tr> 
   <td>tinyformat</td> 
   <td>29.1</td> 
   <td>161</td> 
   <td>136</td> 
  </tr> 
  <tr> 
   <td>Boost Format</td> 
   <td>55.0</td> 
   <td>530</td> 
   <td>317</td> 
  </tr> 
 </tbody> 
</table> 
<p>{fmt} is fast to compile and is comparable to <code>printf</code> in terms of per-call binary size (within a rounding error on this system).</p> 
<p><strong>Non-optimized build</strong></p> 
<table> 
 <thead> 
  <tr> 
   <th>Method</th> 
   <th>Compile Time, s</th> 
   <th>Executable size, KiB</th> 
   <th>Stripped size, KiB</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>printf</td> 
   <td>1.4</td> 
   <td>54</td> 
   <td>50</td> 
  </tr> 
  <tr> 
   <td>IOStreams</td> 
   <td>23.4</td> 
   <td>92</td> 
   <td>68</td> 
  </tr> 
  <tr> 
   <td>{fmt} 83652df</td> 
   <td>4.4</td> 
   <td>89</td> 
   <td>85</td> 
  </tr> 
  <tr> 
   <td>tinyformat</td> 
   <td>24.5</td> 
   <td>204</td> 
   <td>161</td> 
  </tr> 
  <tr> 
   <td>Boost Format</td> 
   <td>36.4</td> 
   <td>831</td> 
   <td>462</td> 
  </tr> 
 </tbody> 
</table> 
<p><code>libc</code>, <code>lib(std)c++</code>, and <code>libfmt</code> are all linked as shared libraries to compare formatting function overhead only. Boost Format is a header-only library so it doesn't provide any linkage options.</p> 
<h2>Running the tests</h2> 
<p>Please refer to <a href="https://fmt.dev/latest/get-started/#building-from-source">Building the library</a> for instructions on how to build the library and run the unit tests.</p> 
<p>Benchmarks reside in a separate repository, <a href="https://github.com/fmtlib/format-benchmark">format-benchmarks</a>, so to run the benchmarks you first need to clone this repository and generate Makefiles with CMake:</p> 
<pre><code>$ git clone --recursive https://github.com/fmtlib/format-benchmark.git
$ cd format-benchmark
$ cmake .
</code></pre> 
<p>Then you can run the speed test:</p> 
<pre><code>$ make speed-test
</code></pre> 
<p>or the bloat test:</p> 
<pre><code>$ make bloat-test
</code></pre> 
<h1>Migrating code</h1> 
<p><a href="https://clang.llvm.org/extra/clang-tidy/">clang-tidy</a> v18 provides the <a href="https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html">modernize-use-std-print</a> check that is capable of converting occurrences of <code>printf</code> and <code>fprintf</code> to <code>fmt::print</code> if configured to do so. (By default it converts to <code>std::print</code>.)</p> 
<h1>Notable projects using this library</h1> 
<ul> 
 <li><a href="https://play0ad.com/">0 A.D.</a>: a free, open-source, cross-platform real-time strategy game</li> 
 <li><a href="https://github.com/ampl/mp">AMPL/MP</a>: an open-source library for mathematical programming</li> 
 <li><a href="https://github.com/apple/foundationdb">Apple's FoundationDB</a>: an open-source, distributed, transactional key-value store</li> 
 <li><a href="https://github.com/aseprite/aseprite">Aseprite</a>: animated sprite editor &amp; pixel art tool</li> 
 <li><a href="https://www.aviobook.aero/en">AvioBook</a>: a comprehensive aircraft operations suite</li> 
 <li><a href="https://battle.net/">Blizzard Battle.net</a>: an online gaming platform</li> 
 <li><a href="https://celestia.space/">Celestia</a>: real-time 3D visualization of space</li> 
 <li><a href="https://ceph.com/">Ceph</a>: a scalable distributed storage system</li> 
 <li><a href="https://ccache.dev/">ccache</a>: a compiler cache</li> 
 <li><a href="https://github.com/ClickHouse/ClickHouse">ClickHouse</a>: an analytical database management system</li> 
 <li><a href="https://github.com/contour-terminal/contour/">Contour</a>: a modern terminal emulator</li> 
 <li><a href="https://cuauv.org/">CUAUV</a>: Cornell University's autonomous underwater vehicle</li> 
 <li><a href="https://drake.mit.edu/">Drake</a>: a planning, control, and analysis toolbox for nonlinear dynamical systems (MIT)</li> 
 <li><a href="https://github.com/envoyproxy/envoy">Envoy</a>: C++ L7 proxy and communication bus (Lyft)</li> 
 <li><a href="https://fivem.net/">FiveM</a>: a modification framework for GTA V</li> 
 <li><a href="https://github.com/MengRao/fmtlog">fmtlog</a>: a performant fmtlib-style logging library with latency in nanoseconds</li> 
 <li><a href="https://github.com/facebook/folly">Folly</a>: Facebook open-source library</li> 
 <li><a href="https://gemrb.org/">GemRB</a>: a portable open-source implementation of Bioware's Infinity Engine</li> 
 <li><a href="https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/">Grand Mountain Adventure</a>: a beautiful open-world ski &amp; snowboarding game</li> 
 <li><a href="https://github.com/pvpgn/pvpgn-server">HarpyWar/pvpgn</a>: Player vs Player Gaming Network with tweaks</li> 
 <li><a href="https://github.com/kbengine/kbengine">KBEngine</a>: an open-source MMOG server engine</li> 
 <li><a href="https://keypirinha.com/">Keypirinha</a>: a semantic launcher for Windows</li> 
 <li><a href="https://kodi.tv/">Kodi</a> (formerly xbmc): home theater software</li> 
 <li><a href="https://kth.cash/">Knuth</a>: high-performance Bitcoin full-node</li> 
 <li><a href="https://github.com/contour-terminal/libunicode/">libunicode</a>: a modern C++17 Unicode library</li> 
 <li><a href="https://mariadb.org/">MariaDB</a>: relational database management system</li> 
 <li><a href="https://github.com/microsoft/verona">Microsoft Verona</a>: research programming language for concurrent ownership</li> 
 <li><a href="https://mongodb.com/">MongoDB</a>: distributed document database</li> 
 <li><a href="https://github.com/duckie/mongo_smasher">MongoDB Smasher</a>: a small tool to generate randomized datasets</li> 
 <li><a href="https://openspaceproject.com/">OpenSpace</a>: an open-source astrovisualization framework</li> 
 <li><a href="https://www.polserver.com/">PenUltima Online (POL)</a>: an MMO server, compatible with most Ultima Online clients</li> 
 <li><a href="https://github.com/pytorch/pytorch">PyTorch</a>: an open-source machine learning library</li> 
 <li><a href="https://www.quasardb.net/">quasardb</a>: a distributed, high-performance, associative database</li> 
 <li><a href="https://github.com/odygrd/quill">Quill</a>: asynchronous low-latency logging library</li> 
 <li><a href="https://github.com/ravijanjam/qkw">QKW</a>: generalizing aliasing to simplify navigation, and execute complex multi-line terminal command sequences</li> 
 <li><a href="https://github.com/HunanTV/redis-cerberus">redis-cerberus</a>: a Redis cluster proxy</li> 
 <li><a href="https://vectorized.io/redpanda">redpanda</a>: a 10x faster Kafka® replacement for mission-critical systems written in C++</li> 
 <li><a href="http://rpclib.net/">rpclib</a>: a modern C++ msgpack-RPC server and client library</li> 
 <li><a href="https://www.salesforce.com/analytics-cloud/overview/">Salesforce Analytics Cloud</a>: business intelligence software</li> 
 <li><a href="https://www.scylladb.com/">Scylla</a>: a Cassandra-compatible NoSQL data store that can handle 1 million transactions per second on a single server</li> 
 <li><a href="http://www.seastar-project.org/">Seastar</a>: an advanced, open-source C++ framework for high-performance server applications on modern hardware</li> 
 <li><a href="https://github.com/gabime/spdlog">spdlog</a>: super fast C++ logging library</li> 
 <li><a href="https://www.stellar.org/">Stellar</a>: financial platform</li> 
 <li><a href="https://www.touchsurgery.com/">Touch Surgery</a>: surgery simulator</li> 
 <li><a href="https://github.com/TrinityCore/TrinityCore">TrinityCore</a>: open-source MMORPG framework</li> 
 <li><a href="https://userver.tech/">🐙 userver framework</a>: open-source asynchronous framework with a rich set of abstractions and database drivers</li> 
 <li><a href="https://github.com/microsoft/terminal">Windows Terminal</a>: the new Windows terminal</li> 
</ul> 
<p><a href="https://github.com/search?q=fmtlib&amp;type=Code">More...</a></p> 
<p>If you are aware of other projects using this library, please let me know by <a href="mailto:victor.zverovich@gmail.com">email</a> or by submitting an <a href="https://github.com/fmtlib/fmt/issues">issue</a>.</p> 
<h1>Motivation</h1> 
<p>So why yet another formatting library?</p> 
<p>There are plenty of methods for doing this task, from standard ones like the printf family of function and iostreams to Boost Format and FastFormat libraries. The reason for creating a new library is that every existing solution that I found either had serious issues or didn't provide all the features I needed.</p> 
<h2>printf</h2> 
<p>The good thing about <code>printf</code> is that it is pretty fast and readily available being a part of the C standard library. The main drawback is that it doesn't support user-defined types. <code>printf</code> also has safety issues although they are somewhat mitigated with <a href="https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html">__attribute__ ((format (printf, ...))</a> in GCC. There is a POSIX extension that adds positional arguments required for <a href="https://en.wikipedia.org/wiki/Internationalization_and_localization">i18n</a> to <code>printf</code> but it is not a part of C99 and may not be available on some platforms.</p> 
<h2>iostreams</h2> 
<p>The main issue with iostreams is best illustrated with an example:</p> 
<pre><code class="language-c++">std::cout &lt;&lt; std::setprecision(2) &lt;&lt; std::fixed &lt;&lt; 1.23456 &lt;&lt; "\n";
</code></pre> 
<p>which is a lot of typing compared to printf:</p> 
<pre><code class="language-c++">printf("%.2f\n", 1.23456);
</code></pre> 
<p>Matthew Wilson, the author of FastFormat, called this "chevron hell". iostreams don't support positional arguments by design.</p> 
<p>The good part is that iostreams support user-defined types and are safe although error handling is awkward.</p> 
<h2>Boost Format</h2> 
<p>This is a very powerful library that supports both <code>printf</code>-like format strings and positional arguments. Its main drawback is performance. According to various benchmarks, it is much slower than other methods considered here. Boost Format also has excessive build times and severe code bloat issues (see <a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#benchmarks">Benchmarks</a>).</p> 
<h2>FastFormat</h2> 
<p>This is an interesting library that is fast, safe and has positional arguments. However, it has significant limitations, citing its author:</p> 
<blockquote> 
 <p>Three features that have no hope of being accommodated within the current design are:</p> 
 <ul> 
  <li>Leading zeros (or any other non-space padding)</li> 
  <li>Octal/hexadecimal encoding</li> 
  <li>Runtime width/alignment specification</li> 
 </ul> 
</blockquote> 
<p>It is also quite big and has a heavy dependency, on STLSoft, which might be too restrictive for use in some projects.</p> 
<h2>Boost Spirit.Karma</h2> 
<p>This is not a formatting library but I decided to include it here for completeness. As iostreams, it suffers from the problem of mixing verbatim text with arguments. The library is pretty fast, but slower on integer formatting than <code>fmt::format_to</code> with format string compilation on Karma's own benchmark, see <a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html">Converting a hundred million integers to strings per second</a>.</p> 
<h1>License</h1> 
<p>{fmt} is distributed under the MIT <a href="https://github.com/fmtlib/fmt/raw/master/LICENSE">license</a>.</p> 
<h1>Documentation License</h1> 
<p>The <a href="https://fmt.dev/latest/syntax/">Format String Syntax</a> section in the documentation is based on the one from Python <a href="https://docs.python.org/3/library/string.html#module-string">string module documentation</a>. For this reason, the documentation is distributed under the Python Software Foundation license available in <a href="https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt">doc/python-license.txt</a>. It only applies if you distribute the documentation of {fmt}.</p> 
<h1>Maintainers</h1> 
<p>The {fmt} library is maintained by Victor Zverovich (<a href="https://github.com/vitaut">vitaut</a>) with contributions from many other people. See <a href="https://github.com/fmtlib/fmt/graphs/contributors">Contributors</a> and <a href="https://github.com/fmtlib/fmt/releases">Releases</a> for some of the names. Let us know if your contribution is not listed or mentioned incorrectly and we'll make it right.</p> 
<h1>Security Policy</h1> 
<p>To report a security issue, please disclose it at <a href="https://github.com/fmtlib/fmt/security/advisories/new">security advisory</a>.</p> 
<p>This project is maintained by a team of volunteers on a reasonable-effort basis. As such, please give us at least <em>90</em> days to work on a fix before public exposure.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>evcc-io/evcc</title>
<link>https://github.com/evcc-io/evcc</link>
<guid>https://github.com/evcc-io/evcc</guid>
<content:encoded><![CDATA[
<div> 关键词：evcc、充电控制器、能源管理系统、广泛兼容性、开源软件

总结:
evcc是一款功能全面的电动汽车充电控制器和家庭能源管理系统。它提供了一个简洁直观的用户界面，支持多种充电设备，包括但不限于ABL eMH1、Alfen（Eve）、Bender（CC612/613）等，并且兼容多种电网、光伏、电池和充电器系统。evcc不仅支持ModBus等通信协议，还提供广泛的集成服务，如与汽车制造商如奥迪、宝马、特斯拉等的车辆进行交互，以及与智能家居设备的连接。此外，evcc强调了其开源性质，鼓励供应商提供开放源代码硬件和文档，以支持像evcc这样的开源项目。为了持续开发和维护evcc，evcc接受赞助，并设有“赞助令牌”机制，以确保项目得到资金支持。 <div>
<p>Sonne tanken ☀️🚘</p><hr /><h1>evcc 🚘☀️</h1> 
<p><a href="https://github.com/evcc-io/evcc/actions/workflows/nightly.yml"><img alt="Build" src="https://github.com/evcc-io/evcc/actions/workflows/nightly.yml/badge.svg?sanitize=true" /></a> <a href="https://hosted.weblate.org/engage/evcc/"><img alt="Translation" src="https://hosted.weblate.org/widgets/evcc/-/evcc/svg-badge.svg?sanitize=true" /></a> <a href="https://open.vscode.dev/evcc-io/evcc"><img alt="Open in Visual Studio Code" src="https://img.shields.io/static/v1?logo=visualstudiocode&amp;label=&amp;message=Open%20in%20VS%20Code&amp;labelColor=2c2c32&amp;color=007acc&amp;logoColor=007acc" /></a> <a href="https://cloudsmith.io/~evcc/packages/"><img alt="OSS hosting by cloudsmith" src="https://img.shields.io/badge/OSS%20hosting%20by-cloudsmith-blue?logo=cloudsmith" /></a> <a href="https://github.com/evcc-io/evcc/releases"><img alt="Latest Version" src="https://img.shields.io/github/release/evcc-io/evcc.svg?sanitize=true" /></a></p> 
<p>evcc is an extensible EV Charge Controller and home energy management system. Featured in <a href="https://www.pv-magazine.de/2021/01/15/selbst-ist-der-groeoenlandhof-wallbox-ladesteuerung-selbst-gebaut/">PV magazine</a>.</p> 
<p><img alt="Screenshot" src="https://raw.githubusercontent.com/evcc-io/evcc/master/docs/screenshot.png" /></p> 
<h2>Features</h2> 
<ul> 
 <li>simple and clean user interface</li> 
 <li>wide range of supported <a href="https://docs.evcc.io/docs/devices/chargers">chargers</a>: 
  <ul> 
   <li>ABL eMH1, Alfen (Eve), Bender (CC612/613), cFos (PowerBrain), Daheimladen, Ebee (Wallbox), Ensto (Chago Wallbox), <a href="https://www.evse-wifi.de">EVSEWifi/ smartWB</a>, Garo (GLB, GLB+, LS4), go-eCharger, HardyBarth (eCB1, cPH1, cPH2), Heidelberg (Energy Control), Innogy (eBox), Juice (Charger Me), KEBA/BMW, Mennekes (Amedio, Amtron Premium/Xtra, Amtron ChargeConrol), older NRGkicks (before 2022/2023), NRGKick Gen2,<a href="https://openwb.de/">openWB (includes Pro)</a>, Optec (Mobility One), PC Electric (includes Garo), Siemens, TechniSat (Technivolt), <a href="https://www.warp-charger.com">Tinkerforge Warp Charger</a>, Ubitricity (Heinz), Vestel, Wallbe, Webasto (Live), Mobile Charger Connect and many more</li> 
   <li>experimental EEBus support (Elli, PMCC)</li> 
   <li>experimental OCPP support</li> 
   <li>Build-your-own: Phoenix Contact (includes ESL Walli), <a href="http://evracing.cz/simple-evse-wallbox">EVSE DIN</a></li> 
   <li>Smart-Home outlets: FritzDECT, Shelly, Tasmota, TP-Link</li> 
  </ul> </li> 
 <li>wide range of supported <a href="https://docs.evcc.io/docs/devices/meters">meters</a> for grid, pv, battery and charger: 
  <ul> 
   <li>ModBus: Eastron SDM, MPM3PM, ORNO WE, SBC ALE3 and many more, see <a href="https://github.com/volkszaehler/mbmd#supported-devices">https://github.com/volkszaehler/mbmd#supported-devices</a> for a complete list</li> 
   <li>Integrated systems: SMA Sunny Home Manager and Energy Meter, KOSTAL Smart Energy Meter (KSEM, EMxx)</li> 
   <li>Sunspec-compatible inverter or home battery devices: Fronius, SMA, SolarEdge, KOSTAL, STECA, E3DC, ...</li> 
   <li>and various others: Discovergy, Tesla PowerWall, LG ESS HOME, OpenEMS (FENECON)</li> 
  </ul> </li> 
 <li><a href="https://docs.evcc.io/docs/devices/vehicles">vehicle</a> integration (state of charge, remote charge, battery and preconditioning status): 
  <ul> 
   <li>Audi, BMW, Citroën, Dacia, Fiat, Ford, Hyundai, Jaguar, Kia, Landrover, Mercedes-Benz, Mini, Nissan, Opel, Peugeot, Porsche, Renault, Seat, Smart, Skoda, Tesla, Volkswagen, Volvo, ...</li> 
   <li>Services: OVMS, Tronity</li> 
   <li>Scooters: Niu, <del>Silence</del></li> 
  </ul> </li> 
 <li><a href="https://docs.evcc.io/docs/reference/plugins">plugins</a> for integrating with any charger/ meter/ vehicle: 
  <ul> 
   <li>Modbus, HTTP, MQTT, Javascript, WebSockets and shell scripts</li> 
  </ul> </li> 
 <li>status <a href="https://docs.evcc.io/docs/reference/configuration/messaging">notifications</a> using <a href="https://telegram.org">Telegram</a>, <a href="https://pushover.net">PushOver</a> and <a href="https://containrrr.dev/shoutrrr/">many more</a></li> 
 <li>logging using <a href="https://www.influxdata.com">InfluxDB</a> and <a href="https://grafana.com/grafana/">Grafana</a></li> 
 <li>granular charge power control down to mA steps with supported chargers (labeled by e.g. smartWB as <a href="https://board.evse-wifi.de/viewtopic.php?f=16&amp;t=187">OLC</a>)</li> 
 <li>REST and MQTT <a href="https://docs.evcc.io/docs/reference/api">APIs</a> for integration with home automation systems</li> 
 <li>Add-ons for <a href="https://github.com/evcc-io/evcc-hassio-addon">Home Assistant</a> and <a href="https://www.openhab.org/addons/bindings/evcc">OpenHAB</a> (not maintained by the evcc core team)</li> 
</ul> 
<h2>Getting Started</h2> 
<p>You'll find everything you need in our <a href="https://docs.evcc.io/">documentation</a>.</p> 
<h2>Contributing</h2> 
<p>Technical details on how to contribute, how to add translations and how to build evcc from source can be found <a href="https://raw.githubusercontent.com/evcc-io/evcc/master/CONTRIBUTING.md">here</a>.</p> 
<p><a href="https://hosted.weblate.org/engage/evcc/"><img alt="Weblate Hosted" src="https://hosted.weblate.org/widgets/evcc/-/evcc/287x66-grey.png" /></a></p> 
<h2>Sponsorship</h2> 
<img align="right" src="https://raw.githubusercontent.com/evcc-io/evcc/master/docs/logo.png" width="150" /> 
<p>evcc believes in open source software. We're committed to provide best in class EV charging experience. Maintaining evcc consumes time and effort. With the vast amount of different devices to support, we depend on community and vendor support to keep evcc alive.</p> 
<p>While evcc is open source, we would also like to encourage vendors to provide open source hardware devices, public documentation and support open source projects like ours that provide additional value to otherwise closed hardware. Where this is not the case, evcc requires "sponsor token" to finance ongoing development and support of evcc.</p> 
<p>The personal sponsor token requires a <a href="https://github.com/sponsors/evcc-io">Github Sponsorship</a> and can be requested at <a href="https://sponsor.evcc.io/">sponsor.evcc.io</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>projectdiscovery/nuclei</title>
<link>https://github.com/projectdiscovery/nuclei</link>
<guid>https://github.com/projectdiscovery/nuclei</guid>
<content:encoded><![CDATA[
<div> 关键词：Nuclei, 模板, 扫描, 命令行工具, 自动化

总结:

Nuclei是一款基于简单YAML DSL的快速可定制漏洞扫描器。其核心功能包括：

1. **模板驱动扫描**：Nuclei通过预定义的模板发送请求到目标，这些模板能够高效地执行安全检查，且能避免假阳性结果。

2. **广泛协议支持**：它支持多种网络协议如TCP、DNS、HTTP、SSL、文件系统、Whois查询、Websocket、无头浏览器、代码执行等，提供全面的安全检测能力。

3. **模板库**：项目提供了由超过300名安全研究人员和工程师贡献的模板库，持续更新以覆盖各种类型的安全检查。

4. **命令行界面**：作为主要的使用方式，Nuclei设计为CLI工具，提供丰富的命令行选项来配置扫描参数、控制输出、管理模板等。

5. **自动化与扩展性**：Nuclei通过自动下载和更新模板，支持自定义模板和工作流程，使得扫描任务能够高度自动化和灵活扩展。

通过上述功能，Nuclei旨在为安全团队提供一种高效、定制化的漏洞扫描解决方案，帮助他们在大规模主机上快速发现潜在的安全风险。 <div>
<p>Fast and customizable vulnerability scanner based on simple YAML based DSL.</p><hr /><h1 align="center"> <br /> <a href="https://nuclei.projectdiscovery.io"><img alt="Nuclei" src="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/static/nuclei-logo.png" width="200px" /></a> </h1> 
<h4 align="center">Fast and customisable vulnerability scanner based on simple YAML based DSL.</h4> 
<p align="center"> <img src="https://img.shields.io/github/go-mod/go-version/projectdiscovery/nuclei" /> <a href="https://github.com/projectdiscovery/nuclei/releases"><img src="https://img.shields.io/github/downloads/projectdiscovery/nuclei/total" /> </a><a href="https://github.com/projectdiscovery/nuclei/graphs/contributors"><img src="https://img.shields.io/github/contributors-anon/projectdiscovery/nuclei" /> </a><a href="https://github.com/projectdiscovery/nuclei/releases/"><img src="https://img.shields.io/github/release/projectdiscovery/nuclei" /> </a><a href="https://github.com/projectdiscovery/nuclei/issues"><img src="https://img.shields.io/github/issues-raw/projectdiscovery/nuclei" /> </a><a href="https://github.com/projectdiscovery/nuclei/discussions"><img src="https://img.shields.io/github/discussions/projectdiscovery/nuclei" /> </a><a href="https://discord.gg/projectdiscovery"><img src="https://img.shields.io/discord/695645237418131507.svg?logo=discord" /></a> <a href="https://twitter.com/pdnuclei"><img src="https://img.shields.io/twitter/follow/pdnuclei.svg?logo=twitter" /></a> </p> 
<p align="center"> <a href="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/#how-it-works">How</a> • <a href="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/#install-nuclei">Install</a> • <a href="https://docs.projectdiscovery.io/tools/nuclei/">Documentation</a> • <a href="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/#credits">Credits</a> • <a href="https://docs.projectdiscovery.io/tools/nuclei/faq">FAQs</a> • <a href="https://discord.gg/projectdiscovery">Join Discord</a> </p> 
<p align="center"> <a href="https://github.com/projectdiscovery/nuclei/raw/main/README.md">English</a> • <a href="https://github.com/projectdiscovery/nuclei/raw/main/README_CN.md">中文</a> • <a href="https://github.com/projectdiscovery/nuclei/raw/main/README_KR.md">Korean</a> • <a href="https://github.com/projectdiscovery/nuclei/raw/main/README_ID.md">Indonesia</a> • <a href="https://github.com/projectdiscovery/nuclei/raw/main/README_ES.md">Spanish</a> • <a href="https://github.com/projectdiscovery/nuclei/raw/main/README_JP.md">日本語</a> </p> 
<p></p> 
<hr /> 
<p>Nuclei is used to send requests across targets based on a template, leading to zero false positives and providing fast scanning on a large number of hosts. Nuclei offers scanning for a variety of protocols, including TCP, DNS, HTTP, SSL, File, Whois, Websocket, Headless, Code etc. With powerful and flexible templating, Nuclei can be used to model all kinds of security checks.</p> 
<p>We have a <a href="https://github.com/projectdiscovery/nuclei-templates">dedicated repository</a> that houses various type of vulnerability templates contributed by <strong>more than 300</strong> security researchers and engineers.</p> 
<h2>How it works</h2> 
<h3 align="center"> <img alt="nuclei-flow" src="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/static/nuclei-flow.jpg" width="700px" /> </h3> 
<table> 
 <thead> 
  <tr> 
   <th><span>❗</span> <strong>Disclaimer</strong></th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><strong>This project is in active development</strong>. Expect breaking changes with releases. Review the release changelog before updating.</td> 
  </tr> 
  <tr> 
   <td>This project was primarily built to be used as a standalone CLI tool. <strong>Running nuclei as a service may pose security risks.</strong> It's recommended to use with caution and additional security measures.</td> 
  </tr> 
 </tbody> 
</table> 
<h1>Install Nuclei</h1> 
<p>Nuclei requires <strong>go1.21</strong> to install successfully. Run the following command to install the latest version -</p> 
<pre><code class="language-sh">go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
</code></pre> 
<details> 
 Brew 
 <pre><code class="language-sh">brew install nuclei
</code></pre> 
</details> 
<details> 
 Docker 
 <pre><code class="language-sh">docker pull projectdiscovery/nuclei:latest
</code></pre> 
</details> 
<p><strong>More installation <a href="https://docs.projectdiscovery.io/tools/nuclei/install">methods can be found here</a>.</strong></p> 
<table> 
 <tbody>
  <tr> 
   <td> <h3>Nuclei Templates</h3> <p>Nuclei has built-in support for automatic template download/update as default since version <a href="https://github.com/projectdiscovery/nuclei/releases/tag/v2.5.2">v2.5.2</a>. <a href="https://github.com/projectdiscovery/nuclei-templates"><strong>Nuclei-Templates</strong></a> project provides a community-contributed list of ready-to-use templates that is constantly updated.</p> <p>You may still use the <code>update-templates</code> flag to update the nuclei templates at any time; You can write your own checks for your individual workflow and needs following Nuclei's <a href="https://docs.projectdiscovery.io/templates/">templating guide</a>.</p> <p>The YAML DSL reference syntax is available <a href="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/SYNTAX-REFERENCE.md">here</a>.</p> </td> 
  </tr> 
 </tbody>
</table> 
<h3>Usage</h3> 
<pre><code class="language-sh">nuclei -h
</code></pre> 
<p>This will display help for the tool. Here are all the switches it supports.</p> 
<pre><code class="language-console">Nuclei is a fast, template based vulnerability scanner focusing
on extensive configurability, massive extensibility and ease of use.

Usage:
  ./nuclei [flags]

Flags:
TARGET:
   -u, -target string[]          target URLs/hosts to scan
   -l, -list string              path to file containing a list of target URLs/hosts to scan (one per line)
   -eh, -exclude-hosts string[]  hosts to exclude to scan from the input list (ip, cidr, hostname)
   -resume string                resume scan using resume.cfg (clustering will be disabled)
   -sa, -scan-all-ips            scan all the IP's associated with dns record
   -iv, -ip-version string[]     IP version to scan of hostname (4,6) - (default 4)

TARGET-FORMAT:
   -im, -input-mode string        mode of input file (list, burp, jsonl, yaml, openapi, swagger) (default "list")
   -ro, -required-only            use only required fields in input format when generating requests
   -sfv, -skip-format-validation  skip format validation (like missing vars) when parsing input file

TEMPLATES:
   -nt, -new-templates                    run only new templates added in latest nuclei-templates release
   -ntv, -new-templates-version string[]  run new templates added in specific version
   -as, -automatic-scan                   automatic web scan using wappalyzer technology detection to tags mapping
   -t, -templates string[]                list of template or template directory to run (comma-separated, file)
   -turl, -template-url string[]          template url or list containing template urls to run (comma-separated, file)
   -w, -workflows string[]                list of workflow or workflow directory to run (comma-separated, file)
   -wurl, -workflow-url string[]          workflow url or list containing workflow urls to run (comma-separated, file)
   -validate                              validate the passed templates to nuclei
   -nss, -no-strict-syntax                disable strict syntax check on templates
   -td, -template-display                 displays the templates content
   -tl                                    list all available templates
   -tgl                                   list all available tags
   -sign                                  signs the templates with the private key defined in NUCLEI_SIGNATURE_PRIVATE_KEY env variable
   -code                                  enable loading code protocol-based templates
   -dut, -disable-unsigned-templates      disable running unsigned templates or templates with mismatched signature

FILTERING:
   -a, -author string[]               templates to run based on authors (comma-separated, file)
   -tags string[]                     templates to run based on tags (comma-separated, file)
   -etags, -exclude-tags string[]     templates to exclude based on tags (comma-separated, file)
   -itags, -include-tags string[]     tags to be executed even if they are excluded either by default or configuration
   -id, -template-id string[]         templates to run based on template ids (comma-separated, file, allow-wildcard)
   -eid, -exclude-id string[]         templates to exclude based on template ids (comma-separated, file)
   -it, -include-templates string[]   path to template file or directory to be executed even if they are excluded either by default or configuration
   -et, -exclude-templates string[]   path to template file or directory to exclude (comma-separated, file)
   -em, -exclude-matchers string[]    template matchers to exclude in result
   -s, -severity value[]              templates to run based on severity. Possible values: info, low, medium, high, critical, unknown
   -es, -exclude-severity value[]     templates to exclude based on severity. Possible values: info, low, medium, high, critical, unknown
   -pt, -type value[]                 templates to run based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript
   -ept, -exclude-type value[]        templates to exclude based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript
   -tc, -template-condition string[]  templates to run based on expression condition

OUTPUT:
   -o, -output string            output file to write found issues/vulnerabilities
   -sresp, -store-resp           store all request/response passed through nuclei to output directory
   -srd, -store-resp-dir string  store all request/response passed through nuclei to custom directory (default "output")
   -silent                       display findings only
   -nc, -no-color                disable output content coloring (ANSI escape codes)
   -j, -jsonl                    write output in JSONL(ines) format
   -irr, -include-rr -omit-raw   include request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only) [DEPRECATED use -omit-raw] (default true)
   -or, -omit-raw                omit request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only)
   -ot, -omit-template           omit encoded template in the JSON, JSONL output
   -nm, -no-meta                 disable printing result metadata in cli output
   -ts, -timestamp               enables printing timestamp in cli output
   -rdb, -report-db string       nuclei reporting database (always use this to persist report data)
   -ms, -matcher-status          display match failure status
   -me, -markdown-export string  directory to export results in markdown format
   -se, -sarif-export string     file to export results in SARIF format
   -je, -json-export string      file to export results in JSON format
   -jle, -jsonl-export string    file to export results in JSONL(ine) format
   -rd, -redact string[]         redact given list of keys from query parameter, request header and body

CONFIGURATIONS:
   -config string                        path to the nuclei configuration file
   -tp, -profile string                  template profile config file to run
   -tpl, -profile-list                   list community template profiles
   -fr, -follow-redirects                enable following redirects for http templates
   -fhr, -follow-host-redirects          follow redirects on the same host
   -mr, -max-redirects int               max number of redirects to follow for http templates (default 10)
   -dr, -disable-redirects               disable redirects for http templates
   -rc, -report-config string            nuclei reporting module configuration file
   -H, -header string[]                  custom header/cookie to include in all http request in header:value format (cli, file)
   -V, -var value                        custom vars in key=value format
   -r, -resolvers string                 file containing resolver list for nuclei
   -sr, -system-resolvers                use system DNS resolving as error fallback
   -dc, -disable-clustering              disable clustering of requests
   -passive                              enable passive HTTP response processing mode
   -fh2, -force-http2                    force http2 connection on requests
   -ev, -env-vars                        enable environment variables to be used in template
   -cc, -client-cert string              client certificate file (PEM-encoded) used for authenticating against scanned hosts
   -ck, -client-key string               client key file (PEM-encoded) used for authenticating against scanned hosts
   -ca, -client-ca string                client certificate authority file (PEM-encoded) used for authenticating against scanned hosts
   -sml, -show-match-line                show match lines for file templates, works with extractors only
   -ztls                                 use ztls library with autofallback to standard one for tls13 [Deprecated] autofallback to ztls is enabled by default
   -sni string                           tls sni hostname to use (default: input domain name)
   -dka, -dialer-keep-alive value        keep-alive duration for network requests.
   -lfa, -allow-local-file-access        allows file (payload) access anywhere on the system
   -lna, -restrict-local-network-access  blocks connections to the local / private network
   -i, -interface string                 network interface to use for network scan
   -at, -attack-type string              type of payload combinations to perform (batteringram,pitchfork,clusterbomb)
   -sip, -source-ip string               source ip address to use for network scan
   -rsr, -response-size-read int         max response size to read in bytes
   -rss, -response-size-save int         max response size to read in bytes (default 1048576)
   -reset                                reset removes all nuclei configuration and data files (including nuclei-templates)
   -tlsi, -tls-impersonate               enable experimental client hello (ja3) tls randomization
   -hae, -http-api-endpoint string       experimental http api endpoint

INTERACTSH:
   -iserver, -interactsh-server string  interactsh server url for self-hosted instance (default: oast.pro,oast.live,oast.site,oast.online,oast.fun,oast.me)
   -itoken, -interactsh-token string    authentication token for self-hosted interactsh server
   -interactions-cache-size int         number of requests to keep in the interactions cache (default 5000)
   -interactions-eviction int           number of seconds to wait before evicting requests from cache (default 60)
   -interactions-poll-duration int      number of seconds to wait before each interaction poll request (default 5)
   -interactions-cooldown-period int    extra time for interaction polling before exiting (default 5)
   -ni, -no-interactsh                  disable interactsh server for OAST testing, exclude OAST based templates

FUZZING:
   -ft, -fuzzing-type string     overrides fuzzing type set in template (replace, prefix, postfix, infix)
   -fm, -fuzzing-mode string     overrides fuzzing mode set in template (multiple, single)
   -fuzz                         enable loading fuzzing templates (Deprecated: use -dast instead)
   -dast                         enable / run dast (fuzz) nuclei templates
   -dfp, -display-fuzz-points    display fuzz points in the output for debugging
   -fuzz-param-frequency int     frequency of uninteresting parameters for fuzzing before skipping (default 10)
   -fa, -fuzz-aggression string  fuzzing aggression level controls payload count for fuzz (low, medium, high) (default "low")

UNCOVER:
   -uc, -uncover                  enable uncover engine
   -uq, -uncover-query string[]   uncover search query
   -ue, -uncover-engine string[]  uncover search engine (shodan,censys,fofa,shodan-idb,quake,hunter,zoomeye,netlas,criminalip,publicwww,hunterhow,google) (default shodan)
   -uf, -uncover-field string     uncover fields to return (ip,port,host) (default "ip:port")
   -ul, -uncover-limit int        uncover results to return (default 100)
   -ur, -uncover-ratelimit int    override ratelimit of engines with unknown ratelimit (default 60 req/min) (default 60)

RATE-LIMIT:
   -rl, -rate-limit int               maximum number of requests to send per second (default 150)
   -rld, -rate-limit-duration value   maximum number of requests to send per second (default 1s)
   -rlm, -rate-limit-minute int       maximum number of requests to send per minute (DEPRECATED)
   -bs, -bulk-size int                maximum number of hosts to be analyzed in parallel per template (default 25)
   -c, -concurrency int               maximum number of templates to be executed in parallel (default 25)
   -hbs, -headless-bulk-size int      maximum number of headless hosts to be analyzed in parallel per template (default 10)
   -headc, -headless-concurrency int  maximum number of headless templates to be executed in parallel (default 10)
   -jsc, -js-concurrency int          maximum number of javascript runtimes to be executed in parallel (default 120)
   -pc, -payload-concurrency int      max payload concurrency for each template (default 25)
   -prc, -probe-concurrency int       http probe concurrency with httpx (default 50)

OPTIMIZATIONS:
   -timeout int                     time to wait in seconds before timeout (default 10)
   -retries int                     number of times to retry a failed request (default 1)
   -ldp, -leave-default-ports       leave default HTTP/HTTPS ports (eg. host:80,host:443)
   -mhe, -max-host-error int        max errors for a host before skipping from scan (default 30)
   -te, -track-error string[]       adds given error to max-host-error watchlist (standard, file)
   -nmhe, -no-mhe                   disable skipping host from scan based on errors
   -project                         use a project folder to avoid sending same request multiple times
   -project-path string             set a specific project path (default "/tmp")
   -spm, -stop-at-first-match       stop processing HTTP requests after the first match (may break template/workflow logic)
   -stream                          stream mode - start elaborating without sorting the input
   -ss, -scan-strategy value        strategy to use while scanning(auto/host-spray/template-spray) (default auto)
   -irt, -input-read-timeout value  timeout on input read (default 3m0s)
   -nh, -no-httpx                   disable httpx probing for non-url input
   -no-stdin                        disable stdin processing

HEADLESS:
   -headless                        enable templates that require headless browser support (root user on Linux will disable sandbox)
   -page-timeout int                seconds to wait for each page in headless mode (default 20)
   -sb, -show-browser               show the browser on the screen when running templates with headless mode
   -ho, -headless-options string[]  start headless chrome with additional options
   -sc, -system-chrome              use local installed Chrome browser instead of nuclei installed
   -lha, -list-headless-action      list available headless actions

DEBUG:
   -debug                    show all requests and responses
   -dreq, -debug-req         show all sent requests
   -dresp, -debug-resp       show all received responses
   -p, -proxy string[]       list of http/socks5 proxy to use (comma separated or file input)
   -pi, -proxy-internal      proxy all internal requests
   -ldf, -list-dsl-function  list all supported DSL function signatures
   -tlog, -trace-log string  file to write sent requests trace log
   -elog, -error-log string  file to write sent requests error log
   -version                  show nuclei version
   -hm, -hang-monitor        enable nuclei hang monitoring
   -v, -verbose              show verbose output
   -profile-mem string       optional nuclei memory profile dump file
   -vv                       display templates loaded for scan
   -svd, -show-var-dump      show variables dump for debugging
   -ep, -enable-pprof        enable pprof debugging server
   -tv, -templates-version   shows the version of the installed nuclei-templates
   -hc, -health-check        run diagnostic check up

UPDATE:
   -up, -update                      update nuclei engine to the latest released version
   -ut, -update-templates            update nuclei-templates to latest released version
   -ud, -update-template-dir string  custom directory to install / update nuclei-templates
   -duc, -disable-update-check       disable automatic nuclei/templates update check

STATISTICS:
   -stats                    display statistics about the running scan
   -sj, -stats-json          display statistics in JSONL(ines) format
   -si, -stats-interval int  number of seconds to wait between showing a statistics update (default 5)
   -mp, -metrics-port int    port to expose nuclei metrics on (default 9092)

CLOUD:
   -auth                      configure projectdiscovery cloud (pdcp) api key (default true)
   -tid, -team-id string      upload scan results to given team id (optional) (default "none")
   -cup, -cloud-upload        upload scan results to pdcp dashboard
   -sid, -scan-id string      upload scan results to existing scan id (optional)
   -sname, -scan-name string  scan name to set (optional)

AUTHENTICATION:
   -sf, -secret-file string[]  path to config file containing secrets for nuclei authenticated scan
   -ps, -prefetch-secrets      prefetch secrets from the secrets file


EXAMPLES:
Run nuclei on single host:
   $ nuclei -target example.com

Run nuclei with specific template directories:
   $ nuclei -target example.com -t http/cves/ -t ssl

Run nuclei against a list of hosts:
   $ nuclei -list hosts.txt

Run nuclei with a JSON output:
   $ nuclei -target example.com -json-export output.json

Run nuclei with sorted Markdown outputs (with environment variables):
   $ MARKDOWN_EXPORT_SORT_MODE=template nuclei -target example.com -markdown-export nuclei_report/

Additional documentation is available at: https://docs.nuclei.sh/getting-started/running
</code></pre> 
<h3>Running Nuclei</h3> 
<p>See <a href="https://docs.projectdiscovery.io/tools/nuclei/running">https://docs.projectdiscovery.io/tools/nuclei/running</a> for details on running Nuclei</p> 
<h3>Using Nuclei From Go Code</h3> 
<p>Complete guide of using Nuclei as Library/SDK is available at <a href="https://pkg.go.dev/github.com/projectdiscovery/nuclei/v3/lib#section-readme">godoc</a></p> 
<h3>Resources</h3> 
<p>You can access the main documentation for Nuclei at <a href="https://docs.projectdiscovery.io/tools/nuclei/">https://docs.projectdiscovery.io/tools/nuclei/</a>, and learn more about Nuclei in the cloud with <a href="https://cloud.projectdiscovery.io">ProjectDiscovery Cloud Platform</a></p> 
<p>See <a href="https://docs.projectdiscovery.io/tools/nuclei/resources">https://docs.projectdiscovery.io/tools/nuclei/resources</a> for more resources and videos about Nuclei!</p> 
<h3>Credits</h3> 
<p>Thanks to all the amazing <a href="https://github.com/projectdiscovery/nuclei/graphs/contributors">community contributors for sending PRs</a> and keeping this project updated. <span>❤️</span></p> 
<p>If you have an idea or some kind of improvement, you are welcome to contribute and participate in the Project, feel free to send your PR.</p> 
<p align="center"> <a href="https://github.com/projectdiscovery/nuclei/graphs/contributors"> <img src="https://contrib.rocks/image?repo=projectdiscovery/nuclei&amp;max=500" /> </a> </p> 
<p>Do also check out the below similar open-source projects that may fit in your workflow:</p> 
<p><a href="https://github.com/ffuf/ffuf">FFuF</a>, <a href="https://github.com/ameenmaali/qsfuzz">Qsfuzz</a>, <a href="https://github.com/proabiral/inception">Inception</a>, <a href="https://github.com/hannob/snallygaster">Snallygaster</a>, <a href="https://github.com/Static-Flow/gofingerprint">Gofingerprint</a>, <a href="https://github.com/1N3/Sn1per/tree/master/templates">Sn1per</a>, <a href="https://github.com/google/tsunami-security-scanner">Google tsunami</a>, <a href="https://github.com/jaeles-project/jaeles">Jaeles</a>, <a href="https://github.com/michelin/ChopChop">ChopChop</a></p> 
<h3>License</h3> 
<p>Nuclei is distributed under <a href="https://github.com/projectdiscovery/nuclei/raw/main/LICENSE.md">MIT License</a></p> 
<h1 align="left"> <a href="https://discord.gg/projectdiscovery"><img alt="Join Discord" src="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/static/Join-Discord.png" width="380" /></a> <a href="https://docs.projectdiscovery.io"><img alt="Check Nuclei Documentation" src="https://raw.githubusercontent.com/projectdiscovery/nuclei/dev/static/check-nuclei-documentation.png" width="380" /></a> </h1>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>spotDL/spotify-downloader</title>
<link>https://github.com/spotDL/spotify-downloader</link>
<guid>https://github.com/spotDL/spotify-downloader</guid>
<content:encoded><![CDATA[
<div> 关键词：spotDL、Spotify、YouTube、下载、命令行

文章总结：

spotDL是一个用于从Spotify播放列表中下载歌曲的工具，它可以从YouTube查找并下载歌曲，同时附带专辑艺术、歌词和元数据。安装可以通过pip进行，推荐使用pip3在某些系统上。对于其他操作系统，可以使用预构建可执行文件、Termux脚本、Docker容器或从源代码编译。FFmpeg是必需的，可以通过在spotDL安装目录下安装或系统级安装（如在OSX上使用brew，或在Linux上使用apt）来获取。

在使用spotDL时，用户可以运行无选项的下载操作，也可以使用各种选项来定制下载行为，如保存元数据、获取直接下载链接、同步目录以保持与Spotify播放列表一致、更新歌曲文件的元数据等。spotDL从YouTube下载音乐，以避免与Spotify相关的任何法律问题，通常提供最高比特率（128kbps对普通用户，256kbps对YouTube音乐高级用户）的音质。

贡献者可以查看贡献资源和开发环境指南，加入社区，支持软件的开发和维护。此项目遵循开源许可证。

最后，用户需要确保他们的行为符合版权法，并承担可能的法律责任。 <div>
<p>Download your Spotify playlists and songs along with album art and metadata (from YouTube if a match is found).</p><hr /><div align="center"> 
 <h1>spotDL v4</h1> 
 <p><strong>spotDL</strong> finds songs from Spotify playlists on YouTube and downloads them - along with album art, lyrics and metadata.</p> 
 <p><a href="https://github.com/spotDL/spotify-downloader/raw/master/LICENSE"><img alt="MIT License" src="https://img.shields.io/github/license/spotdl/spotify-downloader?color=44CC11&amp;style=flat-square" /></a> <a href="https://pypi.org/project/spotdl/"><img alt="PyPI version" src="https://img.shields.io/pypi/pyversions/spotDL?color=%2344CC11&amp;style=flat-square" /></a> <a href="https://pypi.org/project/spotdl/"><img alt="PyPi downloads" src="https://img.shields.io/pypi/dw/spotDL?label=downloads@pypi&amp;color=344CC11&amp;style=flat-square" /></a> <img alt="Contributors" src="https://img.shields.io/github/contributors/spotDL/spotify-downloader?style=flat-square" /> <a href="https://discord.gg/xCa23pwJWY"><img alt="Discord" src="https://img.shields.io/discord/771628785447337985?label=discord&amp;logo=discord&amp;style=flat-square" /></a></p> 
 <blockquote> 
  <p>spotDL: The fastest, easiest and most accurate command-line music downloader.</p> 
 </blockquote> 
</div> 
<hr /> 
<p><strong><a href="https://spotdl.readthedocs.io">Read the documentation on ReadTheDocs!</a></strong></p> 
<hr /> 
<h2>Installation</h2> 
<p>Refer to our <a href="https://spotdl.rtfd.io/en/latest/installation/">Installation Guide</a> for more details.</p> 
<h3>Python (Recommended Method)</h3> 
<ul> 
 <li><em>spotDL</em> can be installed by running <code>pip install spotdl</code>.</li> 
 <li>To update spotDL run <code>pip install --upgrade spotdl</code></li> 
</ul> 
<blockquote> 
 <p>On some systems you might have to change <code>pip</code> to <code>pip3</code>.</p> 
</blockquote> 
<details> 
 <strong>Other options</strong> 
 <ul> 
  <li> <p>Prebuilt executable</p> 
   <ul> 
    <li>You can download the latest version from the <a href="https://github.com/spotDL/spotify-downloader/releases">Releases Tab</a></li> 
   </ul> </li> 
  <li> <p>On Termux</p> 
   <ul> 
    <li><code>curl -L https://raw.githubusercontent.com/spotDL/spotify-downloader/master/scripts/termux.sh | sh</code></li> 
   </ul> </li> 
  <li> <p>Arch</p> 
   <ul> 
    <li>There is an <a href="https://aur.archlinux.org/packages/python-spotdl/">Arch User Repository (AUR) package</a> for spotDL.</li> 
   </ul> </li> 
  <li> <p>Docker</p> 
   <ul> 
    <li> <p>Build image:</p> <pre><code class="language-bash">docker build -t spotdl .
</code></pre> </li> 
    <li> <p>Launch container with spotDL parameters (see section below). You need to create mapped volume to access song files</p> <pre><code class="language-bash">docker run --rm -v $(pwd):/music spotdl download [trackUrl]
</code></pre> </li> 
   </ul> </li> 
  <li> <p>Build from source</p> <pre><code class="language-bash">git clone https://github.com/spotDL/spotify-downloader &amp;&amp; cd spotify-downloader
pip install poetry
poetry install
poetry run python3 scripts/build.py
</code></pre> <p>An executable is created in <code>spotify-downloader/dist/</code>.</p> </li> 
 </ul> 
</details> 
<h3>Installing FFmpeg</h3> 
<p>FFmpeg is required for spotDL. If using FFmpeg only for spotDL, you can simply install FFmpeg to your spotDL installation directory: <code>spotdl --download-ffmpeg</code></p> 
<p>We recommend the above option, but if you want to install FFmpeg system-wide, follow these instructions</p> 
<ul> 
 <li><a href="https://windowsloop.com/install-ffmpeg-windows-10/">Windows Tutorial</a></li> 
 <li>OSX - <code>brew install ffmpeg</code></li> 
 <li>Linux - <code>sudo apt install ffmpeg</code> or use your distro's package manager</li> 
</ul> 
<h2>Usage</h2> 
<p>Using SpotDL without options::</p> 
<pre><code class="language-sh">spotdl [urls]
</code></pre> 
<p>You can run <em>spotDL</em> as a package if running it as a script doesn't work:</p> 
<pre><code class="language-sh">python -m spotdl [urls]
</code></pre> 
<p>General usage:</p> 
<pre><code class="language-sh">spotdl [operation] [options] QUERY
</code></pre> 
<p>There are different <strong>operations</strong> spotDL can perform. The <em>default</em> is <code>download</code>, which simply downloads the songs from YouTube and embeds metadata.</p> 
<p>The <strong>query</strong> for spotDL is usually a list of Spotify URLs, but for some operations like <strong>sync</strong>, only a single link or file is required. For a list of all <strong>options</strong> use <code>spotdl -h</code></p> 
<details> 
 <strong>Supported operations</strong> 
 <ul> 
  <li> <p><code>save</code>: Saves only the metadata from Spotify without downloading anything.</p> 
   <ul> 
    <li>Usage: <code>spotdl save [query] --save-file {filename}.spotdl</code></li> 
   </ul> </li> 
  <li> <p><code>web</code>: Starts a web interface instead of using the command line. However, it has limited features and only supports downloading single songs.</p> </li> 
  <li> <p><code>url</code>: Get direct download link for each song from the query.</p> 
   <ul> 
    <li>Usage: <code>spotdl url [query]</code></li> 
   </ul> </li> 
  <li> <p><code>sync</code>: Updates directories. Compares the directory with the current state of the playlist. Newly added songs will be downloaded and removed songs will be deleted. No other songs will be downloaded and no other files will be deleted.</p> 
   <ul> 
    <li> <p>Usage: <code>spotdl sync [query] --save-file {filename}.spotdl</code></p> <p>This create a new <strong>sync</strong> file, to update the directory in the future, use:</p> <p><code>spotdl sync {filename}.spotdl</code></p> </li> 
   </ul> </li> 
  <li> <p><code>meta</code>: Updates metadata for the provided song files.</p> </li> 
 </ul> 
</details> 
<h2>Music Sourcing and Audio Quality</h2> 
<p>spotDL uses YouTube as a source for music downloads. This method is used to avoid any issues related to downloading music from Spotify.</p> 
<blockquote> 
 <p><strong>Note</strong> Users are responsible for their actions and potential legal consequences. We do not support unauthorized downloading of copyrighted material and take no responsibility for user actions.</p> 
</blockquote> 
<h3>Audio Quality</h3> 
<p>spotDL downloads music from YouTube and is designed to always download the highest possible bitrate; which is 128 kbps for regular users and 256 kbps for YouTube Music premium users.</p> 
<p>Check the <a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/usage.md#audio-formats-and-quality">Audio Formats</a> page for more info.</p> 
<h2>Contributing</h2> 
<p>Interested in contributing? Check out our <a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/CONTRIBUTING.md">CONTRIBUTING.md</a> to find resources around contributing along with a guide on how to set up a development environment.</p> 
<h4>Join our amazing community as a code contributor, and help accelerate</h4> 
<p><br /><br /> <a href="https://github.com/spotDL/spotify-downloader/graphs/contributors"> <img class="dark-light" src="https://contrib.rocks/image?repo=spotDL/spotify-downloader&amp;anon=0&amp;columns=25&amp;max=100&amp;r=true" /> </a></p> 
<h2>Donate</h2> 
<p>help support the development and maintenance of the software ❤️</p> 
<p><a href="https://paypal.me/kko7"><img alt="paypal" src="https://img.shields.io/badge/paypal-%2300457C.svg?&amp;style=for-the-badge&amp;logo=paypal&amp;logoColor=white" /></a> <a href="https://ko-fi.com/xnetcat"><img alt="kofi" src="https://img.shields.io/badge/kofi-%23F16061.svg?&amp;style=for-the-badge&amp;logo=ko-fi&amp;logoColor=white" /></a></p> 
<h2>License</h2> 
<p>This project is Licensed under the <a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/LICENSE">MIT</a> License.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>bunkerity/bunkerweb</title>
<link>https://github.com/bunkerity/bunkerweb</link>
<guid>https://github.com/bunkerity/bunkerweb</guid>
<content:encoded><![CDATA[
<div> 关键词：BunkerWeb、Web应用防火墙（WAF）、免费开源、自动化安全、专业服务

总结:

BunkerWeb是一款下一代的免费开源Web应用防火墙(WAF)，旨在为您的网络服务提供“默认即安全”的保护。它基于NGINX构建，无缝集成到Linux、Docker、Swarm、Kubernetes等环境中，高度可定制以满足特定需求。BunkerWeb内置基本安全功能，并可通过插件系统扩展更多安全措施。其特点包括：

1. **易于集成**：BunkerWeb支持多种环境，如Linux、Docker、Swarm和Kubernetes，轻松与现有系统结合。

2. **高度可定制性**：用户可以根据需要启用、禁用或配置功能，实现个性化的安全设置。

3. **默认安全**：提供预设的安全配置，无需复杂设置即可快速启动保护。

4. **用户界面友好**：通过直观的Web界面管理配置，简化操作，无需命令行知识。

5. **专业服务**：提供技术支持、咨询和定制开发服务，确保用户获得最佳安全体验。

BunkerWeb致力于为用户提供强大、灵活且易于管理的网络安全解决方案，通过集成自动化安全功能和专业支持，帮助用户有效保护其网络服务免受威胁。 <div>
<p>🛡️ Open-source and next-generation Web Application Firewall (WAF)</p><hr /><p align="center"> <img alt="BunkerWeb logo" height="100" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/misc/logo.png" width="350" /> </p> 
<p align="center"> <img src="https://img.shields.io/github/v/release/bunkerity/bunkerweb?label=stable" /> <img src="https://img.shields.io/github/v/release/bunkerity/bunkerweb?include_prereleases&amp;label=latest" /> <br /> <img src="https://img.shields.io/github/last-commit/bunkerity/bunkerweb" /> <img src="https://img.shields.io/github/issues/bunkerity/bunkerweb" /> <img src="https://img.shields.io/github/issues-pr/bunkerity/bunkerweb" /> <br /> <img src="https://img.shields.io/github/actions/workflow/status/bunkerity/bunkerweb/dev.yml?branch=dev&amp;label=CI%2FCD%20dev" /> <img src="https://img.shields.io/github/actions/workflow/status/bunkerity/bunkerweb/staging.yml?branch=staging&amp;label=CI%2FCD%20staging" /> <a href="https://www.bestpractices.dev/projects/8001"> <img src="https://www.bestpractices.dev/projects/8001/badge" /> </a> </p> 
<p align="center"> 🌐 <a href="https://www.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Website</a> | 🤝 <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Panel</a> | 📓 <a href="https://docs.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Documentation</a> | 👨‍💻 <a href="https://demo.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Demo</a> | 🛡️ <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/examples">Examples</a> | 💬 <a href="https://discord.com/invite/fTf46FmtyD">Chat</a> | 📝 <a href="https://github.com/bunkerity/bunkerweb/discussions">Forum</a> <br /> ⚙️ <a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Configurator</a> | 🗺️ <a href="https://threatmap.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Threatmap</a> | 🔎 <a href="https://forms.gle/e3VgymAteYPnwM1j9">Feedbacks</a> </p> 
<blockquote> 
 <p>🛡️ Make security by default great again !</p> 
</blockquote> 
<h1>BunkerWeb</h1> 
<p align="center"> <img alt="Overview banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/intro-overview.svg?sanitize=true" /> </p> 
<p>BunkerWeb is a next-generation and open-source Web Application Firewall (WAF).</p> 
<p>Being a full-featured web server (based on <a href="https://nginx.org/">NGINX</a> under the hood), it will protect your web services to make them "secure by default". BunkerWeb integrates seamlessly into your existing environments (<a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#linux">Linux</a>, <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#docker">Docker</a>, <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#swarm">Swarm</a>, <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#kubernetes">Kubernetes</a>, …) and is fully configurable (don't panic, there is an <a href="https://docs.bunkerweb.io/1.5.9/web-ui/?utm_campaign=self&amp;utm_source=github">awesome web UI</a> if you don't like the CLI) to meet your own use-cases . In other words, cybersecurity is no more a hassle.</p> 
<p>BunkerWeb contains primary <a href="https://docs.bunkerweb.io/1.5.9/security-tuning/?utm_campaign=self&amp;utm_source=github">security features</a> as part of the core but can be easily extended with additional ones thanks to a <a href="https://docs.bunkerweb.io/1.5.9/plugins/?utm_campaign=self&amp;utm_source=github">plugin system</a>.</p> 
<h2>Why BunkerWeb ?</h2> 
<ul> 
 <li><strong>Easy integration into existing environments</strong> : Seamlessly integrate BunkerWeb into various environments such as Linux, Docker, Swarm, Kubernetes and more. Enjoy a smooth transition and hassle-free implementation.</li> 
 <li><strong>Highly customizable</strong> : Tailor BunkerWeb to your specific requirements with ease. Enable, disable, and configure features effortlessly, allowing you to customize the security settings according to your unique use case.</li> 
 <li><strong>Secure by default</strong> : BunkerWeb provides out-of-the-box, hassle-free minimal security for your web services. Experience peace of mind and enhanced protection right from the start.</li> 
 <li><strong>Awesome web UI</strong> : Take control of BunkerWeb more efficiently with the exceptional web user interface (UI). Navigate settings and configurations effortlessly through a user-friendly graphical interface, eliminating the need for the command-line interface (CLI).</li> 
 <li><strong>Plugin system</strong> : Extend the capabilities of BunkerWeb to meet your own use cases. Seamlessly integrate additional security measures and customize the functionality of BunkerWeb according to your specific requirements.</li> 
 <li><strong>Free as in "freedom"</strong> : BunkerWeb is licensed under the free <a href="https://www.gnu.org/licenses/agpl-3.0.en.html">AGPLv3 license</a>, embracing the principles of freedom and openness. Enjoy the freedom to use, modify, and distribute the software, backed by a supportive community.</li> 
 <li><strong>Professional services</strong> : Get technical support, tailored consulting and custom development directly from the maintainers of BunkerWeb. Visit the <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">Bunker Panel</a> for more information.</li> 
</ul> 
<h2>Security features</h2> 
<p>A non-exhaustive list of security features :</p> 
<ul> 
 <li><strong>HTTPS</strong> support with transparent <strong>Let's Encrypt</strong> automation</li> 
 <li><strong>State-of-the-art web security</strong> : HTTP security headers, prevent leaks, TLS hardening, ...</li> 
 <li>Integrated <strong>ModSecurity WAF</strong> with the <strong>OWASP Core Rule Set</strong></li> 
 <li><strong>Automatic ban</strong> of strange behaviors based on HTTP status code</li> 
 <li>Apply <strong>connections and requests limit</strong> for clients</li> 
 <li><strong>Block bots</strong> by asking them to solve a <strong>challenge</strong> (e.g. : cookie, javascript, captcha, hCaptcha or reCAPTCHA)</li> 
 <li><strong>Block known bad IPs</strong> with external blacklists and DNSBL</li> 
 <li>And much more ...</li> 
</ul> 
<p>Learn more about the core security features in the <a href="https://docs.bunkerweb.io/1.5.9/security-tuning/?utm_campaign=self&amp;utm_source=github">security tuning</a> section of the documentation.</p> 
<h2>Demo</h2> 
<p align="center"> <a href="https://www.youtube.com/watch?v=ZhYV-QELzA4" target="_blank"><img alt="BunkerWeb demo" src="https://img.youtube.com/vi/ZhYV-QELzA4/0.jpg" /></a> </p> 
<p>A demo website protected with BunkerWeb is available at <a href="https://demo.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">demo.bunkerweb.io</a>. Feel free to visit it and perform some security tests.</p> 
<h2>BunkerWeb Cloud</h2> 
<p>Don't want to self-host and manage your own BunkerWeb instance(s) ? You might be interested into BunkerWeb Cloud, our fully managed SaaS offer for BunkerWeb.</p> 
<p>Try our <a href="https://panel.bunkerweb.io/order/bunkerweb-cloud/14?utm_source=github&amp;utm_campaign=self">BunkerWeb Cloud beta offer for free</a> and get access to :</p> 
<ul> 
 <li>Fully managed BunkerWeb instance hosted in our cloud</li> 
 <li>All BunkerWeb features including PRO ones</li> 
 <li>Monitoring platform including dashboards and alerts</li> 
 <li>Technical support to assist you in the configuration</li> 
</ul> 
<p>You will find more information about BunkerWeb Cloud in the <a href="https://panel.bunkerweb.io/knowledgebase/55/BunkerWeb-Cloud?utm_source=github&amp;utm_campaign=self">FAQ page</a> of the BunkerWeb panel.</p> 
<h2>PRO version</h2> 
<p>When using BunkerWeb you have the choice of the version you want to use : open-source or PRO.</p> 
<p>Whether it's enhanced security, an enriched user experience, or technical supervision, the BunkerWeb PRO version will allow you to fully benefit from BunkerWeb and respond to your professional needs.</p> 
<p>Be it in the documentation or the user interface, the PRO features are annotated with a crown <img alt="crow pro icon" height="24px" src="https://docs.bunkerweb.io/1.5.9/assets/img/pro-icon.svg?sanitize=true" width="24px" /> to distinguish them from those integrated into the open-source version.</p> 
<p>You can upgrade from the open-source version to the PRO one easily and at any time you want. The process is pretty straightforward :</p> 
<ul> 
 <li>Claim your <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=doc">free trial on the BunkerWeb panel</a></li> 
 <li>Once connected to the client area, copy your PRO license key</li> 
 <li>Paste your private key into BunkerWeb using the <a href="https://docs.bunkerweb.io/1.5.9/web-ui/#upgrade-to-pro">web UI</a> or <a href="https://docs.bunkerweb.io/1.5.9/settings/#pro">specific setting</a></li> 
</ul> 
<p>Do not hesitate to visit the <a href="https://panel.bunkerweb.io/knowledgebase?utm_campaign=self&amp;utm_source=doc">BunkerWeb panel</a> or <a href="https://panel.bunkerweb.io/contact.php?utm_campaign=self&amp;utm_source=doc">contact us</a> if you have any question regarding the PRO version.</p> 
<h2>Professional services</h2> 
<p>Get the most of BunkerWeb by getting professional services directly from the maintainers of the project. From technical support to tailored consulting and development, we are here to assist you in the security of your web services.</p> 
<p>You will find more information by visiting the <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=doc">BunkerWeb Panel</a>, our dedicated platform for professional services.</p> 
<p>Don't hesitate to <a href="https://panel.bunkerweb.io/contact.php?utm_campaign=self&amp;utm_source=doc">contact us</a> if you have any question, we will be more than happy to respond to your needs.</p> 
<h2>Ecosystem, community and resources</h2> 
<p>Official websites, tools and resources about BunkerWeb :</p> 
<ul> 
 <li><a href="https://www.bunkerweb.io/?utm_campaign=self&amp;utm_source=github"><strong>Website</strong></a> : get more information, news and articles about BunkerWeb</li> 
 <li><a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github"><strong>Panel</strong></a> : dedicated platform to order and manage professional services (e.g. technical support) around BunkerWeb</li> 
 <li><a href="https://docs.bunkerweb.io/?utm_campaign=self&amp;utm_source=github"><strong>Documentation</strong></a> : technical documentation of the BunkerWeb solution</li> 
 <li><a href="https://demo.bunkerweb.io/?utm_campaign=self&amp;utm_source=github"><strong>Demo</strong></a> : demonstration website of BunkerWeb, don't hesitate to attempt attacks to test the robustness of the solution</li> 
 <li><a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github"><strong>Configurator</strong></a> : user-friendly tool to help you configure BunkerWeb</li> 
 <li><a href="https://threatmap.bunkerweb.io/?utm_campaign=self&amp;utm_source=github"><strong>Threatmap</strong></a> : live cyber attack blocked by BunkerWeb instances all around the world</li> 
</ul> 
<p>Community and social networks :</p> 
<ul> 
 <li><a href="https://discord.com/invite/fTf46FmtyD"><strong>Discord</strong></a></li> 
 <li><a href="https://www.linkedin.com/company/bunkerity/"><strong>LinkedIn</strong></a></li> 
 <li><a href="https://twitter.com/bunkerity"><strong>Twitter</strong></a></li> 
 <li><a href="https://www.reddit.com/r/BunkerWeb/"><strong>Reddit</strong></a></li> 
</ul> 
<h1>Concepts</h1> 
<p align="center"> <img alt="Concepts banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/concepts.svg?sanitize=true" /> </p> 
<p>You will find more information about the key concepts of BunkerWeb in the <a href="https://docs.bunkerweb.io/1.5.9/concepts/?utm_campaign=self&amp;utm_source=github">documentation</a>.</p> 
<h2>Integrations</h2> 
<p>The first concept is the integration of BunkerWeb into the target environment. We prefer to use the word "integration" instead of "installation" because one of the goals of BunkerWeb is to integrate seamlessly into existing environments.</p> 
<p>The following integrations are officially supported :</p> 
<ul> 
 <li><a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#docker">Docker</a></li> 
 <li><a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#linux">Linux</a></li> 
 <li><a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#docker-autoconf">Docker autoconf</a></li> 
 <li><a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#kubernetes">Kubernetes</a></li> 
 <li><a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#swarm">Swarm</a></li> 
 <li><a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#microsoft-azure">Microsoft Azure</a></li> 
</ul> 
<h2>Settings</h2> 
<p>Once BunkerWeb is integrated into your environment, you will need to configure it to serve and protect your web applications.</p> 
<p>The configuration of BunkerWeb is done by using what we call the "settings" or "variables". Each setting is identified by a name such as <code>AUTO_LETS_ENCRYPT</code> or <code>USE_ANTIBOT</code>. You can assign values to the settings to configure BunkerWeb.</p> 
<p>Here is a dummy example of a BunkerWeb configuration :</p> 
<pre><code class="language-conf">SERVER_NAME=www.example.com
AUTO_LETS_ENCRYPT=yes
USE_ANTIBOT=captcha
REFERRER_POLICY=no-referrer
USE_MODSECURITY=no
USE_GZIP=yes
USE_BROTLI=no
</code></pre> 
<p>You will find an easy to use settings generator at <a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">config.bunkerweb.io</a>.</p> 
<h2>Multisite mode</h2> 
<p>The multisite mode is a crucial concept to understand when using BunkerWeb. Because the goal is to protect web applications, we intrinsically inherit the concept of "virtual host" or "vhost" (more info <a href="https://en.wikipedia.org/wiki/Virtual_hosting">here</a>) which makes it possible to serve multiple web applications from a single (or a cluster of) instance.</p> 
<p>By default, the multisite mode of BunkerWeb is disabled which means that only one web application will be served and all the settings will be applied to it. The typical use case is when you have a single application to protect : you don't have to worry about the multisite and the default behavior should be the right one for you.</p> 
<p>When multisite mode is enabled, BunkerWeb will serve and protect multiple web applications. Each web application is identified by a unique server name and have its own set of settings. The typical use case is when you have multiple applications to protect and you want to use a single (or a cluster depending of the integration) instance of BunkerWeb.</p> 
<h2>Custom configurations</h2> 
<p>Because meeting all the use cases only using the settings is not an option (even with <a href="https://docs.bunkerweb.io/1.5.9/plugins/?utm_campaign=self&amp;utm_source=github">external plugins</a>), you can use custom configurations to solve your specific challenges.</p> 
<p>Under the hood, BunkerWeb uses the notorious NGINX web server, that's why you can leverage its configuration system for your specific needs. Custom NGINX configurations can be included in different <a href="https://docs.nginx.com/nginx/admin-guide/basic-functionality/managing-configuration-files/#contexts">contexts</a> like HTTP or server (all servers and/or specific server block).</p> 
<p>Another core component of BunkerWeb is the ModSecurity Web Application Firewall : you can also use custom configurations to fix some false positives or add custom rules for example.</p> 
<h2>Database</h2> 
<p align="center"> <img alt="Database model" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/bunkerweb_db.svg?sanitize=true" /> </p> 
<p>State of the current configuration of BunkerWeb is stored in a backend database which contains the following data :</p> 
<ul> 
 <li>Settings defined for all the services</li> 
 <li>Custom configurations</li> 
 <li>BunkerWeb instances</li> 
 <li>Metadata about jobs execution</li> 
 <li>Cached files</li> 
</ul> 
<p>The following backend database are supported : SQLite, MariaDB, MySQL and PostgreSQL</p> 
<h2>Scheduler</h2> 
<p>To make things automagically work together, a dedicated service called the scheduler is in charge of :</p> 
<ul> 
 <li>Storing the settings and custom configurations inside the database</li> 
 <li>Executing various tasks (called jobs)</li> 
 <li>Generating a configuration which is understood by BunkerWeb</li> 
 <li>Being the intermediary for other services (like web UI or autoconf)</li> 
</ul> 
<p>In other words, the scheduler is the brain of BunkerWeb.</p> 
<h1>Setup</h1> 
<h2>BunkerWeb Cloud</h2> 
<p align="center"> <img alt="Docker banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/bunkerweb-cloud.webp" /> </p> 
<p>BunkerWeb Cloud is the easiest way to get started with BunkerWeb. It offers you a fully managed BunkerWeb service with no hassle. Think of a like a BunkerWeb-as-a-Service !</p> 
<p>You will find more information about BunkerWeb Cloud beta <a href="https://www.bunkerweb.io/cloud?utm_campaign=self&amp;utm_source=docs">here</a> and you can apply for free <a href="https://panel.bunkerweb.io/order/bunkerweb-cloud/14?utm_campaign=self&amp;utm_source=docs">in the BunkerWeb panel</a>.</p> 
<h2>Docker</h2> 
<p align="center"> <img alt="Docker banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/integration-docker.svg?sanitize=true" /> </p> 
<p>We provide ready to use prebuilt images for x64, x86, armv7 and arm64 platforms on <a href="https://hub.docker.com/u/bunkerity">Docker Hub</a>.</p> 
<p>Docker integration key concepts are :</p> 
<ul> 
 <li><strong>Environment variables</strong> to configure BunkerWeb</li> 
 <li><strong>Scheduler</strong> container to store configuration and execute jobs</li> 
 <li><strong>Networks</strong> to expose ports for clients and connect to upstream web services</li> 
</ul> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#docker">Docker integration section</a> of the documentation.</p> 
<h2>Docker autoconf</h2> 
<p align="center"> <img alt="Docker autoconf banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/integration-autoconf.svg?sanitize=true" /> </p> 
<p>The downside of using environment variables is that the container needs to be recreated each time there is an update which is not very convenient. To counter that issue, you can use another image called <strong>autoconf</strong> which will listen for Docker events and automatically reconfigure BunkerWeb in real-time without recreating the container.</p> 
<p>Instead of defining environment variables for the BunkerWeb container, you simply add <strong>labels</strong> to your web applications containers and the <strong>autoconf</strong> will "automagically" take care of the rest.</p> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#docker-autoconf">Docker autoconf section</a> of the documentation.</p> 
<h2>Swarm</h2> 
<p align="center"> <img alt="Swarm banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/integration-swarm.svg?sanitize=true" /> </p> 
<p>To automatically configure BunkerWeb instances, a special service, called <strong>autoconf</strong> will listen for Docker Swarm events like service creation or deletion and automatically configure the <strong>BunkerWeb instances</strong> in real-time without downtime.</p> 
<p>Like the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#docker-autoconf">Docker autoconf integration</a>, configuration for web services is defined using labels starting with the special <strong>bunkerweb.</strong> prefix.</p> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#swarm">Swarm section</a> of the documentation.</p> 
<h2>Kubernetes</h2> 
<p align="center"> <img alt="Kubernetes banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/integration-kubernetes.svg?sanitize=true" /> </p> 
<p>The autoconf acts as an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">Ingress controller</a> and will configure the BunkerWeb instances according to the <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress resources</a>. It also monitors other Kubernetes objects like <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">ConfigMap</a> for custom configurations.</p> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#kubernetes">Kubernetes section</a> of the documentation.</p> 
<h2>Linux</h2> 
<p align="center"> <img alt="Linux banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/integration-linux.svg?sanitize=true" /> </p> 
<p>List of supported Linux distros :</p> 
<ul> 
 <li>Debian 12 "Bookworm"</li> 
 <li>Ubuntu 22.04 "Noble"</li> 
 <li>Ubuntu 24.04 "Jammy"</li> 
 <li>Fedora 40</li> 
 <li>RHEL 8.9</li> 
 <li>RHEL 9.4</li> 
</ul> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#linux">Linux section</a> of the documentation.</p> 
<h2>Microsoft Azure</h2> 
<p align="center"> <img alt="Azure banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/integration-azure.webp" /> </p> 
<p>BunkerWeb is referenced in the <a href="https://azuremarketplace.microsoft.com/fr-fr/marketplace/apps/bunkerity.bunkerweb?tab=Overview">Azure Marketplace</a> and a ARM template is available in the <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/misc/integrations/azure-arm-template.json">misc folder</a>.</p> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/integrations/?utm_campaign=self&amp;utm_source=github#microsoft-azure">Microsoft Azure section</a> of the documentation.</p> 
<h1>Quickstart guide</h1> 
<p>Once you have setup BunkerWeb with the integration of your choice, you can follow the <a href="https://docs.bunkerweb.io/1.5.9/quickstart-guide/?utm_campaign=self&amp;utm_source=github">quickstart guide</a> that will cover the following common use cases :</p> 
<ul> 
 <li>Protecting a single HTTP application</li> 
 <li>Protecting multiple HTTP application</li> 
 <li>Retrieving the real IP of clients when operating behind a load balancer</li> 
 <li>Adding custom configurations</li> 
 <li>Protecting generic TCP/UDP applications</li> 
 <li>In combination with PHP</li> 
</ul> 
<h1>Security tuning</h1> 
<p>BunkerWeb offers many security features that you can configure with <a href="https://docs.bunkerweb.io/1.5.9/settings/?utm_campaign=self&amp;utm_source=github">settings</a>. Even if the default values of settings ensure a minimal "security by default", we strongly recommend you to tune them. By doing so you will be able to ensure a security level of your choice but also manage false positives.</p> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/security-tuning/?utm_campaign=self&amp;utm_source=github">security tuning section</a> of the documentation.</p> 
<h1>Settings</h1> 
<p>To help you tuning BunkerWeb we have made an easy to use settings generator tool available at <a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">config.bunkerweb.io</a>.</p> 
<p>As a general rule when multisite mode is enabled, if you want to apply settings with multisite context to a specific server you will need to add the primary (first) server name as a prefix like <code>www.example.com_USE_ANTIBOT=captcha</code> or <code>myapp.example.com_USE_GZIP=yes</code> for example.</p> 
<p>When settings are considered as "multiple", it means that you can have multiple groups of settings for the same feature by adding numbers as suffix like <code>REVERSE_PROXY_URL_1=/subdir</code>, <code>REVERSE_PROXY_HOST_1=http://myhost1</code>, <code>REVERSE_PROXY_URL_2=/anotherdir</code>, <code>REVERSE_PROXY_HOST_2=http://myhost2</code>, ... for example.</p> 
<p>Check the <a href="https://docs.bunkerweb.io/1.5.9/settings/?utm_campaign=self&amp;utm_source=github">settings section</a> of the documentation to get the full list.</p> 
<h1>Web UI</h1> 
<p align="center"> <a href="https://www.youtube.com/watch?v=Ao20SfvQyr4"> <img height="300" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/docs/assets/img/user_interface_demo.webp" /> </a> </p> 
<p>The "Web UI" is a web application that helps you manage your BunkerWeb instance using a user-friendly interface instead of the command-line one.</p> 
<ul> 
 <li>Start, stop, restart and reload your BunkerWeb instance</li> 
 <li>Add, edit and delete settings for your web applications</li> 
 <li>Add, edit and delete custom configurations for NGINX and ModSecurity</li> 
 <li>Install and uninstall external plugins</li> 
 <li>Explore the cached files</li> 
 <li>Monitor jobs execution</li> 
 <li>View the logs and search pattern</li> 
</ul> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/web-ui/?utm_campaign=self&amp;utm_source=github">Web UI section</a> of the documentation.</p> 
<h1>Plugins</h1> 
<p>BunkerWeb comes with a plugin system to make it possible to easily add new features. Once a plugin is installed, you can manage it using additional settings defined by the plugin.</p> 
<p>Here is the list of "official" plugins that we maintain (see the <a href="https://github.com/bunkerity/bunkerweb-plugins/?utm_campaign=self&amp;utm_source=github">bunkerweb-plugins</a> repository for more information) :</p> 
<table> 
 <thead> 
  <tr> 
   <th align="center">Name</th> 
   <th align="center">Version</th> 
   <th align="left">Description</th> 
   <th align="center">Link</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td align="center"><strong>ClamAV</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">Automatically scans uploaded files with the ClamAV antivirus engine and denies the request when a file is detected as malicious.</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/clamav">bunkerweb-plugins/clamav</a></td> 
  </tr> 
  <tr> 
   <td align="center"><strong>Coraza</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">Inspect requests using a the Coraza WAF (alternative of ModSecurity).</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/coraza">bunkerweb-plugins/coraza</a></td> 
  </tr> 
  <tr> 
   <td align="center"><strong>CrowdSec</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">CrowdSec bouncer for BunkerWeb.</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/crowdsec">bunkerweb-plugins/crowdsec</a></td> 
  </tr> 
  <tr> 
   <td align="center"><strong>Discord</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">Send security notifications to a Discord channel using a Webhook.</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/discord">bunkerweb-plugins/discord</a></td> 
  </tr> 
  <tr> 
   <td align="center"><strong>Slack</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">Send security notifications to a Slack channel using a Webhook.</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/slack">bunkerweb-plugins/slack</a></td> 
  </tr> 
  <tr> 
   <td align="center"><strong>VirusTotal</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">Automatically scans uploaded files with the VirusTotal API and denies the request when a file is detected as malicious.</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/virustotal">bunkerweb-plugins/virustotal</a></td> 
  </tr> 
  <tr> 
   <td align="center"><strong>WebHook</strong></td> 
   <td align="center">1.6</td> 
   <td align="left">Send security notifications to a custom HTTP endpoint using a Webhook.</td> 
   <td align="center"><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/webhook">bunkerweb-plugins/slack</a></td> 
  </tr> 
 </tbody> 
</table> 
<p>You will find more information in the <a href="https://docs.bunkerweb.io/1.5.9/plugins/?utm_campaign=self&amp;utm_source=github">plugins section</a> of the documentation.</p> 
<h1>Support</h1> 
<h2>Professional</h2> 
<p>Get technical support directly from the BunkerWeb maintainers. You will find more information by visiting the <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github">BunkerWeb Panel</a>, our dedicated platform for professional services.</p> 
<p>Don't hesitate to <a href="https://panel.bunkerweb.io/contact.php?utm_campaign=self&amp;utm_source=github">contact us</a> if you have any question, we will be more than happy to respond to your needs.</p> 
<h2>Community</h2> 
<p>To get free community support you can use the following media :</p> 
<ul> 
 <li>The #help channel of BunkerWeb in the <a href="https://discord.com/invite/fTf46FmtyD">Discord server</a></li> 
 <li>The help category of <a href="https://github.com/bunkerity/bunkerweb/discussions">GitHub discussions</a></li> 
 <li>The <a href="https://www.reddit.com/r/BunkerWeb">/r/BunkerWeb</a> subreddit</li> 
 <li>The <a href="https://serverfault.com/">Server Fault</a> and <a href="https://superuser.com/">Super User</a> forums</li> 
</ul> 
<p>Please don't use <a href="https://github.com/bunkerity/bunkerweb/issues">GitHub issues</a> to ask for help, use it only for bug reports and feature requests.</p> 
<h1>License</h1> 
<p>This project is licensed under the terms of the <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/LICENSE.md">GNU Affero General Public License (AGPL) version 3</a>.</p> 
<h1>Contribute</h1> 
<p>If you would like to contribute to the plugins you can read the <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/CONTRIBUTING.md">contributing guidelines</a> to get started.</p> 
<h1>Security policy</h1> 
<p>We take security bugs as serious issues and encourage responsible disclosure, see our <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/SECURITY.md">security policy</a> for more information.</p> 
<h1>Star History</h1> 
<a href="https://star-history.com/#bunkerity/bunkerweb&amp;Date"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <source media="(prefers-color-scheme: light)" /> 
  <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=bunkerity/bunkerweb&amp;type=Date" /> 
  </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>home-assistant/core</title>
<link>https://github.com/home-assistant/core</link>
<guid>https://github.com/home-assistant/core</guid>
<content:encoded><![CDATA[
<div> 关键词：Home Assistant, 开源, 家庭自动化, 私人控制, Raspberry Pi

总结:

Home Assistant是一款专注于本地控制和隐私保护的家庭自动化平台。它基于开源社区开发，适合运行于Raspberry Pi或本地服务器上。该系统采用模块化设计，方便用户添加其他设备或功能集成。访问home-assistant.io可以获取演示、安装指南、教程和文档。

Home Assistant是Open Home Foundation项目的一部分，旨在为DIY爱好者提供强大的家庭自动化解决方案。用户可以通过访问帮助部分解决使用过程中的问题，或在开发组件时寻求进一步的帮助。

通过这种方式，Home Assistant不仅提供了灵活的家庭自动化解决方案，而且强调了对用户隐私和数据安全的重视。无论是初学者还是高级用户，都可以根据自己的需求定制和扩展系统功能。 <div>
<p>🏡 Open source home automation that puts local control and privacy first.</p><hr /><h1>Home Assistant |Chat Status|</h1> 
<p>Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.</p> 
<p>Check out <code>home-assistant.io &lt;https://home-assistant.io&gt;</code>__ for <code>a demo &lt;https://demo.home-assistant.io&gt;</code><strong>, <code>installation instructions &lt;https://home-assistant.io/getting-started/&gt;</code></strong>, <code>tutorials &lt;https://home-assistant.io/getting-started/automation/&gt;</code>__ and <code>documentation &lt;https://home-assistant.io/docs/&gt;</code>__.</p> 
<p>This is a project of the <code>Open Home Foundation &lt;https://www.openhomefoundation.org/&gt;</code>__.</p> 
<p>|screenshot-states|</p> 
<h2>Featured integrations</h2> 
<p>|screenshot-integrations|</p> 
<p>The system is built using a modular approach so support for other devices or actions can be implemented easily. See also the <code>section on architecture &lt;https://developers.home-assistant.io/docs/architecture_index/&gt;</code>__ and the <code>section on creating your own components &lt;https://developers.home-assistant.io/docs/creating_component_index/&gt;</code>__.</p> 
<p>If you run into issues while using Home Assistant or during development of a component, check the <code>Home Assistant help section &lt;https://home-assistant.io/help/&gt;</code>__ of our website for further help and information.</p> 
<p>.. |Chat Status| image:: <a href="https://img.shields.io/discord/330944238910963714.svg">https://img.shields.io/discord/330944238910963714.svg</a> :target: <a href="https://www.home-assistant.io/join-chat/">https://www.home-assistant.io/join-chat/</a> .. |screenshot-states| image:: <a href="https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-states.png">https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-states.png</a> :target: <a href="https://demo.home-assistant.io">https://demo.home-assistant.io</a> .. |screenshot-integrations| image:: <a href="https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-integrations.png">https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-integrations.png</a> :target: <a href="https://home-assistant.io/integrations/">https://home-assistant.io/integrations/</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AI4Finance-Foundation/FinGPT</title>
<link>https://github.com/AI4Finance-Foundation/FinGPT</link>
<guid>https://github.com/AI4Finance-Foundation/FinGPT</guid>
<content:encoded><![CDATA[
<div> 关键词：FinGPT、开源、金融大型语言模型、金融大模型、金融自然语言处理

文章主要介绍了FinGPT，一种开源的金融大型语言模型。以下是文章的主要内容总结：

1. **FinGPT介绍**：FinGPT是一个面向金融领域的开源大型语言模型，旨在通过结合通用数据和金融数据进行训练，解决金融数据的动态性和需求快速更新的问题。

2. **新功能与成果**：文章详细列出了FinGPT的几个关键发布，包括模型的公开发布、论文被重要会议接受、特定模型的发布以及对现有模型的改进等。这些成果展示了FinGPT在金融领域应用的多样性和潜力。

3. **AI智能投顾**：文章提到了FinGPT在智能投顾领域的应用，特别是FinGPT-Forecaster，用户可以通过输入公司代码、预测日期、历史新闻检索数量和财务信息来获取公司分析及未来一周股价走势预测。

4. **金融情感分析**：介绍了FinGPT在金融情感分析方面的性能，使用了多种预训练模型和优化方法（如LoRA）进行微调，结果优于或接近当前最先进的模型。

5. **开源贡献与引用**：文章鼓励社区成员为FinGPT贡献更多的开源基础模型，并提供了相关模型的性能比较和实验结果。同时，提供了详细的教程和文献引用指南，方便研究人员和开发者了解和使用FinGPT。

总结：FinGPT是一个专注于金融领域的开源大型语言模型，通过创新的技术和方法，提高了金融数据处理的效率和准确性，特别是在智能投顾和金融情感分析方面展现出强大的能力。其开放的特性促进了金融领域内模型的共享和合作，推动了金融自然语言处理技术的发展。 <div>
<p>FinGPT: Open-Source Financial Large Language Models! Revolutionize 🔥 We release the trained model on HuggingFace.</p><hr /><div align="center"> 
 <img align="center" alt="image" src="https://github.com/AI4Finance-Foundation/FinGPT/assets/31713746/e0371951-1ce1-488e-aa25-0992dafcc139" width="30%" /> 
</div> 
<h1>FinGPT: Open-Source Financial Large Language Models</h1> 
<p><a href="https://pepy.tech/project/fingpt"><img alt="Downloads" src="https://static.pepy.tech/badge/fingpt" /></a> <a href="https://pepy.tech/project/fingpt"><img alt="Downloads" src="https://static.pepy.tech/badge/fingpt/week" /></a> <a href="https://www.python.org/downloads/release/python-360/"><img alt="Python 3.8" src="https://img.shields.io/badge/python-3.6-blue.svg?sanitize=true" /></a> <a href="https://pypi.org/project/fingpt/"><img alt="PyPI" src="https://img.shields.io/pypi/v/fingpt.svg?sanitize=true" /></a> <img alt="License" src="https://img.shields.io/github/license/AI4Finance-Foundation/fingpt.svg?color=brightgreen" /> <img alt="" src="https://img.shields.io/github/issues-raw/AI4Finance-Foundation/fingpt?label=Issues" /> <img alt="" src="https://img.shields.io/github/issues-closed-raw/AI4Finance-Foundation/fingpt?label=Closed+Issues" /> <img alt="" src="https://img.shields.io/github/issues-pr-raw/AI4Finance-Foundation/fingpt?label=Open+PRs" /> <img alt="" src="https://img.shields.io/github/issues-pr-closed-raw/AI4Finance-Foundation/fingpt?label=Closed+PRs" /></p> 
<div align="center"> 
 <img align="center" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/logo_transparent_background.png" width="40%" /> 
</div> 
<p>Let us not expect Wall Street to open-source LLMs or open APIs, due to FinTech institutes' internal regulations and policies.</p> 
<p><a href="https://arxiv.org/abs/2306.06031">Blueprint of FinGPT</a></p> 
<p><a href="https://huggingface.co/FinGPT">https://huggingface.co/FinGPT</a></p> 
<p><a href="https://discord.gg/trsr8SXpW5"><img alt="" src="https://dcbadge.vercel.app/api/server/trsr8SXpW5" /></a></p> 
<p><img alt="Visitors" src="https://api.visitorbadge.io/api/VisitorHit?user=AI4Finance-Foundation&amp;repo=FinGPT&amp;countColor=%23B17A" /></p> 
<h2>What's New:</h2> 
<ul> 
 <li>[Model Release] Nov, 2023: We release <a href="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster">FinGPT-Forecaster</a>! 🔥<a href="https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster">Demo</a>, <a href="https://medium.datadriveninvestor.com/introducing-fingpt-forecaster-the-future-of-robo-advisory-services-50add34e3d3c">Medium Blog</a> &amp; <a href="https://huggingface.co/FinGPT/fingpt-forecaster_dow30_llama2-7b_lora">Model</a> are available on Huggingface🤗!</li> 
 <li>[Paper Acceptance] Oct, 2023: <a href="https://arxiv.org/abs/2310.04793">"FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets"</a> is accepted🎉 by <a href="https://an-instructive-workshop.github.io/">Instruction Workshop</a> @ NeurIPS 2023</li> 
 <li>[Paper Acceptance] Oct, 2023: <a href="https://arxiv.org/abs/2307.10485">"FinGPT: Democratizing Internet-scale Data for Financial Large Language Models"</a> is accepted🎉 by <a href="https://an-instructive-workshop.github.io/">Instruction Workshop</a> @ NeurIPS 2023</li> 
 <li>[Model Release] Oct, 2023: We release the <a href="https://huggingface.co/FinGPT">financial multi-task LLMs</a> 🔥 produced when evaluating base-LLMs on <a href="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark">FinGPT-Benchmark</a></li> 
 <li>[Paper Acceptance] Sep, 2023: <a href="https://arxiv.org/abs/2310.04027">"Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models"</a> is accepted🎉 by <a href="https://ai-finance.org/icaif-23-accepted-papers/">ACM International Conference on AI in Finance (ICAIF-23)</a></li> 
 <li>[Model Release] Aug, 2023: We release the <a href="https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora">financial sentiment analysis model</a> 🔥</li> 
 <li>[Paper Acceptance] Jul, 2023: <a href="https://arxiv.org/abs/2306.12659">"Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models"</a> is accepted🎉 by <a href="https://finllm.github.io/workshop/#/fcb">FinLLM 2023</a>@IJCAI 2023</li> 
 <li>[Paper Acceptance] Jul, 2023: <a href="https://arxiv.org/abs/2306.06031">"FinGPT: Open-Source Financial Large Language Models"</a> is accepted🎉 by <a href="https://finllm.github.io/workshop/#/fcb">FinLLM 2023</a>@IJCAI 2023</li> 
 <li>[Medium Blog] Jun 2023: <a href="https://medium.datadriveninvestor.com/fingpt-powering-the-future-of-finance-with-20-cutting-edge-applications-7c4d082ad3d8">FinGPT: Powering the Future of Finance with 20 Cutting-Edge Applications</a></li> 
</ul> 
<h2>Why FinGPT?</h2> 
<p>1). Finance is highly dynamic. <a href="https://arxiv.org/abs/2303.17564">BloombergGPT</a> trained an LLM using a mixture of finance data and general-purpose data, which took about 53 days, at a cost of around <strong>$3M</strong>). It is costly to retrain an LLM model like BloombergGPT every month or every week, thus lightweight adaptation is highly favorable. FinGPT can be fine-tuned swiftly to incorporate new data (the cost falls significantly, less than <strong>$300 per fine-tuning</strong>).</p> 
<p>2). Democratizing Internet-scale financial data is critical, say allowing timely updates of the model (monthly or weekly updates) using an automatic data curation pipeline. BloombergGPT has privileged data access and APIs, while FinGPT presents a more accessible alternative. It prioritizes lightweight adaptation, leveraging the best available open-source LLMs.</p> 
<p>3). The key technology is "RLHF (Reinforcement learning from human feedback)", which is missing in BloombergGPT. RLHF enables an LLM model to learn individual preferences (risk-aversion level, investing habits, personalized robo-advisor, etc.), which is the "secret" ingredient of ChatGPT and GPT4.</p> 
<h3>Milestone of AI Robo-Advisor: FinGPT-Forecaster</h3> 
<p>Try the latest released FinGPT-Forecaster demo at our <a href="https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster">HuggingFace Space</a></p> 
<p>The dataset for FinGPT-Forecaster: <a href="https://huggingface.co/datasets/FinGPT/fingpt-forecaster-dow30-202305-202405">https://huggingface.co/datasets/FinGPT/fingpt-forecaster-dow30-202305-202405</a></p> 
<p><img alt="demo_interface" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Forecaster/figs/interface.png" /></p> 
<p>Enter the following inputs:</p> 
<ol> 
 <li>ticker symbol (e.g. AAPL, MSFT, NVDA)</li> 
 <li>the day from which you want the prediction to happen (yyyy-mm-dd)</li> 
 <li>the number of past weeks where market news are retrieved</li> 
 <li>whether to add the latest basic financials as additional information</li> 
</ol> 
<p>Click Submit！ And you'll be responded with a well-rounded analysis of the company and a prediction for next week's stock price movement!</p> 
<p>For detailed and more customized implementation, please refer to <a href="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster">FinGPT-Forecaster</a></p> 
<h2>FinGPT Demos:</h2> 
<h3>Current State-of-the-arts for Financial Sentiment Analysis</h3> 
<ul> 
 <li> <p><a href="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt">FinGPT V3 (Updated on 10/12/2023)</a></p> 
  <ul> 
   <li> <p>What's new: <strong>Best trainable and inferable FinGPT for sentiment analysis on a single RTX 3090, which is even better than GPT-4 and ChatGPT Finetuning.</strong></p> </li> 
   <li> <p><a href="https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora">FinGPT v3</a> series are LLMs finetuned with the LoRA method on the News and Tweets sentiment analysis dataset which achieve the best scores on most of the financial sentiment analysis datasets with low cost.</p> </li> 
   <li> <p>FinGPT v3.3 use llama2-13b as base model; FinGPT v3.2 uses llama2-7b as base model; FinGPT v3.1 uses chatglm2-6B as base model.</p> </li> 
   <li> <p>Benchmark Results:</p> </li> 
   <li> 
    <table> 
     <thead> 
      <tr> 
       <th>Weighted F1</th> 
       <th align="center">FPB</th> 
       <th align="center">FiQA-SA</th> 
       <th align="center">TFNS</th> 
       <th align="center">NWGI</th> 
       <th align="center">Devices</th> 
       <th align="center">Time</th> 
       <th align="center">Cost</th> 
      </tr> 
     </thead> 
     <tbody> 
      <tr> 
       <td><a href="https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora">FinGPT v3.3</a></td> 
       <td align="center"><strong>0.882</strong></td> 
       <td align="center">0.874</td> 
       <td align="center"><strong>0.903</strong></td> 
       <td align="center"><strong>0.643</strong></td> 
       <td align="center">1 × RTX 3090</td> 
       <td align="center">17.25 hours</td> 
       <td align="center">$17.25</td> 
      </tr> 
      <tr> 
       <td>FinGPT v3.2</td> 
       <td align="center">0.850</td> 
       <td align="center">0.860</td> 
       <td align="center">0.894</td> 
       <td align="center">0.636</td> 
       <td align="center">1 × A100</td> 
       <td align="center">5.5 hours</td> 
       <td align="center">$ 22.55</td> 
      </tr> 
      <tr> 
       <td>FinGPT v3.1</td> 
       <td align="center">0.855</td> 
       <td align="center">0.850</td> 
       <td align="center">0.875</td> 
       <td align="center">0.642</td> 
       <td align="center">1 × A100</td> 
       <td align="center">5.5 hours</td> 
       <td align="center">$ 22.55</td> 
      </tr> 
      <tr> 
       <td>FinGPT (8bit)</td> 
       <td align="center">0.855</td> 
       <td align="center">0.847</td> 
       <td align="center">0.879</td> 
       <td align="center">0.632</td> 
       <td align="center">1 × RTX 3090</td> 
       <td align="center">6.47 hours</td> 
       <td align="center">$ 6.47</td> 
      </tr> 
      <tr> 
       <td>FinGPT (QLoRA)</td> 
       <td align="center">0.777</td> 
       <td align="center">0.752</td> 
       <td align="center">0.828</td> 
       <td align="center">0.583</td> 
       <td align="center">1 × RTX 3090</td> 
       <td align="center">4.15 hours</td> 
       <td align="center">$ 4.15</td> 
      </tr> 
      <tr> 
       <td>OpenAI Fine-tune</td> 
       <td align="center">0.878</td> 
       <td align="center"><strong>0.887</strong></td> 
       <td align="center">0.883</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
      </tr> 
      <tr> 
       <td>GPT-4</td> 
       <td align="center">0.833</td> 
       <td align="center">0.630</td> 
       <td align="center">0.808</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
      </tr> 
      <tr> 
       <td>FinBERT</td> 
       <td align="center">0.880</td> 
       <td align="center">0.596</td> 
       <td align="center">0.733</td> 
       <td align="center">0.538</td> 
       <td align="center">4 × NVIDIA K80 GPU</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
      </tr> 
      <tr> 
       <td>Llama2-7B</td> 
       <td align="center">0.390</td> 
       <td align="center">0.800</td> 
       <td align="center">0.296</td> 
       <td align="center">0.503</td> 
       <td align="center">2048 × A100</td> 
       <td align="center">21 days</td> 
       <td align="center">$ 4.23 million</td> 
      </tr> 
      <tr> 
       <td>BloombergGPT</td> 
       <td align="center">0.511</td> 
       <td align="center">0.751</td> 
       <td align="center">-</td> 
       <td align="center">-</td> 
       <td align="center">512 × A100</td> 
       <td align="center">53 days</td> 
       <td align="center">$ 2.67 million</td> 
      </tr> 
     </tbody> 
    </table> <p><strong>Cost per GPU hour.</strong> For <strong>A100 GPUs</strong>, the AWS p4d.24xlarge instance, equipped with 8 A100 GPUs is used as a benchmark to estimate the costs. Note that BloombergGPT also used p4d.24xlarge As of July 11, 2023, the hourly rate for this instance stands at $32.773. Consequently, the estimated cost per GPU hour comes to $32.77 divided by 8, resulting in approximately <strong>$4.10</strong>. With this value as the reference unit price (1 GPU hour). <strong>BloombergGPT estimated cost= 512 x 53 x 24 = 651,264 GPU hours x $4.10 = $2,670,182.40</strong>. For <strong>RTX 3090</strong>, we assume its cost per hour is approximately <strong>$1.0</strong>, which is actually much higher than available GPUs from platforms like vast.ai.</p> </li> 
   <li> <p>Reproduce the results by running <a href="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Sentiment_Analysis_v3/benchmark/benchmarks.ipynb">benchmarks</a>, and the detailed tutorial is on the way.</p> </li> 
   <li> <p>Finetune your own FinGPT v3 model with the LoRA method on only an RTX 3090 with this <a href="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Sentiment_Analysis_v3/training_8bit/train_Llama2_13B.ipynb">notebook</a> in 8bit or this <a href="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Sentiment_Analysis_v3/training_int4/train.ipynb">notebook</a> in int4 (QLoRA)</p> </li> 
  </ul> </li> 
 <li> <p><a href="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt">FinGPT V1</a></p> 
  <ul> 
   <li><strong>FinGPT by finetuning ChatGLM2 / Llama2 with LoRA with the market-labeled data for the Chinese Market</strong></li> 
  </ul> </li> 
</ul> 
<h2>Instruction Tuning Datasets and Models</h2> 
<p>The datasets we used, and the <strong>multi-task financial LLM</strong> models are available at <a href="https://huggingface.co/FinGPT">https://huggingface.co/FinGPT</a></p> 
<p><a href="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark">Our Code</a></p> 
<table> 
 <thead> 
  <tr> 
   <th>Datasets</th> 
   <th>Train Rows</th> 
   <th>Test Rows</th> 
   <th>Description</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://huggingface.co/datasets/FinGPT/fingpt-sentiment-train">fingpt-sentiment-train</a></td> 
   <td>76.8K</td> 
   <td>N/A</td> 
   <td>Sentiment Analysis Training Instructions</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/datasets/FinGPT/fingpt-finred">fingpt-finred</a></td> 
   <td>27.6k</td> 
   <td>5.11k</td> 
   <td>Financial Relation Extraction Instructions</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/datasets/FinGPT/fingpt-headline">fingpt-headline</a></td> 
   <td>82.2k</td> 
   <td>20.5k</td> 
   <td>Financial Headline Analysis Instructions</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/datasets/FinGPT/fingpt-ner">fingpt-ner</a></td> 
   <td>511</td> 
   <td>98</td> 
   <td>Financial Named-Entity Recognition Instructions</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/datasets/FinGPT/fingpt-fiqa_qa">fingpt-fiqa_qa</a></td> 
   <td>17.1k</td> 
   <td>N/A</td> 
   <td>Financial Q&amp;A Instructions</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/datasets/FinGPT/fingpt-fineval">fingpt-fineval</a></td> 
   <td>1.06k</td> 
   <td>265</td> 
   <td>Chinese Multiple-Choice Questions Instructions</td> 
  </tr> 
 </tbody> 
</table> 
<p>Multi-task financial LLMs Models:</p> 
<pre><code class="language-python">  demo_tasks = [
      'Financial Sentiment Analysis',
      'Financial Relation Extraction',
      'Financial Headline Classification',
      'Financial Named Entity Recognition',]
  demo_inputs = [
      "Glaxo's ViiV Healthcare Signs China Manufacturing Deal With Desano",
      "Apple Inc. Chief Executive Steve Jobs sought to soothe investor concerns about his health on Monday, saying his weight loss was caused by a hormone imbalance that is relatively simple to treat.",
      'gold trades in red in early trade; eyes near-term range at rs 28,300-28,600',
      'This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (" Bank "), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste .',]
  demo_instructions = [
      'What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.',
      'Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text. The output format should be "relation1: word1, word2; relation2: word3, word4". Options: product/material produced, manufacturer, distributed by, industry, position held, original broadcaster, owned by, founded by, distribution format, headquarters location, stock exchange, currency, parent organization, chief executive officer, director/manager, owner of, operator, member of, employer, chairperson, platform, subsidiary, legal form, publisher, developer, brand, business division, location of formation, creator.',
      'Does the news headline talk about price going up? Please choose an answer from {Yes/No}.',
      'Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.',]
</code></pre> 
<table> 
 <thead> 
  <tr> 
   <th>Models</th> 
   <th>Description</th> 
   <th>Function</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-mt_llama2-7b_lora">fingpt-mt_llama2-7b_lora</a></td> 
   <td>Fine-tuned Llama2-7b model with LoRA</td> 
   <td>Multi-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-mt_falcon-7b_lora">fingpt-mt_falcon-7b_lora</a></td> 
   <td>Fine-tuned falcon-7b model with LoRA</td> 
   <td>Multi-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-mt_bloom-7b1_lora">fingpt-mt_bloom-7b1_lora</a></td> 
   <td>Fine-tuned bloom-7b1 model with LoRA</td> 
   <td>Multi-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-mt_mpt-7b_lora">fingpt-mt_mpt-7b_lora</a></td> 
   <td>Fine-tuned mpt-7b model with LoRA</td> 
   <td>Multi-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-mt_chatglm2-6b_lora">fingpt-mt_chatglm2-6b_lora</a></td> 
   <td>Fine-tuned chatglm-6b model with LoRA</td> 
   <td>Multi-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-mt_qwen-7b_lora">fingpt-mt_qwen-7b_lora</a></td> 
   <td>Fine-tuned qwen-7b model with LoRA</td> 
   <td>Multi-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora">fingpt-sentiment_llama2-13b_lora</a></td> 
   <td>Fine-tuned llama2-13b model with LoRA</td> 
   <td>Single-Task</td> 
  </tr> 
  <tr> 
   <td><a href="https://huggingface.co/FinGPT/fingpt-forecaster_dow30_llama2-7b_lora">fingpt-forecaster_dow30_llama2-7b_lora</a></td> 
   <td>Fine-tuned llama2-7b model with LoRA</td> 
   <td>Single-Task</td> 
  </tr> 
 </tbody> 
</table> 
<h2>Tutorials</h2> 
<p><a href="https://byfintech.medium.com/beginners-guide-to-fingpt-training-with-lora-chatglm2-6b-9eb5ace7fe99">[Training] Beginner’s Guide to FinGPT: Training with LoRA and ChatGLM2–6B One Notebook, $10 GPU</a></p> 
<h2>Understanding FinGPT: An Educational Blog Series</h2> 
<ul> 
 <li><a href="https://medium.datadriveninvestor.com/fingpt-powering-the-future-of-finance-with-20-cutting-edge-applications-7c4d082ad3d8">FinGPT: Powering the Future of Finance with 20 Cutting-Edge Applications </a></li> 
 <li><a href="https://medium.datadriveninvestor.com/fingpt-i-why-we-built-the-first-open-source-large-language-model-for-finance-c01b5517ca">FinGPT I: Why We Built the First Open-Source Large Language Model for Finance </a></li> 
 <li><a href="https://medium.datadriveninvestor.com/fingpt-ii-cracking-the-financial-sentiment-analysis-task-using-instruction-tuning-of-3333bce428c4">FinGPT II: Cracking the Financial Sentiment Analysis Task Using Instruction Tuning of General-Purpose Large Language Models </a></li> 
</ul> 
<h2>FinGPT Ecosystem</h2> 
<h3>FinGPT embraces a full-stack framework for FinLLMs with five layers:</h3> 
<ol> 
 <li><strong>Data source layer</strong>: This layer assures comprehensive market coverage, addressing the temporal sensitivity of financial data through real-time information capture.</li> 
 <li><strong>Data engineering layer</strong>: Primed for real-time NLP data processing, this layer tackles the inherent challenges of high temporal sensitivity and low signal-to-noise ratio in financial data.</li> 
 <li><strong>LLMs layer</strong>: Focusing on a range of fine-tuning methodologies such as LoRA, this layer mitigates the highly dynamic nature of financial data, ensuring the model’s relevance and accuracy.</li> 
 <li><strong>Task layer</strong>: This layer is responsible for executing fundamental tasks. These tasks serve as the benchmarks for performance evaluations and cross-comparisons in the realm of FinLLMs</li> 
 <li><strong>Application layer</strong>: Showcasing practical applications and demos, this layer highlights the potential capability of FinGPT in the financial sector.</li> 
</ol> 
<ul> 
 <li>FinGPT Framework: Open-Source Financial Large Language Models</li> 
</ul> 
<div align="center"> 
 <img align="center" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_framework_20240301.png" /> 
</div> 
<ul> 
 <li><a href="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_RAG">FinGPT-RAG</a>: We present a retrieval-augmented large language model framework specifically designed for financial sentiment analysis, optimizing information depth and context through external knowledge retrieval, thereby ensuring nuanced predictions.</li> 
</ul> 
<div align="center"> 
 <img align="center" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_RAG_framework.png" /> 
</div> 
<ul> 
 <li><a href="https://github.com/AI4Finance-Foundation/FinNLP">FinGPT-FinNLP</a>: FinNLP provides a playground for all people interested in LLMs and NLP in Finance. Here we provide full pipelines for LLM training and finetuning in the field of finance. The full architecture is shown in the following picture. Detail codes and introductions can be found <a href="https://github.com/AI4Finance-Foundation/FinNLP">here</a>. Or you may refer to the <a href="https://ai4finance-foundation.github.io/FinNLP/">wiki</a></li> 
</ul> 
<div align="center"> 
 <img align="center" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_FinNLP_data_source.png" /> 
</div> 
<ul> 
 <li><a href="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark">FinGPT-Benchmark</a>: We introduce a novel Instruction Tuning paradigm optimized for open-source Large Language Models (LLMs) in finance, enhancing their adaptability to diverse financial datasets while also facilitating cost-effective, systematic benchmarking from task-specific, multi-task, and zero-shot instruction tuning tasks.</li> 
</ul> 
<div align="center"> 
 <img align="center" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_Benchmark_20231110.png" /> 
</div> 
<h2>Open-Source Base Model used in the LLMs layer of FinGPT</h2> 
<ul> 
 <li>Feel free to contribute more open-source base models tailored for various language-specific financial markets.</li> 
</ul> 
<table> 
 <thead> 
  <tr> 
   <th>Base Model</th> 
   <th>Pretraining Tokens</th> 
   <th>Context Length</th> 
   <th>Model Advantages</th> 
   <th>Model Size</th> 
   <th>Experiment Results</th> 
   <th>Applications</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://github.com/facebookresearch/llama">Llama-2</a></td> 
   <td>2 Trillion</td> 
   <td>4096</td> 
   <td>Llama-2 excels on English-based market data</td> 
   <td><a href="https://huggingface.co/meta-llama/Llama-2-7b-hf">llama-2-7b</a> and <a href="https://huggingface.co/meta-llama/Llama-2-13b-hf">Llama-2-13b</a></td> 
   <td>llama-2 consistently shows superior fine-tuning results</td> 
   <td>Financial Sentiment Analysis, Robo-Advisor</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/falconry/falcon">Falcon</a></td> 
   <td>1,500B</td> 
   <td>2048</td> 
   <td>Maintains high-quality results while being more resource-efficient</td> 
   <td><a href="https://huggingface.co/tiiuae/falcon-7b">falcon-7b</a></td> 
   <td>Good for English market data</td> 
   <td>Financial Sentiment Analysis</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/mosaicml/llm-foundry">MPT</a></td> 
   <td>1T</td> 
   <td>2048</td> 
   <td>MPT models can be trained with high throughput efficiency and stable convergence</td> 
   <td><a href="https://huggingface.co/mosaicml/mpt-7b">mpt-7b</a></td> 
   <td>Good for English market data</td> 
   <td>Financial Sentiment Analysis</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/bigscience-workshop/bigscience/tree/master/train/tr11-176B-ml#readme">Bloom</a></td> 
   <td>366B</td> 
   <td>2048</td> 
   <td>World’s largest open multilingual language model</td> 
   <td><a href="https://huggingface.co/bigscience/bloom-7b1">bloom-7b1</a></td> 
   <td>Good for English market data</td> 
   <td>Financial Sentiment Analysis</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/THUDM/ChatGLM2-6B">ChatGLM2</a></td> 
   <td>1.4T</td> 
   <td>32K</td> 
   <td>Exceptional capability for Chinese language expression</td> 
   <td><a href="https://huggingface.co/THUDM/chatglm2-6b">chatglm2-6b</a></td> 
   <td>Shows prowess for Chinese market data</td> 
   <td>Financial Sentiment Analysis, Financial Report Summary</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/QwenLM/Qwen-7B">Qwen</a></td> 
   <td>2.2T</td> 
   <td>8k</td> 
   <td>Fast response and high accuracy</td> 
   <td><a href="https://huggingface.co/tangger/Qwen-7B-Chat">qwen-7b</a></td> 
   <td>Effective for Chinese market data</td> 
   <td>Financial Sentiment Analysis</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/InternLM/InternLM">InternLM</a></td> 
   <td>1.8T</td> 
   <td>8k</td> 
   <td>Can flexibly and independently construct workflows</td> 
   <td><a href="https://huggingface.co/internlm/internlm-7b">internlm-7b</a></td> 
   <td>Effective for Chinese market data</td> 
   <td>Financial Sentiment Analysis</td> 
  </tr> 
 </tbody> 
</table> 
<ul> 
 <li>Benchmark Results for the above open-source Base Models in the financial sentiment analysis task using the same instruction template for SFT (LoRA): 
  <table> 
   <thead> 
    <tr> 
     <th>Weighted F1/Acc</th> 
     <th>Llama2</th> 
     <th>Falcon</th> 
     <th>MPT</th> 
     <th>Bloom</th> 
     <th>ChatGLM2</th> 
     <th>Qwen</th> 
     <th>InternLM</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td><a href="https://huggingface.co/datasets/financial_phrasebank">FPB</a></td> 
     <td>0.863/0.863</td> 
     <td>0.846/0.849</td> 
     <td><strong>0.872</strong>/<strong>0.872</strong></td> 
     <td>0.810/0.810</td> 
     <td>0.850/0.849</td> 
     <td>0.854/0.854</td> 
     <td>0.709/0.714</td> 
    </tr> 
    <tr> 
     <td><a href="https://huggingface.co/datasets/pauri32/fiqa-2018">FiQA-SA</a></td> 
     <td><strong>0.871</strong>/0.855</td> 
     <td>0.840/0.811</td> 
     <td>0.863/0.844</td> 
     <td>0.771/0.753</td> 
     <td>0.864/<strong>0.862</strong></td> 
     <td>0.867/0.851</td> 
     <td>0.679/0.687</td> 
    </tr> 
    <tr> 
     <td><a href="https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment">TFNS</a></td> 
     <td>0.896/0.895</td> 
     <td>0.893/0.893</td> 
     <td><strong>0.907</strong>/<strong>0.907</strong></td> 
     <td>0.840/0.840</td> 
     <td>0.859/0.858</td> 
     <td>0.883/0.882</td> 
     <td>0.729/0.731</td> 
    </tr> 
    <tr> 
     <td><a href="https://huggingface.co/datasets/oliverwang15/news_with_gpt_instructions">NWGI</a></td> 
     <td><strong>0.649/0.651</strong></td> 
     <td>0.636/0.638</td> 
     <td>0.640/0.641</td> 
     <td>0.573/0.574</td> 
     <td>0.619/0.629</td> 
     <td>0.638/0.643</td> 
     <td>0.498/0.503</td> 
    </tr> 
   </tbody> 
  </table> </li> 
</ul> 
<h3>All Thanks To Our Contributors :</h3> 
<a href="https://github.com/AI4Finance-Foundation/FinGPT/graphs/contributors"> <img src="https://contrib.rocks/image?repo=AI4Finance-Foundation/FinGPT" /> </a> 
<h2>News</h2> 
<ul> 
 <li><a href="https://datascience.columbia.edu/news/2023/columbia-perspectives-on-chatgpt/?utm_source=sendinblue&amp;utm_campaign=DSI%20Newsletter%20April%202023&amp;utm_medium=email">Columbia Perspectives on ChatGPT</a></li> 
 <li>[MIT Technology Review] <a href="https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/">ChatGPT is about to revolutionize the economy. We need to decide what that looks like</a></li> 
 <li>[BloombergGPT] <a href="https://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance</a></li> 
 <li>[Finextra] <a href="https://www.finextra.com/newsarticle/41973/chatgpt-and-bing-ai-to-sit-as-panellists-at-fintech-conference">ChatGPT and Bing AI to sit as panellists at fintech conference</a></li> 
</ul> 
<h2>ChatGPT at AI4Finance</h2> 
<ul> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=fhBw3j_O9LE">I Built a Trading Bot with ChatGPT</a>, combining ChatGPT and FinRL.</li> 
 <li><a href="https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f">Hey, ChatGPT! Explain FinRL code to me!</a></li> 
</ul> 
<h2>Introductory</h2> 
<ul> 
 <li><a href="https://arxiv.org/abs/2303.12712">Sparks of artificial general intelligence: Early experiments with GPT-4</a></li> 
 <li>[GPT-4] <a href="https://arxiv.org/abs/2303.08774">GPT-4 Technical Report</a></li> 
 <li>[InstructGPT] <a href="https://openreview.net/forum?id=TG8KACxEON">Training language models to follow instructions with human feedback</a> NeurIPS 2022.</li> 
</ul> 
<p><a href="https://medium.com/walmartglobaltech/the-journey-of-open-ai-gpt-models-32d95b7b7fb2">The Journey of Open AI GPT models</a>. GPT models explained. Open AI's GPT-1, GPT-2, GPT-3.</p> 
<ul> 
 <li>[GPT-3] <a href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html">Language models are few-shot learners</a> NeurIPS 2020.</li> 
 <li>[GPT-2] <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a></li> 
 <li>[GPT-1] <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></li> 
 <li>[Transformer] <a href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Attention is All you Need</a> NeurIPS 2017.</li> 
</ul> 
<h2>(Financial) Big Data</h2> 
<ul> 
 <li> <p>[BloombergGPT] <a href="https://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance</a></p> </li> 
 <li> <p><a href="https://lifearchitect.ai/whats-in-my-ai/">WHAT’S IN MY AI?</a> A Comprehensive Analysis of Datasets Used to Train GPT-1, GPT-2, GPT-3, GPT-NeoX-20B, Megatron-11B, MT-NLG, and Gopher</p> </li> 
 <li> <p><a href="https://github.com/AI4Finance-Foundation/FinRL-Meta">FinRL-Meta Repo</a> and paper <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/0bf54b80686d2c4dc0808c2e98d430f7-Abstract-Datasets_and_Benchmarks.html">FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning</a>. Advances in Neural Information Processing Systems, 2022.</p> </li> 
 <li> <p>[AI4Finance] <a href="https://github.com/AI4Finance-Foundation/FinNLP">FinNLP</a> Democratizing Internet-scale financial data.</p> </li> 
</ul> 
<h2>Interesting Demos</h2> 
<ul> 
 <li><a href="https://gwern.net/gpt-3#prompts-as-programming">GPT-3 Creative Fiction</a> Creative writing by OpenAI’s GPT-3 model, demonstrating poetry, dialogue, puns, literary parodies, and storytelling. Plus advice on effective GPT-3 prompt programming &amp; avoiding common errors.</li> 
</ul> 
<h2>ChatGPT for FinTech</h2> 
<p><strong>ChatGPT Trading Bot</strong></p> 
<ul> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=unsa_gXPAJ4">ChatGPT Trading strategy 20097% returns</a></li> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=4SG2884RcDY">ChatGPT Coding - Make A Profitable Trading Strategy In Five Minutes!</a></li> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=dIEZVPVOZPQ">Easy Automated Live Trading using ChatGPT (+9660.3% hands free)</a></li> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=YxjvjK5AD2M">ChatGPT Trading Strategy 893% Returns</a></li> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=9VPfd08uU4Q">ChatGPT 10 Million Trading Strategy</a></li> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=LpzeshX6s2w">ChatGPT: Your Crypto Assistant</a></li> 
 <li>[YouTube video] <a href="https://www.youtube.com/watch?v=ekz6ugJE1h0&amp;t=3s">Generate Insane Trading Returns with ChatGPT and TradingView</a></li> 
</ul> 
<!-- 
**(Fast and accurate) Sentiment Analysis**

   GPT-3 can help study customer surveys, social media tweets from customers/users.

   Tweets
+ [Tweet Classifier](https://platform.openai.com/playground/p/default-tweet-classifier?model=text-davinci-003)
+ [Advanced Tweet Classifier](https://platform.openai.com/playground/p/default-adv-tweet-classifier?model=text-davinci-003)

  Financial News
+ [Algorithmic Trading using Sentiment Analysis on News Articles](https://towardsdatascience.com/https-towardsdatascience-com-algorithmic-trading-using-sentiment-analysis-on-news-articles-83db77966704)
+ [Accessing Historical Financial News Headlines with Python](https://python.plainenglish.io/access-historical-financial-news-headlines-with-python-be1b8faaea9f)

**PromptNet** Analogy to ImageNet and WordNet, it is critical to build a PromptNet.

+ [Awesome_Prompting_Papers_in_Computer_Vision](https://github.com/ttengwang/Awesome_Prompting_Papers_in_Computer_Vision)
+ [OpenPrompt](https://github.com/thunlp/OpenPrompt)
+ [promptsource](https://github.com/bigscience-workshop/promptsource)

**Robo-advisor**

**Coding-tutor**

+ [Hey, ChatGPT! Explain FinRL code to me!](https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f)

**Blogs about ChatGPT for FinTech**

## ChatGPT APIs

Prompting as a new programming paradigm!
+ [Towards Data Science] [GPT-3: Creative Potential of NLP](https://towardsdatascience.com/gpt-3-creative-potential-of-nlp-d5ccae16c1ab)
+ [YouTube video] [OpenAI GPT-3 - Prompt Engineering For Financial NLP](https://www.youtube.com/watch?v=Nl2Cdbao5Ws)

+ [OpenAI API for GPT-3](https://platform.openai.com/docs/models/gpt-3)
+ [ChatGPT-wrapper: python and shell](https://github.com/mmabrouk/chatgpt-wrapper)
+ [OpenAI Examples Library](https://platform.openai.com/examples)
+ [GPT-3 Sandbox (Github)](https://github.com/shreyashankar/gpt3-sandbox) Enable users to create cool web demos using OpenAI GPT-3 API.
+ [Exploring the Capabilities of the ChatGPT API: A Beginner’s Guide](https://levelup.gitconnected.com/exploring-the-capabilities-of-the-chatgpt-api-a-beginners-guide-e9089d49961f)
+ [Reverse engineered ChatGPT API](https://github.com/acheong08/ChatGPT)

**Prompting programming**

## ChatGPT relatives: 

[A Release Timeline](https://github.com/osanseviero/ml_timeline) of many LLMs.

[PaLM](https://arxiv.org/abs/2204.02311)

[Chincella](https://arxiv.org/abs/2203.15556)

Interesting evaluations:
+ [RLHF for pretraining](https://arxiv.org/abs/2302.08582)

+ [Compare ChatGPT with GPT3.5](https://arxiv.org/pdf/2302.06476.pdf)

+ [Is ChatGPT A Good Translator? A Preliminary Study](https://arxiv.org/pdf/2301.08745.pdf)

+ [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT
on Reasoning, Hallucination, and Interactivity](https://arxiv.org/pdf/2302.04023.pdf)

[YouTube video] [Physics Solution: ChatGPT vs. Google](https://www.youtube.com/watch?v=x4dIx9VYQoM)
---> 
<h2>Citing FinGPT</h2> 
<pre><code>@article{yang2023fingpt,
  title={FinGPT: Open-Source Financial Large Language Models},
  author={Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan},
  journal={FinLLM Symposium at IJCAI 2023},
  year={2023}
}
@article{zhang2023instructfingpt,
      title={Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models}, 
      author={Boyu Zhang and Hongyang Yang and Xiao-Yang Liu},
      journal={FinLLM Symposium at IJCAI 2023},
      year={2023}
}
@article{zhang2023fingptrag,
  title={Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models},
  author={Zhang, Boyu and Yang, Hongyang and Zhou, tianyu and Babar, Ali and Liu, Xiao-Yang},
 journal = {ACM International Conference on AI in Finance (ICAIF)},
  year={2023}
}

@article{wang2023fingptbenchmark,
  title={FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets},
  author={Wang, Neng and Yang, Hongyang and Wang, Christina Dan},
  journal={NeurIPS Workshop on Instruction Tuning and Instruction Following},
  year={2023}
}
@article{2023finnlp,
  title={Data-centric FinGPT: Democratizing Internet-scale Data for Financial Large Language Models},
  author={Liu, Xiao-Yang and Wang, Guoxuan and Yang, Hongyang and Zha, Daochen},
  journal={NeurIPS Workshop on Instruction Tuning and Instruction Following},
  year={2023}
}

</code></pre> 
<div align="center"> 
 <a href="https://finllm.github.io/workshop/#/fcb" target="_blank"> <img align="center" src="https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/fingpt_best_presentation.png" width="65%" /> </a>
</div>
<a href="https://finllm.github.io/workshop/#/fcb" target="_blank"> <h2>LICENSE</h2> <p>MIT License</p> <p><strong>Disclaimer: We are sharing codes for academic purposes under the MIT education license. Nothing herein is financial advice, and NOT a recommendation to trade real money. Please use common sense and always first consult a professional before trading or investing.</strong></p> </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>midday-ai/midday</title>
<link>https://github.com/midday-ai/midday</link>
<guid>https://github.com/midday-ai/midday</guid>
<content:encoded><![CDATA[
<div> 关键词：Midday、时间追踪、自动对账、安全存储、无缝导出

总结:

Midday 是一款专为自由职业者、合同工、顾问和独立企业家设计的一站式工具，旨在帮助他们更高效地管理业务运营。它整合了多个平台的功能，提供了一个统一的系统来优化工作流程。

1. **时间追踪**：Midday 提供实时项目时间追踪功能，有助于提升生产力和团队协作，同时提供详细的项目概览。
   
2. **自动对账**：通过其“魔术收件箱”功能，Midday 可以自动匹配收到的发票或收据与正确的交易，简化财务跟踪和组织过程。

3. **安全存储**：Midday 的“保险库”功能确保重要文件如合同和协议的安全存储，一切内容都集中在一个易于访问的地方。

4. **无缝导出**：用户可以轻松导出财务数据，以 CSV 格式打包，方便会计师处理。

5. **智能分析**：通过内置的助手功能，Midday 提供定制化的财务洞察，帮助用户理解开支模式、降低成本并查找所需文档。 <div>
<p>Run your business smarter 🪄</p><hr /><p><img alt="hero" src="https://raw.githubusercontent.com/midday-ai/midday/main/github.png" /></p> 
<p align="center"> </p>
<h1 align="center"><b>Midday</b></h1> 
<p align="center"> Run your business smarter <br /> <br /> <a href="https://go.midday.ai/anPiuRx">Discord</a> · <a href="https://midday.ai">Website</a> · <a href="https://github.com/midday-ai/midday/issues">Issues</a> </p> 
<p></p> 
<h2>About Midday</h2> 
<p>Midday is an all-in-one tool designed to help freelancers, contractors, consultants, and solo entrepreneurs manage their business operations more efficiently. It integrates various functions typically scattered across multiple platforms into a single, cohesive system.</p> 
<h2>Features</h2> 
<p><strong>Time Tracking</strong>: Allows for live time tracking of projects to boost productivity and collaboration, providing insightful project overviews.<br /> <strong>Invoicing</strong>: An upcoming feature that will enable users to create web-based invoices, collaborate in real-time, and synchronize projects seamlessly.<br /> <strong>Magic Inbox</strong>: Automatically matches incoming invoices or receipts to the correct transactions, simplifying financial tracking and organization.<br /> <strong>Vault</strong>: Secure storage for important files like contracts and agreements, keeping everything in one place for easy access​.<br /> <strong>Seamless Export</strong>: Facilitates easy export of financial data, packaged neatly in CSV files for accountants.<br /> <strong>Assistant</strong>: Provides tailored insights into financial situations, helping users understand spending patterns, cut costs, and find documents.<br /></p> 
<h2>Recognition</h2> 
<a href="https://news.ycombinator.com/item?id=40737901"> <img alt="Featured on Hacker News" height="54" src="https://hackernews-badge.vercel.app/api?id=40737901" style="width: 250px; height: 54px;" width="250" /> </a> 
<p><a href="https://www.producthunt.com/posts/midday-2?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-midday-2" target="_blank"><img alt="Midday - Run your business smarter | Product Hunt" height="54" src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=460784&amp;theme=light" style="width: 250px; height: 54px;" width="250" /></a></p> 
<br /> 
<h2>Get started</h2> 
<p>We are working on the documentation to get started with Midday for local development: <a href="https://docs.midday.ai">https://docs.midday.ai</a></p> 
<h2>App Architecture</h2> 
<ul> 
 <li>Monorepo</li> 
 <li>Bun</li> 
 <li>React</li> 
 <li>TypeScript</li> 
 <li>Nextjs</li> 
 <li>Supabase</li> 
 <li>Shadcn</li> 
 <li>ToDesktop</li> 
 <li>Expo</li> 
 <li>TailwindCSS</li> 
</ul> 
<h3>Hosting</h3> 
<ul> 
 <li>Supabase (database, storage, realtime, auth)</li> 
 <li>Vercel (Website, edge-config, and metrics)</li> 
 <li>Upstash (redis)</li> 
</ul> 
<h3>Services</h3> 
<ul> 
 <li>Trigger.dev (background jobs)</li> 
 <li>Resend (email)</li> 
 <li>Novu (notifications)</li> 
 <li>Github Actions (CI/CD)</li> 
 <li>GoCardLess (Bank connection EU)</li> 
 <li>Plaid (Bank connection in Canada and US)</li> 
 <li>Teller (Bank connection in the US)</li> 
 <li>Loops (Marketing email)</li> 
 <li>OpenPanel (Events and Analytics)</li> 
 <li>Dub (Short URLs)</li> 
</ul> 
<h2>Repo Activity</h2> 
<p><img alt="Alt" src="https://repobeats.axiom.co/api/embed/96aae855e5dd87c30d53c1d154b37cf7aa5a89b3.svg?sanitize=true" title="Repobeats analytics image" /></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>sherlock-project/sherlock</title>
<link>https://github.com/sherlock-project/sherlock</link>
<guid>https://github.com/sherlock-project/sherlock</guid>
<content:encoded><![CDATA[
<div> 关键词：Sherlock、社交网络、用户名搜索、多平台支持、命令行工具

总结:

Sherlock是一个强大的命令行工具，用于在各种社交网络中搜索特定的用户名。它支持多种安装方式，包括通过pipx、Docker、Debian家族系统、BlackArch和Homebrew等。用户可以输入一个或多个用户名进行搜索，搜索结果将被保存到单独的文本文件中，文件名与用户名对应（例如，user123.txt）。

Sherlock提供了丰富的选项来定制搜索行为，如是否使用Tor网络以增加隐私保护、是否输出CSV或Excel格式的结果、以及限制搜索的社交网站类型。此外，用户可以选择是否输出找不到用户名的站点信息，以及控制终端输出的颜色显示。

在开发和维护方面，Sherlock得到了社区的广泛支持，感谢所有贡献者为该项目所做的努力。该项目遵循MIT许可协议，鼓励用户自由使用、修改和分发。

通过使用Sherlock，用户可以在一个集中化的工具中执行跨平台的社交网络用户名搜索任务，简化了查找过程，提高了效率。 <div>
<p>Hunt down social media accounts by username across social networks</p><hr /><p align="center"> <br /> <a href="https://sherlock-project.github.io/" target="_blank"><img src="https://raw.githubusercontent.com/sherlock-project/sherlock/master/images/sherlock-logo.png" /></a> <br /> <span>Hunt down social media accounts by username across <a href="https://sherlockproject.xyz/sites">400+ social networks</a></span> <br /> </p> 
<p align="center"> <a href="https://sherlockproject.xyz/installation">Installation</a> &nbsp;&nbsp;&nbsp;•&nbsp;&nbsp;&nbsp; <a href="https://sherlockproject.xyz/usage">Usage</a> &nbsp;&nbsp;&nbsp;•&nbsp;&nbsp;&nbsp; <a href="https://sherlockproject.xyz/contribute">Contributing</a> </p> 
<p align="center"> <img height="70%" src="https://raw.githubusercontent.com/sherlock-project/sherlock/master/images/demo.png" width="70%" />  </p> 
<h2>Installation</h2> 
<table> 
 <thead> 
  <tr> 
   <th></th> 
   <th>Command</th> 
   <th>Notes</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>PyPI</td> 
   <td><code>pipx install sherlock-project</code></td> 
   <td><code>pip</code> may be used in place of <code>pipx</code></td> 
  </tr> 
  <tr> 
   <td>Docker</td> 
   <td><code>docker pull sherlock/sherlock</code></td> 
   <td></td> 
  </tr> 
  <tr> 
   <td>Debian family</td> 
   <td><code>apt install sherlock</code></td> 
   <td>Kali, Parrot, Debian Testing and Sid</td> 
  </tr> 
  <tr> 
   <td>BlackArch</td> 
   <td><code>pacman -S sherlock</code></td> 
   <td></td> 
  </tr> 
  <tr> 
   <td>Homebrew</td> 
   <td><code>brew install sherlock</code></td> 
   <td></td> 
  </tr> 
 </tbody> 
</table> 
<p>See all alternative installation methods <a href="https://sherlockproject.xyz/installation">here</a></p> 
<h2>Usage</h2> 
<p>To search for only one user:</p> 
<pre><code class="language-bash">sherlock user123
</code></pre> 
<p>To search for more than one user:</p> 
<pre><code class="language-bash">sherlock user1 user2 user3
</code></pre> 
<p>Accounts found will be stored in an individual text file with the corresponding username (e.g <code>user123.txt</code>).</p> 
<pre><code class="language-console">$ sherlock --help
usage: sherlock [-h] [--version] [--verbose] [--folderoutput FOLDEROUTPUT]
                [--output OUTPUT] [--tor] [--unique-tor] [--csv] [--xlsx]
                [--site SITE_NAME] [--proxy PROXY_URL] [--json JSON_FILE]
                [--timeout TIMEOUT] [--print-all] [--print-found] [--no-color]
                [--browse] [--local] [--nsfw]
                USERNAMES [USERNAMES ...]

Sherlock: Find Usernames Across Social Networks (Version 0.14.3)

positional arguments:
  USERNAMES             One or more usernames to check with social networks.
                        Check similar usernames using {?} (replace to '_', '-', '.').

optional arguments:
  -h, --help            show this help message and exit
  --version             Display version information and dependencies.
  --verbose, -v, -d, --debug
                        Display extra debugging information and metrics.
  --folderoutput FOLDEROUTPUT, -fo FOLDEROUTPUT
                        If using multiple usernames, the output of the results will be
                        saved to this folder.
  --output OUTPUT, -o OUTPUT
                        If using single username, the output of the result will be saved
                        to this file.
  --tor, -t             Make requests over Tor; increases runtime; requires Tor to be
                        installed and in system path.
  --unique-tor, -u      Make requests over Tor with new Tor circuit after each request;
                        increases runtime; requires Tor to be installed and in system
                        path.
  --csv                 Create Comma-Separated Values (CSV) File.
  --xlsx                Create the standard file for the modern Microsoft Excel
                        spreadsheet (xlsx).
  --site SITE_NAME      Limit analysis to just the listed sites. Add multiple options to
                        specify more than one site.
  --proxy PROXY_URL, -p PROXY_URL
                        Make requests over a proxy. e.g. socks5://127.0.0.1:1080
  --json JSON_FILE, -j JSON_FILE
                        Load data from a JSON file or an online, valid, JSON file.
  --timeout TIMEOUT     Time (in seconds) to wait for response to requests (Default: 60)
  --print-all           Output sites where the username was not found.
  --print-found         Output sites where the username was found.
  --no-color            Don't color terminal output
  --browse, -b          Browse to all results on default browser.
  --local, -l           Force the use of the local data.json file.
  --nsfw                Include checking of NSFW sites from default list.
</code></pre> 
<h2>Credits</h2> 
<p>Thank you to everyone who has contributed to Sherlock! ❤️</p> 
<a href="https://github.com/sherlock-project/sherlock/graphs/contributors"> <img src="https://contrib.rocks/image?&amp;columns=25&amp;max=10000&amp;&amp;repo=sherlock-project/sherlock" /> </a> 
 
 <source media="(prefers-color-scheme: dark)" /> 
 <source media="(prefers-color-scheme: light)" /> 
 <img alt="Sherlock Project Star History Chart" src="https://api.star-history.com/svg?repos=sherlock-project/sherlock&amp;type=Date" /> 
 
<h2>License</h2> 
<p>MIT © Sherlock Project<br /> Original Creator - <a href="https://github.com/sdushantha">Siddharth Dushantha</a></p> 
<!-- Reference Links -->
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OpenBB-finance/OpenBB</title>
<link>https://github.com/OpenBB-finance/OpenBB</link>
<guid>https://github.com/OpenBB-finance/OpenBB</guid>
<content:encoded><![CDATA[
<div> 关键词：OpenBB平台、免费、开源、AI金融分析、社区贡献

总结:
本文介绍了一款名为OpenBB的全新金融平台，其特点在于免费、开源，为用户提供股票、期权、加密货币、外汇、宏观经济、固定收益等多种投资选项。该平台不仅提供广泛的用户自定义扩展功能，还推出了基于AI的金融分析师代理服务，旨在为用户提供全面的数据访问和分析工具。

OpenBB平台支持两种安装方式：通过pip安装CLI或直接从GitHub克隆代码。CLI提供了命令行界面，使得用户可以直接从终端访问平台功能，同时保持与主平台一致的外观和体验。

对于希望参与项目贡献的用户，文章鼓励成为贡献者，并提供了详细的指南和途径，如创建GitHub问题、参与社区讨论等。此外，平台强调了对用户反馈的重视，欢迎用户在多种社交媒体平台上提供反馈。

项目遵循AGPLv3许可证发布，强调了风险提示，包括但不限于交易风险、数据准确性以及对第三方品牌使用的说明。最后，文章提供了多种联系方式，供用户咨询或寻求合作机会。 <div>
<p>Investment Research for Everyone, Everywhere.</p><hr /><br /> 
<img alt="OpenBB Terminal logo" src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" width="600" /> 
<img alt="OpenBB Terminal logo" src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" width="600" /> 
<br /> 
<br /> 
<p><a href="https://twitter.com/openbb_finance"><img alt="Twitter" src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance" /></a> <img alt="Discord Shield" src="https://discordapp.com/api/guilds/831165782750789672/widget.png?style=shield" /> <a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"><img alt="Open in Dev Containers" src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode" /></a> <a href="https://codespaces.new/OpenBB-finance/OpenBBTerminal"> <img height="20" src="https://github.com/codespaces/badge.svg?sanitize=true" /> </a> <a href="https://colab.research.google.com/github/OpenBB-finance/OpenBBTerminal/blob/develop/examples/googleColab.ipynb" target="_blank"> <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" /> </a> <a href="https://pypi.org/project/openbb/"><img alt="PyPI" src="https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package" /></a></p> 
<p>The first financial Platform that is free and fully open source.</p> 
<p>Offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.</p> 
<p>Sign up to the <a href="https://my.openbb.co/login">OpenBB Hub</a> to get the most out of the OpenBB ecosystem.</p> 
<p>We have also open source an AI financial analyst agent that can access all the data within OpenBB, and that repo can be found <a href="https://github.com/OpenBB-finance/openbb-agents">here</a>.</p> 
<hr /> 
<p>If you are looking for the first AI financial terminal for professionals, the OpenBB Terminal Pro can be found at <a href="https://pro.openbb.co">pro.openbb.co</a></p> 
<a href="https://pro.openbb.co"> 
 <div align="center"> 
  <img alt="Logo" src="https://openbb.co/api/image?src=%252Fassets%252Fimages%252Fhome%252Fhero.png&amp;width=2400&amp;fit=cover&amp;position=center&amp;background%5B%5D=0&amp;background%5B%5D=0&amp;background%5B%5D=0&amp;background%5B%5D=0&amp;quality=100&amp;compressionLevel=9&amp;loop=0&amp;delay=100&amp;crop=null" width="600" /> 
 </div> </a> 
<hr /> 
<!-- TABLE OF CONTENTS --> 
<details> 
 <h2 style="display: inline-block;">Table of Contents</h2> 
 <ol> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation">Installation</a></li> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing">Contributing</a></li> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license">License</a></li> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer">Disclaimer</a></li> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts">Contacts</a></li> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history">Star History</a></li> 
  <li><a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors">Contributors</a></li> 
 </ol> 
</details> 
<h2>1. Installation</h2> 
<p>The OpenBB Platform can be installed as a <a href="https://pypi.org/project/openbb/">PyPI package</a> by running <code>pip install openbb</code></p> 
<p>or by cloning the repository directly with <code>git clone https://github.com/OpenBB-finance/OpenBB.git</code>.</p> 
<p>Please find more about the installation process in the <a href="https://docs.openbb.co/platform/installation">OpenBB Documentation</a>.</p> 
<h3>OpenBB Platform CLI installation</h3> 
<p>The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your terminal.</p> 
<p>It can be installed by running <code>pip install openbb-cli</code></p> 
<p>or by cloning the repository directly with <code>git clone https://github.com/OpenBB-finance/OpenBB.git</code>.</p> 
<p>Please find more about the installation process in the <a href="https://docs.openbb.co/cli/installation">OpenBB Documentation</a>.</p> 
<blockquote> 
 <p>The OpenBB Platform CLI offers an alternative to the former <a href="https://github.com/OpenBB-finance/LegacyTerminal">OpenBB Terminal</a> as it has the same look and feel while offering the functionalities and extendability of the OpenBB Platform.</p> 
</blockquote> 
<h2>2. Contributing</h2> 
<p>There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)</p> 
<h3>Become a Contributor</h3> 
<ul> 
 <li>More information on our <a href="https://docs.openbb.co/platform/developer_guide/contributing">Contributing Documentation</a>.</li> 
</ul> 
<h3>Create a GitHub ticket</h3> 
<p>Before creating a ticket make sure the one you are creating doesn't exist already <a href="https://github.com/OpenBB-finance/OpenBB/issues">here</a></p> 
<ul> 
 <li><a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D">Report bug</a></li> 
 <li><a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D">Suggest improvement</a></li> 
 <li><a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D">Request a feature</a></li> 
</ul> 
<h3>Provide feedback</h3> 
<p>We are most active on <a href="https://openbb.co/discord">our Discord</a>, but feel free to reach out to us in any of <a href="https://openbb.co/links">our social media</a> for feedback.</p> 
<h2>3. License</h2> 
<p>Distributed under the AGPLv3 License. See <a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE">LICENSE</a> for more information.</p> 
<h2>4. Disclaimer</h2> 
<p>Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.</p> 
<p>Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.</p> 
<p>The data contained in the OpenBBTerminal is not necessarily accurate.</p> 
<p>OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.</p> 
<p>All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties. Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.</p> 
<h2>5. Contacts</h2> 
<p>If you have any questions about the terminal or anything OpenBB, feel free to email us at <code>support@openbb.co</code></p> 
<p>If you want to say hi, or are interested in partnering with us, feel free to reach us at <code>hello@openbb.co</code></p> 
<p>Any of our social media platforms: <a href="https://openbb.co/links">openbb.co/links</a></p> 
<h2>6. Star History</h2> 
<p>This is a proxy of our growth and that we are just getting started.</p> 
<p>But for more metrics important to us check <a href="https://openbb.co/open">openbb.co/open</a>.</p> 
<p><a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBBTerminal&amp;type=Date&amp;theme=dark"><img alt="Star History Chart" src="https://api.star-history.com/svg?repos=openbb-finance/OpenBBTerminal&amp;type=Date&amp;theme=dark" /></a></p> 
<h2>7. Contributors</h2> 
<p>OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.</p> 
<a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"> <img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBBTerminal" width="800" /> </a> 
<!-- MARKDOWN LINKS & IMAGES --> 
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>deepset-ai/haystack</title>
<link>https://github.com/deepset-ai/haystack</link>
<guid>https://github.com/deepset-ai/haystack</guid>
<content:encoded><![CDATA[
<div> 关键词：Haystack、LLM、检索增强生成（RAG）、文档搜索、问答系统

总结:

Haystack是一个全栈式自然语言处理（NLP）框架，旨在构建基于大型语言模型（LLM）的应用程序。它提供了从数据清理到训练、评估、推理等全生命周期管理工具，支持多种NLP任务，如检索增强生成（RAG）、文档搜索和问答系统。通过其技术中立性，用户可以灵活选择模型供应商或技术，并轻松替换组件。Haystack强调透明性和可扩展性，使用户能够构建自定义组件并集成到现有技术栈中。此外，它还提供了一个生态系统，鼓励社区贡献和第三方组件开发，以促进持续创新。通过使用Haystack，开发者能够构建复杂的决策支持系统，解决复杂查询和大规模文档的搜索问题，同时支持模型的预训练和微调以适应特定需求。 <div>
<p>🔍 LLM orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.</p><hr /><div align="center"> 
 <a href="https://haystack.deepset.ai/"><img alt="Green logo of a stylized white 'H' with the text 'Haystack, by deepset. Haystack 2.0 is live 🎉'&nbsp;Abstract green and yellow diagrams in the background." src="https://raw.githubusercontent.com/deepset-ai/haystack/main/docs/img/banner_20.png" /></a> 
 <table> 
  <thead> 
   <tr> 
    <th></th> 
    <th></th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr> 
    <td>CI/CD</td> 
    <td><a href="https://github.com/deepset-ai/haystack/actions/workflows/tests.yml"><img alt="Tests" src="https://github.com/deepset-ai/haystack/actions/workflows/tests.yml/badge.svg?sanitize=true" /></a> <a href="https://github.com/python/mypy"><img alt="types - Mypy" src="https://img.shields.io/badge/types-Mypy-blue.svg?sanitize=true" /></a> <a href="https://coveralls.io/github/deepset-ai/haystack?branch=main"><img alt="Coverage Status" src="https://coveralls.io/repos/github/deepset-ai/haystack/badge.svg?branch=main" /></a> <a href="https://github.com/astral-sh/ruff"><img alt="Ruff" src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json" /></a></td> 
   </tr> 
   <tr> 
    <td>Docs</td> 
    <td><a href="https://docs.haystack.deepset.ai"><img alt="Website" src="https://img.shields.io/website?label=documentation&amp;up_message=online&amp;url=https%3A%2F%2Fdocs.haystack.deepset.ai" /></a></td> 
   </tr> 
   <tr> 
    <td>Package</td> 
    <td><a href="https://pypi.org/project/haystack-ai/"><img alt="PyPI" src="https://img.shields.io/pypi/v/haystack-ai" /></a> <img alt="PyPI - Downloads" src="https://img.shields.io/pypi/dm/haystack-ai?color=blue&amp;logo=pypi&amp;logoColor=gold" /> <img alt="PyPI - Python Version" src="https://img.shields.io/pypi/pyversions/haystack-ai?logo=python&amp;logoColor=gold" /> <a href="https://anaconda.org/conda-forge/haystack-ai"><img alt="Conda Version" src="https://img.shields.io/conda/vn/conda-forge/haystack-ai.svg?sanitize=true" /></a> <a href="https://raw.githubusercontent.com/deepset-ai/haystack/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/deepset-ai/haystack?color=blue" /></a> <a href="https://github.com/deepset-ai/haystack/actions/workflows/license_compliance.yml"><img alt="License Compliance" src="https://github.com/deepset-ai/haystack/actions/workflows/license_compliance.yml/badge.svg?sanitize=true" /></a></td> 
   </tr> 
   <tr> 
    <td>Meta</td> 
    <td><a href="https://discord.com/invite/VBpFzsgRVF"><img alt="Discord" src="https://img.shields.io/discord/993534733298450452?logo=discord" /></a> <a href="https://twitter.com/haystack_ai"><img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/haystack_ai" /></a></td> 
   </tr> 
  </tbody> 
 </table> 
</div> 
<p><a href="https://haystack.deepset.ai/">Haystack</a> is an end-to-end LLM framework that allows you to build applications powered by LLMs, Transformer models, vector search and more. Whether you want to perform retrieval-augmented generation (RAG), document search, question answering or answer generation, Haystack can orchestrate state-of-the-art embedding models and LLMs into pipelines to build end-to-end NLP applications and solve your use case.</p> 
<h2>Installation</h2> 
<p>The simplest way to get Haystack is via pip:</p> 
<pre><code class="language-sh">pip install haystack-ai
</code></pre> 
<p>Haystack supports multiple installation methods including Docker images. For a comprehensive guide please refer to the <a href="https://docs.haystack.deepset.ai/v2.0/docs/installation">documentation</a>.</p> 
<h2>Documentation</h2> 
<p>If you're new to the project, check out <a href="https://haystack.deepset.ai/overview/intro">"What is Haystack?"</a> then go through the <a href="https://haystack.deepset.ai/overview/quick-start">"Get Started Guide"</a> and build your first LLM application in a matter of minutes. Keep learning with the <a href="https://haystack.deepset.ai/tutorials?v=2.0">tutorials</a>. For more advanced use cases, or just to get some inspiration, you can browse our Haystack recipes in the <a href="https://github.com/deepset-ai/haystack-cookbook">Cookbook</a>.</p> 
<p>At any given point, hit the <a href="https://docs.haystack.deepset.ai/v2.0/docs/intro">documentation</a> to learn more about Haystack, what can it do for you and the technology behind.</p> 
<h2>Features</h2> 
<blockquote> 
 <p>[!IMPORTANT] <strong>You are currently looking at the readme of Haystack 2.0</strong>. We are still maintaining Haystack 1.x to give everyone enough time to migrate to 2.0. <a href="https://github.com/deepset-ai/haystack/tree/v1.x">Switch to Haystack 1.x here</a>.</p> 
</blockquote> 
<ul> 
 <li><strong>Technology agnostic:</strong> Allow users the flexibility to decide what vendor or technology they want and make it easy to switch out any component for another. Haystack allows you to use and compare models available from OpenAI, Cohere and Hugging Face, as well as your own local models or models hosted on Azure, Bedrock and SageMaker.</li> 
 <li><strong>Explicit:</strong> Make it transparent how different moving parts can “talk” to each other so it's easier to fit your tech stack and use case.</li> 
 <li><strong>Flexible:</strong> Haystack provides all tooling in one place: database access, file conversion, cleaning, splitting, training, eval, inference, and more. And whenever custom behavior is desirable, it's easy to create custom components.</li> 
 <li><strong>Extensible:</strong> Provide a uniform and easy way for the community and third parties to build their own components and foster an open ecosystem around Haystack.</li> 
</ul> 
<p>Some examples of what you can do with Haystack:</p> 
<ul> 
 <li>Build <strong>retrieval augmented generation (RAG)</strong> by making use of one of the available vector databases and customizing your LLM interaction, the sky is the limit 🚀</li> 
 <li>Perform Question Answering <strong>in natural language</strong> to find granular answers in your documents.</li> 
 <li>Perform <strong>semantic search</strong> and retrieve documents according to meaning.</li> 
 <li>Build applications that can make complex decisions making to answer complex queries: such as systems that can resolve complex customer queries, do knowledge search on many disconnected resources and so on.</li> 
 <li>Scale to millions of docs using retrievers and production-scale components.</li> 
 <li>Use <strong>off-the-shelf models</strong> or <strong>fine-tune</strong> them to your data.</li> 
 <li>Use <strong>user feedback</strong> to evaluate, benchmark, and continuously improve your models.</li> 
</ul> 
<blockquote> 
 <p>[!TIP] <img height="30%" src="https://github.com/deepset-ai/haystack/raw/main/docs/img/deepset-cloud-logo-lightblue.png" width="30%" /></p> 
 <p>Are you looking for a managed solution that benefits from Haystack? <a href="https://www.deepset.ai/deepset-cloud?utm_campaign=developer-relations&amp;utm_source=haystack&amp;utm_medium=readme">deepset Cloud</a> is our fully managed, end-to-end platform to integrate LLMs with your data, which uses Haystack for the LLM pipelines architecture.</p> 
</blockquote> 
<h2>Telemetry</h2> 
<p>Haystack collects <strong>anonymous</strong> usage statistics of pipeline components. We receive an event every time these components are initialized. This way, we know which components are most relevant to our community.</p> 
<p>Read more about telemetry in Haystack or how you can opt out in <a href="https://docs.haystack.deepset.ai/v2.0/docs/telemetry">Haystack docs</a>.</p> 
<h2>🖖 Community</h2> 
<p>If you have a feature request or a bug report, feel free to open an <a href="https://github.com/deepset-ai/haystack/issues">issue in Github</a>. We regularly check these and you can expect a quick response. If you'd like to discuss a topic, or get more general advice on how to make Haystack work for your project, you can start a thread in <a href="https://github.com/deepset-ai/haystack/discussions">Github Discussions</a> or our <a href="https://discord.com/invite/VBpFzsgRVF">Discord channel</a>. We also check <a href="https://twitter.com/haystack_ai">𝕏 (Twitter)</a> and <a href="https://stackoverflow.com/questions/tagged/haystack">Stack Overflow</a>.</p> 
<h2>Contributing to Haystack</h2> 
<p>We are very open to the community's contributions - be it a quick fix of a typo, or a completely new feature! You don't need to be a Haystack expert to provide meaningful improvements. To learn how to get started, check out our <a href="https://github.com/deepset-ai/haystack/raw/main/CONTRIBUTING.md">Contributor Guidelines</a> first.</p> 
<p>There are several ways you can contribute to Haystack:</p> 
<ul> 
 <li>Contribute to the main Haystack project</li> 
 <li>Contribute an integration on <a href="https://github.com/deepset-ai/haystack-core-integrations">haystack-core-integrations</a></li> 
</ul> 
<blockquote> 
 <p>[!TIP] 👉 <strong><a href="https://github.com/orgs/deepset-ai/projects/14">Check out the full list of issues that are open to contributions</a></strong></p> 
</blockquote> 
<h2>Who Uses Haystack</h2> 
<p>Here's a list of projects and companies using Haystack. Want to add yours? Open a PR, add it to the list and let the world know that you use Haystack!</p> 
<ul> 
 <li><a href="https://www.airbus.com/en">Airbus</a></li> 
 <li><a href="https://www.al-enterprise.com/">Alcatel-Lucent</a></li> 
 <li><a href="https://www.apple.com/">Apple</a></li> 
 <li><a href="https://www.betterup.com/">BetterUp</a></li> 
 <li><a href="https://www.databricks.com/">Databricks</a></li> 
 <li><a href="https://deepset.ai/">Deepset</a></li> 
 <li><a href="https://www.deepset.ai/blog/improving-on-site-search-for-government-agencies-etalab">Etalab</a></li> 
 <li><a href="https://www.infineon.com/">Infineon</a></li> 
 <li><a href="https://github.com/intel/open-domain-question-and-answer#readme">Intel</a></li> 
 <li><a href="https://www.intelijus.ai/">Intelijus</a></li> 
 <li><a href="https://github.com/IntelLabs/fastRAG#readme">Intel Labs</a></li> 
 <li><a href="https://github.com/larsbaunwall/bricky#readme">LEGO</a></li> 
 <li><a href="https://netflix.com">Netflix</a></li> 
 <li><a href="https://www.nos.pt/en/welcome">NOS Portugal</a></li> 
 <li><a href="https://developer.nvidia.com/blog/reducing-development-time-for-intelligent-virtual-assistants-in-contact-centers/">Nvidia</a></li> 
 <li><a href="https://github.com/PostHog/max-ai#readme">PostHog</a></li> 
 <li><a href="https://www.rakuten.com/">Rakuten</a></li> 
 <li><a href="https://www.deepset.ai/blog/advanced-neural-search-with-sooth-ai">Sooth.ai</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>bluenviron/mediamtx</title>
<link>https://github.com/bluenviron/mediamtx</link>
<guid>https://github.com/bluenviron/mediamtx</guid>
<content:encoded><![CDATA[
<p>Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.</p><hr /><h1 align="center"> <img alt="MediaMTX / rtsp-simple-server" src="https://raw.githubusercontent.com/bluenviron/mediamtx/main/logo.png" /> <br /> <br /> <p><a href="https://github.com/bluenviron/mediamtx/actions?query=workflow:test"><img alt="Test" src="https://github.com/bluenviron/mediamtx/workflows/test/badge.svg?sanitize=true" /></a> <a href="https://github.com/bluenviron/mediamtx/actions?query=workflow:lint"><img alt="Lint" src="https://github.com/bluenviron/mediamtx/workflows/lint/badge.svg?sanitize=true" /></a> <a href="https://app.codecov.io/gh/bluenviron/mediamtx/branch/main"><img alt="CodeCov" src="https://codecov.io/gh/bluenviron/mediamtx/branch/main/graph/badge.svg?sanitize=true" /></a> <a href="https://github.com/bluenviron/mediamtx/releases"><img alt="Release" src="https://img.shields.io/github/v/release/bluenviron/mediamtx" /></a> <a href="https://hub.docker.com/r/bluenviron/mediamtx"><img alt="Docker Hub" src="https://img.shields.io/badge/docker-bluenviron/mediamtx-blue" /></a> <a href="https://bluenviron.github.io/mediamtx"><img alt="API Documentation" src="https://img.shields.io/badge/api-documentation-blue" /></a></p> </h1> 
<br /> 
<p><em>MediaMTX</em> (formerly <em>rtsp-simple-server</em>) is a ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams. It has been conceived as a "media router" that routes media streams from one end to the other.</p> 
<p>Live streams can be published to the server with:</p> 
<table> 
 <thead> 
  <tr> 
   <th>protocol</th> 
   <th>variants</th> 
   <th>video codecs</th> 
   <th>audio codecs</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt-clients">SRT clients</a></td> 
   <td></td> 
   <td>H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt-cameras-and-servers">SRT cameras and servers</a></td> 
   <td></td> 
   <td>H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc-clients">WebRTC clients</a></td> 
   <td>Browser-based, WHIP</td> 
   <td>AV1, VP9, VP8, H265, H264</td> 
   <td>Opus, G722, G711 (PCMA, PCMU)</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc-servers">WebRTC servers</a></td> 
   <td>WHEP</td> 
   <td>AV1, VP9, VP8, H265, H264</td> 
   <td>Opus, G722, G711 (PCMA, PCMU)</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-clients">RTSP clients</a></td> 
   <td>UDP, TCP, RTSPS</td> 
   <td>AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-cameras-and-servers">RTSP cameras and servers</a></td> 
   <td>UDP, UDP-Multicast, TCP, RTSPS</td> 
   <td>AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp-clients">RTMP clients</a></td> 
   <td>RTMP, RTMPS, Enhanced RTMP</td> 
   <td>AV1, VP9, H265, H264</td> 
   <td>MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), G711 (PCMA, PCMU), LPCM</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp-cameras-and-servers">RTMP cameras and servers</a></td> 
   <td>RTMP, RTMPS, Enhanced RTMP</td> 
   <td>H264</td> 
   <td>MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3)</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#hls-cameras-and-servers">HLS cameras and servers</a></td> 
   <td>Low-Latency HLS, MP4-based HLS, legacy HLS</td> 
   <td>AV1, VP9, H265, H264</td> 
   <td>Opus, MPEG-4 Audio (AAC)</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#udpmpeg-ts">UDP/MPEG-TS</a></td> 
   <td>Unicast, broadcast, multicast</td> 
   <td>H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#raspberry-pi-cameras">Raspberry Pi Cameras</a></td> 
   <td></td> 
   <td>H264</td> 
   <td></td> 
  </tr> 
 </tbody> 
</table> 
<p>And can be read from the server with:</p> 
<table> 
 <thead> 
  <tr> 
   <th>protocol</th> 
   <th>variants</th> 
   <th>video codecs</th> 
   <th>audio codecs</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt">SRT</a></td> 
   <td></td> 
   <td>H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc">WebRTC</a></td> 
   <td>Browser-based, WHEP</td> 
   <td>AV1, VP9, VP8, H264</td> 
   <td>Opus, G722, G711 (PCMA, PCMU)</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp">RTSP</a></td> 
   <td>UDP, UDP-Multicast, TCP, RTSPS</td> 
   <td>AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp">RTMP</a></td> 
   <td>RTMP, RTMPS, Enhanced RTMP</td> 
   <td>H264</td> 
   <td>MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3)</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#hls">HLS</a></td> 
   <td>Low-Latency HLS, MP4-based HLS, legacy HLS</td> 
   <td>AV1, VP9, H265, H264</td> 
   <td>Opus, MPEG-4 Audio (AAC)</td> 
  </tr> 
 </tbody> 
</table> 
<p>And can be recorded and played back with:</p> 
<table> 
 <thead> 
  <tr> 
   <th>format</th> 
   <th>video codecs</th> 
   <th>audio codecs</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#record-streams-to-disk">fMP4</a></td> 
   <td>AV1, VP9, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM</td> 
  </tr> 
  <tr> 
   <td><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#record-streams-to-disk">MPEG-TS</a></td> 
   <td>H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video</td> 
   <td>Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3</td> 
  </tr> 
 </tbody> 
</table> 
<p><strong>Features</strong></p> 
<ul> 
 <li>Publish live streams to the server</li> 
 <li>Read live streams from the server</li> 
 <li>Streams are automatically converted from a protocol to another</li> 
 <li>Serve multiple streams at once in separate paths</li> 
 <li>Record streams to disk</li> 
 <li>Playback recorded streams</li> 
 <li>Authenticate users</li> 
 <li>Redirect readers to other RTSP servers (load balancing)</li> 
 <li>Control the server through the Control API</li> 
 <li>Reload the configuration without disconnecting existing clients (hot reloading)</li> 
 <li>Read Prometheus-compatible metrics</li> 
 <li>Run hooks (external commands) when clients connect, disconnect, read or publish streams</li> 
 <li>Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it's a single executable</li> 
</ul> 
<p><strong>Note about rtsp-simple-server</strong></p> 
<p><em>rtsp-simple-server</em> has been rebranded as <em>MediaMTX</em>. The reason is pretty obvious: this project started as a RTSP server but has evolved into a much more versatile product that is not tied to the RTSP protocol anymore. Nothing will change regarding license, features and backward compatibility.</p> 
<h2>Table of contents</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#installation">Installation</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#standalone-binary">Standalone binary</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#docker-image">Docker image</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#arch-linux-package">Arch Linux package</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#openwrt-binary">OpenWrt binary</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#basic-usage">Basic usage</a></li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#publish-to-the-server">Publish to the server</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#by-software">By software</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg">FFmpeg</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer">GStreamer</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#obs-studio">OBS Studio</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#opencv">OpenCV</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#web-browsers">Web browsers</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#by-device">By device</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#generic-webcam">Generic webcam</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#raspberry-pi-cameras">Raspberry Pi Cameras</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#by-protocol">By protocol</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt-clients">SRT clients</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt-cameras-and-servers">SRT cameras and servers</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc-clients">WebRTC clients</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc-servers">WebRTC servers</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-clients">RTSP clients</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-cameras-and-servers">RTSP cameras and servers</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp-clients">RTMP clients</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp-cameras-and-servers">RTMP cameras and servers</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#hls-cameras-and-servers">HLS cameras and servers</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#udpmpeg-ts">UDP/MPEG-TS</a></li> 
    </ul> </li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#read-from-the-server">Read from the server</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#by-software-1">By software</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg-1">FFmpeg</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer-1">GStreamer</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#vlc">VLC</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#web-browsers-1">Web browsers</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#by-protocol-1">By protocol</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt">SRT</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc">WebRTC</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp">RTSP</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp">RTMP</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#hls">HLS</a></li> 
    </ul> </li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#other-features">Other features</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#configuration">Configuration</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#authentication">Authentication</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#internal">Internal</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#http-based">HTTP-based</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#jwt-based">JWT-based</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#encrypt-the-configuration">Encrypt the configuration</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#remuxing-re-encoding-compression">Remuxing, re-encoding, compression</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#record-streams-to-disk">Record streams to disk</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#playback-recorded-streams">Playback recorded streams</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#forward-streams-to-other-servers">Forward streams to other servers</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#proxy-requests-to-other-servers">Proxy requests to other servers</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#on-demand-publishing">On-demand publishing</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#start-on-boot">Start on boot</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#linux">Linux</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#openwrt">OpenWrt</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#windows">Windows</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#hooks">Hooks</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#control-api">Control API</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#metrics">Metrics</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#pprof">pprof</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#srt-specific-features">SRT-specific features</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#standard-stream-id-syntax">Standard stream ID syntax</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc-specific-features">WebRTC-specific features</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#authenticating-with-whipwhep">Authenticating with WHIP/WHEP</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#solving-webrtc-connectivity-issues">Solving WebRTC connectivity issues</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#transport-protocols">Transport protocols</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#encryption">Encryption</a></li> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#corrupted-frames">Corrupted frames</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp-specific-features">RTMP-specific features</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#encryption-1">Encryption</a></li> 
    </ul> </li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#compile-from-source">Compile from source</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#standard">Standard</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#openwrt-1">OpenWrt</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#cross-compile">Cross compile</a></li> 
   <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#compile-for-all-supported-platforms">Compile for all supported platforms</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#license">License</a></li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#specifications">Specifications</a></li> 
 <li><a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#related-projects">Related projects</a></li> 
</ul> 
<h2>Installation</h2> 
<p>There are several installation methods available: standalone binary, Docker image, Arch Linux package and OpenWrt binary.</p> 
<h3>Standalone binary</h3> 
<ol> 
 <li> <p>Download and extract a standalone binary from the <a href="https://github.com/bluenviron/mediamtx/releases">release page</a> that corresponds to your operating system and architecture.</p> </li> 
 <li> <p>Start the server:</p> <pre><code class="language-sh">./mediamtx
</code></pre> </li> 
</ol> 
<h3>Docker image</h3> 
<p>Download and launch the image:</p> 
<pre><code>docker run --rm -it --network=host bluenviron/mediamtx:latest
</code></pre> 
<p>Available images:</p> 
<table> 
 <thead> 
  <tr> 
   <th>name</th> 
   <th>FFmpeg included</th> 
   <th>RPI Camera support</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>bluenviron/mediamtx:latest</td> 
   <td><span>❌</span></td> 
   <td><span>❌</span></td> 
  </tr> 
  <tr> 
   <td>bluenviron/mediamtx:latest-ffmpeg</td> 
   <td><span>✔</span></td> 
   <td><span>❌</span></td> 
  </tr> 
  <tr> 
   <td>bluenviron/mediamtx:latest-rpi</td> 
   <td><span>❌</span></td> 
   <td><span>✔</span></td> 
  </tr> 
  <tr> 
   <td>bluenviron/mediamtx:latest-ffmpeg-rpi</td> 
   <td><span>✔</span></td> 
   <td><span>✔</span></td> 
  </tr> 
 </tbody> 
</table> 
<p>The <code>--network=host</code> flag is mandatory since Docker can change the source port of UDP packets for routing reasons, and this doesn't allow the RTSP server to identify the senders of the packets. This issue can be avoided by disabling the UDP transport protocol:</p> 
<pre><code>docker run --rm -it \
-e MTX_PROTOCOLS=tcp \
-e MTX_WEBRTCADDITIONALHOSTS=192.168.x.x \
-p 8554:8554 \
-p 1935:1935 \
-p 8888:8888 \
-p 8889:8889 \
-p 8890:8890/udp \
-p 8189:8189/udp \
bluenviron/mediamtx
</code></pre> 
<p>set <code>MTX_WEBRTCADDITIONALHOSTS</code> to your local IP address.</p> 
<h3>Arch Linux package</h3> 
<p>If you are running the Arch Linux distribution, run:</p> 
<pre><code class="language-sh">git clone https://aur.archlinux.org/mediamtx.git
cd mediamtx
makepkg -si
</code></pre> 
<h3>OpenWrt binary</h3> 
<p>If the architecture of the OpenWrt device is amd64, armv6, armv7 or arm64, use the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#standalone-binary">standalone binary method</a> and download a Linux binary that corresponds to your architecture.</p> 
<p>Otherwise, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#openwrt-1">compile the server from source</a>.</p> 
<h2>Basic usage</h2> 
<ol> 
 <li> <p>Publish a stream. For instance, you can publish a video/audio file with <em>FFmpeg</em>:</p> <pre><code class="language-sh">ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream
</code></pre> <p>or <em>GStreamer</em>:</p> <pre><code class="language-sh">gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream filesrc location=file.mp4 \
! qtdemux name=d d.video_0 ! queue ! s.sink_0 d.audio_0 ! queue ! s.sink_1
</code></pre> </li> 
 <li> <p>Open the stream. For instance, you can open the stream with <em>VLC</em>:</p> <pre><code class="language-sh">vlc --network-caching=50 rtsp://localhost:8554/mystream
</code></pre> <p>or <em>GStreamer</em>:</p> <pre><code class="language-sh">gst-play-1.0 rtsp://localhost:8554/mystream
</code></pre> <p>or <em>FFmpeg</em>:</p> <pre><code class="language-sh">ffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4
</code></pre> </li> 
</ol> 
<h2>Publish to the server</h2> 
<h3>By software</h3> 
<h4>FFmpeg</h4> 
<p>FFmpeg can publish a stream to the server in multiple ways (SRT client, SRT server, RTSP client, RTMP client, UDP/MPEG-TS, WebRTC with WHIP). The recommended one consists in publishing as a <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-clients">RTSP client</a>:</p> 
<pre><code>ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream
</code></pre> 
<p>The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>). You can set the transport protocol by using the <code>rtsp_transport</code> flag, for instance, in order to use TCP:</p> 
<pre><code class="language-sh">ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp -rtsp_transport tcp rtsp://localhost:8554/mystream
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<h4>GStreamer</h4> 
<p>GStreamer can publish a stream to the server in multiple ways (SRT client, SRT server, RTSP client, RTMP client, UDP/MPEG-TS, WebRTC with WHIP). The recommended one consists in publishing as a <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-clients">RTSP client</a>:</p> 
<pre><code class="language-sh">gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream \
filesrc location=file.mp4 ! qtdemux name=d \
d.video_0 ! queue ! s.sink_0 \
d.audio_0 ! queue ! s.sink_1
</code></pre> 
<p>If the stream is video only:</p> 
<pre><code class="language-sh">gst-launch-1.0 filesrc location=file.mp4 ! qtdemux name=d \
d.video_0 ! rtspclientsink location=rtsp://localhost:8554/mystream
</code></pre> 
<p>The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>). You can set the transport protocol by using the <code>protocols</code> flag:</p> 
<pre><code class="language-sh">gst-launch-1.0 filesrc location=file.mp4 ! qtdemux name=d \
d.video_0 ! rtspclientsink protocols=tcp name=s location=rtsp://localhost:8554/mystream
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<p>GStreamer can also publish a stream by using the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc">WebRTC / WHIP protocol</a>. Make sure that GStreamer version is at least 1.22, and that if the codec is H264, the profile is baseline. Use the <code>whipclientsink</code> element:</p> 
<pre><code>gst-launch-1.0 videotestsrc \
! video/x-raw,width=1920,height=1080,format=I420 \
! x264enc speed-preset=ultrafast bitrate=2000 \
! video/x-h264,profile=baseline \
! whipclientsink signaller::whip-endpoint=http://localhost:8889/mystream/whip
</code></pre> 
<h4>OBS Studio</h4> 
<p>OBS Studio can publish to the server in multiple ways (SRT client, RTMP client, WebRTC client). The recommended one consists in publishing as a <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtmp-clients">RTMP client</a>. In <code>Settings -&gt; Stream</code> (or in the Auto-configuration Wizard), use the following parameters:</p> 
<ul> 
 <li>Service: <code>Custom...</code></li> 
 <li>Server: <code>rtmp://localhost</code></li> 
 <li>Stream key: <code>mystream</code></li> 
</ul> 
<p>If credentials are in use, use the following parameters:</p> 
<ul> 
 <li>Service: <code>Custom...</code></li> 
 <li>Server: <code>rtmp://localhost</code></li> 
 <li>Stream key: <code>mystream?user=myuser&amp;pass=mypass</code></li> 
</ul> 
<p>Save the configuration and click <code>Start streaming</code>.</p> 
<p>If you want to generate a stream that can be read with WebRTC, open <code>Settings -&gt; Output -&gt; Recording</code> and use the following parameters:</p> 
<ul> 
 <li>FFmpeg output type: <code>Output to URL</code></li> 
 <li>File path or URL: <code>rtsp://localhost:8554/mystream</code></li> 
 <li>Container format: <code>rtsp</code></li> 
 <li>Check <code>show all codecs (even if potentically incompatible)</code></li> 
 <li>Video encoder: <code>h264_nvenc (libx264)</code></li> 
 <li>Video encoder settings (if any): <code>bf=0</code></li> 
 <li>Audio track: <code>1</code></li> 
 <li>Audio encoder: <code>libopus</code></li> 
</ul> 
<p>Then use the button <code>Start Recording</code> (instead of <code>Start Streaming</code>) to start streaming.</p> 
<p>Latest versions of OBS Studio can publish to the server with the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc">WebRTC / WHIP protocol</a>. Use the following parameters:</p> 
<ul> 
 <li>Service: <code>WHIP</code></li> 
 <li>Server: <code>http://localhost:8889/mystream/whip</code></li> 
 <li>Bearer Token: <code>myuser:mypass</code> (if internal authentication is enabled) or JWT (if JWT-based authentication is enabled)</li> 
</ul> 
<p>Save the configuration and click <code>Start streaming</code>.</p> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<h4>OpenCV</h4> 
<p>OpenCV can publish to the server through its GStreamer plugin, as a <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-clients">RTSP client</a>. It must be compiled with GStreamer support, by following this procedure:</p> 
<pre><code class="language-sh">sudo apt install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-plugins-ugly gstreamer1.0-rtsp python3-dev python3-numpy
git clone --depth=1 -b 4.5.4 https://github.com/opencv/opencv
cd opencv
mkdir build &amp;&amp; cd build
cmake -D CMAKE_INSTALL_PREFIX=/usr -D WITH_GSTREAMER=ON ..
make -j$(nproc)
sudo make install
</code></pre> 
<p>You can check that OpenCV has been installed correctly by running:</p> 
<pre><code class="language-sh">python3 -c 'import cv2; print(cv2.getBuildInformation())'
</code></pre> 
<p>Check that the output contains <code>GStreamer: YES</code>.</p> 
<p>Videos can be published with <code>VideoWriter</code>:</p> 
<pre><code class="language-python">from datetime import datetime
from time import sleep, time

import cv2
import numpy as np

fps = 15
width = 800
height = 600
colors = [
    (0, 0, 255),
    (255, 0, 0),
    (0, 255, 0),
]

out = cv2.VideoWriter('appsrc ! videoconvert' + \
    ' ! video/x-raw,format=I420' + \
    ' ! x264enc speed-preset=ultrafast bitrate=600 key-int-max=' + str(fps * 2) + \
    ' ! video/x-h264,profile=baseline' + \
    ' ! rtspclientsink location=rtsp://localhost:8554/mystream',
    cv2.CAP_GSTREAMER, 0, fps, (width, height), True)
if not out.isOpened():
    raise Exception("can't open video writer")

curcolor = 0
start = time()

while True:
    frame = np.zeros((height, width, 3), np.uint8)

    # create a rectangle
    color = colors[curcolor]
    curcolor += 1
    curcolor %= len(colors)
    for y in range(0, int(frame.shape[0] / 2)):
        for x in range(0, int(frame.shape[1] / 2)):
            frame[y][x] = color

    out.write(frame)
    print("%s frame written to the server" % datetime.now())

    now = time()
    diff = (1 / fps) - now - start
    if diff &gt; 0:
        sleep(diff)
    start = now
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<h4>Web browsers</h4> 
<p>Web browsers can publish a stream to the server by using the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc">WebRTC protocol</a>. Start the server and open the web page:</p> 
<pre><code>http://localhost:8889/mystream/publish
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<p>This web page can be embedded into another web page by using an iframe:</p> 
<pre><code class="language-html">&lt;iframe src="http://mediamtx-ip:8889/mystream/publish" scrolling="no"&gt;&lt;/iframe&gt;
</code></pre> 
<p>For more advanced setups, you can create and serve a custom web page by starting from the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/internal/servers/webrtc/publish_index.html">source code of the WebRTC publish page</a>.</p> 
<h3>By device</h3> 
<h4>Generic webcam</h4> 
<p>If the OS is Linux-based, edit <code>mediamtx.yml</code> and replace everything inside section <code>paths</code> with the following content:</p> 
<pre><code class="language-yml">paths:
  cam:
    runOnInit: ffmpeg -f v4l2 -i /dev/video0 -pix_fmt yuv420p -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH
    runOnInitRestart: yes
</code></pre> 
<p>If the OS is Windows:</p> 
<pre><code class="language-yml">paths:
  cam:
    runOnInit: ffmpeg -f dshow -i video="USB2.0 HD UVC WebCam" -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH
    runOnInitRestart: yes
</code></pre> 
<p>Where <code>USB2.0 HD UVC WebCam</code> is the name of a webcam, that can be obtained with:</p> 
<pre><code class="language-sh">ffmpeg -list_devices true -f dshow -i dummy
</code></pre> 
<p>The resulting stream will be available in path <code>/cam</code>.</p> 
<h4>Raspberry Pi Cameras</h4> 
<p><em>MediaMTX</em> natively supports the Raspberry Pi Camera, enabling high-quality and low-latency video streaming from the camera to any user, for any purpose. There are a couple of requirements:</p> 
<ol> 
 <li> <p>The server must run on a Raspberry Pi, with one of the following operating systems:</p> 
  <ul> 
   <li>Raspberry Pi OS Bookworm</li> 
   <li>Raspberry Pi OS Bullseye</li> 
  </ul> <p>Both 32 bit and 64 bit architectures are supported.</p> </li> 
 <li> <p>If you are using Raspberry Pi OS Bullseye, make sure that the legacy camera stack is disabled. Type <code>sudo raspi-config</code>, then go to <code>Interfacing options</code>, <code>enable/disable legacy camera support</code>, choose <code>no</code>. Reboot the system.</p> </li> 
</ol> 
<p>If you want to run the standard (non-Docker) version of the server:</p> 
<ol> 
 <li> <p>Download the server executable. If you're using 64-bit version of the operative system, make sure to pick the <code>arm64</code> variant.</p> </li> 
 <li> <p>Edit <code>mediamtx.yml</code> and replace everything inside section <code>paths</code> with the following content:</p> <pre><code class="language-yml">paths:
  cam:
    source: rpiCamera
</code></pre> </li> 
</ol> 
<p>The resulting stream will be available in path <code>/cam</code>.</p> 
<p>If you want to run the server inside Docker, you need to use the <code>latest-rpi</code> image and launch the container with some additional flags:</p> 
<pre><code class="language-sh">docker run --rm -it \
--network=host \
--privileged \
--tmpfs /dev/shm:exec \
-v /run/udev:/run/udev:ro \
-e MTX_PATHS_CAM_SOURCE=rpiCamera \
bluenviron/mediamtx:latest-rpi
</code></pre> 
<p>Be aware that the server is not compatible with cameras that requires a custom <code>libcamera</code> (like some ArduCam products), since it comes with a bundled <code>libcamera</code>. If you want to use a custom one, you can <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#compile-from-source">compile from source</a>.</p> 
<p>Camera settings can be changed by using the <code>rpiCamera*</code> parameters:</p> 
<pre><code class="language-yml">paths:
  cam:
    source: rpiCamera
    rpiCameraWidth: 1920
    rpiCameraHeight: 1080
</code></pre> 
<p>All available parameters are listed in the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/mediamtx.yml">sample configuration file</a>.</p> 
<p>In order to add audio from a USB microfone, install GStreamer and alsa-utils:</p> 
<pre><code class="language-sh">sudo apt install -y gstreamer1.0-tools gstreamer1.0-rtsp gstreamer1.0-alsa alsa-utils
</code></pre> 
<p>list available audio cards with:</p> 
<pre><code class="language-sh">arecord -L
</code></pre> 
<p>Sample output:</p> 
<pre><code>surround51:CARD=ICH5,DEV=0
    Intel ICH5, Intel ICH5
    5.1 Surround output to Front, Center, Rear and Subwoofer speakers
default:CARD=U0x46d0x809
    USB Device 0x46d:0x809, USB Audio
    Default Audio Device
</code></pre> 
<p>Find the audio card of the microfone and take note of its name, for instance <code>default:CARD=U0x46d0x809</code>. Then create a new path that takes the video stream from the camera and audio from the microphone:</p> 
<pre><code class="language-yml">paths:
  cam:
    source: rpiCamera

  cam_with_audio:
    runOnInit: &gt;
      gst-launch-1.0
      rtspclientsink name=s location=rtsp://localhost:$RTSP_PORT/cam_with_audio
      rtspsrc location=rtsp://127.0.0.1:$RTSP_PORT/cam latency=0 ! rtph264depay ! s.
      alsasrc device=default:CARD=U0x46d0x809 ! opusenc bitrate=16000 ! s.
    runOnInitRestart: yes
</code></pre> 
<p>The resulting stream will be available in path <code>/cam_with_audio</code>.</p> 
<h3>By protocol</h3> 
<h4>SRT clients</h4> 
<p>SRT is a protocol that allows to publish and read live data stream, providing encryption, integrity and a retransmission mechanism. It is usually used to transfer media streams encoded with MPEG-TS. In order to publish a stream to the server with the SRT protocol, use this URL:</p> 
<pre><code>srt://localhost:8890?streamid=publish:mystream&amp;pkt_size=1316
</code></pre> 
<p>Replace <code>mystream</code> with any name you want. The resulting stream will be available in path <code>/mystream</code>.</p> 
<p>If credentials are enabled, append username and password to <code>streamid</code>:</p> 
<pre><code>srt://localhost:8890?streamid=publish:mystream:user:pass&amp;pkt_size=1316
</code></pre> 
<p>If you need to use the standard stream ID syntax instead of the custom one in use by this server, see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#standard-stream-id-syntax">Standard stream ID syntax</a>.</p> 
<p>If you want to publish a stream by using a client in listening mode (i.e. with <code>mode=listener</code> appended to the URL), read the next section.</p> 
<p>Known clients that can publish with SRT are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer">GStreamer</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#obs-studio">OBS Studio</a>.</p> 
<h4>SRT cameras and servers</h4> 
<p>In order to ingest into the server a SRT stream from an existing server, camera or client in listening mode (i.e. with <code>mode=listener</code> appended to the URL), add the corresponding URL into the <code>source</code> parameter of a path:</p> 
<pre><code class="language-yml">paths:
  proxied:
    # url of the source stream, in the format srt://host:port?streamid=streamid&amp;other_parameters
    source: srt://original-url
</code></pre> 
<h4>WebRTC clients</h4> 
<p>WebRTC is an API that makes use of a set of protocols and methods to connect two clients together and allow them to exchange real-time media or data streams. You can publish a stream with WebRTC and a web browser by visiting:</p> 
<pre><code>http://localhost:8889/mystream/publish
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<p>WHIP is a WebRTC extensions that allows to publish streams by using a URL, without passing through a web page. This allows to use WebRTC as a general purpose streaming protocol. If you are using a software that supports WHIP (for instance, latest versions of OBS Studio), you can publish a stream to the server by using this URL:</p> 
<pre><code>http://localhost:8889/mystream/whip
</code></pre> 
<p>Regarding authentication, read <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#authenticating-with-whipwhep">Authenticating with WHIP/WHEP</a>.</p> 
<p>Depending on the network it may be difficult to establish a connection between server and clients, read <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#solving-webrtc-connectivity-issues">Solving WebRTC connectivity issues</a>.</p> 
<p>Known clients that can publish with WebRTC and WHIP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer">GStreamer</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#obs-studio">OBS Studio</a>.</p> 
<h4>WebRTC servers</h4> 
<p>In order to ingest into the server a WebRTC stream from an existing server, add the corresponding WHEP URL into the <code>source</code> parameter of a path:</p> 
<pre><code class="language-yml">paths:
  proxied:
    # url of the source stream, in the format whep://host:port/path (HTTP) or wheps:// (HTTPS)
    source: wheps://host:port/path
</code></pre> 
<h4>RTSP clients</h4> 
<p>RTSP is a protocol that allows to publish and read streams. It supports different underlying transport protocols and allows to encrypt streams in transit (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>). In order to publish a stream to the server with the RTSP protocol, use this URL:</p> 
<pre><code>rtsp://localhost:8554/mystream
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<p>Known clients that can publish with RTSP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer">GStreamer</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#obs-studio">OBS Studio</a>.</p> 
<h4>RTSP cameras and servers</h4> 
<p>Most IP cameras expose their video stream by using a RTSP server that is embedded into the camera itself. In particular, cameras that are compliant with ONVIF profile S or T meet this requirement. You can use <em>MediaMTX</em> to connect to one or multiple existing RTSP servers and read their video streams:</p> 
<pre><code class="language-yml">paths:
  proxied:
    # url of the source stream, in the format rtsp://user:pass@host:port/path
    source: rtsp://original-url
</code></pre> 
<p>The resulting stream will be available in path <code>/proxied</code>.</p> 
<p>The server supports any number of source streams (count is just limited by available hardware resources) it's enough to add additional entries to the paths section:</p> 
<pre><code class="language-yml">paths:
  proxied1:
    source: rtsp://url1

  proxied2:
    source: rtsp://url1
</code></pre> 
<h4>RTMP clients</h4> 
<p>RTMP is a protocol that allows to read and publish streams, but is less versatile and less efficient than RTSP and WebRTC (doesn't support UDP, doesn't support most RTSP codecs, doesn't support feedback mechanism). Streams can be published to the server by using the URL:</p> 
<pre><code>rtmp://localhost/mystream
</code></pre> 
<p>The resulting stream will be available in path <code>/mystream</code>.</p> 
<p>In case authentication is enabled, credentials can be passed to the server by using the <code>user</code> and <code>pass</code> query parameters:</p> 
<pre><code>rtmp://localhost/mystream?user=myuser&amp;pass=mypass
</code></pre> 
<p>Known clients that can publish with RTMP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer">GStreamer</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#obs-studio">OBS Studio</a>.</p> 
<h4>RTMP cameras and servers</h4> 
<p>You can use <em>MediaMTX</em> to connect to one or multiple existing RTMP servers and read their video streams:</p> 
<pre><code class="language-yml">paths:
  proxied:
    # url of the source stream, in the format rtmp://user:pass@host:port/path
    source: rtmp://original-url
</code></pre> 
<p>The resulting stream will be available in path <code>/proxied</code>.</p> 
<h4>HLS cameras and servers</h4> 
<p>HLS is a streaming protocol that works by splitting streams into segments, and by serving these segments and a playlist with the HTTP protocol. You can use <em>MediaMTX</em> to connect to one or multiple existing HLS servers and read their video streams:</p> 
<pre><code class="language-yml">paths:
  proxied:
    # url of the playlist of the stream, in the format http://user:pass@host:port/path
    source: http://original-url/stream/index.m3u8
</code></pre> 
<p>The resulting stream will be available in path <code>/proxied</code>.</p> 
<h4>UDP/MPEG-TS</h4> 
<p>The server supports ingesting UDP/MPEG-TS packets (i.e. MPEG-TS packets sent with UDP). Packets can be unicast, broadcast or multicast. For instance, you can generate a multicast UDP/MPEG-TS stream with GStreamer:</p> 
<pre><code>gst-launch-1.0 -v mpegtsmux name=mux alignment=1 ! udpsink host=238.0.0.1 port=1234 \
videotestsrc ! video/x-raw,width=1280,height=720,format=I420 ! x264enc speed-preset=ultrafast bitrate=3000 key-int-max=60 ! video/x-h264,profile=high ! mux. \
audiotestsrc ! audioconvert ! avenc_aac ! mux.
</code></pre> 
<p>or FFmpeg:</p> 
<pre><code>ffmpeg -re -f lavfi -i testsrc=size=1280x720:rate=30 \
-pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k \
-f mpegts udp://238.0.0.1:1234?pkt_size=1316
</code></pre> 
<p>Edit <code>mediamtx.yml</code> and replace everything inside section <code>paths</code> with the following content:</p> 
<pre><code class="language-yml">paths:
  mypath:
    source: udp://238.0.0.1:1234
</code></pre> 
<p>The resulting stream will be available in path <code>/mypath</code>.</p> 
<p>Known clients that can publish with WebRTC and WHIP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg">FFmpeg</a> and <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer">GStreamer</a>.</p> 
<h2>Read from the server</h2> 
<h3>By software</h3> 
<h4>FFmpeg</h4> 
<p>FFmpeg can read a stream from the server in multiple ways (RTSP, RTMP, HLS, WebRTC with WHEP, SRT). The recommended one consists in reading with <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp">RTSP</a>:</p> 
<pre><code class="language-sh">ffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4
</code></pre> 
<p>The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>). You can set the transport protocol by using the <code>rtsp_transport</code> flag:</p> 
<pre><code class="language-sh">ffmpeg -rtsp_transport tcp -i rtsp://localhost:8554/mystream -c copy output.mp4
</code></pre> 
<h4>GStreamer</h4> 
<p>GStreamer can read a stream from the server in multiple ways (RTSP, RTMP, HLS, WebRTC with WHEP, SRT). The recommended one consists in reading with <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp">RTSP</a>:</p> 
<pre><code class="language-sh">gst-launch-1.0 rtspsrc location=rtsp://127.0.0.1:8554/mystream latency=0 ! decodebin ! autovideosink
</code></pre> 
<p>The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>). You can change the transport protocol by using the <code>protocols</code> flag:</p> 
<pre><code class="language-sh">gst-launch-1.0 rtspsrc protocols=tcp location=rtsp://127.0.0.1:8554/mystream latency=0 ! decodebin ! autovideosink
</code></pre> 
<p>If encryption is enabled, set <code>tls-validation-flags</code> to <code>0</code>:</p> 
<pre><code class="language-sh">gst-launch-1.0 rtspsrc tls-validation-flags=0 location=rtsps://ip:8322/...
</code></pre> 
<h4>VLC</h4> 
<p>VLC can read a stream from the server in multiple ways (RTSP, RTMP, HLS, SRT). The recommended one consists in reading with <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp">RTSP</a>:</p> 
<pre><code class="language-sh">vlc --network-caching=50 rtsp://localhost:8554/mystream
</code></pre> 
<p>The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>).</p> 
<p>In order to use the TCP transport protocol, use the <code>--rtsp_tcp</code> flag:</p> 
<pre><code class="language-sh">vlc --network-caching=50 --rtsp-tcp rtsp://localhost:8554/mystream
</code></pre> 
<p>In order to use the UDP-multicast transport protocol, append <code>?vlcmulticast</code> to the URL:</p> 
<pre><code class="language-sh">vlc --network-caching=50 rtsp://localhost:8554/mystream?vlcmulticast
</code></pre> 
<h5>Ubuntu bug</h5> 
<p>The VLC shipped with Ubuntu 21.10 doesn't support playing RTSP due to a license issue (see <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=982299">here</a> and <a href="https://stackoverflow.com/questions/69766748/cvlc-cannot-play-rtsp-omxplayer-instead-can">here</a>). To fix the issue, remove the default VLC instance and install the snap version:</p> 
<pre><code>sudo apt purge -y vlc
snap install vlc
</code></pre> 
<h5>Encrypted streams</h5> 
<p>At the moment VLC doesn't support reading encrypted RTSP streams. However, you can use a proxy like <a href="https://www.stunnel.org">stunnel</a> or <a href="https://nginx.org/">nginx</a> or a local <em>MediaMTX</em> instance to decrypt streams before reading them.</p> 
<h4>Web browsers</h4> 
<p>Web browsers can read a stream from the server in multiple ways (WebRTC or HLS).</p> 
<p>You can read a stream by using the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#webrtc-1">WebRTC protocol</a> by visiting the web page:</p> 
<pre><code>http://localhost:8889/mystream
</code></pre> 
<p>This web page can be embedded into another web page by using an iframe:</p> 
<pre><code class="language-html">&lt;iframe src="http://mediamtx-ip:8889/mystream" scrolling="no"&gt;&lt;/iframe&gt;
</code></pre> 
<p>For more advanced setups, you can create and serve a custom web page by starting from the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/internal/servers/webrtc/read_index.html">source code of the WebRTC read page</a>.</p> 
<p>Web browsers can also read a stream with the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#hls">HLS protocol</a>. Latency is higher but there are less problems related to connectivity between server and clients, furthermore the server load can be balanced by using a common HTTP CDN (like CloudFront or Cloudflare), and this allows to handle readers in the order of millions. Visit the web page:</p> 
<pre><code>http://localhost:8888/mystream
</code></pre> 
<p>This web page can be embedded into another web page by using an iframe:</p> 
<pre><code class="language-html">&lt;iframe src="http://mediamtx-ip:8888/mystream" scrolling="no"&gt;&lt;/iframe&gt;
</code></pre> 
<p>For more advanced setups, you can create and serve a custom web page by starting from the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/internal/servers/hls/index.html">source code of the HLS read page</a>.</p> 
<h3>By protocol</h3> 
<h4>SRT</h4> 
<p>SRT is a protocol that allows to publish and read live data stream, providing encryption, integrity and a retransmission mechanism. It is usually used to transfer media streams encoded with MPEG-TS. In order to read a stream from the server with the SRT protocol, use this URL:</p> 
<pre><code>srt://localhost:8890?streamid=read:mystream
</code></pre> 
<p>Replace <code>mystream</code> with the path name.</p> 
<p>If credentials are enabled, append username and password to <code>streamid</code>:</p> 
<pre><code>srt://localhost:8890?streamid=read:mystream:user:pass
</code></pre> 
<p>If you need to use the standard stream ID syntax instead of the custom one in use by this server, see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#standard-stream-id-syntax">Standard stream ID syntax</a>.</p> 
<p>Known clients that can read with SRT are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg-1">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer-1">GStreamer</a> and <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#vlc">VLC</a>.</p> 
<h4>WebRTC</h4> 
<p>WebRTC is an API that makes use of a set of protocols and methods to connect two clients together and allow them to exchange real-time media or data streams. You can read a stream with WebRTC and a web browser by visiting:</p> 
<pre><code>http://localhost:8889/mystream
</code></pre> 
<p>WHEP is a WebRTC extensions that allows to read streams by using a URL, without passing through a web page. This allows to use WebRTC as a general purpose streaming protocol. If you are using a software that supports WHEP, you can read a stream from the server by using this URL:</p> 
<pre><code>http://localhost:8889/mystream/whep
</code></pre> 
<p>Regarding authentication, read <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#authenticating-with-whipwhep">Authenticating with WHIP/WHEP</a>.</p> 
<p>Depending on the network it may be difficult to establish a connection between server and clients, read <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#solving-webrtc-connectivity-issues">Solving WebRTC connectivity issues</a>.</p> 
<p>Known clients that can read with WebRTC and WHEP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg-1">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer-1">GStreamer</a> and <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#web-browsers-1">web browsers</a>.</p> 
<h4>RTSP</h4> 
<p>RTSP is a protocol that allows to publish and read streams. It supports different underlying transport protocols and allows to encrypt streams in transit (see <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#rtsp-specific-features">RTSP-specific features</a>). In order to read a stream with the RTSP protocol, use this URL:</p> 
<pre><code>rtsp://localhost:8554/mystream
</code></pre> 
<p>Known clients that can read with RTSP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg-1">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer-1">GStreamer</a> and <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#vlc">VLC</a>.</p> 
<h5>Latency</h5> 
<p>The RTSP protocol doesn't introduce any latency by itself. Latency is usually introduced by clients, that put frames in a buffer to compensate network fluctuations. In order to decrease latency, the best way consists in tuning the client. For instance, in VLC, latency can be decreased by decreasing the <em>Network caching</em> parameter, that is available in the <em>Open network stream</em> dialog or alternatively can be set with the command line:</p> 
<pre><code>vlc --network-caching=50 rtsp://...
</code></pre> 
<h4>RTMP</h4> 
<p>RTMP is a protocol that allows to read and publish streams, but is less versatile and less efficient than RTSP and WebRTC (doesn't support UDP, doesn't support most RTSP codecs, doesn't support feedback mechanism). Streams can be read from the server by using the URL:</p> 
<pre><code>rtmp://localhost/mystream
</code></pre> 
<p>In case authentication is enabled, credentials can be passed to the server by using the <code>user</code> and <code>pass</code> query parameters:</p> 
<pre><code>rtmp://localhost/mystream?user=myuser&amp;pass=mypass
</code></pre> 
<p>Known clients that can read with RTMP are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg-1">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer-1">GStreamer</a> and <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#vlc">VLC</a>.</p> 
<h4>HLS</h4> 
<p>HLS is a protocol that works by splitting streams into segments, and by serving these segments and a playlist with the HTTP protocol. You can use <em>MediaMTX</em> to generate a HLS stream, that is accessible through a web page:</p> 
<pre><code>http://localhost:8888/mystream
</code></pre> 
<p>and can also be accessed without using the browsers, by software that supports the HLS protocol (for instance VLC or <em>MediaMTX</em> itself) by using this URL:</p> 
<pre><code>http://localhost:8888/mystream/index.m3u8
</code></pre> 
<p>Although the server can produce HLS with a variety of video and audio codecs (that are listed at the beginning of the README), not all browsers can read all codecs.</p> 
<p>You can check what codecs your browser can read by <a href="https://jsfiddle.net/g1qyf4ea">using this tool</a>.</p> 
<p>If you want to support most browsers, you can to re-encode the stream by using the H264 and AAC codecs, for instance by using FFmpeg:</p> 
<pre><code class="language-sh">ffmpeg -i rtsp://original-source \
-pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k \
-c:a aac -b:a 160k \
-f rtsp rtsp://localhost:8554/mystream
</code></pre> 
<p>Known clients that can read with HLS are <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#ffmpeg-1">FFmpeg</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#gstreamer-1">GStreamer</a>, <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#vlc">VLC</a> and <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#web-browsers-1">web browsers</a>.</p> 
<h5>LL-HLS</h5> 
<p>Low-Latency HLS is a recently standardized variant of the protocol that allows to greatly reduce playback latency. It works by splitting segments into parts, that are served before the segment is complete. LL-HLS is enabled by default. If the stream is not shown correctly, try tuning the hlsPartDuration parameter, for instance:</p> 
<pre><code class="language-yml">hlsPartDuration: 500ms
</code></pre> 
<h5>Compatibility with Apple devices</h5> 
<p>In order to correctly display Low-Latency HLS streams in Safari running on Apple devices (iOS or macOS), a TLS certificate is needed and can be generated with OpenSSL:</p> 
<pre><code class="language-sh">openssl genrsa -out server.key 2048
openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650
</code></pre> 
<p>Set the <code>hlsEncryption</code>, <code>hlsServerKey</code> and <code>hlsServerCert</code> parameters in the configuration file:</p> 
<pre><code class="language-yml">hlsEncryption: yes
hlsServerKey: server.key
hlsServerCert: server.crt
</code></pre> 
<p>Keep also in mind that not all H264 video streams can be played on Apple Devices due to some intrinsic properties (distance between I-Frames, profile). If the video can't be played correctly, you can either:</p> 
<ul> 
 <li> <p>re-encode it by following instructions in this README</p> </li> 
 <li> <p>disable the Low-latency variant of HLS and go back to the legacy variant:</p> <pre><code class="language-yml">  hlsVariant: mpegts
</code></pre> </li> 
</ul> 
<h5>Latency</h5> 
<p>in HLS, latency is introduced since a client must wait for the server to generate segments before downloading them. This latency amounts to 500ms-3s when the low-latency HLS variant is enabled (and it is by default), otherwise amounts to 1-15secs.</p> 
<p>To decrease the latency, you can:</p> 
<ul> 
 <li> <p>try decreasing the hlsPartDuration parameter</p> </li> 
 <li> <p>try decreasing the hlsSegmentDuration parameter</p> </li> 
 <li> <p>The segment duration is influenced by the interval between the IDR frames of the video track. An IDR frame is a frame that can be decoded independently from the others. The server changes the segment duration in order to include at least one IDR frame into each segment. Therefore, you need to decrease the interval between the IDR frames. This can be done in two ways:</p> 
  <ul> 
   <li> <p>if the stream is being hardware-generated (i.e. by a camera), there's usually a setting called Key-Frame Interval in the camera configuration page</p> </li> 
   <li> <p>otherwise, the stream must be re-encoded. It's possible to tune the IDR frame interval by using ffmpeg's -g option:</p> <pre><code class="language-sh">ffmpeg -i rtsp://original-stream -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -max_muxing_queue_size 1024 -g 30 -f rtsp rtsp://localhost:$RTSP_PORT/compressed
</code></pre> </li> 
  </ul> </li> 
</ul> 
<h2>Other features</h2> 
<h3>Configuration</h3> 
<p>All the configuration parameters are listed and commented in the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/mediamtx.yml">configuration file</a>.</p> 
<p>There are 3 ways to change the configuration:</p> 
<ol> 
 <li> <p>By editing the <code>mediamtx.yml</code> file, that is</p> 
  <ul> 
   <li> <p>included into the release bundle</p> </li> 
   <li> <p>available in the root folder of the Docker image (<code>/mediamtx.yml</code>); it can be overridden in this way:</p> <pre><code>docker run --rm -it --network=host -v $PWD/mediamtx.yml:/mediamtx.yml bluenviron/mediamtx
</code></pre> </li> 
  </ul> <p>The configuration can be changed dynamically when the server is running (hot reloading) by writing to the configuration file. Changes are detected and applied without disconnecting existing clients, whenever it's possible.</p> </li> 
 <li> <p>By overriding configuration parameters with environment variables, in the format <code>MTX_PARAMNAME</code>, where <code>PARAMNAME</code> is the uppercase name of a parameter. For instance, the <code>rtspAddress</code> parameter can be overridden in the following way:</p> <pre><code>MTX_RTSPADDRESS="127.0.0.1:8554" ./mediamtx
</code></pre> <p>Parameters that have array as value can be overridden by setting a comma-separated list. For example:</p> <pre><code>MTX_PROTOCOLS="tcp,udp"
</code></pre> <p>Parameters in maps can be overridden by using underscores, in the following way:</p> <pre><code>MTX_PATHS_TEST_SOURCE=rtsp://myurl ./mediamtx
</code></pre> <p>This method is particularly useful when using Docker; any configuration parameter can be changed by passing environment variables with the <code>-e</code> flag:</p> <pre><code>docker run --rm -it --network=host -e MTX_PATHS_TEST_SOURCE=rtsp://myurl bluenviron/mediamtx
</code></pre> </li> 
 <li> <p>By using the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#control-api">Control API</a>.</p> </li> 
</ol> 
<h3>Authentication</h3> 
<h4>Internal</h4> 
<p>The server provides three way to authenticate users:</p> 
<ul> 
 <li>Internal: users are stored in the configuration file</li> 
 <li>HTTP-based: an external HTTP URL is contacted to perform authentication</li> 
 <li>JWT: an external identity server provides authentication through JWTs</li> 
</ul> 
<p>The internal authentication method is the default one. Users are stored inside the configuration file, in this format:</p> 
<pre><code class="language-yml">authInternalUsers:
  # Username. 'any' means any user, including anonymous ones.
- user: any
  # Password. Not used in case of 'any' user.
  pass:
  # IPs or networks allowed to use this user. An empty list means any IP.
  ips: []
  # List of permissions.
  permissions:
    # Available actions are: publish, read, playback, api, metrics, pprof.
  - action: publish
    # Paths can be set to further restrict access to a specific path.
    # An empty path means any path.
    # Regular expressions can be used by using a tilde as prefix.
    path:
  - action: read
    path:
  - action: playback
    path:
</code></pre> 
<p>Only clients that provide username and passwords will be able to perform a certain action:</p> 
<pre><code>ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://myuser:mypass@localhost:8554/mystream
</code></pre> 
<p>If storing plain credentials in the configuration file is a security problem, username and passwords can be stored as hashed strings. The Argon2 and SHA256 hashing algorithms are supported. To use Argon2, the string must be hashed using Argon2id (recommended) or Argon2i:</p> 
<pre><code>echo -n "mypass" | argon2 saltItWithSalt -id -l 32 -e
</code></pre> 
<p>Then stored with the <code>argon2:</code> prefix:</p> 
<pre><code class="language-yml">authInternalUsers:
- user: argon2:$argon2id$v=19$m=4096,t=3,p=1$MTIzNDU2Nzg$OGGO0eCMN0ievb4YGSzvS/H+Vajx1pcbUmtLp2tRqRU
  pass: argon2:$argon2i$v=19$m=4096,t=3,p=1$MTIzNDU2Nzg$oct3kOiFywTdDdt19kT07hdvmsPTvt9zxAUho2DLqZw
  permissions:
  - action: publish
</code></pre> 
<p>To use SHA256, the string must be hashed with SHA256 and encoded with base64:</p> 
<pre><code>echo -n "mypass" | openssl dgst -binary -sha256 | openssl base64
</code></pre> 
<p>Then stored with the <code>sha256:</code> prefix:</p> 
<pre><code class="language-yml">authInternalUsers:
- user: sha256:j1tsRqDEw9xvq/D7/9tMx6Jh/jMhk3UfjwIB2f1zgMo=
  pass: sha256:BdSWkrdV+ZxFBLUQQY7+7uv9RmiSVA8nrPmjGjJtZQQ=
  permissions:
  - action: publish
</code></pre> 
<p><strong>WARNING</strong>: enable encryption or use a VPN to ensure that no one is intercepting the credentials in transit.</p> 
<h4>HTTP-based</h4> 
<p>Authentication can be delegated to an external HTTP server:</p> 
<pre><code class="language-yml">authMethod: http
authHTTPAddress: http://myauthserver/auth
</code></pre> 
<p>Each time a user needs to be authenticated, the specified URL will be requested with the POST method and this payload:</p> 
<pre><code class="language-json">{
  "user": "user",
  "password": "password",
  "ip": "ip",
  "action": "publish|read|playback|api|metrics|pprof",
  "path": "path",
  "protocol": "rtsp|rtmp|hls|webrtc|srt",
  "id": "id",
  "query": "query"
}
</code></pre> 
<p>If the URL returns a status code that begins with <code>20</code> (i.e. <code>200</code>), authentication is successful, otherwise it fails. Be aware that it's perfectly normal for the authentication server to receive requests with empty users and passwords, i.e.:</p> 
<pre><code class="language-json">{
  "user": "",
  "password": ""
}
</code></pre> 
<p>This happens because RTSP clients don't provide credentials until they are asked to. In order to receive the credentials, the authentication server must reply with status code <code>401</code>, then the client will send credentials.</p> 
<p>Some actions can be excluded from the process:</p> 
<pre><code class="language-yml"># Actions to exclude from HTTP-based authentication.
# Format is the same as the one of user permissions.
authHTTPExclude:
- action: api
- action: metrics
- action: pprof
</code></pre> 
<h4>JWT-based</h4> 
<p>Authentication can be delegated to an external identity server, that is capable of generating JWTs and provides a JWKS endpoint. With respect to the HTTP-based method, this has the advantage that the external server is contacted just once, and not for every request, greatly improving performance. In order to use the JWT-based authentication method, set <code>authMethod</code> and <code>authJWTJWKS</code>:</p> 
<pre><code class="language-yml">authMethod: jwt
authJWTJWKS: http://my_identity_server/jwks_endpoint
authJWTClaimKey: mediamtx_permissions
</code></pre> 
<p>The JWT is expected to contain a claim, with a list of permissions in the same format as the one of user permissions:</p> 
<pre><code class="language-json">{
 "mediamtx_permissions": [
    {
      "action": "publish",
      "path": ""
    }
  ]
}
</code></pre> 
<p>Clients are expected to pass the JWT in the Authorization header (in case of HLS and WebRTC) or in query parameters (in case of all other protocols), for instance:</p> 
<pre><code>ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream?jwt=MY_JWT
</code></pre> 
<p>For instance (HLS):</p> 
<pre><code>GET /mypath/index.m3u8 HTTP/1.1
Host: example.com
Authorization: Bearer MY_JWT
</code></pre> 
<p>Here's a tutorial on how to setup the <a href="https://www.keycloak.org/">Keycloak identity server</a> in order to provide such JWTs:</p> 
<ol> 
 <li> <p>Start Keycloak:</p> <pre><code>docker run --name=keycloak -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:23.0.7 start-dev
</code></pre> </li> 
 <li> <p>Open the Keycloak administration console on <a href="http://localhost:8080">http://localhost:8080</a>, click on <em>master</em> in the top left corner, <em>create realm</em>, set realm name to <code>mediamtx</code>, Save</p> </li> 
 <li> <p>Open page <em>Client scopes</em>, <em>create client scope</em>, set name to <code>mediamtx</code>, Save</p> </li> 
 <li> <p>Open tab <em>Mappers</em>, <em>Configure a new Mapper</em>, <em>User Attribute</em></p> 
  <ul> 
   <li>Name: <code>mediamtx_permissions</code></li> 
   <li>User Attribute: <code>mediamtx_permissions</code></li> 
   <li>Token Claim Name: <code>mediamtx_permissions</code></li> 
   <li>Claim JSON Type: <code>JSON</code></li> 
   <li>Multivalued: <code>On</code></li> 
  </ul> <p>Save</p> </li> 
 <li> <p>Open page <em>Clients</em>, <em>Create client</em>, set Client ID to <code>mediamtx</code>, Next, Client authentication <code>On</code>, Next, Save</p> </li> 
 <li> <p>Open tab <em>Credentials</em>, copy client secret somewhere</p> </li> 
 <li> <p>Open tab <em>Client scopes</em>, <em>Add client scope</em>, Select <code>mediamtx</code>, Add, Default</p> </li> 
 <li> <p>Open page <em>Users</em>, <em>Create user</em>, Username <code>testuser</code>, Tab credentials, <em>Set password</em>, pick a password, Save</p> </li> 
 <li> <p>Open tab <em>Attributes</em>, <em>Add an attribute</em></p> 
  <ul> 
   <li>Key: <code>mediamtx_permissions</code></li> 
   <li>Value: <code>{"action":"publish", "paths": "all"}</code></li> 
  </ul> <p>You can add as many attributes with key <code>mediamtx_permissions</code> as you want, each with a single permission in it</p> </li> 
 <li> <p>In MediaMTX, use the following URL:</p> <pre><code class="language-yml">authJWTJWKS: http://localhost:8080/realms/mediamtx/protocol/openid-connect/certs
</code></pre> </li> 
 <li> <p>Perform authentication on Keycloak:</p> <pre><code>curl \
-d "client_id=mediamtx" \
-d "client_secret=$CLIENT_SECRET" \
-d "username=$USER" \
-d "password=$PASS" \
-d "grant_type=password" \
http://localhost:8080/realms/mediamtx/protocol/openid-connect/token
</code></pre> <p>The JWT is inside the <code>access_token</code> key of the response:</p> <pre><code class="language-json">{"access_token":"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICIyNzVjX3ptOVlOdHQ0TkhwWVk4Und6ZndUclVGSzRBRmQwY3lsM2wtY3pzIn0.eyJleHAiOjE3MDk1NTUwOTIsImlhdCI6MTcwOTU1NDc5MiwianRpIjoiMzE3ZTQ1NGUtNzczMi00OTM1LWExNzAtOTNhYzQ2ODhhYWIxIiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MDgwL3JlYWxtcy9tZWRpYW10eCIsImF1ZCI6ImFjY291bnQiLCJzdWIiOiI2NTBhZDA5Zi03MDgxLTQyNGItODI4Ni0xM2I3YTA3ZDI0MWEiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJtZWRpYW10eCIsInNlc3Npb25fc3RhdGUiOiJjYzJkNDhjYy1kMmU5LTQ0YjAtODkzZS0wYTdhNjJiZDI1YmQiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIi8qIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1tZWRpYW10eCJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoibWVkaWFtdHggcHJvZmlsZSBlbWFpbCIsInNpZCI6ImNjMmQ0OGNjLWQyZTktNDRiMC04OTNlLTBhN2E2MmJkMjViZCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibWVkaWFtdHhfcGVybWlzc2lvbnMiOlt7ImFjdGlvbiI6InB1Ymxpc2giLCJwYXRocyI6ImFsbCJ9XSwicHJlZmVycmVkX3VzZXJuYW1lIjoidGVzdHVzZXIifQ.Gevz7rf1qHqFg7cqtSfSP31v_NS0VH7MYfwAdra1t6Yt5rTr9vJzqUeGfjYLQWR3fr4XC58DrPOhNnILCpo7jWRdimCnbPmuuCJ0AYM-Aoi3PAsWZNxgmtopq24_JokbFArY9Y1wSGFvF8puU64lt1jyOOyxf2M4cBHCs_EarCKOwuQmEZxSf8Z-QV9nlfkoTUszDCQTiKyeIkLRHL2Iy7Fw7_T3UI7sxJjVIt0c6HCNJhBBazGsYzmcSQ_GrmhbUteMTg00o6FicqkMBe99uZFnx9wIBm_QbO9hbAkkzF923I-DTAQrFLxT08ESMepDwmzFrmnwWYBLE3u8zuUlCA","expires_in":300,"refresh_expires_in":1800,"refresh_token":"eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI3OTI3Zjg4Zi05YWM4LTRlNmEtYWE1OC1kZmY0MDQzZDRhNGUifQ.eyJleHAiOjE3MDk1NTY1OTIsImlhdCI6MTcwOTU1NDc5MiwianRpIjoiMGVhZWFhMWItYzNhMC00M2YxLWJkZjAtZjI2NTRiODlkOTE3IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MDgwL3JlYWxtcy9tZWRpYW10eCIsImF1ZCI6Imh0dHA6Ly9sb2NhbGhvc3Q6ODA4MC9yZWFsbXMvbWVkaWFtdHgiLCJzdWIiOiI2NTBhZDA5Zi03MDgxLTQyNGItODI4Ni0xM2I3YTA3ZDI0MWEiLCJ0eXAiOiJSZWZyZXNoIiwiYXpwIjoibWVkaWFtdHgiLCJzZXNzaW9uX3N0YXRlIjoiY2MyZDQ4Y2MtZDJlOS00NGIwLTg5M2UtMGE3YTYyYmQyNWJkIiwic2NvcGUiOiJtZWRpYW10eCBwcm9maWxlIGVtYWlsIiwic2lkIjoiY2MyZDQ4Y2MtZDJlOS00NGIwLTg5M2UtMGE3YTYyYmQyNWJkIn0.yuXV8_JU0TQLuosNdp5xlYMjn7eO5Xq-PusdHzE7bsQ","token_type":"Bearer","not-before-policy":0,"session_state":"cc2d48cc-d2e9-44b0-893e-0a7a62bd25bd","scope":"mediamtx profile email"}
</code></pre> </li> 
</ol> 
<h3>Encrypt the configuration</h3> 
<p>The configuration file can be entirely encrypted for security purposes by using the <code>crypto_secretbox</code> function of the NaCL function. An online tool for performing this operation is <a href="https://play.golang.org/p/rX29jwObNe4">available here</a>.</p> 
<p>After performing the encryption, put the base64-encoded result into the configuration file, and launch the server with the <code>MTX_CONFKEY</code> variable:</p> 
<pre><code>MTX_CONFKEY=mykey ./mediamtx
</code></pre> 
<h3>Remuxing, re-encoding, compression</h3> 
<p>To change the format, codec or compression of a stream, use <em>FFmpeg</em> or <em>GStreamer</em> together with <em>MediaMTX</em>. For instance, to re-encode an existing stream, that is available in the <code>/original</code> path, and publish the resulting stream in the <code>/compressed</code> path, edit <code>mediamtx.yml</code> and replace everything inside section <code>paths</code> with the following content:</p> 
<pre><code class="language-yml">paths:
  compressed:
  original:
    runOnReady: &gt;
      ffmpeg -i rtsp://localhost:$RTSP_PORT/$MTX_PATH
        -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k
        -max_muxing_queue_size 1024 -f rtsp rtsp://localhost:$RTSP_PORT/compressed
    runOnReadyRestart: yes
</code></pre> 
<h3>Record streams to disk</h3> 
<p>To save available streams to disk, set the <code>record</code> and the <code>recordPath</code> parameter in the configuration file:</p> 
<pre><code class="language-yml">pathDefaults:
  # Record streams to disk.
  record: yes
  # Path of recording segments.
  # Extension is added automatically.
  # Available variables are %path (path name), %Y %m %d %H %M %S %f %s (time in strftime format)
  recordPath: ./recordings/%path/%Y-%m-%d_%H-%M-%S-%f
</code></pre> 
<p>All available recording parameters are listed in the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/mediamtx.yml">sample configuration file</a>.</p> 
<p>Be aware that not all codecs can be saved with all formats, as described in the compatibility matrix at the beginning of the README.</p> 
<p>To upload recordings to a remote location, you can use <em>MediaMTX</em> together with <a href="https://github.com/rclone/rclone">rclone</a>, a command line tool that provides file synchronization capabilities with a huge variety of services (including S3, FTP, SMB, Google Drive):</p> 
<ol> 
 <li> <p>Download and install <a href="https://github.com/rclone/rclone">rclone</a>.</p> </li> 
 <li> <p>Configure <em>rclone</em>:</p> <pre><code>rclone config
</code></pre> </li> 
 <li> <p>Place <code>rclone</code> into the <code>runOnInit</code> and <code>runOnRecordSegmentComplete</code> hooks:</p> <pre><code class="language-yml">pathDefaults:
  # this is needed to sync segments after a crash.
  # replace myconfig with the name of the rclone config.
  runOnInit: rclone sync -v ./recordings myconfig:/my-path/recordings

  # this is called when a segment has been finalized.
  # replace myconfig with the name of the rclone config.
  runOnRecordSegmentComplete: rclone sync -v --min-age=1ms ./recordings myconfig:/my-path/recordings
</code></pre> <p>If you want to delete local segments after they are uploaded, replace <code>rclone sync</code> with <code>rclone move</code>.</p> </li> 
</ol> 
<h3>Playback recorded streams</h3> 
<p>Existing recordings can be served to users through a dedicated HTTP server, that can be enabled inside the configuration:</p> 
<pre><code class="language-yml">playback: yes
playbackAddress: :9996
</code></pre> 
<p>The server provides an endpoint to list recorded timespans:</p> 
<pre><code>http://localhost:9996/list?path=[mypath]
</code></pre> 
<p>Where [mypath] is the name of a path. The server will return a list of timespans in JSON format:</p> 
<pre><code class="language-json">[
  {
    "start": "2006-01-02T15:04:05Z07:00",
    "duration": "60.0",
    "url": "http://localhost:9996/get?path=[mypath]&amp;start=2006-01-02T15%3A04%3A05Z07%3A00&amp;duration=60.0"
  },
  {
    "start": "2006-01-02T15:07:05Z07:00",
    "duration": "32.33",
    "url": "http://localhost:9996/get?path=[mypath]&amp;start=2006-01-02T15%3A07%3A05Z07%3A00&amp;duration=32.33"
  }
]
</code></pre> 
<p>The server provides an endpoint to download recordings:</p> 
<pre><code>http://localhost:9996/get?path=[mypath]&amp;start=[start_date]&amp;duration=[duration]&amp;format=[format]
</code></pre> 
<p>Where:</p> 
<ul> 
 <li>[mypath] is the path name</li> 
 <li>[start_date] is the start date in <a href="https://www.utctime.net/">RFC3339 format</a></li> 
 <li>[duration] is the maximum duration of the recording in seconds</li> 
 <li>[format] (optional) is the output format of the stream. Available values are "fmp4" (default) and "mp4"</li> 
</ul> 
<p>All parameters must be <a href="https://www.urlencoder.org/">url-encoded</a>. For instance:</p> 
<pre><code>http://localhost:9996/get?path=mypath&amp;start=2024-01-14T16%3A33%3A17%2B00%3A00&amp;duration=200.5
</code></pre> 
<p>The resulting stream uses the fMP4 format, that is natively compatible with any browser, therefore its URL can be directly inserted into a &lt;video&gt; tag:</p> 
<pre><code class="language-html">&lt;video controls&gt;
  &lt;source src="http://localhost:9996/get?path=[mypath]&amp;start=[start_date]&amp;duration=[duration]" type="video/mp4" /&gt;
&lt;/video&gt;
</code></pre> 
<p>The fMP4 format may offer limited compatibility with some players. To fix the issue, it's possible to use the standard MP4 format, by adding <code>format=mp4</code> to a <code>/get</code> request:</p> 
<pre><code>http://localhost:9996/get?path=[mypath]&amp;start=[start_date]&amp;duration=[duration]&amp;format=mp4
</code></pre> 
<h3>Forward streams to other servers</h3> 
<p>To forward incoming streams to another server, use <em>FFmpeg</em> inside the <code>runOnReady</code> parameter:</p> 
<pre><code class="language-yml">pathDefaults:
  runOnReady: &gt;
    ffmpeg -i rtsp://localhost:$RTSP_PORT/$MTX_PATH
    -c copy
    -f rtsp rtsp://other-server:8554/another-path
  runOnReadyRestart: yes
</code></pre> 
<h3>Proxy requests to other servers</h3> 
<p>The server allows to proxy incoming requests to other servers or cameras. This is useful to expose servers or cameras behind a NAT. Edit <code>mediamtx.yml</code> and replace everything inside section <code>paths</code> with the following content:</p> 
<pre><code class="language-yml">paths:
  "~^proxy_(.+)$":
    # If path name is a regular expression, $G1, G2, etc will be replaced
    # with regular expression groups.
    source: rtsp://other-server:8554/$G1
    sourceOnDemand: yes
</code></pre> 
<p>All requests addressed to <code>rtsp://server:8854/proxy_a</code> will be forwarded to <code>rtsp://other-server:8854/a</code> and so on.</p> 
<h3>On-demand publishing</h3> 
<p>Edit <code>mediamtx.yml</code> and replace everything inside section <code>paths</code> with the following content:</p> 
<pre><code class="language-yml">paths:
  ondemand:
    runOnDemand: ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH
    runOnDemandRestart: yes
</code></pre> 
<p>The command inserted into <code>runOnDemand</code> will start only when a client requests the path <code>ondemand</code>, therefore the file will start streaming only when requested.</p> 
<h3>Start on boot</h3> 
<h4>Linux</h4> 
<p>On most Linux distributions (including Ubuntu and Debian, but not OpenWrt), <em>systemd</em> is in charge of managing services and starting them on boot.</p> 
<p>Move the server executable and configuration in global folders:</p> 
<pre><code class="language-sh">sudo mv mediamtx /usr/local/bin/
sudo mv mediamtx.yml /usr/local/etc/
</code></pre> 
<p>Create a <em>systemd</em> service:</p> 
<pre><code class="language-sh">sudo tee /etc/systemd/system/mediamtx.service &gt;/dev/null &lt;&lt; EOF
[Unit]
Wants=network.target
[Service]
ExecStart=/usr/local/bin/mediamtx /usr/local/etc/mediamtx.yml
[Install]
WantedBy=multi-user.target
EOF
</code></pre> 
<p>Enable and start the service:</p> 
<pre><code class="language-sh">sudo systemctl daemon-reload
sudo systemctl enable mediamtx
sudo systemctl start mediamtx
</code></pre> 
<h4>OpenWrt</h4> 
<p>Move the server executable and configuration in global folders:</p> 
<pre><code class="language-sh">mv mediamtx /usr/bin/
mkdir -p /usr/etc &amp;&amp; mv mediamtx.yml /usr/etc/
</code></pre> 
<p>Create a procd service:</p> 
<pre><code class="language-sh">tee /etc/init.d/mediamtx &gt;/dev/null &lt;&lt; EOF
#!/bin/sh /etc/rc.common
USE_PROCD=1
START=95
STOP=01
start_service() {
    procd_open_instance
    procd_set_param command /usr/bin/mediamtx
    procd_set_param stdout 1
    procd_set_param stderr 1
    procd_close_instance
}
EOF
</code></pre> 
<p>Enable and start the service:</p> 
<pre><code class="language-sh">chmod +x /etc/init.d/mediamtx
/etc/init.d/mediamtx enable
/etc/init.d/mediamtx start
</code></pre> 
<p>Read the server logs:</p> 
<pre><code class="language-sh">logread
</code></pre> 
<h4>Windows</h4> 
<p>Download the <a href="https://github.com/winsw/winsw/releases/download/v2.11.0/WinSW-x64.exe">WinSW v2 executable</a> and place it into the same folder of <code>mediamtx.exe</code>.</p> 
<p>In the same folder, create a file named <code>WinSW-x64.xml</code> with this content:</p> 
<pre><code class="language-xml">&lt;service&gt;
  &lt;id&gt;mediamtx&lt;/id&gt;
  &lt;name&gt;mediamtx&lt;/name&gt;
  &lt;description&gt;&lt;/description&gt;
  &lt;executable&gt;%BASE%/mediamtx.exe&lt;/executable&gt;
&lt;/service&gt;
</code></pre> 
<p>Open a terminal, navigate to the folder and run:</p> 
<pre><code>WinSW-x64 install
</code></pre> 
<p>The server is now installed as a system service and will start at boot time.</p> 
<h3>Hooks</h3> 
<p>The server allows to specify commands that are executed when a certain event happens, allowing the propagation of events to external software.</p> 
<p><code>runOnConnect</code> allows to run a command when a client connects to the server:</p> 
<pre><code class="language-yml"># Command to run when a client connects to the server.
# This is terminated with SIGINT when a client disconnects from the server.
# The following environment variables are available:
# * RTSP_PORT: RTSP server port
# * MTX_CONN_TYPE: connection type
# * MTX_CONN_ID: connection ID
runOnConnect: curl http://my-custom-server/webhook?conn_type=$MTX_CONN_TYPE&amp;conn_id=$MTX_CONN_ID
# Restart the command if it exits.
runOnConnectRestart: no
</code></pre> 
<p><code>runOnDisconnect</code> allows to run a command when a client disconnects from the server:</p> 
<pre><code class="language-yml"># Command to run when a client disconnects from the server.
# Environment variables are the same of runOnConnect.
runOnDisconnect: curl http://my-custom-server/webhook?conn_type=$MTX_CONN_TYPE&amp;conn_id=$MTX_CONN_ID
</code></pre> 
<p><code>runOnInit</code> allows to run a command when a path is initialized. This can be used to publish a stream when the server is launched:</p> 
<pre><code class="language-yml">paths:
  mypath:
    # Command to run when this path is initialized.
    # This can be used to publish a stream when the server is launched.
    # The following environment variables are available:
    # * MTX_PATH: path name
    # * RTSP_PORT: RTSP server port
    # * G1, G2, ...: regular expression groups, if path name is
    #   a regular expression.
    runOnInit: ffmpeg -i my_file.mp4 -c copy -f rtsp rtsp://localhost:8554/mypath
    # Restart the command if it exits.
    runOnInitRestart: no
</code></pre> 
<p><code>runOnDemand</code> allows to run a command when a path is requested by a reader. This can be used to publish a stream on demand:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when this path is requested by a reader
  # and no one is publishing to this path yet.
  # This is terminated with SIGINT when there are no readers anymore.
  # The following environment variables are available:
  # * MTX_PATH: path name
  # * MTX_QUERY: query parameters (passed by first reader)
  # * RTSP_PORT: RTSP server port
  # * G1, G2, ...: regular expression groups, if path name is
  #   a regular expression.
  runOnDemand: ffmpeg -i my_file.mp4 -c copy -f rtsp rtsp://localhost:8554/mypath
  # Restart the command if it exits.
  runOnDemandRestart: no
</code></pre> 
<p><code>runOnUnDemand</code> allows to run a command when there are no readers anymore:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when there are no readers anymore.
  # Environment variables are the same of runOnDemand.
  runOnUnDemand:
</code></pre> 
<p><code>runOnReady</code> allows to run a command when a stream is ready to be read:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when the stream is ready to be read, whenever it is
  # published by a client or pulled from a server / camera.
  # This is terminated with SIGINT when the stream is not ready anymore.
  # The following environment variables are available:
  # * MTX_PATH: path name
  # * MTX_QUERY: query parameters (passed by publisher)
  # * MTX_SOURCE_TYPE: source type
  # * MTX_SOURCE_ID: source ID
  # * RTSP_PORT: RTSP server port
  # * G1, G2, ...: regular expression groups, if path name is
  #   a regular expression.
  runOnReady: curl http://my-custom-server/webhook?path=$MTX_PATH&amp;source_type=$MTX_SOURCE_TYPE&amp;source_id=$MTX_SOURCE_ID
  # Restart the command if it exits.
  runOnReadyRestart: no
</code></pre> 
<p><code>runOnNotReady</code> allows to run a command when a stream is not available anymore:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when the stream is not available anymore.
  # Environment variables are the same of runOnReady.
  runOnNotReady: curl http://my-custom-server/webhook?path=$MTX_PATH&amp;source_type=$MTX_SOURCE_TYPE&amp;source_id=$MTX_SOURCE_ID
</code></pre> 
<p><code>runOnRead</code> allows to run a command when a client starts reading:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when a client starts reading.
  # This is terminated with SIGINT when a client stops reading.
  # The following environment variables are available:
  # * MTX_PATH: path name
  # * MTX_QUERY: query parameters (passed by reader)
  # * MTX_READER_TYPE: reader type
  # * MTX_READER_ID: reader ID
  # * RTSP_PORT: RTSP server port
  # * G1, G2, ...: regular expression groups, if path name is
  #   a regular expression.
  runOnRead: curl http://my-custom-server/webhook?path=$MTX_PATH&amp;reader_type=$MTX_READER_TYPE&amp;reader_id=$MTX_READER_ID
  # Restart the command if it exits.
  runOnReadRestart: no
</code></pre> 
<p><code>runOnUnread</code> allows to run a command when a client stops reading:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when a client stops reading.
  # Environment variables are the same of runOnRead.
  runOnUnread: curl http://my-custom-server/webhook?path=$MTX_PATH&amp;reader_type=$MTX_READER_TYPE&amp;reader_id=$MTX_READER_ID
</code></pre> 
<p><code>runOnRecordSegmentCreate</code> allows to run a command when a recording segment is created:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when a recording segment is created.
  # The following environment variables are available:
  # * MTX_PATH: path name
  # * RTSP_PORT: RTSP server port
  # * G1, G2, ...: regular expression groups, if path name is
  #   a regular expression.
  # * MTX_SEGMENT_PATH: segment file path
  runOnRecordSegmentCreate: curl http://my-custom-server/webhook?path=$MTX_PATH&amp;segment_path=$MTX_SEGMENT_PATH
</code></pre> 
<p><code>runOnRecordSegmentComplete</code> allows to run a command when a recording segment is complete:</p> 
<pre><code class="language-yml">pathDefaults:
  # Command to run when a recording segment is complete.
  # The following environment variables are available:
  # * MTX_PATH: path name
  # * RTSP_PORT: RTSP server port
  # * G1, G2, ...: regular expression groups, if path name is
  #   a regular expression.
  # * MTX_SEGMENT_PATH: segment file path
  # * MTX_SEGMENT_DURATION: segment duration
  runOnRecordSegmentComplete: curl http://my-custom-server/webhook?path=$MTX_PATH&amp;segment_path=$MTX_SEGMENT_PATH
</code></pre> 
<h3>Control API</h3> 
<p>The server can be queried and controlled with an API, that can be enabled by setting the <code>api</code> parameter in the configuration:</p> 
<pre><code class="language-yml">api: yes
</code></pre> 
<p>To obtain a list of of active paths, run:</p> 
<pre><code>curl http://127.0.0.1:9997/v3/paths/list
</code></pre> 
<p>Full documentation of the Control API is available on the <a href="https://bluenviron.github.io/mediamtx/">dedicated site</a>.</p> 
<p>Be aware that by default the Control API is accessible by localhost only; to increase visibility or add authentication, check <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#authentication">Authentication</a>.</p> 
<h3>Metrics</h3> 
<p>A metrics exporter, compatible with <a href="https://prometheus.io/">Prometheus</a>, can be enabled with the parameter <code>metrics: yes</code>; then the server can be queried for metrics with Prometheus or with a simple HTTP request:</p> 
<pre><code>curl localhost:9998/metrics
</code></pre> 
<p>Obtaining:</p> 
<pre><code class="language-ini"># metrics of every path
paths{name="[path_name]",state="[state]"} 1
paths_bytes_received{name="[path_name]",state="[state]"} 1234
paths_bytes_sent{name="[path_name]",state="[state]"} 1234

# metrics of every HLS muxer
hls_muxers{name="[name]"} 1
hls_muxers_bytes_sent{name="[name]"} 187

# metrics of every RTSP connection
rtsp_conns{id="[id]"} 1
rtsp_conns_bytes_received{id="[id]"} 1234
rtsp_conns_bytes_sent{id="[id]"} 187

# metrics of every RTSP session
rtsp_sessions{id="[id]",state="idle"} 1
rtsp_sessions_bytes_received{id="[id]",state="[state]"} 1234
rtsp_sessions_bytes_sent{id="[id]",state="[state]"} 187

# metrics of every RTSPS connection
rtsps_conns{id="[id]"} 1
rtsps_conns_bytes_received{id="[id]"} 1234
rtsps_conns_bytes_sent{id="[id]"} 187

# metrics of every RTSPS session
rtsps_sessions{id="[id]",state="[state]"} 1
rtsps_sessions_bytes_received{id="[id]",state="[state]"} 1234
rtsps_sessions_bytes_sent{id="[id]",state="[state]"} 187

# metrics of every RTMP connection
rtmp_conns{id="[id]",state="[state]"} 1
rtmp_conns_bytes_received{id="[id]",state="[state]"} 1234
rtmp_conns_bytes_sent{id="[id]",state="[state]"} 187

# metrics of every RTMPS connection
rtmps_conns{id="[id]",state="[state]"} 1
rtmps_conns_bytes_received{id="[id]",state="[state]"} 1234
rtmps_conns_bytes_sent{id="[id]",state="[state]"} 187

# metrics of every SRT connection
srt_conns{id="[id]",state="[state]"} 1
srt_conns_packets_sent{id="[id]",state="[state]"} 123
srt_conns_packets_received{id="[id]",state="[state]"} 123
srt_conns_packets_sent_unique{id="[id]",state="[state]"} 123
srt_conns_packets_received_unique{id="[id]",state="[state]"} 123
srt_conns_packets_send_loss{id="[id]",state="[state]"} 123
srt_conns_packets_received_loss{id="[id]",state="[state]"} 123
srt_conns_packets_retrans{id="[id]",state="[state]"} 123
srt_conns_packets_received_retrans{id="[id]",state="[state]"} 123
srt_conns_packets_sent_ack{id="[id]",state="[state]"} 123
srt_conns_packets_received_ack{id="[id]",state="[state]"} 123
srt_conns_packets_sent_nak{id="[id]",state="[state]"} 123
srt_conns_packets_received_nak{id="[id]",state="[state]"} 123
srt_conns_packets_sent_km{id="[id]",state="[state]"} 123
srt_conns_packets_received_km{id="[id]",state="[state]"} 123
srt_conns_us_snd_duration{id="[id]",state="[state]"} 123
srt_conns_packets_send_drop{id="[id]",state="[state]"} 123
srt_conns_packets_received_drop{id="[id]",state="[state]"} 123
srt_conns_packets_received_undecrypt{id="[id]",state="[state]"} 123
srt_conns_bytes_sent{id="[id]",state="[state]"} 187
srt_conns_bytes_received{id="[id]",state="[state]"} 1234
srt_conns_bytes_sent_unique{id="[id]",state="[state]"} 123
srt_conns_bytes_received_unique{id="[id]",state="[state]"} 123
srt_conns_bytes_received_loss{id="[id]",state="[state]"} 123
srt_conns_bytes_retrans{id="[id]",state="[state]"} 123
srt_conns_bytes_received_retrans{id="[id]",state="[state]"} 123
srt_conns_bytes_send_drop{id="[id]",state="[state]"} 123
srt_conns_bytes_received_drop{id="[id]",state="[state]"} 123
srt_conns_bytes_received_undecrypt{id="[id]",state="[state]"} 123
srt_conns_us_packets_send_period{id="[id]",state="[state]"} 123.123
srt_conns_packets_flow_window{id="[id]",state="[state]"} 123
srt_conns_packets_flight_size{id="[id]",state="[state]"} 123
srt_conns_ms_rtt{id="[id]",state="[state]"} 123.123
srt_conns_mbps_send_rate{id="[id]",state="[state]"} 123
srt_conns_mbps_receive_rate{id="[id]",state="[state]"} 123.123
srt_conns_mbps_link_capacity{id="[id]",state="[state]"} 123.123
srt_conns_bytes_avail_send_buf{id="[id]",state="[state]"} 123
srt_conns_bytes_avail_receive_buf{id="[id]",state="[state]"} 123
srt_conns_mbps_max_bw{id="[id]",state="[state]"} -123
srt_conns_bytes_mss{id="[id]",state="[state]"} 123
srt_conns_packets_send_buf{id="[id]",state="[state]"} 123
srt_conns_bytes_send_buf{id="[id]",state="[state]"} 123
srt_conns_ms_send_buf{id="[id]",state="[state]"} 123
srt_conns_ms_send_tsb_pd_delay{id="[id]",state="[state]"} 123
srt_conns_packets_receive_buf{id="[id]",state="[state]"} 123
srt_conns_bytes_receive_buf{id="[id]",state="[state]"} 123
srt_conns_ms_receive_buf{id="[id]",state="[state]"} 123
srt_conns_ms_receive_tsb_pd_delay{id="[id]",state="[state]"} 123
srt_conns_packets_reorder_tolerance{id="[id]",state="[state]"} 123
srt_conns_packets_received_avg_belated_time{id="[id]",state="[state]"} 123
srt_conns_packets_send_loss_rate{id="[id]",state="[state]"} 123
srt_conns_packets_received_loss_rate{id="[id]",state="[state]"} 123

# metrics of every WebRTC session
webrtc_sessions{id="[id]",state="[state]"} 1
webrtc_sessions_bytes_received{id="[id]",state="[state]"} 1234
webrtc_sessions_bytes_sent{id="[id]",state="[state]"} 187
</code></pre> 
<h3>pprof</h3> 
<p>A performance monitor, compatible with pprof, can be enabled with the parameter <code>pprof: yes</code>; then the server can be queried for metrics with pprof-compatible tools, like:</p> 
<pre><code>go tool pprof -text http://localhost:9999/debug/pprof/goroutine
go tool pprof -text http://localhost:9999/debug/pprof/heap
go tool pprof -text http://localhost:9999/debug/pprof/profile?seconds=30
</code></pre> 
<h3>SRT-specific features</h3> 
<h4>Standard stream ID syntax</h4> 
<p>In SRT, the stream ID is a string that is sent to the counterpart in order to advertise what action the caller is gonna do (publish or read), the path and the credentials. All these informations have to be encoded into a single string. This server supports two stream ID syntaxes, a custom one (that is the one reported in rest of the README) and also a <a href="https://github.com/Haivision/srt/raw/master/docs/features/access-control.md">standard one</a> proposed by the authors of the protocol and sometimes enforced by some hardware. The standard syntax can be used in this way:</p> 
<pre><code>srt://localhost:8890?streamid=#!::m=publish,r=mypath,u=myuser,s=mypass&amp;pkt_size=1316
</code></pre> 
<p>Where:</p> 
<ul> 
 <li>key <code>m</code> contains the action (<code>publish</code> or <code>request</code>)</li> 
 <li>key <code>r</code> contains the path</li> 
 <li>key <code>u</code> contains the username</li> 
 <li>key <code>s</code> contains the password</li> 
</ul> 
<h3>WebRTC-specific features</h3> 
<h4>Authenticating with WHIP/WHEP</h4> 
<p>When using WHIP or WHEP to establish a WebRTC connection, there are multiple ways to provide credentials.</p> 
<p>If internal authentication or HTTP-based authentication is enabled, username and password can be passed through the <code>Authentication: Basic</code> header:</p> 
<pre><code>Authentication: Basic [base64_encoded_credentials]
</code></pre> 
<p>Username and password can be also passed through the <code>Authentication: Bearer</code> header (since it's mandated by the specification):</p> 
<pre><code>Authentication: Bearer username:password
</code></pre> 
<p>If JWT-based authentication is enabled, JWT can be passed through the <code>Authentication: Bearer</code> header:</p> 
<pre><code>Authentication: Bearer [jwt]
</code></pre> 
<p>The JWT can also be passed through query parameters:</p> 
<pre><code>http://localhost:8889/mystream/whip?jwt=[jwt]
</code></pre> 
<h4>Solving WebRTC connectivity issues</h4> 
<p>If the server is hosted inside a container or is behind a NAT, additional configuration is required in order to allow the two WebRTC parts (server and client) to establish a connection.</p> 
<p>Make sure that <code>webrtcAdditionalHosts</code> includes your public IPs, that are IPs that can be used by clients to reach the server. If clients are on the same LAN as the server, then insert the LAN address of the server. If clients are coming from the internet, insert the public IP address of the server, or alternatively a DNS name, if you have one. You can insert multiple values to support all scenarios:</p> 
<pre><code class="language-yml">webrtcAdditionalHosts: [192.168.x.x, 1.2.3.4, my-dns.example.org, ...]
</code></pre> 
<p>If there's a NAT / container between server and clients, it must be configured to route all incoming UDP packets on port 8189 to the server. If you're using Docker, this can be achieved with the flag:</p> 
<pre><code class="language-sh">docker run --rm -it \
-p 8189:8189/udp
....
bluenviron/mediamtx
</code></pre> 
<p>If you still have problems, maybe the UDP protocol is blocked by a firewall. Enable the local TCP listener:</p> 
<pre><code class="language-yml"># any port of choice
webrtcLocalTCPAddress: :8189
</code></pre> 
<p>If there's a NAT / container between server and clients, it must be configured to route all incoming TCP packets on port 8189 to the server.</p> 
<p>If you still have problems, enable a STUN server:</p> 
<pre><code class="language-yml"># STUN servers allows to obtain and share the public IP of the server.
webrtcICEServers2:
  - url: stun:stun.l.google.com:19302
</code></pre> 
<p>If you really still have problems, you can force all WebRTC/ICE connections to pass through a TURN server, like coturn, that must be configured externally. The server address and credentials must be set in the configuration file:</p> 
<pre><code class="language-yml"># TURN/TURNS servers forces all traffic through them.
webrtcICEServers2:
- url: turn:host:port
  username: user
  password: password
</code></pre> 
<p>Where user and pass are the username and password of the server. Note that port is not optional.</p> 
<p>If the server uses a secret-based authentication (for instance, coturn with the use-auth-secret option), it must be configured by using AUTH_SECRET as username, and the secret as password:</p> 
<pre><code class="language-yml">webrtcICEServers2:
- url: turn:host:port
  username: AUTH_SECRET
  password: secret
</code></pre> 
<p>where secret is the secret of the TURN server. MediaMTX will generate a set of credentials by using the secret, and credentials will be sent to clients before the WebRTC/ICE connection is established.</p> 
<p>In some cases you may want the browser to connect using TURN servers but have mediamtx not using TURN (for example if the TURN server is on the same network as mediamtx). To allow this you can configure the TURN server to be client only:</p> 
<pre><code class="language-yml">webrtcICEServers2:
- url: turn:host:port
  username: user
  password: password
  clientOnly: true
</code></pre> 
<h3>RTSP-specific features</h3> 
<h4>Transport protocols</h4> 
<p>The RTSP protocol supports different underlying transport protocols, that are chosen by clients during the handshake with the server:</p> 
<ul> 
 <li>UDP: the most performant, but doesn't work when there's a NAT/firewall between server and clients. It doesn't support encryption.</li> 
 <li>UDP-multicast: allows to save bandwidth when clients are all in the same LAN, by sending packets once to a fixed multicast IP. It doesn't support encryption.</li> 
 <li>TCP: the most versatile, does support encryption.</li> 
</ul> 
<p>The default transport protocol is UDP. To change the transport protocol, you have to tune the configuration of your client of choice.</p> 
<h4>Encryption</h4> 
<p>Incoming and outgoing RTSP streams can be encrypted with TLS, obtaining the RTSPS protocol. A TLS certificate is needed and can be generated with OpenSSL:</p> 
<pre><code class="language-sh">openssl genrsa -out server.key 2048
openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650
</code></pre> 
<p>Edit <code>mediamtx.yml</code>, and set the <code>protocols</code>, <code>encryption</code>, <code>serverKey</code> and serverCert parameters:</p> 
<pre><code class="language-yml">protocols: [tcp]
encryption: optional
serverKey: server.key
serverCert: server.crt
</code></pre> 
<p>Streams can be published and read with the <code>rtsps</code> scheme and the <code>8322</code> port:</p> 
<pre><code>rtsps://localhost:8322/mystream
</code></pre> 
<h4>Corrupted frames</h4> 
<p>In some scenarios, when publishing or reading from the server with RTSP, frames can get corrupted. This can be caused by multiple reasons:</p> 
<ul> 
 <li> <p>the write queue of the server is too small and can't keep up with the stream throughput. A solution consists in increasing its size:</p> <pre><code class="language-yml">writeQueueSize: 1024
</code></pre> </li> 
 <li> <p>The stream throughput is too big and the stream can't be transmitted correctly with the UDP transport protocol. UDP is more performant, faster and more efficient than TCP, but doesn't have a retransmission mechanism, that is needed in case of streams that need a large bandwidth. A solution consists in switching to TCP:</p> <pre><code class="language-yml">protocols: [tcp]
</code></pre> <p>In case the source is a camera:</p> <pre><code class="language-yml">paths:
  test:
    source: rtsp://..
    rtspTransport: tcp
</code></pre> </li> 
 <li> <p>The stream throughput is too big to be handled by the network between server and readers. Upgrade the network or decrease the stream bitrate by re-encoding it.</p> </li> 
</ul> 
<h3>RTMP-specific features</h3> 
<h4>Encryption</h4> 
<p>RTMP connections can be encrypted with TLS, obtaining the RTMPS protocol. A TLS certificate is needed and can be generated with OpenSSL:</p> 
<pre><code class="language-yml">openssl genrsa -out server.key 2048
openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650
</code></pre> 
<p>Edit mediamtx.yml, and set the <code>rtmpEncryption</code>, <code>rtmpServerKey</code> and <code>rtmpServerCert</code> parameters:</p> 
<pre><code class="language-yml">rtmpEncryption: optional
rtmpServerKey: server.key
rtmpServerCert: server.crt
</code></pre> 
<p>Streams can be published and read with the rtmps scheme and the 1937 port:</p> 
<pre><code>rtmps://localhost:1937/...
</code></pre> 
<p>Be aware that RTMPS is currently unsupported by all major players. However, you can use a proxy like <a href="https://www.stunnel.org">stunnel</a> or <a href="https://nginx.org/">nginx</a> or a dedicated <em>MediaMTX</em> instance to decrypt streams before reading them.</p> 
<h2>Compile from source</h2> 
<h3>Standard</h3> 
<p>Install git and Go ≥ 1.22. Clone the repository, enter into the folder and start the building process:</p> 
<pre><code class="language-sh">git clone https://github.com/bluenviron/mediamtx
cd mediamtx
go generate ./...
CGO_ENABLED=0 go build .
</code></pre> 
<p>The command will produce the <code>mediamtx</code> binary.</p> 
<h3>OpenWrt</h3> 
<p>The compilation procedure is the same as the standard one. On the OpenWrt device, install git and Go:</p> 
<pre><code class="language-sh">opkg update
opkg install golang git git-http
</code></pre> 
<p>Clone the repository, enter into the folder and start the building process:</p> 
<pre><code class="language-sh">git clone https://github.com/bluenviron/mediamtx
cd mediamtx
go generate ./...
CGO_ENABLED=0 go build .
</code></pre> 
<p>The command will produce the <code>mediamtx</code> binary.</p> 
<p>If the OpenWrt device doesn't have enough resources to compile, you can <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/#cross-compile">cross compile</a> from another machine.</p> 
<h3>Cross compile</h3> 
<p>Cross compilation allows to build an executable for a target machine from another machine with different operating system or architecture. This is useful in case the target machine doesn't have enough resources for compilation or if you don't want to install the compilation dependencies on it.</p> 
<p>On the machine you want to use to compile, install git and Go ≥ 1.22. Clone the repository, enter into the folder and start the building process:</p> 
<pre><code class="language-sh">git clone https://github.com/bluenviron/mediamtx
cd mediamtx
go generate ./...
CGO_ENABLED=0 GOOS=my_os GOARCH=my_arch go build .
</code></pre> 
<p>Replace <code>my_os</code> and <code>my_arch</code> with the operating system and architecture of your target machine. A list of all supported combinations can be obtained with:</p> 
<pre><code class="language-sh">go tool dist list
</code></pre> 
<p>For instance:</p> 
<pre><code class="language-sh">CGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build .
</code></pre> 
<p>In case of the <code>arm</code> architecture, there's an additional flag available, <code>GOARM</code>, that allows to set the ARM version:</p> 
<pre><code class="language-sh">CGO_ENABLED=0 GOOS=linux GOARCH=arm64 GOARM=7 go build .
</code></pre> 
<p>In case of the <code>mips</code> architecture, there's an additional flag available, <code>GOMIPS</code>, that allows to set additional parameters:</p> 
<pre><code class="language-sh">CGO_ENABLED=0 GOOS=linux GOARCH=mips GOMIPS=softfloat go build .
</code></pre> 
<p>The command will produce the <code>mediamtx</code> binary.</p> 
<h3>Compile for all supported platforms</h3> 
<p>Install Docker and launch:</p> 
<pre><code class="language-sh">make binaries
</code></pre> 
<p>The command will produce tarballs in folder <code>binaries/</code>.</p> 
<h2>License</h2> 
<p>All the code in this repository is released under the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/LICENSE">MIT License</a>. Compiled binaries make use of some third-party dependencies:</p> 
<ul> 
 <li>hls.js, released under the <a href="https://github.com/video-dev/hls.js/raw/master/LICENSE">Apache License 2.0</a></li> 
 <li>all the dependencies listed into the <a href="https://raw.githubusercontent.com/bluenviron/mediamtx/main/go.mod">go.mod file</a>, which are all released under either the MIT license, BSD-3-Clause license or Apache License 2.0</li> 
</ul> 
<h2>Specifications</h2> 
<table> 
 <thead> 
  <tr> 
   <th>name</th> 
   <th>area</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><a href="https://github.com/bluenviron/gortsplib#specifications">RTSP / RTP / RTCP specifications</a></td> 
   <td>RTSP</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/bluenviron/gohlslib#specifications">HLS specifications</a></td> 
   <td>HLS</td> 
  </tr> 
  <tr> 
   <td><a href="https://rtmp.veriskope.com/pdf/rtmp_specification_1.0.pdf">RTMP</a></td> 
   <td>RTMP</td> 
  </tr> 
  <tr> 
   <td><a href="https://veovera.org/docs/enhanced/enhanced-rtmp-v1.pdf">Enhanced RTMP v1</a></td> 
   <td>RTMP</td> 
  </tr> 
  <tr> 
   <td><a href="https://rtmp.veriskope.com/pdf/amf0-file-format-specification.pdf">Action Message Format</a></td> 
   <td>RTMP</td> 
  </tr> 
  <tr> 
   <td><a href="https://www.w3.org/TR/webrtc/">WebRTC: Real-Time Communication in Browsers</a></td> 
   <td>WebRTC</td> 
  </tr> 
  <tr> 
   <td><a href="https://datatracker.ietf.org/doc/draft-ietf-wish-whip/">WebRTC HTTP Ingestion Protocol (WHIP)</a></td> 
   <td>WebRTC</td> 
  </tr> 
  <tr> 
   <td><a href="https://datatracker.ietf.org/doc/draft-murillo-whep/">WebRTC HTTP Egress Protocol (WHEP)</a></td> 
   <td>WebRTC</td> 
  </tr> 
  <tr> 
   <td><a href="https://haivision.github.io/srt-rfc/draft-sharabayko-srt.html">The SRT Protocol</a></td> 
   <td>SRT</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/bluenviron/mediacommon#specifications">Codec specifications</a></td> 
   <td>codecs</td> 
  </tr> 
  <tr> 
   <td><a href="https://github.com/golang-standards/project-layout">Golang project layout</a></td> 
   <td>project layout</td> 
  </tr> 
 </tbody> 
</table> 
<h2>Related projects</h2> 
<ul> 
 <li><a href="https://github.com/bluenviron/gortsplib">gortsplib (RTSP library used internally)</a></li> 
 <li><a href="https://github.com/bluenviron/gohlslib">gohlslib (HLS library used internally)</a></li> 
 <li><a href="https://github.com/bluenviron/mediacommon">mediacommon (codecs and formats library used internally)</a></li> 
 <li><a href="https://github.com/datarhei/gosrt">datarhei/gosrt (SRT library used internally)</a></li> 
 <li><a href="https://github.com/pion/webrtc">pion/webrtc (WebRTC library used internally)</a></li> 
 <li><a href="https://github.com/pion/sdp">pion/sdp (SDP library used internally)</a></li> 
 <li><a href="https://github.com/pion/rtp">pion/rtp (RTP library used internally)</a></li> 
 <li><a href="https://github.com/pion/rtcp">pion/rtcp (RTCP library used internally)</a></li> 
 <li><a href="https://github.com/asticode/go-astits">go-astits (MPEG-TS library used internally)</a></li> 
 <li><a href="https://github.com/abema/go-mp4">go-mp4 (MP4 library used internally)</a></li> 
 <li><a href="https://github.com/video-dev/hls.js">hls.js (browser-side HLS library used internally)</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>duckdb/pg_duckdb</title>
<link>https://github.com/duckdb/pg_duckdb</link>
<guid>https://github.com/duckdb/pg_duckdb</guid>
<content:encoded><![CDATA[
<div> 关键词：DuckDB、Postgres、pg_duckdb、object storage、hybrid execution

总结:

这篇文章介绍了pg_duckdb，这是一个用于Postgres的扩展，它整合了DuckDB的列式向量化分析引擎和特性。pg_duckdb允许直接从Postgres表执行DuckDB查询，并支持多种数据类型，如数值、字符、二进制、日期/时间、布尔值、UUID、JSON和数组。此外，pg_duckdb还能读取存储在对象存储（如AWS S3、Cloudflare R2或Google GCS）中的Parquet和CSV文件，以及Iceberg文件。

用户可以通过运行`SET duckdb.execution TO true`来激活DuckDB执行，以避免对现有查询产生影响。pg_duckdb还支持将查询结果或整个表写入对象存储中的Parquet格式，并允许查询和连接对象存储中的数据与Postgres表、视图和物化视图。

未来，pg_duckdb计划与MotherDuck集成，实现混合执行、零拷贝快照和复制、时间旅行、数据分层等功能，以提高并发性和缓存效率。对于贡献者，文章鼓励投票、提出功能建议、提交PR、报告问题等参与开发活动。最后，用户可以访问相关资源了解详细信息和限制。 <div>
<p>DuckDB-powered Postgres for high performance apps & analytics.</p><hr /><h1>pg_duckdb: Official Postgres extension for DuckDB</h1> 
<p>pg_duckdb is a Postgres extension that embeds DuckDB's columnar-vectorized analytics engine and features into Postgres. We recommend using pg_duckdb to build high performance analytics and data-intensive applications.</p> 
<p>pg_duckdb was developed in collaboration with our partners, <a href="https://hydra.so">Hydra</a> and <a href="https://motherduck.com">MotherDuck</a>.</p> 
<h2>Installation</h2> 
<p>Pre-built binaries and additional installation options are coming soon.</p> 
<p>To build pg_duckdb, you need:</p> 
<ul> 
 <li>Postgres 16 or 17</li> 
 <li>Ubuntu 22.04 or MacOS</li> 
 <li>Standard set of build tools for building Postgres extensions</li> 
 <li><a href="https://duckdb.org/docs/dev/building/build_instructions">Build tools that are required to build DuckDB</a></li> 
</ul> 
<p>To build and install, run:</p> 
<pre><code class="language-sh">make install
</code></pre> 
<p>Next, load the pg_duckdb extension:</p> 
<pre><code class="language-sql">CREATE EXTENSION pg_duckdb;
</code></pre> 
<p><strong>IMPORTANT:</strong> Once loaded you can use DuckDB execution by running <code>SET duckdb.execution TO true</code>. This is <em>opt-in</em> to avoid breaking existing queries. To avoid doing that for every session, you can configure it for a certain user by doing <code>ALTER USER my_analytics_user SET duckdb.execution TO true</code>.</p> 
<h2>Features</h2> 
<ul> 
 <li> <p><code>SELECT</code> queries executed by the DuckDB engine can directly read Postgres tables.</p> 
  <ul> 
   <li>Able to read <a href="https://www.postgresql.org/docs/current/datatype.html">data types</a> that exist in both Postgres and DuckDB. The following data types are supported: numeric, character, binary, date/time, boolean, uuid, json, and arrays.</li> 
   <li>If DuckDB cannot support the query for any reason, execution falls back to Postgres.</li> 
  </ul> </li> 
 <li> <p>Read parquet and CSV files from object storage (AWS S3, Cloudflare R2, or Google GCS).</p> 
  <ul> 
   <li><code>SELECT n FROM read_parquet('s3://bucket/file.parquet') AS (n int)</code></li> 
   <li><code>SELECT n FROM read_csv('s3://bucket/file.csv') AS (n int)</code></li> 
   <li>You can pass globs and arrays to these functions, just like in DuckDB</li> 
  </ul> </li> 
 <li> <p>Enable the DuckDB Iceberg extension using <code>SELECT duckdb.enable_extension('iceberg')</code> and read Iceberg files with <code>iceberg_scan</code>.</p> </li> 
 <li> <p>Write a query — or an entire table — to parquet in object storage.</p> 
  <ul> 
   <li><code>COPY (SELECT foo, bar FROM baz) TO 's3://...'</code></li> 
   <li><code>COPY table TO 's3://...'</code></li> 
  </ul> </li> 
 <li> <p>Read and write to Parquet format in a single query</p> <pre><code class="language-sql"> COPY (
   SELECT count(*), name
   FROM read_parquet('s3://bucket/file.parquet') AS (name text)
   GROUP BY name
   ORDER BY count DESC
 ) TO 's3://bucket/results.parquet';
</code></pre> </li> 
 <li> <p>Query and <code>JOIN</code> data in object storage with Postgres tables, views, and materialized views.</p> </li> 
 <li> <p>Create indexes on Postgres tables to accelerate your DuckDB queries</p> </li> 
 <li> <p>Install DuckDB extensions using <code>SELECT duckdb.install_extension('extension_name');</code></p> </li> 
 <li> <p>Toggle DuckDB execution on/off with a setting:</p> 
  <ul> 
   <li><code>SET duckdb.execution = true|false</code></li> 
  </ul> </li> 
</ul> 
<h2>Getting Started</h2> 
<p>The best way to get started is to connect Postgres to a new or existing object storage bucket (AWS S3, Cloudflare R2, or Google GCS) with pg_duckdb. You can query data in Parquet, CSV, and Iceberg format using <code>read_parquet</code>, <code>read_csv</code>, and <code>iceberg_scan</code> respectively.</p> 
<ol> 
 <li> <p>Add a credential to enable DuckDB's httpfs support.</p> <pre><code class="language-sql">INSERT INTO duckdb.secrets
(cloud_type, cloud_id, cloud_secret, cloud_region)
VALUES ('S3', 'access_key_id', 'secret_accss_key', 'us-east-1');
</code></pre> </li> 
 <li> <p>Copy data directly to your bucket - no ETL pipeline!</p> <pre><code class="language-sql">COPY (SELECT user_id, item_id, price, purchased_at FROM purchases)
TO 's3://your-bucket/purchases.parquet;
</code></pre> </li> 
 <li> <p>Perform analytics on your data.</p> <pre><code class="language-sql">SELECT SUM(price) AS total, item_id
FROM read_parquet('s3://your-bucket/purchases.parquet')
  AS (price float, item_id int)
GROUP BY item_id
ORDER BY total DESC
LIMIT 100;
</code></pre> </li> 
</ol> 
<h2>Roadmap</h2> 
<p>Please see the <a href="https://github.com/orgs/duckdb/projects/10">project roadmap</a> for upcoming planned tasks and features.</p> 
<h3>Connect with MotherDuck</h3> 
<p>pg_duckdb integration with MotherDuck will enable hybrid execution with Differential Storage.</p> 
<ul> 
 <li>Zero-copy snapshots and forks</li> 
 <li>Time travel</li> 
 <li>Data tiering</li> 
 <li>Improved concurrency and cacheability</li> 
</ul> 
<h2>Contributing</h2> 
<p>pg_duckdb was developed in collaboration with our partners, <a href="https://hydra.so">Hydra</a> and <a href="https://motherduck.com">MotherDuck</a>. We look forward to their continued contributions and leadership.</p> 
<p><a href="https://hydra.so">Hydra</a> is a Y Combinator-backed database company, focused on DuckDB-Powered Postgres for app developers.</p> 
<p><a href="https://motherduck.com">MotherDuck</a> is the cloud-based data warehouse that extends the power of DuckDB.</p> 
<p>We welcome all contributions big and small:</p> 
<ul> 
 <li>Vote on or suggest features for our roadmap.</li> 
 <li>Open a PR.</li> 
 <li>Submit a feature request or bug report.</li> 
</ul> 
<h2>Resources</h2> 
<ul> 
 <li>Please see the <a href="https://github.com/orgs/duckdb/projects/10">project roadmap</a> for upcoming planned tasks and features.</li> 
 <li><a href="https://github.com/duckdb/pg_duckdb/issues">GitHub Issues</a> for bugs and missing features</li> 
 <li><a href="https://discord.duckdb.org/">Discord discussion</a> with the DuckDB community</li> 
 <li>See our docs for more info and limitations</li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>amnezia-vpn/amnezia-client</title>
<link>https://github.com/amnezia-vpn/amnezia-client</link>
<guid>https://github.com/amnezia-vpn/amnezia-client</guid>
<content:encoded><![CDATA[
<p>Amnezia VPN Client (Desktop+Mobile)</p><hr /><h1>Amnezia VPN</h1> 
<h2><em>The best client for self-hosted VPN</em></h2> 
<p><a href="https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml?query=branch:dev"><img alt="Build Status" src="https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml/badge.svg?branch=dev" /></a> <a href="https://gitpod.io/#https://github.com/amnezia-vpn/amnezia-client"><img alt="Gitpod ready-to-code" src="https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod" /></a></p> 
<p>Amnezia is an open-source VPN client, with a key feature that enables you to deploy your own VPN server on your server.</p> 
<p><img alt="Image" src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/uipic4.png" /></p> 
<br /> 
<p><a href="https://github.com/amnezia-vpn/amnezia-client/releases/download/4.6.0.3/AmneziaVPN_4.6.0.3_x64.exe"><img src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/win.png" width="150" /></a> <a href="https://github.com/amnezia-vpn/amnezia-client/releases/download/4.6.0.3/AmneziaVPN_4.6.0.3.dmg"><img src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/mac.png" width="150" /></a> <a href="https://github.com/amnezia-vpn/amnezia-client/releases/download/4.6.0.3/AmneziaVPN_Linux_4.6.0.3.tar.zip"><img src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/lin.png" width="150" /></a> <a href="https://github.com/amnezia-vpn/amnezia-client/releases/tag/4.6.0.3"><img src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/andr.png" width="150" /></a></p> 
<br /> 
<p><a href="https://play.google.com/store/search?q=amnezia+vpn&amp;c=apps"><img src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/play.png" width="150" /></a> <a href="https://apps.apple.com/us/app/amneziavpn/id1600529900"><img src="https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/apl.png" width="150" /></a></p> 
<p><a href="https://github.com/amnezia-vpn/amnezia-client/releases">All releases</a></p> 
<br /> 
<h2>Features</h2> 
<ul> 
 <li>Very easy to use - enter your IP address, SSH login, password and Amnezia will automatically install VPN docker containers to your server and connect to the VPN.</li> 
 <li>Classic VPN-protocols: OpenVPN, WireGuard and IKEv2 protocols.</li> 
 <li>Protocols with traffic Masking (Obfuscation): OpenVPN over <a href="https://github.com/cbeuw/Cloak">Cloak</a> plugin, Shadowsocks (OpenVPN over Shadowsocks), <a href="https://docs.amnezia.org/documentation/amnezia-wg/">AmneziaWG</a> and XRay.</li> 
 <li>Split tunneling support - add any sites to the client to enable VPN only for them or add Apps (only for Android and Desktop).</li> 
 <li>Windows, MacOS, Linux, Android, iOS releases.</li> 
 <li>Support for AmneziaWG protocol configuration on <a href="https://docs.keenetic.com/ua/air/kn-1611/en/6319-latest-development-release.html#UUID-186c4108-5afd-c10b-f38a-cdff6c17fab3_section-idm33192196168192-improved">Keenetic beta firmware</a>.</li> 
</ul> 
<h2>Links</h2> 
<ul> 
 <li><a href="https://amnezia.org">https://amnezia.org</a> - project website</li> 
 <li><a href="https://www.reddit.com/r/AmneziaVPN">https://www.reddit.com/r/AmneziaVPN</a> - Reddit</li> 
 <li><a href="https://t.me/amnezia_vpn_en">https://t.me/amnezia_vpn_en</a> - Telegram support channel (English)</li> 
 <li><a href="https://t.me/amnezia_vpn_ir">https://t.me/amnezia_vpn_ir</a> - Telegram support channel (Farsi)</li> 
 <li><a href="https://t.me/amnezia_vpn_mm">https://t.me/amnezia_vpn_mm</a> - Telegram support channel (Myanmar)</li> 
 <li><a href="https://t.me/amnezia_vpn">https://t.me/amnezia_vpn</a> - Telegram support channel (Russian)</li> 
 <li><a href="https://vpnpay.io/en/amnezia-premium/">https://vpnpay.io/en/amnezia-premium/</a> - Amnezia Premium</li> 
</ul> 
<h2>Tech</h2> 
<p>AmneziaVPN uses several open-source projects to work:</p> 
<ul> 
 <li><a href="https://www.openssl.org/">OpenSSL</a></li> 
 <li><a href="https://openvpn.net/">OpenVPN</a></li> 
 <li><a href="https://shadowsocks.org/">Shadowsocks</a></li> 
 <li><a href="https://www.qt.io/">Qt</a></li> 
 <li><a href="https://libssh.org">LibSsh</a> - forked from Qt Creator</li> 
 <li>and more...</li> 
</ul> 
<h2>Checking out the source code</h2> 
<p>Make sure to pull all submodules after checking out the repo.</p> 
<pre><code class="language-bash">git submodule update --init --recursive
</code></pre> 
<h2>Development</h2> 
<p>Want to contribute? Welcome!</p> 
<h3>Help with translations</h3> 
<p>Download the most actual translation files.</p> 
<p>Go to <a href="https://github.com/amnezia-vpn/amnezia-client/actions?query=is%3Asuccess+branch%3Adev">"Actions" tab</a>, click on the first line. Then scroll down to the "Artifacts" section and download "AmneziaVPN_translations".</p> 
<p>Unzip this file. Each *.ts file contains strings for one corresponding language.</p> 
<p>Translate or correct some strings in one or multiple *.ts files and commit them back to this repository into the <code>client/translations</code> folder. You can do it via a web-interface or any other method you're familiar with.</p> 
<h3>Building sources and deployment</h3> 
<p>Check deploy folder for build scripts.</p> 
<h3>How to build an iOS app from source code on MacOS</h3> 
<ol> 
 <li> <p>First, make sure you have <a href="https://developer.apple.com/xcode/">XCode</a> installed, at least version 14 or higher.</p> </li> 
 <li> <p>We use QT to generate the XCode project. We need QT version 6.6.2. Install QT for MacOS <a href="https://doc.qt.io/qt-6/macos.html">here</a> or <a href="https://www.qt.io/download-open-source">QT Online Installer</a>. Required modules:</p> 
  <ul> 
   <li>MacOS</li> 
   <li>iOS</li> 
   <li>Qt 5 Compatibility Module</li> 
   <li>Qt Shader Tools</li> 
   <li>Additional Libraries: 
    <ul> 
     <li>Qt Image Formats</li> 
     <li>Qt Multimedia</li> 
     <li>Qt Remote Objects</li> 
    </ul> </li> 
  </ul> </li> 
 <li> <p>Install CMake if required. We recommend CMake version 3.25. You can install CMake <a href="https://cmake.org/download/">here</a></p> </li> 
 <li> <p>You also need to install go &gt;= v1.16. If you don't have it installed already, download go from the <a href="https://golang.org/dl/">official website</a> or use Homebrew. The latest version is recommended. Install gomobile</p> </li> 
</ol> 
<pre><code class="language-bash">export PATH=$PATH:~/go/bin
go install golang.org/x/mobile/cmd/gomobile@latest
gomobile init
</code></pre> 
<ol start="5"> 
 <li>Build the project</li> 
</ol> 
<pre><code class="language-bash">export QT_BIN_DIR="&lt;PATH-TO-QT-FOLDER&gt;/Qt/&lt;QT-VERSION&gt;/ios/bin"
export QT_MACOS_ROOT_DIR="&lt;PATH-TO-QT-FOLDER&gt;/Qt/&lt;QT-VERSION&gt;/macos"
export QT_IOS_BIN=$QT_BIN_DIR
export PATH=$PATH:~/go/bin
mkdir build-ios
$QT_IOS_BIN/qt-cmake . -B build-ios -GXcode -DQT_HOST_PATH=$QT_MACOS_ROOT_DIR
</code></pre> 
<p>Replace PATH-TO-QT-FOLDER and QT-VERSION to your environment</p> 
<p>If you get <code>gomobile: command not found</code> make sure to set PATH to the location of the bin folder where gomobile was installed. Usually, it's in <code>GOPATH</code>.</p> 
<pre><code class="language-bash">export PATH=$(PATH):/path/to/GOPATH/bin
</code></pre> 
<ol start="6"> 
 <li>Open the XCode project. You can then run /test/archive/ship the app.</li> 
</ol> 
<p>If the build fails with the following error</p> 
<pre><code>make: *** 
[$(PROJECTDIR)/client/build/AmneziaVPN.build/Debug-iphoneos/wireguard-go-bridge/goroot/.prepared] 
Error 1
</code></pre> 
<p>Add a user-defined variable to both AmneziaVPN and WireGuardNetworkExtension targets' build settings with key <code>PATH</code> and value <code>${PATH}/path/to/bin/folder/with/go/executable</code>, e.g. <code>${PATH}:/usr/local/go/bin</code>.</p> 
<p>if the above error persists on your M1 Mac, then most probably you need to install arch based CMake</p> 
<pre><code>arch -arm64 brew install cmake
</code></pre> 
<p>Build might fail with the "source files not found" error the first time you try it, because the modern XCode build system compiles dependencies in parallel, and some dependencies end up being built after the ones that require them. In this case, simply restart the build.</p> 
<h2>How to build the Android app</h2> 
<p><em>Tested on Mac OS</em></p> 
<p>The Android app has the following requirements:</p> 
<ul> 
 <li>JDK 11</li> 
 <li>Android platform SDK 33</li> 
 <li>CMake 3.25.0</li> 
</ul> 
<p>After you have installed QT, QT Creator, and Android Studio, you need to configure QT Creator correctly.</p> 
<ul> 
 <li>Click in the top menu bar on <code>QT Creator</code> -&gt; <code>Preferences</code> -&gt; <code>Devices</code> and select the tab <code>Android</code>.</li> 
 <li>Set path to JDK 11</li> 
 <li>Set path to Android SDK (<code>$ANDROID_HOME</code>)</li> 
</ul> 
<p>In case you get errors regarding missing SDK or 'SDK manager not running', you cannot fix them by correcting the paths. If you have some spare GBs on your disk, you can let QT Creator install all requirements by choosing an empty folder for <code>Android SDK location</code> and clicking on <code>Set Up SDK</code>. Be aware: This will install a second Android SDK and NDK on your machine!&nbsp; Double-check that the right CMake version is configured: &nbsp;Click on <code>QT Creator</code> -&gt; <code>Preferences</code> and click on the side menu on <code>Kits</code>. Under the center content view's <code>Kits</code> tab, you'll find an entry for <code>CMake Tool</code>. If the default selected CMake version is lower than 3.25.0, install on your system CMake &gt;= 3.25.0 and choose <code>System CMake at &lt;path&gt;</code> from the drop-down list. If this entry is missing, you either have not installed CMake yet or QT Creator hasn't found the path to it. In that case, click in the preferences window on the side menu item <code>CMake</code>, then on the tab <code>Tools</code> in the center content view, and finally on the button <code>Add</code> to set the path to your installed CMake.&nbsp; Please make sure that you have selected Android Platform SDK 33 for your project: click in the main view's side menu on <code>Projects</code>, and on the left, you'll see a section <code>Build &amp; Run</code> showing different Android build targets. You can select any of them, Amnezia VPN's project setup is designed in a way that all Android targets will be built. Click on the targets submenu item <code>Build</code> and scroll in the center content view to <code>Build Steps</code>. Click on <code>Details</code> at the end of the headline <code>Build Android APK</code> (the <code>Details</code> button might be hidden in case the QT Creator Window is not running in full screen!). Here we are: Choose <code>android-33</code> as <code>Android Build Platform SDK</code>.</p> 
<p>That's it! You should be ready to compile the project from QT Creator!</p> 
<h3>Development flow</h3> 
<p>After you've hit the build button, QT-Creator copies the whole project to a folder in the repository parent directory. The folder should look something like <code>build-amnezia-client-Android_Qt_&lt;version&gt;_Clang_&lt;architecture&gt;-&lt;BuildType&gt;</code>. If you want to develop Amnezia VPNs Android components written in Kotlin, such as components using system APIs, you need to import the generated project in Android Studio with <code>build-amnezia-client-Android_Qt_&lt;version&gt;_Clang_&lt;architecture&gt;-&lt;BuildType&gt;/client/android-build</code> as the projects root directory. While you should be able to compile the generated project from Android Studio, you cannot work directly in the repository's Android project. So whenever you are confident with your work in the generated project, you'll need to copy and paste the affected files to the corresponding path in the repository's Android project so that you can add and commit your changes!</p> 
<p>You may face compiling issues in QT Creator after you've worked in Android Studio on the generated project. Just do a <code>./gradlew clean</code> in the generated project's root directory (<code>&lt;path&gt;/client/android-build/.</code>) and you should be good to go.</p> 
<h2>License</h2> 
<p>GPL v3.0</p> 
<h2>Donate</h2> 
<p>Patreon: <a href="https://www.patreon.com/amneziavpn">https://www.patreon.com/amneziavpn</a></p> 
<p>Bitcoin: bc1q26eevjcg9j0wuyywd2e3uc9cs2w58lpkpjxq6p <br /> USDT BEP20: 0x6abD576765a826f87D1D95183438f9408C901bE4 <br /> USDT TRC20: TELAitazF1MZGmiNjTcnxDjEiH5oe7LC9d <br /> XMR: 48spms39jt1L2L5vyw2RQW6CXD6odUd4jFu19GZcDyKKQV9U88wsJVjSbL4CfRys37jVMdoaWVPSvezCQPhHXUW5UKLqUp3</p> 
<h2>Acknowledgments</h2> 
<p>This project is tested with BrowserStack. We express our gratitude to <a href="https://www.browserstack.com">BrowserStack</a> for supporting our project.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>s0md3v/roop</title>
<link>https://github.com/s0md3v/roop</link>
<guid>https://github.com/s0md3v/roop</guid>
<content:encoded><![CDATA[
<div> 关键词：face swap、Roop软件、安装、使用、伦理责任

总结:

Roop是一个用于一键面部替换的软件，用户仅需一张目标面部图片即可替换视频中的面部。此项目已停止更新，但现有版本仍可使用。

### 安装与运行：
- **技术要求**：安装过程需要一定的技术知识，对初学者不友好。
- **性能优化**：安装后可充分利用CPU和GPU，提升处理速度。

### 使用方法：
- 启动命令：`python run.py [选项]`。
- **参数说明**：通过参数指定源图像路径、目标图像或视频路径以及输出文件或目录等。
- **高级功能**：支持自定义帧处理器、保持原始帧率、保留临时帧等高级设置。

### 头部模式运行：
- 通过源、目标和输出参数直接运行软件，无需图形界面。

### 遵守伦理准则：
- 软件旨在促进AI生成媒体行业，如角色动画、服装模型制作。
- 意识到潜在伦理问题，防止用于不适当内容（如裸体）。
- 用户须遵守当地法律，负责任地使用软件，避免侵犯隐私权和版权。

### 软件许可与信用：
- 使用了大量第三方库和预训练模型，用户需注意这些组件的独立许可。
- 致谢了为提供库和模型做出贡献的所有开发者。 <div>
<p>one-click face swap</p><hr /><h2>This project has been discontinued</h2> 
<p>Yes, it still works, you can still use this software. It just won't recieve any updates now.</p> 
<blockquote> 
 <p>I do not have the interest or time to oversee the development of this software. I thank all the amazing people who contributed to this project and made what it is in it's final form.</p> 
</blockquote> 
<h1>Roop</h1> 
<blockquote> 
 <p>Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training.</p> 
</blockquote> 
<p><a href="https://github.com/s0md3v/roop/actions?query=workflow:ci"><img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/s0md3v/roop/ci.yml.svg?branch=main" /></a></p> 
<img src="https://i.ibb.co/4RdPYwQ/Untitled.jpg" /> 
<h2>Installation</h2> 
<p>Be aware, the installation needs technical skills and is not for beginners. Please do not open platform and installation related issues on GitHub.</p> 
<p><a href="https://github.com/s0md3v/roop/wiki/1.-Installation">Basic</a> - It is more likely to work on your computer, but will be quite slow</p> 
<p><a href="https://github.com/s0md3v/roop/wiki/2.-Acceleration">Acceleration</a> - Unleash the full potential of your CPU and GPU</p> 
<h2>Usage</h2> 
<p>Start the program with arguments:</p> 
<pre><code>python run.py [options]

-h, --help                                                                 show this help message and exit
-s SOURCE_PATH, --source SOURCE_PATH                                       select an source image
-t TARGET_PATH, --target TARGET_PATH                                       select an target image or video
-o OUTPUT_PATH, --output OUTPUT_PATH                                       select output file or directory
--frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]                    frame processors (choices: face_swapper, face_enhancer, ...)
--keep-fps                                                                 keep target fps
--keep-frames                                                              keep temporary frames
--skip-audio                                                               skip target audio
--many-faces                                                               process every face
--reference-face-position REFERENCE_FACE_POSITION                          position of the reference face
--reference-frame-number REFERENCE_FRAME_NUMBER                            number of the reference frame
--similar-face-distance SIMILAR_FACE_DISTANCE                              face distance used for recognition
--temp-frame-format {jpg,png}                                              image format used for frame extraction
--temp-frame-quality [0-100]                                               image quality used for frame extraction
--output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}  encoder used for the output video
--output-video-quality [0-100]                                             quality used for the output video
--max-memory MAX_MEMORY                                                    maximum amount of RAM in GB
--execution-provider {cpu} [{cpu} ...]                                     available execution provider (choices: cpu, ...)
--execution-threads EXECUTION_THREADS                                      number of execution threads
-v, --version                                                              show program's version number and exit
</code></pre> 
<h3>Headless</h3> 
<p>Using the <code>-s/--source</code>, <code>-t/--target</code> and <code>-o/--output</code> argument will run the program in headless mode.</p> 
<h2>Disclaimer</h2> 
<p>This software is designed to contribute positively to the AI-generated media industry, assisting artists with tasks like character animation and models for clothing.</p> 
<p>We are aware of the potential ethical issues and have implemented measures to prevent the software from being used for inappropriate content, such as nudity.</p> 
<p>Users are expected to follow local laws and use the software responsibly. If using real faces, get consent and clearly label deepfakes when sharing. The developers aren't liable for user actions.</p> 
<h2>Licenses</h2> 
<p>Our software uses a lot of third party libraries as well pre-trained models. The users should keep in mind that these third party components have their own license and terms, therefore our license is not being applied.</p> 
<h2>Credits</h2> 
<ul> 
 <li><a href="https://github.com/deepinsight">deepinsight</a> for their <a href="https://github.com/deepinsight/insightface">insightface</a> project which provided a well-made library and models.</li> 
 <li>all developers behind the libraries used in this project</li> 
</ul> 
<h2>Documentation</h2> 
<p>Read the <a href="https://github.com/s0md3v/roop/wiki">documentation</a> for a deep dive.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>astral-sh/uv</title>
<link>https://github.com/astral-sh/uv</link>
<guid>https://github.com/astral-sh/uv</guid>
<content:encoded><![CDATA[
<div> 关键词：uv、Python、Rust、项目管理、工具管理

uv 是一个由 Astral 团队开发的 Python 包和项目管理工具，采用 Rust 语言编写。它旨在提供比 pip 更快的性能，并支持多种 Python 版本和应用。uv 具有以下核心功能：

1. **项目管理**：uv 可以管理项目依赖关系和环境，类似于 rye 或 poetry，支持锁定文件和工作空间等特性。
2. **工具管理**：uv 提供了一种执行和安装命令行工具的方式，类似于 pipx，允许用户在瞬时环境中运行工具。
3. **Python 管理**：uv 支持安装和快速切换 Python 版本，允许用户安装多个版本并使用特定版本执行任务。
4. **单文件脚本支持**：uv 可以管理单文件脚本的依赖关系和环境。
5. **pip 兼容性**：uv 提供了与 pip、pip-tools 和 virtualenv 命令相兼容的接口，但增加了高级特性，如依赖版本覆盖、平台独立的解决方案等。

总结：
uv 是一个全面的 Python 工具链，集成了项目管理、工具管理、Python 版本控制以及单文件脚本支持等功能。通过采用 Rust 编写，uv 在性能上优于传统的 Python 工具，如 pip。它提供了一个统一的界面来处理依赖、环境设置和工具执行，简化了开发流程。uv 的核心优势在于其速度提升（相比 pip 快10到100倍）、多版本 Python 支持、灵活的项目和工具管理能力，以及与现有 Python 工具链的兼容性，使得开发者能够无缝迁移到这个高效且功能丰富的工具中。 <div>
<p>An extremely fast Python package and project manager, written in Rust.</p><hr /><h1>uv</h1> 
<p><a href="https://github.com/astral-sh/uv"><img alt="uv" src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" /></a> <a href="https://pypi.python.org/pypi/uv"><img alt="image" src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" /></a> <a href="https://pypi.python.org/pypi/uv"><img alt="image" src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" /></a> <a href="https://pypi.python.org/pypi/uv"><img alt="image" src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" /></a> <a href="https://github.com/astral-sh/uv/actions"><img alt="Actions status" src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" /></a> <a href="https://discord.gg/astral-sh"><img alt="Discord" src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white" /></a></p> 
<p>An extremely fast Python package and project manager, written in Rust.</p> 
<p align="center"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <source media="(prefers-color-scheme: light)" /> 
  <img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /> 
  </p> 
<p align="center"> <i>Installing <a href="https://trio.readthedocs.io/">Trio</a>'s dependencies with a warm cache.</i> </p> 
<h2>Highlights</h2> 
<ul> 
 <li>🚀 A single tool to replace <code>pip</code>, <code>pip-tools</code>, <code>pipx</code>, <code>poetry</code>, <code>pyenv</code>, <code>virtualenv</code>, and more.</li> 
 <li>⚡️ <a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md">10-100x faster</a> than <code>pip</code>.</li> 
 <li>🐍 <a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-management">Installs and manages</a> Python versions.</li> 
 <li>🛠️ <a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tool-management">Runs and installs</a> Python applications.</li> 
 <li>❇️ <a href="https://raw.githubusercontent.com/astral-sh/uv/main/#script-support">Runs single-file scripts</a>, with support for <a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies">inline dependency metadata</a>.</li> 
 <li>🗂️ Provides <a href="https://raw.githubusercontent.com/astral-sh/uv/main/#project-management">comprehensive project management</a>, with a <a href="https://docs.astral.sh/uv/concepts/projects#lockfile">universal lockfile</a>.</li> 
 <li>🔩 Includes a <a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface">pip-compatible interface</a> for a performance boost with a familiar CLI.</li> 
 <li>🏢 Supports Cargo-style <a href="https://docs.astral.sh/uv/concepts/workspaces">workspaces</a> for scalable projects.</li> 
 <li>💾 Disk-space efficient, with a <a href="https://docs.astral.sh/uv/concepts/cache">global cache</a> for dependency deduplication.</li> 
 <li>⏬ Installable without Rust or Python via <code>curl</code> or <code>pip</code>.</li> 
 <li>🖥️ Supports macOS, Linux, and Windows.</li> 
</ul> 
<p>uv is backed by <a href="https://astral.sh">Astral</a>, the creators of <a href="https://github.com/astral-sh/ruff">Ruff</a>.</p> 
<h2>Installation</h2> 
<p>Install uv with our standalone installers, or from <a href="https://pypi.org/project/uv/">PyPI</a>:</p> 
<pre><code class="language-console"># On macOS and Linux.
$ curl -LsSf https://astral.sh/uv/install.sh | sh

# On Windows.
$ powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# With pip.
$ pip install uv
</code></pre> 
<p>See the <a href="https://docs.astral.sh/uv/getting-started/installation/">installation documentation</a> for details and alternative installation methods.</p> 
<h2>Documentation</h2> 
<p>uv's documentation is available at <a href="https://docs.astral.sh/uv">docs.astral.sh/uv</a>.</p> 
<p>Additionally, the command line reference documentation can be viewed with <code>uv help</code>.</p> 
<h2>Features</h2> 
<h3>Project management</h3> 
<p>uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to <code>rye</code> or <code>poetry</code>:</p> 
<pre><code class="language-console">$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtualenv at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.4

$ uv run ruff check
All checks passed!
</code></pre> 
<p>See the <a href="https://docs.astral.sh/uv/guides/projects/">project documentation</a> to get started.</p> 
<h3>Tool management</h3> 
<p>uv executes and installs command-line tools provided by Python packages, similar to <code>pipx</code>.</p> 
<p>Run a tool in an ephemeral environment using <code>uvx</code> (an alias for <code>uv tool run</code>):</p> 
<pre><code class="language-console">$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
</code></pre> 
<p>Install a tool with <code>uv tool install</code>:</p> 
<pre><code class="language-console">$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.4
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.4
</code></pre> 
<p>See the <a href="https://docs.astral.sh/uv/guides/tools/">tools documentation</a> to get started.</p> 
<h3>Python management</h3> 
<p>uv installs Python and allows quickly switching between versions.</p> 
<p>Install multiple Python versions:</p> 
<pre><code class="language-console">$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
</code></pre> 
<p>Download Python versions as needed:</p> 
<pre><code class="language-console">$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtualenv at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;&gt;
</code></pre> 
<p>Use a specific Python version in the current directory:</p> 
<pre><code>$ uv python pin pypy@3.11
Pinned `.python-version` to `pypy@3.11`
</code></pre> 
<p>See the <a href="https://docs.astral.sh/uv/guides/install-python/">Python installation documentation</a> to get started.</p> 
<h3>Script support</h3> 
<p>uv manages dependencies and environments for single-file scripts.</p> 
<p>Create a new script and add inline metadata declaring its dependencies:</p> 
<pre><code class="language-console">$ echo 'import requests; print(requests.get("https://astral.sh"))' &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
</code></pre> 
<p>Then, run the script in an isolated virtual environment:</p> 
<pre><code>$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
</code></pre> 
<p>See the <a href="https://docs.astral.sh/uv/guides/scripts/">scripts documentation</a> to get started.</p> 
<h3>A pip-compatible interface</h3> 
<p>uv provides a drop-in replacement for common <code>pip</code>, <code>pip-tools</code>, and <code>virtualenv</code> commands.</p> 
<p>uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.</p> 
<p>Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the <code>uv pip</code> interface.</p> 
<p>Compile requirements into a platform-independent requirements file:</p> 
<pre><code class="language-console">$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
</code></pre> 
<p>Create a virtual environment:</p> 
<pre><code class="language-console">$ uv venv
Using Python 3.12.3
Creating virtualenv at: .venv
Activate with: source .venv/bin/activate
</code></pre> 
<p>Install the locked requirements:</p> 
<pre><code class="language-console">$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
</code></pre> 
<p>See the <a href="https://docs.astral.sh/uv/pip/index/">pip interface documentation</a> to get started.</p> 
<h2>Platform support</h2> 
<p>See uv's <a href="https://docs.astral.sh/uv/reference/platforms/">platform support</a> document.</p> 
<h2>Versioning policy</h2> 
<p>See uv's <a href="https://docs.astral.sh/uv/reference/versioning/">versioning policy</a> document.</p> 
<h2>Contributing</h2> 
<p>We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the <a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md">contributing guide</a> to get started.</p> 
<h2>Acknowledgements</h2> 
<p>uv's dependency resolver uses <a href="https://github.com/pubgrub-rs/pubgrub">PubGrub</a> under the hood. We're grateful to the PubGrub maintainers, especially <a href="https://github.com/Eh2406">Jacob Finkelman</a>, for their support.</p> 
<p>uv's Git implementation is based on <a href="https://github.com/rust-lang/cargo">Cargo</a>.</p> 
<p>Some of uv's optimizations are inspired by the great work we've seen in <a href="https://pnpm.io/">pnpm</a>, <a href="https://github.com/orogene/orogene">Orogene</a>, and <a href="https://github.com/oven-sh/bun">Bun</a>. We've also learned a lot from Nathaniel J. Smith's <a href="https://github.com/njsmith/posy">Posy</a> and adapted its <a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline">trampoline</a> for Windows support.</p> 
<h2>License</h2> 
<p>uv is licensed under either of</p> 
<ul> 
 <li>Apache License, Version 2.0, (<a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE">LICENSE-APACHE</a> or <a href="https://www.apache.org/licenses/LICENSE-2.0">https://www.apache.org/licenses/LICENSE-2.0</a>)</li> 
 <li>MIT license (<a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT">LICENSE-MIT</a> or <a href="https://opensource.org/licenses/MIT">https://opensource.org/licenses/MIT</a>)</li> 
</ul> 
<p>at your option.</p> 
<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.</p> 
<div align="center"> 
 <a href="https://astral.sh" style="background: none;" target="_blank"> <img alt="Made by Astral" src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" /> </a> 
</div>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>openai/whisper</title>
<link>https://github.com/openai/whisper</link>
<guid>https://github.com/openai/whisper</guid>
<content:encoded><![CDATA[
<div> 关键词：Whisper、Transformer模型、语音识别、多语言支持、多任务学习

总结：

Whisper是一种通用的语音识别模型，它在大规模数据集上进行了训练，可以进行多语言的语音识别、语音翻译和语言识别。该模型采用了一个Transformer序列到序列的架构，能够处理多个语音处理任务，如多语言语音识别、语音翻译、口语语种识别和语音活动检测。通过将这些任务联合表示为需要预测的序列中的令牌，模型可以取代传统语音处理管道中的多个阶段。在训练过程中，使用了一组特殊令牌作为任务指定器或分类目标，实现了多任务学习。

Whisper提供了五个不同大小的模型，包括四个仅限英语的版本，每个模型都有不同的参数量、内存需求和推理速度。这些模型在性能和准确度之间提供了权衡，适用于不同的应用场景。在安装时，需要确保系统中安装了ffmpeg工具，并可能需要配置PATH环境变量以支持Rust开发环境的安装。

Whisper提供了命令行和Python接口供用户使用。通过命令行，用户可以直接输入音频文件并使用选定的模型进行转录。在Python环境中，用户可以加载模型并使用其方法进行转录和语言检测等操作。此外，Whisper还提供了一个帮助文档，详细介绍了所有可用的选项和命令。

最后，Whisper的代码和模型权重遵循MIT许可证发布，用户可以在GitHub仓库中找到详细的许可信息。 <div>
<p>Robust Speech Recognition via Large-Scale Weak Supervision</p><hr /><h1>Whisper</h1> 
<p><a href="https://openai.com/blog/whisper">[Blog]</a> <a href="https://arxiv.org/abs/2212.04356">[Paper]</a> <a href="https://github.com/openai/whisper/raw/main/model-card.md">[Model card]</a> <a href="https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb">[Colab example]</a></p> 
<p>Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.</p> 
<h2>Approach</h2> 
<p><img alt="Approach" src="https://raw.githubusercontent.com/openai/whisper/main/approach.png" /></p> 
<p>A Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.</p> 
<h2>Setup</h2> 
<p>We used Python 3.9.9 and <a href="https://pytorch.org/">PyTorch</a> 1.10.1 to train and test our models, but the codebase is expected to be compatible with Python 3.8-3.11 and recent PyTorch versions. The codebase also depends on a few Python packages, most notably <a href="https://github.com/openai/tiktoken">OpenAI's tiktoken</a> for their fast tokenizer implementation. You can download and install (or update to) the latest release of Whisper with the following command:</p> 
<pre><code>pip install -U openai-whisper
</code></pre> 
<p>Alternatively, the following command will pull and install the latest commit from this repository, along with its Python dependencies:</p> 
<pre><code>pip install git+https://github.com/openai/whisper.git 
</code></pre> 
<p>To update the package to the latest version of this repository, please run:</p> 
<pre><code>pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git
</code></pre> 
<p>It also requires the command-line tool <a href="https://ffmpeg.org/"><code>ffmpeg</code></a> to be installed on your system, which is available from most package managers:</p> 
<pre><code class="language-bash"># on Ubuntu or Debian
sudo apt update &amp;&amp; sudo apt install ffmpeg

# on Arch Linux
sudo pacman -S ffmpeg

# on MacOS using Homebrew (https://brew.sh/)
brew install ffmpeg

# on Windows using Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# on Windows using Scoop (https://scoop.sh/)
scoop install ffmpeg
</code></pre> 
<p>You may need <a href="http://rust-lang.org"><code>rust</code></a> installed as well, in case <a href="https://github.com/openai/tiktoken">tiktoken</a> does not provide a pre-built wheel for your platform. If you see installation errors during the <code>pip install</code> command above, please follow the <a href="https://www.rust-lang.org/learn/get-started">Getting started page</a> to install Rust development environment. Additionally, you may need to configure the <code>PATH</code> environment variable, e.g. <code>export PATH="$HOME/.cargo/bin:$PATH"</code>. If the installation fails with <code>No module named 'setuptools_rust'</code>, you need to install <code>setuptools_rust</code>, e.g. by running:</p> 
<pre><code class="language-bash">pip install setuptools-rust
</code></pre> 
<h2>Available models and languages</h2> 
<p>There are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. Below are the names of the available models and their approximate memory requirements and inference speed relative to the large model; actual speed may vary depending on many factors including the available hardware.</p> 
<table> 
 <thead> 
  <tr> 
   <th align="center">Size</th> 
   <th align="center">Parameters</th> 
   <th align="center">English-only model</th> 
   <th align="center">Multilingual model</th> 
   <th align="center">Required VRAM</th> 
   <th align="center">Relative speed</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td align="center">tiny</td> 
   <td align="center">39 M</td> 
   <td align="center"><code>tiny.en</code></td> 
   <td align="center"><code>tiny</code></td> 
   <td align="center">~1 GB</td> 
   <td align="center">~32x</td> 
  </tr> 
  <tr> 
   <td align="center">base</td> 
   <td align="center">74 M</td> 
   <td align="center"><code>base.en</code></td> 
   <td align="center"><code>base</code></td> 
   <td align="center">~1 GB</td> 
   <td align="center">~16x</td> 
  </tr> 
  <tr> 
   <td align="center">small</td> 
   <td align="center">244 M</td> 
   <td align="center"><code>small.en</code></td> 
   <td align="center"><code>small</code></td> 
   <td align="center">~2 GB</td> 
   <td align="center">~6x</td> 
  </tr> 
  <tr> 
   <td align="center">medium</td> 
   <td align="center">769 M</td> 
   <td align="center"><code>medium.en</code></td> 
   <td align="center"><code>medium</code></td> 
   <td align="center">~5 GB</td> 
   <td align="center">~2x</td> 
  </tr> 
  <tr> 
   <td align="center">large</td> 
   <td align="center">1550 M</td> 
   <td align="center">N/A</td> 
   <td align="center"><code>large</code></td> 
   <td align="center">~10 GB</td> 
   <td align="center">1x</td> 
  </tr> 
 </tbody> 
</table> 
<p>The <code>.en</code> models for English-only applications tend to perform better, especially for the <code>tiny.en</code> and <code>base.en</code> models. We observed that the difference becomes less significant for the <code>small.en</code> and <code>medium.en</code> models.</p> 
<p>Whisper's performance varies widely depending on the language. The figure below shows a performance breakdown of <code>large-v3</code> and <code>large-v2</code> models by language, using WERs (word error rates) or CER (character error rates, shown in <em>Italic</em>) evaluated on the Common Voice 15 and Fleurs datasets. Additional WER/CER metrics corresponding to the other models and datasets can be found in Appendix D.1, D.2, and D.4 of <a href="https://arxiv.org/abs/2212.04356">the paper</a>, as well as the BLEU (Bilingual Evaluation Understudy) scores for translation in Appendix D.3.</p> 
<p><img alt="WER breakdown by language" src="https://github.com/openai/whisper/assets/266841/f4619d66-1058-4005-8f67-a9d811b77c62" /></p> 
<h2>Command-line usage</h2> 
<p>The following command will transcribe speech in audio files, using the <code>medium</code> model:</p> 
<pre><code>whisper audio.flac audio.mp3 audio.wav --model medium
</code></pre> 
<p>The default setting (which selects the <code>small</code> model) works well for transcribing English. To transcribe an audio file containing non-English speech, you can specify the language using the <code>--language</code> option:</p> 
<pre><code>whisper japanese.wav --language Japanese
</code></pre> 
<p>Adding <code>--task translate</code> will translate the speech into English:</p> 
<pre><code>whisper japanese.wav --language Japanese --task translate
</code></pre> 
<p>Run the following to view all available options:</p> 
<pre><code>whisper --help
</code></pre> 
<p>See <a href="https://github.com/openai/whisper/raw/main/whisper/tokenizer.py">tokenizer.py</a> for the list of all available languages.</p> 
<h2>Python usage</h2> 
<p>Transcription can also be performed within Python:</p> 
<pre><code class="language-python">import whisper

model = whisper.load_model("base")
result = model.transcribe("audio.mp3")
print(result["text"])
</code></pre> 
<p>Internally, the <code>transcribe()</code> method reads the entire file and processes the audio with a sliding 30-second window, performing autoregressive sequence-to-sequence predictions on each window.</p> 
<p>Below is an example usage of <code>whisper.detect_language()</code> and <code>whisper.decode()</code> which provide lower-level access to the model.</p> 
<pre><code class="language-python">import whisper

model = whisper.load_model("base")

# load audio and pad/trim it to fit 30 seconds
audio = whisper.load_audio("audio.mp3")
audio = whisper.pad_or_trim(audio)

# make log-Mel spectrogram and move to the same device as the model
mel = whisper.log_mel_spectrogram(audio).to(model.device)

# detect the spoken language
_, probs = model.detect_language(mel)
print(f"Detected language: {max(probs, key=probs.get)}")

# decode the audio
options = whisper.DecodingOptions()
result = whisper.decode(model, mel, options)

# print the recognized text
print(result.text)
</code></pre> 
<h2>More examples</h2> 
<p>Please use the <a href="https://github.com/openai/whisper/discussions/categories/show-and-tell">🙌 Show and tell</a> category in Discussions for sharing more example usages of Whisper and third-party extensions such as web demos, integrations with other tools, ports for different platforms, etc.</p> 
<h2>License</h2> 
<p>Whisper's code and model weights are released under the MIT License. See <a href="https://github.com/openai/whisper/raw/main/LICENSE">LICENSE</a> for further details.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>thuml/Time-Series-Library</title>
<link>https://github.com/thuml/Time-Series-Library</link>
<guid>https://github.com/thuml/Time-Series-Library</guid>
<content:encoded><![CDATA[
<div> 关键词：TSLib、时间序列分析、深度学习、模型评估、开源库

总结：

TSLib是一个面向深度学习研究人员的时间序列分析开源库。它提供了一个干净的代码基础，用于评估先进的深度时间序列模型或开发自己的模型，涵盖了长期和短期预测、缺失值填充、异常检测和分类等五大主流任务。该库的最新新闻包括新增了流行序列模型mamba和改进的长短期预测方法iTransformer等。此外，TSLib还提供了详细的使用指南、实验脚本以及与时间序列分析相关的基准测试。

TSLib的用户可以利用这个综合性的基准和代码库来训练和评估时间序列模型，通过运行实验脚本来复现研究结果。对于那些希望贡献新模型的研究人员，TSLib也欢迎他们提交论文链接或发起Pull请求，以更新模型列表和排行榜。为了促进研究，TSLib还发布了一篇全面的综述论文，对当前支持的模型进行了深入的实验分析和设计原则总结。最终，TSLib得到了国家关键研发项目的资金支持，并在时间序列预测、异常检测、分类和相关领域拥有丰富的实验数据集来源。

此库为深度时间序列分析提供了一个强大的工具集合，旨在促进学术研究和应用开发。 <div>
<p>A Library for Advanced Deep Time Series Models.</p><hr /><h1>Time Series Library (TSLib)</h1> 
<p>TSLib is an open-source library for deep learning researchers, especially for deep time series analysis.</p> 
<p>We provide a neat code base to evaluate advanced deep time series models or develop your model, which covers five mainstream tasks: <strong>long- and short-term forecasting, imputation, anomaly detection, and classification.</strong></p> 
<p><span>🚩</span><strong>News</strong> (2024.07) We wrote a comprehensive survey of <a href="https://arxiv.org/abs/2407.13278">[Deep Time Series Models]</a> with a rigorous benchmark based on TSLib. In this paper, we summarized the design principles of current time series models supported by insightful experiments, hoping to be helpful to future research.</p> 
<p><span>🚩</span><strong>News</strong> (2024.04) Many thanks for the great work from <a href="https://github.com/thuml/Time-Series-Library/pull/378">frecklebars</a>. The famous sequential model <a href="https://arxiv.org/abs/2312.00752">Mamba</a> has been included in our library. See <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Mamba.py">this file</a>, where you need to install <code>mamba_ssm</code> with pip at first.</p> 
<p><span>🚩</span><strong>News</strong> (2024.03) Given the inconsistent look-back length of various papers, we split the long-term forecasting in the leaderboard into two categories: Look-Back-96 and Look-Back-Searching. We recommend researchers read <a href="https://openreview.net/pdf?id=7oLshfEIC2">TimeMixer</a>, which includes both look-back length settings in experiments for scientific rigor.</p> 
<p><span>🚩</span><strong>News</strong> (2023.10) We add an implementation to <a href="https://arxiv.org/abs/2310.06625">iTransformer</a>, which is the state-of-the-art model for long-term forecasting. The official code and complete scripts of iTransformer can be found <a href="https://github.com/thuml/iTransformer">here</a>.</p> 
<p><span>🚩</span><strong>News</strong> (2023.09) We added a detailed <a href="https://github.com/thuml/Time-Series-Library/raw/main/tutorial/TimesNet_tutorial.ipynb">tutorial</a> for <a href="https://openreview.net/pdf?id=ju_Uqw384Oq">TimesNet</a> and this library, which is quite friendly to beginners of deep time series analysis.</p> 
<p><span>🚩</span><strong>News</strong> (2023.02) We release the TSlib as a comprehensive benchmark and code base for time series models, which is extended from our previous GitHub repository <a href="https://github.com/thuml/Autoformer">Autoformer</a>.</p> 
<h2>Leaderboard for Time Series Analysis</h2> 
<p>Till March 2024, the top three models for five different tasks are:</p> 
<table> 
 <thead> 
  <tr> 
   <th>Model<br />Ranking</th> 
   <th>Long-term<br />Forecasting<br />Look-Back-96</th> 
   <th>Long-term<br />Forecasting<br />Look-Back-Searching</th> 
   <th>Short-term<br />Forecasting</th> 
   <th>Imputation</th> 
   <th>Classification</th> 
   <th>Anomaly<br />Detection</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>🥇 1st</td> 
   <td><a href="https://arxiv.org/abs/2310.06625">iTransformer</a></td> 
   <td><a href="https://openreview.net/pdf?id=7oLshfEIC2">TimeMixer</a></td> 
   <td><a href="https://arxiv.org/abs/2210.02186">TimesNet</a></td> 
   <td><a href="https://arxiv.org/abs/2210.02186">TimesNet</a></td> 
   <td><a href="https://arxiv.org/abs/2210.02186">TimesNet</a></td> 
   <td><a href="https://arxiv.org/abs/2210.02186">TimesNet</a></td> 
  </tr> 
  <tr> 
   <td>🥈 2nd</td> 
   <td><a href="https://openreview.net/pdf?id=7oLshfEIC2">TimeMixer</a></td> 
   <td><a href="https://github.com/yuqinie98/PatchTST">PatchTST</a></td> 
   <td><a href="https://github.com/thuml/Nonstationary_Transformers">Non-stationary<br />Transformer</a></td> 
   <td><a href="https://github.com/thuml/Nonstationary_Transformers">Non-stationary<br />Transformer</a></td> 
   <td><a href="https://github.com/thuml/Nonstationary_Transformers">Non-stationary<br />Transformer</a></td> 
   <td><a href="https://github.com/MAZiqing/FEDformer">FEDformer</a></td> 
  </tr> 
  <tr> 
   <td>🥉 3rd</td> 
   <td><a href="https://arxiv.org/abs/2210.02186">TimesNet</a></td> 
   <td><a href="https://arxiv.org/pdf/2205.13504.pdf">DLinear</a></td> 
   <td><a href="https://github.com/MAZiqing/FEDformer">FEDformer</a></td> 
   <td><a href="https://github.com/thuml/Autoformer">Autoformer</a></td> 
   <td><a href="https://github.com/zhouhaoyi/Informer2020">Informer</a></td> 
   <td><a href="https://github.com/thuml/Autoformer">Autoformer</a></td> 
  </tr> 
 </tbody> 
</table> 
<p><strong>Note: We will keep updating this leaderboard.</strong> If you have proposed advanced and awesome models, you can send us your paper/code link or raise a pull request. We will add them to this repo and update the leaderboard as soon as possible.</p> 
<p><strong>Compared models of this leaderboard.</strong> ☑ means that their codes have already been included in this repo.</p> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>TimeMixer</strong> - TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting <a href="https://openreview.net/pdf?id=7oLshfEIC2">[ICLR 2024]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/TimeMixer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>TSMixer</strong> - TSMixer: An All-MLP Architecture for Time Series Forecasting <a href="https://arxiv.org/pdf/2303.06053.pdf">[arXiv 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/TSMixer.py">[Code]</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>iTransformer</strong> - iTransformer: Inverted Transformers Are Effective for Time Series Forecasting <a href="https://arxiv.org/abs/2310.06625">[ICLR 2024]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/iTransformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>PatchTST</strong> - A Time Series is Worth 64 Words: Long-term Forecasting with Transformers <a href="https://openreview.net/pdf?id=Jbdc0vTOcol">[ICLR 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/PatchTST.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>TimesNet</strong> - TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis <a href="https://openreview.net/pdf?id=ju_Uqw384Oq">[ICLR 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/TimesNet.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>DLinear</strong> - Are Transformers Effective for Time Series Forecasting? <a href="https://arxiv.org/pdf/2205.13504.pdf">[AAAI 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/DLinear.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>LightTS</strong> - Less Is More: Fast Multivariate Time Series Forecasting with Light Sampling-oriented MLP Structures <a href="https://arxiv.org/abs/2207.01186">[arXiv 2022]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/LightTS.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>ETSformer</strong> - ETSformer: Exponential Smoothing Transformers for Time-series Forecasting <a href="https://arxiv.org/abs/2202.01381">[arXiv 2022]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/ETSformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Non-stationary Transformer</strong> - Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting <a href="https://openreview.net/pdf?id=ucNDIDRNjjv">[NeurIPS 2022]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Nonstationary_Transformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>FEDformer</strong> - FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting <a href="https://proceedings.mlr.press/v162/zhou22g.html">[ICML 2022]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/FEDformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Pyraformer</strong> - Pyraformer: Low-complexity Pyramidal Attention for Long-range Time Series Modeling and Forecasting <a href="https://openreview.net/pdf?id=0EXmFzUn5I">[ICLR 2022]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Pyraformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Autoformer</strong> - Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting <a href="https://openreview.net/pdf?id=I55UqU-M11y">[NeurIPS 2021]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Autoformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Informer</strong> - Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17325/17132">[AAAI 2021]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Informer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Reformer</strong> - Reformer: The Efficient Transformer <a href="https://openreview.net/forum?id=rkgNKkHtvB">[ICLR 2020]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Reformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Transformer</strong> - Attention is All You Need <a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">[NeurIPS 2017]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Transformer.py">[Code]</a>.</li> 
</ul> 
<p>See our latest paper <a href="https://arxiv.org/abs/2210.02186">[TimesNet]</a> for the comprehensive benchmark. We will release a real-time updated online version soon.</p> 
<p><strong>Newly added baselines.</strong> We will add them to the leaderboard after a comprehensive evaluation.</p> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Mamba</strong> - Mamba: Linear-Time Sequence Modeling with Selective State Spaces <a href="https://arxiv.org/abs/2312.00752">[arXiv 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Mamba.py">[Code]</a></li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>SegRNN</strong> - SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting <a href="https://arxiv.org/abs/2308.11200.pdf">[arXiv 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/SegRNN.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Koopa</strong> - Koopa: Learning Non-stationary Time Series Dynamics with Koopman Predictors <a href="https://arxiv.org/pdf/2305.18803.pdf">[NeurIPS 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Koopa.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>FreTS</strong> - Frequency-domain MLPs are More Effective Learners in Time Series Forecasting <a href="https://arxiv.org/pdf/2311.06184.pdf">[NeurIPS 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/FreTS.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>TiDE</strong> - Long-term Forecasting with TiDE: Time-series Dense Encoder <a href="https://arxiv.org/pdf/2304.08424.pdf">[arXiv 2023]</a> <a href="https://github.com/thuml/Time-Series-Library/raw/main/models/TiDE.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>FiLM</strong> - FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting <a href="https://openreview.net/forum?id=zTQdHSQUQWc">[NeurIPS 2022]</a><a href="https://github.com/thuml/Time-Series-Library/raw/main/models/FiLM.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>MICN</strong> - MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting <a href="https://openreview.net/pdf?id=zt53IDUR1U">[ICLR 2023]</a><a href="https://github.com/thuml/Time-Series-Library/raw/main/models/MICN.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>Crossformer</strong> - Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting <a href="https://openreview.net/pdf?id=vSVLM2j9eie">[ICLR 2023]</a><a href="https://github.com/thuml/Time-Series-Library/raw/main/models/Crossformer.py">[Code]</a>.</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> <strong>TFT</strong> - Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting <a href="https://arxiv.org/abs/1912.09363">[arXiv 2019]</a><a href="https://github.com/thuml/Time-Series-Library/raw/main/models/TemporalFusionTransformer.py">[Code]</a>.</li> 
</ul> 
<h2>Usage</h2> 
<ol> 
 <li>Install Python 3.8. For convenience, execute the following command.</li> 
</ol> 
<pre><code>pip install -r requirements.txt
</code></pre> 
<ol start="2"> 
 <li>Prepare Data. You can obtain the well pre-processed datasets from <a href="https://drive.google.com/drive/folders/13Cg1KYOlzM5C7K8gK8NfC-F3EYxkM3D2?usp=sharing">[Google Drive]</a> or&nbsp;<a href="https://pan.baidu.com/s/1r3KhGd0Q9PJIUZdfEYoymg?pwd=i9iy">[Baidu Drive]</a>, Then place the downloaded data in the folder<code>./dataset</code>. Here is a summary of supported datasets.</li> 
</ol> 
<p align="center"> <img align="center" alt="" height="200" src="https://raw.githubusercontent.com/thuml/Time-Series-Library/main/.%5Cpic%5Cdataset.png" /> </p> 
<ol start="3"> 
 <li>Train and evaluate model. We provide the experiment scripts for all benchmarks under the folder <code>./scripts/</code>. You can reproduce the experiment results as the following examples:</li> 
</ol> 
<pre><code># long-term forecast
bash ./scripts/long_term_forecast/ETT_script/TimesNet_ETTh1.sh
# short-term forecast
bash ./scripts/short_term_forecast/TimesNet_M4.sh
# imputation
bash ./scripts/imputation/ETT_script/TimesNet_ETTh1.sh
# anomaly detection
bash ./scripts/anomaly_detection/PSM/TimesNet.sh
# classification
bash ./scripts/classification/TimesNet.sh
</code></pre> 
<ol start="4"> 
 <li>Develop your own model.</li> 
</ol> 
<ul> 
 <li>Add the model file to the folder <code>./models</code>. You can follow the <code>./models/Transformer.py</code>.</li> 
 <li>Include the newly added model in the <code>Exp_Basic.model_dict</code> of <code>./exp/exp_basic.py</code>.</li> 
 <li>Create the corresponding scripts under the folder <code>./scripts</code>.</li> 
</ul> 
<p>Note: The original code for the classification task can be found <a href="https://github.com/thuml/Flowformer/tree/main/Flowformer_TimeSeries">here</a>. It is hard to fuse all five tasks in one library. We are still working on this task.</p> 
<h2>Citation</h2> 
<p>If you find this repo useful, please cite our paper.</p> 
<pre><code>@inproceedings{wu2023timesnet,
  title={TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis},
  author={Haixu Wu and Tengge Hu and Yong Liu and Hang Zhou and Jianmin Wang and Mingsheng Long},
  booktitle={International Conference on Learning Representations},
  year={2023},
}

@article{wang2024tssurvey,
  title={Deep Time Series Models: A Comprehensive Survey and Benchmark},
  author={Yuxuan Wang and Haixu Wu and Jiaxiang Dong and Yong Liu and Mingsheng Long and Jianmin Wang},
  booktitle={arXiv preprint arXiv:2407.13278},
  year={2024},
}
</code></pre> 
<h2>Contact</h2> 
<p>If you have any questions or suggestions, feel free to contact our maintenance team:</p> 
<p>Current:</p> 
<ul> 
 <li>Haixu Wu (Ph.D. student, <a href="mailto:wuhx23@mails.tsinghua.edu.cn">wuhx23@mails.tsinghua.edu.cn</a>)</li> 
 <li>Yong Liu (Ph.D. student, <a href="mailto:liuyong21@mails.tsinghua.edu.cn">liuyong21@mails.tsinghua.edu.cn</a>)</li> 
 <li>Yuxuan Wang (Ph.D. student, <a href="mailto:wangyuxu22@mails.tsinghua.edu.cn">wangyuxu22@mails.tsinghua.edu.cn</a>)</li> 
 <li>Huikun Weng (Undergraduate, <a href="mailto:wenghk22@mails.tsinghua.edu.cn">wenghk22@mails.tsinghua.edu.cn</a>)</li> 
</ul> 
<p>Previous:</p> 
<ul> 
 <li>Tengge Hu (Master student, <a href="mailto:htg21@mails.tsinghua.edu.cn">htg21@mails.tsinghua.edu.cn</a>)</li> 
 <li>Haoran Zhang (Master student, <a href="mailto:z-hr20@mails.tsinghua.edu.cn">z-hr20@mails.tsinghua.edu.cn</a>)</li> 
 <li>Jiawei Guo (Undergraduate, <a href="mailto:guo-jw21@mails.tsinghua.edu.cn">guo-jw21@mails.tsinghua.edu.cn</a>)</li> 
</ul> 
<p>Or describe it in Issues.</p> 
<h2>Acknowledgement</h2> 
<p>This project is supported by the National Key R&amp;D Program of China (2021YFB1715200).</p> 
<p>This library is constructed based on the following repos:</p> 
<ul> 
 <li> <p>Forecasting: <a href="https://github.com/thuml/Autoformer">https://github.com/thuml/Autoformer</a>.</p> </li> 
 <li> <p>Anomaly Detection: <a href="https://github.com/thuml/Anomaly-Transformer">https://github.com/thuml/Anomaly-Transformer</a>.</p> </li> 
 <li> <p>Classification: <a href="https://github.com/thuml/Flowformer">https://github.com/thuml/Flowformer</a>.</p> </li> 
</ul> 
<p>All the experiment datasets are public, and we obtain them from the following links:</p> 
<ul> 
 <li> <p>Long-term Forecasting and Imputation: <a href="https://github.com/thuml/Autoformer">https://github.com/thuml/Autoformer</a>.</p> </li> 
 <li> <p>Short-term Forecasting: <a href="https://github.com/ServiceNow/N-BEATS">https://github.com/ServiceNow/N-BEATS</a>.</p> </li> 
 <li> <p>Anomaly Detection: <a href="https://github.com/thuml/Anomaly-Transformer">https://github.com/thuml/Anomaly-Transformer</a>.</p> </li> 
 <li> <p>Classification: <a href="https://www.timeseriesclassification.com/">https://www.timeseriesclassification.com/</a>.</p> </li> 
</ul> 
<h2>All Thanks To Our Contributors</h2> 
<a href="https://github.com/thuml/Time-Series-Library/graphs/contributors"> <img src="https://contrib.rocks/image?repo=thuml/Time-Series-Library" /> </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>danielmiessler/fabric</title>
<link>https://github.com/danielmiessler/fabric</link>
<guid>https://github.com/danielmiessler/fabric</guid>
<content:encoded><![CDATA[
<div> 关键词：fabric、AI、人类辅助、模块化框架、Go语言

总结：
fabric 是一个开源的人类辅助框架，利用 AI 提供了一个模块化的解决方案，能够针对特定问题使用众包的 AI 提示来解决具体任务。其核心理念是将复杂问题分解为多个可单独处理的部分，并通过集成不同的 AI 提示来实现自动化处理。fabric 支持用户收集和整合各种有用的 AI 提示（称为“模式”），以适应日常生活的不同场景，如提取视频和播客精华、撰写自定义风格的文章、总结学术论文等。

在安装方面，用户可以通过命令行直接从仓库安装并运行 setup 命令进行初始化配置。为了确保与新版本的兼容性，需要在迁移至 Go 语言版本时卸载旧版 Python 版本并重新安装 Go 版本的 fabric。

在使用过程中，用户可以调用特定的模式来执行所需任务，并通过设置参数如温度、顶部概率等来调整 AI 的响应。fabric 还提供了一些辅助工具，如 yt，用于从 YouTube 获取视频转录内容，以便于后续的 AI 处理。

此外，fabric 强调了用户自定义模式的能力，允许用户创建私有或公开共享的模式，以适应个性化需求或社区分享。通过与多种 AI 模型（如 openai 和 ollama）兼容，fabric 扩展了 AI 应用的灵活性和范围。 <div>
<p>fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.</p><hr /><div align="center"> 
 <img alt="fabriclogo" height="400" src="https://raw.githubusercontent.com/danielmiessler/fabric/main/images/fabric-logo-gif.gif" width="400" /> 
 <h1><code>fabric</code></h1> 
 <p><img alt="Static Badge" src="https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple" /> <br /> <img alt="GitHub top language" src="https://img.shields.io/github/languages/top/danielmiessler/fabric" /> <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/danielmiessler/fabric" /> <a href="https://opensource.org/licenses/MIT"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" /></a></p> 
 <p class="align center"> </p>
 <h4><code>fabric</code> is an open-source framework for augmenting humans using AI.</h4> 
 <p></p> 
 <p><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#whatandwhy">What and Why</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#philosophy">Philosophy</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Installation">Installation</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Usage">Usage</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#examples">Examples</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#just-use-the-patterns">Just Use the Patterns</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#custom-patterns">Custom Patterns</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#helper-apps">Helper Apps</a> • <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#meta">Meta</a></p> 
</div> 
<h2>Navigation</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#what-and-why">What and Why</a></li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#philosophy">Philosophy</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#breaking-problems-into-components">Breaking problems into components</a></li> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#too-many-prompts">Too many prompts</a></li> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#our-approach-to-prompting">The Fabric approach to prompting</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Installation">Installation</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Migrating">Migrating</a></li> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Upgrading">Upgrading</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Usage">Usage</a></li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#examples">Examples</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#just-use-the-patterns">Just use the Patterns</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#custom-patterns">Custom Patterns</a></li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#helper-apps">Helper Apps</a></li> 
 <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#meta">Meta</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#primary-contributors">Primary contributors</a></li> 
  </ul> </li> 
</ul> 
<br /> 
<blockquote> 
 <p>[!NOTE] August 20, 2024 — We have migrated to Go, and the transition has been pretty smooth! The biggest thing to know is that <strong>the previous installation instructions in the various Fabric videos out there will no longer work</strong> because they were for the legacy (Python) version. Check the new <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Installation">install instructions</a> below.</p> 
</blockquote> 
<h2>Intro videos</h2> 
<p>Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#Installation">install instructions</a> below.</p> 
<ul> 
 <li><a href="https://www.youtube.com/watch?v=UbDyjIIGaxQ">Network Chuck</a></li> 
 <li><a href="https://www.youtube.com/watch?v=vF-MQmVxnCs">David Bombal</a></li> 
 <li><a href="https://www.youtube.com/watch?v=wPEyyigh10g">My Own Intro to the Tool</a></li> 
 <li><a href="https://www.youtube.com/results?search_query=fabric+ai">More Fabric YouTube Videos</a></li> 
</ul> 
<h2>What and why</h2> 
<p>Since the start of 2023 and GenAI we've seen a massive number of AI applications for accomplishing tasks. It's powerful, but <em>it's not easy to integrate this functionality into our lives.</em></p> 
<div align="center"> 
 <h4>In other words, AI doesn't have a capabilities problem—it has an <em>integration</em> problem.</h4> 
</div> 
<p>Fabric was created to address this by enabling everyone to granularly apply AI to everyday challenges.</p> 
<h2>Philosophy</h2> 
<blockquote> 
 <p>AI isn't a thing; it's a <em>magnifier</em> of a thing. And that thing is <strong>human creativity</strong>.</p> 
</blockquote> 
<p>We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the <strong>human</strong> problems we want to solve.</p> 
<h3>Breaking problems into components</h3> 
<p>Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.</p> 
<img alt="augmented_challenges" src="https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06" width="2078" /> 
<h3>Too many prompts</h3> 
<p>Prompts are good for this, but the biggest challenge I faced in 2023——which still exists today—is <strong>the sheer number of AI prompts out there</strong>. We all have prompts that are useful, but it's hard to discover new ones, know if they are good or not, <em>and manage different versions of the ones we like</em>.</p> 
<p>One of <code>fabric</code>'s primary features is helping people collect and integrate prompts, which we call <em>Patterns</em>, into various parts of their lives.</p> 
<p>Fabric has Patterns for all sorts of life and work activities, including:</p> 
<ul> 
 <li>Extracting the most interesting parts of YouTube videos and podcasts</li> 
 <li>Writing an essay in your own voice with just an idea as an input</li> 
 <li>Summarizing opaque academic papers</li> 
 <li>Creating perfectly matched AI art prompts for a piece of writing</li> 
 <li>Rating the quality of content to see if you want to read/watch the whole thing</li> 
 <li>Getting summaries of long, boring content</li> 
 <li>Explaining code to you</li> 
 <li>Turning bad documentation into usable documentation</li> 
 <li>Creating social media posts from any content input</li> 
 <li>And a million more…</li> 
</ul> 
<h2>Installation</h2> 
<p>To install Fabric, <a href="https://go.dev/doc/install">make sure Go is installed</a>, and then run the following command.</p> 
<pre><code class="language-bash"># Install Fabric directly from the repo
go install github.com/danielmiessler/fabric@latest

# Run the setup to set up your directories and keys
fabric --setup
</code></pre> 
<h3>Environment Variables</h3> 
<p>If everything works you are good to go, but you may need to set some environment variables in your <code>~/.bashrc</code> or <code>~/.zshrc</code> file. Here is an example of what you can add:</p> 
<pre><code class="language-bash"># Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH:
</code></pre> 
<h3>Migration</h3> 
<p>If you have the Legacy (Python) version installed and want to migrate to the Go version, here's how you do it. It's basically two steps: 1) uninstall the Python version, and 2) install the Go version.</p> 
<pre><code class="language-bash"># Uninstall Legacy Fabric
pipx uninstall fabric

# Clear any old Fabric aliases
(check your .bashrc, .zshrc, etc.)
# Install the Go version
go install github.com/danielmiessler/fabric@latest
# Run setup for the new version. Important because things have changed
fabric --setup
</code></pre> 
<p>Then <a href="https://raw.githubusercontent.com/danielmiessler/fabric/main/#environmental-variables">set your environmental variables</a> as shown above.</p> 
<h3>Upgrading</h3> 
<p>The great thing about Go is that it's super easy to upgrade. Just run the same command you used to install it in the first place and you'll always get the latest version.</p> 
<pre><code class="language-bash">go install github.com/danielmiessler/fabric@latest
</code></pre> 
<h2>Usage</h2> 
<p>Once you have it all set up, here's how to use it.</p> 
<pre><code class="language-bash">fabric -h
</code></pre> 
<pre><code class="language-bash">usage: fabric -h
Usage:
  fabric [OPTIONS]

Application Options:
  -p, --pattern=          Choose a pattern
  -C, --context=          Choose a context
      --session=          Choose a session
  -S, --setup             Run setup
  -t, --temperature=      Set temperature (default: 0.7)
  -T, --topp=             Set top P (default: 0.9)
  -s, --stream            Stream
  -P, --presencepenalty=  Set presence penalty (default: 0.0)
  -F, --frequencypenalty= Set frequency penalty (default: 0.0)
  -l, --listpatterns      List all patterns
  -L, --listmodels        List all available models
  -x, --listcontexts      List all contexts
  -X, --listsessions      List all sessions
  -U, --updatepatterns    Update patterns
  -c, --copy              Copy to clipboard
  -m, --model=            Choose model
  -u, --url=              Choose ollama url (default: http://127.0.0.1:11434)
  -o, --output=           Output to file
  -n, --latest=           Number of latest patterns to list (default: 0)

Help Options:
  -h, --help              Show this help message

</code></pre> 
<h2>Our approach to prompting</h2> 
<p>Fabric <em>Patterns</em> are different than most prompts you'll see.</p> 
<ul> 
 <li><strong>First, we use <code>Markdown</code> to help ensure maximum readability and editability</strong>. This not only helps the creator make a good one, but also anyone who wants to deeply understand what it does. <em>Importantly, this also includes the AI you're sending it to!</em></li> 
</ul> 
<p>Here's an example of a Fabric Pattern.</p> 
<pre><code class="language-bash">https://github.com/danielmiessler/fabric/blob/main/patterns/extract_wisdom/system.md
</code></pre> 
<img alt="pattern-example" src="https://github.com/danielmiessler/fabric/assets/50654/b910c551-9263-405f-9735-71ca69bbab6d" width="1461" /> 
<ul> 
 <li> <p><strong>Next, we are extremely clear in our instructions</strong>, and we use the Markdown structure to emphasize what we want the AI to do, and in what order.</p> </li> 
 <li> <p><strong>And finally, we tend to use the System section of the prompt almost exclusively</strong>. In over a year of being heads-down with this stuff, we've just seen more efficacy from doing that. If that changes, or we're shown data that says otherwise, we will adjust.</p> </li> 
</ul> 
<h2>Examples</h2> 
<p>Now let's look at some things you can do with Fabric.</p> 
<ol> 
 <li>Run the <code>summarize</code> Pattern based on input from <code>stdin</code>. In this case, the body of an article.</li> 
</ol> 
<pre><code class="language-bash">pbpaste | fabric --pattern summarize
</code></pre> 
<ol start="2"> 
 <li>Run the <code>analyze_claims</code> Pattern with the <code>--stream</code> option to get immediate and streaming results.</li> 
</ol> 
<pre><code class="language-bash">pbpaste | fabric --stream --pattern analyze_claims
</code></pre> 
<ol start="3"> 
 <li>Run the <code>extract_wisdom</code> Pattern with the <code>--stream</code> option to get immediate and streaming results from any Youtube video (much like in the original introduction video).</li> 
</ol> 
<pre><code class="language-bash">yt --transcript https://youtube.com/watch?v=uXs-zPc63kM | fabric --stream --pattern extract_wisdom
</code></pre> 
<ol start="4"> 
 <li>Create patterns- you must create a .md file with the pattern and save it to ~/.config/fabric/patterns/[yourpatternname].</li> 
</ol> 
<h2>Just use the Patterns</h2> 
<img alt="fabric-patterns-screenshot" src="https://github.com/danielmiessler/fabric/assets/50654/9186a044-652b-4673-89f7-71cf066f32d8" width="1173" /> 
<br /> 
<br /> 
<p>If you're not looking to do anything fancy, and you just want a lot of great prompts, you can navigate to the <a href="https://github.com/danielmiessler/fabric/tree/main/patterns"><code>/patterns</code></a> directory and start exploring!</p> 
<p>We hope that if you used nothing else from Fabric, the Patterns by themselves will make the project useful.</p> 
<p>You can use any of the Patterns you see there in any AI application that you have, whether that's ChatGPT or some other app or website. Our plan and prediction is that people will soon be sharing many more than those we've published, and they will be way better than ours.</p> 
<p>The wisdom of crowds for the win.</p> 
<h2>Custom Patterns</h2> 
<p>You may want to use Fabric to create your own custom Patterns—but not share them with others. No problem!</p> 
<p>Just make a directory in <code>~/.config/custompatterns/</code> (or wherever) and put your <code>.md</code> files in there.</p> 
<p>When you're ready to use them, copy them into:</p> 
<pre><code>~/.config/fabric/patterns/
</code></pre> 
<p>You can then use them like any other Patterns, but they won't be public unless you explicitly submit them as Pull Requests to the Fabric project. So don't worry—they're private to you.</p> 
<p>This feature works with all openai and ollama models but does NOT work with claude. You can specify your model with the -m flag</p> 
<h2>Helper Apps</h2> 
<p>Fabric also makes use of some core helper apps (tools) to make it easier to integrate with your various workflows. Here are some examples:</p> 
<p><code>yt</code> is a helper command that extracts the transcript from a YouTube video. You can use it like this:</p> 
<pre><code class="language-bash">yt https://www.youtube.com/watch?v=lQVcbY52_gY
</code></pre> 
<p>This will return the transcript from the video, which you can then pipe into Fabric like this:</p> 
<pre><code class="language-bash">yt https://www.youtube.com/watch?v=lQVcbY52_gY | fabric --pattern extract_wisdom
</code></pre> 
<h3><code>yt</code> Installation</h3> 
<p>To install <code>yt</code>, install it the same way as you install Fabric, just with a different repo name.</p> 
<pre><code class="language-bash">go install github.com/danielmiessler/yt@latest
</code></pre> 
<p>Be sure to add your <code>YOUTUBE_API_KEY</code> to <code>~/.config/fabric/.env</code>.</p> 
<h2>Meta</h2> 
<blockquote> 
 <p>[!NOTE] Special thanks to the following people for their inspiration and contributions!</p> 
</blockquote> 
<ul> 
 <li><em>Jonathan Dunn</em> for being the absolute MVP dev on the project, including spearheading the new Go version, as well as the GUI! All this while also being a full-time medical doctor!</li> 
 <li><em>Caleb Sima</em> for pushing me over the edge of whether to make this a public project or not.</li> 
 <li><em>Eugen Eisler</em> and <em>Frederick Ros</em> for their invaluable contributions to the Go version</li> 
 <li><em>Joel Parish</em> for super useful input on the project's Github directory structure..</li> 
 <li><em>Joseph Thacker</em> for the idea of a <code>-c</code> context flag that adds pre-created context in the <code>./config/fabric/</code> directory to all Pattern queries.</li> 
 <li><em>Jason Haddix</em> for the idea of a stitch (chained Pattern) to filter content using a local model before sending on to a cloud model, i.e., cleaning customer data using <code>llama2</code> before sending on to <code>gpt-4</code> for analysis.</li> 
 <li><em>Andre Guerra</em> for assisting with numerous components to make things simpler and more maintainable.</li> 
</ul> 
<h3>Primary contributors</h3> 
<p><a href="https://github.com/danielmiessler"><img height="50" src="https://avatars.githubusercontent.com/u/50654?v=4" title="Daniel Miessler" width="50" /></a> <a href="https://github.com/xssdoctor"><img height="50" src="https://avatars.githubusercontent.com/u/9218431?v=4" title="Jonathan Dunn" width="50" /></a> <a href="https://github.com/sbehrens"><img height="50" src="https://avatars.githubusercontent.com/u/688589?v=4" title="Scott Behrens" width="50" /></a> <a href="https://github.com/agu3rra"><img height="50" src="https://avatars.githubusercontent.com/u/10410523?v=4" title="Andre Guerra" width="50" /></a></p> 
<p><code>fabric</code> was created by <a href="https://danielmiessler.com/subscribe" target="_blank">Daniel Miessler</a> in January of 2024. <br /><br /> <a href="https://twitter.com/intent/user?screen_name=danielmiessler"><img alt="X (formerly Twitter) Follow" src="https://img.shields.io/twitter/follow/danielmiessler" /></a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>princeton-nlp/SWE-agent</title>
<link>https://github.com/princeton-nlp/SWE-agent</link>
<guid>https://github.com/princeton-nlp/SWE-agent</guid>
<content:encoded><![CDATA[
<div> 关键词：SWE-agent、GitHub、自动修复、GPT-4、软件工程代理

总结:

本文介绍了一种名为SWE-agent的工具，它旨在利用大型语言模型（如GPT-4）来解决实际GitHub仓库中的软件工程问题。SWE-agent通过设计简单的命令和反馈格式，即所谓的Agent-Computer Interface (ACI)，使语言模型更容易浏览代码仓库、查看、编辑和执行代码文件。该工具在SWE-bench评估集上实现了12.47%的问题解决率，这是当前的领先性能。SWE-agent由普林斯顿大学的研究人员构建和维护。

用户可以通过Web界面或命令行使用SWE-agent。要开始使用，请访问指定链接。详细信息和未来功能更新可通过加入特定社区获取。如果希望参与代码贡献，欢迎提出问题、学习新功能并参与开发过程。项目遵循MIT许可证，感兴趣的开发者可以访问LICENSE文件获取更多信息。如果此工作对您有帮助，请考虑引用以下文献：

@misc{yang2024sweagent,
      title={SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering},
      author={John Yang and Carlos E. Jimenez and Alexander Wettig and Kilian Lieret and Shunyu Yao and Karthik Narasimhan and Ofir Press},
      year={2024},
      eprint={2405.15793},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
} <div>
<p>SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4, or your LM of choice. It solves 12.47% of bugs in the SWE-bench evaluation set and takes just 1 minute to run.</p><hr /><p align="center"> <a href="https://www.swe-agent.com/"> <img alt="swe-agent.com" src="https://raw.githubusercontent.com/princeton-nlp/SWE-agent/main/assets/swe-agent-banner.png" /> </a> </p> 
<p align="center"> <a href="https://swe-agent.com"><strong>Website &amp; Demo</strong></a>&nbsp; | &nbsp; <a href="https://princeton-nlp.github.io/SWE-agent/"><strong>Documentation</strong></a>&nbsp; | &nbsp; <a href="https://discord.gg/AVEFbBn2rH"><strong>Discord</strong></a>&nbsp; | &nbsp; <a href="https://arxiv.org/abs/2405.15793"><strong>Preprint</strong></a> </p> 
<p><strong>SWE-agent turns LMs (e.g. GPT-4) into software engineering agents that can resolve issues in real GitHub repositories.</strong></p> 
<p>On <a href="https://github.com/princeton-nlp/SWE-bench">SWE-bench</a>, SWE-agent resolves 12.47% of issues, achieving the state-of-the-art performance on the full test set.</p> 
<p>We accomplish our results by designing simple LM-centric commands and feedback formats to make it easier for the LM to browse the repository, view, edit and execute code files. We call this an <strong>Agent-Computer Interface (ACI)</strong>. Read more about it in our <a href="https://arxiv.org/abs/2405.15793">paper</a>!</p> 
<p>SWE-agent is built and maintained by researchers from Princeton University.</p> 
<p><img alt="My Movie 3" src="https://github.com/princeton-nlp/SWE-agent/assets/13602468/fa201621-ec31-4644-b658-c1d0feb92253" /></p> 
<p>You can use SWE-agent either through a web interface (shown above) or through the command line.</p> 
<h2>🚀 Get started!</h2> 
<p>👉 Try SWE-agent in your browser: <a href="https://codespaces.new/princeton-nlp/SWE-agent"><img alt="Open in GitHub Codespaces" src="https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github" /></a> (<a href="https://princeton-nlp.github.io/SWE-agent/installation/codespaces/">more information</a>)</p> 
<p>Read our <a href="https://princeton-nlp.github.io/SWE-agent/">documentation</a> to learn more:</p> 
<ul> 
 <li><a href="https://princeton-nlp.github.io/SWE-agent/installation/">Installation</a></li> 
 <li><a href="https://princeton-nlp.github.io/SWE-agent/usage/cl_tutorial/">Command line usage</a></li> 
 <li><a href="https://princeton-nlp.github.io/SWE-agent/usage/web_ui/">Using the web UI</a></li> 
 <li><a href="https://princeton-nlp.github.io/SWE-agent/usage/benchmarking/">Benchmarking on SWE-bench</a></li> 
 <li><a href="https://princeton-nlp.github.io/SWE-agent/faq/">Frequently Asked Questions</a></li> 
</ul> 
<div align="center"> 
 <a href="https://princeton-nlp.github.io/SWE-agent/"><img src="https://raw.githubusercontent.com/princeton-nlp/SWE-agent/main/assets/doc-scrot.png" style="width: 600px;" /></a> 
</div> 
<h2>💫 Contributions <a name="contributions"></a></h2> 
<ul> 
 <li>If you'd like to ask questions, learn about upcoming features, and participate in future development, join our <a href="https://discord.gg/AVEFbBn2rH">Discord community</a>!</li> 
 <li>If you'd like to contribute to the codebase, we welcome <a href="https://github.com/princeton-nlp/SWE-agent/issues">issues</a> and <a href="https://github.com/princeton-nlp/SWE-agent/pulls">pull requests</a>!</li> 
</ul> 
<p>Contact person: <a href="https://john-b-yang.github.io/">John Yang</a> and <a href="http://www.carlosejimenez.com/">Carlos E. Jimenez</a> (Email: <a href="mailto:johnby@stanford.edu">johnby@stanford.edu</a>, <a href="mailto:carlosej@princeton.edu">carlosej@princeton.edu</a>).</p> 
<h2>📝 Citation <a name="citation"></a></h2> 
<p>If you found this work helpful, please consider citing it using the following:</p> 
<pre><code>@misc{yang2024sweagent,
      title={SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering},
      author={John Yang and Carlos E. Jimenez and Alexander Wettig and Kilian Lieret and Shunyu Yao and Karthik Narasimhan and Ofir Press},
      year={2024},
      eprint={2405.15793},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}
</code></pre> 
<h2>🪪 License <a name="license"></a></h2> 
<p>MIT. Check <code>LICENSE</code>.</p> 
<div align="center"> 
 <p><a href="https://github.com/princeton-nlp/SWE-agent/actions/workflows/pytest.yaml"><img alt="Pytest" src="https://github.com/princeton-nlp/SWE-agent/actions/workflows/pytest.yaml/badge.svg?sanitize=true" /></a> <a href="https://github.com/princeton-nlp/SWE-agent/actions/workflows/test_build_containers.yaml"><img alt="Test build containers" src="https://github.com/princeton-nlp/SWE-agent/actions/workflows/test_build_containers.yaml/badge.svg?sanitize=true" /></a> <a href="https://github.com/princeton-nlp/SWE-agent/actions/workflows/release-dockerhub-nightly.yaml"><img alt="Release to dockerhub (nightly)" src="https://github.com/princeton-nlp/SWE-agent/actions/workflows/release-dockerhub-nightly.yaml/badge.svg?sanitize=true" /></a> <a href="https://github.com/princeton-nlp/SWE-agent/actions/workflows/release-dockerhub-release.yaml"><img alt="Release to dockerhub (release)" src="https://github.com/princeton-nlp/SWE-agent/actions/workflows/release-dockerhub-release.yaml/badge.svg?sanitize=true" /></a> <a href="https://github.com/princeton-nlp/SWE-agent/actions/workflows/build-docs.yaml"><img alt="build-docs" src="https://github.com/princeton-nlp/SWE-agent/actions/workflows/build-docs.yaml/badge.svg?sanitize=true" /></a> <a href="https://codecov.io/gh/princeton-nlp/SWE-agent"><img alt="codecov" src="https://codecov.io/gh/princeton-nlp/SWE-agent/graph/badge.svg?token=18XAVDK365" /></a> <a href="https://results.pre-commit.ci/latest/github/princeton-nlp/SWE-agent/main"><img alt="pre-commit.ci status" src="https://results.pre-commit.ci/badge/github/princeton-nlp/SWE-agent/main.svg?sanitize=true" /></a> <a href="https://github.com/princeton-nlp/SWE-agent/actions/workflows/check-links.yaml"><img alt="Markdown links" src="https://github.com/princeton-nlp/SWE-agent/actions/workflows/check-links.yaml/badge.svg?sanitize=true" /></a></p> 
</div>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>nikitabobko/AeroSpace</title>
<link>https://github.com/nikitabobko/AeroSpace</link>
<guid>https://github.com/nikitabobko/AeroSpace</guid>
<content:encoded><![CDATA[
<div> 关键词：AeroSpace、macOS、i3、tiling window manager、System Integrity Protection（SIP）

总结:

AeroSpace是一款基于i3设计理念的macOS窗口管理器，它为用户提供了一个快速、无动画的工作空间切换体验，无需禁用SIP。这款软件支持全文本配置，便于与dotfiles集成，并提供了命令行优先接口，包括man页面和shell完成功能。用户可以通过Homebrew进行安装，以获取自动更新。AeroSpace旨在为高级用户和开发者提供服务，强调键盘为中心的操作方式，并尽量避免引入破坏性更改，除非在重大版本中明确需要进行。

AeroSpace不依赖macOS的Spaces功能，而是采用了自己的实现方式。它允许用户在多显示器设置下进行配置，并提供了bash、fish和zsh的完成支持。用户需要注意确保显示器正确配置，以获得最佳体验。此外，AeroSpace提供了自动删除com.apple.quarantine属性的功能，确保应用可以无缝运行。

为了参与项目的发展，用户可以查看贡献指南、提出问题或提交拉取请求。项目的核心价值观包括面向高级用户和开发者、键盘驱动的操作方式以及最小化破坏性更改的策略。AeroSpace避免使用GUI界面进行配置，并提供系统菜单图标作为反馈机制。它专注于实用功能，避免不必要的复杂性和外观调整。

在不违反Apple安全政策的前提下，AeroSpace提供了一种替代方案，让macOS用户能够享受类似于i3的窗口管理体验。通过遵循上述关键点，用户可以更好地理解AeroSpace的特性和使用方法。 <div>
<p>AeroSpace is an i3-like tiling window manager for macOS</p><hr /><img align="right" height="40%" src="https://raw.githubusercontent.com/nikitabobko/AeroSpace/main/resources/Assets.xcassets/AppIcon.appiconset/icon.png" width="40%" /> 
<h1>AeroSpace Beta <a href="https://github.com/nikitabobko/AeroSpace/actions/workflows/build.yml"><img alt="Build" src="https://github.com/nikitabobko/AeroSpace/actions/workflows/build.yml/badge.svg?branch=main" /></a></h1> 
<p>AeroSpace is an i3-like tiling window manager for macOS</p> 
<p>Videos:</p> 
<ul> 
 <li><a href="https://www.youtube.com/watch?v=UOl7ErqWbrk">YouTube 91 sec Demo</a></li> 
 <li><a href="https://www.youtube.com/watch?v=-FoWClVHG5g">YouTube Guide by Josean Martinez</a></li> 
</ul> 
<p>Docs:</p> 
<ul> 
 <li><a href="https://nikitabobko.github.io/AeroSpace/guide">AeroSpace Guide</a></li> 
 <li><a href="https://nikitabobko.github.io/AeroSpace/commands">AeroSpace Commands</a></li> 
 <li><a href="https://nikitabobko.github.io/AeroSpace/goodness">AeroSpace Goodness</a></li> 
</ul> 
<h2>Project status</h2> 
<p>Public Beta. AeroSpace can be used as a daily driver, but expect breaking changes until 1.0 is reached.</p> 
<h2>Key features</h2> 
<ul> 
 <li>Tiling window manager based on a <a href="https://nikitabobko.github.io/AeroSpace/guide#tree">tree paradigm</a></li> 
 <li><a href="https://i3wm.org/">i3</a> inspired</li> 
 <li>Fast workspaces switching without animations and without the necessity to disable SIP</li> 
 <li>AeroSpace employs its <a href="https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces">own emulation of virtual workspaces</a> instead of relying on native macOS Spaces due to <a href="https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces">their considerable limitations</a></li> 
 <li>Plain text configuration (dotfiles friendly). See: <a href="https://nikitabobko.github.io/AeroSpace/guide#default-config">default-config.toml</a></li> 
 <li>CLI first (manpages and shell completion included)</li> 
 <li>Doesn't require disabling SIP (System Integrity Protection)</li> 
 <li><a href="https://nikitabobko.github.io/AeroSpace/guide#multiple-monitors">Proper multi-monitor support</a> (i3-like paradigm)</li> 
</ul> 
<h2>Installation</h2> 
<p>Install via <a href="https://brew.sh/">Homebrew</a> to get autoupdates (Preferred)</p> 
<pre><code>brew install --cask nikitabobko/tap/aerospace
</code></pre> 
<p><strong>(Optional)</strong> You might need to configure your shell to enable completion provided by homebrew packages: <a href="https://docs.brew.sh/Shell-Completion">https://docs.brew.sh/Shell-Completion</a> AeroSpace provides bash, fish and zsh completions.</p> 
<p>In multi-monitor setup please make sure that monitors <a href="https://nikitabobko.github.io/AeroSpace/guide#proper-monitor-arrangement">are properly arranged</a>.</p> 
<p>You can also install specific previous versions:</p> 
<pre><code>brew install --cask nikitabobko/tap/aerospace@0.12.0
</code></pre> 
<p>For the list of all the versions available for installation via brew see: <a href="https://github.com/nikitabobko/homebrew-tap/tree/main/Casks">https://github.com/nikitabobko/homebrew-tap/tree/main/Casks</a></p> 
<p><a href="https://nikitabobko.github.io/AeroSpace/guide#manual-installation">Manual installation</a></p> 
<blockquote> 
 <p>[!NOTE] By using AeroSpace, you acknowledge that it's not <a href="https://developer.apple.com/documentation/security/notarizing_macos_software_before_distribution">notarized</a>.</p> 
 <p>Notarization is a "security" feature by Apple. You send binaries to Apple, and they either approve the binaries or not. In reality, notarization is about building binaries the way Apple likes it.</p> 
 <p>Let's be honest. Tiling window manager is not something Apple will be totally ok with. Even if they approve one version, it doesn't mean that they won't revoke it (yes, they can do it), or approve further versions.</p> 
 <p>I don't have anything against notarization as a concept. I specifically don't like the way Apple does notarization. I don't have time to fight Apple.</p> 
 <p><a href="https://github.com/nikitabobko/homebrew-tap/raw/main/Casks/aerospace.rb">Homebrew installation script</a> is configured to automatically delete <code>com.apple.quarantine</code> attribute, that's why the app should work out of the box, without any warnings that "Apple cannot check AeroSpace for malicious software"</p> 
</blockquote> 
<h2>Contributing, creating issues, submitting pull requests</h2> 
<p>See: <a href="https://raw.githubusercontent.com/nikitabobko/AeroSpace/main/CONTRIBUTING.md">CONTRIBUTING.md</a></p> 
<h2>Development</h2> 
<p>A notes on how to setup the project, build it, how to run the tests, etc. can be found here: <a href="https://raw.githubusercontent.com/nikitabobko/AeroSpace/main/dev-docs/development.md">dev-docs/development.md</a></p> 
<h2>Values of the project</h2> 
<p><strong>Values</strong></p> 
<ul> 
 <li>AeroSpace is targeted at advanced users and developers</li> 
 <li>Keyboard centric</li> 
 <li>Breaking changes (configuration files, CLI, behavior) are avoided as much as possible, but it must not let the software stagnate. Thus breaking changes can happen, but with careful considerations and helpful message. <a href="https://semver.org/">Semver</a> major version is bumped in case of a breaking change (It's all guaranteed once AeroSpace reaches 1.0 version, until then breaking changes just happen)</li> 
 <li>AeroSpace doesn't use GUI, unless necessarily 
  <ul> 
   <li>AeroSpace will never provide a GUI for configuration. For advanced users, it's easier to edit a configuration file in text editor rather than navigating through checkboxes in GUI.</li> 
   <li>Status menu icon is ok, because visual feedback is needed</li> 
  </ul> </li> 
 <li>Provide <em>practical</em> features. Fancy appearance features are not <em>practical</em> (e.g. window borders, transparency, etc)</li> 
 <li>If "dark magic" (aka "private APIs", "code injections", etc) can be avoided, it must be avoided 
  <ul> 
   <li>Right now, AeroSpace uses only a single private API to get window ID of accessibility object <code>_AXUIElementGetWindow</code>. Everything else is <a href="https://developer.apple.com/documentation/applicationservices/axuielement_h">macOS public accessibility API</a>.</li> 
   <li>AeroSpace will never require you to disable SIP (System Integrity Protection). For example, yabai <a href="https://github.com/koekeishiya/yabai/issues/1863">requires you to disable SIP</a> to use some of its features. AeroSpace will either find another way (such as <a href="https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces">emulation of workspaces</a>) or will not implement this feature at all (window transparency and window shadowing are not <em>practical</em> features)</li> 
  </ul> </li> 
</ul> 
<p><strong>Non Values</strong></p> 
<ul> 
 <li>Play nicely with existing macOS features. If limitations are imposed then AeroSpace won't play nicely with existing macOS features 
  <ul> 
   <li>E.g. AeroSpace doesn't acknowledge the existence of macOS Spaces, and it uses <a href="https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces">emulation of its own workspaces</a></li> 
  </ul> </li> 
</ul> 
<h2>Tip of the day</h2> 
<pre><code class="language-bash">defaults write -g NSWindowShouldDragOnGesture -bool true
</code></pre> 
<p>Now, you can move windows by holding <code>ctrl</code>+<code>cmd</code> and dragging any part of the window (not necessarily the window title)</p> 
<p>Source: <a href="https://www.reddit.com/r/MacOS/comments/k6hiwk/keyboard_modifier_to_simplify_click_drag_of/">reddit</a></p> 
<h2>Related projects</h2> 
<ul> 
 <li><a href="https://github.com/ianyh/Amethyst">Amethyst</a></li> 
 <li><a href="https://github.com/koekeishiya/yabai">yabai</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>hcengineering/platform</title>
<link>https://github.com/hcengineering/platform</link>
<guid>https://github.com/hcengineering/platform</guid>
<content:encoded><![CDATA[
<div> 关键词：Huly Platform、自托管、预安装脚本、Docker、Rush工具

总结:

Huly Platform 是一个全面的企业应用开发框架，旨在加速构建CRM系统等商业应用。该平台包含多个应用程序，如聊天、项目管理、CRM、HRM和ATS，并支持多个团队在其基础上开发产品。

对于希望自托管 Huly 而不打算修改或贡献到其发展的用户，推荐使用 "自托管" 版本，该版本提供了一个方便的 Docker 安装方法，旨在快速部署并易于使用。

为了确保安装正确，用户需要完成一系列验证步骤，包括检查 Docker 的可用性、运行特定脚本来启动环境，并根据文档中的说明执行安装和配置命令。

为了简化开发环境的设置，Rush 工具被引入作为全球安装选项，用于管理项目依赖关系和构建过程。通过使用 Rush，用户可以轻松地安装项目所需的所有依赖项、构建项目并验证源代码。

此外，为了支持自托管环境，Huly 提供了预安装脚本，允许用户快速执行关键操作，如创建工作空间、创建账户、配置环境和分配权限。这些脚本简化了整个流程，使得部署和管理变得高效且直观。

最后，Huly 平台支持多种集成，尽管本地安装可能无法实现所有功能，但关键集成如电子邮件发送、第三方内容源集成以及与 Telegram、Gmail 等服务的集成仍然可以使用。同时，平台还提供了开发模式以优化开发体验，并提供了测试策略来确保代码质量和功能完整性。

总之，Huly Platform 通过提供自托管选项、预安装脚本、强大的开发工具（如 Rush）和广泛的集成支持，为开发者提供了一站式解决方案，旨在简化企业应用的开发、部署和维护过程。 <div>
<p>Huly — All-in-One Project Management Platform (alternative to Linear, Jira, Slack, Notion, Motion)</p><hr /><h1>Huly Platform</h1> 
<p><a href="https://x.com/huly_io"><img alt="X (formerly Twitter) Follow" src="https://img.shields.io/twitter/follow/huly_io?style=for-the-badge" /></a> <img alt="GitHub License" src="https://img.shields.io/github/license/hcengineering/platform?style=for-the-badge" /></p> 
<p>⭐️ Your star shines on us. Star us on GitHub!</p> 
<h2>About</h2> 
<p>The Huly Platform is a robust framework designed to accelerate the development of business applications, such as CRM systems. This repository includes several applications, such as Chat, Project Management, CRM, HRM, and ATS. Various teams are building products on top of the Platform, including <a href="https://huly.io">Huly</a> and <a href="https://tracex.co">TraceX</a>.</p> 
<p><img alt="Huly" src="https://repository-images.githubusercontent.com/392073243/6d27d5cc-38cd-4d88-affe-bb88b393180c" /></p> 
<h2>Self-Hosting</h2> 
<p>If you're primarily interested in self-hosting Huly without the intention to modify or contribute to its development, please use <a href="https://github.com/hcengineering/huly-selfhost">huly-selfhost</a>. This project offers a convenient method to host Huly using <code>docker</code>, designed for ease of use and quick setup. Explore this option to effortlessly enjoy Huly on your own server.</p> 
<h2>Activity</h2> 
<p><img alt="Alt" src="https://repobeats.axiom.co/api/embed/c42c99e21691fa60ea61b5cdf11c2e0647621534.svg?sanitize=true" title="Repobeats analytics image" /></p> 
<h2>Table of Content</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#huly-platform">Huly Platform</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#about">About</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#self-hosting">Self-Hosting</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#activity">Activity</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#table-of-content">Table of Content</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#pre-requisites">Pre-requisites</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#verification">Verification</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#installation">Installation</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#build-and-run">Build and run</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#run-in-development-mode">Run in development mode</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#update-project-structure-and-database">Update project structure and database</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#troubleshooting">Troubleshooting</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#build--watch">Build &amp; Watch</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#tests">Tests</a> 
    <ul> 
     <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#unit-tests">Unit tests</a></li> 
     <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#ui-tests">UI tests</a></li> 
    </ul> </li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#package-publishing">Package publishing</a></li> 
   <li><a href="https://raw.githubusercontent.com/hcengineering/platform/develop/#additional-testing">Additional testing</a></li> 
  </ul> </li> 
</ul> 
<h2>Pre-requisites</h2> 
<ul> 
 <li>Before proceeding, ensure that your system meets the following requirements: 
  <ul> 
   <li><a href="https://nodejs.org/en/download/">Node.js</a> (v20.11.0 is required)</li> 
   <li><a href="https://docs.docker.com/get-docker/">Docker</a></li> 
   <li><a href="https://docs.docker.com/compose/install/">Docker Compose</a></li> 
  </ul> </li> 
</ul> 
<h2>Verification</h2> 
<p>To verify the installation, perform the following checks in your terminal:</p> 
<ul> 
 <li>Ensure that the <code>docker</code> commands are available: <pre><code class="language-bash">docker --version
docker compose version
</code></pre> </li> 
</ul> 
<h2>Fast start</h2> 
<pre><code class="language-bash">sh ./scripts/fast-start.sh
</code></pre> 
<h2>Installation</h2> 
<p>You need Microsoft's <a href="https://rushjs.io">rush</a> to install application.</p> 
<ol> 
 <li>Install Rush globally using the command: <pre><code class="language-bash">npm install -g @microsoft/rush
</code></pre> </li> 
 <li>Navigate to the repository root and run the following commands: <pre><code class="language-bash">rush install
rush build
</code></pre> </li> 
</ol> 
<p>Alternatively, you can just execute:</p> 
<pre><code class="language-bash">sh ./scripts/presetup-rush.sh
</code></pre> 
<h2>Build and run</h2> 
<p>Development environment setup requires Docker to be installed on system.</p> 
<p>Support is available for both amd64 and arm64 containers on Linux and macOS.</p> 
<pre><code class="language-bash">cd ./dev/
rush build    # Will build all the required packages. 
# rush rebuild  # could be used to omit build cache.
rush bundle   # Will prepare bundles.
rush package  # Will build all webpack packages.
rush validate # Will validate all sources with typescript and generate d.ts files required for ts-node execution.
rush svelte-check # Optional. svelte files validation using svelte-check.
rush docker:build   # Will build Docker containers for all applications in the local Docker environment.
rush docker:up # Will set up all the containers
</code></pre> 
<p>Be aware <code>rush docker:build</code> will automatically execute all required phases like build, bundle, package.</p> 
<p>Alternatively, you can just execute:</p> 
<pre><code class="language-bash">sh ./scripts/build.sh
</code></pre> 
<p>By default, Docker volumes named dev_db, dev_elastic, and dev_files will be created for the MongoDB, Elasticsearch, and MinIO instances.</p> 
<p>Before you can begin, you need to create a workspace and an account and associate it with the workspace.</p> 
<pre><code class="language-bash">cd ./tool # dev/tool in the repository root
rushx run-local create-workspace ws1 -w DevWorkspace # Create workspace
rushx run-local create-account user1 -p 1234 -f John -l Appleseed # Create account
rushx run-local configure ws1 --list --enable '*' # Enable all modules, even if they are not yet intended to be used by a wide audience.
rushx run-local assign-workspace user1 ws1 # Assign workspace to user.
rushx run-local confirm-email user1 # To allow the creation of additional test workspaces.

</code></pre> 
<p>Alternatively, you can just execute:</p> 
<pre><code class="language-bash">sh ./scripts/create-workspace.sh
</code></pre> 
<p>Accessing the URL <a href="http://localhost:8087">http://localhost:8087</a> will lead you to the app in production mode.</p> 
<p>Limitations:</p> 
<ul> 
 <li>Local installation does not support sending emails, thus disabling functionalities such as password recovery and email notifications.</li> 
 <li>Integrations with Telegram, Gmail, and other content sources are exclusively available as Docker containers, sourced from private repositories. However, these integrations are fully functional and can be utilized with the platform.</li> 
</ul> 
<h2>Run in development mode</h2> 
<p>Development mode allows for live reloading and a smoother development process.</p> 
<pre><code class="language-bash">cd dev/prod
rushx dev-server
</code></pre> 
<p>Then go to <a href="http://localhost:8080">http://localhost:8080</a></p> 
<p>Use the following login credentials:</p> 
<pre><code class="language-plain">Email: user1
Password: 1234
Workspace: ws1
</code></pre> 
<h2>Update project structure and database</h2> 
<p>If the project's structure is updated, it may be necessary to relink and rebuild the projects.</p> 
<pre><code class="language-bash">rush update
rush build
</code></pre> 
<p>It may also be necessary to upgrade the running database.</p> 
<pre><code class="language-bash">cd ./dev/tool
rushx upgrade -f
</code></pre> 
<h2>Troubleshooting</h2> 
<p>If a build fails, but the code is correct, try to delete the <a href="https://rushjs.io/pages/maintainer/build_cache/">build cache</a> and retry.</p> 
<pre><code class="language-bash"># from the project root
rm -rf common/temp/build-cache
</code></pre> 
<h2>Build &amp; Watch</h2> 
<p>For development purpose <code>rush build:watch</code> action could be used.</p> 
<p>It includes build and validate phases in watch mode.</p> 
<h2>Tests</h2> 
<h3>Unit tests</h3> 
<pre><code class="language-bash">rush test # To execute all tests

rushx test # For individual test execution inside a package directory
</code></pre> 
<h3>UI tests</h3> 
<pre><code class="language-bash">cd ./tests
rush build
rush bundle
rush docker:build
## creates test Docker containers and sets up test database
./prepare.sh
## runs UI tests
rushx uitest
</code></pre> 
<p>To execute tests in the development environment, please follow these steps:</p> 
<pre><code class="language-bash">cd ./tests
./create-local.sh ## use ./restore-local.sh if you only want to restore the workspace to a predefined initial state for sanity.
cd ./sanity
rushx dev-uitest # To execute all tests against the development environment.
rushx dev-debug -g 'pattern' # To execute tests in debug mode with only the matching test pattern.
</code></pre> 
<h2>Package publishing</h2> 
<pre><code class="language-bash">node ./common/scripts/bump.js -p projectName
</code></pre> 
<h2>Additional testing</h2> 
<p>This project is tested with BrowserStack.</p> 
<p><sub><sup>© 2024 <a href="https://hardcoreeng.com">Hardcore Engineering Inc</a>.</sup></sub></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>rustdesk/rustdesk</title>
<link>https://github.com/rustdesk/rustdesk</link>
<guid>https://github.com/rustdesk/rustdesk</guid>
<content:encoded><![CDATA[
<div> 关键词：RustDesk、远程桌面、自托管、开源、安全

总结:

RustDesk是一款基于Rust语言编写的远程桌面应用，旨在为用户提供无需配置即可使用的便捷体验。它强调数据安全与自主控制权，用户可以选择使用RustDesk提供的中继/转接服务器，或自行部署。RustDesk欢迎所有人的贡献，提供了详细的开始指南。

为了构建RustDesk，开发者需要准备Rust和C++的开发环境，并安装依赖库如libvpx、libyuv、opus、aom等。构建过程涉及设置环境变量、安装依赖和运行特定命令来编译程序。对于Linux用户，提供了不同发行版的安装指导。构建RustDesk还可以通过Docker容器简化流程，这允许在任何地方快速构建应用。

RustDesk的代码结构复杂，包含多个模块，如视频编码、文件传输、音频服务等，以支持全面的远程桌面功能。此外，RustDesk还支持多平台，包括Windows、Linux、macOS等操作系统，并提供Flutter版本的客户端。其构建过程包含了详细的步骤说明，以确保开发者能够顺利进行本地构建。

RustDesk由欧盟免费服务器支持，该服务器由Codext GmbH慷慨提供，确保了稳定性和可靠性，为用户提供了一个可靠的选择。 <div>
<p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p><hr /><p align="center"> <img alt="RustDesk - Your remote desktop" src="https://raw.githubusercontent.com/rustdesk/rustdesk/master/res/logo-header.svg?sanitize=true" /><br /> <a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#public-servers">Servers</a> • <a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#raw-steps-to-build">Build</a> • <a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#how-to-build-with-docker">Docker</a> • <a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#file-structure">Structure</a> • <a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#snapshot">Snapshot</a><br /> [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-UA.md">Українська</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-CS.md">česky</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ZH.md">中文</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-HU.md">Magyar</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ES.md">Español</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FA.md">فارسی</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FR.md">Français</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DE.md">Deutsch</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PL.md">Polski</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ID.md">Indonesian</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FI.md">Suomi</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ML.md">മലയാളം</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-JP.md">日本語</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NL.md">Nederlands</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-IT.md">Italiano</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RU.md">Русский</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PTBR.md">Português (Brasil)</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-EO.md">Esperanto</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-KR.md">한국어</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-AR.md">العربي</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-VN.md">Tiếng Việt</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DA.md">Dansk</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-GR.md">Ελληνικά</a>] | [<a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-TR.md">Türkçe</a>]<br /> <b>We need your help to translate this README, <a href="https://github.com/rustdesk/rustdesk/tree/master/src/lang">RustDesk UI</a> and <a href="https://github.com/rustdesk/doc.rustdesk.com">RustDesk Doc</a> to your native language</b> </p> 
<p>Chat with us: <a href="https://discord.gg/nDceKgxnkV">Discord</a> | <a href="https://twitter.com/rustdesk">Twitter</a> | <a href="https://www.reddit.com/r/rustdesk">Reddit</a></p> 
<p><a href="https://ko-fi.com/I2I04VU09"><img alt="ko-fi" src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" /></a></p> 
<p>Yet another remote desktop software, written in Rust. Works out of the box, no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, <a href="https://rustdesk.com/server">set up your own</a>, or <a href="https://github.com/rustdesk/rustdesk-server-demo">write your own rendezvous/relay server</a>.</p> 
<p><img alt="image" src="https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png" /></p> 
<p>RustDesk welcomes contribution from everyone. See <a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/CONTRIBUTING.md">CONTRIBUTING.md</a> for help getting started.</p> 
<p><a href="https://github.com/rustdesk/rustdesk/wiki/FAQ"><strong>FAQ</strong></a></p> 
<p><a href="https://github.com/rustdesk/rustdesk/releases"><strong>BINARY DOWNLOAD</strong></a></p> 
<p><a href="https://github.com/rustdesk/rustdesk/releases/tag/nightly"><strong>NIGHTLY BUILD</strong></a></p> 
<p><a href="https://f-droid.org/en/packages/com.carriez.flutter_hbb"><img alt="Get it on F-Droid" height="80" src="https://fdroid.gitlab.io/artwork/badge/get-it-on.png" /></a></p> 
<h2>Dependencies</h2> 
<p>Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our <a href="https://github.com/rustdesk/rustdesk/raw/master/.github/workflows/flutter-build.yml">CI</a> for building Flutter version.</p> 
<p>Please download Sciter dynamic library yourself.</p> 
<p><a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll">Windows</a> | <a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so">Linux</a> | <a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib">macOS</a></p> 
<h2>Raw steps to build</h2> 
<ul> 
 <li> <p>Prepare your Rust development env and C++ build env</p> </li> 
 <li> <p>Install <a href="https://github.com/microsoft/vcpkg">vcpkg</a>, and set <code>VCPKG_ROOT</code> env variable correctly</p> 
  <ul> 
   <li>Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static</li> 
   <li>Linux/macOS: vcpkg install libvpx libyuv opus aom</li> 
  </ul> </li> 
 <li> <p>run <code>cargo run</code></p> </li> 
</ul> 
<h2><a href="https://rustdesk.com/docs/en/dev/build/">Build</a></h2> 
<h2>How to build on Linux</h2> 
<h3>Ubuntu 18 (Debian 10)</h3> 
<pre><code class="language-sh">sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
</code></pre> 
<h3>openSUSE Tumbleweed</h3> 
<pre><code class="language-sh">sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
</code></pre> 
<h3>Fedora 28 (CentOS 8)</h3> 
<pre><code class="language-sh">sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
</code></pre> 
<h3>Arch (Manjaro)</h3> 
<pre><code class="language-sh">sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
</code></pre> 
<h3>Install vcpkg</h3> 
<pre><code class="language-sh">git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
</code></pre> 
<h3>Fix libvpx (For Fedora)</h3> 
<pre><code class="language-sh">cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile
sed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
</code></pre> 
<h3>Build</h3> 
<pre><code class="language-sh">curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
</code></pre> 
<h2>How to build with Docker</h2> 
<p>Begin by cloning the repository and building the Docker container:</p> 
<pre><code class="language-sh">git clone https://github.com/rustdesk/rustdesk
cd rustdesk
docker build -t "rustdesk-builder" .
</code></pre> 
<p>Then, each time you need to build the application, run the following command:</p> 
<pre><code class="language-sh">docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID="$(id -u)" -e PGID="$(id -g)" rustdesk-builder
</code></pre> 
<p>Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the <code>&lt;OPTIONAL-ARGS&gt;</code> position. For instance, if you wanted to build an optimized release version, you would run the command above followed by <code>--release</code>. The resulting executable will be available in the target folder on your system, and can be run with:</p> 
<pre><code class="language-sh">target/debug/rustdesk
</code></pre> 
<p>Or, if you're running a release executable:</p> 
<pre><code class="language-sh">target/release/rustdesk
</code></pre> 
<p>Please ensure that you are running these commands from the root of the RustDesk repository, otherwise the application might not be able to find the required resources. Also note that other cargo subcommands such as <code>install</code> or <code>run</code> are not currently supported via this method as they would install or run the program inside the container instead of the host.</p> 
<h2>File Structure</h2> 
<ul> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common">libs/hbb_common</a></strong>: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/libs/scrap">libs/scrap</a></strong>: screen capture</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/libs/enigo">libs/enigo</a></strong>: platform specific keyboard/mouse control</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard">libs/clipboard</a></strong>: file copy and paste implementation for Windows, Linux, macOS.</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/src/ui">src/ui</a></strong>: obsolete Sciter UI (deprecated)</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/src/server">src/server</a></strong>: audio/clipboard/input/video services, and network connections</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/src/client.rs">src/client.rs</a></strong>: start a peer connection</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs">src/rendezvous_mediator.rs</a></strong>: Communicate with <a href="https://github.com/rustdesk/rustdesk-server">rustdesk-server</a>, wait for remote direct (TCP hole punching) or relayed connection</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/src/platform">src/platform</a></strong>: platform specific code</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/flutter">flutter</a></strong>: Flutter code for desktop and mobile</li> 
 <li><strong><a href="https://github.com/rustdesk/rustdesk/tree/master/flutter/web/js">flutter/web/js</a></strong>: JavaScript for Flutter web client</li> 
</ul> 
<h2>Screenshots</h2> 
<p><img alt="Connection Manager" src="https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651" /></p> 
<p><img alt="Connected to a Windows PC" src="https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea" /></p> 
<p><img alt="File Transfer" src="https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad" /></p> 
<p><img alt="TCP Tunneling" src="https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5" /></p> 
<h2><a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#public-servers">Public Servers</a></h2> 
<p>RustDesk is supported by a free EU server, graciously provided by Codext GmbH</p> 
<p align="center"> <a href="https://codext.link/rustdesk?utm_source=github"> <img alt="Codext GmbH" src="https://camo.githubusercontent.com/aaf1c033d7b35f067414edd769a63320d028e9edf256789641aab5f02786c370/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f636f6f6c6c616273696f2f6f7267616e697a6174696f6e2f342f6176617461722e737667" /> </a> </p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>huggingface/lerobot</title>
<link>https://github.com/huggingface/lerobot</link>
<guid>https://github.com/huggingface/lerobot</guid>
<content:encoded><![CDATA[
<div> 关键词：LeRobot、AI、机器人、预训练模型、真实世界应用

总结：

LeRobot是一个旨在降低机器人领域入门门槛的开源项目，目标是提供基于PyTorch的机器学习模型、数据集和工具，以促进真实世界的机器人应用。它包含了模仿学习和强化学习的最新方法，这些方法已被证明可以在真实环境中进行迁移。LeRobot不仅提供了预训练的模型和人类演示的数据集，还为用户提供了一个易于上手的环境来开始构建自己的机器人系统。

LeRobot支持多种预训练模型在模拟环境中的使用，包括ACT策略、TDMPC策略和Diffusion策略。用户可以下载这些模型并评估它们在特定环境中的表现，例如ALOHA、SimXArm或PushT环境。

该项目特别强调了与社区的互动和贡献，鼓励用户上传自己的数据集和模型到Hugging Face社区页面。这不仅促进了知识共享，也加速了真实世界机器人技术的发展。LeRobot还提供了一套完整的开发流程和指南，从安装环境、可视化数据集到训练和评估自定义策略，使用户能够快速上手并探索不同的机器人任务。

LeRobot的目标是让每个人都能参与到机器人技术的创新中来，无论是通过使用现有的资源还是通过贡献自己的工作成果，从而推动这一领域的进步。 <div>
<p>🤗 LeRobot: Making AI for Robotics more accessible with end-to-end learning</p><hr /><p align="center"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <source media="(prefers-color-scheme: light)" /> 
  <img alt="LeRobot, Hugging Face Robotics Library" src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/lerobot-logo-thumbnail.png" /> 
  <br /> <br /> </p> 
<div align="center"> 
 <p><a href="https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml?query=branch%3Amain"><img alt="Tests" src="https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml/badge.svg?branch=main" /></a> <a href="https://codecov.io/gh/huggingface/lerobot"><img alt="Coverage" src="https://codecov.io/gh/huggingface/lerobot/branch/main/graph/badge.svg?token=TODO" /></a> <a href="https://www.python.org/downloads/"><img alt="Python versions" src="https://img.shields.io/pypi/pyversions/lerobot" /></a> <a href="https://github.com/huggingface/lerobot/raw/main/LICENSE"><img alt="License" src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" /></a> <a href="https://pypi.org/project/lerobot/"><img alt="Status" src="https://img.shields.io/pypi/status/lerobot" /></a> <a href="https://pypi.org/project/lerobot/"><img alt="Version" src="https://img.shields.io/pypi/v/lerobot" /></a> <a href="https://github.com/huggingface/lerobot/tree/main/examples"><img alt="Examples" src="https://img.shields.io/badge/Examples-green.svg?sanitize=true" /></a> <a href="https://github.com/huggingface/lerobot/raw/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?sanitize=true" /></a> <a href="https://discord.gg/s3KuuzsPFb"><img alt="Discord" src="https://dcbadge.vercel.app/api/server/C5P34WJ68S?style=flat" /></a></p> 
</div> 
<h2 align="center"> <p><a href="https://github.com/huggingface/lerobot/raw/main/examples/7_get_started_with_real_robot.md">Hot new tutorial: Getting started with real-world robots</a></p> </h2> 
<div align="center"> 
 <img alt="Koch v1.1 leader and follower arms" src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/tutorial/koch_v1_1_leader_follower.webp?raw=true" title="Koch v1.1 leader and follower arms" width="50%" /> 
 <p>We just dropped an in-depth tutorial on how to build your own robot!</p> 
 <p>Teach it new skills by showing it a few moves with just a laptop.</p> 
 <p>Then watch your homemade robot act autonomously 🤯</p> 
 <p>For more info, see <a href="https://x.com/RemiCadene/status/1825455895561859185">our thread on X</a> or <a href="https://github.com/huggingface/lerobot/raw/main/examples/7_get_started_with_real_robot.md">our tutorial page</a>.</p> 
</div> 
<br /> 
<h3 align="center"> <p>LeRobot: State-of-the-art AI for real-world robotics</p> </h3> 
<hr /> 
<p>🤗 LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models.</p> 
<p>🤗 LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.</p> 
<p>🤗 LeRobot already provides a set of pretrained models, datasets with human collected demonstrations, and simulation environments to get started without assembling a robot. In the coming weeks, the plan is to add more and more support for real-world robotics on the most affordable and capable robots out there.</p> 
<p>🤗 LeRobot hosts pretrained models and datasets on this Hugging Face community page: <a href="https://huggingface.co/lerobot">huggingface.co/lerobot</a></p> 
<h4>Examples of pretrained models on simulation environments</h4> 
<table> 
 <tbody>
  <tr> 
   <td><img alt="ACT policy on ALOHA env" src="http://remicadene.com/assets/gif/aloha_act.gif" width="100%" /></td> 
   <td><img alt="TDMPC policy on SimXArm env" src="http://remicadene.com/assets/gif/simxarm_tdmpc.gif" width="100%" /></td> 
   <td><img alt="Diffusion policy on PushT env" src="http://remicadene.com/assets/gif/pusht_diffusion.gif" width="100%" /></td> 
  </tr> 
  <tr> 
   <td align="center">ACT policy on ALOHA env</td> 
   <td align="center">TDMPC policy on SimXArm env</td> 
   <td align="center">Diffusion policy on PushT env</td> 
  </tr> 
 </tbody>
</table> 
<h3>Acknowledgment</h3> 
<ul> 
 <li>Thanks to Tony Zaho, Zipeng Fu and colleagues for open sourcing ACT policy, ALOHA environments and datasets. Ours are adapted from <a href="https://tonyzhaozh.github.io/aloha">ALOHA</a> and <a href="https://mobile-aloha.github.io">Mobile ALOHA</a>.</li> 
 <li>Thanks to Cheng Chi, Zhenjia Xu and colleagues for open sourcing Diffusion policy, Pusht environment and datasets, as well as UMI datasets. Ours are adapted from <a href="https://diffusion-policy.cs.columbia.edu">Diffusion Policy</a> and <a href="https://umi-gripper.github.io">UMI Gripper</a>.</li> 
 <li>Thanks to Nicklas Hansen, Yunhai Feng and colleagues for open sourcing TDMPC policy, Simxarm environments and datasets. Ours are adapted from <a href="https://github.com/nicklashansen/tdmpc">TDMPC</a> and <a href="https://www.yunhaifeng.com/FOWM">FOWM</a>.</li> 
 <li>Thanks to Antonio Loquercio and Ashish Kumar for their early support.</li> 
 <li>Thanks to <a href="https://sjlee.cc/">Seungjae (Jay) Lee</a>, <a href="https://mahis.life/">Mahi Shafiullah</a> and colleagues for open sourcing <a href="https://sjlee.cc/vq-bet/">VQ-BeT</a> policy and helping us adapt the codebase to our repository. The policy is adapted from <a href="https://github.com/jayLEE0301/vq_bet_official">VQ-BeT repo</a>.</li> 
</ul> 
<h2>Installation</h2> 
<p>Download our source code:</p> 
<pre><code class="language-bash">git clone https://github.com/huggingface/lerobot.git
cd lerobot
</code></pre> 
<p>Create a virtual environment with Python 3.10 and activate it, e.g. with <a href="https://docs.anaconda.com/free/miniconda/index.html"><code>miniconda</code></a>:</p> 
<pre><code class="language-bash">conda create -y -n lerobot python=3.10
conda activate lerobot
</code></pre> 
<p>Install 🤗 LeRobot:</p> 
<pre><code class="language-bash">pip install -e .
</code></pre> 
<blockquote> 
 <p><strong>NOTE:</strong> Depending on your platform, If you encounter any build errors during this step you may need to install <code>cmake</code> and <code>build-essential</code> for building some of our dependencies. On linux: <code>sudo apt-get install cmake build-essential</code></p> 
</blockquote> 
<p>For simulations, 🤗 LeRobot comes with gymnasium environments that can be installed as extras:</p> 
<ul> 
 <li><a href="https://github.com/huggingface/gym-aloha">aloha</a></li> 
 <li><a href="https://github.com/huggingface/gym-xarm">xarm</a></li> 
 <li><a href="https://github.com/huggingface/gym-pusht">pusht</a></li> 
</ul> 
<p>For instance, to install 🤗 LeRobot with aloha and pusht, use:</p> 
<pre><code class="language-bash">pip install -e ".[aloha, pusht]"
</code></pre> 
<p>To use <a href="https://docs.wandb.ai/quickstart">Weights and Biases</a> for experiment tracking, log in with</p> 
<pre><code class="language-bash">wandb login
</code></pre> 
<p>(note: you will also need to enable WandB in the configuration. See below.)</p> 
<h2>Walkthrough</h2> 
<pre><code>.
├── examples             # contains demonstration examples, start here to learn about LeRobot
|   └── advanced         # contains even more examples for those who have mastered the basics
├── lerobot
|   ├── configs          # contains hydra yaml files with all options that you can override in the command line
|   |   ├── default.yaml   # selected by default, it loads pusht environment and diffusion policy
|   |   ├── env            # various sim environments and their datasets: aloha.yaml, pusht.yaml, xarm.yaml
|   |   └── policy         # various policies: act.yaml, diffusion.yaml, tdmpc.yaml
|   ├── common           # contains classes and utilities
|   |   ├── datasets       # various datasets of human demonstrations: aloha, pusht, xarm
|   |   ├── envs           # various sim environments: aloha, pusht, xarm
|   |   ├── policies       # various policies: act, diffusion, tdmpc
|   |   ├── robot_devices  # various real devices: dynamixel motors, opencv cameras, koch robots
|   |   └── utils          # various utilities
|   └── scripts          # contains functions to execute via command line
|       ├── eval.py                 # load policy and evaluate it on an environment
|       ├── train.py                # train a policy via imitation learning and/or reinforcement learning
|       ├── control_robot.py        # teleoperate a real robot, record data, run a policy
|       ├── push_dataset_to_hub.py  # convert your dataset into LeRobot dataset format and upload it to the Hugging Face hub
|       └── visualize_dataset.py    # load a dataset and render its demonstrations
├── outputs               # contains results of scripts execution: logs, videos, model checkpoints
└── tests                 # contains pytest utilities for continuous integration
</code></pre> 
<h3>Visualize datasets</h3> 
<p>Check out <a href="https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py">example 1</a> that illustrates how to use our dataset class which automatically download data from the Hugging Face hub.</p> 
<p>You can also locally visualize episodes from a dataset on the hub by executing our script from the command line:</p> 
<pre><code class="language-bash">python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --episode-index 0
</code></pre> 
<p>or from a dataset in a local folder with the root <code>DATA_DIR</code> environment variable (in the following case the dataset will be searched for in <code>./my_local_data_dir/lerobot/pusht</code>)</p> 
<pre><code class="language-bash">DATA_DIR='./my_local_data_dir' python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --episode-index 0
</code></pre> 
<p>It will open <code>rerun.io</code> and display the camera streams, robot states and actions, like this:</p> 
<p><a href="https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20240505T172924Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;X-Amz-SignedHeaders=host&amp;actor_id=24889239&amp;key_id=0&amp;repo_id=748713144">https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20240505T172924Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;X-Amz-SignedHeaders=host&amp;actor_id=24889239&amp;key_id=0&amp;repo_id=748713144</a></p> 
<p>Our script can also visualize datasets stored on a distant server. See <code>python lerobot/scripts/visualize_dataset.py --help</code> for more instructions.</p> 
<h3>The <code>LeRobotDataset</code> format</h3> 
<p>A dataset in <code>LeRobotDataset</code> format is very simple to use. It can be loaded from a repository on the Hugging Face hub or a local folder simply with e.g. <code>dataset = LeRobotDataset("lerobot/aloha_static_coffee")</code> and can be indexed into like any Hugging Face and PyTorch dataset. For instance <code>dataset[0]</code> will retrieve a single temporal frame from the dataset containing observation(s) and an action as PyTorch tensors ready to be fed to a model.</p> 
<p>A specificity of <code>LeRobotDataset</code> is that, rather than retrieving a single frame by its index, we can retrieve several frames based on their temporal relationship with the indexed frame, by setting <code>delta_timestamps</code> to a list of relative times with respect to the indexed frame. For example, with <code>delta_timestamps = {"observation.image": [-1, -0.5, -0.2, 0]}</code> one can retrieve, for a given index, 4 frames: 3 "previous" frames 1 second, 0.5 seconds, and 0.2 seconds before the indexed frame, and the indexed frame itself (corresponding to the 0 entry). See example <a href="https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py">1_load_lerobot_dataset.py</a> for more details on <code>delta_timestamps</code>.</p> 
<p>Under the hood, the <code>LeRobotDataset</code> format makes use of several ways to serialize data which can be useful to understand if you plan to work more closely with this format. We tried to make a flexible yet simple dataset format that would cover most type of features and specificities present in reinforcement learning and robotics, in simulation and in real-world, with a focus on cameras and robot states but easily extended to other types of sensory inputs as long as they can be represented by a tensor.</p> 
<p>Here are the important details and internal structure organization of a typical <code>LeRobotDataset</code> instantiated with <code>dataset = LeRobotDataset("lerobot/aloha_static_coffee")</code>. The exact features will change from dataset to dataset but not the main aspects:</p> 
<pre><code>dataset attributes:
  ├ hf_dataset: a Hugging Face dataset (backed by Arrow/parquet). Typical features example:
  │  ├ observation.images.cam_high (VideoFrame):
  │  │   VideoFrame = {'path': path to a mp4 video, 'timestamp' (float32): timestamp in the video}
  │  ├ observation.state (list of float32): position of an arm joints (for instance)
  │  ... (more observations)
  │  ├ action (list of float32): goal position of an arm joints (for instance)
  │  ├ episode_index (int64): index of the episode for this sample
  │  ├ frame_index (int64): index of the frame for this sample in the episode ; starts at 0 for each episode
  │  ├ timestamp (float32): timestamp in the episode
  │  ├ next.done (bool): indicates the end of en episode ; True for the last frame in each episode
  │  └ index (int64): general index in the whole dataset
  ├ episode_data_index: contains 2 tensors with the start and end indices of each episode
  │  ├ from (1D int64 tensor): first frame index for each episode — shape (num episodes,) starts with 0
  │  └ to: (1D int64 tensor): last frame index for each episode — shape (num episodes,)
  ├ stats: a dictionary of statistics (max, mean, min, std) for each feature in the dataset, for instance
  │  ├ observation.images.cam_high: {'max': tensor with same number of dimensions (e.g. `(c, 1, 1)` for images, `(c,)` for states), etc.}
  │  ...
  ├ info: a dictionary of metadata on the dataset
  │  ├ codebase_version (str): this is to keep track of the codebase version the dataset was created with
  │  ├ fps (float): frame per second the dataset is recorded/synchronized to
  │  ├ video (bool): indicates if frames are encoded in mp4 video files to save space or stored as png files
  │  └ encoding (dict): if video, this documents the main options that were used with ffmpeg to encode the videos
  ├ videos_dir (Path): where the mp4 videos or png images are stored/accessed
  └ camera_keys (list of string): the keys to access camera features in the item returned by the dataset (e.g. `["observation.images.cam_high", ...]`)
</code></pre> 
<p>A <code>LeRobotDataset</code> is serialised using several widespread file formats for each of its parts, namely:</p> 
<ul> 
 <li>hf_dataset stored using Hugging Face datasets library serialization to parquet</li> 
 <li>videos are stored in mp4 format to save space or png files</li> 
 <li>episode_data_index saved using <code>safetensor</code> tensor serialization format</li> 
 <li>stats saved using <code>safetensor</code> tensor serialization format</li> 
 <li>info are saved using JSON</li> 
</ul> 
<p>Dataset can be uploaded/downloaded from the HuggingFace hub seamlessly. To work on a local dataset, you can set the <code>DATA_DIR</code> environment variable to your root dataset folder as illustrated in the above section on dataset visualization.</p> 
<h3>Evaluate a pretrained policy</h3> 
<p>Check out <a href="https://raw.githubusercontent.com/huggingface/lerobot/main/examples/2_evaluate_pretrained_policy.py">example 2</a> that illustrates how to download a pretrained policy from Hugging Face hub, and run an evaluation on its corresponding environment.</p> 
<p>We also provide a more capable script to parallelize the evaluation over multiple environments during the same rollout. Here is an example with a pretrained model hosted on <a href="https://huggingface.co/lerobot/diffusion_pusht">lerobot/diffusion_pusht</a>:</p> 
<pre><code class="language-bash">python lerobot/scripts/eval.py \
    -p lerobot/diffusion_pusht \
    eval.n_episodes=10 \
    eval.batch_size=10
</code></pre> 
<p>Note: After training your own policy, you can re-evaluate the checkpoints with:</p> 
<pre><code class="language-bash">python lerobot/scripts/eval.py -p {OUTPUT_DIR}/checkpoints/last/pretrained_model
</code></pre> 
<p>See <code>python lerobot/scripts/eval.py --help</code> for more instructions.</p> 
<h3>Train your own policy</h3> 
<p>Check out <a href="https://raw.githubusercontent.com/huggingface/lerobot/main/examples/3_train_policy.py">example 3</a> that illustrates how to train a model using our core library in python, and <a href="https://raw.githubusercontent.com/huggingface/lerobot/main/examples/4_train_policy_with_script.md">example 4</a> that shows how to use our training script from command line.</p> 
<p>In general, you can use our training script to easily train any policy. Here is an example of training the ACT policy on trajectories collected by humans on the Aloha simulation environment for the insertion task:</p> 
<pre><code class="language-bash">python lerobot/scripts/train.py \
    policy=act \
    env=aloha \
    env.task=AlohaInsertion-v0 \
    dataset_repo_id=lerobot/aloha_sim_insertion_human \
</code></pre> 
<p>The experiment directory is automatically generated and will show up in yellow in your terminal. It looks like <code>outputs/train/2024-05-05/20-21-12_aloha_act_default</code>. You can manually specify an experiment directory by adding this argument to the <code>train.py</code> python command:</p> 
<pre><code class="language-bash">    hydra.run.dir=your/new/experiment/dir
</code></pre> 
<p>In the experiment directory there will be a folder called <code>checkpoints</code> which will have the following structure:</p> 
<pre><code class="language-bash">checkpoints
├── 000250  # checkpoint_dir for training step 250
│   ├── pretrained_model  # Hugging Face pretrained model dir
│   │   ├── config.json  # Hugging Face pretrained model config
│   │   ├── config.yaml  # consolidated Hydra config
│   │   ├── model.safetensors  # model weights
│   │   └── README.md  # Hugging Face model card
│   └── training_state.pth  # optimizer/scheduler/rng state and training step
</code></pre> 
<p>To use wandb for logging training and evaluation curves, make sure you've run <code>wandb login</code> as a one-time setup step. Then, when running the training command above, enable WandB in the configuration by adding:</p> 
<pre><code class="language-bash">    wandb.enable=true
</code></pre> 
<p>A link to the wandb logs for the run will also show up in yellow in your terminal. Here is an example of what they look like in your browser:</p> 
<p><img alt="" src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/wandb.png" /></p> 
<p>Note: For efficiency, during training every checkpoint is evaluated on a low number of episodes. You may use <code>eval.n_episodes=500</code> to evaluate on more episodes than the default. Or, after training, you may want to re-evaluate your best checkpoints on more episodes or change the evaluation settings. See <code>python lerobot/scripts/eval.py --help</code> for more instructions.</p> 
<h4>Reproduce state-of-the-art (SOTA)</h4> 
<p>We have organized our configuration files (found under <a href="https://raw.githubusercontent.com/huggingface/lerobot/main/lerobot/configs"><code>lerobot/configs</code></a>) such that they reproduce SOTA results from a given model variant in their respective original works. Simply running:</p> 
<pre><code class="language-bash">python lerobot/scripts/train.py policy=diffusion env=pusht
</code></pre> 
<p>reproduces SOTA results for Diffusion Policy on the PushT task.</p> 
<p>Pretrained policies, along with reproduction details, can be found under the "Models" section of <a href="https://huggingface.co/lerobot">https://huggingface.co/lerobot</a>.</p> 
<h2>Contribute</h2> 
<p>If you would like to contribute to 🤗 LeRobot, please check out our <a href="https://github.com/huggingface/lerobot/raw/main/CONTRIBUTING.md">contribution guide</a>.</p> 
<h3>Add a new dataset</h3> 
<p>To add a dataset to the hub, you need to login using a write-access token, which can be generated from the <a href="https://huggingface.co/settings/tokens">Hugging Face settings</a>:</p> 
<pre><code class="language-bash">huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
</code></pre> 
<p>Then point to your raw dataset folder (e.g. <code>data/aloha_static_pingpong_test_raw</code>), and push your dataset to the hub with:</p> 
<pre><code class="language-bash">python lerobot/scripts/push_dataset_to_hub.py \
--raw-dir data/aloha_static_pingpong_test_raw \
--out-dir data \
--repo-id lerobot/aloha_static_pingpong_test \
--raw-format aloha_hdf5
</code></pre> 
<p>See <code>python lerobot/scripts/push_dataset_to_hub.py --help</code> for more instructions.</p> 
<p>If your dataset format is not supported, implement your own in <code>lerobot/common/datasets/push_dataset_to_hub/${raw_format}_format.py</code> by copying examples like <a href="https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/pusht_zarr_format.py">pusht_zarr</a>, <a href="https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/umi_zarr_format.py">umi_zarr</a>, <a href="https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/aloha_hdf5_format.py">aloha_hdf5</a>, or <a href="https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/xarm_pkl_format.py">xarm_pkl</a>.</p> 
<h3>Add a pretrained policy</h3> 
<p>Once you have trained a policy you may upload it to the Hugging Face hub using a hub id that looks like <code>${hf_user}/${repo_name}</code> (e.g. <a href="https://huggingface.co/lerobot/diffusion_pusht">lerobot/diffusion_pusht</a>).</p> 
<p>You first need to find the checkpoint folder located inside your experiment directory (e.g. <code>outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500</code>). Within that there is a <code>pretrained_model</code> directory which should contain:</p> 
<ul> 
 <li><code>config.json</code>: A serialized version of the policy configuration (following the policy's dataclass config).</li> 
 <li><code>model.safetensors</code>: A set of <code>torch.nn.Module</code> parameters, saved in <a href="https://huggingface.co/docs/safetensors/index">Hugging Face Safetensors</a> format.</li> 
 <li><code>config.yaml</code>: A consolidated Hydra training configuration containing the policy, environment, and dataset configs. The policy configuration should match <code>config.json</code> exactly. The environment config is useful for anyone who wants to evaluate your policy. The dataset config just serves as a paper trail for reproducibility.</li> 
</ul> 
<p>To upload these to the hub, run the following:</p> 
<pre><code class="language-bash">huggingface-cli upload ${hf_user}/${repo_name} path/to/pretrained_model
</code></pre> 
<p>See <a href="https://github.com/huggingface/lerobot/raw/main/lerobot/scripts/eval.py">eval.py</a> for an example of how other people may use your policy.</p> 
<h3>Improve your code with profiling</h3> 
<p>An example of a code snippet to profile the evaluation of a policy:</p> 
<pre><code class="language-python">from torch.profiler import profile, record_function, ProfilerActivity

def trace_handler(prof):
    prof.export_chrome_trace(f"tmp/trace_schedule_{prof.step_num}.json")

with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    schedule=torch.profiler.schedule(
        wait=2,
        warmup=2,
        active=3,
    ),
    on_trace_ready=trace_handler
) as prof:
    with record_function("eval_policy"):
        for i in range(num_episodes):
            prof.step()
            # insert code to profile, potentially whole body of eval_policy function
</code></pre> 
<h2>Citation</h2> 
<p>If you want, you can cite this work with:</p> 
<pre><code class="language-bibtex">@misc{cadene2024lerobot,
    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas},
    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},
    howpublished = "\url{https://github.com/huggingface/lerobot}",
    year = {2024}
}
</code></pre> 
<p>Additionally, if you are using any of the particular policy architecture, pretrained models, or datasets, it is recommended to cite the original authors of the work as they appear below:</p> 
<ul> 
 <li><a href="https://diffusion-policy.cs.columbia.edu">Diffusion Policy</a></li> 
</ul> 
<pre><code class="language-bibtex">@article{chi2024diffusionpolicy,
	author = {Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
	title ={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	journal = {The International Journal of Robotics Research},
	year = {2024},
}
</code></pre> 
<ul> 
 <li><a href="https://tonyzhaozh.github.io/aloha">ACT or ALOHA</a></li> 
</ul> 
<pre><code class="language-bibtex">@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}
</code></pre> 
<ul> 
 <li><a href="https://www.nicklashansen.com/td-mpc/">TDMPC</a></li> 
</ul> 
<pre><code class="language-bibtex">@inproceedings{Hansen2022tdmpc,
	title={Temporal Difference Learning for Model Predictive Control},
	author={Nicklas Hansen and Xiaolong Wang and Hao Su},
	booktitle={ICML},
	year={2022}
}
</code></pre> 
<ul> 
 <li><a href="https://sjlee.cc/vq-bet/">VQ-BeT</a></li> 
</ul> 
<pre><code class="language-bibtex">@article{lee2024behavior,
  title={Behavior generation with latent actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2403.03181},
  year={2024}
}
</code></pre>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>microsoft/generative-ai-for-beginners</title>
<link>https://github.com/microsoft/generative-ai-for-beginners</link>
<guid>https://github.com/microsoft/generative-ai-for-beginners</guid>
<content:encoded><![CDATA[
<div> 关键词：Microsoft、Generative AI、课程、开发环境、学习资源

总结:
Microsoft为初学者提供了“Generative AI for Beginners”课程，旨在通过18个模块教授构建生成式人工智能应用所需的基础知识。本课程覆盖从入门到进阶的内容，包括设置开发环境、理解生成式AI及其工作原理、选择合适的模型、负责任地构建应用、最佳提示工程实践、模型集成与应用等。课程还提供了Python和TypeScript代码示例，并鼓励学员加入社区获取支持。

课程内容包括视频介绍、详细阅读材料、代码示例以及额外的学习资源链接。学员需要具备基本的Python或TypeScript知识，并且可以访问Azure或OpenAI的API。为了帮助学员快速上手，课程提供了一节关于设置开发环境的指导课。此外，对于寻求更高级代码示例的学员，课程还提供了Python和TypeScript代码库。

为了促进社区交流和项目合作，参与者可以加入课程的讨论区。对构建初创企业感兴趣的学员，可以注册获取免费的OpenAI信用和Azure信用，以便通过Azure OpenAI服务访问OpenAI模型。对于希望贡献课程内容的学员，也提供了反馈渠道。

总之，“Generative AI for Beginners”课程是一个全面的资源，旨在帮助初学者从零开始构建生成式AI应用，同时提供了丰富的学习材料、社区支持和实践机会，以加速学习过程并促进技能提升。 <div>
<p>18 Lessons, Get Started Building with Generative AI 🔗 https://microsoft.github.io/generative-ai-for-beginners/</p><hr /><p><img alt="Generative AI For Beginners" src="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/images/repo-thumbnailv3.png?WT.mc_id=academic-105485-koreyst" /></p> 
<h3>18 Lessons teaching everything you need to know to start building Generative AI applications</h3> 
<p><a href="https://github.com/microsoft/Generative-AI-For-Beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst"><img alt="GitHub license" src="https://img.shields.io/github/license/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" /></a> <a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" /></a> <a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/issues/?WT.mc_id=academic-105485-koreyst"><img alt="GitHub issues" src="https://img.shields.io/github/issues/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" /></a> <a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/pulls/?WT.mc_id=academic-105485-koreyst"><img alt="GitHub pull-requests" src="https://img.shields.io/github/issues-pr/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" /></a> <a href="http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst"><img alt="PRs Welcome" src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" /></a></p> 
<p><a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/watchers/?WT.mc_id=academic-105485-koreyst"><img alt="GitHub watchers" src="https://img.shields.io/github/watchers/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;label=Watch" /></a> <a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/network/?WT.mc_id=academic-105485-koreyst"><img alt="GitHub forks" src="https://img.shields.io/github/forks/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;label=Fork" /></a> <a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/stargazers/?WT.mc_id=academic-105485-koreyst"><img alt="GitHub stars" src="https://img.shields.io/github/stars/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;label=Star" /></a></p> 
<p><a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst"><img alt="" src="https://dcbadge.vercel.app/api/server/ByRwuEEgH4" /></a></p> 
<h1>Generative AI for Beginners (Version 2) - A Course</h1> 
<p>Learn the fundamentals of building Generative AI applications with our 18-lesson comprehensive course by Microsoft Cloud Advocates.</p> 
<h2>🌱 Getting Started</h2> 
<p>This course has 18 lessons. Each lesson covers its own topic so start wherever you like!</p> 
<p>Lessons are labeled either "Learn" lessons explaining a Generative AI concept or "Build" lessons that explain a concept and code examples in both <strong>Python</strong> and <strong>TypeScript</strong> when possible.</p> 
<p>Each lesson also includes a "Keep Learning" section with additional learning tools.</p> 
<p><strong>What You Need</strong></p> 
<ul> 
 <li>Access to the <a href="https://azure.microsoft.com/products/ai-services/openai-service?WT.mc_id=academic-105485-koreyst">Azure OpenAI Service</a> <strong>OR</strong> <a href="https://platform.openai.com/docs/quickstart?context=python?WT.mc_id=academic-105485-koreyst">OpenAI API</a> <strong>OR</strong> <a href="https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst">GitHub Marketplace Model Catalog</a> - <em>Only required to complete coding lessons</em></li> 
 <li>Basic knowledge of Python or TypeScript is helpful - *For absolute beginners check out these <a href="https://learn.microsoft.com/training/paths/python-language/?WT.mc_id=academic-105485-koreyst">Python</a> and <a href="https://learn.microsoft.com/training/paths/build-javascript-applications-typescript/?WT.mc_id=academic-105485-koreyst">TypeScript</a> courses.</li> 
 <li>A GitHub account to <a href="https://github.com/microsoft/generative-ai-for-beginners/fork?WT.mc_id=academic-105485-koreyst">fork this entire repo</a> to your own GitHub account</li> 
</ul> 
<p>We have created a <strong><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst">Course Setup</a></strong> lesson to help you with setting up your development environment.</p> 
<p>Don't forget to <a href="https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst">star (🌟) this repo</a> to find it easier later.</p> 
<h2>🧠 Ready to Deploy?</h2> 
<p>If you are looking for more advanced code samples, check out our <a href="https://aka.ms/genai-beg-code?WT.mc_id=academic-105485-koreyst">collection of Generative AI Code Samples</a> in both <strong>Python</strong> and <strong>TypeScript</strong>.</p> 
<h2>🗣️ Meet Other Learners, Get Support</h2> 
<p>Join our <a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst">official AI Discord server</a> to meet and network with other learners taking this course and get support.</p> 
<h2>🚀 Building a Startup?</h2> 
<p>Sign up for <a href="https://aka.ms/genai-foundershub?WT.mc_id=academic-105485-koreyst">Microsoft for Startups Founders Hub</a> to receive <strong>free OpenAI credits</strong> and up to <strong>$150k towards Azure credits to access OpenAI models through Azure OpenAI Services</strong>.</p> 
<h2>🙏 Want to help?</h2> 
<p>Do you have suggestions or found spelling or code errors? <a href="https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst">Raise an issue</a> or <a href="https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst">Create a pull request</a></p> 
<h2>📂 Each lesson includes:</h2> 
<ul> 
 <li>A short video introduction to the topic</li> 
 <li>A written lesson located in the README</li> 
 <li>Python and TypeScript code samples supporting Azure OpenAI and OpenAI API</li> 
 <li>Links to extra resources to continue your learning</li> 
</ul> 
<h2>🗃️ Lessons</h2> 
<table> 
 <thead> 
  <tr> 
   <th>#</th> 
   <th><strong>Lesson Link</strong></th> 
   <th><strong>Description</strong></th> 
   <th><strong>Video</strong></th> 
   <th><strong>Extra Learning</strong></th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>00</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst">Course Setup</a></td> 
   <td><strong>Learn:</strong> How to Setup Your Development Environment</td> 
   <td>Coming Soon</td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>01</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst">Introduction to Generative AI and LLMs</a></td> 
   <td><strong>Learn:</strong> Understanding what Generative AI is and how Large Language Models (LLMs) work.</td> 
   <td><a href="https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>02</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst">Exploring and comparing different LLMs</a></td> 
   <td><strong>Learn:</strong> How to select the right model for your use case</td> 
   <td><a href="https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>03</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst">Using Generative AI Responsibly</a></td> 
   <td><strong>Learn:</strong> How to build Generative AI Applications responsibly</td> 
   <td><a href="https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>04</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst">Understanding Prompt Engineering Fundamentals</a></td> 
   <td><strong>Learn:</strong> Hands-on Prompt Engineering Best Practices</td> 
   <td><a href="https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>05</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst">Creating Advanced Prompts</a></td> 
   <td><strong>Learn:</strong> How to apply prompt engineering techniques that improve the outcome of your prompts.</td> 
   <td><a href="https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>06</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst">Building Text Generation Applications</a></td> 
   <td><strong>Build:</strong> A text generation app using Azure OpenAI / OpenAI API</td> 
   <td><a href="https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>07</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst">Building Chat Applications</a></td> 
   <td><strong>Build:</strong> Techniques for efficiently building and integrating chat applications.</td> 
   <td><a href="https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>08</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst">Building Search Apps Vector Databases</a></td> 
   <td><strong>Build:</strong> A search application that uses Embeddings to search for data.</td> 
   <td><a href="https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>09</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst">Building Image Generation Applications</a></td> 
   <td><strong>Build:</strong> A image generation application</td> 
   <td><a href="https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>10</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst">Building Low Code AI Applications</a></td> 
   <td><strong>Build:</strong> A Generative AI application using Low Code tools</td> 
   <td><a href="https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>11</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst">Integrating External Applications with Function Calling</a></td> 
   <td><strong>Build:</strong> What is function calling and its use cases for applications</td> 
   <td><a href="https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>12</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst">Designing UX for AI Applications</a></td> 
   <td><strong>Learn:</strong> How to apply UX design principles when developing Generative AI Applications</td> 
   <td><a href="https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>13</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst">Securing Your Generative AI Applications</a></td> 
   <td><strong>Learn:</strong> The threats and risks to AI systems and methods to secure these systems.</td> 
   <td><a href="https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>14</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst">The Generative AI Application Lifecycle</a></td> 
   <td><strong>Learn:</strong> The tools and metrics to manage the LLM Lifecycle and LLMOps</td> 
   <td><a href="https://aka.ms/gen-ai-lesson14-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>15</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst">Retrieval Augmented Generation (RAG) and Vector Databases</a></td> 
   <td><strong>Build:</strong> An application using a RAG Framework to retrieve embeddings from a Vector Databases</td> 
   <td><a href="https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>16</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/16-open-source-models/README.md?WT.mc_id=academic-105485-koreyst">Open Source Models and Hugging Face</a></td> 
   <td><strong>Build:</strong> An application using open source models available on Hugging Face</td> 
   <td><a href="https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>17</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/17-ai-agents/README.md?WT.mc_id=academic-105485-koreyst">AI Agents</a></td> 
   <td><strong>Build:</strong> An application using an AI Agent Framework</td> 
   <td><a href="https://aka.ms/gen-ai-lesson17-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
  <tr> 
   <td>18</td> 
   <td><a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst">Fine-Tuning LLMs</a></td> 
   <td><strong>Learn:</strong> The what, why and how of fine-tuning LLMs</td> 
   <td><a href="https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst">Video</a></td> 
   <td><a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Learn More</a></td> 
  </tr> 
 </tbody> 
</table> 
<h3>🌟 Special thanks</h3> 
<p>Special thanks to <a href="https://www.linkedin.com/in/john0isaac/"><strong>John Aziz</strong></a> for creating all of the GitHub Actions and workflows</p> 
<h2>🎒 Other Courses</h2> 
<p>Our team produces other courses! Check out:</p> 
<ul> 
 <li><a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst">ML for Beginners</a></li> 
 <li><a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst">Data Science for Beginners</a></li> 
 <li><a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst">AI for Beginners</a></li> 
 <li><a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"><strong>NEW</strong> Cybersecurity for Beginners</a></li> 
 <li><a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst">Web Dev for Beginners</a></li> 
 <li><a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst">IoT for Beginners</a></li> 
 <li><a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst">XR Development for Beginners</a></li> 
 <li><a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst">Mastering GitHub Copilot for AI Paired Programming</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>huggingface/parler-tts</title>
<link>https://github.com/huggingface/parler-tts</link>
<guid>https://github.com/huggingface/parler-tts</guid>
<content:encoded><![CDATA[
<div> 关键词：Parler-TTS、文本到语音（TTS）、开源、高质量、自然发音

总结：
Parler-TTS 是一个由 Stability AI 和爱丁堡大学的研究人员 Dan Lyth 和 Simon King 开发的轻量级文本到语音生成模型。该模型旨在产生具有高保真度和自然发音的语音，同时允许用户通过文本提示自定义说话者的风格，包括性别、音调、语速等。Parler-TTS 的特别之处在于其完全开源，提供了数据集、预处理、训练代码和权重的公开访问权限，鼓励社区成员在此基础上进行创新和发展。该模型能够通过简单的安装步骤（`pip install git+https://github.com/huggingface/parler-tts.git`）轻松集成到项目中。

Parler-TTS 支持随机语音生成，以及特定说话者的声音控制，后者基于对不同说话人特征的训练。模型的使用方法简单直观，通过提供描述性文本和生成指令来定制输出语音。此外，Parler-TTS 还支持优化推理速度，如使用 SDPA 和 Flash Attention 技术，以及编译模型的能力。

为了提高质量和速度，Parler-TTS 团队正在探索多个改进方向，包括数据集扩展、更多语言支持、训练流程优化、模型架构探索、编译支持、静态缓存和多语言训练等。这些改进旨在进一步提升模型性能和应用范围。 <div>
<p>Inference and training library for high-quality TTS models.</p><hr /><h1>Parler-TTS</h1> 
<p>Parler-TTS is a lightweight text-to-speech (TTS) model that can generate high-quality, natural sounding speech in the style of a given speaker (gender, pitch, speaking style, etc). It is a reproduction of work from the paper <a href="https://www.text-description-to-speech.com">Natural language guidance of high-fidelity text-to-speech with synthetic annotations</a> by Dan Lyth and Simon King, from Stability AI and Edinburgh University respectively.</p> 
<p>Contrarily to other TTS models, Parler-TTS is a <strong>fully open-source</strong> release. All of the datasets, pre-processing, training code and weights are released publicly under permissive license, enabling the community to build on our work and develop their own powerful TTS models.</p> 
<p>This repository contains the inference and training code for Parler-TTS. It is designed to accompany the <a href="https://github.com/huggingface/dataspeech">Data-Speech</a> repository for dataset annotation.</p> 
<blockquote> 
 <p>[!IMPORTANT] <strong>08/08/2024:</strong> We are proud to release two new Parler-TTS checkpoints:</p> 
 <ol> 
  <li><a href="https://huggingface.co/parler-tts/parler-tts-mini-v1">Parler-TTS Mini</a>, an 880M parameter model.</li> 
  <li><a href="https://huggingface.co/parler-tts/parler-tts-large-v1">Parler-TTS Large</a>, a 2.3B parameter model.</li> 
 </ol> 
 <p>These checkpoints have been trained on 45k hours of audiobook data.</p> 
 <p>In addition, the code is optimized for much faster generation: we've added SDPA and Flash Attention 2 compatibility, as well as the ability to compile the model.</p> 
</blockquote> 
<h2>📖 Quick Index</h2> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/#installation">Installation</a></li> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/#usage">Usage</a> 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/#-random-voice">🎲 Using a random voice</a></li> 
   <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/#-using-a-specific-speaker">🎯 Using a specific speaker</a></li> 
  </ul> </li> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/#training">Training</a></li> 
 <li><a href="https://huggingface.co/spaces/parler-tts/parler_tts">Demo</a></li> 
 <li><a href="https://huggingface.co/parler-tts">Model weights and datasets</a></li> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/#-optimizing-inference-speed">Optimizing inference</a></li> 
</ul> 
<h2>Installation</h2> 
<p>Parler-TTS has light-weight dependencies and can be installed in one line:</p> 
<pre><code class="language-sh">pip install git+https://github.com/huggingface/parler-tts.git
</code></pre> 
<p>Apple Silicon users will need to run a follow-up command to make use the nightly PyTorch (2.4) build for bfloat16 support:</p> 
<pre><code class="language-sh">pip3 install --pre torch torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
</code></pre> 
<h2>Usage</h2> 
<blockquote> 
 <p>[!TIP] You can directly try it out in an interactive demo <a href="https://huggingface.co/spaces/parler-tts/parler_tts">here</a>!</p> 
</blockquote> 
<p>Using Parler-TTS is as simple as "bonjour". Simply install the library once:</p> 
<pre><code class="language-sh">pip install git+https://github.com/huggingface/parler-tts.git
</code></pre> 
<h3>🎲 Random voice</h3> 
<p><strong>Parler-TTS</strong> has been trained to generate speech with features that can be controlled with a simple text prompt, for example:</p> 
<pre><code class="language-py">import torch
from parler_tts import ParlerTTSForConditionalGeneration
from transformers import AutoTokenizer
import soundfile as sf

device = "cuda:0" if torch.cuda.is_available() else "cpu"

model = ParlerTTSForConditionalGeneration.from_pretrained("parler-tts/parler-tts-mini-v1").to(device)
tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler-tts-mini-v1")

prompt = "Hey, how are you doing today?"
description = "A female speaker delivers a slightly expressive and animated speech with a moderate speed and pitch. The recording is of very high quality, with the speaker's voice sounding clear and very close up."

input_ids = tokenizer(description, return_tensors="pt").input_ids.to(device)
prompt_input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)

generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)
audio_arr = generation.cpu().numpy().squeeze()
sf.write("parler_tts_out.wav", audio_arr, model.config.sampling_rate)
</code></pre> 
<h3>🎯 Using a specific speaker</h3> 
<p>To ensure speaker consistency across generations, this checkpoint was also trained on 34 speakers, characterized by name (e.g. Jon, Lea, Gary, Jenna, Mike, Laura).</p> 
<p>To take advantage of this, simply adapt your text description to specify which speaker to use: <code>Jon's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise.</code></p> 
<pre><code class="language-py">import torch
from parler_tts import ParlerTTSForConditionalGeneration
from transformers import AutoTokenizer
import soundfile as sf

device = "cuda:0" if torch.cuda.is_available() else "cpu"

model = ParlerTTSForConditionalGeneration.from_pretrained("parler-tts/parler-tts-mini-v1").to(device)
tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler-tts-mini-v1")

prompt = "Hey, how are you doing today?"
description = "Jon's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise."

input_ids = tokenizer(description, return_tensors="pt").input_ids.to(device)
prompt_input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)

generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)
audio_arr = generation.cpu().numpy().squeeze()
sf.write("parler_tts_out.wav", audio_arr, model.config.sampling_rate)
</code></pre> 
<p><strong>Tips</strong>:</p> 
<ul> 
 <li>Include the term "very clear audio" to generate the highest quality audio, and "very noisy audio" for high levels of background noise</li> 
 <li>Punctuation can be used to control the prosody of the generations, e.g. use commas to add small breaks in speech</li> 
 <li>The remaining speech features (gender, speaking rate, pitch and reverberation) can be controlled directly through the prompt</li> 
</ul> 
<h3>✨ Optimizing Inference Speed</h3> 
<p>We've set up an <a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/INFERENCE.md">inference guide</a> to make generation faster. Think SDPA, torch.compile and streaming!</p> 
<p><a href="https://github.com/huggingface/parler-tts/assets/52246514/251e2488-fe6e-42c1-81cd-814c5b7795b0">https://github.com/huggingface/parler-tts/assets/52246514/251e2488-fe6e-42c1-81cd-814c5b7795b0</a></p> 
<h2>Training</h2> 
<a href="https://github.com/ylacombe/scripts_and_notebooks/raw/main/Finetuning_Parler_TTS_v1_on_a_single_speaker_dataset.ipynb" target="_blank"> <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" /> </a> 
<p>The <a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/training/">training folder</a> contains all the information to train or fine-tune your own Parler-TTS model. It consists of:</p> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/training/README.md#1-architecture">1. An introduction to the Parler-TTS architecture</a></li> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/training/README.md#2-getting-started">2. The first steps to get started</a></li> 
 <li><a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/training/README.md#3-training">3. A training guide</a></li> 
</ul> 
<blockquote> 
 <p>[!IMPORTANT] <strong>TL;DR:</strong> After having followed the <a href="https://raw.githubusercontent.com/huggingface/parler-tts/main/training/README.md#requirements">installation steps</a>, you can reproduce the Parler-TTS Mini v1 training recipe with the following command line:</p> 
</blockquote> 
<pre><code class="language-sh">accelerate launch ./training/run_parler_tts_training.py ./helpers/training_configs/starting_point_v1.json
</code></pre> 
<blockquote> 
 <p>[!IMPORTANT] You can also follow <a href="https://github.com/ylacombe/scripts_and_notebooks/raw/main/Finetuning_Parler_TTS_v1_on_a_single_speaker_dataset.ipynb">this fine-tuning guide</a> on a mono-speaker dataset example.</p> 
</blockquote> 
<h2>Acknowledgements</h2> 
<p>This library builds on top of a number of open-source giants, to whom we'd like to extend our warmest thanks for providing these tools!</p> 
<p>Special thanks to:</p> 
<ul> 
 <li>Dan Lyth and Simon King, from Stability AI and Edinburgh University respectively, for publishing such a promising and clear research paper: <a href="https://arxiv.org/abs/2402.01912">Natural language guidance of high-fidelity text-to-speech with synthetic annotations</a>.</li> 
 <li>the many libraries used, namely <a href="https://huggingface.co/docs/datasets/v2.17.0/en/index">🤗 datasets</a>, <a href="https://huggingface.co/docs/accelerate/en/index">🤗 accelerate</a>, <a href="https://github.com/jitsi/jiwer">jiwer</a>, <a href="https://wandb.ai/">wandb</a>, and <a href="https://huggingface.co/docs/transformers/index">🤗 transformers</a>.</li> 
 <li>Descript for the <a href="https://github.com/descriptinc/descript-audio-codec">DAC codec model</a></li> 
 <li>Hugging Face 🤗 for providing compute resources and time to explore!</li> 
</ul> 
<h2>Citation</h2> 
<p>If you found this repository useful, please consider citing this work and also the original Stability AI paper:</p> 
<pre><code>@misc{lacombe-etal-2024-parler-tts,
  author = {Yoach Lacombe and Vaibhav Srivastav and Sanchit Gandhi},
  title = {Parler-TTS},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/parler-tts}}
}
</code></pre> 
<pre><code>@misc{lyth2024natural,
      title={Natural language guidance of high-fidelity text-to-speech with synthetic annotations},
      author={Dan Lyth and Simon King},
      year={2024},
      eprint={2402.01912},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
</code></pre> 
<h2>Contribution</h2> 
<p>Contributions are welcome, as the project offers many possibilities for improvement and exploration.</p> 
<p>Namely, we're looking at ways to improve both quality and speed:</p> 
<ul> 
 <li>Datasets: 
  <ul> 
   <li>Train on more data</li> 
   <li>Add more features such as accents</li> 
  </ul> </li> 
 <li>Training: 
  <ul> 
   <li>Add PEFT compatibility to do Lora fine-tuning.</li> 
   <li>Add possibility to train without description column.</li> 
   <li>Add notebook training.</li> 
   <li>Explore multilingual training.</li> 
   <li>Explore mono-speaker finetuning.</li> 
   <li>Explore more architectures.</li> 
  </ul> </li> 
 <li>Optimization: 
  <ul> 
   <li>Compilation and static cache</li> 
   <li>Support to FA2 and SDPA</li> 
  </ul> </li> 
 <li>Evaluation: 
  <ul> 
   <li>Add more evaluation metrics</li> 
  </ul> </li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>aria2/aria2</title>
<link>https://github.com/aria2/aria2</link>
<guid>https://github.com/aria2/aria2</guid>
<content:encoded><![CDATA[
<div> 关键词：aria2、下载工具、命令行界面、多协议支持、多源下载

总结：

文章主要介绍了aria2，这是一个功能强大的、命令行操作的下载工具。它支持多种下载协议，包括HTTP、HTTPS、FTP、SFTP和BitTorrent，能够从多个来源或协议同时下载文件，充分利用带宽资源。其特色包括金属链接（Metalink）版本4和3.0的支持，允许从多个源下载并验证数据块的完整性；支持HTTP代理、自定义HTTP头部、断点续传、速度限制等功能。此外，aria2还支持与BitTorrent协议的深度整合，如快进扩展、DHT、PEX等，提供本地对等发现和重新命名目录结构的功能。其设计遵循C++11标准，支持跨平台构建，并提供了丰富的API接口。

文章详细阐述了aria2的配置选项、依赖库需求、构建过程以及版本控制策略。通过使用不同的构建脚本（如针对Mac OS X和Android的特定脚本），用户可以轻松地构建适用于不同操作系统环境的aria2版本。文章还强调了SSL证书验证的重要性，并提供了多种配置SSL和加密库的方法。

总的来说，aria2是一个功能全面、高度可定制的下载工具，适合需要跨协议、多源高效下载文件的用户，尤其在需要自动化、脚本驱动或者需要深度集成到其他系统中的场景中表现突出。 <div>
<p>aria2 is a lightweight multi-protocol & multi-source, cross platform download utility operated in command-line. It supports HTTP/HTTPS, FTP, SFTP, BitTorrent and Metalink.</p><hr /><h1>aria2 - The ultra fast download utility</h1> 
<h2>Disclaimer</h2> 
<p>This program comes with no warranty. You must use this program at your own risk.</p> 
<h2>Introduction</h2> 
<p>aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum download bandwidth. It supports downloading a file from HTTP(S)/FTP/SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink's chunk checksums, aria2 automatically validates chunks of data while downloading a file like BitTorrent.</p> 
<p>The project page is located at <a href="https://aria2.github.io/">https://aria2.github.io/</a>.</p> 
<p>See the <code>aria2 Online Manual &lt;https://aria2.github.io/manual/en/html/&gt;</code>_ (<code>Russian translation &lt;https://aria2.github.io/manual/ru/html/&gt;</code><em>, <code>Portuguese translation &lt;https://aria2.github.io/manual/pt/html/&gt;</code></em>) to learn how to use aria2.</p> 
<h2>Features</h2> 
<p>Here is a list of features:</p> 
<ul> 
 <li>Command-line interface</li> 
 <li>Download files through HTTP(S)/FTP/SFTP/BitTorrent</li> 
 <li>Segmented downloading</li> 
 <li>Metalink version 4 (RFC 5854) support(HTTP/FTP/SFTP/BitTorrent)</li> 
 <li>Metalink version 3.0 support(HTTP/FTP/SFTP/BitTorrent)</li> 
 <li>Metalink/HTTP (RFC 6249) support</li> 
 <li>HTTP/1.1 implementation</li> 
 <li>HTTP Proxy support</li> 
 <li>HTTP BASIC authentication support</li> 
 <li>HTTP Proxy authentication support</li> 
 <li>Well-known environment variables for proxy: <code>http_proxy</code>, <code>https_proxy</code>, <code>ftp_proxy</code>, <code>all_proxy</code> and <code>no_proxy</code></li> 
 <li>HTTP gzip, deflate content encoding support</li> 
 <li>Verify peer using given trusted CA certificate in HTTPS</li> 
 <li>Client certificate authentication in HTTPS</li> 
 <li>Chunked transfer encoding support</li> 
 <li>Load Cookies from the file using the Firefox3 format, Chromium/Google Chrome and the Mozilla/Firefox (1.x/2.x)/Netscape format.</li> 
 <li>Save Cookies in the Mozilla/Firefox (1.x/2.x)/Netscape format.</li> 
 <li>Custom HTTP Header support</li> 
 <li>Persistent Connections support</li> 
 <li>FTP/SFTP through HTTP Proxy</li> 
 <li>Download/Upload speed throttling</li> 
 <li>BitTorrent extensions: Fast extension, DHT, PEX, MSE/PSE, Multi-Tracker, UDP tracker</li> 
 <li>BitTorrent <code>WEB-Seeding &lt;http://getright.com/seedtorrent.html&gt;</code>_. aria2 requests chunk more than piece size to reduce the request overhead. It also supports pipelined requests with piece size.</li> 
 <li>BitTorrent Local Peer Discovery</li> 
 <li>Rename/change the directory structure of BitTorrent downloads completely</li> 
 <li>JSON-RPC (over HTTP and WebSocket)/XML-RPC interface</li> 
 <li>Run as a daemon process</li> 
 <li>Selective download in multi-file torrent/Metalink</li> 
 <li>Chunk checksum validation in Metalink</li> 
 <li>Can disable segmented downloading in Metalink</li> 
 <li>Netrc support</li> 
 <li>Configuration file support</li> 
 <li>Download URIs found in a text file or stdin and the destination directory and output file name can be specified optionally</li> 
 <li>Parameterized URI support</li> 
 <li>IPv6 support with Happy Eyeballs</li> 
 <li>Disk cache to reduce disk activity</li> 
</ul> 
<h2>Versioning and release schedule</h2> 
<p>We use 3 numbers for the aria2 version: MAJOR.MINOR.PATCH. We will ship MINOR updates on the 15th of every month. We may skip a release if we have had no changes since the last release. The feature and documentation freeze happens 10 days before the release day (the 5th day of the month) for translation teams. We will raise an issue about the upcoming release around that day.</p> 
<p>We may release PATCH releases between regular releases if we have security issues.</p> 
<p>The MAJOR version will stay at 1 for the time being.</p> 
<h2>How to get source code</h2> 
<p>We maintain the source code at Github: <a href="https://github.com/aria2/aria2">https://github.com/aria2/aria2</a></p> 
<p>To get the latest source code, run the following command::</p> 
<pre><code>$ git clone https://github.com/aria2/aria2.git
</code></pre> 
<p>This will create an aria2 directory in your current directory and source files are stored there.</p> 
<h2>Dependency</h2> 
<p>======================== ======================================== features dependency ======================== ======================================== HTTPS OSX or GnuTLS or OpenSSL or Windows SFTP libssh2 BitTorrent None. Optional: libnettle+libgmp or libgcrypt or OpenSSL (see note) Metalink libxml2 or Expat. Checksum None. Optional: OSX or libnettle or libgcrypt or OpenSSL or Windows (see note) gzip, deflate in HTTP zlib Async DNS C-Ares Firefox3/Chromium cookie libsqlite3 XML-RPC libxml2 or Expat. JSON-RPC over WebSocket libnettle or libgcrypt or OpenSSL ======================== ========================================</p> 
<p>.. note::</p> 
<p>libxml2 has precedence over Expat if both libraries are installed. If you prefer Expat, run configure with <code>--without-libxml2</code>.</p> 
<p>.. note::</p> 
<p>On Apple OSX, OS-level SSL/TLS support will be preferred. Hence neither GnuTLS nor OpenSSL is required on that platform. If you'd like to disable this behavior, run configure with <code>--without-appletls</code>.</p> 
<p>GnuTLS has precedence over OpenSSL if both libraries are installed. If you prefer OpenSSL, run configure with <code>--without-gnutls</code> <code>--with-openssl</code>.</p> 
<p>On Windows, there is SSL implementation available that is based on the native Windows SSL capabilities (Schannel) and it will be preferred. Hence neither GnuTLS nor OpenSSL is required on that platform. If you'd like to disable this behavior, run configure with <code>--without-wintls</code>.</p> 
<p>.. note::</p> 
<p>On Apple OSX, the OS-level checksum support will be preferred, unless aria2 is configured with <code>--without-appletls</code>.</p> 
<p>libnettle has precedence over libgcrypt if both libraries are installed. If you prefer libgcrypt, run configure with <code>--without-libnettle --with-libgcrypt</code>. If OpenSSL is selected over GnuTLS, neither libnettle nor libgcrypt will be used.</p> 
<p>If none of the optional dependencies are installed, an internal implementation that only supports md5 and sha1 will be used.</p> 
<p>On Windows, there is SSL implementation available that is based on the native Windows capabilities and it will be preferred, unless aria2 is configured with <code>--without-wintls</code>.</p> 
<p>A user can have one of the following configurations for SSL and crypto libraries:</p> 
<ul> 
 <li>OpenSSL</li> 
 <li>GnuTLS + libgcrypt</li> 
 <li>GnuTLS + libnettle</li> 
 <li>Apple TLS (OSX only)</li> 
 <li>Windows TLS (Windows only)</li> 
</ul> 
<p>You can disable BitTorrent and Metalink support by providing <code>--disable-bittorrent</code> and <code>--disable-metalink</code> to the configure script respectively.</p> 
<p>To enable async DNS support, you need c-ares.</p> 
<ul> 
 <li>c-ares: <a href="http://c-ares.haxx.se/">http://c-ares.haxx.se/</a></li> 
</ul> 
<h2>How to build</h2> 
<p>aria2 is primarily written in C++. Initially, it was written based on C++98/C++03 standard features. We are now migrating aria2 to the C++11 standard. The current source code requires a C++11 aware compiler. For well-known compilers, such as g++ and clang, the <code>-std=c++11</code> or <code>-std=c++0x</code> flag must be supported.</p> 
<p>To build aria2 from the source package, you need the following development packages (package name may vary depending on the distribution you use):</p> 
<ul> 
 <li>libgnutls-dev (Required for HTTPS, BitTorrent, Checksum support)</li> 
 <li>nettle-dev (Required for BitTorrent, Checksum support)</li> 
 <li>libgmp-dev (Required for BitTorrent)</li> 
 <li>libssh2-1-dev (Required for SFTP support)</li> 
 <li>libc-ares-dev (Required for async DNS support)</li> 
 <li>libxml2-dev (Required for Metalink support)</li> 
 <li>zlib1g-dev (Required for gzip, deflate decoding support in HTTP)</li> 
 <li>libsqlite3-dev (Required for Firefox3/Chromium cookie support)</li> 
 <li>pkg-config (Required to detect installed libraries)</li> 
</ul> 
<p>You can use libgcrypt-dev instead of nettle-dev and libgmp-dev:</p> 
<ul> 
 <li>libgpg-error-dev (Required for BitTorrent, Checksum support)</li> 
 <li>libgcrypt-dev (Required for BitTorrent, Checksum support)</li> 
</ul> 
<p>You can use libssl-dev instead of libgnutls-dev, nettle-dev, libgmp-dev, libgpg-error-dev and libgcrypt-dev:</p> 
<ul> 
 <li>libssl-dev (Required for HTTPS, BitTorrent, Checksum support)</li> 
</ul> 
<p>You can use libexpat1-dev instead of libxml2-dev:</p> 
<ul> 
 <li>libexpat1-dev (Required for Metalink support)</li> 
</ul> 
<p>On Fedora you need the following packages: gcc, gcc-c++, kernel-devel, libgcrypt-devel, libxml2-devel, openssl-devel, gettext-devel, cppunit</p> 
<p>If you downloaded source code from a git repository, you have to install the following packages to get autoconf macros:</p> 
<ul> 
 <li>libxml2-dev</li> 
 <li>libcppunit-dev</li> 
 <li>autoconf</li> 
 <li>automake</li> 
 <li>autotools-dev</li> 
 <li>autopoint</li> 
 <li>libtool</li> 
</ul> 
<p>And run the following command to generate configure script and other files necessary to build the program::</p> 
<pre><code>$ autoreconf -i
</code></pre> 
<p>Also, you need <code>Sphinx &lt;http://sphinx-doc.org/&gt;</code>_ to build the man page.</p> 
<p>If you are building aria2 for Mac OS X, take a look at the makerelease-osx.mk GNU Make makefile.</p> 
<p>The quickest way to build aria2 is first to run configure script::</p> 
<pre><code>$ ./configure
</code></pre> 
<p>To build statically linked aria2, use <code>ARIA2_STATIC=yes</code> command-line option::</p> 
<pre><code>$ ./configure ARIA2_STATIC=yes
</code></pre> 
<p>After configuration is done, run <code>make</code> to compile the program::</p> 
<pre><code>$ make
</code></pre> 
<p>See <code>Cross-compiling Windows binary</code>_ to create a Windows binary. See <code>Cross-compiling Android binary</code>_ to create an Android binary.</p> 
<p>The configure script checks available libraries and enables as many features as possible except for experimental features not enabled by default.</p> 
<p>Since 1.1.0, aria2 checks the certificate of HTTPS servers by default. If you build with OpenSSL or the recent version of GnuTLS which has <code>gnutls_certificate_set_x509_system_trust()</code> function and the library is properly configured to locate the system-wide CA certificates store, aria2 will automatically load those certificates at the startup. If it is not the case, I recommend supplying the path to the CA bundle file. For example, in Debian the path to CA bundle file is '/etc/ssl/certs/ca-certificates.crt' (in ca-certificates package). This may vary depending on your distribution. You can give it to configure script using <code>--with-ca-bundle option</code>::</p> 
<pre><code>$ ./configure --with-ca-bundle='/etc/ssl/certs/ca-certificates.crt'
$ make
</code></pre> 
<p>Without <code>--with-ca-bundle</code> option, you will encounter the error when accessing HTTPS servers because the certificate cannot be verified without the CA bundle. In such a case, you can specify the CA bundle file using aria2's <code>--ca-certificate</code> option. If you don't have the CA bundle file installed, then the last resort is to disable the certificate validation using <code>--check-certificate=false</code>.</p> 
<p>Using the native OSX (AppleTLS) and/or Windows (WinTLS) implementation will automatically use the system certificate store, so <code>--with-ca-bundle</code> is not necessary and will be ignored when using these implementations.</p> 
<p>By default, the bash_completion file named <code>aria2c</code> is installed to the directory <code>$prefix/share/doc/aria2/bash_completion</code>. To change the install directory of the file, use <code>--with-bashcompletiondir</code> option.</p> 
<p>After a <code>make</code>, the executable is located at <code>src/aria2c</code>.</p> 
<p>aria2 uses CppUnit for automated unit testing. To run the unit test::</p> 
<pre><code>$ make check
</code></pre> 
<h2>Cross-compiling Windows binary</h2> 
<p>In this section, we describe how to build a Windows binary using a mingw-w64 (<a href="http://mingw-w64.org/doku.php">http://mingw-w64.org/doku.php</a>) cross-compiler on Debian Linux. The MinGW (<a href="http://www.mingw.org/">http://www.mingw.org/</a>) may not be able to build aria2.</p> 
<p>The easiest way to build Windows binary is using Dockerfile.mingw. See Dockerfile.mingw how to build a binary. If you cannot use Dockerfile, then continue to read the following paragraphs.</p> 
<p>Basically, after compiling and installing depended libraries, you can do cross-compile just passing appropriate <code>--host</code> option and specifying <code>CPPFLAGS</code>, <code>LDFLAGS</code>, and <code>PKG_CONFIG_LIBDIR</code> variables to configure. For convenience and to lower our own development cost, we provide an easier way to configure the build settings.</p> 
<p><code>mingw-config</code> script is a configure script wrapper for mingw-w64. We use it to create official Windows build. This script assumes the following libraries have been built for cross-compile:</p> 
<ul> 
 <li>c-ares</li> 
 <li>expat</li> 
 <li>sqlite3</li> 
 <li>zlib</li> 
 <li>libssh2</li> 
 <li>cppunit</li> 
</ul> 
<p>Some environment variables can be adjusted to change build settings:</p> 
<p><code>HOST</code> cross-compile to build programs to run on <code>HOST</code>. It defaults to <code>i686-w64-mingw32</code>. To build a 64bit binary, specify <code>x86_64-w64-mingw32</code>.</p> 
<p><code>PREFIX</code> Prefix to the directory where dependent libraries are installed. It defaults to <code>/usr/local/$HOST</code>. <code>-I$PREFIX/include</code> will be added to <code>CPPFLAGS</code>. <code>-L$PREFIX/lib</code> will be added to <code>LDFLAGS</code>. <code>$PREFIX/lib/pkgconfig</code> will be set to <code>PKG_CONFIG_LIBDIR</code>.</p> 
<p>For example, to build a 64bit binary do this::</p> 
<pre><code>$ HOST=x86_64-w64-mingw32 ./mingw-config
</code></pre> 
<p>If you want libaria2 dll with <code>--enable-libaria2</code>, then don't use <code>ARIA2_STATIC=yes</code> and prepare the DLL version of external libraries.</p> 
<h2>Cross-compiling Android binary</h2> 
<p>In this section, we describe how to build Android binary using Android NDK cross-compiler on Debian Linux.</p> 
<p>At the time of this writing, Android NDK r21e should compile aria2 without errors.</p> 
<p><code>android-config</code> script is a configure script wrapper for Android build. We use it to create an official Android build. This script assumes the following libraries have been built for cross-compile:</p> 
<ul> 
 <li>c-ares</li> 
 <li>openssl</li> 
 <li>expat</li> 
 <li>zlib</li> 
 <li>libssh2</li> 
</ul> 
<p>When building the above libraries, make sure that disable shared library and enable only static library. We are going to link those libraries statically.</p> 
<p><code>android-config</code> assumes that <code>$ANDROID_HOME</code> and <code>$NDK</code> environment variables are defined.</p> 
<p>We currently use Android NDK r21e. <code>$NDK</code> should point to the directory to Android NDK. The build tools will be found under <code>$NDK/toolchains/llvm/prebuilt/linux-x86_64/bin/</code>.</p> 
<p>All the dependent libraries must be installed under <code>$ANDROID_HOME/usr/local</code>.</p> 
<p>After <code>android-config</code>, run <code>make</code> to compile sources.</p> 
<h2>Building documentation</h2> 
<p><code>Sphinx &lt;http://sphinx-doc.org/&gt;</code>_ is used to building the documentation. aria2 man pages will be build when you run <code>make</code> if they are not up-to-date. You can also build an HTML version of the aria2 man page by <code>make html</code>. The HTML version manual is also available <code>online &lt;https://aria2.github.io/manual/en/html/&gt;</code>_ (<code>Russian translation &lt;https://aria2.github.io/manual/ru/html/&gt;</code><em>, <code>Portuguese translation &lt;https://aria2.github.io/manual/pt/html/&gt;</code></em>).</p> 
<h2>BitTorrent</h2> 
<p>About file names</p> 
<pre><code>The file name of the downloaded file is determined as follows:

single-file mode
    If "name" key is present in .torrent file, the file name is the value
    of "name" key. Otherwise, the file name is the base name of .torrent
    file appended by ".file". For example, .torrent file is
    "test.torrent", then file name is "test.torrent.file".  The
    directory to store the downloaded file can be specified by -d
    option.

multi-file mode
    The complete directory/file structure mentioned in .torrent file
    is created.  The directory to store the top directory of
    downloaded files can be specified by -d option.

Before download starts, a complete directory structure is created if
needed. By default, aria2 opens at most 100 files mentioned in
.torrent file, and directly writes to and reads from these files.
The number of files to open simultaneously can be controlled by
``--bt-max-open-files`` option.

DHT
~~~

aria2 supports mainline compatible DHT. By default, the routing table
for IPv4 DHT is saved to ``$XDG_CACHE_HOME/aria2/dht.dat`` and the
routing table for IPv6 DHT is saved to
``$XDG_CACHE_HOME/aria2/dht6.dat`` unless files exist at
``$HOME/.aria2/dht.dat`` or ``$HOME/.aria2/dht6.dat``. aria2 uses the
same port number to listen on for both IPv4 and IPv6 DHT.

UDP tracker
~~~~~~~~~~~

UDP tracker support is enabled when IPv4 DHT is enabled.  The port
number of the UDP tracker is shared with DHT. Use ``--dht-listen-port``
option to change the port number.

Other things should be noted
</code></pre> 
<ul> 
 <li><code>-o</code> option is used to change the file name of .torrent file itself, not a file name of a file in .torrent file. For this purpose, use <code>--index-out</code> option instead.</li> 
 <li>The port numbers that aria2 uses by default are 6881-6999 for TCP and UDP.</li> 
 <li>aria2 doesn't configure port-forwarding automatically. Please configure your router or firewall manually.</li> 
 <li>The maximum number of peers is 55. This limit may be exceeded when the download rate is low. This download rate can be adjusted using <code>--bt-request-peer-speed-limit</code> option.</li> 
 <li>As of release 0.10.0, aria2 stops sending request messages after selective download completes.</li> 
</ul> 
<h2>Metalink</h2> 
<p>The current implementation supports HTTP(S)/FTP/SFTP/BitTorrent. The other P2P protocols are ignored. Both Metalink4 (RFC 5854) and Metalink version 3.0 documents are supported.</p> 
<p>For checksum verification, md5, sha-1, sha-224, sha-256, sha-384, and sha-512 are supported. If multiple hash algorithms are provided, aria2 uses a stronger one. If whole file checksum verification fails, aria2 doesn't retry the download and just exits with a non-zero return code.</p> 
<p>The supported user preferences are version, language, location, protocol, and os.</p> 
<p>If chunk checksums are provided in the Metalink file, aria2 automatically validates chunks of data during download. This behavior can be turned off by a command-line option.</p> 
<p>If a signature is included in a Metalink file, aria2 saves it as a file after the completion of the download. The file name is download file name + ".sig". If the same file already exists, the signature file is not saved.</p> 
<p>In Metalink4, a multi-file torrent could appear in metalink:metaurl element. Since aria2 cannot download 2 same torrents at the same time, aria2 groups files in metalink:file element which has the same BitTorrent metaurl, and downloads them from a single BitTorrent swarm. This is a basically multi-file torrent download with file selection, so the adjacent files which are not in Metalink document but share the same piece with the selected file are also created.</p> 
<p>If relative URI is specified in metalink:url or metalink:metaurl element, aria2 uses the URI of Metalink file as base URI to resolve the relative URI. If relative URI is found in the Metalink file which is read from the local disk, aria2 uses the value of <code>--metalink-base-uri</code> option as base URI. If this option is not specified, the relative URI will be ignored.</p> 
<h2>Metalink/HTTP</h2> 
<p>The current implementation only uses rel=duplicate links. aria2 understands Digest header fields and check whether it matches the digest value from other sources. If it differs, drop the connection. aria2 also uses this digest value to perform checksum verification after the download is finished. aria2 recognizes geo value. To tell aria2 which location you prefer, you can use <code>--metalink-location</code> option.</p> 
<h2>netrc</h2> 
<p>netrc support is enabled by default for HTTP(S)/FTP/SFTP. To disable netrc support, specify -n command-line option. Your .netrc file should have correct permissions(600).</p> 
<h2>WebSocket</h2> 
<p>The WebSocket server embedded in aria2 implements the specification defined in RFC 6455. The supported protocol version is 13.</p> 
<h2>libaria2</h2> 
<p>The libaria2 is a C++ library that offers aria2 functionality to the client code. Currently, libaria2 is not built by default. To enable libaria2, use <code>--enable-libaria2</code> configure option. By default, only the shared library is built. To build a static library, use <code>--enable-static</code> configure option as well. See libaria2 documentation to know how to use API.</p> 
<h2>References</h2> 
<ul> 
 <li> <p><code>aria2 Online Manual &lt;https://aria2.github.io/manual/en/html/&gt;</code>_</p> </li> 
 <li> <p><a href="https://aria2.github.io/">https://aria2.github.io/</a></p> </li> 
 <li> <p><code>RFC 959 FILE TRANSFER PROTOCOL (FTP) &lt;http://tools.ietf.org/html/rfc959&gt;</code>_</p> </li> 
 <li> <p><code>RFC 1738 Uniform Resource Locators (URL) &lt;http://tools.ietf.org/html/rfc1738&gt;</code>_</p> </li> 
 <li> <p><code>RFC 2428 FTP Extensions for IPv6 and NATs &lt;http://tools.ietf.org/html/rfc2428&gt;</code>_</p> </li> 
 <li> <p><code>RFC 2616 Hypertext Transfer Protocol -- HTTP/1.1 &lt;http://tools.ietf.org/html/rfc2616&gt;</code>_</p> </li> 
 <li> <p><code>RFC 3659 Extensions to FTP &lt;http://tools.ietf.org/html/rfc3659&gt;</code>_</p> </li> 
 <li> <p><code>RFC 3986 Uniform Resource Identifier (URI): Generic Syntax &lt;http://tools.ietf.org/html/rfc3986&gt;</code>_</p> </li> 
 <li> <p><code>RFC 4038 Application Aspects of IPv6 Transition &lt;http://tools.ietf.org/html/rfc4038&gt;</code>_</p> </li> 
 <li> <p><code>RFC 5854 The Metalink Download Description Format &lt;http://tools.ietf.org/html/rfc5854&gt;</code>_</p> </li> 
 <li> <p><code>RFC 6249 Metalink/HTTP: Mirrors and Hashes &lt;http://tools.ietf.org/html/rfc6249&gt;</code>_</p> </li> 
 <li> <p><code>RFC 6265 HTTP State Management Mechanism &lt;http://tools.ietf.org/html/rfc6265&gt;</code>_</p> </li> 
 <li> <p><code>RFC 6266 Use of the Content-Disposition Header Field in the Hypertext Transfer Protocol (HTTP) &lt;http://tools.ietf.org/html/rfc6266&gt;</code>_</p> </li> 
 <li> <p><code>RFC 6455 The WebSocket Protocol &lt;http://tools.ietf.org/html/rfc6455&gt;</code>_</p> </li> 
 <li> <p><code>RFC 6555 Happy Eyeballs: Success with Dual-Stack Hosts &lt;http://tools.ietf.org/html/rfc6555&gt;</code>_</p> </li> 
 <li> <p><code>The BitTorrent Protocol Specification &lt;http://www.bittorrent.org/beps/bep_0003.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: DHT Protocol &lt;http://www.bittorrent.org/beps/bep_0005.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: Fast Extension &lt;http://www.bittorrent.org/beps/bep_0006.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: IPv6 Tracker Extension &lt;http://www.bittorrent.org/beps/bep_0007.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: Extension for Peers to Send Metadata Files &lt;http://www.bittorrent.org/beps/bep_0009.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: Extension Protocol &lt;http://www.bittorrent.org/beps/bep_0010.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: Multitracker Metadata Extension &lt;http://www.bittorrent.org/beps/bep_0012.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: UDP Tracker Protocol for BitTorrent &lt;http://www.bittorrent.org/beps/bep_0015.html&gt;</code>_ and <code>BitTorrent udp-tracker protocol specification &lt;http://www.rasterbar.com/products/libtorrent/udp_tracker_protocol.html&gt;</code>_.</p> </li> 
 <li> <p><code>BitTorrent: WebSeed - HTTP/FTP Seeding (GetRight style) &lt;http://www.bittorrent.org/beps/bep_0019.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: Private Torrents &lt;http://www.bittorrent.org/beps/bep_0027.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: BitTorrent DHT Extensions for IPv6 &lt;http://www.bittorrent.org/beps/bep_0032.html&gt;</code>_</p> </li> 
 <li> <p><code>BitTorrent: Message Stream Encryption &lt;http://wiki.vuze.com/w/Message_Stream_Encryption&gt;</code>_</p> </li> 
 <li> <p><code>Kademlia: A Peer-to-peer Information System Based on the XOR Metric &lt;https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf&gt;</code>_</p> </li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>toss/es-toolkit</title>
<link>https://github.com/toss/es-toolkit</link>
<guid>https://github.com/toss/es-toolkit</guid>
<content:encoded><![CDATA[
<div> 关键词：es-toolkit, 高性能, 小型bundle, TypeScript支持, 性能优化

总结:

es-toolkit 是一款高性能、小型体积的现代JavaScript工具库。它提供了各种实用的函数，如debounce、chunk等，旨在提升开发效率。es-toolkit在现代JavaScript环境中实现了显著的性能提升，比其他库快了2-3倍，同时体积减少了97%，这使得它成为轻量级项目和追求高效执行的理想选择。

es-toolkit还具有内置的类型注解支持，与TypeScript兼容，提供清晰且强大的类型定义。它包括有用的类型守卫，帮助开发者更好地理解数据结构。此外，es-toolkit的代码经过全面测试，拥有100%的覆盖率，确保了其稳定性和可靠性。

对于那些寻求高性能、轻量级且类型安全的JavaScript库的开发者来说，es-toolkit是一个值得考虑的选择。无论是需要处理大量数据还是希望优化代码执行速度，es-toolkit都能提供有效的解决方案。同时，es-toolkit欢迎社区成员的贡献，共同推动其发展和改进。 <div>
<p>A modern JavaScript utility library that's 2-3 times faster and up to 97% smaller—a major upgrade to lodash.</p><hr /><p><img alt="" src="https://raw.githubusercontent.com/toss/es-toolkit/main/docs/public/og.png" /></p> 
<h1>es-toolkit · <a href="https://github.com/toss/slash/raw/main/LICENSE"><img alt="MIT License" src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" /></a> <a href="https://codecov.io/gh/toss/es-toolkit"><img alt="codecov" src="https://codecov.io/gh/toss/es-toolkit/graph/badge.svg?token=8N5S3AR3C7" /></a> <a href="https://www.npmjs.com/package/es-toolkit"><img alt="NPM badge" src="https://img.shields.io/npm/v/es-toolkit?logo=npm" /></a> <a href="https://jsr.io/@es-toolkit/es-toolkit"><img alt="JSR badge" src="https://jsr.io/badges/@es-toolkit/es-toolkit" /></a></h1> 
<p>English | <a href="https://github.com/toss/es-toolkit/raw/main/README-ko_kr.md">한국어</a> | <a href="https://github.com/toss/es-toolkit/raw/main/README-zh_hans.md">简体中文</a> | <a href="https://github.com/toss/es-toolkit/raw/main/README-ja_jp.md">日本語</a></p> 
<p>es-toolkit is a state-of-the-art, high-performance JavaScript utility library with a small bundle size and strong type annotations.</p> 
<ul> 
 <li>es-toolkit offers a variety of everyday utility functions with modern implementations, such as <a href="https://es-toolkit.slash.page/reference/function/debounce.html">debounce</a>, <a href="https://es-toolkit.slash.page/reference/promise/delay.html">delay</a>, <a href="https://es-toolkit.slash.page/reference/array/chunk.html">chunk</a>, <a href="https://es-toolkit.slash.page/reference/math/sum.html">sum</a>, and <a href="https://es-toolkit.slash.page/reference/object/pick.html">pick</a>.</li> 
 <li>Designed with performance in mind, es-toolkit achieves <a href="https://es-toolkit.slash.page/performance.html">2-3× better performance</a> in modern JavaScript environments.</li> 
 <li>es-toolkit supports tree shaking out of the box, and <a href="https://es-toolkit.slash.page/bundle-size.html">reduces JavaScript code by up to 97%</a> compared to other libraries.</li> 
 <li>es-toolkit includes built-in TypeScript support, with straightforward yet robust types. It also provides useful type guards such as <a href="https://es-toolkit.slash.page/reference/predicate/isNotNil.html">isNotNil</a>.</li> 
 <li>es-toolkit is battle-tested with 100% test coverage, ensuring reliability and robustness.</li> 
</ul> 
<h2>Examples</h2> 
<pre><code class="language-tsx">// import from '@es-toolkit/es-toolkit' in jsr.
import { debounce, chunk } from 'es-toolkit';

const debouncedLog = debounce(message =&gt; {
  console.log(message);
}, 300);

// This call will be debounced
debouncedLog('Hello, world!');

const array = [1, 2, 3, 4, 5, 6];
const chunkedArray = chunk(array, 2);

console.log(chunkedArray);
// Output: [[1, 2], [3, 4], [5, 6]]
</code></pre> 
<h2>Contributing</h2> 
<p>We welcome contribution from everyone in the community. Read below for detailed contribution guide.</p> 
<p><a href="https://github.com/toss/es-toolkit/raw/main/.github/CONTRIBUTING.md">CONTRIBUTING</a></p> 
<h2>License</h2> 
<p>MIT © Viva Republica, Inc. See <a href="https://raw.githubusercontent.com/toss/es-toolkit/main/LICENSE">LICENSE</a> for details.</p> 
<a href="https://toss.im" title="Toss"> 
  
  <source media="(prefers-color-scheme: dark)" /> 
  <img alt="Toss" src="https://static.toss.im/logos/png/4x/logo-toss.png" width="100" /> 
  </a>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>comfyanonymous/ComfyUI</title>
<link>https://github.com/comfyanonymous/ComfyUI</link>
<guid>https://github.com/comfyanonymous/ComfyUI</guid>
<content:encoded><![CDATA[
<div> 关键词：ComfyUI、Stable Diffusion、GUI、API、Backend

总结：
ComfyUI 是一个强大且模块化的图形界面（GUI）、API 和后端系统，专为稳定扩散模型设计，支持用户通过流程图（Nodes/Flowchart）界面构建和执行复杂的稳定扩散工作流，无需编写代码。它支持多种稳定扩散版本，包括SD1.x、SD2.x等，并提供了异步队列系统、优化的记忆管理、GPU兼容性以及CPU模式运行等功能。ComfyUI 可以加载ckpt、safetensors、diffusers模型和独立VAE、CLIP模型，并支持嵌入式文本反转等高级功能。此外，用户可以使用ComfyUI加载和保存完整的工作流程，创建自定义节点进行高级操作，如图像生成或修复等。系统还提供了快捷键支持，增强用户体验。用户可以通过命令行安装ComfyUI，并根据自己的硬件环境（如AMD、NVIDIA GPU或Intel GPU）进行相应的配置。对于Mac用户，提供了一个特定的指南来安装和运行ComfyUI。在使用过程中，用户需要注意模型路径设置、依赖安装和一些特定硬件的兼容性问题。为了提高预览质量，用户可以启用自动预览方法或手动安装额外的模型。同时，ComfyUI支持TLS/SSL加密以增强安全性。最后，前端的更新和维护被转移到了单独的仓库中，以便于开发者管理和用户报告前端相关的问题。 <div>
<p>The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.</p><hr /><div align="center"> 
 <h1>ComfyUI</h1> 
 <p><strong>The most powerful and modular stable diffusion GUI and backend.</strong></p> 
 <p><a href="https://www.comfy.org/"><img alt="Website" src="https://img.shields.io/badge/ComfyOrg-4285F4?style=flat" /></a> <a href="https://www.comfy.org/discord"><img alt="Dynamic JSON Badge" src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;logo=discord&amp;logoColor=white&amp;label=Discord&amp;color=green&amp;suffix=%20total" /></a> <a href="https://app.element.io/#/room/%23comfyui_space%3Amatrix.org"><img alt="Matrix" src="https://img.shields.io/badge/Matrix-000000?style=flat&amp;logo=matrix&amp;logoColor=white" /></a> <br /> <a href="https://github.com/comfyanonymous/ComfyUI/releases"><img alt="" src="https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&amp;sort=semver" /></a> <a href="https://github.com/comfyanonymous/ComfyUI/releases"><img alt="" src="https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat" /></a> <a href="https://github.com/comfyanonymous/ComfyUI/releases"><img alt="" src="https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat" /></a> <a href="https://github.com/comfyanonymous/ComfyUI/releases"><img alt="" src="https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&amp;label=downloads%40latest" /></a></p> 
 <!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 --> 
 <p><img alt="ComfyUI Screenshot" src="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/comfyui_screenshot.png" /></p> 
</div> 
<p>This ui will let you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. For some workflow examples and see what ComfyUI can do you can check out:</p> 
<h3><a href="https://comfyanonymous.github.io/ComfyUI_examples/">ComfyUI Examples</a></h3> 
<h3><a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#installing">Installing ComfyUI</a></h3> 
<h2>Features</h2> 
<ul> 
 <li>Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.</li> 
 <li>Fully supports SD1.x, SD2.x, <a href="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/">SDXL</a>, <a href="https://comfyanonymous.github.io/ComfyUI_examples/video/">Stable Video Diffusion</a>, <a href="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/">Stable Cascade</a>, <a href="https://comfyanonymous.github.io/ComfyUI_examples/sd3/">SD3</a> and <a href="https://comfyanonymous.github.io/ComfyUI_examples/audio/">Stable Audio</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/flux/">Flux</a></li> 
 <li>Asynchronous Queue system</li> 
 <li>Many optimizations: Only re-executes the parts of the workflow that changes between executions.</li> 
 <li>Smart memory management: can automatically run models on GPUs with as low as 1GB vram.</li> 
 <li>Works even if you don't have a GPU with: <code>--cpu</code> (slow)</li> 
 <li>Can load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs and CLIP models.</li> 
 <li>Embeddings/Textual inversion</li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/lora/">Loras (regular, locon and loha)</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/">Hypernetworks</a></li> 
 <li>Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.</li> 
 <li>Saving/Loading workflows as Json files.</li> 
 <li>Nodes interface can be used to create complex workflows like one for <a href="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/">Hires fix</a> or much more advanced ones.</li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/">Area Composition</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/">Inpainting</a> with both regular and inpainting models.</li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/">ControlNet and T2I-Adapter</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/">Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/unclip/">unCLIP Models</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/gligen/">GLIGEN</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/">Model Merging</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/lcm/">LCM models and Loras</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/">SDXL Turbo</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/">AuraFlow</a></li> 
 <li><a href="https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/">HunyuanDiT</a></li> 
 <li>Latent previews with <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#how-to-show-high-quality-previews">TAESD</a></li> 
 <li>Starts up very fast.</li> 
 <li>Works fully offline: will never download anything.</li> 
 <li><a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/extra_model_paths.yaml.example">Config file</a> to set the search paths for models.</li> 
</ul> 
<p>Workflow examples can be found on the <a href="https://comfyanonymous.github.io/ComfyUI_examples/">Examples page</a></p> 
<h2>Shortcuts</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Keybind</th> 
   <th>Explanation</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>Ctrl + Enter</td> 
   <td>Queue up current graph for generation</td> 
  </tr> 
  <tr> 
   <td>Ctrl + Shift + Enter</td> 
   <td>Queue up current graph as first for generation</td> 
  </tr> 
  <tr> 
   <td>Ctrl + Alt + Enter</td> 
   <td>Cancel current generation</td> 
  </tr> 
  <tr> 
   <td>Ctrl + Z/Ctrl + Y</td> 
   <td>Undo/Redo</td> 
  </tr> 
  <tr> 
   <td>Ctrl + S</td> 
   <td>Save workflow</td> 
  </tr> 
  <tr> 
   <td>Ctrl + O</td> 
   <td>Load workflow</td> 
  </tr> 
  <tr> 
   <td>Ctrl + A</td> 
   <td>Select all nodes</td> 
  </tr> 
  <tr> 
   <td>Alt + C</td> 
   <td>Collapse/uncollapse selected nodes</td> 
  </tr> 
  <tr> 
   <td>Ctrl + M</td> 
   <td>Mute/unmute selected nodes</td> 
  </tr> 
  <tr> 
   <td>Ctrl + B</td> 
   <td>Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)</td> 
  </tr> 
  <tr> 
   <td>Delete/Backspace</td> 
   <td>Delete selected nodes</td> 
  </tr> 
  <tr> 
   <td>Ctrl + Backspace</td> 
   <td>Delete the current graph</td> 
  </tr> 
  <tr> 
   <td>Space</td> 
   <td>Move the canvas around when held and moving the cursor</td> 
  </tr> 
  <tr> 
   <td>Ctrl/Shift + Click</td> 
   <td>Add clicked node to selection</td> 
  </tr> 
  <tr> 
   <td>Ctrl + C/Ctrl + V</td> 
   <td>Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)</td> 
  </tr> 
  <tr> 
   <td>Ctrl + C/Ctrl + Shift + V</td> 
   <td>Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes)</td> 
  </tr> 
  <tr> 
   <td>Shift + Drag</td> 
   <td>Move multiple selected nodes at the same time</td> 
  </tr> 
  <tr> 
   <td>Ctrl + D</td> 
   <td>Load default graph</td> 
  </tr> 
  <tr> 
   <td>Alt + <code>+</code></td> 
   <td>Canvas Zoom in</td> 
  </tr> 
  <tr> 
   <td>Alt + <code>-</code></td> 
   <td>Canvas Zoom out</td> 
  </tr> 
  <tr> 
   <td>Ctrl + Shift + LMB + Vertical drag</td> 
   <td>Canvas Zoom in/out</td> 
  </tr> 
  <tr> 
   <td>Q</td> 
   <td>Toggle visibility of the queue</td> 
  </tr> 
  <tr> 
   <td>H</td> 
   <td>Toggle visibility of history</td> 
  </tr> 
  <tr> 
   <td>R</td> 
   <td>Refresh graph</td> 
  </tr> 
  <tr> 
   <td>Double-Click LMB</td> 
   <td>Open node quick search palette</td> 
  </tr> 
  <tr> 
   <td>Shift + Drag</td> 
   <td>Move multiple wires at once</td> 
  </tr> 
  <tr> 
   <td>Ctrl + Alt + LMB</td> 
   <td>Disconnect all wires from clicked slot</td> 
  </tr> 
 </tbody> 
</table> 
<p>Ctrl can also be replaced with Cmd instead for macOS users</p> 
<h1>Installing</h1> 
<h2>Windows</h2> 
<p>There is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the <a href="https://github.com/comfyanonymous/ComfyUI/releases">releases page</a>.</p> 
<h3><a href="https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z">Direct link to download</a></h3> 
<p>Simply download, extract with <a href="https://7-zip.org">7-Zip</a> and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\models\checkpoints</p> 
<p>If you have trouble extracting it, right click the file -&gt; properties -&gt; unblock</p> 
<h4>How do I share models between another UI and ComfyUI?</h4> 
<p>See the <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/extra_model_paths.yaml.example">Config file</a> to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.</p> 
<h2>Jupyter Notebook</h2> 
<p>To run it on services like paperspace, kaggle or colab you can use my <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/notebooks/comfyui_colab.ipynb">Jupyter Notebook</a></p> 
<h2>Manual Install (Windows, Linux)</h2> 
<p>Git clone this repo.</p> 
<p>Put your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints</p> 
<p>Put your VAE in: models/vae</p> 
<h3>AMD GPUs (Linux only)</h3> 
<p>AMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:</p> 
<p><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.0</code></p> 
<p>This is the command to install the nightly with ROCm 6.0 which might have some performance improvements:</p> 
<p><code>pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.1</code></p> 
<h3>NVIDIA</h3> 
<p>Nvidia users should install stable pytorch using this command:</p> 
<p><code>pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121</code></p> 
<p>This is the command to install pytorch nightly instead which might have performance improvements:</p> 
<p><code>pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu124</code></p> 
<h4>Troubleshooting</h4> 
<p>If you get the "Torch not compiled with CUDA enabled" error, uninstall torch with:</p> 
<p><code>pip uninstall torch</code></p> 
<p>And install it again with the command above.</p> 
<h3>Dependencies</h3> 
<p>Install the dependencies by opening your terminal inside the ComfyUI folder and:</p> 
<p><code>pip install -r requirements.txt</code></p> 
<p>After this you should have everything installed and can proceed to running ComfyUI.</p> 
<h3>Others:</h3> 
<h4>Intel GPUs</h4> 
<p>Intel GPU support is available for all Intel GPUs supported by Intel's Extension for Pytorch (IPEX) with the support requirements listed in the <a href="https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu">Installation</a> page. Choose your platform and method of install and follow the instructions. The steps are as follows:</p> 
<ol> 
 <li>Start by installing the drivers or kernel listed or newer in the Installation page of IPEX linked above for Windows and Linux if needed.</li> 
 <li>Follow the instructions to install <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html">Intel's oneAPI Basekit</a> for your platform.</li> 
 <li>Install the packages for IPEX using the instructions provided in the Installation page for your platform.</li> 
 <li>Follow the <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux">ComfyUI manual installation</a> instructions for Windows and Linux and run ComfyUI normally as described above after everything is installed.</li> 
</ol> 
<p>Additional discussion and help can be found <a href="https://github.com/comfyanonymous/ComfyUI/discussions/476">here</a>.</p> 
<h4>Apple Mac silicon</h4> 
<p>You can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.</p> 
<ol> 
 <li>Install pytorch nightly. For instructions, read the <a href="https://developer.apple.com/metal/pytorch/">Accelerated PyTorch training on Mac</a> Apple Developer guide (make sure to install the latest pytorch nightly).</li> 
 <li>Follow the <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux">ComfyUI manual installation</a> instructions for Windows and Linux.</li> 
 <li>Install the ComfyUI <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#dependencies">dependencies</a>. If you have another Stable Diffusion UI <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies">you might be able to reuse the dependencies</a>.</li> 
 <li>Launch ComfyUI by running <code>python main.py</code></li> 
</ol> 
<blockquote> 
 <p><strong>Note</strong>: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in <a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux">ComfyUI manual installation</a>.</p> 
</blockquote> 
<h4>DirectML (AMD Cards on Windows)</h4> 
<p><code>pip install torch-directml</code> Then you can launch ComfyUI with: <code>python main.py --directml</code></p> 
<h1>Running</h1> 
<p><code>python main.py</code></p> 
<h3>For AMD cards not officially supported by ROCm</h3> 
<p>Try running it with this command if you have issues:</p> 
<p>For 6700, 6600 and maybe other RDNA2 or older: <code>HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py</code></p> 
<p>For AMD 7600 and maybe other RDNA3 cards: <code>HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py</code></p> 
<h1>Notes</h1> 
<p>Only parts of the graph that have an output with all the correct inputs will be executed.</p> 
<p>Only parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.</p> 
<p>Dragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.</p> 
<p>You can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \( or \).</p> 
<p>You can use {day|night}, for wildcard/dynamic prompts. With this syntax "{wild|card|test}" will be randomly replaced by either "wild", "card" or "test" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \{ or \}.</p> 
<p>Dynamic prompts also support C-style comments, like <code>// comment</code> or <code>/* comment */</code>.</p> 
<p>To use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):</p> 
<p><code>embedding:embedding_filename.pt</code></p> 
<h2>How to show high-quality previews?</h2> 
<p>Use <code>--preview-method auto</code> to enable previews.</p> 
<p>The default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with <a href="https://github.com/madebyollin/taesd">TAESD</a>, download the <a href="https://github.com/madebyollin/taesd/raw/main/taesd_decoder.pth">taesd_decoder.pth</a> (for SD1.x and SD2.x) and <a href="https://github.com/madebyollin/taesd/raw/main/taesdxl_decoder.pth">taesdxl_decoder.pth</a> (for SDXL) models and place them in the <code>models/vae_approx</code> folder. Once they're installed, restart ComfyUI to enable high-quality previews.</p> 
<h2>How to use TLS/SSL?</h2> 
<p>Generate a self-signed certificate (not appropriate for shared/production use) and key by running the command: <code>openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj "/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname"</code></p> 
<p>Use <code>--tls-keyfile key.pem --tls-certfile cert.pem</code> to enable TLS/SSL, the app will now be accessible with <code>https://...</code> instead of <code>http://...</code>.</p> 
<blockquote> 
 <p>Note: Windows users can use <a href="https://github.com/alexisrolland/docker-openssl">alexisrolland/docker-openssl</a> or one of the <a href="https://wiki.openssl.org/index.php/Binaries">3rd party binary distributions</a> to run the command example above. <br /><br />If you use a container, note that the volume mount <code>-v</code> can be a relative path so <code>... -v ".\:/openssl-certs" ...</code> would create the key &amp; cert files in the current directory of your command prompt or powershell terminal.</p> 
</blockquote> 
<h2>Support and dev channel</h2> 
<p><a href="https://app.element.io/#/room/%23comfyui_space%3Amatrix.org">Matrix space: #comfyui_space:matrix.org</a> (it's like discord but open source).</p> 
<p>See also: <a href="https://www.comfy.org/">https://www.comfy.org/</a></p> 
<h2>Frontend Development</h2> 
<p>As of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: <a href="https://github.com/Comfy-Org/ComfyUI_frontend">ComfyUI Frontend</a>. This repository now hosts the compiled JS (from TS/Vue) under the <code>web/</code> directory.</p> 
<h3>Reporting Issues and Requesting Features</h3> 
<p>For any bugs, issues, or feature requests related to the frontend, please use the <a href="https://github.com/Comfy-Org/ComfyUI_frontend">ComfyUI Frontend repository</a>. This will help us manage and address frontend-specific concerns more efficiently.</p> 
<h3>Using the Latest Frontend</h3> 
<p>The new frontend is now the default for ComfyUI. However, please note:</p> 
<ol> 
 <li>The frontend in the main ComfyUI repository is updated weekly.</li> 
 <li>Daily releases are available in the separate frontend repository.</li> 
</ol> 
<p>To use the most up-to-date frontend version:</p> 
<ol> 
 <li> <p>For the latest daily release, launch ComfyUI with this command line argument:</p> <pre><code>--front-end-version Comfy-Org/ComfyUI_frontend@latest
</code></pre> </li> 
 <li> <p>For a specific version, replace <code>latest</code> with the desired version number:</p> <pre><code>--front-end-version Comfy-Org/ComfyUI_frontend@1.2.2
</code></pre> </li> 
</ol> 
<p>This approach allows you to easily switch between the stable weekly release and the cutting-edge daily updates, or even specific versions for testing purposes.</p> 
<h3>Accessing the Legacy Frontend</h3> 
<p>If you need to use the legacy frontend for any reason, you can access it using the following command line argument:</p> 
<pre><code>--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest
</code></pre> 
<p>This will use a snapshot of the legacy frontend preserved in the <a href="https://github.com/Comfy-Org/ComfyUI_legacy_frontend">ComfyUI Legacy Frontend repository</a>.</p> 
<h1>QA</h1> 
<h3>Which GPU should I buy for this?</h3> 
<p><a href="https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI">See this page for some recommendations</a></p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ostris/ai-toolkit</title>
<link>https://github.com/ostris/ai-toolkit</link>
<guid>https://github.com/ostris/ai-toolkit</guid>
<content:encoded><![CDATA[
<div> 关键词：AI Toolkit、Ostris、Stable Diffusion、LoRA、FLUX.1

文章总结：

1. **AI Toolkit**：这是一个由Ostris创建的研究仓库，专注于实验各种AI模型，尤其是Stable Diffusion技术。它允许用户训练和自定义多种模型。

2. **Ostris与团队支持**：Ostris强调了他/她的工作离不开团队的支持，特别是Glif、和所有人。他/她鼓励支持团队的工作，具体方式是支持Glif。

3. **FLUX.1 Training**：FLUX.1是一个需要GPU资源进行训练的模型。对于特定配置的GPU（至少24GB VRAM），用户可以训练此模型。训练过程中需要一些技巧来适应有限的VRAM使用。

4. **许可证问题**：训练FLUX.1模型前，用户需接受许可证协议。这涉及到登录Hugging Face平台并接受访问权限。此外，还提供了一个名为“FLUX.1-schnell”的版本，其许可协议更为宽松，允许用户根据自己的需求自由使用和发布训练结果。

5. **运行和部署**：文章介绍了如何在本地或云环境中运行AI Toolkit模型。包括如何在Linux或Windows上安装环境，以及如何在RunPod云平台上设置和运行模型进行训练。

简而言之，AI Toolkit是一个用于研究和实验各种AI模型的平台，特别是Stable Diffusion相关技术。它提供了从本地到云的模型训练和部署解决方案，同时也强调了许可证管理的重要性。通过遵循文档中的指导，用户可以利用这个工具集进行创新性的AI研究和应用开发。 <div>
<p>Various AI scripts. Mostly Stable Diffusion stuff.</p><hr /><h1>AI Toolkit by Ostris</h1> 
<h2>IMPORTANT NOTE - READ THIS</h2> 
<p>This is my research repo. I do a lot of experiments in it and it is possible that I will break things. If something breaks, checkout an earlier commit. This repo can train a lot of things, and it is hard to keep up with all of them.</p> 
<h2>Support my work</h2> 
<a href="https://glif.app" target="_blank"> <img alt="glif.app" height="auto" src="https://raw.githubusercontent.com/ostris/ai-toolkit/main/assets/glif.svg?v=1" width="256" /> </a> 
<p>My work on this project would not be possible without the amazing support of <a href="https://glif.app/">Glif</a> and everyone on the team. If you want to support me, support Glif. <a href="https://glif.app/">Join the site</a>, <a href="https://discord.com/invite/nuR9zZ2nsh">Join us on Discord</a>, <a href="https://x.com/heyglif">follow us on Twitter</a> and come make some cool stuff with us</p> 
<h2>Installation</h2> 
<p>Requirements:</p> 
<ul> 
 <li>python &gt;3.10</li> 
 <li>Nvidia GPU with enough ram to do what you need</li> 
 <li>python venv</li> 
 <li>git</li> 
</ul> 
<p>Linux:</p> 
<pre><code class="language-bash">git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python3 -m venv venv
source venv/bin/activate
# .\venv\Scripts\activate on windows
# install torch first
pip3 install torch
pip3 install -r requirements.txt
</code></pre> 
<p>Windows:</p> 
<pre><code class="language-bash">git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
.\venv\Scripts\activate
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
</code></pre> 
<h2>FLUX.1 Training</h2> 
<h3>WIP. I am updating docs and optimizing as fast as I can. If there are bugs open a ticket. Not knowing how to get it to work is NOT a bug. Be paitient as I continue to develop it.</h3> 
<h3>Requirements</h3> 
<p>You currently need a GPU with <strong>at least 24GB of VRAM</strong> to train FLUX.1. If you are using it as your GPU to control your monitors, you probably need to set the flag <code>low_vram: true</code> in the config file under <code>model:</code>. This will quantize the model on CPU and should allow it to train with monitors attached. Users have gotten it to work on Windows with WSL, but there are some reports of a bug when running on windows natively. I have only tested on linux for now. This is still extremely experimental and a lot of quantizing and tricks had to happen to get it to fit on 24GB at all.</p> 
<h3>FLUX.1-dev</h3> 
<p>FLUX.1-dev has a non-commercial license. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.</p> 
<ol> 
 <li>Sign into HF and accept the model access here <a href="https://huggingface.co/black-forest-labs/FLUX.1-dev">black-forest-labs/FLUX.1-dev</a></li> 
 <li>Make a file named <code>.env</code> in the root on this folder</li> 
 <li><a href="https://huggingface.co/settings/tokens/new?">Get a READ key from huggingface</a> and add it to the <code>.env</code> file like so <code>HF_TOKEN=your_key_here</code></li> 
</ol> 
<h3>FLUX.1-schnell</h3> 
<p>FLUX.1-schnell is Apache 2.0. Anything trained on it can be licensed however you want and it does not require a HF_TOKEN to train. However, it does require a special adapter to train with it, <a href="https://huggingface.co/ostris/FLUX.1-schnell-training-adapter">ostris/FLUX.1-schnell-training-adapter</a>. It is also highly experimental. For best overall quality, training on FLUX.1-dev is recommended.</p> 
<p>To use it, You just need to add the assistant to the <code>model</code> section of your config file like so:</p> 
<pre><code class="language-yaml">      model:
        name_or_path: "black-forest-labs/FLUX.1-schnell"
        assistant_lora_path: "ostris/FLUX.1-schnell-training-adapter"
        is_flux: true
        quantize: true
</code></pre> 
<p>You also need to adjust your sample steps since schnell does not require as many</p> 
<pre><code class="language-yaml">      sample:
        guidance_scale: 1  # schnell does not do guidance
        sample_steps: 4  # 1 - 4 works well
</code></pre> 
<h3>Training</h3> 
<ol> 
 <li>Copy the example config file located at <code>config/examples/train_lora_flux_24gb.yaml</code> (<code>config/examples/train_lora_flux_schnell_24gb.yaml</code> for schnell) to the <code>config</code> folder and rename it to <code>whatever_you_want.yml</code></li> 
 <li>Edit the file following the comments in the file</li> 
 <li>Run the file like so <code>python run.py config/whatever_you_want.yml</code></li> 
</ol> 
<p>A folder with the name and the training folder from the config file will be created when you start. It will have all checkpoints and images in it. You can stop the training at any time using ctrl+c and when you resume, it will pick back up from the last checkpoint.</p> 
<p>IMPORTANT. If you press crtl+c while it is saving, it will likely corrupt that checkpoint. So wait until it is done saving</p> 
<h3>Need help?</h3> 
<p>Please do not open a bug report unless it is a bug in the code. You are welcome to <a href="https://discord.gg/SzVB3wYvxF">Join my Discord</a> and ask for help there. However, please refrain from PMing me directly with general question or support. Ask in the discord and I will answer when I can.</p> 
<h3>Training in RunPod cloud</h3> 
<p>Example RunPod template: <strong>runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04</strong></p> 
<blockquote> 
 <p>You need a minimum of 24GB VRAM, pick a GPU by your preference.</p> 
</blockquote> 
<h4>Example config ($0.5/hr):</h4> 
<ul> 
 <li>1x A40 (48 GB VRAM)</li> 
 <li>19 vCPU 100 GB RAM</li> 
</ul> 
<h4>Custom overrides (you need some storage to clone FLUX.1, store datasets, store trained models and samples):</h4> 
<ul> 
 <li>~120 GB Disk</li> 
 <li>~120 GB Pod Volume</li> 
 <li>Start Jupyter Notebook</li> 
</ul> 
<h3>1. Setup</h3> 
<pre><code>git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
source venv/bin/activate
pip install torch
pip install -r requirements.txt
pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues
</code></pre> 
<h3>2. Upload your dataset</h3> 
<ul> 
 <li>Create a new folder in the root, name it <code>dataset</code> or whatever you like</li> 
 <li>Drag and drop your .jpg and .txt files inside the newly created dataset folder</li> 
</ul> 
<h3>3. Login into Hugging Face with an Access Token</h3> 
<ul> 
 <li>Get a READ token from <a href="https://huggingface.co/settings/tokens">here</a></li> 
 <li>Run <code>huggingface-cli login</code> and paste your token</li> 
</ul> 
<h3>4. Training</h3> 
<ul> 
 <li>Copy an example config file located at <code>config/examples</code> to the config folder and rename it to <code>whatever_you_want.yml</code></li> 
 <li>Edit the config following the comments in the file</li> 
 <li>Change <code>folder_path: "/path/to/images/folder"</code> to your dataset path like <code>folder_path: "/workspace/ai-toolkit/your-dataset"</code></li> 
 <li>Run the file: <code>python run.py config/whatever_you_want.yml</code></li> 
</ul> 
<h3>Screenshot from RunPod</h3> 
<img alt="RunPod Training Screenshot" src="https://github.com/user-attachments/assets/53a1b8ef-92fa-4481-81a7-bde45a14a7b5" width="1728" /> 
<!--
### Training in the cloud
Coming very soon. Getting base out then will have a notebook that makes all that work. 
--> 
<hr /> 
<h2>Dataset Preparation</h2> 
<p>Datasets generally need to be a folder containing images and associated text files. Currently, the only supported formats are jpg, jpeg, and png. Webp currently has issues. The text files should be named the same as the images but with a <code>.txt</code> extension. For example <code>image2.jpg</code> and <code>image2.txt</code>. The text file should contain only the caption. You can add the word <code>[trigger]</code> in the caption file and if you have <code>trigger_word</code> in your config, it will be automatically replaced.</p> 
<p>Images are never upscaled but they are downscaled and placed in buckets for batching. <strong>You do not need to crop/resize your images</strong>. The loader will automatically resize them and can handle varying aspect ratios.</p> 
<hr /> 
<h2>EVERYTHING BELOW THIS LINE IS OUTDATED</h2> 
<p>It may still work like that, but I have not tested it in a while.</p> 
<hr /> 
<h3>Batch Image Generation</h3> 
<p>A image generator that can take frompts from a config file or form a txt file and generate them to a folder. I mainly needed this for an SDXL test I am doing but added some polish to it so it can be used for generat batch image generation. It all runs off a config file, which you can find an example of in <code>config/examples/generate.example.yaml</code>. Mere info is in the comments in the example</p> 
<hr /> 
<h3>LoRA (lierla), LoCON (LyCORIS) extractor</h3> 
<p>It is based on the extractor in the <a href="https://github.com/KohakuBlueleaf/LyCORIS">LyCORIS</a> tool, but adding some QOL features and LoRA (lierla) support. It can do multiple types of extractions in one run. It all runs off a config file, which you can find an example of in <code>config/examples/extract.example.yml</code>. Just copy that file, into the <code>config</code> folder, and rename it to <code>whatever_you_want.yml</code>. Then you can edit the file to your liking. and call it like so:</p> 
<pre><code class="language-bash">python3 run.py config/whatever_you_want.yml
</code></pre> 
<p>You can also put a full path to a config file, if you want to keep it somewhere else.</p> 
<pre><code class="language-bash">python3 run.py "/home/user/whatever_you_want.yml"
</code></pre> 
<p>More notes on how it works are available in the example config file itself. LoRA and LoCON both support extractions of 'fixed', 'threshold', 'ratio', 'quantile'. I'll update what these do and mean later. Most people used fixed, which is traditional fixed dimension extraction.</p> 
<p><code>process</code> is an array of different processes to run. You can add a few and mix and match. One LoRA, one LyCON, etc.</p> 
<hr /> 
<h3>LoRA Rescale</h3> 
<p>Change <code>&lt;lora:my_lora:4.6&gt;</code> to <code>&lt;lora:my_lora:1.0&gt;</code> or whatever you want with the same effect. A tool for rescaling a LoRA's weights. Should would with LoCON as well, but I have not tested it. It all runs off a config file, which you can find an example of in <code>config/examples/mod_lora_scale.yml</code>. Just copy that file, into the <code>config</code> folder, and rename it to <code>whatever_you_want.yml</code>. Then you can edit the file to your liking. and call it like so:</p> 
<pre><code class="language-bash">python3 run.py config/whatever_you_want.yml
</code></pre> 
<p>You can also put a full path to a config file, if you want to keep it somewhere else.</p> 
<pre><code class="language-bash">python3 run.py "/home/user/whatever_you_want.yml"
</code></pre> 
<p>More notes on how it works are available in the example config file itself. This is useful when making all LoRAs, as the ideal weight is rarely 1.0, but now you can fix that. For sliders, they can have weird scales form -2 to 2 or even -15 to 15. This will allow you to dile it in so they all have your desired scale</p> 
<hr /> 
<h3>LoRA Slider Trainer</h3> 
<a href="https://colab.research.google.com/github/ostris/ai-toolkit/blob/main/notebooks/SliderTraining.ipynb" target="_blank"> <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" /> </a> 
<p>This is how I train most of the recent sliders I have on Civitai, you can check them out in my <a href="https://civitai.com/user/Ostris/models">Civitai profile</a>. It is based off the work by <a href="https://github.com/p1atdev/LECO">p1atdev/LECO</a> and <a href="https://github.com/rohitgandikota/erasing">rohitgandikota/erasing</a> But has been heavily modified to create sliders rather than erasing concepts. I have a lot more plans on this, but it is very functional as is. It is also very easy to use. Just copy the example config file in <code>config/examples/train_slider.example.yml</code> to the <code>config</code> folder and rename it to <code>whatever_you_want.yml</code>. Then you can edit the file to your liking. and call it like so:</p> 
<pre><code class="language-bash">python3 run.py config/whatever_you_want.yml
</code></pre> 
<p>There is a lot more information in that example file. You can even run the example as is without any modifications to see how it works. It will create a slider that turns all animals into dogs(neg) or cats(pos). Just run it like so:</p> 
<pre><code class="language-bash">python3 run.py config/examples/train_slider.example.yml
</code></pre> 
<p>And you will be able to see how it works without configuring anything. No datasets are required for this method. I will post an better tutorial soon.</p> 
<hr /> 
<h2>Extensions!!</h2> 
<p>You can now make and share custom extensions. That run within this framework and have all the inbuilt tools available to them. I will probably use this as the primary development method going forward so I dont keep adding and adding more and more features to this base repo. I will likely migrate a lot of the existing functionality as well to make everything modular. There is an example extension in the <code>extensions</code> folder that shows how to make a model merger extension. All of the code is heavily documented which is hopefully enough to get you started. To make an extension, just copy that example and replace all the things you need to.</p> 
<h3>Model Merger - Example Extension</h3> 
<p>It is located in the <code>extensions</code> folder. It is a fully finctional model merger that can merge as many models together as you want. It is a good example of how to make an extension, but is also a pretty useful feature as well since most mergers can only do one model at a time and this one will take as many as you want to feed it. There is an example config file in there, just copy that to your <code>config</code> folder and rename it to <code>whatever_you_want.yml</code>. and use it like any other config file.</p> 
<h2>WIP Tools</h2> 
<h3>VAE (Variational Auto Encoder) Trainer</h3> 
<p>This works, but is not ready for others to use and therefore does not have an example config. I am still working on it. I will update this when it is ready. I am adding a lot of features for criteria that I have used in my image enlargement work. A Critic (discriminator), content loss, style loss, and a few more. If you don't know, the VAE for stable diffusion (yes even the MSE one, and SDXL), are horrible at smaller faces and it holds SD back. I will fix this. I'll post more about this later with better examples later, but here is a quick test of a run through with various VAEs. Just went in and out. It is much worse on smaller faces than shown here.</p> 
<img height="auto" src="https://raw.githubusercontent.com/ostris/ai-toolkit/main/assets/VAE_test1.jpg" width="768" /> 
<hr /> 
<h2>TODO</h2> 
<ul> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> Add proper regs on sliders</li> 
 <li><input checked="checked" disabled="disabled" type="checkbox" /> Add SDXL support (base model only for now)</li> 
 <li><input disabled="disabled" type="checkbox" /> Add plain erasing</li> 
 <li><input disabled="disabled" type="checkbox" /> Make Textual inversion network trainer (network that spits out TI embeddings)</li> 
</ul> 
<hr /> 
<h2>Change Log</h2> 
<h4>2023-08-05</h4> 
<ul> 
 <li>Huge memory rework and slider rework. Slider training is better thant ever with no more ram spikes. I also made it so all 4 parts of the slider algorythm run in one batch so they share gradient accumulation. This makes it much faster and more stable.</li> 
 <li>Updated the example config to be something more practical and more updated to current methods. It is now a detail slide and shows how to train one without a subject. 512x512 slider training for 1.5 should work on 6GB gpu now. Will test soon to verify.</li> 
</ul> 
<h4>2021-10-20</h4> 
<ul> 
 <li>Windows support bug fixes</li> 
 <li>Extensions! Added functionality to make and share custom extensions for training, merging, whatever. check out the example in the <code>extensions</code> folder. Read more about that above.</li> 
 <li>Model Merging, provided via the example extension.</li> 
</ul> 
<h4>2023-08-03</h4> 
<p>Another big refactor to make SD more modular.</p> 
<p>Made batch image generation script</p> 
<h4>2023-08-01</h4> 
<p>Major changes and update. New LoRA rescale tool, look above for details. Added better metadata so Automatic1111 knows what the base model is. Added some experiments and a ton of updates. This thing is still unstable at the moment, so hopefully there are not breaking changes.</p> 
<p>Unfortunately, I am too lazy to write a proper changelog with all the changes.</p> 
<p>I added SDXL training to sliders... but.. it does not work properly. The slider training relies on a model's ability to understand that an unconditional (negative prompt) means you do not want that concept in the output. SDXL does not understand this for whatever reason, which makes separating out concepts within the model hard. I am sure the community will find a way to fix this over time, but for now, it is not going to work properly. And if any of you are thinking "Could we maybe fix it by adding 1 or 2 more text encoders to the model as well as a few more entirely separate diffusion networks?" No. God no. It just needs a little training without every experimental new paper added to it. The KISS principal.</p> 
<h4>2023-07-30</h4> 
<p>Added "anchors" to the slider trainer. This allows you to set a prompt that will be used as a regularizer. You can set the network multiplier to force spread consistency at high weights</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>versotile-org/verso</title>
<link>https://github.com/versotile-org/verso</link>
<guid>https://github.com/versotile-org/verso</guid>
<content:encoded><![CDATA[
<div> 关键词：Verso、Servo、Web浏览器、多窗口支持、多进程模式

总结:
Verso是一个基于Servo引擎开发的Web浏览器项目，旨在探索Servo的多视图和多窗口功能，最终目标是构建一个成熟的功能完备的浏览器。当前版本仍处于开发阶段，主要关注于用户界面的自定义构建以及问题修复的PR接受。为了获取最佳体验，推荐使用Git、Python、LLVM、CMake等工具进行本地编译和运行。

对于不同的操作系统，Verso提供了不同的安装方式：
- 在Windows系统上，首先需要通过Scoop或Chocolatey安装Git、Python等依赖项，然后通过`cargo run`命令启动浏览器。
- MacOS用户则需要安装Homebrew并执行类似的命令来完成安装和启动过程。
- Linux用户可以借助Flatpak进行统一的环境设置与包管理，通过特定命令生成manifest文件并构建Verso应用。

Verso还支持在Nix环境中使用NixShell进行本地构建，尽管当前并未直接在Nix仓库中打包该应用。对于需要构建但不希望使用任何沙箱环境的用户，可以参考文档中的指导进行操作，但需注意在遇到构建问题时可能无法得到支持。

未来计划包括实现多窗口支持、启用多进程模式、增强安全性的沙箱功能，以及集成Gstreamer以提供更丰富的多媒体播放能力。目前的Nightly版本可以通过特定链接访问，但请注意，这些版本未经过签名，对于MacOS用户在安装后可能需要手动解除应用的安全限制（通过命令`xattr -d com.apple.quarantine /Applications/verso.app`）。

通过持续的开发和社区贡献，Verso有望在未来成为一款功能强大、用户体验优秀的Web浏览器。 <div>
<p>A web browser that plays old world blues to build new world hope</p><hr /><h1>Verso</h1> 
<p><a href="https://versotile.zulipchat.com/"><img alt="project chat" src="https://img.shields.io/badge/zulip-57a7ff?style=for-the-badge&amp;labelColor=555555&amp;logo=zulip" /></a></p> 
<p>A web browser that plays old world blues to build new world hope.</p> 
<p><img alt="verso" src="https://github.com/user-attachments/assets/48a834af-858e-4f93-969f-07fb8f5f2496" /></p> 
<p>Verso is a web browser built on top of the <a href="https://servo.org/">Servo</a> web engine. We aim to explore embedding solutions for Servo while growing it into a mature browser one day. This means we want to experiment with multi-view and multi-window first and then build UI elements entirely from Servo itself. At the moment, <a href="https://servo.org/download/">Servoshell</a> should provide a better user experience.</p> 
<p>Verso is still under development. We don't accept feature requests at the moment, and the whole navigation workflow hasn't been polished yet, either. But if you are interested, feel free to open bug-fix PRs.</p> 
<h1>Usage</h1> 
<h2>Getting Started</h2> 
<h3>Windows</h3> 
<ul> 
 <li>Install <a href="https://scoop.sh/">scoop</a> and then install other tools:</li> 
</ul> 
<pre><code class="language-sh">scoop install git python llvm cmake curl
pip install mako
</code></pre> 
<blockquote> 
 <p>You can also use chocolatey to install if you prefer it.</p> 
</blockquote> 
<ul> 
 <li>Build &amp; run:</li> 
</ul> 
<pre><code class="language-sh">cargo run
</code></pre> 
<h3>MacOS</h3> 
<ul> 
 <li>Install <a href="https://developer.apple.com/xcode/">Xcode</a></li> 
 <li>Install <a href="https://brew.sh/">Homebrew</a> and then install other tools:</li> 
</ul> 
<pre><code class="language-sh">brew install cmake pkg-config harfbuzz
pip install mako
</code></pre> 
<ul> 
 <li>Build &amp; run:</li> 
</ul> 
<pre><code class="language-sh">cargo run
</code></pre> 
<h3>Linux</h3> 
<h4>Flatpak</h4> 
<p>For unified environment setup and package experience, we choose Flatpak to build the project from the start. Please follow the <a href="https://flatpak.org/setup/">Flatpak Setup</a> page to install Flatpak based on your distribution.</p> 
<ul> 
 <li>Generate manifests and build: // TODO Exporting to a repository instead</li> 
</ul> 
<pre><code class="language-sh">python3 ./flatpak-cargo-generator.py ./Cargo.lock -o cargo-sources.json
flatpak-builder --user --install --install-deps-from=flathub --force-clean target org.versotile.verso.yml
flatpak run org.versotile.verso
</code></pre> 
<h4>Nix</h4> 
<p>We also support building Verso in nix shell. But we don't bundle it in nix at the moment.</p> 
<ul> 
 <li>For NixOS:</li> 
</ul> 
<pre><code class="language-sh">nix-shell shell.nix --run 'cargo r'
</code></pre> 
<ul> 
 <li>For non-NixOS distributions:</li> 
</ul> 
<pre><code class="language-sh">nix-shell shell.nix --run 'nixGL cargo r'
</code></pre> 
<p>If you prefer to build the project without any sandbox, please follow the instructions in <a href="https://book.servo.org/hacking/setting-up-your-environment.html#tools-for-linux">Servo book</a> to bootstrap. But please understand we don't triage any build issue without flatpak or nix setup.</p> 
<h2>Nightly Release</h2> 
<p>Nightly releases built with CrabNebula Cloud can be found at <a href="https://web.crabnebula.cloud/verso/verso-nightly/releases">releases</a>.</p> 
<blockquote> 
 <p>Packages are unsigned currently. If you have problem opening the app on macOS, try <code>xattr -d com.apple.quarantine /Applications/verso.app</code> after installation.</p> 
</blockquote> 
<h2>Future Work</h2> 
<ul> 
 <li>Multi-window support.</li> 
 <li>Enable multiprocess mode.</li> 
 <li>Enable sandbox in all platforms.</li> 
 <li>Enable <code>Gstreamer</code> feature.</li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>chen08209/FlClash</title>
<link>https://github.com/chen08209/FlClash</link>
<guid>https://github.com/chen08209/FlClash</guid>
<content:encoded><![CDATA[
<div> 关键词：FlClash、ClashMeta、开源、无广告、多平台

总结：

FlClash是一款基于ClashMeta开发的跨平台代理客户端，其设计简洁易用，且完全开源，不含有任何广告。这款软件支持Android、Windows、macOS和Linux等多个操作系统，能够适应不同屏幕尺寸，提供多种主题色供用户选择，界面设计符合Material You风格，既美观又实用。它还具有通过WebDAV进行数据同步的功能，同时支持订阅链接和深色模式。

为了构建和部署FlClash，开发者需要遵循一定的步骤。对于桌面用户，他们需要安装相应的环境（如Android SDK、NDK或GCC），然后运行特定的构建脚本。对于Windows和Linux用户，需要额外安装一些辅助工具（如Inno Setup），而MacOS用户则直接运行构建脚本即可。

最后，鼓励用户通过点击页面顶部的星标按钮来支持开发者的工作，这是最简单有效的方式之一。 <div>
<p>A multi-platform proxy client based on ClashMeta,simple and easy to use, open-source and ad-free.</p><hr /><div> 
 <p><a href="https://raw.githubusercontent.com/chen08209/FlClash/main/README_zh_CN.md"><strong>简体中文</strong></a></p> 
</div> 
<h2>FlClash</h2> 
<p style="text-align: left;"> <img alt="stars" src="https://img.shields.io/github/stars/chen08209/FlClash?style=flat-square&amp;logo=github" /> <img alt="downloads" src="https://img.shields.io/github/downloads/chen08209/FlClash/total" /> <a href="https://raw.githubusercontent.com/chen08209/FlClash/main/LICENSE"> <img alt="license" src="https://img.shields.io/github/license/chen08209/FlClash" /> </a> </p> 
<p>A multi-platform proxy client based on ClashMeta, simple and easy to use, open-source and ad-free.</p> 
<p>on Desktop:</p> 
<p style="text-align: center;"> <img alt="desktop" src="https://raw.githubusercontent.com/chen08209/FlClash/main/snapshots/desktop.gif" /> </p> 
<p>on Mobile:</p> 
<p style="text-align: center;"> <img alt="mobile" src="https://raw.githubusercontent.com/chen08209/FlClash/main/snapshots/mobile.gif" /> </p> 
<h2>Features</h2> 
<p>✈️ Multi-platform: Android, Windows, macOS and Linux</p> 
<p>💻 Adaptive multiple screen sizes, Multiple color themes available</p> 
<p>💡 Based on Material You Design, <a href="https://github.com/getsurfboard/surfboard">Surfboard</a>-like UI</p> 
<p>☁️ Supports data sync via WebDAV</p> 
<p>✨ Support subscription link, Dark mode</p> 
<h2>Download</h2> 
<p><a href="https://chen08209.github.io/FlClash-fdroid-repo/repo?fingerprint=789D6D32668712EF7672F9E58DEEB15FBD6DCEEC5AE7A4371EA72F2AAE8A12FD"><img alt="Get it on F-Droid" src="https://raw.githubusercontent.com/chen08209/FlClash/main/snapshots/get-it-on-fdroid.svg?sanitize=true" width="200px" /></a> <a href="https://github.com/chen08209/FlClash/releases"><img alt="Get it on GitHub" src="https://raw.githubusercontent.com/chen08209/FlClash/main/snapshots/get-it-on-github.svg?sanitize=true" width="200px" /></a></p> 
<h2>Contact</h2> 
<p><a href="https://t.me/+G-veVtwBOl4wODc1">Telegram</a></p> 
<h2>Build</h2> 
<ol> 
 <li> <p>Update submodules</p> <pre><code class="language-bash">git submodule update --init --recursive
</code></pre> </li> 
 <li> <p>Install <code>Flutter</code> and <code>Golang</code> environment</p> </li> 
 <li> <p>Build Application</p> 
  <ul> 
   <li> <p>android</p> 
    <ol> 
     <li> <p>Install <code>Android SDK</code> , <code>Android NDK</code></p> </li> 
     <li> <p>Set <code>ANDROID_NDK</code> environment variables</p> </li> 
     <li> <p>Run Build script</p> <pre><code class="language-bash">dart .\setup.dart android
</code></pre> </li> 
    </ol> </li> 
   <li> <p>windows</p> 
    <ol> 
     <li> <p>You need a windows client</p> </li> 
     <li> <p>Install <code>Gcc</code>，<code>Inno Setup</code></p> </li> 
     <li> <p>Run build script</p> <pre><code class="language-bash">dart .\setup.dart	
</code></pre> </li> 
    </ol> </li> 
   <li> <p>linux</p> 
    <ol> 
     <li> <p>You need a linux client</p> </li> 
     <li> <p>Run build script</p> <pre><code class="language-bash">dart .\setup.dart	
</code></pre> </li> 
    </ol> </li> 
   <li> <p>macOS</p> 
    <ol> 
     <li> <p>You need a macOS client</p> </li> 
     <li> <p>Run build script</p> <pre><code class="language-bash">dart .\setup.dart	
</code></pre> </li> 
    </ol> </li> 
  </ul> </li> 
</ol> 
<h2>Star</h2> 
<p>The easiest way to support developers is to click on the star (⭐) at the top of the page.</p> 
<p style="text-align: center;"> <a href="https://api.star-history.com/svg?repos=chen08209/FlClash&amp;Date"> <img alt="start" src="https://api.star-history.com/svg?repos=chen08209/FlClash&amp;Date" width="50%" /> </a> </p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>n8n-io/n8n</title>
<link>https://github.com/n8n-io/n8n</link>
<guid>https://github.com/n8n-io/n8n</guid>
<content:encoded><![CDATA[
<div> 关键词：n8n、自动化工具、源代码、可扩展性、集成

总结：

n8n是一款开源的自动化工作流工具，具有高度可扩展性和自定义功能。它采用节点式架构，使得用户能够轻松连接各种服务和应用，实现跨平台的任务自动化。n8n提供了超过200种不同的节点，覆盖了广泛的自动化需求。官方文档提供了详细的使用指南、示例工作流以及版本更新信息。用户可以通过npm命令行工具或在线云服务进行快速启动和操作。此外，n8n还支持与LangChain集成，引入AI功能到工作流中，增强自动化能力。对于遇到问题的用户，n8n社区提供论坛支持，帮助解决技术难题。最后，n8n遵循Apache 2.0许可协议发布，同时为商业客户提供企业级许可选项，确保了其灵活性和适应性。 <div>
<p>Free and source-available fair-code licensed workflow automation tool. Easily automate tasks across different services.</p><hr /><p><img alt="n8n.io - Workflow Automation" src="https://user-images.githubusercontent.com/65276001/173571060-9f2f6d7b-bac0-43b6-bdb2-001da9694058.png" /></p> 
<h1>n8n - Workflow automation tool</h1> 
<p>n8n is an extendable workflow automation tool. With a <a href="https://faircode.io">fair-code</a> distribution model, n8n will always have visible source code, be available to self-host, and allow you to add your own custom functions, logic and apps. n8n's node-based approach makes it highly versatile, enabling you to connect anything to everything.</p> 
<p><img alt="n8n.io - Screenshot" src="https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot.png" /></p> 
<h2>Demo</h2> 
<p><a href="https://www.youtube.com/watch?v=1MwSoB0gnM4"><span>📺</span> A short video (&lt; 5 min)</a> that goes over key concepts of creating workflows in n8n.</p> 
<h2>Available integrations</h2> 
<p>n8n has 200+ different nodes to automate workflows. The list can be found on: <a href="https://n8n.io/integrations">https://n8n.io/integrations</a></p> 
<h2>Documentation</h2> 
<p>The official n8n documentation can be found on our <a href="https://docs.n8n.io">documentation website</a></p> 
<p>Additional information and example workflows on the <a href="https://n8n.io">n8n.io website</a></p> 
<p>The release notes can be found <a href="https://docs.n8n.io/release-notes/">here</a> and the list of breaking changes <a href="https://github.com/n8n-io/n8n/raw/master/packages/cli/BREAKING-CHANGES.md">here</a>.</p> 
<h2>Usage</h2> 
<ul> 
 <li><span>📚</span> Learn <a href="https://docs.n8n.io/reference/cli-commands/">how to <strong>use</strong> it from the command line</a></li> 
 <li><span>🐳</span> Learn <a href="https://docs.n8n.io/hosting/installation/docker/">how to run n8n in <strong>Docker</strong></a></li> 
</ul> 
<h2>Start</h2> 
<p>You can try n8n without installing it using npx. You must have <a href="https://nodejs.org/en/">Node.js</a> installed. From the terminal, run:</p> 
<p><code>npx n8n</code></p> 
<p>This command will download everything that is needed to start n8n. You can then access n8n and start building workflows by opening <a href="http://localhost:5678">http://localhost:5678</a>.</p> 
<h2>n8n cloud</h2> 
<p>Sign-up for an <a href="https://www.n8n.io/cloud/">n8n cloud</a> account.</p> 
<p>While n8n cloud and n8n are the same in terms of features, n8n cloud provides certain conveniences such as:</p> 
<ul> 
 <li>Not having to set up and maintain your n8n instance</li> 
 <li>Managed OAuth for authentication</li> 
 <li>Easily upgrading to the newer n8n versions</li> 
</ul> 
<h2>Build with LangChain and AI in n8n (beta)</h2> 
<p>With n8n's LangChain nodes you can build AI-powered functionality within your workflows. The LangChain nodes are configurable, meaning you can choose your preferred agent, LLM, memory, and so on. Alongside the LangChain nodes, you can connect any n8n node as normal: this means you can integrate your LangChain logic with other data sources and services.</p> 
<p>Learn more in the <a href="https://docs.n8n.io/langchain/">documentation</a>.</p> 
<ul> 
 <li><a href="https://www.npmjs.com/package/@n8n/n8n-nodes-langchain">LangChain nodes package</a></li> 
 <li><a href="https://www.npmjs.com/package/@n8n/chat">Chatbot package</a></li> 
</ul> 
<h2>Support</h2> 
<p>If you have problems or questions go to our forum, we will then try to help you asap:</p> 
<p><a href="https://community.n8n.io">https://community.n8n.io</a></p> 
<h2>Jobs</h2> 
<p>If you are interested in working for n8n and so shape the future of the project check out our <a href="https://apply.workable.com/n8n/">job posts</a></p> 
<h2>What does n8n mean and how do you pronounce it?</h2> 
<p><strong>Short answer:</strong> It means "nodemation" and it is pronounced as n-eight-n.</p> 
<p><strong>Long answer:</strong> "I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. 'node-' in the sense that it uses a Node-View and that it uses Node.js and '-mation' for 'automation' which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on 'n8n'." - <strong>Jan Oberhauser, Founder and CEO, n8n.io</strong></p> 
<h2>Development setup</h2> 
<p>Have you found a bug <span>🐛</span> ? Or maybe you have a nice feature <span>✨</span> to contribute ? The <a href="https://github.com/n8n-io/n8n/raw/master/CONTRIBUTING.md">CONTRIBUTING guide</a> will help you get your development environment ready in minutes.</p> 
<h2>License</h2> 
<p>n8n is <a href="https://faircode.io">fair-code</a> distributed under the <a href="https://github.com/n8n-io/n8n/raw/master/LICENSE.md"><strong>Sustainable Use License</strong></a> and the <a href="https://github.com/n8n-io/n8n/raw/master/LICENSE_EE.md"><strong>n8n Enterprise License</strong></a>.</p> 
<p>Proprietary licenses are available for enterprise customers. <a href="mailto:license@n8n.io">Get in touch</a></p> 
<p>Additional information about the license model can be found in the <a href="https://docs.n8n.io/reference/license/">docs</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>electric-sql/pglite</title>
<link>https://github.com/electric-sql/pglite</link>
<guid>https://github.com/electric-sql/pglite</guid>
<content:encoded><![CDATA[
<div> 关键词：PGlite、Postgres、WASM、TypeScript、浏览器/Node.js/Bun/Deno

总结:

PGlite 是一个轻量级的 PostgreSQL 实现，它将数据库引擎打包为 WebAssembly (WASM) 格式，并提供了 TypeScript 客户端库。这种设计允许开发者在浏览器、Node.js、Bun 或 Deno 环境中直接运行 PostgreSQL，无需安装额外依赖。PGlite 的体积仅为 3MB（压缩后），并且支持多种 PostgreSQL 扩展，包括全文搜索等。

在浏览器环境中，开发者可以通过常规的包管理器或 CDN 来引入和使用 PGlite。对于内存数据库场景，开发者可以直接创建新的 PGlite 实例；若需持久化存储，可以将数据库与文件系统（Node/Bun）或 IndexedDB（浏览器）进行集成。

在 Node.js 或 Bun 环境下，PGlite 可以通过 npm 进行安装，并根据具体需求配置内存数据库或持久化数据到本地文件或 IndexedDB 中。

PGlite 的工作原理基于 PostgreSQL 的单用户模式，该模式主要用于命令行操作和启动恢复流程。通过构建一个输入/输出通道，PGlite 能够在 JavaScript 环境中与被编译为 WASM 的 PostgreSQL 进行交互。

当前版本的限制在于它仅支持单用户/单连接模式。对于贡献者而言，需要确保已安装 Emscripten 和最新版本的 Node.js，并且下载最新的 WASM 构建文件以构建 PGlite 及其依赖的工作空间项目。此外，PGlite 遵循双许可协议，开发者可以根据需要选择 PostgreSQL 许可证或自由软件许可证。

最后，PGlite 建立在前人的工作之上，特别感谢为该项目做出贡献的人们。 <div>
<p>Lightweight Postgres packaged as WASM into a TypeScript library for the browser, Node.js, Bun and Deno from https://electric-sql.com</p><hr /><p align="center"> <a href="https://electric-sql.com" target="_blank"> 
   
   <source media="(prefers-color-scheme: dark)" /> 
   <source media="(prefers-color-scheme: light)" /> 
   <img alt="ElectricSQL logo" src="https://raw.githubusercontent.com/electric-sql/meta/main/identity/ElectricSQL-logo-black.svg?sanitize=true" /> 
   </a> </p> 
<p align="center"> PGlite - the WASM build of Postgres from <a href="https://electric-sql.com" target="_blank">ElectricSQL</a>.<br /> Build reactive, realtime, local-first apps directly on Postgres. </p>
<p> </p>
<p align="center"> <a href="https://github.com/electric-sql/pglite/stargazers/"><img src="https://img.shields.io/github/stars/electric-sql/pglite?style=social&amp;label=Star" /></a> 
 <!-- <a href="https://github.com/electric-sql/pglite/actions"><img src="https://github.com/electric-sql/pglite/workflows/CI/badge.svg" alt="CI"></a> --> <a href="https://github.com/electric-sql/pglite/raw/main/LICENSE"><img alt="License - Apache 2.0" src="https://img.shields.io/badge/license-Apache_2.0-green" /></a> <a href="https://raw.githubusercontent.com/electric-sql/pglite/main/#roadmap"><img alt="Status - Alpha" src="https://img.shields.io/badge/status-alpha-orange" /></a> <a href="https://discord.electric-sql.com"><img alt="Chat - Discord" src="https://img.shields.io/discord/933657521581858818?color=5969EA&amp;label=discord" /></a> <a href="https://twitter.com/ElectricSQL" target="_blank"><img src="https://img.shields.io/twitter/follow/nestframework.svg?style=social&amp;label=Follow%20@ElectricSQL" /></a> <a href="https://fosstodon.org/@electric" target="_blank"><img src="https://img.shields.io/mastodon/follow/109599644322136925.svg?domain=https%3A%2F%2Ffosstodon.org" /></a> </p> 
<h1>PGlite - Postgres in WASM</h1> 
<p><img alt="PGlite" src="https://raw.githubusercontent.com/electric-sql/pglite/main/screenshot.png" /></p> 
<p>PGlite is a WASM Postgres build packaged into a TypeScript client library that enables you to run Postgres in the browser, Node.js and Bun, with no need to install any other dependencies. It is only 3mb gzipped and has support for many Postgres extensions, including <a href="https://github.com/pgvector/pgvector">pgvector</a>.</p> 
<pre><code class="language-javascript">import { PGlite } from "@electric-sql/pglite";

const db = new PGlite();
await db.query("select 'Hello world' as message;");
// -&gt; { rows: [ { message: "Hello world" } ] }
</code></pre> 
<p>It can be used as an ephemeral in-memory database, or with persistence either to the file system (Node/Bun) or indexedDB (Browser).</p> 
<p>Unlike previous "Postgres in the browser" projects, PGlite does not use a Linux virtual machine - it is simply Postgres in WASM.</p> 
<p>For full documentation and user guides see <a href="https://pglite.dev">pglite.dev</a>.</p> 
<h2>Browser</h2> 
<p>It can be installed and imported using your usual package manager:</p> 
<pre><code class="language-js">import { PGlite } from "@electric-sql/pglite";
</code></pre> 
<p>or using a CDN such as JSDeliver:</p> 
<pre><code class="language-js">import { PGlite } from "https://cdn.jsdelivr.net/npm/@electric-sql/pglite/dist/index.js";
</code></pre> 
<p>Then for an in-memory Postgres:</p> 
<pre><code class="language-js">const db = new PGlite()
await db.query("select 'Hello world' as message;")
// -&gt; { rows: [ { message: "Hello world" } ] }
</code></pre> 
<p>or to persist the database to indexedDB:</p> 
<pre><code class="language-js">const db = new PGlite("idb://my-pgdata");
</code></pre> 
<h2>Node/Bun</h2> 
<p>Install into your project:</p> 
<pre><code class="language-bash">npm install @electric-sql/pglite
</code></pre> 
<p>To use the in-memory Postgres:</p> 
<pre><code class="language-javascript">import { PGlite } from "@electric-sql/pglite";

const db = new PGlite();
await db.query("select 'Hello world' as message;");
// -&gt; { rows: [ { message: "Hello world" } ] }
</code></pre> 
<p>or to persist to the filesystem:</p> 
<pre><code class="language-javascript">const db = new PGlite("./path/to/pgdata");
</code></pre> 
<h2>How it works</h2> 
<p>PostgreSQL typically operates using a process forking model; whenever a client initiates a connection, a new process is forked to manage that connection. However, programs compiled with Emscripten - a C to WebAssembly (WASM) compiler - cannot fork new processes, and operates strictly in a single-process mode. As a result, PostgreSQL cannot be directly compiled to WASM for conventional operation.</p> 
<p>Fortunately, PostgreSQL includes a "single user mode" primarily intended for command-line usage during bootstrapping and recovery procedures. Building upon this capability, PGlite introduces a input/output pathway that facilitates interaction with PostgreSQL when it is compiled to WASM within a JavaScript environment.</p> 
<h2>Limitations</h2> 
<ul> 
 <li>PGlite is single user/connection.</li> 
</ul> 
<h2>How to contribute</h2> 
<p>You will need <a href="https://pnpm.io/">pnpm</a> installed, and a recent version of Node.js (v20 and above).</p> 
<p>You will also need the Postgres WASM build files, which you download from a comment under the most recently merged PR, labeled as <em>interim build files</em>, and place them under <code>packages/pglite/release</code>. These are necessary to build PGlite and the dependent workspace projects. We plan to enable a local build in the future to streamline this step.</p> 
<p>Once the requirements are met, you can install dependencies and build the workspace projects:</p> 
<pre><code class="language-bash">pnpm install
pnpm build
</code></pre> 
<p>This will build all packages in the correct order based on their dependency relationships. You can now develop any individual package using the <code>build</code> and <code>test</code> scripts, as well as the <code>stylecheck</code> and <code>typecheck</code> scripts to ensure style and type validity.</p> 
<p>When ready to open a PR, run the following command at the root of the repository:</p> 
<pre><code class="language-bash">pnpm changeset
</code></pre> 
<p>And follow the instructions to create an appropriate changeset. Please ensure any contributions that touch code are accompanied by a changeset.</p> 
<h2>Acknowledgments</h2> 
<p>PGlite builds on the work of <a href="https://github.com/kelvich">Stas Kelvich</a> of <a href="https://neon.tech">Neon</a> in this <a href="https://github.com/electric-sql/postgres-wasm">Postgres fork</a>.</p> 
<h2>License</h2> 
<p>PGlite is dual-licensed under the terms of the&nbsp;<a href="https://github.com/electric-sql/pglite/raw/main/LICENSE">Apache License 2.0</a>&nbsp;and the&nbsp;<a href="https://github.com/electric-sql/pglite/raw/main/POSTGRES-LICENSE">PostgreSQL License</a>, you can choose which you prefer.</p> 
<p>Changes to the&nbsp;<a href="https://github.com/electric-sql/postgres-wasm">Postgres source</a>&nbsp;are licensed under the PostgreSQL License.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>poloclub/transformer-explainer</title>
<link>https://github.com/poloclub/transformer-explainer</link>
<guid>https://github.com/poloclub/transformer-explainer</guid>
<content:encoded><![CDATA[
<div> 关键词：Transformer Explainer、GPT、Transformer模型、交互可视化、在线实验

总结:
Transformer Explainer是一个交互式可视化工具，旨在帮助用户理解Transformer模型（如GPT）的工作原理。通过在线运行GPT-2模型，用户可以实时输入文本并观察内部组件和操作如何协同工作以预测下一个词汇。该工具提供了直观的学习体验，使任何人都能探索和学习文本生成模型的工作机制。要本地运行此工具，需要安装Node.js 20或更高版本以及NPM。运行命令后，您可以通过浏览器访问特定网址来使用它。

Transformer Explainer由来自乔治亚理工学院的研究人员Aeree Cho、Grace C. Kim、Alexander Karpekov、Alec Helbling、Zijie J. Wang、Seongmin Lee、Benjamin Hoover和Duen Horng Chau共同开发。该工具遵循开源许可证，用户可以通过提供的问题反馈或直接联系开发者进行交流。 <div>
<p>Transformer Explained: Learn How LLM Transformer Models Work with Interactive Visualization</p><hr /><h1>Transformer Explainer: Interactive Learning of Text-Generative Models</h1> 
<p>Transformer Explainer is an interactive visualization tool designed to help anyone learn how Transformer-based models like GPT work. It runs a live GPT-2 model right in your browser, allowing you to experiment with your own text and observe in real time how internal components and operations of the Transformer work together to predict the next tokens. Try Transformer Explainer at <a href="http://poloclub.github.io/transformer-explainer">http://poloclub.github.io/transformer-explainer</a> and watch a demo video on YouTube <a href="https://youtu.be/ECR4oAwocjs">https://youtu.be/ECR4oAwocjs</a> .<br /><br /> <a href="http://opensource.org/licenses/MIT"><img alt="MIT license" src="http://img.shields.io/badge/license-MIT-brightgreen.svg?sanitize=true" /></a> <a href="https://arxiv.org/abs/2408.04619"><img alt="arxiv badge" src="https://img.shields.io/badge/arXiv-2408.04619-red" /></a></p> 
<table> 
 <tbody>
  <tr> 
   <td colspan="2">
    <video src="https://github.com/poloclub/transformer-explainer/assets/5067740/5c2d6a9d-2cbf-4b01-9ce1-bdf8e190dc42" width="100%"></video></td> 
  </tr> 
  <tr> 
   <td>🚀 <a href="http://poloclub.github.io/transformer-explainer">Live Demo</a></td> 
   <td>📺 <a href="https://youtu.be/ECR4oAwocjs">Demo Video</a></td> 
  </tr> 
 </tbody>
</table> 
<h3>Research Paper</h3> 
<p><a href="https://arxiv.org/abs/2408.04619"><strong>Transformer Explainer: Interactive Learning of Text-Generative Models</strong></a>. Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau. <em>Poster, IEEE VIS 2024.</em></p> 
<h2>How to run locally</h2> 
<h4>Prerequisites</h4> 
<ul> 
 <li>Node.js 20 or higher</li> 
 <li>NPM</li> 
</ul> 
<h4>Steps</h4> 
<pre><code class="language-bash">git clone https://github.com/poloclub/transformer-explainer.git
cd transformer-explainer
npm install
npm run dev
</code></pre> 
<p>Then, on your web browser, access <a href="http://localhost:5173">http://localhost:5173</a>.</p> 
<h2>Credits</h2> 
<p>Transformer Explainer was created by <a href="https://aereeeee.github.io/" target="_blank">Aeree Cho</a>, <a href="https://www.linkedin.com/in/chaeyeonggracekim/" target="_blank">Grace C. Kim</a>, <a href="https://alexkarpekov.com/" target="_blank">Alexander Karpekov</a>, <a href="https://alechelbling.com/" target="_blank">Alec Helbling</a>, <a href="https://zijie.wang/" target="_blank">Jay Wang</a>, <a href="https://seongmin.xyz/" target="_blank">Seongmin Lee</a>, <a href="https://bhoov.com/" target="_blank">Benjamin Hoover</a>, and <a href="https://poloclub.github.io/polochau/" target="_blank">Polo Chau</a> at the Georgia Institute of Technology.</p> 
<h2>Citation</h2> 
<pre><code class="language-bibTeX">@article{cho2024transformer,
  title = {Transformer Explainer: Interactive Learning of Text-Generative Models},
  shorttitle = {Transformer Explainer},
  author = {Cho, Aeree and Kim, Grace C. and Karpekov, Alexander and Helbling, Alec and Wang, Zijie J. and Lee, Seongmin and Hoover, Benjamin and Chau, Duen Horng},
  journal={IEEE VIS},
  year={2024}
}
</code></pre> 
<h2>License</h2> 
<p>The software is available under the <a href="https://github.com/poloclub/transformer-explainer/raw/main/LICENSE">MIT License</a>.</p> 
<h2>Contact</h2> 
<p>If you have any questions, feel free to <a href="https://github.com/poloclub/transformer-explainer/issues/new/choose">open an issue</a> or contact <a href="https://aereeeee.github.io/">Aeree Cho</a> or any of the contributors listed above.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>erincatto/box2d</title>
<link>https://github.com/erincatto/box2d</link>
<guid>https://github.com/erincatto/box2d</guid>
<content:encoded><![CDATA[
<div> 关键词：Box2D、2D 物理引擎、游戏、构建状态、兼容性

总结:

Box2D 是一款专门用于游戏开发的二维物理引擎。它提供了丰富的功能和特性，包括但不限于碰撞检测、物理模拟、系统设计等。以下是对其主要特点的总结：

1. **碰撞检测**：Box2D 支持多种形状的碰撞检测，如凸多边形、胶囊体、圆形、圆角多边形、线段和链等。同时，它还支持传感器、接触事件以及多形状的单个物体。

2. **物理模拟**：引擎采用稳健的软步解算器进行快速的平移和旋转模拟，实现连续物理。此外，它还包括岛基睡眠、关节（如轮轴、滑动、距离、鼠标等）以及各种类型的关节，如铰链、电机、弹簧和摩擦力。

3. **系统设计**：Box2D 的设计注重数据导向，使用标准可移植的 C17 编写，支持多线程和 SIMD 指令集，提高了性能和效率。

4. **构建与兼容性**：Box2D 可以在 Windows、Linux 和 macOS 上构建和运行，要求使用最新版本的 Clang 或 GCC 进行编译。对于特定平台如 Windows，需要安装 Visual Studio。而对于 Mac 和 Linux，则可以通过 CMake 进行构建。

5. **社区与贡献**：Box2D 有一个活跃的社区，鼓励用户通过问题报告或 Discord 服务器寻求帮助和支持。开发者可通过赞助来支持 Box2D 的发展，同时也提供了一些官方和第三方的版本、封装和绑定资源。 <div>
<p>Box2D is a 2D physics engine for games</p><hr /><p><img alt="Box2D Logo" src="https://box2d.org/images/logo.svg?sanitize=true" /></p> 
<h1>Build Status</h1> 
<p><a href="https://github.com/erincatto/box2d/actions"><img alt="Build Status" src="https://github.com/erincatto/box2d/actions/workflows/build.yml/badge.svg?sanitize=true" /></a></p> 
<h1>Box2D</h1> 
<p>Box2D is a 2D physics engine for games.</p> 
<p><a href="https://www.youtube.com/watch?v=dAoM-xjOWtA"><img alt="Box2D Version 3.0 Release Demo" src="https://img.youtube.com/vi/dAoM-xjOWtA/0.jpg" /></a></p> 
<h2>Features</h2> 
<h3>Collision</h3> 
<ul> 
 <li>Continuous collision detection</li> 
 <li>Contact events and sensors</li> 
 <li>Convex polygons, capsules, circles, rounded polygons, segments, and chains</li> 
 <li>Multiple shapes per body</li> 
 <li>Collision filtering</li> 
 <li>Ray casts, shape casts, and overlap queries</li> 
</ul> 
<h3>Physics</h3> 
<ul> 
 <li>Robust <em>Soft Step</em> rigid body solver</li> 
 <li>Continuous physics for fast translations and rotations</li> 
 <li>Island based sleep</li> 
 <li>Revolute, prismatic, distance, mouse joint, weld, and wheel joints</li> 
 <li>Joint limits, motors, springs, and friction</li> 
 <li>Joint and contact forces</li> 
 <li>Body movement events and sleep notification</li> 
</ul> 
<h3>System</h3> 
<ul> 
 <li>Data-oriented design</li> 
 <li>Written in portable C17</li> 
 <li>Extensive multithreading and SIMD</li> 
</ul> 
<h3>Samples</h3> 
<ul> 
 <li>OpenGL with GLFW and enkiTS</li> 
 <li>Graphical user interface with imgui</li> 
 <li>Many samples to demonstrate features and performance</li> 
</ul> 
<h2>Building</h2> 
<ul> 
 <li>Install <a href="https://cmake.org/">CMake</a></li> 
 <li>Ensure CMake is in the user <code>PATH</code></li> 
 <li>Visual Studio: run <code>build.bat</code> from the command prompt</li> 
 <li>Otherwise: run <code>build.sh</code> from a bash shell</li> 
 <li>Results are in the build sub-folder</li> 
 <li>On Windows you can open box2d.sln</li> 
</ul> 
<h2>Building for Xcode</h2> 
<ul> 
 <li>Install <a href="https://cmake.org">CMake</a></li> 
 <li>Add Cmake to the path in .zprofile (the default Terminal shell is zsh) 
  <ul> 
   <li>export PATH="/Applications/CMake.app/Contents/bin:$PATH"</li> 
  </ul> </li> 
 <li>mkdir build</li> 
 <li>cd build</li> 
 <li>cmake -G Xcode ..</li> 
 <li>open box2d.xcodeproj</li> 
 <li>Select the samples scheme</li> 
 <li>Edit the scheme to set a custom working directory to the box2d directory</li> 
 <li>You can now build and run the samples</li> 
</ul> 
<h2>Compatibility</h2> 
<p>The Box2D library and samples build and run on Windows, Linux, and Mac.</p> 
<p>Box2D should be built on recent versions of clang and gcc. You will need the latest Visual Studio version for C11 atomics to compile (17.8.3+).</p> 
<p>AVX2 CPU support is assumed on x64. You can turn this off in the CMake options and use SSE2 instead. There are some compatibility issues with very old CPUs.</p> 
<h2>Documentation</h2> 
<ul> 
 <li><a href="https://box2d.org/documentation/">Manual</a></li> 
 <li><a href="https://github.com/erincatto/box2d/raw/main/docs/migration.md">Migration Guide</a></li> 
</ul> 
<h2>Community</h2> 
<ul> 
 <li><a href="https://discord.gg/NKYgCBP">Discord</a></li> 
</ul> 
<h2>Contributing</h2> 
<p>Please do not submit pull requests. Instead, please file an issue for bugs or feature requests. For support, please visit the Discord server.</p> 
<h1>Giving Feedback</h1> 
<p>Please file an issue or start a chat on discord.</p> 
<h2>License</h2> 
<p>Box2D is developed by Erin Catto and uses the <a href="https://en.wikipedia.org/wiki/MIT_License">MIT license</a>.</p> 
<h2>Sponsorship</h2> 
<p>Support development of Box2D through <a href="https://github.com/sponsors/erincatto">Github Sponsors</a></p> 
<h2>Ports, wrappers, and bindings</h2> 
<ul> 
 <li><a href="https://github.com/EnokViking/Box2DBeef">https://github.com/EnokViking/Box2DBeef</a></li> 
 <li><a href="https://github.com/HolyBlackCat/box2cpp">https://github.com/HolyBlackCat/box2cpp</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>LLaVA-VL/LLaVA-NeXT</title>
<link>https://github.com/LLaVA-VL/LLaVA-NeXT</link>
<guid>https://github.com/LLaVA-VL/LLaVA-NeXT</guid>
<content:encoded><![CDATA[
<div> 关键词：LLaVA-NeXT、大型多模态模型、多图像、视频、3D任务

总结:

LLaVA-NeXT系列模型是为解决多图像、视频和三维任务而设计的一系列大型多模态模型。自发布以来，LLaVA-NeXT不断更新与优化，实现了在多个基准测试中的新状态最优性能。以下为关键更新点：

1. **多模态能力增强**：LLaVA-NeXT模型通过集成图像、文本和视频理解能力，显著提高了处理多模态数据的任务性能。

2. **性能提升**：新发布的模型如LLaVA-NeXT-Interleave和LLaVA-NeXT-Video，分别针对多图像任务和视频理解任务进行了优化，实现了在相关领域的新高点。

3. **训练策略改进**：通过使用高质量的数据集和可训练模块，LLaVA-NeXT系列模型在训练策略上进行了创新，有效提升了模型的泛化能力和任务解决效率。

4. **支持多样化硬件**：项目提供针对不同硬件平台（如Intel GPU和CPU）的支持，使得模型部署更加灵活。

5. **开源资源与社区贡献**：除了模型本身，还提供了包括评估框架、教程文档等在内的丰富资源，鼓励社区成员参与模型训练和优化，共同推动多模态AI技术的发展。

这些更新不仅展示了LLaVA-NeXT在多模态处理能力上的强大，也为未来AI研究者和开发者提供了宝贵的工具和资源。 <div>
<p></p><hr /><p align="center" width="100%"> <img height="80%" src="https://i.postimg.cc/pL17YtG4/WX20240508-220230-2x.png" width="80%" /> </p> 
<h1>LLaVA-NeXT: Open Large Multimodal Models</h1> 
<p><a href="https://arxiv.org/abs/2408.03326"><img alt="Static Badge" src="https://img.shields.io/badge/llava_onevision-paper-green" /></a> <a href="https://llava-vl.github.io/blog/"><img alt="llava_next-blog" src="https://img.shields.io/badge/llava_next-blog-green" /></a></p> 
<p><a href="https://llava-onevision.lmms-lab.com/"><img alt="llava_onevision-demo" src="https://img.shields.io/badge/llava_onevision-demo-red" /></a> <a href="https://huggingface.co/spaces/lmms-lab/LLaVA-NeXT-Interleave-Demo"><img alt="llava_next-interleave_demo" src="https://img.shields.io/badge/llava_next-interleave_demo-red" /></a> <a href="https://huggingface.co/spaces/WildVision/vision-arena"><img alt="llava_next-video_demo" src="https://img.shields.io/badge/llava_next-video_demo-red" /></a></p> 
<p><a href="https://huggingface.co/collections/lmms-lab/llava-onevision-66a259c3526e15166d6bba37"><img alt="llava_onevision-checkpoints" src="https://img.shields.io/badge/llava_onevision-checkpoints-blue" /></a> <a href="https://huggingface.co/collections/lmms-lab/llava-next-interleave-66763c55c411b340b35873d1"><img alt="llava_next-interleave_checkpoints" src="https://img.shields.io/badge/llava_next-interleave_checkpoints-blue" /></a> <a href="https://huggingface.co/collections/lmms-lab/llava-next-video-661e86f5e8dabc3ff793c944"><img alt="llava_next-video_checkpoints" src="https://img.shields.io/badge/llava_next-video_checkpoints-blue" /></a> <a href="https://huggingface.co/lmms-lab"><img alt="llava_next-image_checkpoints" src="https://img.shields.io/badge/llava_next-image_checkpoints-blue" /></a></p> 
<h2>Release Notes</h2> 
<ul> 
 <li> <p>[2024/08/06] 🔥 <strong>🚀 <a href="https://llava-vl.github.io/blog/2024-08-05-llava-onevision/">LLaVA-OneVision (OV)</a>!</strong> The new LLaVA-OV models (0.5B/7B/72B) achieve new state-of-the-art performance across single-image, multi-image, and video benchmarks, sometimes rivaling top commercial models on 47 diverse benchmarks. 📄 Explore More:</p> 
  <ul> 
   <li><a href="https://arxiv.org/abs/2408.03326">[Paper]</a>: In-depth insights, new emegerging scenarios, ie, strong video understadning through task transfer from images.</li> 
   <li><a href="https://github.com/LLaVA-VL/LLaVA-NeXT/raw/main/docs/LLaVA_OneVision.md">[LLaVA-OV Doc]</a>: Model inference and evaluation guidance.</li> 
   <li><a href="https://github.com/LLaVA-VL/LLaVA-NeXT/raw/main/scripts/train">[Scripts]</a>: Start training models on your single-image/multi-image/video data.</li> 
  </ul> </li> 
 <li> <p>[2024/07/16] 🔥 <strong>LLaVA-NeXT-Video</strong> has been upgraded. The new 32B model achieves the best open-source performance on several video benchmarks, including <a href="https://video-mme.github.io/home_page.html#leaderboard">Video-MME</a>. Please refer to <a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT-Video_0716.md">this page</a> for details, refer to <a href="https://huggingface.co/spaces/WildVision/vision-arena">llava_next-video_demo</a> for demo.</p> </li> 
 <li> <p>[2024/06/23] 🔥 <strong>LLaVA-NeXT-Interleave</strong> is released. We utilize image-text interleaved format to unify multi-image, video, and 3D tasks in one LLM and achieve <strong>SoTA</strong> performance on a wide range of benchmarks. Check out <a href="https://arxiv.org/pdf/2407.07895">paper</a>, <a href="https://llava-vl.github.io/blog/2024-06-16-llava-next-interleave/">blog</a>, and <a href="https://huggingface.co/collections/lmms-lab/llava-next-interleave-66763c55c411b340b35873d1">checkpoints</a> to see new capabilities and improved performance! We have released 0.5b, 7b, and 7b-dpo models.</p> 
  <ul> 
   <li>An all-round LLM for multi-image, video, and 3D with strong performance [<a href="https://huggingface.co/spaces/lmms-lab/LLaVA-NeXT-Interleave-Demo">demo</a>]</li> 
   <li>Construct interleave training data <a href="https://huggingface.co/datasets/lmms-lab/M4-Instruct-Data"><strong>M4-Instruct</strong></a></li> 
   <li>Construct multi-image benchmark <a href="https://huggingface.co/datasets/lmms-lab/LLaVA-NeXT-Interleave-Bench"><strong>LLaVA-Interleave Bench</strong></a></li> 
  </ul> </li> 
 <li> <p>[2024/05/25] 🔥 Wondering "<a href="https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/">What Else Influences Visual Instruction Tuning Beyond Data?</a>" Our new <a href="https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/">blog</a> summarizes empirical explorations to ablate the various design choices in improving LMMs except instruct data itself. Meanwhile, open-source the recapioned high-quality data using LLaVA-NeXT-34B on <a href="https://huggingface.co/datasets/lmms-lab/LLaVA-ReCap-118K">[COCO]</a> <a href="https://huggingface.co/datasets/lmms-lab/LLaVA-ReCap-558K">[LCS]</a> <a href="https://huggingface.co/datasets/lmms-lab/LLaVA-ReCap-CC3M">[CC3M]</a>.</p> 
  <ul> 
   <li>Architectures (LMM &amp; Vision Encoder)</li> 
   <li>Visual Representations (Resolution &amp; # Tokens)</li> 
   <li>Training Strategies (High-quality data &amp; Trainable modules)</li> 
  </ul> </li> 
 <li> <p>[2024/05/10] 🔥 <strong>LLaVA-NeXT</strong> (Stronger) models are released, with support of stronger LMM inlcuding LLama-3 (8B) and Qwen-1.5 (72B/110B) Check out [<a href="https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/">blog</a>] and [<a href="https://huggingface.co/lmms-lab">checkpoints</a>] to see improved performance!</p> </li> 
 <li> <p>[2024/05/10] 🔥 <strong>LLaVA-NeXT</strong> (Video) is released. The image-only-trained LLaVA-NeXT model is surprisingly strong on video tasks with zero-shot modality transfer. DPO training with AI feedback on videos can yield significant improvement. [<a href="https://llava-vl.github.io/blog/2024-04-30-llava-next-video/">Blog</a>], [<a href="https://huggingface.co/collections/lmms-lab/llava-next-video-661e86f5e8dabc3ff793c944">checkpoints</a>] and [<a href="https://github.com/sgl-project/sglang">sglang</a>]</p> </li> 
 <li> <p>[2024/01/30] 🔥 <strong>LLaVA-NeXT</strong> is out! With additional scaling to LLaVA-1.5, LLaVA-NeXT-34B outperforms Gemini Pro on some benchmarks. It can now process 4x more pixels and perform more tasks/applications than before. Check out the <a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">blog post</a>, and explore the <a href="https://llava.hliu.cc/">demo</a>! Models are available in <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md">Model Zoo</a>. Training/eval data and scripts coming soon.</p> </li> 
</ul> 
<details> 
 More 
 <ul> 
  <li> <p>[2024/03/10] 🔥 Releasing <strong>LMMs-Eval</strong>, a highly efficient evaluation pipeline we used when developing LLaVA-NeXT. It supports the evaluation of LMMs on dozens of public datasets and allows new dataset onboarding, making the dev of new LMMs much faster. [<a href="https://lmms-lab.github.io/lmms-eval-blog/lmms-eval-0.1/">Blog</a>] [<a href="https://github.com/EvolvingLMMs-Lab/lmms-eval">Codebase</a>]</p> </li> 
  <li> <p>[2023/11/10] <a href="https://llava-vl.github.io/llava-plus/">LLaVA-Plus</a> is released: Learning to Use Tools for Creating Multimodal Agents, with LLaVA-Plus (LLaVA that Plug and Learn to Use Skills). [<a href="https://llava-vl.github.io/llava-plus/">Project Page</a>] [<a href="https://llavaplus.ngrok.io/">Demo</a>] [<a href="https://github.com/LLaVA-VL/LLaVA-Plus-Codebase">Code</a>] [<a href="https://arxiv.org/abs/2311.05437">Paper</a>]</p> </li> 
  <li> <p>[2023/11/02] <a href="https://llava-vl.github.io/llava-interactive/">LLaVA-Interactive</a> is released: Experience the future of human-AI multimodal interaction with an all-in-one demo for Image Chat, Segmentation, Generation and Editing. [<a href="https://llava-vl.github.io/llava-interactive/">Project Page</a>] [<a href="https://llavainteractive.ngrok.io/">Demo</a>] [<a href="https://github.com/LLaVA-VL/LLaVA-Interactive-Demo">Code</a>] [<a href="https://arxiv.org/abs/2311.00571">Paper</a>]</p> </li> 
  <li> <p>[2023/10/26] 🔥 LLaVA-1.5 with LoRA achieves comparable performance as full-model finetuning, with a reduced GPU RAM requirement (<a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md#llava-v15">ckpts</a>, <a href="https://github.com/haotian-liu/LLaVA#train">script</a>). We also provide a <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/Finetune_Custom_Data.md">doc</a> on how to finetune LLaVA-1.5 on your own dataset with LoRA.</p> </li> 
  <li> <p>[2023/10/12] Check out the Korean LLaVA (Ko-LLaVA), created by ETRI, who has generously supported our research! [<a href="https://huggingface.co/spaces/etri-vilab/Ko-LLaVA">🤗 Demo</a>]</p> </li> 
  <li> <p>[2023/10/05] 🔥 LLaVA-1.5 is out! Achieving SoTA on 11 benchmarks, with just simple modifications to the original LLaVA, utilizes all public data, completes training in ~1 day on a single 8-A100 node, and surpasses methods like Qwen-VL-Chat that use billion-scale data. Check out the <a href="https://arxiv.org/abs/2310.03744">technical report</a>, and explore the <a href="https://llava.hliu.cc/">demo</a>! Models are available in <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md">Model Zoo</a>. The training data and scripts of LLaVA-1.5 are released <a href="https://github.com/haotian-liu/LLaVA#train">here</a>, and evaluation scripts are released <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/Evaluation.md">here</a>!</p> </li> 
  <li> <p>[2023/09/26] LLaVA is improved with reinforcement learning from human feedback (RLHF) to improve fact grounding and reduce hallucination. Check out the new SFT and RLHF checkpoints at project <a href="https://llava-rlhf.github.io/">[LLavA-RLHF]</a></p> </li> 
  <li> <p>[2023/09/22] <a href="https://arxiv.org/abs/2304.08485">LLaVA</a> is accepted by NeurIPS 2023 as <strong>oral presentation</strong>, and <a href="https://arxiv.org/abs/2306.00890">LLaVA-Med</a> is accepted by NeurIPS 2023 Datasets and Benchmarks Track as <strong>spotlight presentation</strong>.</p> </li> 
  <li> <p>[2023/11/06] Support <strong>Intel</strong> dGPU and CPU platforms. <a href="https://github.com/haotian-liu/LLaVA/tree/intel/docs/intel">More details here.</a></p> </li> 
  <li> <p>[2023/10/12] LLaVA is now supported in <a href="https://github.com/ggerganov/llama.cpp/pull/3436">llama.cpp</a> with 4-bit / 5-bit quantization support!</p> </li> 
  <li> <p>[2023/10/11] The training data and scripts of LLaVA-1.5 are released <a href="https://github.com/haotian-liu/LLaVA#train">here</a>, and evaluation scripts are released <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/Evaluation.md">here</a>!</p> </li> 
  <li> <p>[2023/10/10] <a href="https://blog.roboflow.com/first-impressions-with-llava-1-5/">Roboflow Deep Dive</a>: First Impressions with LLaVA-1.5.</p> </li> 
  <li> <p>[2023/09/20] We summarize our empirical study of training 33B and 65B LLaVA models in a <a href="https://arxiv.org/abs/2309.09958">note</a>. Further, if you are interested in the comprehensive review, evolution and trend of multimodal foundation models, please check out our recent survey paper <a href="https://arxiv.org/abs/2309.10020">``Multimodal Foundation Models: From Specialists to General-Purpose Assistants''.</a></p> </li> 
 </ul> 
 <p align="center"> <img src="https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings/raw/main/images/mfm_evolution.jpeg?raw=true" width="50%/" /> </p> 
 <ul> 
  <li>[2023/07/19] 🔥 We release a major upgrade, including support for LLaMA-2, LoRA training, 4-/8-bit inference, higher resolution (336x336), and a lot more. We release <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/LLaVA_Bench.md">LLaVA Bench</a> for benchmarking open-ended visual chat with results from Bard and Bing-Chat. We also support and verify training with RTX 3090 and RTX A6000. Check out <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/LLaVA_from_LLaMA2.md">LLaVA-from-LLaMA-2</a>, and our <a href="https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md">model zoo</a>!</li> 
  <li>[2023/06/26] <a href="https://vlp-tutorial.github.io/">CVPR 2023 Tutorial</a> on <strong>Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4</strong>! Please check out [<a href="https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Chunyuan_cvpr2023_tutorial_lmm.pdf">Slides</a>] [<a href="https://arxiv.org/abs/2306.14895">Notes</a>] [<a href="https://youtu.be/mkI7EPD1vp8">YouTube</a>] [<a href="https://www.bilibili.com/video/BV1Ng4y1T7v3/">Bilibli</a>].</li> 
  <li>[2023/06/11] We released the preview for the most requested feature: DeepSpeed and LoRA support! Please see documentations <a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LoRA.md">here</a>.</li> 
  <li>[2023/06/01] We released <strong>LLaVA-Med: Large Language and Vision Assistant for Biomedicine</strong>, a step towards building biomedical domain large language and vision models with GPT-4 level capabilities. Checkout the <a href="https://arxiv.org/abs/2306.00890">paper</a> and <a href="https://github.com/microsoft/LLaVA-Med">page</a>.</li> 
  <li>[2023/05/06] We are releasing <a href="https://huggingface.co/liuhaotian/LLaVA-Lightning-MPT-7B-preview">LLaVA-Lighting-MPT-7B-preview</a>, based on MPT-7B-Chat! See <a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/#LLaVA-MPT-7b">here</a> for more details.</li> 
  <li>[2023/05/02] 🔥 We are releasing LLaVA-Lighting! Train a lite, multimodal GPT-4 with just $40 in 3 hours! See <a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/#train-llava-lightning">here</a> for more details.</li> 
  <li>[2023/04/27] Thanks to the community effort, LLaVA-13B with 4-bit quantization allows you to run on a GPU with as few as 12GB VRAM! Try it out <a href="https://github.com/oobabooga/text-generation-webui/tree/main/extensions/llava">here</a>.</li> 
  <li>[2023/04/17] 🔥 We released <strong>LLaVA: Large Language and Vision Assistant</strong>. We propose visual instruction tuning, towards building large language and vision models with GPT-4 level capabilities. Checkout the <a href="https://arxiv.org/abs/2304.08485">paper</a> and <a href="https://llava.hliu.cc/">demo</a>.</li> 
 </ul> 
</details> 
<!-- <a href="https://llava.hliu.cc/"><img src="assets/demo.gif" width="70%"></a> --> 
<p><strong>Usage and License Notices</strong>: This project utilizes certain datasets and checkpoints that are subject to their respective original licenses. Users must comply with all terms and conditions of these original licenses, including but not limited to the <a href="https://openai.com/policies/terms-of-use">OpenAI Terms of Use</a> for the dataset and the specific licenses for base language models for checkpoints trained using the dataset (e.g. <a href="https://ai.meta.com/llama/license/">Llama-1/2 community license</a> for LLaMA-2 and Vicuna-v1.5, <a href="https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat/blob/main/LICENSE">Tongyi Qianwen RESEARCH LICENSE AGREEMENT</a> and <a href="https://llama.meta.com/llama3/license/">Llama-3 Research License</a>). This project does not impose any additional constraints beyond those stipulated in the original licenses. Furthermore, users are reminded to ensure that their use of the dataset and checkpoints is in compliance with all applicable laws and regulations.</p> 
<h2>Models &amp; Scripts</h2> 
<h3>Installation</h3> 
<h4>1. <strong>Clone this repository and navigate to the LLaVA folder:</strong></h4> 
<pre><code class="language-bash">git clone https://github.com/LLaVA-VL/LLaVA-NeXT
cd LLaVA-NeXT
</code></pre> 
<h4>2. <strong>Install the inference package:</strong></h4> 
<pre><code class="language-bash">conda create -n llava python=3.10 -y
conda activate llava
pip install --upgrade pip  # Enable PEP 660 support.
pip install -e ".[train]"
</code></pre> 
<h3>Project Navigation</h3> 
<p>Please checkout the following page for more inference &amp; evaluation details.</p> 
<h4>- <strong>LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild</strong></h4> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT.md">LLaVA-NeXT-Image</a>: for image demo inference and evaluation of stronger LMMs using <a href="https://github.com/EvolvingLMMs-Lab/lmms-eval">lmms-eval</a>.</li> 
</ul> 
<h4>- LLaVA-NeXT: A Strong Zero-shot Video Understanding Model</h4> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT-Video.md">LLaVA-NeXT-Video</a>: for video inference and evaluation scripts. We recommend to use <a href="https://lmms-lab.github.io/posts/lmms-eval-0.2/">LMMs-video</a> for evaluation.</li> 
</ul> 
<h4>- LLaVA-NeXT: Tackling Multi-image, Video, and 3D in Large Multimodal Models</h4> 
<ul> 
 <li><a href="https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT-Interleave.md">LLaVA-NeXT-Interleave</a>: for multi-image demo and evaluation scripts.</li> 
</ul> 
<h2>SGLang for SpeedUp Inference and Deployment</h2> 
<p>We use <a href="https://github.com/sgl-project/sglang">SGLang</a> to speed up inference and deployment of LLaVA-NeXT. You could make LLaVA-NeXT as a backend API service with SGLang.</p> 
<p><strong>Prepare Environment</strong>: Following the instruction in the <a href="https://github.com/sgl-project/sglang?tab=readme-ov-file#install">sglang</a></p> 
<h3>LLaVA-NeXT (Image)</h3> 
<p>Checkout the HTTP Post/Get and SRT usage at <a href="https://github.com/sgl-project/sglang/raw/main/examples/usage/llava">sglang/examples/usage/llava</a></p> 
<h3>LLaVA-NeXT (Video)</h3> 
<p><strong>Launch and Run on (K) Nodes</strong>:</p> 
<ul> 
 <li>Go to sglang project <pre><code>cd PATH_TO/sglang
</code></pre> </li> 
 <li>First node: <pre><code class="language-sh">bash examples/usage/llava_video/srt_example_llava_v.sh K 0 YOUR_VIDEO_PATH YOUR_MODEL_PATH FRAMES_PER_VIDEO
(e.g. bash examples/usage/llava_video/srt_example_llava_v.sh K 0 examples/usage/llava_video/videos/Q98Z4OTh8RwmDonc.mp4 lmms-lab/LLaVA-NeXT-Video-7B-DPO 16)
</code></pre> </li> 
 <li>Second node: <pre><code class="language-sh">bash examples/usage/llava_video/srt_example_llava_v.sh K 1 YOUR_VIDEO_PATH YOUR_MODEL_PATH FRAMES_PER_VIDEO
</code></pre> </li> 
 <li>The K node: <pre><code class="language-sh">bash examples/usage/llava_video/srt_example_llava_v.sh K K-1 YOUR_VIDEO_PATH YOUR_MODEL_PATH FRAMES_PER_VIDEO
</code></pre> </li> 
</ul> 
<h2>Citation</h2> 
<p>If you find it useful for your research and applications, please cite related papers/blogs using this BibTeX:</p> 
<pre><code class="language-bibtex">@article{li2024llava,
  title={LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models},
  author={Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan},
  journal={arXiv preprint arXiv:2407.07895},
  year={2024}
}

@misc{li2024llavanext-ablations,
	title={LLaVA-NeXT: What Else Influences Visual Instruction Tuning Beyond Data?},
	url={https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/},
	author={Li, Bo and Zhang, Hao and Zhang, Kaichen and Guo, Dong and Zhang, Yuanhan and Zhang, Renrui and Li, Feng and Liu, Ziwei and Li, Chunyuan},
	month={May},
	year={2024}
}

@misc{li2024llavanext-strong,
    title={LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild},
    url={https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/},
    author={Li, Bo and Zhang, Kaichen and Zhang, Hao and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Yuanhan and Liu, Ziwei and Li, Chunyuan},
    month={May},
    year={2024}
}

@misc{zhang2024llavanext-video,
  title={LLaVA-NeXT: A Strong Zero-shot Video Understanding Model},
  url={https://llava-vl.github.io/blog/2024-04-30-llava-next-video/},
  author={Zhang, Yuanhan and Li, Bo and Liu, haotian and Lee, Yong jae and Gui, Liangke and Fu, Di and Feng, Jiashi and Liu, Ziwei and Li, Chunyuan},
  month={April},
  year={2024}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@misc{liu2023improvedllava,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
      publisher={arXiv:2310.03744},
      year={2023},
}

@misc{liu2023llava,
      title={Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
      publisher={NeurIPS},
      year={2023},
}
</code></pre> 
<h2>Acknowledgement</h2> 
<ul> 
 <li><a href="https://github.com/lm-sys/FastChat">Vicuna</a>: the codebase we built upon, and our base model Vicuna-13B that has the amazing language capabilities!</li> 
 <li>The LLaVA-NeXT project is currently maintained by the team along with our contributors (listed alphabetically by the first names): <a href="https://brianboli.com/">Bo Li</a>, <a href="https://www.linkedin.com/in/dongguoset/">Dong Guo</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=ybRe9GcAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Feng Li</a>, <a href="https://scholar.google.com/citations?user=B8hPxMQAAAAJ&amp;hl=en">Hao Zhang</a>, <a href="https://www.linkedin.com/in/kaichen-zhang-014b17219/?originalSubdomain=sg">Kaichen Zhang</a>, <a href="https://zrrskywalker.github.io/">Renrui Zhang</a>, <a href="https://zhangyuanhan-ai.github.io/">Yuanhan Zhang</a>, led by <a href="https://chunyuan.li/">Chunyuan Li</a> and with the guidance and help from <a href="https://hliu.cc/">Haotian Liu</a>.</li> 
 <li>The <code>﻿lmms-eval</code> framework and its core contributors, including Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, and Kairui Hu, for their support on the evaluation side.</li> 
</ul> 
<h2>Related Projects</h2> 
<ul> 
 <li><a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM">Instruction Tuning with GPT-4</a></li> 
 <li><a href="https://github.com/microsoft/LLaVA-Med">LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day</a></li> 
 <li><a href="https://github.com/Luodian/Otter">Otter: In-Context Multi-Modal Instruction Tuning</a></li> 
</ul> 
<p>For future project ideas, please check out:</p> 
<ul> 
 <li><a href="https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once">SEEM: Segment Everything Everywhere All at Once</a></li> 
 <li><a href="https://github.com/IDEA-Research/Grounded-Segment-Anything">Grounded-Segment-Anything</a> to detect, segment, and generate anything by marrying <a href="https://github.com/IDEA-Research/GroundingDINO">Grounding DINO</a> and <a href="https://github.com/facebookresearch/segment-anything">Segment-Anything</a>.</li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>hacksider/Deep-Live-Cam</title>
<link>https://github.com/hacksider/Deep-Live-Cam</link>
<guid>https://github.com/hacksider/Deep-Live-Cam</guid>
<content:encoded><![CDATA[
<div> 关键词：实时人脸互换、一键视频深度伪造、单张图像、AI生成媒体、法律与伦理

总结:

本文介绍了一款用于实时人脸互换和一键视频深度伪造的软件，旨在为艺术家提供工具，如动画定制角色或作为服装模特等任务。开发者意识到该软件可能被不当使用，并已内置检查机制以防止处理不适当内容，如裸体、暴力或敏感素材。如果要求，项目可能会关闭或在输出中添加水印。

安装步骤包括安装Python、pip和Git，克隆代码库，下载模型文件，使用虚拟环境安装依赖项，并根据GPU可用性选择特定的执行提供程序进行加速。软件通过命令行运行，允许用户指定源图像、目标图像或视频、输出位置、帧处理器、保持帧速率、音频和临时文件等功能。

使用方法涉及选择面部图像、目标图像或视频，启动程序，观察实时预览并处理完成后的输出文件。命令行选项提供额外控制，如保持原始帧率、音频和临时文件、处理每个面部、过滤不适当内容等。

最后，用户被提醒负责任地使用软件，特别是当使用真实人物面部时，需获得同意并在在线发布内容时明确表示为深度伪造。开发者不承担用户行为的责任。 <div>
<p>real time face swap and one-click video deepfake with only a single image</p><hr /><p><img alt="demo-gif" src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/demo.gif" /></p> 
<h2>Disclaimer</h2> 
<p>This software is meant to be a productive contribution to the rapidly growing AI-generated media industry. It will help artists with tasks such as animating a custom character or using the character as a model for clothing etc.</p> 
<p>The developers of this software are aware of its possible unethical applications and are committed to take preventative measures against them. It has a built-in check which prevents the program from working on inappropriate media including but not limited to nudity, graphic content, sensitive material such as war footage etc. We will continue to develop this project in the positive direction while adhering to law and ethics. This project may be shut down or include watermarks on the output if requested by law.</p> 
<p>Users of this software are expected to use this software responsibly while abiding by local laws. If the face of a real person is being used, users are required to get consent from the concerned person and clearly mention that it is a deepfake when posting content online. Developers of this software will not be responsible for actions of end-users.</p> 
<h2>How do I install it?</h2> 
<h3>Basic: It is more likely to work on your computer but it will also be very slow. You can follow instructions for the basic install (This usually runs via <strong>CPU</strong>)</h3> 
<h4>1.Setup your platform</h4> 
<ul> 
 <li>python (3.10 recommended)</li> 
 <li>pip</li> 
 <li>git</li> 
 <li><a href="https://www.youtube.com/watch?v=OlNWCpFdVMA">ffmpeg</a></li> 
 <li><a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/">visual studio 2022 runtimes (windows)</a></li> 
</ul> 
<h4>2. Clone Repository</h4> 
<pre><code>https://github.com/hacksider/Deep-Live-Cam.git
</code></pre> 
<h4>3. Download Models</h4> 
<ol> 
 <li><a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth">GFPGANv1.4</a></li> 
 <li><a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx">inswapper_128_fp16.onnx</a></li> 
</ol> 
<p>Then put those 2 files on the "<strong>models</strong>" folder</p> 
<h4>4. Install dependency</h4> 
<p>We highly recommend to work with a <code>venv</code> to avoid issues.</p> 
<pre><code>pip install -r requirements.txt
</code></pre> 
<p>For MAC OS, You have to install or upgrade python-tk package:</p> 
<pre><code>brew install python-tk@3.10
</code></pre> 
<h5>DONE!!! If you dont have any GPU, You should be able to run roop using <code>python run.py</code> command. Keep in mind that while running the program for first time, it will download some models which can take time depending on your network connection.</h5> 
<h3>*Proceed if you want to use GPU Acceleration</h3> 
<h3>CUDA Execution Provider (Nvidia)*</h3> 
<ol> 
 <li> <p>Install <a href="https://developer.nvidia.com/cuda-11-8-0-download-archive">CUDA Toolkit 11.8</a></p> </li> 
 <li> <p>Install dependencies:</p> </li> 
</ol> 
<pre><code>pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.16.3

</code></pre> 
<ol start="3"> 
 <li>Usage in case the provider is available:</li> 
</ol> 
<pre><code>python run.py --execution-provider cuda

</code></pre> 
<h3><a href="https://github.com/s0md3v/roop/wiki/2.-Acceleration#coreml-execution-provider-apple-silicon"></a>CoreML Execution Provider (Apple Silicon)</h3> 
<ol> 
 <li>Install dependencies:</li> 
</ol> 
<pre><code>pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1

</code></pre> 
<ol start="2"> 
 <li>Usage in case the provider is available:</li> 
</ol> 
<pre><code>python run.py --execution-provider coreml

</code></pre> 
<h3><a href="https://github.com/s0md3v/roop/wiki/2.-Acceleration#coreml-execution-provider-apple-legacy"></a>CoreML Execution Provider (Apple Legacy)</h3> 
<ol> 
 <li>Install dependencies:</li> 
</ol> 
<pre><code>pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.13.1

</code></pre> 
<ol start="2"> 
 <li>Usage in case the provider is available:</li> 
</ol> 
<pre><code>python run.py --execution-provider coreml

</code></pre> 
<h3><a href="https://github.com/s0md3v/roop/wiki/2.-Acceleration#directml-execution-provider-windows"></a>DirectML Execution Provider (Windows)</h3> 
<ol> 
 <li>Install dependencies:</li> 
</ol> 
<pre><code>pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.15.1

</code></pre> 
<ol start="2"> 
 <li>Usage in case the provider is available:</li> 
</ol> 
<pre><code>python run.py --execution-provider directml

</code></pre> 
<h3><a href="https://github.com/s0md3v/roop/wiki/2.-Acceleration#openvino-execution-provider-intel"></a>OpenVINO™ Execution Provider (Intel)</h3> 
<ol> 
 <li>Install dependencies:</li> 
</ol> 
<pre><code>pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.15.0

</code></pre> 
<ol start="2"> 
 <li>Usage in case the provider is available:</li> 
</ol> 
<pre><code>python run.py --execution-provider openvino
</code></pre> 
<h2>How do I use it?</h2> 
<blockquote> 
 <p>Note: When you run this program for the first time, it will download some models ~300MB in size.</p> 
</blockquote> 
<p>Executing <code>python run.py</code> command will launch this window: <img alt="gui-demo" src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/instruction.png" /></p> 
<p>Choose a face (image with desired face) and the target image/video (image/video in which you want to replace the face) and click on <code>Start</code>. Open file explorer and navigate to the directory you select your output to be in. You will find a directory named <code>&lt;video_title&gt;</code> where you can see the frames being swapped in realtime. Once the processing is done, it will create the output file. That's it.</p> 
<h2>For the webcam mode</h2> 
<p>Just follow the clicks on the screenshot</p> 
<ol> 
 <li>Select a face</li> 
 <li>Click live</li> 
 <li>Wait for a few seconds (it takes a longer time, usually 10 to 30 seconds before the preview shows up)</li> 
</ol> 
<p><img alt="demo-gif" src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/demo.gif" /></p> 
<p>Just use your favorite screencapture to stream like OBS</p> 
<blockquote> 
 <p>Note: In case you want to change your face, just select another picture, the preview mode will then restart (so just wait a bit).</p> 
</blockquote> 
<p>Additional command line arguments are given below. To learn out what they do, check <a href="https://github.com/s0md3v/roop/wiki/Advanced-Options">this guide</a>.</p> 
<pre><code>options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --nsfw-filter                                            filter the NSFW image or video
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
</code></pre> 
<p>Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.</p> 
<h2>Want the Next Update Now?</h2> 
<p>If you want the latest and greatest build, or want to see some new great features, go to our <a href="https://github.com/hacksider/Deep-Live-Cam/tree/experimental">experimental branch</a> and experience what the contributors have given.</p> 
<h2>Credits</h2> 
<ul> 
 <li><a href="https://ffmpeg.org/">ffmpeg</a>: for making video related operations easy</li> 
 <li><a href="https://github.com/deepinsight">deepinsight</a>: for their <a href="https://github.com/deepinsight/insightface">insightface</a> project which provided a well-made library and models.</li> 
 <li><a href="https://github.com/havok2-htwo">havok2-htwo</a> : for sharing the code for webcam</li> 
 <li><a href="https://github.com/GosuDRM/nsfw-roop">GosuDRM</a> : for uncensoring roop</li> 
 <li>and <a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors">all developers</a> behind libraries used in this project.</li> 
 <li>Foot Note: <a href="https://github.com/hacksider/roop-cam">This is originally roop-cam, see the full history of the code here.</a> Please be informed that the base author of the code is <a href="https://github.com/s0md3v/roop">s0md3v</a></li> 
</ul>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>goauthentik/authentik</title>
<link>https://github.com/goauthentik/authentik</link>
<guid>https://github.com/goauthentik/authentik</guid>
<content:encoded><![CDATA[
<div> 关键词：authentik、身份验证、开放源代码、Docker Compose、Helm Chart

总结:
authentik是一个强调灵活性和多样性的开源身份提供者，支持广泛的协议。它被推荐用于小型测试设置中的Docker Compose部署，以及大型设置中的Helm Chart部署。对于需要替换Okta、Auth0、Entra ID、Ping Identity等传统IDP的大规模企业或B2B2C业务来说，authentik是一个自托管的理想选择。用户可以根据自己的需求选择适合的部署方式。此外，authentik提供了一个开发者社区，鼓励贡献和合作，希望有更多组织使用并参与到项目中来。如果您正在使用authentik，可以向项目团队提交您的Logo以示支持，并参与贡献代码或提出改进建议。 <div>
<p>The authentication glue you need.</p><hr /><p align="center"> <img alt="authentik logo" height="150" src="https://goauthentik.io/img/icon_top_brand_colour.svg?sanitize=true" /> </p> 
<hr /> 
<p><a href="https://goauthentik.io/discord"><img alt="Join Discord" src="https://img.shields.io/discord/809154715984199690?label=Discord&amp;style=for-the-badge" /></a> <a href="https://github.com/goauthentik/authentik/actions/workflows/ci-main.yml"><img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/goauthentik/authentik/ci-main.yml?branch=main&amp;label=core%20build&amp;style=for-the-badge" /></a> <a href="https://github.com/goauthentik/authentik/actions/workflows/ci-outpost.yml"><img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/goauthentik/authentik/ci-outpost.yml?branch=main&amp;label=outpost%20build&amp;style=for-the-badge" /></a> <a href="https://github.com/goauthentik/authentik/actions/workflows/ci-web.yml"><img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/goauthentik/authentik/ci-web.yml?branch=main&amp;label=web%20build&amp;style=for-the-badge" /></a> <a href="https://codecov.io/gh/goauthentik/authentik"><img alt="Code Coverage" src="https://img.shields.io/codecov/c/gh/goauthentik/authentik?style=for-the-badge" /></a> <img alt="Docker pulls" src="https://img.shields.io/docker/pulls/beryju/authentik.svg?style=for-the-badge" /> <img alt="Latest version" src="https://img.shields.io/docker/v/beryju/authentik?sort=semver&amp;style=for-the-badge" /> <a href="https://www.transifex.com/authentik/authentik/"><img alt="" src="https://img.shields.io/badge/Help%20translate-transifex-blue?style=for-the-badge" /></a></p> 
<h2>What is authentik?</h2> 
<p>authentik is an open-source Identity Provider that emphasizes flexibility and versatility, with support for a wide set of protocols.</p> 
<p>Our <a href="https://goauthentik.io/pricing">enterprise offer</a> can also be used as a self-hosted replacement for large-scale deployments of Okta/Auth0, Entra ID, Ping Identity, or other legacy IdPs for employees and B2B2C use.</p> 
<h2>Installation</h2> 
<p>For small/test setups it is recommended to use Docker Compose; refer to the <a href="https://goauthentik.io/docs/installation/docker-compose/?utm_source=github">documentation</a>.</p> 
<p>For bigger setups, there is a Helm Chart <a href="https://github.com/goauthentik/helm">here</a>. This is documented <a href="https://goauthentik.io/docs/installation/kubernetes/?utm_source=github">here</a>.</p> 
<h2>Screenshots</h2> 
<table> 
 <thead> 
  <tr> 
   <th>Light</th> 
   <th>Dark</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><img alt="" src="https://docs.goauthentik.io/img/screen_apps_light.jpg" /></td> 
   <td><img alt="" src="https://docs.goauthentik.io/img/screen_apps_dark.jpg" /></td> 
  </tr> 
  <tr> 
   <td><img alt="" src="https://docs.goauthentik.io/img/screen_admin_light.jpg" /></td> 
   <td><img alt="" src="https://docs.goauthentik.io/img/screen_admin_dark.jpg" /></td> 
  </tr> 
 </tbody> 
</table> 
<h2>Development</h2> 
<p>See <a href="https://goauthentik.io/developer-docs/?utm_source=github">Developer Documentation</a></p> 
<h2>Security</h2> 
<p>See <a href="https://raw.githubusercontent.com/goauthentik/authentik/main/SECURITY.md">SECURITY.md</a></p> 
<h2>Adoption and Contributions</h2> 
<p>Your organization uses authentik? We'd love to add your logo to the readme and our website! Email us @ <a href="mailto:hello@goauthentik.io">hello@goauthentik.io</a> or open a GitHub Issue/PR! For more information on how to contribute to authentik, please refer to our <a href="https://raw.githubusercontent.com/goauthentik/authentik/main/CONTRIBUTING.md">CONTRIBUTING.md file</a>.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>lllyasviel/stable-diffusion-webui-forge</title>
<link>https://github.com/lllyasviel/stable-diffusion-webui-forge</link>
<guid>https://github.com/lllyasviel/stable-diffusion-webui-forge</guid>
<content:encoded><![CDATA[
<div> 关键词：Stable Diffusion WebUI Forge、安装、高级安装、状态、UnetPatcher

文章总结：

Stable Diffusion WebUI Forge是一个基于Stable Diffusion WebUI的平台，旨在简化开发过程，优化资源管理，加速推理速度并研究实验功能。其名称“Forge”灵感来源于Minecraft中的同名组件，目标是成为Stable Diffusion WebUI的扩展。

**1. 安装**
Forge提供了一个一键安装包，其中包含了Git和Python，用户只需解压缩文件、运行update.bat更新并使用run.bat启动即可。

**2. 高级安装**
对于熟悉Git的用户，可以将Forge作为SD-WebUI的分支进行安装，这样可以复用原有的检查点和扩展，但需要用户了解操作风险。

**3. 状态**
文章列出了多个组件的状态，包括基本扩散、GPU内存管理系统、LoRAs、预处理器、控制网等，均显示为正常工作。同时，指出了部分UI（如Gradio 4 UIs）和特定功能（如Microsoft Surface触压支持）的状态。

**4. UnetPatcher**
文章展示了UnetPatcher的实现代码，用于集成FreeU V2功能，包括FFT滤波器实现、设备适应性和块补丁逻辑，以及与主模型的整合方式。

**5. 建设中**
文章指出Forge正处于建设阶段，文档、用户界面和功能可能会随着更新而改变。

总结：
Stable Diffusion WebUI Forge是一个为Stable Diffusion WebUI量身定制的增强平台，通过提供一键安装包、支持高级安装选项、展示组件状态、展示UnetPatcher实现细节以及提示用户注意其仍在建设中，为用户提供了一种更高效、更灵活的使用体验。其目标是通过优化资源管理和加速推理速度来提升扩散模型的实用性，同时也为实验性功能的研究提供了便利。 <div>
<p></p><hr /><h1>Stable Diffusion WebUI Forge</h1> 
<p>Stable Diffusion WebUI Forge is a platform on top of <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">Stable Diffusion WebUI</a> (based on <a href="https://www.gradio.app/">Gradio</a> <a href="https://github.com/gradio-app/gradio"><img src="https://img.shields.io/github/stars/gradio-app/gradio" /></a>) to make development easier, optimize resource management, speed up inference, and study experimental features.</p> 
<p>The name "Forge" is inspired from "Minecraft Forge". This project is aimed at becoming SD WebUI's Forge.</p> 
<p>Forge is currently based on SD-WebUI 1.10.1 at <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2">this commit</a>. (Because original SD-WebUI is almost static now, Forge will sync with original WebUI every 90 days, or when important fixes.)</p> 
<h1>Quick List</h1> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/853">Gradio 4 UI Must Read (TLDR: You need to use RIGHT MOUSE BUTTON to move canvas!)</a></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981">Flux Tutorial (BitsandBytes Models, NF4, "GPU Weight", "Offload Location", "Offload Method", etc)</a></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1050">Flux Tutorial 2 (Seperated Full Models, GGUF, Technically Correct Comparison between GGUF and NF4, etc)</a></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1181">Report Flux Performance Problems (TLDR: DO NOT set "GPU Weight" too high! Lower "GPU Weight" solves 99% problems!)</a></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1224#discussioncomment-10384104">(Save Flux BitsandBytes UNet/Checkpoint)</a></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/854">LayerDiffuse Transparent Image Editing</a></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1286">(Policy) Soft Advertisement Removal Policy</a></p> 
<p>(Flux BNB NF4 / GGUF Q8_0/Q5_0/Q5_1/Q4_0/Q4_1 are all natively supported with GPU weight slider and Quene/Async Swap toggle and swap location toggle. All Flux BNB NF4 / GGUF Q8_0/Q5_0/Q4_0 have LoRA support.)</p> 
<h1>Installing Forge</h1> 
<p><strong>Just use this one-click installation package (with git and python included).</strong></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z">&gt;&gt;&gt; Click Here to Download One-Click Package (CUDA 12.1 + Pytorch 2.3.1) &lt;&lt;&lt;</a></p> 
<p>Some other CUDA/Torch Versions:</p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z">Forge with CUDA 12.1 + Pytorch 2.3.1</a> &lt;- <strong>Recommended</strong></p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu124_torch24.7z">Forge with CUDA 12.4 + Pytorch 2.4</a> &lt;- <strong>Fastest</strong>, but MSVC may be broken, xformers may not work</p> 
<p><a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch21.7z">Forge with CUDA 12.1 + Pytorch 2.1</a> &lt;- the previously used old environments</p> 
<p>After you download, you uncompress, use <code>update.bat</code> to update, and use <code>run.bat</code> to run.</p> 
<p>Note that running <code>update.bat</code> is important, otherwise you may be using a previous version with potential bugs unfixed.</p> 
<p><img alt="image" src="https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/19834515/c49bd60d-82bd-4086-9859-88d472582b94" /></p> 
<h3>Advanced Install</h3> 
<p>If you are proficient in Git and you want to install Forge as another branch of SD-WebUI, please see <a href="https://github.com/continue-revolution/sd-webui-animatediff/raw/forge/master/docs/how-to-use.md#you-have-a1111-and-you-know-git">here</a>. In this way, you can reuse all SD checkpoints and all extensions you installed previously in your OG SD-WebUI, but you should know what you are doing.</p> 
<p>If you know what you are doing, you can also install Forge using same method as SD-WebUI. (Install Git, Python, Git Clone the forge repo <code>https://github.com/lllyasviel/stable-diffusion-webui-forge.git</code> and then run webui-user.bat).</p> 
<h3>Previous Versions</h3> 
<p>You can download previous versions <a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/849">here</a>.</p> 
<h1>Forge Status</h1> 
<p>Based on manual test one-by-one:</p> 
<table> 
 <thead> 
  <tr> 
   <th>Component</th> 
   <th>Status</th> 
   <th>Last Test</th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td>Basic Diffusion</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>GPU Memory Management System</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>LoRAs</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>All Preprocessors</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>All ControlNets</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>All IP-Adapters</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>All Instant-IDs</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>All Reference-only Methods</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>All Integrated Extensions</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>Popular Extensions (Adetailer, etc)</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>Gradio 4 UIs</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>Gradio 4 Forge Canvas</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>LoRA/Checkpoint Selection UI for Gradio 4</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>Photopea/OpenposeEditor/etc for ControlNet</td> 
   <td>Normal</td> 
   <td>2024 July 27</td> 
  </tr> 
  <tr> 
   <td>Wacom 128 level touch pressure support for Canvas</td> 
   <td>Normal</td> 
   <td>2024 July 15</td> 
  </tr> 
  <tr> 
   <td>Microsoft Surface touch pressure support for Canvas</td> 
   <td>Broken, pending fix</td> 
   <td>2024 July 29</td> 
  </tr> 
  <tr> 
   <td>txt2img and img2img API Endpoints</td> 
   <td>Broken, pending fix</td> 
   <td>2024 July 29</td> 
  </tr> 
 </tbody> 
</table> 
<p>Feel free to open issue if anything is broken and I will take a look every several days. If I do not update this "Forge Status" then it means I cannot reproduce any problem. In that case, fresh re-install should help most.</p> 
<h1>UnetPatcher</h1> 
<p>Below are self-supported <strong>single file</strong> of all codes to implement FreeU V2.</p> 
<p>See also <code>extension-builtin/sd_forge_freeu/scripts/forge_freeu.py</code>:</p> 
<pre><code class="language-python">import torch
import gradio as gr

from modules import scripts


def Fourier_filter(x, threshold, scale):
    # FFT
    x_freq = torch.fft.fftn(x.float(), dim=(-2, -1))
    x_freq = torch.fft.fftshift(x_freq, dim=(-2, -1))

    B, C, H, W = x_freq.shape
    mask = torch.ones((B, C, H, W), device=x.device)

    crow, ccol = H // 2, W // 2
    mask[..., crow - threshold:crow + threshold, ccol - threshold:ccol + threshold] = scale
    x_freq = x_freq * mask

    # IFFT
    x_freq = torch.fft.ifftshift(x_freq, dim=(-2, -1))
    x_filtered = torch.fft.ifftn(x_freq, dim=(-2, -1)).real

    return x_filtered.to(x.dtype)


def patch_freeu_v2(unet_patcher, b1, b2, s1, s2):
    model_channels = unet_patcher.model.diffusion_model.config["model_channels"]
    scale_dict = {model_channels * 4: (b1, s1), model_channels * 2: (b2, s2)}
    on_cpu_devices = {}

    def output_block_patch(h, hsp, transformer_options):
        scale = scale_dict.get(h.shape[1], None)
        if scale is not None:
            hidden_mean = h.mean(1).unsqueeze(1)
            B = hidden_mean.shape[0]
            hidden_max, _ = torch.max(hidden_mean.view(B, -1), dim=-1, keepdim=True)
            hidden_min, _ = torch.min(hidden_mean.view(B, -1), dim=-1, keepdim=True)
            hidden_mean = (hidden_mean - hidden_min.unsqueeze(2).unsqueeze(3)) / (hidden_max - hidden_min).unsqueeze(2).unsqueeze(3)

            h[:, :h.shape[1] // 2] = h[:, :h.shape[1] // 2] * ((scale[0] - 1) * hidden_mean + 1)

            if hsp.device not in on_cpu_devices:
                try:
                    hsp = Fourier_filter(hsp, threshold=1, scale=scale[1])
                except:
                    print("Device", hsp.device, "does not support the torch.fft.")
                    on_cpu_devices[hsp.device] = True
                    hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)
            else:
                hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)

        return h, hsp

    m = unet_patcher.clone()
    m.set_model_output_block_patch(output_block_patch)
    return m


class FreeUForForge(scripts.Script):
    sorting_priority = 12  # It will be the 12th item on UI.

    def title(self):
        return "FreeU Integrated"

    def show(self, is_img2img):
        # make this extension visible in both txt2img and img2img tab.
        return scripts.AlwaysVisible

    def ui(self, *args, **kwargs):
        with gr.Accordion(open=False, label=self.title()):
            freeu_enabled = gr.Checkbox(label='Enabled', value=False)
            freeu_b1 = gr.Slider(label='B1', minimum=0, maximum=2, step=0.01, value=1.01)
            freeu_b2 = gr.Slider(label='B2', minimum=0, maximum=2, step=0.01, value=1.02)
            freeu_s1 = gr.Slider(label='S1', minimum=0, maximum=4, step=0.01, value=0.99)
            freeu_s2 = gr.Slider(label='S2', minimum=0, maximum=4, step=0.01, value=0.95)

        return freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2

    def process_before_every_sampling(self, p, *script_args, **kwargs):
        # This will be called before every sampling.
        # If you use highres fix, this will be called twice.

        freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2 = script_args

        if not freeu_enabled:
            return

        unet = p.sd_model.forge_objects.unet

        unet = patch_freeu_v2(unet, freeu_b1, freeu_b2, freeu_s1, freeu_s2)

        p.sd_model.forge_objects.unet = unet

        # Below codes will add some logs to the texts below the image outputs on UI.
        # The extra_generation_params does not influence results.
        p.extra_generation_params.update(dict(
            freeu_enabled=freeu_enabled,
            freeu_b1=freeu_b1,
            freeu_b2=freeu_b2,
            freeu_s1=freeu_s1,
            freeu_s2=freeu_s2,
        ))

        return
</code></pre> 
<p>See also <a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/raw/main/backend/nn/unet.py">Forge's Unet Implementation</a>.</p> 
<h1>Under Construction</h1> 
<p>WebUI Forge is now under some constructions, and docs / UI / functionality may change with updates.</p>
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>geekan/MetaGPT</title>
<link>https://github.com/geekan/MetaGPT</link>
<guid>https://github.com/geekan/MetaGPT</guid>
<content:encoded><![CDATA[
<div> 关键词：MetaGPT、软件公司、多代理系统、自然语言编程、LLM

总结：

MetaGPT是一款基于人工智能的软件公司模拟平台，旨在通过多代理系统实现复杂任务的协作完成。其核心理念是将“代码等于流程（SOP）”，即通过机器学习模型（LLM）来模拟软件开发公司中的各个角色和流程。MetaGPT支持用户通过一句需求描述生成项目规划、用户故事、竞争分析、数据结构、API设计等文档，甚至可以作为库直接调用，实现从概念到代码的自动化过程。

MetaGPT提供了一个开放源代码的框架，允许用户配置不同的LLM模型以扮演不同的角色，如产品经理、架构师、项目经理和工程师。这使得用户可以根据实际需求灵活地组合和调整AI代理的角色和能力。此外，MetaGPT还支持多种语言、多模态输入和增量开发功能，增强了其实用性和灵活性。

在发展过程中，MetaGPT不断更新和优化，增加了对RAG（阅读理解+代码生成）模块的支持，引入了更多强大的LLM模型，并通过集成不同的API和工具扩展了其功能。这些进展使得MetaGPT在软件开发领域展现了强大的潜力，成为了一个值得关注的开源项目。

MetaGPT不仅是一个技术创新的体现，也是自然语言处理和人工智能在软件工程领域的应用探索。它为开发者提供了全新的工作方式，有望加速软件开发流程并提升开发质量。 <div>
<p>🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming</p><hr /><h1>MetaGPT: The Multi-Agent Framework</h1> 
<p align="center"> <a href=""><img alt="MetaGPT logo: Enable GPT to work in software company, collaborating to tackle more complex tasks." src="https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/resources/MetaGPT-new-log.png" width="150px" /></a> </p> 
<p align="center"> <b>Assign different roles to GPTs to form a collaborative entity for complex tasks.</b> </p> 
<p align="center"> <a href="https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/README_CN.md"><img alt="CN doc" src="https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E4%B8%AD%E6%96%87%E7%89%88-blue.svg?sanitize=true" /></a> <a href="https://raw.githubusercontent.com/geekan/MetaGPT/main/README.md"><img alt="EN doc" src="https://img.shields.io/badge/document-English-blue.svg?sanitize=true" /></a> <a href="https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/README_JA.md"><img alt="JA doc" src="https://img.shields.io/badge/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88-%E6%97%A5%E6%9C%AC%E8%AA%9E-blue.svg?sanitize=true" /></a> <a href="https://opensource.org/licenses/MIT"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" /></a> <a href="https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/ROADMAP.md"><img alt="roadmap" src="https://img.shields.io/badge/ROADMAP-%E8%B7%AF%E7%BA%BF%E5%9B%BE-blue" /></a> <a href="https://discord.gg/DYn29wFk9z"><img alt="Discord Follow" src="https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat" /></a> <a href="https://twitter.com/MetaGPT_"><img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/MetaGPT?style=social" /></a> </p> 
<p align="center"> <a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/geekan/MetaGPT"><img alt="Open in Dev Containers" src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode" /></a> <a href="https://codespaces.new/geekan/MetaGPT"><img alt="Open in GitHub Codespaces" src="https://img.shields.io/badge/Github_Codespace-Open-blue?logo=github" /></a> <a href="https://huggingface.co/spaces/deepwisdom/MetaGPT" target="_blank"><img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20-Hugging%20Face-blue?color=blue&amp;logoColor=white" /></a> </p> 
<h2>News</h2> 
<p>🚀 Mar. 29, 2024: <a href="https://github.com/geekan/MetaGPT/releases/tag/v0.8.0">v0.8.0</a> released. Now you can use Data Interpreter (<a href="https://arxiv.org/abs/2402.18679">arxiv</a>, <a href="https://docs.deepwisdom.ai/main/en/DataInterpreter/">example</a>, <a href="https://github.com/geekan/MetaGPT/tree/main/examples/di">code</a>) via pypi package import. Meanwhile, we integrated RAG module and supported multiple new LLMs.</p> 
<p>🚀 Feb. 08, 2024: <a href="https://github.com/geekan/MetaGPT/releases/tag/v0.7.0">v0.7.0</a> released, supporting assigning different LLMs to different Roles. We also introduced <a href="https://github.com/geekan/MetaGPT/raw/main/examples/di/README.md">Data Interpreter</a>, a powerful agent capable of solving a wide range of real-world problems.</p> 
<p>🚀 Jan. 16, 2024: Our paper <a href="https://openreview.net/forum?id=VtmBAGCN7o">MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework </a> accepted for <strong>oral presentation (top 1.2%)</strong> at ICLR 2024, <strong>ranking #1</strong> in the LLM-based Agent category.</p> 
<p>🚀 Jan. 03, 2024: <a href="https://github.com/geekan/MetaGPT/releases/tag/v0.6.0">v0.6.0</a> released, new features include serialization, upgraded OpenAI package and supported multiple LLM, provided <a href="https://github.com/geekan/MetaGPT/raw/main/examples/debate_simple.py">minimal example for debate</a> etc.</p> 
<p>🚀 Dec. 15, 2023: <a href="https://github.com/geekan/MetaGPT/releases/tag/v0.5.0">v0.5.0</a> released, introducing some experimental features such as incremental development, multilingual, multiple programming languages, etc.</p> 
<p>🔥 Nov. 08, 2023: MetaGPT is selected into <a href="https://www.benchcouncil.org/evaluation/opencs/annual.html">Open100: Top 100 Open Source achievements</a>.</p> 
<p>🔥 Sep. 01, 2023: MetaGPT tops GitHub Trending Monthly for the <strong>17th time</strong> in August 2023.</p> 
<p>🌟 Jun. 30, 2023: MetaGPT is now open source.</p> 
<p>🌟 Apr. 24, 2023: First line of MetaGPT code committed.</p> 
<h2>Software Company as Multi-Agent System</h2> 
<ol> 
 <li>MetaGPT takes a <strong>one line requirement</strong> as input and outputs <strong>user stories / competitive analysis / requirements / data structures / APIs / documents, etc.</strong></li> 
 <li>Internally, MetaGPT includes <strong>product managers / architects / project managers / engineers.</strong> It provides the entire process of a <strong>software company along with carefully orchestrated SOPs.</strong> 
  <ol> 
   <li><code>Code = SOP(Team)</code> is the core philosophy. We materialize SOP and apply it to teams composed of LLMs.</li> 
  </ol> </li> 
</ol> 
<p><img alt="A software company consists of LLM-based roles" src="https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/resources/software_company_cd.jpeg" /></p> 
<p align="center">Software Company Multi-Agent Schematic (Gradually Implementing)</p> 
<h2>Get Started</h2> 
<h3>Installation</h3> 
<blockquote> 
 <p>Ensure that Python 3.9+ is installed on your system. You can check this by using: <code>python --version</code>.<br /> You can use conda like this: <code>conda create -n metagpt python=3.9 &amp;&amp; conda activate metagpt</code></p> 
</blockquote> 
<pre><code class="language-bash">pip install --upgrade metagpt
# or `pip install --upgrade git+https://github.com/geekan/MetaGPT.git`
# or `git clone https://github.com/geekan/MetaGPT &amp;&amp; cd MetaGPT &amp;&amp; pip install --upgrade -e .`
</code></pre> 
<p>For detailed installation guidance, please refer to <a href="https://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-stable-version">cli_install</a> or <a href="https://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-with-docker">docker_install</a></p> 
<h3>Configuration</h3> 
<p>You can init the config of MetaGPT by running the following command, or manually create <code>~/.metagpt/config2.yaml</code> file:</p> 
<pre><code class="language-bash"># Check https://docs.deepwisdom.ai/main/en/guide/get_started/configuration.html for more details
metagpt --init-config  # it will create ~/.metagpt/config2.yaml, just modify it to your needs
</code></pre> 
<p>You can configure <code>~/.metagpt/config2.yaml</code> according to the <a href="https://github.com/geekan/MetaGPT/raw/main/config/config2.example.yaml">example</a> and <a href="https://docs.deepwisdom.ai/main/en/guide/get_started/configuration.html">doc</a>:</p> 
<pre><code class="language-yaml">llm:
  api_type: "openai"  # or azure / ollama / groq etc. Check LLMType for more options
  model: "gpt-4-turbo"  # or gpt-3.5-turbo
  base_url: "https://api.openai.com/v1"  # or forward url / other llm url
  api_key: "YOUR_API_KEY"
</code></pre> 
<h3>Usage</h3> 
<p>After installation, you can use MetaGPT at CLI</p> 
<pre><code class="language-bash">metagpt "Create a 2048 game"  # this will create a repo in ./workspace
</code></pre> 
<p>or use it as library</p> 
<pre><code class="language-python">from metagpt.software_company import generate_repo, ProjectRepo
repo: ProjectRepo = generate_repo("Create a 2048 game")  # or ProjectRepo("&lt;path&gt;")
print(repo)  # it will print the repo structure with files
</code></pre> 
<p>You can also use <a href="https://github.com/geekan/MetaGPT/tree/main/examples/di">Data Interpreter</a> to write code:</p> 
<pre><code class="language-python">import asyncio
from metagpt.roles.di.data_interpreter import DataInterpreter

async def main():
    di = DataInterpreter()
    await di.run("Run data analysis on sklearn Iris dataset, include a plot")

asyncio.run(main())  # or await main() in a jupyter notebook setting
</code></pre> 
<h3>QuickStart &amp; Demo Video</h3> 
<ul> 
 <li>Try it on <a href="https://huggingface.co/spaces/deepwisdom/MetaGPT">MetaGPT Huggingface Space</a></li> 
 <li><a href="https://youtu.be/uT75J_KG_aY">Matthew Berman: How To Install MetaGPT - Build A Startup With One Prompt!!</a></li> 
 <li><a href="https://github.com/geekan/MetaGPT/assets/2707039/5e8c1062-8c35-440f-bb20-2b0320f8d27d">Official Demo Video</a></li> 
</ul> 
<p><a href="https://github.com/geekan/MetaGPT/assets/34952977/34345016-5d13-489d-b9f9-b82ace413419">https://github.com/geekan/MetaGPT/assets/34952977/34345016-5d13-489d-b9f9-b82ace413419</a></p> 
<h2>Tutorial</h2> 
<ul> 
 <li>🗒 <a href="https://docs.deepwisdom.ai/main/en/">Online Document</a></li> 
 <li>💻 <a href="https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html">Usage</a></li> 
 <li>🔎 <a href="https://docs.deepwisdom.ai/main/en/guide/get_started/introduction.html">What can MetaGPT do?</a></li> 
 <li>🛠 How to build your own agents? 
  <ul> 
   <li><a href="https://docs.deepwisdom.ai/main/en/guide/tutorials/agent_101.html">MetaGPT Usage &amp; Development Guide | Agent 101</a></li> 
   <li><a href="https://docs.deepwisdom.ai/main/en/guide/tutorials/multi_agent_101.html">MetaGPT Usage &amp; Development Guide | MultiAgent 101</a></li> 
  </ul> </li> 
 <li>🧑‍💻 Contribution 
  <ul> 
   <li><a href="https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/ROADMAP.md">Develop Roadmap</a></li> 
  </ul> </li> 
 <li>🔖 Use Cases 
  <ul> 
   <li><a href="https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html">Data Interpreter</a></li> 
   <li><a href="https://docs.deepwisdom.ai/main/en/guide/use_cases/multi_agent/debate.html">Debate</a></li> 
   <li><a href="https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/researcher.html">Researcher</a></li> 
   <li><a href="https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/receipt_assistant.html">Recepit Assistant</a></li> 
  </ul> </li> 
 <li>❓ <a href="https://docs.deepwisdom.ai/main/en/guide/faq.html">FAQs</a></li> 
</ul> 
<h2>Support</h2> 
<h3>Discord Join US</h3> 
<p>📢 Join Our <a href="https://discord.gg/ZRHeExS6xv">Discord Channel</a>! Looking forward to seeing you there! 🎉</p> 
<h3>Contributor form</h3> 
<p>📝 <a href="https://airtable.com/appInfdG0eJ9J4NNL/pagK3Fh1sGclBvVkV/form">Fill out the form</a> to become a contributor. We are looking forward to your participation!</p> 
<h3>Contact Information</h3> 
<p>If you have any questions or feedback about this project, please feel free to contact us. We highly appreciate your suggestions!</p> 
<ul> 
 <li><strong>Email:</strong> <a href="mailto:alexanderwu@deepwisdom.ai">alexanderwu@deepwisdom.ai</a></li> 
 <li><strong>GitHub Issues:</strong> For more technical inquiries, you can also create a new issue in our <a href="https://github.com/geekan/metagpt/issues">GitHub repository</a>.</li> 
</ul> 
<p>We will respond to all questions within 2-3 business days.</p> 
<h2>Citation</h2> 
<p>To stay updated with the latest research and development, follow <a href="https://twitter.com/MetaGPT_">@MetaGPT_</a> on Twitter.</p> 
<p>To cite <a href="https://openreview.net/forum?id=VtmBAGCN7o">MetaGPT</a> or <a href="https://arxiv.org/abs/2402.18679">Data Interpreter</a> in publications, please use the following BibTeX entries.</p> 
<pre><code class="language-bibtex">@inproceedings{hong2024metagpt,
      title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},
      author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\"u}rgen Schmidhuber},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=VtmBAGCN7o}
}
@misc{hong2024data,
      title={Data Interpreter: An LLM Agent For Data Science}, 
      author={Sirui Hong and Yizhang Lin and Bang Liu and Bangbang Liu and Binhao Wu and Danyang Li and Jiaqi Chen and Jiayi Zhang and Jinlin Wang and Li Zhang and Lingyao Zhang and Min Yang and Mingchen Zhuge and Taicheng Guo and Tuo Zhou and Wei Tao and Wenyi Wang and Xiangru Tang and Xiangtao Lu and Xiawu Zheng and Xinbing Liang and Yaying Fei and Yuheng Cheng and Zongze Xu and Chenglin Wu},
      year={2024},
      eprint={2402.18679},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
</code></pre>
]]></content:encoded>
<pubDate></pubDate>
</item>
</channel>
</rss>