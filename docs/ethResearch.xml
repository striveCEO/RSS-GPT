<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Ethereum Research - Latest topics</title>
<link>https://ethresear.ch/latest</link>


<item>
<title>Preconfirmation Bidding Increased Block Values on Holesky</title>
<link>https://ethresear.ch/t/preconfirmation-bidding-increased-block-values-on-holesky/20190</link>
<guid>https://ethresear.ch/t/preconfirmation-bidding-increased-block-values-on-holesky/20190</guid>
<content:encoded><![CDATA[
<div> 关键词：Mev-commit、Holesky、预确认、竞标行为、区块价值

总结:
文章主要探讨了自7月10日以来，Mev-commit 0.4.3版本在Holesky tesnet上启用预确认功能的情况。在这段时间里，预确认功能参与度逐渐增加，目前有1个转接器、3个提供者、9个竞标者参与其中。从7月10日至7月29日期间，提供者共发布了807次预确认，涉及415个Holesky区块。预确认交易数量较少（815次），但价值相对较高，平均每个预确认交易的价值为0.0049 ETH，而平均优先费用仅为0.0045 ETH。这表明预确认交易对整体区块价值的贡献显著。

此外，文章还指出，预确认交易平均为区块贡献的价值（0.0093 ETH）远高于常规区块（0.0044 ETH）。这表明预确认机制可以有效提升区块价值，从而增加验证者的奖励。同时，文章也提到，由于Holesky作为测试网与主网存在差异，其预确认功能的使用情况可能与主网有所不同。为了进一步研究和优化预确认机制，计划进行更多在模拟主网环境下的测试，并邀请更多的参与者加入到Mev-commit生态系统中。 <div>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TLDR</h1>
<ul>
<li>Since July 10, mev-commit 0.4.3 has enabled over 800 execution preconfirmations on Holesky, with increasing network participation.</li>
<li>Providers issued 807 preconfirmations across 415 blocks. Bidders sent 4.24 ETH worth of bids.</li>
<li>Average mev-commit block value was 0.0093 ETH compared to 0.0044 ETH for a vanilla block.</li>
<li>Average preconfirmation bid was 0.0049 ETH, slightly higher than the average priority fee of 0.0045 ETH.</li>
<li>Data shows that preconf bids contribute significantly to overall block value, despite limited participation for the nascent network.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#overview-2" name="overview-2"></a>Overview</h1>
<p>Since July 10, mev-commit 0.4.3 has been facilitating execution preconfirmations on Holesky tesnet. There has been an upwards trend of participation with currently 1 relay, 3 providers, 9 bidders, and <a href="https://validators.mev-commit.xyz/" rel="noopener nofollow ugc">27,000 validators</a> participating. From July 10 to July 29 (Holesky block range 1902173 to 2027932), providers have issued 807 preconfirmations across 415 Holesky blocks. Some examples of preconfirmation blocks:</p>
<ul>
<li><a href="https://holesky.etherscan.io/block/1943039" rel="noopener nofollow ugc">1943039</a> with 21 preconfs and .016 ETH worth of bids</li>
<li><a href="https://holesky.etherscan.io/block/1986732" rel="noopener nofollow ugc">1986732</a> with 7 preconfs and .04 ETH worth of bids</li>
<li><a href="https://holesky.etherscan.io/block/1986963" rel="noopener nofollow ugc">1986963</a> with 5 preconfs and .022 ETH worth of bids</li>
</ul>
<p>There are two caveats to these initial results. The first is that network participation is still growing. As more actors onboard or opt in to the network, the flow of preconfs is likely to increase. The second caveat is that Holesky does not have the same competitive use cases for preconfs as mainnet, and does not mirror mainnet Ethereum transacting behavior as closely as desired.</p>
<p>The notebook used for analytics <a href="https://github.com/Evan-Kim2028/preconf_analytics/blob/e6fdb9886c600315d531b59cb13e6efccc7d56bd/notebooks/preconfs.ipynb" rel="noopener nofollow ugc">can be found here</a>. The data for these results can be replicated using the <a href="https://github.com/primev/mev_commit_sdk_py" rel="noopener nofollow ugc">mev-commit-sdk-py</a> repository to collect mev-commit events powered by Hypersync indexer. There is also <a href="http://explorer.testnet.mev-commit.xyz/app/discover" rel="noopener nofollow ugc">an explorer</a>, which is currently in development.</p>
<h1><a class="anchor" href="https://ethresear.ch#bidding-behavior-3" name="bidding-behavior-3"></a>Bidding Behavior</h1>
<p>We observe 815 preconfirmation transactions, indicating a niche but valuable market segment compared to 4 million regular transactions. This significant difference suggests preconfs are currently used by a smaller subset of users who are testing preconfirmations.</p>
<p>A total of 9 bidders participated, sending 4.24 ETH in bids compared to 0.13 ETH in priority fees, with an average preconfirmation bid of 0.005 ETH versus 0.00016 ETH for priority fees on the same transaction, indicating a heavier bidding preference for preconfirmations over priority fees.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/4/04d6296e99153e73f2e018b8c21b727582d0c89e.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/0/4/04d6296e99153e73f2e018b8c21b727582d0c89e_2_563x500.png" width="563" /></a></div><p></p>
<p>Overall, priority fees totaled 544 ETH with the average preconfirmation bid being 0.0049 ETH, slightly higher than the average priority fee of 0.0045 ETH.</p>
<h1><a class="anchor" href="https://ethresear.ch#block-value-4" name="block-value-4"></a>Block Value</h1>
<p>We hypothesized that preconfs would add an increase in block value, resulting in higher validator rewards per mev-commit block. On average, we observe 1.95 preconfirmation transactions per block compared to 42.3 total transactions. Average mev-commit block value was 0.0093 ETH compared to 0.0044 ETH for a vanilla block.</p>
<p><img alt="image" height="474" src="https://ethresear.ch/uploads/default/original/3X/d/9/d97a557eefe85c83cef80122c55b8695d60307b1.png" width="542" /></p>
<p>One limitation in comparing mev-commit blocks to vanilla Holesky blocks is that there are only ~400 mev-commit blocks compared to ~50,000 Holesky blocks. This is primarily due to the nascent mev-commit network participation rates. Additionally the average bid amount at 0.005 ETH seems on the higher side for Holesky blocks and may not accurately reflect mainnet amounts. However accurately pricing preconfirmations is a difficult task and has to be balanced with the presence of mev spikes on mainnet that can greatly skew results. We are actively researching how to price preconfirmations more effectively.</p>
<p>We illustrate the block revenue breakdown over several days in the chart below for mev-commit blocks, showing the breakdown between preconfirmation bids and priority fees:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/0/c04ec97bff2be44d3e1f79915157487def6eb685.png" title="image"><img alt="image" height="409" src="https://ethresear.ch/uploads/default/optimized/3X/c/0/c04ec97bff2be44d3e1f79915157487def6eb685_2_690x409.png" width="690" /></a></div><p></p>
<p>Preconfirmation bids significantly contributed to increasing block value. On days such as July 11th, 18th, and 24th, preconfirmation bids markedly boosted total block value, highlighting their substantial impact.</p>
<p>The charts below illustrate an outsized impact that preconfirmation bids on block value:</p>
<ul>
<li><strong>Preconf Bids per Block</strong>: Despite a smaller number of transactions, preconfirmation bids are consistently higher, often reaching up to 0.02 ETH.</li>
<li><strong>Priority Fees per Block</strong>: While more frequent, priority fees are generally lower, seldom exceeding 0.01 ETH.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/3/43fe06dfdd10788ec3344bc9e8592e3773cf34a6.png" title="image"><img alt="image" height="312" src="https://ethresear.ch/uploads/default/optimized/3X/4/3/43fe06dfdd10788ec3344bc9e8592e3773cf34a6_2_690x312.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/0/1078d70fc113dfd6d3a0d5a291ef56a81a12f361.png" title="image"><img alt="image" height="317" src="https://ethresear.ch/uploads/default/optimized/3X/1/0/1078d70fc113dfd6d3a0d5a291ef56a81a12f361_2_690x317.png" width="690" /></a></div><p></p>
<p>A notable example is block <a href="https://holesky.etherscan.io/block/1943039" rel="noopener nofollow ugc">1943039</a>, which had the highest number of preconfs with 21 out of 48 transactions. In this block, preconf bid revenue was 0.008 ETH, vastly outpacing the 0.0009 ETH from priority fees.</p>
<p>These observations demonstrate that even a few preconfirmation transactions can substantially enhance block value due to their higher bid amounts.</p>
<h1><a class="anchor" href="https://ethresear.ch#limitations-5" name="limitations-5"></a>Limitations</h1>
<p>As mentioned earlier, the caveats to our initial findings is that Holesky is a testnet and does not have the same types of competitive opportunities as Mainnet. Users tend to have less urgency on Holesky and this is reflected in smaller block sizes and lower priority fees.</p>
<p>As a result, the preconf bids may not have the same relationship to priority fees on mainnet compared to testnet and may not accurately reflect the user’s true bidding preferences since testnet tokens are being used.</p>
<h1><a class="anchor" href="https://ethresear.ch#closing-remarks-6" name="closing-remarks-6"></a>Closing Remarks</h1>
<p>This report initially touches on some preconfirmation bidding behavior observed through early mev-commit usage and offers insights into how preconf bids can increase validator rewards. We plan to follow up with a more detailed report on mev-commit protocol details such as the decay mechanism, rewards and slashing, settlement process, and revenue.</p>
<p>We plan to onboard more bidders, providers and validators into the mev-commit ecosystem and conduct more tests in an environment that mimics mainnet more closely. We invite you to participate starting at <a class="inline-onebox" href="https://docs.primev.xyz/get-started/welcome-to-primev" rel="noopener nofollow ugc">Welcome to Primev - Documentation</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmation-bidding-increased-block-values-on-holesky/20190">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 02:58:46 +0000</pubDate>
</item>
<item>
<title>Affiliated AMMs and permissionless solving for uniform price batch auctions</title>
<link>https://ethresear.ch/t/affiliated-amms-and-permissionless-solving-for-uniform-price-batch-auctions/20187</link>
<guid>https://ethresear.ch/t/affiliated-amms-and-permissionless-solving-for-uniform-price-batch-auctions/20187</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、批拍卖、AMM、公正执行、分散化

总结:

本文探讨了通过批拍卖机制降低矿工提取费用(MEV)的可能性及其潜在应用。MEV是区块链交易中的一个重要议题，它涉及到交易排序、删除和插入带来的经济利益。批拍卖通过确保交易执行顺序的中立性以及统一清算价格来尝试解决这一问题。

文章首先强调了批拍卖的概念和其在减少MEV方面的潜力。批拍卖允许在区块构建阶段进行交易批量处理，以确保所有交易在同一时间以相同价格执行，这有助于接近理想状态下的公平市场环境。

接着，文章提出了“公正执行”概念，即批拍卖合同执行时不依赖于交易顺序，且统一清算价格保证了交易双方获得一致的价格。CoW协议是当前实现批拍卖机制的一个实例，但作者指出，仅依靠批拍卖机制并不足以完全消除MEV，因为仍然存在数据被忽略或插入的风险。因此，文章提出了一种折衷策略，即在正常市场条件下，通过激励机制让特权行为者不进行数据篡改，并享受仅有的微小优势。

文章进一步讨论了批拍卖系统与自动做市商（AMM）的集成，尤其是引入“附属AMM”，这些AMM可以参与批拍卖并设定特定的交易规则，以此来减少流动性提供者的损失和MEV。

此外，文章还提出了“无许可解决”策略，即允许任何实体执行批拍卖，以最大化去中心化程度。这需要建立信任执行环境，确保诚实解决者能够通过最大化收入来优化执行过程，从而防止恶意操纵价格的行为。

最后，文章讨论了批拍卖系统的实施细节，如费用覆盖、流动性迁移和监管机制等，并强调了系统稳定性的关键因素，包括市场流动性、价格波动范围以及解决者之间的竞争平衡。文章认为，通过引入多级AMM和附属AMM，以及优化解决者激励机制，批拍卖系统可以在一定程度上降低MEV，从而促进更公平、更透明的交易环境，为Dex交易提供更多便利，最终提升区块链的价值。 <div>
<p>The idea of mitigating MEV through batch auctions is as old as the concept of MEV itself. They can both be traced back to <a href="https://www.reddit.com/r/ethereum/comments/2d84yv/miners_frontrunning/" rel="noopener nofollow ugc">this Reddit post</a> from August 2014<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-1" id="footnote-ref-49420-1">[1]</a></sup>. Today, ten years later, this is still an ongoing discussion (see for instance <a href="https://ethresear.ch#references">[UNIX]</a>, <a href="https://ethresear.ch#references">[COW]</a>). To what extent can we reduce MEV by using batch auctions? Can we build batch auction protocols that are better than those existing today? In this article we propose an optimistic point of view for the first question and a candidate affirmative answer to the second question through concrete mechanisms.</p>
<p><strong>Note:</strong> This article was primarily conceived while working at Flashbots Research for a year spanning 2023 and 2024. Special thanks to Christoph Schlegel.</p>
<p>The article assumes that the reader is familiar with the concepts of MEV, batch auctions and AMMs in the context of decentralized exchange (DEX).</p>
<h3><a class="anchor" href="https://ethresear.ch#a-cooperative-endeavour-between-traders-1" name="a-cooperative-endeavour-between-traders-1"></a>A cooperative endeavour between traders</h3>
<p>In the long term, on-chain traders will use those DEX protocols that are most convenient for them. Ideally, they would trade at market prices with no fee other than the gas cost, equalling the gas price of a transfer. Even though Ethereum’s reality is far from this, in my opinion we shouldn’t rush to dismiss the possibility. Carefully designed smart contracts jointly with off-chain mechanisms might help traders get close to this ideal<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-2" id="footnote-ref-49420-2">[2]</a></sup>. It is likely that these clever designs are not out there yet.</p>
<p>A very powerful idea is that the smart contract that settles trade orders does so in batches, enforcing uniform clearing prices. This has two fundamental properties:</p>
<p>(a) The execution does not depend on the ordering of the trade orders.</p>
<p>(b) Uniform clearing prices ensure that a user trading in one direction receives the same price as the other users trading in that same direction, and is a direct counterpart to the users trading in the other directions, with no room for intermediaries between them.</p>
<p>The most famous (or even the only) live system implementing this mechanism on a blockchain is CoW protocol <a href="https://ethresear.ch#references">[COW]</a> (see also <a href="https://ethresear.ch#references">[SPEEDEX]</a>). Unfortunately, the sole existence of a uniform price batch auction mechanism is not enough to reach the ideal situation described above. MEV occurs through the reordering, censoring, or insertion of data by a privileged player. While according to (a) reordering trade orders has no effect in our case, it is still possible that privileged players censor and insert data. As a matter of fact, for the players who write a transaction or a block, it will always be physically possible to ignore some data and to include their own data, maybe even pretending that this new data was produced by someone else. Therefore, here we will simply abandon the search of a protocol that logically guarantees no censorship nor privileged insertions. Nevertheless, we will not rule out the possibility of a mechanism such that in normal market conditions and assuming wide adoption, the privileged players will be incentivized not to censor, and enjoy only a marginal advantage from last moment inclusions.</p>
<p>While CoW protocol has achieved an interesting degree of adoption, it represents only a small fraction of Ethereum DEX activity —<a href="https://defillama.com/aggregators/chains/ethereum" rel="noopener nofollow ugc">around 1% these days</a>. CoW runs a centralized solving protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#uniform-clearing-prices-and-walrasian-equilibrium-2" name="uniform-clearing-prices-and-walrasian-equilibrium-2"></a>Uniform clearing prices and Walrasian equilibrium</h3>
<p>A trade order can be understood as a mathematical function of the clearing prices. The output of the function is the traded amounts for each asset. Given a set of trade orders, there is typically only a limited set of valid clearing price vectors, maybe even only one. This situation perfectly corresponds to the concept of Walrasian equilibrium in a pure exchange market (see <a href="https://ethresear.ch#references">[RGGM]</a>, <a href="https://ethresear.ch#references">[FY]</a> and references therein). A Walrasian equilibrium is a vector of prices at which the supply of each good equals the demand for that good.</p>
<p>Under very mild hypothesis, we can guarantee the existence of at least one equilibrium. The computational problem of finding equilibrium price vectors translates to the search of fixed points of a certain mapping.</p>
<h3><a class="anchor" href="https://ethresear.ch#affiliated-amms-3" name="affiliated-amms-3"></a>Affiliated AMMs</h3>
<p>Decentralized exchange predominantly occurs through automated market makers (AMMs). Many researchers and industry actors have pointed out that AMM liquidity providers (LPs) typically receive worse prices than what the market has to offer at each time. This phenomenon is usually referred to as loss vs. rebalancing (LVR) and described as MEV suffered by the liquidity providers <a href="https://ethresear.ch#references">[LVR]</a>, <a href="https://ethresear.ch#references">[WLVR]</a>.</p>
<p>There is a natural mechanism to attack this issue that no one seems to have considered yet<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-3" id="footnote-ref-49420-3">[3]</a></sup>. Special AMMs may participate in a uniform price batch auction just like any other trader. These would be the affiliated AMMs. They would allow certain swaps depending on their state and execution price, only admitting the price from the batch. We can think of the allowed swaps as preprogrammed trade orders. To implement this, the contract that executes batches should be prepared to call affiliated swaps passing the batch prices. From now on, let us call <em>W</em> the smart contract that executes batches, i.e. the main contract of the system under consideration. Specially designed affiliated AMMs may be added <em>a posteriori</em> following specifications determined by the <em>W</em> contract<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-4" id="footnote-ref-49420-4">[4]</a></sup>. It is possible that affiliated AMMs benefit by only allowing swaps coming from <em>W</em>. However, we do not need to discuss it at this point: the scheme allows to decouple the problem of choosing a specific AMM design. A multiplicity of them may coexist, and liquidity migration can happen seamlessly at any time. The existence of multiple AMMs affiliated to the same <em>W</em> contract does not entail liquidity fragmentation.</p>
<p>Assuming wide adoption of the <em>W</em> contract and low incidence of censorship, we have clearing prices that are actual market prices, thus mitigating LVR and MEV.</p>
<p>
<br />
</p><p><img alt="diagram" height="451" src="https://ethresear.ch/uploads/default/original/3X/4/8/4824aef76acd0078806fd0c5418d95c44555a648.png" width="642" /></p>
<p></p>
<h3><a class="anchor" href="https://ethresear.ch#permissionless-solving-4" name="permissionless-solving-4"></a>Permissionless solving</h3>
<p>Once we have truly accepted that we cannot enforce censorship resistance for trade orders at code level, we may reasonably conjecture that the best we can do is to open the gates as much as possible in order to minimize censorship and democratize the system. The proposal is to let <em>W</em> allow anyone to execute a batch. The block proposers, as always, will exercise their right to choose the transactions they prefer, possibly through a PBS mechanism <a href="https://ethresear.ch#references">[PBS]</a>, <a href="https://ethresear.ch#references">[MEV-BOOST]</a>. This feature achieves the maximum degree of decentralization possible at smart contract level for a batch auction system. The auction will occur at block building level. This is analogous to the usual permissionless access to AMMs, which is only regulated by the PBS apparatus or whatever mechanism adopted by the block proposers. Another example is UniswapX: their reactors allow anyone to be a <a href="https://docs.uniswap.org/contracts/uniswapx/guides/createfiller" rel="noopener nofollow ugc">filler</a>, though they don’t enforce uniform clearing prices.</p>
<p>Let us explain why it is reasonable to expect that this mechanism will work well, i.e., that potential price manipulations by censoring orders are expected to be under control. The flow of the reasoning is as follows. We will first imagine the system flourished, running a large portion of Ethereum’s DEX volume. We will try to visualize this scenario and assess whether it is stable or if we should expect frequent price manipulations. Let us list some properties of the flourished scenario:</p>
<p><strong>(1)</strong> Since there are many important tokens on Ethereum blockchain, we expect to have a main cluster of several tokens interconnected by swaps at each batch. This is desirable because it means the liquidity in one pair can benefit traders in other pairs (e.g., an order in pair A/B can be settled against orders in pairs B/C and C/A).</p>
<p><strong>(2)</strong> By looking at how prices vary, it turns out that very-short-term volatility is easy to estimate. Only as an example, on a normal day the price of ETH measured in USD typically varies less than 0.1% in a 12s period, with some larger jumps occasionally. Uninformed traders may use this kind of magnitude for the slippage tolerance. Furthermore, public tools that monitor real time price movements can aid users to reduce the slippage tolerance depending on their preferences. Meanwhile, informed traders doing statistical arbitrage or plain arbitrage are expected to use very low values for the slippage tolerance when trading liquid assets. This will set a tight bound on the bounty that a malicious solver can obtain by deviating the price.</p>
<p><strong>(3)</strong> We may assume the existence of honest solvers. As usual, the batch that generates more income for the block proposer should make it to the chain. Honest solvers will aim to maximize that income by maximizing inclusion. They will frequently need to discard some orders for various reasons, such as limited block space, or computation deadlines. As a result, we will often have more than one honest proposed batch. Trusted execution environments can be useful in increasing the transparency of honest solvers.</p>
<p>When a malicious solver tries to manipulate the price, they have to beat the best honest solution. To this end, they will censor every order in one direction for a given pair A/B exceeding certain price threshold. By doing so, they will not only miss out on the gas fees of the censored orders, but also on orders in other pairs due to operating away from the market equilibrium prices (recall (1)). Because of this and (2) it is possible that in most cases it will not be profitable to manipulate the prices of the batch. In addition, we may have other off-chain mechansims to further prevent malicious solving. One such mechanism can be to use private channels between traders and honest solvers in certain cases.</p>
<h3><a class="anchor" href="https://ethresear.ch#mev-a-zoom-out-analysis-5" name="mev-a-zoom-out-analysis-5"></a>MEV: a zoom-out analysis</h3>
<p>Total MEV extraction from Ethereum has been stable during the last two years, at levels above 250 kETH per year<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-5" id="footnote-ref-49420-5">[5]</a></sup>. During this period, there haven’t been many innovations generating optimism about MEV reduction. This has led many people to believe that such levels of MEV are inevitable. The fundamental economic reason for the existence of MEV can be summarized by the concept of block proposer monopoly. If traders want to improve their situation, they need to coordinate by adopting a mechanism that gives them more bargaining power, a trade union. This is the principle underlying the concrete proposals presented here. A system that integrates the different types of liquidity and unifies the execution prices helps traders coordinate their orders around true market prices as described in (2).</p>
<p>Reducing the incidence of MEV would be a great achievement, since it would allow the DEX volume to grow. On-chain trading would become more convenient than centralized alternatives in many cases, thus increasing the global value of the blockchain.</p>
<h3><a class="anchor" href="https://ethresear.ch#final-remarks-6" name="final-remarks-6"></a>Final remarks</h3>
<p>(I) The above description of <em>W</em> is incomplete. Possibly the most important undefined aspect is how to cover gas and trade fees (by <em>gas fee</em> we mean the cost of gas usage as if it were a transfer). What kind of regulations should <em>W</em> implement regarding the operational cost or trade fees? Can the system work well at zero trade fee? See footnote [2]. These questions don’t seem very easy to answer. Fortunately, we will be able to continue iterating theory and practice.</p>
<p>(II) If there are non-affiliated AMMs coexisting with <em>W</em>, the solvers of <em>W</em> can extract profit from them. Every time there is a price movement, it will be possible to find surplus-generating solutions. To find them, they need to consider non-affiliated AMMs as virtual agents of the batch, following a procedure explained in <a href="https://ethresear.ch#references">[FY]</a>. This mathematical fact should act as an attractor of liquidity from traditional to affiliated AMMs.</p>
<h3><a class="anchor" href="https://ethresear.ch#references-7" name="references-7"></a>References</h3>
<p><strong>[COW]</strong> CoW protocol, <a class="inline-onebox" href="https://docs.cow.fi/cow-protocol" rel="noopener nofollow ugc">CoW Protocol | CoW Protocol Documentation</a>;</p>
<p>Felix Leupold, <em>Gnosis Protocol v2 Fighting the MEV Crisis with Batch Auctions one CoW at a time</em>, <a href="https://www.youtube.com/watch?v=6MfcZGVeQsQ" rel="noopener nofollow ugc">https://www.youtube.com/watch?v=6MfcZGVeQsQ</a></p>
<p><strong>[CF]</strong> Andrea Canidio, Robin Fritsch, <em>Arbitrageurs’ profits, LVR, and sandwich attacks: batch trading as an AMM design response</em>, <a class="inline-onebox" href="https://arxiv.org/abs/2307.02074" rel="noopener nofollow ugc">[2307.02074] Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response</a></p>
<p><strong>[FB2]</strong> Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li, Xueyuan Zhao, Iddo Bentov, Lorenz Breidenbach, Ari Juels, <em>Flash Boys 2.0: Frontrunning, Transaction Reordering, and Consensus Instability in Decentralized Exchanges</em> <a class="inline-onebox" href="https://arxiv.org/abs/1904.05234" rel="noopener nofollow ugc">[1904.05234] Flash Boys 2.0: Frontrunning, Transaction Reordering, and Consensus Instability in Decentralized Exchanges</a></p>
<p><strong>[FY]</strong> Sergio Yuhjtman, Flashbots, <em>Walraswap: a solution to uniform price batch auctions</em>, <a class="inline-onebox" href="https://arxiv.org/abs/2310.12255" rel="noopener nofollow ugc">[2310.12255] Walraswap: a solution to uniform price batch auctions</a></p>
<p><strong>[LVR]</strong> Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden, Anthony Lee Zhang, <em>Automated Market Making and Loss-Versus-Rebalancing</em>, <a href="https://arxiv.org/pdf/2208.06046" rel="noopener nofollow ugc">https://arxiv.org/pdf/2208.06046</a></p>
<p><strong>[MEV-BOOST]</strong> Flashbots, <em>MEV-Boost in a Nutshell</em>, <a href="https://boost.flashbots.net/" rel="noopener nofollow ugc">https://boost.flashbots.net/</a></p>
<p><strong>[PBS]</strong> Ethereum Foundation, <em>Proposer-builder separation</em>, <a class="inline-onebox" href="https://ethereum.org/en/roadmap/pbs/" rel="noopener nofollow ugc">Proposer-builder separation | ethereum.org</a></p>
<p><strong>[RGGM]</strong> Geoffrey Ramseyer, Mohak Goyal, Ashish Goel, David Mazières,</p>
<p><em>Augmenting Batch Exchanges with Constant Function Market Makers</em>, <a class="inline-onebox" href="https://arxiv.org/abs/2210.04929" rel="noopener nofollow ugc">[2210.04929] Augmenting Batch Exchanges with Constant Function Market Makers</a></p>
<p><strong>[SPEEDEX]</strong> Geoffrey Ramseyer, Ashish Goel, and David Mazières, <em>SPEEDEX: A Scalable, Parallelizable, and Economically Efficient Decentralized EXchange</em>, <a href="https://www.usenix.org/conference/nsdi23/presentation/ramseyer" rel="noopener nofollow ugc">https://www.usenix.org/conference/nsdi23/presentation/ramseyer</a>, <a class="inline-onebox" href="https://stellar.org/blog/developers/building-speedex-a-novel-design-for-decentralized-exchanges" rel="noopener nofollow ugc">Stellar | Building SPEEDEX – A Novel Design for a Scalable Decentralized Exchange</a></p>
<p><strong>[UNIX]</strong> Hayden Adams, Noah Zinsmeister, Mark Toda, Emily Williams, Xin Wan, Matteo Leibowitz, Will Pote, Allen Lin, Eric Zhong, Zhiyuan Yang, Riley Campbell, Alex Karys, Dan Robinson, <em>UniswapX</em> <a href="https://uniswap.org/whitepaper-uniswapx.pdf" rel="noopener nofollow ugc">https://uniswap.org/whitepaper-uniswapx.pdf</a></p>
<p><strong>[WLVR]</strong> Cow DAO, <em>What is Loss-Versus-Rebalancing (LVR)?</em>, <a class="inline-onebox" href="https://cow.fi/learn/what-is-loss-versus-rebalancing-lvr" rel="noopener nofollow ugc">What is Loss-Versus-Rebalancing (LVR)? - CoW DAO</a></p>
<hr class="footnotes-sep" />

<ol class="footnotes-list">
<li class="footnote-item" id="footnote-49420-1"><p>Though the origin of the name MEV and its systematic study started at <a href="https://ethresear.ch#references">[FB2]</a>. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-1">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-2"><p>An example of a scenario close to this ideal is to allow a small trade fee that is sublinear in the traded amount. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-2">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-3"><p>The same general approach can be found in <a href="https://ethresear.ch#references">[CF]</a>, as is apparent from the title. However the concrete mechanism described there is different from the one proposed here. Additionally, <a href="https://ethresear.ch#references">[RGGM]</a> studies uniform price batches where AMMs swap at the prices of the batch. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-3">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-4"><p>This can be implemented without calling ERC20 approvals between contracts. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-4">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-5"><p>Most of the extracted MEV is being distributed through MEV-BOOST. See some numbers at <a href="https://mevboost.pics/" rel="noopener nofollow ugc">https://mevboost.pics/</a> and <a href="https://eigenphi.io/" rel="noopener nofollow ugc">https://eigenphi.io/</a>. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-5">↩︎</a></p>
</li>
</ol>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/affiliated-amms-and-permissionless-solving-for-uniform-price-batch-auctions/20187">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 31 Jul 2024 22:17:33 +0000</pubDate>
</item>
<item>
<title>Ethereum + Industry of Integrations (IOI)</title>
<link>https://ethresear.ch/t/ethereum-industry-of-integrations-ioi/20167</link>
<guid>https://ethresear.ch/t/ethereum-industry-of-integrations-ioi/20167</guid>
<content:encoded><![CDATA[
<div> 关键词：IPSME、IOI、Ethereum、智能合约、集成

文章主要探讨了通过将集成系统（Integration of Integrations, IOI）概念应用于以太坊（Ethereum）网络的可能性。以下是文章的主要要点总结：

1. **IPSME与IOI**：IPSME是一种由社区开发的集成系统演进架构，而IOI则提出，只要两个系统的接口（APIs）已知且可访问，就能通过特定方式创建翻译来实现集成，并且这种集成可以商业化。

2. **以太坊与智能合约**：文章指出，以太坊已经支持发布/订阅（Pub/Sub）机制，这是实现IOI概念的基础。通过将集成逻辑封装为智能合约，可以在以太坊上创建可重用的集成，从而可能实现原开发者对集成的商业化。

3. **去中心化集成**：通过将集成作为智能合约执行，可以减少与外部系统集成的复杂性，特别是通过传递性（transitivity），即如果A与B集成，B与C集成，那么理论上A可以直接与C集成，减少了对中心化或去中心化Oracle服务的需求。

4. **智能合约的潜力**：文章讨论了智能合约在协议通信中的强大能力，认为它们不仅能够实现自动化集成，还能够在无需信任第三方的情况下确保数据的一致性和完整性。

5. **对Oracle服务的影响**：通过智能合约实现的集成，理论上可以降低对依赖Oracle服务的需求，因为智能合约能够提供一种更直接、更安全的方式来获取和处理外部数据。

总结：将集成系统（如IPSME定义的IOI）概念应用到以太坊网络中，通过利用智能合约实现集成，不仅能够简化与外部系统的集成过程，提高效率，同时还能通过集成的可重用性和潜在的商业化途径，降低对传统Oracle服务的依赖，实现更加去中心化、安全和高效的集成解决方案。 <div>
<p>(This is my first post here, so I hope that I have not missed any protocol)</p>
<p>I’ve been integrating systems using IPSME, which lead to the Industry of Integrations concept <a href="https://root-interface.se/IOI" rel="noopener nofollow ugc">IOI</a>. IPSME defines an evolutionary architecture for integrations developed by the community.</p>
<p>Demos of my work can be found here:<br />
            
</p>
<p>The concept of the IOI is such that: if any two system interfaces (APIs) are known and accessible, that (via the conventions of <a href="https://ipsme.dev" rel="noopener nofollow ugc">IPSME</a>) a translation can be created integrating the two APIs …​ And! That that translation can be monetized.</p>
<p>The Ethereum blockchain is often linked to Oracles or Oracles services that are off-chain. AFAIK, Ethereum already support a pubsub (the basis for IPSME). The question is then if an IOI can be created within the Ethereum network. Namely, can integrations to external services be smart contracts so that integrations are on-chain and are re-usable by other developers. Is it possible that smart contract integration contains the logic so that the original developer can possibly monetize off building the integration. If the integrations can be reused, then the complexity for integrating with external systems can be reduced through the property of transitivity i.e., if A integrates with B and B with C, then A is integrated with C.</p>
<p>I’m interested in doing exploratory research to see if IOI can be applied to Web3. I would like to ask here:</p>
<ul>
<li>Does this idea sound feasible with the Ethereum network?</li>
<li>Are smart contacts powerful enough for protocol communication?</li>
<li>Is it correct that Ethereum supports pubsub and can it be utilized for this?</li>
<li>Would this idea alleviate the need for Oracle services/networks?</li>
</ul>
<p>I’m looking forward to your feedback.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/ethereum-industry-of-integrations-ioi/20167">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 28 Jul 2024 19:52:10 +0000</pubDate>
</item>
<item>
<title>ePBS Metagame: SSP peacekeeping and alternative public service</title>
<link>https://ethresear.ch/t/epbs-metagame-ssp-peacekeeping-and-alternative-public-service/20162</link>
<guid>https://ethresear.ch/t/epbs-metagame-ssp-peacekeeping-and-alternative-public-service/20162</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Burn、公共利益建设者(PGB)、有机建设者、SSP、社会层

总结:文章深入探讨了MEV-Burn背景下公共利益建设者(PGB)的策略和影响。首先，介绍了五种潜在的MEV-Burn参与者类型，其中重点分析了公共利益建设者与有机建设者的角色及其动机。公共利益建设者通过高燃烧率或排除有害行为为网络做出贡献，而有机建设者则侧重于维护网络的纯净与实用价值。文章还提出了一种可能的提名机制，即验证者在考虑其声誉和社会信誉的同时选择PGB进行区块构建。

其次，文章通过案例研究探讨了SSP如何通过竞标和恶意攻击来维持其市场地位，以及PGB如何通过减少燃烧率和包括所有MEV（包括有害的）来实现盈利并促进网络改进。这表明PGB可以通过牺牲部分利润来增加其被选中构建区块的机会，从而提高其效率并提升社会信誉。

最后，文章强调了MEV-Burn的社会影响，包括可能形成的利益集团和网络中的动态变化。尽管存在潜在的负面影响，但文章认为有道德的建设者和验证者将找到方法来抵消不法行为，并保持网络的平衡与健康。文章呼吁继续对这一领域进行深入研究，以全面理解MEV-Burn带来的复杂社会影响。 <div>
<h3><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a><strong>Introduction</strong></h3>
<p>Alongside Enshrined Proposer-Builder Separation, MEV-Burn is expected to produce a major shift in many on-chain economic and social dynamics. From reducing rugpool incentives to making ReOrg’s even less profitable, this rollout is sure to provide some tangible improvements to the Ethereum protocol, but what seems to get all too frequently overlooked is the on-chain behavioral impact.</p>
<p>If you haven’t already, I would <em>strongly</em> recommend taking a peek at both <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">how i learned to stop worrying and love mev-burn</a> by <a href="https://ethresear.ch/u/mikeneuder">Mike Neuder</a>, and <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Burn incentives in MEV pricing auctions</a> by <a href="https://ethresear.ch/u/aelowsson">aelowsson</a> as they both inspired me to write this piece and may help decipher some of the more technical details.</p>
<p>As stated in <a href="https://ethresear.ch/u/aelowsson">aelowsson</a>’s <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Burn incentives in MEV pricing auctions</a> there are five types of potential MEV-Burners within pricing auctions:</p>
<aside class="quote no-group">
<div class="title">
<div class="quote-controls"></div>
<img alt="" class="avatar" height="24" src="https://ethresear.ch/user_avatar/ethresear.ch/aelowsson/48/7611_2.png" width="24" /><a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856/1">Burn incentives in MEV pricing auctions</a></div>
<blockquote>
<p>(A) Public good builder, (B) For-profit public good builder, (C) Extortion racket, (D) Staker-initiated griefing, (E) Staker-initiated griefing cartel.</p>
</blockquote>
</aside>
<h3><a class="anchor" href="https://ethresear.ch#pgb-overview-2" name="pgb-overview-2"></a><strong>PGB Overview</strong></h3>
<p>Narrowing in on the Public Goods division, there are several ways to be considered a Public Goods Builder; one being burn rates. Simply put, the more profits a builder dedicates to burning, the more ‘ultrasound’ Ethereum gets, the more deflationary Ether is, and ultimately, the more service is done to the public. This could be a strategy chosen over a For-Profit Builder if the operator determines that the potential social credit outweighs the mere profit a For-Profit Builder would contribute. Once again this motivation would apply to another type of Public Good Builder, an ‘Organic’ Builder. Instead of contributing high burn rates, this builder would rather exclude toxic MEV such as Sandwitching or even swear off censorship, creating a stronger Ethereum protocol rather than just making Ether more economically plausible. Both would be critical to maintaining the integrity and utility of Ethereum, and both can be used in harmony or to different degrees.</p>
<p>In order for a PGB to be nominated to build a block, both a validator would need to value its reputation/social credit over its slot profit and a builder would go through the trouble to construct a public service block. Due to the random nature of POS, even if a validator were to choose a PGB for its block construction it would <em>not</em> experience a epoch-over-epoch profit increase, but a builder may. This is touched on later, but the social credit a PGB acquires could bring in more <em>business</em> while the randomness of validation ensures that a validator would not.</p>
<p>Some of these public service examples have already been theorized, and many tend to restrict public good opportunities to <em>just</em> these examples. If you take anything away from this article, know that this ePBS social layer may be more dynamic than many predict it to be.</p>
<h3><a class="anchor" href="https://ethresear.ch#case-study-3" name="case-study-3"></a><strong>Case Study</strong></h3>
<p>When choosing a block builder, validators have a choice; a choice of image; a choice of profit; and ultimately a choice that will contribute to the ePBS social layer. Once again, public service can be attractive to many builders still establishing their image. Potential for this public service can be found even in the ePBS vulnerability of Staker-initiated griefing. (theorized by <a href="https://ethresear.ch/u/aelowsson">aelowsson</a>) Simply put, SSPs will do anything to remain the most profitable staking model, even if they need to sabotage or grief competing validators. By outbidding other builders, SSP-sponsored builders can achieve the slot held by an opposing validator and tank opposing SSP rewards. This then reduces the average user rewards for competing SSPs and drives users (and fees) to their own platform. One example of alternative public service resides within SSP peacekeeping. By reducing burn rates and including all MEV (including toxic) a for-profit model can be derived. Using liquidity developed via this method can then be used to outbid suspected SSP griefers or even direct bidding aggression at any SSP-sponsored builder, further enforcing ePBS and preventing large validators and builders from being run together again. However, looking past technical difficulties such as identifying SSP builders, this method also proves to be inefficient, as it offers minimal public credit, due to the fact it leverages harmful building practices to enforce SSP unity.</p>
<h3><a class="anchor" href="https://ethresear.ch#pgb-efficiency-4" name="pgb-efficiency-4"></a><strong>PGB Efficiency</strong></h3>
<p>The efficiency of a public goods builder or PGB is multidimensional, to say the least. Two sections I’ll touch on are popularity efficiency and network improvement-based efficiency.</p>
<p>PBE or Population-Based Efficiency is the simpler of the two and can be represented by the following equation:</p>
<div class="math">
E = \frac{pq}{ra}
</div>
<p>This equation combines a popularity index (<span class="math">\frac{q}{a}</span>) and a profit margin (<span class="math">\frac{p}{r}</span>); where <span class="math">E</span> is relative efficiency, <span class="math">p</span> is average slot profits, <span class="math">q</span> is average builder pick rate, <span class="math">r</span> is average slot revenue and a is average builder pick rate.</p>
<p>This equation represents the efficiency of a PGB’s ‘social marketing’. By sacrificing some slot profit a PGB can increase its pick rates and potentially increase its epoch-over-epoch profit or even just control more of the builder market. <em>Of course, all the while serving the Ethereum public.</em></p>
<p>Another form of efficiency modeling is NIBE or Network Improvement Based Efficiency. This model bases the efficiency of a PGB on its actual public service. However, the idea is harder to put an equation behind, as each public service action contributes varying improvements to the network and each have their own relative values.</p>
<h3><a class="anchor" href="https://ethresear.ch#the-social-layer-5" name="the-social-layer-5"></a><strong>The Social Layer</strong></h3>
<p>As ePBS rolls out and additional features like MEV burn hit the network, it’s clear that countless social impacts will arise. From SSP sabotage to even the PGB social dynamic, there are many opportunities for cliques, groups, and cartels to form. However, no matter what social problems may arise, any reputable builder will find a way to negate any nefarious builder patterns, and any reputable validators will find a way to support any honest builders. Ultimately, the idea of social credibility and the value of PGB’s may balance the many Immiscible groups that are predicted to form after the introduction of ePBS and MEV burn.</p>
<p>Concluding this paper I would like to, once again, thank both <a href="https://ethresear.ch/u/aelowsson">aelowsson</a> and <a href="https://ethresear.ch/u/mikeneuder">Mike Neuder</a> for their wonderful research on MEV burn and pricing auctions respectively. Between PGB dynamics and ePBS metagame, there’s so much more to uncover in this field, so I would like to end by wrapping up this research on PGB dynamics and the resulting social layer by reminding everyone that there is still a world of research to be done.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/epbs-metagame-ssp-peacekeeping-and-alternative-public-service/20162">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 27 Jul 2024 18:47:18 +0000</pubDate>
</item>
<item>
<title>Rollup-Centric Considerations of Based Preconfimations</title>
<link>https://ethresear.ch/t/rollup-centric-considerations-of-based-preconfimations/20160</link>
<guid>https://ethresear.ch/t/rollup-centric-considerations-of-based-preconfimations/20160</guid>
<content:encoded><![CDATA[
<div> 关键词：基于链、预确认、盈利性、时间性、领导者选举

总结:
本文详细阐述了基于链（Taiko链）的构建与优化策略。首先，文章介绍了基于链的基本架构，包括去中心化提案者同步至L2内存池，以及如何通过预确认机制来提升盈利性和时间效率。预确认允许节点周期性地对较小的序列化批次进行确认，从而减少数据发布成本，并通过设置预确认间隔T来确保L2块的定期发布。

接着，文章讨论了数据发布问题，当前Taiko链采用将所有编码的L2交易列表打包成blob的方式，这导致提案者需要支付整个blob的L1 Gas费用，降低了块的盈利能力。Gwyneth引入预确认后，可以实现更高效的数据打包和发布，通过预确认者批量提交块到L1，同时分离了序列化承诺和数据可用性。

文章还分析了预确认带来的非确定性提案问题，即多个预确认者并行构建链会导致链的非确定性。为解决这一问题，文章提出领导者选举作为解决方案之一，以确保在任何给定时间点只有一个节点有权限更新链的状态。领导者选举有助于维护链的确定性和安全性，同时不影响其基础特性。

最后，文章强调了基于链在继承L1安全性和最终性的同时，面临的一些实际挑战，如提案者的盈利性、链启动时的活力建设以及块时间配置。通过预确认机制的优化，基于链可以在不牺牲安全性和最终性的情况下，提供快速的交易确认时间和高效的盈利能力，从而接近理论上可能达到的最大去中心化水平。

综上所述，本文围绕基于链的构建、预确认机制的实施、非确定性提案的解决方案以及面对的实际挑战，提供了一套全面的优化策略，旨在提升基于链的性能和用户体验，同时保证系统的安全性和稳定性。 <div>
<p><em>Special thanks to <a href="https://x.com/Brechtpd" rel="noopener nofollow ugc">Brecht Devos</a>, <a href="https://twitter.com/linoscope" rel="noopener nofollow ugc">Lin Oshitani</a>, <a href="https://twitter.com/ConorMcMenamin9" rel="noopener nofollow ugc">Conor McMenamin</a>, <a href="https://medium.com/@jonas.bostoen" rel="noopener nofollow ugc">Jonas Bostoen</a>, <a href="https://twitter.com/ccpamatt" rel="noopener nofollow ugc">Christian Matt</a> for the reviews <img alt=":tada:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/tada.png?v=12" title=":tada:" width="20" /></em></p>
<p>TLDR;<br />
This article presents <a href="https://x.com/gwyneth_taiko" rel="noopener nofollow ugc">Gwyneth</a> from the <a href="https://x.com/taikoxyz" rel="noopener nofollow ugc">Taiko Labs</a>.  We outline the Taiko chain setup, discuss the profitability and timeliness of L2 block building, and explore how implementations of preconfirmations can configure blocktime and more efficient data publishing. We also address the issue of nondeterministic proposals caused by multiple preconfirmers through leader election, which affect UX for builders and users. The designs in this article are subject to change.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-the-simplest-taiko-chain-1" name="background-the-simplest-taiko-chain-1"></a>Background: The Simplest Taiko Chain</h2>
<p>At present, Taiko Labs is subsidizing block production by running proposers, effectively burning ETH to maintain a fast and inexpensive network. With that in mind, our effort on preconfirmations needs to be expedited, as we aim to facilitate profitable block building in the community without compromising security and throughput. This is the basic setup of the Taiko chain:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/1/f196c6e6be939ac54173b7e6802df9776c2728b6.png" title="Untitled (4)"><img alt="Untitled (4)" height="294" src="https://ethresear.ch/uploads/default/optimized/3X/f/1/f196c6e6be939ac54173b7e6802df9776c2728b6_2_517x294.png" width="517" /></a></div><p></p>
<ul>
<li>
<p>Decentralized proposers run their <a href="https://docs.taiko.xyz/core-concepts/taiko-nodes/" rel="noopener nofollow ugc">taiko-geth</a> to sync with the L2 mempool.</p>
</li>
<li>
<p>When a batch of Tx constitutes a <strong>profitable block</strong>, the rational proposer <a href="https://github.com/taikoxyz/taiko-mono/blob/b89e97b1cd7795753bba57b8ca6caf8a77e22613/packages/protocol/contracts/L1/ITaikoL1.sol#L14" rel="noopener nofollow ugc">submits this block</a> to L1.</p>
<ul>
<li>The profitable criteria is the total tip collected from all Tx plus their MEV covers the costs to interact with L1 and prover:<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/6/261274c74370de26d6ec593f649377533be6ea83.png" title="Screen Shot 2024-07-05 at 12.54.04 PM"><img alt="Screen Shot 2024-07-05 at 12.54.04 PM" height="50" src="https://ethresear.ch/uploads/default/optimized/3X/2/6/261274c74370de26d6ec593f649377533be6ea83_2_690x50.png" width="690" /></a></div></li>
</ul>
</li>
<li>
<p>Taiko smart contract on L1 contains the decentralized ledger of L2 Tx batches. These batches will, inevitably, contain invalid Tx with vanilla proposing strategy, since the sequencing is not coordinated. For example:</p>
<ul>
<li>L2-75 has a Tx transferring 100 ETH from Alice to Bob without Alice’s correct signature</li>
<li>L2-76 and 77 both contain a Tx from Cassy with nonce equaling 9;</li>
</ul>
<p>In such cases,  <a href="https://github.com/taikoxyz/taiko-mono/tree/ec6c179967b9ac93cd967ff3a1fe8b331fdb8256/packages/taiko-client" rel="noopener nofollow ugc">taiko-client</a>, similar to Ethereum’s consensus client, will witness the invalid Txs from the L1 ledger and exclude them from the actual block being synced to L2.</p>
</li>
<li>
<p>Back to L2, each <a href="https://github.com/taikoxyz/taiko-mono/tree/ec6c179967b9ac93cd967ff3a1fe8b331fdb8256/packages/taiko-client" rel="noopener nofollow ugc">taiko-client</a> (fork of Ethereum’s consensus client), witnesses the L1 ledger and applies a deterministic rule that invalidates the above Txs. Subsequently, the client can form a correct batch constituting the next block and construct the blockhash.</p>
</li>
<li>
<p>This blockhash is considered finalized when a prover submits proof of the execution of valid Txs, as well as the exclusion of invalid Txs from the state of the ledger.</p>
</li>
</ul>
<p>As Vitalik noted, a based rollup can be a <a href="https://vitalik.eth.limo/general/2021/01/05/rollup.html" rel="noopener nofollow ugc">“total anarchy”</a> amid the chaos, but it remains functional as long as the decentralized ledger persists and the L2 network maintains synchronization. Taiko will continue to progress by inheriting <strong>L1 security and finality</strong>. However, proposers may still encounter challenges, resulting in a <strong>liveness</strong> issue due to lack of profitability.</p>
<h2><a class="anchor" href="https://ethresear.ch#challenges-and-solutions-2" name="challenges-and-solutions-2"></a>Challenges and Solutions</h2>
<h3><a class="anchor" href="https://ethresear.ch#profitability-timing-game-in-l2-block-building-3" name="profitability-timing-game-in-l2-block-building-3"></a>Profitability &amp; Timing Game in L2 Block Building</h3>
<p>In the diagram below proposer Alice observes L2-75 upon confirming L1-100, and she creates L2-76 with blockhash 0xabc. Proposer Bob, attempting the same, causes a fork with an alternate blockhash 0xf3c. Both submit proposals to L1-100 and pay the current L1 transaction fee. However, since Alice’s transactions were incorporated first, Bob’s transaction reverts due to L1_UNEXPECTED_PARENT(), causing Bob to lose his proposing fee. Alice successfully earns the tip and MEV of L2-76, but she still needs to compensate the prover to validate her block afterward.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/8/c8a72e51d5473fb6e20d1824d69e4a3baf4c6921.png" title="Untitled (5)"><img alt="Untitled (5)" height="303" src="https://ethresear.ch/uploads/default/optimized/3X/c/8/c8a72e51d5473fb6e20d1824d69e4a3baf4c6921_2_517x303.png" width="517" /></a></div><p></p>
<p>An L2 block is proposed to the rollup Contract as a raw transaction batch. Consequently, each node subscribing to the event derives the blockhash in their own execution clients. Despite this, the <strong>rollup state is finalized when the proposal is confirmed on L1 because block hash derivation is deterministic.</strong> We still need a proof to validate the block hash to rollup’s L1 ledger, enabling light clients to fetch the states and users to perform withdrawals. Hence, real-time proving solutions such as SGX are important because they enforce L2 state finality with high probability. Let’s recall:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/6/261274c74370de26d6ec593f649377533be6ea83.png" title="Screen Shot 2024-07-05 at 12.54.04 PM"><img alt="Screen Shot 2024-07-05 at 12.54.04 PM" height="50" src="https://ethresear.ch/uploads/default/optimized/3X/2/6/261274c74370de26d6ec593f649377533be6ea83_2_690x50.png" width="690" /></a></div><p></p>
<p>Solving for MEV is a knapsack problem - the larger the knapsack, the more value extracted. It’s been well-studied that L1 proposers will play <a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612">the timing game</a> to extend the MEV solving window as much as possible; the same logics apply to L2. Even worse, because L2 users typically tip much lower in an ecosystem with significantly less liquidity, the current 12s block time on Taiko is far less than enough for anyone to profit, which results in a <strong>liveness issue for decentralized proposing</strong>. This is why Taiko Labs operates an unprofitable proposer to sustain the 12s block time. Without taking measures, the L2 blocktime would be arbitrarily long if rational proposers play the timing game.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/e/9ea87c99a3e43e4879c1d6de369b3bb71d885276.png" title="Untitled (6)"><img alt="Untitled (6)" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/9/e/9ea87c99a3e43e4879c1d6de369b3bb71d885276_2_495x375.png" width="495" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#solving-blocktime-data-publishing-with-preconfirmations-4" name="solving-blocktime-data-publishing-with-preconfirmations-4"></a>Solving Blocktime &amp; Data Publishing with Preconfirmations</h3>
<p>Essentially, we’re facing a conflict in a <strong>UX property of L2 (blocktime) versus decentralized block building</strong>. In centralized L2, timeliness is easily managed by the centralized sequencer, while on L1, the beacon attestation enforces the time to publish the execution payload. Thus, we observe that timeliness must be enforced by some mechanism other than builders in the game. Whoever facilitates preconfirmations could also mandate blocktime.</p>
<p><strong>A preconfirmer can periodically issue preconfirmations to builders for smaller sequenced batches, then batch publish the batches to reduce the data publishing costs.</strong> The periodic issuance of batches now constitutes L2 blocks. The L2 protocol, which allows the preconfirmer to opt in, can facilitate timeliness by ensuring preconfirmed blocks are released every T second. Now, we define <strong>T as the L2 blocktime</strong>, which can be adjusted faster to improve user experience.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/2/d204bb354780b7e25543312984493e2f719d2f72.png" title="Untitled (7)"><img alt="Untitled (7)" height="387" src="https://ethresear.ch/uploads/default/optimized/3X/d/2/d204bb354780b7e25543312984493e2f719d2f72_2_690x387.png" width="690" /></a></div><p></p>
<p>Regarding data publishing, Taiko currently publishes all encoded L2 transaction lists in blobs. This requires the proposer to cover the L1 gas fee for a whole blob regardless how much data is actually necessary, further reducing the block’s profitability. In Gwyneth, preconfirmations will allow for <strong>more batching of L2 blocks into blobs</strong> if the preconfirmer is assigned multiple L1 slots, which also implies the separation of sequencing commitment and data availability:</p>
<ul>
<li><strong>Preconfirmations Issuance ⇒ commit L2 sequencing</strong></li>
<li><strong>Preconfirmations Delivery ⇒ data publishing to L1</strong></li>
</ul>
<p>Now we can characterize the L1 preconfirmer as the de facto L2 proposer, and the existing decentralized sequencer who submits batches as L2 builders - we just migrate the PBS architecture to L2. Moreover, this L2 PBS mechanism can use a similar pipeline as on L1, because the L2 proposer is exactly an L1 validator who runs something like <a href="https://github.com/flashbots/mev-boost.git" rel="noopener nofollow ugc">MEV-boost</a> with a preconfirmation add-on. The new fee model functions as follows:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7f1262f29380aea940d4c5152693be272949797.png" title="Screen Shot 2024-07-11 at 2.46.47 AM (1)"><img alt="Screen Shot 2024-07-11 at 2.46.47 AM (1)" height="212" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7f1262f29380aea940d4c5152693be272949797_2_460x212.png" width="460" /></a></div><p></p>
<p>For clarification, L2 proposers are the preconfirmers who opt into the Gwyneth protocol to propose L2 blocks, and the preconfrmers are the L1 validators who can issue preconfirmations.</p>
<p><img alt="Screen Shot 2024-07-11 at 2.47.22 AM (1)" height="32" src="https://ethresear.ch/uploads/default/original/3X/f/0/f01ebd831084ad709d4805fe4ff1b83327b3ce73.png" width="372" /></p>
<p>Overall, preconfirmations enable Gwyneth blocks to be built in short and steady intervals by decentralized participants, while not compromising profitability. A deficiency of liveness caused by lacking liquidity on L2 will not jeopardize blocktime; in other words, users can always enjoy fast transaction confirmation. It also provides a clear model for L2 MEV compatible with the existing PBS pipeline.</p>
<h3><a class="anchor" href="https://ethresear.ch#decentralized-block-proposing-with-pbs-5" name="decentralized-block-proposing-with-pbs-5"></a>Decentralized Block Proposing with PBS</h3>
<p>We have discussed how preconfirmation benefits L2 proposers. Now, let’s consider <strong>proposal inclusion</strong> from the perspective of L1 validators.</p>
<p>Initially, we have a distinct group of L2 participants who compete to propose the next L2 batch by calling the <code>ProposeBlock</code> function in the Taiko smart contract. Their proposal transactions with encoded L2 batches are exposed in the public mempool, and L1 validators or builders will choose to include these proposals. Apparently, t<strong>he L1 parties can easily capture the transactions, stealing the L2 tip and MEV when producing the L1 block.</strong> We’re revisiting the PBS playbook. Rollup with permissionless sequencing can implement similar mechanisms to mitigate block stealing.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/1/d17ee918d3b13e915483a110c04c22af49e6fe0e.png" title="Untitled (8)"><img alt="Untitled (8)" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/d/1/d17ee918d3b13e915483a110c04c22af49e6fe0e_2_517x260.png" width="517" /></a></div><p></p>
<p>However, there’s no need for mitigation following the <a href="https://ethresear.ch/t/based-preconfirmations/17353">definition</a> of base rollup:</p>
<blockquote>
<p>A rollup is said to be based, or L1-sequenced, when its sequencing is driven by the base L1.</p>
</blockquote>
<p>In other words, all L2 proposers are L1 validators. Given access to both mempools, a builder can incorporate L2 batches in her L1 bundles, which is by far the most <strong>efficient paradigm for Gwyneth block-building</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68eae50a088bf3c631d1fb23e52d49855f0a0ad5.png" title="Untitled (9)"><img alt="Untitled (9)" height="249" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68eae50a088bf3c631d1fb23e52d49855f0a0ad5_2_517x249.png" width="517" /></a></div><p></p>
<p>Recall also in PBS, validators have a choice to build the block natively without using <a href="https://github.com/flashbots/mev-boost.git" rel="noopener nofollow ugc">MEV-boost</a> connecting to external builders. The L1 validator, who’s also an L2 proposer, can issue consecutive preconfirmations to self-produce L2 blocks until her slot to propose. In this case, we may also omit the separate role of builders, and rewrite the fee model for L2 proposers:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/1291f379205c49d484fda26e97169d2671738cdd.png" title="Screen Shot 2024-07-11 at 2.46.17 AM"><img alt="Screen Shot 2024-07-11 at 2.46.17 AM" height="90" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/1291f379205c49d484fda26e97169d2671738cdd_2_517x90.png" width="517" /></a></div><p></p>
<p>With the inclusion model much simplified, we note that the L1 validator who includes the L2 proposal is the deterministic proposer of L2. Given Taiko’s current 12s blocktime, there is a one-to-one correspondence between each L1 and L2 block, hence the state of the chain at any slot is deterministic.</p>
<h3><a class="anchor" href="https://ethresear.ch#nondeterministic-proposer-and-leader-election-6" name="nondeterministic-proposer-and-leader-election-6"></a>Nondeterministic Proposer and Leader Election</h3>
<p>Now, as we decouple the L1-to-L2 block correspondence with preconfirmation, we argue that <strong>nondeterminism is also introduced because, during the L1 epoch, multiple preconfirmers exist to perform sequencing concurrently.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/2/b24f24e1ef4885e714897d2f95d25f8c1f2582fb.jpeg" title="Untitled (10)"><img alt="Untitled (10)" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/2/b24f24e1ef4885e714897d2f95d25f8c1f2582fb_2_660x500.jpeg" width="660" /></a></div><p></p>
<p>If these preconfirmers are the subset of L2 proposers who produce blocks natively, everyone will start building on top of the latest finalized parent. This continues until the set of preconfirmations is settled, updating the head of the chain. Then, a proposer will restart with the new head and <strong>abandon their local ledger, resulting in previous preconfirmed transactions being reverted upon delivery</strong>. If the proposer does not restart and proposes the local fork with data publishing during their slot, <strong>that proposal will also revert</strong>. In such a case, the L2 will miss a slot to update; users will experience the <strong>chain halting</strong> until the next proposer comes on board. The malfunctioning proposer might be slashed depending on the protocol implementation.</p>
<p>Considering builders in the PBS setting, who can send their sequenced batches to all L2 proposers in the current epoch, <strong>the head of the chain will appear nondeterministic</strong> to them, as all proposers will endorse different forks simultaneously. However, only the next-in-line proposer holds the source of truth, since her ledger will be settled first. <strong>Therefore, a rational builder should request preconfirmation only from the next-in-line proposer</strong>. Nonetheless, the protocol cannot prevent a malicious proposer from forcing his fork proposal through a regular transaction on Ethereum.</p>
<p>There are two possible solutions: 1)  <strong>define the ledger held by the next-in-line proposer as canonical, which yields a leader selection protocol;</strong> 2) disable block proposals at the non-preconfirmed L1 slots, then fork proposals will likely be excluded by a rational next-in-line preconfirmer. The latter solution is sub-optimal because we still want to preserve the option of non-preconfirmed block proposals unless there are enough preconfirmers to achieve our desirable liveness.</p>
<h4><a class="anchor" href="https://ethresear.ch#on-leader-election-7" name="on-leader-election-7"></a>On Leader Election</h4>
<p>In a decentralized setting at anytime, <strong>only one L1 validator should have exclusive write access to the L2 state</strong>, even if all opt-in participants can issue preconfirmations. <strong>Such systems are inherently finalized without any external finality gadget</strong>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/3/23c6258764b5d1c0ec9df8be0a3db5b6cd2132a8.png" title="Untitled (11)"><img alt="Untitled (11)" height="231" src="https://ethresear.ch/uploads/default/optimized/3X/2/3/23c6258764b5d1c0ec9df8be0a3db5b6cd2132a8_2_690x231.png" width="690" /></a></div><p></p>
<p>On the other hand, an L2 builder who’s building the latest Gwyneth chain can only write to preconfirmed L1 block space from the next opt-in validator. Requesting preconfirmations from others is strictly prohibited because that creates a gap in the slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/d/3d2b9b203eda188c0ebc6520cdb249d14b114b14.png" title="Untitled (12)"><img alt="Untitled (12)" height="251" src="https://ethresear.ch/uploads/default/optimized/3X/3/d/3d2b9b203eda188c0ebc6520cdb249d14b114b14_2_690x251.png" width="690" /></a></div><p></p>
<p>Essentially, we create a just-in-time market for exchanging L1/L2 block space. Instead of a JIT auction, Some suggest using <a href="https://ethresear.ch/t/execution-tickets/17944">execution tickets</a> for an ahead-of-time auction, which means in the diagram above, the L1-104 proposer can sell L2-79 block space simultaneously while the L1-102 proposer sells L2-78. This establishes a one-to-one correspondence between L1/L2 slots in a more controlled manner, and since it allows all participants to buy and sell these rights, an ahead-of-time auction aligns better with the preconfirmation market. From the L2 perspective, the protocol’s sale of execution tickets can imply new fee models for value-capturing. <a href="https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837">XGA-style preconfirmations</a> can be a good implementation.</p>
<h2><a class="anchor" href="https://ethresear.ch#summary-8" name="summary-8"></a>Summary</h2>
<p>Taiko started as a rollup with decentralized proposers, with a protocol that deterministically derives L2 state as long as the ledger is finalized on L1. We realized that based sequencing, which unites L1 and L2 proposers, transforms our framework into something more simple and powerfull. Based sequencing will work, naively, with finality and security inherited from L1.</p>
<p>Based sequencing may not work, in practice, considering builder profitability, bootstrapping liveness, and the configuration of fast blocktime. We discuss preconfirmations to tackle these challenges with some tweaks on timeliness and proposal mechanisms. However, having multiple validators who issue preconfirmations can cause the concurrent building of L2 forks. This introduces nondeterminism for the spectators of chains including builders, exchanges, and users, although fortunately, nondeterministic sequencing does not affect finality - <strong>most obstacles in based sequencing relate to essential UX properties for builders and users.</strong></p>
<p>Despite some controversy, leader election could be a practical middle-ground solution. We anticipate a significant number of L1 proposers opting in as preconfirmations gain adoption. Consequently, <strong>proposer decentralization still remains close to the (at least theoretically) maximal achievable decentralization offered by a vanilla based rollup.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/0/40dd31cbef98940c5ba5f843d943f08e9ab8a7e2.png" title="Untitled (13)"><img alt="Untitled (13)" height="339" src="https://ethresear.ch/uploads/default/optimized/3X/4/0/40dd31cbef98940c5ba5f843d943f08e9ab8a7e2_2_690x339.png" width="690" /></a></div><p></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/rollup-centric-considerations-of-based-preconfimations/20160">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 27 Jul 2024 14:41:46 +0000</pubDate>
</item>
<item>
<title>Notes on the LVR of FM-AMM</title>
<link>https://ethresear.ch/t/notes-on-the-lvr-of-fm-amm/20151</link>
<guid>https://ethresear.ch/t/notes-on-the-lvr-of-fm-amm/20151</guid>
<content:encoded><![CDATA[
<div> 关键词：FM-AMM、LVR、CEX-DEX、交易成本、流动性池大小

总结:
本文详细介绍了改进后的自动做市商（FM-AMM）的额外特性，通过找到纯粹策略纳什均衡来解决CEX-DEX套利商之间的博弈问题。文中计算了理论设置下的FM-AMM的渐近LVR，并将其性能与Uniswap V2风格的固定费率CPMM进行了对比。观察结果表明，FM-AMM的性能受到价格波动、交易成本和流动性池规模的影响，在特定条件下，它对套利商的损失较小。

文章首先回顾了LVR在自动做市商领域的重要性及其在减少LVR方面的努力。接着，作者详细阐述了FM-AMM的设计，并通过修改原始设计解决了更广泛情况下的批量交易执行问题。随后，通过建立模型分析了具有固定交易成本和零售订单流不存在条件下的FM-AMM性能，发现其纳什均衡存在并具有对称性，且LVR随参与者数量成反比衰减。进一步地，文章考虑了交易成本由参与者决定的情况，指出FM-AMM的优势取决于跳动大小、频率和成本，而数值模拟显示FM-AMM与基于rollup的解决方案相匹配。

最后，通过对比FM-AMM和CPMM的LVR，文章指出FM-AMM在高波动率、低交易成本和较大流动性池的情况下表现出色。同时，文章讨论了在不同参数下的性能比较，发现FM-AMM在L2环境中以及低交易成本的L1环境中具有优势，这解释了之前研究结果的混杂性。此外，文章还提出了未来研究应考虑更宽松条件以提供更全面评估的建议。

总的来说，本文提供了对FM-AMM在不同市场条件下的性能分析，强调了其在特定场景下的优越性，同时也指出了现有模型的局限性和未来研究方向。 <div>
<h1><a class="anchor" href="https://ethresear.ch#h-0-tldr-1" name="h-0-tldr-1"></a>0. TL;DR</h1>
<p>We introduced and detailed the additional features of FM-AMM, as presented in [CF23]. We modeled the game between CEX-DEX arbitrageurs for arbitrage profit on FM-AMM and then solved it by finding the pure strategy Nash equilibrium. Lastly, we calculated the asymptotic LVR of FM-AMM in theoretical settings and compared its performance against the Uniswap V2-style fixed-rate fee CPMM through numerical simulations. Our observations indicated that the performance is heavily influenced by price volatility, transaction costs, and the size of the liquidity pool, with FM-AMM showing a reduced loss to arbitrageurs under specific conditions.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-1-introduction-2" name="h-1-introduction-2"></a>1. Introduction</h1>
<p>Since LVR was introduced in [MMRZ22] and [MMR23], it has quickly become the standard for measuring the performance of AMMs. Numerous attempts have been made to reduce LVR through dynamic fee policies, and this research continues actively. However, batch trade execution has not received much attention, except in [CF23] and [GGMR22]. In [CF23], the authors proposed a function-maximizing automated market maker (FM-AMM), asserting it effectively eliminates LVR, and provided numerical simulations comparing its performance with various Uniswap V3 pools. They later <a href="https://forum.cow.fi/t/4-months-of-cow-amm-what-we-have-learned-and-the-next-steps/2432" rel="noopener nofollow ugc">claimed</a> that CoW-AMM (their implementation of FM-AMM) performed well in live settings too, which led to <a href="https://x.com/0x94305/status/1813690004331438306" rel="noopener nofollow ugc">debate</a> on Twitter regarding the legitimacy of their measurement methods. Although the debate focused more on whether markout is a useful metric for measuring performance, the existence of retail order flow and fluctuating transaction costs are also obstacles to precisely comparing their performance. In this article, we analyze the performance of FM-AMM and compare it to CPMM under fixed transaction costs and in the absence of retail order flow conditions like those in [N22] and [E24].</p>
<p>In detail, we slightly modified their design and found a Nash equilibrium in a game where arbitrageurs strategically submit orders to the (slightly modified) FM-AMM to maximize their returns. The game is similar to the liquidity provision game introduced in [MC24], which is a special form of the generalized Tullock contest. The resulting equilibrium has many favorable properties: the solution always uniquely exists, and it is symmetric. Moreover, LVR decays inversely proportionally to the number of participants. This model assumes that the number of arbitrageurs, <span class="math">N</span>, is pre-determined and transaction cost, <span class="math">c</span>, is zero. We proceed to a model where the number of participants is determined endogenously according to <span class="math">c</span>. In this setting, FM-AMM is not always superior; the result now depends on jump size, frequency, and cost. We provide numerical simulation results and suggest that FM-AMM fits well with rollup-based solutions.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-2-fm-amm-3" name="h-2-fm-amm-3"></a>2. FM-AMM</h1>
<p>In this section we fill the omitted details of FM-AMM introduced in [CF23] to handle the more general case. The underlying AMM curve introduced in [CF23] is:</p>
<div class="math">
y_\text{out} = \frac{x_\text{in}}{X + 2x_\text{in}}Y,
</div>
<p>where <span class="math">x_\text{in}</span> is the amount of token <span class="math">X</span> the trader is willing to sell, and <span class="math">y_\text{in}</span> is the amount of token <span class="math">Y</span> that she will receive. However, this is the simplest case where only a single side of order is submitted in batch. Authors of original paper handled the case such that both side of orders exist in the same batch by assuming users only specify the amount of token X to buy or sell. Unfortunately, this is hard to implement in fully on-chain manner since whether the trader has enough capital to buy specified amount of token X is not guaranteed before the batch is settled (Selling is not problematic; we can pull the token from trader and keep it by settlement). We generalize the formula to handle broader range of cases. Let <span class="math">X, Y</span> be reserves of pool, <span class="math">T</span> be total supply of LP tokens before batch settlement, <span class="math">x_\text{in}, y_\text{in}</span> be aggregate amount of each token that traders are willing to sell, and <span class="math">x_\text{mint}, y_\text{mint}</span> be aggregate amount of each token provided from LPs. The fundamental equation we will start with is:</p>
<div class="math">
\begin{align}\begin{bmatrix}x_{\text{mint}} \\y_{\text{mint}}\end{bmatrix}&amp;=x_{\text{mint}} \begin{bmatrix}1 \\p\end{bmatrix}+\begin{bmatrix}0 \\2\alpha\end{bmatrix}\\\begin{bmatrix}x_{\text{in}} \\y_{\text{in}}\end{bmatrix}&amp;=x_{\text{in}} \begin{bmatrix}1 \\p\end{bmatrix}+\begin{bmatrix}0 \\\beta\end{bmatrix}\\\begin{bmatrix}x_1 \\y_1\end{bmatrix}&amp;=\begin{bmatrix}x_0 \cdot \frac{y_0 + \alpha + \beta}{y_0 + 2(\alpha + \beta)} \\y_0 + \alpha + \beta\end{bmatrix}\end{align}
</div>
<p>Here, the <span class="math">p</span> is the clearing price, and <span class="math">\alpha, \beta</span> are the net swap amount for swapping and minting, respectively. In short, among the submitted orders, we swap only part of them, <span class="math">\alpha</span> and <span class="math">\beta</span>, then exchange the rest via p2p without changing the spot price. The fact that</p>
<div class="math">
\begin{bmatrix}x_{\text{mint}} \\y_{\text{mint}} - 2\alpha\end{bmatrix}, \begin{bmatrix}x_{\text{in}} \\y_{\text{in}} - \beta\end{bmatrix}, \begin{bmatrix}x_1 \\y_1\end{bmatrix}
</div>
<p>are all parallel gives us following matrix equation:</p>
<div class="math">
\begin{equation}\begin{bmatrix}2x_0 + 2x_{\text{mint}} &amp; 2x_{\text{mint}} \\2x_{\text{in}} &amp; 2x_{\text{in}} + x_0\end{bmatrix}\begin{bmatrix}\alpha \\\beta\end{bmatrix}=\begin{bmatrix}x_0 y_{\text{mint}} - x_{\text{mint}} y_0 \\x_0 y_{\text{in}} - x_{\text{in}} y_0\end{bmatrix}\end{equation}
</div>
<p>Note that the determinant of matrix in LHS is always strictly positive so above equation is not singular. <span class="math">\alpha, \beta</span>  are:</p>
<div class="math">
\begin{align} (\alpha, \beta) = \left( \frac{\frac{x_{0} y_{mint}}{2} + x_{in} y_{mint} - \frac{x_{mint} y_{0}}{2} - x_{mint} y_{in}}{x_{0} + 2 x_{in} + x_{mint}}, \  \frac{x_{0} y_{in} - x_{in} y_{0} - x_{in} y_{mint} + x_{mint} y_{in}}{x_{0} + 2 x_{in} + x_{mint}}\right) \end{align}
</div>
<p>The clearing price, <span class="math">p_c</span>, is:</p>
<div class="math">
\begin{align} 
p_c = \frac{y_{0} + 2 y_{in} + y_{mint}}{x_{0} + 2 x_{in} + x_{mint}}
\end{align}
</div>
<p><span class="math">x_\text{out}, y_\text{out}</span> are:</p>
<div class="math">
\begin{align}
(x_\text{out}, y_\text{out}) &amp;= 
\left( \frac{y_{in} \left(x_{0} + 2 x_{in} + x_{mint}\right)}{y_{0} + 2 y_{in} + y_{mint}}, \  \frac{x_{in} \left(y_{0} + 2 y_{in} + y_{mint}\right)}{x_{0} + 2 x_{in} + x_{mint}}\right) \\
&amp;= \left(\frac{y_\text{in}}{p_c}, p_c x_\text{in} \right) \\
\end{align} 
</div>
<p>It is straight forward to find <span class="math">x_2, y_2</span>, the reserves after minting LP tokens, and <span class="math">t</span>, the newly issued LP token amount, so we would skip on them here.</p>
<p>Above construction charges no fee. To keep price same even after charging fee, we will take <span class="math">1/(1 + \gamma)</span> portion of input and <span class="math">\gamma</span> portion of output as fee. So the effective fee rate will be   <span class="math">\frac{2 \gamma}{1+ \gamma}</span>, which is approximately <span class="math">2 \gamma</span>. Considering arbitrageurs it may better to take fee fully on input, though.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-3-model-4" name="h-3-model-4"></a>3. Model</h1>
<p>In this section, we describe the model upon which our analysis is based. We model a normal form game involving strategic arbitrageurs. This means that each player is unaware of the bids of others, and all bids are submitted simultaneously. Additionally, each player’s bid is never censored. Although this assumption does not perfectly reflect the current state of blockchains, ongoing cryptographic developments and improved market designs, such as inclusion lists, will help bridge the gap between theory and reality. This formulation is almost the same as that of [CM24]; the only difference is that players now “take” mispriced liquidity instead of providing it to the AMM.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-31-automated-market-maker-5" name="h-31-automated-market-maker-5"></a>3.1. Automated Market Maker</h2>
<p>For the AMM, we will use the FM-AMM introduced in Section 2. Note that the AMM itself is not a player; we assume that the LPs of the AMM are passive investors who will not take any action in the short term.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-32-arbitrageurs-6" name="h-32-arbitrageurs-6"></a>3.2. Arbitrageurs</h2>
<p>We assume that all players are homogeneous. They are risk-neutral and can execute trades of any size and in any direction on CEX without any slippage. Their sole goal is to maximize profit.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-33-strategic-game-of-liquidity-taking-7" name="h-33-strategic-game-of-liquidity-taking-7"></a>3.3. Strategic Game of Liquidity Taking</h2>
<p>First, we solve the game with <span class="math">N</span> players where <span class="math">N</span> is given exogenously, without considering transaction costs. Then, we introduce a strictly positive transaction cost <span class="math">c</span> and derive <span class="math">N</span> from the equilibrium condition. We will restrict our interest to conditions with positive trading fees, which guarantees the uniqueness of the equilibrium. Players observe the pool reserves <span class="math">X</span>, <span class="math">Y</span>, and the external true price <span class="math">P</span>. Then, they submit bids <span class="math">(x_i, y_i)</span>, which are the amounts of tokens to sell to the pool. The clearing price will be:</p>
<div class="math">
\begin{align}
P_c = \frac{Y + 2\sum^N_{i=1} y_i }{X + 2\sum^N_{i=1} x_i} \tag{1} \\
\end{align}
</div>
<p>The utility function is the arbitrage profit after charging the swap fee (and transaction cost, if applicable). The utility of player <span class="math">i</span>, <span class="math">U_i</span>, is:</p>
<div class="math">
\begin{align}
R_i = -(1 + \gamma)(P x_i + y_i) + (1 - \gamma)\left(\frac{P}{P_c}y_i + P_c x_i\right) \tag{2}
\end{align}
</div>
<p>Now, we are ready to find the equilibrium.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-4-equilibrium-analysis-8" name="h-4-equilibrium-analysis-8"></a>4. Equilibrium Analysis</h1>
<h2><a class="anchor" href="https://ethresear.ch#h-41-n-is-determined-exogenously-and-transaction-cost-c-is-zero-9" name="h-41-n-is-determined-exogenously-and-transaction-cost-c-is-zero-9"></a>4.1. <span class="math">N</span> is Determined Exogenously, and Transaction Cost <span class="math">c</span> is Zero</h2>
<p>We first introduce the following lemma:</p>
<div class="math">
\text{Lemma. The player } i\text{'s best response is submitting a bid with at least one 0 component, that is, either } (x_i, 0) \text{ or } (0, y_i).
</div>
<p>The proof is straightforward. Assume <span class="math">(x_i, y_i)</span> and <span class="math">(x'_i, y'_i)</span> result in the same clearing price. Then <span class="math">x_i \leq x'_i</span> if and only if <span class="math">y_i \leq y'_i</span>. Combining these and subtracting the utility of one from the other yields the desired result.</p>
<p>Meanwhile, the first order condition and the profitability condition give us that the best response is, when <span class="math">P_{-i}</span> is defined as <span class="math">P_{-i} = \frac{Y + 2\sum^N_{j \neq i} y_j }{X + 2\sum^N_{j \neq i} x_j}</span>, submitting <span class="math">x_i</span> or <span class="math">y_i</span> such that the following holds:</p>
<div class="math">
\begin{align}
P_c = 
\begin{cases} 
\sqrt{\frac{1 - \gamma}{1 + \gamma} P P_{-i}} &amp; \text{if } \frac{1 - \gamma}{1 + \gamma} P \geq P_{-i} \\
\sqrt{\frac{1 + \gamma}{1 - \gamma} P P_{-i}} &amp; \text{if } \frac{1 + \gamma}{1 - \gamma} P \leq P_{-i}
\end{cases}. \tag{3}
\end{align}
</div>
<p>Otherwise, it is better not to submit any order (i.e., bid). One can think of <span class="math">\frac{1+\gamma}{1-\gamma}P_{-i}</span> and <span class="math">\frac{1-\gamma}{1+ \gamma}P_{-i}</span> as the threshold prices such that arbitrage becomes profitable. Note that this holds for every <span class="math">i</span>, so <span class="math">P_{-i} = P_{-j}</span> for every <span class="math">i</span> and <span class="math">j</span>, which tells us the equilibrium is symmetric and always exists.</p>
<p>From now on, we only consider the external price to be sufficiently higher than the pool’s spot price, <span class="math">Y/X</span>. The opposite case can be solved in a similar manner. It is clear that <span class="math">x_\text{eq} = 0</span> for the case we are dealing with. Then, <span class="math">(3)</span> is equivalent to:</p>
<div class="math">
\begin{align}
\frac{Y + 2Ny_\text{eq}}{X} = \sqrt{\frac{1-\gamma}{1+\gamma}P\cdot \frac{Y + 2 (N-1) y_\text{eq}}{X}} \tag{4}
\end{align}
</div>
<p>Solving <span class="math">(4)</span> yields that</p>
<div class="math">
\begin{align}
y_\text{eq} = \frac{1}{4N^2}\left[ (N - 1) \cdot \frac{1-\gamma}{1+\gamma} \cdot PX -2NY +  \sqrt{(N-1)^2 + 4N \cdot \frac{Y}{X} \cdot \frac{1+\gamma}{1-\gamma} \cdot \frac{1}{P}} \cdot \frac{1-\gamma}{1+\gamma}\cdot PX \right] \tag{5}
\end{align}
</div>
<p>From now on, we will proceed with radical approximations due to its complexity. Although we do not provide any rigorous proof for the validity of such approximations, we will see it works well in the simulations later. Let <span class="math">P_0 = \frac{Y}{X}</span> and <span class="math">\varepsilon = \frac{1-\gamma}{1+\gamma} \cdot \frac{P}{P_0} - 1</span>, that is, the price difference between the threshold price and the external price. Approximating <span class="math">y_\text{eq}</span> with <span class="math">\varepsilon</span> through a Taylor series gives us a simpler form:</p>
<div class="math">
\begin{align}
y_\text{eq} &amp;=  \frac{Y}{4N^2}\left[ (N-1) \cdot (1+ \varepsilon) - 2N +(1+\varepsilon)\sqrt{(N-1)^2 +\frac{4N}{1+\varepsilon}}\right] \tag{6} \\
&amp;\approx \frac{Y}{2(N+1)} \varepsilon + o(\varepsilon^2) \tag{7}
\end{align}
</div>
<p>Using <span class="math">(7)</span>, one can compute the profit of individual arbitrageurs and the total loss of the AMM against arbitrageurs:</p>
<div class="math">
\begin{align}
ARB &amp;\approx L\sqrt{P_0}\cdot\left(\frac{1+\gamma}{2(N+1)^2}\right)\cdot\varepsilon^2 \tag{8} \\
LVR &amp;\approx (1+\gamma)\cdot L\sqrt{P_0}\cdot\left(\frac{N}{2(N+1)^2}\right)\cdot\varepsilon^2 \tag{9}
\end{align}
</div>
<p>Thus, assuming the transaction cost is <span class="math">0</span>, for any <span class="math">N</span>, every <span class="math">N</span> arbitrageur will submit identical bids and they will share the profit equally, while each individual arbitrageur’s profit will decay by <span class="math">O(N^{-2})</span>. Moreover, as <span class="math">N </span> goes to infinity the clearing price <span class="math">P_c</span> converges to threshold price, and therefore the stationary distribution of price discrepancy will be as same as that of fixed fee rate CPMM in [MMR23].</p>
<h2><a class="anchor" href="https://ethresear.ch#h-42-transaction-cost-is-not-free-and-the-number-of-arbitrageurs-is-determined-endogenously-10" name="h-42-transaction-cost-is-not-free-and-the-number-of-arbitrageurs-is-determined-endogenously-10"></a>4.2. Transaction Cost is Not Free, and the Number of Arbitrageurs is Determined Endogenously</h2>
<p>Now we extend the model in 4.1 to a more realistic one by adopting a nonzero transaction cost <span class="math">c</span>. The utility function remains the same as in <span class="math">(2)</span>, except we have an additional term <span class="math">-c</span>. Since this term disappears when we take the derivative, the best response remains the same as long as it is profitable. Thus, the solution is not much different from <span class="math">(7)</span>, except <span class="math">N</span> is replaced with <span class="math">N^{*}</span>, where <span class="math">N^{*}</span> is the largest integer that satisfies <span class="math">L\sqrt{P_0}\cdot\left(\frac{1+\gamma}{2(N^{*}+1)^2}\right)\cdot\varepsilon^2 \geq c</span>. Then, the LVR will be:</p>
<div class="math">
\begin{align}
LVR &amp;\approx (1+\gamma) \cdot  L \sqrt{P_0} \cdot\varepsilon^2 \cdot \frac{N^{*}}{2(N^{*}+1)^2} \tag{10} \\
&amp;\approx cN^{*} \tag{11} \\
&amp;\approx c \left \lfloor \varepsilon\sqrt{\frac{1+\gamma}{2c} \cdot L \sqrt{P_0}}- 1 \right\rfloor \tag{12} \\
&amp;\leq \varepsilon\sqrt{(1+\gamma)2c \cdot L \sqrt{P_0}} \tag{13}
\end{align}
</div>
<h2><a class="anchor" href="https://ethresear.ch#h-43-comparison-with-cpmm-11" name="h-43-comparison-with-cpmm-11"></a>4.3. Comparison with CPMM</h2>
<p>The derivation of the LVR for CPMM has already been studied extensively, so we will simply present the result:</p>
<div class="math">
\begin{align}
LVR_\text{CPMM} \approx \frac{1}{1-\gamma} \cdot L \sqrt{P_0} \cdot \frac{\varepsilon^2}{4}, \tag{14}
\end{align}
</div>
<p>where <span class="math">\gamma</span> is the fee rate taken from the input and <span class="math">\varepsilon</span> is again the price difference between the external price and the threshold price, in this case, <span class="math">\frac{P_0}{1-\gamma}</span>. In short, the LVR of CPMM grows faster than that of FM-AMM as <span class="math">\varepsilon</span> (the price difference) and <span class="math">L\sqrt{P_0}</span> (the initial pool size) grow. From this, we can predict that the performance of FM-AMM will be better in larger pools compared to CPMM.</p>
<p>FM-AMM performance is affected by the transaction cost <span class="math">c</span>, while CPMM is not affected as long as the arbitrageur’s profit is greater than <span class="math">c</span>. This implies that FM-AMM suits well with rollup settings that have longer block times (resulting in higher volatility between blocks) and low transaction costs.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-5-simulations-12" name="h-5-simulations-12"></a>5. Simulations</h1>
<p>Due to the nonzero transaction cost, finding an analytic solution for instantaneous LVR or the stationary distribution of price discrepancy is no longer straightforward. Therefore, we proceed with numerical simulations. You can check the code used <a href="https://github.com/kosunghun317/FMAMM_LVR/tree/main/notebooks" rel="noopener nofollow ugc">here</a>. This code is largely copy-pasted with minor tweaks from <a href="https://github.com/alexnezlobin/simulations/tree/main" rel="noopener nofollow ugc">this source</a>. Swap fees are fixed at 0.3% across all simulations (i.e., <span class="math">\gamma_\text{FMAMM} = 0.0015</span>, <span class="math">\gamma_\text{CPMM} = 0.003</span>).</p>
<h2><a class="anchor" href="https://ethresear.ch#h-51-distribution-of-lvr-13" name="h-51-distribution-of-lvr-13"></a>5.1. Distribution of LVR</h2>
<p>In this section, we observe the distribution of LVR under several cases without iterating over many parameters. Note that the variance is always greater in FM-AMM; this is because the price is not corrected perfectly under the nonzero transaction cost condition.</p>
<p>The conditions of the first case are L1 (12-second block time), $10 transaction cost, with 5% daily volatility and $100M pool size.<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/1/0/101edc5f8de31543cda7c084f2d7e98e3e522ebf.png" width="604" /></p>
<p>The second is L1, $10 transaction cost, with 10% volatility and $100M pool size.<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/a/4/a49fb0096777435725991cf46954abd43c9a26a8.png" width="597" /><br />
As predicted, FM-AMM outperforms CPMM as volatility increases.</p>
<p>Next one is L1 with congestion; transaction cost went up to $30.<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/f/3/f3a2fc79c45044e5ef9c61b01a5ae50b913299d7.png" width="597" /><br />
This fits to our prediction well, too. As tx cost increases FM-AMM loses more than CPMM.</p>
<p>The last result is L1 with congestion, but with smaller liquidity ($10M).<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/f/8/f82923769edf0a3f8df22d9c2327ee0473eae369.png" width="597" /><br />
This result is a bit contradictory to our initial guess: usually, smaller liquidity conditions are more favorable to CPMM, as LVR per pool value of FM-AMM increases as the pool value gets smaller. To clarify this, we will run simulations over various parameters and compare the performances.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-52-performance-comparisons-14" name="h-52-performance-comparisons-14"></a>5.2. Performance Comparisons</h2>
<p>Below are the numerical simulations of LVR for CPMM and FM-AMM under various parameters. Swap fees are set at 0.3% for both of them. Blue regions indicate where CPMM performs better, while grey regions indicate where FM-AMM performs better. Note that the results in the low volatility and high-cost regions are not as reliable due to the very few trades occurring in these conditions.</p>
<p>First is the cases for L1:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/f/3f4b7c4f8afa28b742eb494cce687ca245b9ded3.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/3/f/3f4b7c4f8afa28b742eb494cce687ca245b9ded3_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/c/2c339052835747c3057c1c6d6b4456033db13814.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/2/c/2c339052835747c3057c1c6d6b4456033db13814_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/1/21678b78eb6b694ff0938209d8de97d84a713df9.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/2/1/21678b78eb6b694ff0938209d8de97d84a713df9_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/b/7b8453c6492353e30665d40174ad349c53cc73da.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/7/b/7b8453c6492353e30665d40174ad349c53cc73da_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/a/ba04ccc1440d5207217bb4056c6d9cc2e2d03291.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/b/a/ba04ccc1440d5207217bb4056c6d9cc2e2d03291_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/f/cf2266ce32541a90a009ee96c05f24714ebf7da6.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/c/f/cf2266ce32541a90a009ee96c05f24714ebf7da6_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/a/daec56f47b5ff0e9cfe26e087f4588f0ce99ebe5.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/d/a/daec56f47b5ff0e9cfe26e087f4588f0ce99ebe5_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f7211259a315e71a052cac3a52055de1eabbda8.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f7211259a315e71a052cac3a52055de1eabbda8_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc23d7506e2cc23e5b29ae96faee7ed609588d70.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc23d7506e2cc23e5b29ae96faee7ed609588d70_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/2/a2153b4ce8fb4ee42360ccff33df0b311aa457e4.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/a/2/a2153b4ce8fb4ee42360ccff33df0b311aa457e4_2_690x196.png" width="690" /></a></div><p></p>
<p>Following are the special cases for based rollup (tx cost = $0.05, block time = 12 sec) and typical L2s (tx cost = 0.01, block time = 2 sec), respectively:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e463cf577f86a2492c5fb4e0f15d30284212bf6d.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e463cf577f86a2492c5fb4e0f15d30284212bf6d_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/55c066b2d8b4c15d67d1eb5eb9ad1008d4840ecd.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/55c066b2d8b4c15d67d1eb5eb9ad1008d4840ecd_2_690x196.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#h-53-discussion-15" name="h-53-discussion-15"></a>5.3. Discussion</h2>
<p>It is clear that FM-AMM performs better under certain conditions, including L2s and L1 with low transaction costs, and this partially explains why the results in [CF23] was rather mixed and defer by each pair. Due to its nature of forcing competition over price between arbitrageurs, it performs well even in high volatility conditions. Notably, this is achieved without raising the swap fee, which typically results in losing retail order flow. Thus, FM-AMM can lose less to arbitrageurs while not sacrificing retail order flow.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-6-conclusion-16" name="h-6-conclusion-16"></a>6. Conclusion</h1>
<p>As the authors of [CF23] claimed, FM-AMM indeed achieves superior performance under certain conditions, even without raising swap fees. It suits L2s particularly well. However, our analysis is based on several non-realistic assumptions, especially the (short-term) censorship resistance assumption and simultaneous bid submission. Future research will focus on more relaxed conditions to provide a more comprehensive evaluation.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-7-references-17" name="h-7-references-17"></a>7. References</h1>
<p>[MMRZ22] J. Milionis, C. C. Moallemi, T. Roughgarden, and A. L. Zhang. Automated Market Making and Loss-Versus-Rebalancing, <em>arXiv preprint <a href="https://arxiv.org/abs/2208.06046" rel="noopener nofollow ugc">arXiv:2208.06046</a></em>, 2022.<br />
[MMR23] J. Milionis, C. C. Moallemi, and T. Roughgarden. Automated Market Making and Arbitrage Profits in the Presence of Fees, <em>arXiv preprint <a href="https://arxiv.org/abs/2305.14604" rel="noopener nofollow ugc">arXiv:2305.14604</a></em>, 2023.<br />
[GGMR22] G. Ramseyer, M. Goyal, A. Goel, and D. Mazières. Augmenting Batch Exchanges with Constant Function Market Makers, <em>arXiv preprint <a href="https://arxiv.org/abs/2210.04929" rel="noopener nofollow ugc">arXiv:2210.04929</a></em>, 2022.<br />
[CF23] A. Canidio and A. Fritsch. Arbitrageurs’ profits, LVR, and sandwich attacks: batch trading as an AMM design response, <em>arXiv preprint <a href="https://arxiv.org/abs/2307.02074" rel="noopener nofollow ugc">arXiv:2307.02074</a></em>, 2023.<br />
[CM24] D. Crapis and J. Ma. The Cost of Permissionless Liquidity Provision in Automated Market Makers, <em>arXiv preprint <a href="https://arxiv.org/abs/2402.18256" rel="noopener nofollow ugc">arXiv:2402.18256</a></em>, 2024.<br />
[N22] A. Nezlobin. Ethereum Block Times, MEV, and LP returns, <em>Medium article <a href="https://medium.com/@alexnezlobin/ethereum-block-times-mev-and-lp-returns-5c13dc99e80" rel="noopener nofollow ugc">Ethereum Block Times, MEV, and LP returns</a></em>, 2022<br />
[E24] A. Elsts. CEX/DEX arbitrage, transaction fees, block times, and LP profits, <em>Ethresearch Forum article <a href="https://ethresear.ch/t/cex-dex-arbitrage-transaction-fees-block-times-and-lp-profits/19444">CEX/DEX arbitrage, transaction fees, block times, and LP profits</a></em>, 2024</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/notes-on-the-lvr-of-fm-amm/20151">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 26 Jul 2024 06:21:02 +0000</pubDate>
</item>
<item>
<title>A design for APS-burn in the context of a Decentralized L2</title>
<link>https://ethresear.ch/t/a-design-for-aps-burn-in-the-context-of-a-decentralized-l2/20146</link>
<guid>https://ethresear.ch/t/a-design-for-aps-burn-in-the-context-of-a-decentralized-l2/20146</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#aps-burn-in-the-context-of-a-decentralized-l2-1" name="aps-burn-in-the-context-of-a-decentralized-l2-1"></a>APS-burn in the context of a Decentralized L2</h1>
<h1><a class="anchor" href="https://ethresear.ch#overview-2" name="overview-2"></a>Overview</h1>
<p>We propose a design for Attester-Proposer-Separation that is tailored for the context of a decentralized L2. This design is intended to operate in the context of an L2 with its own validator set, running some sort of BFT consensus protocol, with single slot finality.</p>
<p>This design is based on the <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">APS-burn design</a> from <a class="mention" href="https://ethresear.ch/u/barnabe">@barnabe</a>, but with some notable differences. It assumes that there are short block times, preferably one second, and no longer than 2 seconds, and that each block is final within the scope of the canonical L2 chain (prior to being finalized on L1) . This design aims to obtain the benefits of APS in an L2 context, while aiming to mitigate censorship, and mitigate the negative externalities of multi-block MEV. These properties are achieved using a sealed-bid auction, similar in principle to the <a href="https://ethresear.ch/t/sealed-execution-auction/20060">Sealed execution auction</a> proposal from Anders, but in an L2 context.</p>
<p>To understand the motivation behind this design, as well as its trade-offs, see the “benefits” and “risks” sections below.</p>
<p>DO NOT read this post if:</p>
<ul>
<li>You are trying to keep up with the important developments in Ethereum and attempting to determine which posts are important and which aren’t. This post is intended for soliciting early feedback on a design that is specific to decentralized rollups, and is not a finalized proposal.</li>
</ul>
<p>DO read this post if:</p>
<ul>
<li>You are trying to decentralize a rollup, and are considering adopting an PoS consensus protocol, and are interested in exploring ideas within the design space.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#related-reading-3" name="related-reading-3"></a>Related Reading</h1>
<ul>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">More pictures about proposers and builders - Barnabé Monnot</a></li>
<li><a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Censorship Resistance in On-Chain Auctions - Elijah Fox, Mallesh Pai, Max Resnick</a></li>
<li><a href="https://ethresear.ch/t/sealed-execution-auction/20060">Sealed execution auction - Anders Elowsson</a></li>
<li><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms - Mike Neuder</a></li>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">Block vs. Slot Auction PBS - Julian Ma<br />
</a></li>
</ul>
<p>MEV Burn related reading:</p>
<ul>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV burn—a simple design</a></li>
<li><a href="https://ethresear.ch/t/the-price-is-right-realigning-proposer-builder-incentives-with-predictive-mev-burn/18656">The price is right: Realigning proposer-builder incentives with predictive MEV-burn</a></li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">Dr. changestuff or: how i learned to stop worrying and love mev-burn</a></li>
<li><a href="https://ethresear.ch/t/in-a-post-mev-burn-world-some-simulations-and-stats/17092">In a post MEV-Burn world - Some simulations and stats</a></li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#description-4" name="description-4"></a>Description</h1>
<p>We propose a method whereby the right to propose a future block is obtained via an on-chain auction.</p>
<p>For every slot <span class="math">n</span>, the auction for block proposal rights starts at slot <span class="math">n - t</span> and runs for <span class="math">k</span> slots. The auction closes at slot <span class="math">(n - t) + k</span>. During the period between <span class="math">n - t</span> and <span class="math">(n - t) + k</span>, bids are submitted to an on-chain smart contract. Each bid specifies an amount of some defined token that will be burned as part of the block that will be proposed at slot <span class="math">n</span>. The winning bid is the bid that burns the most tokens.</p>
<p>During the auction between slot <span class="math">n - t</span> and <span class="math">(n - t) + k</span>, bids are posted on-chain as sealed commitments. After the auction closes at slot <span class="math">k</span>, there is a buffer period of <span class="math">b</span> blocks in which no new bids are accepted by the smart contract for slot <span class="math">n</span>. After this buffer period, and up to slot <span class="math">n</span>, bidders post their opened commitments, which reveal the amount they are bidding. The block that is proposed to the network at slot <span class="math">n</span>, must be from the same address specified in the highest bid in the auction for slot <span class="math">n</span>, and also burn the amount of tokens specified in the bid.</p>
<p>Each bid is composed of the height of the slot being bidded on, the address that will propose the block, and an amount of MEV that will be burned in the block.</p>
<h3><a class="anchor" href="https://ethresear.ch#mitigating-multi-block-mev-5" name="mitigating-multi-block-mev-5"></a>Mitigating multi-block MEV</h3>
<p>By incorporating a sealed bid auction, we can mitigate concerns around multi-block MEV. One of the main concerns with various APS designs is that it allows bidders to bid on block proposal rights for a contiguous segment of slots. If a bidder knows that they have the rights to slot <span class="math">n</span>, then they can bid higher than anyone else for slot <span class="math">n+1</span>, because they know that they can employ lucrative multi-block MEV strategies such as censoring price oracle updates or censoring sell orders on a trading pair to drive up the price etc.</p>
<p>In order to mitigate this concern, it is imperative that the bidders have no guarantee of having won the auction for slot <span class="math">n</span> while the auction for slot <span class="math">n+1</span> is open.</p>
<p>As an illustrative example, consider the following instantiation where bidders bid for the right to propose a block 12 slots in the future <span class="math">(t = 12)</span>, and they have 4 slots in which to submit bids <span class="math">(k = 4)</span>, followed by a buffer phase in which the on-chain auction will not accept bids <span class="math">(b = 2)</span> followed by the reveal phase.</p>
<p>As you can see from the following visualization, is we assume that all bids for the slot <span class="math">n</span> auction are revealed at slot <span class="math">(n - t) + k + b</span> then the bidder for slot <span class="math">n</span> only finds out that they have won block proposal rights for slot <span class="math">n</span> after the auction for slot <span class="math">n+1</span> and slot <span class="math">n+2</span> have already closed.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/12de37869ca318f21a59cb84c3ddab8f309c90ee.png" title="L2_APS-burn"><img alt="L2_APS-burn" height="280" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/12de37869ca318f21a59cb84c3ddab8f309c90ee_2_690x280.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#censorship-6" name="censorship-6"></a>Censorship</h3>
<p>Censorship is a concern with any on-chain auction (ref: <a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Censorship Resistance in On-Chain Auctions</a>). Obviously block builders are highly incentivized to censor any transactions to the on-chain auction that that carry bids that aren’t their own, which means that the only bids that will make it to the on-chain contract are from block builders that already have proposal rights to slots, as these builders will likely only include their own transactions to the auction contract.</p>
<p>The only way to fully mitigate censorship is through some form of <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">inclusion lists</a>, or a design that facilitates <a href="https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777">multiple concurrent block proposers</a>. We propose that this sort of mechanism is an integral part of this design, but the exact details of the mechanism employed are out of scope for this piece.</p>
<p>However, even without an inclusion list / MCP mechanism, censorship of auction transactions becomes prohibitively expensive quite quickly. This is because every transaction that is censored has associated transaction fees that can be collected by some other block builder, which they can use to increase their bids with. The censoring block builder will therefore incur a competitive disadvantage for every bid they censor. Moreover, the censoring block builder will incur the cost of each bid they censor for every block they propose, resulting in a linear increase in cost over time. In other words, If <span class="math">n</span> blocks are proposed, and <span class="math">k</span> transactions are censored per block, the total cost incurred by the censoring block builder becomes:</p>
<p><span class="math">CoC=n\times\sum_{i=1}^{k}C_{i}</span></p>
<h3><a class="anchor" href="https://ethresear.ch#collateralization-and-penalties-7" name="collateralization-and-penalties-7"></a>Collateralization and Penalties</h3>
<p>This design requires that bidders are collateralized in order to submit bids, and that this collateral is slashed under certain circumstances:</p>
<ul>
<li>If bid commitments are not revealed, this can incur penalties. The reason for this is to prevent bidders from submitting multiple bids and then just revealing them conditionally based on what other bidders reveal (as detailed in <a href="https://arxiv.org/pdf/2301.12532" rel="noopener nofollow ugc">this paper</a> - h/t <a class="mention" href="https://ethresear.ch/u/quintuskilbourn">@quintuskilbourn</a> for this). Obviously censorship resistance is important in order to prevent these penalties from being used for griefing attacks.</li>
<li>If the winner of an auction for slot <span class="math">n</span>, does not propose a block for slot <span class="math">n</span>, they are slashed.</li>
<li>If the winner of an auction for slot <span class="math">n</span>, equivocates and proposes more than one block for slot <span class="math">n</span>, they are slashed.</li>
<li>If the proposed block is valid, and is from the auction winner, but does not burn the amount of MEV that was stipulated in the winning bid, the collateral is slashed.</li>
</ul>
<p>There are two ways to approach collateralization:</p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-per-bidder-collateralization-8" name="h-1-per-bidder-collateralization-8"></a>1 | Per-Bidder-Collateralization</h4>
<p>This requires that a block builders / bidders posts some collateral on-chain, and that this will be subject to slashing conditions. Once the collateral is posted, the bidder can participate in any number of auctions and submit any number of bids. The collateral can be withdrawn at any stage, but is subject to some defined delay period.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-2-per-bid-bonding-9" name="h-2-per-bid-bonding-9"></a>2 | Per-Bid-Bonding</h4>
<p>Bidders do not need to be collateralized, but each individual bid will require a bond. In the case of the winning bid, the bond is returned when the block for the slot is delivered. In the case of not winning the bid, the bond is returned only if the bid commitment was revealed.</p>
<p>As a side note: per-bid-bonding can also potentially be used to prevent bids being revealed earlier through some side-channel, by allowing anyone to cancel their bid before the auction closes and withdraw their bond if they reveal the pre-image. Once the auction is closed, then only the original bidder can withdraw the bond.</p>
<p>There are subtle trade-offs between the two approaches:</p>
<ul>
<li>
<p>Per-bid-bonding could potentially be more centralizing, as it favors better capitalized bidders. With a slot <span class="math">n+t</span> auction with a per-bid bond of <span class="math">S</span>, then bidders will need <span class="math">t \times S</span> to participate in every auction.</p>
</li>
<li>
<p>On the other hand, this potentially improves censorship resistance to a degree, as the same bidder can bid from different addresses, reducing the scope for targeted censorship of specific rival block builders.</p>
</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#preventing-bids-from-being-revealed-early-10" name="preventing-bids-from-being-revealed-early-10"></a>Preventing bids from being revealed early</h3>
<p>It’s not entirely clear what the incentives would be for bidders to reveal their bids early, but the effect of revealing bids early will undermine the value of a sealed-bid auction, and will allow for multi-block MEV strategies to be employed. We can imagine a scenario whereby somebody constructs a mechanism employing ZKPs to allow bidders to reveal their bids, in order to understand if their bid is lower than another bid, which would give them the option to bid higher. This could be a useful tool for participants in the auction.</p>
<p>To mitigate against the risks of bidders revealing their bids early, it should be impossible, or very hard, to prove what the bid was. There are a number of ways of accomplishing this:</p>
<h4><a class="anchor" href="https://ethresear.ch#using-threshold-encryption-11" name="using-threshold-encryption-11"></a>Using threshold encryption</h4>
<p>The validators will use distributed-key-generation (DKG) to create a threshold encryption key, which is part of the headers for every block. The BFT round leader will also be responsible for collecting the keys from validators, posting the encryption key, and also gossipping the decryption key at the right time, so that it can also be included in the block headers. This will allow bidders to encrypt their bids when they are posted on-chain. It will also allow them to decrypt their bids locally to ascertain if they have won the block proposal rights for slot <span class="math">n</span>. At this stage it should be deterministically known to all parties who have won the slot <span class="math">n</span> auction.</p>
<p>Upon receiving a new block for slot <span class="math">n</span>, validators will examine the amount of MEV burned in the block as well as the address of the proposer. They will take these two pieces of data and encrypt them using the threshold encryption key for the auction for slot <span class="math">n</span>. If there is a bid that exactly matches the ciphertext, and that bid is from the proposer that is proposing the block, and is correctly collateralized, and most importantly, if there is no higher bid in the auction, then that block is accepted. This construction can be strengthened by imposing slashing conditions on entities that propose blocks that do not have a winning bid associated with it.</p>
<p>The benefit of this approach is that it precludes any possibility of revealing bids early, assuming an honest majority of validators. However, it does add some extra complexity to the consensus layer, as well as the overhead of establishing clear and reliable public transmission of threshold encryption keys.</p>
<h4><a class="anchor" href="https://ethresear.ch#using-a-verifiable-delay-function-12" name="using-a-verifiable-delay-function-12"></a>Using a Verifiable Delay Function</h4>
<p>In order to reveal a commitment, the smart contract must verify an accompanying Verifiable Delay Function (VDF) proof. The VDF ensures that any bid must take at least <span class="math">d</span> seconds to produce a proof for. While there is nothing to stop bidders revealing their bids, it makes it difficult for bidders to prove what they bid, as the proof will take approximately <span class="math">d</span> seconds to produce.</p>
<p>There are multiple VDF schemes that can be employed. Such a scheme was proposed by Nomadic Labs (see <a href="https://eprint.iacr.org/2023/977.pdf" rel="noopener nofollow ugc">Timed Commitments Revisited</a>).</p>
<p>Note that in this scheme, the commit binding is deterministic, so not completely resilient to revealing bids. In the specific scheme, if the bidder shares the values used to generate the commitment (i.e., <span class="math">G</span>, <span class="math">g</span>, <span class="math">e</span>, <span class="math">k</span>, and <span class="math">ct</span>), others can reproduce the commitment <span class="math">\psi</span>, thereby revealing the bid. Further work is needed to understand the complexity involved in doing this in a ZKP, in order to understand whether the complexity is sufficient to discourage revealing of bids. If needed, we would change the scheme to use a key derivation function that is suboptimal for use within zk circuits, resulting in inefficient proof generation, and therefore a similar level of effort required to create the actual VDF proof.</p>
<p>Note that while it is possible to just use VDFs by themselves without the complexity of a commit-reveal scheme, this has the drawback of allowing bidders to produce multiple VDFs concurrently in order to retain the option of conditional bidding.</p>
<h1><a class="anchor" href="https://ethresear.ch#risks-concerns-13" name="risks-concerns-13"></a>Risks / Concerns</h1>
<h4><a class="anchor" href="https://ethresear.ch#reduced-competitiveness-in-bidding-14" name="reduced-competitiveness-in-bidding-14"></a>Reduced Competitiveness in Bidding</h4>
<p>Bids are a bet on averages, this can potentially have more centralizing effects than a JIT block auction, because it precludes any opportunistic MEV strategies that capitalize on MEV spikes, which could prevent block builders that exist on these strategies from participating. Also, because it is a bet on averages, the system may favor the most well capitalized block builders.</p>
<p>Also, because we are using a sealed-bid auction, participants are not bidding in response to each other’s bids. This removes the natural competitiveness that drives up prices, and so the overall level of bidding is likely to be somewhat lower.</p>
<h4><a class="anchor" href="https://ethresear.ch#l2-reorg-resistance-15" name="l2-reorg-resistance-15"></a>L2 reorg resistance</h4>
<p>This design assumes a BFT consensus protocol with single-slot-finality, wherein reorgs do not occur in the normal case. If reorgs are a concern, one can adapt the above design to include a second buffer phase at the end of the reveal phase but before slot <span class="math">n</span>. This would force any incentivized reorg to be at least as deep as the size of the second buffer phase, making it much more expensive, and so disincentivizing malicious reorgs.</p>
<h1><a class="anchor" href="https://ethresear.ch#benefits-16" name="benefits-16"></a>Benefits</h1>
<h4><a class="anchor" href="https://ethresear.ch#the-benefit-of-aps-is-that-there-is-no-longer-a-requirement-for-mev-boost-relays-17" name="the-benefit-of-aps-is-that-there-is-no-longer-a-requirement-for-mev-boost-relays-17"></a>The benefit of APS is that there is no longer a requirement for mev-boost relays</h4>
<p>The reason is that there is no negotiation between proposers and relayers (in terms of the proposer being the BFT round leader, who proposes blocks to the validator set). In the mev-boost scenario, the relayers are required in order to give some assurance to the builder that the proposer will not unbundle their block and steal the MEV, and also to give assurance to the proposer that the builder will in fact release the block on time, and not cause the proposer to get slashed. This is necessary to maintain PBS (unless ePBS is implemented), without which searcher bots will engage in PGAs which will cause significant and adverse network congestion.</p>
<h4><a class="anchor" href="https://ethresear.ch#it-reduces-the-centralizing-effects-of-mev-on-the-validator-set-18" name="it-reduces-the-centralizing-effects-of-mev-on-the-validator-set-18"></a>It reduces the centralizing effects of MEV on the validator set</h4>
<p>While mev-boost already does this in terms of democratizing access to MEV, there are still some centralizing effects from having MEV flowing to validators. For example, co-locating validator nodes close to relays means that validators can benefit from reduced latency and the higher bids that emerge in the final milliseconds of the slot. This latency advantage has compelling economies of scale for larger staking pools, which drives both economic and geographic centralization.</p>
<h4><a class="anchor" href="https://ethresear.ch#strengthens-pos-tokenomic-design-19" name="strengthens-pos-tokenomic-design-19"></a>Strengthens PoS tokenomic design</h4>
<p>For L2s that maintain their own gas token, APS simplifies the modeling of token rewards and penalties with regards to the validator set. This is because MEV no longer flows to the validators, which makes the validator risk/reward profile more deterministic and easier to reason about. Validators will just receive rewards as designed by the protocol and nothing more, which makes it easier to design PoS tokenomics. APS-burn also acts as a natural token sink, strengthening the tokenomics by having a deflationary effect on the token itself.</p>
<hr />
<h1><a class="anchor" href="https://ethresear.ch#future-work-20" name="future-work-20"></a>Future Work</h1>
<p>As well as soliciting early feedback and peer review, we plan to work on determining how best to model this design so that we can understand the trade-offs in the design choices such as threshold encryption or VDFs, parameterization of the on-chain auction, per-bidder-collateralization or per-bid-bonding, and to understand the extent to which we can confidently predict the behavior of participants.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/a-design-for-aps-burn-in-the-context-of-a-decentralized-l2/20146">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 25 Jul 2024 10:16:16 +0000</pubDate>
</item>
<item>
<title>The case for decentralization increasing efficiency is overstated</title>
<link>https://ethresear.ch/t/the-case-for-decentralization-increasing-efficiency-is-overstated/20140</link>
<guid>https://ethresear.ch/t/the-case-for-decentralization-increasing-efficiency-is-overstated/20140</guid>
<content:encoded><![CDATA[
<p>Block-building on Ethereum has become quite centralized. 90% of blocks are auctioned off through MEV-Boost. Numerous solutions have been proposed, including anonymous inclusion lists and execution tickets. People are concerned about this, both for essentially ideological reasons, and for reasons of efficiency. Blockchains have an ethos of being open to all people, whether or not that is maximally efficient. There is a tradeoff between efficiency (in the sense of getting each block built in the most efficient way, by the most efficient builders) and “fairness”, or including all transactions, if people’s use of the chain is unaffected by the degree of centralization. If blockchain users are concerned their transactions will eventually be sanctioned and rendered worthless, they may avoid that blockchain, or avoid cryptocurrencies altogether. Thus, seemingly inefficient decentralization may be optimal for the blockchain as a whole, and would be unanimously preferred by all blockbuilders to the present equilibrium.</p>
<p>I am concerned, however, that the efficiency case is overstated. Imagine there is a firm so efficient at MEV extraction that they build all of the blocks on chain. If them doing so would cause people to leave the blockchain altogether, then they are incentivized to not bid on some blocks at all.</p>
<p>In “<a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>”, Neuder, Garavmidi, and Roughgarden propose execution-tickets as a mechanism for distributing block-building rights, using a proportional all-pay auction. Bidders buy lottery tickets for the right to build a block. In the example given, they have two buyers, buyer 1 with value 4, and buyer 2 with value 2. Under a perfectly efficient system, buyer one always gets the block, at price 2+epsilon. Under their all-pay system, buyer 1 bids 8/9th and buyer 2 bids 4/9th, with them receiving the block rights 2/3rds and 1/3rd of the time, respectively.</p>
<p>Under the description of the example, however, this necessarily <em>cannot</em> improve efficiency. If excessive centralization would scare away some users from using the chain at all, the winning monopolist is incentivized to give away some of the block. The value of efficiency is already reflected in their valuations. If you assume that their valuation is always higher, then you are assuming that there is no efficiency case whatsoever. You only have an ideological case, which is fine on its own terms — but you should not mix and match arguments which overstate your case. Note too that we are only caring about one side of the ledger, those who want their transactions to be included. Mightn’t it be possible that some people are repulsed by crypto’s shady reputation?</p>
<p>Nor should this necessarily apply in cases of monopolistic competition. To simply not bid is not the only way to redistribute blocks. If it were the case, the main block-builders would indeed be stuck in a prisoner’s dilemma — they could choose not to bid, but they would have to all do it. If, however, the winners hold another auction for the block, with some of the fairness raising characteristics as before, they can decentralize to the extent which is optimal for them.The drawback is that now the builders internalize a smaller portion of the gains. There is a free-rider problem with decentralization. However, as the market becomes more decentralized, doubtless people will be less concerned about censorship.</p>
<p>The efficiency argument for decentralization therefore much smaller than it would appear. There should probably be a split between allocatively efficient auctions for blocks, and allocatively fair but inefficient markets. What is the right split between the two? It is highly unlikely that it is optimal to only sell blocks in one way all the time.</p>
<p>I think that this is an ideal question for a prediction market. The right amount of decentralization is a macro question. You’re not going to be able to A/B test it in a couple days. Your choices are trying to influence people’s choice in the long run, and answer the question: what is the long run amount of decentralization that maximizes the amount of capital put on the chain. Is there any better use of prediction markets than this? I am somewhat agnostic to the exact method of determining the split — and have no opinions whatsoever as to the proper proportion.</p>
<p><em>This post was first posted on my blog <a href="https://nicholasdecker.substack.com/p/the-case-for-blockchain-decentralization" rel="noopener nofollow ugc">here</a>. Thank you for reading this, please tell me if you disagree.</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/the-case-for-decentralization-increasing-efficiency-is-overstated/20140">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 24 Jul 2024 18:48:55 +0000</pubDate>
</item>
<item>
<title>Builder Bidding Behaviors in ePBS</title>
<link>https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129</link>
<guid>https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129</guid>
<content:encoded><![CDATA[
<p>Special thanks to <a class="mention" href="https://ethresear.ch/u/soispoke">@soispoke</a> for the review</p>
<h1><a class="anchor" href="https://ethresear.ch#background-1" name="background-1"></a>Background</h1>
<p>Builder bidding strategies in the MEV-Boost world have been studied extensively over some time. Numerous <a href="https://arxiv.org/html/2312.14510v3" rel="noopener nofollow ugc">excellent resources</a>, <a href="https://arxiv.org/abs/2407.13931" rel="noopener nofollow ugc">literature</a>, <a href="https://ethresear.ch/t/game-theoretic-model-for-MEV-Boost-auctions-mma/16206">game-theoretic models</a>, and <a href="https://collective.flashbots.net/t/MEV-Boost-builder-bids-archive/3561" rel="noopener nofollow ugc">archives</a> capture the current builder bidding behaviors on how to win block building right for an Ethereum slot. Today, builder bidding war for MEV-Boost is a complex interplay between latencies, relays, and strategy effectiveness. In this post, we argue that builder bidding strategies become simpler in ePBS world and we highlight the key differences in how bidding strategies change under the new ePBS market space rules, strategy limitations, and reduced latency benefits in ePBS.</p>
<h1><a class="anchor" href="https://ethresear.ch#market-spaces-2" name="market-spaces-2"></a>Market Spaces</h1>
<p>Here, we summarize three types of market spaces. The first one is MEV-Boost. The second and third ones are ePBS. MEV-Boost is push + pull based market space, meaning the builders push the bids to the relays, and the proposer pulls the bids from the relays. ePBS contains two types of market spaces: the P2P Bid Gossip Netwok, which is push-based, and the Builder RPC Endpoint, which is pull-based.</p>
<ul>
<li><strong>MEV-Boost market space</strong>
<ul>
<li><strong>Push + pull-based</strong>: The builders push bids to the relay, and the proposer pulls the bids from the relay.</li>
</ul>
</li>
<li><strong>ePBS market spaces</strong>
<ul>
<li><strong>P2P market space</strong>
<ul>
<li><strong>Push-based</strong>. The builder pushes the bid to the p2p network.</li>
</ul>
</li>
<li><strong>Builder RPC market space</strong>
<ul>
<li><strong>Pull-based</strong>. The proposer pulls the bids from the builder RPC end points.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We define the following market space characteristics given how the consensus <a href="https://github.com/ethereum/consensus-specs/pull/3828" rel="noopener nofollow ugc">spec</a> is written today. Builder-API is still <strong>TBD</strong> for ePBS.</p>
<h2><a class="anchor" href="https://ethresear.ch#mev-boost-market-space-3" name="mev-boost-market-space-3"></a>MEV-Boost Market Space</h2>
<ul>
<li><strong>Open auction</strong>: Builders that subscribe to the relay’s feed can see the every builder’s latest bid.</li>
<li><strong>Continuous auction</strong>: Builders can bid multiple times and cancel previous bids.</li>
<li><strong>Auction termination</strong>: The auction terminates when the proposer calls <code>getHeader</code> and when the relay returns the header to the proposer to sign. The relay may delay the header response for a timing game. This means the relayer has the final control over when the auction terminates.</li>
<li><strong>Profit sharing</strong>: Some relays take the difference between the winning bid and the second-highest bid received from builders. This difference goes to the relay, with a portion potentially refunded to the builder. This transforms the auction dynamic into a second-price auction. However, not all relays adopt this approach, and complete trust in the relay is mandatory.</li>
<li>We assume the market space doesn’t verify block contents from the builder, hence it is an <a href="https://github.com/michaelneuder/optimistic-relay-documentation/blob/4fb032e92080383b7b5d8af5675ef2bf9855adc3/towards-ePBS.md" rel="noopener nofollow ugc"><strong>optimistic market space</strong></a>. The only delay is when the builder sends the block to the relay.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#epbs-p2p-market-space-4" name="epbs-p2p-market-space-4"></a>ePBS P2P Market Space</h2>
<ul>
<li><strong>Open auction</strong>: Anyone can subscribe and listen to the P2P network for gossiped builder bids.</li>
<li><strong>Single bid auction</strong>: To prevent DOS attacks on the P2P network, the current spec only allows builders to submit a single bid and above a certain minimum value. Any subsequent bid will be dropped by the nodes. There is no cancellation support over the P2P network.</li>
<li><strong>Auction termination</strong>: The auction terminates when the proposer proposes the block which includes the builder’s bid. The proposer could play a timing game here and has the final control over when the auction terminates.</li>
<li><strong>Profit sharing</strong>: The bid specifies the value, and the proposer gets the full value on the consensus layer as long as the consensus block that includes the bid remains canonical. There’s no profit sharing with 3rd parties.</li>
<li>The market space is still <strong>optimistic</strong> and doesn’t need to verify the execution contents at inclusion time. If the execution block later becomes invalid or fails to reveal, the proposer still gets unconditional payment. The only delay here is the builder sending the bid to the P2P network. This delay is argubly <strong>longer</strong> than using a relay in MEV-Boost market space.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#epbs-builder-rpc-market-space-5" name="epbs-builder-rpc-market-space-5"></a>ePBS Builder RPC Market Space</h2>
<p>Note: The <a href="https://github.com/ethereum/builder-specs" rel="noopener nofollow ugc">Builder API</a> is undefined at this moment. This section is based on what we think the ePBS Builder API might look like, but it’s highly subjective to change and open for feedback. Below outlines one version of Builder API which we have been thinking.</p>
<ul>
<li><strong>Private auction</strong>: Only the proposer can request a bid from the builder. The proposer will sign the <code>getHeader</code> request using the builder’s public key. The builder’s bid remains private until requested by the proposer. Builders can’t sniff other builders’ bids unless the builder API allows this or the builder voluntarily opens their bids to the public.</li>
<li><strong>Single</strong> (maybe multiple?) <strong>bid auction</strong>: Builders allow proposers to request a bid once, and any subsequent requests will result in an error. Builders may also allow proposers to request bids multiple times without error; this specific detail is undefined, and it’s unclear what the Nash outcome is here. If builders allow multiple requests, then the builder must ensure previous bids are canceled.</li>
<li><strong>Auction termination</strong>: The auction terminates when the proposer requests the header and the proposer receives the header. The builder can play a timing game, but this may backfire and lead to the proposer using another builder’s bid. Builder timing game will not work here, but proposer timing games are still relevant.</li>
<li><strong>Profit sharing</strong>: Same as the P2P market space.</li>
<li>The market space is still <strong>optimistic</strong>, and the delay here is the builder returning the bid to the proposer. This delay is shorter than the P2P market space and likely the same as MEV-Boost if the builder is well co-located.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#builder-bidding-profiles-under-epbs-6" name="builder-bidding-profiles-under-epbs-6"></a>Builder Bidding Profiles under ePBS</h1>
<p>In the <a href="https://arxiv.org/abs/2312.14510" rel="noopener nofollow ugc">Strategic Bidding Wars in On-chain Auctions</a>, four profiles of builder behavior are listed in MEV-Boost auction:</p>
<ul>
<li><strong>Naive Behavior</strong>: Aggressively updates bids based on their valuation as long as the aggregated signal surpasses their profit margin.</li>
<li><strong>Adaptive Behavior</strong>: Monitors the current highest bid and places a bid if able to outbid by a small constant. Defaults to the naive strategy if unable to outbid.</li>
<li><strong>Last Minute Behavior</strong>: Reveals valuation at the final possible moment before auction termination to minimize the reaction window for other players.</li>
<li><strong>Bluff Behavior</strong>: Initially places high bids (bluff) and later reverts to actual valuation, leveraging bid cancellation to compel other players to disclose their valuations.</li>
</ul>
<p>Given the new market space in ePBS, we will examine which strategies are viable under the auction rules.</p>
<h3><a class="anchor" href="https://ethresear.ch#p2p-market-space-7" name="p2p-market-space-7"></a>P2P Market Space</h3>
<ul>
<li><strong>Naive, Adaptive, and Bluff Behaviors</strong>: These strategies are harder to execute since bids can only be sent once. The builder might use different staked addresses, each sending one bid. However, this requires staking on the consensus layer for each address, assuming payment is handled on the consensus layer. Additionally, bluffing is not possible because bids cannot be canceled.</li>
<li><strong>Last Minute Behavior</strong>: This is the <strong>only</strong> possible strategy. Builders will reveal their valuation at the final moment before auction termination to minimize the reaction window for other players.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#builder-rpc-market-space-8" name="builder-rpc-market-space-8"></a>Builder RPC Market Space</h3>
<ul>
<li><strong>Naive, Adaptive, Bluff, and Last Minute Behavior</strong>: For similar reasons to the P2P market space, these strategies are not possible. Additionally, the auction is private, meaning builders cannot see each other’s bids. Most importantly, the auction has shifted from push-based to pull-based, so the builder no longer has control over when to submit bids. The only way for builders to get their bids to the proposer is through the proposer’s request.</li>
</ul>
<p>We conclude that builders’ bidding strategies are heavily limited under ePBS. For P2P, only last-minute bidding is possible. For Builder RPC, builders can only respond to the proposer as it is a pull-based model.</p>
<h1><a class="anchor" href="https://ethresear.ch#market-space-considerations-9" name="market-space-considerations-9"></a>Market Space Considerations</h1>
<p>We add a few more concerns in this section that was emphasized in the MEV-Boost market space but may no longer be relevant in ePBS market space.</p>
<h2><a class="anchor" href="https://ethresear.ch#latency-and-dos-concerns-10" name="latency-and-dos-concerns-10"></a>Latency and DOS Concerns</h2>
<p>Different market spaces impose varying latency constraints. In the P2P market space, builders push bids to the proposers, and the market operates as a large P2P gossip network constrained by anti-DOS measures. With 1 million validators, the worst-case scenario could mean 1 million bids. Due to these concerns, rules like disallowing multiple bids and ensuring bids are above certain values are necessary. The P2P network is inherently slow, so we don’t foresee serious bidders using it to win bids. However, the P2P market space is valuable for maintaining a good <strong>baseline for competitive bids</strong> that isn’t latency-sensitive. If builders using RPC collude to drive bid prices low, an <strong>altruistic builder</strong> over P2P can ensure the bid value baseline remains healthy and competitive with minimal effort. The baseline P2P bid value may also be used for burning in future iterations, as it only requires a 1/n honest assumption.</p>
<p>In the builder RPC market space, which is pull-based, latency matters significantly. Instead of two latencies (global and individual) defined in the MEV-Boost market space, there’s only one individual delay to consider: how fast the builder can return the bids to the proposer. Delaying the return of <code>getHeader</code> may result in proposer missing builder’s bid.</p>
<h2><a class="anchor" href="https://ethresear.ch#auction-interval-uncertainty-11" name="auction-interval-uncertainty-11"></a>Auction Interval Uncertainty</h2>
<p>The auction interval uncertainty becomes clearer in ePBS because MEV-Boost middleware and relays no longer control the timing of when the block gets returned to the proposer or released to the network. The proposer either uses the pushed bids from the P2P network or pulls bids from the builders RPC. The proposer has the final say on the auction interval cut-off. From the builder RPC market space perspective, it will keep updating its bids until the proposer requests them.</p>
<h3><a class="anchor" href="https://ethresear.ch#new-bluff-behavior-under-epbs-12" name="new-bluff-behavior-under-epbs-12"></a>New: Bluff Behavior under ePBS</h3>
<p>In ePBS, proposers or builders may attempt to bluff other builders. This may not be scalable given the nature of the single bid auction over P2P and the fact that every builder is a validator and needs to have a stake on the beacon chain. One bluff strategy is for the proposer of next slot to reveal a high value P2P bid, intentionally stating that this is the bid it will include for the next slot unless others can beat it. This helps set the base price and forces everyone else to beat it. However, the proposer doesn’t have to include its bid.</p>
<p>Although it’s obvious that anyone can see that the bid comes from the proposer and just ignore it, the proposer may use sybil validators to perform the same bluff. However, it’s still unclear how scalable this strategy is, given that one bid equals one validator.</p>
<h1><a class="anchor" href="https://ethresear.ch#open-questions-13" name="open-questions-13"></a>Open questions</h1>
<p>The current ePBS market space design and requirements leave some open questions. We will summarize the open questions here for feedback:</p>
<ul>
<li>
<p><strong>P2P Market Space Conditions</strong>:</p>
<ul>
<li>Every builder can only submit one bid, and the subsequent bids get dropped. Are there any advantages to allowing multiple bids here? If yes, then how many?</li>
<li>Every builder’s bid needs to be above a certain value to deter DOS attacks. What should the value be?
<ul>
<li>We can look at current or past empirical data here.</li>
</ul>
</li>
<li>There’s a tradeoff between the number of bids allowed and the minimal values. If we set the values high, we may allow multiple bids.</li>
<li>Is there a strong argument for requiring bid cancellation?</li>
</ul>
</li>
<li>
<p><strong>Builder RPC Market Space’s Builder API Interface</strong>:</p>
<ul>
<li>What does the Builder API interface look like?
<ul>
<li>We want to leverage the existing Builder API and aim for minimal changes.</li>
<li>When the proposer makes a header request to the builder, what should the request look like? Can we use the current get header request with a signature, or should we modify it?</li>
<li>Do we allow multiple getHeader requests, such as continuous polling from the proposer, or do we enforce a common standard?</li>
</ul>
</li>
<li>What kind of auction is most ideal?
<ul>
<li>Sealed second-price auction may be most ideal.</li>
<li>How to design this over Builder API?</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Comparing MEV-Boost Market Space to ePBS Market Space</strong>:</p>
<ul>
<li>Do we lose anything in the ePBS market space that is important to maintain from the MEV-Boost market space?</li>
</ul>
</li>
<li>
<p><strong>Implications of staking pools also bidding:</strong></p>
<ul>
<li>Pools that hold a significant chunk of validators could be in a privileged position for submitting bids and manipulating the market extensively compared to a builder that doesn’t hold as many keys.
<ul>
<li>Is there an advantage to this asymmetry?</li>
<li>Will we see staking pools and builders teaming up, and how will this dynamic play out?</li>
</ul>
</li>
</ul>
</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 23 Jul 2024 13:44:07 +0000</pubDate>
</item>
<item>
<title>Enabling standardized on chain executions through modular accounts</title>
<link>https://ethresear.ch/t/enabling-standardized-on-chain-executions-through-modular-accounts/20127</link>
<guid>https://ethresear.ch/t/enabling-standardized-on-chain-executions-through-modular-accounts/20127</guid>
<content:encoded><![CDATA[
<div> 关键词：标准化执行、Modular Accounts、Verifiable Credentials (VCs)、Zero-Knowledge Proofs (ZKPs)、Validation Module

总结:<br />
这篇文章讨论了通过Modular Accounts实现区块链上标准执行的过程。它提出了一种框架，结合ERC 7579提案，将用户身份验证和交易授权分离，使用zk证明验证VC以确保操作的合法性和隐私。该系统利用智能合约、账户抽象和接口检测来提升安全性、隐私和用户体验。文章列举了几个关键应用领域，如DeFi、DAOs和供应链管理，以展示这种标准化执行的价值。未来，文章还关注了账户灵活性和安全性的增强，如P-256椭圆曲线签名验证、Keystore合同和passkeys在提高用户体验中的作用。整体而言，这个框架旨在为大规模企业服务提供一个安全、合规和高效的区块链执行环境。 <div>
<p><strong>Enabling standardized on chain executions through Modular Accounts</strong></p>
<p><strong>Introduction</strong></p>
<p>This blogpost is intended to be an extension from a previous work “ <a href="https://ethresear.ch/t/self-sovereign-identity-and-account-abstraction-for-privacy-preserving-cross-chain-user-operations-across-roll-ups/19599">Self-sovereign identity and account abstraction for privacy preserving cross chain user operations across roll ups</a> ” with the intent of proposing a system implementation of network features. In the previous work I tried to envision a system combining a three-layered architecture that I will briefly summarize here:</p>
<ol>
<li>An application layer comprises wallets and other service apps to facilitate the generation and management of Verifiable Credentials, set a permission logic for compiling user operation objects through apps.</li>
<li>A network layer based on different L2s, which include a Keystore contract and Smart Contract Accounts. This layer is responsible for generating Zero-Knowledge Proofs (ZKPs) and Merkle proofs for Sequencers. The Keystore contract manages encryption keys and user authentication, ensuring the correct key pairing for Verifiable Credentials and Operations. Smart Contract Accounts verify user operations, by validating ZK cryptographic proofs to ensure the integrity of the signatures of the transactions before they are executed.</li>
<li>A sequencing layer which interconnects L2s with Ethereum main-net and manages the execution of batches of transactions anchoring Roll-up IDs to sequencing networks batching, validation cross chain atomic transactions via the Keystore roll-up, and the Roll-up contract within Ethereum’s slots.</li>
</ol>
<p>Today, I am trying to focus on some elements on the 1 and 2 layer, sitting in the conjunction between External Owned Accounts and Contract Accounts trying to envision an implementation pathway for the adoption of standardized on chain execution.</p>
<p><strong>The concept</strong></p>
<p>To facilitate the adoption of blockchain based services globally there is a need for standardizing secure, privacy and regulatory-compliant on chain executions to scale. As we move towards a more decentralized future, ensuring cyber security, data minimization from origination to processing, and improving UX in executing on chain operations is crucial.</p>
<p>This blog post introduces a framework based on the ERC 7579 proposal, which integrates a module to lavage onchain verifiable credentials and zero-knowledge (zk) proofs in the context of modular smart accounts. This framework aims to standardize onchain executions by separating user authentication and transaction authorization while preserving privacy and regulatory requirements throughout the transaction lifecycle.</p>
<p>The core function of the system described involves validating zk proofs generated by VCs to authenticate users and authorize operations. This makes the Validation Module the most appropriate choice, as it is designed to validate user operations before they are executed.</p>
<p>The Validation Module allows for checking the validity and authenticity of zk proofs, ensuring that only legitimate user operations are processed.</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/c/1c3ddecf471befecea0769a9e94397e93d1a0bb7.png" title=""><img alt="" height="153" src="https://ethresear.ch/uploads/default/optimized/3X/1/c/1c3ddecf471befecea0769a9e94397e93d1a0bb7_2_455x153.png" width="455" /></a></div><p></p>
<p>For reference, the framework considers a minimal set of ERC for implementation:</p>
<ul>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-7579#modules">ERC 7579</a> - Minimal Modular Smart Accounts: to set a module to validate user operations by verifying ZK proofs derived from verifiable credentials (VCs) ensuring that user operations are authenticated and authorized before execution.</p>
</li>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-1271">ERC 1271</a> - Standard Signature Validation Method for Contracts: to standardize how smart contracts validate signatures, defining the function to verify the validity of a signature, crucial for transaction authorization.</p>
</li>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-4337">ERC 4337</a> - Account Abstraction Using Alt Mempool: to abstract account management and operations, enabling more complex and user-friendly interactions allowing smart contract accounts to handle user operations and transaction executions.</p>
</li>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-165">ERC 165</a> - Standard Interface Detection: to allow contracts to declare support for certain interfaces and enabling smart contracts to query and interact with other contracts that implement specific interfaces.</p>
</li>
</ul>
<p><strong>High-level process flow</strong></p>
<p>The framework leverages the strengths of different proposals to create a robust, secure, and privacy-preserving onchain execution environment.</p>
<p>I list here a high-level overview:</p>
<ol>
<li>Users issue on chain merklized Verifiable Credentials (VCs) through a contract identifier operated by an issuer. These credentials are stored in the user’s identity wallet (EOA)</li>
<li>Users generate and validate ZK proofs derived from their VCs through a contract verifier to access service apps and compile User Operation objects.</li>
<li>Smart Contract Account entry point perform canonical verification loop according ERC 4337.</li>
<li>The validation module verifies the zk proofs against the VCs in the execution loop and upon successful validation, the module calls the isValidSignature function as defined by ERC 1271 to authorize entry point to executeUserOps.</li>
<li>Smart contract Account entry point executes onchain operations and distributes the fees to the Bundler address.</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/0/8054bf5b0b25390eb19a159f9c698f66c091eb2f.jpeg" title=""><img alt="" height="237" src="https://ethresear.ch/uploads/default/optimized/3X/8/0/8054bf5b0b25390eb19a159f9c698f66c091eb2f_2_643x237.jpeg" width="643" /></a></div><p></p>
<p><strong>Market &amp; Business Considerations</strong></p>
<p>This framework offers significant value for large-scale enterprise services requiring validation logic before authorizing onchain operations. By integrating SSI and zk proofs, enterprises can ensure privacy and regulatory compliance while enhancing security and efficiency. The separation of authentication and authorization further strengthens the system’s robustness.</p>
<p>Here a short list of valuable use cases that would fit nicely with this logic:</p>
<ol>
<li><strong>Trading</strong>: A DeFi platform allows users to interact with various financial services such as lending, borrowing, and trading. The platform issues VCs containing user identity and KYC information. Whenever a user wants to execute a financial transaction, they submit a zk proofs on VC and compile user operations objects along as operation request. The Validation Module verifies the zk proof against the stored VC and upon successful verification, the entry point is executing the operations on chain.</li>
<li><strong>DAOs</strong>: a decentralized voting system allows DAO members to vote for grants allocation privacy preserving and reducing conflict of interest. Voters authenticate themselves using VCs and zk proofs to cast their votes and upon the voting completion the entry point executes grants allocations on chain according to the voting results.</li>
<li><strong>Supply chain</strong>: a management system tracks the manufacturing and logistics of goods, participants in the supply chain authenticate using VCs and zk proofs to update and access the status of goods up to the distributor and at the moment of the sale the entry point execute onchain rewards, or payment premiums, to the different members.</li>
</ol>
<p><strong>Conclusion &amp; further thoughts</strong></p>
<p>When we look forward to what kind of functionalities we would like to have as user for the future I believe there has been a big trend in providing standardization through native abstraction, modularity, and functional collaboration between EOAs and SCAs. Considering the future road map of Ethereum in Pectra, <a href="https://github.com/ethereum/EIPs/blob/master/EIPS/eip-7702.md">EIP 7702</a> sets the way for a new transaction type which enables account properties of both externally owned accounts (EOAs) and Smart Contract Accounts (SCAs). Furthering looking ahead, there is a way to set “native account abstraction” by <a href="https://github.com/ethereum/RIPs/blob/master/RIPS/rip-7560.md">RIP 7560</a> and <a href="https://eips.ethereum.org/EIPS/eip-7562">ERC 7562</a> which align with ERC 4337 rules at least on validation rules.</p>
<p>A side of this is also important <a href="https://eips.ethereum.org/EIPS/eip-7212">EIP 7212</a> proposes a precompiled contract to perform signature verifications using the secp256r1 elliptic curve. This curve, also known as P-256, is widely supported in modern devices like Apple’s Secure Enclave, Webauthn, and Android Keychain, and Passkeys. This would allows more efficient and flexible management of accounts by transaction signs in mobile devices. Both EIP 7702 and EIP 7212 are potentially taking place in Pectra.</p>
<p>Network harmonization is a key capability of every growing community, in this context personally I see value in further exploring the use of keystore contracts, session keys and passkeys as additional features to provide security, flexibility and usability to the product experience.</p>
<p>Passkeys can be used to authenticate users providing a smoother UX while combining strong user authentication. Session keys can improve security of communication at application level, meaning when users are interacting with dapps for using market services, and keystore contract could represent an reliable solution for setting a functional framework for operating key sessions.</p>
<p>The shared focus on improving account flexibility and security through different methods highlights the committment of the community’s to address scalability, usability, and security concerns within the Ethereum network. In this setting collaboration between EOAs and SCAs, and additional features as passkeys keystore contracts can live in a modular setting where specific modules enforce optional rules for executions, and different cryptographic tecniques could ensure data minimization for controllers and processors.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/enabling-standardized-on-chain-executions-through-modular-accounts/20127">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 22 Jul 2024 12:43:52 +0000</pubDate>
</item>
<item>
<title>Diseconomies of Scale: Anti-Correlation Penalties (EIP-7716)</title>
<link>https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114</link>
<guid>https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114</guid>
<content:encoded><![CDATA[
<div> 关键词：Diseconomies of Scale、Anti-Correlation Penalties、EIP-7716、Proposer Timing Games、Centralization

总结:
这篇文章讨论了以太坊共识机制中的中心化问题，尤其是经济规模效应导致的不平衡和集中风险。EIP-7716提案旨在通过实施反相关惩罚来抵消这些影响，通过调整奖励和罚款，鼓励小型和分散的参与者，同时抑制大型运营商可能滥用的优势。反相关惩罚会根据验证者之间行为的相关性动态调整，例如对源投票错误的惩罚会根据网络中未参与或错误投票的总余额来调整。文章还提到，虽然惩罚可能会对单个验证者造成短期影响，但长期来看，它有利于提高网络的抗风险能力并促进去中心化。 <div>
<h1><a class="anchor" href="https://ethresear.ch#diseconomies-of-scale-anti-correlation-penalties-eip-7716-1" name="diseconomies-of-scale-anti-correlation-penalties-eip-7716-1"></a>Diseconomies of Scale: Anti-Correlation Penalties (EIP-7716)</h1>
<blockquote>
<p>Special thanks to <a href="https://x.com/dapplion">DappLion</a> and <a href="https://x.com/VitalikButerin">Vitalik</a> for their collaborative effort on the overall concept, and <a href="https://x.com/weboftrees">Anders</a> and <a href="https://x.com/_julianma">Julian</a> for their valuable feedback on this post!</p>
</blockquote>
<p>Ethereum relies on a decentralized set of validators to ensure properties like credible neutrality and censorship resistance. Validators <a href="https://ethereum.org/en/staking/">stake</a> a certain amount of ETH to participate in Ethereum’s consensus and secure the network. In return, validators receive rewards directly from the protocol (<a href="https://ethresear.ch/t/faq-ethereum-issuance-reduction/19675">#issuance</a>) as well as execution layer rewards when proposing a block, which include transaction fees and <a href="https://ethereum.org/en/developers/docs/mev/">MEV</a> from the blocks they propose (<a href="https://boost.flashbots.net/">#mevboost</a>). As of today, thousands, if not tens of thousands, of small-sized entities run validators from their homes despite several disadvantages. These include the risk and responsibility of operating and maintaining a node, the technical burden associated with setup and upkeep, potential downtime, and the lack of a liquid staking token that would otherwise provide flexibility and liquidity.</p>
<p>With the ongoing maturation of Ethereum’s PoS, we’ve encountered various <strong>centralizing forces</strong> inherent to the current protocol:</p>
<ul>
<li><strong>EL Reward Variance</strong>: While attestation rewards are distributed fairly evenly, the rewards for proposing a block can vary significantly. This variation arises because <a href="https://ethereum.org/en/developers/docs/mev/">MEV</a> is extremely spiky, resulting in a few outlier blocks with proposer profits exceeding 10 ETH. Large operators running many validators have better chances of capturing these “juicy” blocks. Although over many years the earnings of individual validators should average out, the future remains uncertain. Assuming 1 million validators and 2,628,000 slots per year, the probability of being selected as a proposer is ~0.0001%. On average, a validator can expect to propose <span class="math">\frac{1,000,000}{365.25 \times 7200} = 2.628</span> blocks per year (there are 7200 slots per day). From April 2023 to April 2024, the percentage of blocks with more than 10 ETH was 0.004041%. Statistically, a single validator will eventually propose a block with more than 10 ETH of MEV, but it’s unknown whether this will happen this year or in ten years, and by then, MEV issues might be resolved. While solo stakers literally participate in a lottery, large operators can average their profits and plan for the future with greater certainty.<br />
Over 1 year, the probability of a random validator getting at least one block with &gt;10 ETH profits is 0.1%:</li>
</ul>
<div class="math">
P(\text{at least one 10} \, \text{ETH} \, \text{block}) = 1 - (1 - 0.0004041)^n = 1 - (1 - 0.0004041)^{2.628}
</div>
<p>If you control 1% of all validators (~10k validators), the probability of getting at least one block with more than 10 ETH of MEV climbs to approximately 99.99% over one year.</p>
<p>The following chart shows the <strong>cumulative sum of MEV-Boost payments</strong> on the y-axis and the <strong>cumulative number of MEV-Boost payments</strong> on the x-axis. We can see that 90% of all blocks distribute around 44% of the total value, leaving 56% to be distributed to the lucky 10% of proposers.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/e/aed0a28f0f91206549c0993488907698504ef2dc.png" title="Bk31ssG_R.png"><img height="428" src="https://ethresear.ch/uploads/default/optimized/3X/a/e/aed0a28f0f91206549c0993488907698504ef2dc_2_600x428.png" width="600" /></a></div>
<p></p>
</div>
<ul>
<li>
<p><strong>Reorgs</strong>: “<em><a href="https://ethresear.ch/t/change-fork-choice-rule-to-mitigate-balancing-and-reorging-attacks/11127">Honest reorgs</a></em>” occur when the proposer of slot <span class="math">n_{1}</span> orphans the block of the proposer of slot <span class="math">n_{0}</span> because that block hasn’t received at least 40% of the slot’s committee members’ votes. By using <a href="https://notes.ethereum.org/@casparschwa/H1T0k7b85">proposer boost</a>, these “<em>weak</em>” blocks (those with less than 40% attestations) can be reorged by the next proposer to penalize the previous proposer for poor performance, such as being late and therefore rugging some attesters for their correct head votes. Reorgs can have centralizing forces and the more stake an entity holds, the more strategically it can decide whether to reorg a particular block. Large-scale operators have more safety because they can ensure their own validators never vote to reorg their own blocks. Essentially, all nodes of an entity can coordinate to always vote for the current slot’s block rather than its parent if the current block comes from that entity. This coordination potentially allows large entities to risk broadcasting their block later in the slot while still having a high probability of the block becoming canonical. <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Analysis has shown</a> that <strong>by second 4</strong> of the slot, <strong>40% of all attestations</strong> for that slot <strong>have been seen</strong>. A large operator, who controls many validators and knows that these validators will never vote to reorganize its blocks, can slightly delay block propagation without significantly increasing its risk. The same principle applies when a single entity owns consecutive slots. In theory, this entity could wait until the end of the slot (or even longer) before publishing its block. Then, it could use the next slot to solidify that weak block into the chain by leveraging proposer boost.</p>
</li>
<li>
<p><strong>Proposer Timing Games</strong>: <a href="https://timing.pics/">Proposer timing games</a> (also see <a href="https://eprint.iacr.org/2023/760">[1]</a>, <a href="https://arxiv.org/abs/2305.09032">[2]</a>) is a term that summarizes a strategy applied by some block proposers in which they delay their proposal to give the builder more time for extracting MEV. This leads to increased profits for the proposer but <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">evidently</a> comes with a negative impact on other proposers and especially attesters. Proposer timing games are risky because late blocks have an increased chance of being reorged. In general, large-size operators face lower risks when playing timing games than small-size entities. This stems from the fact that larger operators are on average more sophisticated and have better connectivity in the P2P network: What might be a late block for an Australian validator (go <a href="https://x.com/sassal0x">sassal</a> <img alt=":crown:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/crown.png?v=12" title=":crown:" width="20" />) might be just in time for a US-based Coinbase validator. Thus, the lower the latency, the more a validator can risk delaying.</p>
</li>
</ul>
<div class="math">
\textbf{The above symptoms are all exacerbated by one thing, namely...}
</div>
<div class="math">
\underline{\mathbf{economies\ of\ scale.}}
</div>
<p><a href="https://en.wikipedia.org/wiki/Economies_of_scale">Economies of scale</a> are nothing new and the crypto landscape isn’t immune either. Looking at Wikipedia, it is defined as “<em>the cost advantages that enterprises obtain due to their scale of operation […]</em>”, and the same applies to Ethereum staking:</p>
<div align="center">
  <div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e548616102366792be17847ac823b351c9f94170.png" title="ryZMFz-_R.png"><img height="359" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e548616102366792be17847ac823b351c9f94170_2_400x359.png" width="400" /></a></div>
</div>
<p>Large operators like Coinbase, Kraken, or Kiln can leverage economies of scale to make staking even more profitable. This allows them to offer rewards competitive with those of solo stakers, even after taking their cut. To illustrate this, consider a simple example (the exact numbers are not important here):</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Entity</th>
<th>Validators on one Node</th>
<th>Hardware Costs</th>
<th>Other Costs</th>
<th>Total Cost ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Solo Staker</td>
<td>1 validator</td>
<td>1 Intel NUC ($ 1,200)</td>
<td>$ 5,000</td>
<td>$ 6,200</td>
</tr>
<tr>
<td>Coinbase</td>
<td>1,000 validators</td>
<td>1 Intel NUC ($ 1,200)</td>
<td>$ 50,000</td>
<td>$ 51,200</td>
</tr>
</tbody>
</table>
</div><blockquote>
<p>For more realistic numbers, refer to the latest EthStaker survey published <a href="https://paragraph.xyz/@ethstaker/staking-survey-2024">here</a>. By allocating 10x as much in <em>Other Costs</em> for large operators, we account for the increased complexity of setting up multiple validators on one machine. This is realistic enough for the point we’re making here.</p>
</blockquote>
<p>We can see the effects of economies of scale: the machine used by Coinbase will generate 1,000 times the profits compared to solo stakers, while the costs are only eight times higher. As a result, the ROI for large-scale operators is significantly better.</p>
<p>Using one hardware device for multiple validators is just one piece of the puzzle. Others include:</p>
<ul>
<li>Cloud service provider</li>
<li>ISPs</li>
<li>Geographical locations</li>
<li>Maintenance responsibilities</li>
<li>Client software</li>
<li>And many more…</li>
</ul>
<p>In all these categories, the goal is maximum diversity to minimize the risk of external factors degrading or damaging the network. Despite this goal, economically rational players might prefer a one-stop-shop solution, such as running a Lighthouse + Geth node on a Google/AWS/Hetzner instance located in central Europe, maintained by a dedicated team of specialists. While this setup may perform well in terms of efficiency, Ethereum should not create incentives that further exacerbate centralization.</p>
<div align="center">
<p>
  <img height="392" src="https://ethresear.ch/uploads/default/original/3X/b/a/bac447c3b4a914807987ea637a010bceb40febef.png" width="400" />
</p>
</div>
<p><strong>But who is large-scale and whose not?</strong></p>
<p>The protocol itself does not know which validator is operated by which entity. From the protocol’s perspective, a Coinbase validator looks the same as a solo staker. Therefore, to prevent correlations from emerging, we cannot simply scale rewards and penalties based on the market share of the entity behind a validator. For more on this topic, I recommend Barnabé’s post, <em><a href="https://barnabe.substack.com/p/seeing-like-a-protocol">“Seeing Like a Protocol”</a></em>.</p>
<p>Fortunately, <strong>economies of scale inherently come with correlations</strong>, which is something the protocol can be made aware of. Leveraging economies of scale may linearly scale with correlations, thus we can implement rules to dynamically scale economic incentives and steer the validator set toward diversification.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/9/697934a0c70e654fbc603e570f422269f8116551.png" title="BJbZ1XWuR.png"><img height="358" src="https://ethresear.ch/uploads/default/optimized/3X/6/9/697934a0c70e654fbc603e570f422269f8116551_2_400x358.png" width="400" /></a></div>
<p></p>
</div>
<p>Penalizing correlated faults isn’t something new to Ethereum. In the current <a href="https://eth2book.info/capella/part2/incentives/slashing/">slashing</a> mechanism, a “malicious” validator is initially penalized by a reduction of 1/32 of their effective balance when they are slashed. After being halfway through the withdrawal period, they are subject to an additional penalty (the <em><a href="https://eth2book.info/capella/part2/incentives/slashing/">correlation penalty</a></em>) that scales with the number of validators (specifically their stake) who were slashed around the same time (+/- 18 days). Therefore, a solo staker accidentally voting for two different head blocks, which is a slashable offense, would lose significantly less than a party with a 20% market share (assuming all 20% collectively fail).</p>
<p>In the end, the goal must be to incentivize validators to diversify their setup. As shown in the following example, we want validators to reduce their correlation with other validators, making the whole network more robust against external influences.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/7/678299142da4a042b47e07270b8ccfc7c644e393.png" title="ry5bkuMO0.png"><img height="229" src="https://ethresear.ch/uploads/default/optimized/3X/6/7/678299142da4a042b47e07270b8ccfc7c644e393_2_690x229.png" width="690" /></a></div>
<p></p>
</div>
<h2><a class="anchor" href="https://ethresear.ch#eip-7716-2" name="eip-7716-2"></a>EIP-7716</h2>
<p>The goal of “<a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716: Anti-Correlation Attestation Penalties</a>” is to get us closer to diseconomies of scale. The more homogeneous an entity’s staking setup, the more it should be penalized while non-correlated setups profit from the proposed changes.</p>
<p>With anti-correlation penalties, the previous “<em>economies of scale vs number of validators</em>” might be more like the following:</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/0/e0a2bcab530fcb98384c27b1765434ef0121fdd3.png" title="S179FsfOA.png"><img height="359" src="https://ethresear.ch/uploads/default/optimized/3X/e/0/e0a2bcab530fcb98384c27b1765434ef0121fdd3_2_400x359.png" width="400" /></a></div>
<p></p>
</div>
<p>Anti-correlation penalties were first described by Vitalik in an <a href="https://ethresear.ch/t/supporting-decentralized-staking-through-more-anti-correlation-incentives/19116">ethresearch post</a>. After some <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">initial analyses</a> and a more <a href="https://ethresear.ch/t/a-concrete-proposal-for-correlated-attester-penalties/19341">concrete proposal</a> available, the <a href="https://eips.ethereum.org/EIPS/eip-7716">EIP</a> is now at the point where everyone is invited to look into the inner workings of correlated penalties and leave feedback.</p>
<p>In short, the EIP proposes to multiply the missed (source) vote penalty by a penalty factor that ranges from 0 to 4 but equals 1 on average <em>(notably, this is important to not touch the issuance policy)</em>.</p>
<h4><a class="anchor" href="https://ethresear.ch#how-does-7716-work-3" name="how-does-7716-work-3"></a>How does 7716 work?</h4>
<div class="md-table">
<table>
<thead>
<tr>
<th>Variable</th>
<th>Symbol</th>
<th>Description</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>penalty_factor</code></td>
<td><span class="math">p</span></td>
<td>Penalty scaling factor</td>
<td>dynamic</td>
</tr>
<tr>
<td><code>net_excess_penalties</code></td>
<td><span class="math">p_{exc}</span></td>
<td>Net excess penalties</td>
<td>dynamic</td>
</tr>
<tr>
<td><code>non_participating_balance</code></td>
<td><span class="math">balance_{non\_attesting}</span></td>
<td>Sum balance of not/wrong attesting validators</td>
<td>dynamic</td>
</tr>
<tr>
<td><code>PENALTY_ADJUSTMENT_FACTOR</code></td>
<td><span class="math">p_{adjustment}</span></td>
<td>Penalty adjustment factor</td>
<td>2**12</td>
</tr>
<tr>
<td><code>MAX_PENALTY_FACTOR</code></td>
<td><span class="math">p_{max}</span></td>
<td>Maximum penalty factor</td>
<td>4</td>
</tr>
<tr>
<td><code>EXCESS_PENALTY_RECOVERY_RATE</code></td>
<td><span class="math">p_{recovery}</span></td>
<td>Rate by which the excess penalty decreases</td>
<td>1</td>
</tr>
</tbody>
</table>
</div><blockquote>
<p>The final values for the constants are still to be decided.</p>
</blockquote>
<p>The penalty factor <span class="math">p</span> scales the slot penalties to a maximum of <code>MAX_PENALTY_FACTOR</code>, or down. It’s determined the following:</p>
<div class="math">
p = \min\left(\frac{balance_{non\_attesting}\ \times\ p_{adjustment}}{\max(p_{excess},\ 0.5)\times\ balance_{total}\ +\ 1},\ p_{max} \right)
</div>
<p>and from the <a href="https://github.com/ethereum/consensus-specs/blob/816d338bd09ffc8e83097c4db1764ba834f3adca/specs/_features/correlated_penalties/beacon_chain.md">pyspec implementation</a>; h/t <a href="https://x.com/dapplion">dapplion</a>:</p>
<pre><code class="lang-python">penalty_factor = min(
    ((total_balance - participating_balance) * PENALTY_ADJUSTMENT_FACTOR) // 
    (max(self.net_excess_penalties, 0.5) * total_balance + 1),
    MAX_PENALTY_FACTOR
)
</code></pre>
<p>The formula calculates the penalty factor as a ratio of the “penalty weight” of non-attesting validators to the net excess penalty scaled by the balance of all validators. A higher penalty adjustment factor increases the sensitivity of the penalty factor. Conversely, a higher net excess penalty leads to a lower penalty factor.</p>
<p>Finally, this is how the <code>penalty_factor</code> variable would be used:</p>
<pre><code class="lang-auto">def get_flag_index_deltas(state: BeaconState, flag_index: int) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:
    """
    Return the deltas for a given ``flag_index`` by scanning through the participation flags.
    """
    ...
    for index in get_eligible_validator_indices(state):
        base_reward = get_base_reward(state, index)
        if index in unslashed_participating_indices:
            if not is_in_inactivity_leak(state):
                reward_numerator = base_reward * weight * unslashed_participating_increments
                rewards[index] += Gwei(reward_numerator // (active_increments * WEIGHT_DENOMINATOR))
        elif flag_index != TIMELY_SOURCE_FLAG_INDEX:
            # [New in correlated_penalties]
            slot = committee_slot_of_validator(state, index, previous_epoch)
            penalty_factor = compute_penalty_factor(state, slot) 
            penalties[index] += Gwei(penalty_factor * base_reward * weight // WEIGHT_DENOMINATOR)
    return rewards, penalties
</code></pre>
<p>We check if we are dealing with source votes (line 12), derive the slot in which the validator was supposed to vote (line 14), compute the penalty factor (line 15), and multiply it by the base reward (line 16).</p>
<blockquote>
<p>Although source votes might be a good starting point, the concept can be equally appied to head and target votes.</p>
</blockquote>
<p>The <span class="math">p_{exc}</span> is updated at the end of each slot using:</p>
<div class="math">
p_{exc} = \max(p_{recovery},\ p_{exc} + p) - p_{recovery}
</div>
<p>Which equals to:</p>
<pre><code class="lang-python">net_excess_penalties = max(
        EXCESS_PENALTY_RECOVERY_RATE, 
        net_excess_penalties + penalty_factor
    ) - EXCESS_PENALTY_RECOVERY_RATE
</code></pre>
<p>We can observe the following dynamics:</p>
<ul>
<li>If the balance of non-attesting validators increases, the penalty factor also increases.</li>
<li>If the balance of non-attesting validators remains the same, the penalty factor approaches 1.</li>
<li>If the balance of non-attesting validators decreases, the penalty factor can go below 1 for a while and then approach 1 afterward.</li>
</ul>
<p>When the <code>non_participating_balance</code> continuously increases for several rounds, the <code>penalty_factor</code> and the <code>net_excess_penalties</code> also increase. This continues until the <code>non_participating_balance</code> stops increasing. Then, the <code>net_excess_penalties</code> and the <code>penalty_factor</code> start decreasing together.</p>
<p>With the <code>net_excess_penalties</code> keeping track of the excess penalties of past epochs, the formula can self-regulate what constitutes a “large” number of misses and what does not.</p>
<p>This mechanism ensures that the sum of penalties doesn’t change with this EIP—only the distribution does.</p>
<h2><a class="anchor" href="https://ethresear.ch#some-faqs-4" name="some-faqs-4"></a>Some FAQs</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-1-wouldnt-that-be-even-worse-for-solo-stakers-5" name="h-1-wouldnt-that-be-even-worse-for-solo-stakers-5"></a>1. Wouldn’t that be even worse for solo stakers?</h3>
<p>No. Solo stakers, commonly referred to as small-scale operators or individuals running 1-10 validators from home, are expected to behave in a very uncorrelated manner compared to larger operators. Although factors like geographical location and client software can impact correlations, solo stakers are likely to be offline at different times than large-scale operators such as Coinbase or Kraken. As a result, the penalties solo stakers receive are smaller than those in the current system. In contrast, if a large-scale operator’s staking setup has a bug causing all their validators to fail to attest, the correlation is clear and the penalties are higher.</p>
<p>This expectation was first confirmed in an <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">initial analysis</a> on anti-correlation penalties, which showed that solo stakers and Rocketpool operators would have been better off, while large-scale operators would have received higher penalties on average.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-wouldnt-that-discourage-people-from-using-minority-clients-6" name="h-2-wouldnt-that-discourage-people-from-using-minority-clients-6"></a>2. Wouldn’t that discourage people from using minority clients?</h3>
<p>No. The opposite is the case, as using the majority client leads to even greater correlations. For example, if the Lighthouse client has a bug that causes attesters to vote for the wrong source, then the correlation is super high, and so is the penalty. On the other hand, all Lodestar attesters failing is regarded as a much smaller collective fault. In the case of minority clients being expected to have more bugs, then this would also balance out better because if it’s only a small minority, then the correlation penalty is more forgiving than if it had been some majority client.</p>
<p>No. In fact, it encourages using minority clients. Using the majority clients leads to higher correlations. For example, if the Lighthouse client has a bug causing attesters to vote for the wrong source, the correlation is high and the penalty increases. Conversely, if all Lodestar attesters fail, it is considered a much smaller collective fault. The correlation penalty is more forgiving to a small minority than to a majority client. So, even if minority clients are expected to have more bugs, correlation penalties can steer validators toward using them.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-why-would-it-benefit-decentralization-7" name="h-3-why-would-it-benefit-decentralization-7"></a>3. Why would it benefit decentralization?</h3>
<p>Anti-correlation penalties effectively differentiate between small and large operators without relying on validators that have consolidated their stake or other out-of-protocol solutions. By introducing economic incentives for diversified behavior, we benefit small players who are already “anti-correlated” while encouraging large players to reduce the impact of external factors such as one-node setups, or cloud providers on their staking operations.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-4-wouldnt-that-just-lead-to-big-parties-investing-in-increased-fault-tolerance-while-even-increasing-the-correlations-8" name="h-4-wouldnt-that-just-lead-to-big-parties-investing-in-increased-fault-tolerance-while-even-increasing-the-correlations-8"></a>4. Wouldn’t that just lead to big parties investing in increased fault tolerance while even increasing the correlations?</h3>
<p>If big parties invest in increased fault tolerance, it’s still beneficial. Enhancing fault tolerance is difficult and expensive. At some point, it becomes cheaper to invest in anti-correlation than in further fault tolerance improvements. While large operators might have to move validators from popular cloud platforms to different environments, solo stakers running their nodes from home can continue as they are. Anything that costs large operators money but is free for solo stakers (=diseconomies of scale) fosters decentralization.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/5/25f018bc53924b32c0a7c1deb29b0a0f3075daf1.jpeg" title="HyW84oMdA.jpg"><img height="216" src="https://ethresear.ch/uploads/default/optimized/3X/2/5/25f018bc53924b32c0a7c1deb29b0a0f3075daf1_2_690x216.jpeg" width="690" /></a></div>
<p></p>
</div>
<p>The main argument is, that no matter how big operators react, either going for anti-correlation or, doing the opposite, putting all validators on a single extremely robust node, both cost money and reduce their APY. As fault tolerance has its limits, there is no escape from harsher penalties other than diversifying.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/2/72c96a75749cc73c7789fac6f4fd97834924d1d5.png" title="BJL374W_0.png"><img height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/2/72c96a75749cc73c7789fac6f4fd97834924d1d5_2_328x500.png" width="328" /></a></div>
<p></p>
</div>
<h3><a class="anchor" href="https://ethresear.ch#h-5-this-sounds-super-dangerous-as-i-could-be-penalized-for-32-eth-just-by-missing-a-single-source-vote-9" name="h-5-this-sounds-super-dangerous-as-i-could-be-penalized-for-32-eth-just-by-missing-a-single-source-vote-9"></a>5. This sounds super dangerous, as I could be penalized for 32 ETH just by missing a single source vote.</h3>
<p>This is incorrect since the penalty_factor variable is capped at 4 (to be analyzed). Capping ensures that the correlation penalties never get out of hand.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-6-why-only-focus-on-source-votes-and-not-do-the-same-for-head-and-target-votes-10" name="h-6-why-only-focus-on-source-votes-and-not-do-the-same-for-head-and-target-votes-10"></a>6. Why only focus on source votes and not do the same for head and target votes?</h3>
<p>This is a good question and since research on that topic is still at the very beginning this isn’t decided yet. An argument against head and target votes is the fact that they depend on external factors: as shown in <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">previous analysis</a>, head votes are sensitive to proposer timing games. So, if those timing games become more and more the standard, less well-connected validators (oftentimes solo stakers) could potentially be worse off. However, <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">this</a> analysis showed that it would be the opposite and in the long run, small-size stakers would profit from anti-correlation penalties. The same applies to target votes that are harder to get right in the first slot of an epoch compared to every other slot. Nevertheless, in the long run, this should smooth out across validators, allowing us to do anti-correlation penalties for all parts of an attestation, source-, target-, and head votes.</p>
<h2><a class="anchor" href="https://ethresear.ch#useful-links-11" name="useful-links-11"></a>Useful links:</h2>
<div class="md-table">
<table>
<thead>
<tr>
<th>Url</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a class="inline-onebox" href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716: Anti-correlation attestation penalties</a></td>
<td>EIP-7716 (draft)</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://ethresear.ch/t/a-concrete-proposal-for-correlated-attester-penalties/19341">A concrete proposal for correlated attester penalties</a></td>
<td>Original Proposal</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://ethereum-magicians.org/t/eip-7716-anti-correlation-attestation-penalties/20137">EIP-7716: Anti-correlation attestation penalties - EIPs - Fellowship of Ethereum Magicians</a></td>
<td>EthMagicians Post</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://github.com/dapplion/anti-correlation-penalties-faq">GitHub - dapplion/anti-correlation-penalties-faq: Anti correlation penalties FAQ</a></td>
<td>EthBerlin Project</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://github.com/igorline/lighthouse/pull/1">Impement anti-correlation attestation penalties eip by igorline · Pull Request #1 · igorline/lighthouse · GitHub</a></td>
<td>Lighthouse Implementation</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">Analysis on ''Correlated Attestation Penalties''</a></td>
<td>Quantitative Analysis</td>
</tr>
</tbody>
</table>
</div>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 20 Jul 2024 08:56:40 +0000</pubDate>
</item>
<item>
<title>EIP 648 for Parallel Rollup</title>
<link>https://ethresear.ch/t/eip-648-for-parallel-rollup/20103</link>
<guid>https://ethresear.ch/t/eip-648-for-parallel-rollup/20103</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP 648, 交易类型, 并行处理, 范围限制, 兼容性问题

总结:<br />
EIP 648是一项2017年的提议，旨在通过引入新的交易类型来提升以太坊网络中交易的并发处理。该提案允许用户指定读写范围，非重叠范围的交易可并行执行。然而，它存在一些问题。首先，用户可能难以预知交易将访问的具体账户，这称为合同预知识问题。其次，它采用悲观并发控制，以账户为单位，可能导致粗粒度的同步，限制了实际的并行性。因此，虽然EIP 648有其优点，但在实际应用到如Rollup等技术时，需要解决这些兼容性和性能优化的问题。 <div>
<h3><a class="anchor" href="https://ethresear.ch#what-is-eip-648-1" name="what-is-eip-648-1"></a>What is EIP 648?</h3>
<p>EIP 648 was proposed back in 2017. The proposal introduces a new transaction type to facilitate parallel transaction processing.</p>
<p>The new type allows users to specify both the read and write ranges of accounts that the transaction will access. Transactions with no overlapping ranges will be executed in parallel. If the ranges overlap, transactions will conflict unless they are all read-only.</p>
<h3><a class="anchor" href="https://ethresear.ch#issues-2" name="issues-2"></a>Issues</h3>
<p>While the proposal is favorable for its simplicity in some cases, it also has some issues that make it difficult to use directly in rollups.</p>
<ol>
<li>
<p><strong>Contract Pre-knowledge:</strong> It is not always straightforward for users to know exactly which accounts their transactions will access beforehand.</p>
</li>
<li>
<p><strong>Account-level:</strong> The approach uses pessimistic concurrency control at the account level. The statements of the ranges act as synchronization primitives, but this has very coarse concurrency granularity (account-level), which can seriously reduce parallelism in many cases.</p>
</li>
</ol>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/eip-648-for-parallel-rollup/20103">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 07:14:22 +0000</pubDate>
</item>
<item>
<title>Commit-Boost: Proposer Platform to Safely Make Commitments</title>
<link>https://ethresear.ch/t/commit-boost-proposer-platform-to-safely-make-commitments/20107</link>
<guid>https://ethresear.ch/t/commit-boost-proposer-platform-to-safely-make-commitments/20107</guid>
<content:encoded><![CDATA[
<div> 关键词：Commit-Boost, Ethereum, Validator Sidecar, Proposer Commitments, Open-Source

总结:<br />
Commit-Boost是一个由社区驱动的开放源代码项目，旨在为Ethereum开发一个通用的验证者平台，以处理与承诺相关的事务。它解决了当前碎片化问题，通过统一标准，让核心开发者能处理升级和故障情况，同时支持MEV-Boost和其他承诺协议。Commit-Boost不依赖于单一侧车，允许验证者安全地参与不同类型的承诺，减少风险和复杂性。团队由非营利实体支持，致力于透明度、安全性和持续发展，没有VC资金，确保软件作为公共利益存在。目前处于MVP阶段，正在进行测试，预计Q3末将进行审计并逐步完善功能。 <div>
<p><em>The following post is an introduction to some and an update to others on a community effort called <a href="https://x.com/Commit_Boost" rel="noopener nofollow ugc">Commit-Boost</a>. Much of this has already been discussed in various public domains / presentations / documentation. Thank you to all the countless teams that already have contributed / committed to contributing to this effort including researchers, validators, builders, relays, client teams, consulting firms, teams building commitment protocols, L2s, restaking platforms, shared sequencers, wallets, and countless others. Please reach out if you would like to contribute to this effort for Ethereum.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/d/adc1d52f519c3c2bb0d61cd00f9c796e249eba81.png" title="Commit-Boost"><img alt="Commit-Boost" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/a/d/adc1d52f519c3c2bb0d61cd00f9c796e249eba81_2_408x375.png" width="408" /></a></div><p></p>
<p><strong>TL;DR</strong></p>
<ul>
<li>Due to the risks developing for Ethereum, core development, and its validator set, a group of teams / individuals are working on developing a public good called Commit-Boost</li>
<li><a href="https://github.com/Commit-Boost/commit-boost-client" rel="noopener nofollow ugc">Commit-Boost</a> is an open-source public good that is fully compatible with <a href="https://github.com/flashbots/mev-boost" rel="noopener nofollow ugc">MEV-Boost</a> but acts as a light-weight validator platform to safely make commitments</li>
<li>Specifically, Commit-Boost is a new Ethereum validator sidecar that is focused on standardizing the last mile of communication between validators and proposer commitment protocols</li>
<li>Commit-Boost has been designed with safety and modularity at its core, with the goal of not limiting the market downstream including stakeholders, flows, proposer commitments, enforcement mechanisms, etc.</li>
<li>While we should always be skeptical of out-of-protocol solutions that directly impact infrastructure this close to the Ethereum protocol layer, if we are going to rely on these solutions, we believe they should be developed, sustained, and governed in a way that encompasses many of the views <a href="https://collective.flashbots.net/t/toward-an-open-research-and-development-process-for-mev-boost/464" rel="noopener nofollow ugc">previously voiced</a> by the community. We have tried to embrace this and strive to model Commit-Boost after it</li>
</ul>
<p><strong>Background</strong></p>
<ul>
<li>Proposer commitments have been an important part of Ethereum’s history. Today, we already see the power of commitments where over 90% of validators give up their autonomy and make a wholesale commitment that outsources block building to a sophisticated actor called a block builder</li>
<li>However, most are starting to agree on a common denominator: in the future, beacon proposers will face a broader set of options of what they may “commit" to–be it inclusions lists or preconfs or other types of commitments such as long-dated blockspace futures–compared to just an external or local payload they see today</li>
<li>A <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">post</a> from Barnabe captures this well; during block construction, the validator “…creates the specs, or the template, by which the resulting block must be created, and the builders engaged by the proposer are tasked with delivering the block according to its specifications”</li>
<li>While this all seems great, the challenge is that many teams building commitments are creating new sidecars driving fragmentation and risks for Ethereum</li>
<li>For Ethereum, there are going to be significant challenges and increased risks during upgrades if there are a handful of sidecars that validators are running</li>
<li>For validators, these risks potentially take us to a world where proposers will need to make decisions on which teams to “bet on” and which sidecars they will need to run to participate in what those teams are offering</li>
<li>For homestakers, this is difficult and they likely will be unable to participate in more than one of these commitments</li>
<li>For sophisticated actors, this increases the attack vector and operational complexity as more and more sidecars are required to be run</li>
<li>Another side effect of this is validators are somewhat locked into using a specific sidecar due to limited operational capacity and the switching costs of running a different sidecar (i.e., vendor lock-in). The higher the switching costs, the more embedded network effects could become if these sidecars only support certain downstream actors / proposer commitment protocols</li>
<li>This also could create a dynamic where core out-of-protocol infrastructure supporting Ethereum which should be a public good, starts being used for monetization, distribution, or other purposes</li>
<li>Due to these dynamics, various teams and individuals across the community are driving the development and testing of open-source / public good software called Commit-Boost. This effort includes researchers, validators, builders, relays, client teams, consulting firms, protocols building commitments, L2s, restaking platforms, and countless others across the community</li>
</ul>
<p><strong>Commit-Boost Overview</strong></p>
<p>Commit-Boost is a community-driven, open-source project developing an unopinionated validator platform to enable safe interactions with commitments. Some of its features include:</p>
<ul>
<li>Unification: Core devs will be able to interact and work with one standard during Ethereum forks / upgrades / when and if things go wrong</li>
<li>Backward compatibility + more: Commit-Boost is not only backward compatible with MEV-Boost, but will improve the life of validators who only run MEV-Boost through increased reporting, telemetry / other off-the-shelf tools validators can employ</li>
<li>Opt-in without running more sidecars: Commit-Boost will allow proposers who want to opt into other commitments do so without having to run multiple sidecars</li>
<li>Robust support: Commit-Boost the software is supported by a not-for-profit entity. This team will be focused on security and robustness through policies and procedures with follow-the-sun type models where there is support 24/7 if / when things go wrong. This team will also be focused on testing and adjustments needed during hard forks and have a team to interact with to help during adoption, improvements, and sustainment</li>
<li>Not VC-backed public good: This team and effort will not be VC-backed. There is no monetization plan. The entity will not be able to sell itself and will not start any monetizable side businesses</li>
</ul>
<p><strong>Robustness, Sustainability, and Security</strong></p>
<ul>
<li>Commit-Boost is being developed as a fully open-source project with contributions from teams across the Ethereum tech stack including from validators, client teams, relays, builders, consulting firms, researchers, and many others. This effort with input and support from these teams will help develop a robust product integrating many perspectives</li>
<li>Commit-Boost will go through code reviews and audits once fully developed</li>
<li>As noted below, there also will be a full-time team that helps maintain and upgrade the software with their core focus on 100% uptime and when there are bugs, robust processes to quickly address and fix</li>
<li>The software stack is also built with the validator at the core and includes off-the-shelf tools for monitoring as well as reducing and proactively addressing any risks that may arise</li>
<li>Last, this public good software will have minimal, but critical open governance around future upgrades with input across the Ethereum</li>
</ul>
<p><strong>Team Supporting / Governance of Commit-Boost Software</strong></p>
<ul>
<li>Entity supporting the software: Not-for-profit entity</li>
<li>Multiple-person team: Multiple devs that focus on transparency, sustainment / development, and research with an initial focus around Commit-Boost the software</li>
<li>Transparency: Open-source <a href="https://github.com/Commit-Boost/commit-boost-client" rel="noopener nofollow ugc">repo</a> and governance calls (see below)</li>
<li>Sustainment / Development: 24/7 follow-the-sun coverage and highly engaged with client teams around upgrades / early in getting testnet support</li>
<li>Research: Helping with open-source research across Ethereum</li>
<li>Governance: This is still a WIP, but at a minimum will run a Commit-Boost, ACD-like calls (first one coming soon) to engage with stakeholders and drive consensus on upgrades / help coordinate around hard forks. A credibly neutral community member will lead these calls / this process that has experience with running governance processes over critical software within the Ethereum community</li>
<li>Funding: All grants</li>
</ul>
<p><strong>Where Will the Grants Come From</strong></p>
<p>The team is in the process of applying for grants from across the ecosystem. We are initially applying to a few organizations across the community that are supporting grants across research organizations and firms focused on PBS and staking. If teams are interested in providing a grant, feel free to comment below / reach out.</p>
<p><strong>Technical Roadmap</strong></p>
<p>Commit-Boost is currently in the MVP phase with <a href="http://holesky.beaconcha.in/slot/2022891" rel="noopener nofollow ugc">testing</a> underway in Holesky with multiple validators. This includes the full functionality of a PBS Module implementing MEV-Boost with additional telemetry and metrics collection. We are continuing the development and feature set of Commit-Boost targeting production-ready software and audits kicking off at the end of Q3. More details are in the Commit-Boost <a href="https://github.com/Commit-Boost/commit-boost-client/issues" rel="noopener nofollow ugc">repo</a> and we are keen to get feedback / engage with the community around these.</p>
<p>Some near-term high-level highlights from the roadmap include:</p>
<ul>
<li>Optimized and functional MEV-Boost module including multiple metrics for reporting and extensions such as configurable timing for get_header / get_payload calls</li>
<li>Pre-made dashboards on Grafana for all core services</li>
<li>Improved reliability and integrations for incident response</li>
<li>R&amp;D / spec signing mechanism to fit as many validator set-ups as possible</li>
<li>Expanding modularity and optionality (i.e., supporting different types of signatures and modules)</li>
</ul>
<p><strong>Commit-Boost Design Principles</strong></p>
<ul>
<li>Built for validators: Platform that not only can help validators today (i.e., can improve the lives of validators even if they just run an MEV-Boost module) but allows validators to be ready for the market of tomorrow (i.e., preconfs, inclusion lists, etc)</li>
<li>Neutrality: No opinions, the platform will be proposer commitment agnostic, relay agnostic, transaction flow agnostic, etc. The goal is to build a platform that doesn’t limit the design space downstream while reducing risks of fragmentation for validators and Ethereum</li>
<li>Unified: Validators run one core sidecar with the ability to opt into many different commitments</li>
<li>Safety: Open-source code developed with input by the community with community reviews / audits</li>
<li>Reduce risks: Modularized and transparency are core to reducing risk / overhead for the proposer to manage commitments and their broader operational processes</li>
<li>Values aligned: Public good with no plans for monetization. We will continuously ask ourselves: would Vitalik run Commit-Boost and can this be designed in a way to increase the decentralization of Ethereum block construction</li>
</ul>
<p><strong>From the Perspective of the Proposer</strong></p>
<p>More details on what it takes to run Commit-Boost as a node operator can be found <a href="https://commit-boost.github.io/commit-boost-client/get_started/overview" rel="noopener nofollow ugc">here</a>. Please note that this has not been finalized and over the next few weeks we will be making updates (see roadmap / milestones above).</p>
<ul>
<li>Run a single sidecar with support for MEV-Boost and other proposer commitments protocols, such as precons / other commitments</li>
<li>Out-of-the-box support for metrics reporting and dashboards to have clear insight around what is happening in your validator seen through dashboards such as Grafana</li>
<li>Plug-in system to add custom modules, i.e., receive a notification on Telegram if a relay fails to deliver a block</li>
<li>Standardized way to provide a signature to opt into a commitment</li>
<li>Creates constraints / condition sets and pass these constraints downstream</li>
</ul>
<p><strong>From the Perspective of the Proposer Commitment Protocol / Module Creator</strong></p>
<p>More details on what it takes to build a module / metrics can be found <a href="https://commit-boost.github.io/commit-boost-client/category/developing" rel="noopener nofollow ugc">here</a>. Please note that this has not been finalized and over the next few weeks we will finalize moving parts that impact module creators (see roadmap / milestones above).</p>
<ul>
<li>A modular platform to develop and distribute proposer commitments protocols</li>
<li>A single API to interact with validators</li>
<li>Support for hard-forks and new protocol requirements</li>
</ul>
<p><strong>Architecture of Commit-Boost</strong></p>
<p>More details can be found in the Commit-Boost <a href="https://commit-boost.github.io/commit-boost-client/" rel="noopener nofollow ugc">documentation</a>. However, below is a schematic of Commit-Boost. This proposed architecture allows proposers to run one sidecar, but still retain the ability to opt into a network of proposer commitment modules. More specifically, with this middleware, the proposer will only need to (in the case of delegation / light weight commitments) run one sidecar and limit their responsibilities to only selecting which module / proposer commitment protocol they would like to subscribe to.</p>
<p>It is important to note that the below depiction contains just a few examples of proposer commitment modules that can run on Commit-Boost. The design space for modules is completely open / not gated by the Commit-Boost software and proposers will be responsible for opting into the commitments they wish to subscribe to (i.e., a proposer is responsible for which modules they will subscribe to).</p>
<p><strong>Terminology</strong></p>
<ul>
<li>Proposer: entity, staking pool NoOp, or DVT cluster with the right to propose the next block</li>
<li>Commitment: a constraint or condition that the proposer choses and agrees to via a signature</li>
<li>Key Manager: some proposers use key managers or remote signers as part of their proposer / validator duties. Please note, that Commit-Boost is being designed in a way where it does not require validators to run key managers and working on solutions for monolithic set-ups</li>
<li>Consensus Client: for example, Lighthouse or Teku (see <a href="https://ethereum.org/en/developers/docs/nodes-and-clients/" rel="noopener nofollow ugc">here</a> for more details)</li>
<li>Commitment Modules: community-built modules allowing proposers to make commitment, including some of the logic of the proposer commitment protocol</li>
<li>Signer API: The signer API is one of the core components around Commit-Boost. This is used to provide signatures from the proposer to the proposer commitment protocol. This is still in the design but proxy signatures will be used in nearly all cases (there are some outlier cases). For more details on the API please see <a href="https://commit-boost.github.io/commit-boost-client/api/" rel="noopener nofollow ugc">here</a>. For an example of how to communicate with the Signer API, please see <a href="https://commit-boost.github.io/commit-boost-client/developing/commit-module" rel="noopener nofollow ugc">here</a></li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/a/ca4fdf7f738261cf46b1505dc56198da182592dc.png" title="Schematic"><img alt="Schematic" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/c/a/ca4fdf7f738261cf46b1505dc56198da182592dc_2_690x411.png" width="690" /></a></div><p></p>
<p>Using this as a middleware instead of direct modification to the consensus client or running a sidecar per commitment will allow for each component to be sustained independently and will provide for cross proposer commitment compatibility. This will also allow for a bit of time for the market to play out, but via a public good, standardize the last mile of communication to help address the risks (discussed in the background section above) developing. Once the market does play out, and the community is able to observe some dynamics (the good and the bad), we can and should push for CL changes.</p>
<p><strong>Resources</strong></p>
<ul>
<li><a href="https://github.com/Commit-Boost" rel="noopener nofollow ugc">Commit-Boost Repo</a></li>
<li>Commit-Boost <a href="https://commit-boost.github.io/commit-boost-client/" rel="noopener nofollow ugc">documentation</a></li>
<li>List of presentations</li>
<li>Original post on ETH Research, read more <a href="https://ethresear.ch/t/based-proposer-commitments-ethereum-s-marketplace-for-proposer-commitments/19517">here</a></li>
<li>First presentation to the community can be found <a href="https://www.youtube.com/watch?v=jrm4ZUoj9xY&amp;list=PLJqWcTqh_zKHDFarAcF29QfdMlUpReZrR&amp;index=11" rel="noopener nofollow ugc">here</a></li>
<li>Second presentation at zuBerlin can be found <a href="https://streameth.org/zuberlin/watch?session=66681afef9b8e98b1ec95fdd" rel="noopener nofollow ugc">here</a></li>
<li>zuBerlin Devnet notion can be found <a href="https://twisty-wednesday-4be.notion.site/ZuBerlin-Preconfs-Devnet-b693047f41e7407cadac0170a6711dea" rel="noopener nofollow ugc">here</a></li>
<li>Mev-Boost Community call <a href="https://www.youtube.com/watch?v=UgoFjNkkTac" rel="noopener nofollow ugc">here</a></li>
<li>Espresso / One Balance Sequencing day here (this will be updated when the link is ready)</li>
<li>Gattaca MEV Day here (this will be updated when the link is ready)</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/commit-boost-proposer-platform-to-safely-make-commitments/20107">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 14:33:05 +0000</pubDate>
</item>
<item>
<title>What is "RealTPS" in Blockchain</title>
<link>https://ethresear.ch/t/what-is-realtps-in-blockchain/20098</link>
<guid>https://ethresear.ch/t/what-is-realtps-in-blockchain/20098</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、TPS、透明度、交易定义、测量工具

总结:<br />这篇文章讨论了区块链中TPS（交易每秒）指标的不透明性问题。传统上，TPS被模糊地定义和测量，与区块链的透明性原则相冲突。文章指出，应以确认交易（ConfirmedTransactions）为基础来计算TPS，质疑现有的高TPS宣称可能未经详细说明。文章提到Hyperledger的Caliper和Quorum推荐的测量工具存在局限，如只考虑单节点性能，未充分反映分布式网络特性。作者团队开发了新的工具AnTPS，旨在提供透明的多节点、多账户测量，支持不同场景和环境，以改进对区块链TPS的准确评估。 <div>
<p>Authors: <a href="https://x.com/Kyungmin7984" rel="noopener nofollow ugc">@Kyungmin</a> <a href="https://github.com/bicoCrypto" rel="noopener nofollow ugc">@bicoCrypto</a> <a href="https://github.com/solmingming" rel="noopener nofollow ugc">@solmingming</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h2>
<p>The current concept of TPS (Transactions Per Second) in blockchain is being disclosed in an ambiguous and opaque manner, conflicting with blockchain’s core value of transparency. This article reconsiders the definition of transactions in blockchain, compares theoretical figures with actual measurements, evaluates existing measurement tools, introduces our self-developed tool, and proposes a more accurate and transparent TPS measurement method.</p>
<h2><a class="anchor" href="https://ethresear.ch#problem-2" name="problem-2"></a>Problem</h2>
<p>The biggest change in the transition from Web2 to Web3 is decentralization. This has led to improved system accessibility and increased information transparency. However, there is still opaque information in the blockchain ecosystem, with TPS being a prime example.</p>
<p>In transaction processing systems, especially financial systems, TPS is a crucial performance indicator. However, the TPS information currently provided in blockchain is limited to simple figures, with detailed information about measurement methods and processes remaining opaque.</p>
<p>While blockchain smart contracts are operated transparently through verification and auditing, we still rely on the foundation’s system for the blockchain nodes themselves, lacking verification procedures similar to smart contracts.</p>
<h2><a class="anchor" href="https://ethresear.ch#tps-in-traditional-web2-3" name="tps-in-traditional-web2-3"></a>TPS in traditional Web2</h2>
<p>When discussing blockchain TPS, VISA’s processing capability is often mentioned as a comparison. <a href="https://www.reddit.com/r/nanocurrency/comments/82438o/visa_is_capable_of_performing_24000_transactions/" rel="noopener nofollow ugc">VISA officially announced a processing capability of 24,000 TPS</a>, but <a href="https://news.bitcoin.com/no-visa-doesnt-handle-24000-tps-and-neither-does-your-pet-blockchain/" rel="noopener nofollow ugc">this has been questioned</a>:</p>
<p>In centralized Web2 systems, it’s difficult to verify such issues. However, blockchain (Web3) systems are decentralized and their code is managed as open source, making it possible to verify TPS.</p>
<h2><a class="anchor" href="https://ethresear.ch#tps-in-web3-4" name="tps-in-web3-4"></a>TPS in Web3</h2>
<p>In blockchain systems with public nodes and permissionless nodes, anyone can participate in the network, operate nodes, and access the system. Even without connecting to the mainnet or testnet, the source code is publicly available, allowing independent network construction or modification after forking.</p>
<p>Ethereum and most EVM-compatible blockchains publish high TPS figures. For example, Avalanche C-Chain is introduced as capable of achieving 4,500 TPS. However, information on how this figure was measured is not provided.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/4/748ee3c646e8c2964dd294eefe5aa1491ce65b45.jpeg" title="Image"><img alt="Image" height="378" src="https://ethresear.ch/uploads/default/optimized/3X/7/4/748ee3c646e8c2964dd294eefe5aa1491ce65b45_2_690x378.jpeg" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#time-to-define-transaction-5" name="time-to-define-transaction-5"></a>Time to Define Transaction</h2>
<p>In EVM blockchains, the term “Transaction” is used in various contexts:</p>
<ul>
<li>SendTransaction: Simply refers to the act of sending a transaction, without guaranteeing the final state or completeness of the transaction.</li>
<li>PendingTransaction: The state where a transaction is waiting in the node’s memory pool (Mempool).</li>
<li>QueuedTransaction: Similar to Pending, waiting in the node’s memory pool, but distinguished in the serialization process through Nonce.</li>
<li>ConfirmedTransaction: The state where a transaction receipt has been issued, indicating the transaction has succeeded or failed.</li>
</ul>
<p>We believe that TPS should be calculated based on ConfirmedTransactions when measuring. Based on this, we propose the following formula for calculating TPS:<br />
TPS = BlockGasLimit / (TxGasUsed * BlockCreationTime)</p>
<p>Currently, Avalanche C-Chain’s BlockGasLimit is 15,000,000<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/9/c909ced7994a754fc7875e8dd1730093faedad3e.png" title="Tx Gaslimit"><img alt="Tx Gaslimit" height="225" src="https://ethresear.ch/uploads/default/optimized/3X/c/9/c909ced7994a754fc7875e8dd1730093faedad3e_2_690x225.png" width="690" /></a></div><p></p>
<p>Even assuming the simplest transaction (TxGasUsed = 21,000) and the shortest block creation time (BlockCreationTime = 1 second), the theoretical maximum TPS is 715. This shows a significant difference from the officially announced 4,500 TPS. (The actual measured value would naturally be even lower)</p>
<p>We speculate that this difference may occur due to:</p>
<ul>
<li>The transaction standard used in TPS calculation may not be ConfirmedTransaction</li>
<li>The Avalanche version that achieved 4,500 TPS may differ from the version currently used in public nodes</li>
<li>Differences in TPS measurement methods and methodologies</li>
</ul>
<p>Such opaque information raises questions about the reliability and accuracy of TPS figures.<br />
Monad has published a critical analysis of these limitations of blockchain TPS: <a href="https://www.monad.xyz/wtf-is-tps" rel="noopener nofollow ugc">WTF is TPS?</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tps-benchmark-tools-6" name="tps-benchmark-tools-6"></a>TPS Benchmark Tools</h2>
<p>There are currently two main blockchain TPS benchmark tools in use:</p>
<ol>
<li><a href="https://github.com/hyperledger/caliper" rel="noopener nofollow ugc">Hyperledger Caliper</a>: Developed by the Hyperledger Foundation</li>
<li><a href="https://github.com/drandreaskrueger/chainhammer" rel="noopener nofollow ugc">ChainHammer</a>: Recommended by Quorum (a private blockchain developed by ConsenSys)<br />
Note: ChainHammer’s most recent commit was 2 years ago, making it essentially outdated.</li>
</ol>
<p>Caliper is written in JavaScript and is a highly complete project. However, there are doubts about whether it is optimized for measuring “blockchain” TPS:</p>
<ol>
<li>TPS measurement on a single node:<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/7/67bd0b50a563472ac93dafc3fa2e17effa0919e8.png" title="Figure2"><img alt="Figure2" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/6/7/67bd0b50a563472ac93dafc3fa2e17effa0919e8_2_690x389.png" width="690" /></a></div></li>
</ol>
<p>The core of blockchain is distributed storage of data through consensus. However, Caliper only conducts TPS measurements on a single node, which can measure the TPS of individual nodes but does not accurately reflect the TPS of the entire blockchain network. (The transaction propagation process is not considered)</p>
<ol>
<li>Limitation of measurement from a single account:<br />
In EVM, EOA (Externally Owned Account) has a Nonce value, causing transactions to be processed sequentially.<br />
While 2024 was predicted to be the era of parallel EVM, current parallel processing technology still proceeds in an optimistic manner, requiring re-execution in case of conflicts. (Cases requiring re-execution can hardly be considered true parallel execution.)<br />
Therefore, execution from a single account versus multiple accounts can have a significant impact on TPS.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#antpsan-ti-tps-7" name="antpsan-ti-tps-7"></a>AnTPS(An-ti TPS)</h2>
<p>To improve these limitations, we have developed our own blockchain benchmark tool, AnTPS, using Golang: <a href="https://github.com/decipherhub/AnTPS" rel="noopener nofollow ugc">Github</a><br />
Features include:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/0/f0cff11ba6f328b500e85b78f194763580ca940c.png" title="image"><img alt="image" height="283" src="https://ethresear.ch/uploads/default/optimized/3X/f/0/f0cff11ba6f328b500e85b78f194763580ca940c_2_690x283.png" width="690" /></a></div><p></p>
<ul>
<li>Transparently providing measurement environment/results.</li>
<li>Conducting measurements on at least two or more nodes.</li>
<li>Supporting measurement cases for both single and multiple accounts.</li>
<li>Supporting various scenarios during measurement (ERC20/721/1155/NativeToken).</li>
<li>Supporting not only local environment measurements but also Cloud environments through IaC.</li>
</ul>
<p>Our goal is to overcome the limitations of existing tools while providing information transparently.<br />
We welcome your opinions and feedback. Thank you.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/what-is-realtps-in-blockchain/20098">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 03:52:11 +0000</pubDate>
</item>
<item>
<title>Based Preconfirmations with Multi-round MEV-Boost</title>
<link>https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091</link>
<guid>https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091</guid>
<content:encoded><![CDATA[
<div> 关键词：基于预确认、多轮MEV-Boost、L1 PBS管道、外部性、区块链安全

总结:
本文探讨了基于预确认的 rollup 模型存在的问题，尤其是其12秒的区块时间所导致的负面效应。作者提出了多轮MEV-Boost（MR-MEV-Boost）的概念，通过在一个槽位内运行多次MEV-Boost拍卖来实现快速预确认，从而保持了基于预确认rollup的优点如同步兼容性和L1抗审查性，同时减轻了预确认带来的负面影响。文章分析了MR-MEV-Boost的优势和挑战，如减少了延迟竞赛、缓解拥堵、改进定价机制，并讨论了用户和协议设计中的公平交换问题。尽管存在一些限制，如较慢的预确认速度和对-relayer负担的增加，但该方案为解决基于预确认的rollup问题提供了新的思路。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb1798cc79775d7958124717d6ba5cc97c1aa008.jpeg" title="image"><img alt="image" height="394" src="https://ethresear.ch/uploads/default/original/3X/f/b/fb1798cc79775d7958124717d6ba5cc97c1aa008.jpeg" width="690" /></a></div><p></p>
<p>By <a href="https://twitter.com/linoscope" rel="noopener nofollow ugc">Lin Oshitani</a> (<a href="https://switchboard.nethermind.io/" rel="noopener nofollow ugc">Nethermind Switchboard</a>, <a href="https://www.nethermind.io/nethermind-research" rel="noopener nofollow ugc">Nethermind Research</a>). Many thanks to <a href="https://twitter.com/ConorMcMenamin9" rel="noopener nofollow ugc">Conor</a> for the detailed back-and-forth on crafting this document and to <a href="https://www.linkedin.com/in/aikaterini-panagiota-stouka/" rel="noopener nofollow ugc">Aikaterini</a>, <a href="https://x.com/ElenaPetreska0x" rel="noopener nofollow ugc">Elena</a>, <a href="https://twitter.com/smartprogrammer" rel="noopener nofollow ugc">Ahmad</a>, <a href="https://twitter.com/aj_jalan" rel="noopener nofollow ugc">Anshu</a>, <a href="https://twitter.com/swp0x0" rel="noopener nofollow ugc">Swapnil</a>, <a href="https://twitter.com/tkstanczak" rel="noopener nofollow ugc">Tomasz</a>, <a href="https://twitter.com/totorovirus" rel="noopener nofollow ugc">Jinsuk</a>, <a href="https://twitter.com/0xQuintus" rel="noopener nofollow ugc">Quintus</a>, <a href="https://x.com/ceciliaz030" rel="noopener nofollow ugc">Ceciliaz</a>, and <a href="https://twitter.com/Brechtpd" rel="noopener nofollow ugc">Brecht</a> for the helpful comments and/or review. This work was partly funded by Taiko. The views expressed are my own and do not necessarily reflect those of the reviewers or Taiko.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h1>
<p>As we outlined in our previous post <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695">Strawmanning Based Preconfirmations</a>, naive implementations of based preconfirmations introduce many negative externalities that require thoughtful consideration.</p>
<p>In this post, we will expand on the negative externalities of based preconfirmations by examining them through the lens of the L1 PBS pipeline. Then, we propose <em>multi-round MEV-Boost</em>, a modification of MEV-Boost that enables based preconfirmations by running multiple rounds of MEV-Boost auctions within a single slot. This approach inherits the L1 PBS pipeline and mitigates the negative externalities of based preconfirmations as a result.</p>
<h1><a class="anchor" href="https://ethresear.ch#motivation-2" name="motivation-2"></a>Motivation</h1>
<p>As Justin Drake <a href="https://ethresear.ch/t/based-rollups-superpowers-from-l1-sequencing/15016#:~:text=a%20based%20rollup%20is%20one%20where%20the%20next%20L1%20proposer%20may%2C%20in%20collaboration%20with%20L1%20searchers%20and%20builders%2C%20permissionlessly%20include%20the%20next%20rollup%20block%20as%20part%20of%20the%20next%20L1%20block">defines</a> in the original post, based rollups are rollups “where the next L1 proposer may, in collaboration with L1 searchers and builders, permissionlessly include the next rollup block as part of the next L1 block”. Using the <a href="https://flashbots.mirror.xyz/bqCakwfQZkMsq63b50vib-nibo5eKai0QuK7m-Dsxpo" rel="noopener nofollow ugc">MEV supply chain</a> diagram, based rollups can be illustrated below:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1.png" title="Based Rollups (5) (1)"><img alt="Based Rollups (5) (1)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1_2_690x346.png" width="690" /></a></div><p></p>
<p>Notice that the L2 transactions, represented as the red line, go through the same process as the L1 transactions, represented as the black line. By effectively “piggybacking” the L1 PBS pipeline, based rollups provide two key benefits:</p>
<ul>
<li><strong>Benefit 1</strong>: Since no additional actors (and thus no additional choke points) are introduced for L2 sequencing, based rollups fully inherit L1 censorship resistance, liveness, and credible neutrality.</li>
<li><strong>Benefit 2</strong>: Since the L1 and L2 transactions are sequenced by the same entity (the builder), based rollups enable not only synchronous L2-L2 composability but also synchronous L1-L2 composability.</li>
</ul>
<p>Based rollups are great. They solve L2 fragmentation and sequencer decentralization while enabling L1 composability and inheriting L1’s censorship resistance, liveness, and credible neutrality. They are the only rollups that can have these properties simultaneously.</p>
<p>However, they have one large drawback: they also inherit the 12-second L1 block time. To address the slow confirmation time, Justin introduced <a href="https://ethresear.ch/t/based-preconfirmations/17353">base preconfirmations</a>. In this approach, L1 proposers can opt into providing preconfirmations for based rollup L2 transactions, as shown below:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/e/6e65221a830715cead4428b2724688ce66d7520c.png" title="Based Preconf (2) (1)"><img alt="Based Preconf (2) (1)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/6/e/6e65221a830715cead4428b2724688ce66d7520c_2_690x346.png" width="690" /></a></div><p></p>
<p>Since providing preconfirmations requires technical sophistication, most based preconfirmation designs include a delegation mechanism that allows validators to outsource the preconfirmation duty to a designated preconfer, as illustrated below:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/9/f9346fd068da5aa3ae0e57fceccc6c2af223b958.png" title="Based Preconf with delegation (2)"><img alt="Based Preconf with delegation (2)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/f/9/f9346fd068da5aa3ae0e57fceccc6c2af223b958_2_690x346.png" width="690" /></a></div><p></p>
<p>Notice that L2 and L1 transactions no longer share the block-building pipeline. As such, the benefits of based rollups are diminished:</p>
<ul>
<li>On benefit 1: We introduced an additional choke point to the system, the preconfer, which can censor L2 transactions or degrade L2 liveness by going down. As a result, the inheritance of L1 censorship resistance and liveness are degraded.</li>
<li>On benefit 2: We now have two parallel block-building entities: one for L1 (the builder) and another for L2 (the preconfer). Consequently, L1-L2 composability now requires coordination between the builder and the preconfer. This adds complexity and can lead to <em>builder-preconfer integration</em>, where the proposer delegates not only their preconfirmation right but also the whole block-building right to the preconfer ahead of their slot.</li>
</ul>
<p>In summary, by introducing preconfirmations, we lost the below structure:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1.png" title="Based Rollups (5) (1)"><img alt="Based Rollups (5) (1)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1_2_690x346.png" width="690" /></a></div><p></p>
<p>As a result, many of the benefits of based rollups are diminished.</p>
<p>So, what if we keep this pipeline but run it multiple times within a slot to achieve fast preconfirmations? This brings us to the main contribution of this document: <em>Multi-round MEV-Boost</em>.</p>
<h1><a class="anchor" href="https://ethresear.ch#multi-round-mev-boost-3" name="multi-round-mev-boost-3"></a>Multi-round MEV-Boost</h1>
<p>At a high level, Multi-round MEV-Boost, or <em>MR-MEV-Boost</em> (pronounced “<em>mister-mev-boost</em>”, h/t <a href="https://twitter.com/ConorMcMenamin9" rel="noopener nofollow ugc">Conor</a> for the idea on the pronounciation :)) for short, works as follows:</p>
<ul>
<li>Split each slot into a fixed number of <em>rounds, e</em>.g., 4 rounds with 3 seconds each.</li>
<li>Within each round, run a single MEV-Boost auction. As a result of the auction, a single <em>partial block</em> (a.k.a <em>partial payload</em>) will be signed and published, i.e., the partial block will be <em>preconfirmed</em>.</li>
<li>The full block is created and published at the end of the slot. The full block should contain the partial blocks in the exact order they were preconfirmed without inserting any transactions before or in between.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#refresher-mev-boost-4" name="refresher-mev-boost-4"></a>Refresher: MEV-Boost</h2>
<p>Before diving deeper into the proposed protocol, let’s quickly review today’s <a href="https://docs.flashbots.net/flashbots-mev-boost/introduction" rel="noopener nofollow ugc">MEV-Boost</a> PBS pipeline used in L1 Ethereum.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/e/fe199d4c844c9230a675292724deb29c9e03a3df.png" title="MEV-Boost"><img alt="MEV-Boost" height="500" src="https://ethresear.ch/uploads/default/original/3X/f/e/fe199d4c844c9230a675292724deb29c9e03a3df.png" width="609" /></a></div><p></p>
<ol>
<li>Builders send the <code>header</code>, <code>payload</code>, and <code>bid</code> to the relayer.</li>
<li>The relayer checks the validity (the <code>bid</code> is correct, the <code>payload</code> does not contain invalid transactions, etc), stores the <code>payload</code>, and then sends the <code>header</code> and <code>bid</code> to the proposer.</li>
<li>The proposer selects the header with the highest bid, signs it, and then sends the signed header to the relayer.</li>
<li>The relayer propagates the signed header and corresponding payload to the network.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#protocol-description-5" name="protocol-description-5"></a>Protocol Description</h2>
<p>In this section, we describe the MR-MEV-Boost protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#protocol-flow-overview-6" name="protocol-flow-overview-6"></a>Protocol Flow Overview</h3>
<p>To incentivize proposers to provide preconfirmations, we introduce a <em>preconf transaction</em>, where the payment of a <em>preconf tip</em> is conditioned on being preconfirmed. It will include the following information on top of the transaction payload itself:</p>
<ul>
<li><code>tip</code>: The preconfirmation tip paid for being preconfirmed.</li>
<li><code>target_slot</code>: The latest slot in which the preconf transaction can be included.</li>
<li><code>target_round</code>: The latest round within the <code>target_slot</code> in which the preconf transaction can be included.</li>
</ul>
<p>The <a href="https://ethresear.ch#preconf-transaction">Preconf Transaction</a> section will discuss the encoding and enforcement of these conditions.</p>
<p>Using this new transaction type, MR-MEV-Boost works as follows:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/a/7a4dc3f4c38b4184016390e2e48dc44e5630da74.png" title="MR-MEV-Boost"><img alt="MR-MEV-Boost" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/a/7a4dc3f4c38b4184016390e2e48dc44e5630da74_2_252x500.png" width="252" /></a></div><p></p>
<ol>
<li>Users submit preconf transactions to the builders. The submission can be through any order flow pipeline used in current L1, such as:
<ul>
<li>Public mempool.</li>
<li>Private order flow.</li>
<li>Order flow auctions on <a href="https://mevblocker.io/" rel="noopener nofollow ugc">MEVBlocker</a>, <a href="https://docs.flashbots.net/flashbots-protect/mev-share" rel="noopener nofollow ugc">MEV-Share</a>, <a href="https://writings.flashbots.net/the-future-of-mev-is-suave" rel="noopener nofollow ugc">SUAVE</a>, etc.</li>
</ul>
</li>
<li>The builders build <code>partial_payload</code>s. The partial payload built by the builders should only include preconf transactions with <code>target_slot</code> and <code>target_round</code> at or after the current block/round. To commit to this, the builder signs the <code>merkle_root</code> (denoted as <code>sig_b</code> ) and becomes subject to builder slashing condition 1, described in the <a href="https://ethresear.ch#slashing-conditions">slashing condition section</a>.</li>
<li>The relayer checks the validity (e.g., the <code>bid</code> is correct, the <code>partial_payload</code> does not contain invalid transactions, etc.), stores the <code>partial_payload</code>, and then sends the <code>merkle_root</code> and <code>bid</code> to the proposer.</li>
<li>Proposer signs (denoted as <code>sig_p</code>) and returns the selected <code>merkle_root</code> together with the current <code>round</code>.</li>
<li>The relay publishes the selected <code>partial_payload</code> and the associated round and signatures to the preconf network. Note that the preconf network is different from the existing L1 p2p network. Only entities interested in the preconfirmed state (partial block builders, relays, full-node providers, etc.) must subscribe to the preconf network.</li>
<li>End users—or, more precisely, the L2/L1 full nodes to which they are connected—verify that the <code>merkle_root</code> is signed by the proposer and is associated with the current <code>round</code>. Upon confirmation, they accept the <code>partial_payload</code> as preconfirmed and execute it to update to the latest preconfirmed state.</li>
<li>
<ol>
<li>to 6. is repeated multiple rounds within the slot. The number of rounds within each slot will be fixed. The final round will run concurrently with the full block MEV-Boost auction at 8.-11.</li>
</ol>
</li>
<li>to 11. The MEV-Boost auction is conducted for the full block. An important difference with the usual L1 MEV-Boost auction is that the <code>merkle_proofs</code> are propagated from the builder to the proposer. These proofs prove that the <code>partial_payload</code>s are included in the full block in the order they were preconfirmed without any other transaction being inserted before or between them. By validating these proofs, the proposer can ensure that the proposer slashing condition 2, described in the <a href="https://ethresear.ch#slashing-conditions">slashing conditions section</a>, is not violated without needing to trust the relayer (h/t to <a href="https://twitter.com/Brechtpd" rel="noopener nofollow ugc">Brecht</a> for the idea of using Merkle proofs here).</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#preconf-transaction-7" name="preconf-transaction-7"></a>Preconf Transaction</h3>
<p>Let’s consider the encoding of the preconf transactions. For L2s, the additional fields can be introduced as custom encodings of the transactions. For L1, they can be implemented through an <a href="https://eips.ethereum.org/EIPS/eip-4337" rel="noopener nofollow ugc">ERC-4337</a>-style entry point contract that wraps the contract calls with additional information.</p>
<p>To enforce the expiration, the L2 execution layer (or <a href="https://github.com/ethereum-optimism/specs/blob/b1c9b7985b65bd2d065a414f5ad0552f36e48540/specs/protocol/derivation.md#deriving-the-transaction-list" rel="noopener nofollow ugc">derivation layer</a>) and L1 entry point contract will filter out preconf transactions with expired <code>target_slot</code>. On the other hand, since the L1 is unaware of the concept of rounds, expiration based on <code>target_round</code> will be enforced via builder slashing condition 1, explained in the next section.</p>
<h3><a class="anchor" href="https://ethresear.ch#slashing-conditions-8" name="slashing-conditions-8"></a>Slashing Conditions</h3>
<p>To ensure that the full block matches with the preconfed partial blocks, the proposer will be subject to:</p>
<ul>
<li><strong>Proposer slashing condition 1</strong>: The proposer must not sign two conflicting <code>merkle_root</code>s within the same round.</li>
<li><strong>Proposer slashing condition 2</strong>: The final <code>full_payload</code> should contain all the <code>partial_payload</code>s in the order they are signed and published without any other transaction being inserted before or in between.</li>
</ul>
<p>Furthermore, to crypto-economically enforce the expiration of preconf transactions, the builder will be subject to:</p>
<ul>
<li><strong>Builder slashing condition 1:</strong> Each <code>partial_payload</code> must only include preconf transactions with <code>target_slot</code> and <code>target_round</code> at or after the current slot/round.</li>
</ul>
<p>We impose this condition on the builder rather than the proposer because the proposer does not see the partial payload when signing. An alternative approach would be to make this a proposer slashing condition and require the relayer to ensure the condition is not violated. However, this would necessitate the proposer trusting the relayer to avoid being slashed rather than only relying on the relayer to avoid missing a slot, as is currently done in L1 MEV-Boost.</p>
<h3><a class="anchor" href="https://ethresear.ch#user-actions-9" name="user-actions-9"></a>User Actions</h3>
<p>To mitigate the <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695#problem-4-fair-exchange-7">fair exchange problem</a>, wallets or full nodes to which end users are connected should take the actions below:</p>
<ul>
<li><strong>User action 1</strong>: Stop submitting preconf transactions if preconfirmed <code>partial_payload</code>s are not published in a timely manner. For example, if we have 4 rounds in a slot, then stop submitting preconf transactions if a <code>partial_payload</code> is not published every 3 seconds.</li>
<li><strong>User action 2</strong>: Set <code>target_slot</code> and <code>target_round</code> to a reasonably close block and round (e.g., one or two rounds ahead). By doing so, builders are required to respond in a timely manner to preconfirmation transactions to avoid the preconfirmation transactions being invalidated.</li>
</ul>
<p>More on how the fair exchange is addressed is described in the <a href="https://ethresear.ch#analysis">analysis section</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#l1-l2-composability-10" name="l1-l2-composability-10"></a>L1-L2 Composability</h3>
<p>Since the partial payloads can contain both L1 and L2 transactions, builders can ensure L1-L2 composability by including L1-L2 transaction bundles in the partial payloads.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-opted-in-slots-11" name="non-opted-in-slots-11"></a>Non-opted-in Slots</h3>
<p>When the current L1 slot’s proposer has not opted in as a preconfer, L1 transactions will be proposed by the current proposer, while L2 transactions will be proposed by the next opted-in preconfer in the lookahead (we follow Justin’s <a href="https://ethresear.ch/t/based-preconfirmations/17353#:~:text=proposer%20lookahead%E2%80%94higher%20precedence%20for%20smaller%20slot%20numbers">original based preconfirmation design</a> here). This results in two simultaneous MEV-Boost auctions: the usual L1 MEV-Boost auction signed by the current L1 proposer and the MR-MEV-Boost auction signed by the next preconfer. As a result, L1-L2 composability and L1 preconfirmation will be lost during these non-opted-in slots. Note that this limitation applies to all off-protocol preconfirmation designs.</p>
<h1><a class="anchor" href="https://ethresear.ch#analysis-12" name="analysis-12"></a>Analysis</h1>
<p>In this section, we will perform an initial analysis of the proposed protocol and identify its drawbacks.</p>
<h3><a class="anchor" href="https://ethresear.ch#have-we-solved-the-problems-13" name="have-we-solved-the-problems-13"></a>Have we solved the problems?</h3>
<p>Let’s revisit the problems raised in the <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695">Strawmanning Based Preconfirmations</a> post and see if and how MR-MEV-Boost addresses them.</p>
<p><strong>Problem 1: Latency race</strong></p>
<p>Latency races are when searchers fight to be the first to access the preconfer, leading to colocation or vertical integration. With MR-MEV-Boost, this issue is largely mitigated by preconfirming batches and conducting auctions within the batch, as it promotes competition based on price rather than speed. It is generally acknowledged that batch auctions help reduce latency wars compared to continuous first-come, first-served ordering, as described in <a href="https://academic.oup.com/qje/article/130/4/1547/1916146" rel="noopener nofollow ugc">this paper</a> and <a href="https://ethresear.ch/t/latency-arms-race-concerns-in-blockspace-markets/14957">this post</a>.</p>
<p><strong>Problem 2: Congestion</strong></p>
<p>Congestion issues arise when searchers flood the rollup with probabilistic arbitrage attempts. With MR-MEV-Boost, this issue is mitigated as searchers are incentivized to participate in auctions rather than resort to spam.</p>
<p><strong>Problem 3: Tip pricing</strong></p>
<p>The MEV-Boost auction will handle the tip pricing of the preconfirmation. Furthermore, by introducing batching and auctions within the batch, proposers can price the preconfirmation tips more effectively (hence capturing revenue) than by providing a continuous stream of per-transaction preconfirmations.</p>
<p><strong>Problem 4: Fair exchange</strong></p>
<p>Let’s see how MR-MEV-Boost addresses the <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695#problem-3-tip-pricing-6">fair exchange problem</a>, where the proposer withholds publishing preconfirmations to the user. Note that preconfers are incentivized to withhold preconf promises as much as possible to maximize their opportunity to reorder and insert transactions, thereby increasing their MEV.</p>
<p>There are two cases to consider:</p>
<ul>
<li>If the proposer withholds preconfirming partial payload (i.e., stops signing <code>merkle_root</code>s of <code>partial_payload</code>s), users will stop sending preconfirmation requests (user action 1), reducing the proposer’s order flow and, consequently, revenue.</li>
<li>If the proposer intentionally publishes empty partial payloads, pending preconf transactions will expire after a few rounds (user action 2 and builder slashing condition 1), reducing the proposer’s order flow and, consequently, revenue.</li>
</ul>
<p>In summary, end users monitor and enforce proposers’ honest behavior by linking the proposers’ revenue to the timely preconfirmation of partial payloads.</p>
<p>A potential alternative would be to introduce a committee to monitor and attest to the timely releases of partial payloads. However, this would require additional trust assumption to an external committee unless we enshrine the protocol into the L1. More on enshrinement in the <a href="https://ethresear.ch#future-direction">future direction section</a>.</p>
<p><strong>Problem 5: Liveness</strong></p>
<p>With existing based preconfirmation designs where preconfirmation duties are delegated ahead of the slot, liveness relies on this single external entity for the duration of the preconfer’s slot(s). On the other hand, with MR-MEV-Boost, liveness concerns are reduced as we do not introduce such “lock-in” to a specific entity before the slot. If some builders or relayers are unavailable, others can step in to maintain functionality. Moreover, even if the entire multi-round MEV-Boost pipeline fails, proposers still have the option to construct their own partial blocks and preconfirm them independently.</p>
<p><strong>Problem 6: Early auctions</strong></p>
<p>Early auctions are not introduced as preconfirmations are provided through the MEV-Boost JIT auctions.</p>
<h2><a class="anchor" href="https://ethresear.ch#round-interval-14" name="round-interval-14"></a>Round Interval</h2>
<p>How short can each round in MR-MEV-Boost be? If it is too long, it will degrade the user experience; if it is too short, it will impose excessive network and hardware requirements on builders and relays, thus hurting decentralization.</p>
<p>In each round, the relayer has two tasks:</p>
<ul>
<li>(A) Run the partial block auction.</li>
<li>(B) Propagate the partial block.</li>
</ul>
<p>Task (A) consists of the time it takes the builder to construct the block, the time it takes the relay to validate the block, and two network round-trips: one between the builder and the relay and another between the relay and the proposer. Assuming that <a href="https://x.com/SheaKetsdever/status/1808509437700665543" rel="noopener nofollow ugc">block construction</a>, validation, and network round-trips take 500 milliseconds each, we get a ballpark estimate of 2 seconds.</p>
<p>For task (B), considering L1 allocates 4 seconds for block propagation and 8 seconds for consensus, and no consensus is needed for partial blocks, a good upper bound for propagation time is 4 seconds. In practice, it should be much shorter because only block builders, relays, and full-node providers need to receive these partial blocks, and they have better network bandwidth and lower latency than average validators. Let’s assume 1-2 seconds for this analysis.</p>
<p>Combining 2 seconds for (A) and 1-2 seconds for (B) gives us 3-4 seconds per round.</p>
<p>These estimates are highly approximate, and further research and analysis are needed. Additionally, making the interval too short will intensify latency races toward the end of the batch duration, as described <a href="https://ethresear.ch/t/latency-arms-race-concerns-in-blockspace-markets/14957#auction-designs-for-transaction-ordering-2">here</a>, and should be considered.</p>
<h2><a class="anchor" href="https://ethresear.ch#drawbacks-15" name="drawbacks-15"></a>Drawbacks</h2>
<p>Next, we will outline the drawbacks of this protocol when compared to existing based preconfirmation designs, such as the one described in the <a href="https://ethresear.ch/t/based-preconfirmations/17353">original post</a>. An analysis of more general drawbacks of preconfirmations will be reserved for future work.</p>
<h3><a class="anchor" href="https://ethresear.ch#no-speed-of-light-continuous-preconfirmations-16" name="no-speed-of-light-continuous-preconfirmations-16"></a>No Speed-of-light Continuous Preconfirmations</h3>
<p>MR-MEV-Boost does not provide speed-of-light preconfirmations with hundreds of milliseconds latency, like <a href="https://docs.arbitrum.io/how-arbitrum-works/sequencer" rel="noopener nofollow ugc">Arbitrum’s first-come-first-serve sequencer</a>. Instead, it offers preconfirmations in batches with a few seconds of latency between them, similar to <a href="https://docs.optimism.io/connect/resources/glossary#time-slot" rel="noopener nofollow ugc">Optimism’s approach</a>.</p>
<p><a href="https://solana.com/" rel="noopener nofollow ugc">Solana</a> and <a href="https://www.jito.wtf/" rel="noopener nofollow ugc">Jito</a> provide an interesting case study on continuous versus batched preconfirmations. In Solana’s “continuous block building,” the leader streams (i.e., preconfirms) processed transactions continuously. Combined with Solana’s fixed low fee, continuous block building led to network spamming and latency races, causing validators to <a href="https://www.jito.network/blog/solving-the-mev-problem-on-solana-a-guide-for-stakers/" rel="noopener nofollow ugc">waste 58% of their time processing failed arbitrages</a>. Jito addressed this by introducing a 200ms “speed bump” (batches) and a mev-geth style bundle auction for batches, achieving an 80% share with their Jito validator client. This example indicates that that continuous preconfirmations are likely unsustainable due to spam and that batching and some auction for each batch are required. For more details, watch this informative talk by Zano Sherwani, co-founder of Jito, <a href="https://www.youtube.com/watch?v=c-O_JZI2QAA" rel="noopener nofollow ugc">here</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#relay-burden-17" name="relay-burden-17"></a>Relay Burden</h3>
<p>MR-MEV-Boost introduces additional burdens to the relays without incentives. Instead of managing a single round of MEV-Boost auctions, relayers must handle multiple rounds within a single slot, each within a limited timeframe. If the cost of operating a relayer increases too much, it may lead to further relayer centralization and <a href="https://collective.flashbots.net/t/builderelay/2688/1" rel="noopener nofollow ugc">builder-relay integration</a>, or alternatively, no relayer may opt to support MR-MEV-Boost. Relayer incentives are a <a href="https://www.gate.io/learn/articles/the-pursuit-of-relay-incentivization/1257" rel="noopener nofollow ugc">long-lasting problem</a> in L1, and MR-MEV-Boost likely worsen this situation.</p>
<p>One way to mitigate the issue is to incorporate <a href="https://frontier.tech/optimistic-relays-and-where-to-find-them" rel="noopener nofollow ugc">optimistic relay</a> schemes to reduce the relayer’s operational costs. With this approach, relayers optimistically assume the honesty of the block-builder and skip the validation work for payloads sent from the builder. If the builder is later found to deviate from honest behavior, their collateral will be used to refund the proposer. Optimistic relaying would be especially helpful as it allows relayers to bypass the need to validate the based rollup transactions when verifying partial blocks.</p>
<p>Another potential solution is for the proposers to share the preconfirmation tip revenue with the relay to compensate for the additional workload.</p>
<h3><a class="anchor" href="https://ethresear.ch#blob-efficiency-18" name="blob-efficiency-18"></a>Blob Efficiency</h3>
<p>So far, we have blurred the line between L1 and L2 preconfirmations. This is somewhat intentional, as L2 transactions are included within L1 transactions. However, there are cases where the difference becomes important.</p>
<p>Consider a scenario where the L2 transactions within a round cannot fill an entire blob. If we only support preconfirmations for L2 transactions by preconfirming the L1 transactions that contain them, we face a problem. Proposers would either have to preconfirm partially filled blob transactions at the end of the round or wait for another round to collect enough transactions to fill the blob.</p>
<p>One solution is to allow proposers to commit to a batch of L2 transactions without linking them to a specific L1 transaction. This would let the builder of the final full block aggregate the L2 transactions into one or more L1 blobs at the end of the slot.</p>
<h3><a class="anchor" href="https://ethresear.ch#issues-with-mev-boost-19" name="issues-with-mev-boost-19"></a>Issues with MEV-Boost</h3>
<p>MR-MEV-Boost inherits the existing L1 MEV-Boost pipeline, which also means that we inherit many of MEV-Boost’s downsides, such as <a href="https://arxiv.org/pdf/2305.19037" rel="noopener nofollow ugc">reliance on a handful of relays and builders</a>. However, based rollups aim to inherit the security of L1, not to exceed it. Therefore, being “as bad as” L1 is the best we can do as a based solution.</p>
<h1><a class="anchor" href="https://ethresear.ch#future-direction-20" name="future-direction-20"></a>Future Direction</h1>
<p>MR-MEV-Boost can be generalized as <em>partial-block preconfirmations</em>, where the proposer incrementally builds the block by committing to and publishing partial blocks during their slot.</p>
<p>One future direction would be to enshrine partial-block preconfirmations into the L1 protocol to achieve faster block times. This aligns with Vitalik’s <a href="https://vitalik.eth.limo/general/2024/06/30/epochslot.html" rel="noopener nofollow ugc">recent post</a> and offers several benefits over off-protocol designs like MR-MEV-Boost:</p>
<ul>
<li>Removes “non-opted-in” proposers, enabling L1 preconfirmations and L1-L2 composability for all slots.</li>
<li>Fully utilizes Ethereum’s validator set, potentially introducing lightweight <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054">PTC</a>-like attestations for timely partial payload releases.</li>
<li>Opens doors to increase the block times without degrading UX, which may help enable <a href="https://ethereum.org/en/roadmap/single-slot-finality/" rel="noopener nofollow ugc">single-slot finality</a>.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#related-work-21" name="related-work-21"></a>Related Work</h1>
<p>In his <a href="https://dba.xyz/were-all-building-the-same-thing/" rel="noopener nofollow ugc">latest post</a>, Jon Charbonneau explains in great detail how based rollups/preconfirmations work and the centralization risk of based preconfirmations.</p>
<p>Furthermore, partial-block preconfirmations are closely related to <a href="https://ethresear.ch/t/how-much-can-we-constrain-builders-without-bringing-back-heavy-burdens-to-proposers/13808">inclusion list</a> research, as both can be viewed under the broader concept of “partial-block building,” where different parts of a block are constructed at different times by different entities. For example, the <a href="https://research.eigenlayer.xyz/t/mev-boost-liveness-first-relay-design/15" rel="noopener nofollow ugc">MEV-Boost++ proposal</a> from Kyodo (EigenLayer) resembles MR-MEV-Boost, as both enable early commitment to partial blocks by imposing additional slashing conditions on the proposer.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-22" name="conclusion-22"></a>Conclusion</h1>
<p>We introduce MR-MEV-Boost, a design that enables based preconfirmations by running multiple rounds of MEV-Boost auctions within a single slot. By inheriting the L1 PBS pipeline, MR-MEV-Boost mitigates many of the negative externalities of based preconfirmations while retaining the benefits of based rollups.</p>
<p>At <a href="https://switchboard.nethermind.io/" rel="noopener nofollow ugc">Nethermind Switchboard</a>, we actively research and tackle the open challenges of based preconfirmations. We are also collaborating closely with Taiko to develop <a href="https://github.com/NethermindEth/Taiko-Preconf-AVS/blob/6b21d85d329986a2a9725048e56be3a45d463dcc/Docs/design-doc.md" rel="noopener nofollow ugc">a PoC for based preconfirmations</a> compatible with L2 PBS, including MR-MEV-Boost. Stay tuned for more updates!</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 18 Jul 2024 06:47:13 +0000</pubDate>
</item>
<item>
<title>A Note On Securely Finding Minimum Mean Cycle</title>
<link>https://ethresear.ch/t/a-note-on-securely-finding-minimum-mean-cycle/20073</link>
<guid>https://ethresear.ch/t/a-note-on-securely-finding-minimum-mean-cycle/20073</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、Minimum Mean Cycle (MMC)、Multi-Party Computation (MPC)、Karp算法、Chaturvedi-McConnell方法

总结:
本文研究了在执行图优化算法，如Minimum Mean Cycle (MMC)，同时保护用户和公司之间敏感信息的问题。先前的工作中，Aly等人的方法基于Karp算法，但存在周期检测问题。作者提出了一种改进的协议，解决了这个问题并提高了效率。新协议使用MP-SPDZ实现，时间复杂度从O(|V|^5)降低到O(|V|^3)，空间复杂度从O(|V|^4)减小到O(|V|^2)。研究着重于在保证隐私的同时，提高MM <div>
<p>This study is supported by an Ethereum Foundation R&amp;D grant and is a collaborative work with Enrico ( <a class="mention" href="https://ethresear.ch/u/enricobottazzi">@enricobottazzi</a> ), Masato ( <a class="mention" href="https://ethresear.ch/u/0xvon">@0xvon</a> ) and Nam ( <a class="inline-onebox" href="https://github.com/namnc" rel="noopener nofollow ugc">namnc (Nam Ngo) · GitHub</a> ) from Ethereum Foundation.</p>
<p><strong>Abstract</strong></p>
<p>Executing graph optimization algorithms such as the Minimum Mean Cycle (MMC) while preserving privacy has significant potential for handling sensitive information between users and companies. For example, it enables multilateral netting to solve the Minimum Cost Flow (MCF) problem without disclosing mutual debts, making it highly relevant for processes like netting among multinational corporations. Aly et. al. [2] proposed an algorithm using Multi-Party Computation (MPC) to execute the MMC problem. However, this approach is based on Karp’s algorithm [1], which was found by Chaturvedi et al. [3] to occasionally fail to detect cycles. In this study, we propose a revised protocol that corrects this issue and enhances its efficiency. We implemented our protocol using MP-SPDZ and confirmed that it correctly identifies the MMC, similar to traditional protocols. Our findings indicate that our proposed protocol operates correctly and more efficiently than Aly’s protocol, which reduces the time/round complexity from <span class="math">O(|V|^5)</span> to <span class="math">O(|V|^3)</span> and the space complexity from <span class="math">O(|V|^4)</span> to <span class="math">O(|V|^2)</span>. Furthermore, we discuss potential improvements for even more efficient algorithms.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-1-introduction-1" name="h-1-introduction-1"></a>1. Introduction</h1>
<h3><a class="anchor" href="https://ethresear.ch#h-1-1-importance-of-graph-theory-optimization-2" name="h-1-1-importance-of-graph-theory-optimization-2"></a>1-1. Importance of Graph Theory Optimization</h3>
<p>Graph theory optimization problems play a crucial role in various domains, from computer science and engineering to economics and finance. These problems involve finding the most efficient way to navigate, connect, or utilize network structures, and solutions to these problems have far-reaching implications for improving systems and processes.</p>
<p>One of the representative problems in graph theory optimization is the Minimum Cost Flow (MCF) problem, which aims to find the least costly way to send a certain amount of flow through a network. The MCF problem is foundational in numerous applications, providing critical insights and optimizations.</p>
<p>In the financial sector, particularly in Netting, the Minimum Cost Flow (MCF) problem is often addressed to optimize the settlement of transactions and reduce systemic risk. Netting involves aggregating multiple financial obligations to streamline transactions, minimize risk, and enhance efficiency. However, one of the critical challenges in this context is maintaining the privacy and confidentiality of sensitive financial data. Traditional methods for solving the MCF problem may require exposing transaction details, leading to significant privacy concerns and potential security risks.</p>
<p>Beyond netting, the MMC problem and its solutions have a wide array of applications across various fields:</p>
<ul>
<li><strong>Network Security:</strong> Enhancing security measures by optimizing the flow of information and resources while minimizing potential points of vulnerability.</li>
<li><strong>Supply Chain Management</strong>: Streamlining logistics and distribution networks to reduce costs and improve delivery times.</li>
<li><strong>Urban Planning</strong>: Developing efficient transportation systems by optimizing traffic flow and reducing congestion.</li>
</ul>
<p>The Minimum Mean Cycle (MMC) problem is a crucial component in solving the MCF problem. The MMC problem focuses on identifying cycles in directed graphs with the minimum average weight, which is essential for detecting inefficient paths and optimizing network performance. By incorporating the MMC problem into the solution of the MCF problem, we can achieve more accurate and efficient outcomes.</p>
<p>To address the privacy concerns inherent in solving the MCF problem, we explore the use of Multi-Party Computation (MPC) to securely solve the MMC problem. MPC is a cryptographic approach that allows multiple parties to collaboratively compute a function over their inputs while keeping those inputs private. By applying MPC techniques, we can solve the MMC problem without exposing sensitive data, thus preserving the privacy of financial transactions and other confidential information.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-1-2-previous-work-3" name="h-1-2-previous-work-3"></a>1-2. Previous Work</h3>
<p>Aly et al. [2] proposed a method to solve Karp’s MMC algorithm [1] using Multi-Party Computation. However, this approach has some problems and suffers from significant computational complexity and time consumption. Additionally, the Karp’s algorithm [1] was found by Chaturvedi et al . [3] to occasionally fail to detect cycles.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-1-3-our-contribution-4" name="h-1-3-our-contribution-4"></a>1-3. Our Contribution</h3>
<p>in this study, we propose a novel approach that not only addresses these shortcomings but also offers a more efficient and practical solution for securely solving the MMC problem using MPC. Our proposed protocol aims to reduce computational and time complexities, enhance cycle detection accuracy, and ensure robust privacy protection. Our experimental results demonstrate a significant improvement in efficiency, with a reduction in time complexity from <span class="math">O(|V|^5)</span> to <span class="math">O(|V|^3)</span> and space complexity from <span class="math">O(|V|^4)</span> to <span class="math">O(|V|^2)</span>.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-2-minimum-mean-cycle-problem-5" name="h-2-minimum-mean-cycle-problem-5"></a>2. Minimum Mean Cycle Problem</h1>
<p>Minimum Mean Cycle Problem and its solution is defined by Karp in 1978 [1].</p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-1-problem-definition-6" name="h-2-1-problem-definition-6"></a>2-1. Problem Definition</h3>
<p>Given a connected graph <span class="math">G(V,E)</span> where <span class="math">V</span> is a set of nodes and <span class="math">E</span> is a set of edges, with defining these parameters:</p>
<ul>
<li><span class="math">c_{i,j} \in C</span> denotes the <strong>cost</strong> on the edge <span class="math">(i,j)</span>.</li>
<li><span class="math">d^k(i)</span> denotes the minimum cost from node <span class="math">s</span> to <span class="math">i</span> that contains exactly <span class="math">k</span> edges.</li>
</ul>
<p>First of all, for any cycle <span class="math">X</span>, the mean cycle is defined by:</p>
<div class="math">
\begin{equation}
\mu (X) = \frac{\sum_{uv \in X} c_{uv}}{|X|}
\end{equation}
</div>
<p>Thus, the minimum mean cycle is:</p>
<div class="math">
\begin{equation}
\mu ^* = \min_{cycle X} \mu (X)
\end{equation}
</div>
<p>Minimum Mean Cycle (MMC) Problem is the problem to find this <span class="math">\mu ^*</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-2-efficient-mmc-7" name="h-2-2-efficient-mmc-7"></a>2-2. Efficient MMC</h3>
<p>The MMC problem is known as NP-hard, and Karp introduces an efficient algorithm for solving it. The solution is followed by 2 steps.</p>
<p>The first step, we call it as <strong>Walk</strong>, is to calculates <span class="math">d^k(i)</span>, which denotes minimum cost from node <span class="math">s</span> to <span class="math">i</span> that contains exactly <span class="math">k</span> edges. Walk can be computed via the recurrence:</p>
<div class="math">
\begin{equation}
d^k(j) = \min_{(i,j) \in E} d^{k-1}(i)+c_{ij}
\end{equation}
</div>
<p>Initially, <span class="math">d^0(j)=\infty</span>, except for the source node <span class="math">d^0(s)=0</span></p>
<p>The second step is to calculate the minimum mean cycle by:</p>
<div class="math">
\begin{equation}
\mu^* = \min_{j \in V} \max_{0 \leq k \leq |V|-1} \left[ \frac{d^V(j) - d^k(j)}{|V| - k} \right]
\end{equation}
</div>
<p>See Karp’s paper [1] for a proof of equation (4). Overall algorithmic complexity is <span class="math">O(|V| \cdot |E|)</span>, and the first step has a significant impact on the entire algorithm.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-3-alys-secure-mmc-protocol-8" name="h-3-alys-secure-mmc-protocol-8"></a>3. Aly’s Secure MMC Protocol</h1>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math">[a]</span> denotes secret shared or encrypted values of <span class="math">a</span></li>
<li><span class="math">[z] = _{[c]} [x]:[y]</span> denotes the assignment that if <span class="math">[c]</span> is one, <span class="math">[x]</span> is assigned to <span class="math">[z]</span> or <span class="math">[y]</span> otherwise.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-3-1-protocol-9" name="h-3-1-protocol-9"></a>3-1. Protocol</h3>
<p>Aly et. al. [2] provide algorithmic solutions to MMC problem in a secure multi-party and distributed setting. This protocol is constructed by 2 sub-protocols:</p>
<ol>
<li><span class="math">walk([C],[b]) \rightarrow [A],[walks]</span></li>
<li><span class="math">mmc([A],[walks]) \rightarrow [\text{min-cost}], [\text{min-cycle}]</span></li>
</ol>
<p>This corresponds to Steps 1 and 2 of Karp’s Algorithm in section 2.</p>
<p>In first sub-protocol, we have two inputs. The cost matrix <span class="math">[C]_{ij}</span> denotes the cost of edge <span class="math">(i,j)</span>. It represents <span class="math">[\infty]</span> for non-existing edges. The viable matrix <span class="math">[b]_{ij}</span> denotes 1 if edge <span class="math">(i,j)</span> doesn’t exist, and 0 otherwise.</p>
<p>From these inputs, we outputs two values. One is the 2-dimensional walk cost matrix <span class="math">[A]</span> which <span class="math">[A]_{jk}</span> records <span class="math">d^k(j)</span>. The other is 4-dimensional walk path matrix <span class="math">[walks]</span> which <span class="math">[walks]_{ijkl}</span> records the number of times the edge <span class="math">(i,j)</span> is traversed by the shortest walk of length <span class="math">k</span> from <span class="math">s</span> to <span class="math">l</span>. The algorithm is detailed as Protocol 3-1.</p>
<hr />
<p><strong>Protocol 3-1. Aly’s Walk Protocol</strong></p>
<hr />
<p><strong>Input</strong>: A matrix of shared costs <span class="math">[C]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>, a binary matrix on viable adges <span class="math">[b]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,1,...,|V|\}</span>, a wak matrix <span class="math">[walks]_{ijkl}</span> for <span class="math">i,j,k,l \in \{1,2,...,|V|\}</span> encoding these walks.</p>
<ol>
<li><span class="math">[A] \leftarrow [\infty], [A]_{00} \leftarrow [0], [C] \leftarrow [C] + [\infty](1-[b])</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow 1</span> to <span class="math">|V|+1</span> do
<ol>
<li><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><strong>for</strong> <span class="math">i \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><span class="math">[c] \leftarrow [A]_{ik-1} + [C]_{ij} &lt; [A]_{jk}</span></li>
<li><span class="math">[A]_{jk} \leftarrow _{[c]} [A]_{ik-1} + [C]_{ij} : [A]_{jk}</span></li>
<li><span class="math">[walks]_{..kj} \leftarrow _{[c]} [walks]_{..k-1i} : [walks]_{..kj}</span></li>
<li><span class="math">[walks]_{ijkj} \leftarrow _{[c]} [walks]_{ijkj} + 1 : [walks]_{ijkj}</span></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
<hr />
<p>In second sub-protocol, we have two outputs. <span class="math">[\text{min-cost}]</span> is the minimum mean cost. <span class="math">[\text{min-cycle}]</span> denotes the 2-dimensional cycle matrix which <span class="math">[\text{min-cycle}]_{jk}</span> is 1 if edge <span class="math">(j,k)</span> is included in the cycle achieving <span class="math">\mu ^*</span> and 0 otherwise. Here, <span class="math">\text{min-cycle}</span> is s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span>, minus the s-j path with k edges whose cost is <span class="math">d^{k}(j)</span>. The details are provided as protocol 3-2. We note that we use the theorem that <span class="math">\frac{a}{b}&gt;\frac{c}{d} \iff ad&gt;bc</span> to make a comparison of <span class="math">\frac{d^V(j) - d^k(j)}{|V| - k}</span> without calculating the inverse.</p>
<hr />
<p><strong>Protocol 3-2. Aly’s MMC Protocol</strong></p>
<hr />
<p><strong>Input:</strong> A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,2,...,|V|\}</span>, a walk matrix <span class="math">[walks]_{ijkl}</span> for <span class="math">i,j,k,l \in \{1,2,...,|V|\}</span> encoding these walks.</p>
<p><strong>Output</strong>: The cost of the minimum mean cycle <span class="math">[\text{min-cost}]</span>, a matrix with the minimum mean cycle <span class="math">[\text{min-cycle}]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span></p>
<ol>
<li>
<p><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do</p>
<ol>
<li><span class="math">[\text{max-cycle}],[\text{max-cost}] \leftarrow \phi</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do
<ol>
<li><span class="math">[\text{a-num}] \leftarrow [A]_{j(|V|+1)} - [A]_{jk}</span></li>
<li><span class="math">[\text{a-den}] \leftarrow |V|-k</span></li>
<li><span class="math">[c] \leftarrow [\text{k-num}] \cdot [\text{a-den}] &lt; [\text{a-num}] \cdot [\text{k-den}]</span></li>
<li><span class="math">[\text{k-num}] \leftarrow _{[c]} [\text{a-num}]  : [\text{k-num}]</span></li>
<li><span class="math">[\text{k-den}] \leftarrow _{[c]} [\text{a-den}]  : [\text{k-den}]</span></li>
<li><span class="math">[\text{max-cycle}] \leftarrow _{[c]} [walks]_{..|V|j} - [walks]_{..kj} : [\text{max-cycle}]</span></li>
<li><span class="math">[\text{max-cost}] \leftarrow _{[c]} [A]_{jk} : [\text{max-cost}]</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><span class="math">[c] \leftarrow [\text{j-num}] \cdot [\text{k-den}] &lt; [\text{k-num}] \cdot [\text{j-den}]</span></li>
<li><span class="math">[\text{j-num}] \leftarrow _{[c]} [\text{k-num}]  : [\text{j-num}]</span></li>
<li><span class="math">[\text{j-den}] \leftarrow _{[c]} [\text{k-den}]  : [\text{j-den}]</span></li>
<li><span class="math">[\text{min-cycle}] \leftarrow _{[c]} [\text{max-cycle}] : [\text{min-cycle}]</span></li>
<li><span class="math">[\text{min-cost}] \leftarrow _{[c]} [\text{max-cost}] : [\text{min-cost}]</span></li>
</ol>
</li>
<li>
<p><strong>end</strong></p>
</li>
</ol>
<hr />
<p><strong>Complexity</strong></p>
<p>This method requires <span class="math">O(|V|^5)</span> time/round complexity, from the conditional assignments to <span class="math">|V| \times |V|</span> elements in <span class="math">[walks]</span> matrix for <span class="math">|V|^3</span> loops (line i-3~4 of Protocol 1). And this method requires <span class="math">O(|V|^4)</span> space complexity, due to 4-dimensional <span class="math">[walks]</span> matrix.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-2-problem-in-alys-protocol-10" name="h-3-2-problem-in-alys-protocol-10"></a>3-2. Problem in Aly’s Protocol</h3>
<p>Aly’s protocol implements Karp algorithm [1] in the secure manner. In karp’s alrogithm, we determine <span class="math">\text{min-cycle}</span> like s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span>, minus the s-j path with k edges whose cost is <span class="math">d^{k}(j)</span>. However, Chaturvedi and McConnell [3] provides an counterexample which the cycle couldn’t detected with this method. Furthermore, they prove the following lemma.</p>
<p><strong>Lemma 1</strong><br />
Let <span class="math">j</span> be a vertex such that there exists <span class="math">k</span>, where <span class="math">j</span> and <span class="math">k</span> are a minimizing pair. Every cycle on the length <span class="math">|V|</span> edge progression from <span class="math">s</span> to <span class="math">j</span> of cost <span class="math">d^{|V|}(j)</span> is a cycle of minimum mean cost. (See the proof on their paper [3].)</p>
<p>This lemma means that the cycle can be detected by traversing the edge progression from the last edge and marking the vertices visited by the walk until a previous marked vertex is encountered, from s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span>.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-4-cm-based-secure-mmc-protocol-11" name="h-4-cm-based-secure-mmc-protocol-11"></a>4. CM-based Secure MMC Protocol</h1>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math">[a]</span> denotes secret shared or encrypted values of <span class="math">a</span></li>
<li><span class="math">[z] = _{[c]} [x]:[y]</span> denotes the assignment that if <span class="math">[c]</span> is one, <span class="math">[x]</span> is assigned to <span class="math">[z]</span> or <span class="math">[y]</span> otherwise.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-4-1-protocol-12" name="h-4-1-protocol-12"></a>4-1. Protocol</h3>
<p>We propose a protocol that converts the minimum mean cycle detection from Aly’s protocol to one with Lemma1. In addition, a few changes have been made to the data structure. We name it “<strong>CM-based Securely MMC Protocol</strong>”, taking the initials of Chaturvedi and McConnell, who proposed Lemma 1.</p>
<p>CM-based protocol is constructed by 3 sub-protocols:</p>
<ol>
<li><span class="math">walk([C],[b]) \rightarrow [A],[ep]</span></li>
<li><span class="math">mmc</span>
<ol>
<li><span class="math">mmcn([A],[ep]) \rightarrow [\text{min-cost}],[\text{minimizing-node}]</span></li>
<li><span class="math">extract\text{-}cycle([\text{minimizing-node}],[ep]) \rightarrow [\text{min-cycle}]</span></li>
</ol>
</li>
</ol>
<p>Here, Aly’s second sub-protocol is divided into CM-based second and third sub-protocols.</p>
<p>In fist sub-protocol, For the most part, it is the same as Protocol 3-1, with one difference: Instead of <span class="math">[walks]</span>, we record the edge progression in a 2-dimensional matrix called <span class="math">[ep]</span>, which <span class="math">[ep]_{jk}</span> means the edge that passes before one of <span class="math">j</span> in the shortest s-j path with k edges. This change eliminates the need for extra <span class="math">|V|^2</span> loops to update <span class="math">[walks]_{..kj}</span>. The algorithm is detailed as Protocol 4-1.</p>
<hr />
<p><strong>Protocol 4-1. CM-based Walk Protocol</strong></p>
<hr />
<p><strong>Input</strong>: A matrix of shared costs <span class="math">[C]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>, a binary matrix on viable adges <span class="math">[b]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,1,...,|V|\}</span>, a matrix of walk edge progressions <span class="math">[ep]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<ol>
<li><span class="math">[A] \leftarrow [\infty], [A]_{00} \leftarrow [0], [C] \leftarrow [C] + [\infty](1-[b])</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow 1</span> to <span class="math">|V|+1</span> do
<ol>
<li><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><strong>for</strong> <span class="math">i \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><span class="math">[c] \leftarrow [A]_{ik-1} + [C]_{ij} &lt; [A]_{jk}</span></li>
<li><span class="math">[A]_{jk} \leftarrow _{[c]} [A]_{ik-1} + [C]_{ij} : [A]_{jk}</span></li>
<li><span class="math">[ep]_{jk} \leftarrow _{[c]} i : [ep]_{jk}</span></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
<hr />
<p>In (a) of the 2nd sub-protocol, instead of computing <span class="math">[\text{min-cycle}]</span>, we detect the node <span class="math">j</span> that achieves mmc. We call it minimizing node.</p>
<p>The algorithm is detailed as Protocol 4-2-a.</p>
<hr />
<p><strong>Protocol 4-2-a. CM-based MMCN Protocol</strong></p>
<hr />
<p><strong>Input:</strong> A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,2,...,|V|\}</span>, a matrix of walk progressions <span class="math">[ep]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: The cost of the minimum mean cycle <span class="math">[\text{min-cost}]</span>, the node achieving the minimum mean cycle <span class="math">[\text{minimizing-node}]</span>.</p>
<ol>
<li>
<p><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do</p>
<ol>
<li>
<p><span class="math">[\text{max-cost}] \leftarrow \phi</span></p>
</li>
<li>
<p><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do</p>
<ol>
<li><span class="math">[\text{a-num}] \leftarrow [A]_{j(|V|+1)} - [A]_{jk}</span></li>
<li><span class="math">[\text{a-den}] \leftarrow |V|-k</span></li>
<li><span class="math">[c] \leftarrow [\text{k-num}] \cdot [\text{a-den}] &lt; [\text{a-num}] \cdot [\text{k-den}]</span></li>
<li><span class="math">[\text{k-num}] \leftarrow _{[c]} [\text{a-num}]  : [\text{k-num}]</span></li>
<li><span class="math">[\text{k-den}] \leftarrow _{[c]} [\text{a-den}]  : [\text{k-den}]</span></li>
<li><span class="math">[\text{max-cost}] \leftarrow _{[c]} [A]_{jk} : [\text{max-cost}]</span></li>
</ol>
</li>
<li>
<p><strong>end</strong></p>
</li>
<li>
<p><span class="math">[c] \leftarrow [\text{j-num}] \cdot [\text{k-den}] &lt; [\text{k-num}] \cdot [\text{j-den}]</span></p>
</li>
<li>
<p><span class="math">[\text{j-num}] \leftarrow _{[c]} [\text{k-num}]  : [\text{j-num}]</span></p>
</li>
<li>
<p><span class="math">[\text{j-den}] \leftarrow _{[c]} [\text{k-den}]  : [\text{j-den}]</span></p>
</li>
<li>
<p><span class="math">[\text{minimizing-node}] \leftarrow _{[c]} j : [\text{minimizing-node}]</span></p>
</li>
<li>
<p><span class="math">[\text{min-cost}] \leftarrow _{[c]} [\text{max-cost}] : [\text{min-cost}]</span></p>
</li>
</ol>
</li>
<li>
<p><strong>end</strong></p>
</li>
</ol>
<hr />
<p>In (b) of the 2nd sub-protocol, from <span class="math">[\text{minimizing-node}]</span>, we construct a back pointer which indicates s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span> and extract a cycle from the back pointer. Compared to Protocol 3-2, instead of expanding <span class="math">[\text{min-cycle}]</span> directly from <span class="math">[walks]</span>, the additional protocol is required. We follow Lemma 1 and consider any cycle included in the back pointer as a minimum mean cycle. The algorithm is detailed as Protocol 4-2-b.</p>
<hr />
<p><strong>Protocol 4-2-b. CM-based Extract-Cycle Protocol</strong></p>
<hr />
<p><strong>Input:</strong> A minmizing node <span class="math">[\text{minimizing-node}]</span>, a matrix of walk progressions <span class="math">[ep]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: A matrix with the minimum mean cycle <span class="math">[\text{min-cycle}]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span></p>
<ol>
<li><span class="math">[\text{backpointers}]_{0} \leftarrow [\text{minimizing-node}]</span>, <span class="math">[\text{next-index}] \leftarrow [\text{minimizing-node}]</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do
<ol>
<li><span class="math">[\text{val}] \leftarrow [0]</span></li>
<li><strong>for</strong> <span class="math">j \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[match] = j == [\text{next-index}]</span></li>
<li><span class="math">[\text{val}] = _{[\text{match}]} [ep]_{jk}:[\text{val}]</span></li>
<li><span class="math">[\text{match-index-matrix}]_{jk} = [match]</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><span class="math">[\text{next-index}] = [\text{val}]</span></li>
<li><span class="math">[\text{backpointers}].append([\text{val}])</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><strong>for</strong> <span class="math">i \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[\text{counter}] \leftarrow [0]</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow 0</span> to <span class="math">|V|</span> do
<ol>
<li><span class="math">[\text{counter}] = [\text{counter}] + [\text{match-index-matrix}]_{ik}</span></li>
</ol>
</li>
<li><span class="math">[c] = [\text{counter}] &gt;= 2</span></li>
<li><span class="math">[\text{cycle-node}] = _{[c]} i : [\text{cycle-node}]</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><span class="math">[\text{min-cycle}] \leftarrow [0],[\text{counter}] \leftarrow [0]</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do
<ol>
<li><span class="math">[\text{edge-from}] \leftarrow [\text{backpointers}]_k</span></li>
<li><span class="math">[c] = [\text{edge-from}] [\text{cycle-node}]</span></li>
<li><span class="math">[\text{counter}] = [\text{counter}] + [c]</span></li>
<li><span class="math">[c_0] = [\text{counter}] + 1</span></li>
<li><strong>for</strong> <span class="math">j \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[c_1] = [\text{match-index-matrix}]_{jn-k}</span></li>
<li><span class="math">[c_2] = [c_0]*[c_1]</span></li>
<li><strong>for</strong> <span class="math">i \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[c_3] = [\text{match-index-matrix}]_{jn-k+1}</span></li>
<li><span class="math">[\text{min-cycle}]_{ji} = [\text{min-cycle}]_{ji} + ([c_2] * [c_3])</span></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
<hr />
<p><strong>Complexity</strong><br />
This ****method requires <span class="math">O(|V|^3)</span> multiplications or communication rounds, from the conditional assignments of <span class="math">[A],[ep],[\text{min-cycle}]</span> for <span class="math">|V|^3</span> loops (line i-2~3 of Protocol 4-1 and like iii-3 of Protocol 4-2-b). And this method requires <span class="math">O(|V|^2)</span> space complexity, largely due to 2-dimensional matrixes. A table comparing the Complexity of each protocol is shown in Table 4-1 below.</p>
<p><strong>Table 4-1. Complexity Analysis of Secure MMC Protocols</strong></p>
<div class="md-table">
<table>
<thead>
<tr>
<th></th>
<th>multiplications/communication rounds complexity</th>
<th>space complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td>Aly’s</td>
<td><span class="math">O(|V|^5)</span></td>
<td><span class="math">O(|V|^4)</span></td>
</tr>
<tr>
<td>CM-based</td>
<td><span class="math">O(|V|^3)</span></td>
<td><span class="math">O(|V|^2)</span></td>
</tr>
</tbody>
</table>
</div><h3><a class="anchor" href="https://ethresear.ch#h-4-2-implementation-13" name="h-4-2-implementation-13"></a>4-2. Implementation</h3>
<p>We have implemented CM-based Securely MMC protocol in naive secret sharing scheme using Python MP-SPDZ. And we confirmed that the minimum mean cycle was found reliably in a number of random edges, including the counterexamples shown by Chaturvedi et al [3].</p>
<h1><a class="anchor" href="https://ethresear.ch#h-5-conclusion-14" name="h-5-conclusion-14"></a>5. Conclusion</h1>
<p>In this study, we have proposed a more efficient protocol for solving the Minimum Mean Cycle (MMC) problem using Multi-Party Computation (MPC). Our CM-based approach not only addresses but also significantly improves upon the issues identified in Aly’s protocol. Specifically, our protocol reduces the time/round complexity from <span class="math">O(|V|^5)</span> to <span class="math">O(|V|^3)</span> and the space complexity from <span class="math">O(|V|^4)</span> to <span class="math">O(|V|^2)</span> compared to Aly’s protocol.</p>
<p>Despite these advancements, the complexity remains super-quadratic in terms of the number of nodes, which can pose practical challenges for very large graphs. To mitigate this limitation, we propose the following strategies:</p>
<ul>
<li>By exposing the graph’s topography, we can optimize the edge search to include only the minimum necessary edges, thereby reducing the time/round complexity to <span class="math">O(|V|^2 \cdot |E|)</span>. This approach, however, requires a trade-off with some degree of privacy.</li>
<li>Implementing simpler algorithms that provide approximate or sub-optimal solutions, such as Greedy Algorithms and Distributed Algorithms, can further enhance practicality. These algorithms can significantly reduce computational overhead while delivering sufficiently accurate results for many applications.</li>
</ul>
<p>In summary, our protocol offers a substantial improvement over existing methods, paving the way for more efficient and practical solutions to the MMC problem in secure computation settings. Future work will focus on refining these strategies to further balance the trade-offs between efficiency, accuracy, and privacy.</p>
<h1><a class="anchor" href="https://ethresear.ch#reference-15" name="reference-15"></a>Reference</h1>
<ol>
<li>Richard M. Karp, “A characterization of the minimum cycle mean in a digraph”, Discrete Mathematics, Volume 23, Issue 3, 1978, Pages 309-311, ISSN 0012-365X, <a href="https://doi.org/10.1016/0012-365X(78)90011-0" rel="noopener nofollow ugc">https://doi.org/10.1016/0012-365X(78)90011-0</a>.</li>
<li>Aly, A., Van Vyve, M. (2015). Securely Solving Classical Network Flow Problems. In: Lee, J., Kim, J. (eds) Information Security and Cryptology - ICISC 2014. ICISC 2014. Lecture Notes in Computer Science(), vol 8949. Springer, Cham. <a class="inline-onebox" href="https://doi.org/10.1007/978-3-319-15943-0_13" rel="noopener nofollow ugc">Securely Solving Classical Network Flow Problems | SpringerLink</a></li>
<li>Mmanu Chaturvedi, Ross M. McConnell, “A note on finding minimum mean cycle”, Information Processing Letters, Volume 127, 2017, Pages 21-22, ISSN 0020-0190, <a class="inline-onebox" href="https://doi.org/10.1016/j.ipl.2017.06.007" rel="noopener nofollow ugc">Redirecting</a>.</li>
</ol>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/a-note-on-securely-finding-minimum-mean-cycle/20073">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 15 Jul 2024 07:09:02 +0000</pubDate>
</item>
<item>
<title>Sealed execution auction</title>
<link>https://ethresear.ch/t/sealed-execution-auction/20060</link>
<guid>https://ethresear.ch/t/sealed-execution-auction/20060</guid>
<content:encoded><![CDATA[
<div> 关键词：密封拍卖、执行提案人、密封投标、公开竞标、MEV问题。

总结:<br />
本文提出了一种名为密封执行拍卖（SEA）的新机制，旨在分离执行提案权和验证者角色，避免MEV问题。该机制包括两个阶段：第一阶段，建设者匿名提交密封投标；第二阶段，建设者公开投标，最高投标者支付第二高投标作为费用。通过这种方式，可以防止建设者与提案者之间的勾结，确保拍卖的公正性。文章还讨论了可能的合谋情况及应对策略，如对提案者错过区块的惩罚和后续拍卖流程设计。总的来说，SEA为区块链执行权拍卖提供了一个潜在的解决方案，以实现更有效的分离和减少激励冲突。 <div>
<h1><a class="anchor" href="https://ethresear.ch#sealed-execution-auction-1" name="sealed-execution-auction-1"></a>Sealed execution auction</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/e/3e0cf08f2021a1cbbe0156d52c8482dba0a00ba6.jpeg" title="Sealed execution auction"><img alt="Sealed execution auction" height="394" src="https://ethresear.ch/uploads/default/optimized/3X/3/e/3e0cf08f2021a1cbbe0156d52c8482dba0a00ba6_2_690x394.jpeg" width="690" /></a></div><p></p>
<p>By <a href="https://x.com/weboftrees">Anders</a>.</p>
<p><em>While working on the <a href="https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024">dynamic pricing auction</a> I though of another way to hold the auction that also seems interesting. Posting a rough sketch here, although I am not yet certain of its viability. Thanks to <a href="https://x.com/drakefjustin">Justin</a>, <a href="https://x.com/barnabemonnot">Barnabé</a> and <a href="https://x.com/terencechain">Terence</a>.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>In the process of enshrining proposer–builder separation (<a href="https://github.com/ethereum/EIPs/pull/8711">ePBS</a>), it has been <a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg">suggested</a> that attesting and execution proposing should be more fully separated. Proposals such as <a href="https://ethresear.ch/t/execution-tickets/17944">execution tickets</a> (ETs) and <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">execution auctions</a> (EAs) strive to allocate the right to propose execution blocks to entities other than the validators. This also facilitates <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV burn</a>. There have been concerns (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">2</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">3</a>) around insufficient early bidding in the MEV pricing auctions with a base fee floor used in EA. By <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">considering the staking metagame</a>, this issue is potentially resolved, but the resulting attester–builder integration can then by itself be <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856#risks-associated-with-attester-builder-integration-14">problematic</a>. There is also a general concern that the decided-upon auction design will <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">induce MEV</a>, and no definite specification among <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764#preliminaries-12">several alternatives</a> for the auction design in ET. For this reason, it seems fruitful to explore an auction that facilitates true separation and does not induce MEV. One such mechanism recently proposed is the <a href="https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024">MEV resistant dynamic pricing auction</a>. In the context of Vickrey auctions of execution rights, <a href="https://forum.arbitrum.foundation/t/constitutional-aip-proposal-to-adopt-timeboost-a-new-transaction-ordering-policy/25167">Timeboost</a> under consideration by Arbitrum can also be mentioned.</p>
<p>This post proposes a <a href="https://en.wikipedia.org/wiki/Vickrey_auction">Vickrey</a> slot auction in two rounds to select a forthcoming execution proposer (akin to EA), referred to as a sealed execution auction (SEA). Staked builders make sealed bids for the right to propose an execution block. Bids are observed by attesters and then collated by the beacon proposer. In subsequent steps, builders reveal their bids, attesters observe the revealed bids, and the proposer once again collates them. The right to propose a forthcoming execution block is awarded to the highest bidder, paying according to the second-highest bid, with the payment burned.</p>
<h2><a class="anchor" href="https://ethresear.ch#auction-3" name="auction-3"></a>Auction</h2>
<h3><a class="anchor" href="https://ethresear.ch#staked-builders-4" name="staked-builders-4"></a>Staked builders</h3>
<p>Builders are staked at a level sufficient for the protocol to penalize them if they fail to reveal committed bids. The stake can also serve as a deposit account to pay for winning bids, or this account can be managed separately.</p>
<h3><a class="anchor" href="https://ethresear.ch#sealed-bids-5" name="sealed-bids-5"></a>Sealed bids</h3>
<p>Figure 1 gives an overview of the auction. In the first round, each builder has the opportunity to make one sealed bid over a public P2P layer. There might be a small fee for making a bid, as a further anti-Sybil measure. Attesters observe the sealed bids that have come in at time <span class="math">T_1</span>. Around two seconds later, at <span class="math">T_2</span>, the beacon proposer collates sealed bids (including any bids it finds after <span class="math">T_1</span>), and broadcasts them in a structure. This structure may be a beacon block if the auction proceeds over two slots (see <a href="https://ethresear.ch/t/sealed-execution-auction/20060#timeline-15">Timeline</a>). At <span class="math">T_3</span>, attesters observe the structure and make sure that all previously observed bids at <span class="math">T_1</span> have been included. If the bids were included in a beacon block, they will attest to the block contingent on correct and timely collation. If not included in a beacon block and the proposer equivocates on the structure, the subsequent block must be rejected.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/9/e9efaf529cceda171c770e9160ed477ff7093303.png" title="Figure 1"><img alt="Figure 1" height="347" src="https://ethresear.ch/uploads/default/optimized/3X/e/9/e9efaf529cceda171c770e9160ed477ff7093303_2_690x347.png" width="690" /></a></div><p></p>
<p><strong>Figure 1.</strong> Sealed execution auction. Staked builders submit sealed bids before <span class="math">T_1</span> and the proposer collates them at <span class="math">T_2</span>. At <span class="math">T_3</span> attesters ensure that all bids they observed at <span class="math">T_1</span> are part of the collated structure. Builders unseal the bids after <span class="math">T_3</span> and attesters observe them at <span class="math">T_4</span>. The proposer then collates bids in a beacon block at <span class="math">T_5</span> and attesters attests to the block at <span class="math">T_6</span> contingent on correct collation. The highest unsealed bid wins, paying a fee corresponding to the second highest bid. The fee is burned. Builders that did not unseal their bids are penalized.</p>
<h3><a class="anchor" href="https://ethresear.ch#revealed-bids-6" name="revealed-bids-6"></a>Revealed bids</h3>
<p>In the second round, after the <span class="math">T_3</span> deadline, builders unseal their bids. They should not release before <span class="math">T_3</span>, because then the proposer can collude with other builders to release a bid structure with some bids placed after other bids were revealed. However, they do not need to observe the proposer’s structure before release, and can proceed right after the <span class="math">T_3</span> mark.</p>
<p>Attesters observe unsealed bids at <span class="math">T_4</span>. The proposer collates all unsealed bids it can find, including them in the beacon block at around <span class="math">T_5</span>. It may also include bids that were never unsealed, so that the associated builder can be penalized (this is a strict requirement in the single-slot design, because then the sealed bids have not been included in a previous beacon block). The highest bid is selected as the forthcoming execution proposer, and the second highest bid value is deducted from the winner’s balance and burned. At <span class="math">T_6</span>, attesters attest to the beacon block, contingent on a correct collation by the beacon proposer.</p>
<h2><a class="anchor" href="https://ethresear.ch#rationale-7" name="rationale-7"></a>Rationale</h2>
<p>Collusion between builders and proposers to reduce the burn as in the MEV burn design is arguably resolved; without stakers actively burning each others’ MEV revenue.</p>
<ul>
<li>There is no longer a stable equilibrium to rely on for colluding parties, such as late bidding.</li>
<li>The proposer no longer has leverage to punish early bidders by electing another builder.</li>
<li>Chiseling at a cartel is trivial, simply by truthful bidding.</li>
<li>Every bid fulfills a real purpose, as opposed to early bids in MEV pricing auctions.</li>
<li>There is no avenue for discouragement attacks, since there is no substantial proposer revenue to remove.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#penalization-8" name="penalization-8"></a>Penalization</h2>
<p>Several actions must be penalized. If the proposer omits an observed sealed bid in the first round or an observed revealed bid in the second round, the proposer’s block must be rejected by attesters. If the proposer fails to release the structure of the sealed bids in the first round or the revealed bids in the second round in a timely manner (reaching attesters before <span class="math">T_3</span> and <span class="math">T_6</span> respectively), the proposer’s block must also be rejected by attesters.</p>
<p>It is possible that a builder made a mistake and will be unable to pay for its bid, if the bid is higher than its staked amount. This will be penalized by burning some proportion of the stake, for example corresponding to the amount of the actual winning bid, some fixed amount of ETH, or its entire stake. In any case, if its unbacked bid is the highest, the builder will not win the auction. The second highest bid will instead be selected as the execution proposer, paying the third highest bid, etc. If the bid underpinning the fee (normally the second highest bid) lacks funds, the bid below it will be set to underpin the fee.</p>
<h2><a class="anchor" href="https://ethresear.ch#builder-proposer-collusion-and-possible-remedies-9" name="builder-proposer-collusion-and-possible-remedies-9"></a>Builder–proposer collusion and possible remedies</h2>
<p>A potential cause for concern is the following scenario: a builder determines that it would not like to unseal its bid (potentially after observing other builders’ unsealed bids). It does not want to subject itself to a penalty, so it colludes with the proposer to have it miss the slot. Is this a cause for concern? This ultimately depends on if the builder benefits more by <em>not</em> revealing its bid than the proposer loses from a missed proposal. This could be the case when bidding for the right to propose the current or next slot, and the expected MEV falls drastically between bid commit and reveal (i.e., a <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">value-in-flight</a> problem). Another potential cause for concern is if the value instead increases drastically. The proposer might then pose an ultimatum to the winning builder: “send me some part of expected profits, or I will fail to propose”. A failed proposal would leave the builder without rights for the slot. An <a href="https://en.wikipedia.org/wiki/Ultimatum_game">ultimatum game</a> emerges. The other builders might also be inclined to pay the proposer, in order to starve off competition, and the winning builder would then also need to pay the proposer to ensure it proposes.</p>
<p>While the outlined collusion scenarios may be a bit speculative, it can still be interesting to explore possible remedies. A few directions then spring to mind:</p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-penalize-beacon-proposers-for-missed-beacon-blocks-10" name="h-1-penalize-beacon-proposers-for-missed-beacon-blocks-10"></a>1. Penalize beacon proposers for missed beacon blocks</h4>
<p>Proposers already lose out on revenue if they miss their block. However, this loss might not be a sufficient deterrent. It would therefore be beneficial to also penalize proposers if they miss their blocks. Otherwise, if the penalty applied to a builder is substantially higher than the loss from missed proposals for the proposer, that builder penalty will be less meaningful. Builders could seek to collude to let the proposer take the fall. In essence, if the value to the builder, its competitors, or the proposer, of having the builder not win the auction, is higher than the loss to the proposer of not proposing, then collusion or an ultimatum game may emerge.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-2-require-subsequent-beacon-proposers-to-conclude-the-auction-11" name="h-2-require-subsequent-beacon-proposers-to-conclude-the-auction-11"></a>2. Require subsequent beacon proposers to conclude the auction</h4>
<p>Is it possible to have the next beacon proposer conclude the auction? This depends to some extent on the <a href="https://ethresear.ch/t/sealed-execution-auction/20060#timeline-15">Timeline</a> of the auction.</p>
<ul>
<li><strong>Single-slot design:</strong> In the single-slot design, attesters do not signal if they rejected a block because of an incorrect initial structure, a late structure, or an incorrect or missing beacon block. A way to deal with this is that the next proposer presents the correct outcome of the auction, in its own view, and that the attesters of <span class="math">n+2</span> either reject or confirm the new block based on the proposed outcome. But this means that these attesters must also have tracked events in the previous slot as they unfolded, and any split views (e.g., from a rather late sealed builder bid) may persist for several blocks in a row.</li>
<li><strong>Two-slot design:</strong> If the auction commences over two slots, there will be an agreed-upon set of committed sealed bids, or the first beacon block will have been rejected. The second step of the auction can then be concluded in a subsequent slot without requiring attesters to have observed the commit-phase. The requirement is to still have attesters make an observation of unsealed bids sometime before the proposer deadline. But that point need not necessarily be taken from the earlier slot. A benefit is that this might starve off split views.</li>
</ul>
<p>One thing to note is that if a builder finds it worthwhile to pay the first proposer to not propose, in order to avoid revealing a bid without being penalized, it might be willing to pay also a second proposer for not proposing. However, the price will go up, and the number of potential collusion partners scheduled to propose in a row may not be too large. It should also be noted that when auctioning off rights for slot <span class="math">n+i</span>, there is a requirement that the delay until the conclusion of the auction does not surpass <span class="math">i</span>. In other words, it will only be possible to repeat a failed auction around <span class="math">i</span> times. Note that this requirement is also due to the fact that the order in which auctioned off execution rights are provided cannot be altered ex post, since the expected MEV for slots may vary.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-3-skip-the-beacon-proposal-reveal-12" name="h-3-skip-the-beacon-proposal-reveal-12"></a>3. Skip the beacon proposal reveal</h4>
<p>Is it possible to skip the beacon proposal reveal? If all bids are unsealed, the outcome will be evident to every participant. The mechanism can then be designed such that the winning builder safely can propose its block at the assigned slot, even if a proposer has not collated the outcome and presented a winner. The previous option 2 is focused on concluding the auction via a beacon proposal in time before the execution proposal, but the point here is that the auction does not need to be concluded by the proposer as long as the outcome is evident to the builder and can be verified by attesters when the builder proposes its block. The sealed bids must then have been included in a beacon block, as in the two-slot design.</p>
<p><a href="https://en.wikipedia.org/wiki/Threshold_cryptosystem">Threshold decryption</a> via a committee of attesters (h/t Barnabé) is one option here. The bids are decrypted by a committee, and the winner made evident to the builders/forthcoming proposer and attesters. There would still be liveness concerns, but collusion would be more difficult. It can be noted that as long as all builders unseal their bids in a timely manner (even without threshold decryption), the winning builder can proceed with the proposal. Always penalizing builders that do not unseal their bids before <span class="math">T_4</span> could then seem sufficient, but the issue is that split views would emerge in potential designs. In any case, the outcome would also at some point need to be included in a block, to process payment and penalties.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-4-auction-of-a-future-slot-to-reduce-value-in-flight-13" name="h-4-auction-of-a-future-slot-to-reduce-value-in-flight-13"></a>4. Auction of a future slot to reduce value-in-flight</h4>
<p>The Vickrey auction is truthful, allowing builders to bid their true value at the commit deadline. Since value-in-flight is the most likely cause for collusion, auctioning off a slot further removed from the present will temper the issue.</p>
<h4><a class="anchor" href="https://ethresear.ch#auctioning-off-multiple-slots-14" name="auctioning-off-multiple-slots-14"></a>Auctioning off multiple slots</h4>
<p>Note that to avoid having a failed beacon proposal result in a missing execution proposal, there is also the option to sell the right to two execution proposals in the subsequent slot (with builders bidding their <a href="https://en.wikipedia.org/wiki/Vickrey_auction">inverse demand curve</a> and paying according to the second and third highest bids).</p>
<h2><a class="anchor" href="https://ethresear.ch#timeline-15" name="timeline-15"></a>Timeline</h2>
<p>This section presents two hypothetical timelines for the auction, either when only including unsealed bids in the beacon block (single-slot auction) or when including both sealed and unsealed bids in separate beacon blocks (two-slot auction).</p>
<h3><a class="anchor" href="https://ethresear.ch#single-slot-auction-16" name="single-slot-auction-16"></a>Single-slot auction</h3>
<p>Example of a slot auction with a tight schedule enacted mostly during a single slot <span class="math">n</span>, auctioning off execution proposal rights for a later slot <span class="math">n+i</span>.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th><span class="math">T_x</span></th>
<th>Time</th>
<th>Overview</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">T_1</span></td>
<td>4s</td>
<td><strong>Sealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe all sealed bids. Builders must have broadcast them some time before this point to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_2</span></td>
<td>6s</td>
<td><strong>Proposer collates bids</strong></td>
<td>The proposer of slot <span class="math">n+1</span> releases a structure containing all sealed bids it can find.</td>
</tr>
<tr>
<td><span class="math">T_3</span></td>
<td>8s</td>
<td><strong>Attesters observe collation</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe the proposer’s structure to ensure it contains all bids they had seen at <span class="math">T_1</span> and that the release of this structure is timely.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><span class="math">T_4</span></td>
<td>10s</td>
<td><strong>Revealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe unsealed bids. Builders must have broadcast them some time before this point (but after <span class="math">T_3</span>) to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_5</span></td>
<td>0s (12s)</td>
<td><strong>Proposer collates in beacon block</strong></td>
<td>The proposer of slot <span class="math">n+1</span> includes every unsealed bid it can find in the  block, also indicating sealed bids that were never unsealed. A winner is declared.</td>
</tr>
<tr>
<td><span class="math">T_6</span></td>
<td>4s (12+4s)</td>
<td><strong>Attesters confirm collation</strong></td>
<td>Attesters of slot <span class="math">n+1</span> confirm that the proposer fulfilled its role and collated bids in a timely manner by attesting to the block.</td>
</tr>
</tbody>
</table>
</div><p>Note that builders can unseal their bids directly after <span class="math">T_3</span>. This should allow attesters of slot <span class="math">n+1</span> to observe revealed bids at 10s. However, if needed, the entire schedule could be pushed back slightly.</p>
<h3><a class="anchor" href="https://ethresear.ch#two-slot-auction-17" name="two-slot-auction-17"></a>Two-slot auction</h3>
<p>Here is an example of a schedule for the two-slot auction:</p>
<div class="md-table">
<table>
<thead>
<tr>
<th><span class="math">T_x</span></th>
<th>Time</th>
<th>Overview</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">T_1</span></td>
<td>10s</td>
<td><strong>Sealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe all sealed bids. Builders must have broadcast them some time before this point to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_2</span></td>
<td>0s (12s)</td>
<td><strong>Proposer collates bids</strong></td>
<td>The proposer of slot <span class="math">n+1</span> includes all sealed bids it can find in its beacon block.</td>
</tr>
<tr>
<td><span class="math">T_3</span></td>
<td>4s (12+4s)</td>
<td><strong>Attesters confirm collation</strong></td>
<td>Attesters of slot <span class="math">n+1</span> confirm that the proposer fulfilled its role and collated bids in a timely manner by attesting to the block.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><span class="math">T_4</span></td>
<td>8s (12+8s)</td>
<td><strong>Revealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+2</span> observe unsealed bids. Builders must have broadcast them some time before this point (but after <span class="math">T_3</span>) to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_5</span></td>
<td>0s (12+12s)</td>
<td><strong>Proposer collates in beacon block</strong></td>
<td>The proposer of slot <span class="math">n+2</span> includes every unsealed bid it can find in the  block, potentially indicating sealed bids that were never unsealed. A winner is declared.</td>
</tr>
<tr>
<td><span class="math">T_6</span></td>
<td>4s (12+12+4s)</td>
<td><strong>Attesters confirm collation</strong></td>
<td>Attesters of slot <span class="math">n+2</span> confirm that the proposer collated all unsealed bids by attesting to the block.</td>
</tr>
</tbody>
</table>
</div>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/sealed-execution-auction/20060">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 13 Jul 2024 16:30:07 +0000</pubDate>
</item>
<item>
<title>Staking Rights Auctions</title>
<link>https://ethresear.ch/t/staking-rights-auctions/20059</link>
<guid>https://ethresear.ch/t/staking-rights-auctions/20059</guid>
<content:encoded><![CDATA[
<div> 关键词：Staking Rights Auctions, Ethereum, Issuance, MEV, Inflation Control

总结: 这篇文章讨论了作者过去为Cartesi和CTSI提出的一种名为"Staking Rights Auctions"的机制，旨在解决以太坊发行（包括ether的质押和MEV问题）中的挑战。该机制通过拍卖赋予节点操作员参与权益，用户可以根据风险偏好支付不同的价格，从而实现更精细的激励分配。文章提到，这有助于平衡MEV差距、控制通胀并允许用户表达不同的投资时间周期。尽管需要进一步研究和生态系统的参数决策，但作者认为这个系统能提高参与度，同时限制通胀，促进更健康的网络环境。 <div>
<p>This post was written by <a class="mention" href="https://ethresear.ch/u/pedroargento">@pedroargento</a> but his account seems unable to post it, so he asked me to do it. I’m not too aware of the necessities/constraints of the ether issuance debate - but this seems quite interesting for defi protocols as well. Anyway, here it goes:</p>
<hr />
<p>Hey everyone,</p>
<p>A friend of mine just watched the “What’s the Issue with Issuance?” talk by Christine Kim, Caspar Schwarz-Schilling, and Ansgar Dietrichs at EthCC. They said that the key points discussed around Ethereum’s issuance reminded them of a proposal I wrote in the past for Cartesi and CTSI.</p>
<p>The significant issues mentioned were the high (and growing) percentage of ether staked, how having too much ether staked isn’t necessarily beneficial for the network, how LST providers might be in a "winner take all ‘’ situation and etc. Both Ansgar and Justin Drake suggested aiming for around 20-25% staked ether (ball park estimates).</p>
<p>It seems to me that the auction mechanism I proposed for the CTSI staking economy could really help to address these issues, by making the staking system much more expressive. The idea also allows participants to pay negative issuance for the right to earn MEV, which not only tackles the problem of excessive ether staking, but might also helps to balance MEV discrepancies.</p>
<p>I’m not an expert in this research area, but based on the feedback from the EthCC talk, it seems like my proposal aligns well with the direction Ethereum is aiming to take. I’m sharing this here on the Ethereum Research forum in hopes that it can contribute to the ongoing conversation and possibly offer a viable solution to the current challenges with Ethereum’s issuance models.</p>
<p>Looking forward to your thoughts and feedback!</p>
<h1><a class="anchor" href="https://ethresear.ch#staking-rights-auctions-1" name="staking-rights-auctions-1"></a>Staking Rights Auctions</h1>
<p>A popular solution to reward users for staking is to mint new tokens and distribute them among stakers. Besides the obvious incentive to gain extra tokens, the inflation created penalizes those who choose not to participate. The challenge is how to measure the opportunity costs of users and how to choose the appropriate issuance amount to achieve a target participation rate, while avoiding exceedingly high inflation rates.</p>
<p>Some projects have a fixed emission rate while others have a dynamic inflation function, which is higher when the participation is below desired and lower otherwise. There are three key problems with these methods:</p>
<ul>
<li>
<p>You need strong assumptions about users’ risk preferences to tailor the parameters of the function;</p>
</li>
<li>
<p>Users have little information about the mining income they will get as it depends on the number of total staked funds.</p>
</li>
<li>
<p>The methods don’t allow for differentiation between players with different risk preferences;</p>
</li>
<li>
<p>It is hard to determine a balanced inflation target.</p>
</li>
</ul>
<p>As a countermeasure to these three issues, I’m proposing a staking system based on a novel mechanism called staking rights, detailed in the sections below.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-mechanism-of-staking-rights-2" name="the-mechanism-of-staking-rights-2"></a>The Mechanism of Staking Rights</h2>
<p>Staking rights give node operators the right to participate in staking. Without the rights, operators cannot be selected in the lottery that chooses the node that will generate the next block.</p>
<p>Rights are transitory. At the end of each staking cycle, a set of rights expires and ceases to exist. Conversely, new rights are created and made available for purchase through an auction.</p>
<p>Staking rights always have a final value of 1 token, which is delivered to the account that purchased it at the precise time of their expiry. When users buy a staking right for a price of less than 1 token, the difference between the price paid and the unit value is proportional to their perceived opportunity of the staking right. In that case, the difference is minted and locked in staking together with the price paid, totaling 1 token staked per right sold.</p>
<p>Here is an example. Suppose that the desired staking participation rate is 50% of the circulating supply of 1 thousand tokens. In this case, the system creates and auctions 500 staking rights, each scheduled to pay 1 token at the end of the cycle.</p>
<blockquote>
<p>Circulating supply: 1000<br />
Target participation: 500 (50%)<br />
Staking rights issued: 500<br />
Auction price = 0.97</p>
</blockquote>
<p>Assume that each staking right is sold for <span class="math">0.97</span> in the auction, thereby generating <span class="math">0.03</span> new tokens. The staking rights buyer at the end of the staking cycle would be rewarded 1 token obtaining a <span class="math">3.09\%</span> return <span class="math">(0.03/0.97)</span>. The total inflation generated for the network would be <span class="math">15</span> tokens (<span class="math">0.03</span> per right * <span class="math">500</span> rights) or <span class="math">1.5\%</span>.</p>
<p>With this system, the user knows exactly how much return they will get for their staked tokens, independent of how many rights are sold or how many other stakers exist. There are also no assumptions about risk preferences, buyers will state them through bidding. This method also allows for bigger differentiation between users: instead of asking for a binary decision (stake or not to stake), we allow users to signal at what price they would be willing to stake.</p>
<p>The system can offer staking rights with different staking cycle periods: 2 weeks, 1 month, 3 months, etc. This achieves two objectives (1) differentiate between users who are willing to stake long term from short term players and, mainly, (2) decrease volatility in token emission. After all, if all staking cycles end at the same time, all new staking rights will be subjected to the same market conditions that may not represent the average behavior of stakers.</p>
<p>With different staking periods, in each cycle only a small number of staking rights will need to be created to replace the expired ones. This is because in each cycle there is going to be a mix of active staking rights bought at different points in time.</p>
<p>User risk preferences can be stated in the form of a discount rate, the rate used to convert future values (promises of payouts) to the present. The discount rate is the income that makes one indifferent between gaining money in the present or in the future. For example, with a discount rate of 10% a year, one would be indifferent between receiving 100 dollars today or 110 dollars a year from now.</p>
<p>The discount rate of a user can be translated to a staking right value using it to compute the present value of all incentives that can be paid by staking the right.</p>
<p>Staking rights give the owner three sources of incentives, provided that the owner remained active within the network:</p>
<ul>
<li>
<p>Staking right’s unit value (paid at the end of the cycle)</p>
</li>
<li>
<p>Block producer’s tips</p>
</li>
<li>
<p>Mine extractable Value</p>
</li>
</ul>
<p>Below is an example of staking rights holder cash flows for a six month locked period.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/8/28063c3ac2b9e1cd18ed0e7aa69be283c8125261.png" title="Chart"><img alt="" height="385" src="https://ethresear.ch/uploads/default/optimized/3X/2/8/28063c3ac2b9e1cd18ed0e7aa69be283c8125261_2_624x385.png" title="Chart" width="624" /></a></div><p></p>
<p>The price to be paid for the staking can be easily calculate based on the return demanded by the staker</p>
<blockquote>
<p>Given:<br />
a staking right in a staking cycle of 12 weeks that pays rewards every 2 weeks<br />
<span class="math">MEV_t</span> the expected mine reward for time <span class="math">t</span><br />
<span class="math">NF_t</span> the expected network fees for time <span class="math">t</span><br />
<span class="math">UV</span> the staking right unit value<br />
<span class="math">i</span> the 2-week return expected by the user<br />
The price <span class="math">P</span> will be calculated as:</p>
<div class="math">
P= \frac {UV} {(1+i)^6} + \sum_ {t=1}^{6} \frac {MEV_t + NF_t} {(1+i)^t}
</div>
</blockquote>
<p>The staking rights can be sold through a closed price auction of Nth price, which means that the higher bid wins the token but will pay the price of the highest loser bid. For example, If 500 tokens are sold and the 501st highest bid was 0.98, all 500 tokens will cost 0.98. This type of auction, also known as a Vickrey auction (or Dutch auction), ensures all players bid their true valuation of the staking right, revealing their true risk preferences.</p>
<blockquote>
<p><strong>Proof</strong><br />
Its not 100% applicable to this specific auction, but a classical proof from Game Theory can give the intuition why the paid price being the lowest winning bid incentivizes truthfully reporting:</p>
<p>Given user <span class="math">i</span> has a valuation <span class="math">B_i</span> for a staking right. They can bid <span class="math">B_+ &gt;B_i</span> or <span class="math">B_- &lt; B_i</span> and the <span class="math">N</span>-th price of the auction ends up being <span class="math">B_n</span>.</p>
<p>If they bids <span class="math">B_+</span> there are two possibilities:</p>
<ol>
<li>
<p><span class="math">B_n &lt; B_i</span></p>
</li>
<li>
<p><span class="math">B_+ &gt; B_n &gt; B_i</span></p>
</li>
</ol>
<p>In (1) they would get <span class="math">(B_i - B_n)</span> independent of bidding <span class="math">B_+</span> or <span class="math">B_i</span> and in (2) they would lose <span class="math">(B_i — B_+)</span> that would be larger than <span class="math">(B_n — B_i)</span>. In neither case they have incentive to bid <span class="math">B_+</span>.</p>
<p>If they bids <span class="math">B_-</span> there are two possibilities:</p>
<ol start="3">
<li>
<p><span class="math">B_n &lt; B_-</span></p>
</li>
<li>
<p><span class="math">B_- &lt; B_n &lt; B_i</span></p>
</li>
</ol>
<p>In (3) they would get <span class="math">(B_i — B_n)</span> independent of bidding <span class="math">B_-</span> or <span class="math">B_i</span> and in (4) they would not get the token, making it better to bid <span class="math">Bi</span> and have the chance to win.</p>
<p>In all possible cases there is no incentive to bid <span class="math">B_+</span> or <span class="math">B_-</span>, making <span class="math">B_i</span> the dominant Nash-Bayesian equilibrium.</p>
</blockquote>
<p>This system also allows for deflation, if the value of the auction ends up above 1 unit. This would make sense if people are expecting such a high reward from the fees and MEV that they are willing to burn a certain amount of tokens in order to participate.</p>
<h2><a class="anchor" href="https://ethresear.ch#inflation-control-mechanisms-3" name="inflation-control-mechanisms-3"></a>Inflation Control Mechanisms</h2>
<p>Besides the burning possibility, its possible to add parameters in the auction to help manage inflation. Although its unclear to me at this time how those parameters could be decided by the Ethereum ecosystem, I’m presenting them anyway. Contributions are welcomed as always.</p>
<p><strong>First</strong>. Auction reserve prices: In the worst-case scenario, where all rights are sold in the auction with a price close to zero, the inflation will be the number of rights sold, divided by the total supply (50% in our previous example).</p>
<p>A reserve price means that only bids above a certain value will be considered valid. If we choose a reserve price of 0.7, the worst-case scenario in our example would be an inflation of 15%.</p>
<p>With a reserve price, it is possible to choose an acceptable inflation range and guarantee it will be complied with at all times.</p>
<p><strong>Second</strong>. The number of issued tokens: The number of tokens directly affects the inflation. If only 100 tokens are issued (out of a total supply of one thousand), the worst-case scenario for inflation would be 10%.</p>
<p>These two variables need to be controlled dynamically in order to make sure the inflation is never higher than a previously determined ceiling. The number of tokens issued will depend not only on the target participation rate but also on the value of bids from the auction. This number will be capped so that the total newly minted tokens are limited to the maximum inflation. The total newly minted tokens can be calculated as the difference between the face value and the highest bid not honored (the Dutch auction price) times the number of tokens issued.</p>
<blockquote>
<p>Let <span class="math">CAP</span> be the maximum number of minted ETH desired</p>
<p>Let <span class="math">N_ {max}</span> be the maximum number of staking rights necessary to achieve the target participation rate</p>
<p>Let <span class="math">B(i)</span> be the <span class="math">i</span>-th largest bid from the auction results</p>
<p>Let <span class="math">N</span> be the number of staking rights issued</p>
<p><span class="math">N</span> will be chosen as the result of the optimization problem:</p>
<div class="math">
\begin{aligned}
\max_{} \quad &amp; N\\
\textrm{s.t.} \quad &amp; N * (1-B(N+1)) \le CAP\\
\quad &amp; N \le N_ {max} \\
\end{aligned}
</div>
</blockquote>
<p>More precisely, suppose that we sort all the bids made during the auction in decreasing order and plot them as in the figure below.</p>
<p><img alt="m1" height="318" src="https://ethresear.ch/uploads/default/original/3X/f/4/f4dd92342507c13ba5e872d205c15c90bf308b60.png" width="477" /></p>
<p>Then N staking rights will be issued in order to preserve the maximum number of ETH issued (CAP). Therefore, we can dynamically choose the minimum value B(N+1) such that the inflation is within the predetermined bounds.</p>
<p>The deflation case is depicted in the figure below:</p>
<p><img alt="m2" height="318" src="https://ethresear.ch/uploads/default/original/3X/7/3/736de5fac6d3efefd1b613297221521da4f9d64b.png" width="459" /></p>
<p>It is important to note that there is no way around the tradeoff between participation rate and inflation, to control the later there is the need to sacrifice the former. The advantage brought by the system of staking rights auction is that we maximize participation, while limiting the inflation and allowing workers to express their economic preferences.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/staking-rights-auctions/20059">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 13 Jul 2024 14:53:13 +0000</pubDate>
</item>
<item>
<title>Bitfinity: A new sharded blockchain</title>
<link>https://ethresear.ch/t/bitfinity-a-new-sharded-blockchain/20054</link>
<guid>https://ethresear.ch/t/bitfinity-a-new-sharded-blockchain/20054</guid>
<content:encoded><![CDATA[
<div> 关键词: 
1. 基于阈值BLS签名
2. 分片（sharding）
3. 无缝跨-shard通信
4. 跨链结算
5. Bitcoin-EVM桥接

总结:
Bitfinity是一个运用了分片技术的新型区块链，通过阈值BLS签名实现线性可扩展性和高速度。它将代币与EVM处理器分离，支持跨-shard通信，实现了顺畅的跨链资产转移，包括与比特币的连接。作为比特币和其它资产的Layer Two，Bitfinity特别适合部署复杂Solidity智能合约，提供极致的性能和效率。<br /><br />总结: Bitfinity利用分片和阈值签名技术，打造高性能的EVM，连接比特币和其他资产，实现跨链交易和智能合约部署。 <div>
<p>Using threshold BLS signatures we design a new blockchain that implements sharding, separating tokens from EVM processors. Bitfinity is linearly scalable and fast.<br />
Bitfinity implements seamless cross-shard communication.</p>
<aside class="onebox pdf">
  <header class="source">

      <a href="https://github.com/bitfinity-network/whitepapers/blob/163145326e321c87956b2f881159f73b7a6409fb/Bitfinity_Network.pdf" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <a href="https://github.com/bitfinity-network/whitepapers/blob/163145326e321c87956b2f881159f73b7a6409fb/Bitfinity_Network.pdf" rel="noopener nofollow ugc" target="_blank"><span class="pdf-onebox-logo"></span></a>

<h3><a href="https://github.com/bitfinity-network/whitepapers/blob/163145326e321c87956b2f881159f73b7a6409fb/Bitfinity_Network.pdf" rel="noopener nofollow ugc" target="_blank">Bitfinity_Network.pdf</a></h3>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>
<p>
Using sharding techniques we also implement seamless cross-chain settlement and can bridge over Bitcoin to the EVM.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="32" src="https://ethresear.ch/uploads/default/original/3X/9/6/966040c1403c32d7669b160eb35a33dc860db193.png" width="32" />

      <a href="https://bitfinity.network/" rel="noopener nofollow ugc" target="_blank">bitfinity.network</a>
  </header>

  <article class="onebox-body">
    

<h3><a href="https://bitfinity.network/" rel="noopener nofollow ugc" target="_blank">Bitfinity EVM</a></h3>

  <p>Bitfinity is a blazingly-fast, next-gen EVM, serving as a Layer Two for Bitcoin and other assets - utilising threshold signature schemes and built on the IC. Use Bitfinity to deploy advanced Solidity smart contracts.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/bitfinity-a-new-sharded-blockchain/20054">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 12 Jul 2024 23:34:33 +0000</pubDate>
</item>
<item>
<title>Searcher Competition in Block Building</title>
<link>https://ethresear.ch/t/searcher-competition-in-block-building/20044</link>
<guid>https://ethresear.ch/t/searcher-competition-in-block-building/20044</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV奖励、验证者、搜索者、合作博弈论、核心

总结:<br />本文探讨了在区块链中，验证者和搜索者之间的MEV（矿工提取价值）收益分配。通过合作博弈论模型，研究了验证者（具有否决权）与可替代或互补的搜索者之间的互动。核心部分分析了可能的支付向量，发现当搜索者竞争激烈时，验证者的奖励增加，符合理论预测。在随机模型中，高概率下搜索者独立发现机会时，验证者独占全部收益；而在低概率或搜索者互补情况下，验证者可能得到零支付。研究还扩展到了有限大小区块的情况。实证结果证实了理论的预测。 <div>
<p>In a new paper with Christoph Schlegel (<a class="mention" href="https://ethresear.ch/u/jcschlegel">@jcschlegel</a>), Benny Sudakov and Danning Sui(<a class="mention" href="https://ethresear.ch/u/sui414">@sui414</a>), we look at the distribution of MEV rewards between the validator and searchers. We model the interaction between all players using tools from cooperative game theory. Namely, for any coalition of players, we define a (maximum achievable) value the coalition can derive by creating the best block together. The validator is a special player, that is needed to create any value. In other words, it has a veto power. However, searchers are the ones that find (arbitrage) opportunities which derive a value. Searchers can be substitutes or complements of each other into finding opportunities. The outcome of this interaction is payoff vector, specifying how much each player gets. In the core of the game payoffs are such that any coalition gets paid at least as much as the value they produce themselves.<br />
First, we study a structure of the core, which is always non-empty set of payoff vectors. Then, we focus on the searcher-optimum allocation and show that each searcher obtains its marginal contribution. In a stochastic model, where each opportunity is independently found with the same probability by each searcher, we show that if this probability is mildly high in the number of searchers, validator gets all rewards. In other words, core is just a single payoff vector. While if this probability is low, with a constant probability the validator can get zero payment, as the searchers are complements of each other. We extend some results to the blocks with bounded size.<br />
On the empirical side, we observe that if there is a high competition of searchers, validator rewards are increasing (in absolute terms), which aligns with our theoretical predictions.<br />
For more details check out the paper: <a class="inline-onebox" href="https://arxiv.org/abs/2407.07474" rel="noopener nofollow ugc">[2407.07474] Searcher Competition in Block Building</a>. Any feedback is welcome.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/searcher-competition-in-block-building/20044">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 11 Jul 2024 11:00:11 +0000</pubDate>
</item>
<item>
<title>L2 Asset Interoperability via Two-way Canonical Bridges</title>
<link>https://ethresear.ch/t/l2-asset-interoperability-via-two-way-canonical-bridges/20039</link>
<guid>https://ethresear.ch/t/l2-asset-interoperability-via-two-way-canonical-bridges/20039</guid>
<content:encoded><![CDATA[
<div> 关键词：L2资产、两向桥接、ERC-1155接口、L2结算合同、跨链流动性

总结:<br />
文章讨论了L2资产桥接问题，强调了现有的L2解决方案如L2之间共享结算层的局限性，导致生态系统碎片化。为解决这一问题，提出了一种两向桥接的概念，即资产能在L2和L1之间双向流动。L2结算合同作为记录，采用ERC-1155接口，用户通过发送资产到系统地址实现转移。返回L2时，使用特殊函数进行销毁并存入。这种设计确保资产安全，用户自行承担风险。同时，用户可利用快速流动性桥，而跨链流动性提供者则用于资产重平衡。该机制还可扩展至L3。总的来说，两向桥接旨在打破链间壁垒，促进资产流动性与互操作性。 <div>
<h2><a class="anchor" href="https://ethresear.ch#motivation-1" name="motivation-1"></a>Motivation</h2>
<p>One key problem with the L2 scaling solutions is that assets natively minted on L2s can only be used on the L2 of issuance but it cannot be bridged back to L1 or other L2s, without utilizing external bridges. This creates fragmentation. At the time of writing, there is already half as much natively-minted assets ($12b) on Eth L2s compared to canonical bridged assets ($24b), according to L2Beat.</p>
<p>Shared settlement layers only solve this problem for L2s using the same shared settlement layer. The ecosystem remain fragmented once more shared settlement layer show up.</p>
<p>We propose <strong>two-way canonical bridges</strong> as a solution, where L2-minted assets can be <strong>reverse-canonically bridged</strong> to L1. It is simply an ERC-1155-like interface that an L2 settlement contracts adopt, plus additional precompiles added to the L2 execution environment.</p>
<h2><a class="anchor" href="https://ethresear.ch#two-way-canonical-bridges-2" name="two-way-canonical-bridges-2"></a>Two-way Canonical Bridges</h2>
<p>Below is a highlevel description of two-way canonical bridging.</p>
<ul>
<li>The L2 settlement contract becomes the ledger of record for all native assets issued on it (that have been reverse-canonically-bridged). The settlement contract (on L1) shall implement the ERC-1155 interface, where the asset id field denotes the L2 asset address.</li>
<li>To send an L2-native asset to an L1 address, the L2 users simply send the asset to a prespecified system address, which shall results in the L2 settlement contract on L1 issuing ERC-1155 tokens to itself. Next, L2-&gt;L1 call mechanisms can be utilized to move the newly-issued asset to any desired destination. This is done within the same L2 transaction.</li>
<li>To send a reverse-canonically-wrapped asset back to its L2 of origin, a special <code>burnAndDeposit</code> function on the L2 settlement contract can be called.</li>
<li>Since the L2 settlement contract is an ERC-1155 contract, L1 EOAs and other L2s can simply hold assets or wrap them as normal. This requires the L2 canonical bridge to support wrapping of ERC-1155 assets.</li>
<li>In normal usage, it is expected that the only holders of the ERC-1155 tokens issued by an L2 settlement contract are other L2 settlement contracts. This means that the state overhead on L1 is small.</li>
</ul>
<p>Additional consideration:</p>
<ul>
<li>The safety of an asset is maintained without additional trust assumptions because the L2 settlement contract acts as the ledger of record for all outstanding assets (those owned by other L1 addresses).</li>
<li>It is assumed that any assets that is reverse-canonically-bridged to L1 addresses is done at the risk of the user initiating the bridging.</li>
<li>In practice, end-users can utilize fast liquidity bridges while crosschain liquidity providers utilize the two-way canonical bridges to rebalance.</li>
<li>This mechanism can extend to L3s on L2s. An asset issued on an L3 can be reverse canonically-bridged to L2 and then reverse canonically-bridged back to L1. We’d need the 1155 ids on the settlement contract to be able to represent the 1155 asset id on L2 alongside with the asset address–this can be done via hashing for example.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#acknowledgements-3" name="acknowledgements-3"></a>Acknowledgements</h3>
<p>Thanks to Shumo Chu for review and comments.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/l2-asset-interoperability-via-two-way-canonical-bridges/20039">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Jul 2024 22:20:35 +0000</pubDate>
</item>
<item>
<title>MEV resistant dynamic pricing auction of execution proposal rights</title>
<link>https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024</link>
<guid>https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV抵抗、动态定价拍卖、执行提案权、随机抽取机制（RANDAO）、票池拍卖（ET）

总结:
这篇文章提出了一种MEV抵抗的动态定价拍卖机制，用于销售执行提案权。这种机制旨在减少 Beacon 验证者在提案选择过程中的影响，通过公开的P2P层接受建造者购买订单，订单由共识层的债务账户支持。购买过程由 attesters 观察并确保其有效性，避免了过多的MEV。设计有执行票拍卖(ETA)和集体铸造两种版本，其中 ETA 利用RANDAO随机排序。文章讨论了价格调整策略、动态定价的复杂性以及如何平衡价格变化与市场需求。尽管存在多块交易MEV和审查抵抗等未解决的问题，但该机制为执行提案权的拍卖提供了一个潜在的、MEV抵抗的解决方案。 <div>
<h1><a class="anchor" href="https://ethresear.ch#mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights-1" name="mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights-1"></a>MEV resistant dynamic pricing auction of execution proposal rights</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/9/3903954c39a134bc9b9fc6b919977da400390b97.jpeg" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/3/9/3903954c39a134bc9b9fc6b919977da400390b97_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><em>Execution proposal of marriage between EA and ET through an auction sequenced by RANDAO (she said yes).</em></p>
<p>By <a href="https://x.com/weboftrees">Anders</a>. Special thanks to <a href="https://x.com/barnabemonnot">Barnabé</a> for helping me improve the clarity of this post. Thanks also for valuable feedback to <a href="https://x.com/soispoke">Thomas</a>, <a href="https://x.com/_julianma">Julian</a>, and <a href="https://x.com/fradamt">Francesco</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-1-introduction-2" name="h-1-introduction-2"></a>1. Introduction</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-11-background-3" name="h-11-background-3"></a>1.1 Background</h3>
<p>As part of the effort to enshrine proposer–builder separation (<a href="https://ethresear.ch/t/minimal-epbs-beacon-chain-changes/18653">ePBS</a>), the role of beacon validators as execution proposers has come under <a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg">scrutiny</a>. <a href="https://ethresear.ch/t/execution-tickets/17944">Execution tickets</a> (ET), first introduced as <a href="https://www.youtube.com/watch?v=IrJz4GZW-VM">attester–proposer separation</a>, is a mechanism for selecting the execution proposer by random draw from a ticket pool, aiming to detach beacon validators from the selection process. However, the mechanism for selling tickets has not been settled, with several <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764#preliminaries-12">alternatives</a> under consideration. A notable <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">concern</a> is that the sale of execution tickets may induce maximal extractable value (MEV). If the mechanism is administered by the consensus layer and the beacon proposer is given too much influence over the price or over the selection of purchasers, the design risks repeating one of the issues it was intended to resolve, with a new source of MEV becoming a concern. An execution layer vending machine raises similar <a href="https://x.com/barnabemonnot/status/1805859642213269739">questions</a>. Therefore, a MEV resistant auction mechanism could be desirable if pursuing ETs.</p>
<p><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">Execution auctions</a> (EA) is a related mechanism for selecting a future execution proposer, omitting the ticket pool. It  relies on a <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">MEV pricing auction</a>, where bidders first make bids that set a <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">floor to the MEV burn</a>, and finally bid through tips in order to be selected by the proposer. Concerns have been raised (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">2</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">3</a>) regarding the viability of MEV pricing auctions due to insufficient bid incentives in the initial phase. It has <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">recently been suggested</a> that this concern is resolved by considering the staking metagame, in which stakers must bid early to deprive other stakers of revenue. However, this resolution implies that EAs will lead to increased staker–builder integration, which might also be a <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856#risks-associated-with-attester-builder-integration-14">cause for concern</a>. For this reason, it seems fruitful to explore an alternative auction mechanism also when selecting the execution proposer without leveraging a ticket pool.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-12-overview-of-proposal-4" name="h-12-overview-of-proposal-4"></a>1.2 Overview of proposal</h3>
<p>This post introduces a dynamic pricing auction with MEV resistance to sell execution proposal rights. Builders hold reserves in a debit account and place binding purchase order for a ticket (ET) or an execution proposal slot (similar to EA). The final price adapts dynamically based on the total outstanding as well as currently incoming orders/tickets, with some similarities to, e.g., <a href="https://github.com/ethereum/EIPs/blob/f93b530c60dc7a88e5b811f9cbdf865ecc1b9b97/EIPS/eip-1559.md">EIP-1559</a>, and the payment is burned. Orders are delimited at the slot level through attester observations to remove agency from the beacon proposers facilitating the auction, thus inducing less new MEV. This produces a high aggregate MEV burn. In one version of the design, dubbed execution ticket auction (ETA), orders that came in during the same slot are sequenced for proposal by leveraging the <a href="https://eth2book.info/capella/part2/building_blocks/randomness/#the-randao">RANDAO</a>. In another version only applicable to ETs, orders that came in during the same slot are minted collectively into tickets. Due to the current limitations of the RANDAO, the mechanism is only capable of auctioning off proposal rights at least one epoch in advance.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-2-purchase-process-5" name="h-2-purchase-process-5"></a>2. Purchase process</h2>
<p>Figure 1 presents the proposed purchase mechanism. Builders send purchase orders (for one ticket/execution slot at a time) over a public P2P layer. They specify a maximum price and hold a debit account within consensus to guarantee that their purchase orders are backed by sufficient funds. This account is funded using a separate transaction (see the discussion).</p>
<p>Beacon attesters observe all orders up to an observation deadline, enacted for example 2 seconds before the slot boundary. The beacon proposer collects all orders (there will be one purchase order per slot on average), including orders they may have found during the last few seconds of their slot. Orders are added as a group to the beacon block and will later be popped from a virtual first-in first-out (FIFO) queue scheduled across blocks. This queue may be just one slot long, depending on implementation.</p>
<p>Attesters reject the block if the beacon proposer fails to include a purchase order that they observed. The mechanism thus far has similarities to MEV pricing auctions (e.g., <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV burn</a>, <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">EA</a>), but attesters are tasked with simply observing all purchases, instead of setting a bid floor. Another design that might come to mind is inclusion lists (ILs) in the style of <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a>, but there is no new active participant in the form of an IL committee.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/0/702bb78973cad1e335953a439305f91bf34e2132.png" title="Figure 1"><img alt="Figure 1" height="424" src="https://ethresear.ch/uploads/default/optimized/3X/7/0/702bb78973cad1e335953a439305f91bf34e2132_2_690x424.png" width="690" /></a></div><p></p>
<p><strong>Figure 1.</strong> Schematic overview of the purchase process. Orders in blue, backed by builders’ debit accounts, are observed by attesters (purple arrows). Beacon proposers subsequently add all incoming orders to the beacon block (dark red arrow). A validity check is performed to ensure that orders are fully backed. Orders are finally processed—using either RANDAO to determine the sequence in cases where several orders came in during the associated slot (yellow), or otherwise using collective minting (red). In ETA, orders are directly queued for proposal.</p>
<p>Once a slot’s orders have been added to the beacon block, a validity check is performed on builders that included at least one new order (cyan in Figure 1). If a builder’s outstanding (not yet processed) orders across the queue are not fully backed by its debit account, all the builder’s pending orders are discarded. A penalty may also be applied. Orders are  priced directly upon being added or, e.g., at the time of sequencing, as described in Section 4. The determined purchase price is charged from the debit account and burned. The remaining ETH of the purchase order is subsequently virtually released such that it can be used to back new purchase orders. Orders are then sequenced and either queued for proposal (yellow arrow) or added to the ticket pool (red arrow), as described in Section 3.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-3-sequencing-process-6" name="h-3-sequencing-process-6"></a>3. Sequencing process</h2>
<p>The purchase orders from the same slot are added unsequenced to the beacon block. The subsequent sequencing of orders from the same slot varies between designs.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-31-et-minting-of-execution-tickets-7" name="h-31-et-minting-of-execution-tickets-7"></a>3.1 ET – Minting of execution tickets</h3>
<p>The natural strategy for ETs is <em>collective minting</em>, wherein all orders from the same slot mint a ticket at the same time, as indicated by the red arrow in Figure 1. The RANDAO used for ETA in the next subsection could also be applied to ETs using the same setup (dashed yellow arrow). However, the only real benefit (which remains marginal) is to facilitate a more even replenishment of the ticket pool.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-32-eta-orders-sequenced-by-randao-8" name="h-32-eta-orders-sequenced-by-randao-8"></a>3.2 ETA – orders sequenced by RANDAO</h3>
<p>Purchase orders that came in during the same slot can be sequenced directly by the RANDAO, completely skipping a ticket pool. Perhaps <em>execution ticket auction</em> (ETA) would be a proper moniker. Indeed, with this design, a buyer will have an <em>Estimated Time of Arrival</em> for their order, which suitably cannot be precisely known beforehand if there is more than one order in the slot. Barnabé’s discussion (<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">1</a>, <a href="https://x.com/barnabemonnot/status/1805872045302898807">2</a>) on the topic of ETs and determinism is relevant here.</p>
<p>Orders can only be sequenced after the RANDAO has been updated. Therefore, there is an initial ineligibility window <span class="math">W</span> during which orders cannot lead to an execution proposal. The RANDAO updates every 32 slots, but the proposed mechanism does not guarantee a new order every slot; in fact, the mode will be zero orders in a slot. Consequently, the safe distance between auction and slot proposal will need to be somewhat longer than 32 slots. Sequenced orders can be understood as sitting in a second FIFO queue while waiting to propose. Note that ETA could set the queue to hold as many proposal rights as the ticket pool, if desirable.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-4-dynamic-pricing-9" name="h-4-dynamic-pricing-9"></a>4. Dynamic pricing</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-41-ticket-saturation-and-delta-10" name="h-41-ticket-saturation-and-delta-10"></a>4.1 Ticket saturation and delta</h3>
<p>The exploration of dynamic pricing will refer to processed orders as “tickets”, although in the ETA design these are just sitting in the ordered queue waiting to propose. The protocol strives to ensure that there are <span class="math">\hat{T}</span> outstanding tickets at any time. The price of a new ticket should be determined by the current number of outstanding tickets <span class="math">T</span> as well as the current supply of purchases and purchase orders <span class="math">T_p</span>, measured over some window of length <span class="math">W_T</span>, which in some versions can be only one slot long.</p>
<p>Define the ticket saturation as <span class="math">T_s=T-\hat{T}</span>. If <span class="math">T_s&lt;0</span>, there are too few tickets, and the protocol would in general like to sell more than one ticket per slot. If <span class="math">T_s&gt;0</span>, there are too many, and it would in general like to sell fewer than one. The delta <span class="math">T_{\delta}=T_p-W_T</span> gives purchase orders relative to an expectation of one ticket per slot, which is the rate at which tickets are consumed by execution proposers. If <span class="math">T_{\delta}&lt;0</span>, the protocol is selling fewer than one ticket per slot and would in general like to sell more. If <span class="math">T_{\delta}&gt;0</span>, it sells more than one and would in general like to sell fewer.</p>
<p>If both <span class="math">T_s</span> and <span class="math">T_{\delta}</span> are negative, the protocol should decrease the ticket price to sell more tickets. If both <span class="math">T_s</span> and <span class="math">T_{\delta}</span> are positive, it should increase the price to sell fewer. The less trivial question is how to approach a situation when one of the variables is negative and the other is positive, how to window sales, and how quickly to adjust the price.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-42-dynamic-pricing-mechanism-11" name="h-42-dynamic-pricing-mechanism-11"></a>4.2 Dynamic pricing mechanism</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-421-overview-12" name="h-421-overview-12"></a>4.2.1 Overview</h4>
<p>The price of tickets adjusts on a relative basis, just like in EIP-1559, gradually shifting by some proportion of the current price each slot. To improve MEV resistance and adapt to the problem at hand, three differences to EIP-1559 however seem useful: (1) the price should depend on orders included in the current slot, not only the preceding; (2) the block should never be “full”, lest the ticket price becomes very high; (3) the mechanism should be “two-dimensional” in the sense that it accounts for both ticket saturation and delta.</p>
<p>This subsection begins by exploring the simplest realization of such a pricing mechanism, which will then gradually be expanded. In the simplest design, <span class="math">W_T=1</span>, and orders can be priced directly when added to the beacon block. If there is one new order (<span class="math">T_{\delta}=0</span>) and the number of outstanding tickets is as desired (<span class="math">T_s=0</span>), the price stays the same. If there are many new orders (a sudden spike in the expected MEV), the pricing mechanism will hike the price substantially. For example, if 100 orders were to come in, the purchase price for them could rise by orders of magnitude; the exact specification would need to be determined based on other auction paramters such as the size of the ticket pool. Builders will of course track incoming orders in real time and update their estimate of the final purchase price. Therefore, even during a sudden rise in expected MEV, there will only be new orders up to the point where the deduced price matches expected MEV.</p>
<p>As another option, <span class="math">W_T</span> can be longer, setting the price <span class="math">W</span> slots after orders have been added to the beacon block. In Figure 1, <span class="math">W=3</span>. An asymmetric window spanning 4 slots up to and including the processing slot is then an option. The most important benefit is MEV resistance during spikes, as will be further discussed in Section 4.3. Other potential benefits include better pricing granularity, a more complete picture when pricing orders, and the marginal simplification in ETA from pricing and sequencing orders at the same. Of course, it can be argued that the picture already is “complete” in the sense that builders can indicate expected MEV already at the current slot, albeit they may not be fully equipped to evaluate incoming orders in real-time. It can also be argued that <span class="math">W&gt;0</span> and <span class="math">W_T&gt;1</span> needlessly increase uncertainty and analytical complexity for builders as well as developers. As an example, builders may place an order several slots before a spike, but still need to pay closer to the real expected value of the MEV they are about to receive (priced closer to proposal time).</p>
<h4><a class="anchor" href="https://ethresear.ch#h-422-equations-13" name="h-422-equations-13"></a>4.2.2 Equations</h4>
<p>A rudimentary example will now be provided. Should this general mechanism be pursued, the exact price controller would have to be determined by reasoning about how quickly the price should adapt to changes in the willingness to buy tickets, sensitivity to ticket saturation, interplay between saturation and delta, sensitivity to MEV induction (see the next subsection), and by running simulations of the purchase process.</p>
<p>Ticket saturation and delta from the previous subsection is first weighed by window length and desired number of outstanding tickets</p>
<div class="math">
w_s=\frac{T_s}{c_s\hat{T}}, \quad w_{\delta}=\frac{T_{\delta}}{c_{\delta}W_T},
</div>
<p>using the constants <span class="math">c_s=2^3</span> and <span class="math">c_{\delta}=2^6</span>. The percentage change <span class="math">w</span> to the ticket price applied each slot (minting <span class="math">n</span> orders) is</p>
<div class="math">
w=(1+w_s)(1+w_{\delta})^k.
</div>
<p>This post uses <span class="math">k=2</span>, ensuring a non-linear price response as <span class="math">T_{\delta}</span> grows. This can be particularly relevant at shorter windows <span class="math">W_T</span>. Setting <span class="math">k=3</span> is also viable. The constant <span class="math">c_{\delta}</span> can then alternatively be increased to offer better pricing granularity at a lower ticket delta, while still offering some guarantees regarding the maximum number of orders that may come in during one slot. The price <span class="math">p</span> updates from its level at the previous slot <span class="math">p_0</span> to its level at the present slot <span class="math">p_1</span> as</p>
<div class="math">
p_1=w \times p_0.
</div>
<h4><a class="anchor" href="https://ethresear.ch#h-423-visualizations-14" name="h-423-visualizations-14"></a>4.2.3 Visualizations</h4>
<p>Figure 2 illustrates what a pricing schedule according to <span class="math">w</span> would look like for the outlined equations, with <span class="math">\hat{T}=4096</span> and <span class="math">W_T=32</span>. The yellow band stipulates no price change (<span class="math">w=1</span>), and passes through the intersection of the black lines, which correspond to a neutral ticket delta (x-axis) and saturation (y-axis). There have been suggestions of much <a href="https://www.youtube.com/watch?v=IrJz4GZW-VM">higher</a> <span class="math">\hat{T}</span>. This issue relates to a wide range of <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">considerations</a> that are not the focus of this post.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/8/383433ceb5b2bfb3db8a88907125d3d913dc871b.png" title="Figure 2"><img alt="Figure 2" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/3/8/383433ceb5b2bfb3db8a88907125d3d913dc871b_2_668x500.png" width="668" /></a></div><p></p>
<p><strong>Figure 2.</strong> Rudimentary example for <span class="math">W_T=32</span> of a percentage change in ticket price  that varies with delta in ticket sales and the overall saturation of tickets in the pool. Black lines indicate a neutral delta (one ticket sold per slot) and saturation (<span class="math">T=\hat{T}</span>).</p>
<p>Figure 3 instead shows a pricing schedule when <span class="math">W_T=1</span> using the same equation and settings as previously. If no orders come in during the measured slot, <span class="math">T_{\delta}=-1</span>. Note that the colormap is log-scaled to capture the large increase in <span class="math">w</span> that is instituted if 64 orders were to come in during a single slot. When <span class="math">T_W=32</span> (Figure 2), a large jump in orders would affect the price for 32 consecutive slots (assuming an asymmetric window), before the purchase takes place, and so <span class="math">w</span> will naturally be lower on a per-slot basis.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4f34c0d1471b29367616a9d71dc0a1fe156cfd73.png" title="Figure 3"><img alt="Figure 3" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4f34c0d1471b29367616a9d71dc0a1fe156cfd73_2_659x500.png" width="659" /></a></div><p></p>
<p><strong>Figure 3.</strong> Rudimentary example for <span class="math">W_T=1</span> of a percentage change in ticket price that varies with delta in ticket sales and the overall saturation of tickets in the pool. Black lines indicate a neutral delta (one ticket sold in the slot) and saturation (<span class="math">T=\hat{T}</span>).</p>
<p>The relative change at <span class="math">W_T=1</span> for different <span class="math">T_{\delta}</span> is shown in Figure 4, at a neutral ticket saturation (<span class="math">T_s=0</span>). The price change instituted with this setting for between 0 to 4 orders is {0.969, 1, 1.031 1.063 1.096}. The same granularity can be preserved at lower quantities of orders while further raising the price at higher quantities, by increasing <span class="math">k</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/1/b1cd5d40cffb62dcaa44cc90cb317c9a4f0ebb76.png" title="Figure 4"><img alt="Figure 4" height="325" src="https://ethresear.ch/uploads/default/optimized/3X/b/1/b1cd5d40cffb62dcaa44cc90cb317c9a4f0ebb76_2_690x325.png" width="690" /></a></div><p></p>
<p><strong>Figure 4.</strong> Rudimentary example for <span class="math">W_T=1</span>, focusing on the relative price change <span class="math">w</span> across <span class="math">T_{\delta}</span> at a neutral saturation. If 60 orders come in during a single slot, the price rises sharply.</p>
<p>Figure 5 instead plots the response at <span class="math">T_{\delta}=-1</span> across <span class="math">T_s</span>. In other words, it shows how the price would change if no purchase orders are registered.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/8/885e3dfacabd2f85c9ee4480a30e67576cb30f5b.png" title="Figure 5"><img alt="Figure 5" height="312" src="https://ethresear.ch/uploads/default/optimized/3X/8/8/885e3dfacabd2f85c9ee4480a30e67576cb30f5b_2_690x312.png" width="690" /></a></div><p></p>
<p><strong>Figure 5.</strong> Rudimentary example for <span class="math">W_T=1</span>, focusing on the relative price change <span class="math">w</span> across <span class="math">T_s</span> when no purchase order comes in.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-43-slot-surge-pricing-15" name="h-43-slot-surge-pricing-15"></a>4.3 Slot surge pricing</h3>
<p>In the outlined pricing mechanism, there is a remaining opportunity for the beacon proposer to derive some MEV at shorter windows <span class="math">T_W</span>. This happens during a sudden spike in interest for purchasing tickets between the point where attesters have observed purchase orders and the slot boundary.</p>
<p>Let <span class="math">n_a</span> be the equilibrium quantity of orders that would have come in during a slot if a spike happened before the attester observation deadline (purple arrows in Figure 1). Builders keep track of incoming orders and calculate the current ticket price, which when compared to the updated expected MEV <span class="math">V_e</span> produces <span class="math">n_a</span> orders. If a spike comes in after the attester deadline, the proposer has exclusivity and could (be paid to) include only a subset of the orders <span class="math">n_p</span>. The surplus MEV for the proposer emerges from providing a lower expected purchase price for each order it lets through. This is a monopoly pricing regime, wherein the proposer sells spots at a price approaching <span class="math">V_e-p_1</span>. It determines <span class="math">n_p</span> to maximize its revenue <span class="math">R(n_p)</span>, in accordance with the revenue function:</p>
<div class="math">
\text{Maximize} \quad R(n) = n (V_e(n) - p_1(n)).
</div>
<p>Here, <span class="math">p_1(n)</span> is based on the price equation provided in the previous subsection. Also note that if many purchase orders come in, <span class="math">V_e</span> might gradually fall (if there is a temporary spike); hence <span class="math">V_e(n)</span>. If the potential price increase between beacon slots is set to be more moderate, while prices still can surge from a high quantity of purchased tickets within a single slot, the proposer’s potential revenue would be reduced. The proposer can then sell fewer spots at a lower price. One way to do this is to set the price in the current slot as previously</p>
<div class="math">
p_1=w \times p_0,
</div>
<p>but to not incorporate the full price change when setting the value <span class="math">p^*_0</span> that will be used as <span class="math">p_0</span> when pricing the next slot</p>
<div class="math">
p^*_0=\left(1+\frac{1-w}{c_w}\right) \times p_0.
</div>
<p>The constant <span class="math">c_w</span> is set above 1, e.g., <span class="math">c_w=2</span>. During a spike in expected value up to a new baseline <span class="math">V_e</span>, the price would then theoretically stay rather fixed (at a new higher level) for subsequent slots, with the number of orders in each slot gradually decreasing, until it proceeds at the regular pace of one purchase order per slot. Yet note that if <span class="math">V_e</span> rises from a temporary opportunity, there will be a bit more MEV for the proposer to extract still, because a lot of the value can depend on getting in early. This also depends on if the mechanism is ET or ETA and the size of the ticket pool. The discussion offers some further thoughts on the proposer’s ability to extract MEV.</p>
<p>As a concluding remark, it should always be remembered that a big ticket pool acts to temper fluctuations in the expected value of tickets. The buyer does not necessarily buy the right to sell tickets within the next couple of epochs, but rather within the next couple of hours, days, weeks or months, depending on the setting for <span class="math">\hat{T}</span>—and it turns out that when measured over longer periods, the level of the MEV has been <a href="https://youtu.be/IrJz4GZW-VM?feature=shared&amp;t=1241">very stable</a> in Ethereum.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-44-the-role-of-a-maximum-price-16" name="h-44-the-role-of-a-maximum-price-16"></a>4.4 The role of a maximum price</h3>
<p>Each buyer assigns a max price to the order. This is the value that needs to be backed by the debit account. If the max price is insufficient at the time of pricing, such that the actual price is higher, the builder does not receive a ticket/slot. Yet builders could make unbacked orders to starve off competitors, which would bring down the purchase price. It seems desirable to not force builders to analyze the balances of every competitor to determine which bids are real and which are “fake”. One simple way to avoid such a situation is to penalize builders for placing orders that turn out to be unbacked at the time of purchase. This can potentially be combined with setting a validity rule requiring some minimum max price, either relative to the prevailing price at bid time, or/and as a fixed overall minimum.</p>
<p>Penalizing builders however exacerbates another potential issue. During an unforeseen spike in expected MEV, there are circumstances where a builder could “liquidate” its competitors’ bids if the current purchase price is close to their stipulated maximum. A builder could enter new bids forcing other builders out, to penalize them and gain cheaper tickets. For this reason, the mechanism could reduce gameability and the risks as well as improve capital efficiency for builders by stipulating an absolute maximum purchase price. A builder that bids the absolute maximum is guaranteed to not get liquidated and will always receive a ticket. This does not mean that the protocol will burn less MEV, merely that in times of extremely high expected MEV, there will temporarily be a higher quantity of bids, wherein each order has a lower chance of actually getting one of the desirable profitable slots.</p>
<p>What should the absolute maximum be set to if this path is pursued? In <a href="https://flashbots-data.s3.us-east-2.amazonaws.com/index.html">data</a> provided by <a href="https://www.flashbots.net/">Flashbots</a> spanning 2.7 million blocks between the last quarter of 2022 and the third quarter of 2023, the maximum average <a href="https://hackmd.io/@flashbots/quantifying-REV">REV</a> across 64 slots is 19.5 ETH. The peak average is skewed by a few spurious blocks with REV of several 100 ETH that may have been hard to predict beforehand. This average does therefore not represent a realistic expected MEV for builders bidding many slots in advance. Expand the window by a factor of 4 to 256 and the maximum average falls almost by a factor of 4, to 5.25. Setting the absolute maximum to 5 ETH would thus presumably not influence the auction even in times of extreme market conditions, since that price would hardly ever be reached.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-5-discussion-17" name="h-5-discussion-17"></a>5. Discussion</h2>
<p>A MEV resistant dynamic pricing auction for selling execution proposal rights has been presented, relevant to the research of both ETs and EAs. It seeks to remove agency from the beacon proposer, thus inducing less MEV. This is achieved by having every order result in a sale, and every order coming in during the same slot having the same expected sales price. The execution ticket auction (ETA) sequences orders directly for proposal by leveraging the RANDAO. Orders that came in during the same slot can otherwise be minted collectively into tickets, with sequencing pursued at a later stage in accordance with the ET proposal.</p>
<p>If pursuing this auction mechanism, the dynamic pricing step would require substantial analysis. One sensitive part is the balance between moderating changes in the supply of orders while still offering sufficient pricing granularity. A high <span class="math">k</span> can be useful here. Another potential avenue is to hold the auction less frequently. The expected timing of orders within the slot would also be interesting to study—orders can be placed early to starve off others, or late to gain better information. One could even theorize that some builders will wait until after the attester deadline, and then pay the proposer a small fee for exclusive post-deadline inclusion (the benefit being to avoid race conditions).</p>
<p>Transactions to fund or withdraw from a builder’s debit account would need to be synchronized with the validity check to avoid race conditions. It may be convenient to expand the role of the debit account if it is desirable to subject builders to slashing or penalties at the execution proposal stage. In other words, the debit account might also function as a stake.</p>
<p>Just as with MEV pricing auctions, attesters accepting or rejecting a block based on some observation deadline is potentially sensitive. However, this particular design should hopefully be less so, since there will only be one order on average per block to observe, and less value (even potentially negative) in bidding later in the block. A potential benefit of an auction administered instead at the execution layer is the “endogenous” component, facilitating a higher burn; the value of a ticket increases if the current ticket holder can extract value from future ticket holders through MEV. However, this direction raises gameability concerns if a single actor can come to monopolize the auction (ILs may here be useful). A MEV resistant mechanism, as here proposed, originating at the consensus layer, therefore seems like a viable direction.</p>
<p>It might seem tempting to replicate some facets of the proposed design for transaction processing: making the protocol more MEV resistant by having attesters observe transactions, the protocol sequence them by RANDAO, and the price adjust in a slot-attentive fashion. However, the requirements for transactions are different than for the purchase orders of execution rights analyzed in this post (e.g., time, quantity). Translating the ideas of this post directly to transaction processing might therefore unfortunately be difficult. Yet the proposed mechanism could perhaps lend some inspiration going forward.</p>
<p>It should be noted that multi-block MEV is a separate topic of concern. The proposed mechanism is resistant to inducing MEV at the purchase stage but does not preclude multi-block MEV. This is a general issue and an underexplored topic at this point in time. Censorship resistance is likewise an important problem not addressed by the auction mechanism. Various strategies, such as ILs (<a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">1</a>, <a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">2</a>, <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">3</a>), have been proposed. Whether the presented auction mechanism can be one part of an overall architecture that also tackles other issues remains to be explored.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 09 Jul 2024 10:52:26 +0000</pubDate>
</item>
<item>
<title>Deep Diving Attestations - A quantitative analysis</title>
<link>https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020</link>
<guid>https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#deep-diving-attestations-1" name="deep-diving-attestations-1"></a>Deep Diving Attestations</h1>
<p><em>I want to provide some quantitative stats on…</em></p>
<ul>
<li><em>Head</em>-, <em>target</em>-, and <em>source</em> votes,</li>
<li>The individual node operators’ attestation performance, including the best and worst validators,</li>
<li>Attestation <em>timing</em> and <em>inclusion delay</em>, and</li>
<li>The impact of <em>MEV-Boost, CL clients, Proposer Timing Games</em> and <em>Big Blocks with Blobs</em> on attestation accuracy.</li>
</ul>
<p><img alt="doge" height="458" src="https://ethresear.ch/uploads/default/original/3X/2/a/2a11d5d44000665f0ed449873280783c5e163cd6.png" width="459" /></p>
<p><em>Many thanks to <a href="https://x.com/casparschwa">Caspar</a>, <a href="https://x.com/dapplion">DappLion</a>, <a href="https://x.com/barnabemonnot">Barnabé</a> and <a href="https://x.com/potuz_eth">Potuz</a> for their feedback and review!</em></p>
<h2><a class="anchor" href="https://ethresear.ch#data-2" name="data-2"></a>Data</h2>
<p>I use data ranging from slot 9,169,184 to slot 9,392,415, amounting to 6,975 epochs, 31 days of data.<br />
The goal is to provide some initial results from analyzing attestations, as a warm-up for analyzing correlated attestation penalties (<a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716</a>).<br />
Some of the data is collected by myself using custom parsing scripts. Other data was provided by <a href="https://ethpandaops.io/">EthPandaOps</a>. This includes timing data collected from running nodes of <strong>every client</strong> in the regions <strong>Sydney</strong>, <strong>Helsinki</strong>, and <strong>San Francisco</strong>, with all nodes being <strong>subscribed to all subnets</strong>. For classifying CL clients, the <a href="https://github.com/sigp/blockprint">blockprint</a> tool was used.</p>
<blockquote>
<p>Importantly, my solo staker categorization is done very conservatively to avoid confusing professional entities with solo stakers. In total, my dataset contains 8,488 validators classified as solo stakers.</p>
</blockquote>
<p>The code for creating the charts is published in <a href="https://github.com/nerolation/eth-deep-diving-attestations">this repo.</a></p>
<h2><a class="anchor" href="https://ethresear.ch#attestations-3" name="attestations-3"></a>Attestations</h2>
<h3><a class="anchor" href="https://ethresear.ch#the-basics-4" name="the-basics-4"></a>The Basics</h3>
<p><a href="https://eth2book.info/capella/part2/consensus/">Attestations</a> are at the core of Ethereum. Through attesting to past checkpoints, Ethereum’s validators agree on a state to become irreversible (<a href="https://eth2book.info/capella/part2/consensus/casper_ffg/">Casper FFG</a>). Furthermore, validators use attestations to agree upon the tip of the chain, deciding which transactions get confirmed and which don’t (<a href="https://eth2book.info/capella/part2/consensus/lmd_ghost/">LMD GHOST</a>).<br />
Every validator, backed by its stake, participates in every epoch and is randomly assigned a slot, during which it is expected to broadcast its view of the chain through attesting.</p>
<p><strong>An attestation contains three things:</strong></p>
<ul>
<li>A <em>source</em> vote: The block (and all predecessors) to be finalized</li>
<li>A <em>target</em> vote: The block (and all predecessors) to be justified (=pre-finalized)</li>
<li>A <em>head</em> vote: The block seen as the head of the chain.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/8/98c353dd9366c270a1d3ef3b75c9efaec79c4fcd.png" title="epochslotvalidator"><img alt="epochslotvalidator" height="182" src="https://ethresear.ch/uploads/default/optimized/3X/9/8/98c353dd9366c270a1d3ef3b75c9efaec79c4fcd_2_690x182.png" width="690" /></a></div><p></p>
<p>Since the <a href="https://ethereum.org/en/history/">Deneb hardfork</a> that included <a href="https://eips.ethereum.org/EIPS/eip-7045">EIP-7045</a>, attestations for a slot in epoch N can be included up until the end of epoch N+1. However, <a href="https://eth2book.info/capella/part2/incentives/rewards/">inclusion doesn’t guarantee a reward</a>:<br />
To be rewarded, a validator must ensure its source vote is included within 5 slots. The target vote has to be included within 32 slots to be rewarded. Head votes must be included in the following slot to be eligible for a reward.</p>
<p>As of today, Ethereum counts <a href="https://beaconcha.in/charts/validators">~1.03</a> million validators. This means we have 1.03 million votes every epoch, ~32,000 every slot. In one day, with 225 epochs, there are approximately 225 million attestations. This data grows quite fast.</p>
<p>If the <strong>source vote</strong> is <strong>invalid</strong>, then the <strong>target</strong> and <strong>head vote</strong> <strong>MUST</strong> be <strong>invalid</strong> too.</p>
<p>A slot can be broken down into 3 phases:<br />
<img alt="slottime" height="92" src="https://ethresear.ch/uploads/default/original/3X/e/2/e2bf8c2e61a6f0079f45f24b5648a1d68f960153.png" width="632" /></p>
<ol>
<li>Validators attest when they have seen a block for the current slot or at second 4 in the slot - the attestation deadline. A block broadcasted at second 0 in the slot has 4 seconds to be seen by all relevant validators and collect votes. Late blocks risk not receiving enough attestations and being reorged by a subsequent block.</li>
<li>Between second 4 and 8 in the slot, attestations are <a href="https://eth2book.info/capella/part2/building_blocks/aggregator/">aggregated</a> and broadcasted by selected validators.</li>
<li>Eventually, the subsequent block proposer includes them into its block.</li>
</ol>
<blockquote>
<p>For more in-depth explanations check out this post by Georgios and Mike on “<a href="https://www.paradigm.xyz/2023/04/mev-boost-ethereum-consensus">Time, slots, and the ordering of events in Ethereum Proof-of-Stake</a>”.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#definitions-5" name="definitions-5"></a>Definitions</h3>
<p><strong>Missed vs. Failed:</strong></p>
<ul>
<li>A validator can either <strong>miss</strong> its attestation (<em>missed</em>) or attest to a <strong>wrong</strong> checkpoint (<em>failed</em>).</li>
<li><strong>Missed attestations</strong> can happen if the node running the validator is out of sync or offline.</li>
<li><strong>Voting for a wrong checkpoint</strong>, e.g. a wrong head, can have various reasons like receiving a block too late, being out of sync or even having a bug, etc.</li>
<li><strong>Regardless of the reason, a <em>failed</em> vote tells us one important fact about a validator—it is online.</strong></li>
</ul>
<p>In the following, we’ll also need the term <em><strong>“high-performing validator”</strong></em> which is a validator that hasn’t failed to cast a correct and timely head vote over the complete time frame analyzed.</p>
<h3><a class="anchor" href="https://ethresear.ch#attestation-inclusion-delay-6" name="attestation-inclusion-delay-6"></a>Attestation Inclusion Delay</h3>
<p>In the best case, attestations are included in the block of the <strong>next slot</strong>, causing a <strong>delay of 0</strong>. Sometimes, especially when the next proposer is offline or gets reorged, attestations are not included in the next slot. Then, the validator misses out on the rewards from the correct head vote, even though the attestation can still be included in a later block.</p>
<p>The following chart shows the distribution of the inclusion delay over seconds 1-63 and the <strong>clients the attesters were using</strong>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/d/fd890aacb6b6636f2240881d9dbbaa7b721face8.png" title="correct_head_delay_clients"><img alt="correct_head_delay_clients" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/f/d/fd890aacb6b6636f2240881d9dbbaa7b721face8_2_690x316.png" width="690" /></a></div><p></p>
<ul>
<li>95.85% of attestations are included in the next slot.</li>
<li>~1.2% of attestations are included in the slot after the next.</li>
<li>When a new epoch begins, old attestations are again picked up and finally included.
<ul>
<li>This is weird (<em>but there’ll be an explanation little down below</em>).</li>
<li>Attestations of validators of all clients are affected.</li>
</ul>
</li>
</ul>
<p><strong>This raises the question, “<em>what are clients doing?</em>”</strong></p>
<p>Examples include slots <strong><a href="https://beaconcha.in/slot/9267438#attestations">9267438</a></strong> with a delay of 35 (5250 validators), <strong><a href="https://beaconcha.in/slot/9267425#attestations">9267425</a></strong> with a delay of 52 (1813 validators), or slot <strong><a href="https://beaconcha.in/slot/9267427#attestations">9267427</a></strong> with a delay of 36 slots (1305 validators).</p>
<p>What if those late attestations were already included earlier and were later just included again (h/t <a href="https://github.com/dapplion">dapplion</a>)? To analyze that, we reproduce the above chart but separate by <em><strong>first inclusion</strong></em> and <em><strong>every following inclusion</strong></em>:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/8/a8cfb4ec1e6b9486dbafddb9587eeb55be1b3d1c.png" title="correct_head_delay_reinclusion"><img alt="correct_head_delay_reinclusion" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/a/8/a8cfb4ec1e6b9486dbafddb9587eeb55be1b3d1c_2_690x316.png" width="690" /></a></div><p></p>
<p>First, it is interesting that almost <strong>half of the attestations included with a delay of 1 slots</strong> (note: best is 0) <strong>have already been included in an earlier slot</strong>. This is possible because proposers are free to pick attestations that have already been included in the past 63 slots and include them again. Additionally, a block can contain the same attestations multiple times, aggregated differently.</p>
<p>We can see that the majority of the attestations included in the second hump with a delay of around 35 slots are <strong>reincluded</strong> attestations.</p>
<p>This raises the question, “<em>why does this occur with a delay of more than 32 slots?</em>”</p>
<p>In <strong>percentage</strong> terms, we can see the <em>first inclusion</em> share reducing over an increasing delay:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/e/5e9f624dcd52ea92cbfedbd5d0da5ebf1f2113e3.png" title="correct_head_delay_reinclusion_per"><img alt="correct_head_delay_reinclusion_per" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/5/e/5e9f624dcd52ea92cbfedbd5d0da5ebf1f2113e3_2_690x316.png" width="690" /></a></div><p></p>
<p>To dig deeper into this reinclusion finding, let’s check the <strong>CL clients that built the blocks</strong> that included attestations with &gt;32 slots delay:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/2/62e38ffb13e5375a76e8d567990bbf2dfcd0c9e6.png" title="correct_head_delay_clients_proposers"><img alt="correct_head_delay_clients_proposers" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/6/2/62e38ffb13e5375a76e8d567990bbf2dfcd0c9e6_2_690x316.png" width="690" /></a></div><p></p>
<p>We can see quite clearly that it’s mainly Prysm proposers who include attestations that have already been included earlier, which is very likely a bug.</p>
<blockquote>
<p>The fact that the plot also shows other clients affected might stem from inaccuracies in classifying clients probabilisticly.</p>
</blockquote>
<p><em>The Prysm team was notified.</em></p>
<p><strong>Edit</strong>: <em>The Prysm team was faster in fixing the bug than I was in finishing this post.</em></p>
<p><strong>Fix</strong>: <a class="inline-onebox" href="https://github.com/prysmaticlabs/prysm/pull/14156#event-13323121631">Increase attestation seen cache exp time to two epochs by terencechain · Pull Request #14156 · prysmaticlabs/prysm · GitHub</a></p>
<h2><a class="anchor" href="https://ethresear.ch#missedfailed-attestations-7" name="missedfailed-attestations-7"></a>Missed/Failed Attestations</h2>
<h3><a class="anchor" href="https://ethresear.ch#missedfailed-head-votes-8" name="missedfailed-head-votes-8"></a>Missed/Failed Head Votes</h3>
<p><strong>Head votes</strong> are the <strong>most difficult</strong> part of an attestation. They need to be cast correctly and timely. Per <a href="https://github.com/ethereum/consensus-specs/blob/1642610bd5994d344fb1b6a9f44ec0e14a527580/specs/phase0/validator.md#attesting">honest validator spec</a>, <strong>validators have 4 seconds</strong> to receive and validate a block for the current slot. If no block is received until second 4, validators attest to the block in the previous slot. <strong>Timeliness in the context of head votes means 1 slot.</strong> Although older head votes can be included, there is no reward for the respective validator.</p>
<blockquote>
<p>The legend is ordered in descending order by the sum of missed votes.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/3/2317707179ceb2e3d59cebbda6ca85119edb590e.png" title="missed_head_votes_over_date"><img alt="missed_head_votes_over_date" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/2/3/2317707179ceb2e3d59cebbda6ca85119edb590e_2_690x380.png" width="690" /></a></div><p></p>
</blockquote>
<p><strong>On average, we observe around ~500 missed or wrong head votes out of ~32k validators per slot and ~16k, out of ~1m, per epoch. This represents around 1.56%.</strong></p>
<blockquote>
<p>The entity labeled as <em>unidentified</em> may consist of multiple independent parties, including solo stakers and entities that haven’t been identified yet, and it has a total market share of 20% of all validators.</p>
</blockquote>
<p>Assuming every node operator performs equally, the market share of each entity should reflect its share of missed head votes. However, this is not the case and we see certain node operators being superior compared to others.</p>
<p><strong>The following chart visualizes the delta in the expected number of missed head votes based on market share and the actual number of missed attestations.</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/7/971dec860541e8e89421505e5ebabcbe71d6154a.png" title="delta_missed_head_votes"><img alt="delta_missed_head_votes" height="335" src="https://ethresear.ch/uploads/default/optimized/3X/9/7/971dec860541e8e89421505e5ebabcbe71d6154a_2_690x335.png" width="690" /></a></div><p></p>
<p>While entities such as <em>Kiln</em>, <em>Ether_fi</em>, <em>Lido</em>, <em>Renzo</em>, <em>Figment</em>, and <em>Stakefish</em> perform better than the average, we observe that Rocketpool validators, Kraken validators, and solo stakers miss up to 3% more head votes than their market share.</p>
<p><strong>Focusing on the slot indices in epochs, we distinguish between missing a head vote due to being offline and voting for the wrong head.</strong></p>
<p>The following chart shows the average number of missed/wrong head votes over the slots of an epoch:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/9/f975b9422a722e62e609aa65aaa40ecc1f722ac7.png" title="failed_missed_head_votes"><img alt="failed_missed_head_votes" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/f/9/f975b9422a722e62e609aa65aaa40ecc1f722ac7_2_690x316.png" width="690" /></a></div><p></p>
<p>From the above chart, we can infer:</p>
<ul>
<li>There is a fairly <strong>constant number of <em>missed</em> head votes</strong>.
<ul>
<li><strong>This is expected</strong> as <em>lost-key validators</em> contribute a constant portion to that category.</li>
</ul>
</li>
<li>The beginning of an epoch, particularly the first slot, has significantly more wrong head votes than the rest.
<ul>
<li><strong>This is expected</strong> because the proposer in the first slot has to carry out the <strong>epoch transition</strong>. It must then broadcast that block to reach all attesters. T</li>
</ul>
</li>
<li>The average amount of missed/wrong head votes is <strong>3 times larger</strong> in the first slot of an epoch than in the epochs 2-32.</li>
</ul>
<p>Focusing on missed head votes and CL clients, we cannot see anything suspicious in the following chart:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/7/f7cbecfb8118dcd5ca0e37e04df641e8c1c994e4.png" title="failed_missed_head_votes_over_clclient"><img alt="failed_missed_head_votes_over_clclient" height="287" src="https://ethresear.ch/uploads/default/optimized/3X/f/7/f7cbecfb8118dcd5ca0e37e04df641e8c1c994e4_2_690x287.png" width="690" /></a></div><p></p>
<p>In general, it looks like all CL clients are affected by early-in-epoch misses the same:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/5/75c8e90cf46709ceb37998916b3ea77c7b9dfe88.png" title="failed_missed_head_votes_over_clclient_over_slot"><img alt="failed_missed_head_votes_over_clclient_over_slot" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/5/75c8e90cf46709ceb37998916b3ea77c7b9dfe88_2_690x316.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#missedfailed-target-votes-9" name="missedfailed-target-votes-9"></a>Missed/Failed Target Votes</h3>
<p>Target votes are already easier to get right. The only exception is the first slot of an epoch that follows the <strong>epoch boundary</strong>: In such cases, the head vote equals the target vote and validators having their target vote wrong tend to vote for the parent block (=the block in the last slot of the previous epoch) instead.</p>
<p>On average, we observe around 150 missed target votes per slot and 4,800 per epoch. This represents around <strong>0.48%</strong> of all validators.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/7/570b69e8ccefa7585e259961fa4afa09206a1663.png" title="missed_target_votes_over_date"><img alt="missed_target_votes_over_date" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/5/7/570b69e8ccefa7585e259961fa4afa09206a1663_2_690x380.png" width="690" /></a></div><p></p>
<p>Visualizing the same over the different CL clients, we see all clients affected to extents close to their market share.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/8/b8284e30b6f3f61ed8a95d5989a6417c275f82bc.png" title="failed_missed_target_votes_over_clclient"><img alt="failed_missed_target_votes_over_clclient" height="287" src="https://ethresear.ch/uploads/default/optimized/3X/b/8/b8284e30b6f3f61ed8a95d5989a6417c275f82bc_2_690x287.png" width="690" /></a></div><p></p>
<p>Looking at the entities that perform better than others, we again see operators such as Lido, Renzo, Mantle, Coinbase, etc. outperforming the average.</p>
<blockquote>
<p>Notably, Lido isn’t a single NO but consists of multiple operators that I combined for simplicity.</p>
</blockquote>
<p>On the other hand, Rocketpool validators and solo stakers perform worse and miss up to 3% more target votes than expected.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/7/17818eccecb8186179f09dbfb5b0fc3de023f5dc.png" title="delta_missed_target_votes"><img alt="delta_missed_target_votes" height="335" src="https://ethresear.ch/uploads/default/optimized/3X/1/7/17818eccecb8186179f09dbfb5b0fc3de023f5dc_2_690x335.png" width="690" /></a></div><p></p>
<p>As seen in <a href="https://ethresear.ch/t/the-second-slot-itch-statistical-analysis-of-reorgs/16333">previous analysis</a> on reorgs, epoch boundaries can cause troubles for certain validators when it comes to proposing a block.<br />
<strong>Blocks are more frequently reorged if they are proposed in the first or second slot of an epoch.</strong> Thus, we would expect those blocks to be responsible for the largest split-views among validators, causing some to attest to the current block, and others to the parent block.</p>
<p>Even though expected, we can see that the slot index in an epoch has a major impact on failed target votes:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/0/20b331e0885aaa2efed7972a75ecbe489ab8dd26.png" title="failed_missed_target_votes"><img alt="failed_missed_target_votes" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/0/20b331e0885aaa2efed7972a75ecbe489ab8dd26_2_690x316.png" width="690" /></a></div><p></p>
<p><strong>Target votes are the hardest to get right at the beginning of an epoch.</strong> This is visible in the above diagram showing the <strong>first slot of an epoch with 18x more wrong target votes</strong> than other slots. The thing is, timely and correct target votes bring twice as many rewards than head or source votes.</p>
<p>Although looking problematic, I’d argue this isn’t a big issue. A target vote at the beginning of an epoch is essentially just a head vote, and the relative share of failures in the first slot at 6.4% is still relatively low. Furthermore, it is a known fact that epoch boundaries come with many different cascading effects including missed slots, which also contributes to the above finding.</p>
<blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/c/2c3c18e5acdc7080ad46101a7f05e775a50edb35.png" title="failed_missed_target_votes_over_clclient_over_slot"><img alt="failed_missed_target_votes_over_clclient_over_slot" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/c/2c3c18e5acdc7080ad46101a7f05e775a50edb35_2_690x316.png" width="690" /></a></div><br />
This phenomenon seems to be agnostic to CL clients.<p></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#missedfailed-source-votes-10" name="missedfailed-source-votes-10"></a>Missed/Failed Source Votes</h3>
<p>Source votes are easy to get correct and even validators that are slightly out of sync have a good chance to vote for the right source checkpoint. This is because the to-be-voted-for checkpoint is at least 6.4 minutes (<em>=1 epoch</em>) in the past. Wrong source votes indicate that the validator is either out of sync or on a completely different chain. Thus, target and head votes must be incorrect if the source vote is wrong.</p>
<blockquote>
<p>For source votes one cannot differentiate between <em>missed</em> and <em>failed</em> because wrong source votes never make it onchain and are ignored by proposers/validators.</p>
</blockquote>
<p>On average, we observe around 100 missed source votes per slot, 3,200 per epoch.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/1/61f31f5346adcf9f2b85495f01d371c64e2bff69.png" title="missed_source_votes_over_date"><img alt="missed_source_votes_over_date" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/6/1/61f31f5346adcf9f2b85495f01d371c64e2bff69_2_690x380.png" width="690" /></a></div><p></p>
<p>Similar to head and target votes, we observe an increased number of missed source votes at the beginning of an epoch. This MIGHT be related to the increased reorg probability at the beginning of an epoch but more analysis would be needed to confirm that.<br />
In general, validators usually have ample time (at least 32 slots) to cast their source vote. However, if their head vote is incorrect, it might result in the entire attestation being ignored by an aggregator and, consequently, not being recorded onchain.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/f/1f1e51c85696870bc5d10d561a9814172f0ef750.png" title="missed_source_votes_over_slot"><img alt="missed_source_votes_over_slot" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/1/f/1f1e51c85696870bc5d10d561a9814172f0ef750_2_690x380.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#best-and-worst-validators-11" name="best-and-worst-validators-11"></a>Best and Worst Validators</h2>
<p>Validators cast a vote in every epoch and quickly checking <a href="https://beaconcha.in/">beaconcha.in</a>, more than 99.9% of validators are active in every epoch.</p>
<p>By summing up correct head votes, we can determine the best and worst-performing validators.</p>
<p><strong>The following chart visualizes the average missed/failed head votes per slot over the validator IDs:</strong></p>
<blockquote>
<p>Withdrawn validators are excluded.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/4/94c96b54be8347449d0d060223ba0a9333dd3013.png" title="head_votes_over_validator_ids"><img alt="head_votes_over_validator_ids" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/9/4/94c96b54be8347449d0d060223ba0a9333dd3013_2_690x316.png" width="690" /></a></div><p></p>
</blockquote>
<p>We can see that the missed slot rate is slightly <strong>increasing with increasing validator IDs,</strong> with outliers for the validators with IDs 0-30k, 300k-330k, and 780k-790k.<br />
The best validators are the group with IDs from 50k-60k.</p>
<p><strong>Over four weeks, most validators miss around 20-30 head votes:</strong></p>
<p>The following chart has a <strong>logarithmic y-axis</strong> to make sure we can also see the last bar on the very right that consists of validators that have never attested in the 4 weeks analyzed.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/7/2757547120b4ca4f9068e3fe491289fa8dec1f06.png" title="failed_missed_head_per_validator_dist_per"><img alt="failed_missed_head_per_validator_dist_per" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/7/2757547120b4ca4f9068e3fe491289fa8dec1f06_2_690x316.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#the-peak-of-performance-best-validators-12" name="the-peak-of-performance-best-validators-12"></a>The peak of performance (best validators)</h3>
<p>For the following, I use data ranging from epoch 292,655 to epoch 293,105, not the entire time frame analyzed, due to the sheer amount of data involved.</p>
<p><em><strong>High-performers</strong></em> are defined as validators who haven’t missed voting for the correct head during a time frame of 3 days, starting from the last slot analyzed and going backward.</p>
<p>The following table shows the largest node operators (sorted in descending order by market share) and the percentage of high-performing validators within 3 days compared to the total number of validators for each entity:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/7/5713faed8326eeee5afcdddcf300a1bbdd15e691.jpeg" title="performer_table"><img alt="performer_table" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/7/5713faed8326eeee5afcdddcf300a1bbdd15e691_2_422x500.jpeg" width="422" /></a></div><p></p>
<p>^ The entities in <em><strong>green</strong></em> have <em><strong>more</strong></em> high-performing validators than the average.</p>
<p><strong>The shares visualized using a bar chart look like the following:</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/0/50ed0ae6c74385c61c57a0e9c89ac9beef1e5d64.png" title="topperformer_percentage"><img alt="topperformer_percentage" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/5/0/50ed0ae6c74385c61c57a0e9c89ac9beef1e5d64_2_690x316.png" width="690" /></a></div><p></p>
<p>We can see that the average high-performer rate is around 0-5% for the shown entities.<br />
<strong>The outliers are <em>Everstake</em>, <em>Frax Finance</em> and <em>Rockx</em>.</strong></p>
<p><em>So, what are those 3 parties doing differently than others?</em></p>
<p><strong>There are two strategies an entity might apply:</strong></p>
<ol>
<li><em>Attest early</em> to ensure their vote has enough time to travel through the network and reach the next proposer for inclusion.</li>
<li><em>Attest late</em> to ensure they vote for the correct head of the chain. The longer a validator waits, the easier it is to determine the head of the chain as other validators have already voted -&gt; <em>the risk is that the vote might not reach the next proposer in time</em>.</li>
</ol>
<p>The latter strategy may be referred to as <em><strong><a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612#attester-timing-games-9">attester timing games</a></strong></em>.</p>
<p><em>But what is better?</em></p>
<p><img alt="Screenshot from 2024-06-27 20-22-27" height="311" src="https://ethresear.ch/uploads/default/original/3X/a/1/a19d7ddccff2f47d6d73e80b5e2b5f1b96572091.png" width="587" /></p>
<p>I asked my Twitter friends, and the majority voted for ‘seen later,’ indicating validators are playing timing games for increased attestation accuracy.</p>
<p>In truth, both are right.</p>
<p>The following chart shows the distributions of attestation-seen timestamps of high-performing validators vs. the rest (non-high-performing validators):</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/a/8acfc992ada1a3b0a22ce9f1cfb036a7f191ab8e.png" title="high_performer_vs_rest_timing"><img alt="high_performer_vs_rest_timing" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/8/a/8acfc992ada1a3b0a22ce9f1cfb036a7f191ab8e_2_690x304.png" width="690" /></a></div><p></p>
<p>We can see that the largest share of head votes from <strong>high-performers</strong> is seen between <strong>second 2 and 3</strong> in the slot. We observe another spike right <strong>after second 5</strong> in the slot. For all other validators (cf. <em>rest</em>), the majority of head votes arrive between <strong>second 4 and 5</strong>.</p>
<p><strong>This points towards:</strong></p>
<ul>
<li>Most attesters are exceptionally good because they are <strong>faster</strong> than others.</li>
<li>Some attesters are exceptionally good because they might <strong>wait longer</strong> for more accuracy.</li>
</ul>
<p><strong>&gt; Early attestations by high-performing validators are seen some milliseconds earlier than the rest.<br />
&gt; Late attestations by high-performing validators are seen about 0.5 seconds later than the rest.</strong></p>
<p>It is worth noting that every high-performing validator can be part of both groups, e.g., attesting late to ‘weak’ blocks (cf. epoch boundaries) and early for ‘strong’ blocks.<br />
Validators with great network connectivity can afford to wait slightly longer. Furthermore, at any second in the slot, validators with great connectivity have more information available than other validators.</p>
<blockquote>
<p>A simple example is Coinbase: Technically, every Coinbase validator can be made aware of the votes of other Coinbase validators before voting. With a 10% market share, this provides significant additional security when voting on the correct head.</p>
</blockquote>
<p>By examining the head votes received/seen timings among the largest entities, we can clearly observe the differences. The best performers—Everstake, Frax Finance, and Rockx—typically attest between 4 and 6 seconds into the slot. While these entities outperform others, the following chart does not necessarily indicate a specific strategy being applied.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/2/c22c5adbedc46936379f5e7d1a775f4ad183cb0c.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/2/c22c5adbedc46936379f5e7d1a775f4ad183cb0c_2_300x500.jpeg" width="300" /></a></div><p></p>
<blockquote>
<p>And for a deeper dive into this topic check out <a href="https://ethereum.github.io/beaconrunner/notebooks/thunderdome/thunderdome.html">this simulation</a> by Barnabé that goes into the depth of strategic attesting behavior.</p>
</blockquote>
<p><strong>Finally, we get the following timings for the attestations over different CL clients:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/0/e01321bc4823cb594799d2c67012c599e352cfcd.png" title="head_timing_cl_clients"><img alt="head_timing_cl_clients" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/e/0/e01321bc4823cb594799d2c67012c599e352cfcd_2_690x345.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#we-like-them-for-what-they-are-worst-validators-13" name="we-like-them-for-what-they-are-worst-validators-13"></a>We like them for what they are… (worst validators)</h3>
<p>Other validators are <em>less performant</em> than others. This becomes obvious by looking at the number of missed attestations over time.</p>
<p>First, let’s consider the validators who are offline. There are various reasons for validators to go offline, and occasionally, random validators might experience brief outages. However, there is a small subset of validators that are very likely to remain permanently offline.</p>
<p><img alt="lost_keys" height="193" src="https://ethresear.ch/uploads/default/original/3X/5/7/57134b955a3de1691a15cf2678146f66c1e04126.png" width="456" /></p>
<p>We observed 139 validators, representing 0.014% of all validators, who were permanently offline in the 4 weeks analyzed.<br />
Now, one can argue that being offline for over 4 weeks doesn’t mean the validator is permanently offline. While this is fair, validators who have never cast any vote provide a good upper-bound estimate for the number of permanently offline validators who might have lost their keys.</p>
<p>Within those offline validators, we identify 12 solo stakers, 37 rocketpool validators, and 90 belonging to the category unidentified (=<em>20% market share, including many many actual solo stakers</em>).</p>
<p><strong>Most offline validators have low validator IDs:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/d/2d0d6b73c9b05e0a3a4bc6ee7b5d020b4c98f24b.png" title="head_votes_over_offline_validator_ids"><img alt="head_votes_over_offline_validator_ids" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/d/2d0d6b73c9b05e0a3a4bc6ee7b5d020b4c98f24b_2_690x316.png" width="690" /></a></div><p></p>
<p>We can see spikes around 730k and 870k, but the <strong>largest portion comes from OG validators</strong> with low IDs, those activated before the Merge. This is both expected and unexpected:</p>
<ul>
<li>OG stakers are generally crypto-native individuals who can securely manage private keys.</li>
<li>OG stakers are generally solo stakers who are less sophisticated.</li>
</ul>
<p>Based on the above, it seems the latter is more likely to hold true.</p>
<p><img alt="ogvalidator" height="411" src="https://ethresear.ch/uploads/default/original/3X/e/7/e70bfc6416b8a68b815f9835f7fe8e5076a340d5.png" width="457" /></p>
<br />
<p>Moving the focus to the bad validators that miss more than the mean but not all slots in the analyzed time frame, the bar chart looks like the following:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e535223a575fe5764af70e6d31676c70b7c09e3c.png" title="head_votes_over_bad_validator_ids"><img alt="head_votes_over_bad_validator_ids" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e535223a575fe5764af70e6d31676c70b7c09e3c_2_690x316.png" width="690" /></a></div><p></p>
<p><strong>If low-id validators aren’t offline they perform quite well.</strong> Looking at the above graph, the largest share of “bad” validators can be found at the IDs 900k-1m.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestations-big-blocks-and-blobs-14" name="attestations-big-blocks-and-blobs-14"></a>Attestations, Big Blocks, and Blobs</h2>
<p><strong>Big blocks and blocks with many blocks are expected to receive fewer attestations.</strong> This is because certain validators might struggle to download and validate the block fast enough and therefore vote for another block.</p>
<p>With <a href="https://www.eip4844.com/">EIP-4844</a> going live, the <a href="https://ethresear.ch/t/on-block-sizes-gas-limits-and-scalability/18444">block size</a> consists of 3 parts:</p>
<ul>
<li>EL Payload (~85 KB)</li>
<li>Beacon Block (excl. EL payload) / CL Part (~5 KB)</li>
<li>Blobs (~384 KB)</li>
</ul>
<p>Previous analysis showed that the average beacon block size excl. blobs is around 90 KiB. One blob has a size of 128 KiB. As a result, on average, we get blocks (incl. blobs) of size <code>nr_blobs * 128 + 90</code>, with the blob being the main contributor to the size of a block.</p>
<p><strong>More blobs mean more data that needs to be transmitted across the globe. Thus, we can expect more failed head votes for blocks with 6 blobs than those with one blob.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/6/76d5ade603b46d1fe148a918bda24f4fe3866fd6.png" title="failed_missed_head_size_boxplot"><img alt="failed_missed_head_size_boxplot" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/6/76d5ade603b46d1fe148a918bda24f4fe3866fd6_2_690x316.png" width="690" /></a></div><p></p>
<p>This expectation holds when looking at the above boxplot diagram:<br />
 → <strong>The median missed head votes doubles going from 0 to 6 blobs.</strong></p>
<p><em><strong>Let’s get more granular…</strong></em></p>
<p>The following visualizes the block size incl. blobs in MiB over the failed head votes per slot.</p>
<blockquote>
<p>This chart shows only wrong/failed head votes and excludes offline validators.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4ffabf4ebdf70341da81e69e95094040f0f6591e.png" title="failed_missed_head_size_scatter"><img alt="failed_missed_head_size_scatter" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4ffabf4ebdf70341da81e69e95094040f0f6591e_2_690x316.png" width="690" /></a></div><p></p>
</blockquote>
<p><strong>For the sizes above 0.8 MiB, which are most likely blocks with 6 blobs, we can see more weak blocks than for 0 blob blocks. “Weak” because up to 32k attesters of that slot, up to 99%, voted for a different block.</strong><br />
The only way that block still made it into the canonical chain is the next validator building on top of it instead of reorging that block out.</p>
<p>In the analyzed month, we observe 401 blocks with &gt;31k attesters voting for different blocks that still made it into the canonical chain. 233 of them carried 6 blobs. Assuming most validators attest at the latest at second 4 of a slot, those blocks must have been propagated very late such that validators already attested to a different block before seeing it.<br />
This can be confirmed by plotting the “first seen” time of those weak blocks over the seconds in a slot, comparing it to all other blocks:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/3/b3e8a77964031d2b79681810e8f527c7c95a1699.png" title="hist_late_performer"><img alt="hist_late_performer" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/b/3/b3e8a77964031d2b79681810e8f527c7c95a1699_2_690x304.png" width="690" /></a></div><p></p>
<p>The chart shows that most blocks are seen between second 1 and 2 in the slot. For those weak blocks, it’s between second 4 and 5, right after the attestation deadline.</p>
<p>We can confirm this by looking at the attestation timing over the seconds in a slot. We can see that 80% of the attestations are seen 5 seconds into the slot. A block propagated at second 4 in the slot will likely miss out on at least ~40% of all possible attestations, no matter how fast it propagates through the network.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/2/42fe46361f7b2a22bd61c0195f719a57df04d64d.png" title="attestations_cdf"><img alt="attestations_cdf" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/4/2/42fe46361f7b2a22bd61c0195f719a57df04d64d_2_690x304.png" width="690" /></a></div><p></p>
<p><em><strong>Are blobs the problem?</strong></em></p>
<p>The following chart shows the first seen time of 1-blob blocks vs 6-blob blocks:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/d/9d9090203cef36a8e47a8b59e7a8e3b54be815ae.png" title="hist_late_performer_blobs"><img alt="hist_late_performer_blobs" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/9/d/9d9090203cef36a8e47a8b59e7a8e3b54be815ae_2_690x304.png" width="690" /></a></div><p></p>
<p>We can see that despite 6-blobs blocks being seen later in the slot, the delta is rather small, not to say negligible. At the time of the block arriving, the blobs should have already been seen.</p>
<p>In the past, the fact that a user was (not) using <strong><a href="https://github.com/flashbots/mev-boost">MEV-Boost</a></strong> impacted different performance metrics. Thus, let’s plot MEV-Boost users vs. local builders for completeness:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/9/c9c92b7f095017be8e86eac8b4a486a6c1dfdaec.png" title="hist_late_performer_mevboost"><img alt="hist_late_performer_mevboost" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/c/9/c9c92b7f095017be8e86eac8b4a486a6c1dfdaec_2_690x304.png" width="690" /></a></div><p></p>
<p>Finally, comparing three of the largest relays, we get the following image:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/6/56eedd8200ca5e5c778261aee74f9405630c1677.png" title="hist_mevboost_relays"><img alt="hist_mevboost_relays" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/5/6/56eedd8200ca5e5c778261aee74f9405630c1677_2_690x304.png" width="690" /></a></div><p></p>
<p>While most relays such as Ultra Sound, BloXroute, Agnostic Gnosis, or Flashbots show a very similar curve, we can see the Titan relay having two peaks instead of just one.<br />
This means that some blocks going through the Titan relay are first seen in the p2p network between 2.5-3 seconds into the slot, which is very late.</p>
<p>Notable, those late blocks of Titan still became canonical, pointing towards proposer timing games.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestations-and-proposer-timing-games-15" name="attestations-and-proposer-timing-games-15"></a>Attestations and Proposer Timing Games</h2>
<p>Next, let’s look at the impact of Proposer Timing Games on attestations.<br />
We refer to Proposer Timing Games (see <a href="https://eprint.iacr.org/2023/760">[1]</a>, <a href="https://arxiv.org/abs/2305.09032">[2]</a>) if block proposers delay their block proposal to give the builders more time for MEV extraction.<br />
Instead of asking the relay for a block in second 0 in the block, a proposer can delay this, e.g. until second 2 in the slot, and maximize profits. This comes with the risk of not getting enough attestations and being reorged out.</p>
<p><em>Find some real-time visuals on timing games at <a href="https://timing.pics/">timing.pics</a>.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/5/c563eb0043362562f84cb3fb2f823a14c92dce14.png" title="timing_games2"><img alt="timing_games2" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/c/5/c563eb0043362562f84cb3fb2f823a14c92dce14_2_373x499.png" width="373" /></a></div><p></p>
<p><strong>Proposer timing games are expected to negatively impact validators’ attestation performance</strong>, although this hasn’t been thoroughly analyzed yet. The concern is that <strong>proposer timing games could have cascading effects</strong>: attesters might slightly <strong>delay their attestations</strong> to ensure they vote for the correct head of the chain. Knowing proposers are playing timing games, it might be rational to delay the attestation too. <strong>Such strategies can be harmful to the network’s overall health.</strong></p>
<blockquote>
<p>For more info on the impact of proposer timing games on attestations, check out <a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612">Caspar’s post</a> on it.</p>
</blockquote>
<p>The following graph shows the average number of missed head votes over the seconds in a slot. The <a href="https://github.com/flashbots/relay-specs">relays’ Data API</a> (<em>bidsReceived</em> endpoint) was used for the in-slot timestamps.</p>
<blockquote>
<p>Multiple prior analyses showed that using the bidsReceived timestamps provides a <em>good enough</em> approximation of actual propagation timings. Notably, bidReceived <strong>must come earlier</strong> than the block’s propagation timing.</p>
</blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/6/763882ecc1e817832856f802783d3aa9643ce8ca.png" title="failed_missed_head_votes_over_timing"><img alt="failed_missed_head_votes_over_timing" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/6/763882ecc1e817832856f802783d3aa9643ce8ca_2_690x316.png" width="690" /></a></div><p></p>
<p>The above chart shows that the number of missed head votes increases rapidly with being 1 - 1.2 seconds into the slot. The longer a proposer waits the fewer attestations its block is expected to receive.</p>
<p><strong>We can see that the number of missed head votes per slot increases to an average of &gt;4k (12.5% of the committee) for late blocks published more than 1.7 seconds into the slot.</strong><br />
This sounds bad although the numbers are still relatively low compared to the 32k validators that attest in each slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/4/540d12e9110a2a48ced72b152688d78d5ab1cc8a.png" title="failed_missed_head_votes_over_timing_per"><img alt="failed_missed_head_votes_over_timing_per" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/5/4/540d12e9110a2a48ced72b152688d78d5ab1cc8a_2_690x316.png" width="690" /></a></div><p></p>
<p>Proposing a block with a <em>bid received</em> timestamp of over 2 seconds causes an average of 5k attestations to be missed. This represents about 15% of the committee.</p>
<h2><a class="anchor" href="https://ethresear.ch#next-steps-16" name="next-steps-16"></a>Next Steps</h2>
<p>In this final section I want to quickly present the idea behing anti-correlation penalties and <a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716</a> in specific.</p>
<p>Operating multiple validators comes with <strong>economies of scale</strong>. Theoretically, one can run thousands of validators from a single node, and validators running on the same node have the same view of the chain and cast the same votes.</p>
<p><img alt="same_node_validators" height="257" src="https://ethresear.ch/uploads/default/original/3X/0/2/02262692e73fd82f5ee6f0ff9a62fc4619db6746.png" width="455" /></p>
<p>Having <strong>multiple validators</strong> on <strong>one node</strong> isn’t the only reason for <strong>correlated failures</strong>: Using the same cloud/ISP provider, the same hardware, running nodes from the same geo-location or having the node be maintained by the same group of individuals; everything that leverages economies of scale increases the correlation among validators. Beautiful.</p>
<p>We should therefore use that knowledge to design economic incentives in a way that makes it harder/less profitable to leverage economies of scale.<br />
Without requiring the protocol to know about the node operators behind validators, correlations present a great way to distinguish small solo stakers from professional operators.<br />
One concrete proposal for improved diversification within the validator set is <a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716 - Anti-Correlation Attestation Penalties</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#eip-7716-anti-correlation-attestation-penalties-17" name="eip-7716-anti-correlation-attestation-penalties-17"></a>EIP-7716 - Anti-Correlation Attestation Penalties</h3>
<p><img alt="7716_correlation" height="317" src="https://ethresear.ch/uploads/default/original/3X/0/5/05134246699e0567331369387e90bc395b260135.png" width="459" /></p>
<p><a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716</a> was first described by Vitalik in an <a href="https://ethresear.ch/t/a-concrete-proposal-for-correlated-attester-penalties/19341">ethresearch post</a>. After some initial analysis and a more concrete proposal available the EIP is now at the point where everyone is invited to look into the inner workings of correlated penalties and leave feedback.</p>
<p>In short, the EIP proposes the following:<br />
Multiply the missed source and missed target votes by a penalty factor that ranges from 0 to 4 but remains at 1 on average.</p>
<ul>
<li>If the balance of non-attesting validators increases, the penalty factor does so too.</li>
<li>If the balance of non-attesting validators remains the same, the penalty factor approaches 1.</li>
<li>If the balance of non-attesting validators decreases, the penalty factor can go below 1 for some time and approaches 1 afterward.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#how-does-7716-work-18" name="how-does-7716-work-18"></a>How does 7716 work?</h4>
<div class="md-table">
<table>
<thead>
<tr>
<th>Abbreviation</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">p</span></td>
<td>Penalty factor</td>
</tr>
<tr>
<td><span class="math">p_{exc}</span></td>
<td>Net excess penalties</td>
</tr>
<tr>
<td><span class="math">balance_{NA}</span></td>
<td>Non attesting balance</td>
</tr>
<tr>
<td><span class="math">p_{adj}</span></td>
<td>Penalty adjustment factor</td>
</tr>
<tr>
<td><span class="math">balance_{TOTAL}</span></td>
<td>Total active balance</td>
</tr>
<tr>
<td><span class="math">p_{max}</span></td>
<td>Maximum penalty factor</td>
</tr>
</tbody>
</table>
</div><p>The penalty factor scales the slot penalties to a maximum of <span class="math">p_{max}</span>, or down. It’s determined the following:</p>
<p><span class="math">p = \min\left(\frac{balance_{NA} \times p_{adj}}{p_{exc} \times balance_{TOTAL} + 1}, p_{max} \right)</span></p>
<p>The <span class="math">nep</span> is updated at the end of each slot using:</p>
<p><span class="math">p_{exc} = \max(1, p_{exc} + p) - 1</span></p>
<p><strong>The formula calculates the penalty factor as a ratio of the “penalty weight” of non-attesting validators to the total scaled balance of all validators. A higher non-attesting balance or penalty adjustment factor increases the penalty factor. Conversely, a higher net excess penalty or total active balance reduces the penalty factor.</strong></p>
<p>When  <span class="math">balance_{NA}</span> continuously increases for several rounds, also the penalty factor, as well as the net excess penalty increases. This continues until  <span class="math">balance_{N}</span> stops decreasing. Then, the net excess penalty starts decreasing together with the penalty factor.</p>
<p>With the net excess penalties, <span class="math">p_{exc}</span>, keeping track of the excess penalties of past epochs, the formula can self-regulate what is a “large” number of misses, and what is not.</p>
<p>This mechanism ensures that the sum of penalties doesn’t change with this EIP - only the distribution does.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 09 Jul 2024 08:02:31 +0000</pubDate>
</item>
<item>
<title>Mantis: Driving Ethereum’s Cross-Domain Future</title>
<link>https://ethresear.ch/t/mantis-driving-ethereum-s-cross-domain-future/20009</link>
<guid>https://ethresear.ch/t/mantis-driving-ethereum-s-cross-domain-future/20009</guid>
<content:encoded><![CDATA[
<div> 关键词：Mantis、Inter-Blockchain Communication (IBC)、Ethereum、Trust-minimized Bridging、Multi-chain Agnostic Trust-minimized Intent Settlement

总结:
Mantis是一个新兴的协议，旨在优化跨链操作并解决DeFi空间中的挑战。它通过与IBC（Inter-Blockchain Communication）协议和Picasso Network的整合，实现了信任最小化的跨链连接，首次将这种技术扩展到以太坊之外的IBC兼容链，如Cosmos Hub、Polkadot和Solana等。Mantis的架构包括竞赛式的解决方案、拍卖机制和与Ethereum的集成，提供了链间资产交换、意图执行和结算的一站式服务。通过Mantis，Ethereum得以加强其在去中心化金融中的核心地位，并促进新用户和流动性流入。此外，Mantis简化了跨链交易体验，为去中心化应用程序开发者提供工具。未来，Mantis计划进一步开发拍卖系统和可信承诺机制，以提升整体系统的福利。 <div>
<p>Author: <a href="https://x.com/0xbrainjar" rel="noopener nofollow ugc">0xbrainjar</a></p>
<p>Reviewers: <a href="https://x.com/ComposableSyd" rel="noopener nofollow ugc">Sydney Sweck</a> &amp; <a href="https://x.com/0xBrMazoRoig" rel="noopener nofollow ugc">Bruno Mazorra</a></p>
<h1><a class="anchor" href="https://ethresear.ch#summary-1" name="summary-1"></a>Summary</h1>
<p>Recently, Composable <a href="https://twitter.com/Picasso_Network/status/1775512007963500772" rel="noopener nofollow ugc">launched its IBC Ethereum mainnet connection</a>. The <a href="https://www.ibcprotocol.dev/" rel="noopener nofollow ugc">IBC Protocol</a> is emerging as the gold standard for cross-chain communication, as we have previously explored in our comparison analysis <a href="https://medium.com/@Picasso_Network/ibc-as-the-end-game-of-bridging-a-comparison-analysis-on-trust-dcc01e0d9377" rel="noopener nofollow ugc">here</a>. IBC’s trust levels parallel that of ZK bridging, which is limited to the Ethereum ecosystem and its layer 2s. Originally, the IBC Protocol was also limited to one ecosystem: the Interchain, which includes Cosmos SDK chains and the Cosmos Hub. However, IBC has now been expanded outside of the Interchain/Cosmos ecosystem for the first time by Composable’s Picasso Network.</p>
<p>IBC Ethereum a significant milestone, marking the first time that trust-minimized bridging is available between Ethereum and other IBC-enabled chains including the Cosmos hub, Cosmos SDK chains, Polkadot and Kusama parachains, Solana, and more ecosystems soon. Moreover, this was a huge technological feat, given that this connection required architecting a light client on Ethereum. While various projects were exploring the concept of Ethereum light clients at the time, there were no light clients fully available on Ethereum when we began development.</p>
<p>Now, Composable is in the process of launching a product that aims to bring more utility to cross-domain Ethereum operations: Multi-chain Agnostic Trust-minimized Intent Settlement, or Mantis. This framework serves as a vertically integrated intent pipeline, complete with expression, execution, and settlement. Ultimately, Mantis strives to establish a decentralized market for cross-domain intent expression through a permissionless solver network and intent-settlement framework. Through Ethereum IBC and now Mantis, Ethereum will be optimally positioned to continue in its role as the leading hub of DeFi; new cross-chain use cases to and from Ethereum will be generated, enabling the flow of new liquidity and users to Ethereum, with all of the complexities abstracted away to improve the user experience.</p>
<p>The present article thus summarizes Mantis from our recently-published Mantis Whitepaper and Litepaper. Moreover, this post details how Mantis can benefit Ethereum and other IBC-enabled ecosystems.</p>
<h1><a class="anchor" href="https://ethresear.ch#about-mantis-2" name="about-mantis-2"></a>About Mantis</h1>
<h2><a class="anchor" href="https://ethresear.ch#the-industry-need-3" name="the-industry-need-3"></a>The Industry Need</h2>
<p>Mantis is a relevant protocol within the present DeFi space for a number of reasons, as it aims to fulfill a number of challenges currently facing the space:</p>
<ul>
<li><strong>Optimizing UX and Execution:</strong> There has always been a need in the space to optimize both user experience (UX) and execution. If this is accomplished, capital efficiency and value accrual can be maximized for all participants.</li>
<li><strong>Combatting Centralization Trends:</strong> In the multi-chain bridging space, there has been an increased reliance upon centralized structures. Unfortunately, there has been a lack of decentralized solutions that rival the speed and cost of centralized structures.</li>
<li><strong>Facilitating Trust-Minimized Interoperability:</strong> Many bridging structures in place today require putting trust in third-party intermediaries, making them vulnerable to attack. However, new technologies are being introduced with the launch of trust-minimized bridging structures like the <a href="https://www.ibcprotocol.dev/" rel="noopener nofollow ugc">IBC Protocol</a>, which powers the <a href="http://picasso.xyz" rel="noopener nofollow ugc">Picasso Network</a>. These developments enable generalized message passing and synchronization of protocols and applications across multiple blockchain ecosystems.</li>
<li><strong>Delivering Intent-Centricity:</strong> Intents are another new area of development in the DeFi space that are positioned to further assist in resolving user experience and execution issues. However, many intents solutions are not cross-chain interoperable, and are not vertically integrated with execution and settlement solutions, rendering them unable to accrue value from pay for orderflow.</li>
</ul>
<p>With Mantis, Composable addresses these present unmet needs in the DeFi space. Overall, our thesis is that cross-domain interoperability widens the intent solution space. We hypothesize that this increased choice in solutions results in value in the form of better user outcomes.</p>
<h2><a class="anchor" href="https://ethresear.ch#architecture-4" name="architecture-4"></a>Architecture</h2>
<p>Mantis accomplishes its functionalities via the Mantis protocol and rollup, a cross-domain auction mechanism, as well as their synergies with the Inter-Blockchain Communication (IBC) Protocol and the Picasso Network. Moreover, a commitment mechanism between chains allows conditions in the other parts of the architecture to be carried out cross-domain.</p>
<h3><a class="anchor" href="https://ethresear.ch#the-mantis-protocol-rollup-5" name="the-mantis-protocol-rollup-5"></a>The Mantis Protocol &amp; Rollup</h3>
<p>The Mantis protocol facilitates optimal execution of cross-domain intents via a competition of solvers. Users sign intents, which are contained on a private rollup mempool. Solvers are staked agents that can a) observe the transactions on the mempool and b) post solutions in the auctioneer contract. The auctioneer contract scores the solutions in terms of users utility maximization. The winner of the auction is responsible for settling the outcome of the intent to the solution settlement contracts in the final chain expressed by the intent.</p>
<p>The Mantis protocol lives on the Mantis Solana Virtual Machine (SVM) rollup. This rollup serves as a coordination and settlement layer for cross-domain intents, in addition providing a framework for cross-domain block proposals and credible commitments. The rollup further allows for assets to be staked and restaked to provide crypto-economic security along the proof-of-stake model. This includes staking both the native token of Solana (SOL) as well as liquid staked token versions of SOL. These assets are staked into the bridge contract of the rollup, which then sends them to the proper place for staking or restaking.</p>
<p>The Mantis rollup also provides developers with a simplified mechanism for designing cross-domain decentralized applications (cdApps), which are defined by their inclusion of scoring, solvers, solution settlement, and cross-domain integrity proofs. An SDK is provided to further enhance the development and integration process.</p>
<h3><a class="anchor" href="https://ethresear.ch#cross-domain-auctions-6" name="cross-domain-auctions-6"></a>Cross-Domain Auctions</h3>
<p>Mantis plans to introduce cross-domain combinatorial auctions, with the goal of accomplishing the following:</p>
<ul>
<li>Optimized cross-domain MEV extraction*</li>
<li>Cross-domain intent solution atomic settlement</li>
<li>Efficient blockspace allocation</li>
<li>Increased distribution of revenue to validators selling items separately</li>
</ul>
<p>*We would like to take a moment here to reflect on MEV and our goals surrounding this concept. MEV is an evolving term with a number of interpretations. Initially MEV stood for miner extractable value, representing the maximum profit an agent (miner or validator) in proof-of-work blockchain systems could incur from its monopolistic rights over transaction inclusion. With the advent of proof-of-stake systems, MEV has become more often described as maximal extractible value, as miners are largely obsolete. Maximal extractible value still refers to the value that agents derive from strategically reordering and including transactions, but now these agents are frequently searchers.</p>
<p>A number of negative ramifications have been reported from these MEV extraction mechanisms. Thus, Flashbots introduced MEV-geth to Ethereum, which implemented a centralized combinatorial auction where searchers can express complex preferences in bundles. Then, this auction system was decentralized by MEV-Boost, allowing anyone to propose their block by bidding at auction. With the introduction of proposer-builder separation, validators on Ethereum now derive value from their monopolistic power over their slots.</p>
<p>As one can see, value from rearranging and including/excluding transactions can now be carried out by a number of parties in a number of manners. In addition to the extraction by validators, miners, and searchers, builders can also derive profits and users themselves can derive financial benefits from these mechanisms by using protocols such as Flashbots Protect, MEV blocker and Cow Protocol . Therefore, it becomes difficult to define exactly what value accrual mechanisms can be considered MEV.</p>
<p>Another complicating factor in the definition of MEV is that some of the aforementioned value accrual mechanisms have an inverse relationship. Most importantly, there is tension between the profits made by validators and other sellers from MEV and the overall welfare of the system (i.e. total value accrued to all users of the system, including end users, solvers, searchers, stakers, etc.). When overall profits to sellers are maximized, overall welfare goes down.</p>
<p>Thus, the goal of Mantis is not necessarily to maximize MEV extraction. Rather, the goal is to maximize overall welfare.One way in which we hope to achieve this is via our mechanisms designed to allocate blockspace efficiently to the users valuing it the most, such as our cross-domain auctions.</p>
<p>Initially, these auctions will be just-in-time to allow builders to express atomically. For two domains, this will involve two simultaneous English auctions with a unique combinatorial block take-it-or-leave it offer. Buyers can place send blocks with bids for the independent blocks and combinatorial blocks. The problems with this approach are the risk of double-signing and the high level of trust placed in the relay.</p>
<p>Therefore, Mantis aims to later introduce a future combinatorial blockspace market, where the rights to future blockspace on multiple domains can be bought and sold. The new crypto-economic primitive of restaking (such as that being facilitated by the Picasso Network) enables block proposers to issue credible commitments about future block construction. These are promises to build blocks in accordance with specific conditions laid out by execution ticket holders if certain payment thresholds are met. Tickets exist outside of a domain’s consensus protocol and will be exchanged via a combinatorial batch auction where buyers express combinatorial valuations over the tickets and sellers express reserve prices. Then, tickets can be traded or sold in a secondary market. This aims to decrease the monopoly of block sellers while increasing market efficiency.</p>
<h3><a class="anchor" href="https://ethresear.ch#the-ibc-protocol-7" name="the-ibc-protocol-7"></a>The IBC Protocol</h3>
<p>The <a href="https://www.ibcprotocol.dev/" rel="noopener nofollow ugc">IBC Protocol</a> facilitates communication between different blockchain ecosystems. <a href="https://medium.com/picasso-network/why-ibc-everywhere-is-the-key-to-cross-chain-defi-041bed829acd" rel="noopener nofollow ugc">Compared to other cross-chain communication protocols</a>, the benefits of IBC are that it is <a href="https://medium.com/@Picasso_Network/ibc-as-the-end-game-of-bridging-a-comparison-analysis-on-trust-dcc01e0d9377" rel="noopener nofollow ugc">trustless</a>, secure, censorship-resistant, permissionless, fast, cost-effective, and natively interoperable. For these reasons, Mantis has opted to use IBC as its mechanism for cross-chain communication.</p>
<p>Composable has expanded the reach of the IBC so that it not only connects the <a href="https://hub.cosmos.network/" rel="noopener nofollow ugc">Cosmos Hub</a> and <a href="https://v1.cosmos.network/sdk" rel="noopener nofollow ugc">Cosmos SDK</a> chains that it originally linked, but also interoperates with <a href="https://polkadot.network/" rel="noopener nofollow ugc">Polkadot</a> and <a href="https://kusama.network/" rel="noopener nofollow ugc">Kusama</a> parachains, <a href="https://ethereum.org/en/" rel="noopener nofollow ugc">Ethereum</a>, and <a href="https://solana.com/" rel="noopener nofollow ugc">Solana</a>. Creating these novel connections required a significant amount of technical development, given that many blockchains lack different components needed for IBC-compatibility.</p>
<p>In the case of Ethereum, the following components needed to be architected in order to enable IBC-compatibility:</p>
<ul>
<li><strong>ZK Circuit:</strong> This program is able to output a proof given a set of inputs. This proof can then be easily verified to ensure that each computational step that was run inside the circuit was done so correctly. In Picasso’s solution, the ZK circuit connects SNARK ED-25519 signatures to a prover. ED-25519 is a digital signature algorithm (DSA) that offers small key and signature sizes and fast computation being impervious to many common attacks to other DSAs.</li>
<li><strong>Tendermint Light Client on Ethereum:</strong> We constructed a <a href="https://docs.tendermint.com/v0.34/tendermint-core/light-client.html" rel="noopener nofollow ugc">Tendermint light client</a> on Ethereum, which lives as an Ethereum smart contract and is able to communicate over IBC with the light client on Picasso.</li>
<li><strong>Ethereum Light Client on the Picasso Chain:</strong> We also created a CosmWasm contract in the Wasm client of the Picasso Cosmos SDK chain to complete the Ethereum IBC connection.</li>
<li><strong>IBC Stack on Ethereum:</strong> We created a modified IBC stack for Ethereum that consists of Solidity smart contracts on Ethereum. Through this IBC stack, all BC components can operate on Ethereum, facilitating Ethereum’s interoperability with IBC.</li>
<li><strong>Hyperspace Relayer:</strong> The Composable Foundation’s <a href="https://informal.systems/blog/comparing-hyperspace-hermes" rel="noopener nofollow ugc">Hyperspace relayer</a> connects the two light clients involved in Ethereum IBC by transferring IBC packets between them. Hyperspace is the first event-driven, chain-agnostic IBC relayer that is based on ibc-rs (the Rust implementation of IBC). Hyperspace can thus relay packets between any IBC-enabled chains.</li>
<li><strong>Prover:</strong> This entity interacts with the relayer and proves to the verifier that something is true without revealing other information. On Picasso, what is being proved is various transactions sent between Ethereum and IBC. In particular, this prover is a rapid SNARK prover living on the Picasso Cosmos SDK chain.</li>
<li><strong>Verifier:</strong> Verifiers receive a proof from provers and validate this claim. This prover-verifier relationship results in the production of zero-knowledge proofs, as Ethereum explains <a href="https://ethereum.org/en/zero-knowledge-proofs/" rel="noopener nofollow ugc">here</a>.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#the-picasso-network-its-restaking-pool-8" name="the-picasso-network-its-restaking-pool-8"></a>The Picasso Network &amp; Its Restaking Pool</h3>
<p>The <a href="https://picasso.xyz/" rel="noopener nofollow ugc">Picasso Network</a> aims to deliver ecosystem-agnosticism to DeFi. It executes on this vision via the Picasso Layer 1, a Cosmos SDK blockchain that acts as an IBC hub between Cosmos and non-Cosmos IBC-enabled chains.</p>
<p>Picasso is the first censorship-resistant, natively-secured cross-ecosystem interoperability solution. The Picasso Network further emphasizes trust-minimization by drawing on the trustless IBC protocol. While a multisig is initially being used for upgradability of IBC contracts on Picasso, the end goal is to transition to decentralized governance.</p>
<p>Picasso is a critical component of Mantis as it allows the Mantis framework to be cross-chain capable over IBC. Specifically, Mantis transactions are grouped into IBC bundles for shipment based on domain. These bundles are then sent from the Mantis rollup over Picasso IBC and out to relevant blockchains for settlement.</p>
<p>Moreover, a restaking pool on Picasso coordinates the agents that have a combination of stake in different chains. Commitments formed between these actors draw upon this restaking pool.</p>
<h2><a class="anchor" href="https://ethresear.ch#development-roadmap-9" name="development-roadmap-9"></a>Development Roadmap</h2>
<p>The development for Mantis will be carried out in the following steps:</p>
<ol>
<li>
<p><strong>Enabling cross-domain swaps:</strong> integrating with IBC bridges and automated market makers across different chains to facilitate seamless asset swaps</p>
</li>
<li>
<p><strong>Setting up the foundational architecture:</strong> establishing a robust framework that includes the initial design of the Mantis architecture and the development of standards for scoring mechanisms and IBC for intent-based mechanisms</p>
</li>
<li>
<p><strong>Implementing cross-domain intent-based mechanisms:</strong> developing application programming interfaces (APIs) and software development kits (SDKs) that enable users to create and manage cross-domain intents, along with implementing an open-source solver that solves these intents</p>
</li>
<li>
<p><strong>Enriching the restaking layer:</strong> building out the restaking layer of Mantis to have additional functionality (simultaneously to step 3)</p>
</li>
<li>
<p><strong>Creating cross-domain MEV auctions:</strong> developing an auction system that efficiently allocates blockspace (simultaneously to step 3)</p>
</li>
<li>
<p><strong>Deploying block proposal commitments:</strong> enhancing the infrastructure for block proposals and establishing a credible commitment mechanism across domains, including robust fraud-proof mechanisms to maintain trust and security.</p>
</li>
<li>
<p><strong>Completing public launch and scaling:</strong> focusing on officially releasing all functionalities and documentation for Mantis</p>
</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#benefits-to-ethereum-10" name="benefits-to-ethereum-10"></a>Benefits to Ethereum</h1>
<p>Mantis supports Ethereum’s continued role as a leader in DeFi as the space becomes increasingly cross-chain. Composable has already connected Ethereum to the IBC, and therefore, to our trust-minimized bridge. This connection will drive new usership and liquidity to Ethereum from Solana, Cosmos, Polkadot, and Kusama. It will also enable the development of new use cases for ETH outside of Ethereum and on these other networks. Through such new use cases in new locations, DeFi users who do not currently hold ETH will likely be incentivized to do so, and existing users may be incentivized to hold more ETH. Thus, the Ethereum network is positioned to expand its reach even further into the cross-domain DeFi landscape, helping the ecosystem to maintain its reputation as a leader in the space.</p>
<p>Another benefit Mantis aims to deliver is chain abstraction. Mantis provides a mechanism for Ethereum and other domains to easily be participants in cross-chain DeFi without the blockchain, its layer 2s, or any protocols in the ecosystem needing to make significant modifications. Now that Ethereum is integrated with IBC, its innumerable DeFi protocols and applications can be leveraged from within Mantis. A user simply puts their intent for a transaction into the Mantis user interface, and the rest is handled for them. For example, A user may be looking to swap ETH for USDC. Once they input this intent, Solvers on Mantis compete to come up with the best execution route. For the sake of this example, perhaps the best price for this swap is through an ETH-USDC pool on Uniswap. The solver who has proposed the best settlement route wins the rights to settle the solution, routing the funds through Uniswap for the swap, and then back to the user. Once the transaction is settled as specified, the solver is rewarded. In this manner, all parties benefit: new traffic is routed through Uniswap in this example (or more generally, any other protocol or protocols providing best execution), the user has a streamlined experience with optimized settlement, and the solver is rewarded for their role.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-11" name="conclusion-11"></a>Conclusion</h1>
<p>Mantis provides the architecture needed for IBC-enabled chains like Ethereum to easily participate in the cross-domain future. This will help Ethereum continue its role at the forefront of DeFi as the industry continues to embrace multi-domain operations.</p>
<h1><a class="anchor" href="https://ethresear.ch#references-more-about-composable-12" name="references-more-about-composable-12"></a>References &amp; More About Composable</h1>
<p>Composable is dedicated to improving DeFi’s accessibility, quality, transparency, efficiency, and security. Our ultimate vision is for the Composable ecosystem to become an execution hub for chain-agnostic transactions. We are actualizing our mission by working to unite the DeFi space, building an ecosystem and a range of infrastructure to support trustless cross-chain operations.</p>
<ul>
<li><a href="https://assets.website-files.com/65b28e756a8eda2e91e76ca4/6656289f21123d6215091555_MANTIS%20Whitepaper.pdf" rel="noopener nofollow ugc">Mantis Whitepaper</a></li>
<li><a href="https://assets.website-files.com/65b28e756a8eda2e91e76ca4/6655e8e69277b97e9c11c793_MANTIS%20Litepaper.pdf" rel="noopener nofollow ugc">Mantis Litepaper</a></li>
<li><a href="https://www.mantis.app/" rel="noopener nofollow ugc">Mantis app</a></li>
<li><a href="https://www.composable.finance/" rel="noopener nofollow ugc">Composable website</a></li>
<li><a href="https://twitter.com/ComposableFin" rel="noopener nofollow ugc">Composable X/twitter</a></li>
<li><a href="http://discord.gg/composable" rel="noopener nofollow ugc">Composable Discord</a></li>
<li><a href="https://t.me/composable_chat" rel="noopener nofollow ugc">Composable Telegram</a></li>
<li><a href="https://github.com/ComposableFi/" rel="noopener nofollow ugc">Composable GitHub</a></li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/mantis-driving-ethereum-s-cross-domain-future/20009">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 08 Jul 2024 13:16:05 +0000</pubDate>
</item>
<item>
<title>Maximum Viable Security: A New Framing for Ethereum Issuance</title>
<link>https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992</link>
<guid>https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#maximum-viable-security-a-new-framing-for-ethereum-issuance-1" name="maximum-viable-security-a-new-framing-for-ethereum-issuance-1"></a><strong>Maximum Viable Security: A New Framing for Ethereum Issuance</strong></h1>
<p><em>by <a href="http://x.com/artofkot" rel="noopener nofollow ugc">@artofkot</a>, <a href="http://x.com/damcnuta" rel="noopener nofollow ugc">@damcnuta</a>, <a href="http://x.com/sonyasunkim" rel="noopener nofollow ugc">@sonyasunkim</a>, <a href="http://x.com/adcv_" rel="noopener nofollow ugc">@adcv_</a></em></p>
<p><em>Appreciate feedback from <a href="http://x.com/ppclunghe" rel="noopener nofollow ugc">@ppclunghe</a>, <a href="https://x.com/ks_kulk" rel="noopener nofollow ugc">@ks_kulk</a>, <a href="http://x.com/lazyleger" rel="noopener nofollow ugc">@lazyleger</a>, <a href="https://cryptecon.org/team-detail-ce/items/juan-beccuti.html" rel="noopener nofollow ugc">Juan Beccuti</a>, <a href="https://x.com/entigdd" rel="noopener nofollow ugc">enti</a>, <a href="https://x.com/stakesaurus" rel="noopener nofollow ugc">Stakesaurus</a>, <a href="http://x.com/hasufl" rel="noopener nofollow ugc">@hasufl</a>, <a href="http://x.com/lex_node" rel="noopener nofollow ugc">@lex_node</a>, <a href="https://x.com/_vshapovalov" rel="noopener nofollow ugc">@_vshapolapov</a>, <a href="http://x.com/brettpalatiello" rel="noopener nofollow ugc">@brettpalatiello</a></em></p>
<hr />
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#tldr-embrace-security-2">TLDR: Embrace security</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-1-the-foundations-of-the-maximum-viable-security-mvs-framework-3">1. The foundations of the Maximum Viable Security (“MVS”) framework</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-11-ethereum-has-a-clear-goal-build-a-secure-and-sovereign-distributed-system-for-everyone-4">1.1. Ethereum has a clear goal: build a secure and sovereign distributed system for everyone</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-12-a-diverse-staking-economy-is-key-5">1.2. A diverse staking economy is key</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-121-stakers-6">1.2.1. Stakers</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-122-validating-entities-7">1.2.2. Validating entities</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-123-entities-decentralization-8">1.2.3. Entities’ decentralization</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-13-there-is-no-future-proof-safe-level-of-security-9">1.3. There is no future-proof safe level of Security</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-14-reframing-the-discourse-expansion-over-efficiency-10">1.4. Reframing the discourse: expansion over efficiency</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-2-analysis-of-ethereum-issuance-reduction-proposal-within-the-mvs-framework-11">2. Analysis of Ethereum Issuance reduction proposal within the MVS framework</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-21-the-assumption-that-ethereum-overpays-for-security-is-wrong-less-issuance-may-lead-to-centralization-of-the-validator-set-12">2.1. The assumption that Ethereum overpays for security is wrong: less issuance may lead to centralization of the validator set</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-211-etf-inflows-would-exacerbate-centralization-in-the-context-of-a-33-stake-cap-13">2.1.1 ETF inflows would exacerbate centralization in the context of a 33% stake cap</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-212-staked-eth-concentration-with-cexs-doesnt-necessarily-have-to-happen-with-a-higher-stake-cap-14">2.1.2 Staked ETH concentration with CEXs doesn’t necessarily have to happen with a higher stake cap</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-213-mvi-effect-on-the-ratio-of-solo-stakers-15">2.1.3 MVI effect on the ratio of solo stakers</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-22-lst-dominance-and-cost-modeling-are-inadequate-arguments-for-issuance-reduction-19">2.2. LST dominance and cost-modeling are inadequate arguments for issuance reduction</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-221-issuance-as-a-cost-is-a-reductive-framing-20">2.2.1. Issuance as a cost is a reductive framing</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-222-stakers-getting-higher-real-vs-nominal-yield-is-not-significant-21">2.2.2. Stakers getting higher real vs nominal yield is not significant</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-223-reducing-lst-dominance-shouldnt-be-a-primary-objective-of-ethereums-monetary-policy-22">2.2.3. Reducing LST dominance shouldn’t be a primary objective of Ethereum’s monetary policy</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-3-putting-it-all-together-23">3. Putting it all together</a></li>
</ul>
<hr />
<h2><a class="anchor" href="https://ethresear.ch#tldr-embrace-security-2" name="tldr-embrace-security-2"></a>TLDR: Embrace security</h2>
<p>Given Ethereum’s goal of building a secure and sovereign distributed system, we believe viewing Ethereum’s monetary policy through the lens of Minimum Viable Issuance (MVI) is not appropriate. Instead, we propose Maximum Viable Security (MVS) as a new framework for the community to consider in the Ethereum issuance debate. That is,</p>
<p>From: <strong>Minimum Viable Issuance (MVI)</strong> – minimize issuance, without compromising security.<br />
→<br />
To: <strong>Maximum Viable Security (MVS)</strong> – maximize security, without compromising scarcity.</p>
<p>After covering the motivation and foundations behind MVS, we evaluate Ethereum issuance reduction proposals through the MVS lens. We show that issuance reduction can compromise security and neutrality in a direct way, through staked ETH concentration with Centralized Exchanges – and this effect, on balance, far outweighs the advantages of cutting the issuance.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-1-the-foundations-of-the-maximum-viable-security-mvs-framework-3" name="h-1-the-foundations-of-the-maximum-viable-security-mvs-framework-3"></a>1. The foundations of the Maximum Viable Security (“MVS”) framework</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-11-ethereum-has-a-clear-goal-build-a-secure-and-sovereign-distributed-system-for-everyone-4" name="h-11-ethereum-has-a-clear-goal-build-a-secure-and-sovereign-distributed-system-for-everyone-4"></a>1.1. Ethereum has a clear goal: build a secure and sovereign distributed system for everyone</h3>
<blockquote>
<p><code>There are many goals of this project; one key goal is to facilitate transactions between consenting individuals who would otherwise have no means to trust one another.</code><br />
<em>Source: Ethereum Yellow Paper (<a href="https://ethereum.github.io/yellowpaper/paper.pdf" rel="noopener nofollow ugc">link</a>)</em></p>
</blockquote>
<p>The growth of Ethereum’s market capitalization from 0 to $400bn today underscores the market’s confidence in its current and future potential. This value hinges on Ethereum’s ability to validate state changes transparently, securely, and sovereignly.</p>
<p>Security is a crucial part of the value proposition. Without sybil resistance and slashing defense (programmable or social) against 34% double-signing attacks, a settlement layer would not be trusted by participants. A secure validation layer is the most scalable (<a href="https://unenumerated.blogspot.com/2017/02/money-blockchains-and-social-scalability.html" rel="noopener nofollow ugc">link</a>) foundation for providing transaction settlement with incorruptible finality.</p>
<p>Sovereignty is equally important – Ethereum should be able to defend against more subtle 51% attacks such as short-range reorgs and censoring (<a href="https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attack-and-defense/#attackers-with-50-stake" rel="noopener nofollow ugc">link</a>), and should be able to resist coercion by state actors. If Ethereum loses sovereignty (aka autonomy), it loses its value as a neutral settlement mechanism:</p>
<blockquote>
<p><code>"Decentralization" is the broad distribution of a system's intrinsic/accepted forms of power, protecting users against arbitrary exercises of power from the recognized legitimate 'authorities' within the system's logic (e.g., validators). "Autonomy" is the system's resistance against extrinsic/unaccepted forms of power, protecting users against all exercises of power from authorities outside the system's logic (e.g., government authorities).</code><br />
<em>Source: lex_node (<a href="https://twitter.com/lex_node/status/1799489646042165662" rel="noopener nofollow ugc">link</a>)</em></p>
</blockquote>
<p>While 34% attacks are costly and 51% attacks are to some extent bounded by reputation and social slashing, a gradual coercion by state actors on independent validators is more feasible, and can even be unintentional. For instance, the European Securities and Markets Authority (ESMA) recently suggested (<a href="https://www.esma.europa.eu/press-news/consultations/consultation-technical-standards-specifying-certain-requirements-mica-3rd#responses" rel="noopener nofollow ugc">link</a>) viewing MEV as a form of market manipulation subject to notification requirements from validators. Such regulations could make it impracticable for node operators to continue to function in Europe. In a worst-case outcome, these regulations could propagate to the rest of the world and impose artificial restrictions on how the consensus algorithm works.</p>
<p>High autonomy is therefore maintained through robust decentralization among validators, which includes:</p>
<ul>
<li><strong>Client software diversity</strong>: running different types of validator software to avoid concentration risk from bugs.</li>
<li><strong>Node operator diversity</strong>: different, independent entities running validator software to prevent individual node operators reaching higher levels of control.</li>
<li><strong>Geographic and jurisdictional diversity</strong>: different levels of base-level infrastructure — such as connectivity to the internet, power supply, law authorities and jurisdictions — that are capable of influencing node operators.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-12-a-diverse-staking-economy-is-key-5" name="h-12-a-diverse-staking-economy-is-key-5"></a>1.2. A diverse staking economy is key</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-121-stakers-6" name="h-121-stakers-6"></a>1.2.1. Stakers</h4>
<p>Stakers fall into three main categories:</p>
<ol>
<li>Retail and Institutions: These participants delegate their staking to Centralized Exchanges (CEXs)</li>
<li>On-chain Actors: They delegate their staking to Decentralized Staking Middleware (DSM), such as Liquid Staking Tokens (LSTs) or decentralized pools, as well as Liquid Restaking Token protocols (LRTs) and Centralized Staking Providers (CSPs).</li>
<li>Solo Stakers: These users choose not to delegate and run validators independently</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#h-122-validating-entities-7" name="h-122-validating-entities-7"></a>1.2.2. Validating entities</h4>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e4e64e83cbc59b58fdfe0316e37c8b548dfb52d8.jpeg" title="tg_image_4158519118"><img alt="tg_image_4158519118" height="469" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e4e64e83cbc59b58fdfe0316e37c8b548dfb52d8_2_690x469.jpeg" width="690" /></a></div><br />
<em>Note: CSP numbers do not include capital delegated from DSM/LRTs. The above numbers are approximate and for illustration purposes; they are our best estimates from Dune (<a href="https://dune.com/hildobby/eth2-staking" rel="noopener nofollow ugc">1</a>, <a href="https://dune.com/lido/eth-deposits-stats" rel="noopener nofollow ugc">2</a>), as of June 30th 2024.</em><p></p>
<p>A hypothetical scenario where most ETF Ether is staked with custodial services, like Coinbase, suggests that this is where most of future inflows will likely originate. Recent Bitcoin ETFs have seen ~$15b of inflows. Proportionally applied to Ethereum, this could mean about 4m ETH. Notably, 8 out of 11 Bitcoin ETFs use Coinbase as their custodian, a pattern that may repeat with ETH.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-123-entities-decentralization-8" name="h-123-entities-decentralization-8"></a>1.2.3. Entities’ decentralization</h4>
<p>Contributions to decentralization and thus censorship resistance and neutrality can be approximated as follows: Solo Stakers &gt; Decentralized Staking Middleware &gt; Liquid Restaking Protocols &gt; Centralized Staking Providers &gt; CEXs.</p>
<ul>
<li><strong>Solo Stakers</strong>: Contribute the most to decentralization because each adds an additional validator</li>
<li><strong>DSM</strong>: Efficiently distribute delegated stake among many parties, bonded via reputation (Lido) or collateral (Rocket Pool, Lido’s Community Staking Module). Their impact on Ethereum’s decentralization is measurable and significant, with data on operational diversity publicly available and regularly updated (<a href="https://app.hex.tech/8dedcd99-17f4-49d8-944e-4857a355b90a/app/3f7d6967-3ef6-4e69-8f7b-d02d903f045b/latest" rel="noopener nofollow ugc">link</a>). The Herfindahl-Hirschmann Index (HHI) can also provide a useful proxy on the effect on validation concentration (<a href="https://dune.com/steakhouse/hhi" rel="noopener nofollow ugc">link</a>)</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/4/b4d2e88d63be2c26d7397166220ad2752e954a34.png" title="dune_hhi"><img alt="dune_hhi" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/b/4/b4d2e88d63be2c26d7397166220ad2752e954a34_2_690x411.png" width="690" /></a></div><p></p>
<ul>
<li><strong>Restaking Infrastructure</strong>: While not cost-optimized for native staking, these protocols distribute stake among fewer node operators without aggregating it under one entity</li>
<li><strong>Centralized Staking Providers</strong>: Risk aggregating large amounts of stake, but competition among them can bolster decentralization if many can sustain independent businesses</li>
<li><strong>CEXs</strong>: Benefit the most from the power law distribution of AUM, often driving staked ETH concentration. Coinbase, for instance, is the largest node operator with nearly 15% market share.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-13-there-is-no-future-proof-safe-level-of-security-9" name="h-13-there-is-no-future-proof-safe-level-of-security-9"></a>1.3. There is no future-proof safe level of Security</h3>
<p>Anders Lowsson suggests (<a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/">link</a>) that Ethereum should reduce its issuance, arguing that “excessive incentives for staking, beyond what is necessary for security, can unfortunately over time turn into perverse subsidies, with many downsides.” However, this raises the question of what constitutes “adequate incentives for staking” and what level of security is truly necessary.</p>
<blockquote>
<p><code>What exactly is "neutrality"? I see that term being used in handwavy fashion, especially when scaling comes up, and it's hard to know what we mean by "preserving credible neutrality" at the moment. Would be nice to get some info there. :)</code><br />
<em>Source: eawosikaa (<a href="https://x.com/eawosikaa/status/1808005717976047799" rel="noopener nofollow ugc">link</a>)</em></p>
</blockquote>
<p>Today’s global capital markets are valued in the hundreds of trillions of dollars, while Ethereum represents only a tiny fraction of that. For Ethereum to become a neutral settlement layer for the world, its cost of corruption would need to be in the hundreds of billions, if not trillions, of dollars, to capture the value that could be extracted in a possible attack. For context, large value payment systems (excluding retail payments) cleared quadrillions of dollars in value in 2022 (<a href="https://data.bis.org/topics/CPMI_FMI/tables-and-dashboards/BIS,CPMI_T9,1.0?view=value&amp;dimensions=REP_CTY%3AUS" rel="noopener nofollow ugc">link</a>). In comparison, over the past 12mos, stablecoin transfer value on Ethereum just about cleared $8tn, or 0.5% (<a href="https://www.theblock.co/data/stablecoins/usd-pegged/adjusted-on-chain-volume-of-stablecoins-monthly" rel="noopener nofollow ugc">link</a>). This is consistent with the proportion of market capitalization of Ethereum relative to global capital markets (well under 1% as well).</p>
<p>The slightest risk of insufficient security would stagnate Ethereum’s growth – decentralization and the resulting neutrality is Ethereum’s <span class="hashtag-raw">#1</span> competitive advantage. No risk should be taken to erode that, and instead, we should seek to strengthen it even further. To answer Emmanuel’s question, in our framing, we would use “neutrality” interchangeably with “sovereignty” and “autonomy”: ability to defend against censorship and coercion attacks (<a href="https://nakamoto.com/credible-neutrality/" rel="noopener nofollow ugc">link</a>). Such that the cost of “coercion” is always higher than the benefit from manipulating the state.</p>
<p>Anders’ argument assumes that a 34% double-singing attack is so costly and 51% censorship attack is so unlikely today, that the network can afford to focus on strengthening other layers. If Ethereum were already a major part of the world’s capital markets, this argument might hold more weight, as incremental risks would be smaller. However, reducing today the network’s most crucial features—security and sovereignty—would compromise the network’s ability to grow.</p>
<p>Currently, Ethereum’s social layer serves as the final defense (<a href="https://ercwl.medium.com/the-case-for-social-slashing-59277ff4d9c7" rel="noopener nofollow ugc">link</a>) against norm violations that threaten its credible neutrality. However, this social layer is structurally fragile. It requires constant vigilance from the community so that enforcement can occur on a daily basis. Yet, as Ethereum grows, massive new inflows might bypass today’s social layer altogether. If a large bank, say, staked $1tn worth of Ether with a CEX, what chance does a community of open source developers have to enforce social norms? The key question, as Emmanuel points out, is: What is the threshold for security that Ethereum needs today and in the future? The MVI proposal, in our view, fails to address this critical question, focusing instead on the other effects of reducing the security budget.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-14-reframing-the-discourse-expansion-over-efficiency-10" name="h-14-reframing-the-discourse-expansion-over-efficiency-10"></a>1.4. Reframing the discourse: expansion over efficiency</h3>
<p>Ethereum should balance incentives for all stakeholders to ensure the highest level of security. This balance involves weighing long-term sustainability and expansion vs short-term efficiency to create enduring security value.</p>
<p>MVS suggests that instead of asking “how much could we reduce issuance for staking efficiency”, we should be asking “how much network incentivisation do we need to perpetuate decentralization to maintain and expand security”.</p>
<p>Strategically, MVI and MVS represent two different paths for Ethereum’s growth. MVI focuses on minimizing costs, benefiting ETH holders in the short term. MVS, on the other hand, emphasizes building a long-lasting moat around the network, optimizing long-term value creation for all stakeholders, including ETH holders.</p>
<p>Ethereum’s unique appeal lies in its secure, credibly neutral blockspace. Unlike commodity blockspace, which competes on price, secure blockspace competes on features. Similar to the advanced chip industry, where success de<br />
ffpends on computational ability rather than price, Ethereum should compete on the magnitude of security it offers. This security creates an enduring competitive advantage, accelerating value creation across the ecosystem.</p>
<p>There is a subtlety in that the market cap of Ethereum is a variable that contributes to security, and so minimizing issuance can be seen as bolstering security. Superficially, there is a reflexive effect, where Ethereum’s security both causes and is driven by its market cap. However, we believe that Ethereum’s security making ETH valuable is the primary causation, and therefore security needs to be prioritized. Below we illustrate diagrammatically the alternative value creation paths for Ethereum contributors deciding between MVS and MVI.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/f/1f2963c356b0018f378fbf4fe73ef79e641aa362.jpeg" title="tg_image_2418175601"><img alt="tg_image_2418175601" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/f/1f2963c356b0018f378fbf4fe73ef79e641aa362_2_530x500.jpeg" width="530" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#h-2-analysis-of-ethereum-issuance-reduction-proposal-within-the-mvs-framework-11" name="h-2-analysis-of-ethereum-issuance-reduction-proposal-within-the-mvs-framework-11"></a>2. Analysis of Ethereum Issuance reduction proposal within the MVS framework</h2>
<p>We posit that, under the MVS framework, Ethereum issuance reduction proposals risk creating downstream effects that would compromise Ethereum’s security value. Overall, we believe that ETH’s moneyness stands to increase with greater security and autonomy, to a degree that far outweighs the downsides of issuance or externalities such as capital gains taxes.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-21-the-assumption-that-ethereum-overpays-for-security-is-wrong-less-issuance-may-lead-to-centralization-of-the-validator-set-12" name="h-21-the-assumption-that-ethereum-overpays-for-security-is-wrong-less-issuance-may-lead-to-centralization-of-the-validator-set-12"></a>2.1. The assumption that Ethereum overpays for security is wrong: less issuance may lead to centralization of the validator set</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-211-etf-inflows-would-exacerbate-centralization-in-the-context-of-a-33-stake-cap-13" name="h-211-etf-inflows-would-exacerbate-centralization-in-the-context-of-a-33-stake-cap-13"></a>2.1.1 ETF inflows would exacerbate centralization in the context of a 33% stake cap</h4>
<p>Lowering the target stake ratio (<a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">link</a>) could lead to a concentration of staked ETH with Centralized Exchanges (CEXs), driving capital away from decentralized alternatives.</p>
<p>Consider a scenario where a 33% cap (equivalent to 40.6 million staked ETH) is implemented, and the curve enacts a sharp drop of yield to zero as stake ratio increases from 30% (36.6 million ETH) to 33% (40.6 million ETH). Suppose Ether ETFs are launched in the US, attracting significant capital inflows. If these ETFs use Coinbase as their custodian (as 8 out of 11 BTC ETF issuers do), this could lead to $15 billion in inflows, adding approximately 4.5 million ETH to Coinbase’s custody. The simulated impact on the validation market might look like this; the 40.1m max staked ETH being slightly lower then 40.6 represents the fact that when yield becomes extremely low there is no marginal staker at all on the market.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th><strong>Illustrative impact on validation market with a 33% MVI limit</strong></th>
<th style="text-align: center;"><strong>Current composition</strong></th>
<th style="text-align: center;"><strong>Effect in 4 years</strong></th>
<th style="text-align: center;"><strong>Future composition</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>ETH staked</td>
<td style="text-align: center;">33.1m</td>
<td style="text-align: center;">+7m</td>
<td style="text-align: center;">40.1m</td>
</tr>
<tr>
<td>ETH held with Coinbase</td>
<td style="text-align: center;">17.5m</td>
<td style="text-align: center;">+4.5m (ETFs)</td>
<td style="text-align: center;">22m</td>
</tr>
<tr>
<td>ETH held &amp; staked with Coinbase</td>
<td style="text-align: center;">4.3m</td>
<td style="text-align: center;">+10m</td>
<td style="text-align: center;">14.3m</td>
</tr>
<tr>
<td>ETH staked on-chain via LSTs/LRTs</td>
<td style="text-align: center;">13.7m</td>
<td style="text-align: center;">-2m</td>
<td style="text-align: center;">11.7</td>
</tr>
<tr>
<td>ETH staked by other entities</td>
<td style="text-align: center;">15.1</td>
<td style="text-align: center;">-1m</td>
<td style="text-align: center;">14.1</td>
</tr>
</tbody>
</table>
</div><ol>
<li>Market forces and fiduciary duties ensure that CEXs like Coinbase squeeze the maximum amount of profit from staking-as-a-service (for their customers and ETF issuers), and long-term the majority of their holdings are staked.</li>
</ol>
<p>We model the above impact by assigning a 10m staked ETH inflow to Coinbase. When Coinbase’s stake reaches 7.8 million, total staked ETH will be about 36.6 million, causing rewards to drop sharply. Consequently:</p>
<ol start="2">
<li>Lido stETH and other LST/LRT users, being sophisticated on-chain actors, will seek higher rewards elsewhere. The switching cost of moving capital on-chain is extremely low, so there is no incentive for capital to stay – the capital will leave for higher yields in DeFi.</li>
<li>CSPs will exit these protocols since the 5% fee from middleware won’t cover their costs.</li>
</ol>
<p>We model the above two impacts by assigning a 2 million ETH outflow to LSTs/LRTs and a 1 million ETH outflow to other entities.</p>
<ol start="4">
<li>Meanwhile, CEXs like Coinbase can continue offering staking products because their marginal costs are extremely low, and can even be offset by other business segments. Their customers may remain loyal or lack alternatives due to regulations or unsophisticated nature of the user base. This can happen despite Coinbase having higher fees (25%) compared to better-performing alternatives (5-15%).</li>
</ol>
<p>In this scenario, Coinbase could control 14.3 million ETH, surpassing the 33% network control threshold independently, while Lido and other DSMs lose market share.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-212-staked-eth-concentration-with-cexs-doesnt-necessarily-have-to-happen-with-a-higher-stake-cap-14" name="h-212-staked-eth-concentration-with-cexs-doesnt-necessarily-have-to-happen-with-a-higher-stake-cap-14"></a>2.1.2 Staked ETH concentration with CEXs doesn’t necessarily have to happen with a higher stake cap</h4>
<p>Without the cap, both CEXs and on-chain market segments could coexist without putting pressure on each other due to sufficient demand for staking. LSTs, LRTs and CSPs wouldn’t face the dramatic yield decrease that would occur when Coinbase’s stake reaches 7.8 million ETH. Some might argue that Coinbase would undercut other staking providers by lowering its 25% fee. However, this is uncertain. Coinbase’s customer base seems inelastic, meaning the most profitable strategy might be to maintain or even increase their fees. In addition, even if Coinbase goes after the on-chain market and lowers their fees, the market may not be fully efficient – some people might prefer to stick with LSTs due to their decentralization preference.</p>
<p>In a highly segmented market, margins don’t need to uniformly compress, leaving space for both CEXs/CSPs and LSTs/restaking segments to thrive. LSTs and CEXs serve distinct market segments. For CEXs, the most profitable approach is to charge high fees from retail and institutional clients (e.g., Coinbase’s 25%) without directly competing with LSTs. Targeting stake ratios could stifle the market for on-chain actors but not significantly affect the market for retail and institutional clients.</p>
<p>Thus, in the absence of a stake cap, the coexistence of various staking actors could lead to a more balanced distribution of staked ETH across different market segments.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-213-mvi-effect-on-the-ratio-of-solo-stakers-15" name="h-213-mvi-effect-on-the-ratio-of-solo-stakers-15"></a>2.1.3 MVI effect on the ratio of solo stakers</h4>
<h5><a class="anchor" href="https://ethresear.ch#the-importance-of-this-effect-is-overrated-16" name="the-importance-of-this-effect-is-overrated-16"></a>The importance of this effect is overrated</h5>
<p>Approximately 30 million ETH is delegated, while only 3 million is solo staked. It is evident that delegation dominates as a modality of staking. The key issue is ETH concentration with CEXs, rather than the interaction between solo stakers and LSTs.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: center;"><strong>Grouping</strong></th>
<th style="text-align: center;"><strong>Approximate stake</strong></th>
<th style="text-align: center;"><strong>Type</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">CEXs</td>
<td style="text-align: center;">10m</td>
<td style="text-align: center;">Delegated</td>
</tr>
<tr>
<td style="text-align: center;">LSTs, LRTs, CSPs</td>
<td style="text-align: center;">20m</td>
<td style="text-align: center;">Delegated</td>
</tr>
<tr>
<td style="text-align: center;">Solo stakers</td>
<td style="text-align: center;">3m</td>
<td style="text-align: center;">Solo staked</td>
</tr>
</tbody>
</table>
</div><h5><a class="anchor" href="https://ethresear.ch#lsts-and-csps-can-also-contribute-to-overall-network-quality-17" name="lsts-and-csps-can-also-contribute-to-overall-network-quality-17"></a>LSTs and CSPs can also contribute to overall network quality</h5>
<p>While solo stakers are often seen as the backbone of Ethereum’s network security, the contributions of LSTs and centralized staking providers are undervalued.</p>
<p>There is a lot of nuance to the emergent risks of malicious actors emerging from LSTs such as Lido. There certainly are risks (cf. Mike Neuder’s extensive post on the subject, <a href="https://notes.ethereum.org/@mikeneuder/magnitude-and-direction" rel="noopener nofollow ugc">link</a>). However, there are also many benefits to deterministic stake allocation to professional or larger node operators. It’s possible for solo stakers to have different motivations than an LST whose main objective is to decentralize Ethereum validation (<a href="https://research.lido.fi/t/lido-dao-vibe-alignment-purpose-mission-vision/" rel="noopener nofollow ugc">link</a>). Some of the most noteworthy examples of malicious proposers, for example, have come from solo validators, such as those involved in the April 3rd, 2023 MEV Boost exploit (<a href="https://collective.flashbots.net/t/post-mortem-april-3rd-2023-mev-boost-relay-incident-and-related-timing-issue/" rel="noopener nofollow ugc">link</a>).</p>
<p>Centralized staking providers and LSTs are quantifiably more performant validators than solo stakers. There is significant existing data (<a href="http://rated.network/" rel="noopener nofollow ugc">link</a>) today to quantify proposer effectiveness and attester effectiveness, which drive fewer missed slots and attestations, faster block propagation and chain finalization. Overall the network is much more stable and responsive with professional validators than it would otherwise be, but also more decentralized.</p>
<h5><a class="anchor" href="https://ethresear.ch#issuance-reductions-would-likely-decrease-the-share-of-solo-stakers-18" name="issuance-reductions-would-likely-decrease-the-share-of-solo-stakers-18"></a>Issuance reductions would likely decrease the share of solo stakers</h5>
<p>Some argue that solo stakers are less elastic with respect to yield, because they are as a cohort more heterogeneous than other validating entities, and hence have a steeper supply curve.</p>
<p>However, our simplified analysis of Ethereum validator economics shows this argument is flawed. Solo stakers in fact have much higher fixed costs, making them much less adaptable to a low issuance rates compared to larger node operators. Specifically,</p>
<p>For solo stakers:</p>
<ul>
<li>Staking APR is lower and closer to the Median staking APR (i.e. 2.4% per Rated, <a href="https://explorer.rated.network/network?network=mainnet&amp;timeWindow=1d&amp;rewardsMetric=average&amp;geoDistType=all&amp;hostDistType=all&amp;soloProDist=stake" rel="noopener nofollow ugc">link</a>) than scale node operators due to the unpredictability of proposer rewards, tips and MEV</li>
<li>The costs of running a single validator include hardware (32 GB RAM, 4 TB SSD) and electricity. Home internet plans are sufficient for solo stakers, so broadband cost is assumed to be 0 (no incremental cost).</li>
<li>In this set up, 100% of solo staker’s total costs are fixed costs. Assuming hardware depreciation of 5 years, profit margins are &gt;90% to solo stakers</li>
<li>We exclude the need to reserve 32 ETH in capital as collateral, which brings the capital outlay (though not outright investment) significantly higher</li>
</ul>
<p>Then consider, on the opposite end of the spectrum, a large centralized node operator with 100,000 validators:</p>
<ul>
<li>Staking APR is higher and closer to the Average staking APR (i.e. 3.3% per Rated, <a href="https://explorer.rated.network/network?network=mainnet&amp;timeWindow=1d&amp;rewardsMetric=average&amp;geoDistType=all&amp;hostDistType=all&amp;soloProDist=stake" rel="noopener nofollow ugc">link</a>) as stake pooling smoothes the unpredictable components of both CL (proposer rewards) and EL (tips + MEV) rewards</li>
<li>Costs include hardware but also significant operational costs including technical and marketing staff</li>
<li>Hardware and internet are fixed costs, electricity is a variable cost and staff costs can be seen as a semi-variable cost
<ul>
<li>Employment footprint can be eventually adjusted should the top line be negatively impacted</li>
</ul>
</li>
<li>Counting half of the maintenance &amp; growth spend as fixed and the other half as variable, we arrive at fixed costs representing 64% of the large node operators’ total costs (i.e. much less than solo stakers). Profit margins are also lower than those of solo stakers</li>
</ul>
<div class="md-table">
<table>
<thead>
<tr>
<th>Assumptions</th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td>ETH ($)</td>
<td style="text-align: right;">3,500</td>
</tr>
<tr>
<td>Average staking APR</td>
<td style="text-align: right;">3.3%</td>
</tr>
<tr>
<td>Median staking APR</td>
<td style="text-align: right;">2.4%</td>
</tr>
<tr>
<td>MVI reduction assumed</td>
<td style="text-align: right;">2.0%</td>
</tr>
</tbody>
</table>
</div><div class="md-table">
<table>
<thead>
<tr>
<th><strong>Illustrative Annual P/L</strong></th>
<th style="text-align: center;"><strong>Current</strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align: center;"><strong>Solo Staker</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Large Node Operator</strong></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
</tr>
<tr>
<td># of validators</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">112,000</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">11,200,000,000</td>
</tr>
<tr>
<td>Staking APR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2.4%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">3.3%</td>
</tr>
<tr>
<td>Staking income</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2,677</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">367,360,000</td>
</tr>
<tr>
<td>Commission</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10%</td>
<td style="text-align: center;">36,736,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Hardware cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>800</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>7,750,000</strong></td>
</tr>
<tr>
<td>Computer/servers</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">800</td>
<td style="text-align: center;">350</td>
<td style="text-align: center;">7,000,000</td>
</tr>
<tr>
<td>Backup servers</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">750,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Operational cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>74</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>19,794,780</strong></td>
</tr>
<tr>
<td>Electricity</td>
<td style="text-align: center;">70Wh, $0.12/kWh</td>
<td style="text-align: center;">74</td>
<td style="text-align: center;">750Wh/server, $0.12/kWh</td>
<td style="text-align: center;">354,780</td>
</tr>
<tr>
<td>Internet connection</td>
<td style="text-align: center;">No incremental cost</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">540GB/month/val @ $0.03/GB</td>
<td style="text-align: center;">19,440,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Maintenance &amp; growth</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>11,400,000</strong></td>
</tr>
<tr>
<td>Technical staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">8,400,000</td>
</tr>
<tr>
<td>Marketing/admin staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">3,000,000</td>
</tr>
<tr>
<td>Cybersecurity/miscellaneous</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Total cost (assume 5Y hardware depreciation)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>234</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>32,744,780</strong></td>
</tr>
<tr>
<td>o/w fixed cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">64%</td>
</tr>
<tr>
<td>o/w variable cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">36%</td>
</tr>
<tr>
<td><strong>Payback period on capex (months)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3.9</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>23.3</strong></td>
</tr>
<tr>
<td><strong>Annual income/loss</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>2,443</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3,991,220</strong></td>
</tr>
<tr>
<td><strong>Profit margin (excl. ETH at stake)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>91.3%</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>10.9%</strong></td>
</tr>
</tbody>
</table>
</div><p>In the event that MVI reduces staking APR for all stakers (e.g. -200bps), the below scenario analysis helps visualize how different stakers may be impacted differently. High level:</p>
<ul>
<li>Solo stakers have very limited, if no, way of adjusting their underlying costs. 100% of the reduced staking rewards will fall through to the bottom line, resulting in a dramatic reduction in profit margin. As a result, the payback period on capex (i.e. hardware) multiplies from 3.9 months to 47.2 months in our example, without considering the need to raise 32 ETH to activate a validator to begin with. This raises the question of whether incremental demand from new solo stakers could be sustained in the post-MVI world</li>
<li>Meanwhile, large node operators have more levers to pull to protect their profits and capex payback periods
<ul>
<li>As in Scenario 1, node operators can raise their commission</li>
<li>As in Scenario 2, node operators can raise their commission and reduce variable costs, notably staff costs</li>
<li>With very minor changes to their structure they can come back to prior levels of profit</li>
</ul>
</li>
</ul>
<div class="md-table">
<table>
<thead>
<tr>
<th><strong>Illustrative Annual P/L</strong></th>
<th style="text-align: center;"><strong>If staking APR reduces by 200bps</strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align: center;"><strong>Solo Staker</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Large Node Operator - Scenario 1</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Large Node Operator - Scenario 2</strong></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
</tr>
<tr>
<td># of validators</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">112,000</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">11,200,000,000</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">11,200,000,000</td>
</tr>
<tr>
<td>Staking APR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>0.4%</em></strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>1.3%</em></strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>1.3%</em></strong></td>
</tr>
<tr>
<td>Staking income</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">437</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">143,360,000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">143,360,000</td>
</tr>
<tr>
<td>Commission</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>25%</em></strong></td>
<td style="text-align: center;">35,840,000</td>
<td style="text-align: center;"><strong><em>25%</em></strong></td>
<td style="text-align: center;">35,840,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Hardware cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>800</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>7,750,000</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>7,750,000</strong></td>
</tr>
<tr>
<td>Computer/servers</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">800</td>
<td style="text-align: center;">350</td>
<td style="text-align: center;">7,000,000</td>
<td style="text-align: center;">350</td>
<td style="text-align: center;">7,000,000</td>
</tr>
<tr>
<td>Backup servers</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">750,000</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">750,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Operational cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>74</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>19,794,780</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>19,794,780</strong></td>
</tr>
<tr>
<td>Electricity</td>
<td style="text-align: center;">70Wh, $0.12/kWh</td>
<td style="text-align: center;">74</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">354,780</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">354,780</td>
</tr>
<tr>
<td>Internet connection</td>
<td style="text-align: center;">No incremental cost</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">19,440,000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">19,440,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Maintenance &amp; growth</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>11,400,000</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>10,504,000</strong></td>
</tr>
<tr>
<td>Technical staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">8,400,000</td>
<td style="text-align: center;"><strong><em>64</em></strong></td>
<td style="text-align: center;">7,739,789</td>
</tr>
<tr>
<td>Marketing/admin staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">3,000,000</td>
<td style="text-align: center;"><strong><em>28</em></strong></td>
<td style="text-align: center;">2,764,211</td>
</tr>
<tr>
<td>Cybersecurity/miscellaneous</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000,000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Total cost (assume 5Y hardware depreciation)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>234</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>32,744,780</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>31,848,780</strong></td>
</tr>
<tr>
<td>o/w fixed cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">64%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">66%</td>
</tr>
<tr>
<td>o/w variable cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">36%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">34%</td>
</tr>
<tr>
<td><strong>Payback period on capex (months)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>47.2</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>30.0</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>23.3</strong></td>
</tr>
<tr>
<td><strong>Annual income/loss</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>203</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3,095,220</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3,991,220</strong></td>
</tr>
<tr>
<td><strong>Profit margin (excl. ETH at stake)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>46.5%</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>8.6%</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>11.1%</strong></td>
</tr>
</tbody>
</table>
</div><p><em>Illustrative figures can be found <a href="https://docs.google.com/spreadsheets/d/1tr7VJqzJLiywf34_debHa20wfjU5d8db1eYrJWU0i3Q/edit?gid=0#gid=0" rel="noopener nofollow ugc">here</a></em></p>
<p>Due to the presence of a higher proportion of fixed costs, solo stakers (and smaller node operators alike) will show higher sensitivity to changes in staking rewards compared to larger node operators. The corollary is that as MVI reduces staking reward APR, the marginal players may be priced out, leading to a greater centralization of stake. This would exacerbate the already decreasing trend of solo stakers alongside Ethereum’s issuance compression over time.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c75ca71bdb5bbc1207a30f9439fd1dc937b2aa59.png" title="dune_marketshare"><img alt="dune_marketshare" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c75ca71bdb5bbc1207a30f9439fd1dc937b2aa59_2_690x411.png" width="690" /></a></div><br />
<em>Source: Dune (<a href="https://dune.com/queries/3852057/6478867" rel="noopener nofollow ugc">link</a>)</em><p></p>
<h3><a class="anchor" href="https://ethresear.ch#h-22-lst-dominance-and-cost-modeling-are-inadequate-arguments-for-issuance-reduction-19" name="h-22-lst-dominance-and-cost-modeling-are-inadequate-arguments-for-issuance-reduction-19"></a>2.2. LST dominance and cost-modeling are inadequate arguments for issuance reduction</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-221-issuance-as-a-cost-is-a-reductive-framing-20" name="h-221-issuance-as-a-cost-is-a-reductive-framing-20"></a>2.2.1. Issuance as a cost is a reductive framing</h4>
<p>“Issuance as a cost” concerns the dilution effect on native ETH holders and the potential welfare loss due to externalities like taxes.</p>
<p>The first component focuses on the direct impact of issuance. It redistributes network ownership from unstaked ETH holders to staked ETH holders. High issuance rates force ETH holders to stake to avoid dilution. This increases Ethereum’s security and neutrality but comes with inconvenience and some risk for native ETH holders – which, under MVS, doesn’t qualify as strongly undesirable. Moreover, the cumulative effect could even be seen as beneficial, to the extent that more stake landing with a distributed set of validators justifies investors’ inconvenience.</p>
<p>The second component addresses additional costs for stakers due to taxes. ETH holders who earn staking rewards may face tax obligations, creating additional sell pressure. However, this concern is specific to certain jurisdictions and points in time. Furthermore, the impact of this sell pressure on Ethereum’s overall functionality is questionable. Assuming 3.5% staking rewards, a $400bn ETH market cap, and 30% average taxes paid by all stakers, we get $4.2bn in annual sell pressure. Given Ethereum’s daily trading volume is in billions, absorbing 1% sell pressure over a year seems immaterial. Furthermore, LSTs such as wstETH provide an efficient way to postpone the tax payments, since the tax event is triggered only when wstETH is sold.</p>
<p>Even though ETH market cap is significant in determining attack costs, the relatively minor effect of sell pressure does not provide enough security benefits to justify reducing issuance. The trade-offs include potential staked ETH concentration, loss of sovereignty, and a more substantial decrease in market cap as a result.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-222-stakers-getting-higher-real-vs-nominal-yield-is-not-significant-21" name="h-222-stakers-getting-higher-real-vs-nominal-yield-is-not-significant-21"></a>2.2.2. Stakers getting higher real vs nominal yield is not significant</h4>
<p>This argument, while mathematically beautiful (<a href="https://notes.ethereum.org/@mikeneuder/subsol#3-Scaled-Root-Curve-alternative-issuance" rel="noopener nofollow ugc">link</a>), is not significant in magnitude. It does not affect security and neutrality in any way; in fact, it is not at all clear if there is any benefit to Ethereum in fewer stakers getting higher real yield compared to more stakers getting less real yield. In addition, this analysis assumes concave supply curves with respect to nominal yield, while it is possible that at a higher staking ratio we should adjust our analysis to concave supply curves with respect to real yield.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-223-reducing-lst-dominance-shouldnt-be-a-primary-objective-of-ethereums-monetary-policy-22" name="h-223-reducing-lst-dominance-shouldnt-be-a-primary-objective-of-ethereums-monetary-policy-22"></a>2.2.3. Reducing LST dominance shouldn’t be a primary objective of Ethereum’s monetary policy</h4>
<p>This argument is directly related to security and neutrality, and thus can be analyzed under a security-maximizing framework.</p>
<p>In his article (<a href="https://notes.ethereum.org/@mikeneuder/magnitude-and-direction" rel="noopener nofollow ugc">link</a>) Mike Neuder analyzed various directions and magnitudes of possible Lido attacks on Ethereum in the future. While there are several potential attacks, all of them have a corresponding mitigation plan. Dual governance is at the heart of many of those mitigations. DG is a mechanism that allows stETH holders to slow down Lido’s governance and exit from the protocol before any decision is made. This mechanism is in active and final stages of development (<a href="https://research.lido.fi/t/dual-governance-design-and-implementation-proposal" rel="noopener nofollow ugc">link</a>).</p>
<p>Another argument for issuance reduction is that stETH risks substituting ETH as the de-facto money and collateral. While there is certainly a possibility that LSTs wind up replacing a lot of ETH functionality in DeFi, it does not diminish the moneyness of ETH – all LSTs are underscored by ETH, and thus derive their value from ETH. In order to execute any of these transactions, users will still need ETH to pay for gas, at the very least. Furthermore, ETH will continue to be bridged to various L2s either way, so at a baseline ETH velocity will already decline with broader adoption of L2s, without compromising its moneyness.</p>
<p>Finally, there are unintended consequences to targeting individual applications in an opinionated manner in order to manipulate the viability of ETH as collateral or as commodity money. The long-term roadmap of Ethereum should not be hostage to short-term tactical considerations, least of all on the application layer. The growth of LSTs has allowed the growth of user activity on Ethereum and has also increased the velocity and usage of Ether itself.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-3-putting-it-all-together-23" name="h-3-putting-it-all-together-23"></a>3. Putting it all together</h2>
<p>MVI, as a framework, ultimately suggests to squeeze as much as possible out of staking, so that stakers’ cost and revenue are more or less at the same low rate. The major problem of this approach is that market forces structurally do not reward decentralization, and ultimately drive stake concentration to CEXs, which are entities with the lowest cost validators and the most inelastic customer base. Thus the downside of MVI is undermining the security and neutrality of Ethereum. In our view, the benefits of MVI, such as decreasing the selling pressure from taxes, do not justify taking this risk on balance.</p>
<p>MVS, on the other hand, suggests evaluating monetary policies primarily through the lens of how it affects security and neutrality, the core value propositions of Ethereum. One of the arguments for issuance reduction, namely to tackle LST dominance, indeed falls into MVS focus. However, the security and neutrality concerns of LST dominance are of second order in nature (“if dual governance doesn’t work”, “LST becomes an additional risk layer for all users”, etc). Meanwhile, stake accumulating in CEXs rather than in LSTs, LRTs or even CSPs creates a very real risk of staked ETH concentration with one single entity. As such, we do not see the case where LST dominance risk outweighs the risk of stake concentration with CEXs.</p>
<p>While we presented the MVS framework, and accordingly evaluated the issuance reduction proposal, the natural question stands: what would be the right issuance policy under the MVS approach? This is an incredibly complex and deep question that we would like to explore in future. Some of the directions that we have in mind include:</p>
<ul>
<li>How do we quantifiably measure security? Is there a way for a protocol to see its security? Credit to the contributions from the StakeSure (<a href="https://arxiv.org/abs/2401.05797" rel="noopener nofollow ugc">link</a>) paper in this direction.</li>
<li>Guided by MVS, rather than focusing on value creation through cost reductions, we should instead consider the value creation by improving security and neutrality. There is a heuristic argument that increasing issuance can improve security through making the network more complex via a more diverse validator set. Is there a way to make this precise? How do we make sure that the extra issued ETH strictly improves security and neutrality?</li>
</ul>
<p>Is there a case for a marginal improvement analysis: the more diverse the validator set is, the more complex the network becomes, and improvements to security could have increasing marginal contributions. (Similar to how complexity contributes to entropy and layered security, <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" rel="noopener nofollow ugc">link</a>)</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/f/1f6daf84bc2dfabd3b7747f049d71b9597079ddb.jpeg" title="image"><img alt="image" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/1/f/1f6daf84bc2dfabd3b7747f049d71b9597079ddb_2_690x389.jpeg" width="690" /></a></div><p></p>
<hr />
<p><em>Disclosure: authors are variously affiliated with cyber.fund, Lido DAO, Steakhouse Financial, Progrmd Capital</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 06 Jul 2024 21:56:34 +0000</pubDate>
</item>
<item>
<title>Releasing Constantine v0.1.0, a modular cryptography stack for Ethereum</title>
<link>https://ethresear.ch/t/releasing-constantine-v0-1-0-a-modular-cryptography-stack-for-ethereum/19990</link>
<guid>https://ethresear.ch/t/releasing-constantine-v0-1-0-a-modular-cryptography-stack-for-ethereum/19990</guid>
<content:encoded><![CDATA[
<p>I am very proud to release the very first version of <a href="https://github.com/mratsim/constantine" rel="noopener nofollow ugc">Constantine</a>, a high-performance modular cryptography stack for blockchains and proof systems.<br />
It is currently as of July 2024 the fastest implementation of Ethereum-specific cryptographic primitives:</p>
<ul>
<li>BLS signatures</li>
<li>BN254 precompiles (EIP-196 and EIP-197, repriced in EIP-1108)</li>
<li>BLS12-381 precompiles (EIP-2537)</li>
<li>KZG Polynomial commitments (EIP-4844)</li>
</ul>
<p>Constantine has bindings in C, Go, Nim and Rust.</p>
<h2><a class="anchor" href="https://ethresear.ch#history-1" name="history-1"></a>History</h2>
<p>Constantine is written in <a href="https://nim-lang.org/" rel="noopener nofollow ugc">Nim</a>, the language was chosen by Status for Nimbus for its expressiveness, its type system strength, the ease to wrap C and C++ and syntactic closeness to Python so that ethereum/research and PyEVM could be ported with ease.</p>
<p>In February 2018, after woes with C++ in Nimbus, the first library I built was a fixed precision big integer library for uint256.<br />
Then we (at Status) realized that we would also need elliptic curves for secp256k1 and BN254 (also known as BN256 or alt_bn128).</p>
<p>How hard could it be to implement elliptic curves, with cryptographic hardening, once you know how to write big integers?</p>
<p>Turned out it was too hard, after a week or so another approach was taken for time-to-market and correctness reasons:</p>
<ul>
<li>Use libsecp256k1 from Bitcoin</li>
<li>Port 1-1 bncurves from Zcash for BN254</li>
<li>Use Apache Milagro for BLS12-381</li>
</ul>
<p>It was then restarted as a personal side-project in February 2020 after learning a lot from implementing hashing-to-curve and Ethereum BLS signatures and identifying significant performance gap. <em>Note that this predates BLST which was initially released in June 2020.</em></p>
<p>Since then Constantine has seen regular contributions (sometimes with couple months gap) up to where it is today.</p>
<h2><a class="anchor" href="https://ethresear.ch#performance-2" name="performance-2"></a>Performance</h2>
<h3><a class="anchor" href="https://ethresear.ch#ethereum-bls-signatures-consensus-layer-3" name="ethereum-bls-signatures-consensus-layer-3"></a>Ethereum BLS signatures (Consensus Layer)</h3>
<p>Benchmarks are done on an AMD Ryzen 7840U, a low-power ultra-mobile 8-core CPU from 2023.</p>
<h4><a class="anchor" href="https://ethresear.ch#blst-through-nim-blscurve-4" name="blst-through-nim-blscurve-4"></a>BLST (through nim-blscurve)</h4>
<p>Nim-blscurve is the backend of Nimbus-eth2. As Nim compiles to machine code through C (or C++), calling C has zero-overhead from Nim.</p>
<p>Repro.<br />
Install the latest Nim version, Nim v2.0.8.</p>
<pre><code class="lang-auto">git clone https://github.com/status-im/nim-blscurve
cd nim-blscurve
git submodule update --init
nimble bench
</code></pre>
<p>2 benchmarks will be done with 2 different memory management solutions (different implementations of refcounting)<br />
BLST is as-of v0.3.12 (May 2024) with runtime CPU features detection</p>
<pre><code class="lang-auto">Backend: BLST, mode: 64-bit
====================================================================================================================================

Scalar multiplication G1 (255-bit, constant-time)                             10332.180 ops/s        96785 ns/op       318784 cycles
Scalar multiplication G2 (255-bit, constant-time)                              4622.247 ops/s       216345 ns/op       712585 cycles
EC add G1 (constant-time)                                                   1795332.136 ops/s          557 ns/op         1836 cycles
EC add G2 (constant-time)                                                    713775.874 ops/s         1401 ns/op         4617 cycles
------------------------------------------------------------------------------------------------------------------------------------
Pairing (Miller loop + Final Exponentiation)                                   1484.823 ops/s       673481 ns/op      2218271 cycles
------------------------------------------------------------------------------------------------------------------------------------
Hash to G2 (Draft #9) + affine conversion                                      6795.232 ops/s       147162 ns/op       484712 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS signature                                                                  3490.864 ops/s       286462 ns/op       943532 cycles
BLS verification                                                               1212.302 ops/s       824877 ns/op      2716928 cycles
BLS agg verif of 1 msg by 128 pubkeys                                          1139.886 ops/s       877281 ns/op      2889519 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 6 msgs by 6 pubkeys                                                203.231 ops/s      4920498 ns/op     16206824 cycles
Serial batch verify 6 msgs by 6 pubkeys (with blinding)                         359.968 ops/s      2778025 ns/op      9150078 cycles
Parallel batch verify of 6 msgs by 6 pubkeys (with blinding)                    615.452 ops/s      1624822 ns/op      5351722 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 60 msgs by 60 pubkeys                                               20.310 ops/s     49236672 ns/op    162172626 cycles
Serial batch verify 60 msgs by 60 pubkeys (with blinding)                        42.709 ops/s     23414406 ns/op     77120772 cycles
Parallel batch verify of 60 msgs by 60 pubkeys (with blinding)                  250.298 ops/s      3995236 ns/op     13159139 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 180 msgs by 180 pubkeys                                              6.746 ops/s    148237745 ns/op    488256390 cycles
Serial batch verify 180 msgs by 180 pubkeys (with blinding)                      14.419 ops/s     69354258 ns/op    228434104 cycles
Parallel batch verify of 180 msgs by 180 pubkeys (with blinding)                 99.467 ops/s     10053540 ns/op     33113513 cycles
------------------------------------------------------------------------------------------------------------------------------------

Using nthreads = 16. The number of threads can be changed with TP_NUM_THREADS environment variable.
</code></pre>
<h4><a class="anchor" href="https://ethresear.ch#constantine-5" name="constantine-5"></a>Constantine</h4>
<p>GCC generates poor code everwhere assembly is not used, hence we force Clang as a compiler.</p>
<pre><code class="lang-auto">git clone https://github.com/mratsim/constantine
cd constantine
CC=clang nimble bench_eth_bls_signatures
</code></pre>
<pre><code class="lang-auto">--------------------------------------------------------------------------------------------------------------------------------------------------
Pubkey deserialization (full checks)                                                     BLS12_381 G1          22295.550 ops/s         44852 ns/op        147729 CPU cycles (approx)
Pubkey deserialization (skip checks)                                                     BLS12_381 G1          92515.496 ops/s         10809 ns/op         35602 CPU cycles (approx)
Signature deserialization (full checks)                                                  BLS12_381 G2          16808.418 ops/s         59494 ns/op        195958 CPU cycles (approx)
Signature deserialization (skip checks)                                                  BLS12_381 G2          46453.291 ops/s         21527 ns/op         70906 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS signature                                                                            BLS12_381 G2           4005.078 ops/s        249683 ns/op        822392 CPU cycles (approx)
BLS verification                                                                         BLS12_381              1498.960 ops/s        667129 ns/op       2197347 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS agg verif of 1 msg by 128 pubkeys                                                    BLS12_381              1423.694 ops/s        702398 ns/op       2313504 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 6 msgs by 6 pubkeys                                                         BLS12_381               249.683 ops/s       4005085 ns/op      13191614 CPU cycles (approx)
BLS serial batch verify of 6 msgs by 6 pubkeys (with blinding)                           BLS12_381               420.912 ops/s       2375795 ns/op       7825187 CPU cycles (approx)
BLS parallel batch verify (16 threads) of 6 msgs by 6 pubkeys (with blinding)            BLS12_381               683.399 ops/s       1463273 ns/op       4819062 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 60 msgs by 60 pubkeys                                                       BLS12_381                24.863 ops/s      40220998 ns/op     132477024 CPU cycles (approx)
BLS serial batch verify of 60 msgs by 60 pubkeys (with blinding)                         BLS12_381                48.878 ops/s      20459201 ns/op      67387049 CPU cycles (approx)
BLS parallel batch verify (16 threads) of 60 msgs by 60 pubkeys (with blinding)          BLS12_381               280.961 ops/s       3559207 ns/op      11722847 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 180 msgs by 180 pubkeys                                                     BLS12_381                 8.334 ops/s     119995222 ns/op     395232558 CPU cycles (approx)
BLS serial batch verify of 180 msgs by 180 pubkeys (with blinding)                       BLS12_381                16.488 ops/s      60650899 ns/op     199767961 CPU cycles (approx)
BLS parallel batch verify (16 threads) of 180 msgs by 180 pubkeys (with blinding)        BLS12_381               112.215 ops/s       8911481 ns/op      29351939 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
</code></pre>
<h4><a class="anchor" href="https://ethresear.ch#analysis-6" name="analysis-6"></a>Analysis</h4>
<ul>
<li>15% performance improvement on signatures</li>
<li>24% performance improvement on verification</li>
</ul>
<p>Furthermore, it is in theory possible to achieve a 2x performance improvement for signing if there is a need for it.</p>
<h3><a class="anchor" href="https://ethresear.ch#kzg-polynomial-commitment-for-eip-4844-consensus-layer-7" name="kzg-polynomial-commitment-for-eip-4844-consensus-layer-7"></a>KZG Polynomial commitment for EIP-4844 (Consensus Layer)</h3>
<p>I will reuse my benchmarks from Dec, 2023: <a class="inline-onebox" href="https://github.com/mratsim/constantine/pull/304#issuecomment-1844795359" rel="noopener nofollow ugc">Productionize KZG EIP-4844 by mratsim · Pull Request #304 · mratsim/constantine · GitHub</a></p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: center;">Bench</th>
<th style="text-align: center;">c-kzg-4844 (serial)</th>
<th style="text-align: center;">go-kzg-4844 (serial)</th>
<th style="text-align: center;">go-kzg-4844 (parallel)</th>
<th style="text-align: center;">constantine (serial)</th>
<th style="text-align: center;">constantine (parallel)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">blob_to_kzg_commitment</td>
<td style="text-align: center;">37.773 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.823 ms</td>
<td style="text-align: center;">23.765 ms</td>
<td style="text-align: center;">4.425 ms</td>
</tr>
<tr>
<td style="text-align: center;">compute_kzg_proof</td>
<td style="text-align: center;">39.945 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.146 ms</td>
<td style="text-align: center;">24.255 ms</td>
<td style="text-align: center;">4.710 ms</td>
</tr>
<tr>
<td style="text-align: center;">compute_blob_kzg_proof</td>
<td style="text-align: center;">40.212 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.205 ms</td>
<td style="text-align: center;">24.288 ms</td>
<td style="text-align: center;">4.794 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_kzg_proof</td>
<td style="text-align: center;">0.915 ms</td>
<td style="text-align: center;">0.923 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.782 ms</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof</td>
<td style="text-align: center;">1.531 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1.390 ms</td>
<td style="text-align: center;">1.266 ms</td>
<td style="text-align: center;">1.113 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 1</td>
<td style="text-align: center;">1.528 ms</td>
<td style="text-align: center;">1.392 ms</td>
<td style="text-align: center;">1.405 ms</td>
<td style="text-align: center;">1.286 ms</td>
<td style="text-align: center;">1.130 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 2</td>
<td style="text-align: center;">2.589 ms</td>
<td style="text-align: center;">3.233 ms</td>
<td style="text-align: center;">1.591 ms</td>
<td style="text-align: center;">2.006 ms</td>
<td style="text-align: center;">1.152 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 4</td>
<td style="text-align: center;">4.553 ms</td>
<td style="text-align: center;">4.671 ms</td>
<td style="text-align: center;">1.914 ms</td>
<td style="text-align: center;">3.437 ms</td>
<td style="text-align: center;">1.250 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 8</td>
<td style="text-align: center;">8.446 ms</td>
<td style="text-align: center;">7.410 ms</td>
<td style="text-align: center;">2.738 ms</td>
<td style="text-align: center;">6.115 ms</td>
<td style="text-align: center;">1.891 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 16</td>
<td style="text-align: center;">16.228 ms</td>
<td style="text-align: center;">12.734 ms</td>
<td style="text-align: center;">3.542 ms</td>
<td style="text-align: center;">11.567 ms</td>
<td style="text-align: center;">3.091 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 32</td>
<td style="text-align: center;">32.016 ms</td>
<td style="text-align: center;">23.048 ms</td>
<td style="text-align: center;">7.215 ms</td>
<td style="text-align: center;">21.779 ms</td>
<td style="text-align: center;">6.764 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 64</td>
<td style="text-align: center;">63.415 ms</td>
<td style="text-align: center;">43.224 ms</td>
<td style="text-align: center;">14.438 ms</td>
<td style="text-align: center;">43.099 ms</td>
<td style="text-align: center;">11.538 ms</td>
</tr>
</tbody>
</table>
</div><ul>
<li>A 37% performance improvement over c-kzg-4844 for serial commitment</li>
<li>A 39% improvement for proof generation</li>
<li>A 17% improvement for a single blob verification</li>
<li>A 32% improvement for 64 blob verification</li>
</ul>
<p>And Constantine offers paralellization to improve those numbers 4~6x on my 8-core machine.</p>
<h3><a class="anchor" href="https://ethresear.ch#evm-precompiles-execution-layer-8" name="evm-precompiles-execution-layer-8"></a>EVM precompiles (Execution Layer)</h3>
<p>Note:</p>
<ul>
<li>Constantine also offers a fast MODEXP precompile that reaches 80% to 110% of GMP, without assembly.</li>
<li>SHA256 is faster than OpenSSL and BLST for data size less than 4MB and within 3% otherwise.</li>
</ul>
<pre><code class="lang-auto">git clone https://github.com/mratsim/constantine
cd constantine
CC=clang nimble bench_eth_evm_precompiles
</code></pre>
<pre><code class="lang-auto">--------------------------------------------------------------------------------------------------------------------------------
SHA256 -  32 bytes            72 gas    1714.29 MGas/s    23809523.810 ops/s           42 ns/op          140 CPU cycles (approx)
SHA256 -  64 bytes            84 gas    1584.91 MGas/s    18867924.528 ops/s           53 ns/op          176 CPU cycles (approx)
SHA256 -  96 bytes            96 gas    1777.78 MGas/s    18518518.519 ops/s           54 ns/op          179 CPU cycles (approx)
SHA256 - 128 bytes           108 gas    1333.33 MGas/s    12345679.012 ops/s           81 ns/op          267 CPU cycles (approx)
SHA256 - 160 bytes           120 gas    1481.48 MGas/s    12345679.012 ops/s           81 ns/op          268 CPU cycles (approx)
SHA256 - 192 bytes           132 gas    1233.64 MGas/s     9345794.393 ops/s          107 ns/op          353 CPU cycles (approx)
SHA256 - 224 bytes           144 gas    1321.10 MGas/s     9174311.927 ops/s          109 ns/op          359 CPU cycles (approx)
SHA256 - 256 bytes           156 gas    1130.43 MGas/s     7246376.812 ops/s          138 ns/op          454 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BN254_G1ADD                  150 gas      87.41 MGas/s      582750.583 ops/s         1716 ns/op         5652 CPU cycles (approx)
BN254_G1MUL                 6000 gas     229.66 MGas/s       38276.047 ops/s        26126 ns/op        86050 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BN254_PAIRINGCHECK 1       79000 gas     166.99 MGas/s        2113.754 ops/s       473092 ns/op      1558009 CPU cycles (approx)
BN254_PAIRINGCHECK 2      113000 gas     191.99 MGas/s        1699.056 ops/s       588562 ns/op      1938370 CPU cycles (approx)
BN254_PAIRINGCHECK 3      147000 gas     183.15 MGas/s        1245.930 ops/s       802613 ns/op      2642801 CPU cycles (approx)
BN254_PAIRINGCHECK 4      181000 gas     191.76 MGas/s        1059.434 ops/s       943900 ns/op      3108745 CPU cycles (approx)
BN254_PAIRINGCHECK 5      215000 gas     169.72 MGas/s         789.374 ops/s      1266827 ns/op      4171120 CPU cycles (approx)
BN254_PAIRINGCHECK 6      249000 gas     181.10 MGas/s         727.321 ops/s      1374909 ns/op      4528210 CPU cycles (approx)
BN254_PAIRINGCHECK 7      283000 gas     189.03 MGas/s         667.965 ops/s      1497084 ns/op      4930714 CPU cycles (approx)
BN254_PAIRINGCHECK 8      317000 gas     204.18 MGas/s         644.095 ops/s      1552566 ns/op      5113680 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_G1ADD                  500 gas     164.10 MGas/s      328191.664 ops/s         3047 ns/op        10034 CPU cycles (approx)
BLS12_G2ADD                  800 gas     161.75 MGas/s      202183.583 ops/s         4946 ns/op        16289 CPU cycles (approx)
BLS12_G1MUL                12000 gas     141.66 MGas/s       11805.400 ops/s        84707 ns/op       279001 CPU cycles (approx)
BLS12_G2MUL                45000 gas     325.51 MGas/s        7233.639 ops/s       138243 ns/op       455333 CPU cycles (approx)
BLS12_MAP_FP_TO_G1          5500 gas     161.82 MGas/s       29422.149 ops/s        33988 ns/op       111947 CPU cycles (approx)
BLS12_MAP_FP2_TO_G2        75000 gas     659.96 MGas/s        8799.486 ops/s       113643 ns/op       374305 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_PAIRINGCHECK 1      108000 gas     216.83 MGas/s        2007.665 ops/s       498091 ns/op      1640562 CPU cycles (approx)
BLS12_PAIRINGCHECK 2      151000 gas     222.00 MGas/s        1470.214 ops/s       680173 ns/op      2240287 CPU cycles (approx)
BLS12_PAIRINGCHECK 3      194000 gas     219.98 MGas/s        1133.901 ops/s       881911 ns/op      2904762 CPU cycles (approx)
BLS12_PAIRINGCHECK 4      237000 gas     222.97 MGas/s         940.782 ops/s      1062946 ns/op      3500927 CPU cycles (approx)
BLS12_PAIRINGCHECK 5      280000 gas     221.08 MGas/s         789.576 ops/s      1266502 ns/op      4171417 CPU cycles (approx)
BLS12_PAIRINGCHECK 6      323000 gas     223.09 MGas/s         690.679 ops/s      1447851 ns/op      4768780 CPU cycles (approx)
BLS12_PAIRINGCHECK 7      366000 gas     222.28 MGas/s         607.311 ops/s      1646603 ns/op      5423299 CPU cycles (approx)
BLS12_PAIRINGCHECK 8      409000 gas     221.94 MGas/s         542.640 ops/s      1842844 ns/op      6069597 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_G1MSM   2            21312 gas     120.40 MGas/s        5649.430 ops/s       177009 ns/op       583004 CPU cycles (approx)
BLS12_G1MSM   4            30768 gas     101.53 MGas/s        3299.960 ops/s       303034 ns/op       998108 CPU cycles (approx)
BLS12_G1MSM   8            43488 gas      81.23 MGas/s        1867.787 ops/s       535393 ns/op      1763434 CPU cycles (approx)
BLS12_G1MSM  16            64128 gas      66.43 MGas/s        1035.864 ops/s       965378 ns/op      3179510 CPU cycles (approx)
BLS12_G1MSM  32           103296 gas      57.99 MGas/s         561.362 ops/s      1781382 ns/op      5867248 CPU cycles (approx)
BLS12_G1MSM  64           170496 gas      50.89 MGas/s         298.504 ops/s      3350039 ns/op     11034035 CPU cycles (approx)
BLS12_G1MSM 128           267264 gas      42.24 MGas/s         158.035 ops/s      6327700 ns/op     20841720 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_G2MSM   2            79920 gas     269.62 MGas/s        3373.637 ops/s       296416 ns/op       976301 CPU cycles (approx)
BLS12_G2MSM   4           115380 gas     225.12 MGas/s        1951.109 ops/s       512529 ns/op      1688121 CPU cycles (approx)
BLS12_G2MSM   8           163080 gas     177.21 MGas/s        1086.654 ops/s       920256 ns/op      3031066 CPU cycles (approx)
BLS12_G2MSM  16           240480 gas     130.56 MGas/s         542.920 ops/s      1841892 ns/op      6066436 CPU cycles (approx)
BLS12_G2MSM  32           387360 gas     126.36 MGas/s         326.195 ops/s      3065648 ns/op     10097244 CPU cycles (approx)
BLS12_G2MSM  64           639360 gas     118.26 MGas/s         184.965 ops/s      5406423 ns/op     17807268 CPU cycles (approx)
BLS12_G2MSM 128          1002240 gas     100.70 MGas/s         100.471 ops/s      9953136 ns/op     32782906 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
</code></pre>
<p>Constantine achieves over 200Mgas/s for a wide range of cryptographic precompiles on a laptop CPU with restricted power consumption (7840U, 15W to 30W)</p>
<p>note, I suggest a repricing for EIP-2537 to help SNARKS applications.</p>
<h2><a class="anchor" href="https://ethresear.ch#security-9" name="security-9"></a>Security</h2>
<p>Constantine, as it names indicates, as a strong focus on security and especially constant-time cryptography is used by default in the core of the library.<br />
It HAS NOT been audited yet, but it has undergone extensive fuzzing by Guido Vranken, thanks to the sponsoring of the Ethereum Foundation in Summer 2023. It has also been added to OSS-Fuzz (<a class="inline-onebox" href="https://github.com/google/oss-fuzz/pull/10710" rel="noopener nofollow ugc">[bls-signatures] Remove Chia, add Constantine by guidovranken · Pull Request #10710 · google/oss-fuzz · GitHub</a>), the Google 24/7 open-source fuzzing initiative.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-future-10" name="the-future-10"></a>The Future</h2>
<p>Constantine will follow and support future Ethereum cryptographic needs. In particular I thank the Ethereum Foundation Fellowship Program and Status for sponsoring work on implementing Verkle Tries in Constantine the past year.</p>
<p>Constantine also supports accelerating Zero-Knowledge proof systems, for example it is possible to use it through PSE (Privacy Scaling Explorations, a branch of the EF) Halo2: <a class="inline-onebox" href="https://github.com/mratsim/constantine/pull/308" rel="noopener nofollow ugc">ZAL: ZK Accel Layer by mratsim · Pull Request #308 · mratsim/constantine · GitHub</a>.</p>
<p>Constantine is has the fastest MSM on x86, all libraries benchmarked as of July 2024 (Arkworks, Barretenberg, Bellman, Gnark, Halo2) and by a factor 2x over popular Rust libraries Arkworks and Halo2. And I do plan to build proof systems on top.</p>
<p>Hidden in Constantine is a compiler for GPU code generation and there are plans for accelerating ARM.</p>
<p>Now I don’t know what a snarkified EVM will look like, but I certainly hope to contribute to make it a reality.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/releasing-constantine-v0-1-0-a-modular-cryptography-stack-for-ethereum/19990">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 06 Jul 2024 11:01:41 +0000</pubDate>
</item>
<item>
<title>Reputation-Centric Light Client Framework for Optimistic Rollups</title>
<link>https://ethresear.ch/t/reputation-centric-light-client-framework-for-optimistic-rollups/19988</link>
<guid>https://ethresear.ch/t/reputation-centric-light-client-framework-for-optimistic-rollups/19988</guid>
<content:encoded><![CDATA[
<div> 关键词：声誉系统、乐观rollup、Herodotus数据处理器、存储证明、快速最终性

总结:<br />
本文提出了一种基于声誉的轻客户端框架，旨在优化乐观rollup（ORU）的性能，特别是缩短最终性时间。框架核心是Herodotus数据处理器，通过计算sequencer的历史行为信誉分数，如无挑战记录和输出根的有效性，允许轻客户端信任信誉良好的sequencer的输出根，无需等待完整的争议期。系统还包括惩罚机制和备份机制，以确保安全性和可靠性。该方法有望改善用户体验并推动L2生态发展。 <div>
<p>Authors: <a href="https://x.com/0xmarcello" rel="noopener nofollow ugc">Marcello Bardus</a> (<a href="https://x.com/HerodotusDev" rel="noopener nofollow ugc">Herodotus</a>), <a href="https://x.com/kacperkozi" rel="noopener nofollow ugc">Kacper Koziol</a> (<a href="https://x.com/HerodotusDev" rel="noopener nofollow ugc">Herodotus</a>)</p>
<p>Thanks for early feedback: <a href="https://x.com/bonustrack87" rel="noopener nofollow ugc">bonustrack87</a> (<a href="https://x.com/SnapshotLabs" rel="noopener nofollow ugc">Snapshot Labs</a>), <a href="https://x.com/lsukernik" rel="noopener nofollow ugc">Larry Sukernik</a> (<a href="https://x.com/hi_reverie" rel="noopener nofollow ugc">Reverie</a>), <a href="https://x.com/piapark_eth" rel="noopener nofollow ugc">Pia Park</a> (<a href="https://x.com/HerodotusDev" rel="noopener nofollow ugc">Herodotus</a>), <a href="https://x.com/wojtekwtf" rel="noopener nofollow ugc">Wojtek</a> (<a href="https://www.supercast.xyz/" rel="noopener nofollow ugc">Supercast</a>),</p>
<h1><a class="anchor" href="https://ethresear.ch#summary-1" name="summary-1"></a>Summary:</h1>
<p>This post introduces a conceptual framework for a reputation-centric light client system designed to address critical challenges in Optimistic Rollups (ORUs), with a primary focus on enabling fast finality for accessing ORU data from Ethereum, ORUs and other Ethereum layers. At its core, the system leverages the Herodotus Data Processor to compute sequencer reputation scores based on the sequencer’s historical behavior, including their track record of submitting valid output roots and avoiding successful challenges. This allows light clients to trust output roots only from sequencers with an impeccable track record without waiting for the full dispute period. This approach significantly reduces finality time while maintaining security. The framework includes a punitive measure that resets a sequencer’s reputation upon successful challenges, ensuring system integrity. Additionally, a fallback mechanism reverts to the standard seven-day dispute period in cases of unresolved conflicts or detected irregularities.</p>
<h3><a class="anchor" href="https://ethresear.ch#reputation-centric-light-client-framework-for-optimistic-rollups-2" name="reputation-centric-light-client-framework-for-optimistic-rollups-2"></a>Reputation-Centric Light Client Framework for Optimistic Rollups</h3>
<p>Optimistic Rollups have seen significant adoption, however, they encounter several challenges, particularly in terms of finality time and data verification. This post introduces a conceptual framework for a reputation-centric light client system that aims to address these issues, enabling fast finality for accessing ORU data from Ethereum, and from other Ethereum layers.</p>
<p>OP Stack and other Optimistic Rollups (ORUs) have a security model based on fraud proofs. In this model, anyone can act as a sequencer, also known as a proposer. The sequencer first proposes the rollup state to Layer 1 (L1), after which a seven-day window is opened. During this period, anyone can challenge the correctness of the proposed state.</p>
<p>In ORU implementations such as OP Stack, proposers periodically submit output roots to L1. These output roots are a hash of certain L2 state information, including the state root, block number, and timestamp of the latest L2 block. OP Stack incorporates a specification for a fault proof system with bonding, which creates incentives for proposers to submit correct output roots.</p>
<p>This mechanism imposes a long finality time for ORUs, which is problematic for Storage Proofs, a secure on-chain data access solution that Herodotus has previously developed for Optimism and several other ORU ecosystems. This is especially problematic following recent upgrades that introduced permissionless fraud proofs on Optimism. With these upgrades, no assumptions can be made about where a valid state root can be found.</p>
<h2><a class="anchor" href="https://ethresear.ch#secure-data-access-and-processing-3" name="secure-data-access-and-processing-3"></a>Secure Data Access and Processing</h2>
<p>The framework incorporates two crucial components:</p>
<h3><a class="anchor" href="https://ethresear.ch#storage-proofs-4" name="storage-proofs-4"></a>Storage Proofs</h3>
<p>Storage Proofs are a secure on-chain data access primitive utilized by the Herodotus Data Processor that enables the cryptographic proving of the provenance of on-chain data. They allow for the verification of any data available on Ethereum, including current and historical balances, transactions, user interactions, liquidations, and more. Storage Proofs also enable the trustless and secure reading of data from arbitrary Ethereum Layers.</p>
<p>By utilizing Storage Proofs, the Herodotus Data Processor can ensure the integrity and authenticity of the on-chain data it processes, providing a foundation of trust for its computations.</p>
<h3><a class="anchor" href="https://ethresear.ch#data-processing-component-5" name="data-processing-component-5"></a>Data Processing Component</h3>
<p>This would leverage the Herodotus Data Processor (HDP) to compute sequencer reputation scores efficiently. HDP can be thought of as a zk-coprocessor, capable of performing computations on verified data. Storage Proofs guarantee the integrity of the input data to HDP. Custom computations can be defined using HDP Modules, which can later process the verified historical data and update reputation scores based on the defined criteria, such as the consistency of avoiding challenges and the validity of proposed output roots over time.</p>
<h2><a class="anchor" href="https://ethresear.ch#reputation-based-light-client-6" name="reputation-based-light-client-6"></a>Reputation based light client</h2>
<p>In our design, a sequencer, identified by an Ethereum address, would be assumed to be the most trustworthy based on the following criteria:</p>
<ul>
<li>The sequencer consistently avoids challenges, or any initiated challenges against them are unsuccessful.</li>
<li>The validity of the sequencer’s proposed output roots over time, as proven by the lack of successful fault proofs against their outputs.</li>
</ul>
<p>In OP Stack implementations like Bedrock, and potentially in other ORUs, output roots represent a compact summary of the L2 state at a specific block. These output roots are not Merkle roots of the entire canonical L2 chain, but rather a hash of certain L2 state information. Bonded proposers periodically submit these output roots to L1.</p>
<p>The output root typically includes a hash of the following information:</p>
<ol>
<li>The state root of the L2 block</li>
<li>The L2 block number</li>
<li>The timestamp of the L2 block</li>
<li>The hash of the L2 block itself</li>
</ol>
<p>This structure allows for efficient verification of specific L2 state information without requiring the entire L2 chain data on L1.</p>
<p>Once a highly reputable sequencer posts a claimed output root to L1, a Light Client contract would assume the claim is valid and treat it as final. This approach ensures that only sequencers with an impeccable track record are trusted, significantly reducing the finality time while relying on the cryptographically proven historical reliability of the sequencer rather than waiting for the full dispute period.</p>
<p>The Light Client contract would store the full output roots proposed by reputable sequencers, not just the block hash, enabling trustless proof of claims like withdrawals against the output roots directly.</p>
<p>The reputation of the sequencer can be periodically updated using the Herodotus Data Processor. This involves assessing historical data to ensure the sequencer continues to meet the criteria of reliability and activity. By continuously evaluating the sequencer’s performance and updating their reputation at fixed intervals, the Light Client can maintain a high level of trust and accuracy in the state roots it accepts.</p>
<h2><a class="anchor" href="https://ethresear.ch#system-architecture-7" name="system-architecture-7"></a>System Architecture</h2>
<h2><a class="anchor" href="https://ethresear.ch#h-326x4111935069506181uploadpmywafztk4c8h3awxejv5ig72gppng-8" name="h-326x4111935069506181uploadpmywafztk4c8h3awxejv5ig72gppng-8"></a><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/4/b4b3807ab51eeeb259a9c7c08890b13cd0910b23.png" title="|326x411.1935069506181"><img alt="|326x411.1935069506181" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/4/b4b3807ab51eeeb259a9c7c08890b13cd0910b23_2_396x500.png" width="396" /></a></div></h2>
<p>The proposed system would operate as follows:</p>
<ol>
<li>Proposers submit output root proposals to the appropriate ORU contracts on L1, based on the state of the ORU L2 chain.</li>
<li>The ORU L1 contracts handle both output root proposals and challenges/fault proofs against these proposals.</li>
<li>The Herodotus Data Processor retrieves and processes data from the ORU L1 contracts, including output root proposals and challenges/fault proofs.</li>
<li>The reputation-based light client contract uses the processed data from the Herodotus Data Processor to track sequencer reputation scores and store trusted output roots. A custom reputation calculation formula can be implemented, allowing for flexible and adaptable assessment of sequencer reliability based on various factors and weighting systems as deemed appropriate for the specific ORU implementation.</li>
<li>The light client interface allows other contracts to query the state root of the L2 chain based on the most reputable sequencer’s output roots.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#handling-successful-challenges-9" name="handling-successful-challenges-9"></a>Handling Successful Challenges</h2>
<p>In the event that any challenge against a sequencer is successful, the reputation of the sequencer would immediately reset to zero in the light client. This punitive measure ensures that only sequencers with an impeccable track record maintain trusted status.</p>
<p>With fault proof systems like those in OP Stack’s Bedrock, the Light Client contract would automatically reset a sequencer’s reputation to zero if a fault proof is successfully submitted and verified, showing an invalid output root proposed by that sequencer. This automated process ensures swift and consistent enforcement of the reputation system.</p>
<p>The permissionless output proposal mechanism provides an objective way to track sequencer reputation over time and identify potentially malicious outputs. Simultaneously, the output roots proposed by sequencers enable the verification of Storage Proofs against these proposed L2 state roots when using the Light Client. Ultimately, this approach creates a self-regulating system that not only incentivizes honest behavior but also ensures quick penalization of any attempts at fraud, thereby maintaining the overall reliability and security of the network.</p>
<h3><a class="anchor" href="https://ethresear.ch#fallback-mechanism-10" name="fallback-mechanism-10"></a>Fallback Mechanism</h3>
<p>In cases of unresolved conflicts or when the system detects any irregularities, it would automatically fall back to the conservative seven-day dispute period. This would ensure that the system remains secure and trustworthy, even in the face of unexpected challenges or disagreements among reputable sequencers.</p>
<h2><a class="anchor" href="https://ethresear.ch#potential-impact-and-future-directions-11" name="potential-impact-and-future-directions-11"></a>Potential Impact and Future Directions</h2>
<p>We believe that this reputation-based light client framework has the potential to significantly decrease duration to finality for ORUs. By reducing finality times while maintaining security, it could substantially improve the user experience and enable new use cases in L2 ecosystems.</p>
<p>As we continue to explore and refine this concept, we welcome input from the community. The next steps would involve further theoretical analysis, simulations, and potentially, prototype implementations.</p>
<h1><a class="anchor" href="https://ethresear.ch#references-12" name="references-12"></a>References</h1>
<p>Optimism Bedrock Documentation: <a class="inline-onebox" href="https://community.optimism.io/docs/developers/bedrock" rel="noopener nofollow ugc">Bedrock Explainer | Optimism Docs</a></p>
<p>L2 Output Root Proposals Specification: <a class="inline-onebox" href="https://github.com/ethereum-optimism/optimism/blob/65ec61dde94ffa93342728d324fecf474d228e1f/specs/proposals.md" rel="noopener nofollow ugc">optimism/specs/proposals.md at 65ec61dde94ffa93342728d324fecf474d228e1f · ethereum-optimism/optimism · GitHub</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/reputation-centric-light-client-framework-for-optimistic-rollups/19988">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 22:01:41 +0000</pubDate>
</item>
<item>
<title>Protocol Asset: canonical tokenized asset with the most social consensus preference of protocol</title>
<link>https://ethresear.ch/t/protocol-asset-canonical-tokenized-asset-with-the-most-social-consensus-preference-of-protocol/19983</link>
<guid>https://ethresear.ch/t/protocol-asset-canonical-tokenized-asset-with-the-most-social-consensus-preference-of-protocol/19983</guid>
<content:encoded><![CDATA[
<div> 关键词：Protocol Asset、社交共识、兼容性、Tokenized、价值体现

总结:
Protocol Asset是一种新型概念，它代表了开放协议或社区标准中最受欢迎的社会共识首选的代币化资产。这类资产如ORDI（Ordinal协议的代表）和Pandora（ERC-404的代表），特点是被广泛接受、完全兼容其底层协议，并承载着该协议的价值。它们不仅是理论与实践的结合体，而且其价值和安全性依赖于社会共识，而非仅仅依赖区块链网络。社交层的共识确保了这些资产作为各自标准的权威象征。 <div>
<p>Idea initiated by <a href="https://x.com/0xozeth" rel="noopener nofollow ugc">0xOZ.eth</a>. Thanks <a href="https://twitter.com/mkkb2156" rel="noopener nofollow ugc">Makd</a> for discussion.</p>
<p>We introduced a new concept: Protocol Asset. Protocol Asset represents canonical tokenized asset with the most social consensus preference of open protocol or community standard.</p>
<p>For example, ORDI is the protocol asset of Ordinal protocol, and Pandora is the protocol asset of ERC-404.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-1" name="background-1"></a>Background</h2>
<p>The evolution of blockchain and crypto has led to the emergence of various standards and protocols, each designed to address specific challenges or enable new functionalities. Notable examples include the Ethereum Improvement Proposals (EIPs) and Ethereum Request for Comments (ERCs) standards, and Ordinal theory with its Inscription protocol.</p>
<p>Despite the establishment of these standards, identifying the materialized asset associated with an open standard remains challenging. For instance, even in the case of ERC standards, which often include a reference implementation, pinpointing a specific instance deployed based on this implementation is not straightforward.</p>
<h2><a class="anchor" href="https://ethresear.ch#concept-2" name="concept-2"></a>Concept</h2>
<p>A Protocol Asset represents a canonical tokenized asset that aligns with the most socially accepted preferences of an open protocol or community standard.</p>
<h3><a class="anchor" href="https://ethresear.ch#characteristics-of-protocol-assets-3" name="characteristics-of-protocol-assets-3"></a>Characteristics of Protocol Assets</h3>
<p>To qualify as a Protocol Asset, it must be:</p>
<ul>
<li><strong>Tokenized and Ownable</strong>: The asset should be a materialized token that can be owned.</li>
<li><strong>Fully Compatible</strong>: The asset must be entirely compatible with the underlying protocol and standard.</li>
<li><strong>Socially Favored</strong>: The asset should be canonically preferred from a social consensus perspective.</li>
</ul>
<p>Typically, the Protocol Asset is the first implementation or instance of the protocol or standard.</p>
<h3><a class="anchor" href="https://ethresear.ch#value-encapsulation-4" name="value-encapsulation-4"></a>Value Encapsulation</h3>
<p>Protocol Assets encapsulate the value inherent in the protocols and standards they represent. They serve as the tangible manifestation of the protocol’s principles, ensuring that the theoretical and practical aspects of the protocol are embodied in a specific, widely recognized asset.</p>
<h3><a class="anchor" href="https://ethresear.ch#social-consensus-and-security-5" name="social-consensus-and-security-5"></a>Social Consensus and Security</h3>
<p>It’s crucial to understand that the security and recognition of token standards, such as ERC-20, are fundamentally based on social consensus rather than being directly secured by the Ethereum network. As Dankrad Feist aptly pointed out, “You have been lied to about ERC-20s. They aren’t secured by Ethereum. It’s just social consensus; any ERC-20 community can just fork away.”</p>
<p>This highlights that the value and trust in these tokens derive from the community’s agreement and collective support. This social layer of consensus is what ultimately secures the token, making it the canonical representation of its respective protocol.</p>
<h2><a class="anchor" href="https://ethresear.ch#examples-6" name="examples-6"></a>Examples</h2>
<h3><a class="anchor" href="https://ethresear.ch#ordi-7" name="ordi-7"></a>ORDI</h3>
<p>ORDI is the Protocol Asset of the Ordinal protocol. It represents the canonical tokenized asset for this protocol, favored by social consensus and adhering to the standards set forth by the Ordinal protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#pandora-8" name="pandora-8"></a>Pandora</h3>
<p>Pandora serves as the Protocol Asset for ERC-404. As with ORDI, Pandora is the materialized token that aligns with the social consensus and standards of the ERC-404 protocol, representing its values and functionalities in a tangible form.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/protocol-asset-canonical-tokenized-asset-with-the-most-social-consensus-preference-of-protocol/19983">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 17:54:05 +0000</pubDate>
</item>
<item>
<title>Gossipsub Message Propagation Latency</title>
<link>https://ethresear.ch/t/gossipsub-message-propagation-latency/19982</link>
<guid>https://ethresear.ch/t/gossipsub-message-propagation-latency/19982</guid>
<content:encoded><![CDATA[
<div> 关键词：Gossipsub、Ethereum、Message propagation latency、Hermes、Lodestar

总结:
研究团队ProbeLab通过工具Hermes对Ethereum P2P网络中的Gossipsub消息传播延迟进行了调查，以确定哪些协议组件消耗了最大的网络带宽。结果显示，98%的消息能在4秒内送达，而Lodestar客户端的接收时间相对较慢，但可能与其特定实现有关。节点位置靠近网络核心的节点通常能更快接收消息，但过度地理集中可能会加剧这种差异。尽管如此，总体上各节点的表现符合4秒内的要求，显示出网络的稳定性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-and-tldr-1" name="summary-and-tldr-1"></a>Summary and TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io </a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the <a href="https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952">Ethereum Node Message Propagation Bandwidth Consumption</a>, in this post we investigate <strong>Gossipsub’s message propagation latency</strong>, i.e., how long it takes to have a message delivered to all nodes in the network. The target of the study is to identify the protocol components that consume the biggest share of network bandwidth. The study has been co-authored by <a class="mention" href="https://ethresear.ch/u/cortze">@cortze</a> and <a class="mention" href="https://ethresear.ch/u/yiannisbot">@yiannisbot</a>.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer.</a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions.</p>
<p><strong>Study Description:</strong> Message propagation and arrival times are sensitive metrics for blockchain networks. We assume that the message is going to arrive to each peer “as fast as possible”, but in some cases, just because the core of the network achieved fast message delivery time, doesn’t mean that  message propagation to the entire network was done in time.</p>
<p>In the particular case of Ethereum, with such strict message delivery deadlines, ensuring the messages arrive within a 4-second window is essential to reduce the probability of forks.</p>
<p>In this study, we will approximate the average message propagation latency throughout the whole network.</p>
<p><strong>TL;DR:</strong> Despite a relatively short dataset of 3 days, we could observe with high confidence that:</p>
<ul>
<li>98% of messages arrive prior to the 4-second mark.</li>
<li>Lodestar seems to be the slowest client in terms of message arrival time, although this could also be related to when the arrivals are traced in the particular implementation.</li>
<li>Nodes located in or near the core of the network (<a href="https://probelab.io/ethereum/discv5/2024-25/#geolocation" rel="noopener nofollow ugc">NA or EU</a>) do have certain advantages when it comes to receiving messages sooner. Although the traced locations do not show any worrying behaviour, it is worth pointing out that extra geographical centralization could exacerbate the differences even further.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#results-2" name="results-2"></a>Results</h1>
<p>The results in this report have been gathered from EF’s Xatu public datasets. We’ve fetched 3 days’ worth of data from the <code>beacon_api_eth_v2_beacon_block</code> table (from the 14th to the 16th of June).</p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-cdf-times-within-the-slot-3" name="arrival-cdf-times-within-the-slot-3"></a>Arrival CDF times within the slot</h2>
<p>The study starts by calculating the arrival time of all the blocks within the slot that they belong to. The calculation is done based on the slot number and the time since genesis, given that each slot lasts 12 seconds:</p>
<pre><code class="lang-go">time_within_slot = arrival_time - (genesis_time + (slot * 12))
</code></pre>
<p>This measurement is crucial, as any block arrival beyond the 4 second mark is likely to generate a fork in some part of the network (as it can start receiving attestations of a non-proposed block).</p>
<p>In this first graph, we observe that 98% of the blocks arrived within the 4-second mark, leaving only the remaining 2% of blocks exceeding it.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/8/d8861bec5a5ad5613b752e126153afffcd236c23.png" title="CDF-propagation-latency"><img alt="CDF-propagation-latency" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/d/8/d8861bec5a5ad5613b752e126153afffcd236c23_2_517x309.png" width="517" /></a></div><p></p>
<p>The data was originated from the sentry nodes that are under the control of the Ethereum Foundation. These nodes include all the main client implementations in each of the locations, as shown in the following table:</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Continent</th>
<th>Country</th>
<th>Client</th>
</tr>
</thead>
<tbody>
<tr>
<td>EU</td>
<td>FI</td>
<td>lighthouse</td>
</tr>
<tr>
<td></td>
<td></td>
<td>lodestar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nimbus</td>
</tr>
<tr>
<td></td>
<td></td>
<td>prysm</td>
</tr>
<tr>
<td></td>
<td></td>
<td>teku</td>
</tr>
<tr>
<td>NA</td>
<td>US</td>
<td>lighthouse</td>
</tr>
<tr>
<td></td>
<td></td>
<td>lodestar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nimbus</td>
</tr>
<tr>
<td></td>
<td></td>
<td>prysm</td>
</tr>
<tr>
<td></td>
<td></td>
<td>teku</td>
</tr>
<tr>
<td>OC</td>
<td>AU</td>
<td>lighthouse</td>
</tr>
<tr>
<td></td>
<td></td>
<td>lodestar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nimbus</td>
</tr>
<tr>
<td></td>
<td></td>
<td>prysm</td>
</tr>
<tr>
<td></td>
<td></td>
<td>teku</td>
</tr>
</tbody>
</table>
</div><p>When comparing the arrival times over the different sentry nodes (figure below), we do see slight differences between them. The exception of <code>Lodestar</code> catches our attention, as it has a less uniform tail in its distribution. However, the rest of the clients follow a similar trend, with 99% of messages arriving within the first 4 seconds.</p>
<p>Since this data has been collected from the standard <a href="https://ethereum.github.io/beacon-APIs/#/Events/eventstream" rel="noopener nofollow ugc">event streamer Beacon API</a>, it is hard to explain the differences within each of the client implementations, as not only the libp2p codebase is written in different languages, but the message arrivals could also be timestamped at different moments of the message validation logic.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/0/60a95219771e0ec9bdc64265b87b0054bc877b83.png" title="gossipsub_arrival_times_within_slot_by_agent_on_mainnet_beacon_block"><img alt="gossipsub_arrival_times_within_slot_by_agent_on_mainnet_beacon_block" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/6/0/60a95219771e0ec9bdc64265b87b0054bc877b83_2_517x309.png" width="517" /></a></div><p></p>
<p>We were expecting to see different arrival times from different geographic locations, as the network geographical distribution seems to be concentrated within European and North American countries (<a href="https://probelab.io/ethereum/discv5/2024-24/#geolocation" rel="noopener nofollow ugc">link to the distribution</a>). The following graphs show that although there are indeed differences between countries or continents, they are minimal, with all the CDF distributions showing 98-99% of the block arrivals completing within the 4-second mark.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bec7e4974200c56b0e35fe8e118e90b97ea4b873.png" title="gossipsub_arrival_times_within_slot_on_by_country_mainnet_beacon_block"><img alt="gossipsub_arrival_times_within_slot_on_by_country_mainnet_beacon_block" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bec7e4974200c56b0e35fe8e118e90b97ea4b873_2_517x309.png" width="517" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/d/bdd5349b57b1f35d0484f1d82e09c9bea1c358fe.png" title="gossipsub_arrival_times_within_slot_on_by_continent_mainnet_beacon_block"><img alt="gossipsub_arrival_times_within_slot_on_by_continent_mainnet_beacon_block" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/d/bdd5349b57b1f35d0484f1d82e09c9bea1c358fe_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-times-4" name="arrival-times-4"></a>Arrival times</h2>
<p>The previous CDFs show that almost all the block arrivals happen within the expected time range. However, the plots do not reveal outliers, as CDFs are not sensitive to sudden network perturbations.</p>
<p>Thus, the following graphs show the <code>maximum</code>, <code>median</code>, <code>mean</code>, and <code>minimum</code> block arrival times on time windows of 4 epochs (1536 seconds).</p>
<p>We do not find large variations in the <code>minimum</code>, <code>mean</code> and the <code>median</code> distributions over the 3 day period. However, we do see that the maximum arrival time does vary quite significantly. We can observe that arrival times vary from 4 seconds to almost 12 seconds, almost exceeding the entire slot duration.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/2/92b9349d287acecc0903a14950d4876f1df18370.png" title="msg-arrival-overall"><img alt="msg-arrival-overall" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/9/2/92b9349d287acecc0903a14950d4876f1df18370_2_517x309.png" width="517" /></a></div><p></p>
<p>Interestingly, there are differences when comparing the mean arrival times of the different client implementations. Lodestar seems to be the latest one receiving the messages in the mesh and presents quite a high variance, while Teku seems to be the one receiving the messages first, followed by Prysm.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/6/c65b77648c36d9692a84fa65efd21ac3043aadd9.png" title="msg-arrival-by-agent"><img alt="msg-arrival-by-agent" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/c/6/c65b77648c36d9692a84fa65efd21ac3043aadd9_2_517x309.png" width="517" /></a></div><p></p>
<p>A similar pattern is also observed for the arrival time distribution by continent. As we could anticipate, European nodes receive slightly sooner messages than the North American and the Oceania ones. Although the difference is not significant, 0.6 seconds still keeps the arrival within the safety margins. However, this still showcases that there are some latency incentives to locate nodes in regions with lower latency, or in other words, around the core of the network (which, however, will, in turn, lead to more geographic centralization).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/f/bf6284e07ea3c5f9c4473be8b629d95b514371ed.png" title="msg-arrival-by-continent"><img alt="msg-arrival-by-continent" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/f/bf6284e07ea3c5f9c4473be8b629d95b514371ed_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#correlation-between-arrival-times-and-size-of-the-messages-5" name="correlation-between-arrival-times-and-size-of-the-messages-5"></a>Correlation between arrival times and size of the messages</h2>
<p>When attempting to correlate our findings to ones described in the previous <a href="http://ethresear.ch">ethresear.ch</a> <a href="https://ethresear.ch/t/big-block-diffusion-and-organic-big-blocks-on-ethereum/17346">blog post</a> that investigated this issue in particular, we haven’t been able to see any major correlation between size and the arrival time of the blocks. Although the block size distribution achieved in three days isn’t fully representative, the following graph shows that most blocks stay within the 50KB to 150KB range with a similar arrival time of 1 to 3 seconds.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/9/0905bc564c76545c3e9fc2c983edcbc280925d47.png" title="msg-arrival-vs-size"><img alt="msg-arrival-vs-size" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/0/9/0905bc564c76545c3e9fc2c983edcbc280925d47_2_375x375.png" width="375" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-6" name="conclusions-and-takeaways-6"></a>Conclusions and Takeaways</h1>
<p>Despite a relatively short dataset of 3.5hrs, we could observe with high confidende that:</p>
<ul>
<li>98% of messages arrive prior to the 4-second mark.</li>
<li>Lodestar seems to be the slowest client in terms of message arrival time, although this could also be related to when the arrivals are traced in the particular implementation.</li>
<li>Nodes located in or near the core of the network (<a href="https://probelab.io/ethereum/discv5/2024-25/#geolocation" rel="noopener nofollow ugc">NA or EU</a>) do have certain advantages when it comes to receiving messages sooner. Although the traced locations do not show any worrying behaviour, it is worth pointing out that extra geographical centralization could exacerbate the differences even further.</li>
</ul>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/gossipsub-message-propagation-latency/19982">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 14:03:33 +0000</pubDate>
</item>
<item>
<title>EVM in Motoko for Trustless Execution Environments</title>
<link>https://ethresear.ch/t/evm-in-motoko-for-trustless-execution-environments/19981</link>
<guid>https://ethresear.ch/t/evm-in-motoko-for-trustless-execution-environments/19981</guid>
<content:encoded><![CDATA[
<div> 关键词：Motoko、Internet Computer (IC)、EVM实现、教育目标、微EVMs

总结:<br />
文章介绍了作者管理的组织正在资助一个在Motoko中构建的EVM，目标是运行在Internet Computer上，未来可能扩展到AO领域。项目已通过GG19和GG20资金支持，主要目的是实现无信任执行和共识代理。目前完成了第一个里程碑——算术函数，寻求经验丰富的开发人员提供反馈和优化建议。这个项目还有助于教育，提供EVM工作原理的学习资源，并作为其他链上智能合约的微EVM基础，支持跨链交互。开发者正在GitHub上开源项目文件和测试代码，以促进改进和集成。 <div>
<p>Hello ethResearch <img alt=":wave:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wave.png?v=12" title=":wave:" width="20" /> it has been a while since I posted. Thanks for your patience as I wade back into the eth universe.</p>
<p>An organization that I’m running called <a href="https://icdevs.org" rel="noopener nofollow ugc">https://icdevs.org</a> is funding an evm built in Motoko that is targeted to run on the Internet Computer(and that we think will slide well into the AO universe as well). We should have started this 3 years ago, but there is no time like the present. To date this work has been funded through <span class="hashtag-raw">#GG19</span> and <span class="hashtag-raw">#GG20</span>. The eventuality of this project is trustless execution and consensus agents and the ability to monitor and relay messages between EVMs(and other chains) in a trustless manner.</p>
<p>The bounty has reached its first milestone and we’re looking for experienced EVM implementors to tell us what we’ve missed and how to make it better. I realize this forum seems to have moved on to bigger and harder scaling challenges, but I’m hoping you all can point me in the right direction to find the right audience. It is a bit too technical for r/ethereum but may be too basic for this forum and not quite an EIP.</p>
<p>Why we are looking to build out an EVM execution layer for the Intenet computer(from our thread at <a class="inline-onebox" href="https://forum.dfinity.org/t/open-icdevs-org-bounty-63-evm-opcodes-motoko-1-9-cketh/27592?u=skilesare" rel="noopener nofollow ugc">Open - ICDevs.org Bounty #63 - EVM OpCodes - Motoko - 1.9 ckETH - Bounties - Internet Computer Developer Forum</a> )</p>
<ol>
<li>The obvious - we can’t build an EVM in motoko without the op-codes. Now building an evm in motoko isn’t particularly a priority at the moment, but long term the Ethereum Foundation has made it a priority to have EVMs in as many languages as possible as a security feature. Would it make sense to have IC canisters as evm nodes for other chains? Probably depends on network config and a few other things, but I could certainly see it being of value long term. Having the op-codes defined separates the execution concerns from any future project that might want to wire up the rest of the EVM machinery. From building from the ground up you get an EVM that takes the IC’s compute pattern and restrictions into account in ways that existing EVMs written in other languages would need significant rewrites to support.</li>
<li>General education - These opcodes are an awesome way to learn about stacks, memories, and crypto primitives. Education is the primary goal of <a href="http://icdevs.org/" rel="noopener nofollow ugc">ICDevs.org </a> and we feel like Motoko versions of these libraries would make a really interesting set of examples for people learning about how EVMs work, why they work, and what concepts mirror over into the IC(and which ones don’t).</li>
<li>Libraries and Integrations - these libraries build on top of a number of other Bounties that we’ve funded that could use some burn-in and integration testing to improve them and make sure they are working properly. <a href="https://github.com/f0i/merkle-patricia-trie.mo" rel="noopener nofollow ugc">GitHub - f0i/merkle-patricia-trie.mo: A Merkle Patricia Trie implementation in Motoko </a> <a href="https://github.com/relaxed04/rlp-motoko" rel="noopener nofollow ugc">GitHub - relaxed04/rlp-motoko: RLP implementation on motoko</a>. In addition, some of the op codes implement core functionality that we’ll need to do cross-chain like ecrecover which would be important for a motoko canister trying to verify a signature from the evm universe.</li>
<li>Micro EVMs - In one universe bitfinity EVMs proliferate and we end up with a garden of highly specialized evms on the IC that interact and interoperate in unique ways. These libraries would allow you to pull in the memory, storage, etc from those EVMs and run transaction simulations to check for opportunities or to automate actions against them using things like the event logs. The always-on nature of IC canisters makes them ideal for writing bots/agents that seek opportunities and execute on them by signing tecdsa messages and relaying them.</li>
</ol>
<p>Our bounty hunter has completed the first milestone, arithmetic functions.</p>
<p>project file:</p><aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="32" src="https://ethresear.ch/uploads/default/original/2X/b/bad3e5f9ad67c1ddf145107ce7032ac1d7b22563.svg" width="32" />

      <a href="https://github.com/icdevsorg/evm.mo" rel="noopener nofollow ugc" target="_blank">GitHub</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image"><img class="thumbnail" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/5/4/546c435f8f13ad709696b772052a5b091237e94b_2_690x345.png" width="690" /></div>

<h3><a href="https://github.com/icdevsorg/evm.mo" rel="noopener nofollow ugc" target="_blank">GitHub - icdevsorg/evm.mo: EVM Based Libraries for Motoko</a></h3>

  <p>EVM Based Libraries for Motoko. Contribute to icdevsorg/evm.mo development by creating an account on GitHub.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

<p>main code file:</p><aside class="onebox githubblob">
  <header class="source">

      <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <h4><a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo" rel="noopener nofollow ugc" target="_blank">icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo</a></h4>


      <pre><code class="lang-mo">import Array "mo:base/Array";
import Nat "mo:base/Nat";
import Nat8 "mo:base/Nat8";
import Nat64 "mo:base/Nat64";
import Int "mo:base/Int";
import Trie "mo:base/Trie";
import Iter "mo:base/Iter";
import Debug "mo:base/Debug";
import Vec "mo:vector"; // see https://github.com/research-ag/vector
import Map "mo:map/Map"; // see https://mops.one/map
import EVMStack "evmStack";
import T "types";

module {
  
  type Result&lt;Ok, Err&gt; = { #ok: Ok; #err: Err};
  type Engine = [(T.ExecutionContext, T.ExecutionVariables) -&gt; Result&lt;T.ExecutionVariables, Text&gt;];
  type Vec&lt;X&gt; = Vec.Vector&lt;X&gt;;
  type Map&lt;K, V&gt; = Map.Map&lt;K, V&gt;;
  type Trie&lt;K, V&gt; = Trie.Trie&lt;K, V&gt;;
</code></pre>



  This file has been truncated. <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo" rel="noopener nofollow ugc" target="_blank">show original</a>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

<p>tests:</p><aside class="onebox githubblob">
  <header class="source">

      <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <h4><a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo" rel="noopener nofollow ugc" target="_blank">icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo</a></h4>


      <pre><code class="lang-mo">import { test; skip } "mo:test/async"; // see https://mops.one/test

import { stateTransition } "../src/evm_mo_backend/main";

import Array "mo:base/Array";
import Nat "mo:base/Nat";
import Nat8 "mo:base/Nat8";
import Nat64 "mo:base/Nat64";
import Int "mo:base/Int";
import Trie "mo:base/Trie";
import Debug "mo:base/Debug";
import Vec "mo:vector";
import Map "mo:map/Map";
import EVMStack "../src/evm_mo_backend/evmStack";
import T "../src/evm_mo_backend/types";

let dummyTransaction: T.Transaction = {
    caller = "\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa";
    nonce = 2;
    gasPriceTx = 5;
</code></pre>



  This file has been truncated. <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo" rel="noopener nofollow ugc" target="_blank">show original</a>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/evm-in-motoko-for-trustless-execution-environments/19981">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 13:37:42 +0000</pubDate>
</item>
<item>
<title>Preconfirmations under the NO lens</title>
<link>https://ethresear.ch/t/preconfirmations-under-the-no-lens/19975</link>
<guid>https://ethresear.ch/t/preconfirmations-under-the-no-lens/19975</guid>
<content:encoded><![CDATA[
<p>by <a href="https://twitter.com/umb_nat" rel="noopener nofollow ugc">U. Natale</a>.</p>
<p><strong>Acknowledgements</strong><br />
This research has been granted by <a href="https://chorus.one/" rel="noopener nofollow ugc">Chorus One</a>. We are grateful to <a href="https://twitter.com/plc_hld" rel="noopener nofollow ugc">M. Moser</a>, <a href="https://x.com/crainbf" rel="noopener nofollow ugc">B. Crain</a>, and <a href="https://x.com/Yannimoto" rel="noopener nofollow ugc">Y. Socolov</a> for useful discussions and comments. We also thanks <a href="https://x.com/mempirate" rel="noopener nofollow ugc">J. Bostoen</a> and <a href="https://x.com/fra_mosterts" rel="noopener nofollow ugc">F. Mosterts</a> from <a href="https://x.com/chainbound_" rel="noopener nofollow ugc">Chainbound</a> team for reviewing the entire document (review ≠ endorsement).</p>
<h1><a class="anchor" href="https://ethresear.ch#preconfirmations-landscape-1" name="preconfirmations-landscape-1"></a>Preconfirmations landscape</h1>
<p>In the context of PBS, bargaining between proposer and relay start at around 1s. This means that users submitting transactions after 1s have to wait for the next slot to know if the transaction is included or not. Even in the context of timing games and assuming some aggressive player, there is a hard cut-off at &lt; 4s due to attestation deadline.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/b/8b20ed4fa8795f4a096dc0d24d975d1b02f78d72.png" title="Screenshot 2024-06-21 alle 11.35.54"><img alt="Screenshot 2024-06-21 alle 11.35.54" height="255" src="https://ethresear.ch/uploads/default/optimized/3X/8/b/8b20ed4fa8795f4a096dc0d24d975d1b02f78d72_2_690x255.png" width="690" /></a></div><br />
<strong>Fig. 1:</strong> The current setup under PBS.<p></p>
<p>With preconfirmation, users have the possibility to access the dead time space between two blocks via a <a href="https://mirror.xyz/preconf.eth/sgcuSbd1jgaRXj9odSJW-_OlWIg6jcDREw1hUJnXtgI" rel="noopener nofollow ugc">credible heads-up before a confirmation happens</a>. However, at the moment, preconfirmations give no guarantees on execution.</p>
<p>For example, imagine 2 users submit 2 conflicting transactions (e.g. a swap against the same pool), but both get a preconfirmation. What happens in slot N+1 is that both transactions land in some place into the slot, but one of the two fails.</p>
<p>From the provider of preconfirmations perspective, the original agreement was respected, however one of the two users next time will think twice before paying for a preconfirmation. The same scenario can happen even if there is only one preconf, but this transaction lands in some place into the slot after other conflicting transactions.</p>
<p>This poses some questions on who can preconfirm a transaction and who can’t. From the two example above it is evident that unsophisticated players can’t play this game and provide a real improvement for the Ethereum ecosystem. It is clear that the burden would be reduced if the preconfs were intended only for transactions that do not touch contentious state — e.g. transfers of tokens and NFTs, dApps with “batching” architecture, L2 settlements, etc. In this case no sophistication is needed so we will exclude it from the goal of this analysis.</p>
<h1><a class="anchor" href="https://ethresear.ch#proposer-as-preconf-provider-2" name="proposer-as-preconf-provider-2"></a>Proposer as preconf provider</h1>
<p>Preconfirmations should be managed in a manner which is similarly decentralized to the current PBS setup; they should not give rise to a centralization bottleneck that exceeds the current builder dominance.</p>
<p>Fundamentally, the PBS transaction pipeline is an auction. Preconfirmations under a gateway architecture follow a delegation scheme, where node operators (NOs) select a third party to select transactions for future inclusion. Therefore, the gateway design is not a spot market, and a generally less competitive scheme as the cost of switching is considerably higher. Indeed, the gateway architecture expects each validator to sign an on-chain transaction to deposit collateral, meanwhile this operation under PBS is done completely off-chain, meaning that there is no cost to switching builders.</p>
<p>This may directly reflect in multi-block MEV, where gateways will be able to provide increasingly more competitive partnership offers to node operators as they scale their dominance over the network. In difference to PBS builders, these gateways will have certainty over the slots for which they hold a mandate. Therefore, a gateway architecture is likely to manifest as a heavily centralized setup, where multi-block MEV is the central return to scale, and switching costs are high. Overall, as it is not an auction or a spot market, the gateway architecture is more likely to manifest a centralization bottleneck which exceeds PBS builder dominance.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/9/193ec08347bb058b66d9b5ead9de72df69a1636d.png" title="stake penetration vs slots in a row"><img alt="stake penetration vs slots in a row" height="421" src="https://ethresear.ch/uploads/default/optimized/3X/1/9/193ec08347bb058b66d9b5ead9de72df69a1636d_2_690x421.png" width="690" /></a></div><br />
<strong>Fig. 2:</strong> Rate of N slots in a row over total Ethereum slots in a year as a function of stake penetration. Growth is higher than linear, and the case of builders/gateways dominance in block production is just an extension of above.<p></p>
<p>A preferable scheme would be the proposer selecting preconfirmations itself. Even in the case of the largest proposers, their ability to engage in multi-block MEV is capped by their voting power (see Fig. 2), which is in turn is capped by the proposer market (i.e. access to capital). Even under PBS, proposers could theoretically already engage in multi-block MEV, but refrain to do so, for a variety of reasons ranging from access to capital and organisational setup, to legal liability. These same patterns would likely extend to a preconfirmation setup.</p>
<p>In this section we are going to analyze some scenarios that may arise if the proposer of the slot is the one providing preconfirmation for transactions. We further assume that the NO is a sophisticated player, since the more transactions an unsophisticated preconfirmations provider includes in the preconfirmation list, the more difficult it is for block builders to create a block with all transactions being successful. This implies an execution guarantee on preconfirmed transactions.</p>
<p>If the majority of preconfirmed transactions fail, the market becomes less attractive, making preconfirmations a difficult tool to use. Including conflicting transactions can also damage the NOs credibility, negatively impacting the brand.</p>
<h2><a class="anchor" href="https://ethresear.ch#information-edge-from-private-order-flow-3" name="information-edge-from-private-order-flow-3"></a>Information edge from private order flow</h2>
<p>In this section we are going to show the different information edge builders have in the current PBS framework. As we did in <a href="https://arxiv.org/pdf/2312.09654" rel="noopener nofollow ugc">The cost of artificial latency in the PBS context</a>, we can define a standardized parameter that allows for a comparison of bids irrespective of their absolute size. This corresponds to the ratio between a given bid and the maximum bid in the auction for a particular slot. That is</p>
<div class="math">
\begin{equation}
R = \frac{b_s(t_E)}{\textrm{max}_{t_E}b_S(t)}\,,\qquad(1)
\end{equation}
</div>
<p>where <span class="math">b</span> is the bid value, <span class="math">s</span> indicate the corresponding slot, and <span class="math">t_E</span> is the time at which the bid was made eligible. This allows us to compare builders bidding strategy over all slot proposed by Chorus One since 2024-03-13.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e83b3b463951c5f72911dad23a05e70b9868c23c.png" title="Builders edge on private order flow"><img alt="Builders edge on private order flow" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e83b3b463951c5f72911dad23a05e70b9868c23c_2_690x345.png" width="690" /></a></div><br />
<strong>Fig. 3:</strong> Builder bidding strategy standardized over all slots proposed by Chorus One since 2024-03-13.<p></p>
<p>If we select 6 of the top builders by entity (according to <a href="https://mevboost.pics/" rel="noopener nofollow ugc">mevboost.pic</a>), we can clearly see a difference in the overall strategy, see Fig. 3. For example, we can see how some builders start to deliver bids “late” into the slot, others seems to start much earlier. Furthermore, some builders have a clear linear trend in bid increase per unit of time, others seems to start being careful near the end of the auction.</p>
<p>Although this is independent from the information edge coming from private order flow, we can see how different builders propagates different values of <span class="math">R</span>. Precisely, at 1s into the slot (that is the median value for bid selection in current PBS framework) we have</p>
<ul>
<li><strong>Builder:</strong> 0xb211df4…, <strong>Median:</strong> 0.91, <strong>0.25-quantile:</strong> 0.83, <strong>0.95-quantile:</strong> 0.99</li>
<li><strong>Builder:</strong> 0x83d3495…, <strong>Median:</strong> 0.86, <strong>0.25-quantile:</strong> 0.75, <strong>0.95-quantile:</strong> 0.97</li>
<li><strong>Builder:</strong> 0xa32aadb…, <strong>Median:</strong> 0.90, <strong>0.25-quantile:</strong> 0.83, <strong>0.95-quantile:</strong> 0.98</li>
<li><strong>Builder:</strong> 0xa03a000…, <strong>Median:</strong> 0.81, <strong>0.25-quantile:</strong> 0.74, <strong>0.95-quantile:</strong> 0.95</li>
<li><strong>Builder:</strong> 0xa91d3e5…, <strong>Median:</strong> 0.79, <strong>0.25-quantile:</strong> 0.65, <strong>0.95-quantile:</strong> 0.93</li>
<li><strong>Builder:</strong> 0xb783f81…, <strong>Median:</strong> 0.88, <strong>0.25-quantile:</strong> 0.82, <strong>0.95-quantile:</strong> 0.96</li>
</ul>
<p>that indicates how different entities arrive to the most-likely-end of the auction with less/higher bid values.</p>
<p>From the NO perspective, a difference in information edge could lead to a mispricing of MEV txs, thus increasing the risk of producing less valuable blocks. In general, builders in the current MEV-Boost framework have a comprehensive view of all transactions and typically include those that maximize the block value. However, with validators as preconfirmation providers, proposers must select transactions in advance, often without knowledge of transactions occurring on private channels. The primary metric available to validators in this scenario is the base fee. Specifically, if a transaction pays the base fee (BF) plus a priority fee (PF), it is considered valid in principle. But if the priority fee is the lowest compared to transactions in the private order flow from builders, the block value could decrease. This is because builders are now required to include the preconfirmed transaction instead of a potentially more valuable one. Here sophisticated NOs are in advance since they can develop models to probabilistically evaluate transactions and perform an opinionated selection.</p>
<p>It is worth noting, that validators with private transaction flows could be incompatible with preconfirmations, depending on implementation. Private transaction flows can also manifest by virtue of network jitter. Indeed, if a proposer gives a preconfirmation on a transaction from private transaction flow (or on a transaction from an RPC that’s close to the proposer, but far away from the builder), there could be a non-zero likelihood this transaction is not known by the builders, which may find it difficult to build a valid block (i.e. with the preconfirmed tx). The solution is that the proposer <a href="https://chainbound.github.io/bolt-docs/api/builder-api" rel="noopener nofollow ugc">sends the full transaction to builders</a>. Concerns about privacy are clearly excluded since the proposer already committed to certain execution, and the builder can’t really do anything about that.</p>
<h2><a class="anchor" href="https://ethresear.ch#enforced-early-timing-games-4" name="enforced-early-timing-games-4"></a>Enforced early timing-games</h2>
<p>Arbitrageurs often engage in short-term trading due to competitive pressures. When they opt to delay immediate gains in hopes of capturing a greater mispricing, they run the risk of losing the lucrative opportunity to other traders. This issue is particularly critical within Ethereum’s Proposer-Builder Separation (PBS) mechanism, where searchers must strategically balance their bidding approaches.</p>
<p>Consider an arbitrage opportunity that arises relative to an external source, such as a centralized exchange (CEX), at t=4 seconds into slot N. Since the on-chain price is stale and searchers are uncertain whether the opportunity will vanish on the CEX side, they may prefer to execute the first leg of the trade on the CEX immediately and wait the canonical 12 seconds to see their transaction confirmed on-chain. In the PBS context, however, if a searcher immediately bids their maximum willingness to pay for the opportunity, there is a non-zero likelihood that other searchers may outbid them, effectively frontrunning the original strategy. Conversely, if the searcher bids aggressively too late, the closing trade may fail to be included on-chain since the proposer has already committed to a block that excludes this particular transaction. This scenario creates an auction dynamic that hinges on accurately pricing the time within the slot. The same applies for a DEX &lt;&gt; DEX opportunity, since other arbitrageurs may offer a higher share of MEV for the same opportunity and then seeing their bundle being selected.</p>
<p>Therefore, searchers must strategize not only about how much to bid, but also about the optimal timing of their bids. Bidding too early or too late can both result in a loss of the arbitrage opportunity. The delicate balance between these factors is crucial for optimizing their strategies in such competitive and time-sensitive environments. This study models this behavior and evaluates various strategies to understand the optimal bidding dynamics in Ethereum’s PBS framework.</p>
<h3><a class="anchor" href="https://ethresear.ch#model-description-5" name="model-description-5"></a>Model Description</h3>
<p>To investigate how the introduction of preconfirmations might influence the auction dynamics in PBS, we conducted simulations using an Agent-Based Modeling (ABM) framework. The model is designed to simulate the behavior of searchers participating in PBS auctions under varying conditions, incorporating elements of competitive bidding and strategic timing. In our model, we assume that searchers at step N are aware of the bids at step N-1. While this might seem at odds with the usual dynamics in MEV-Boost, where the auction is not publicly visible, we can reconcile this assumption with two scenarios:</p>
<ol>
<li><strong>Historical Data Adjustment</strong>: Searchers adjust their bidding strategies based on the share of MEV extracted as a function of past data. In this scenario, at each step N, searchers are informed about the behavior of searchers at the corresponding step N-1 from the previous slot. Thus, the predictive model is grounded in the historical data of past auctions.</li>
<li><strong>Vertically Integrated Builders</strong>: In this scenario, searchers are considered as vertically integrated builders. Here, we can imagine a block as a composition of transactions that produce a certain value for the MEV, with the bidding phase representing the exact competition between builders.</li>
</ol>
<p>By incorporating these scenarios, our model aims to provide a simplistic but comprehensive understanding of how searchers might operate within the PBS auction mechanism under the influence of preconfirmations.</p>
<h3><a class="anchor" href="https://ethresear.ch#searchers-behaviour-6" name="searchers-behaviour-6"></a>Searchers behaviour</h3>
<p>In the model, each agent represents a searcher with a specific profit margin, aggressivity parameter, and fear-of-missing-out (FOMO) factor. These agents operate in a simulated environment that mimics the Ethereum PBS auction mechanism. Each agent’s decision-making process is influenced by the bids placed in previous auction steps, representing the competitive nature of the environment.</p>
<p>Agents update their bids in each step based on a combination of their internal parameters and the observed bids from the previous step. The bid update process is governed by a logistic growth model, where the increment of the bid follows a logistic function, adjusted by the agent’s aggressivity parameter and FOMO factor. This approach ensures that agents increase their bids more cautiously in the early stages and more rapidly as the auction progresses, reflecting the strategic balance between the risk of being outbid and the urgency of capturing the arbitrage opportunity. This dynamic allows the agents to optimize their bidding strategies over time, aiming to reach the maximum bid value closer to the end of the auction period.</p>
<p>Additionally, agents take into account the probability that the auction may terminate at any given step. This probability is derived from a fictitious empirical distribution of auction durations, modelled using a truncated normal distribution to generate realistic auction durations, cfr. Fig. 4. In case of preconfirmation, we add a half-normal distribution to the previous one, cfr. Fig. 5. The termination probability influences the agents’ urgency in placing bids, as they must balance the risk of the auction ending unexpectedly with the potential benefits of waiting for a more opportune moment to bid. This probabilistic approach ensures that agents are not only competing against each other but also managing the inherent uncertainty of the auction’s duration.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/6/06e7143081bbd056f94a6b8f8e3873b675a2a89f.png" title="Auction Time - no preconf - PDF &amp; CDF"><img alt="Auction Time - no preconf - PDF &amp; CDF" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/0/6/06e7143081bbd056f94a6b8f8e3873b675a2a89f_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 4:</strong> Single instances of a fictitious empirical distribution for the transaction selection time into the auction in the absence of preconfirmations.<p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/3/d3d2b8c36e3810f0175271e67a2b49d9804afd44.png" title="Auction Time - preconf - PDF &amp; CDF"><img alt="Auction Time - preconf - PDF &amp; CDF" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/d/3/d3d2b8c36e3810f0175271e67a2b49d9804afd44_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 5:</strong> Single instances of a fictitious empirical distribution for the transaction selection time into the auction in the presence of preconfirmations.<p></p>
<p>The model incorporates four different types of searchers, each using a different predictive model to estimate the bid for the next step before applying their respective increment:</p>
<ol>
<li><strong>Predictive Model 1</strong>: This model predicts the next bid as simply the maximum bid observed so far. It assumes that the current trend will continue without significant changes.</li>
<li><strong>Predictive Model 2</strong>: This model uses a linear regression based on the bid history to predict the next bid. It fits a linear model to the previous bids and uses the resulting slope and intercept to estimate the next bid. This approach assumes that the bid growth can be approximated by a linear trend.</li>
<li><strong>Predictive Model 3</strong>: This model calculates the average increment of the bids from previous steps and adds this average increment to the current maximum bid. This model assumes that past increments provide a good estimate for future increases.</li>
<li><strong>Predictive Model 4</strong>: This model uses a logarithmic fit based on the bid history to predict the next bid. It fits a logarithmic model to the previous bids and uses the resulting parameters to estimate the next bid. This approach assumes that the bid growth follows a decelerating trend, reflecting a more conservative strategy as the auction progresses.</li>
</ol>
<p>By incorporating these diverse predictive models, the simulation captures a wide range of bidding behaviors and strategies, providing a more comprehensive understanding of how different types of searchers might operate within the Ethereum PBS auction mechanism.</p>
<h3><a class="anchor" href="https://ethresear.ch#results-7" name="results-7"></a>Results</h3>
<p>Analyzing the results in Fig. 6, we observe that in scenarios where preconfirmations on transactions are possible, searchers begin to increase their share of captured MEV earlier. This suggests that to increase MEV share received, a node operator might opt to run the version that allows for preconfirmations but never actually selects any MEV transactions. This creates a situation where searchers bid higher because the auction might end sooner. However, since no preconfirmations are offered (as the validator does not select any), the auction continues, and searchers find themselves starting from a higher base bid.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/b/5be75738445af00fdf93f6b1e455b905c46a23c2.png" title="Auction war - combined"><img alt="Auction war - combined" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/5/b/5be75738445af00fdf93f6b1e455b905c46a23c2_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 6:</strong> Distribution of different bidding strategy extracted from a set of simulation using the ABM described in previous section. Simulations including a preconfirmation phase are in red, simulations without a preconfirmation phase are in blue.<p></p>
<p>This situation can be likened to a modified version of the prisoner’s dilemma. In this strategic game, each searcher (or prisoner) must decide whether to bid aggressively early (cooperate) or wait for a more opportune moment (defect). If all searchers bid aggressively early, they collectively drive up the MEV share and risk overbidding. Conversely, if they all wait, the auction proceeds normally, and they can potentially secure MEV shares at a lower cost. However, if some searchers bid aggressively while others wait, the aggressive bidders might secure a higher share early, pushing the late bidders to increase their bids even further as the auction continues.</p>
<p>This dynamic creates a tension between the searchers: each must decide whether to trust that others will not bid aggressively early or to secure their position by doing so themselves. The presence of preconfirmations adds an additional layer of complexity, as the threat of an early auction end prompts higher early bids, even when no actual preconfirmations are selected.</p>
<p>In summary, the introduction of preconfirmations influences searchers’ bidding behavior, leading to higher initial bids due to the perceived risk of an early auction end. This strategic interplay resembles the prisoner’s dilemma, where individual decisions to bid early or wait impact the collective outcome, highlighting the intricate balance between cooperation and competition in optimizing MEV shares.</p>
<p>In other words, with preconfirmations, searchers competing for the same opportunity can no longer rely on the probability that a certain builder will win a slot. If a competing searcher’s transaction is preconfirmed, even if the transaction is accepted by the winning builder, the builder must prioritize the preconfirmed one.</p>
<h2><a class="anchor" href="https://ethresear.ch#reversal-timing-game-8" name="reversal-timing-game-8"></a>Reversal timing-game</h2>
<p>Currently, the dynamics involve searchers relying on private auctions through builders, who have a certain probability of winning the block. Builders construct a block based on the privately received transactions and subsequently compete with other builders (through a public auction) to determine the winning block.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/8/d86ee43d92e0249f4368147a23f5f2f24a1560bf.png" title="latency_vs_ntxs"><img alt="latency_vs_ntxs" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/d/8/d86ee43d92e0249f4368147a23f5f2f24a1560bf_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 7:</strong> Dependency in current auction dynamic between number of transactions included in the block and bid value, source from <a href="https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847">The cost of artificial latency in the PBS context</a>.<p></p>
<p>Empirical data shows that the number of transactions included in blocks proposed by builders and the value of the block increase linearly, cfr. Fig 7 and [The cost of artificial latency in the PBS context](<a href="https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847**.">https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847**.</a>** This implies that once an arbitrage opportunity between CEX and DEX is identified, stat-arbitrageurs submit their transaction, which is not further modified, and the additional value builders obtain comes from a greater inclusion of transactions. In fact, searchers prefer to submit their transaction immediately as the opportunity might vanish on the CEX, and there is a form of preconfirmation due to the historical probability of a builder winning an auction. Therefore, it is highly likely that the rebalancing on the CEX occurs in the early stages of the block.</p>
<p>By modeling the price difference between CEX and DEX as a Markovian jump-diffusion process, we can derive the expression for the probability that searchers can execute a profitable trade (i.e. that the price difference is greater than the fees needed to execute the trade). This probability, <span class="math">P</span>,  is given by (see Appendix for a derivation):</p>
<div class="math">
\begin{equation}
P = \frac{1}{1+\frac{\sqrt{2\lambda}\gamma}{\sigma}}\,,\qquad(2)
\end{equation}
</div>
<p>where <span class="math">\gamma</span> represents the fee of the trade,  <span class="math">\lambda</span> is such that the time mean interval between trades is <span class="math">\bar{t} = \lambda^{-1}</span>, <span class="math">\sigma</span> is the volatility of the price difference.</p>
<p>Equation (2) allows us to define a new dynamic for stat-arbs under the preconfirmation framework. Indeed, when the time interval between trades is small (i.e. high values of <span class="math">\lambda</span>), the probability of having a profitable trade decrease. On the other hand, if volatility becomes predominant, the dynamic may change. Preconfirmations allows arbitrageurs to tune the time interval <span class="math">\lambda^{-1}</span> in order to maximize the probability of being in the trading regime on a volatility based strategy.<br />
Precisely, the time between trades is determined by the time at which the previous slot selected transactions and the time at which new transactions are selected for current block. With current PBS design this corresponds to 12s. Indeed, even if the builder knows he won the slot at t=4s into the slot N-1, he now has to wait 12s (i.e. 4s into the slot N) before knowing if he wins the slot N. With preconfirmations the frequency of transaction selections is a dynamic variable, because you know that your transaction is selected at different time wrt. the usual 4s into the slot. Clearly, by alternating preconfirmations with normal block inclusion, the parameter <span class="math">\lambda</span> is non-constant.</p>
<p>If now the objective is to minimize the ratio <span class="math">\sqrt{2\lambda}/\sigma</span>, if the volatility is low searchers can start to increase the frequency of trades submission (i.e. participate in preconfirmation auction) in order to maintain <span class="math">\sqrt{2\lambda}/\sigma &lt;&lt; 1</span>.</p>
<p>This modeling is consistent with the hypothesis that searchers may be interested in submit their transaction at the beginning of the block. This creates a dynamic potentially opposite to the timing games observed in the MEV-Boost context, where now searchers strive to compete from the early stages in the preconfirmation market.</p>
<h2><a class="anchor" href="https://ethresear.ch#capturing-on-chain-mev-9" name="capturing-on-chain-mev-9"></a>Capturing on-chain MEV</h2>
<p>With node operators as preconf provider, preconfirmations give validators the power back to decide on some transaction that have to be included in the slot. This means that NO can add new transactions on top of the current MEV-Boost pipeline, meaning that the ways of capturing MEV augment. Indeed, if we stay in the assumption that preconf transactions are likely to be executed as valid transactions, each time a validator is selected to propose a slot, it can preconf on his own transactions. This means that some types of on-chain MEV, in principle, can be captured by NO using preconfirmations, without renouncing to CEX &lt;&gt; DEX arbitrage, that might result more complicated for NOs.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/1/41859fc9aeca6897bb9ff6312cc64a64d9c2414a.png" title="Screenshot 2024-06-20 alle 12.13.39"><img alt="Screenshot 2024-06-20 alle 12.13.39" height="327" src="https://ethresear.ch/uploads/default/optimized/3X/4/1/41859fc9aeca6897bb9ff6312cc64a64d9c2414a_2_690x327.png" width="690" /></a></div><br />
<strong>Fig. 8:</strong> Daily extracted MEV in 30 days by profit. Source <a href="https://eigenphi.io/" rel="noopener nofollow ugc">EigenPhi</a>.<p></p>
<p>Given the importance on the order of transaction execution, only arbitrage and liquidation could be captured using preconfirmation. According to <a href="https://eigenphi.io/" rel="noopener nofollow ugc">EigenPhi</a>, arbitrages and liquidations produced revenue of $3M profit in 30 days. From the Top 12 leaderboard on arbitrageurs, we can see that only 66% of captured MEV is shared with builders. Clearly, also builders retain a portion of MEV, but due to lack of data, we exclude this from our calculation, which at the end will provide a lower bound on extra revenue a NO can make.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e5f6e65454a19f24711d87a2fac6c81cbf950962.png" title="Screenshot 2024-06-20 alle 12.13.52"><img alt="Screenshot 2024-06-20 alle 12.13.52" height="162" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e5f6e65454a19f24711d87a2fac6c81cbf950962_2_690x162.png" width="690" /></a></div><br />
<strong>Fig. 9:</strong> Leaderboard of top 12 on-chain arbitrageurs in 30 days. Source <a href="https://eigenphi.io/" rel="noopener nofollow ugc">EigenPhi</a>.<p></p>
<p>If we assume that a NO with 1% of stake penetration captures 1% of this extra MEV, there is an extra $345,600 in a year. Since the median MEV revenue for a NO with such share is ETH 392.31 (cfr. Fig.  10), assuming a price per ETH of $3,500 this (98.74 ETH extra MEV) corresponds to a 25.17% increase from MEV revenue in a year. It is worth mentioning that <a href="https://adagio.chorus.one/" rel="noopener nofollow ugc">current timing games provide ~10% extra MEV</a>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/8/a869e4823ee39f779a3b39c028ff5e4d784e2066.png" title="MEV yearly size - NO size 10000 over 1005387"><img alt="MEV yearly size - NO size 10000 over 1005387" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/a/8/a869e4823ee39f779a3b39c028ff5e4d784e2066_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 10:</strong> Probability Distribution Function of MEV proceeds in a year for a node operator with 1% of stake penetration.<p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-10" name="conclusions-10"></a>Conclusions</h1>
<p>Implementing a sophisticated system for preconfirmations within Ethereum’s PBS framework is far from trivial. This complexity opens new avenues for sophisticated NOs to enhance their revenues from MEV.</p>
<p>Our study has demonstrated that preconfirmations introduce a significant layer of strategic depth to the PBS auction mechanism. By providing searchers with a credible heads-up before a transaction is confirmed, preconfirmations alter the timing and aggressiveness of bids. This shift is particularly pronounced in scenarios where NOs, acting as preconfirmation providers, selectively include transactions that maximize their revenue while ensuring successful block proposals.</p>
<p>This analysis highlighted the varied strategies employed by different builders in the current PBS framework, revealing significant differences in how they time their bids. This information asymmetry can lead to mispricing of MEV transactions, potentially reducing the overall value of blocks for node operators.</p>
<p>The presence of preconfirmations forces searchers to engage in more sophisticated bidding strategies. They must carefully balance the risk of being outbid by competitors against the potential for an early auction termination, which could prevent their transactions from being included. This dynamic is akin to a modified prisoner’s dilemma, where searchers must decide between bidding aggressively early or waiting for a more opportune moment, knowing that their decisions impact the overall auction outcome. Overall, this may push for a new type of timing games, where now searchers will compete more aggressively in the first part of the preconfirmation interval.</p>
<p>Complex implementation of preconfirmations provide NOs with a powerful tool to capture on-chain MEV directly. By preconfirming their transactions, NOs can ensure the inclusion of high-value arbitrage and liquidation opportunities, significantly boosting their MEV revenue. Our calculations indicate that a NO with a 1% stake penetration could see a 25.17% increase in annual MEV revenue through strategic use of preconfirmations. This increase is substantial compared to the ~10% extra MEV derived from current timing games.</p>
<p>Despite the potential benefits, the implementation of preconfirmations must be carefully managed to avoid centralization risks. A decentralized approach, where proposers themselves manage preconfirmations, is preferable to a gateway architecture that could lead to undue centralization and higher switching costs.</p>
<h1><a class="anchor" href="https://ethresear.ch#appendix-a-11" name="appendix-a-11"></a>Appendix A</h1>
<h2><a class="anchor" href="https://ethresear.ch#deriving-the-trade-probability-12" name="deriving-the-trade-probability-12"></a>Deriving the trade probability</h2>
<p>To see where Eq. (2) comes from, let’s model the price difference between CEX and DEX  as a Markovian jump-diffusion process. This allows us to derive the expression for the probability that stat-arbitrageurs can execute a profitable trade, i.e. that the price difference is higher than the fees needed to execute the trade.</p>
<p>If we assume that DEX and CEX prices follows a Brownian motion, since the difference between two Brownian motion is still a Brownian motion, we can model the price difference as a Brownian motion with volatility <span class="math">\sigma</span></p>
<div class="math">
\begin{equation}
dM(t) = \mu_Mdt+\sigma dW(t)\,,
\end{equation}
</div>
<p>where <span class="math">\mu_M</span> represents the drift of motion. In the presence of discrete time arrival for trades (i.e. jumps) modelled as a Poisson process with rate <span class="math">\lambda</span>,  we get</p>
<div class="math">
\begin{equation}
dM(t) = \mu_Mdt+\sigma dW(t) + j(M_{t-1}) dN(t)\,,
\end{equation}
</div>
<p>where <span class="math">j(M_{t-1}) dN(t)</span> is the contribution from jumps (depending only on immediately previous state <span class="math">j(M_{t-1})</span>, that’s where the Markovian approximation comes in). The density <span class="math">p(x,t)</span> of the process <span class="math">M(t)</span> is governed by Fokker-Planck equation</p>
<div class="math">
\begin{align}
\partial_t p(x,t) &amp;= -\mu_M\partial_x p(x,t) + \frac{\sigma^2}{2}\partial^2_xp(x,t)+\lambda\left[\int_{-\infty}^{+\infty}p(x-y,t)\delta(y-j)dy - p(x,t)\right]\\
&amp;=-\mu_M\partial_x p(x,t) + \frac{\sigma^2}{2}\partial^2_xp(x,t)+\lambda\left[p(x-j,t)-p(x,t)\right]\,,
\end{align}
</div>
<p>where the Dirac <span class="math">\delta</span> determine the dimension of the jump (we are assuming constant jumps) and <span class="math">\lambda</span> is the mean dimension of jumps in the price difference. In the absence of drift, the equation of the process is</p>
<div class="math">
\begin{equation}
\partial_tp(x,t)=\frac{\sigma^2}{2}\partial^2_xp(x,t)+\lambda\left[p(x-j,t)-p(x,t)\right]\,.
\end{equation}
</div>
<p>To find the stationary distribution (i.e. <span class="math">p(x)</span>), we can consider the case with <span class="math">\partial_tp(x,t)=0</span>, such that Fokker-Planck equation becomes</p>
<div class="math">
\begin{equation}
0=\frac{\sigma^2}{2}\partial^2_xp(x)+\lambda\left[p(x-j)-p(x)\right]\,.
\end{equation}
</div>
<p>Now, if we consider the Taylor expansion of <span class="math">p(x)</span> for small <span class="math">j</span> we obtain</p>
<div class="math">
\begin{equation}
p(x-j)\sim p(x)-j\partial_xp(x)+\frac{\lambda j^2}{2}\partial_x^2p(x)+\ldots\,,
\end{equation}
</div>
<p>which gives</p>
<div class="math">
\begin{equation}
0=\frac{1}{2}\left(\sigma^2+\lambda j^2\right)\partial^2_xp(x,t)-\lambda j\partial_xp(x)\,.
\end{equation}
</div>
<p>If we now observe that for</p>
<div class="math">
j\ll\frac{\sigma}{\sqrt{\lambda}}\,,
</div>
<p>we can neglect second order terms in <span class="math">j</span>. For the next part of the paper we’ll use</p>
<div class="math">
j=\frac{\sigma}{\sqrt{2\lambda}}=\sigma\sqrt{\frac{\bar{t}}{2}}\,,
</div>
<p>which means the dimension of the jump between trades is given by the volatility of price difference times the square root of half the time interval between trades. Under these assumptions our Fokker-Planck equation becomes</p>
<div class="math">
\begin{equation}
0=\frac{\sigma^2}{2}\partial^2_xp(x,t)-\frac{\sqrt{\lambda}\sigma}{\sqrt{2}}\partial_xp(x)\,.
\end{equation}
</div>
<p>This is a second order differential equation, with solution of the form</p>
<div class="math">
\begin{equation}
p(x)=Ae^{r_1x}+Be^{r_2x}\,,
\end{equation}
</div>
<p>where <span class="math">r_1</span> and <span class="math">r_2</span> are the solution of</p>
<div class="math">
\begin{equation}
r^2-\frac{\sqrt{2\lambda}}{\sigma}r=0\,.
\end{equation}
</div>
<p>It follows that</p>
<div class="math">
\begin{equation}
p(x)=A+Be^{\frac{\sqrt{2\lambda}}{\sigma}x}\,.
\end{equation}
</div>
<p>Since <span class="math">p(x)</span> is a density, it has to be normalized and not diverging for <span class="math">x\to\pm\infty</span>. This means that the solution has to be</p>
<div class="math">
\begin{equation}
p(x)=p_1(x|x\in[-\gamma,\gamma])+p_2(x|x\in(-\infty,-\gamma)\,\cup\,(\gamma,\infty))\,,
\end{equation}
</div>
<p>where</p>
<div class="math">
\begin{align}
&amp;p_1(x) = A\,,\qquad\qquad\qquad\,\,\,\, x\in[-\gamma,\gamma]\\
&amp;p_2(x) = Be^{-\frac{\sqrt{2\lambda}}{\sigma}(|x|-\gamma)}\,,\qquad x\in(-\infty,\gamma] \cup [\gamma,\infty)\,.
\end{align}
</div>
<p>The nature of <span class="math">p_2(x)</span> is that it is null at infinity. Now, if we impose continuity of <span class="math">p(x)</span> at boundaries, we have</p>
<div class="math">
p_1(\gamma)=p_2(\gamma)\Rightarrow A = B e^0 = B\,.
</div>
<p>It follows that, by imposing the symmetry condition and the fact that <span class="math">p(x)</span> is a density we get</p>
<div class="math">
\begin{align*}
&amp;2\int_0^\infty p(x)dx = 1 \\
&amp;\to \left.2Ax\right|_0^\gamma-\left.2\frac{B\sigma}{\sqrt{2\lambda}}e^{-\frac{\sqrt{2\lambda}}{\sigma}(|x|-\gamma)}\right|_\gamma^\infty=1\\
&amp;\to 2A\gamma\left(1+\frac{1}{\xi}\right)=1\,,
\end{align*}
</div>
<p>where we introduced the parameter <span class="math">\xi=\frac{\sqrt{2\lambda}\gamma}{\sigma}</span>, characterizing the behaviour of the price difference process. By solving for A, it follows that</p>
<div class="math">
\begin{split}
&amp;p_1(x) = \frac{1}{2\gamma}\frac{\xi}{1+\xi}\,,\qquad\qquad\qquad\,\,\,\, x\in[-\gamma,\gamma]\\
&amp;p_2(x) = \frac{1}{1+\xi}\frac{\xi}{2\gamma}e^{-\frac{\xi}{\gamma}(|x|-\gamma)}\,,\qquad x\in(-\infty,\gamma] \cup [\gamma,\infty)\,.
\end{split}
</div>
<p>Now, we are interested in computing the probability of the trade area. This has as density</p>
<div class="math">
\begin{equation}
p_2(x|x\in(-\infty,-\gamma))+p_2(x|x\in(\gamma,\infty))=\frac{1}{1+\xi}\frac{\xi}{\gamma}e^{-\frac{\xi}{\gamma}(|x|-\gamma)}\,,
\end{equation}
</div>
<p>and since</p>
<div class="math">
\frac{\xi}{\gamma}e^{-\frac{\xi}{\gamma}(|x|-\gamma)}\,,
</div>
<p>is the density of an exponential distribution and that is the only part dependent from <span class="math">x</span>, we have that the invariant for the trade region probability is</p>
<div class="math">
P=\frac{1}{1+\xi}=\frac{1}{1+\frac{\sqrt{2\lambda}\gamma}{\sigma}}\,,
</div>
<p>that is the result used in Eq. (2). Note that this result is consistent with what presented in <a href="https://arxiv.org/pdf/2305.14604" rel="noopener nofollow ugc">Milionis et al</a>, even if the derivation is different.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmations-under-the-no-lens/19975">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 09:39:35 +0000</pubDate>
</item>
<item>
<title>Leaderless and Leader-Based Preconfirmations</title>
<link>https://ethresear.ch/t/leaderless-and-leader-based-preconfirmations/19971</link>
<guid>https://ethresear.ch/t/leaderless-and-leader-based-preconfirmations/19971</guid>
<content:encoded><![CDATA[
<div> 关键词：preconfirmation (预确认), leader-based, leaderless, sourcing leaders, mev-boost

总结:
本文讨论了两种类型的预确认系统：领导型和无领导型。领导型预确认由单一权威提供，确保较高保证但可能导致集中；无领导型通过竞争提供价格发现，可能创造更有价值的区块，但存在不确定性。文章提出“ sourcing leaders”作为结合两者的优势，他们从竞争性提供商处获取预确认并为用户提供100%保证。文章还探讨了领导选举机制、拍卖与抽奖等方法，以及如何优化价格结构以防止集中。未来研究方向包括游戏理论分析、定价策略和集成现有MEV提升基础设施。 <div>
<p><em>Joint work with <a class="mention" href="https://ethresear.ch/u/murat">@murat</a>. Thanks to <a class="mention" href="https://ethresear.ch/u/the-ctra1n">@The-CTra1n</a> and <a class="mention" href="https://ethresear.ch/u/bemagri">@bemagri</a> for reviewing and providing valuable feedback.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>A preconfirmation (preconf) for the context of this article refers to a promise about a given set of transactions relative to a future block, e.g., execution of a transaction in the next block or placing transactions at the top of the block. Entities who want to obtain a preconf can bid a certain amount indicating how much they are willing to pay for a preconf.</p>
<p>One dimension in which preconfs can be distinguished is whether there exists a unique preconf provider for every L1 block (a preconf leader), or whether there can be multiple competing preconf providers for every L1 block, without a leader. We here discuss the two approaches, their respective advantages and disadvantages, and how they can be combined. A particularly promising approach for combining the two concepts to obtain the best of both worlds appears to be using “sourcing leaders”, which are operating in a leaderless setting and collect preconfs from competing preconf providers.</p>
<h1><a class="anchor" href="https://ethresear.ch#overview-and-definitions-2" name="overview-and-definitions-2"></a>Overview and Definitions</h1>
<h2><a class="anchor" href="https://ethresear.ch#leader-based-preconfs-3" name="leader-based-preconfs-3"></a>Leader-Based Preconfs</h2>
<p>The simplest form of preconfs are ones issued by an appointed leader. This leader must have the authority to issue preconfs and have some means to enforce them. It is not necessary to have a single leader overall, as long as there is a unique, predetermined, and publicly known leader at each point in time. A straightforward way to choose leaders is using the current L1 proposer, as, e.g., in <a href="https://github.com/Commit-Boost/commit-boost-client" rel="noopener nofollow ugc">commit-boost</a>. More sophisticated leader-election methods are discussed below, and can be employed by <a href="https://docs.primev.xyz/concepts/what-is-mev-commit" rel="noopener nofollow ugc">mev-commit</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#leaderless-preconfs-4" name="leaderless-preconfs-4"></a>Leaderless Preconfs</h2>
<p>An alternative to leader-based preconfs is to have multiple preconf providers simultaneously. The most natural instantiation of this is to have the block builders act as preconf providers, leveraging the strengths of the existing mev-boost landscape. This mechanism is <a href="https://docs.primev.xyz/concepts/what-is-mev-commit" rel="noopener nofollow ugc">used by mev-commit</a>. In this case, a single preconf provider cannot provide an authoritative preconf; in case the block builders are preconf providers, a single builder can only promise to honor the preconf for the blocks this block builder builds.</p>
<p>A preconf from a single block builder thus constitutes a probabilistic preconf in the sense that the preconf is conditioned on the issuing block builder winning the corresponding block. This can already be useful, e.g., for arbitrage searchers. A proper preconf with a 100% guarantee is obtained if all block builders preconfirm. A subtlety of this is that the set of all possible block builders must be known, which is not the case in a permissionless setting. This is solved by mev-commit by letting <a href="https://docs.primev.xyz/get-started/providers/registering-a-provider" rel="noopener nofollow ugc">block builders register</a> as providers and <a href="https://docs.primev.xyz/get-started/validators" rel="noopener nofollow ugc">proposers and relays opt-in</a> to only deliver blocks from registered block builders. Analyzing the game-theoretic interplay between bidders and multiple preconf providers is an interesting open problem.</p>
<h1><a class="anchor" href="https://ethresear.ch#comparison-5" name="comparison-5"></a>Comparison</h1>
<p>Both approaches have their advantages and disadvantages, which we discuss below.</p>
<h2><a class="anchor" href="https://ethresear.ch#advantages-of-leader-based-preconfs-6" name="advantages-of-leader-based-preconfs-6"></a>Advantages of Leader-Based Preconfs</h2>
<p>The most obvious advantage of leader-based preconfs is that a single preconf already constitutes almost a 100% guarantee (almost because the slot may be missed or the chain reorged). This simplifies the protocol interaction and also possibly provides faster feedback. Note that reorg risks are the same for all types of preconfs, so we do not discuss them further here.</p>
<h2><a class="anchor" href="https://ethresear.ch#advantages-of-leaderless-preconfs-7" name="advantages-of-leaderless-preconfs-7"></a>Advantages of Leaderless Preconfs</h2>
<p>Having multiple simultaneous preconf providers creates a competitive environment, allowing for efficient preconf price discovery and thereby optimizing validator yield. A single provider having a preconf monopoly, on the other hand, can dictate the prices arbitrarily.</p>
<p>Further advantages come from letting the block builders be the preconf providers. First, block builders have sufficient sophistication to properly price preconfs. Secondly, builders are building the blocks and thus are the only entities that can issue preconfs without interfering with block production and adding latency: If another party issues a preconf, it must be communicated to the block builders such that they can build compatible blocks, and failure to receive the preconf in time leads to the block builder building a block violating the preconf. This also means that there is some delay between issuing the preconf and the builders learning about it in a leader based approach, which is particularly problematic towards the end of a slot, where builders may learn too late about the preconf. This also creates an advantage for block builders with fast connections to the preconf leaders, potentially leading to further centralization. Furthermore, receiving a preconf from a separate entity interferes with the block building strategy of the builders and thus can potentially lead to substantially less valuable blocks. Finally, leaderless preconfs can be integrated more easily into the existing mev-boost infrastructure.</p>
<h1><a class="anchor" href="https://ethresear.ch#leader-election-8" name="leader-election-8"></a>Leader Election</h1>
<p>As mentioned above, the simplest way to elect a preconf leader is to choose the current L1 proposer. This, however, requires additional sophistication from the proposer and likely leads to economic inefficiencies. It is therefore likely that proposers want to outsource preconfs similarly to how proposers outsource block building in PBS, even though this might raise concerns such as increased complexity due to additional actors, and potentially more centralization. A crucial difference from PBS is that preconf leaders need to be chosen in advance, i.e., before preconf bids are available. Thus, when the right to become a preconf leader is auctioned off, the potential leaders need to place their bids in the leader election without knowing the value they can derive from becoming a leader. This means their bids can only be based on expected values rather than actual amounts as in PBS, similarly to <a href="https://ethresear.ch/t/execution-tickets/17944">execution tickets</a>. A notable exemption to this are scenarios in which preconfs are not time critical such as preconfs for blob inclusion bids. In this case, the auction can be run after all preconf bids have been issued and thus the auction can be based on the actual value instead of the expected one (cf. <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">Ethereum Research - Blob Preconfirmations with Inclusion Lists to Mitigate Blob Contention and Censorship</a>).</p>
<p>One concern with an expected-value-based auction is that this value likely remains relatively stable over time and thus a possible scenario is that a single entity that is very good at pricing wins an overwhelming fraction of the auctions, leading to centralization and a preconf monopoly (cf. <a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814/1" rel="noopener nofollow ugc">The Flashbots Collective - When To Sell Your Blocks</a>). A possible mitigation to this problem is to instead of running an auction, sell lottery tickets and choose the leader randomly as the holder of the winning ticket. This is akin to a similar mechanism recently proposed by <a href="https://hackmd.io/@EspressoSystems/market-design" rel="noopener nofollow ugc">Espresso Systems in a related context</a>. Further research is required to determine an optimal pricing structure for such lotteries.</p>
<h1><a class="anchor" href="https://ethresear.ch#combining-leaderless-and-leader-based-preconfs-9" name="combining-leaderless-and-leader-based-preconfs-9"></a>Combining Leaderless and Leader-Based Preconfs</h1>
<p>To obtain the best of both worlds, one can combine a leaderless with a leader-based approach. We discuss some options how to achieve this below.</p>
<h2><a class="anchor" href="https://ethresear.ch#simultaneous-leaders-and-leaderless-providers-10" name="simultaneous-leaders-and-leaderless-providers-10"></a>Simultaneous Leaders and Leaderless Providers</h2>
<p>One option to combine leaderless and leader-based preconfs is to have a dedicated preconf leader, but let this leader operate simultaneously with multiple non-leader preconf providers. We assume below that the non-leader providers are block builders. In such a scheme, both the leader and the builders can issue preconfs at any point in time. When the leader issues a preconf, it must be communicated to the block builders, who then need to honor them when building their blocks. At this point, block builders cannot commit to the already committed bid anymore (since such commitment would not add any value). On the other hand, if a builder issues a preconf first, the leader can still commit to the same bid, turning the preconf from the builder into a 100% guaranteed preconf.</p>
<p>While this approach might appear conceptually simple, it comes with several challenges. One issue is that it is probably very hard, if not impossible, for the leader to issue execution preconfs that are compatible with execution preconfs of the block builders. This approach might therefore be limited to inclusion preconfs. Another issue is the timing of preconfs: For the mechanism to work, a total order among preconfs needs to be established, since a builder should only be rewarded for a preconf on a bid that also been committed to by the leader if the builder committed first. This total order can be established by a dedicated side-chain, such as the mev-commit chain. Nevertheless, there is room for leaders to play games with the competing builders by delaying their preconfs or trying to frontrun the builders. Yet another difficulty of this approach are the more complex incentives. Who should be paid how much in case multiple preconfs are issued? Developing a fair mechanism that leads to good preconf prices requires further research.</p>
<h2><a class="anchor" href="https://ethresear.ch#sourcing-leaders-11" name="sourcing-leaders-11"></a>Sourcing Leaders</h2>
<p>An alternative is to have leaders that themselves have no authority to enforce preconfs. Instead, the leaders receive bids from end users and subsequently try to obtain preconfs from the preconf providers. We call such leaders “sourcing leaders”. Once the sourcing leader has obtained preconfs from all providers, they issue a preconf to the end user. A sourcing leader is not strictly speaking a leader as defined above, but can provide the same advantage of a leader, namely issuing preconfs that themselves provide a 100% guarantee to the end user.</p>
<p>The role of a sourcing leader can be taken on by sophisticated actors such as solvers. A sourcing leader can in this case also offer preconfs before all providers have issued one and charge a premium to take on the risk that the preconf is violated. It is furthermore possible to have multiple competing sourcing leaders that offer preconfs with different prices at different speeds, where users can choose the best one for their purposes.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/d/1df247e0731521b812fdecf14287017b6e1a772b.png" title="Sourcing Leader"><img alt="Sourcing Leader" height="219" src="https://ethresear.ch/uploads/default/optimized/3X/1/d/1df247e0731521b812fdecf14287017b6e1a772b_2_690x219.png" width="690" /></a></div><br />
<strong>Figure 1:</strong> Illustration of the interaction between an end user, a sourcing leader running a bidder node, and three preconf providers.<p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-and-open-problems-12" name="conclusion-and-open-problems-12"></a>Conclusion and Open Problems</h1>
<p>Both leader-based and leaderless preconfs offer unique advantages and challenges. Leader-based preconfs offer a 100% guarantee (ignoring missed slots and reorgs) with a single preconfirmation, whereas leaderless ones create a competitive environment, enabling efficient price discovery, and potentially leading to more valuable blocks. Different methods for leader election also have their own trade-offs, with options ranging from auctions to lotteries.</p>
<p>Combining leaderless and leader-based preconfs can provide the benefits of both systems. One approach is to have a dedicated preconf leader operating alongside non-leader providers. Another approach is to use sourcing leaders who have no enforcement authority themselves, but attempt to obtain preconfs from providers. Both approaches allow for a high degree of competition, but also pose additional challenges.</p>
<p>There are still several unresolved research problems uncovered in this article. One of them is to analyze the game-theoretic interplay between bidders and multiple preconf providers in a leaderless preconf system. For a leader-based approach, relevant open problems are determining an optimal pricing structure for preconf leader lotteries to mitigate the risk of centralization and a preconf monopoly, and how to integrate with the existing mev-boost infrastructure. For combining leaderless and leader-based preconfs, designing fair mechanisms for the interaction between both types of preconf providers is left for future research. Finally, an important open question is how the approach with a sourcing leader compares to the others in terms of obtaining fair prices.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/leaderless-and-leader-based-preconfirmations/19971">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 20:41:05 +0000</pubDate>
</item>
<item>
<title>Execution Consensus Separation</title>
<link>https://ethresear.ch/t/execution-consensus-separation/19964</link>
<guid>https://ethresear.ch/t/execution-consensus-separation/19964</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、共识层、执行层、应用层、多提案者共识（MCP）

总结:<br />
文章讨论了执行一致性分离在解决以太坊上的交易优先权执行问题（MEV）中的关键作用。首先，需要改善共识层的抗审查能力，引入多提案者共识（MCP），允许多个提案者同时提出交易，增强交易的包容性。其次，执行层需实现延迟执行和确定性调度规则，确保交易按照规则有序进行。最后，应用层应发展为无序机制，例如通过链上拍卖避免价格猜测导致的价值损失。这些升级将使以太坊对开发者和用户更加友好，研究者可共同推进这一安全协议的改进。 <div>
<h2><a class="anchor" href="https://ethresear.ch#execution-consensus-separation-1" name="execution-consensus-separation-1"></a>Execution Consensus Separation</h2>
<p><strong></strong></p><div class="lightbox-wrapper"><strong><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b9eb4b7bcec14c8b9a8aee948a332d9d48013e4.jpeg" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b9eb4b7bcec14c8b9a8aee948a332d9d48013e4_2_500x500.jpeg" width="500" /></a></strong></div><br />
MEV is fundamentally about control. The proposer has control of which transactions make it into blocks and which order they appear in. In other words MEV is all about censorship and reordering. All of the goals on the Ethereum roadmap related to MEV are therefore impossible without fixing these things. The good news is that fixing these things is possible, the bad news is that the solution requires us to work together to study and prove the security of some meaningful upgrades to both consensus and execution.<p></p>
<p>Current work on the <a href="https://x.com/VitalikButerin/status/1741190491578810445" rel="noopener nofollow ugc">“Scourge” section</a> of the <a href="https://ethereum.org/en/roadmap/" rel="noopener nofollow ugc">Ethereum roadmap</a> has been siloed. People work on individual problems and sometimes lose the broader scope of what we are ultimately trying to achieve. <a href="https://ethresear.ch/t/epbs-design-constraints/18728">ePBS</a>, <a href="https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474" rel="noopener nofollow ugc">Inclusion Lists</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV Burn</a>, <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">Distributed Block Building</a>, and <a href="https://x.com/VitalikButerin/status/1741190491578810445" rel="noopener nofollow ugc">Application-layer MEV minimization</a>, are examples of ideas that require censorship resistance and control over ordering, but we haven’t yet addressed the pre-requisites. Solving these allows us to kill 5 birds with 1 stone. But to do this we need to think from first principles and work on the underlying root causes rather than tinkering with a thin veneer on top of the protocol.</p>
<p>Solving MEV at the protocol level requires buy in from all three levels of the chain:</p>
<ol>
<li><strong>Consensus Layer:</strong> Multiple concurrent proposers.</li>
<li><strong>Execution Layer:</strong> Delayed execution and deterministic scheduling rules.</li>
<li><strong>Application Layer:</strong> Order-agnostic applications.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#consensus-layer-2" name="consensus-layer-2"></a>Consensus layer</h2>
<p>We cannot get anywhere without vastly improved censorship resistance at the consensus layer. This is what allows us to hold auctions and prevent censorship of competing bids. The root cause of Ethereum’s weak censorship resistance is the fact that only a single entity can include transactions during each 12 second slot. <strong>Multiple concurrent proposers (MCP)</strong> fixes this problem. Instead of coming to consensus on an ordered block of transactions from a single block proposer, each of the K proposers propose a set of transactions at the same time. The protocol then aggregates these proposals using a <strong>common subset</strong> primitive (or a similar algorithm, this is an active area of research), yielding an unordered set of transactions which are to be included in the block.</p>
<p>MCP solves the problem of censorship-resistant inclusion, achieving the goals of <a href="https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474" rel="noopener nofollow ugc">Inclusion Lists</a> in a more natural way. The output is an unordered set of transactions, so it does not solve the problem of reordering. That will be the responsibility of the execution layer.</p>
<p>MCP is an area of active study and we encourage people to get involved. See SMG <a href="https://mechanism.org/spec/01" rel="noopener nofollow ugc">SPEC-01</a> for a theoretical description of MCP. Work is currently underway at SMG to formally specify MCP and create a proposed implementation of a gadget for use in the Ethereum protocol. Contact us if you are interested in working on this.</p>
<h2><a class="anchor" href="https://ethresear.ch#execution-layer-3" name="execution-layer-3"></a>Execution layer</h2>
<p>Ethereum’s execution layer must be upgraded to solve the problem of transaction reordering. To do this, we must delay the calculation of the state root to the next block so that the execution layer has time to implement a deterministic ordering rule.</p>
<p>Once it has the transactions, the execution layer has a new important job: figuring out how to order them. To do this, we need to select a <strong>deterministic scheduling rule</strong>. This is an area of active study where we encourage people to get involved. There are many promising candidates: <a href="https://www.paradigm.xyz/2024/06/priority-is-all-you-need" rel="noopener nofollow ugc">priority fee ordering</a>, as-needed execution, and <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">distributed block building</a>. We will elaborate on the last two in an upcoming article.</p>
<p>With delayed execution and a deterministic scheduling rule, Ethereum’s execution layer will determine the order of transactions in a block, allowing it to achieve the same goals as <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">distributed block building</a> and <a href="https://ethresear.ch/t/epbs-design-constraints/18728">ePBS</a> in a more natural way. In addition, since the ordering is enforced by the logic of the protocol, not by the goodwill of any particular validator, the protocol can burn all the fees at this stage, achieving the goals of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV Burn</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#application-layer-4" name="application-layer-4"></a>Application layer</h2>
<p>Assuming we succeed in the above upgrades, Ethereum’s application layer will be free to upgrade their applications to be natively MEV-resistant while remaining totally onchain. We call the class of things they will do <strong>order-agnostic applications</strong> or order-agnostic mechanisms.</p>
<p>For example take the problem of liquidation MEV. For the sake of argument, suppose we have 1000 ETH that needs to be liquidated for DAI. We don’t know what the appropriate price is for the ETH, so we have two options: we can guess the right price and have a posted price available to the first person who claims it, which is how Compound and Aave work, and leads to tremendous value leaked to liquidation races, reducing UX. Or, we can hold a Dutch auction, which leads to slightly less value leakage, but doesn’t allow us to clear the distressed debt right away. But now, with MCP and deterministic scheduling, these protocols can simply hold an onchain auction for the right to liquidate 1000 ETH and elicit the price that way.</p>
<p>Order agnostic application design has a number of benefits, and there are many more examples of places where MEV leaks that can be solved. Future posts will elaborate on this.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-5" name="conclusion-5"></a>Conclusion</h2>
<p>The successful implementation of these upgrades will result in a much friendlier Ethereum for both developers and users. The first step of this research program is fleshing out and proving the security of a multi proposer design with simultaneous release. Other blockchains have multiple proposers, but are not designed in the same way or for the same purpose. If you are a consensus researcher interested in working on this topic, please reach out, we have funding available for this.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/execution-consensus-separation/19964">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 19:09:20 +0000</pubDate>
</item>
<item>
<title>Fork Choice compliance test suites &amp; test generator</title>
<link>https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954</link>
<guid>https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954</guid>
<content:encoded><![CDATA[
<div> 关键词：Fork Choice、测试生成器、测试套件、性能优化、未来步骤

总结:<br />
Fork Choice合规性测试生成器已完成初步实施，能够为客户端开发团队提供测试模板。已经生成了三个测试套件（Tiny、Small和Standard），涵盖不同规模的测试目的。尽管生成Extended测试套件需要时间，但支持多进程以提高效率。目前的测试速度较慢，未来将优化性能并增加模型灵活性，计划进行覆盖率导向的模糊测试和新的测试向量格式。整体目标是简化测试采用并确保协议的正确实现。 <div>
<p>This is a preliminary announcement, we’ll officially announce during the next All Core Devs call.</p>
<p>We (TxRx team, ConsenSys) have implemented a Fork Choice compliance test generator as well as have generated Fork Choice compliance test suites.</p>
<p>Overall F/C compliance testing methodology is described <a href="https://hackmd.io/@ericsson49/fork-choice-implementation-vs-spec-testing" rel="noopener nofollow ugc">here</a>.</p>
<p>In this report we briefly describe the results of the initial implementation phase (i.e. the F/C test generator and F/C test suites).  A more detailed description of the work is TBD.</p>
<p>This work was supported by a grant from the Ethereum Foundation.</p>
<h1><a class="anchor" href="https://ethresear.ch#implementation-status-1" name="implementation-status-1"></a>Implementation status</h1>
<h2><a class="anchor" href="https://ethresear.ch#test-generator-2" name="test-generator-2"></a>Test generator</h2>
<p>The initial version of the Fork Choice tests generator is implemented and currently available as a draft <a href="https://github.com/ethereum/consensus-specs/pull/3831" rel="noopener nofollow ugc">consensus-specs PR</a>. We have been focusing on minimizing efforts for client implementer teams to adopt the generated tests. The only a small change to the existing <a href="https://github.com/ethereum/consensus-specs/tree/dev/tests/formats/fork_choice" rel="noopener nofollow ugc">FC test format</a> is the addition of a <a href="https://github.com/ericsson49/eth2.0-specs/tree/fc-compliance2/tests/formats/fork_choice#checks-step" rel="noopener nofollow ugc">new check</a>, which is safe to ignore initially.</p>
<h2><a class="anchor" href="https://ethresear.ch#test-suites-3" name="test-suites-3"></a>Test suites</h2>
<p>We have developed test generation parameters for three suites at the moment.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Test suite</th>
<th>size</th>
<th>Purpose</th>
<th>Status</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tiny</td>
<td>135 tests</td>
<td>Demonstration, smoke testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1dWbkJY27fhOVX8i4aUuZ7VBkH3P_Vr1i/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Small</td>
<td>1472 tests</td>
<td>Initial adoption, smoke testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1EAIeTL5F3zelXK5pBkSLuawJjuLWQx3r/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Standard</td>
<td>13240 tests</td>
<td>Main testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1_56JObwYWHARgm5QYmE4vrkcLEru854G/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Extended</td>
<td>about 100K tests</td>
<td>Extended testing</td>
<td>TBD</td>
<td></td>
</tr>
</tbody>
</table>
</div><p><strong>Note</strong>: We are able to generate the Extended test suite. However, it will take significant time (about a week), therefore, we have delayed actual test suite generation until it will be demanded.</p>
<p>It should be possible to generate test suites for any fork (Altair, Capella, Deneb) and preset (mainnet or minimal). However, test generation for mainnet is very slow. We have tested minimal/altair and minimal/deneb.</p>
<p>Test generation currently is slow (about 10-15 seconds per test on average). However, a multiprocessing mode is supported (about 2 seconds per test on Apple M1). Generation of the Standard test suite takes about 8 hours (multiprocessing mode) or two days (single process mode).</p>
<p>The reasons of slow performance are known and are to be alleviated in future. Currently, our top priority is to simplify adoption of the new test suites.</p>
<h2><a class="anchor" href="https://ethresear.ch#testing-the-tests-4" name="testing-the-tests-4"></a>Testing the tests</h2>
<p>We have run the generated tests against <a href="https://github.com/Consensys/teku" rel="noopener nofollow ugc">Teku</a>, using Teku test runner and against the official executable Fork Choice spec (minimal/deneb), using a simple Python <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_run.py" rel="noopener nofollow ugc">test runner</a>.</p>
<h1><a class="anchor" href="https://ethresear.ch#test-generation-approach-5" name="test-generation-approach-5"></a>Test generation approach</h1>
<p>The test generation approach is a mix of model-based and fuzz testing.</p>
<p>Principles:</p>
<ul>
<li>the Fork Choice spec is virtually “decomposed” into two parts: topological sorting of events and actual event processing</li>
<li>tests are generated for the event processing part, the topological sorting part is addressed via event shuffling (time shift plus drop/duplication)</li>
<li>models are used to describe the spec aspects that we want to cover. There are two flavors: trees of various shapes (for block trees and super-majority link trees) and predicates to be covered (<code>filter_block_tree</code>)</li>
<li>for each model there can be multiple solutions, each solution can be seen as a template (e.g. SM link tree + block tree) which can be instantiated in multiple ways (varying validator actions)</li>
<li>each test case can be mutated multiple times</li>
</ul>
<p>Tests are generated with four steps:</p>
<ol>
<li>Models (implemented using MiniZinc), describing abstract coverage aspects that we want to cover. Currently there are three models: <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/SM_links.mzn" rel="noopener nofollow ugc">SM link</a> (super-majority link) tree model, <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/Block_tree.mzn" rel="noopener nofollow ugc">Block tree</a> model and <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/Block_cover3.mzn" rel="noopener nofollow ugc">Block cover</a> model.</li>
<li>For each model a set of solutions is produced. The models are parameterized, which affects the size of solution set generated.
<ul>
<li>SM link and block tree solutions are combined into a single block tree.</li>
</ul>
</li>
<li>Each solution is instantiated using two test instantiators (<a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/block_tree.py" rel="noopener nofollow ugc">block tree</a> and <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/block_cover.py" rel="noopener nofollow ugc">block cover</a>). The instantiation is randomized, i.e. a coin is flipped on each decision point. This results in a complete Fork Choice test case (i.e. <em>anchor state</em> plus a sequence of <em>tick</em> | <em>block</em> | <em>attestation</em> | <em>attester_slashing</em> events).</li>
<li>Each test case is mutated via <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/mutation_operators.py" rel="noopener nofollow ugc">mutation</a> (shuffling) operators. Currently, there are thee mutation operator: time shift, drop and duplicate (with consequent shifting).</li>
</ol>
<p>The models are developed manually.<br />
Solutions to the models are produced with a special <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/generate_test_instances.py" rel="noopener nofollow ugc">generator</a>.<br />
Test instantiators and mutations are performed with <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_gen.py" rel="noopener nofollow ugc">test_gen.py</a>.</p>
<p>After tests are generated, one can validate the produced test steps using <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_run.py" rel="noopener nofollow ugc">test_run.py</a> script, which executes the steps using the pyspecs, performing prescribed checks.</p>
<h1><a class="anchor" href="https://ethresear.ch#test-structure-6" name="test-structure-6"></a>Test structure</h1>
<div class="md-table">
<table>
<thead>
<tr>
<th>Test group</th>
<th>size (standard suite)</th>
<th>parameters (solutions + variations + mutations)</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Block tree</td>
<td>4096 tests</td>
<td>1024*2*(1+1)</td>
<td>focus on trees of varying shapes</td>
</tr>
<tr>
<td>Block weight</td>
<td>2048 tests</td>
<td>8*64*(1+3)</td>
<td>focus on producing block trees with varying weights</td>
</tr>
<tr>
<td>Shuffling</td>
<td>2048 tests</td>
<td>8*4*(1+63)</td>
<td>focus on shuffling/mutation operators</td>
</tr>
<tr>
<td>Attester slashing</td>
<td>1024 tests</td>
<td>8*16*(1+7)</td>
<td>focus on attester slashing</td>
</tr>
<tr>
<td>Invalid messages</td>
<td>1024 tests</td>
<td>8*32*(1+3)</td>
<td>focus on invalid messages</td>
</tr>
<tr>
<td>Block cover</td>
<td>3000 tests</td>
<td>60*5*(1+9)</td>
<td>cover various combinations of predicates from the <code>filter_block_tree</code> method</td>
</tr>
</tbody>
</table>
</div><h1><a class="anchor" href="https://ethresear.ch#future-steps-7" name="future-steps-7"></a>Future steps</h1>
<ul>
<li>improve performance. Performance is adequate right now (for the initial adoption phase). But is the main blocker otherwise.</li>
<li>more flexible test generation. More and better models, better instantiators, better mutation operators.</li>
<li>coverage-guided fuzzing</li>
<li>new test vector format (don’t need full test cases for fuzz testing, as need to compare against the FC spec anyway)</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 20:00:49 +0000</pubDate>
</item>
<item>
<title>Ethereum Node Message Propagation Bandwidth Consumption</title>
<link>https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952</link>
<guid>https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952</guid>
<content:encoded><![CDATA[
<div> 关键词：GossipSub, Bandwidth consumption, Hermes, Optimization, Ethereum P2P network

总结:
GossipSub在以太坊P2P网络中的性能研究发现，SENT_IHAVE和RECV_IHAVE消息消耗了大量带宽，分别占总带宽的23.4%和10%，对出站和入站流量影响显著。研究建议改进机制以减少重复消息，这将节省约42%的总带宽。尽管Hermes节点配置非标准，但研究结果证实了优化空间。与其他节点的比较显示，当前以太坊节点的带宽使用率相对较低，仍有提升余地。总的来说，这项工作旨在通过深入了解GossipSub的性能，为协议优化提供依据。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-tldr-1" name="summary-tldr-1"></a>Summary &amp; TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io </a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the <a class="inline-onebox" href="https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921">Number Duplicate Messages in Ethereum's Gossipsub Network</a>, in this post we investigate bandwidth consumption at the GossipSub level, i.e., bandwidth consumption for message propagation. The target of the study is to identify the protocol components that consume the biggest share of network bandwidth. The study has been co-authored by <a class="mention" href="https://ethresear.ch/u/cortze">@cortze</a> and <a class="mention" href="https://ethresear.ch/u/yiannisbot">@yiannisbot</a>.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer. </a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions. The results reported here are from a 3.5hr trace.</p>
<p><strong>Study Description:</strong> The distributed nature of p2p systems makes them generally less effective in computational, latency, and bandwidth consumption. This is due to the extra interactions between nodes needed to organize a p2p network without a central authority that bridges between peers. Thus, taking care of processes, such as peer or content discovery, content sharing, and message broadcasting often become a challenge, or bottleneck.</p>
<p>Ethereum is not different in that respect. Message propagation takes a large portion of the network bandwidth used by a node in the Ethereum network. This study investigates bandwidth consumption at the GossipSub level. The target is to identify the protocol components that consume the biggest share of network bandwidth.</p>
<p><strong>TL;DR:</strong> Despite the fact that the configuration of our <code>Hermes</code> node, which, in this case, doesn’t represent a standard node in the Ethereum network, the bandwidth consumption numbers of GossipSub validate that there’s plenty of space for optimization.</p>
<p>We observed that a significant portion of bandwidth is spent on <code>SENT_IHAVE</code> messages (23.4% of the total bandwidth and 30% of the total outgoing bandwidth) and <code>RECV_IHAVE</code> messages (10% of the total bandwidth, and 42% of the total inbound bandwidth).</p>
<p>More than anything, these findings validate the improvement recommendations made during our previous study on the “Effectiveness of Gossipsub’s gossip mechanism”: <a class="inline-onebox" href="https://ethresear.ch/t/gossip-iwant-ihave-effectiveness-in-ethereums-gossipsusb-network/19686">Gossip IWANT/IHAVE Effectiveness in Ethereum's Gossipsusb network</a></p>
<p>Taking into account that a node doesn’t only receive duplicated messages but also generates duplicates to others, we strongly recommend pushing the <a href="https://github.com/libp2p/specs/pull/560" rel="noopener nofollow ugc">GossipSub1.2</a> initiative, as it will effectively eliminate the bandwidth wasted on receiving or generating duplicates, which amounts to ~42% of total bandwidth.</p>
<h1><a class="anchor" href="https://ethresear.ch#results-on-bandwidth-consumption-2" name="results-on-bandwidth-consumption-2"></a>Results on Bandwidth Consumption</h1>
<blockquote>
<p><img alt=":eyes:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/eyes.png?v=12" title=":eyes:" width="20" /> NOTES: The bandwidth usage displayed in this study is limited to:</p>
<ul>
<li>The <code>Holesky</code> network</li>
<li>The GossipSub RPC calls</li>
<li>The following GossipSub topics:
<ul>
<li><code>beacon_block</code></li>
<li><code>beacon_aggregate_and_proof</code></li>
<li><code>sync_commmittee_contribution_and_proof</code></li>
<li><code>attester_slashing</code></li>
<li><code>proposer_slashing</code></li>
<li><code>voluntary_exit</code> * (check <code>Hermes</code> issue → <a class="inline-onebox" href="https://github.com/probe-lab/hermes/issues/24" rel="noopener nofollow ugc">Broadcasting of invalid `voluntary_exit` messages to mesh peers · Issue #24 · probe-lab/hermes · GitHub</a>)</li>
<li><code>bls_to_execution_change</code></li>
</ul>
</li>
<li>The bandwidth of <code>SENT_IHAVE</code> and <code>RECV_IHAVE</code> RPC calls has been calculated based on the number of bytes per <code>topic</code>  strings and <code>msg_ids</code> that were inside.</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#netin-vs-netout-3" name="netin-vs-netout-3"></a>NetIn vs NetOut</h2>
<p>The study starts with a general overview of what is the ratio of sent vs received bandwidth consumption. The following graph shows that on the <code>Hermes</code> node, the biggest share of the bandwidth comes from the data that we send out to the connected peers.</p>
<p>The total outbound bandwidth is around 3 to 4 times higher than the inbound. Note that <code>Hermes</code> differs from a standard node in that it keeps more peer connections (around 250 peers). This clearly has a significant impact on bandwidth usage. That said, although the numbers are not representative of the bandwidth usage of a normal node in absolute terms, the percentage split still represents that of a normal node.</p>
<p>Narrowing down, we observe a ratio of 700-800 KB/s for outgoing traffic and 200 KB/s for incoming traffic.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4fb2e194b5b97ea9f84092740d059ad4447d2061.jpeg" title="bandwidth-in-out"><img alt="bandwidth-in-out" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4fb2e194b5b97ea9f84092740d059ad4447d2061_2_517x309.jpeg" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#bandwidth-based-on-each-event-type-4" name="bandwidth-based-on-each-event-type-4"></a>Bandwidth based on each event type</h2>
<p>GossipSub sends multiple types of messages with different purposes. From control messages to keep the mesh stable to pure messages or gossip  <code>IHAVE</code> / <code>IWANT</code>  messages to ensure that the host didn’t miss any message. Each of these message types requires sending RPC calls, adding up to the total of sent and received network traffic.</p>
<p>The following graphs isolate the bandwidth attributed to each of the events. The first one shows the raw KB/s over time, and the second one shows the percentage of each event over the aggregated total.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/3/b352576dc2b9350a99470bde3eb0710d0e710d3c.jpeg" title="bandwidth-by-event"><img alt="bandwidth-by-event" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/3/b352576dc2b9350a99470bde3eb0710d0e710d3c_2_517x309.jpeg" width="517" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/b/ab8bda76fba67303a9b9991902f5ff1805c63175.jpeg" title="bandwidth-ratio-by-event"><img alt="bandwidth-ratio-by-event" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/a/b/ab8bda76fba67303a9b9991902f5ff1805c63175_2_517x309.jpeg" width="517" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#percentage-table-5" name="percentage-table-5"></a>Percentage Table</h3>
<pre><code>| Event | % of total BW | % of Received BW | % of Sent BW |
| --- | --- | --- | --- |
| RECV_GRAFT | 0.000367 | 0.001565 | ———————— |
| RECV_IHAVE | 9.974349 | 42.537746 | ———————— |
| RECV_IWANT | 2.368042 | 10.099021 | ———————— |
| RECV_MSG  (duplicated) | 7.347250 | 31.333920 | ———————— |
| RECV_MSG | 3.640691 | 15.526507 | ———————— |
| RECV_PRUNE | 0.002973 | 0.012678 | ———————— |
| RECV_SUBS | 0.114559 | 0.488562 | ———————— |
| SENT_GRAFT | 0.002863 | ———————— | 0.003740 |
| SENT_IHAVE | 23.404913 | ———————— | 30.573967 |
| SENT_IWANT | 0.094569 | ———————— | 0.123536 |
| SENT_MSG | 53.049257 | ———————— | 69.298539 |
| SENT_PRUNE | 0.000164 | ———————— | 0.000214 |
| SENT_SUBS | 0.000003 | ———————— | 0.000004 |
</code></pre>
<p>From the above graphs, we can observe that:</p>
<ul>
<li>The <code>SENT_MSG</code> event is the one that consumes the most network traffic, with a total of 53% of the total network traffic and 69% of the total sent traffic.<br />
It has a spiky oscillation between 500 to 700 KB/s, and it is clearly the most bandwidth consuming event.<br />
It is hard to define which is the ratio of duplicates that all those sent messages generate on the remote side. However, we could assume that it would follow a similar pattern to the <code>RECV_MSG</code> one (2 duplicate bytes per 1 original byte).</li>
<li>Surprisingly, the <code>SENT_IHAVE</code> event follows <code>SENT_MSG</code>s in terms of consumed bandwidth with a total of 23.4% of the total bandwidth and 30% of the total outgoing bandwidth. Interestingly, subscribing to topics with a high frequency of messages (even if they are small in size), does have an impact on the bandwidth that we use sending those <code>IHAVE</code> messages.<br />
Each <code>IHAVE</code> is limited to <code>5,000</code> message IDs; however, with a message ID of 40 bytes, it still adds up to a maximum of 200KBs in message IDs on every heartbeat (0.7s in the case of Ethereum).</li>
<li><code>RECV_IHAVES</code> represent 10% of the total bandwidth, and 42% of the total inbound bandwidth, with an inbound network bandwidth requirement of 100KB/s.</li>
<li>The above two points showcase that, far from being negligible on the overall value they provide, the total bandwidth used on <code>IHAVE</code> messages represents almost 400KB/s, consuming 23% of the total outgoing bandwidth and more than 40% of the incoming bandwidth.</li>
<li>The <code>RECV_MSG</code> events remain in the fourth position with a representation of 11% of the total consumed bandwidth, where only 3.6% belong to unique or original messages, and the remaining 7.3% belong to duplicates. In terms of the overall inbound bandwidth, they represent 15% and 31%, respectively, for original and duplicated received messages.</li>
<li>On a much lower ratio, the whole list of <code>RECV_IWANT</code> messages stays within a lower 2.3% of the total bandwidth usage, which represents 10% of the total received bytes.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#comparison-with-live-nodes-6" name="comparison-with-live-nodes-6"></a>Comparison with live nodes</h2>
<p>In order to validate the previous measurements taken from the GossipSub module at <code>Hermes</code>, we’ve compared the bandwidth usage ratios with standard running Ethereum nodes:</p>
<ul>
<li>Local Prysm node at home setup (Holesky) reports an average received network traffic of 386KB/s and a sent network traffic of 580KB/s.<br />
Although the numbers might be slightly different, these measurements take the whole traffic of the Beacon Node docker container, which includes:
<ul>
<li>Peer discovery</li>
<li>Requests/Responses like <code>beacon_blocs</code> or <code>blobs</code> by range or by root</li>
</ul>
</li>
</ul>
<p>The MigaLabs <a href="https://monitoreth.io/node_metrics#network-in-out" rel="noopener nofollow ugc">public dashboard</a> at <a href="https://monitoreth.io/node_metrics" rel="noopener nofollow ugc">monitor.eth</a> shows slightly bigger bandwidth usage than the ones we measured. However, it is unclear whether the measurement includes the Execution Layer. The reported bandwidth reports an average of 290KB/s inbound and 1.2MB/s outbound, although it doesn’t include many data points (5 points per hour) and the variation is noticeable.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7cf74da4a25ce8b98d757eeaebf56696d2c6aa6.jpeg" title="migalabs"><img alt="migalabs" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7cf74da4a25ce8b98d757eeaebf56696d2c6aa6_2_517x315.jpeg" width="517" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-7" name="conclusions-and-takeaways-7"></a>Conclusions and takeaways</h1>
<p>Despite the fact that the configuration of our <code>Hermes</code> node, which, in this case, doesn’t represent a standard node in the Ethereum network, the bandwidth consumption numbers of GossipSub validate that there’s plenty of space for optimization.</p>
<p>We observed that <strong>a significant portion of bandwidth is spent on <code>SENT_IHAVE</code> (23.4% of the total bandwidth and 30% of the total outgoing bandwidth) and <code>RECV_IHAVE</code> (10% of the total bandwidth, and 42% of the total inbound bandwidth)</strong>.</p>
<p>More than anything, these findings validate the improvement recommendations made during our previous study on the “Effectiveness of Gossipsub’s gossip mechanism”: <a class="inline-onebox" href="https://ethresear.ch/t/gossip-iwant-ihave-effectiveness-in-ethereums-gossipsusb-network/19686">Gossip IWANT/IHAVE Effectiveness in Ethereum's Gossipsusb network</a></p>
<p>Taking into account that a node doesn’t only receive duplicated messages but also generates duplicates to others, we strongly recommend pushing the <a href="https://github.com/libp2p/specs/pull/560" rel="noopener nofollow ugc">GossipSub1.2</a> initiative, as it will effectively eliminate the bandwidth wasted on receiving or generating duplicates, which amounts to ~42% of total bandwidth.</p>
<p>Even currently though, the network bandwidth usage of a host in the Ethereum network (around 300 KB/s inbound and 1.1 MB/s outbound, including the EL) still constitutes a small percentage of the <a href="https://fairinternetreport.com/research/internet-speed-by-country/" rel="noopener nofollow ugc">average household</a> bandwidth availability, which varies between 8MB/s and 26MB/s depending on the region.</p>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 14:39:15 +0000</pubDate>
</item>
<item>
<title>Fork Choice Attacks and Protections in EPBS</title>
<link>https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951</link>
<guid>https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、fork choice attack、proposer boost、builder boost、ex-anti attack

总结:
本文探讨了ePBS（增强版持久拜占庭容错）中的分叉选择攻击，重点关注新的分叉选择提升参数设计。文章分析了两种主要攻击类型（后抗攻击和外抗攻击），以及在引入builder块后，ePBS中出现的新攻击情景，如攻击者与建设者合谋的情况。作者提到，尽管存在削弱的防御，但攻击者需要更高的恶意比例才能成功，例如40%的proposer boost和20%的attacker committee。文章还讨论了各种攻击的动机、优势和潜在后果，以及相应的防范措施，包括Reveal Boost和Withheld Boost。最后，文章提出了可能的改进方向，如考虑网络同步性和多槽活度的影响。 <div>
<h2><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h2>
<p>This post explores fork choice attacks through the perspective of ePBS, focusing on the new fork choice boost parameters and the rationale behind their design. We’ll begin by examining why these parameters are crucial, followed by a review of the existing designs. For background reading, I recommend reading <a href="https://ethresear.ch/t/payload-boosts-in-epbs/18769">Payload Boosts in ePBS</a> by Potuz. Additionally, for a deeper understanding of how the LMD GHOST fork choice operates today, consider Ben Edgington’s section on fork choice in his book, <a href="https://eth2book.info/capella/part3/forkchoice/" rel="noopener nofollow ugc">Upgrading Ethereum</a>. Let’s dive in!</p>
<h4><a class="anchor" href="https://ethresear.ch#references-2" name="references-2"></a>References</h4>
<p><a href="https://ethresear.ch/t/payload-boosts-in-epbs/18769">Payload boosts in ePBS</a> - Feb/2024 By Potuz<br />
<a href="https://ethresear.ch/t/sandwitch-attacks-on-epbs/19538/1">Sandwitch attacks on ePBS</a> - May/2024 By Potuz</p>
<h2><a class="anchor" href="https://ethresear.ch#fork-choice-attacks-today-3" name="fork-choice-attacks-today-3"></a>Fork choice attacks today</h2>
<p>We analyze these scenarios from both the attacker’s and the victim’s perspectives, focusing on two consecutive proposal slots, each with distinct proposers. Two primary types of attacks can emerge:</p>
<ol>
<li>The proposer of slot <span class="math">n+1</span> attacks the proposer of slot <span class="math">n</span>.</li>
<li>The proposer of slot <span class="math">n</span> attacks the proposer of slot <span class="math">n+1</span>.</li>
</ol>
<p>To clarify, by “attack,” we mean an attempt to reorg the block out of the canonical chain. The motives behind such a reorg typically include:</p>
<ol>
<li>Stealing the content of the block.</li>
<li>Increasing the time available to build the block, making a 24-second block more valuable than a 12-second one.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#post-anti-attack-4" name="post-anti-attack-4"></a>Post-anti attack</h3>
<p>The first type of attack is a post-anti attack, where the proposer of slot <span class="math">n+1</span> attempts to reorg the block from slot <span class="math">n</span>. In this scenario, the proposer of <span class="math">n+1</span> utilizes the <a href="https://eth2book.info/capella/part3/forkchoice/phase0/#proposer-boost" rel="noopener nofollow ugc">proposer boost</a> to gain an advantage and potentially reorg the block from slot <span class="math">n</span>. Currently, the proposer boost is set at 40%. This means that as long as the block at slot <span class="math">n</span> receives votes from more than 40% of the beacon committee, it is safe against a reorg. Typically, we define the percentage of the beacon committee that belongs to the attacker as <span class="math">\delta</span>. An attacker can successfully reorg a block if <span class="math">\delta &gt; 1 - PB</span>, which is 60% under today’s parameters.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/f/3f93dac13fced8dbaa43115f19cd6ae45668406d.png" title="Screenshot 2024-06-26 at 12.57.24 PM"><img alt="Screenshot 2024-06-26 at 12.57.24 PM" height="297" src="https://ethresear.ch/uploads/default/optimized/3X/3/f/3f93dac13fced8dbaa43115f19cd6ae45668406d_2_690x297.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#ex-anti-attack-5" name="ex-anti-attack-5"></a>Ex-anti attack</h3>
<p>The second type of attack is known as the ex-anti attack, where the proposer of slot <span class="math">n</span> attempts to reorg the block from slot <span class="math">n+1</span>. This type of attack is inherently difficult to pull off because the proposer boost grants a 40% advantage to the block at slot <span class="math">n+1</span>. To successfully carry out this attack, the attacker’s beacon committee must withhold their attestations and block then release them synchronously which occurs shortly after the block at slot <span class="math">n+1</span> is published. To reorg the block at slot <span class="math">n+1</span>, the attacker’s beacon committee support must exceed the proposer boost. We can assert that an attacker can reorg a block if <span class="math">\delta &gt; PB</span>, which is 40% under today’s parameter.</p>
<p>It is worth mentioning in ex-anti attack, attackers who propose multiple consecutive slots have an added advantage. For two slots, the effectiveness of the attack can be simplified to the expression <span class="math">\delta / 2 &gt; PB</span>, requiring only 20% of the stake per slot to reorg an honest block.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/ccb28f1581907f015d5780dae95dd78444ba59d8.png" title="Screenshot 2024-06-26 at 12.57.38 PM"><img alt="Screenshot 2024-06-26 at 12.57.38 PM" height="340" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/ccb28f1581907f015d5780dae95dd78444ba59d8_2_690x340.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#fork-choice-attacks-in-epbs-6" name="fork-choice-attacks-in-epbs-6"></a>Fork choice attacks in ePBS</h2>
<p>In the ePBS model, the introduction of a <strong>builder block between two proposer blocks</strong> complicates the landscape of potential attacks beyond what we see today. This addition expands the array of possible attack scenarios:</p>
<h3><a class="anchor" href="https://ethresear.ch#pre-epbs-scenarios-7" name="pre-epbs-scenarios-7"></a>Pre-ePBS Scenarios:</h3>
<ol>
<li><strong>Proposer <span class="math">n+1</span> attacking proposer <span class="math">n</span></strong> - This scenario concerns post-anti reorg safety.</li>
<li><strong>Proposer <span class="math">n</span> attacking proposer <span class="math">n+1</span></strong> - This scenario concerns ex-anti reorg safety.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#post-epbs-scenarios-8" name="post-epbs-scenarios-8"></a>Post-ePBS Scenarios:</h3>
<ol>
<li><strong>Proposer of <span class="math">n+1</span> and builder of <span class="math">n</span> collude and attack proposer of <span class="math">n</span></strong> - This scenario concerns proposer post-anti reorg safety.</li>
<li><strong>Proposer and builder of <span class="math">n</span> collude and attack proposer of <span class="math">n+1</span></strong> - This scenario concerns proposer ex-anti reorg safety.</li>
<li><strong>Proposer of <span class="math">n+1</span> and <span class="math">n</span> collude and attack builder of <span class="math">n</span></strong> - This scenario introduces builder safety, including reorg safety and withholding safety.</li>
</ol>
<p>Before we go into the specific attack scenarios under the ePBS framework, it’s important to establish the incentives for honest builder behavior. Similar to the proposer boost, builders are also incentivized through boosts for honest actions through <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054">payload timeliness committee</a>.</p>
<ul>
<li><strong>Reveal Boost (<span class="math">RB</span>)</strong>: Awarded to builders who timely reveal their payloads.</li>
<li><strong>Withheld Boost (<span class="math">WB</span>)</strong>: Granted if a builder, feeling unsafe about revealing the payload, opts to release a withheld message. This boost gives weight to the parent block of the committed consensus block.</li>
</ul>
<p>These boosts also ensure both builder <strong>reveal</strong> and <strong>withhold</strong> safety. Builder reveal safety means that if the builder acted honestly and revealed a payload in a timely fashion (as attested by the PTC), then the revealed payload should be on-chain. Builder withhold safety means that if a beacon block containing a builder’s header is withheld or revealed late, then that beacon block should not be the canonical head of the blockchain in the view of honest validators.</p>
<p>To ensure clarity and maintain focus throughout our discussion, we will designate the boosts as follows: Reveal Boost (<span class="math">RB</span>), Withheld Boost (<span class="math">WB</span>), and Proposer Boost (<span class="math">PB</span>). The specific values of these boosts will be displayed towards the end of the post. Now, let’s explore the first scenario: the proposer post-anti attack in ePBS.</p>
<h3><a class="anchor" href="https://ethresear.ch#proposer-post-anti-attack-9" name="proposer-post-anti-attack-9"></a>Proposer post-anti attack</h3>
<p>As you may have noted, this scenario is similar to the post-anti attack today, except that the builder of <span class="math">n</span> colludes with the proposer of <span class="math">n+1</span>. We also assume that a portion of the beacon committee is part of the malicious team, represented by <span class="math">\delta</span>. The post-anti attack is successful if <span class="math">WB + PB + \delta &gt; 1 - \delta</span>. This indicates that post-anti attack resistance is weaker in ePBS due to the added power of the withheld boost from the colluding builder.</p>
<p>Let’s examine the benefits for the attacker in a successful attack:</p>
<ul>
<li>The block at <span class="math">n+1</span> gains two slots worth of transactions by reorg out <span class="math">n</span>, resulting in more time and more transactions, thereby increasing its block value.</li>
<li>Since <span class="math">n</span>'s payload was revealed as withheld, and both <span class="math">n</span>'s builder and <span class="math">n+1</span>'s proposer collude, there is no opportunity to steal <span class="math">n</span>'s payload transaction content. They are all on the same team.</li>
<li>From <span class="math">n</span>'s proposer’s perspective, the loss includes the opportunity to propose a beacon block, and from the protocol’s perspective, it results in the loss of one slot worth of consensus liveness.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/c/bceef4d59d54e6590addac9fc886b98f4d419f29.png" title="Screenshot 2024-06-26 at 12.57.48 PM"><img alt="Screenshot 2024-06-26 at 12.57.48 PM" height="225" src="https://ethresear.ch/uploads/default/optimized/3X/b/c/bceef4d59d54e6590addac9fc886b98f4d419f29_2_690x225.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#proposer-ex-anti-attack-10" name="proposer-ex-anti-attack-10"></a>Proposer ex-anti attack</h3>
<p>Let’s move on to the second scenario: the proposer ex-anti attack in ePBS. In this scenario, we will examine the most extreme version where the builder’s Reveal Boost (<span class="math">RB</span>) is leveraged for the ex-anti attack. What does this attack look like?</p>
<p>The proposer of slot <span class="math">n</span> withholds the block and the beacon committee, represented by <span class="math">\delta</span>, withholds the attestations. The attacking builder of slot <span class="math">n</span> releases the payload on time to gain the <span class="math">RB</span>. The ex-anti attack is successful if <span class="math">RB + \delta &gt; PB</span>. However, realistically, the proposer will try to split the beacon committee into portions seen (<span class="math">x</span>) and not seen (<span class="math">1-x</span>). This modifies the equation to <span class="math">RB + x + \delta &gt; PB + 1-x</span>.</p>
<p>Let’s examine the benefits for the attacker in a successful attack:</p>
<ul>
<li>The block at slot <span class="math">n</span> reorgs out slot <span class="math">n+1</span>. Unlike a post-anti attack, the builder of slot <span class="math">n</span> must commit and release the payload on time to gain the <span class="math">RB</span>. Due to this commitment:
<ul>
<li>Even if the attack is successful, it only provides one slot of transactions without leading to more time and more transactions. The proposer of slot <span class="math">n+2</span> benefits here.</li>
<li>It cannot steal slot <span class="math">n+1</span>'s transactions because the payload is pre-committed, leaving nothing to steal from the consensus block.</li>
</ul>
</li>
</ul>
<p>In other words, the ex-anti attack is less valuable than the post-anti attack if we assume the worst-case scenario for both.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/f/0fb72294c98dbb6a1be55419420ebf8144cfaa62.png" title="Screenshot 2024-06-26 at 12.57.58 PM"><img alt="Screenshot 2024-06-26 at 12.57.58 PM" height="263" src="https://ethresear.ch/uploads/default/optimized/3X/0/f/0fb72294c98dbb6a1be55419420ebf8144cfaa62_2_690x263.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#builder-attacks-11" name="builder-attacks-11"></a>Builder attacks</h3>
<p>Finally, let’s move to the last section: proposers of <span class="math">n</span> and <span class="math">n+1</span> collude to attack the builder of <span class="math">n</span>. We will divide this section into two parts. The first part will focus on reorg out the builder’s payload, and the second part will focus on making the payload part of the canonical chain even if the builder chooses to withhold it.</p>
<h4><a class="anchor" href="https://ethresear.ch#payload-reorging-attack-12" name="payload-reorging-attack-12"></a>Payload reorging attack</h4>
<p>Let’s examine the first part. The proposer of slot <span class="math">n</span> releases the block late / attempts to split the beacon committee view, resulting in <span class="math">x</span> beacon committee members voting for the block and <span class="math">1-x</span> not voting for it. The builder reveals the payload on time and gains a <span class="math">RB</span>. The proposer of slot <span class="math">n+1</span> could then reorg the payload by reorg the entire proposer block of slot <span class="math">n</span>, which is more powerful than just reorganizing the payload itself. The attack is successful if <span class="math">PB + 1 - x &gt; RB + x</span>.</p>
<p>What does a successful attack provide to the attacker?</p>
<ul>
<li>Given that proposers of slots <span class="math">n</span> and <span class="math">n+1</span> are colluding, there is no extra slot advantage gained by reorg out the block at slot $n. It is essentially the same as not proposing a block at slot <span class="math">n</span>.</li>
<li>A minor advantage of the collusion between the two proposers is the ability to steal the payload transactions from slot <span class="math">n</span>. This issue is mitigated if transactions are protected by binding them to slot $n. This scenario is known as a next-slot unbundling attack, which differs from same-slot unbundling. Same-slot unbundling is impossible in ePBS.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e50f3d20a2b304825cb05436a2a3e610fbddcf4f.png" title="Screenshot 2024-06-26 at 12.58.35 PM"><img alt="Screenshot 2024-06-26 at 12.58.35 PM" height="210" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e50f3d20a2b304825cb05436a2a3e610fbddcf4f_2_690x210.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#payload-withholding-attack-13" name="payload-withholding-attack-13"></a>Payload withholding attack</h4>
<p>Let’s look at the second part. The proposer of slot <span class="math">n</span> releases the block late or tries to split the beacon committee view, resulting in <span class="math">x</span> beacon committee members voting for the block and <span class="math">1-x</span> not voting for it. The builder withholds the payload on time and gains a Withheld Boost (<span class="math">WB</span>). The proposer of slot <span class="math">n+1</span> could attempt to force the builder to fulfill unconditional payment by making the block at slot <span class="math">n</span> canonical, which from the chain’s perspective, appears as if the builder did not release the payload. The attack is successful if <span class="math">PB + x &gt; WB + 1 - x</span>.</p>
<p>What does a successful attack provide to the attacker?</p>
<ul>
<li>The only plausible scenario for this attack is when the builder is not confident in revealing the payload and hence withholds it. In this case, the proposer of slot <span class="math">n+1</span>, colluding with the proposer of slot <span class="math">n</span>, wants to take the builder’s payment regardless.</li>
<li>Another primary advantage is that the block at slot <span class="math">n+1</span> can contain two slots’ worth of transactions since the builder submits an empty payload by withholding.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/f/5f04c5fc36d5b005e7dcc6c7839e90f40a4a0af7.png" title="Screenshot 2024-06-26 at 12.58.09 PM"><img alt="Screenshot 2024-06-26 at 12.58.09 PM" height="266" src="https://ethresear.ch/uploads/default/optimized/3X/5/f/5f04c5fc36d5b005e7dcc6c7839e90f40a4a0af7_2_690x266.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#boost-numbers-14" name="boost-numbers-14"></a>Boost numbers</h3>
<p>Finally, let’s summarize the equations for each worst-case attack scenario if the attacker wins:</p>
<ol>
<li><strong>Proposers post-anti attack</strong>: <span class="math">WB + PB + \delta &gt; 1 - \delta</span></li>
<li><strong>Proposers ex-anti attack</strong>: <span class="math">RB + x + \delta &gt; PB + 1 - x</span></li>
<li><strong>Builder reorg payload attack</strong>: <span class="math">PB + 1 - x &gt; RB + x</span></li>
<li><strong>Builder withhold payload attack</strong>: <span class="math">PB + x &gt; WB + 1 - x</span></li>
</ol>
<p>Overall, we can derive that the parameters are approximately <span class="math">PB = 20\%</span>, <span class="math">WB = 40\%</span>, <span class="math">RB = 40\%</span>, and <span class="math">\delta = 20\%</span>. This means we can tolerate a malicious beacon committee up to 20%, whereas today, this tolerance is 40%.</p>
<p>The real question to ask is whether the worst-case scenario of a 20% attack even makes sense, as in the ex-anti attack, the builder must release the payload to perform the attack. Nevertheless, it certainly represents a degradation in fork choice. A 20% attack is significantly more dangerous in the post-anti attack than in the ex-anti attack due to the additional time available.</p>
<p>Something we haven’t analyzed here is how multi-slot liveness may play a role in this context. Given (block, slot) voting and under worse network asynchrony conditions, we may experience prolonged empty slots, making recovery difficult. Solutions like a backoff scheme have been proposed, which require further thought and analysis.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 14:24:34 +0000</pubDate>
</item>
<item>
<title>P2P ZK Light Client Bridge between Tron and Ethereum L2s</title>
<link>https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931</link>
<guid>https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931</guid>
<content:encoded><![CDATA[
<div> 关键词：Tron USDT、Ethereum L2、Zero-knowledge proofs、Cross-chain bridge、Decentralization

总结:<br />
这篇文章讨论了Tron网络上的USDT在第三世界国家的广泛应用，但其高度中心化的控制导致高额交易费和生态系统孤立。为解决这些问题，作者提出了一种设计，即利用零知识轻验证的跨链桥，将USDT TRC20与以太坊L2网络低成本连接起来。这种设计旨在减少交易费用、促进去中心化并增强两个生态系统的流动性。通过零知识证明确保交易安全，同时简化用户操作，使得从Tron无缝接入Ethereum成为可能，从而降低集中风险并推动全球去中心化金融基础设施的发展。 <div>
<p><em>By <a href="https://x.com/alexhooketh" rel="noopener nofollow ugc">Alex Hook</a>. Thanks to these people for inspiration, feedback and suggestions: <a href="https://x.com/alexanderchopan" rel="noopener nofollow ugc">accountless.eth</a>, <a href="https://x.com/pseudotheos" rel="noopener nofollow ugc">pseudotheos</a>, <a href="https://x.com/domothy" rel="noopener nofollow ugc">Domothy</a>, <a href="https://x.com/DoganEth" rel="noopener nofollow ugc">Dogan Alpaslan</a>, <a href="https://zkp2p.xyz" rel="noopener nofollow ugc">ZKP2P team</a></em></p>
<hr />
<p><strong>Abstract.</strong> USDT on the Tron Network has emerged as a dominant crypto application in the Third World countries. However, the current cartelized control of the Tron Network results in elevated transaction fees, capital concentration, and an ecosystem isolated from other crypto networks. We propose a design for a cost-effective, peer-to-peer bridge from USDT TRC20 to Ethereum L2 networks, utilizing zero-knowledge light verification of the Tron blockchain.</p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>According to <a href="https://tokenterminal.com/terminal/datasets/stablecoins" rel="noopener nofollow ugc">Token Terminal</a>, USDT on Tron has achieved preeminence by several metrics, including outstanding supply, 30d transfer volume, number of transfers, and number of holders. At the time of writing, the second place by volume, DAI on Ethereum, has only ~20% less volume than it, but two orders of magnitude fewer holders and number of transfers. The second place by number of transfers, USDC on Base, has 5x fewer transfers.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/4/6476c0c44ca7866bfea5a4f35205a47fa7c74204.png" title="Screenshot 2024-06-27 at 8.00.11 PM"><img alt="Screenshot 2024-06-27 at 8.00.11 PM" height="459" src="https://ethresear.ch/uploads/default/optimized/3X/6/4/6476c0c44ca7866bfea5a4f35205a47fa7c74204_2_690x459.png" width="690" /></a></div><p></p>
<p>This shows Tron USDT’s monstrous levels of payment usage among individuals. Unsurprising—Tron team has done an extensive advertisement campaign for its payment solution in Africa and Latin America. Shortly after, the network effect spread it to the developing countries in Asia and Post-Soviet area.</p>
<p>If we look at the areas of the largest prevalence of Tron USDT, a noteworthy pattern can be noticed. Tron USDT is largely used in the countries with weak economies and unsustainable local currencies: Türkiye, Lebanon, Zimbabwe, Venezuela, Argentina, and more. In these countries, traditional banking doesn’t provide people with options for reliable store of value and means of payment, as local currencies are unreliable, and foreign currencies are either banned for payment use or subject to strict control.</p>
<h3><a class="anchor" href="https://ethresear.ch#problems-2" name="problems-2"></a>Problems</h3>
<p>It is fair to say that USDT on Tron is one of the largest crypto applications by usage today. Millions of people around the world are interacting with it every day. It’s massively used as a store of value, acts as a medium of exchange in isolated economies such as Northern Cyprus, Cuba, and Vietnam. <a href="https://mirror.xyz/0x8958D0c419BCDFB8A86b8c0089552bE015fbe364/ODhOuYjK80atc9_jGprXotSo3PNobT1PRLFtorXHBrA" rel="noopener nofollow ugc">Local P2P platforms are building their infrastructure around USDT on Tron</a>. However, its dominance presents certain challenges for the broader Web3 community:</p>
<ul>
<li>
<p><em>A primary concern is the high degree of centralization</em> within the Tron Network. <a href="https://github.com/alexhooketh/tron-light-client/blob/cc3e037c5b71ba5e6216c8d19fee4dfe9d254e69/README.md" rel="noopener nofollow ugc">According to our research</a>, over the past 250 days there were only 28 unique block producers. The same entities are constantly winning the DPoS election due to delegations from the largest TRX holders. Most of these Super Representatives (block producers in Tron) <a href="https://tronscan.org/#/sr/representatives" rel="noopener nofollow ugc">lack any public information</a> beyond their status as block producers.</p>
</li>
<li>
<p>Despite this centralization, <em>transaction fees on Tron remain among the highest in crypto</em>—<a href="https://developers.tron.network/docs/resource-model#energy" rel="noopener nofollow ugc">420 sun</a> (1 sun = 1e-6 TRX) per gas. At the <a href="https://coinmarketcap.com/currencies/tron/" rel="noopener nofollow ugc">TRX’s price of ~0.000035 ETH</a>, this roughly corresponds to Ethereum L1’s gas price of 14.7 gwei. The usual fee for USDT transfers in Tron is <strong>$1-1.5 in TRX</strong>, rendering small transfers barely economical. However, the usage is still very high, as Tron’s ecosystem is isolated and there’s no convenient way to interact with other ecosystems from it.</p>
</li>
</ul>
<p>In contrast, the Ethereum ecosystem continues to thrive. Following the Dencun upgrade, transaction fees on rollups have drastically decreased to <a href="https://www.growthepie.xyz/fundamentals/transaction-costs" rel="noopener nofollow ugc">less than a cent</a> per ERC20 transfer. Combined with L2s, Ethereum DeFi <a href="https://defillama.com/chains" rel="noopener nofollow ugc">now comprises &gt;80% of the entire DeFi TVL</a>. <a href="https://l2beat.com/scaling/activity" rel="noopener nofollow ugc">Rollups alone consistently handle upwards of 100 TPS</a>, <a href="https://mirror.xyz/alexhook.eth/y9PTlM6tVr0H8X68r1LV2UwAnT9D6u1MEEiUFvcpyG0" rel="noopener nofollow ugc">with theoretical limits of 400-800 TPS</a> depending on the specific rollup. OP Mainnet has upgraded to Stage 1 trustlessness with all OP Chains and ZKsync catching up this summer. Arbitrum is working towards Stage 2.</p>
<p>People in developed countries are already integrated with Ethereum. By allowing ones from developing countries to seamlessly move into it from Tron, we can unite these disparate ecosystems and mitigate the risks associated with increasing centralization and monopolization of Sun’s machine.</p>
<h1><a class="anchor" href="https://ethresear.ch#rationale-3" name="rationale-3"></a>Rationale</h1>
<p>The protocol for cross-chain transfers from Tron should ideally possess the following characteristics:</p>
<ul>
<li><strong>Trust-minimized:</strong> The system should preclude the provision of incorrect information about the Tron blockchain or the theft of locked funds, except in the event of an attack on Tron’s consensus. In such a case, the security council authorized to stop the system can be established.</li>
<li><strong>Permissionless liquidity supply:</strong> The protocol should allow any entity to provide liquidity at their preferred rate. This fosters fair competition among providers, potentially resulting in more favorable and flexible exchange rates based on order size.</li>
<li><strong>Permissionless operation:</strong> While a centralized relay for light client updates and order fulfillment is acceptable, provided there exists a self-proposing mechanism in case of liveness failure, the relay must not serve as a source of trust. When feasible, on-chain operations should be implemented instead (e.g., a paymaster for gasless order claims).</li>
<li><strong>As simple as possible from the Tron side:</strong> Gas fees on Tron are extremely high, so it may be not affordable for users to execute more than necessary on-chain. Moreover, USDT Tron users are mostly using wallets such as Trust Wallet, Exodus, hardware wallets, and local exchange accounts, that do not support contract calls or token approvals. The only Tron wallet with these features, TronLink, is not common among USDT Tron users.</li>
<li><strong>Reasonably cheap on the destination side:</strong> Zero-knowledge proofs should be employed where possible to minimize costs. While the system can be more extensive than on the Tron side, it should still be optimized to keep user claim costs low.</li>
<li><strong>Single liquidity hub with enshrined bridging:</strong> The protocol should be deployed on a single L2 network to prevent liquidity fragmentation. To mitigate protocol isolation, cross-chain token bridges can be integrated at the UI level, <a href="https://zkp2p.xyz/send" rel="noopener nofollow ugc">similarly to ZKP2P</a>.</li>
<li><strong>USDC-native:</strong> Given USDC’s prevalence in the Ethereum ecosystem, the protocol can be based on USDC, effectively providing USDT-USDC swaps. However, USDC is virtually unknown in areas of extensive USDT Tron usage, so this difference should be addressed on UX level to reduce user distrust.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#trons-consensus-and-protocol-101-4" name="trons-consensus-and-protocol-101-4"></a>Tron’s consensus and protocol 101</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/1/81e8ead1ee5585f245d51ac55f4f1db43f3785d2.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/1/81e8ead1ee5585f245d51ac55f4f1db43f3785d2_2_540x500.png" width="540" /></a></div><p></p>
<p>Every 6 hours (7200 blocks), network participants delegate their TRX to validator candidates. The 27 candidates accumulating the most votes are elected as Super Representatives (SRs), who are then responsible for block production. Block producer selection follows a deterministic round-robin pattern. A block is considered finalized after receiving 18 confirmations, 2/3 of the SR set.</p>
<p>The block production is an ECDSA signature over the SHA256 hash of the protobuf-encoded block header. That is, one block = one signature. The top 128 representatives, beyond the 27 SRs, are designated as Super Representative Partners, voting on blocks produced by SRs. However, <a href="https://developers.tron.network/docs/concensus#block-generation-mechanism" rel="noopener nofollow ugc">as producers are predictable and the longest-chain rule is applied</a>, there is no necessity in validating votes.</p>
<p>Block header consists of the following elements:</p>
<pre><code class="lang-auto">message BlockHeader {
  message raw {
    int64 timestamp = 1;
    bytes txTrieRoot = 2;
    bytes parentHash = 3;
    int64 number = 7;
    bytes witness_address = 9;
    int32 version = 10;
  }
  raw raw_data = 1;
  bytes witness_signature = 2;
}
</code></pre>
<p>Even though state root is formally specified in the protocol, it’s not added to the header. We assume this is for backward-compatibility purposes, as the current version of Tron Network does not merkleize state.</p>
<p>The signature is made over a SHA256 hash of the serialized <code>raw_data</code> element. That is, by utilizing light verification, we can access only one transaction-specific element—the Merkle root of the transaction tree. However, in Tron, transactions carry their execution status, so we don’t need to access the state to validate the success of one-transaction operations, such as TRC20 transfer().</p>
<pre><code class="lang-auto">message Transaction {
  ...
  message Result {
    enum code {
      SUCESS = 0;
      FAILED = 1;
    }
    enum contractResult {
      DEFAULT = 0;
      SUCCESS = 1;
      REVERT = 2;
      BAD_JUMP_DESTINATION = 3;
      OUT_OF_MEMORY = 4;
      PRECOMPILED_CONTRACT = 5;
      STACK_TOO_SMALL = 6;
      STACK_TOO_LARGE = 7;
      ILLEGAL_OPERATION = 8;
      STACK_OVERFLOW = 9;
      OUT_OF_ENERGY = 10;
      OUT_OF_TIME = 11;
      JVM_STACK_OVER_FLOW = 12;
      UNKNOWN = 13;
      TRANSFER_FAILED = 14;
      INVALID_CODE = 15;
    }
    int64 fee = 1;
    code ret = 2;
    contractResult contractRet = 3;
    ...
}
</code></pre>
<p>Votes for witnesses (representatives) are of a specific transaction type. This means that in order to calculate the votes, the light client has to download all transactions and re-execute ones of this type.</p>
<pre><code class="lang-auto">message Transaction {
  message Contract {
    enum ContractType {
      ...
      VoteWitnessContract = 4;
      ...
}
</code></pre>
<p>However, considering the fact that the SR set is almost static, we believe that it would be computationally cheaper to delegate choosing the canonical set to DAO or enshrine the set into the circuit.</p>
<p>Normal contract calls, such as TRC20 transfer, have the <code>TriggerSmartContract</code> type and are nearly identical to ERC20 transactions. This means that we can prove the USDT transfer on Tron network using only the transaction root, which can be safely accessed on-chain using ZK light client relay.</p>
<h1><a class="anchor" href="https://ethresear.ch#design-proposal-5" name="design-proposal-5"></a>Design proposal</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b4b8d0d74dfe0a7dd5991bce974eac97c8621fc.jpeg" title="image"><img alt="image" height="402" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b4b8d0d74dfe0a7dd5991bce974eac97c8621fc_2_690x402.jpeg" width="690" /></a></div><p></p>
<p>The proposed cross-chain swap mechanism involves three primary entities: the <em>User</em>, the <em>Buyer</em> (or liquidity provider), and the <em>Relayer</em>. The process unfolds as follows:</p>
<ol>
<li>
<p><em>The Buyer</em> locks USDC into the swap contract on the L2, specifying their exchange rate and Tron address for transfers.</p>
</li>
<li>
<p><em>The User</em> selects a <em>Buyer</em> offering the most favorable rate with sufficient liquidity. <em>The User</em> then initiates a transaction on the L2 to temporarily lock a portion of the <em>Buyer’s</em> USDC. This step prevents liquidity depletion before order fulfillment. If supported by the L2, this transaction may be funded by a paymaster.</p>
</li>
<li>
<p><em>The User</em> transfers the corresponding amount of Tron USDT to the <em>Buyer’s</em> specified address.</p>
</li>
<li>
<p>Following 18 block confirmations (~54 seconds, ensuring finality), the <em>Relayer</em> retrieves the latest Tron block headers and generates a ZK proof to them. The circuit for light verification must contain the transaction root from the header as the public input so that it’s known to the relay contract. This proof is needed to efficiently prove the new Tron blocks and their transaction roots <em>to the relay contract</em>.</p>
</li>
<li>
<p><em>The Relayer</em> obtains the finalized transaction from the Tron blockchain and generates a zero-knowledge proof of transaction inclusion against the transaction root. This proof is needed to efficiently prove the order fulfillment <em>to the swap contract</em>. Just like light client proofs, transaction proofs can be aggregated to minimize the costs of on-chain proof verification.</p>
</li>
<li>
<p><em>The Relayer</em> submits these proofs to the respective smart contracts on the L2. Upon verification, the swap contract releases the funds to the <em>User</em> and allocates a small portion to the <em>Relayer</em> as compensation. In case of liveness failure, the <em>User</em> can generate and relay proofs themselves, removing the need for relayer fees.</p>
</li>
<li>
<p><em>The Buyer</em> can exchange their acquired Tron USDT for USDC on the L2 through various means, including direct 1:1 exchange with issuers, and reinvest in the swap contract.</p>
</li>
</ol>
<p>This system streamlines the user experience to just two primary actions: committing to the order on the destination chain and transferring Tron USDT to a specified address. The User receives the equivalent USDC on the L2 within approximately one minute. This system can even be used to accept payments in USDT Tron, requiring only a web browser with a connected wallet for order creation.</p>
<p>For Buyers, liquidity provision is fully automated. They create a Tron wallet, and supply USDC with specified Tron address to the smart contract. When their liquidity is out, it is automatically removed. Received USDT can be spent and exchanged back to USDC at any time. This system is expected to provide higher exchange rates than the existing P2P platforms, as the rate is competitive and there’s no need to cover the costs of KYC and other web2-specific processes.</p>
<p>Relayers require only a server running relayer and ZK prover software. As relayers do not serve as the source of trust, this role can be either permissionless or delegated to the development team, provided self-proposing functionality is supported.</p>
<h1><a class="anchor" href="https://ethresear.ch#zk-light-client-poc-6" name="zk-light-client-poc-6"></a>ZK Light Client PoC</h1>
<p>We’ve written a proof-of-concept of ZK light verification of Tron blocks in Noir language. It receives the previous and new block IDs with a transaction root as the public input, and the block header as the private input. It does not implement round-robin checks and election mechanism for efficiency purposes, and the SR set is hardcoded into the circuit. The proof is generated in about 35 seconds on an M1 machine.</p>
<p>For the production version of this system, it may be necessary to rewrite the circuits to STARK-based proof systems and/or implement GPU proving to improve proving speed.</p>
<p>The source code can be found here: <a class="inline-onebox" href="https://github.com/alexhooketh/zktron" rel="noopener nofollow ugc">GitHub - alexhooketh/zktron: ZK light client for Tron Network written in Noir</a></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-7" name="conclusion-7"></a>Conclusion</h1>
<p>The proposed P2P ZK Light Client Bridge between Tron and Ethereum L2s is a significant advancement in addressing the problems of Tron Network in a Web3 way. By leveraging zero-knowledge proofs and efficient light client verification, this system offers a trust-minimized, permissionless, and cost-effective solution for bridging the gap between these two prominent blockchain ecosystems.</p>
<p>This bridge design addresses several key challenges:</p>
<ol>
<li>It mitigates the risks associated with the centralization of the Tron Network by providing users with seamless access to the more decentralized and robust Ethereum ecosystem.</li>
<li>It significantly reduces transaction costs for users, particularly benefiting those in developing economies who rely heavily on USDT for daily transactions and value storage.</li>
<li>It enhances liquidity and interoperability between Tron and Ethereum, expanding Ethereum ecosystem to the areas of extensive Tron usage.</li>
<li>It maintains a high level of security through the use of ZK proofs, ensuring the integrity of cross-chain transactions without compromising on efficiency.</li>
</ol>
<p>By bridging these ecosystems, we can solve the problem of increasing influence of Tron, taking a significant step towards realizing the vision of a truly global, decentralized financial infrastructure that can benefit users across all economic backgrounds.</p>
<p>We welcome feedback and questions from the community. Feel free to leave your comments, suggestions, or inquiries in the comments section below. <strong>Thank you for reading.</strong></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 20:03:10 +0000</pubDate>
</item>
<item>
<title>Orbit SSF: solo-staking-friendly validator set management for SSF</title>
<link>https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928</link>
<guid>https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928</guid>
<content:encoded><![CDATA[
<p><em>Much of the post came together during a week of in-person whiteboarding with <a href="https://rig.ethereum.org" rel="noopener nofollow ugc">RIG</a> and wannabe RIGs like myself, Ansgar and Toni. Thanks in particular to <a href="https://twitter.com/weboftrees" rel="noopener nofollow ugc">Anders</a>, <a href="https://twitter.com/adietrichs" rel="noopener nofollow ugc">Ansgar</a>, <a href="https://twitter.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://twitter.com/soispoke" rel="noopener nofollow ugc">Thomas</a> for continued discussions and feedback, again to Anders for most of the ideas around individual incentives, and again to Barnabé for the diagrams about finality. The core idea that the post explores was originally proposed by Vitalik in <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">this post</a></em>.</p>
<h2><a class="anchor" href="https://ethresear.ch#where-we-are-1" name="where-we-are-1"></a>Where we are</h2>
<p>The <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality" rel="noopener nofollow ugc">Single Slot Finality (SSF) roadmap</a> has <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#What-are-the-key-questions-we-need-to-solve-to-implement-single-slot-finality" rel="noopener nofollow ugc">three main components</a>:</p>
<ul>
<li>Consensus algorithm</li>
<li>Signature aggregation</li>
<li>Validator set economics</li>
</ul>
<p>Since the previously linked post, there has been a lot of progress on the consensus algorithm side, with <a href="https://ethresear.ch/t/a-simple-single-slot-finality-protocol/14920">multiple</a> <a href="https://arxiv.org/abs/2310.11331" rel="noopener nofollow ugc">candidate</a> <a href="https://notes.ethereum.org/@fradamt/chained-3sf" rel="noopener nofollow ugc">protocols</a> and <a href="https://github.com/fradamt/ssf/tree/main/high_level" rel="noopener nofollow ugc">the beginning of a specification effort</a>. There have also been some effort to explore the design space of signature aggregation, both with a <a href="https://ethresear.ch/t/horn-collecting-signatures-for-faster-finality/14219">networking</a> <a href="https://ethresear.ch/t/flooding-protocol-for-collecting-attestations-in-a-single-slot/17553">focus</a> and a <a href="https://ethresear.ch/t/signature-merging-for-large-scale-consensus/17386">cryptographic focus</a>. Still, we are likely not close to being able to reliably aggregate millions of signatures per slot, without increasing the slot time or validator requirements significantly. On the staking economics side, there has been lots of work over the last year, but for the most part focused on understanding <a href="https://mirror.xyz/barnabe.eth/v7W2CsSVYW6I_9bbHFDqvqShQ6gTX3weAtwkaVAzAL4" rel="noopener nofollow ugc">liquid staking</a> and <a href="https://mirror.xyz/barnabe.eth/96MD_A194uXLLjcOWePW3O2N3P-JG-SHtNxU0b40o50" rel="noopener nofollow ugc">restaking</a>, and on <em>stake</em> capping, i.e., constraining the amount of ETH staked (if you’re reading this, you’re probably already at least at a surface level familiar with the issuance conversation, in which case you might want to dig deeper and check out these posts <a href="https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/1">[1]</a> <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">[2]</a>). Here, we are instead interested in <em>validator capping</em>, i.e., constraining the amount of validator identities in the system, or at least the ones actively participating at any given time, to satisfy technical constraints. Some ideas in this direction can be found in this <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#what-would-8192-signatures-per-slot-under-ssf-look-like-2">recent post</a>, and in fact <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">approach 3</a> from the post provides the foundation for this post. Moreover, a recent important development is that <a href="https://eips.ethereum.org/EIPS/eip-7251" rel="noopener nofollow ugc">EIP-7251 (MaxEB)</a> has been included in the <a href="https://github.com/ethereum/consensus-specs/blob/a3a6c916b236c9e8904090303f0c38ae49db1002/specs/electra/beacon-chain.md" rel="noopener nofollow ugc">Electra fork</a>. Validator effective balances will be allowed to be as high as 2048 ETH, enabling staking pools to <a href="https://notes.ethereum.org/@fradamt/maxeb-consolidation" rel="noopener nofollow ugc">consolidate their validators</a>, a new capability which we can leverage in our designs.</p>

<h2><a class="anchor" href="https://ethresear.ch#goals-2" name="goals-2"></a>Goals</h2>
<p>With the goal of finding a design which can make its way into the protocol in a reasonable timeline, we are here going to focus on solutions that <em>do not</em> rely on large improvements in the signature aggregation process. We also do not think it is very realistic to propose significant increases of the slot time, which have many externalities. Given these technical constraints, let’s focus on a minimal set of properties that we ideally want to achieve:</p>
<ul>
<li><strong>Validator capping</strong>: at most <span class="math">N</span> <em>active</em> validators at a time. For example, <span class="math">N = 2^{15} \approx 32k</span>, which we know we can handle because it is the size of a committee today. If we wanted to completely remove attestation aggregation, we would likely need to drop this number to a few thousands.</li>
<li><strong>Solo staking viability</strong>: staking with 32 ETH is <em>guaranteed</em> to still be possible, <em>and</em> the solo staking yield should still not compare unfavorably to delegated staking yields.</li>
<li><strong>High eventual economic security</strong>: More than <span class="math">D_f</span> stake provides economic security, at least <em>eventually</em>. For example <span class="math">D_f = 20M</span> ETH. Ideally, we also do not have to wait longer than today for it (two epochs).</li>
<li><strong>Fast finality</strong>: at least <em>some</em> amount of economic security is available shortly after a block is proposed (think: 10 to 30 seconds, not over 10 minutes).</li>
<li><strong>Optimally secure consensus protocol</strong>: the consensus protocol is (provably) resilient to ~1/2 adversaries under network synchrony, and 1/3 under partial synchrony.</li>
</ul>
<p>Without solo staking viability as defined here, we could simply raise the minimum balance, or go with approaches that allow for a low minimum balance but do not <em>guarantee</em> it, for example in the face of large stakers intentionally splitting their stake. Such solutions would likely have to lean on <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-1-go-all-in-on-decentralized-staking-pools-3">decentralized staking pools</a> or <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-2-two-tiered-staking-4">two-tier staking</a> to preserve the accessible nature of staking as it is today, or perhaps even to carve out a more tailored role for smaller stakers, as is suggested by <a href="https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683">rainbow staking</a>. While there is merit to these approaches and we believe they (and more generally the role of solo staking/broad consensus participation) deserve further exploration, we are choosing here to only explore designs that are compatible with this narrow interpretation of solo staking viability.</p>
<h2><a class="anchor" href="https://ethresear.ch#overview-of-approaches-3" name="overview-of-approaches-3"></a>Overview of approaches</h2>
<p>Validator capping, solo staking viability and high economic security immediately raise an issue: high economic security requires millions of ETH to participate in finalizing and a minimum balance of 32 ETH then implies a worst case of hundreds of thousands or millions of validators (~1M at the time of writing), which seems to conflict with validator capping. There are two main classes of approaches that attempt to deal with this problem:</p>
<ul>
<li><strong>Validator set rotation</strong>: the full validator set is allowed to be large, but only a subset is actively participating at any given time.</li>
<li><strong>Economic validator set capping</strong>: the size of the full validator set is constrained through economic incentives. To <em>guarantee</em> a small validator set size we can for example <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-validator-count" rel="noopener nofollow ugc">reduce issuance past the target validator count</a>. However, this leaves all stakers open to a cheap griefing attack, where a small amount of stake can have a disproportionate negative impact on issuance.</li>
</ul>
<p>In this post we are not going to focus on the latter approach <em>in isolation</em>, but we are going to propose a way to combine economic incentives with a form of validator set rotation.</p>
<h2><a class="anchor" href="https://ethresear.ch#validator-set-rotation-4" name="validator-set-rotation-4"></a>Validator set rotation</h2>
<p>The current protocol also has to deal with the issue we have outlined in the previous section, and the chosen “solution” is precisely validator set rotation: only 1/32 of the validator set votes in any given slot. This design <a href="https://notes.ethereum.org/@vbuterin/serenity_design_rationale#Why-32-ETH-validator-sizes" rel="noopener nofollow ugc">trades off finality time</a>, and fails to satisfy our desired property of fast finality.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/83646288afbace1b452239618b34e83319531d0a.png" title=""><img alt="" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/8/3/83646288afbace1b452239618b34e83319531d0a_2_690x388.png" width="690" /></a></div><p></p>
<p>Let’s then explore whether we can use validator set rotation without giving up on fast finality or other properties.</p>
<h3><a class="anchor" href="https://ethresear.ch#fast-rotation-5" name="fast-rotation-5"></a>Fast rotation</h3>
<p>One way to go about validator set rotation is to have committees which rotate fast, as in the current protocol. In order to avoid a high time-to-finality, we can use a different consensus protocol allowing for <a href="https://ethresear.ch/t/a-model-for-cumulative-committee-based-finality/10259">committee-based finality</a>, i.e., such that even a committee can provide economic security proportional to its stake. In fact, the post linked above deals with <em>cumulative</em> committee-based finality, where the consensus protocol even allows for accumulation of economic security over multiple finalizations, such that <span class="math">k</span> committees finalizing in a row results in <span class="math">k</span> times the economic security that a single committee can provide. We get two birds with one stone, getting both fast (partial) finality and full <em>eventual</em> economic security. In particular, we could have full finality <em>in the same time as today</em> (which gives enough time for each committee to do its own finalization by voting twice), but with the big improvement that economic security accrues every slot, rather than all at once after two epochs.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/6/b6816fefcf5021bb672ed76029c844d1f311047d.png" title=""><img alt="" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/b/6/b6816fefcf5021bb672ed76029c844d1f311047d_2_690x388.png" width="690" /></a></div><p></p>
<p>This seems like a clear improvement on today’s protocol, so why are we not just doing it? An answer comes from the consensus protocol design space: it is not clear at this point how to have an optimally secure dynamically available protocol with <em>fast</em> rotating committees. In fact, much of the problems with the LMD-GHOST component of today’s protocol, or at least the <a href="https://ethresear.ch/t/reorg-resilience-and-security-in-post-ssf-lmd-ghost/14164#introduction-2">fundamental ones</a>, come precisely from the interaction of multiple committees. In short, an adversary can accumulate weight across multiple committees, and use it to reorg honest blocks that have a single committee supporting them.</p>
<p>For interested readers, there actually are optimally secure dynamically available consensus protocols that allow for committees (<a href="https://arxiv.org/abs/2209.03255" rel="noopener nofollow ugc">[1]</a> <a href="https://eprint.iacr.org/2022/1448.pdf" rel="noopener nofollow ugc">[2]</a> for example), but all known ones suffer from catastrophic failures under even short-lived asynchrony (<a href="https://arxiv.org/abs/2302.11326" rel="noopener nofollow ugc">[1]</a> <a href="https://arxiv.org/abs/2309.05347" rel="noopener nofollow ugc">[2]</a>). It is not known whether this is a fundamental limitation, but at least so far we do not know any protocol that gets around it.</p>
<h3><a class="anchor" href="https://ethresear.ch#slow-rotation-6" name="slow-rotation-6"></a>Slow rotation</h3>
<p>There is however a simple way to avoid the problem altogether: giving up on <em>fast</em> committee rotation, and instead having a committee which rotates out slowly, for example by replacing a small percentage of it every slot. The upshot is that such a committee effectively acts as a full validator set, in the sense that its actions do not interact with those of other committees, as would be the case with fast rotation. We can in principle take any protocol that works when the whole validator set is able to participate at once, and make it work with this mechanism by slowing down the rotation sufficiently.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/c/4c21c0ca0871b1e7c6440325b3a3174df016793f.png" title=""><img alt="" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/4/c/4c21c0ca0871b1e7c6440325b3a3174df016793f_2_690x389.png" width="690" /></a></div><p></p>
<p>At a first glance, one obvious downside is that a full rotation of the validator set would be much slower than today, and thus so would finality. However, we could do things a bit differently, by decoupling the committee which votes for the available chain (LMD-GHOST votes) from those which vote for finality (Casper FFG votes). Only LMD-GHOST has problems with fast committee rotation, so we could have a slowly rotating committee whose votes count for LMD-GHOST and in parallel also fast rotating committees whose votes accumulate economic security over time, up to full finality in no more than today’s two epochs.</p>
<p>Besides some amount of extra complexity in the consensus protocol, one remaining downside is that we leave a single committee “in charge” of LMD-GHOST for extended periods of time. Moreover, while linearly accumulating finality is a strict improvement over today’s step function finality, we do not achieve something even stronger, namely getting a high level of economic security immediately. This is of course impossible to achieve given the constraints we have laid out, <em>unless we make some assumptions about the stake distribution</em>, for example that it is <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#The-good-news-gains-from-enabling-voluntary-validator-balance-consolidation" rel="noopener nofollow ugc">Zipfian</a>, or anyway such that a large portion of the stake is concentrated in the first few thousand entities.</p>

<h2><a class="anchor" href="https://ethresear.ch#orbit-ssf-stable-core-rotating-periphery-7" name="orbit-ssf-stable-core-rotating-periphery-7"></a>Orbit SSF: Stable core, rotating periphery</h2>
<p>Our starting point is <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">approach 3 from this post</a>, where validators are (roughly) sampled by balance, so that validators with a lot of stake are always in the validator set. Contrast this with the previously considered validator set rotation approaches where validators were (implicitly) sampled by indices, as we do today, which results in each committee having small weight regardless of what the stake distribution looks like.</p>
<p>We then consider adding consolidation incentives, to have stronger guarantees about the level of finality that we can reach with a single committee. The rotating parts of the committee can then rotate slowly, and we do not need to take on the extra consensus complexity of decoupling voting for the available chain and for the finality gadget. Moreover, there is never a small committee (in terms of stake) in charge of a critical consensus component: at all times, we can expect the active validator set to hold a meaningful fraction of the whole stake.</p>
<h3><a class="anchor" href="https://ethresear.ch#active-validator-set-management-8" name="active-validator-set-management-8"></a>Active validator set management</h3>
<p>There are two key components here:</p>
<ul>
<li><em>Active validator set selection</em>: We set a stake threshold <span class="math">T</span> (in principle it could also be set dynamically), and then define the probability of validator with stake <span class="math">S</span> to be sampled in the active set to be <span class="math">p(S) = \min(\frac{S}{T}, 1) = 
\begin{cases}
\frac{S}{T} &amp; S \le T \\ 
1 &amp; S \ge T 
\end{cases}</span><br />
A validator with stake <span class="math">S \le T</span> is selected with probability <span class="math">\frac{S}{T}</span> proportional to its stake, whereas validators with stake <span class="math">S \ge T</span> are <em>always</em> in the validator set. The idea here is of course that it is helpful to have a stable core of large validators always in the active set, because they contribute a lot of economic security but still only add the same load as any other validator.</li>
<li><em>Reward adjustment</em>: We adjust attestation rewards so that all validators still get compensated proportionally to their stake, regardless of whether they fall below or above the threshold <span class="math">T</span>. To define the reward function, we take as reference the maximum attestation reward <span class="math">R</span> that the protocol gives to a validator with stake <span class="math">T</span>, for a single attestation (<span class="math">R</span> can of course vary depending on the overall issuance level). Given <span class="math">R</span>, the maximum reward for an attestation by a validator with stake <span class="math">S</span> is <span class="math">r(S) = R\cdot\max(1, \frac{S}{T}) = 
\begin{cases} 
R &amp; S \le T \\
R \cdot \frac{S}{T} &amp;S \ge T
\end{cases}</span><br />
Overall, the <em>expected</em> rewards of a validator with stake <span class="math">S</span> are then <span class="math">p(S)\cdot r(S) = R\cdot\frac{S}{T} = \frac{R}{T} \cdot S</span>. In other words, <span class="math">\frac{R}{T}</span> per unit of stake, regardless of how it is distributed.  To help visualize this, here’s a plot of <span class="math">p(S)</span>, <span class="math">r(S)</span> and <span class="math">p(S)\cdot r(S)</span>, for <span class="math">R = 2</span> (arbitrary value just for the plot) and <span class="math">T = 1024</span>. Validators with less than <span class="math">T</span> stake do have higher variance, because they only participate <span class="math">\frac{S}{T}</span> of the time, but over longer periods of time the variance will still very low, since attestation rewards are constant and very frequent.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/9/69e8f45397940a38df6d146660314fa29c2f790c.png" title=""><img alt="" height="355" src="https://ethresear.ch/uploads/default/optimized/3X/6/9/69e8f45397940a38df6d146660314fa29c2f790c_2_690x355.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#validator-capping-9" name="validator-capping-9"></a>Validator capping</h4>
<p>We can easily compute the expected size of an active validator set <span class="math">V_a</span> that is sampled this way from a full validator set <span class="math">V</span> whose total deposit size is <span class="math">D</span>:<br />
<span class="math">\mathbb{E}[|V_a|] = \sum_{i \in V} p(S_i) = \sum_{i \in V} \min(\frac{S_i}{T}, 1) = \frac{1}{T}\sum_{i \in V} \min(S_i, T) \le \frac{1}{T}\sum_{i \in V} S_i = \frac{D}{T}</span></p>
<p>Basically, any validator with stake <span class="math">S \le T</span> contributes exactly <span class="math">\frac{S}{T}</span> to the expectation. Crucially, these contribution scale linearly in <span class="math">S</span>: the only effect of splitting up to <span class="math">T</span> stake into small validators is to increase the variance of the active validator set size, without affecting the expectation. As for validators with stake <span class="math">S &gt; T</span>, they even decrease the expectation compared to the worst case, which is <span class="math">\frac{D}{T}</span>, equal to the full validator set size if all validators had <span class="math">T</span> stake.</p>
<p>For example, we can set <span class="math">T = 4096</span> ETH, giving us a <em>maximum</em> expected active validator set size of <span class="math">\frac{120M}{4096} \approx 30k</span>. If we were to employ stake capping (we will later discuss how to do so in this context) to ensure (or have high assurances) that <span class="math">D</span> is bounded by (for example) <span class="math">2^{25}M</span> ETH, we could even set <span class="math">T = 1024</span> and still have an expected active validator set size of at most ~32k. There can of course be deviations from this expected size, but with high probability the actual active validator set size would always fall within reasonably narrow bounds, so we can have very strong guarantees about the maximum load that we would need to be able to handle. We look at this in more detail <a href="https://ethresear.ch#Validator-capping-active-validator-set-variance">in the appendix</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#incentivizing-consolidation-10" name="incentivizing-consolidation-10"></a>Incentivizing consolidation</h3>
<p>Let <span class="math">D_a</span> be the active deposit size, i.e., the total stake of the active validator set, contrasted with the total deposit size <span class="math">D</span>, the stake of the whole validator set. Optimistically, as long as there is sufficient consolidation, <span class="math">D_a</span> will be high, a clear improvement over the <a href="https://ethresear.ch#Slow-rotation">previous slow rotation approach</a>. Still, we would like this to be more than an optimistic property. The question we are left to answer is then how we can ensure, or at least highly incentivize, a high <span class="math">\frac{D_a}{D}</span> ratio. For example, we want to prevent that all validators keep 32 ETH balances (no one consolidates), which would result in <span class="math">\mathbb{E}[D_a] = \frac{32}{T} D</span>, e.g., only <span class="math">\frac{D}{32}</span> with <span class="math">T = 1024</span>. With today’s <span class="math">D = 32M</span> ETH, the expected active deposit size would only be <span class="math">1M</span> ETH. On the other hand, we do not want to reward consolidated validators disproportionately compared to small validators.</p>
<p>We explore two complementary approaches:</p>
<ul>
<li><strong>Collective consolidation incentives</strong>, growing the size of the pie for the whole validator set when the set is more consolidated.</li>
<li><strong>Individual consolidation incentives</strong>, accounting for the extra risk accruing from further individual consolidation.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#collective-consolidation-incentives-11" name="collective-consolidation-incentives-11"></a>Collective consolidation incentives</h4>
<p>The first approach we explore is to reward <em>everyone</em> for consolidation, spreading out the benefits beyond the consolidating validators so as to maintain rewards undifferentiated, while still providing an incentive to consolidate.</p>
<p>A first proposal in this direction is to set the rewards based on <span class="math">D_a</span>, rather than <span class="math">D</span>. For example, we could use the same issuance curve <span class="math">I</span> we use today, but where the deposit size used as input is <span class="math">D_a</span> instead of <span class="math">D</span>: the cumulative issuance would then be <span class="math">I(D_a)</span>, and the resulting yield per unit of stake <span class="math">\frac{I(D_a)}{D}</span>. Notably, <span class="math">I</span> is monotonically increasing, so, whenever <span class="math">D_a &lt; D</span>, the cumulative issuance <span class="math">I(D_a)</span> is less than the maximum issuance <span class="math">I(D)</span> that would be possible at this deposit size, with full consolidation. The yield gap <span class="math">\frac{I(D) - I(D_a)}{D}</span> between the current yield and the yield with full consolidation then acts as a consolidation incentive.</p>
<p>Consolidation incentives aside, another way to think about this proposal is that we simply pay for the economic security we get, at least from a single committee: if today our security budget for <span class="math">X</span> amount of deposits is <span class="math">Y</span>, as expressed by <span class="math">I(X) = Y</span>, we would now be wiling to pay <span class="math">Y</span> in order to get <span class="math">X</span> amount of <em>active</em> deposits. To get an idea of what this looks like in practice, here’s a color plot of the yield for <span class="math">(D, \frac{D_a}{D})</span> (starting from <span class="math">D = 1</span> to help the visualization).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/afced2f656e5db107f33e22007ab6b5fdd5859fc.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/a/f/afced2f656e5db107f33e22007ab6b5fdd5859fc_2_623x500.png" width="623" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#individual-consolidation-incentives-12" name="individual-consolidation-incentives-12"></a>Individual consolidation incentives</h4>
<p><em>Credit to Anders for raising the issue of differentiated risk and for proposing the kind of individual incentives we explore here</em></p>
<p>Though our exploration of collective incentives has found them to be decently strong, there is one factor we have not considered: validators with stake <span class="math">\ll T</span> have a better risk profile than validators with stake <span class="math">\ge T</span>. This is because they are in the active only a fraction of the time, which means two things:</p>
<ul>
<li>In a staking pool, accidental slashing caused by a bad setup can be caught early with only a fraction of the validators being subject to it</li>
<li>Tail risk of mass slashing or leaking, for example due to client bugs, is much lower, as in many cases this would only affect the active set. For a staking pool, this effectively caps the pool’s slashing exposure to a fraction of the stake, in almost all scenarios.</li>
</ul>
<p>We might then be unwilling to solely rely on collective incentives, which cannot properly account for the risk differentiation between consolidated and non consolidated validators, itself an individual anti-consolidation incentive. On the other hand, we are hesitant to use individual consolidation incentives, because differentiated rewards threaten our goal of solo staking viability. Faced with this dilemma, a potential approach to mitigate the consequences on solo staking viability is to try to set individual consolidation incentives that just offset the added risk from consolidation. The goal is for risk-adjusted rewards to be roughly equivalent for consolidated and non consolidated validators, so that the available choices of higher risk, higher reward and lower risk, lower rewards are similarly attractive. In particular, it is then at least in principle possible (though not guaranteed) to have a validator set where both setups coexist, so that we can aspire to both have a high consolidation ratio and solo staking viability.</p>
<p>Concretely, here’s a way we could go about this. Given the base yield <span class="math">y(D_a, D) = \frac{I(D_a, D)}{D}</span>, we can adjust the yield of a validator with <span class="math">S</span> stake to be <span class="math">y(D_a, D)(1 + \frac{\min(S,T)}{T}g(\frac{D_a}{D}))</span>, where <span class="math">g(x)</span> is decreasing and <span class="math">g(1) = 0</span>. In other words, a validator with <span class="math">S</span> stake gets additional <em>consolidation yield</em> <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T}g(\frac{D_a}{D})y(D_a, D)</span>, or equivalently its yield increases by a factor of <span class="math">\frac{\min(S,T)}{T}g(\frac{D_a}{D})</span>, up to <span class="math">g(\frac{D_a}{D})</span> for fully consolidated validators with <span class="math">S = T</span>. This factor decreases as <span class="math">\frac{D_a}{D}</span> grows, because there are diminishing returns to further consolidation (same reason why the staking yield falls as the total deposit size grows). In particular, it falls all the way to <span class="math">0</span> if <span class="math">\frac{D_a}{D}</span> goes to <span class="math">1</span>, restoring the base yield <span class="math">y(D_a, D)</span> for everyone, and generally making the rewards less and less differentiated as more consolidation occurs. The idea is that an equilibrium will be reached where <span class="math">g(\frac{D_a}{D})</span> just about compensates for the additional risk from consolidating, and further consolidation is not incentivized. We can even set <span class="math">g</span> to reach <span class="math">0</span> at some lower level of consolidation that we are happy with, leaving more space for staking with non consolidated validators to be economically viable. For example, if <span class="math">g(0.8) = 0</span>, then a validator with 32 ETH gets the same yield, and less risk, as a validator with 1024 ETH, even if 20% of the stake is made up of 32 ETH validators.</p>
<p>Let’s now look at a specific form of <span class="math">g</span>. The simplest possible choice is a linear function, which is fully determined by <span class="math">g(0)</span>, the initial yield increase factor when there is no consolidation at all. The function is then simply <span class="math">g(x) = g(0)(1 - x)</span>. For example <span class="math">g(x) = \frac{1-x}{4}</span>, where the maximum yield increase is 25%. The extra yield of a validator with stake <span class="math">S</span> is:<br />
<span class="math">y_c(D_a, D, S) = g(0)\frac{\min(S,T)}{T} \cdot y(D_a, D) \cdot (1 - \frac{D_a}{D})</span></p>
<p>Let’s see what this looks like in combination with the collective incentives introduced <a href="https://ethresear.ch#Collective-consolidation-incentives">in the previous section</a>, where issuance is based on <span class="math">D_a</span>, i.e., <span class="math">y(D_a, D) = \frac{I(D_a)}{D}</span>, and <span class="math">I</span> is the current issuance curve <span class="math">I(x) = c\sqrt{x}</span>. The maximum consolidation yield, or the yield advantage of a consolidated validator over a regular one, is:</p>
<p><span class="math">y_c(D_a, D, S=T) = g(0) \cdot y(D_a, D) (1 - \frac{D_a}{D})  = \\
= g(0) \cdot c \cdot \frac{\sqrt{D_a}}{D}(1 - \frac{D_a}{D}) = \\ g(0) \cdot c \cdot \frac{1}{\sqrt{D_a}} \frac{D_a}{D}(1 - \frac{D_a}{D})</span></p>
<p>The next color plot shows <span class="math">y_c(D_a, D, S=T)</span> as a function of <span class="math">\frac{D_a}{D}</span> and <span class="math">D_a</span>, for <span class="math">g(0) = \frac{1}{4}</span> (some portion on the upper left corner is infeasible, because <span class="math">D</span> would be <span class="math">&gt; 120M</span>). Horizontally, the function looks like <span class="math">x(1-x)</span>: the consolidation yield is low at low consolidation levels, when collective incentives are strong, and at high consolidation levels, when we don’t have a strong requirement for more consolidation and we are more worried about the economic viability of running non consolidated validators. Vertically it looks like <span class="math">\frac{1}{\sqrt{y}}</span>, with the consolidation yield slowly falling off as <span class="math">D_a</span> grows and we have less need for consolidation in general, since the economic security of the active set is determined by <span class="math">D_a</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/c/fc72bbb9885865bf40afe632e841d2ab2ff06e70.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/f/c/fc72bbb9885865bf40afe632e841d2ab2ff06e70_2_586x500.png" width="586" /></a></div><p></p>
<p>We can of course very easily modify any such function <span class="math">g</span> so that the incentives fall to <span class="math">0</span> after a certain consolidation level <span class="math">r_0 \in [0,1]</span>, by replacing <span class="math">g</span> with <span class="math">\tilde{g}(x) = \max(g(\frac{x}{r_0}), 0)</span>, which squeezes <span class="math">g</span> in the range <span class="math">[0,r_0]</span> and sets the consolidation yield to <span class="math">0</span> afterwards. For example, this is the consolidation yield with <span class="math">r_0 = 80\%</span>, starting from the previous <span class="math">g(x) = \frac{1-x}{4}</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/b/1bf37fb8df61c4442a5054ccdaf8d55b02c351f9.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/b/1bf37fb8df61c4442a5054ccdaf8d55b02c351f9_2_573x500.png" width="573" /></a></div><p></p>



<h2><a class="anchor" href="https://ethresear.ch#appendix-13" name="appendix-13"></a>Appendix</h2>
<h3><a class="anchor" href="https://ethresear.ch#validator-capping-active-validator-set-variance-14" name="validator-capping-active-validator-set-variance-14"></a>Validator capping: active validator set variance</h3>
<p>Let’s also get an upper bound on the variance of the active validator set size. <span class="math">\mathbb{V}[|V_a|] = \mathbb{V}[\sum_{i\in V} \chi_{\{i \in V_a\}}] = \sum_{i\in V} \mathbb{V}[\chi_{\{i \in V_a\}}]</span>, since each validator is sampled independently. Moreover, <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = 0</span> whenever <span class="math">S_i \ge T</span>, since validator <span class="math">i</span> is then always in <span class="math">V_a</span>.<br />
For <span class="math">S_i &lt; T</span>, the variance is <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = p(S_i)(1 - p(S_i)) = \frac{S_i}{T}(1 - \frac{S_i}{T})</span>, which is maximized when <span class="math">p(S_i) = \frac{1}{2}</span>, or equivalently when <span class="math">S_i = \frac{T}{2}</span>, in which case <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = \frac{1}{4}</span>. Therefore, <span class="math">\mathbb{V}[|V_a|] \le \frac{1}{4}|V|</span>.</p>
<p>Concretely, say we keep a minimum balance of 32 ETH, so that the maximum validator set size <span class="math">|V|</span> is ~4M. The standard deviation of <span class="math">|V_a|</span> is then bounded by <span class="math">\frac{\sqrt{|V|}}{2} \approx 1000</span>. The probability of deviations beyond 10k is then vanishingly low. We can then even explicitly cap the active validator set size, say at 40k validators. Doing so introduces only a tiny correlation to the sampling of different validators, because sampling is completely unaffected other than in the exceedingly rare events of massive deviations.</p>
<h3><a class="anchor" href="https://ethresear.ch#collective-incentives-15" name="collective-incentives-15"></a>Collective incentives</h3>
<h4><a class="anchor" href="https://ethresear.ch#quantifying-the-individual-effect-of-collective-consolidation-incentives-16" name="quantifying-the-individual-effect-of-collective-consolidation-incentives-16"></a>Quantifying the individual effect of collective consolidation incentives</h4>
<p>Let’s look into the consolidation incentives a bit more quantitatively. While it is true that there is always some consolidation incentive whenever consolidation is at all possible, we should also consider how strong these incentives are for various stakers. In particular, the strength of the incentives varies based on how large a staker is, because a consolidation increases yield <em>for everyone</em>, not just for the party which peforms it. In other words, the gains of a consolidation are socialized, to avoid having a sort of consolidation reward, which would effectively disadvantage smaller validators that cannot access it. Consolidation incentives are therefore stronger the larger a validator is. On the one hand, this means that sufficiently large validators have a strong incentive to consolidate, which means we should expect <span class="math">D_a</span> to always represent at least a meaningful portion of the total stake <span class="math">D</span>. On the other hand, it means that small but still meaningfully sized stakers (e.g. 1%) might not be particularly incentivized to consolidate.</p>
<p>To quantify this, let’s look at how much of an issuance increase there is in the event of the full consolidation of a staker having a fraction <span class="math">p</span> of the total stake <span class="math">D</span>, when <span class="math">\frac{D_a}{D} = r</span>. Here we assume that the stake <span class="math">pD</span> in question is initially not consolidated at all, and neglect the small effect it has on <span class="math">D_a</span> (e.g. if <span class="math">T = 1024</span>, a minimum balance validator only increases <span class="math">D_a</span> by 1/32 of its stake). Issuance, and thus yield, increases by a factor of <span class="math">\frac{I(D_a + pD) - I(D_a)}{I(D_a)} = \frac{I((r + p)D)}{I(rD)} - 1</span>. Plugging in the definition of <span class="math">I</span>, we can simplify this to <span class="math">\sqrt{1 + \frac{p}{r}} - 1</span>. As expected, the consolidation incentives grow with <span class="math">p</span>. It is also expected that they fall with <span class="math">r</span>, since the issuance curve <span class="math">I</span> is concave. As it turns out, there’s no dependency on <span class="math">D</span> for this particular form of <span class="math">I</span>.</p>
<p>We now plot <span class="math">100(\sqrt{1 + \frac{p}{r}} - 1)</span>, the <em>percentage</em> of yield increase that every validator experiences when a fraction <span class="math">p</span> of the stake is fully consolidated, starting from <span class="math">D_a = rD</span>. We restrict <span class="math">r</span> to the range <span class="math">[0.1, 1]</span> for ease of visualization, because the consolidation incentives blow up for <span class="math">r</span> near <span class="math">0</span>, as we would wish. Notice that the minimum <span class="math">r</span> is actually <span class="math">1/32</span> for <span class="math">T = 1024</span> and minimum balance 32 ETH.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/ccde75a7bf33c1105849424713dceee8fd5b151d.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/ccde75a7bf33c1105849424713dceee8fd5b151d_2_598x500.png" width="598" /></a></div><p></p>
<p>On the other hand, the <em>absolute</em> yield increase <span class="math">100\cdot\frac{I(D_a + pD) - I(D_a)}{D_a}</span> is not independent of <span class="math">D</span>. We plot it here specifically for <span class="math">D = 30M</span> ETH. For lower values of <span class="math">D</span>, the consolidation incentives only get stronger in absolute terms.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/3/53bb8a566b7597b844788fa776551f98df5b36c3.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/3/53bb8a566b7597b844788fa776551f98df5b36c3_2_567x500.png" width="567" /></a></div><p></p>
<p>Finally, we also plot the yearly ETH returns from consolidation, <span class="math">(I(D_a + pD) - I(D_a))\cdot \frac{p}{r}</span>, again for <span class="math">D = 30M</span> ETH.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68a7e7faee22708549d1b4c2738e1016de2cf661.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68a7e7faee22708549d1b4c2738e1016de2cf661_2_578x500.png" width="578" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#generalizing-collective-incentives-17" name="generalizing-collective-incentives-17"></a>Generalizing collective incentives</h4>
<p>When <span class="math">I</span> is our current issuance curve, <span class="math">I(x) = c\sqrt{x}</span>, we have that <span class="math">I(D_a) = c\sqrt{D_a} = c \sqrt{D} \sqrt{\frac{D_a}{D}} = I(D)\sqrt{\frac{D_a}{D}}</span>. In other words, we can think about the previous proposal as incentivizing a high <span class="math">\frac{D_a}{D}</span> ratio by directly a  applying an issuance penalty based on it. More generally, we can let the issuance be <span class="math">I(D_a, D) = I(D) \cdot \delta(\frac{D_a}{D})</span> for any <span class="math">\delta</span> such that <span class="math">\delta(0) = 0</span> and <span class="math">\delta(1) = 1</span>. With this, the yield increase from consolidating is exactly <span class="math">\frac{I(D)}{D} \cdot (\delta(r + p) - \delta(p))</span>, i.e., a fraction <span class="math">\delta(r + p) - \delta(r)</span> of the maximum yield available at deposit size <span class="math">D</span>. The percentage yield increase is instead <span class="math">\frac{\delta(r + p) - \delta(r)}{\delta(r)}</span>. The simplest case is <span class="math">\delta(r) = r</span>, where <span class="math">I(D_a, D) = I(D) \cdot \frac{D_a}{D}</span>, in which case the yield increase is simply <span class="math">p \frac{I(D)}{D}</span>, constant in <span class="math">r</span>, and the percentage yield increase is <span class="math">\frac{p}{r}</span>.</p>
<p>In this form, we can more clearly separate the design of incentives to stake from that of incentives to consolidate the stake: <span class="math">I(D)</span> provides the <em>maximum</em> possible incentive to stake at a given total deposit level <span class="math">D</span>, while <span class="math">\delta</span> regulates the incentive to consolidate at a given ratio <span class="math">\frac{D_a}{D}</span>. We can for example have <span class="math">I</span> being concave, as it is currently, but <span class="math">\delta</span> linear as in the previous example: the protocol then considers stake deposits to have diminishing returns, while it believes consolidation to be equally valuable regardless of where <span class="math">\frac{D_a}{D}</span> currently sits.</p>
<h4><a class="anchor" href="https://ethresear.ch#discouragement-attacks-18" name="discouragement-attacks-18"></a>Discouragement attacks</h4>
<p>At any point, it is possible to increase <span class="math">D</span> while barely increasing <span class="math">D_a</span>, by activating validators with minimum balance. Thus, the issuance <span class="math">I(D_a)</span> is approximately constant, but distributed to more stake. This is the same <a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171#h-53-discouragement-attacks-32">discouragement attack</a> that would be possible with a constant issuance curve, or with issuance capped at some maximum value, where the yield also decreases like <span class="math">\frac{1}{D}</span>. While worse than today, where it decreases like <span class="math">\frac{1}{\sqrt{D}}</span>, this discouragement attack is nothing like the ultra cheap griefing vector that would arise with if we were to <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-validator-count" rel="noopener nofollow ugc">use issuance to target a validator count</a>. For example, say we started reducing issuance past our ideal target of ~30k validators, and were to go negative at 40k. Then, activating a few thousands minimum balance validators, in the order of 0.01% to 0.1% of the stake, would be enough to make yields go negative. On the other hand, in the context of the discouragement attack we are considering here, reducing yield by a factor of <span class="math">k</span> requires increasing the deposit size by a factor of <span class="math">k</span>. For example, halving issuance when <span class="math">D = </span> 20M requires depositing another 20M.</p>
<h4><a class="anchor" href="https://ethresear.ch#stake-capping-19" name="stake-capping-19"></a>Stake capping</h4>
<p>If we were to set the issuance based on <span class="math">D_a</span>, we would not be able to immediately adopt any issuance curve that reduces issuance past some deposit size, like the ones discussed <a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171/1">here</a> and <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">here</a>. The reason for that is simple: if issuance goes down past a certain value of <span class="math">D_a</span>, but it turns out that the yield at that point is still attractive, the incentives are such that <span class="math">D</span> would still grow (more stake wants yield at these levels) while <span class="math">D_a</span> would not (growing <span class="math">D_a</span> lowers yield). In fact, instead of consolidation incentives, we end up having incentives for splitting up stake over multiple validators, so as to decrease <span class="math">D_a</span> and keep it at the point of maximum issuance! Meanwhile, stake capping is not achieved, at least not any more than we would already achieve it by capping issuance at the maximum value, rather than having it decrease afterwards.</p>
<p>If we did want to adopt some form of stake capping, we would then need to do things a bit differently. We could let the issuance be <span class="math">I(D_a, D) = I(D_a) - f(D)</span>, where <span class="math">f</span> acts to reduce the issuance past some critical <em>total</em> deposit size. Intuitively, the goal is to try to ensure two things at once: that we have enough <span class="math">D_a</span>, and that we do not have too much <span class="math">D</span>. For example:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/8/c83ba4769d0fc0c8db841d28c0210dfdd3ab53d2.png" title=""><img alt="" height="227" src="https://ethresear.ch/uploads/default/optimized/3X/c/8/c83ba4769d0fc0c8db841d28c0210dfdd3ab53d2_2_690x227.png" width="690" /></a></div><p></p>
<p>To help visualizing the effect of this further, here are the cumulative issuance and yield while holding <span class="math">\frac{D_a}{D} = 0.8</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/4/044c55ed764d7dfddac4c2df5be73783c8017800.png" title=""><img alt="" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/0/4/044c55ed764d7dfddac4c2df5be73783c8017800_2_690x230.png" width="690" /></a></div><p></p>
<p>Finally, here is a color plot of the yield in the <span class="math">(D, \frac{D_a}{D})</span> space. <span class="math">D</span> starts at 2 to help the visualization be effective.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/4/744db3435b9b033af6e55309e19068c435be1ffb.png" title=""><img alt="" height="463" src="https://ethresear.ch/uploads/default/optimized/3X/7/4/744db3435b9b033af6e55309e19068c435be1ffb_2_690x463.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#individual-incentives-20" name="individual-incentives-20"></a>Individual incentives</h3>
<h4><a class="anchor" href="https://ethresear.ch#total-issuance-21" name="total-issuance-21"></a>Total issuance</h4>
<p>The total <em>extra</em> issuance is:</p>
<p><span class="math">I_c(D_a, D) = \sum_{i \in V} y_c(D_a, D, S_i) S_i = g(0) y(D_a, D)(1 - \frac{D_a}{D}) \sum_{i \in V} p(S_i)S_i = \\ = g(0)y(D_a, D)\cdot D_a(1 - \frac{D_a}{D}) = g(0)I(D_a)\cdot \frac{D_a}{D}(1 - \frac{D_a}{D}) = \\
= g(0) \sqrt{D} \sqrt{\frac{D_a}{D}}\cdot \frac{D_a}{D}(1 - \frac{D_a}{D}) = g(0)I(D) \sqrt{\frac{D_a}{D}}\cdot \frac{D_a}{D}(1 - \frac{D_a}{D})</span></p>
<p>The total issuance then is:</p>
<p><span class="math">I_T(D_a, D) = I(D_a) + I_c(D_a, D) = I(D_a)(1 + g(0) \frac{D_a}{D}(1 - \frac{D_a}{D})) = \\
= c \sqrt{D} \sqrt{\frac{D_a}{D}}(1 + g(0)\cdot \frac{D_a}{D}(1 - \frac{D_a}{D})) = \\
= I(D) \sqrt{\frac{D_a}{D}} (1 + g(0)\frac{D_a}{D}(1 - \frac{D_a}{D})) = I(D) \cdot h(\frac{D_a}{D})</span>, where <span class="math">h(x) = \sqrt{x}(1 + g(0)x(1-x))</span>. For <span class="math">g(0) = \frac{1}{4}</span>, we have that <span class="math">h(x) \le 1</span> for <span class="math">x \in [0,1]</span>, so <span class="math">I(D)</span> remains an upper bound on the total issuance.</p>
<p><img alt="" height="435" src="https://ethresear.ch/uploads/default/original/3X/5/4/543c7981de3b9feeff11aff29ac6556c3f9ad5cf.png" width="547" /></p>
<h4><a class="anchor" href="https://ethresear.ch#generalizing-individual-consolidation-incentives-22" name="generalizing-individual-consolidation-incentives-22"></a>Generalizing individual consolidation incentives</h4>
<p>More generally, we can choose any consolidation yield curve <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} y_c(D_a, D)</span>, not necessarily depending on <span class="math">y(D_a, D)</span>, or even any curve <span class="math">y_c(D_a, D, S)</span> with a different kind of dependency on <span class="math">S</span>. An interesting example of the first kind is the curve <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} (y(D) - y(D_a, D))</span>, where <span class="math">y_c(D_a, D, S)</span> essentially interpolates between the yield <span class="math">y(D) = y(D_a = D, D)</span> that would be paid out to a fully consolidated validator set at deposit size <span class="math">D</span>, and the base yield <span class="math">y(D_a, D)</span> paid out at the current consolidation level. In other words, a validator with <span class="math">T</span> stake always gets paid the maximum possible yield for deposit size <span class="math">D</span>, <span class="math">y(D)</span>, regardless of the consolidation level achieved by the whole validator set, while validators with minimum stake get paid closer to the base yield <span class="math">y(D_a, D)</span>, and their yield linearly increases to <span class="math">y(D)</span> as they consolidate. In this case, the consolidation incentives are quite a bit stronger at lower consolidation levels.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/5229207a5722061af774a3d38e53aa0d28a08a89.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/5229207a5722061af774a3d38e53aa0d28a08a89_2_573x500.png" width="573" /></a></div><p></p>
<p>While the absolute yield increase falls with <span class="math">D_a</span>, the percentage yield increase from consolidating does not. As it turns out, it only depends on <span class="math">\frac{D_a}{D}</span>:<br />
<span class="math">\frac{y_c(D_a, D)}{y(D_a, D)} = \frac{y(D) - y(D_a, D)}{y(D_a, D)} =
\frac{y(D)}{y(D_a, D)} - 1 = \sqrt{\frac{D}{D_a}} - 1 </span></p>
<p>In other words, this also fits the previous form <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} g(\frac{D_a}{D}) y(D_a, D)</span>, with <span class="math">g(x) = \sqrt{\frac{1}{x}} - 1</span> instead of a linear function.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/a/4ab4a1cd832f6644730fd660799e1167f71af570.png" title=""><img alt="" height="293" src="https://ethresear.ch/uploads/default/optimized/3X/4/a/4ab4a1cd832f6644730fd660799e1167f71af570_2_690x293.png" width="690" /></a></div><p></p>
<p>Since <span class="math">y(D_a, D) + y_c(D_a, D, S) \le y(D)</span>, it still holds that <span class="math">I(D)</span> is a bound on the total issuance. In fact, the total issuance can be worked out to be <span class="math">I_T(D_a, D) = I(D_a) + I_c(D_a, D) = I(D) \sqrt{\frac{D_a}{D}}(1 + \sqrt{\frac{D_a}{D}} (1 - \sqrt{\frac{D_a}{D}})) = I(D) h(\frac{D_a}{D})</span>, with <span class="math">h(x) = \sqrt{x}(1 + \sqrt{x}(1 - \sqrt{x})))</span>, which we compare here to the previous example:</p>
<p><img alt="" height="435" src="https://ethresear.ch/uploads/default/original/3X/8/e/8e42613ed48e495edae62b74cecc8f994f7499a9.png" width="547" /></p>
            <p><small>3 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 07:22:10 +0000</pubDate>
</item>
<item>
<title>Number Duplicate Messages in Ethereum's Gossipsub Network</title>
<link>https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921</link>
<guid>https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921</guid>
<content:encoded><![CDATA[
<div> 关键词：GossipSub、Ethereum、消息重复、Hermes、优化建议

总结:<br />
GossipSub是Ethereum P2P网络中的消息广播协议，其设计允许一定程度的消息重复。研究团队使用工具Hermes追踪GossipSub性能，发现正常情况下每个消息最多接收3次重复（不包括通过IHAVE/IWANT控制消息传播的情况）。研究发现，通过网格的重复消息保持在3次或以下，但通过Gossip机制可能会有额外的重复。团队提出两点优化建议：限制并发IWANT请求的数量（类似Kademlia的alpha参数）和降低心跳频率，以减少IHAVE消息和额外重复。最后，尽管存在一些边缘情况，但大部分重复消息并不构成重大问题。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-tldr-1" name="summary-tldr-1"></a>Summary &amp; TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the “<a href="https://ethresear.ch/t/gossipsub-network-dynamicity-through-grafts-and-prunes/19750">Gossipsub Network Dynamicity through GRAFTs and PRUNEs</a>” in this post we investigate the number of messages and duplicated messages seen by our node, per topic. There is no public data on the overhead that broadcasting messages and control data over the network imply on each participating node.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer.</a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions. The results reported here are from a 3.5hr trace.</p>
<p><strong>Study Description:</strong> Gossipsub’s design is inherently allowing for message duplicates. A brief model we develop shows that it’s normal to receive each message up to 3 extra times (as a duplicate). This excludes the gossip mechanism which propagates messages through the IHAVE/IWANT control message sequence.</p>
<p><strong>TL;DR:</strong> We find that indeed duplicates through mesh stay in the order of 3 per message or below, which, however, doesn’t count for duplicates through gossip. For instance, there are edge cases where a message is requested (and responded to) through an IWANT message while the actual message is already in transit. Eventually, this results in an extra duplicate. We make two recommendations:</p>
<ol>
<li><strong>Reduce the number of concurrent <code>IWANT</code> messages we send through a limiting factor</strong> (somewhat similar to kademlia’s <code>alpha</code> parameter).</li>
<li><strong>Lower the current <code>heartbeat</code> frequency (i.e., increasing the <code>heartbeat</code> interval) from 0.7 seconds to 1 second</strong> (as per the original protocol spec and recommendation). This would reduce the excessive <code>IHAVE</code> messages and reduce the chances of generating extra duplicates.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#background-2" name="background-2"></a>Background</h1>
<p><a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.1.md" rel="noopener nofollow ugc">GossipSub</a> is a routing system that can be enabled on libp2p’s <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/README.md" rel="noopener nofollow ugc">PubSub</a> message broadcasting protocol. This protocol organizes the message broadcasting channels on what is commonly known as Topics, where peers subscribed to a given topic keep a particular subset of connected peers for that particular topic. This subset of peer connections per topic is also known as “mesh”.</p>
<p>In the case of GossipSub, the standard broadcasting mechanism of PubSub is extended with a few sets of enhancements that make it:</p>
<ul>
<li>more efficient than what is commonly called flooding, reducing the protocol’s bandwidth usage</li>
<li>more resilient, as the protocol:
<ul>
<li>shares metadata of seen messages over sporadic Gossip messages (for censorship or Sybil attacks)</li>
<li>keeps a local score for each mesh-connected peer to ensure healthy and useful connections, where each peer keeps connections with the highest scoring neighbours</li>
<li>avoids sharing a message with peers that already sent the message to us</li>
</ul>
</li>
</ul>
<p>This all looks good on paper. However, there is still no public data on the overhead that broadcasting messages and control data over the network imply on each participating node. Even more importantly, how much room for improvement exists within the protocol and the implementations to make it more optimal.</p>
<h2><a class="anchor" href="https://ethresear.ch#expected-results-3" name="expected-results-3"></a>Expected Results</h2>
<p>Message propagation through the GossipSub’s mesh considers some occasional duplicates that can arrive as the message might come from different peers within the mesh:</p>
<p>Given:</p>
<ul>
<li><code>n</code> as the number of nodes in the graph</li>
<li><code>k</code> as the mesh degree</li>
<li><code>l</code> as the number of connections (links) between two nodes <span class="math">l = \frac{nk}{2}</span></li>
</ul>
<p>The number of links used to propagate a message to all nodes in the graph can be defined as <code>n-1 ~= n</code>. The links form a spanning tree with the message origin as root (<code>n</code> is big enough compared to the initial sender link, so that it can be considered negligible).</p>
<p>The number of links not used to propagate a specific message corresponds to <span class="math">l-n = \frac{n(k-2)}{2}</span>.</p>
<p>This means that on average each node will have 1 link used to receive a message, 1 to propagate it to a peer that doesn’t have it yet. And the rest <code>k-2</code>, to either send or receive the duplicate message.</p>
<p>Assuming that <span class="math">\frac{k-2}{2}</span> links are used to send the message to peers that already have it, it means that we receive <span class="math">\frac{k-2}{2}</span> duplicate messages.</p>
<p>In the case of Ethereum, <code>k=8</code>, and therefore, it follows that <span class="math">\frac{k-2}{2} = 3</span>. So, <strong>the expected value is to receive 3 duplicate messages for each message</strong>.</p>
<h1><a class="anchor" href="https://ethresear.ch#results-4" name="results-4"></a>Results</h1>
<p>As previously introduced, this report aims to provide insights on:</p>
<ul>
<li>the number of duplicate messages that we receive per each shared message in the network,</li>
<li>the extra bandwidth that we are spending on duplicates,</li>
<li>any existing unexpected behavior or potential optimization that could be applied on GossipSub.</li>
</ul>
<blockquote>
<p>NOTES:<br />
The numbers presented in the following sections belong to the same 3.5 hours run of <code>Hermes</code> as the previous studies, with the following extra configuration:</p>
<ul>
<li>The experiment is ran on the <code>Holesky</code> network</li>
<li>Our node was subscribed to the following topics:
<ul>
<li><code>beacon_block</code></li>
<li><code>beacon_aggregate_and_proof</code></li>
<li><code>sync_commmittee_contribution_and_proof</code></li>
<li><code>attester_slashing</code></li>
<li><code>proposer_slashing</code></li>
<li><code>voluntary_exit</code> * (check <code>Hermes</code> issue → <a class="inline-onebox" href="https://github.com/probe-lab/hermes/issues/24" rel="noopener nofollow ugc">Broadcasting of invalid `voluntary_exit` messages to mesh peers · Issue #24 · probe-lab/hermes · GitHub</a>)</li>
<li><code>bls_to_execution_change</code></li>
</ul>
</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#overall-number-of-messages-5" name="overall-number-of-messages-5"></a>Overall Number of Messages</h2>
<p>To give a little bit of context, the report starts by taking a look at the number of messages and the respective duplicates received over time. The following graph shows the number of <code>HANDLED</code> events by the libp2p-host in comparison with the <code>DELIVERED</code> and <code>DUPLICATED</code> ones.</p>
<blockquote>
<p>NOTE: In this report we will consider the <code>DELIVER</code> events as unique identifier of the arrival of a message. This is because the internal event tracer at the libp2p host notifies of the arrival of a unique message at multiple levels, which in turn, makes the <code>HANDLED</code> and <code>DELIVER</code> events at the arrival of a new message the exact same notification, just at different levels of the host.</p>
</blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65a05809dfbc2915a07ceadedbf9cd8d85f16fe8.jpeg" title="overall-number-of-events"><img alt="overall-number-of-events" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/6/5/65a05809dfbc2915a07ceadedbf9cd8d85f16fe8_2_517x309.jpeg" width="517" /></a></div><p></p>
<ul>
<li>The number of unique messages (i.e., <code>HANDLE_MESSAGE</code>) stays steady around the 3,000 and 3,200 unique messages per minute.</li>
<li>By looking closer into the messages per topic (not shown here), we observe that the topic with the highest message frequency is the <code>beacon_aggregate_and_proof</code> one, receiving over 90% of the tracked unique messages.</li>
<li>There are some duplicated spikes at the <code>beacon_block</code> topic that reach up to 60 duplicates  in some occasions.</li>
<li>The number of duplicates seems to vary quite wildly over time, which can be related to the number of connections per mesh (as per the analysis done further up which showed that 3 duplicates per message are expected).</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#number-of-duplicate-messages-6" name="number-of-duplicate-messages-6"></a>Number of Duplicate Messages</h2>
<p>When it comes to the actual number of <code>DUPLICATE</code> messages, the following figures show that number of duplicates can oscillate over time.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/d/edacb4d1d050448d2a5b17ef6c67ed0cb3ca42e0.png" title="duplicates-per-topic"><img alt="duplicates-per-topic" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/e/d/edacb4d1d050448d2a5b17ef6c67ed0cb3ca42e0_2_517x309.png" width="517" /></a></div><p></p>
<p>Clearly, the <code>beacon_block</code> topic seems to be the only one generating the largest number of spikes at times.</p>
<h2><a class="anchor" href="https://ethresear.ch#cdf-of-duplicate-messages-7" name="cdf-of-duplicate-messages-7"></a>CDF of Duplicate Messages</h2>
<p>The following graph shows the Cumulative Distribution Function (CDF) of the duplicates per message per topic. In the graph, we can see that:</p>
<ul>
<li>smaller but more frequent messages like the <code>beacon_ggregate_and_proof</code> and <code>sync_commitee_contributions</code> do have fewer duplicates.
<ul>
<li>between 32% and 45% of the messages do not have any duplicates.</li>
<li>50% of the messages are received with less than 2 duplicate messages, keeping the mean lower than the theoretical target of <code>3</code> duplicates per message.</li>
<li>the upper tail shows that less than 10% of the messages get more than 4 duplicates, with a cap at 8-10 duplicates (i.e., the node’s mesh size, <code>D</code>).</li>
</ul>
</li>
<li>the case of the <code>beacon_blocks</code> is completely different.
<ul>
<li>there are almost no recorded messages without duplicates (1%-2%).</li>
<li>54% of the messages report the expected <code>3</code>  duplicates from the mesh</li>
<li>Taking look at the tail of the CDF (shown in the dropdown plot further down) there are a few messages that were received up to 34 or 40 times.</li>
</ul>
</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/1/0153b674d22c5c90c7fee45cbf880ec5b865d548.png" title="CDF-duplicates"><img alt="CDF-duplicates" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/0/1/0153b674d22c5c90c7fee45cbf880ec5b865d548_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#correlation-between-message-size-and-number-of-duplicates-8" name="correlation-between-message-size-and-number-of-duplicates-8"></a>Correlation between Message Size and Number of Duplicates</h2>
<p>From the CDF above there seems to be a pattern of “the bigger the size of the message, the more duplicates it has”. So we went a step further to investigate if there is indeed a correlation. The following graph shows that the correlation between the size of a message and the number of duplicates is somewhat present but is not a norm or at least doesn’t follow any fixed pattern.</p>
<p>The figure is complemented by two auxiliary quartile plots or “boxplots”, which represent the given distribution of points of their respective axis, helping us understand that:</p>
<ul>
<li><code>sync_commmittee_contribution_and_proof</code> messages are the smallest ones in size, which also correlates with the smallest ratio of duplicate messages.</li>
<li><code>beacon_aggregate_and_proof</code> messages are the second ones in size, having also a bigger tail of duplicates on the Y concentration plot.</li>
<li><code>beacon_block</code> messages, despite being the ones with the widest variation in size, do not follow any particular pattern that could correlate the message size with the number of duplicates.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb40e85a2381cd48f38c553e329c3f0083a27196.png" title="msg-size-number-of-duplicates"><img alt="msg-size-number-of-duplicates" height="374" src="https://ethresear.ch/uploads/default/optimized/3X/f/b/fb40e85a2381cd48f38c553e329c3f0083a27196_2_383x374.png" width="383" /></a></div><p></p>
<p>As such, we conclude that <strong>there is no correlation between message size and number of duplicates</strong>.</p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-time-of-duplicates-9" name="arrival-time-of-duplicates-9"></a>Arrival Time of Duplicates</h2>
<p>Reducing the number of duplicates has already been a topic of discussion in the community. There are already some proposals like <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2 </a> that spotted this large number of duplicated messages previously, proposing the addition of a new control <code>IDONTWANT</code> message that could not only notify other peers that we already got a message, but also cancel the <code>IWANT</code> ongoing messages.</p>
<p>In order to see how effective the <code>IDONTWANT</code> control message would be, we’ve computed the time between the first delivery of each message and their respective first duplicate. This is done to validate that there is enough time to send the <code>IDONTWANT</code> message once a new message is received (prior to the message validation) and before the duplicate starts being sent over.</p>
<p>The following graph gives the time between the delivery time of a message and the time to the first duplicated message in seconds.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e87ebed2ebacfb8abd79473ceb14e2af58bc7b82.png" title="arrival-cdf"><img alt="arrival-cdf" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e87ebed2ebacfb8abd79473ceb14e2af58bc7b82_2_517x309.png" width="517" /></a></div><p></p>
<p>Results show that 50% of the duplicated beacon blocks arrive within 73 milliseconds, roughly an entire Round Trip Time (RTT) with a well connected peer. In practice, this means that <strong>the <code>IDONTWANT</code> message could prevent at least the other 50% of messages that arrive between 73 milliseconds and 2 seconds of the first arrival</strong>.</p>
<p>We’ve spotted that a big part of the duplicated messages arrive from <code>IWANT</code> messages that we sent milliseconds before the arrival of the same message though the mesh.<br />
The <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2</a> proposal already contemplates <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md#cancelling-iwant" rel="noopener nofollow ugc">this scenario</a>, where the same <code>IDONTWANT</code> message could break or stop any ongoing responses to <code>IWANT</code> messages for that <code>msgID</code>.</p>
<p>In summary, we conclude that <strong>the <code>IDONTWANT</code> control message addition to Gossipsub will be a valuable enhancement that can indeed prevent the vast majority of duplicate messages</strong>.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-10" name="conclusions-and-takeaways-10"></a>Conclusions and takeaways</h1>
<blockquote>
<p>This set of conclusions have been extracted from running the <code>go-libp2p</code>  implementation and, although it also involves the traces of how other implementations interact with Hermes, it might be a biased conclusion from the point of view of the Go implementation.</p>
</blockquote>
<ol>
<li>
<p>We have identified that there is no limit on the number of peers that we simultaneously send <code>IWANT</code> messages to for the same <code>msgID</code>.<br />
We identify that this has some benefits:</p>
<ul>
<li>Concurrently fetches the message from multiple actors.</li>
<li>Bypasses bandwidth limitations of peer(s) we have sent <code>IWANT</code> messages to, since we have forwarded the <code>IWANT</code> message to multiple peers.</li>
</ul>
<p>However, it also has obvious downsides:</p>
<ul>
<li>
<p>We receive multiple duplicates from the peers that respond to our simultaneous <code>IWANT</code> request, consuming more bandwidth on both ends.</p>
</li>
<li>
<p>The message could be already on the wire through the mesh connections, so when the <code>IWANT</code> message responses arrive, the message was already delivered through the mesh.</p>
</li>
<li>
<p>There is no track of who we contacted for a given message, given that Gossipsub is:</p>
<ul>
<li>forwarding the message only the first time we see it, and</li>
<li>removing the peer that sent us the message from the list of peers we’re broadcasting the message to and forgetting about that peer.</li>
</ul>
<p>This makes the entire broadcasting process unaware of who sent us that message in <code>IHAVE</code>s, or who we are already contacting for a particular message - resulting in multiple duplicates.</p>
</li>
</ul>
<p><a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md#cancelling-iwant" rel="noopener nofollow ugc">Canceling ongoing <code>IWANT</code>messages</a> with <code>IDONTWANT</code> messages, which is a proposal included in <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2</a> is a valuable enhancement that will limit the number of duplicates.</p>
<h3><a class="anchor" href="https://ethresear.ch#recommendation-1-11" name="recommendation-1-11"></a><strong>Recommendation 1</strong></h3>
<p>We propose having a limiting factor (somewhat similar to kademlia’s <code>alpha</code> parameter), which would limit the number of concurrent <code>IWANT</code> messages we send for the same <code>msgID</code>.</p>
<hr />
<hr />
</li>
<li>
<p>The gossiping mechanism of Gossipsub acts as a backup mechanism to the broadcasting/mesh propagation part of the protocol for those messages that didn’t manage to reach all nodes in the network. The more frequent gossiping is, the higher its contribution becomes to message propagation (i.e., more messages are being requested through <code>IWANT</code> requests because they have not reached the entirety of the network).</p>
<p>An edge case that results from very frequent gossiping (i.e., small <code>heartbeat</code> interval) is that messages that are already in transit, but have not been downloaded completely, are being requested through an <code>IWANT</code> message. This inevitably results in a duplicate message once both messages arrive at their destination.</p>
<p>It is hard to quantify how often the message responses to <code>IWANT</code> messages are indeed future duplicates, but it is still worth pointing out that high heartbeat frequency increases the chances of those edge cases.</p>
<h3><a class="anchor" href="https://ethresear.ch#recommendation-2-12" name="recommendation-2-12"></a>Recommendation 2</h3>
<p>A quick and straightforward optimization is to <strong>lower the current <code>heartbeat</code> frequency (i.e., increasing the <code>heartbeat</code> interval) from 0.7 seconds to 1 second</strong> (as per the original protocol spec and recommendation). This would reduce the excessive <code>IHAVE</code> messages and reduce the chances of generating extra duplicates.</p>
<hr />
<hr />
</li>
<li>
<p>We have spotted some edge cases that may occur due to the “lack” of control over the triggered events at GossipSub (<code>IHAVE</code>/ <code>IWANT</code>).</p>
<p>It isn’t easy to judge from the logs whether those cases are just a matter of timing, as GossipSub replies to those events as interruptions (at least in the Go implementation), or if some of those cases are caused by a bug in one of the implementations.</p>
<p>We found that <strong>the number of messages where we received multiple duplicates from the same peer to just 1% of the total number of <code>beacon_blocks</code> received</strong>. We, therefore, conclude that this is not critical or an issue that requires further investigation.</p>
</li>
</ol>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 08:48:46 +0000</pubDate>
</item>
<item>
<title>Estimating Validator Decentralization Using p2p Data</title>
<link>https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920</link>
<guid>https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920</guid>
<content:encoded><![CDATA[
<div> 关键词：地理分布、验证器、Ethereum、共识层网络、节点连接

总结:<br />
文章探讨了Ethereum区块链中验证器的地理分布问题，重点关注了验证器客户端与 beacon 节点的分离。研究者通过分析验证器的职责、随机分配的委员会以及使用的网络协议，确定了验证器在短-lived attestation subnets上的活动作为调查核心。方法论包括监听节点订阅请求、收集和分析元数据，尤其是订阅的子网数量。然而，由于某些客户端的行为策略，实际观察到的短-lived子网订阅较少，限制了验证器数量的准确估计。结果仅提供了部分验证器的地理分布信息，且存在一些局限性，如最大估计值为62个验证器等。 <div>
<blockquote>
<p>Written by <a href="https://x.com/mempirate" rel="noopener nofollow ugc">Jonas</a> &amp; <a href="https://x.com/namn_grg" rel="noopener nofollow ugc">Naman</a> from <a href="https://x.com/chainbound_" rel="noopener nofollow ugc">Chainbound</a>.<br /><br />
This research was funded by the Robust Incentives Group at the Ethereum Foundation. This work is specifically related to ROP-8. Additional information can be found <a href="https://www.notion.so/bad7233658cc41f38b26e7b4f6cf6e8b?pvs=21" rel="noopener nofollow ugc">here</a>. We want to thank <a href="https://x.com/soispoke" rel="noopener nofollow ugc">soispoke</a>, the <a href="https://x.com/EthPandaOps" rel="noopener nofollow ugc">EF DevOps team</a>, <a href="https://migalabs.io/" rel="noopener nofollow ugc">MigaLabs</a> and <a href="https://probelab.io/" rel="noopener nofollow ugc">ProbeLab</a> for their advice and contributions!</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#table-of-contents-1" name="table-of-contents-1"></a>Table of Contents</h2>
<ul>
<li><a href="https://ethresear.ch#introduction">Introduction</a></li>
<li><a href="https://ethresear.ch#anatomy-of-a-validator">Anatomy of a validator</a></li>
<li><a href="https://ethresear.ch#attestation-duties-and-committees">Attestation duties and committees</a></li>
<li><a href="https://ethresear.ch#attestation-subnets">Attestation subnets</a>
<ul>
<li><a href="https://ethresear.ch#subnet-types">Subnet types</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#validator-footprints">Validator footprints</a></li>
<li><a href="https://ethresear.ch#methodology">Methodology</a>
<ul>
<li><a href="https://ethresear.ch#long-lived-subnets">Long-lived subnets &amp; node metadata</a></li>
<li><a href="https://ethresear.ch#short-lived-subnets">Short-lived subnets</a></li>
<li><a href="https://ethresear.ch#estimating-validator-counts">Estimating validator counts</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#architecture">Architecture</a>
<ul>
<li><a href="https://ethresear.ch#crawler">Crawler</a></li>
<li><a href="https://ethresear.ch#consumer">Consumer</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#results">Result</a></li>
<li><a href="https://ethresear.ch#limitations">Limitations</a></li>
<li><a href="https://ethresear.ch#references">References</a></li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>The geographical distribution of a validator set is <a href="https://collective.flashbots.net/t/decentralized-crypto-needs-you-to-be-a-geographical-decentralization-maxi/1385" rel="noopener nofollow ugc">one of the most critical factors</a> in determining a blockchain’s level of decentralization. Validator decentralization is vital for Ethereum. It enhances network security, resilience, and censorship resistance by distributing control and minimizing the risk of single points of failure or malicious attacks.</p>
<p>It is well known that Ethereum has a <a href="https://beaconcha.in/charts/validators" rel="noopener nofollow ugc">very large</a> validator set, but <strong>is this validator set geographically distributed?</strong> Ethereum has a substantial amount  of beacon nodes running on the consensus layer network, with current estimates at around ~12,000 active nodes (<a href="https://nodewatch.io/" rel="noopener nofollow ugc">source</a>). A beacon node serves as a <em>potential</em> entrypoint into the network for validators, but it is not representative of the actual validator distribution.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f1dda810cb6cc5f9d3db8c3c592d8167d16710e.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f1dda810cb6cc5f9d3db8c3c592d8167d16710e_2_500x500.jpeg" width="500" /></a></div><br />
<small><em>Probably not.</em></small><p></p>
<p>In this article, we present the methodology and results of an investigation aiming to address this question. We start with some context about the logical components making up a validator, then proceed with some potential methods of identifying validators on the beacon P2P network. We then expand on our chosen methodology and finally present the results.</p>
<h2><a class="anchor" href="https://ethresear.ch#anatomy-of-a-validator-3" name="anatomy-of-a-validator-3"></a>Anatomy of a validator</h2>
<p>An Ethereum validator is a virtual entity that consists of a balance, public key and other properties on the beacon chain. They are roughly responsible for 4 things:</p>
<ol>
<li>Proposing new blocks</li>
<li>Voting on other block proposals (attesting)</li>
<li>Aggregating attestations</li>
<li>Slashing other validators in case they commit faults</li>
</ol>
<p>A <em>validator client</em> is the piece of software that executes these responsibilities for each of its registered validator keys (which can be many). But a validator client on its own cannot connect to the P2P beacon network to talk directly to other validators. Instead, it connects to an entity known as a <em>beacon node</em>, which is a standalone client that maintains the beacon chain and communicates with other beacon nodes.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68536fc182f09a1eb2c1e4b89f380dd4aca9c326.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68536fc182f09a1eb2c1e4b89f380dd4aca9c326_2_495x500.jpeg" width="495" /></a></div><br />
<small><em>Schematic of validator clients and a beacon node</em></small><p></p>
<p>Beacon nodes can have a number of validators attached to them that ranges from zero to thousands. In fact, <a href="https://medium.com/@grandine/grandine-0-4-1-released-fb98daef6d60" rel="noopener nofollow ugc">it’s been reported</a> that in some Ethereum testnets client developers have been running upwards of 50k validators on a single machine. This separation of concerns makes our investigation somewhat harder: a simple crawl of the P2P network might give us a good overview of the set of online beacon nodes in real time, but this is not representative of the overall validator client distribution at all. Before we address this problem, we’ll take a closer look at validator duties and their footprint on the network.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestation-duties-and-committees-4" name="attestation-duties-and-committees-4"></a>Attestation duties and committees</h2>
<p>As mentioned above, one of the main responsibilities of a validator is voting on blocks by broadcasting <em>attestations</em>. These attestations express the view of a validator about which chain they think is correct. In more detail, they actually cast 2 different votes: one to express their view of the current head block, and one to help finalize past blocks. This is because Ethereum’s  consensus is a combination of <a href="https://arxiv.org/pdf/2003.03052" rel="noopener nofollow ugc">2 subprotocols</a>: LMD GHOST, a fork-choice rule, and a finality gadget called Casper FFG.</p>
<p>These duties are assigned randomly every epoch (with some <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/validator.md#lookahead" rel="noopener nofollow ugc">lookahead</a>) with RANDAO as the source of randomness. Validators get assigned to one slot per epoch at which they have to cast their attestation, which is just a message with the votes that is signed over with the validator BLS private key. These votes are then to be packed and stored in the next beacon block. However, if <a href="https://beaconcha.in/charts/validators" rel="noopener nofollow ugc">all 1 million validators</a> were to attest for every block, the network would be flooded with messages, and the proposer that is supposed to pack these attestations into their block would have trouble verifying all of those signatures in time. This would make Ethereum’s design goal of low resource validation unfeasible.</p>
<p>To address these issues, the beacon network is subdivided into <em>committees</em>, which are subsets of the active validator set that distribute the overall workload. Committees have a minimum size of <span class="math">128</span> validators, and there are <span class="math">64</span> committees that are assigned per slot. But how is this achieved in practice? What network primitives do we require to enable such a logical separation?</p>
<h2><a class="anchor" href="https://ethresear.ch#attestation-subnets-5" name="attestation-subnets-5"></a>Attestation subnets</h2>
<p>The Ethereum consensus P2P network is built with <a href="https://github.com/libp2p/specs/tree/master/pubsub/gossipsub" rel="noopener nofollow ugc">GossipSub</a>, a scalable pubsub protocol running on libp2p. Being a pubsub protocol, GossipSub supports publish/subscribe patterns and the segmentation of networks into logical components called <em>topics</em> (aka P2P overlays)<em>.</em> These are the networking primitives that underpin beacon committees.</p>
<p>One example of a topic is the <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_block" rel="noopener nofollow ugc"><code>beacon_block</code></a> topic, which is a <em>global topic</em> on which new beacon blocks are broadcast. Every validator must subscribe to this topic in order to update their local view of the chain and perform their duties.</p>
<p>The attestation overlays look quite a bit different. For each committee, we derive a subnet ID based on the committee index (0-64). The topic for the respective subnets then becomes <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_attestation_subnet_id" rel="noopener nofollow ugc"><code>beacon_attestation_{subnet_id}</code></a>. Every validator knows their upcoming attestation duties at least 1 epoch ahead of time and can join the correct subnet in advance. When they have to make an attestation, they broadcast it on this subnet.</p>
<p>As mentioned before, these attestations are eventually supposed to make it into a beacon block. But since upcoming proposers might not be subscribed to these subnets, how does that work? This is where <em>attestation aggregators</em> come in. These are a subset of the beacon committees that are responsible for <em>aggregating</em> all of the attestations they see and broadcasting the aggregate attestations on the global <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_attestation_subnet_id" rel="noopener nofollow ugc"><code>beacon_aggregate_and_proof</code></a> topic. This topic is again a mandatory global topic that all validators will be subscribed to, thus providing a way for local unaggregated attestations to make it into the global view of the network. Per committee, there’s a target number of aggregators of <span class="math">16</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#subnet-types-6" name="subnet-types-6"></a>Subnet types</h3>
<p>These attestation subnets described above are ephemeral and directly tied to the validator duties. We call these <strong>short-lived</strong> attestation subnets. The problem with these ephemeral subnets is that they are not very robust, and could result in lost messages. To deal with this issue, the notion of a “<a href="https://github.com/ethereum/consensus-specs/issues/2749" rel="noopener nofollow ugc">subnet backbone</a>” was introduced.</p>
<p>This backbone consists of <strong>long-lived</strong>, persistent subnet subscriptions that are not tied to validator duties but rather a <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#attestation-subnet-subscription" rel="noopener nofollow ugc">deterministic function</a> of the beacon node’s unique ID and the current epoch. These long-lived subnets are maintained for <span class="math">256</span> epochs, or around 27 hours, and each beacon node has to subscribe to 2 of them. They are also advertised on the discovery layer, making it easier for beacon nodes with certain duties to find peers on the relevant subnets.</p>
<h2><a class="anchor" href="https://ethresear.ch#validator-footprints-7" name="validator-footprints-7"></a>Validator footprints</h2>
<p>Returning to the separation of the beacon node and validator clients, there’s now a clear footprint that validators leave on the beacon node’s network identity: their short-lived subnet subscriptions. This will be the core of our methodology.</p>
<h2><a class="anchor" href="https://ethresear.ch#methodology-8" name="methodology-8"></a>Methodology</h2>
<p>Generally, the beacon network consists of 3 domains:</p>
<ul>
<li>The discovery domain</li>
<li>The Req/Resp domain</li>
<li>The gossip domain</li>
</ul>
<p>Each of these domains provides some information about a beacon node.</p>
<h3><a class="anchor" href="https://ethresear.ch#long-lived-subnets-node-metadata-9" name="long-lived-subnets-node-metadata-9"></a>Long-lived subnets &amp; node metadata</h3>
<p>At the <strong>discovery layer</strong> (<a href="https://github.com/ethereum/devp2p/blob/5713591d0366da78a913a811c7502d9ca91d29a8/discv5/discv5.md" rel="noopener nofollow ugc">discv5</a>), a beacon node’s identity consists of an <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#enr-structure" rel="noopener nofollow ugc">ENR</a> with some additional metadata. This metadata can roughly be represented as the following object:</p>
<pre><code class="lang-js">{ 
	peer_id, 
	ip, 
	tcp_port, 
	udp_port, 
	attnets, // Important
	fork_digest, 
	next_fork_version, 
	next_fork_epoch 
}
</code></pre>
<p>This metadata helps other peers connect to peers that are relevant to them, indeed, one of the extra metadata fields are the (long-lived) attestation subnets that this node is subscribed to!</p>
<p>The <strong>Req/Resp domain</strong> is where the actual handshake happens. This is where nodes exchange <code>Status</code> messages that look like the following in order to establish a connection:</p>
<pre><code class="lang-js">(
  fork_digest: ForkDigest
  finalized_root: Root
  finalized_epoch: Epoch
  head_root: Root
  head_slot: Slot
)
</code></pre>
<p>The underlying protocol used for the Req/Resp domain is (again) libp2p. On the lower levels, additional information like <code>client_version</code> is also exchanged when connections are set up.</p>
<p>It is at this level that peers can also exchange <code>MetaData</code> objects to identify each other’s most up to date long-lived subnet subscriptions. The <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#metadata" rel="noopener nofollow ugc"><code>MetaData</code></a> object looks like this:</p>
<pre><code class="lang-js">(
  seq_number: uint64
  attnets: Bitvector[ATTESTATION_SUBNET_COUNT]
  ...
)
</code></pre>
<h3><a class="anchor" href="https://ethresear.ch#short-lived-subnets-10" name="short-lived-subnets-10"></a>Short-lived subnets</h3>
<p>So far, we’ve only seen how nodes exchange metadata and their long-lived subnet subscriptions, which tell us nothing about potential validators. For that, we need the short-lived subnets, which we can only collect on the gossip domain. Our initial strategy was doing just that:</p>
<ol>
<li>Listen to incoming topic subscription requests</li>
<li>Save and index them</li>
</ol>
<p>However, on an initial review of the data, we saw way too many beacon nodes that didn’t subscribe to any additional subnets besides their long-lived, mandatory subscriptions.</p>
<p>Our assumption was that in order to publish data on a gossipsub topic, one needed to be subscribed to it. It turns out that this is not the case, and many clients have different behaviour to minimize bandwidth and CPU usage. Rather than subscribing to the subnet directly, the peer finds other peers that are subscribed to the required subnet beforehand and shares the attestation with them. The subscribed peers make sure to verify and forward these attestations. Remember that in theory, only attestation aggregators need to be listening to all incoming attestations in order to do their jobs. This is exactly what was happening, and explains why we had so little short-lived subnet observations.</p>
<p>With this understanding, we could now tune our assumptions:</p>
<ul>
<li>For each subnet, there’s a target of <code>TARGET_AGGREGATORS_PER_COMMITTEE=16</code> aggregators per committee</li>
<li>This means that on average, there will only be <span class="math">16</span> validators per committee that will be subscribed to an additional short-lived subnet for the duration of an epoch</li>
<li>This results in a maximum of <span class="math">16 * 32 * 64 = 32768</span> useful observations per epoch</li>
</ul>
<p>With these assumptions in mind, we can start estimating validator counts.</p>
<h3><a class="anchor" href="https://ethresear.ch#estimating-validator-counts-11" name="estimating-validator-counts-11"></a>Estimating validator counts</h3>
<p>For each observation, we subtract the number of long-lived subnets <span class="math">S_l</span> from all subscribed subnets <span class="math">S_{all}</span> to arrive at the number of short-lived subnets <span class="math">S_s</span>:</p>
<div class="math">
S_s = S_{all} - S_l
</div>
<p>Since we know aggregators are subscribed to one additional subnet per epoch, <span class="math">S_s</span> will result in an estimated validator count for a certain beacon node in this epoch. Note that just one observation will not be enough to get an accurate estimate, because of the following reasons:</p>
<ul>
<li>It could be that a validator is not an aggregator for this epoch, and thus won’t subscribe to any subnets</li>
<li>There could be overlap between the long-lived and short-lived subnets</li>
</ul>
<p>Due to this reason, we continuously try to collect observations for each known beacon node per epoch, and save the maximum estimated validator counts. Note also that the ceiling for validator estimations is at <span class="math">64 - 2</span>, because that’s the maximum amount of short-lived subnets we can record. This is important! It means that for beacon nodes with more than <span class="math">62</span> validators, we can not estimate how many there are, and just record the ceiling. We want to highlight again that this is just an estimation and won’t be a very accurate representation of the total number of validators.</p>
<h2><a class="anchor" href="https://ethresear.ch#architecture-12" name="architecture-12"></a>Architecture</h2>
<p>In this section we’ll dive a bit deeper into the architecture. All the code for this is open source and can be found in this repository: <a class="inline-onebox" href="https://github.com/chainbound/valtrack" rel="noopener nofollow ugc">GitHub - chainbound/valtrack: An Ethereum validator crawler</a>. A lot of the crawler code is based on projects like <a href="https://github.com/probe-lab/hermes" rel="noopener nofollow ugc">Hermes</a> and <a href="https://github.com/migalabs/armiarma/" rel="noopener nofollow ugc">Armiarma</a>. An overview can be seen here:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e856490bf2dd28b100abeb8c0f37e50f389e882b.jpeg" title="image"><img alt="image" height="305" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e856490bf2dd28b100abeb8c0f37e50f389e882b_2_690x305.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#crawler-13" name="crawler-13"></a>Crawler</h3>
<p>The crawler is the core component of the system. It will crawl the discv5 discovery DHT, find nodes that are on the correct network by looking at the metadata in their ENRs, and then try to connect with them. It will keep a local cache of known peers and try to reconnect every epoch to get updated observations.</p>
<p>We outline 2 types of events (observations): <code>PeerDiscoveryEvent</code> and <code>MetadataReceivedEvent</code>. The second one is most relevant and contains the following fields:</p>
<pre><code class="lang-go">type MetadataReceivedEvent struct {
	ENR               string          `json:"enr"`
	ID                string          `json:"id"`
	Multiaddr         string          `json:"multiaddr"`
	Epoch             int             `json:"epoch"`
	MetaData          *eth.MetaDataV1 `json:"metadata"`
	SubscribedSubnets []int64         `json:"subscribed_subnets"`
	ClientVersion     string          `json:"client_version"`
	CrawlerID         string          `json:"crawler_id"`
	CrawlerLoc        string          `json:"crawler_location"`
	Timestamp         int64           `json:"timestamp"` // Timestamp in UNIX milliseconds
}
</code></pre>
<p>Along with some metadata, this contains all of the fields required to apply the previously described methodology: <code>SubscribedSubnets</code> contains the actually subscribed subnets, obtained by listening on the GossipSub domain, and <code>MetaData</code> contains the peer’s long-lived subnets.</p>
<p>All of these events are then sent to a persistent message queue, where they are stored until they’re read by the consumer.</p>
<h3><a class="anchor" href="https://ethresear.ch#consumer-14" name="consumer-14"></a>Consumer</h3>
<p>The consumer turns the event logs into a stateful view of the network by implementing the methodology described above. It parses the short-lived subnets from the metadata events to get the estimated validator counts, and updates any existing entries in its stateful view. This stateful view is saved in a local sqlite database, which we expose over an API. The table schema roughly looks like this:</p>
<pre><code class="lang-sql">validator_tracker (
	peer_id TEXT PRIMARY KEY,
	enr TEXT,
	multiaddr TEXT,
	ip TEXT,
	port INTEGER,
	last_seen INTEGER,
	last_epoch INTEGER,
	client_version TEXT,
	possible_validator BOOLEAN,
	max_validator_count INTEGER,
	num_observations INTEGER,
	hostname TEXT,
	city TEXT,
	region TEXT,
	country TEXT,
	latitude REAL,
	longitude REAL,
	postal_code TEXT,
	asn TEXT,	
	asn_organization TEXT,
	asn_type TEXT
)
</code></pre>
<p>We then join this data together with an IP location dataset to provide more information about geographical distribution.</p>
<h2><a class="anchor" href="https://ethresear.ch#results-15" name="results-15"></a>Results</h2>
<p><a href="https://www.chainbound.io/" rel="noopener nofollow ugc">Chainbound</a> runs a <a class="inline-onebox" href="https://github.com/chainbound/valtrack" rel="noopener nofollow ugc">GitHub - chainbound/valtrack: An Ethereum validator crawler</a> deployment that pushes all data to Dune every 24 hours.</p>
<blockquote>
<p><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> Dune table link: <a href="https://dune.com/data/dune.rig_ef.validator_metadata" rel="noopener nofollow ugc">https://dune.com/data/dune.rig_ef.validator_metadata</a>.</p>
</blockquote>
<p><em>This data has been stripped of sensitive information such as IP addresses and exact coordinates. However, it retains information like city, coordinates with a precision of a 10km radius, and ASN information.</em></p>
<p>An example dashboard leveraging this information can be seen <a href="https://chainbound.grafana.net/dashboard/snapshot/AmuaGRjfOrARoc7BWY9L43dD5jIgsgnf?orgId=1" rel="noopener nofollow ugc">here</a>.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e5a141037b8bcb98e8247ccb94f3daeeb2d143ce.jpeg" title="image"><img alt="image" height="360" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e5a141037b8bcb98e8247ccb94f3daeeb2d143ce_2_690x360.jpeg" width="690" /></a></div><p></p>
<p>We also store the individual event logs, like PeerDiscoveryEvent and MetadataReceivedEvent. These are available on demand by sending an email to <a href="mailto:admin@chainbound.io">admin@chainbound.io</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#limitations-16" name="limitations-16"></a>Limitations</h2>
<ul>
<li>The maximum number of validators we can estimate with this methodology per beacon node is 62, due to that being the maximum amount of short-lived subnet subscriptions. This will result in a significantly underreported total number of validators, but should still be able to provide a reasonable estimation of the geographical distribution.</li>
<li>We failed to gather any meaningful data on Teku nodes over the 30-day period, which could signify an error in our P2P implementation and impact the results.</li>
<li>These results will be skewed towards validators attached to beacon nodes that have opened P2P networking ports in their firewall, which will mostly be beacon nodes running on cloud providers. The reason for this is that our crawler can more easily connect to nodes that have exposed ports.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#references-17" name="references-17"></a>References</h2>
<ul>
<li><a class="inline-onebox" href="https://eth2book.info/capella/" rel="noopener nofollow ugc">Upgrading Ethereum</a></li>
<li><a class="inline-onebox" href="https://hackmd.io/@dmarz/ethereum_overlays" rel="noopener nofollow ugc">The Hitchhiker's Guide to P2P Overlays in Ethereum Consensus - HackMD</a></li>
<li><a class="inline-onebox" href="https://github.com/ethereum/consensus-specs/tree/dev" rel="noopener nofollow ugc">GitHub - ethereum/consensus-specs: Ethereum Proof-of-Stake Consensus Specifications</a></li>
</ul>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 08:33:30 +0000</pubDate>
</item>
<item>
<title>Presenting Klaster - rethinking chain abstraction</title>
<link>https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910</link>
<guid>https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910</guid>
<content:encoded><![CDATA[
<div> 关键词：Klaster、Interchain Transaction (iTx)、Transaction Commitment Layer、Smart Accounts、Cross-chain transaction flow

总结:
Klaster是一个旨在解决区块链碎片化问题的协议，通过引入网络节点（Klaster Nodes）作为用户和链之间的中介。核心概念包括iTx（跨链交易捆绑），它是一系列可能相互依赖的交易，跨越多个链。Klaster利用智能账户和ERC-4337 Entrypoint，通过经济激励建立可靠的节点网络，允许开发者构建链抽象应用，用户只需一次签名即可执行跨链事务。协议提供了一站式服务，简化复杂操作，如资产转移、交换等，提升了用户体验。Klaster正在测试阶段，未来将实现去中心化，增强网络可靠性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>We are witnessing an ever-growing list of new chains popping out, and attracting a high level of activity and transactions. Ethereum is also scaling nicely, and with the EIP-4844 it’s becoming increasingly cheaper to onboard as a user and start interacting with chains.</p>
<p>This introduces fragmentation, which in our opinion is here to stay especially in a world where there will be hundreds of chains, users will demand fragmentation to be solved for. If we build solutions that kind of aggregate different assets in some sort of “centralized” service only to make all chains look like one and make it easy to move across chains, then we haven’t accomplished much.</p>
<p>We propose a solution which abstracts away chains and solves for fragmentation by introducing <strong>Klaster</strong> - a network of nodes placed between the users and chains. This layer wraps multiple blockchain networks and makes it easy for users to execute complex transaction flows spanning across one or more chains - all of that approved by the single off-chain signature.</p>
<p>By introducing the Klaster Nodes as a generic execution network, and defining how cross-chain transactions are being bundled and approved, we hope to set the standard for building chain abstracted applications. This goes beyond just a simple balance abstraction - spend your funds from one chain by interacting on another chain. It provides a “full” chain abstraction by allowing any arbitrary flow to be defined and executed.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-2" name="tldr-2"></a>TL;DR</h1>
<p>Klaster Protocol aims to position itself as a chain abstraction framework which allows dApps or Wallets to build complex cross-chain transaction bundles and let the users sign only once to execute these bundles across one or more blockchain networks.</p>
<p>We introduce two key concepts:</p>
<ul>
<li><strong>iTx bundles</strong>: series of (possibly dependent) transactions spanning across many chains</li>
<li><strong>Transaction Commitment Layer</strong>: network of nodes providing execution guarantees and offering orchestrated iTx execution across many blockchain networks</li>
</ul>
<p>Klaster Protocol leans on Smart Accounts and ERC-4337 EntryPoint and by introducing the economic incentives provides a reliable network of Klaster Nodes which anyone can use to build truly chain abstracted dApps while not sacrificing on the security, or taking the control from the user.</p>
<h1><a class="anchor" href="https://ethresear.ch#klaster-3" name="klaster-3"></a>Klaster</h1>
<p>Klaster provides an infrastructure for building chain abstracted apps. Klaster does this by introducing a network of Nodes, which act as a <strong>Transaction Commitment Layer</strong>. This layer is placed between the dApp and multiple blockchain networks, It talks to the outside world (users, dApps) via <strong>interchain transactions (iTx)</strong>.</p>
<p>Developers can use these primitives to:</p>
<ul>
<li>Build chain abstracted dApps (no switch network button)</li>
<li>Define complex flows involving multiple chains without having to think of the specifics of how the flow will get executed</li>
<li>Automate the execution of the dependent actions spanning across many chains</li>
<li>Onboard the users from different chains and ecosystems into their dApp with a single user signature</li>
</ul>
<p>Users on the other hand:</p>
<ul>
<li>Can interact with chain abstracted dApps using any wallet they prefer</li>
<li>Don’t have to care of where their funds are, the dApp will be able to spend their funds from other chains with a single user signature</li>
<li>Don’t have to “lock” their funds in order for the dApp to consume their funds</li>
<li>Can use any asset on any chain to pay for gas cost of the full iTx execution involving many transactions on different chains</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#core-concepts-4" name="core-concepts-4"></a>Core concepts</h2>
<p>At its core, Klaster leans on its unique approach of <strong>separating transaction signing from<br />
the transaction execution</strong>.</p>
<p>If we think about how the EOA is executing a transaction on an EVM - it’s all bundled in the same operation - sign &amp; execute happening simultaneously with the user having one EOA wallet popup and interacting with the chain/RPC.</p>
<p>A more advanced approach can be seen with the Account Abstraction (ERC-4337), where users can approve their UserOp and then hand it over to the Bundler for execution. This approach is still bounded to one single chain - the one where the user’s smart account is deployed.</p>
<p>Klaster Model breaks the boundaries of a single chain, and allows an account owner to approve a complex series of (possibly dependent) UserOps targeting different blockchain networks - with a single off-chain signature! This signature is then provided to the Klaster Node (what would be a bundler in AA), for orchestrating an execution across all the different chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/5/755b51c20b470de874fc70cf3589d99577681458.jpeg" title="photo_2024-06-26_14-25-17"><img alt="photo_2024-06-26_14-25-17" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/7/5/755b51c20b470de874fc70cf3589d99577681458_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>As seen from the illustration above, if the user wanted to bridge funds and then swap on the destination chain, they would usually execute two transactions, on two different applications (Bridge app &amp; then DEX app), while also having to pay for gas fees on two different chains.</p>
<p>By splitting the signature from the execution, Klaster is able to convert two actions into one <strong>iTx bundle</strong> and then execute them through the Klaster Node. Klaster node will figure out the ordering of transactions, and execute them as user intended, while also covering for execution fees.</p>
<h2><a class="anchor" href="https://ethresear.ch#interchain-transaction-itx-bundle-5" name="interchain-transaction-itx-bundle-5"></a>Interchain Transaction (iTx bundle)</h2>
<p><strong>Interchain Transaction (iTx)</strong> is the fundamental working unit used within the Klaster protocol. It’s a bundle of one or more blockchain transactions spanning across one or more blockchain networks. It fully describes what the user or the dApp is trying to achieve. One iTx, consisting of two transactions, might be: “bridge assets from chain A using some 3rd party bridge to chain B, and then swap bridged assets for something else on chain B”.</p>
<p>From the Klaster Protocol perspective, one iTx bundle is actually a Merkle Tree of all the UserOps as leaves, and is defined by its Merkle Root hash (iTx hash): <strong>one iTx bundle = one unique iTx hash</strong>.</p>
<p>Any on-chain interaction on any blockchain network can be converted to the UserOp and placed as a part of a bigger iTx Merkle Tree - meaning the iTx tree approach can be used to basically define any complex operation spanning across multiple blockchain networks provided that there’s at least some liquidity services connecting the chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/a/2a26e4bc6a55b451b319a567816c3f9fd11c8b5a.jpeg" title="photo_2024-06-26_14-27-23"><img alt="photo_2024-06-26_14-27-23" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/2/a/2a26e4bc6a55b451b319a567816c3f9fd11c8b5a_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>Transaction Commitment Layer takes unsigned iTx requests, and <strong>commits</strong> to execute them in the specific time frame - and therefore provides a reliable execution layer capable of executing the parts of the iTx on different blockchain networks. This involves strategically determining the optimal order for executing the individual transactions within the bundle. For instance, if a transaction on Polygon relies on assets being transferred from Ethereum first, the node will ensure that the Ethereum transfer is finalized before proceeding with the Polygon transaction.</p>
<h2><a class="anchor" href="https://ethresear.ch#high-level-protocol-overview-6" name="high-level-protocol-overview-6"></a>High Level Protocol Overview</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/4/44e74558671473aa21b67bb54151e8dea1ce9070.jpeg" title="photo_2024-06-26_14-28-18"><img alt="photo_2024-06-26_14-28-18" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/4/4/44e74558671473aa21b67bb54151e8dea1ce9070_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>The following steps are involved for the user/dApp to interact with the Klaster Protocol:</p>
<ol>
<li>dApp defines a list of operations to be executed across one or many chains and bundle them together into the iTx</li>
<li>dApp asks the Klaster Network for a quote (fee) for executing an iTx</li>
<li>dApp receives back the iTx with included fee amount and cryptographic execution guarantees given by the Klaster Network</li>
<li>User signs the iTx by signing its root iTx hash and then broadcasts the signed iTx back to the Klaster Network</li>
</ol>
<p>Once the Klaster Network receives the signed iTx, it will charge the user upfront by pulling the fee amount as defined in the quote, and it will start processing the transactions from the iTx bundle, executing them on the different blockchain networks in the correct order. The specifics of how the fee is being calculated and charged upfront is outlined in the technical breakdown section.</p>
<h2><a class="anchor" href="https://ethresear.ch#chain-abstraction-vs-balance-abstraction-aave-example-7" name="chain-abstraction-vs-balance-abstraction-aave-example-7"></a>Chain Abstraction vs Balance Abstraction (AAVE example)</h2>
<p>While balance abstraction is a great step forward in solving for liquidity fragmentation, it’s not covering all bases. Let’s say we want to build a chain abstracted version of AAVE, where users can interact with the dApp not only by having the “balance” abstracted away (supply assets from one chain to AAVE deployed on another chain), but also having an <strong>AAVE “position” abstracted</strong> away which is a more dApp specific use-case.</p>
<p>For example, a user might have 100 USDC supplied on AAVE on Optimism, but they want to switch the position to Base, and supply USDC there, because of better rates. Or there’s a bot that wants to do this periodically, in the user’s name and with the user’s approval.</p>
<p>Right now, the user would have to unwind their position, find a bridge to use, move liquidity to Base and then resupply the USDC. This involves signing multiple transactions and switching between multiple frontends and blockchain networks / RPCs, not to mention also having some gas dust on these chains to be able to execute transactions in the first place. We believe this is unsustainable and there has to be a way of “standardizing” these interactions &amp; making life easier on the user facing side.</p>
<p>By using Klaster protocol, this complicated “position” rebalancing operation can be converted to one simple iTx bundle containing three UserOps:</p>
<ul>
<li>[<em>Optimism</em>] UserOp1: unwinds AAVE USDC position on Optimism</li>
<li>[<em>Optimism</em>] UserOp2: bridges 100 USDC to Base using some third party bridge (across bridge, for example)</li>
<li>[<em>Base</em>] UserOp3: supplies 100 USDC on AAVE</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/a/aaccd85ed18ac9bacdc8cfe3806eb872019b0363.jpeg" title="photo_2024-06-26_14-35-03"><img alt="photo_2024-06-26_14-35-03" height="390" src="https://ethresear.ch/uploads/default/optimized/3X/a/a/aaccd85ed18ac9bacdc8cfe3806eb872019b0363_2_690x390.jpeg" width="690" /></a></div><p></p>
<p>The only thing the user would have to do from their side is provide one signature for the iTx and the balance reposition would be handled by the Klaster Protocol automatically. No gas required on the destination chain. No different apps involved. One simple signature. And we bet that if the developers are provided with tools like Klaster, many more other interesting use-cases might emerge other than the one we’re describing here.</p>
<h1><a class="anchor" href="https://ethresear.ch#technical-breakdown-i-want-to-know-more-8" name="technical-breakdown-i-want-to-know-more-8"></a>Technical Breakdown (I want to know more)</h1>
<h2><a class="anchor" href="https://ethresear.ch#smart-accounts-itx-module-9" name="smart-accounts-itx-module-9"></a>Smart Accounts - iTx Module</h2>
<p>Using an iTx bundle in combination with Smart Contract Accounts allows for one very powerful feature to be implemented - and is there to help on the UX side: <strong>single signature iTx approvals</strong>.</p>
<p>Smart Account modular architecture allows for building a standardized ERC-7579 module which “understands” iTx bundles and can be installed on top of existing smart account wallets or used to initialize new wallets as the UserOp model allows for providing the wallet initialization data as a UserOp parameter.</p>
<p>A smart account owner can approve the whole iTx bundle of many chain transactions by only <strong>signing once</strong> - one off-chain signature of the iTx Merkle Root hash can be used to approve for executing all the transactions across many chains.</p>
<p>As mentioned earlier, the tree is defined by its Merkle root hash - iTx hash. The smart contract owner signs the iTx hash with a signer. This typically is an EOA which is a common owner of all the smart accounts across different chains where the assets are being bridged and consumed, and by providing one signature, all of these operations are immediately executable.</p>
<p>If the user doesn’t have a smart contract account on one or more blockchain networks - the accounts can be “lazy deployed” for the user - meaning, the iTx bundle can contain an operation which bridges some amount of funds to the “not yet created” account as the address of the smart account can be precomputed.</p>
<p>By having the iTx validation module as a standardized module - Klaster protocol remains neutral &amp; unopiniated - it can work with different smart account providers.</p>
<h2><a class="anchor" href="https://ethresear.ch#klaster-fees-node-selection-10" name="klaster-fees-node-selection-10"></a>Klaster Fees &amp; Node Selection</h2>
<p>The Klaster Transaction Commitment Layer consists of many Klaster Nodes - all of them being equal. Every Node is defined by its wallet address, and in order for nodes to join the network, they have to stake capital - this is how the nodes provide uptime &amp; execution guarantees.</p>
<p>Klaster Nodes are taking care of the following:</p>
<ol>
<li>Estimating iTx fees &amp; responding to quote requests</li>
<li>Committing to iTx execution (or rejecting the request)</li>
<li>Executing fully signed iTx (if previously committed to execution)</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#estimating-itx-fees-responding-to-quote-requests-11" name="estimating-itx-fees-responding-to-quote-requests-11"></a>Estimating iTx fees &amp; responding to quote requests</h3>
<p>When the user or the dApp asks the protocol for quotes, every node will estimate the total cost of executing the iTx on different chains. The node adds its own fee on top of the total cost, including the <strong>success execution tip</strong> (more on this in the “optimistic execution” chapter) and responds back with the full cost the user will have to pay in order for the node to do the job.</p>
<h3><a class="anchor" href="https://ethresear.ch#committing-to-itx-execution-or-rejecting-the-request-12" name="committing-to-itx-execution-or-rejecting-the-request-12"></a>Committing to iTx execution (or rejecting the request)</h3>
<p>The user or the dApp chooses the best received quote by taking into account the total execution cost offered by each of the nodes, and their reputation. The dApp then connects directly with the selected node, and asks for a commitment - a guarantee from the node that they are going to execute the iTx in full, provided that the user pays for what the node asks for.</p>
<p>The node commits to the iTx execution by</p>
<ol>
<li>Prepending the payment tx* in the list of the transactions in the iTx bundle</li>
<li>Signing the root iTx hash with its own private key - essentially binding itself to the execution of the iTx</li>
</ol>
<p>*<em>A payment transaction generated and prepended by the node transfers some liquid asset from the user’s account to the node wallet address. The asset is selected by the user and the amount is calculated by the node to cover for all the execution costs + the node fee. This means that the user can pay for the execution on any chain and in any asset supported by the node.</em></p>
<h3><a class="anchor" href="https://ethresear.ch#executing-fully-signed-itx-if-previously-committed-to-execution-13" name="executing-fully-signed-itx-if-previously-committed-to-execution-13"></a>Executing fully signed iTx (if previously committed to execution)</h3>
<p>Once the dApp receives the iTx which includes the payment transaction and the node commitment, the user is finally prompted to approve the full iTx bundle by signing the root iTx hash - essentially approving the execution of all the transactions contained in the bundle. The iTx bundle, whose root iTx hash has been signed by both the node (commitment) &amp; user (execution approval) is sent to back the selected node which:</p>
<ol>
<li>Verifies the iTx bundle integrity (calculates &amp; verifies merkle root)</li>
<li>Verifies the commitment signature (make sure the node really did commit to this iTx)</li>
<li>Verifies the user signature</li>
<li>Collects the payment from the user (the first transaction in the iTx bundle)</li>
<li>Once the payment is complete, proceeds to execute the rest of the operations by performing the optimistic execution algorithm</li>
</ol>
<p>If the node fails to execute the iTx bundle, the user can use the node commitment (node iTx signature) to initiate a slashing request and prove on-chain that the node actually promised to execute the iTx but failed to do so in a given timeframe.</p>
<h2><a class="anchor" href="https://ethresear.ch#meta-paymaster-and-multichain-gas-refunds-14" name="meta-paymaster-and-multichain-gas-refunds-14"></a>Meta Paymaster and Multichain Gas Refunds</h2>
<p>For the node to be fully operational, they have to own the native coin balance on their wallet address for every chain they support - in order to be able to pay for gas and execute UserOps as a part of iTx bundle. By accepting the upfront payment from the user in one token and one chain, and then executing the transactions and subsidizing gas on one or more chains, Klaster Node acts in a way as a Meta Paymaster.</p>
<p>The node executes UserOps contained in the iTx by routing them through the official ERC-4337 EntryPoint on different chains, and after receiving post-operation execution callbacks with the actual gas consumption data, the node will execute refunds for every processed UserOp, that is if actual UserOp cost (including the Klaster Node fee) was less than the maximum UserOp that was prepaid by the user. The process is illustrated below:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/c/9ca11c122eee71670ddf3e95a2ecee88cf427bcb.png" title="klaster-meta-paymaster-latest"><img alt="klaster-meta-paymaster-latest" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/c/9ca11c122eee71670ddf3e95a2ecee88cf427bcb_2_569x500.png" width="569" /></a></div><p></p>
<p>By relying on the official ERC-4337 EntryPoint for UserOp routing, the Klaster Protocol is staying compliant with the AA space, since most of the AA wallets today choose to trust and give control to one EntryPoint contract. Any existing AA wallet could technically activate the Klaster iTx module and gain cross-chain capabilities.</p>
<h2><a class="anchor" href="https://ethresear.ch#optimistic-itx-execution-15" name="optimistic-itx-execution-15"></a>Optimistic iTx Execution</h2>
<p>Klaster Node is incentivized to execute UserOps from a given iTx bundle in the right order of events, without the user having to explicitly provide the order of events.</p>
<p>The right order of events is implicitly deduced by the Klaster Node, by repeatedly simulating every UserOp, between the timestamp deadlines set by the user when defining UserOp, and waiting for the simulation to yield 0 <em>REVERT</em> opcodes in the simulated execution breakdown. Once this happens, Klaster Node “knows” all the preconditions have been met (whatever they may be) and will proceed to execute the UserOp as this maxmizes the profits for the Klaster Node.</p>
<p>In our AAVE example from above, Klaster Node will wait for the bridge action to complete without having to be aware of which bridge is being used and what the estimated bridge time to destination might be. It’s not even aware of the context of any UserOp or the potential dependencies between those. The execution flow would look like this:</p>
<ol start="0">
<li>
<p>The Node executes the Payment UserOp (at index 0 in the list of UserOps). That way the Node charges for the full execution of all the other UserOps upfront and can proceed with the next steps</p>
</li>
<li>
<p>The Node “sees” that out of three UserOps (<strong>unwind, bridge, supply</strong>), the only one with 0 REVERTs is the <strong>unwind</strong> operation, and it proceeds to execute the UserOp successfully (on Optimism)</p>
</li>
<li>
<p>Afterward, another operation that yields 0 REVERTs is the bridge operation as the funds are now there to be bridged (unwinded position), so it proceeds to execute <strong>bridge</strong> action (on Optimism)</p>
</li>
<li>
<p>Finally, once the funds arrive at the user’s dest chain smart account (whenever that may be, depending on the 3rd party bridge being used), the <strong>supply</strong> operation is executed which marks the full iTx execution as complete.</p>
</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/b/bb781b0246065508b7a832ee5060408e61d20a87.jpeg" title="photo_2024-06-26_14-45-59"><img alt="photo_2024-06-26_14-45-59" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/b/b/bb781b0246065508b7a832ee5060408e61d20a87_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>By having this generic approach of not being aware of the context, iTx bundles can express pretty much any complex cross-chain flow. To incentivize the node to wait for the simulation success (0 REVERTs), but then also to execute the UserOp <strong>as soon as 0 REVERT is detected,</strong> Klaster fee will include the <strong>diminishing success tip</strong>. This fee can be collected by the Node only if the UserOp was executed with 0 REVERT status and the tip is fading to 0 as the UserOp execution moment is closing to the upper bound execution timestamp.</p>
<p><em>It is still possible for some of the UserOps to fail, for example, 3rd party bridge not working properly. In that case - the node has fulfilled its obligation, as it’s recorded on-chain that the node “attempted” to execute the UserOp, although the funds haven’t reached the destination chain. In that case, the node is protected from slashing, while the user experienced a partially executed iTx. The funds are still owned by the user, and have remained on their wallet on one of the chains where the UserOp failed.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#integration-16" name="integration-16"></a>Integration</h1>
<p>dApp/Wallet developers will soon have access to the SDK, which in turn will allow for building chain abstracted applications much more efficiently, while staying neutral and not locking the developer to having to use any specific technology.</p>
<p>The developers are free to use any bridges or 3rd party services as a part of the iTx bundle - depending on the level of security/speed they require, and to rely on different AA wallet providers as the smart account wallets used behind the scenes.</p>
<p>On the user side, they have to sign once, and see their cross-chain intent being executed step by step without having to do any other action or even own gas funds on any of the chains they interact with.</p>
<p>This is how we see it developed further and how dApps might integrate the SDK in order to provide cross-chain experience to the end user:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65e8e1fa54439727f6d9a820b1d86e740f228025.jpeg" title="photo_2024-06-18_13-18-43"><img alt="photo_2024-06-18_13-18-43" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/6/5/65e8e1fa54439727f6d9a820b1d86e740f228025_2_690x315.jpeg" width="690" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#demo-use-cases-17" name="demo-use-cases-17"></a>Demo &amp; Use Cases</h1>
<p>At the moment, we’re building a chain abstracted AAVE dApp - to showcase what the protocol can do in terms of UX improvements.</p>
<p>The frontend will only contain two buttons: “supply” &amp; “borrow” without specifying the chains. When executing borrow or supply, user’s funds will be routed to any chain where the AAVE market’s rates are most favorable, regardless of the fact which chain the user’s funds are on.</p>
<p>If the user wants to rebalance the existing position, again, it’s a one-click interaction for the user, but in the background, iTx is being executed by the Klaster Nodes.</p>
<p>Some other interesting use cases:</p>
<ul>
<li>streamlined checkout flows</li>
<li>easier onboarding to the SocialFi L2/L3 apps, as Klaster protocol works with AA by default, and many of these apps choose to have embedded wallets generated for the users behind the scenes</li>
<li>building chain abstracted flavors of dapps that are natively multichain (DEXs, lending markets, NFT marketplaces)</li>
<li>single-chain dApps can use the Klaster Stack to streamline onboarding flows, attracting users from various chains. With Klaster Stack, users can interact with the dApp in just one click, regardless of their original blockchain</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#faq-18" name="faq-18"></a>FAQ</h1>
<p><strong>Q: Is Klaster a Blockchain Network?</strong><br />
A: No.</p>
<p><strong>Q: What’s the current development status?</strong></p>
<p>A: Centralized Klaster Node including the SDK and the docs is in the testing phase and will be launched very soon. The decentralization phase including the slashing and multichain staking which in turn makes the network more reliable will most likely be rolled out later this year.</p>
<p><strong>Q: What are the dangers of using Klaster Protocol?</strong></p>
<p>A: Dangers are mostly related to the impaired UX.</p>
<p>For example, malicous Klaster Node can refuse to process an iTx bundle in full - they only execute the Payment UserOp part of the iTx bundle. The user can still replay their UserOps manually and achieve the same effect but will have to pay for gas execution themselves. Nodes on the other hand get slashed in the decentralized model because the user can submit a proof of Node commiting to execute the iTx but failing to do so in a given timeframe - which is fully verifiable on-chain. As the AA wallets are used behind the scenes, the user is in full control of their funds, and the security is reduced to security of bridges used as an intermediary steps to move assets between chains. Klaster’s iTx-enabled AA wallet module is pending audits and the reports will be shared soon.</p>
<p><strong>Q: Can I run my own node, and what are the advantages of running a node?</strong></p>
<p>A: Klaster Protocol will host its own public node, with the implementation publicly available for everyone to take a look and verify the inner workings of the Node itself. While the initial version of the protocol is not decentralized in a sense of having a p2p networking implemented between public Klaster nodes, anyone can still choose to run their own Klaster Node either for their own purposes (only handling one single dApp) or even providing this node for others to connect to.</p>
<p>New chains can spin up their own Klaster node to easily onboard users from other chains.</p>
<p>Klaster Node if operational earns a % of the total gas processed and is another revenue stream for Node operators. To set up a node, one needs to have a wallet connected to the node, and funded with native coin on every chain which the Node operator decides to support.</p>
<p><strong>Q: How does Klaster compare to other chain abstraction solutions?</strong></p>
<p>A: For a start, we think we have a unique approach here in being highly focused on the UX part. We’re trying to stay as generic and as neutral as possible, and we’ve developed something that can be used today to fix the UX in some ways. Comparing to some other approaches we see being built in this space, Klaster’s main difference is that Klaster doesn’t work with liquidity nor does it require the Node operators to provide liquidity - meaning it’s easier to run the network and gain an initial base of Node operators. It doesn’t try to be “one solution fits all” which hides away blockchains completely, but rather a framework where, given the fact that the cross-chain action details are known upfront - it enables developers to easily define and build the action, and for the user to sign once and see the effects happening on different chains.</p>
<p><strong>Q: Where does Klaster Protocol fit in the CAKE framework?</strong></p>
<p>A: According to the CAKE Layer definitions, we’d say Klaster comes somewhere in the Settlement Layer (Execution part).</p>
<p><strong>Q: Is Klaster Protocol a bridge?</strong></p>
<p>A: Not really. Klaster Protocol can <em>wrap</em> bridges and other services to create a true cross-chain experience by having bridge action only there as a one step of the more comple iTx interaction.</p>
<p><strong>Q: I want to know more about the slashing process. Why do the Nodes have to stake capital, and how does slashing work?</strong></p>
<p>A: Klaster Nodes have to execute iTx bundles if they previously “promised” to the user they will do so. There has to be a way of punishing the Node for not doing their job - or even worse, collecting the fee payment from the user but never executing their desired intent. To make this possible, Klaster Nodes have to stake capital in order to be accepted by the network and allowed to execute iTx bundles on user’s behalf.</p>
<p>Every UserOp contains lower and upper bound timestamps, and the interval between these are when the UserOp is considered valid and can be executed on-chain. When the Node builds a full iTx tree, and signs the root iTx hash with their private key - we say the Node is “commited” to the iTx. The user has received the full quote including the Node commitment, and can use this commitment to initiate a slashing procedure if the nonce of the user’s smart account was not increased by one in the given timeframe, on any chain where their UserOp was <strong>not executed</strong>.</p>
<p><strong>Q: Is Klaster Protocol actually an Intent Solver network?</strong></p>
<p>A: Not really. Intents mean the user describes the end-result state and <em>someone somehow</em> finds the solution to the steps (txs) required to achieve the desired outcome. Klaster takes a completely opposite approach. The design space of the intent solvers is just too big and solving for all cases using intents is simply too complicated. We say - let’s make the system more exact, in a sense that, we assume that the developers of either dApps or wallets will always know upfront what exactly they want to achieve - and then let’s give them tools and means of how to express this interaction (iTx bundle) while making it easy for users to approve and execute these iTx bundles.</p>
<p>Klaster Protocol though is a great tool for Intent Solvers to express &amp; execute their “paths of execution” once they solve for some specific user’s request.</p>
<p><strong>Q: What’s the role of AA Wallets in the Klaster Protocol?</strong></p>
<p>A: AA Wallet is the only viable option for Klaster Protocol to work. Since we need to be able to have the user authorize many actions with only one signature - the only possibility for this to work is to actually use programmable smart contract wallets.</p>
<p><strong>Q: How is the Node protected from users? How are the users protected from the Node?</strong></p>
<p>A: The Node charges for its service fee plus all the other execution gas costs upfront. This way, the node might overcharge for the gas spendings, but the user will still get charged fairly if the actual gas spent was lower than what the node calculated. The Node will not commit to execute the iTx if the iTx looks risky - too short timespans for the UserOp execution, or the UserOp execution window which starts far away in the future (gas price spike risks).</p>
<p>The user is protected from the Node by being the only owner of the AA Wallet which used to execute iTx steps. Even if the Klaster Network dies completely, the user can still access and manage funds. The Klaster Node can only do what the user explicitly signs &amp; approves.</p>
<p><strong>Q: Does the user need to own the funds on the AA Wallet to interact with the Klaster Protocol in the first place?</strong></p>
<p>A: Unfortunately yes. If the user’s coming with an EOA wallet and assets are held by this EOA, the user will have to execute at least one EOA transaction and move funds from this wallet to an iTx enabled AA wallet to be able to use Klaster for chain abstraction / gas abstraction purposes. Luckily, the EIP-7702 which is confirmed will improve this flow substantially.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 13:13:35 +0000</pubDate>
</item>
<item>
<title>Pricing Gas Fee Derivatives</title>
<link>https://ethresear.ch/t/pricing-gas-fee-derivatives/19898</link>
<guid>https://ethresear.ch/t/pricing-gas-fee-derivatives/19898</guid>
<content:encoded><![CDATA[
<p><em>Thanks to Nethermind, <a class="mention" href="https://ethresear.ch/u/tkstanczak">@tkstanczak</a>, <a class="mention" href="https://ethresear.ch/u/swapnilraj">@swapnilraj</a> , <a class="mention" href="https://ethresear.ch/u/dapplion">@dapplion</a>, Martin Koppelmann and <a class="mention" href="https://ethresear.ch/u/drewvanderwerff">@DrewVanderWerff</a> for discussion, feedback and review.</em></p>
<p><strong>This is the first instalment in a series of posts where I will outline a methodology for understanding and pricing gas derivatives. The following approach for pricing will be valuable for gas hedging and can also be applied to develop a subscription model for Ethereum.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/0/2075264e1980cd984ec67a32af4bbe1689af4874.jpeg" title="There-Will-Be-Blood1-ezgif.com-webp-to-jpg-converter"><img alt="There-Will-Be-Blood1-ezgif.com-webp-to-jpg-converter" height="460" src="https://ethresear.ch/uploads/default/optimized/3X/2/0/2075264e1980cd984ec67a32af4bbe1689af4874_2_690x460.jpeg" width="690" /></a></div><p></p>
<p><em>There Will Be Blood” (2007) - are we going to be unwitting extras in the ‘digital oil’ sequel?</em></p>
<p><strong>TLDR:</strong> I show how a two-factor model can be used to price base fee options, of both European and American type. A developed gas derivatives market would be highly beneficial for participants looking to hedge against volatile operational expenses on gas or for those aiming to speculate on future gas fee trends.</p>
<p><strong>Why Price Base Fee Derivatives?</strong></p>
<p>Gas expenditure is a substantial portion of operational costs within blockchain ecosystems. Whether it involves L2 sequencers committing transactions to L1, the running of a DeFi protocols keeper, interacting with oracle contracts, rebalancing liquidity on platforms like Uniswap, verifying proofs, or conducting arbitrage, gas fees are an unpredictable expense. This inherent volatility poses challenges for financial planning and budgeting in blockchain operations. Gas hedging, analogous to its counterpart in traditional financial markets, provides a mechanism to manage and mitigate this uncertainty.</p>
<p>By purchasing gas derivatives, stakeholders can secure current gas fee levels for future transactions, effectively insuring against unforeseen spikes in gas prices. Additionally, with a strike price of zero on a call option, one can fully prepay for gas, paving the way for a ‘gas subscription’ model on Ethereum—assuming a delivery mechanism is established. This research could be particularly useful for pre-confirmations, where blockspace is purchased in advance.</p>
<p>The following post breaks down the importance of understanding base fees, examining their volatility, and proposing a detailed model for pricing base fee derivatives. The first section delves into the calculation of base fees, while the second outlines their structure. In the third section, a model incorporating both deterministic and stochastic components is detailed to simulate base fees using a Monte Carlo process. The fourth and final section explains how to use these Monte Carlo generated paths to price base fee options, including both European and American types. Use cases of this research include participants that want to examine the fair value of a base fee option, a task helpful for those interacting with derivative protocols like Oiler’s Pitch lake <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018" rel="noopener nofollow ugc">[1]</a>.</p>
<p>This post is the first in a series on the topic, aimed at sparking interest among both Ethereum researchers and traders. My goal is to engage quants in the conversation around Ethereum infrastructure.</p>
<p><strong>Understanding Base Fees</strong></p>
<p>Before pricing base fees, we should understand its constituent parts. EIP-1559, implemented in the London hard fork of Ethereum in August 2021, introduced a significant overhaul to the transaction fee mechanism on the Ethereum network. The proposal aimed to improve the predictability and efficiency of transaction fees, addressing several issues inherent in the previous auction-based system. Under EIP-1559, each block has a base fee, which is dynamically adjusted according to network congestion. When demand for block space increases, the base fee rises, and when demand decreases, the base fee falls. This mechanism helps to stabilize transaction fees and makes them more predictable for users.</p>
<p>The specific adjustment rule proposed in the EIP-1559 spec computes the base fee <span class="math">BF_{\text{cur}}</span> for the current block from the base fee <span class="math">BF_{\text{pred}}</span> and size <span class="math">s_{\text{pred}}</span> of the predecessor block using the following formula, where <span class="math">s_{\text{target}}</span> denotes the target block size:</p>
<div class="math">
BF_{\text{cur}} := BF_{\text{pred}} \cdot \left( 1 + \frac{1}{8} \cdot \frac{s_{\text{pred}} - s_{\text{target}}}{s_{\text{target}}} \right)

</div>
<p>In short, the next base fee is adjusted by a percentage that equals one-eighth of the difference to the target percentage - meaning base fees are within the bounds of 12.5% higher or lower than the previous block. As is visible below when comparing gas usage, full blocks of 30M are most frequent, with gas usage of just below 13M second most frequent.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/3/f3ef180d0b94b634c3727e72c56bcf12cb7ccbfa.png" title="Histogram"><img alt="Histogram" height="500" src="https://ethresear.ch/uploads/default/original/3X/f/3/f3ef180d0b94b634c3727e72c56bcf12cb7ccbfa.png" width="657" /></a></div><p></p>
<p><strong>Those Are Some Large Percentage Changes… Why Are Base Fees So Volatile?</strong></p>
<p>Several factors contribute to the high volatility of base fees, with the non-storability of base fees and the limited block-space supply being the most significant. Since block-space has a strict limit to 30M gas, which cannot be stored or transferred over time, supply in each time period is fixed, while demand can fluctuate based on usage needs. Base fees for transactions is thus demand inelastic. Consequently, during periods of low demand, the base fee remains relatively stable. However, during peak times, the relative insensitivity of demand to price changes can lead to significant volatility in short-term base fee prices—‘Jumps’. This situation is similar to the electricity market, where demand remains high regardless of price, causing extreme price volatility during peak usage. In the blockchain context, the necessity of paying the base fee to conduct transactions ensures somewhat steady demand, even as prices fluctuate dramatically.</p>
<p>Additionally, since base fees are influenced by the previous base fee, a block with high demand for blockspace—such as one resulting from the deployment of a large simultaneous smart-contract architecture—will primarily impact users in the following block. Users pay for blockspace based on the previous blocks usage, not the current one. Consequently, in the short term, a deployer will not always experience the negative externalities of increasing gas fees for near-future blockchain users. This creates a scenario where users are indifferent to increasing base fees by the cap of 12.5%. Current discussions, as well researched by SMG <a href="https://www.mechanism.org/spec/04" rel="noopener nofollow ugc">[2]</a>, suggest to minimise this externality, and subsequent short-term volatility by modifying the denominator to a higher value. The change would reduce sensitivity to randomness in gas usage and better align the process with underlying trends, improving stability and predictability.</p>
<p><strong>Characteristics of Base Fees</strong></p>
<p>Base fees can be simulated through understanding the structure of gas usage, before feeding the resulting parameters into the <span class="math">BF_{\text{cur}}</span> equation to find the base fees, or observing base fees themself. The model I propose focuses on the latter, as a result of my focus being on hourly averaged base fees for use in 1 day plus dated options, and a focus on gas usage would also mean accounting for variable gas limits. The model I am proposing is very flexible, and allow us to simultaneously include trends, seasonality, mean reversion, volatility and jumps.</p>
<p><strong>Overarching Trend</strong></p>
<p>Unlike electricity, wherein supply can vary, base fees relate directly to the demand side usage of a product, a blockchain. When a new EIP is passed as to change the structure of base fees, or if gas usage dramatically decreases. Unlike electricity, trends in gas usage are far shorter and dissimilar to one another, trends should thus be likened to regimes. For example, one regime may be a simple horizontal linear trend in periods of stable usage,  where another is an exponential trend downwards as a result of blobs being recently introduced.</p>
<p><strong>Seasonality</strong></p>
<p>Base Fee demand is heavily influenced by varying usage of economic and business activities of agents on the underlying blockchain. Different kinds of seasonality appear in the data; intra-daily and weekly. As it is usual in this type of research, I assume that seasonality is generated by deterministic factors and since I use the average hourly prices.</p>
<p><strong>Mean-reversion</strong></p>
<p>In the short term, during periods of high demand, base fees spike, discouraging excessive gas usage, which in turn reduces congestion and drives fees back down. Conversely, during low demand periods, lower fees encourage more transactions, increasing congestion and pushing fees back up. This cyclical nature of congestion creates a mean-reverting behaviour in base fees. Essentially, despite short-term fluctuations, base fees tend to stabilize around an average level, influenced by the balance of demand and network capacity.</p>
<p><strong>Jumps and volatility</strong></p>
<p>By simple eye inspection of base fees over time, there is clear existence of important jumps in the behaviour of base fees, as a result of sequential filling of blocks. One of the characteristics of evolution of these jumps is that the base fees do not stay in the new level, to which it jumps, but revert to the previous level rapidly. Such a behaviour can be captured by introducing a jump-diffusion component to a simulation model.</p>
<h2><a class="anchor" href="https://ethresear.ch#pricing-base-fees-1" name="pricing-base-fees-1"></a><strong>Pricing Base Fees</strong></h2>
<p>How should one price option premiums? Determining the appropriate pricing model for gas fees involves understanding their nature and selecting an appropriate financial framework. Gas fees could be treated as equities, interest rates, or commodities, each with distinct modelling approaches. Popular analytical models like the Black-Scholes closed-form model, often used for equities, offer theoretical insights into price movements and volatility - but in the case of base fees, the underlying assumption of normality in returns would be too naive, and the mean reversion and seasonality present in base fees wouldn’t be accounted for. Alternatively, numerical methods such as finite difference and Monte Carlo simulations would provide far more flexible and robust techniques for capturing the stochastic and path dependent nature of base fees. I therefore opt for the Monte Carlo simulation approach.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-specification-and-estimation-2" name="model-specification-and-estimation-2"></a><strong>Model Specification and Estimation</strong></h2>
<p><strong>Exponential Trend Examination</strong></p>
<p>I first assess the presence of an exponential trend by computing the weekly statistics of the mean and standard deviation. If the spot price series exhibits an exponential trend, then the means and standard deviations, computed over time periods, should be correlated with a statistically significant slope.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/f/ffd93a4891dbf0193c6c5b3a00494d51f2569a4a.jpeg" title="Figure_1"><img alt="Figure_1" height="449" src="https://ethresear.ch/uploads/default/optimized/3X/f/f/ffd93a4891dbf0193c6c5b3a00494d51f2569a4a_2_690x449.jpeg" width="690" /></a></div><p></p>
<p>Demonstrated by a p-value close to zero (4.43e-18), an exponential trend is evident in the data. When base fees are high, base fees are volatile. Consequently, to simplify modelling and work with linear trends, I from hereon out use the logarithm of the base fee.</p>
<h3><a class="anchor" href="https://ethresear.ch#deterministic-model-specification-3" name="deterministic-model-specification-3"></a><strong>Deterministic Model Specification</strong></h3>
<p>We have seen in the previous section that a reasonable model for base fee prices should allow for the existence of deterministic seasonality, the possibility of mean-reversion, seasonality jumps, and volatility (randomness). Therefore, I propose a model that simultaneously incorporates all these factors in a flexible way.</p>
<p>The combined long-term model can be written as the composite of a deterministic component <span class="math">f(t)</span> and a stochastic component <span class="math">X_t</span>:</p>
<div class="math">
\log(BF_t) = f(t) + X_t
</div>
<p><strong>Estimation of Deterministic Component</strong> <span class="math">f(t)</span></p>
<p>The deterministic component  <span class="math">f(t)</span> is given by the sum of piecewise regime-based quadratic polynomial trends and sinusoidal functions corresponding to different harmonics and periods:</p>
<div class="math">
f(t) = \sum_{i=1}^{m} \mathbb{I}{\{t \in R_i\}} \left( \gamma{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2 \right) + \beta_1 \sin\left(\frac{2\pi t}{24}\right) + \beta_2 \cos\left(\frac{2\pi t}{24}\right) \\
 + \beta_3 \sin\left(\frac{4\pi t}{24}\right) + \beta_4 \cos\left(\frac{4\pi t}{24}\right) + \beta_5 \sin\left(\frac{8\pi t}{24}\right) + \beta_6 \cos\left(\frac{8\pi t}{24}\right) \\
 + \beta_7 \sin\left(\frac{2\pi t}{168}\right) + \beta_8 \cos\left(\frac{2\pi t}{168}\right) + \beta_9 \sin\left(\frac{4\pi t}{168}\right) + \beta_{10} \cos\left(\frac{4\pi t}{168}\right) \\
 + \beta_{11} \sin\left(\frac{8\pi t}{168}\right) + \beta_{12} \cos\left(\frac{8\pi t}{168}\right) + \xi_t
</div>
<p>Where:</p>
<ul>
<li><span class="math">\log BF_t</span> is the logarithm of the base fees per gasat time (t).</li>
<li><span class="math">t</span> is the time in hours since the start of the sample.</li>
<li><span class="math">\beta_1</span> and <span class="math">\beta_2</span> are the coefficients for the fundamental daily seasonal components (1 day period).</li>
<li><span class="math">\beta_3</span> and <span class="math">\beta_4</span>  are the coefficients for the first harmonic daily seasonal components (1 day period).</li>
<li><span class="math">\beta_5</span> and <span class="math">\beta_6</span> are the coefficients for the second harmonic daily seasonal components (1 day period).</li>
<li><span class="math">\beta_7</span> and <span class="math">\beta_8</span> are the coefficients for the fundamental weekly seasonal components (7 day period).</li>
<li><span class="math">\beta_9</span> and <span class="math">\beta_{10}</span>  are the coefficients for the first harmonic weekly seasonal components (7 day period).</li>
<li><span class="math">\beta_{11}</span> and <span class="math">\beta_{12}</span> are the coefficients for the second harmonic weekly seasonal components (7 day period).</li>
<li><span class="math">\mathbb{I}_{\{t \in R_i\}}</span> is an indicator function that equals 1 if <span class="math">t</span> is within regime <span class="math">R_i</span> and 0 otherwise.</li>
<li><span class="math">\gamma_{i,0}</span>, <span class="math">\gamma_{i,1}</span>, and <span class="math">\gamma_{i,2}</span> are the coefficients for the piecewise polynomial trend within regime <span class="math">R_i</span>.</li>
<li><span class="math">\xi_t</span> is the error term.</li>
</ul>
<p>For each regime <span class="math">R_i</span>, I fit a quadratic model of the form:</p>
<div class="math">
z_i(t) = \gamma_{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2
</div>
<p>To discover the boundaries of each regime, I utilise binary segmentation for detection of change points within the time series. This technique employs a piecewise model, identifying changes based on the L2 norm (Euclidean distance). Initially, the algorithm treats the entire time series as a single segment, searching for a point that maximises the cost function by minimising the residual sum of squares. When a significant change point is identified, the segment is split, and the algorithm recursively continues this process until no further significant change points are found.</p>
<p>In our dataset of roughly two years, and discovered partially heuristically, I identify 16 change points, 17 regimes, with an initial regime immediately after EIP-1559’s release. This finding indicates that the underlying trend in base fees shifts approximately every half to two months. Such shifts are likely influenced by market events such as changes in market sentiment, or other critical factors, all of which could warrant their own focused research to fully understand their cause. I then discover the parameters <span class="math">\gamma_{i,0}</span>, <span class="math">\gamma_{i,1}</span>, <span class="math">\gamma_{i,2}</span> for each regime <span class="math">R_i</span>, using the least squares method. This involves minimising the sum of the squared differences between the observed values <span class="math">BF_t</span> and the predicted values <span class="math">z_i(t)</span> within each regime <span class="math">R_i</span>:</p>
<div class="math">
\min_{\gamma_{i,0}, \gamma_{i,1}, \gamma_{i,2}} \sum_{t \in R_i} \left( BF_t - (\gamma_{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2) \right)^2
</div>
<p>To solve this minimisation problem, I set up the following normal equations by taking partial derivatives with respect to each parameter and setting them to zero:</p>
<div class="math">
\frac{\partial}{\partial \hat{\gamma}_{i,0}} \sum{t \in R_i} \left( y_t - (\hat{\gamma_{i,0}} + \hat{\gamma}_{i,1}) + \hat{\gamma}_{i,2} t^2) \right)^2 = 0 \\
\frac{\partial}{\partial \hat{\gamma}_{i,1}} \sum_{t \in R_i} \left( y_t - (\hat{\gamma}_{i,0} + \hat{\gamma}_{i,1} t + \hat{\gamma}_{i,2} t^2) \right)^2 = 0 \\
\frac{\partial}{\partial \hat{\gamma}_{i,2}} \sum_{t \in R_i} \left( y_t - (\hat{\gamma}_{i,0} + \hat{\gamma}_{i,1} t + \hat{\gamma}_{i,2} t^2) \right)^2 = 0
</div>
<p>Solving these equations yields the least squares estimates for <span class="math">\hat{\gamma}_{i,0}</span><em>, <span class="math">\hat{\gamma}_{i,1}</span></em>, <span class="math">\hat{\gamma}_{i,2}</span>  for each regime <span class="math">R_i</span>. The below figure displays the resulting regimes and trend curves. The regression analysis has a low <span class="math">R^2</span> for the majority of regimes, indicating that the trends are well-fitted to the data. Notably, the current regime, characterised by the implementation of EIP-4844, differs markedly from the previous two regimes, as base fees dramatically decrease immediately after the fork, and are recovering upwards, likely due to the recent bull market activity. I eagerly ask for a discussion with respect to the underlying reasons for each trend.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/4935f9d2b9492a72761b825cbab25df5fc18342c.jpeg" title="Trends"><img alt="Trends" height="412" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/4935f9d2b9492a72761b825cbab25df5fc18342c_2_690x412.jpeg" width="690" /></a></div><p></p>
<p>To calibrate the seasonality components, I first analyse the seasonality present within the data. To do so, I performed a spectral analysis using the Fast Fourier Transform (FFT). The FFT decomposes the time-domain signal into its constituent frequencies, allowing us to compute the power spectrum, which represents the signal’s power distribution across different frequencies. I focused on the positive half of the spectrum and converted frequencies to periods in hours. Significant periodic components were identified by locating peaks in the power spectrum. The identified cycles, with the most prominent displaying daily (24 hours) and weekly (168 hours) seasonality, reinforcing the sinusoidal functions specified above. I visualise the results below to highlight the dominant seasonal patterns in the data.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/c/fc3302537e3548a88afc036869c60322fd6efed6.png" title="Period"><img alt="Period" height="413" src="https://ethresear.ch/uploads/default/original/3X/f/c/fc3302537e3548a88afc036869c60322fd6efed6.png" width="690" /></a></div><p></p>
<p>In estimating the <span class="math">\beta</span> parameters, I also use a least squares optimisation method. Given the observed log base fees <span class="math">BF</span> and the seasonality matrix <span class="math">C</span>, the objective is to estimate the seasonality parameters <span class="math">\beta</span> that minimise the sum of squared residuals. This is formulated as:</p>
<div class="math">
\min_{\beta} \| log(BF)_{detrended} - C \beta \|^2

</div>
<p>where:</p>
<ul>
<li><span class="math">log(BF)_{detrended}</span>  is the vector of de-trended log base fees,</li>
<li><span class="math">C</span>  is the matrix containing the seasonality functions (sine, cosine),</li>
<li><span class="math">\beta</span>  is the vector of seasonality parameters to be estimated.</li>
</ul>
<p>The expanded form of the objective function is:</p>
<div class="math">
\min_{\beta} \sum_{I=1}^{n} (log(BF_i)_{detrended} - C_i \beta)^2
</div>
<p>where  <span class="math">log(BF_i)_{detrended}</span> is the <span class="math">i</span> -th observed log base fee and <span class="math">C_i</span>  is the  <span class="math">i</span>-th row of the seasonality matrix. To find the least squares solution, I set the gradient of the objective function with respect to <span class="math">\beta</span> to zero, yielding the normal equations:</p>
<div class="math">
\frac{\partial}{\partial \beta} \left( \sum_{i=1}^{n} (log(BF_i)_{detrended} - C_i \beta)^2 \right) = -2 C^T (log(BF_i)_{detrended} - C \hat{\beta}) = 0
</div>
<p>Simplifying, I obtain:</p>
<div class="math">
C^T C \hat{\beta} = C^T log(BF)_{detrended}
</div>
<p>Solving the normal equations for  \beta  provides the least squares estimates:</p>
<div class="math">
\hat{\beta} = (C^T C)^{-1} C^T log(BF)_{detrended}
</div>
<p>where  <span class="math">(C^T C)^{-1} C^T</span>  is the Moore-Penrose pseudoinverse of <span class="math">C</span>. The de-seasonalized and de-trended log prices are then calculated by subtracting the combined seasonality components from the observed log prices, as is shown in the figure below.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f324d5ecfcda3c65cc3aebdbfbd09ac4e6bf621.png" title="Seasoned"><img alt="Seasoned" height="459" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f324d5ecfcda3c65cc3aebdbfbd09ac4e6bf621_2_690x459.png" width="690" /></a></div><p></p>
<p>Visibly, base fees in the Ethereum network fluctuate due to weekly and daily patterns of usage. During the week, gas usage is typically higher as business activities, market trading, and development deployments peaks. This weekly seasonality contrasts with daily patterns where peak periods of gas usage occur in the morning and evening as global participants, including Europe and North America, overlap in activity.</p>
<p>Despite removing trend and overarching seasonality, I observe that autocorrelative structure is still present in our time series. To address this, I explore the autocorrelation function (ACF) and the partial autocorrelation function (PACF) of the data. The ACF helps identify the correlation between observations at different lags of base fees, providing insights into the persistence of shocks over time. The PACF isolates the direct effect of a lagged observation by controlling for the contributions of intermediate lags, aiding in the identification of the order of the autoregressive (AR) terms in an ARIMA model. By observing the graph below, we observe 34 autocorrelated lags, and 5 partially autocorrelated lags.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/1/519bf7d93d2812acc39ec47dc5879a39ec44dca8.png" title="Autocorrelation"><img alt="Autocorrelation" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/1/519bf7d93d2812acc39ec47dc5879a39ec44dca8_2_532x500.png" width="532" /></a></div><p></p>
<p>To address these lags, I fit an ARIMA(34, 5, 5) model to the de-seasonalized and de-trended data. This model captures the autoregressive and moving average components along with differencing. By fitting this model, we obtain the residuals, which represent the underlying structure of the noise after accounting for these components. Upon examining the residuals, we find that the distribution of the noise is sharply centered around zero with fat tails. The transition between the central peak and the tails appears to follow an exponential pattern. Consequently, we fit a Laplace distribution to the residuals and compare the observed values against the expected values, where the Laplace distribution is defined as:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/520b0b7803ad250ea93fc680b158f762eb2571b0.png" title="StandardisedResidules"><img alt="StandardisedResidules" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/520b0b7803ad250ea93fc680b158f762eb2571b0_2_673x500.png" width="673" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65238658d70c03f7293ed41bb385d7eb95d65c7d.png" title="PDF"><img alt="PDF" height="499" src="https://ethresear.ch/uploads/default/original/3X/6/5/65238658d70c03f7293ed41bb385d7eb95d65c7d.png" width="690" /></a></div><p></p>
<div class="math">
f(x; \mu, b, \kappa) =
\begin{cases}
\frac{\kappa}{b} \exp \left( \frac{x - \mu}{b} \kappa \right), &amp; \text{if } x \leq \mu \\
\frac{1}{b \kappa} \exp \left( -\frac{x - \mu}{b \kappa} \right), &amp; \text{if } x &gt; \mu
\end{cases}
</div>
<ul>
<li><span class="math">\mu</span>  is the location parameter (mean),</li>
<li><span class="math">b &gt; 0</span>  is the scale parameter,</li>
<li><span class="math">\kappa &gt; 0</span>  controls the asymmetry of the distribution. a Kappa equal to 1 produces a symmetrical Laplace distribution.</li>
</ul>
<p>A Laplace distribution is significant because it characterises the distribution as having exponential decay on both sides of the peak. In the context of Ethereum base fees, changes often occur as a percentage of the previous base fee rather than by fixed amounts. This implies that large deviations from the mean are more probable than would be expected under a normal distribution, leading to the characteristic heavy tails of the Laplace distribution. The sharp central peak of the Laplace distribution indicates a high probability of small changes around the long term mean. The fat tails, on the other hand, reflect the occasional large percentage changes, driven by significant network, a series of full block events or structural shifts in demand for block space. One would expect a higher denominator parameter (reducing sensitivity of base fees to gas usage) to create a ‘tighter’ distribution with a lower standard deviation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/8359c539f8d3aae5ec27461b63895a852255410e.png" title="QQ"><img alt="QQ" height="482" src="https://ethresear.ch/uploads/default/original/3X/8/3/8359c539f8d3aae5ec27461b63895a852255410e.png" width="690" /></a></div><p></p>
<p>I plot the theoretical quantiles of the Laplace distribution against the observed residual quantiles in a QQ plot. The plot revealed that a few outlier observations exhibited fatter tails than predicted by the Laplace distribution, indicating that the residuals have more extreme values than our model accounts for. Nevertheless, the majority of the data points followed the expected distribution, suggesting that the Laplace distribution still provides a reasonable fit for the central portion of the residuals.</p>
<p><strong>Stochastic Component Specification</strong></p>
<div class="math">
X_t = \log BF_t - f(t)
</div>
<p><strong>Cox, Ingersoll &amp; Ross Poisson Asymmetrical Laplace calibrated model</strong></p>
<p>Removing the trend and observing the noise, the stochastic component <span class="math">X_t</span>  is modelled as an Ornstein-Uhlenbeck process (mean-reverting) with jumps, incorporating a Laplace distribution for both the noise term and the jump size</p>
<div class="math">
dX_t = (\alpha - \kappa X_t) \, dt + \sigma \, dL_t + J(\mu_J, \sigma_J) \, d\Pi(\lambda),
</div>
<p>where:</p>
<ul>
<li><span class="math">α</span> is the drift parameter,</li>
<li><span class="math">κ</span>  is the rate of mean reversion,</li>
<li><span class="math">σ</span> is the volatility,</li>
<li><span class="math">L_t</span> is a noise term following a Laplace distribution,</li>
<li><span class="math">J(μ_J , σ_J )</span> is the jump size, following a Laplace distribution with mean  <span class="math">μ_J</span> and scale parameter <span class="math">σ_J</span> ,</li>
<li><span class="math">Π(λ)</span> is a Poisson process with jump intensity <span class="math">λ</span>.</li>
</ul>
<p>The transition probabilities for base fee equilibrium prices follow a Poisson-Laplace process. This can be expressed as:</p>
<div class="math">

p(X_t | X_{t-1}) = \lambda \frac{1}{2b} \exp\left(-\frac{|X_t - (a \Delta t + \phi X_{t-1} + \mu_J)|}{\sqrt{v_t (\sigma^2 + \sigma_J^2)}}\right)

</div>
<div class="math">

• (1-\lambda) \cdot \frac{1}{2b} \exp\left(-\frac{|X_t - (a \Delta t + \phi X_{t-1})|}{\sqrt{v_t \sigma^2}}\right)

</div>
<p>where:</p>
<ul>
<li><span class="math">∆t</span> is the time increment,</li>
<li><span class="math">a</span> is the drift term,</li>
<li><span class="math">φ</span> is the autoregressive coefficient,</li>
<li><span class="math">b</span> is the scale parameter of the Laplace distribution.</li>
</ul>
<p>The parameters <span class="math">Q = {α, κ, σ, a, b, μ_J , σ_J , λ}</span> can first be estimated by Maximum Likelihood (ML). This approach ensures that the parameters <span class="math">Q</span> are optimised to best fit the observed data under the specified model. The results of the simulation, displayed below, demonstrate the simulated log base fees for the next month. Notably, considering the most recent regime of exponential increase, I adopt a neutral market approach by assuming a linear (horizontal) trend. For pricing derivative products, consideration of what the future trend will be should be taken into account. After retrieving calibrated parameters, a range of future hourly dates is produced, before trend and seasonality is added back in, and the exponential is taken to revert the log.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/af172a8475671fb615b0494f03c0e53f7d01c0fb.png" title="Simulation"><img alt="Simulation" height="500" src="https://ethresear.ch/uploads/default/original/3X/a/f/af172a8475671fb615b0494f03c0e53f7d01c0fb.png" width="592" /></a></div><p></p>
<p><strong>ARIMA Monte Carlo Method</strong></p>
<p>An alternative method, which requires less computation simulates a monte-carlo process by modelling standardised residuals directly from a Laplace distribution, augmenting these standardised residuals back de-normalising them, before generating future paths as the composite of both this noise and ARIMA forecasts. A simulated residual path is shown below, producing the resulting simulation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/0/70411cba63138e2322e32a338e350acc9dbeebe9.png" title="Residules"><img alt="Residules" height="500" src="https://ethresear.ch/uploads/default/original/3X/7/0/70411cba63138e2322e32a338e350acc9dbeebe9.png" width="651" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/7/a71fae0b0032a14bc4099ebbd6b20f28c69bfd5a.png" title="Sim2"><img alt="Sim2" height="479" src="https://ethresear.ch/uploads/default/optimized/3X/a/7/a71fae0b0032a14bc4099ebbd6b20f28c69bfd5a_2_690x479.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/e/ce326060566053721576245372a025708af87d0b.jpeg" title="Screenshot 2024-06-14 at 12.50.40"><img alt="Screenshot 2024-06-14 at 12.50.40" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/e/ce326060566053721576245372a025708af87d0b_2_687x500.jpeg" width="687" /></a></div><p></p>
<p><strong>Pricing with these simulated values</strong></p>
<p>For the purpose of hedging, pricing a European call or put option based on the simulated paths can be expressed as follows. Let <span class="math">BF_T^i</span> represent base fees per gas at maturity <span class="math">T</span> for the <span class="math">i</span>-th simulated path, where <span class="math">i = 1, 2, \ldots, N</span>, and denote the strike price by <span class="math">K</span>. The payoff for the European call option at maturity for the <span class="math">i</span>-th path is given by <span class="math">\max(BF_T^i - K, 0)</span>, and for the European put option, it is given by <span class="math">\max(K - BF_T^i, 0)</span>. To find the option price, I first calculate the average payoff across all <span class="math">N</span> simulated paths: <span class="math">\frac{1}{N} \sum_{i=1}^N \max(BF_T^i - K, 0)</span> for the call option, and <span class="math">\frac{1}{N} \sum_{i=1}^N \max(K - BF_T^i, 0)</span> for the put option. These average payoffs are then discounted to the present value using the risk-free rate <span class="math">r</span>, giving the price of the European call option at time 0 as <span class="math">C_0 = e^{-rT} \times \frac{1}{N} \sum_{i=1}^N \max(BF_T^i - K, 0)</span> and the price of the European put option at time 0 as <span class="math">P_0 = e^{-rT} \times \frac{1}{N} \sum_{i=1}^N \max(K - BF_T^i, 0)</span>.</p>
<p>In pricing a gas plan where the underwriter subsidises the entire unit of gas at any point before <span class="math">T</span> I can model this as an American call option on gas fees with a strike price of zero and implement the Longstaff and Schwartz Regression Approach. This method involves calculating the payoff at the final period <span class="math">T</span> as the gas fee <span class="math">BF_T^i</span> for each path <span class="math">i</span>, assuming no transaction has been exercised before this time. Moving one time step backward, one regress the discounted future payoffs against the current gas fees <span class="math">BF_t^i</span> to estimate continuation values. This regression, known as a basis function, typically includes terms like a constant, <span class="math">BF_t^i</span>, and <span class="math">(BF_t^i)^2</span>. At each time step <span class="math">t</span>, we compare the immediate exercise value <span class="math">BF_t^i</span> with the estimated continuation value <span class="math">\hat{C}_t^i</span> from the regression. If the exercise value is higher, one updates the cash flow to reflect exercising the option; otherwise, we carry forward the discounted cash flow. Finally, the option price at time 0 (now) is obtained by averaging the discounted cash flows across all paths and all time periods.</p>
<p><strong>Utility in Oiler Pitch Lake</strong><br />
Oiler Pitch Lake is a protocol designed to allow liquidity providers (LPs) by pooling their assets to act as sellers in time-weighted moving average (TWAP) base fee cash-settled call options. Utilizing Starknet STARKS and the Fossil coprocessor for verifiability, Pitch Lake determines option payoffs based on the average base fee over a specified time interval, akin to an Asian option.</p>
<p>Given that LPs put up a limited amount of collateral, there is a cap on each option’s payoff. To protect LPs, a reserve price can be set, which is the minimum price at which the option must be sold. Using the aforementioned methodology, this reserve price can be calculated with both accuracy and verifiability, ensuring that LPs are safeguarded. Pitch Lake is currently in development and is expected to launch in the coming months.</p>
<p><strong>Next Steps</strong></p>
<ul>
<li><strong>Call for reproduction</strong>: Please reproduce my analysis and methodology. Working with complex financial mathematics can be prone to assumptions that may be easily violated. View this as an initial attempt to dive into the gas fee pricing topic</li>
<li><strong>What about the blobs market and L2 fee markets? I</strong> am currently working on similar analysis for the blob fee market place, L2 fees, and other blockchains. Expect more results soon.</li>
</ul>
<p><strong>Bibliography</strong><br />
[1] Oiler Pitch Lake. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018" rel="noopener nofollow ugc">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018</a><br />
[2] SMG Spec <a class="inline-onebox" href="https://www.mechanism.org/spec/04" rel="noopener nofollow ugc">04</a><br />
[3] [2] Lucia, Julio J., Schwartz, Eduaro. “Electricity Prices and Power Derivatives: Evidence from the Nordic Power Exchange.” Review of Derivatives Research. Vol. 5, Issue 1, pp 5-50, 2002. <a class="inline-onebox" href="https://link.springer.com/article/10.1023/A:1013846631785" rel="noopener nofollow ugc">Electricity Prices and Power Derivatives: Evidence from the Nordic Power Exchange | Review of Derivatives Research</a><br />
[4] Seifert, Jan, Uhrig-Homburg, Marliese. “Modelling Jumps in Electricity Prices: Theory and Empirical Evidence.” <em>Review of Derivatives Research</em>. Vol. 10, pp 59-85, 2007. <a class="inline-onebox" href="https://uk.mathworks.com/help/fininst/simulating-electricity-prices-with-mean-reversion-and-jump-diffusion.html" rel="noopener nofollow ugc">Simulating Electricity Prices with Mean-Reversion and Jump-Diffusion - MATLAB &amp; Simulink - MathWorks United Kingdom</a><br />
[5] Escribano, Alvaro, Pena, Juan Ignacio, Villaplana, Pablo. “Modeling Electricity Prices: International Evidence.” Universidad Carloes III de Madrid, Working Paper 02-27, 2002. Modeling Electricity Prices: International Evidence <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=299360" rel="noopener nofollow ugc">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=299360</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pricing-gas-fee-derivatives/19898">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 20:59:59 +0000</pubDate>
</item>
<item>
<title>Execution Auctions as an Alternative to Execution Tickets</title>
<link>https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894</link>
<guid>https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894</guid>
<content:encoded><![CDATA[
<div> 关键词：执行拍卖（Execution Auctions, EAs）、执行门票（Execution Tickets, ETs）、MEV、中央化、价值分配

总结:<br />
文章比较了两种解决以太坊中矿工效用提升（MEV）问题的机制：执行拍卖和执行门票。这两种方法旨在通过出售执行权来解决协议中的代理人问题，提高效率并减少外部性。文章分析了两种机制的经济差异，包括预期现值（NPV）、风险折扣、成本控制和中央化风险。执行拍卖简单易实现，但可能导致集中化；执行门票利用随机性，虽能防止集中，但可能涉及复杂性。最后，文章认为执行拍卖在实践中可能更优，尽管执行门票在某些方面提供保护。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/128696dce49653e3211f52d33f86612013a883c4.jpeg" title="ealien"><img alt="ealien" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/128696dce49653e3211f52d33f86612013a883c4_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><br />
<em>By <a href="https://twitter.com/_JonahB_">Jonah Burian</a> &amp; <a href="https://twitter.com/DavideCrapis">Davide Crapis</a></em></p>
<p><em>Special thanks to <a href="https://x.com/weboftrees">Anders Elowsson</a>, <a href="https://twitter.com/barnabemonnot">Barnabé Monnot</a>, <a href="https://twitter.com/drakefjustin">Justin Drake</a> and <a href="https://twitter.com/mikeneuder">Mike Neuder</a> for the feedback and review.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>There is a principal-agent problem in Ethereum. While the protocol creates MEV, it leaks it to proposers. Moreover, MEV in its current state exposes the protocol to other externalities, such as <a href="https://arxiv.org/abs/2305.09032">timing games</a>. It is widely held in the research community that capturing and properly redistributing MEV is an important step in the evolution of Ethereum, to make the protocol more resilient and efficient (<em>note: there are some people who <a href="https://www.nano210.blog/infinite-blockspace-equilibrium/">disagree</a>)</em>. The only way to solve this principal-agent problem is for the protocol to sell the rights to earn the MEV with a credible and efficient mechanism.</p>
<p>After many years of research, two approaches have recently emerged as potential avenues for solving MEV-burn. These are mechanisms where the right to propose an execution payload is not given for free to the <em>beacon proposer</em>, but it is instead sold separately to an <em>execution proposer</em>.</p>
<ul>
<li><strong>Execution Auctions (EAs):</strong> The right to propose an execution payload is <em>deterministically allocated</em> in advance for each slot, the slot execution proposer can purchase this right by bidding in a slot auction held beforehand, for example <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ#:~:text=introduce%20it%20next.-,Slot%2Dauction%2B32%20ePBS,-We%20suggest%20now">32 slots earlier</a>.</li>
<li><strong>Execution Tickets (ETs):</strong> the execution proposer right is not deterministically allocated, proposers can purchase a lottery ticket in advance and then, before each slot, a winner is drawn at random from the ticket pool and gets the right to propose.
<ul>
<li>The simple version of the protocol gives the winner the right to propose the following block. This was the focus of <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>.</li>
<li>The original execution ticket post <a href="https://ethresear.ch/t/execution-tickets/17944#:~:text=There%20exists%20a,market%20function%20smoothly.">suggested</a> a general version of the protocol where the winner has the right to propose <span class="math">m</span> slots later (e.g., 32). The intuition for why winners are given slots multiple slots in advance as opposed to immediately is that the solution allows for winners to offer preconfs.</li>
</ul>
</li>
</ul>
<p>The mechanisms have the same objective but important differences. The goal of this post is to compare the two solutions.</p>
<h1><a class="anchor" href="https://ethresear.ch#setup-2" name="setup-2"></a>Setup</h1>
<p>We will introduce formulas throughout this post to outline the key economic differences between the protocols. We will also explain the practical nuances, so if you want to skip the math, no worries! For the extra curious, we lay out the proof of the formulas in the appendix.</p>
<h2><a class="anchor" href="https://ethresear.ch#terms-3" name="terms-3"></a>Terms</h2>
<ul>
<li><span class="math">t</span> — discrete time intervals (slot).</li>
<li><span class="math">n</span> — the number of tickets.</li>
<li><span class="math">d</span> is the inter-slot discount rate used to calculate the present value of future prizes.
<ul>
<li>Note: assuming that the vanilla staking rate is the risk-free rate in Ethereum, <span class="math">d \approx 10^{-8}</span></li>
</ul>
</li>
<li><span class="math">\mathcal{R}</span> is a random variable representing the value of controlling an execution payload at time <span class="math">t</span>.
<ul>
<li>We term this the Execution Layer Reward (EL Reward) which equals MEV + fees in slot <span class="math">t</span>.</li>
<li>We assume that <span class="math">\mathcal{R}</span> has a distribution that does not vary with time and that each draw is independent. (This is usually not the case in practice, as EL rewards are time-varying and correlated, but it allows for a less complicated analysis that can be expanded later.)</li>
</ul>
</li>
<li><span class="math">\mu_{\mathcal{R}}</span> is the expected value of <span class="math">\mathcal{R}</span>.</li>
<li><span class="math">V_{ticket}</span> — Net Present Value (NPV) of a single ticket.
<ul>
<li>Note: present value of some value <span class="math">X</span> realized at time <span class="math">t</span> is calculated as <span class="math">\frac{X}{(1+d)^t}</span>.</li>
</ul>
</li>
<li><span class="math">m</span> — number of slots t after winning that the right to propose is given (e.g., <span class="math">m=32</span>).</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#northstar-4" name="northstar-4"></a>Northstar</h2>
<p>The expected net present value of all future EL Rewards is</p>
<div class="math">
NPV_{\mathcal{R}} = \frac{\mu_{\mathcal{R}}}{d}
</div>
<p>This is the total value of all block space from now into the future of Ethereum. Given that the goal of the Execution Auctions and Execution Tickets is to capture the value of block space and redistribute the value to align with the protocol’s goals, all solutions must be analyzed in terms of how well they capture <span class="math">NPV_{\mathcal{R}}</span>.</p>
<p><em>Note: Capturing all the value depends on the selling mechanism. In this analysis, we assume that the selling mechanism is efficient. Detailed analysis of the selling mechanism in a dynamic/repeated strategic interaction context is an open problem currently under research.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#execution-auctions-5" name="execution-auctions-5"></a>Execution Auctions</h1>
<p>Execution Auctions (EAs) are essentially slot auctions carried out in advance:</p>
<ul>
<li><strong>Proposer right allocation:</strong> the <em>execution proposer right</em> for slot <span class="math">k+m</span> is sold <span class="math">m</span> slots in advance, at slot <span class="math">k</span>.</li>
<li><strong>Selling mechanism:</strong> the beacon proposer of slot <span class="math">k</span> receives bids for that right and commits to the highest bid, attesters vote.</li>
</ul>
<p>A <strong>secondary market</strong> will most likely develop where an EA ticket winner can resell their proposer right before their turn to propose. Even if the protocol does not allow them to transfer that right, this can be easily done via an out-of-protocol gadget.</p>
<h1><a class="anchor" href="https://ethresear.ch#execution-tickets-6" name="execution-tickets-6"></a>Execution Tickets</h1>
<p>Execution Tickets (ETs) have a lottery component that adds uncertainty on the specific block a holder will be able to propose in the future, this can be resolved closer to the time of proposing or further ahead of time.</p>
<ul>
<li><strong>Proposer right allocation:</strong> the <em>execution proposer right</em> for <em>a slot</em> in the future is sold in the form of a lottery ticket.</li>
<li><strong>Selling mechanism:</strong> assume there are already <span class="math">n</span> tickets in the lottery pool, at each slot a ticket is selected as lottery winner (e.g., at the end of the slot using RANDAO) and a new ticket is sold to enter the pool starting from the next slot.
<ul>
<li><strong>Pricing:</strong> We assume an English Auction for comparison with EAs.</li>
<li><strong>Uncertainty resolution:</strong> we can have a next-slot execution lottery, where at the end of slot <span class="math">k</span> we select proposer for slot <span class="math">k+1</span> (we term these sETs i.e, simple ETs), or a future-slot execution lottery, where at the end of slot <span class="math">k</span> we select proposer for slot <span class="math">k+m</span> (we term these ETs).</li>
</ul>
</li>
</ul>
<p>Similarly to EAs, a secondary market will likely emerge where a ticket holder or a winning ticket holder can resell their right to participate in the lottery or propose.</p>
<p><em>Note: In the initial post <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a> we did not yet make the distinction between sETs and ETs. That post was about sETs (a special case of ETs).</em></p>
<p><em>Note 2: <a href="https://twitter.com/drakefjustin">Justin </a> perceptively pointed out that we don’t know how to achieve low-latency randomness using RANDAO, and VDFs wouldn’t help either. Low-latency RANDAO would be biasable (as well as fully predictable when you control two slots in a row).</em></p>
<h1><a class="anchor" href="https://ethresear.ch#analysis-7" name="analysis-7"></a>Analysis</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/0/c088b53c1b671ac4704f3ff5c99e4b792264c861.png" title="Chart 1"><img alt="Chart 1" height="174" src="https://ethresear.ch/uploads/default/optimized/3X/c/0/c088b53c1b671ac4704f3ff5c99e4b792264c861_2_690x174.png" width="690" /></a></div><p></p>
<p><em>Note: All approximations assume <span class="math">m</span> (time from when the ticket wins to when the right is conferred) and <span class="math">n</span> (number of ETs) are not large. Given that <span class="math">d</span> is nearly zero, we are able to simplify the equations.</em></p>
<p><em>Note 2: Without using the approximation,</em> EA tickets <em>and ETs have some Dead Weight Loss associated with the fact that winning tickets cannot be immediately used, i.e., there is some loss given the time discount. The intuition for the approximation is that given <span class="math">d</span> is small, this value loss due to the time discount is nominal.</em></p>
<p><em>Note 3: While we assume in the approximation for the variance of sETs and ETs that <span class="math">n</span> is small, we discussed in “<a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>” that a large <span class="math">n</span> leads to less centralization risk and more democratization in terms of who can afford a ticket. That said, a large <span class="math">n</span> creates valuation complexity and adds the additional complexity of having to run a large sale at the beginning of the lottery to bootstrap the ticket pool. (Read the article to learn more.)</em></p>
<p>Here is a simplified version of the chart assuming the approximation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/a/dad825aa8d8c8324d64726716ed5a0fd84508ffe.png" title="Chart 2"><img alt="Chart 2" height="186" src="https://ethresear.ch/uploads/default/optimized/3X/d/a/dad825aa8d8c8324d64726716ed5a0fd84508ffe_2_517x186.png" width="517" /></a></div><p></p>
<p>Notice that all three approaches using the approximation arrive at the same conclusion: we can effectively capture (assuming an efficient auction) all the value associated with block space. Moreover, in each design, the tickets have a simple explanation: they are worth about the value associated with proposing an execution payload.</p>
<p>The variance of the ticket value is the variance of the rewards per slot, which is about as good as you are going to get given that the rights to propose are sold in advance, namely prior to the block’s construction.</p>
<h1><a class="anchor" href="https://ethresear.ch#sure-thing-vs-future-possibility-comparing-eas-and-setsets-8" name="sure-thing-vs-future-possibility-comparing-eas-and-setsets-8"></a>Sure Thing vs Future Possibility: Comparing EAs and sETs/ETs</h1>
<p>We now turn to comparing EAs and sETs/ETs to elucidate trade-offs when thinking about implementing such mechanisms in practice. It should be noted that most of the tradeoffs stand from the fundamental difference between EAs and sETs/ETs - the former is a deterministic protocol while the latter leverages nondeterminism.</p>
<ul>
<li><strong>Implementation Simplicity:</strong> EAs are simpler to implement, the tickets do not require randomness so there is no need to worry about RANDAO bias. Moreover, it is unclear how to implement the randomness for sETs. The secondary market for proposer rights with EA tickets will be much simpler than with sETs/ETs, no need to worry about ticket MEV. Moreover, there seems to be a <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">clear path to implement EAs via ePBS</a> and bypassability not an issue since we’re selling future slots.</li>
<li><strong>Simpler Assets:</strong> It is easier to reason about a deterministic asset than a random one, which makes EA better than sETs and ETS. That said, buyers in the protocol are most likely sophisticated, and the current paradigm for selecting validators relies on randomness, meaning maintaining non-determinism won’t be a substantial break from the status quo. However, a counterargument is that current proposers might not be buyers of tickets.</li>
<li><strong>Variance could affect valuation and EA tickets are less exposed:</strong> It is reasonable for ticket holders to apply a risk discount to the tickets; that is, they might value the tickets less given risk aversion. While EA tickets are only exposed to the variance in the value of the EL rewards in slot <span class="math">t+m</span>, both sETs and ETs are exposed to the variance in EL rewards and the variance in when a ticket wins. Intuitively, EA would therefore have the lowest risk discount.</li>
<li><strong>Efficiency:</strong> From the protocol’s POV, sETs are more efficient because proposer rights are sold closer to the slot of the MEV in expectation while EAs and ETs have dead weight loss in theory. That said, when factoring in risk aversion, EAs might be more efficient.</li>
<li><strong>Preconfs</strong>: Preconfs require there to be a lookahead, meaning the protocol must know in advance who will control the rights to the execution payload. While EAs and ETs allow for preconfs, sETs do not, as winners are decided at each block.</li>
<li><strong>Cost-of-control:</strong>
<ul>
<li><strong>In EA</strong>
<ul>
<li>EAs put <em>transaction liveness</em> risk on Ethereum—namely, the cost of monopolizing block space is disjoint from the security budget of Ethereum, and the cost of controlling consecutive blocks has a fixed value. Controlling <span class="math">x</span> blocks in a row costs approximately <strong><span class="math">\approx x\mu_{\mathcal{R}}</span></strong>. Luckily, new <a href="https://eips.ethereum.org/EIPS/eip-7547">IL designs</a> could rectify this. Even with ILs, relying heavily on them is suboptimal (they are designed to be a last resort, not commonplace—this can be argued). Importantly as well, the ability to consistently control multiple slots means that well-capitalized parties will perpetually win more block space. This could lead to centralization of the execution payload construction pipeline, exacerbating the current centralization challenges within this pipeline. (See the Multi-block MEV section in “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>”).</li>
<li><a href="https://twitter.com/barnabemonnot">Barnabé</a> aptly noted to us that saying the “the cost of monopolizing block space is disjoint from the security budget of Ethereum” is no different from the existing setup where validators can sell building rights. Currently, validators can sell multiple consecutive blocks in a row. <em>This does not mean that the centralization argument is incorrect but indicates that EAs are not a substantial break from the status quo.</em></li>
</ul>
</li>
<li><strong>In sETs (and ETs):</strong>
<ul>
<li>
<p>While the cost of monopolizing block space is disjoint from the security budget with sETs (and ETs), it is substantially more expensive and less likely that a single party can control multiple consecutive blocks in a row. Non-determinism prevents guaranteed control over block space reducing the likelihood of control. Randomness serves as a defense against centralization.</p>
<ul>
<li>
<p>The first chart provides an intuitive understanding of this principle. It shows a scenario with 100 outstanding sETs/ETs. If someone owns 95% of the initial outstanding tickets (remember, one is subsequently minted per block), the probability of winning 20 slots in a row is approximately 4%, while the probability of winning 35 in a row is almost impossible.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/3/63786be4729c8134b1fa101788af325a31fb7427.png" title="Graph 1"><img alt="Graph 1" height="412" src="https://ethresear.ch/uploads/default/optimized/3X/6/3/63786be4729c8134b1fa101788af325a31fb7427_2_690x412.png" width="690" /></a></div><p></p>
</li>
<li>
<p>Moreover, the costs of controlling <span class="math">P\%</span> of the blocks increases in <span class="math">n</span> (See: <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>)<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/5/b5e0ee59790fe044c3adbb4ae4f5ae4408e0694c.png" title="Graph 2"><img alt="Graph 2" height="186" src="https://ethresear.ch/uploads/default/optimized/3X/b/5/b5e0ee59790fe044c3adbb4ae4f5ae4408e0694c_2_690x186.png" width="690" /></a></div><p></p>
</li>
</ul>
</li>
<li>
<p><strong>Where ETs differ:</strong></p>
<ul>
<li>While an attacker in sETs must rely on chance to win consecutive blocks, a clever ETs user can buy a sequence of winning tickets for <span class="math">t+m</span> to <span class="math">t+m+x</span> on the secondary market, making the centralization in ETs similar to the centralization problem with EAs. One can argue that sETs are subject to the same risk as an out-of-protocol auction for control of the sETs winners’ rights can happen. That said, there may be honest actors who don’t sell rights to execution payload construction. If one of these holders wins, they end the sequence of winning blocks for a sET attacker, meaning that a sET attack, even with the out-of-protocol option, is exposed to uncertainty.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#concluding-remarks-9" name="concluding-remarks-9"></a>Concluding Remarks</h1>
<p>EAs dominate in simplicity, while sETs protect from centralization but at the expense of allowing for preconfs. sETs may also be unimplementable in the Ethereum Protocol today given the RANDAO problem. ILs can curb centralization concerns with EAs, and the secondary market for sETs/ETs can nullify their protective benefits. Moreover, EAs are not a substantial break from the status quo in terms of centralization.</p>
<p><em>While there are still open questions around implementing EAs and their efficiency, EAs seem to be superior to sETs and ETs for the Ethereum protocol.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#related-work-10" name="related-work-10"></a><strong>Related work</strong></h1>
<p><em>This list is copied and pasted from</em> <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a> with the addition of <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>. lol</p>
<ol>
<li><em>mev-boost &amp; relays</em>
<ul>
<li><a href="https://ethresear.ch/t/mev-boost-merge-ready-flashbots-architecture/11177"><em>MEV-Boost: Merge ready Flashbots Architecture</em></a>; Flashbots team</li>
<li><a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278"><em>Relays in a post-ePBS world</em></a>; Mike, Jon, Hasu, Tomasz, Chris, Toni</li>
</ul>
</li>
<li><em>mev-burn / mev-smoothing</em>
<ul>
<li><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>Burning MEV through block proposer auctions</em></a>; Domothy</li>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn – a simple design</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408"><em>Committee-driven MEV smoothing</em></a>; Francesco</li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384"><em>Dr. changestuff or: how I learned to stop worrying and love mev-burn</em></a>; Mike, Toni, Justin</li>
</ul>
</li>
<li><em>enshrined Proposer-Builder Separation (ePBS)</em>
<ul>
<li><a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980"><em>Two-slot proposer/builder separation</em></a>; Vitalik</li>
<li><a href="https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879"><em>Unbundling PBS: towards protocol-enforced proposer commitments (PEPC)</em></a>; Barnabé</li>
<li><a href="https://barnabe.substack.com/p/pbs"><em>Notes on Proposer-Builder Separation</em></a>; Barnabé</li>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ"><em>More pictures about proposers and builders</em></a>; Barnabé</li>
<li><a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710"><em>Why enshrine Proposer-Builder Separation?</em></a>; Mike, Justin</li>
<li><a href="https://ethresear.ch/t/epbs-design-constraints/18728"><em>ePBS design constraints</em></a>; Potuz</li>
<li><a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg"><em>Reconsidering the market structure of PBS</em></a>; Barnabé</li>
</ul>
</li>
<li><em>block-space futures</em>
<ul>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ"><em>Block vs. Slot Auction PBS</em></a>; Julian</li>
<li><a href="https://frontier.tech/ethereums-blockspace-future"><em>Opportunities and Considerations of Ethereum’s Blockspace Future</em></a>; Drew, Ankit</li>
<li><a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814"><em>When to sell your blocks</em></a>; Quintus, Conor</li>
</ul>
</li>
<li><em>execution tickets</em>
<ul>
<li><a href="https://www.youtube.com/watch?v=MtvbGuBbNqI"><em>Attester-proposer separation</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/execution-tickets/17944"><em>Execution tickets</em></a>; Justin, Mike</li>
<li><a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894"><em>Economic Analysis of Execution Tickets</em></a>; Jonah, Davide</li>
<li><a href="https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232"><em>Block-auction ePBS versus Execution Ticket</em></a>; Terence</li>
</ul>
</li>
<li><em><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>; Mike, Pranav, &amp; Dr. Tim Roughgarden</em></li>
</ol>
<p><em>This post has a similar goal to</em> <a href="https://x.com/mikeneuder">Mike</a>, <a href="https://x.com/PGarimidi">Pranav</a>, &amp; <a href="https://x.com/Tim_Roughgarden">Tim</a>’s recent work titled <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>: <em>comparing new mechanisms for execution rights allocation.</em> However, there are a few key differences in our analysis that we highlight here:</p>
<ol>
<li>They use a modified ET model (i.e., a model where all tickets are burned between slots). This model, while easier to implement, does not lead to an efficient allocation (as those with lower valuations for block space can still be allocated it).</li>
<li>They focus on a Tullock Contest model, while our model resembles a fixed-income model.</li>
<li>Their analysis focuses on the trade-off between the quality of the in-protocol MEV oracle and the fairness of the mechanism, while we focus on other trade-offs such as implementation ease, risk discounts, centralization control, and economic efficiency.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#appendix-11" name="appendix-11"></a>Appendix</h1>
<p><strong>Calculating the discount rate:</strong></p>
<p>The staking rate at the time of this article is <code>~3.4%</code> (<a href="https://www.coindesk.com/indices/ether/cesr">source</a>).</p>
<p><span class="math">1.34=(1+d)^{\text{number of slots in a year}}=(1+d)^{365 * 24 * 60 * 60 / 12}</span> <img alt=":arrow_right:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/arrow_right.png?v=12" title=":arrow_right:" width="20" />  <span class="math">d=1.27e-08 \approx 10^{-8}</span></p>
<p><strong>The expected net present value of all future EL Rewards:</strong></p>
<p>See this <a href="https://arxiv.org/abs/2404.04262">paper</a> for the proof</p>
<p><strong>Calculating:</strong> <span class="math">E[V_{\text{EA ticket}}]</span></p>
<div class="math">
E[V_{\text{EA ticket}}] =  \frac{\mu_{\mathcal{R}}}{(1+d)^m}
</div>
<p>This is because the value is recognized <span class="math">m</span> slots later so you need to discount the MEV received in <span class="math">m</span> blocks by the discount rate <span class="math">d</span>.</p>
<p><strong>Calculating <span class="math">E[V_{\text{all EA tickets}}]</span></strong></p>
<div class="math">
\begin{align*}
    E[V_{\text{all EA tickets}}] &amp;=
    \sum_{t=1}^{\infty} \frac{ E[V_{\text{EA ticket}}]}{(1+d)^t} \\
    &amp;= \sum_{t=1}^{\infty} \frac{\mu_{\mathcal{R}}}{(1+d)^{m+t}} \\
    &amp;= \frac{1}{(1+d)^{m}} \sum_{t=1}^{\infty} \frac{\mu_{\mathcal{R}}}{(1+d)^{t}} \\
    &amp;= \frac{1}{(1+d)^{m}} NPV_{\mathcal{R}} 
\end{align*}
</div>
<p><strong>Calculating</strong> <span class="math">\text{Var}(V_{\text{EA ticket}})</span></p>
<div class="math">
\text{Var}(V_{\text{EA ticket}}) =  \text{Var}\left(\mathcal{\frac{R}{(1+d)^m}}\right) =  \frac{\text{Var}(\mathcal{R})}{(1+d)^{2m}}
</div>
<p><strong>Calculating</strong> <span class="math">NPV_{\mathcal{R}}</span>, <span class="math">E[V_{\text{sET}}]</span>, <span class="math">E[V_{\text{all sETs}}]</span> and  <span class="math">\text{Var}(V_{\text{sET}})</span></p>
<p>The proofs can be found in Jonah’s “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>” paper. Remember, the paper does not make the sET vs. ET distinction.</p>
<p><strong>Calculating</strong> <span class="math">E[V_{\text{ET}}]</span>, <span class="math">E[V_{\text{all ETs}}]</span> and  <span class="math">\text{Var}(V_{\text{ET}})</span>,</p>
<p>These are simple modifications to the sET calculations using the <span class="math">m</span> slot discount.</p>
<p><strong>Calculating Graph 1:</strong></p>
<p>The probability of winning <span class="math">m</span> consecutive slots when holding <span class="math">p</span> percent of the sETs/ETs initially (without rebuying a ticket each block) is determined by the product of the probabilities of winning each individual draw:</p>
<div class="math">
\begin{align*}W &amp;= \left(\frac{pn}{n}\right) \cdot \left(\frac{pn-1}{n}\right) \cdot \left(\frac{pn-2}{n}\right) \cdots \left(\frac{pn-(m-1)}{n}\right) \\&amp;= \frac{(pn)!}{(pn-m)! n^m}\end{align*}
</div>
<p><strong>Calculating Graph 2:</strong></p>
<p>See section 4.4 in the “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>” paper.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 15:40:47 +0000</pubDate>
</item>
<item>
<title>Avoiding Accidental Liveness Faults for Based Preconfs</title>
<link>https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888</link>
<guid>https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888</guid>
<content:encoded><![CDATA[
<div> 关键词：基于预确认、意外活期性故障、保护、链条化、预验证

总结:<br />
本文讨论了在引入基于预确认（based preconfirmations）的以太坊网络中，如何解决提案者面临的意外活期性故障（liveness faults）导致的潜在损失问题。作者提出了一种利用预验证链条（preconf chaining）的方法，该机制无需修改现有协议设计，旨在防止个体提案者因偶然事件导致的活期性故障被罚。通过链条化的预验证请求，依赖关系和智能的切割条件，可以确保即使一个提案者出现问题，后续的链条也能保证预验证的履行，从而减少误罚。此外，文章还探讨了如何通过激励措施鼓励链条化行为，如共享提示和建立良好的声誉预期。总的来说，链条化预验证为提案者提供了更好的保护，增强了预验证的可靠性，促进了系统的整体稳定性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#avoiding-accidental-liveness-faults-for-based-preconfs-1" name="avoiding-accidental-liveness-faults-for-based-preconfs-1"></a>Avoiding Accidental Liveness Faults for Based Preconfs</h1>
<p><em>thanks to <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin Drake</a>, <a href="https://x.com/jon_charb" rel="noopener nofollow ugc">Jon Charbonneau</a>, <a href="https://x.com/lvdaniels" rel="noopener nofollow ugc">Ladislaus</a>, <a href="https://x.com/aimxhaisse" rel="noopener nofollow ugc">Sébastien Rannou</a>, <a href="https://x.com/lazyleger" rel="noopener nofollow ugc">sacha</a>, <a href="https://x.com/DrewVdW" rel="noopener nofollow ugc">Drew van Der Werff</a>, and Max Wilde from <a href="https://x.com/aestusrelay" rel="noopener nofollow ugc">Aestus</a> for thinking and review</em><br />
.<br />
.<br />
<em><strong>tl;dr:</strong> We solve one of the largest problems with based preconf opt-in from proposers: accidental liveness slashing. The mechanism we introduce requires no changes to existing based preconf protocol designs and has been under our noses the whole time. We use preconf chaining to protect individual proposers from being slashed for liveness failures.</em><br />
.<br />
.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-2" name="background-2"></a>Background</h2>
<p>On Ethereum today, liveness issues with block proposals are largely accepted, and penalties are minimal. When we introduce based preconfirmations, liveness issues can mean different consequences.</p>
<p>When dealing with preconfs: from the user’s perspective, liveness faults (missing a block proposal) and safety faults (proposing a block that does not fulfill preconf commitments) are the same thing. In both scenarios, a user experiences a situation where their preconfirmation is not fulfilled.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/d/9d996b95a0c2f74f54edf8f3d3b89beda26956db.png" title="liveness faults are safety faults"><img alt="liveness faults are safety faults" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/d/9d996b95a0c2f74f54edf8f3d3b89beda26956db_2_406x500.png" width="406" /></a></div><p></p>
<p>Now, from the perspective of the proposer, liveness faults and safety faults are two very different things. Liveness faults may occur from a multitude of external, accidental circumstances (like power outages, wifi downtime, reorgs, spontaneous combustion) that many proposers just aren’t prepared for. On the other hand, safety faults can only occur when some party (the proposer or some delegate) acts maliciously.</p>
<p>Additionally, attributing liveness faults is difficult. Many actors within the block supply chain may be responsible for a liveness fault occurring. The complexity involved with this attribution would be nice to avoid.</p>
<p>To make proposers feel more comfortable with putting up potentially high amounts of collateral, being slashed for accidental liveness faults should be very rare if not impossible.</p>
<h2><a class="anchor" href="https://ethresear.ch#preconf-chaining-3" name="preconf-chaining-3"></a>Preconf Chaining</h2>
<p><img alt="preconf chaining" height="500" src="https://ethresear.ch/uploads/default/original/3X/5/2/524180b5ef3a6673ab62d02d5afdc1a4d0d94fe5.png" width="500" /></p>
<h3><a class="anchor" href="https://ethresear.ch#brief-assumptions-4" name="brief-assumptions-4"></a>Brief Assumptions:</h3>
<ul>
<li>(we are talking about based preconfs here, not L1 preconfs)</li>
<li>slashing conditions are expressive</li>
<li>preconf requests include L2 block number</li>
<li>“active preconfer” refers to the current preconfer (an L1 proposer or delegate in the lookahead), “next active preconfer” refers to the entity who will be the next preconfer.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#slashing-conditions-construction-5" name="slashing-conditions-construction-5"></a>Slashing Conditions Construction:</h3>
<p>We assume a slashing conditions paradigm that is similar to the one presented in <a href="https://ethresear.ch/t/credibly-neutral-preconfirmation-collateral-the-preconfirmation-registry/19634">The Preconf Registry.</a> Specifically, that slashing conditions are “smart” and expressive enough to represent the following constructions.</p>
<p>The slashing conditions are designed so that a preconfer is slashed if:</p>
<ul>
<li>they sign a preconf request about a transaction <code>A</code> and block <code>B</code>, where <code>B</code> is a future L2 block. Also signed is a list of “dependents”, a list of other preconfers (by address or other ID).</li>
<li><code>A</code> is not fulfilled in <code>B</code>, or was not fulfilled in a block prior to <code>B</code></li>
<li>All dependents have signed the same preconf request (commitments/signatures from these are required) and have not been slashed (a challenge/cooldown period is useful here).</li>
</ul>
<p>This dependent design enables a preconfer to conditionally preconfirm a transaction, based on the choices of other preconfer.</p>
<h3><a class="anchor" href="https://ethresear.ch#preconf-flow-6" name="preconf-flow-6"></a>Preconf Flow</h3>
<ul>
<li>Alice (a based L2 user) wants an inclusion preconf for a transaction <code>A</code></li>
<li>Alice <a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812">delivers a preconf request to the active preconfer</a></li>
<li>Some entity who obtains a preconf commitment from the active preconfer (Alice, a gateway, or even the active preconfer itself) forwards Alice’s preconf request to the next active preconfer (with a dependent on the active preconfer added) and also forwards the active preconfer’s commitment.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/4/84a8b7a1158dfc8f844abfc5447b193b3d35f12e.png" title="diagram representing how any actor can send a chained preconf request to the next active preconfer"><img alt="diagram representing how any actor can send a chained preconf request to the next active preconfer" height="387" src="https://ethresear.ch/uploads/default/optimized/3X/8/4/84a8b7a1158dfc8f844abfc5447b193b3d35f12e_2_690x387.png" width="690" /></a></div><p></p>
<p><strong>Any actor with access to a preconf commitment may construct a chained preconf and forward it to the next active preconfer.</strong></p>
<p>Note that incentives for doing this vary:</p>
<ul>
<li><strong>preconf RPC:</strong> aka <a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812">The Preconfirmation Gateway</a> might chain preconfs as a public good for proposers.</li>
<li><strong>gateway:</strong> A gateway might also chain preconfs as a public good for proposers, but may also use this as a feature to attract proposers (maybe called “liveness fault protection”).</li>
<li><strong>proposers:</strong> A proposer (or node operator) might also chain preconfs themselves. Their incentive is obviously to avoid being slashed for liveness faults.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#determining-penalties-7" name="determining-penalties-7"></a>Determining Penalties</h3>
<ul>
<li>In the case where the active preconfer represents a proposer that has a liveness failure and proposes no L2 block, they wouldn’t be slashed because the preconf could still be fulfilled by the next preconfer (and the preconf request block number would match).</li>
<li>If the active preconfer proposes a block and does not fulfill the preconf request, they would be slashed for a safety fault.</li>
<li>If the active preconfer does not propose a block and the next preconfer does but does not fulfill the preconf request, the second preconfer is slashed for a safety fault.</li>
<li>If both preconfers have liveness issues, both are slashed for a safety fault. (This can be avoided by chaining beyond 2.)</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#incentivizing-chaining-8" name="incentivizing-chaining-8"></a>Incentivizing Chaining</h3>
<p>To incentivize a future active preconfer to chain preconfs, an active preconfer might share tips. Also, a reputational expectation to chain preconfs can encourage more chaining.</p>
<p>One possible way to get chaining adoption is to simply require that chaining happens. To make this practical, the future active preconfers must be able to access the preconf commitments of previous preconfers. The DA problem must be solved to make this practical, and this could be done with an external DA layer. Notably, using an external DA layer introduces dependencies on another sequencer: the DA sequencer. TBD how designs of different DA layers can work around this issue and potential censorship that might occur.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-9" name="conclusion-9"></a>Conclusion</h2>
<p>In this post, we focus on the benefits of chaining for proposers. Widespread chaining also increases the guarantees that users get for preconfirmations, making preconfs even more valuable. It’s a win-win!</p>
<p>Whether forced or opt-in, preconf chaining can protect proposers from being slashed for accidental liveness faults. This system can help proposers feel more comfortable opting into higher collateral requirements.</p>
<p><img alt="preconf chaining protects proposers from penalties for liveness faults" height="451" src="https://ethresear.ch/uploads/default/original/3X/c/c/cc0abe035c50a142437976c953764a60e774427a.png" width="553" /></p>
<h4><a class="anchor" href="https://ethresear.ch#references-10" name="references-10"></a>References</h4>
<ul>
<li><a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812#chained-preconfirmations-13">The Preconfirmation Gateway</a> by <a href="https://x.com/mteamisloading" rel="noopener nofollow ugc">mteam (me)</a> mentions chained preconfirmations as better liveness guarantees for users.</li>
<li><a href="https://ethresear.ch/t/based-preconfirmations/17353">Based preconfirmations</a> by <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin Drake</a> introduces a simple design for based preconfs.</li>
<li><a href="https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884">Pre-confirmation Liveness Slashing Penalties from the Proposer’s Perspective</a> by <a href="https://x.com/aimxhaisse" rel="noopener nofollow ugc">Sébastien Rannou</a> touches on the liveness slashing problem and explains how it decreases the economic viability of preconfs for proposers.</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 18:46:11 +0000</pubDate>
</item>
<item>
<title>Pre-confirmation Liveness Slashing Penalties from the Proposer's Perspective</title>
<link>https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884</link>
<guid>https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884</guid>
<content:encoded><![CDATA[
<div> 关键词：liveness penalty, proposer, pre-confirmations, economic viability, missed blocks

总结:
这篇文章探讨了以太坊网络中预确认（pre-confirmations）的预设罚金对提案者（proposer）经济可行性的影响。文章指出，约0.54%的区块在过去7天内被错过，为了收支平衡，提案者需要从预确认接收的额外小费（tip）至少为错过块罚金（0.0054 ETH）的一半。模型显示，随着错过率增加，预确认小费需相应提高。文章提出了几种可能的解决方案，如基于网络错过率自动调整罚金、用户自定义罚金和小费，以及只在经济上可行时才参与预确认。然而，模型缺乏激励机制，不确定是否能鼓励提案者积极参与。 <div>
<p>Current designs around pre-confirmations involve a slashing penalty on liveness, that is if a proposer who commited to pre-confirmations misses its proposal, part of its collateral is burned or redistributed to the user that sent the pre-confirmation as a payback.</p>
<p>This post explores the liveness penalty from the point of view of proposers from an economical perspective.</p>
<h2><a class="anchor" href="https://ethresear.ch#sources-of-liveness-issues-1" name="sources-of-liveness-issues-1"></a>Sources of Liveness Issues</h2>
<p>Liveness issues are complex and can come from different actors or sources, part of them are the result of the proposer’s actions or choices, part of them don’t depend on the proposer. For example:</p>
<ul>
<li>proposing a block in time but being reorg by the next proposer,</li>
<li>failure from the relayer to send the header in time,</li>
<li>failure from the relayer to propagate the signed header in time and reveal the block to the proposer.</li>
</ul>
<p>As a result, the decision on whether to opt-in or not from a proposer perspective has to take into account an <strong>inherent</strong> risk outside of its actions. Using a statistical approach on network history sounds like an easy starting point.</p>
<h2><a class="anchor" href="https://ethresear.ch#economical-minimal-viability-2" name="economical-minimal-viability-2"></a>Economical Minimal Viability</h2>
<p>In the last 7 days on the network, about <code>0.54%</code> of slots were missed, to break-even economically (that is, for an operator to not lose or win anything in the long run), assuming the liveness fault is <code>1 ETH</code>, the minimal extra-tip of a pre-confirmation would be <code>0.0054 ETH</code>.</p>
<p>To put it in perspective, the median execution reward in the last 7 days is <code>~0.048 ETH</code>, so with <code>1 ETH</code> of collateral, the pre-confirmations would need to be about <code>10%</code> of the block’s value with the current network conditions. Using <code>P(miss)</code> as the probability to miss a block, the break-even formula is:</p>
<div class="math">
(1 - (P(miss))) * tip = P(miss) * penalty
</div>
<p>And so the minimal tip:</p>
<div class="math">
tip = {(P(miss) * penalty) \over (1 - P(miss))}
</div>
<p>With <code>1 ETH</code> as a collateral, here is the model for low probabilites of missed block with <code>P(miss) &lt; 0.025</code>:</p>
<p><img alt="download" height="455" src="https://ethresear.ch/uploads/default/original/3X/e/a/ea574d8ff641f0e75064bfc788d672f031b6a3cb.png" width="626" /></p>
<p>Zooming out up with <code>P(miss) &lt; 0.5</code>:</p>
<p><img alt="download" height="455" src="https://ethresear.ch/uploads/default/original/3X/0/6/0638f8a59181327ccce1392f2bd48663d52562aa.png" width="608" /></p>
<h2><a class="anchor" href="https://ethresear.ch#opt-in-if-economically-viable-3" name="opt-in-if-economically-viable-3"></a>Opt-in if Economically Viable</h2>
<p>One idea to make it viable at scale with little effort from proposers would be for the pre-confirmation sidecar on the proposer side to opt-in to pre-confirmations only it if the tip is above what’s economically sound given the current rate of misses on the network. For example, if in the last 24 hours the average missed block proposal is <code>0.5%</code>, only commit to pre-confirmations which tip is above <code>0.005 ETH</code>.</p>
<p>This approach requires the relayer to pass the pre-confirmation tip information to the proposer to decide whether or not to commit to pre-confirmations, or the proposer to send the minimal-tip to the builder so it can provide a block that match it.</p>
<p>The advantage of this approach is if the network is struggling at scale, the risk for a proposer to miss a slot increases, and so it makes sense for proposers to opt-out of pre-confirmations until the situation resolves. Increasing the pre-confirmer bid under such conditions makes sense as more risk is taken.</p>
<p>A disavantage is that the missed block proposal rate is an approximation: it doesn’t account for totally offline validators, or for the extra-cost involved in validating the pre-confirmation on the proposer side which can take time and increase the risks of missing the slot.</p>
<h2><a class="anchor" href="https://ethresear.ch#alternatives-4" name="alternatives-4"></a>Alternatives</h2>
<h4><a class="anchor" href="https://ethresear.ch#adjusted-liveness-penalty-5" name="adjusted-liveness-penalty-5"></a>Adjusted Liveness Penalty</h4>
<p>Instead of using a minimal tip as a way to decide if it’s viable, the liveness penalty could be dynamically adjusted to what is the minimal viable condition. The tip could then be a fixed value.</p>
<h4><a class="anchor" href="https://ethresear.ch#user-defined-liveness-penalty-6" name="user-defined-liveness-penalty-6"></a>User-Defined Liveness Penalty</h4>
<p>The user sending the pre-confirmation could also decide both the liveness penalty and the tip as suggested in <a href="https://ethresear.ch/t/user-defined-penalties-ensuring-honest-preconf-behavior/19545">User-Defined Penalties: Ensuring Honest Preconf Behavior</a>, and adjust it to what the current state of the network is/what validators accept. The assumption here is maybe for some pre-confirmations the goal is to be as soon as possible on the L1, and so, reducing the liveness penalty would increase their probabilities of being pre-confirmed. On the other hand an arbitrage pre-confirmation could prefer to opt-in for a larger liveness penalty as its opportunity would be lost if the block is missed.</p>
<h2><a class="anchor" href="https://ethresear.ch#caveats-7" name="caveats-7"></a>Caveats</h2>
<p>This simple break-even model on the proposer side has no incentive, it is unclear if it will motivate proposers to opt-in.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 11:44:23 +0000</pubDate>
</item>
<item>
<title>Blob Usage Strategies by Rollups and Non-rollup Applications</title>
<link>https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874</link>
<guid>https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874</guid>
<content:encoded><![CDATA[
<div> 关键词：rollup, non-rollup, blobs, type 3 transactions, cost-effectiveness

总结:
这篇文章深入研究了以太坊升级后type 3交易中携带blob的应用策略，主要关注rollup和non-rollup应用的差异。rollup应用倾向于根据自身需求选择不同的blob使用策略，如blob数量、利用率和提交频率，以平衡可用数据费用和延迟成本。非-rollup应用通常用于上传完整内容，其blob策略与rollup不同，交易频繁且单blob利用率较高。

文章分析了blob成本效益、gas价格波动对不同应用的影响，以及blob与块重组的关系。结果表明，虽然blob作为数据可用性解决方案通常更经济，但在某些情况下，calldata可能更便宜。此外，blob gas价格的短期波动主要受non-rollup应用驱动，而非rollup应用对价格变动的响应并不明显。

总结:<br />rollup和non-rollup应用的blob策略各有特点，rollup通过调整blob数量和利用率来平衡成本；non-rollup则以高频次、低利用率的方式使用blob。文章还探讨了blob成本、gas价格和块重组之间的关系，发现blob滥用的识别对设计反滥用机制至关重要。 <div>
<p><a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc">Full Report</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tdlr-1" name="tdlr-1"></a>TDLR</h2>
<ol>
<li>The main applications using blobs are rollups, accounting for approximately 87%. Non-rollup applications mainly include <a href="https://blobscan.com/tx/0x3ff787f16ad6d65dc8d6e45a3ea95440fca2da2c0e344e76a6e509857673da01" rel="noopener nofollow ugc">Blobscriptions</a> and <a href="https://blobscan.com/tx/0x1956039b71bbc1c5de31ceafb27782eb2e8a07c9299d1d534e470bcf35f9835a" rel="noopener nofollow ugc">customized type 3 transactions</a>.</li>
<li>Rollup applications choose different blob usage strategies according to their own situations. The strategies will consider the number of blobs carried by type 3 transactions, blob utilization, and blob submission frequency to balance the costs of availability data fees and delay costs.</li>
<li>Non-rollup applications can be characterized and distinguished from rollup applications by the number of blobs carried by type 3 transactions, blob utilization, and blob submission frequency. These features help identify scenarios of blob abuse, allowing for the design of corresponding anti-abuse mechanisms.</li>
<li>In most cases, using blobs as a data availability solution is more cost-effective than calldata. However, there are a few scenarios where calldata is cheaper: blob gas price spikes and blob utilization is extremely low.</li>
<li>Short-term fluctuations in blob gas price is mainly influenced by the demand from non-rollup applications. Rollup applications have a relatively inelastic demand for blobs, so they do not significantly impact short-term fluctuations in blob gas prices.</li>
<li>Currently, rollup applications do not seem to consider blob gas price as a reference factor in their blob usage strategies.</li>
<li>The probability of blocks containing type 3 transactions being reorganized is extremely low. Additionally, carrying more blobs does not increase the probability of block reorganization. However, there is a clustering phenomenon in block height for blocks containing type 3 transactions.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>This report provides an in-depth analysis of type 3 transactions used for carrying blobs from the time of the Ethereum Decun upgrade until May 22, 2024. It focuses on blob usage strategies of rollup and non-rollup applications. The dataset, data processing programs, and visualization code for this report are <a href="https://github.com/doublespending/EIP-4844-Data-Analysis" rel="noopener nofollow ugc">open source</a>, detailed in the following “Dataset” section.</p>
<h2><a class="anchor" href="https://ethresear.ch#type-3-transactions-blobs-share-by-applications-3" name="type-3-transactions-blobs-share-by-applications-3"></a>Type 3 Transactions &amp; Blobs Share by Applications</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/1/9101b16c984217aa1e5a51a59e7c0024aa6e8e18.jpeg" title="image"><img alt="image" height="363" src="https://ethresear.ch/uploads/default/optimized/3X/9/1/9101b16c984217aa1e5a51a59e7c0024aa6e8e18_2_690x363.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#rollup-applications-4" name="rollup-applications-4"></a>Rollup Applications</h3>
<p>Observations from Figure 1 on the proportion of type 3 transactions:</p>
<ul>
<li>Base, Scroll, Linea, and Starknet are in the same tier, having the highest transaction proportions.</li>
<li>Arbitrum, Optimism, and Zksync are in the next tier, having the second-highest transaction proportions.</li>
</ul>
<p>This phenomenon seems counterintuitive as Arbitrum and Optimism have higher TPS than Scroll, Linea, and Starknet and should have a higher proportion of type 3 transactions.</p>
<p>Figure 2 shows that counterintuitive phenomenon is caused by different rollup strategies in the number of blobs carried by type 3 transactions.</p>
<p>Observations from Figure 2 on the proportion of blobs:</p>
<ul>
<li>Base stands alone, having the highest proportion of blobs.</li>
<li>Arbitrum and Optimism are in the same tier, having the second-highest proportion of blobs.</li>
<li>Scroll, Linea, Starknet, and Zksync are in the same tier, having a medium proportion of blobs.</li>
</ul>
<p>This phenomenon aligns more with intuition: blob proportions are directly related to the scale of rollup’s availability data, thus showing a positive correlation with rollup TPS.</p>
<p>The difference between the proportion of type 3 transactions (31%) and blobs (14%) for non-rollup applications indicates that non-rollup applications and rollup applications have different needs.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-rollup-applications-5" name="non-rollup-applications-5"></a>Non-Rollup Applications</h3>
<ul>
<li>Rollup applications are B2B businesses aiming to fill fine-grained Layer 2 transaction availability data, so their type 3 transactions are not limited to carrying only 1 blob.</li>
<li>Non-rollup applications are B2C businesses aiming to upload complete text, images, etc., so their type 3 transactions usually carry only 1 blob to meet their needs.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#rollup-blob-usage-strategies-6" name="rollup-blob-usage-strategies-6"></a>Rollup Blob Usage Strategies</h2>
<h3><a class="anchor" href="https://ethresear.ch#rollup-strategy-model-7" name="rollup-strategy-model-7"></a>Rollup Strategy Model</h3>
<p>This section models the rollup blob usage strategies with</p>
<ol>
<li><code>blobNumber</code>, i.e. the number of blobs carried by type 3 transactions</li>
<li><code>blobUtilization</code>, i.e. blob space utilization</li>
<li><code>blobInterval</code>, i.e. the blob submission interval</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#fee-cost-8" name="fee-cost-8"></a>Fee Cost</h4>
<p>The fee cost per transaction for rollups is expressed as:</p>
<div class="math">
\begin{equation}
feeCost = \frac{1}{k}(\frac{blobCost}{blobUtilization}+\frac{fixedCost}{blobNumber*blobUtilization})
\end{equation}
</div>
<ul>
<li><code>fixedCost</code>: the fixed cost of a type 3 transaction</li>
<li><code>blobCost</code>: the cost of a single blob</li>
<li>The larger the <code>blobUtilization</code>, the lower the amortized cost of the blob fee <span class="math">\frac{blobCost}{blobUtilization}</span> and the fixed cost <span class="math">\frac{fixedCost}{blobNumber*blobUtilization}</span>, resulting in a lower fee cost <code>feeCost</code>.</li>
<li>The larger the <code>blobNumber</code>, the lower the amortized cost of the fixed cost <span class="math">\frac{fixedCost}{blobNumber*blobUtilization}</span>, resulting in a lower fee cost <code>feeCost</code>.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#delay-cost-9" name="delay-cost-9"></a>Delay Cost</h4>
<p><strong>The delay cost per transaction for rollups is expressed as:</strong></p>
<div class="math">
\begin{equation}
delayCost = F(\frac{blobNumber*blobUtilization*k}{tps})
\end{equation}
</div>
<ul>
<li>The larger the <code>blobUtilization</code>, the larger the delay cost <code>delayCost</code>.</li>
<li>The larger the <code>blobNumber</code>, the larger the delay cost <code>delayCost</code>.</li>
<li>The larger the <code>tps</code>, the smaller the delay cost <code>delayCost</code>.</li>
</ul>
<blockquote>
<p>The derivation of the formula can be found in the <a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc">full version</a>.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#rollup-strategy-analysis-10" name="rollup-strategy-analysis-10"></a>Rollup Strategy Analysis</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced.png" title="image"><img alt="image" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced_2_690x260.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/2/32521830fd7aab2cbd7f19d504720344afb2eff7.jpeg" title="image"><img alt="image" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/3/2/32521830fd7aab2cbd7f19d504720344afb2eff7_2_574x499.jpeg" width="574" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#non-rollup-blob-strategies-11" name="non-rollup-blob-strategies-11"></a>Non-Rollup Blob Strategies</h3>
<p>Rollup applications are B2B, while non-rollup applications are B2C. Therefore, non-rollup applications differ from the rollup strategy model. For non-rollup applications:</p>
<ul>
<li>The number of blobs carried by type 3 transactions depends on the size of the content (texts/images) stored in the blobs.</li>
<li>Blob utilization depends on the size of the content (texts/images) stored in the blobs.</li>
<li>Blob submission intervals depend on the immediate needs of C-end users, with no delay costs involved.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced.png" title="image"><img alt="image" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced_2_690x260.png" width="690" /></a></div><p></p>
<ul>
<li>
<p>According to Figure 5 (<strong>Others</strong> ), 1 blob can meet the needs of most non-rollup applications.</p>
</li>
<li>
<p>According to Figure 6 (<strong>Others</strong> ), the blob utilization is concentrated between 20% and 40%, indicating that non-rollup applications generally cannot fill the blob, with the data size mainly between 25.6 kB and 51.2 kB.</p>
</li>
<li>
<p>According to Figure 7 (<strong>Others</strong> ), about 83% of blobs have a submission interval of less than 1 minute, indicating a relative high frequency of user demand for non-rollup applications.</p>
</li>
</ul>
<p>In summary, the type 3 transactions for non-rollup applications can be characterized as: <strong>high-frequency transactions carrying 1 low-utilization blob</strong> .</p>
<p>The essence of this characterization is that non-rollup applications are driven by immediate needs and are less concerned about the fee cost per data byte compared to rollup applications.</p>
<p>This characterization allows for the identification of non-rollup applications, which in turn helps design mechanisms to limit blob abuse by non-rollup applications.</p>
<h2><a class="anchor" href="https://ethresear.ch#is-using-blobs-always-more-cost-effective-than-calldata-12" name="is-using-blobs-always-more-cost-effective-than-calldata-12"></a>Is Using Blobs Always More Cost-effective than Calldata?</h2>
<p>Introducing <code>feeRatio</code> to measure the relative advantages of the two solutions:</p>
<div class="math">
\begin{equation}
feeRatio = \frac{calldataFeeCost }{blobFeeCost}
\end{equation}
</div>
<ul>
<li>When <code>feeRatio</code> ≥ 1, it indicates that using blobs as a data availability solution is not worse than calldata.</li>
<li>When <code>feeRatio</code> &lt; 1, it indicates that using blobs as a data availability solution is worse than calldata.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/5/b5e1ca6b02490795bf2e742ecb92586d1b18e685.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/5/b5e1ca6b02490795bf2e742ecb92586d1b18e685_2_472x500.jpeg" width="472" /></a></div><p></p>
<p>Figure 8 also shows a few cases where <code>feeRatio</code> &lt; 1 (red), indicating that calldata is more cost-effective than blobs:</p>
<ul>
<li>Mostly in non-Rollup applications (<strong>Others</strong>):
<ul>
<li>Non-rollup applications generally do not care about the cost differences between blobs and calldata; they care about using blobs itself, such as in Blobscriptions.</li>
</ul>
</li>
<li>A few in Metal rollup:
<ul>
<li>Rollup application Metal seems not to have considered switching between blobs and calldata in its strategy, leading to suboptimal choices in some extreme cases.</li>
<li>Extreme cases are mainly due to Metal’s low blob utilization (see Figure 6) coinciding with a spike in blob gas prices.</li>
<li>However, given that extreme scenarios are rare and maintaining two data availability solutions is costly, Metal’s suboptimal strategy in extreme cases seems acceptable.</li>
</ul>
</li>
</ul>
<blockquote>
<p>The analysis of blob and calldata solutions in this section only considers fee costs and not delay costs. Considering delay costs, calldata has an actual advantage.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#blob-gas-price-and-blob-usage-strategies-13" name="blob-gas-price-and-blob-usage-strategies-13"></a>Blob Gas Price and Blob Usage Strategies</h2>
<h3><a class="anchor" href="https://ethresear.ch#analysis-of-blob-gas-price-fluctuations-14" name="analysis-of-blob-gas-price-fluctuations-14"></a>Analysis of Blob Gas Price Fluctuations</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/8/58dd45e0e206936eb5eb2b32fc343a70322254c1.jpeg" title="image"><img alt="image" height="363" src="https://ethresear.ch/uploads/default/optimized/3X/5/8/58dd45e0e206936eb5eb2b32fc343a70322254c1_2_690x363.jpeg" width="690" /></a></div><br />
Figures 9 and 10 show that in scenarios of high blob gas prices (&gt; 10), the proportion of non-rollup applications (<strong>Others</strong>) is significantly higher than in scenarios of low blob gas prices (&lt; 10).<p></p>
<p>Therefore, it can be concluded that the surge in blob gas prices is mainly driven by the demand from non-rollup applications, rather than rollup applications. Otherwise, the proportion of rollup and non-rollup applications should remain stable.</p>
<h3><a class="anchor" href="https://ethresear.ch#how-rollups-respond-to-blob-gas-price-fluctuations-15" name="how-rollups-respond-to-blob-gas-price-fluctuations-15"></a>How Rollups Respond to Blob Gas Price Fluctuations</h3>
<p><em>Hypothesis 1: The higher the blob gas price, to reduce fee costs, applications should carry more blobs in type 3 transactions, i.e., the number of blobs should be positively correlated with blob gas prices.</em><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb34ad1ab0fcf6250662d82b007a763309889ef7.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/f/b/fb34ad1ab0fcf6250662d82b007a763309889ef7_2_505x500.jpeg" width="505" /></a></div><p></p>
<p>Figure 14 shows that the hypothesis does not hold.</p>
<p><em>Hypothesis 2: The higher the blob gas price, to reduce fee costs, applications should increase blob utilization, i.e., blob utilization should be positively correlated with blob gas prices.</em><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/521bb465406b224d50b0117150169a5991c5029c.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/521bb465406b224d50b0117150169a5991c5029c_2_498x500.jpeg" width="498" /></a></div><p></p>
<p>Figure 15 shows that the hypothesis does not hold.</p>
<p><em>Hypothesis 3: The higher the blob gas price, to reduce fee costs, applications should delay blob submissions, i.e., blob submission intervals should be positively correlated with blob gas prices.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/e/9e1dd1bbb0bad1163b9eaf7f8d61f340279bb0fd.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/e/9e1dd1bbb0bad1163b9eaf7f8d61f340279bb0fd_2_514x500.jpeg" width="514" /></a></div><p></p>
<p>Figure 16 shows that the hypothesis does not hold.</p>
<blockquote>
<p>In Figures 9 and 10, readers might notice that some rollup applications seem to respond to high blob gas prices. Scroll seems to suspend blob submissions under high blob gas prices. However, this conclusion is incorrect. The reason is that not all rollups immediately used blobs after the EIP-4844 upgrade.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#blobs-and-block-reorg-16" name="blobs-and-block-reorg-16"></a>Blobs and Block Reorg</h2>
<p>From the Decun upgrade to May 22, there were 171 type 3 transactions included in the forked blocks and 348,121 included in the canonical blocks. Therefore, the proportion of type 3 transactions being forked is approximately 0.049%. This section explores the relationship between block reorg and blob.</p>
<h3><a class="anchor" href="https://ethresear.ch#blob-number-distribution-in-the-canonical-and-forked-blocks-with-blobs-17" name="blob-number-distribution-in-the-canonical-and-forked-blocks-with-blobs-17"></a>Blob Number Distribution in the Canonical and Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bef1c025b4ae7c6990e2c7968acf12a6eccba1a2.jpeg" title="image"><img alt="image" height="403" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bef1c025b4ae7c6990e2c7968acf12a6eccba1a2_2_690x403.jpeg" width="690" /></a></div><p></p>
<p><em>Hypothesis: More blobs increase the probability of block reorganizations.</em></p>
<p>If the hypothesis holds, the following inequality should be satisfied:</p>
<div class="math">
\begin{equation}
P(reorg|blob=n)  &gt; P(reorg|blob=n-1)
\end{equation}
</div>
<p>According to <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener nofollow ugc">Bayes’ theorem</a>, inequality above is equivalent to:</p>
<div class="math">
\begin{equation}
\frac{P(blob=n|reorg)}{P(blob=n)}  &gt; \frac{P(blob=n-1|reorg)}{P(blob=n-1)}
\end{equation}
</div>
<p>We check whether the actual data satisfies inequality and obtain the following table:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/c/ec253f7881bbf00cf3b5a37a8635dfb0181309ee.png" title="image"><img alt="image" height="201" src="https://ethresear.ch/uploads/default/optimized/3X/e/c/ec253f7881bbf00cf3b5a37a8635dfb0181309ee_2_690x201.png" width="690" /></a></div><p></p>
<p>The table above shows that equation (10) does not hold for all <code>n</code>. Therefore, the hypothesis does not hold, indicating that more blobs are not significantly related to block reorganizations.</p>
<h3><a class="anchor" href="https://ethresear.ch#distribution-of-type-3-transactions-and-blobs-by-applications-in-the-canonical-and-forked-blocks-with-blobs-18" name="distribution-of-type-3-transactions-and-blobs-by-applications-in-the-canonical-and-forked-blocks-with-blobs-18"></a>Distribution of Type 3 Transactions and Blobs by Applications in the Canonical and Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/d/ddfc7f0d5d5b2a90aaf6efff87b6d7a3733c2aff.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/d/d/ddfc7f0d5d5b2a90aaf6efff87b6d7a3733c2aff_2_425x500.jpeg" width="425" /></a></div><br />
Figures 18 and 19 show that the proportion of type 3 transactions/blobs for Zksync and Scroll in forked blocks is significantly higher than in the canonical blocks.<p></p>
<p>Applications seem to have some connection with block reorganizations, possibly related to differences in blob usage strategies by applications:</p>
<ul>
<li>Zksync and Scroll are less strategic in selecting the timing of submitting type 3 transactions, targeting block heights prone to reorganization.</li>
<li>The unique characteristics of Zksync and Scroll’s type 3 transactions make the blocks containing them more likely to be reorganized.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#clustering-phenomenon-of-forked-blocks-with-blobs-19" name="clustering-phenomenon-of-forked-blocks-with-blobs-19"></a>Clustering Phenomenon of Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/8/281e3d3c49f900b77406ef467f2c32a1b08331eb.jpeg" title="image"><img alt="image" height="286" src="https://ethresear.ch/uploads/default/optimized/3X/2/8/281e3d3c49f900b77406ef467f2c32a1b08331eb_2_690x286.jpeg" width="690" /></a></div><br />
If each block has the same probability of being reorganized, the forked blocks should be evenly distributed across the block height range. However, Figure 20 shows a clustering phenomenon in block heights for forked blocks, possibly related to network conditions.<p></p>
<p>In addition, the clustering phenomenon that occurs in block reorganization seems to be somewhat related to the applications that submit blobs. For example, type 3 transactions for non rollup applications are only included in forked blocks between 19500000 and 19600000.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="64" src="https://ethresear.ch/uploads/default/original/3X/3/0/30aea33d55bd45ce96fab5bf70ecd7a3d0178f9d.png" width="64" />

      <a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc" target="_blank">0xpantarhei.substack.com</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image"><img class="thumbnail" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/f/7/f7108d3b335a7303d071fa1c0b9afa898ea3fa24_2_690x345.jpeg" width="690" /></div>

<h3><a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc" target="_blank">Blob Usage Strategies by Rollups and Non-rollup Applications</a></h3>

  <p>This report provides an in-depth analysis of type 3 transactions used for carrying blobs.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 03:39:04 +0000</pubDate>
</item>
<item>
<title>Block Building is not just knapsack!</title>
<link>https://ethresear.ch/t/block-building-is-not-just-knapsack/19871</link>
<guid>https://ethresear.ch/t/block-building-is-not-just-knapsack/19871</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、块构建、NP-hard、贪婪算法、交易冲突

总结:
本文探讨了区块链中块构建的复杂性，通过将问题与背包问题和最大独立集问题关联，揭示其NP-hard性质。研究者提出几种贪婪算法，包括经典和改进版本，以及如何考虑交易间的冲突。实验结果显示，通过结合背包约束优化的贪婪算法比现有方法能多赚约15%的费用。文章还讨论了模型对以太坊矿工的实际意义，以及未来研究方向，如更精确的序列化问题和交易效用影响的建模。 <div>
<p>Authors: <a class="mention" href="https://ethresear.ch/u/mikerah">@Mikerah</a> Afonso <a class="mention" href="https://ethresear.ch/u/sarisht">@sarisht</a></p>
<p>Shoutout to Gabearro Ventalitan Nerla Yun Qi and Surya for all the vibes and discussions!</p>
<p>This project was done as a Hackathon Project at IC3 camp last week.</p>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h2>
<p>We present a formal model or block building in blockchains. We show that block building is at least a combination of the Knapsack problem and the Maximum Independent Set problem, thus showing that block building is an NP-hard problem. Next, we provide various greedy algorithms with different tradeoffs. Then, we show simulation results to justify the algorithms and benchmarks. Our results show that tweaking the greedy solution with the results of the known knapsack constraint outperforms the currently used greedy algorithm by ~15% in terms of fee earned. Finally, we discuss how this is relevant for block builders in Ethereum in practice and directions for future research.</p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>Block building in Ethereum has evolved into a multimillion-dollar industry, particularly with the introduction of MEV-Boost. This has significantly increased the revenue earned by the builders. However, the builders’ algorithm for selecting transactions and transaction bundles needs more study. In collaboration with Flashbots, Mikerah (group lead for the project) has recently worked on a project that <a href="https://collective.flashbots.net/t/frp-10-distributed-blockbuilding-networks-via-secure-knapsack-auctions/1955" rel="noopener nofollow ugc">formalizes the model for block building as a knapsack problem</a>. This model considers each transaction’s utility (the fee offered by the transaction) and cost (the gas used by the transaction), with a budget for the maximum price that can be paid (the gas limit for the block). The practical relevance of this research is evident, as it addresses a significant limitation of the current model, where not all transactions are independent of each other.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-problem-3" name="the-problem-3"></a>The Problem</h2>
<p>Let’s delve into the heart of the matter by examining why transactions are not independent, a key challenge in block building.</p>
<h3><a class="anchor" href="https://ethresear.ch#bitcoin-blockchain-4" name="bitcoin-blockchain-4"></a>Bitcoin Blockchain</h3>
<p>The most critical problem described in the Satoshi Nakamoto blockchain paper was catching double-spending. If two transactions try to spend the same UTXO, only one of them should make it on-chain. Thus, we can see that some transactions are dependent on each other. However, that is not all; some transactions that interact with Bitcoin’s OP-Code design can also depend on each other. A classic example of this would be that in an HTLC, either a refund transaction (released by revealing a pre-image of a hash) or payment (released when the timelock on the transaction expires) can go through. If both transactions are simultaneously in the mempool, then the transactions conflict with each other.</p>
<h3><a class="anchor" href="https://ethresear.ch#ethereum-blockchain-5" name="ethereum-blockchain-5"></a>Ethereum Blockchain</h3>
<p>Ethereum inherits the double-spending transaction problem, but owing to its smart contract and gas fee design, it only partially suffers from the other type of conflict since the fee is paid based on the gas used. This causes the model to shift slightly, where the fee paid and the gas used depends on other chain transactions. Further, in the presence of searchers, some transactions are bundled such that multiple bundles contain the same transaction and thus cannot be included in the block simultaneously.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-6" name="model-6"></a>Model</h2>
<p>We first introduce the assumptions we make before describing the mathematical formulations.</p>
<h4><a class="anchor" href="https://ethresear.ch#assumptions-7" name="assumptions-7"></a>Assumptions</h4>
<ul>
<li>Dependent fees and gas are hard to model since we cannot have a boolean representation. Thus, we only consider “Conflicts” and touch upon “Dependency.” Conflicts are situations in which the transactions cannot occur together, and dependency is when one transaction requires another transaction to be executed before it is valid.</li>
<li>We further ignore the optimal ordering of transactions inside a block. Ordering transactions in a particular order can lead to higher profits due to MEV, which we ignore for the same reason as above.</li>
<li>For Ethereum, under the conditions of EIP 1559, the fee considered is the part above the base fee. Any transaction with a negative fee is ignored.</li>
</ul>
<p>Given these assumptions, we now model the binary allocation problem with constraints and dependencies as follows:<br />
Let <span class="math">T</span> be the set of transactions. A transaction in <span class="math">T</span> is denoted by <span class="math">tx_i</span>.<br />
Let <span class="math">f_i</span> denote the fee associated with a transaction <span class="math">tx_i</span>.<br />
Let <span class="math">g_i</span> denote the gas associated with a transaction <span class="math">t_i</span><br />
Let <span class="math">B</span> be the maximum block gas limit.</p>
<p>Then, we have the following optimization problem<br />
Maximise</p>
<div class="math">
\sum_{i\in n} f_ix_i 
</div>
<p>Subject to</p>
<div class="math">
\begin{align*}
 &amp;\sum_{i\in n} x_ig_i \leq B \\
 &amp; x_i+x_j \leq C_{ij}, \forall i\neq j \in n\\
 &amp; x_j - x_i \leq M_{ij}, \forall i\neq j \in n\\
 &amp; x_i \in \{0,1\}
 \end{align*}
</div>
<p>where,</p>
<ul>
<li><span class="math">C_{ij} = 1</span> if <span class="math">t_i</span> and <span class="math">t_j</span> are conflicting transactions, 2 otherwise</li>
<li><span class="math">M_{ij} = 0</span> if <span class="math">t_j</span> depends on <span class="math">t_i</span> and can only be allocated after <span class="math">t_i</span>, 1 otherwise</li>
</ul>
<p>Since, in practice, it is hard for a block builder to infer the 3rd condition (without executing all of the transactions) within a limit snapshot of the transactions within their order flow pools, we can omit the 3rd constraint to simplify the problem. If the builder comes across such a transaction, it would be considered invalid.</p>
<p>As such, we can obtain the following simplified optimization problem<br />
Maximise</p>
<div class="math">
\sum_{i\in n} f_ix_i
</div>
<p>Subject to</p>
<div class="math">
\begin{align*}
 &amp;\sum_{i\in n} x_ig_i \leq BL \\
 &amp; x_i+x_j \leq C_{ij}, \forall i\neq j \in n\\
 &amp; x_i \in \{0,1\}
 \end{align*}
</div>
<p>where,</p>
<ul>
<li><span class="math">C_{ij} = 1</span> if <span class="math">t_i</span> and <span class="math">t_j</span> are conflicting transactions, 2 otherwise</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#reductions-8" name="reductions-8"></a>Reductions</h3>
<p>Now, we present formal arguments as to why block building is an instance of the knapsack problem and the maximum independent set problem.</p>
<h4><a class="anchor" href="https://ethresear.ch#reduction-to-knapsack-9" name="reduction-to-knapsack-9"></a>Reduction to knapsack</h4>
<p>The reduction of the above problem to knapsack is easy to see. We assume no conflicts arise amongst any transactions. In that case, the problem is the same as solving a knapsack problem, with the utility as the fee paid by the transaction, space occupied as the gas used by a transaction, and finally, the block’s gas limit determines the knapsack size. Thus, the block-building problem is at least as hard as the knapsack problem.</p>
<h4><a class="anchor" href="https://ethresear.ch#reduction-to-maximum-independent-set-10" name="reduction-to-maximum-independent-set-10"></a>Reduction to Maximum Independent Set</h4>
<p>If we can solve the above instance of block building problem without any constraint that limits the size of the block in polynomials, then consider the following instance where the block gas limit is set to the sum of gas of all transactions in the mempool. This would imply enough space for all the transactions in the mempool to fit in the block. This problem is now equivalent to finding the maximum weighted independent set because we can consider all transactions as vertices, and an edge exists between two vertices if the corresponding transactions conflict. The above reduction creates the instantiation of the maximum weighted independent set problem, which is again known as NP-hard.</p>
<h2><a class="anchor" href="https://ethresear.ch#algorithms-for-approximate-result-11" name="algorithms-for-approximate-result-11"></a>Algorithms for approximate result</h2>
<p>As we mentioned above, block building is an NP-hard problem with reductions to both the knapsack problem and the maximum weighted independent set problem. Since we know that the maximum weighted independent set problem doesn’t have a C-approximation, this implies that the block-building problem also doesn’t have a C-approximation.</p>
<p>As such, we devise several greedy algorithms in order to solve the block-building problem in practice.</p>

<h3><a class="anchor" href="https://ethresear.ch#greedy-classic-gc-12" name="greedy-classic-gc-12"></a>Greedy Classic (GC)</h3>
<p>We expect today’s builders to use the first algorithm we present. It follows the most widely used knapsack greedy solution, where all objects are sorted according to the ratio of their utility to cost, and then greedily allocate space to each object until you can no longer allocate more space. Due to the added conflict constraint, the builder must check for conflict with any transaction already added to the block. Thus, the algorithm works as follows:</p>
<p>Algorithm input: <span class="math">T = \{t_i\}, F = \{f_i\}, G = \{g_i\}</span><br />
Algorithm output: An ordered block with gas used less than BL<br />
Algorithm description:</p>
<pre><code class="lang-auto">Sort T by corresponding F/G
Let B  := {}
Let BS := 0
For each t in T, f in F, g in G do:
    if t has any conflict with tx in B: continue;
    if g + BS &lt; BL: B.append(t); BS += g
return B
</code></pre>
<p>In practice, the conflict between transactions is only known if simulated sequentially. We propose two constraints on how this conflict can be modeled.</p>
<ul>
<li>Two transactions <span class="math">t_1</span> and <span class="math">t_2</span> conflict if the transactions cannot be executed together. This can happen if some address is trying to double-spend some money it has or if two searcher bundles try to extract MEV from the transaction. We call this conflict a “Real” conflict.</li>
<li>Two transactions <span class="math">t_1</span> and <span class="math">t_2</span> conflict if they interact with the same address. We call this conflict an “All” condition. These transactions do not necessarily invalidate each other. Still, we keep this as a potential conflict condition since this conflict is more straightforward to determine (constant size operation) than the other constraint (gas size operation), and thus can be helpful for builders optimizing based on the time computing is used.</li>
</ul>
<p>Note: In the solution simulation, we assume that <span class="math">p=0.95</span> of transactions in the “All” conflict are not in the “Real” conflict.</p>
<p>Based on the definition of conflicts, we present the two baseline greedy solutions, which we label CG All and CG Real.</p>
<h2><a class="anchor" href="https://ethresear.ch#knapsack-greedy-13" name="knapsack-greedy-13"></a>Knapsack Greedy</h2>
<p>The greedy solution described above is not a good approximation solution. Looking back at the knapsack problem, we get a 1/2 approximation over the optimal solution by comparing the above classic greedy with the utility of the first object that was not allocated.</p>
<p>The algorithm begins by running an instance of the greedy classic. It then finds the highest paying (highest f/g) transaction and adds it to the block. Adding this transaction would require modification of the block since some transactions in block (B) conflicted with this transaction, or the transaction could not be inserted due to insufficient space. Thus, we remove transactions that conflict with this new addition and then make enough space to add this transaction. After inserting the transaction, we repeat the greedy insertion until the block is again full. We repeat the above algorithm until we have seen each transaction at least once over the greedy solution.</p>
<p>The pseudocode for the solution is as follows:</p>
<pre><code class="lang-auto">Sort T by corresponding F/G
Let B  := {}
Let B_f:= {}
Let S  := {}
Let BS := 0
while S != T: 
    let t := t in T, not in S, with maximum f/g:
    remove any transaction from B that conflicts with t.
    remove smallest f/g txs until there is space to insert t.
    B.append(t)
    S.append(t)
    For each t in T, f in F, g in G do:
        if t has any conflict with tx in B: continue;
        if g + BS &lt; BL: B.append(t); BS += g; S.append(t)
    if sum(B.f) &gt; sum(B_f.f): B_f = B

return B_f

# B.f is the fee corresponding to each transaction in B
</code></pre>
<p>In this greedy protocol, we attempt to enforce the inclusion of a transaction every time. It is still distinct from the greedy knapsack 1/2 approximation, but it tries to replicate what was accomplished by the knapsack greedy but for all items not picked by the greedy algorithm.</p>
<p>This solution will outperform its classic greedy counterpart since it computes maximum over all solutions, one of which is the classic greedy solution. Like the classic greedy solution, we analyze this when conflicts are “Real” and “All”.</p>
<h2><a class="anchor" href="https://ethresear.ch#classic-greedy-informed-solutions-14" name="classic-greedy-informed-solutions-14"></a>Classic Greedy Informed Solutions</h2>
<p>Solving the knapsack problem is very easy compared to all known NP-Hard problems, especially the maximum independent set condition we have been imposing. Thus, we allow the builder to solve the knapsack reasonably accurately and quickly via a BLP solver. The knapsack solution gives the builder some idea about how to build the block, and then when there are conflicting transactions in the chosen block, the “later” transactions are discarded. In this solution, we run a knapsack LP solution. On the output of the LP, we sort the output based on i) f/g ratio ii) f, and finally iii) g. The way greedy works here is that the transactions are picked in the order of the metric, and whenever there is a conflict, the LP solver is recalled, but removing constraints on the already added and the conflicting transaction (<span class="math">x_i</span> is set to 1 for all that have already been chosen and <span class="math">x_i</span> is set to 0 for the conflicting transaction). This is repeated until the block is full.</p>
<pre><code class="lang-auto">Let B  := {}
Let B_c:= {nil}
Let BS := 0
Let C  := {}
while B_c != B:
    B_c = LP.solve(sum(x.f), x.g &lt;= BL, C)
    Sort B_c by "heuristic"
    for t in B_c:
        if t has any conflict with tx in B: 
            C.add(x_t = 0)
            break;
        B.append(t)
        C.add(x_t = 1)

return B


# Replace "heurestic" by f/g for standard, 
                       f for high-value 
# Sorting is in descending order 
</code></pre>
<p>We label these transactions as CGI-f/g and CGI-f. We only analyze the “All” conflicts for this since the time to run the algorithm is potentially higher than for the other Greedy Algorithms.</p>
<h2><a class="anchor" href="https://ethresear.ch#simulation-15" name="simulation-15"></a>Simulation</h2>
<p>Due to our limited time to work on the project, we tried to replicate the transaction data synthetically instead of working with real transactions. To properly simulate Ethereum mempool transactions, we choose the following dataset:</p>
<h3><a class="anchor" href="https://ethresear.ch#dataset-16" name="dataset-16"></a>Dataset</h3>
<p>We choose 2000 transactions under this distribution.</p>
<ul>
<li>80%: SMALL: g ~ N(24k, 3k)  f/g ~ N(16,4) - These low gas-consuming transactions have minimal smart contract interactions and thus use less gas. In almost all cases, the gas fees for these transactions are small since they are usually never a priority transaction.</li>
<li>18%  : LARGE1: g ~ N(200k, 20K)  f/g ~ N(16,4) - These represent transactions that have a significant contract execution; however, in this case, these are still not priority transactions, since the user is okay to wait for some time for the contract execution.</li>
<li>2%  : LARGE2: g ~ N(200k, 20K)  f/g ~ N(40,10) - These are the priority transactions. Usually, these have high gas usage since they mostly interact with, for example, DeFi contracts and want to be executed as soon as possible.</li>
</ul>
<p>We simulate the conflicts among these transactions by randomly choosing transactions such that each transaction has a <span class="math">\sigma</span> number of conflicts. While our preliminary results constitute the same <span class="math">\sigma</span> across all types of transactions, in practice, the larger transactions, especially the high-paying ones, would have a more significant number of conflicts since usually MEV extracting bundles would be constructed around them.</p>
<h3><a class="anchor" href="https://ethresear.ch#results-17" name="results-17"></a>Results</h3>
<p>We ran our simulation over 100 blocks with the mempool created as above.</p>
<p>When we consider <span class="math">\sigma=2</span> number of conflicts per transaction, we see the following results:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/5/45d6ba5351f45cbc8f51bd30a3637d3f1554c6f5.png" title="s2feeratio"><img alt="s2feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/4/5/45d6ba5351f45cbc8f51bd30a3637d3f1554c6f5_2_668x499.png" width="668" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/4/1430b955e746ba6faf056ac169b049c0e3dded9a.png" title="s2wastedgas"><img alt="s2wastedgas" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/1/4/1430b955e746ba6faf056ac169b049c0e3dded9a_2_668x499.png" width="668" /></a></div><p></p>
<p>Increasing the number of conflicts each transaction had increases the problem’s difficulty. Therefore, the various greedy algorithms have a larger separation in performance:</p>
<p>For <span class="math">\sigma = 10</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/e/ae043667cfb292234612d06e14e402d2cc86b268.png" title="s10feeratio"><img alt="s10feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/a/e/ae043667cfb292234612d06e14e402d2cc86b268_2_668x499.png" width="668" /></a></div><p></p>
<p>For <span class="math">\sigma = 20</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/9/79e0d8ad31f56fcb617c858775285e5e6b5b28fb.png" title="s20feeratio"><img alt="s20feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/7/9/79e0d8ad31f56fcb617c858775285e5e6b5b28fb_2_668x499.png" width="668" /></a></div><p></p>
<p>For <span class="math">\sigma = 40</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/3/e333c84dc6daa57f54481113545d081b8bb2af91.png" title="s40feeratio"><img alt="s40feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/e/3/e333c84dc6daa57f54481113545d081b8bb2af91_2_668x499.png" width="668" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#future-research-direction-18" name="future-research-direction-18"></a>Future Research Direction</h2>
<p>Based on our results, solving the block-building problem is an NP-Hard problem, and as long as conflicts exist amongst the transactions, it remains a complex problem.</p>
<p>However, this does not mean that all hope is lost. The block-building problem may have more potential than the Maximum Independent Set problem. Combining the space of Knapsack and Maximum Independent Set gives us a smaller search space to find a satisfactory approximate solution for the issue at hand.</p>
<p>Further, for Ethereum bundles from searchers, if <span class="math">tx_i</span> and <span class="math">tx_j</span> conflict, as well as <span class="math">tx_j</span> and <span class="math">tx_k</span> conflict, then there is a high likelihood that <span class="math">tx_i</span> and <span class="math">tx_k</span> also conflict. This eases the constraints on the solution since, amongst an all-2-all graph of transactions, for MIS, you only need to pick the transaction with the highest utility (also satisfying knapsack).</p>
<p>Another thing to note is that our algorithms can inform how block builders construct blocks in practice. Notably, the Classical Greedy Informed algorithm, in which we sort the transactions by highest fee, is closest to the optimal solution.</p>
<p>That being said, the most exciting extension to this research would be modeling the block-building problem as a job sequencing problem instead and somehow estimating how utility (fee+MEV) from one transaction affects the utility of other transactions sequenced after the first transaction.</p>
<p>On that note, we invite potential collaborators to explore new ideas for building blocks that maximize the builders’ utility.</p>
            <p><small>7 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/block-building-is-not-just-knapsack/19871">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 17:35:36 +0000</pubDate>
</item>
<item>
<title>Fork-Choice enforced Inclusion Lists (FOCIL): A simple committee-based inclusion list proposal</title>
<link>https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870</link>
<guid>https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870</guid>
<content:encoded><![CDATA[
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/3/639a5b7de796701a13a5759e8f5a1fe393f067f3.jpeg" title="DALL·E 2024-06-05 14.58.08 - A highly realistic illustration of a rock with the Ethereum symbol fossilized into it, set in a cave. The rock should appear weathered and ancient, wi"><img alt="DALL·E 2024-06-05 14.58.08 - A highly realistic illustration of a rock with the Ethereum symbol fossilized into it, set in a cave. The rock should appear weathered and ancient, wi" height="394" src="https://ethresear.ch/uploads/default/optimized/3X/6/3/639a5b7de796701a13a5759e8f5a1fe393f067f3_2_690x394.jpeg" width="690" /></a></div><br />
<em>^focil =&gt; fossil =&gt; protocol ossification</em><p></p>
<p><em>by <a href="https://ethresear.ch/u/soispoke/summary">Thomas</a>, <a href="https://ethresear.ch/u/fradamt/summary">Barnabé</a>, <a href="https://ethresear.ch/u/fradamt/summary">Francesco</a> and <a href="https://ethresear.ch/u/julian/summary">Julian</a></em> - June 19th, 2024</p>
<p><em>This design came together during a small, week long, in-person gathering in Berlin with RIG and friends to discuss censorship resistance, issuance, and Attester-Proposer-Builder-Consensus-Execution-[insert here] Separation.</em></p>
<p><em>Thanks to Luca, Terence, Toni, Ansgar, Alex, Caspar and Anders for discussions, feedback and comments on this proposal.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a><strong>tldr</strong></h1>
<p>In this post, we introduce Fork-Choice enforced Inclusion Lists (FOCIL), a simple committee-based IL design.</p>
<p>FOCIL is built in three simple steps:</p>
<ol>
<li>Each slot, a set of validators is selected to become <strong>IL committee members.</strong> Each member gossips one <em>local inclusion list</em> according to their subjective view of the mempool.</li>
<li><strong>The block proposer</strong> collects and aggregates available local inclusion lists into a concise <em>aggregate</em>, which is included in its block.</li>
<li><strong>The attesters</strong> evaluate the quality of the <em>aggregate</em> given their own view of the gossiped local lists to ensure the block proposer accurately reports the available local lists.</li>
</ol>
<p>This design ensures a robust and reliable mechanism to uphold Ethereum’s censorship resistance and <a href="https://ethresear.ch/t/uncrowdable-inclusion-lists-the-tension-between-chain-neutrality-preconfirmations-and-proposer-commitments/19372">chain neutrality</a> properties, by guaranteeing timely transaction inclusion.</p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h1>
<p>In an effort to shield the Ethereum validator set from centralizing forces, the right to build blocks has been auctioned off to specialized entities known as builders. Over the past year, this has resulted in a few sophisticated builders dominating the network’s block production. Economies of scale have further entrenched their position, making it increasingly difficult for new entrants to gain significant market share. A direct consequence of oligopolistic block production is a deterioration of the network’s (weak) censorship resistance properties. Today, <a href="https://censorship.pics/" rel="noopener nofollow ugc">two of the top three builders</a> are actively filtering out transactions interacting with sanctioned addresses from their blocks. In contrast, 90% of the <a href="https://www.ethernodes.org/countries" rel="noopener nofollow ugc">more decentralized and heterogeneous validator set</a> is not engaging in censorship.</p>
<p>This has driven <a href="https://github.com/michaelneuder/mev-bibliography?tab=readme-ov-file#censorship-resistance" rel="noopener nofollow ugc">research</a> toward ways that allow validators to impose constraints on builders by force-including transactions in their blocks. These efforts recently culminated in the first practical implementation of forward <span class="math">\text{ILs}</span> (<span class="math">\text{fILs}</span>) being considered for inclusion in the upcoming Pectra fork (see <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">design</a>, <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP</a>, and <a href="https://notes.ethereum.org/@mikeneuder/il-spec-overview" rel="noopener nofollow ugc">specs</a> <a href="https://gist.github.com/michaelneuder/ba32e608c75d48719a7ecba29ec3d64b" rel="noopener nofollow ugc">here</a>). However, some concerns were raised about the specific mechanism proposed in <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a>, leading to its rejection.</p>
<p>Here, we introduce FOCIL, a simple committee-based design improving upon previous IL mechanisms (<a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">Forward ILs</a>, <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a>) or co-created blocks (<a href="https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777">CBP</a>) and addressing issues related to <a href="https://ethresear.ch/t/fun-and-games-with-inclusion-lists/16557">bribing/extortion attacks</a>, IL equivocation, <a href="https://ethereum.org/en/roadmap/account-abstraction/" rel="noopener nofollow ugc">account abstraction</a> (AA) and incentive incompatibilities. Note also Vitalik’s recent proposal “<a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">One-bit-per-attester inclusion lists</a>”, where the committee chosen to build the list is essentially the whole set of attesters.</p>
<h1><a class="anchor" href="https://ethresear.ch#design-3" name="design-3"></a><strong>Design</strong></h1>
<p>In this section, we introduce the core properties of the FOCIL mechanism (see <strong>Figure 1.</strong>).</p>
<h2><a class="anchor" href="https://ethresear.ch#high-level-overview-4" name="high-level-overview-4"></a><strong>High-level overview</strong></h2>
<p>Each slot, a set of validators is randomly selected to become part of an inclusion list (<span class="math">\text{IL}</span>) committee. <span class="math">\text{IL}</span> committee members are responsible for creating local inclusion lists (<span class="math">\text{IL}_\text{local}</span>) of transactions pending in the public mempool. Local <span class="math">\text{ILs}</span> are then broadcast over the global topic, and the block producer must include a canonical aggregate (<span class="math">\text{IL}_\text{agg}</span>) of transactions from the collected local <span class="math">\text{ILs}</span> in its block <span class="math">B</span>. The quality of <span class="math">\text{IL}_\text{agg}</span> is checked by attesters, and conditions the validity of block <span class="math">B</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bedfe43a4319b8ef24f99db6089793aeda7dc3fb.png" title="Screenshot 2024-06-04 at 15.58.51"><img alt="Screenshot 2024-06-04 at 15.58.51" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bedfe43a4319b8ef24f99db6089793aeda7dc3fb_2_690x375.png" width="690" /></a></div><p></p>
<blockquote>
<p><strong>Figure 1.</strong> Diagram illustrating the FOCIL mechanism.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#mechanism-5" name="mechanism-5"></a><strong>Mechanism</strong></h2>
<ul>
<li><strong>Validator Selection and Local Inclusion Lists</strong>
<ul>
<li>A set of validators is selected from the beacon committee to become <span class="math">\text{IL}</span> committee members for slot <span class="math">n</span>. This set is denoted as <span class="math">\text{IL}_\text{committee}(n) = \{ 1, \dots, m \}</span>, where <span class="math">m</span> is the number of <span class="math">\text{IL}</span> committee members.</li>
<li>Each <span class="math">\text{IL}</span> committee member <span class="math">i \in \text{IL}_\text{committee}(n)</span> releases a local <span class="math">\text{IL}</span>, resulting in a set of local <span class="math">\text{ILs}</span> for slot <span class="math">n</span>, defined as <span class="math">\text{IL}_\text{local}(n) = \{ \text{IL}_1, \dots, \text{IL}_m \}</span>.</li>
<li>Each local <span class="math">\text{IL}_i</span> contains transactions: <span class="math">\text{IL}_i = \{ \text{tx}^1_i, \dots, \text{tx}^{j_i}_i \}</span>, where each <span class="math">\text{tx}</span> is represented as  <span class="math">\text{tx} = (\text{tx}[\text{From}], \text{tx}[\text{Gas Limit}])</span>, and  <span class="math">j_i</span> indicates the number of transactions in <span class="math">\text{IL}_i</span>. The <code>From</code> field represents the sender’s address, and the <code>Gas Limit</code> field represents the maximum gas consumed by a transaction. This is used to check whether a transaction can be included in a block given the <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">conditional</a> IL property.</li>
</ul>
</li>
<li><strong>Block Producer’s Role</strong>
<ul>
<li>The block producer of slot <span class="math">n</span>, denoted <span class="math">\text{BP}(n)</span>, must include an <span class="math">\text{IL}</span> aggregate denoted <span class="math">\text{IL}_\text{agg}</span> and a payload in their block  <span class="math">B = (B[\text{IL}_\text{agg}], B[\text{payload}])</span>.</li>
<li><span class="math">\text{IL}_\text{agg}</span> consists of transactions: <span class="math">\text{IL}_\text{agg} = \{ \text{tx}^1_\text{agg}, \dots, \text{tx}^{t_\text{agg}}_\text{agg} \}</span> where each transaction <span class="math">\text{tx}_\text{agg}</span> is defined as <span class="math">(\text{tx}_\text{agg}[\text{tx}], \text{tx}_\text{agg}[\text{bitlist}])</span>, and the <span class="math">\text{payload}</span> must include transactions present in the <span class="math">\text{IL}_\text{agg}</span>.</li>
<li>The bitlist <span class="math">\text{tx}_\text{agg}[\text{bitlist}] \in \{0, 1\}^m</span> indicates which local $\text{IL}$s included a given transaction.</li>
<li>The function <span class="math">\text{Agg}</span> takes the set of available local ILs <span class="math">\text{IL}_\text{local}(n)</span> and outputs a “canonical” aggregate. The proposer aggregate <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> is included in block <span class="math">B</span>, and each attester evaluates it quality by comparing it against its own <span class="math">\text{IL}_\text{agg}^\text{attester}</span>, using the function <span class="math">\text{Eval}(\text{IL}_\text{agg}^\text{attester}, \text{IL}_\text{agg}^\text{proposer}, Δ) \in \{ \text{True}, \text{False} \}</span>.</li>
</ul>
</li>
<li><strong>Attesters’ Role</strong>
<ul>
<li>Attesters for slot <span class="math">n</span> receive the block <span class="math">B</span> and apply a function <span class="math">\text{Valid}(B)</span> to determine the block validity.</li>
<li><span class="math">\text{Valid}</span> encodes the block validity according to the result of <span class="math">\text{Eval}</span>, as well as core IL properties such as <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">conditional vs. unconditional</a>.</li>
<li>Here are some scenarios to illustrate <span class="math">\text{IL}</span>-dependent validity conditions:
<ul>
<li>If local <span class="math">\text{ILs}</span> are made available before deadline <span class="math">d</span>, but the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is considered invalid.</li>
<li>If no local <span class="math">\text{ILs}</span> are made available before deadline <span class="math">d</span>, and the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is considered valid.</li>
<li>If block <span class="math">B</span> is full, local $\text{IL}$s were available before <span class="math">d</span>, and the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is still considered valid.</li>
<li>If <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> doesn’t overlap with most of attesters’ <span class="math">\text{IL}_\text{agg}^\text{attester}</span> according to <span class="math">\text{Eval}</span>, block <span class="math">B</span> is considered invalid.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>The core FOCIL mechanism could be defined as:</strong></p>
<div class="math">
\mathcal{M}_\text{FOCIL}= (\text{Agg}, \text{Eval}, \text{Valid})
</div>
<h2><a class="anchor" href="https://ethresear.ch#timeline-6" name="timeline-6"></a>Timeline</h2>
<p>The specific timing is given here as an example, but more research is required to figure out which numbers make sense.</p>
<ul>
<li><strong>Slot</strong> <span class="math">n-1</span><strong>,</strong> <span class="math">t = 6</span><strong>:</strong> The <span class="math">\text{IL}</span> committee releases their local <span class="math">\text{ILs}</span>, knowing the contents of block <span class="math">n-1</span>.</li>
<li><strong>Slot</strong> <span class="math">n-1</span><strong>,</strong> <span class="math">t=9</span><strong>:</strong> There is a local <span class="math">\text{IL}</span> freeze deadline <span class="math">d</span> after which everyone locks their view of the observed local <span class="math">\text{ILs}</span>. The proposer broadcast the <span class="math">\text{IL}_\text{agg}</span> over the global topic.</li>
<li><strong>Slot</strong> <span class="math">n</span><strong>,</strong> <span class="math">t=0</span><strong>:</strong> The block producer of slot <span class="math">n</span> releases their block <span class="math">B</span> which contains both the payload and aggregated <span class="math">\text{IL}_\text{agg}</span>.</li>
<li><strong>Slot</strong> <span class="math">n</span><strong>,</strong> <span class="math">t=4</span><strong>:</strong> The attesters of slot <span class="math">n</span> vote on block <span class="math">B</span>, deciding whether <span class="math">\text{IL}_\text{agg}</span> is “good enough” by comparing the result of computing the <span class="math">\text{Agg}</span> function over their local view of available local <span class="math">\text{ILs}</span> (applying <span class="math">\text{Eval}</span>) and checking if block <span class="math">B</span> is <span class="math">\text{Valid}</span>.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#aggregation-evaluation-and-validation-functions-7" name="aggregation-evaluation-and-validation-functions-7"></a><strong>Aggregation, Evaluation and Validation Functions</strong></h2>
<p>As mentioned in the mechanism section, FOCIL relies on three core functions. Each of these needs to be specified to ensure the mechanism fulfils its purpose.</p>
<ul>
<li>
<p><strong>The <span class="math">\text{Agg}</span> function</strong> is probably the most straightforward to define: Transactions from all collected local <span class="math">\text{ILs}</span> should be deterministically aggregated and deduplicated to construct <span class="math">\text{IL}_\text{agg}</span>. We let:</p>
<ul>
<li><span class="math">\text{IL}_\text{local} = \{\text{IL}_1, \text{IL}_2, \ldots, \text{IL}_m\}</span> be the set of local inclusion lists collected from committee members <span class="math">m</span>.</li>
<li>Each <span class="math">\text{IL}_i = \{\text{tx}_i^1, \text{tx}_i^2, \ldots, \text{tx}_i^{t_i}\}</span><br />
be the transactions in the local inclusion list of the <span class="math">i</span>-th committee member.</li>
<li>Each transaction <span class="math">\text{tx}</span> be defined by <span class="math">(\text{hash}, \text{sender}, \text{nonce})</span></li>
</ul>
<p><span class="math">\text{Agg}(\text{IL}_\text{local})</span>  can be thus defined as:</p>
<div class="math">
\text{Agg}(\text{IL}_\text{local}) = {\text{tx} | \text{tx} \in \bigcup_{i \in m} \text{tx}_{i} }
</div>
</li>
<li>
<p><strong>The <span class="math">\text{Eval}</span> function</strong> is used by each slot <span class="math">n</span> attester to assess the quality of the <span class="math">\text{IL}_\text{agg}</span> included in block <span class="math">B</span>. Each attester calculates the <span class="math">\text{Agg}</span> function over all local <span class="math">\text{ILs}</span> they have observed in their view and then compares their generated <span class="math">\text{IL}_\text{agg}^\text{attester}</span> to the one included by the proposer <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>. The <strong><span class="math">\text{Eval}</span></strong> function can then be defined so that the proposer’s <span class="math">IL_{\text{agg}}^{\text{proposer}}</span> is valid if it includes a sufficient proportion of transactions observed by the attesters, as defined by the parameter <span class="math">Δ</span>:</p>
<div class="math">
\text{Eval}(IL_{\text{agg}}^{\text{attester}}, IL_{\text{agg}}^{\text{proposer}}, \Delta) = 
\begin{cases} 
\text{True} &amp; \text{if } \frac{|IL_{\text{agg}}^{\text{attester}} \cap IL_{\text{agg}}^{\text{proposer}}|}{|IL_{\text{agg}}^{\text{attester}}|} \geq \Delta \\
\text{False} &amp; \text{otherwise}
\end{cases}
</div>
<p><em>Note that the <span class="math">\text{Eval}</span> function, and especially its parameter <span class="math">Δ</span>, will determine the trade-off between <strong>(1) the quality</strong> of the <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> and the agency we are willing to give to proposers, and <strong>(2)</strong> <strong>liveness</strong>, as we might see an increase in missed slots if the criteria are set too strictly.</em></p>
</li>
<li>
<p><strong>The <span class="math">\text{Valid}</span> function</strong> encodes whether the  <span class="math">\text{IL}_\text{agg}</span> conforms to pre-defined core <span class="math">\text{IL}</span> properties, such as:</p>
<ul>
<li><strong>Conditional vs. Unconditional</strong>: Should the proposer include as many <span class="math">\text{IL}</span> transactions in the block as possible as long as there is space left, or is there dedicated block space reserved for <span class="math">\text{IL}</span> transactions?</li>
<li><strong>Where-in-block</strong>: Where should <span class="math">\text{IL}</span> transactions be included in the block? Should they be placed anywhere, at the top of the block, or at the end of the block?</li>
<li><strong>Expiry</strong>: How long do transactions remain in the <span class="math">\text{IL}</span> once they have been included? What happens if a slot is skipped?</li>
</ul>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#more-rules-8" name="more-rules-8"></a><strong>More rules</strong></h2>
<p>In the following section, we introduce other rules that could be added to the core mechanism to specify:</p>
<ul>
<li>How users should pay for having their transactions included (<span class="math">\text{Payment}</span>)</li>
<li>How rewards can be distributed across FOCIL participants (<span class="math">\text{Reward}</span>)</li>
<li>How local <span class="math">\text{ILs}</span> are constructed (<strong><span class="math">\text{Inclusion}</span></strong>)</li>
<li>Interactions between <span class="math">\text{IL}</span> and payload transactions (<span class="math">\text{Priority}</span>).</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#user-bidding-textpayment-and-textreward-rules-9" name="user-bidding-textpayment-and-textreward-rules-9"></a><strong>User Bidding,</strong> <span class="math">\text{Payment}</span> <strong>and</strong> <span class="math">\text{Reward}</span> <strong>rules</strong></h3>
<ul>
<li>Users place bids based on the value they assign to having their transactions included in block <span class="math">B</span>. They need to take into consideration the FOCIL mechanism <span class="math">\mathcal{M}_\text{FOCIL}</span>, but also how the <a href="https://eips.ethereum.org/EIPS/eip-1559" rel="noopener nofollow ugc">EIP-1559</a> mechanism works to set their base fees, denoted <span class="math">\mathcal{M}_\text{1559}</span>. For instance, a user <span class="math">t</span> makes a bid <span class="math">b^t(v^t, \mathcal{M}_\text{FOCIL},\mathcal{M}_\text{1559}) = (\delta^t, f^t)</span>, where <span class="math">\delta^t</span> is the maximum priority fee and <span class="math">f^t</span> is the maximum total fee (i.e., base fee <span class="math">r</span> + priority fee <span class="math">\delta^t</span>).</li>
<li>The vector of bids from all users is denoted as <span class="math">\mathbf{b} = (b^1, b^2, \dots, b^T)</span>, where each <span class="math">b^t</span> represents the bid from user <span class="math">t</span>.</li>
<li>The <span class="math">\text{Payment}</span> rule <span class="math">p(\mathbf{b}) = (p_0(\mathbf{b}), p_1(\mathbf{b}), \dots, p_t(\mathbf{b}), \dots, p_m(\mathbf{b}))</span> ensures that users pay no more than their priority fee <span class="math">\hat{\delta}^t = \min(\delta^t, f^t - r)</span>. Here, <span class="math">p_0(\mathbf{b}</span>) represents the payment to the block producer, and <span class="math">p_t(\mathbf{b}</span>) represents the payment made by user <span class="math">t</span> to all other <span class="math">\text{IL}</span> committee members, where the set of users has size <span class="math">m</span> and the block producer is indexed by 0.</li>
</ul>
<p>The <span class="math">\text{Payment}</span> rule defined above is meant to give a general view of how the value paid by users’ transactions can be redistributed across FOCIL participants (e.g., <span class="math">\text{IL}</span> committee members, block producer) to incentivize behavior that is considered good for the network, in this case preserving its censorship-resistant properties. Incentivizing <span class="math">\text{IL}</span> committee members for including transactions strengthens the robustness of the mechanism by increasing the <a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">cost of censorship</a>, or the amount a censoring party would have to pay for <span class="math">\text{IL}</span> committee members to exclude transactions from their local <span class="math">\text{ILs}</span>. Delving into the specifics of how the builder and <span class="math">\text{IL}</span> committee members should be rewarded is beyond the scope of this post as distributing rewards in an incentive-compatible way, especially during congestion, gets quite complex.</p>
<p>However, here are three high-level options to consider:</p>
<ul>
<li><strong>Option 1</strong>: All transaction priority fees go to the builder, and <span class="math">\text{IL}</span> committee members are just not incentivized to include transactions in their local <span class="math">\text{ILs}</span>. This simple option doesn’t require any changes to the existing fee market, but entirely relies on altruism from <span class="math">\text{IL}</span> committee members. We could even consider an opt-in version of FOCIL, where validators can choose to be part of a list that may be elected to become <span class="math">\text{IL}</span> committee members and participate in building <span class="math">\text{ILs}</span> altruistically. However, it wouldn’t increase the cost of censorship nor would it make it very appealing for validators to participate in the mechanism. This could also lead to out-of-band payments from users wanted to have their transactions included in local <span class="math">\text{ILs}</span>.</li>
<li><strong>Option 2</strong>: Priority fees from transactions included in the block are given to the <span class="math">\text{IL}</span> committee members. To distribute rewards among members, we could implement a weighted incentive system by defining a <span class="math">\text{Reward}</span> rule to calculate and distribute rewards for each member, considering the quantity (i.e., count) and uniqueness of transactions included in their local lists (see Appendix 1 of the <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS post</a> for more details). If transactions are not part of the <span class="math">\text{IL}_\text{agg}</span>, priority fees go to the builder. However, this approach could be problematic during congestion periods with the conditional <span class="math">\text{IL}</span> property, as builders might be incentivized to fill the block with transactions that are not in the <span class="math">\text{IL}_\text{agg}</span>, even if <span class="math">\text{IL}</span> transactions have higher priority fees. To address this, we might need to design a mechanism that redirects priority fees to the builder during congestion. However, the practical implementation and potential secondary effects need further investigation.</li>
<li><strong>Option 3</strong>: A third option is to introduce a new, separate inclusion fee that always go to IL committee members while priority fees always go to the builder. This would likely address the concerns of <strong>Option 2</strong> related to congestion but would introduce a whole other variable that users need to set. A useful distinction between Option 2 and Option 3 is whether the complexity is pushed upon the IL committee members or the end users.</li>
</ul>
<p>Another interesting question to explore is the impact of fee distribution across <span class="math">\text{IL}</span> committee members on mechanisms like <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">MEV-burn</a>. <strong>Options 2</strong> and <strong>3</strong> would effectively “reduce the burn” and produce a similar effect as <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV-smoothing</a>, but on a smaller scale limited to the size of the <span class="math">\text{IL}</span> committee (h/t Anders).</p>
<h3><a class="anchor" href="https://ethresear.ch#textinclusion-rule-10" name="textinclusion-rule-10"></a><span class="math">\text{Inclusion}</span> <strong>Rule</strong></h3>
<p>The <span class="math">\text{Inclusion}</span> rule determines the criteria according to which <span class="math">\text{IL}</span> committee members should build their local <span class="math">\text{ILs}</span>. In FOCIL, we define it with the premise that IL committee members will try to maximize their rewards. Assuming <strong>Option 2</strong> for the <span class="math">\text{Payment}</span> rule, the <span class="math">\text{Inclusion}</span> rule could be to include all transactions seen in the public mempool, ordered by priority fees.</p>
<h3><a class="anchor" href="https://ethresear.ch#textpriority-rule-11" name="textpriority-rule-11"></a><span class="math">\text{Priority}</span> <strong>Rule</strong></h3>
<p>We assume the block will be made of two components: a payload and an  <span class="math">\text{IL}_\text{agg}</span> included by the proposer to impose constraints on transactions that need to be included in the builder’s payload. Imposing constraints to the block payload via the  <span class="math">\text{IL}_\text{agg}</span> thus requires a priority rule to determine what happens during congestion. Generally, the priority rule in FOCIL states that transactions in the  <span class="math">\text{IL}_\text{agg}</span> might be excluded if the block can be filled with the builder’s payload transactions. In other words, the block will still be valid even if some transactions in the <span class="math">\text{IL}_\text{agg}</span> are not included, as long as the block is completely full (i.e., the <code>30 M</code> gas limit is reached).</p>
<p><em>Note: Rules are not set in stone and should be interpreted as candidates for FOCIL. Rules also don’t necessarily have to be made explicit. For instance, we can define the <span class="math">\text{Reward}</span> such that the dominant strategy of the <span class="math">\text{IL}</span> committee is to adhere to the <span class="math">\text{Inclusion}</span> rule without any kind of enforcement by the protocol.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#improvements-and-mitigations-12" name="improvements-and-mitigations-12"></a>Improvements and Mitigations</h2>
<p>In this section, we discuss improvements over previous  <span class="math">\text{IL}</span> proposals, focusing on simplification and addressing specific implementation concerns.</p>
<h3><a class="anchor" href="https://ethresear.ch#commitment-attacks-13" name="commitment-attacks-13"></a><strong>Commitment attacks</strong></h3>
<p>One of the main differences between FOCIL and the forward IL (<span class="math">\text{fIL}</span>) design proposed in <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> is that FOCIL relies on a committee of multiple validators, rather than a single proposer, to construct and broadcast the <span class="math">\text{IL}</span>. This approach imposes stricter constraints on creating a “good” aggregate list and significantly reduces the surface for bribery attacks. Instead of targeting a single party to influence the exclusion of transactions from the <span class="math">\text{IL}</span>, attackers would now need to bribe an entire <span class="math">\text{IL}</span> committee (e.g., <code>256</code> members), substantially increasing the cost of such attacks. Previous designs (e.g., <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a> and <a href="https://ethresear.ch/t/anonymous-inclusion-lists-anon-ils/19627">anon-IL</a>), also involved multiple parties in building inclusion lists but still relied on an aggregator to collect, aggregate, and deduplicate local <span class="math">\text{ILs}</span>. In FOCIL, the entire set of attesters now participates in enforcing and ensuring the quality of the <span class="math">\text{IL}</span> included in the proposer’s block, thus removing single-party dependency other than the proposer. Additionally, it is worth noting that a censoring proposer would have to forego all consensus and execution layer rewards and cause a missed slot to avoid including transactions in the <span class="math">\text{IL}</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#splitting-attacks-and-il-equivocation-14" name="splitting-attacks-and-il-equivocation-14"></a><strong>Splitting attacks and IL equivocation</strong></h3>
<p>Another concern with <span class="math">\text{fILs}</span> focused on possible “splitting” attacks using <span class="math">\text{ILs}</span>. <a href="https://eprint.iacr.org/2021/1413.pdf" rel="noopener nofollow ugc">Splitting attacks</a> like timed release or “equivocation” occur when malicious participants attempt to divide the honest view of the network to stall consensus. On Ethereum, a validator equivocating by contradicting something it previously advertised to the network is a <a href="https://eth2book.info/capella/part2/incentives/slashing/" rel="noopener nofollow ugc">slashable offense</a>. If there is evidence of the offence being included in a beacon chain block, the malicious validator gets ejected from the validator set. Quick reminder that in the <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> design, the proposer for slot <span class="math">n-1</span> is responsible for making the <span class="math">\text{IL}</span> to constrain proposer <span class="math">n</span>, and can broadcast multiple <span class="math">\text{ILs}</span> (check out the <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">No-free lunch</a> post to see why, and how it relates to solving the free data availability problem). This means a malicious proposer could split the honest view of the network through <span class="math">\text{IL}</span> equivocation without being slashed. However, this is not a concern with FOCIL, since <span class="math">\text{IL}_\text{agg}</span> has to be part of proposer $n$’s block. An <span class="math">\text{IL}</span> equivocation would thus be equivalent to a block equivocation, which is a known, slashable offense from the protocol’s perspective.</p>
<h3><a class="anchor" href="https://ethresear.ch#incentives-incompatibilities-15" name="incentives-incompatibilities-15"></a>Incentives incompatibilities</h3>
<p>Previous <span class="math">\text{fILs}</span> proposals did not consider incentivizing the <span class="math">\text{IL}</span> proposer(s) for including “good” transactions. Relying on altruistic behavior might be fine, but there is always the risk that only very few validators will choose to participate in the mechanism if there is no incentive to gain. There is a strong argument to be made that the adoption of any <span class="math">\text{IL}</span> mechanism might be very low if validators risk being flagged as either non-censoring or censoring entities by revealing their preferences (see the <a href="https://ethresear.ch/t/anonymous-inclusion-lists-anon-ils/19627">Anonymous Inclusion Lists post</a>), and if they are not rewarded for contributing to preserving the network’s censorship resistance properties. In FOCIL, we consider mechanisms to distribute rewards across <span class="math">\text{IL}</span> committee members and mention two options (<strong>Option 2</strong> and Option 3 in the <span class="math">\text{Payment}</span> rule section) for sharing transaction fees based on the quantity (i.e., count) and uniqueness of transactions included in their local lists. We hope to continue working in this direction and to find incentive-compatible ways to increase the costs of censorship.</p>
<h3><a class="anchor" href="https://ethresear.ch#same-slot-censorship-resistance-16" name="same-slot-censorship-resistance-16"></a>Same-slot censorship resistance</h3>
<p>By having FOCIL run in parallel with block building during slot  <span class="math">n-1</span>, we can impose constraints on the block by including transactions submitted during the same slot in local <span class="math">\text{ILs}</span>. This is a strict improvement over <span class="math">\text{fILs}</span> designs, where the forward property imposes a 1-slot delay on <span class="math">\text{IL}</span> transactions. This property is particularly useful for time-sensitive transactions that might be censored for MEV reasons (see <a href="https://cdn.prod.website-files.com/642f3d0236c604d1022330f2/6499f35e0bd0f43471a95adc_MEV_Auctions_ArXiV_6.pdf" rel="noopener nofollow ugc">Censorship resistance in onchain auctions</a> paper). Admittedly, the mechanism is not exactly real-time because we still need to impose the “local <span class="math">\text{IL}</span> freeze” deadline <span class="math">d</span> so block producers have time to consider <span class="math">\text{IL}_\text{agg}</span> transactions before proposing their block.</p>
<h3><a class="anchor" href="https://ethresear.ch#textil-conditionality-17" name="textil-conditionality-17"></a><span class="math">\text{IL}</span> conditionality</h3>
<p>A core property of <span class="math">\text{ILs}</span> is their conditionality, which determines whether ILs should have dedicated block space for their transactions (<a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">unconditional</a>) or share block space with the payload and only being included if the block isn’t full (conditional). For FOCIL, we’re leaning towards using conditional <span class="math">\text{ILs}</span> for a couple of reasons. Firstly, it might generally be best to give sophisticated entities like builders the maximum amount of freedom in organizing block space as long as they include <span class="math">\text{IL}</span> transactions. Allowing them to order transactions and fill blocks as they prefer, rather than imposing too many restrictions on their action space, reduces the risk of them using side channels to circumvent overly rigid mechanisms. Specifically, the unconditional property just couldn’t really be enforced effectively with FOCIL, since builders wanting to use <span class="math">\text{IL}</span> dedicated block space could simply “buy up <span class="math">\text{IL}</span> committee seats” from the elected validators to include their transactions via local <span class="math">\text{ILs}</span>. Another reason to opt for conditional <span class="math">\text{ILs}</span> is the flexibility in the size of the list. With unconditional ILs, an added block space must strictly set an arbitrary maximum <span class="math">\text{IL}</span> gas limit (e.g., <code>3M</code> gas). In contrast, conditional <span class="math">\text{ILs}</span> allow for a much more flexible <span class="math">\text{IL}</span> size, depending on the remaining space in the block. The known tradeoff with conditional <span class="math">\text{ILs}</span> is block stuffing: censoring builders might fill their blocks up to the gas limit to keep <span class="math">\text{IL}</span> transactions out. More research is needed to determine the sustainability of block stuffing, as <a href="https://timroughgarden.org/papers/eip1559.pdf" rel="noopener nofollow ugc">consecutive full blocks exponentially increase base fees</a> and the overall cost of this strategy.</p>
<h3><a class="anchor" href="https://ethresear.ch#account-abstraction-accounting-18" name="account-abstraction-accounting-18"></a><strong>Account Abstraction accounting</strong></h3>
<p>In previous proposals, <span class="math">\text{IL}</span> summaries were constructed as structures to constrain blocks without committing to specific raw transactions. Each <span class="math">\text{IL}</span> summary —or <span class="math">\text{IL}_\text{agg}</span> for FOCIL— entry represents a transaction by including the following fields: <code>From</code> and <code>Gas Limit</code>. Satisfying an entry in the <span class="math">IL</span> summary requires that at least <em>some</em> transaction from the <code>From</code> address has been executed, <em>unless</em> the remaining gas in the block is less than <code>Gas Limit</code> . The idea is simple: if a transaction was previously valid and had a sufficiently high basefee, the only two things preventing its inclusion are the lack of sufficient gas in the block or its invalidation, which would require a transaction from the same sender to have been previously executed. Here we rely on a property of Ethereum EOAs: the <code>nonce</code> and <code>balance</code> of an EOA determine the validity of any transaction originating from that EOA, and can only be modified by such a transaction.</p>
<p>However, even limited forms of Account Abstraction that have been considered for inclusion in Electra (e.g., <a href="https://github.com/ethereum/EIPs/blob/43fb1e0ca950c42a09efdf9a85d8acfe260efac1/EIPS/eip-3074.md" rel="noopener nofollow ugc">EIP-3074</a> or <a href="https://github.com/ethereum/EIPs/blob/43fb1e0ca950c42a09efdf9a85d8acfe260efac1/EIPS/eip-7702.md" rel="noopener nofollow ugc">EIP-7702</a>) allow a transaction to trigger a change in an EOA’s balance, <em>without originating from that EOA</em>. This <a href="https://hackmd.io/@potuz/BkWngLly0#Transactions-that-become-invalid" rel="noopener nofollow ugc">raised concerns</a> regarding previous <span class="math">\text{fIL}</span> proposals, as proposer <span class="math">n</span> is not aware of what is included in builder $n$’s payload when proposing its <span class="math">\text{IL}</span>. This could lead to a scenario where proposer <span class="math">n</span> includes a transaction <span class="math">txn_A</span> from address <span class="math">A</span> in the <span class="math">\text{IL}</span>, while builder <span class="math">n</span> includes an EIP-7702 transaction <span class="math">txn_B</span>, originating from address <span class="math">B</span> but sweeping out all the <code>ETH</code> from address <span class="math">A</span>, and thus invalidating  <span class="math">txn_A</span>. Consequently, builder <span class="math">n+1</span> would no longer be able to include <span class="math">txn_A</span>, though no other transaction from address <span class="math">A</span> has been previously executed. In other words, the <span class="math">IL</span> summary would be unsatisfiable.</p>
<p>In FOCIL, one simplification is that the constraints from the <span class="math">\text{IL}_\text{agg}</span> apply to the block that is being built concurrently. This means a transaction in the <span class="math">\text{IL}_\text{agg}</span> can’t be invalidated because of a transaction in the previous block, as it can in <span class="math">\text{fIL}</span> designs. In other words, we do not need to worry about what happened in the previous block in order to check for satisfaction of the <span class="math">\text{IL}_\text{agg}</span>. However, a builder could still insert EIP-7702 transactions in its payload that invalidate <span class="math">\text{IL}_\text{agg}</span> transactions. To handle this case, we can do the following when validating a block:</p>
<ul>
<li>Before executing the block’s transactions, we store <code>nonce</code> and <code>balance</code> of all <code>From</code> addresses that appear in the <span class="math">\text{IL}_\text{agg}</span>.</li>
<li>After execution, we check the <code>nonce</code> and <code>balance</code> of all <code>From</code> addresses from the <span class="math">\text{IL}_\text{agg}</span> again, and for each (<code>From</code>, <code>Gas Limit</code>) pair in the <span class="math">\text{IL}_\text{agg}</span> we require that either the <code>nonce</code> or the <code>balance</code> has changed, or the <code>Gas Limit</code> is more than the remaining gas.</li>
</ul>
<p>If the <code>nonce</code> has changed, some transaction from that address has been executed. If the <code>balance</code> has changed but the <code>nonce</code> has not, some AA transaction has touched that address. In either case, that address has transacted in the block, and the entry is satisfied.</p>
<p><em>Note: With "full” AA, transactions could have validity that depends on arbitrary state (e.g., the price changing in a Uniswap pool). In such cases, relying on a reduced form of transactions (i.e., entries with <code>From</code> and <code>Gas limit</code> fields) is insufficient, as the full validation logic of the transaction is needed. Due to the <a href="https://notes.ethereum.org/@vbuterin/pbs_censorship_resistance#What-are-the-design-goals-of-any-anti-censorship-scheme" rel="noopener nofollow ugc">free data-availability</a> problem, putting raw transactions on-chain is not an option. Instead, attesters could check this locally since they need to construct their own <span class="math">\text{IL}_\text{agg}^\text{attester}</span> and could, therefore, evaluate the full validation logic. This allows them to verify if the transaction has been invalidated and if its inclusion should be enforced. However, attesters might have <span class="math">\text{IL}_\text{agg}^\text{attester}\text{s}</span> that contain different transactions from the same <code>From</code> address, leading to a situation where one transaction might be invalidated while another is not. This would result in split views and potential attacks</em></p>
            <p><small>10 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 15:42:04 +0000</pubDate>
</item>
<item>
<title>Burn incentives in MEV pricing auctions</title>
<link>https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856</link>
<guid>https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV定价拍卖、公共利益、竞争、贿赂、共识机制

总结:
本文分析了MEV定价拍卖中的五种潜在激励，包括公有利益建设者、营利性公有利益建设者、敲诈勒索、攻击性竞争（包括单个和联合攻击）以及与共识机制的风险。这些因素促使参与者竞相烧掉MEV，以确保自身或竞争对手的收益。文章指出，尽管存在对晚投标和缺乏公平性的担忧，但实际博弈中，特别是通过与验证者服务提供商（SSP）的紧密合作，MEV燃烧的动机变得更加强烈。此外，作者提醒要警惕MEV定价拍卖可能对共识机制产生的负面影响，比如attester-builder的整合可能导致共识形成过程中的竞争失衡。因此，设计MEV机制时需平衡各方利益，防止意外破坏网络稳定。 <div>
<h1><a class="anchor" href="https://ethresear.ch#burn-incentives-in-mev-pricing-auctions-1" name="burn-incentives-in-mev-pricing-auctions-1"></a>Burn incentives in MEV pricing auctions</h1>
<p><em>Thanks to Barnabé Monnot, Thomas Thiery and Caspar Schwarz-Schilling for feedback and comments.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/7/1703882e171fbc76c500a2799ebea0ad8dfe61d7.jpeg" title="The process of burning MEV"><img alt="The process of burning MEV" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/1/7/1703882e171fbc76c500a2799ebea0ad8dfe61d7_2_375x375.jpeg" width="375" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<h3><a class="anchor" href="https://ethresear.ch#overview-3" name="overview-3"></a>Overview</h3>
<p>This post presents a rudimentary review of incentives for burning MEV under the <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">“simple” MEV burn mechanism</a> presented by Justin, as well as its slot auction counterpart, <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">“execution auctions”</a> presented by Barnabé. The analysis is also applicable to Francesco’s original <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a> design. These auctions—involving builders bidding, attesters enforcing a base fee floor, and proposers selecting a winning bid—will be defined as MEV pricing auctions (in the author’s view, the “execution auction” moniker could also be extended to cover all MEV pricing auctions).</p>
<p>The post highlights how incentives to drive up the price floor (and thus burn more MEV) can emerge in these designs regardless of any direct profit motive among builders for doing so. Importantly, stakers and staking service providers wish to ensure that competitors do not attain more rewards for selling MEV capture rights than them. They may therefore integrate with builders to bid away competing stakers’ profits. Auctions that set a price floor on proposers’ MEV capture rights will thus be influenced by the overarching staking <a href="https://en.wikipedia.org/wiki/Metagame">metagame</a>. It is only at this layer that griefing attacks against proposers to burn their MEV capture rights can be understood. Adverse competition during the consensus formation process might hypothetically lead attesters to bias their MEV base fee floor during split views, rejecting or admitting blocks depending on how it impacts their bottom line (in their roles as both builders and stakers). This is something to be attentive to. Naturally, burning MEV might also be considered a public good, and such incentives are reviewed in the text as well.</p>
<h3><a class="anchor" href="https://ethresear.ch#mev-pricing-auctions-4" name="mev-pricing-auctions-4"></a>MEV pricing auctions</h3>
<p>In <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn–a simple design</em></a>, Justin formulated an add-on to <a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710">enshrined proposer–builder separation</a> (ePBS), modifying the <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a> design.  Builders can specify a base fee and a tip in their block bids. At some specific time before the slot begins (e.g., 2 seconds), attesters observe the highest base fee among the bids (“observation deadline”) and impose it as a subjective base fee floor when attesting to the proposer’s block. Only bids with a base fee above the floor are accepted, and the base fee is burned.</p>
<p>If builders bid before the observation deadline with the same timing as today, then the mechanism will <a href="https://ethresear.ch/t/in-a-post-mev-burn-world-some-simulations-and-stats/17092">burn substantial MEV</a>. Concerns have however been raised over the risk of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">collusion between proposers and builders</a> and lack of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">proper incentivization</a>. A <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">recent write-up</a> on the benefits of the design and MEV burn in general generated similar worries of a <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">stable equilibrium of late bidding</a>.</p>
<p>The design can be further modified to involve auctioning off the rights to the entire slot, 32 slots in advance (“<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">execution auction</a>”). A benefit of this design is the ability to offer long-lived preconfirmations and—hypothetically—the reduced value-in-flight during the auction. The same concerns raised for the block auction design can be applied to the slot auction design, because the beacon proposer might still benefit from colluding with builders to form late-bidding cartels when selecting the execution proposer.</p>
<p>A modified MEV pricing auction, <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">MEV burn with builder kickbacks</a>, attempts to compensate builders for bidding early. That design is not the focus of this post, but incentives and side effects in uncompensated MEV pricing auctions will affect its relevance.</p>
<h2><a class="anchor" href="https://ethresear.ch#five-burn-incentives-in-mev-pricing-auctions-5" name="five-burn-incentives-in-mev-pricing-auctions-5"></a>Five burn incentives in MEV pricing auctions</h2>
<p>The outlined concerns of late bidding are valid, but it turns out that it is not possible to analyze MEV burn without incorporating stakers as participating agents. In such an analysis, competition for attaining the most yield will—under equilibrium—drive participants to burn each other’s MEV. Other incentives for burning MEV also exist. The analysis starts from the most idealistic public good example in (A) and gradually builds toward a metagame of active collusion to discourage other stakers in (E) (see Figure 1).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/a/7a0cc1b660d8b22ac81aff0bbc070505e6f30e7e.jpeg" title="Figure 1"><img alt="Figure 1" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/a/7a0cc1b660d8b22ac81aff0bbc070505e6f30e7e_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><strong>Figure 1.</strong> Five types of builders potentially burning MEV in MEV pricing auctions: (A) Public good builder, (B) For-profit public good builder, (C) Extortion racket, (D) Staker-initiated griefing, (E) Staker-initiated griefing cartel. The incentives behind (D) are important to understand (indicated by an arrow).</p>
<h3><a class="anchor" href="https://ethresear.ch#a-public-good-builder-6" name="a-public-good-builder-6"></a>(A) Public good builder</h3>
<p>The first example is a builder that dedicates resources to burning MEV without a direct profit motive. If Ethereum’s users believe that burning MEV is a public good, and in particular if no other incentive is sufficient, they may come together to fund the development and operation of a public good builder. Initiatives to fund public goods are fairly <a href="https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c">prevalent</a> within the Ethereum ecosystem. The public good builder can for example consistently bid according to guaranteed MEV at the observation deadline in the block auction design. This ensures that the MEV is burned while the builder will not suffer any direct losses from the bid. In the slot auction design, the builder would instead need to bid according to its expected MEV for the entire slot and might bid slightly below to stay safe.</p>
<p>The public good builder will likely not be the best and will often be outbid in terms of tips from other builders in the proposer auction (taking place after the observation deadline), in which the proposer selects a winning bid. But the operation can still be very impactful. After all, priority fees are a significant portion of all value (in this post these fees are also treated as MEV), and some further “low-hanging MEV fruits” are potentially available without dedicating too large resources for extraction. While the builder may use any public goods funding received diligently and not strive for any profit, pursuing an idealistic path can still raise the originators’ public profile and provide significant economic benefits in the future (perhaps not even directly related to building blocks).</p>
<h3><a class="anchor" href="https://ethresear.ch#b-for-profit-public-good-builder-7" name="b-for-profit-public-good-builder-7"></a>(B) For-profit public good builder</h3>
<p>A builder that positions itself as providing a public good may also enjoy direct economic benefits from its operation if some validators sympathize with the mission. There may for example be a market fit for builders that do not censor, nor extract various types of toxic MEV. In the block auction design, the builder could keep the MEV base fee in line with the available (non-censorship/non-toxic) MEV during the attester auction, and then pivot to tipping afterward, retaining some small profit margin. The MEV in some blocks is not particularly geared towards specialized searchers, and stakers may not lose that much in tips for some blocks by selecting the public good builder. Therefore, the public good builder could have higher profit margins in the blocks it does eventually get to build than builders that have not positioned themselves as providing a public good. A builder bidding before the observation deadline might of course also hope that its bids are the only ones to reach the proposer in times of degraded network conditions.</p>
<h3><a class="anchor" href="https://ethresear.ch#c-extortion-racket-8" name="c-extortion-racket-8"></a>(C) Extortion racket</h3>
<p>Given the lower effort required for extracting some of the MEV, it seems like (A) and (B) could have a natural position and high impact within the Ethereum ecosystem. But it may very well be that no successful public good builder can be sustained over the long run. After all, many stakers will not be particularly enthusiastic over a builder that burns their MEV opportunities.</p>
<p>Still, consider the importance of a dedicated MEV-burning builder within the staking ecosystem. If the builder is operational, proposers will lose out on a lot of value relative to if it does not operate. Is there a business opportunity here? Perhaps a builder could commit to burning the maximum possible MEV but abstain from doing so if it receives a bribe from the proposer? It seems natural that proposers would be willing to pay for this, since the proposer stands to capture most value from the available MEV if none is burned. But the prospect of competition makes the business model perilous. If a sole extortive builder is profitable, then a few more may try to enter the market as well. There is not much use in paying off two builders if it turns out that a third burned the MEV anyway through a bid. A mechanism for reconciling this ex-post would become rather complex. The validator may then be better off by simply not negotiating with any extortion racket.</p>
<p>While the extortion racket seems unsustainable, it helps to underscore the power that builders have over proposers. The ultimate incentive for burning MEV then emerges when changing the responsible actor from one unaffected by the staking equilibrium (extorting builder) to one that is not (other stakers). The auction will eventually become part of the <a href="https://en.wikipedia.org/wiki/Metagame">metagame</a> of the overarching staking equilibrium.</p>
<h3><a class="anchor" href="https://ethresear.ch#d-metagame-staker-initiated-griefing-9" name="d-metagame-staker-initiated-griefing-9"></a>(D) Metagame—staker-initiated griefing</h3>
<p>Staking service providers (SSPs) compete for delegated stake and derive income by taking a cut of the staking yield when they pass it back to the delegators. An SSP must ensure that the yield it offers delegating stakers is competitive relative to offers from other SSPs. The MEV pricing auction may therefore lead SSPs to burn competing proposers’ MEV by tightly integrating with builders or running them in-house. If a competitor burns an SSP’s MEV, then the SSP must respond in kind or will lose out on delegators and thus income. When considering the metalevel of SSPs, this equilibrium seems more stable than an equilibrium of late bidding leading to little or no MEV burn. All it takes to break the late-bidding cartel is one defecting SSP builder, forcing others to respond.</p>
<p>An SSP that through a builder griefs other stakers without taking any loss executes something comparable to a <a href="https://github.com/ethereum/research/blob/d1d465f658e0024a2010b0a6ad960a76d9c40cac/papers/discouragement/discouragement.pdf">discouragement attack</a> with an infinite griefing factor. This is a very advantageous attack, primarily because delegators will flow to the best performing SSP. In addition, a reduction in overall yield for other stakers pushes down the quantity of supplied stake, bringing up the equilibrium yield. Thus, even if some delegators do not flow to the SSP that burns its competitor’s MEV, the expected staking yield (that the SSP will share in the profit from) will still go up, if the competitor’s customers simply stop delegating. Of course, the cost of running the builder must be accounted for. But large SSPs can amortize that cost across a vast amount of yield-bearing validators.</p>
<p>Yet, directly profiting from the MEV is almost always better than burning it. When an SSP’s builder is able to extract more MEV in a competitor’s slot than any other builder, it will still be better off only bidding to a level that ensures it wins the auction. The SSP must thus make a probabilistic judgment as to the uniqueness of its MEV opportunity in the particular slot before deciding how to proceed (or more precisely, any edge in MEV value <span class="math">V_e</span> relative to the second best builder). An SSP builder must in essence bid before the observation deadline up to the point where the expected payoff from burning the marginal MEV is equal to the expected payoff from waiting and hoping to extract it. There are some game-theoretic nuances to this that here will be set aside, with some aspects discussed in the next section. The point is to assert that there are stronger incentives for builders to bid before the observation deadline than what has been previously understood, because a builder might be run by an SSP that indirectly profits from burning other stakers’ potential MEV revenue.</p>
<p>What happens in the metagame to smaller SSPs and solo stakers? They may not afford to run a builder of their own to ensure that their competitors’ MEV is burned. It is of course possible for solo stakers to try to come together to form a union around a builder, where each contributor is guaranteed to see their validators excluded from MEV base fee bids by the specific builder (and receive full tips during the proposer auction). There is then a question of if they will be able to organize such a union, but also if it really would be necessary. On the one hand, if there are several “griefing builders” running concurrently among the largest SSPs, parties holding less stake may not need to run their own griefing builder. Everyone will see their MEV burned anyway, since the big SSPs burn each other’s and everyone else’s MEV. On the other hand, a party not having a griefing builder readily available may be suboptimally positioned when considering the prospect of cartelization.</p>
<h3><a class="anchor" href="https://ethresear.ch#e-metagame-staker-initiated-griefing-cartel-10" name="e-metagame-staker-initiated-griefing-cartel-10"></a>(E) Metagame—staker-initiated griefing cartel</h3>
<p>Can builders operating at the metalevel collude to selectively burn or selectively <em>not</em> burn MEV, depending on the identity of the slot’s validator? The cartel would strive to ensure that all participating SSPs (or any union of solo stakers) receive the MEV in their validators’ proposed blocks, while minimizing MEV in all other validators’ blocks.</p>
<p>However, if attesters are honest, builders can only cartelize to selectively burn or not burn MEV that they uniquely are able to extract. As long as competing builders are operational, this substantially limits the power of any cartel. Therefore, the advantage of (E) over (D) is not substantial.</p>
<h4><a class="anchor" href="https://ethresear.ch#proposer-is-part-of-the-cartel-11" name="proposer-is-part-of-the-cartel-11"></a>Proposer is part of the cartel</h4>
<p>When the beacon proposer is part of the cartel, members will abstain from bidding before the observation deadline to ensure that as much value as possible flows to the proposer. This type of cartelization has been highlighted as a concern (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">2</a>) in the debate around MEV pricing auctions. The idea is that participants come to an explicit or implicit agreement to not bid before the observation deadline. Yet the incentive to burn MEV is stronger than previously understood, since stakers outside the cartel will wish to grief cartel members by bidding early (D), and so from this perspective, the risk of late-bidding-cartelization is lower than feared.</p>
<p>It might also be difficult to efficiently uphold cartelization, because it is not possible for members to know which, if any, defected in pursuit of (D). One avenue would be to try to share the profits from every slot to give all participants incentives to hold back bids before the observation deadline. Yet overall, the existence of (A), (B), and (D) means that some value will still reasonably be burned by public good builders or any competitors not part of the cartel.</p>
<h4><a class="anchor" href="https://ethresear.ch#proposer-is-not-part-of-the-cartel-12" name="proposer-is-not-part-of-the-cartel-12"></a>Proposer is not part of the cartel</h4>
<p>When the beacon proposer is outside the cartel, the goal is to deprive it of revenue while still capturing as much of the MEV as possible. It will still be more profitable for the cartel to extract any unique MEV opportunity rather than burn it. Define <span class="math">V_s</span> as the value a builder can attain in the slot auction and <span class="math">V_b</span> as its value for the block auction (from a block built at the observation deadline). When a builder can extract the most MEV, it has an edge <span class="math">V_e</span> over the second-best builder (kept constant for simplicity). Just as in (D), the cartel can bid up to <span class="math">V_b-V_e</span> or <span class="math">V_s-V_e</span>, with the difference that <span class="math">V_e</span> expands if the cartel collectively gains a larger edge against the best builder outside of the cartel. This expansion is what the cartel tries to capitalize on, both when the proposer is part of the cartel (expanding <span class="math">V_e</span> to lower the burn) and when not (expanding <span class="math">V_e</span> to increase builder profits). A challenge—just as in (D)—is that the cartel might not be able to properly estimate <span class="math">V_e</span>. After the observation deadline, the cartel attempts to extract as much value as possible, leaving the MEV either burned or in their hands.</p>
<h4><a class="anchor" href="https://ethresear.ch#collusion-at-other-levels-13" name="collusion-at-other-levels-13"></a>Collusion at other levels</h4>
<p>The presentation so far has been somewhat simplistic. It bears mentioning that collusion need not happen at the level of the builders, but can for example happen at the level of searchers or any out-of-protocol relay that the cartel still finds beneficial to maintain before posting to the P2P layer. In all scenarios of successful cartelization, if some stakers (for example solo stakers) are unable to act collectively, they may end up at the short end of the discouragement dynamic.</p>
<h2><a class="anchor" href="https://ethresear.ch#risks-associated-with-attester-builder-integration-14" name="risks-associated-with-attester-builder-integration-14"></a>Risks associated with attester–builder integration</h2>
<p>The analysis so far indicates that (D) may have a significant effect on its own but that it does not necessarily lead to the riskier cartelization in (E). But what might happen when we give SSPs tools for depriving each other of revenue? While SSPs will always compete, competition in MEV pricing auctions is on the verge of seeping into the consensus formation process. At the consensus level, all participants are expected to behave honestly and are rewarded for good behaviour. Through staker–builder integration in (D)-(E), SSPs will come to actively influence each other’s rewards, cooperating or griefing each other. A risk is that SSPs might navigate down perilous paths in this landscape.</p>
<p>It has been noted that MEV pricing auctions suffer from attesters potentially having <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">split views</a> of the MEV base fee floor. Biasing the outcome in a split view one way or the other might benefit one builder over another, result in a block being forked out to deprive the beacon proposer of all rewards, or allow the proposer to reap higher rewards when selling MEV capture rights. One concern is that SSPs might eventually try to profit by tuning their attestations of the MEV base fee floor to produce favorable outcomes. This can also be done as part of a cartel. The honest majority assumption need not be broken to derive profits, due to split views. It is only necessary to put a thumb on the scale, and a competitive consensus formation might make such behavior more likely.</p>
<p>Of course, stakers who do not honestly attest to which bids they have observed at which specific time point subject themselves to risks of social slashing if malicious behavior can be uncovered. This is always a potential final resort under proof of stake. In essence, just as it is prudent to be cautious of MEV or excessive issuance as strata for cartelization, it also seems prudent to be cautious of MEV pricing auctions as a stratum for consensus adversity.</p>
<h2><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-in-terms-of-mev-pricing-15" name="block-vs-slot-auctions-in-terms-of-mev-pricing-15"></a>Block vs. slot auctions in terms of MEV pricing</h2>
<p>Will block auctions or slot auctions burn more MEV? Is one more centralizing than the other? These questions are not easy to answer, because it depends on which burn incentive that comes to dominate, the likelihood of cartelization under different designs, etc. This section will discuss some differences (previous writings on <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ">block vs. slot auctions</a> provide a broader perspective).</p>
<h3><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-concerning-d-16" name="block-vs-slot-auctions-concerning-d-16"></a>Block vs. slot auctions concerning (D)</h3>
<p>Assume that (D) becomes an important incentive for burning MEV. Further, assume a competitive market without cartelization and perfect information about how much MEV each participant can extract. In the block auction design, the builder can bid <span class="math">V_b-V_e</span> for the block at the observation deadline to maximize burn while retaining opportunities to extract value. It then updates its block and bid through tips in the proposer auction up until the slot boundary. There is <span class="math">V_s-V_b</span> worth of value that the proposer hopes to attain through tips, and <span class="math">V_e</span> worth of value left for the builder (under these simplified conditions).</p>
<p>In the slot auction design, the builder can instead bid <span class="math">V_s-V_e</span> already at the observation deadline. It is just buying the rights to build the block, not committing to its content, and that value is an entire slot’s worth of MEV. Naturally, <span class="math">V_s</span> will here just be an estimate, and the risk that builders take on by bidding on an expected value instead of a tangible value might be worth some fraction of the total bid value. But incomplete information around competitors’ eventual final bids will likely serve to pull down the bid value at the observation deadline more. The staker–builder can ideally burn <span class="math">V_s-V_e</span> of a competing beacon proposer’s auctionable MEV, and again retain <span class="math">V_e</span> for itself. The difference in MEV burn between the two designs is then <span class="math">V_s-V_b</span>.</p>
<p>If the staker–builder could estimate <span class="math">V_s</span> also in the block auction design (which nominally is easier since it bids much closer to the deadline), it could bid <span class="math">V_s-V_e-V_g</span> already at the observation deadline. Since the bid is attached to a block containing only <span class="math">V_b</span> of MEV, <span class="math">V_g</span> is reserved as a tip for the proposer auction. If there is no tip, the proposer might elect to pick the block from the observation deadline, depriving the builder of <span class="math">V_s-V_b</span>. However, while the proposer might specifically wish to do so if the same builder bids with low tips also in the proposer auction, a staker can obfuscate its identity by running several builders (the kickback design disincentivizes obfuscation).</p>
<p>In either design, it seems most likely that the burn ends up being lower than these theoretical maxima due to incomplete information in combination with the fact that capturing the MEV is more valuable than burning it. The staker–builder will therefore operate with quite some margin to maximize expected profits.</p>
<h3><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-concerning-a-b-17" name="block-vs-slot-auctions-concerning-a-b-17"></a>Block vs. slot auctions concerning (A)-(B)</h3>
<p>The analysis for (D) is to some extent also applicable for (A) and (B). The public good builder could theoretically bid higher in the slot auction than in the block auction. However, the risk associated with overbidding in the slot auction design might be more serious for these builders. In the block auction design, the available value will be much clearer, making it easier for an unsophisticated builder to make low-risk bids.</p>
<h3><a class="anchor" href="https://ethresear.ch#value-of-preconfirmations-18" name="value-of-preconfirmations-18"></a>Value of preconfirmations</h3>
<p>As previously mentioned, the slot auction design facilitates execution layer preconfirmations, which can provide a welfare gain to Ethereum. In addition, their value can be burnt (just as in <a href="https://ethresear.ch/t/execution-tickets/17944#roadmap-compatibility-6">execution tickets</a>), since builders are bidding to attain that value. This increases the burn of the slot auction design.</p>
<h3><a class="anchor" href="https://ethresear.ch#builder-centralization-under-competition-over-expected-mev-19" name="builder-centralization-under-competition-over-expected-mev-19"></a>Builder centralization under competition over expected MEV</h3>
<p>If builders have different strengths and weaknesses, they will intermittently attain the highest <span class="math">V_b</span> in the block auction design. While one builder might be able to extract the highest MEV in expectation, not all blocks will play to its strengths. However, in the slot auction, builders bid on expected MEV, and one specific builder might then always have the highest expected <span class="math">V_s</span>. <a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814">This could potentially be a centralizing force</a>, depending on how secondary markets evolve.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-20" name="conclusion-20"></a>Conclusion</h2>
<p>There are strong incentives for burning MEV even in designs that do not directly compensate for it, for example to provide a public good service or to ensure that other participants in the staking metagame do not attain a higher yield. Uncompensated MEV pricing auctions accommodates these incentives. Of particular relevance is staker-initiated griefing (D). It seems clear that SSPs will seek to influence builders’ bidding strategies, and this can lead to staker–builder integration. Still, this form of integration does not necessarily lead to censorship or higher MEV profits; thus not negating sought benefits of proposer–builder separation. If it is desirable to give an outside party an independent incentive to burn MEV, then <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">builder kickbacks</a> are an option. They can also be applied to the slot auction design.</p>
<p>When implementing a MEV burn mechanism, it is important to ensure that the burn mechanism does not accidentally set fire to Ethereum’s consensus mechanism. Giving SSPs tools for griefing each other could lead to adverse competition during the consensus formation process. A particular concern is then if emerging attester–builder integration leads attesters to bias their MEV base fee floor, rejecting or admitting blocks depending on how it impacts their bottom line (in their roles as both builders and stakers). Which of the different scenarios (A-E) that would predominate is seemingly a more important parameter when evaluating the merits of MEV pricing auctions than the mechanism’s ability to burn substantial MEV (which this post suggests it can).</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 20:58:14 +0000</pubDate>
</item>
<item>
<title>Preconfirmations: On splitting the block, mev-boost compatibility and relays</title>
<link>https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837</link>
<guid>https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837</guid>
<content:encoded><![CDATA[
<div> 关键词：Preconfirmation, XGA-style, Ethereum, Block Splitting, Relay

总结:
本文讨论了一种名为XGA-style的预确认机制，它为非优先级交易提供有限时间内（2个epoch后）的区块底部预留空间。这种机制将区块分为顶部和底部两部分，顶部用于传统MEV竞拍，底部通过预确认拍卖分配。预确认通过多单位拍卖进行，买家可以锁定区块容量确保交易成功纳入。文章还提到，这有助于缓解竞争性建块者压力，简化预确认定价，以及对Relay角色的重新思考，提出通过保险和奖励机制来保障预确认平台的稳定运行。XGA是首个实现这一设计的L2平台，目前已有主网版本，但正在进行进一步开发以支持更多功能。 <div>
<p>Thanks to <a class="mention" href="https://ethresear.ch/u/fabrizioromanogenove">@FabrizioRomanoGenove</a>, <a class="mention" href="https://ethresear.ch/u/meridian">@meridian</a> and Philipp Zahn for helpful comments and feedback on this post.</p>
<h2><a class="anchor" href="https://ethresear.ch#what-is-a-preconfirmation-1" name="what-is-a-preconfirmation-1"></a><img alt=":question:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/question.png?v=12" title=":question:" width="20" /> What is a Preconfirmation?</h2>
<p>There have been a lot of variations on the definition of preconfirmation going around recently in the Ethereum community. In this post we will keep the definition as simple and broad as possible in order to generate the least amount of confusion and avoid arguing on semantics as much as possible:</p>
<blockquote>
<p>We call a <strong><em>preconfirmation mechanism</em></strong> any mechanism that ensures (non-positional) inclusion of a (bundle of) transaction(s), if execution is successful, in a finite and bounded amount of time from the emission of the preconfirmation.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#xga-style-preconfirmations-2" name="xga-style-preconfirmations-2"></a><img alt=":mag:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/mag.png?v=12" title=":mag:" width="20" /> XGA-Style Preconfirmations</h3>
<p>We will analyze a specific kind of preconfirmation mechanism – as hinted to in <a href="https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800/3">this post on ethresearch</a> – that we came up with some time ago and have been building since then:</p>
<blockquote>
<p>An <strong><em>XGA-style preconfirmation mechanism</em></strong> is a preconfirmation mechanism that guarantees (non-positional) inclusion of a sized bundle of transactions <strong>in the bottom portion of a predetermined block to be minted 2 epochs after the preconfirmation was emitted</strong>. Maximum bundle size is determined at the time of emission of the preconfirmation.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#splitting-the-block-3" name="splitting-the-block-3"></a><img alt=":scissors:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/scissors.png?v=12" title=":scissors:" width="20" /> Splitting the Block</h2>
<p>Looking at the previous definition, I assume the first couple of questions that would come to mind is “what do you mean exactly by the bottom portion of a block?” and “how is the block to include the bundle predetermined?”. Our idea is pretty simple: Partition the block in such a way to keep a top-of-the-block (ToB)<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-1" id="footnote-ref-48655-1">[1]</a></sup>, high-priority section, in which traditional builders do their usual thing and is allocated through a traditional mev-boost auction or whatever the relay running it prefers; and a reserved bottom-of-the-block (BoB) section, which will serve as allocation space for preconfirmations. In this design, preconfirmation bundles will be allocated via a separate auction in the form of <strong><em>forward contracts</em></strong>.</p>
<h3><a class="anchor" href="https://ethresear.ch#a-two-auction-format-4" name="a-two-auction-format-4"></a><img alt=":busts_in_silhouette:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/busts_in_silhouette.png?v=12" title=":busts_in_silhouette:" width="20" /> A Two-Auction Format</h3>
<p>As briefly mentioned above, in the XGA-style split-block design, preconfirmations are allocated in a completely separate way from the traditional mev-boost auction, allowing them to coexist without excessively disrupting the ecosystem. Traditional builders will be able to do their own thing with minimal adjustments, while everyone else can still enjoy the benefits of preconfirmations.</p>
<p>In simple terms: An XGA-style BoB auction is a multi-unit auction selling gas tokens for a specific block <span class="math">B</span> in fixed-size units (e.g. <span class="math">100</span> K gas). These tokens can then be used to submit a bundle<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-2" id="footnote-ref-48655-2">[2]</a></sup> that is guaranteed inclusion in <span class="math">B</span> if execution is successful.</p>
<p>As an example, picture this scenario:</p>
<ul>
<li><img alt=":clock2:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/clock2.png?v=12" title=":clock2:" width="20" /> At the start of epoch <span class="math">N-2</span> we know that the validator <span class="math">V</span>, serving XGA-style preconfirmations, will be the proposer for the <span class="math">K</span>-th slot of epoch <span class="math">N</span>.</li>
<li><img alt=":oil_drum:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/oil_drum.png?v=12" title=":oil_drum:" width="20" /> $5$M gas out of the standard <span class="math">30</span> M will be auctioned off into <span class="math">50</span> gas tokens, each representing a capacity of <span class="math">100</span> K gas.</li>
<li><img alt=":shopping_cart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/shopping_cart.png?v=12" title=":shopping_cart:" width="20" /> At some fixed time <span class="math">t</span> before the start of slot <span class="math">K</span>, a multi-unit auction allocating the tokens is run. Aki manages to win 5 tokens for <span class="math">K</span>, for a combined capacity of <span class="math">500</span> K.</li>
<li><img alt=":alarm_clock:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/alarm_clock.png?v=12" title=":alarm_clock:" width="20" /> Within the deadline fixed at some time <span class="math">d</span> before the end of <span class="math">K</span>, Aki uses the <span class="math">5</span> tokens to submit a bundle of size just over <span class="math">400</span> K gas.</li>
<li><img alt=":outbox_tray:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/outbox_tray.png?v=12" title=":outbox_tray:" width="20" /> In the meantime, other BoB auction winners submit their own bundles.</li>
<li><img alt=":dollar:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/dollar.png?v=12" title=":dollar:" width="20" /> At the start of <span class="math">K</span>, a traditional mev-boost auction for <span class="math">25</span> M gas is run as usual by all relays, and is won by Bogdan via relay <span class="math">R</span>.</li>
<li><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> After deadline <span class="math">d</span> is reached and the mev-boost auction is over, the BoB part is assembled and attached at the bottom of the max-<span class="math">25</span> M block submitted by Bogdan via relay <span class="math">R</span>.</li>
<li><img alt=":tada:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/tada.png?v=12" title=":tada:" width="20" /> Since Aki’s bundle contained no reverting transactions, it is included without any problem – together with the non-reverting bundles submitted by the other BoB winners – somewhere after the portion built by Bogdan.</li>
<li><img alt=":satellite:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/satellite.png?v=12" title=":satellite:" width="20" /> The block for <span class="math">K</span> gets broadcasted as usual.</li>
<li><img alt=":x:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/x.png?v=12" title=":x:" width="20" /> Excess tokens for <span class="math">K</span> that didn’t get spent can no longer be used.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#who-builds-the-blocks-then-5" name="who-builds-the-blocks-then-5"></a><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> Who Builds the Blocks, then?</h3>
<p>Block building, in the case of XGA-style preconfirmations, is handled by multiple parties:</p>
<ul>
<li><img alt=":package:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/package.png?v=12" title=":package:" width="20" /> The ToB part is built by traditional mev-boost builders as usual.</li>
<li><img alt=":gift:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/gift.png?v=12" title=":gift:" width="20" /> The BoB part is assembled by the party running the BoB auction.</li>
<li><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> Merging the two parts and sending the block over is handled by the relay.</li>
</ul>
<p>In this setup, the relay takes on more work and responsibilities than it currently does. We will explore a potentially beneficial approach to this change later.</p>
<h3><a class="anchor" href="https://ethresear.ch#what-are-the-economic-advantages-of-preconfirmations-6" name="what-are-the-economic-advantages-of-preconfirmations-6"></a><img alt=":money_with_wings:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/money_with_wings.png?v=12" title=":money_with_wings:" width="20" /> What Are the Economic Advantages of Preconfirmations?</h3>
<p>Well… In general, for the whole range of designs that are being discussed right now this is not clear yet! <strong>Conjecturally</strong>, some of the proposed preconfirmation mechanisms will allow more value to trickle down to validators, but since the preconfirmation design landscape is so broad and confused right now it’s hard to take into account all the possible market effects that could come out of such designs. For example, most of the preconf mechanisms currently being discussed are pretty unfriendly towards what has been one of the main APY-cows for validators since the dawn of mev-boost: competitive builder/searchers.</p>
<h4><a class="anchor" href="https://ethresear.ch#why-are-we-betting-on-xga-style-preconfs-7" name="why-are-we-betting-on-xga-style-preconfs-7"></a><img alt=":game_die:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/game_die.png?v=12" title=":game_die:" width="20" /> Why Are We Betting on XGA-Style Preconfs?</h4>
<p>It seems clear to us that reserving a spot for non-priority-sensitive transactions can offer several benefits:</p>
<ul>
<li>Users and platforms (e.g. rollups) that are not involved in competitive building/searching just doesn’t care about running HFT operations on L1 can greatly benefit from separating their concerns from those of competitive builder/searchers.</li>
<li>On the other end, it eases some of the pressure on the competitive builder/searcher side by removing some of the burden of having to include <em>“filler transactions”</em> to keep their blocks competitive. E.g. freeing them from needing to include blob-bearing transactions that could negatively impact latency.</li>
<li>It makes actually pricing inclusion preconfirmations simpler, since it is still regulated by the usual gas pricing model, and at the same time the preconf inclusion market is kept separate from the traditional priority market for position-sensitive transactions.</li>
<li>Moreover, we believe in gradual change, allowing time for everyone to adapt to and observe the effects of new, potentially disruptive features in a controlled manner. A split-block design compatible with traditional mev-boost block building offers a less intrusive path to adoption.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#rethinking-relays-8" name="rethinking-relays-8"></a><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> Rethinking Relays</h2>
<p>At the moment running a relay naively is mostly a non remunerative gig. Under XGA-style preconfirmations, the relay does significantly more work and takes on more risk than before, e.g. if a block is missed and/or already sold preconfirmation tokens end up not getting included due to the relay malfunctioning, whoever bought them incurs an active loss of assets. While this sounds scary, it is also a good opportunity to rethink the role of relays in the Ethereum ecosystem.</p>
<h3><a class="anchor" href="https://ethresear.ch#insurance-and-reward-mechanisms-for-relays-9" name="insurance-and-reward-mechanisms-for-relays-9"></a><img alt=":shield:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/shield.png?v=12" title=":shield:" width="20" /> Insurance and Reward Mechanisms for Relays</h3>
<p>What we are proposing is that a relay can subscribe to an XGA-style preconf platform by staking a collateral that could be used to offer the damaged parties a refund in case of the relay malfunctioning, while sharing a percentage of the platform revenue each time it submits a successful block that includes XGA-enabled preconfirmations<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-3" id="footnote-ref-48655-3">[3]</a></sup>.</p>
<h2><a class="anchor" href="https://ethresear.ch#introducing-xga-10" name="introducing-xga-10"></a><img alt=":mega:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/mega.png?v=12" title=":mega:" width="20" /> Introducing XGA</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/4/448bd42d21b7642cd38d003f7cec9cb82adfc3b6.png" title="image"><img alt="image" height="99" src="https://ethresear.ch/uploads/default/optimized/3X/4/4/448bd42d21b7642cd38d003f7cec9cb82adfc3b6_2_690x99.png" width="690" /></a></div><br />
XGA – eXtensible Gas Auctions – is the first L2 platform for XGA-style preconfirmations (lol), designed and built by the combined efforts of <a href="https://www.manifoldfinance.com/" rel="noopener nofollow ugc">Manifold Finance</a> and <a href="https://20squares.xyz/" rel="noopener nofollow ugc">20Squares</a>. We’re very willing to make this an open and collaborative effort, so if you have any feedback and/or are interested in building this together with us, please reach out!<p></p>
<p>Right now we have released on mainnet our v1.0 (yes, this is not a beta, <strong>we’re ready to go</strong> and currently onboarding validators), with the caveat that in v1.0, the ToB mev-boost auction can only be run on a single relay. We’re currently working on shipping v2.0, which will allow a <strong>relay-agnostic</strong> auction to be run in the ToB part. You can find more about it at <a href="https://docs.xga.com/" rel="noopener nofollow ugc">docs.xga.com</a>.</p>
<hr class="footnotes-sep" />

<ol class="footnotes-list">
<li class="footnote-item" id="footnote-48655-1"><p>We have specific terms for ToB and BoB auctions, namely α and β-auctions respectively. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-1">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-48655-2"><p>Note that this doesn’t exclude the possibility of overwriting an already submitted bundle, if re-submitted before the deadline. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-2">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-48655-3"><p>We are already iterating on designs for captive insurance mechanisms for XGA-style platforms. We will upload a new post detailing some of the possible designs soon. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-3">↩︎</a></p>
</li>
</ol>
            <p><small>4 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 09:40:41 +0000</pubDate>
</item>
<item>
<title>IPv6 vs Ethereum?</title>
<link>https://ethresear.ch/t/ipv6-vs-ethereum/19829</link>
<guid>https://ethresear.ch/t/ipv6-vs-ethereum/19829</guid>
<content:encoded><![CDATA[
<div> 关键词：IPv6、CGA、BCA、Subnet ID、Interface ID

总结: 这篇文章探讨了IPv6地址结构与以太坊区块链网络之间的类比。作者提出将IPv6 Subnet ID和Interface ID的概念应用于以太坊，形成类似VPC（虚拟私有云）的结构，每个链对应不同的Subnet。使用加密技术如Cryptographically Generated Addresses (CGA) 和 Bitcoin Address-based Addresses (BCA)，可以增强节点身份验证和隐私保护。这种设想旨在通过利用IPv6的发现协议和现有机制，简化Solano节点设置，解决网络碎片问题，并增强跨链通信的安全性。 <div>
<p>I started writing this after a few days of unsuccessful attempts to run solo node behind CGNAT, as just a brainbreeze on whether it could be somehow done differently to ease up solo node setup.<br />
So far It does not seem to be an answer, however I want to share some thoughts on analogies seen with ipv6 networking to see if anyone has ideas on how this can be useful . .</p>
<h2><a class="anchor" href="https://ethresear.ch#ipv6-101-1" name="ipv6-101-1"></a>ipv6 101</h2>
<p>An IPv6 address consists of 128 bits, represented as eight groups of four hexadecimal digits separated by colons. Each group is called a hextet. For example:</p>
<p><code>2001:0db8:85a3:0000:0000:8a2e:0370:7334</code></p>
<p>where</p>
<ul>
<li>Global Routing Prefix: 2001:0db8 (Assigned by the Regional Internet Registry)</li>
<li>Subnet ID: 85a3:0000 (Identifies a specific subnet within the network)</li>
<li>Interface ID: 0000:8a2e:0370:7334 (identify the individual interface or device on the subnet)</li>
</ul>
<p>This hierarchical structure allows for efficient routing of IPv6 packets. Routers can quickly determine the destination network based on the global routing prefix, then further refine the path based on the subnet ID.</p>
<p><em>Multiple gateways</em> from ipv6 subnet may exist to public ipv6 space. Addresses within ipv6 sub network may access global ipv6 address space. Routing protocols such as <a href="https://datatracker.ietf.org/doc/html/rfc5340" rel="noopener nofollow ugc">OSPFv3</a> or <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol" rel="noopener nofollow ugc">BGP</a> may be used.</p>
<h2><a class="anchor" href="https://ethresear.ch#subnet-gateway-analogy-2" name="subnet-gateway-analogy-2"></a>Subnet Gateway analogy</h2>
<p>Just as an IPv6 router directs traffic to devices within its subnet, an RPC node facilitates communication with nodes and smart contracts within its respective blockchain network.</p>
<p>When we consider the concept of Chain IDs. In blockchain, Chain IDs are unique identifiers for different networks (e.g., Ethereum Mainnet has Chain ID 1, while various testnets have different IDs). Similarly, in IPv6, a subnet is identified by its unique prefix, which is a portion of the IPv6 address.</p>
<h2><a class="anchor" href="https://ethresear.ch#address-analogy-3" name="address-analogy-3"></a>Address analogy</h2>
<p>Since Interface Ids in IPv6 are only 64 bits long, they are too small to fit in 160 bits address of Eth.</p>
<p>However, what could be useful is using InterfaceIds to identify the nodes in the P2P network, forming VPC for Ethereum.</p>
<p>In IPv6, organizations or individuals can assign themselves a unique subnet prefix, effectively creating their own independent addressing space.</p>
<h3><a class="anchor" href="https://ethresear.ch#cryptography-for-ipv6-address-generation-4" name="cryptography-for-ipv6-address-generation-4"></a>Cryptography for IPv6 address generation</h3>
<p><a href="https://en.wikipedia.org/wiki/Secure_Neighbor_Discovery" rel="noopener nofollow ugc">Secure Neighbor Discovery (SEND)</a> is a security extension to the Neighbor Discovery Protocol (NDP) in IPv6, designed to address the vulnerabilities in the original NDP.</p>
<p>There are several papers and RFCs (Requests for Comments) relevant to cryptography for IPv6 address generation, particularly focusing on enhancing privacy and security:</p>
<p><strong><a href="https://datatracker.ietf.org/doc/html/rfc3972" rel="noopener nofollow ugc">RFC 3972</a> - Cryptographically Generated Addresses (CGA)</strong>: This RFC introduces the concept of CGA, where the interface identifier of an IPv6 address is generated using a cryptographic hash function from a public key and other parameters. This approach aims to bind a public key to an address securely, deterring address theft and enhancing authentication.</p>
<p><strong><a href="https://datatracker.ietf.org/doc/html/rfc7721" rel="noopener nofollow ugc">RFC 7721</a> - Security and Privacy Considerations for IPv6 Address Generation Mechanisms</strong>: This RFC discusses the security and privacy implications of different IPv6 address generation mechanisms, including SLAAC, privacy extensions, and CGAs. It provides recommendations for mitigating potential risks and improving privacy protection.</p>
<p><strong><a href="https://www.researchgate.net/publication/350518202_IPv6_Cryptographically_Generated_Address_Analysis_Optimization_and_Protection" rel="noopener nofollow ugc">IPv6 Cryptographically Generated Address: Analysis, Optimization and Protection</a></strong>:  This paper delves into the details of CGAs, analyzing their security and performance characteristics. It proposes optimizations to improve the efficiency of CGA generation and suggests additional security measures to strengthen the protection they offer.</p>
<p><strong><a href="https://arxiv.org/pdf/2311.15842" rel="noopener nofollow ugc">IPv6 Bitcoin-Certified Addresses, Mathieu Ducroux</a></strong>: proposes mechanism for enhancing the security and privacy of IPv6 addresses by leveraging the Bitcoin blockchain.<br />
In essence, BCAs are IPv6 addresses where the interface identifier is derived from a Bitcoin address.</p>
<h2><a class="anchor" href="https://ethresear.ch#how-could-this-be-beneficial-5" name="how-could-this-be-beneficial-5"></a>How could this be beneficial?</h2>
<p>If we can think of ethereum ecosystem as one big VPN where chains are subnet addressable that potentially solves fragmentation issues, allowing to use already established discovery protocols to route traffic between different nodes, use features like <a href="https://en.wikipedia.org/wiki/Multicast_address" rel="noopener nofollow ugc">multicast</a> etc.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/ipv6-vs-ethereum/19829">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 21:28:45 +0000</pubDate>
</item>
<item>
<title>Slot Inclusion Rates and Blob Market Combinatorics</title>
<link>https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817</link>
<guid>https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817</guid>
<content:encoded><![CDATA[
<div> 关键词：slot inclusion rate, blob market, integer packing problem, reorg risk, builder censorship

总结:<br />本文探讨了blob市场的slot inclusion rate（区块包含率）问题，指出其存在高波动性和某些Rollup（如Optimism和Base）的高值。文章分析了当前blob提交策略导致的竞争和整数打包问题（integer packing problem），这可能导致更高的slot inclusion rate而非建设者审查。研究发现，虽然市场容量未充分利用，但大blob交易的策略（如Base一次提交多个）导致平均slot inclusion rate较高。文章还提出了优化建议，如调整最大blob数量、动态投标策略和预确认机制，以提高效率并减少竞争中的潜在延迟审查。总的来说，文章强调了blob市场设计对slot inclusion rate影响的重要性，并呼吁进一步研究来改善市场动态。 <div>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TLDR</h2>
<ul>
<li><strong>Slot inclusion rate</strong>, the number of slots required for a blob to be included in the beacon chain, has a high variance and is higher for some rollups than others.</li>
<li>The current combinatorics of the blob market has an <strong>integer packing problem</strong>. This is a type of combinatorial optimization that generally involves packing objects of different sizes into a finite number of containers or bins.</li>
<li>Data suggests that the integer packing problem is contributing more to higher slot inclusion rates than builder censorship.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>This post offers a fresh perspective on the current design and constraints of the blob market, presenting additional data (<a href="https://blobs.primev.xyz/dashboard" rel="noopener nofollow ugc">from a blob tracking dashboard created at Primev</a>) on slot inclusion concerning reorg risks, and a combinatorial analysis of the blob market design, revealing an integer packing problem.</p>
<p>The key metric in this post is the <strong>slot inclusion rate</strong>. The slot inclusion rate indicates the number of slots required for a blob to be included in the beacon chain,<br />
with a higher rate signifying a longer inclusion time.</p>
<p>Recent research on the blob market <a href="https://ethresear.ch/t/big-blocks-blobs-and-reorgs/19674">[1]</a>, <a href="https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783">[2]</a>, <a href="https://mirror.xyz/preconf.eth/cxUO8pPBfqnqAlzFUzoEUa6sgnr68DRmsNhBWPb2u-c" rel="noopener nofollow ugc">[3]</a> has focused on how larger blobs increase reorg risk due to higher latency. This could incentivize builder censorship to reduce latency by excluding blobs from blocks.</p>
<p>Despite the blob market being under capacity and the base fee remaining at 1 wei, research <a href="https://mirror.xyz/preconf.eth/6lZYL62DR9U14KC7wCC4RHReVdHcBeMy5PKeHVbPq5k" rel="noopener nofollow ugc">[4]</a> shows that rollups like Optimism and Base often have high slot inclusion rates, taking more than five slots to be included. Given the underutilized market, this seems counterintuitive, suggesting possible latency censorship. However, the current blob submission strategies and blob market combinatorics suggest that higher slot inclusion rates may indicate increased competition between blob producers rather than builder censorship.</p>
<h2><a class="anchor" href="https://ethresear.ch#blob-submission-strategies-3" name="blob-submission-strategies-3"></a>Blob Submission Strategies</h2>
<p>The below table <a href="https://analytics.mev-commit.xyz/dashboard" rel="noopener nofollow ugc">from the dashboard</a> shows a 7 day snapshot of the largest blob market participants.</p>
<p>There are now 3 major strategies across the number of blobs:</p>
<ul>
<li>submit the max 5-6 blobs at a time (blast, base, linea, optimism)</li>
<li>submit 3-4 blobs at a time (arbitrum, zksync)</li>
<li>submit 1-2 blobs at a time (taiko, metal, paradex, scroll)<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7e768a0ed198c966965d14171b97d1c2600eea7d.png" title="image"><img alt="image" height="244" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7e768a0ed198c966965d14171b97d1c2600eea7d_2_690x244.png" width="690" /></a></div></li>
</ul>
<p>Aggregating blobs into fewer transactions reduces transaction expenses (base fee, blob fee, priority fee) but increases slot inclusion times. In contrast, smaller blob transactions improve slot inclusion times at the cost of higher transaction expenses.</p>
<h2><a class="anchor" href="https://ethresear.ch#slot-inclusion-rates-4" name="slot-inclusion-rates-4"></a>Slot Inclusion Rates</h2>
<p>The next chart displays a time series overlay of base block demand (total transaction fees and base fee in gwei) with the slot inclusion rate for each blob transaction. It shows high slot inclusion rates, up to 30 slots, even during periods of low blockspace demand.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/832319c888134f3fe0b465411923147c0c85c5fa.png" title="image"><img alt="image" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/8/3/832319c888134f3fe0b465411923147c0c85c5fa_2_690x258.png" width="690" /></a></div><p></p>
<p>The table mentioned earlier above contains the average slot inclusion rate for each rollup. Base, which submits the largest blobs in each transaction has the highest, averaging 13 slots. Taiko has the lowest average at 1.7 slots and submits only single blobs for each transaction right now.</p>
<p><strong>Base slot inclusion rate:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/5/a5f9d2f0d94388d88993444ae9da999347121e7e.png" title="image"><img alt="image" height="300" src="https://ethresear.ch/uploads/default/optimized/3X/a/5/a5f9d2f0d94388d88993444ae9da999347121e7e_2_690x300.png" width="690" /></a></div><p></p>
<p>taiko slot inclusion rate<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/e/ce84eb73e15b668adaa7dc811f23e8c3606000ee.png" title="image"><img alt="image" height="300" src="https://ethresear.ch/uploads/default/optimized/3X/c/e/ce84eb73e15b668adaa7dc811f23e8c3606000ee_2_690x300.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#builder-slot-inclusion-rates-5" name="builder-slot-inclusion-rates-5"></a>Builder Slot Inclusion Rates</h2>
<p>This table examines slot inclusion rates from the builder’s perspective, including the number of blocks, blob transactions, average blob count, and priority fees collected.</p>
<p>A higher slot inclusion rate means a blob has waited longer to be included in a block. An efficiency metric would be to have the lowest possible slot inclusion rate, indicating that builders are including blobs sooner rather than later.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/f/9fe6938327d570742a8b7f278788cacfa4df81ca.png" title="image"><img alt="image" height="211" src="https://ethresear.ch/uploads/default/original/3X/9/f/9fe6938327d570742a8b7f278788cacfa4df81ca.png" width="690" /></a></div><p></p>
<p>Builders like Titan and Beaverbuild have more efficient blob slot inclusion rates than vanilla builders. They also have the lowest average blobs per block. This could be due to their efficiency in accepting strategies like Taiko blobs over other block builders.</p>
<h2><a class="anchor" href="https://ethresear.ch#combinatorics-6" name="combinatorics-6"></a>Combinatorics</h2>
<p><a href="https://colab.research.google.com/drive/1EeRpWjb0meIi53IyyyZu7QWmg8HqVAMr#scrollTo=PDAJADyB24Jv" rel="noopener nofollow ugc">This notebook</a> uses dynamic programming to count the number of combinations of blobs for the current blob market. Given the current 6 blob per block capacity and 6 blobs per block, there are 11 possible combinations.</p>
<p><strong>Occurrences of each number:</strong><br />
1: 19<br />
2: 8<br />
3: 4<br />
4: 2<br />
5: 1<br />
6: 1</p>
<p>A trivial observation is that there is only one combination in which a block can fit 5 or 6 blobs. Since 4 out of 10 rollups submit these 5 and 6 blob transactions, there will only be one winner. Additionally, a single 1-blob transaction can “censor” a 6-blob transaction for an entire slot by being accepted first.</p>
<p>The combinatorics of the current blob market size suggest that the small size itself is causing higher slot inclusion problems, rather than blob censorship latency. This indicates that censorship is not from builders but from competition among blob users.</p>
<p>This raises an important question: what is the optimal maximum number of blobs allowed in a block relative to the maximum number that can fit in a block? Would the combinatorics be more favorable if the maximum blob size were 3 instead of 6? Would it be better to allow 9 blobs per block instead of 8? There is an economic incentive to group blobs as large as possible to save on costs, which disproportionately favors larger rollups over smaller ones until blob sharing becomes feasible.</p>
<h2><a class="anchor" href="https://ethresear.ch#bidding-strategies-7" name="bidding-strategies-7"></a>Bidding Strategies</h2>
<p>Currently, blobs use static bidding strategies, generally resubmitting their blobs if their bids sit in the mempool for too long. This shows a certain level of insensitivity to slot inclusion for each rollup. If a blob is delayed for 100 slots, there seem to be no consequences or incentives to increase slot inclusion rates at this time.</p>
<p>The two charts below show sample bidding strategies used by Base and Taiko, just two examples of the rollup strategies available on the dashboard. Base averages a priority fee of 4.5 gwei, while Taiko averages 2.9 gwei. There is no correlation between priority bids and base fee fluctuations.</p>
<p><strong>base:</strong><br />
<img alt="image" height="336" src="https://ethresear.ch/uploads/default/original/3X/8/7/8785ccb0b147a318d6426a694bf7697d3f1a5383.png" width="501" /></p>
<p><strong>taiko:</strong><br />
<img alt="image" height="336" src="https://ethresear.ch/uploads/default/original/3X/9/1/91bab571ac6836399edf78b7c7ce757ad62cf2ed.png" width="501" /></p>
<p>Resubmitting blobs through the mempool is expensive and generally not recommended as a good practice. This creates the problem of how blob producers can become more competitive in their bidding strategies if they need to make their slot inclusion rates more efficient.</p>
<p>One solution is to use preconfirmations. For example, using a protocol such as mev-commit to attach preconf bids to blob transactions would allow rollups to dynamically adjust their bids without having to resubmit blobs into the mempool. A stronger solution would be <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">to receive preconfirmations from proposers</a> to guarantee that builders wouldn’t be able to censor blobs.</p>
<h3><a class="anchor" href="https://ethresear.ch#conclusion-8" name="conclusion-8"></a>Conclusion</h3>
<p>Analysis of slot inclusion rates and blob market combinatorics reveals a complex interplay between efficient slot inclusion, competition, and potential censorship. While current data suggests that high slot inclusion rates are primarily driven by competition among blob users, there remain several unanswered questions:</p>
<ul>
<li>What is the optimal maximum number of blobs per block to balance efficiency and fairness?</li>
<li>How can blob producers develop more competitive bidding strategies?</li>
<li>Could the implementation of dynamic bidding strategies or preconfirmations significantly reduce slot inclusion times?</li>
<li>What long-term effects might increased competition and potential latency censorship have on the blob market?</li>
</ul>
<p>The combinatorics of the blob market are a fundamental factor affecting slot inclusion efficiency and cost. By understanding and optimizing these combinatorial constraints, it is possible to enhance market dynamics, reduce costs, and improve transaction efficiency for all participants. Further research and experimentation are needed to address these questions and optimize the blob market for all participants.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 16:47:05 +0000</pubDate>
</item>
<item>
<title>A simple, small, mev-boost compatible preconfirmation idea</title>
<link>https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800</link>
<guid>https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-boost、preconfs、proposer、relayer、merging policies

总结:<br />
本文提出了一种扩展MEV-boost以支持预配置交易（preconfs）的机制。该想法保持了现有MEV-boost流程的稳定性，仅改变提案阶段，让提案者在开始投票前提供预配置交易列表。提案者发送包含交易要求的签名JSON对象给中继器，如必须包含或排除的交易。中继器根据合并策略处理这些信息，同时保持传统MEV-boost拍卖的兼容性。尽管存在一些挑战，如中继器的额外计算负担和预配置信息的一致性问题，但作者认为这个设计有助于减少生态系统分裂，且具有渐进式替代MEV-boost的潜力。 <div>
<p><strong>Disclaimer</strong>: This post will not contain any nice images, because I am artistically inept.</p>
<p>The reasons why I’m writing this are the following:</p>
<ol>
<li>Preconfs are a very hot topic right now and many people are working on them;</li>
<li>As usual, some of the proposed solutions advocate for punching changes all the way into the main Ethereum protocol. I’m personally not a fan of this, since life is already full of <em>oh my God, what have I done?™</em> moments and <em>more drama™</em> is the least thing everyone probably needs.</li>
<li>MEV-boost is probably the <em>only</em> thing this community has really almost universally agreed upon since MEV has been a thing. So I’d very much try to preserve backwards-compatibility with MEV-boost and generalize on this than coming up with more innovative ways to balkanize our ecosystem even further.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#a-primer-on-mev-boost-1" name="a-primer-on-mev-boost-1"></a>A primer on MEV-boost</h2>
<p>This section exists just so that everyone is on the same page. Feel free to skip it or to insult me if you think I summarised things stupidly.</p>
<p>In layman terms, MEV-boost works like this:</p>
<ol>
<li>Proposer polls the relayer(s) for their best blocks;</li>
<li>Relayer(s) send their best block headers to proposer;</li>
<li>Proposer picks the best block by comparing the block headers received and the block built in-house.</li>
<li>For an in-house block, proposer just signs and broadcasts. For a mev-boost block, proposer signs the header. Relay will broadcast the complete block revealing the payload.</li>
</ol>
<p>This mechanism is nice because the only party that builders have to trust is relayer: Proposer cannot unbundle blocks and scam builders.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-actual-idea-2" name="the-actual-idea-2"></a>The actual idea</h2>
<p>The idea I have in mind works towards extending mev-boost by allowing for preconfs (and most likely for a lot of other stuff if one wants to). Notably, it does not change points 2,3,4 in the previous section, but only point 1.</p>
<p>Suppose proposer has a stash of preconfed txs on the side. The only thing the idea assumes is the following:</p>
<blockquote>
<p>By the time Proposer starts polling, it needs to have a finalized lists of preconfed txs to include.</p>
</blockquote>
<p>The reason for this will become clear shortly. Having this list at hand, proposer sends a signed JSON object to the relayer when it polls, containing the preconfed txs. This object could look, for instance, like this:</p>
<pre><code class="lang-JSON">{
    proposer: address,
    slotNumber: int,
    gasUsed: int,
    blobsUsed: int.
    mergingPolicy: int,
    mustBeginWith: txBundle,
    mustContain: txBundle,
    mustOmit: txBundle,
    mustEndWith: txBundle,
    otherStuff: JSON,
    signature : signature
}
</code></pre>
<p><strong>This design is just an idea. It is by no means fixed yet and most likely can be improved upon both in conceptual and performance terms, so take it with a grain of salt.</strong><br />
The fields <code>proposer</code> and <code>slotNumber</code> are obvious. The fields <code>mergingPolicy</code>, <code>mustBeginWith</code>, <code>mustContain</code>, <code>mustOmit</code>, <code>mustEndWith</code> can all be empty: They contain bundles of transactions that must (or must not) be included in the block. These fields are, effectively, the ones that proposer can use to signal relayer that 'hey, I need the block to respect these requirements, because of previous agreement I made with other parties."</p>
<p>How the proposer comes to define this json object is not our concern, and is outside of the scope of this idea. Just for the sake of clarity though, let’s consider some examples: For instance, <a href="https://docs.xga.com" rel="noopener nofollow ugc">XGA</a>, one of the projects <code>20[ ]</code> is contributing to, provides preconfs as tokenized bottom-of-block space. As such, XGA-style preconfs will produce objects where only <code>mustEndWith</code> is not empty.</p>
<p>The fields <code>gasUsed</code> and <code>blobsUsed</code> tell the relay how much gas and blobs the ‘preconf space’ already claimed. <code>otherStuff</code> exists to be able to extend this standard in the future without <em>more drama™</em>.</p>
<h3><a class="anchor" href="https://ethresear.ch#merging-policies-3" name="merging-policies-3"></a>Merging policies</h3>
<p>The <code>mergingPolicy</code> fields instructs the relay about how to deal with all this information. This is fundamental because, in the end, the relay will still run a traditional mev-boost auction for the remaining blockspace. As soon as a block is built by more than one party there’s a risk that different parties may step up on each other’s toes. As such, <code>mergingPolicy</code> serves as a well-defined conflict resolution policy. If you need a mental reference, think about git conflicts and automated ways to solve them if you so like.</p>
<p>How to define merging policies is up for debate. The community could agree on a common repository where merging policies are defined, voted and agreed upon, and where merging algos are explicitly provided. So, for instance, one merging policy could be:</p>
<blockquote>
<p>If the payload coming from the builder contains a transaction that also appears in the preconf bundle, deal with it in the following way:</p>
</blockquote>
<p>As said above, XGA sells BOB as preconfs, and leaves TOB open for traditional mev-boost auctions. As such, it has already defined and implemented a merging policy for its bottom of the block case, which will hopefully be open sourced soon.</p>
<h3><a class="anchor" href="https://ethresear.ch#what-does-the-relay-do-4" name="what-does-the-relay-do-4"></a>What does the relay do?</h3>
<p>This is probably already kinda clear at this point, but to make it explicit: The relay receives this signed JSON object when the proposer polls. What should it do with it? First of all, it should make some of these fields public to the builders, such as <code>mergingPolicy</code>, <code>gasUsed</code>, <code>blobsUsed</code> and <code>mustOmit</code>. This way builders will know what they can build.</p>
<p>When a block from a builder is received, the relayer will <strong>unbundle</strong> the block and apply the merging policy to merge it with the preconfed txs. The <strong>relay</strong> will sign the block header, and send it to the proposer.</p>
<p>From the POV of a builder, everything is kinda the same. They create their block using the info provided by the relay (in the simplest case this just means using slightly less gas than limit), and submit it as their bid.</p>
<p>From this point on, everything works as in traditional MEV-boost.</p>
<h2><a class="anchor" href="https://ethresear.ch#analysis-5" name="analysis-5"></a>Analysis</h2>
<p>Ok, so let’s run a rapid analysis of this thing.</p>
<h3><a class="anchor" href="https://ethresear.ch#pros-6" name="pros-6"></a>Pros</h3>
<ol>
<li>
<p>Changes to MEV-boost proper are really minimal. We just need to define an API that MEV-boost must listen to to build the polling payload, and redefine the polling logic.</p>
</li>
<li>
<p>Very little work from Proposer’s side. More work may be needed depending on the preconf system a given proposer wants to use, but then again this is out of the scope of this idea.</p>
</li>
<li>
<p>Very little work from builder’s side unless people go overly crazy with merging policies. I do not think this is necessarily a problem tho as an overly deranged merging policy would result in builders not submitting anything, and most likely in relayers not taking bets in the first place. So I’d bet that this could pretty much evolve as a ‘let the markets decide’ thing.</p>
</li>
<li>
<p>This idea is straightforwardly backwads-compatible with traditional MEV-boost: If the polling payload is empty, we collapse to a traditional MEV-boost auction with no other requisites.</p>
</li>
<li>
<p>This idea allows for gradual phasing out of MEV-boost if the community so decides. For instance, proposers may agree to produce bundles where <code>usedGas</code> is a very low parameter in the beginning (it won’t exceed 5M for XGA, for instance), meaning that the majority of blockspace would come from traditional building, with only a tiny part being preconfs or more generally ‘other stuff’. This parameter may then be increasingly crancked up or varied with time if the community so decides, effectively phasing out traditional block building in favor of ‘something else’. In this respect yes, I know I’m being vague here but when it comes to how this thing could be adopted I can only speculate.</p>
</li>
<li>
<p>This system can be extended in many ways, and it is flexible. Merging policies could be defined democratically, and the polling info could be extended effectively implementing something akin to PEPSI, for instance. Another possible extension/evolution can be using <code>otherStuff</code> to define Jito-style auctions. I mean, there’s really a plethora of ways to go from here.</p>
</li>
<li>
<p>The polling payload is signed by the proposer, and the block header is signed by the relayer. This keeps both parties in check as we accumulate evidence for slashing both. For instance:</p>
<ul>
<li>Imagine I get some preconf guarantee from proposer and that I have evidence of this. Again how this happens is outside of the scope of this post, as this mechanism is agnostic wrt how preconfs are negotiated.</li>
<li>Now suppose furthermore than my preconfed tx does <strong>not</strong> land in the block.</li>
<li>I can use the chain of signed objects to challenge both relayer and proposer. If my tx wasn’t in the polling info signed by proposer, that’s proposer’s fault. On the other hand, if it was, but it wasn’t in the block, then it’s relayer’s fault. I think this is enough to build a slashing mechanism of sorts, which could for instance leverage some already available restaking solution.</li>
</ul>
<p><strong>Note:</strong> If there’s enough interest in this idea, we as 20[  ] can throw some open games at it and simulate the various scenarios. Let me know!</p>
</li>
<li>
<p><strong>Ethereum protocol doesn’t see any of this.</strong> So if it fucks up, we just call it a day and retire in good order without having caused the apocalypse: Relays will only accept empty payloads, proposers will only send empty payloads, and we’ll essentially revert to mev-boost without anyone having to downgrade their infra. I think this is the main selling point of this idea: The amount of ways to make stuff explode in mev-related infraland are countless, so this whole idea was built with a ‘it has to be failsafe’ idea in mind.</p>
</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#cons-7" name="cons-7"></a>Cons</h3>
<ol>
<li>
<p>Relayer must unbundle builder blocks to do the merging. I do not think this creates a huge trust issue as relayer can already do this as of now: In general, a relayer that scams builders is a relayer that won’t be used again, and will go out of business quickly.</p>
</li>
<li>
<p>Relayer must do computational work. This is probably the major pain point. This idea entails slightly more latency, as an incoming bid cannot be relayed instantly because <code>mergingPolicy</code> has to be applied. The computational penalty is furthermore heavily dependent on how deranged the merging policy is. As a silver lining, this computational work is <em>provable</em> as both the merging info and the resulting block are signed. The result is that we have <strong>provable evidence to remunerate a relay for its work if we want to</strong>, possibly solving a major pain point for relayers in traditional mev-boost.</p>
</li>
<li>
<p>Relayer is slashable if it screws up. Again, how this should be implemented is outside of the scope of this idea as this mechanism only accounts for the needed trail of evidence to implement slashing, but does not deal with the slashing per sé. Anyway, it is still worth reasoning on the possible consequences of this: If slashing policies are implemented, Relayers will most likely need to provide some collateral or implement some form of captive insurance. Again, this may signify more complexity on one hand but also opportunity on the other, as relayers may for instance decide to tokenize said collateral and develop mechanisms to make money out of these newly created financial instruments. As relayers are private enterprises I’ll leave these considerations to the interested parties.</p>
</li>
<li>
<p><strong>Polling info must stay fixed</strong>. This is related to point 3 above and point 6 of the <a href="https://ethresear.ch#pros">Pros</a> subsection: If the polling info changes all the time, this means huge computational stress for the relayer, and it furthermore allows for malicious behavior from the proposer: For instance, a proposer could send two different polling payloads, and include a given preconfed tx only in one of them. How to resolve these inconsistencies is an open question. In my opinion, the wisest and simplest thing to do would be requiring the polling info to be fixed, meaning that if proposer signs conflicting payloads for the same slot this should be considered akin to equivocation, and thus a slashable offence.</p>
<p>By the way, the consequence of this is that the idea proposed here necessarily excludes some preconf use cases. This is related to my comment <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695/2">here</a> and I think it is unavoidable if we want to keep MEV-boost around. As the majority  of revenue from MEV comes precisely from the bids of very refined, high-time frame searchers, and as I am quite sure that validators don’t want to give this money up at least for now, ‘leaving these players be’ by ruling out such preconf use-cases is in my opinion the most practical option, and exactly the rationale motivating this idea.</p>
</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#closing-remarks-8" name="closing-remarks-8"></a>Closing remarks</h2>
<p>That’s it. If the idea is interesting enough let me know, I’ll be happy to start a discussion around it.  The <code>20[ ]</code> team will also be around at EthCC if you want to discuss this in person.</p>
            <p><small>8 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 13:33:55 +0000</pubDate>
</item>
<item>
<title>One-bit-per-attester inclusion lists</title>
<link>https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797</link>
<guid>https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797</guid>
<content:encoded><![CDATA[
<div> 关键词：Inclusion lists, transaction selection, RANDAO_REVEAL, Reed-Solomon decoding, fork choice rule.

总结:
本文提出了一种新的机制，用于在区块链中实现更去中心化的交易入选列表（Inclusion lists）。机制的核心是利用RANDAO_REVEAL生成随机种子，将验证者分为小组，每个小组负责查找优先级高、费用支付的交易，并通过Erasure编码提供与种子相关联的交易部分。如果多数验证者诚实，Reed-Solomon解码可以确定交易；否则，可能需要使用更复杂的方法恢复交易。验证者的选择和交易的入选受制于区块生产者的决定，但通过调整时间权重和fork choice规则，可以增加对长期未被选中的交易的包容性。这种机制旨在减少集中化风险，提高去中心化程度。 <div>
<p>Inclusion lists are a technology for distributing the authority for choosing which transactions to include into the next block. Currently, the best idea for them is to have an actor that is from a set that is likely to be highly decentralized (eg. consensus block proposers) generate the list. This authority is decoupled from the right to <em>order</em> (or <em>prepend</em>) transactions, which is an inherently economies-of-scale-demanding and so likely to be highly concentrated in practice.</p>
<p>But what if we could avoid putting the responsibility onto a <em>single</em> actor, and instead put it on a <em>large set of actors</em>? In fact, we can even do it in such a way that it’s semi-deniable: from each attester’s contribution, there is no clear evidence of which transaction they included, because one individual piece of provided data could come from multiple possible transactions.</p>
<p>This post proposes a possible way to do this.</p>
<h3><a class="anchor" href="https://ethresear.ch#mechanism-1" name="mechanism-1"></a>Mechanism</h3>
<p>When the block for slot N is published, let <code>seed</code> be the RANDAO_REVEAL of the block. Suppose for convenience that each transaction is under <code>T</code> bytes (eg. <code>T = 500</code>); we can say in this initial proposal that larger transactions are not supported. We put all attesters for that slot into groups of size <code>2 * T</code>, with <code>k = attesters_per_slot / (2 * T)</code> groups.</p>
<p>Each attester is chosen to be the j’th attester of the i’th group. They identify the highest-priority-fee-paying valid transaction which was published before the slot N block, and where <code>hash(seed + tx)</code> is between <code>2**256 / k * i</code> and <code>2**256 / k * (i+1)</code>. They erasure-code that transaction to <code>2T</code> bits, and publish the j’th bit of the erasure encoding as part of their attestation.</p>
<p>When those attestations are included in the next block, an algorithm such as <a href="https://en.wikipedia.org/wiki/Berlekamp%E2%80%93Welch_algorithm">Berlekamp-Welch</a> is used to try to extract the transaction from the provided attester bits.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/e/deedccb04e5bb133ccacdbe2c2c17d1e5abdc3ce.png" title="attester_inclusion_list.drawio"><img alt="attester_inclusion_list.drawio" height="271" src="https://ethresear.ch/uploads/default/optimized/3X/d/e/deedccb04e5bb133ccacdbe2c2c17d1e5abdc3ce_2_690x271.png" width="690" /></a></div><p></p>
<p>The Reed-Solomon decoding will fail in two cases:</p>
<ol>
<li>If too many attesters are dishonest</li>
<li>If attesters have different views about whether a particular transaction was published before or after the block, and so they are split between providing bits for two or more different transactions.</li>
</ol>
<p>Note that in case (2), if the transactions are sufficiently small, advanced <a href="https://www.cs.cmu.edu/~venkatg/teaching/codingtheory/notes/notes10.pdf">list decoding algorithms</a> may nevertheless be able to recover several or all of the transactions!</p>
<p>The next block proposer will be able to see which transactions the attestations imply, and so they will be able to block transactions from the list by selectively failing to include attestations. This is an unavoidable limitation of the scheme, though it can be mitigated by having a fork choice rule discount blocks that fail to include enough attestations.</p>
<p>Additionally, the mechanism can be modified so that if a transaction has not been included for 2+ slots, <em>all</em> attesters (or a large fraction thereof) attempt to include it, and so any block that fails to include the transaction would lose the fork choice. One simple way to do this is to score transactions not by <code>priority_fee</code>, but by <code>priority_fee * time_seen</code>, and at the same time have a rule that a transaction that has been seen for <code>k</code> slots is a candidate not just for attester group <code>i</code>, but also for attester group <code>i...i+k-1</code> (wrapping around if needed).</p>
            <p><small>8 posts - 7 participants</small></p>
            <p><a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 09:33:36 +0000</pubDate>
</item>
<item>
<title>Torrents and EIP-4444</title>
<link>https://ethresear.ch/t/torrents-and-eip-4444/19788</link>
<guid>https://ethresear.ch/t/torrents-and-eip-4444/19788</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP-4444、Torrents、Ethereum、Pre-merge data、Merkle roots

总结:
EIP-4444目标是减少以太坊节点所需存储的历史数据。文章介绍了使用BitTorrent技术来分发历史数据的方法，通过在geth v1.14.3版本上创建era文件并验证根文件（roots.txt）来实现。这个过程产生了427GB的torrent文件，用于同步pre-merge数据。虽然torrent有依赖多个活跃节点和增加节点网络需求的缺点，但它提供了一种可能的解决方案。客户端可以选择不预下载数据，用户可以通过命令行或特定标志获取。要重现或验证torrent，需同步geth节点、执行era文件导出和创建torrent，以及使用era工具验证数据完整性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#torrents-and-eip-4444-1" name="torrents-and-eip-4444-1"></a>Torrents and EIP-4444</h1>
<h3><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h3>
<p>EIP-4444 aims to limit the historical data that Ethereum nodes need to store. This EIP has two main problems that require solutions: Format for history archival and Methods to reliably retrieve history. The client teams have agreed on a common <a href="https://ethresear.ch/t/era-archival-files-for-block-and-consensus-data/13526">era files</a> format, solving one half of the problem. The second half of the problem, i.e Method to reliably retrieve history will likely not rely on a single solution. Some client teams may rely on the <a href="https://ethereum.org/en/developers/docs/networking-layer/portal-network/" rel="noopener nofollow ugc">Portal network</a>, some rely on torrents, others might rely on some form of snapshot storage.</p>
<h3><a class="anchor" href="https://ethresear.ch#torrents-for-eip-4444-3" name="torrents-for-eip-4444-3"></a>Torrents for EIP-4444</h3>
<p>Torrents offer us a unique way to distribute this history, torrents as a technology have existed since 2001 and have withstood the test of time. Some client teams, such as <a href="https://github.com/ledgerwatch/erigon" rel="noopener nofollow ugc">Erigon</a> already include a method to sync via torrents that has run in production systems.</p>
<p>In order to make some progress on the Torrent approach of history retrieval, the files would first be required. So an era file export was made on a <a href="https://github.com/ethereum/go-ethereum/" rel="noopener nofollow ugc">geth</a> running version <code>v1.14.3</code> . To explore the initial idea, the torrent approach chose pre-merge data as a target. The merge occurred at block height <a href="https://etherscan.io/block/15537393" rel="noopener nofollow ugc">15537393</a>, meaning all pre-merge data could be archived by choosing a range of 0 to block 15537393. The era files were then created using the command <code> geth --datadir=/data export-history /data/erafiles 0 15537393</code>.</p>
<p>Once the era files were created, they were verified using the command <code>era verify roots.txt</code>, with the source of the <code>roots.txt</code> file being <a href="https://gist.githubusercontent.com/lightclient/528b95ffe434ac7dcbca57bff6dd5bd1/raw/fd660cfedb65cd8f133b510c442287dc8a71660f/roots.txt" rel="noopener nofollow ugc">this</a>. The entire process has been outlined in <a href="https://github.com/ethereum/go-ethereum/pull/26621#issuecomment-1434023464" rel="noopener nofollow ugc">this PR comment</a>. The verification output was found to be this log message: <code>Verifying Era1 files             verified=1896,  elapsed=5h21m49.184s</code></p>
<p>The output era files were then uploaded onto a server and a torrent was created using the software <code>mktorrent</code>. An updated list of trackers was found using the github repo <a href="https://github.com/ngosang/trackerslist" rel="noopener nofollow ugc">trackerslist</a>. The trackers chosen were a mix of http/https/udp in order to allow for maximal compatibility. The chunk size of the torrent was chosen to be 64MB, which was the max allowed and recommended value for a torrent of this size.</p>
<p>The result of this process is now a torrent of size 427GB. This torrent can be imported with <a href="https://ethresear.ch">this magnet link</a>  and a torrent client would be able to pull the entire pre-merge history as era files.</p>
<h4><a class="anchor" href="https://ethresear.ch#tradeoffs-4" name="tradeoffs-4"></a>Tradeoffs</h4>
<p>There are of course some tradeoffs with torrents, as with many of the other EIP-4444 approaches:</p>
<ul>
<li>Torrents rely on a robust set of peers to share the data, there is however no way to incentivise or ensure that this data is served by peers</li>
<li>A torrent client would need to be included in the client releases and some client languages might not have a torrent library</li>
<li>Torrents would de-facto expect the nodes to also seed the content they leech, this would increase node network requirements if they choose to store history</li>
<li>The JSON-RPC response needs to take into account that it may not have the data to return a response in case the user decides to not download pre-merge data</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#conclusion-5" name="conclusion-5"></a>Conclusion</h3>
<p>A client could potentially include this torrent into their releases and avoid syncing pre-merge data by default, which could then be fetched via torrent if a user requests it (perhaps with a flag similar to <code>--preMergeData=True</code>). The client could also hardcode the hash of the expected data, ensuring that the data retrieved matches what they expect.</p>
<h3><a class="anchor" href="https://ethresear.ch#instructions-for-re-creating-torrent-6" name="instructions-for-re-creating-torrent-6"></a>Instructions for re-creating torrent:</h3>
<ul>
<li>Sync a geth node using the latest release</li>
<li>Stop the geth node and run <code>geth --datadir=/data export-history /data/erafiles 0 15537393</code> to export the data in a folder called <code>data/erafiles</code>(Warning, this will use ~427GB of additional space)</li>
<li>Use the <code>mktorrent</code> tool or the <code>rutorrent</code> GUI to create a torrent. Choose the <code>/data/erafiles/</code> folder as the source for the data. Next, obtain the latest open trackers from <a href="https://github.com/ngosang/trackerslist?tab=readme-ov-file" rel="noopener nofollow ugc">this github repository</a>. Choose a healthy mix of udp/http/https trackers and choose the chunk size of the torrent to be 64MB.</li>
<li>The tool should output a <code>.torrent</code> file, the GUI will also allow you to copy a magnet link if that is required</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#instructions-for-download-and-verification-of-torrent-data-7" name="instructions-for-download-and-verification-of-torrent-data-7"></a>Instructions for download and verification of torrent data:</h3>
<ul>
<li>Download the torrent data with this magnet link and in a torrent client of your choice: <a href="https://ethresear.ch">link</a></li>
<li>Clone the latest release of <a href="https://github.com/ethereum/go-ethereum/" rel="noopener nofollow ugc">geth</a> and install the dependencies</li>
<li>Run <code>make all</code> in the geth repository to build the <code>era</code> binary</li>
<li>Fetch the <code>roots.txt</code> file with the command: <code>wget https://gist.githubusercontent.com/lightclient/528b95ffe434ac7dcbca57bff6dd5bd1/raw/fd660cfedb65cd8f133b510c442287dc8a71660f/roots.txt</code></li>
<li>Run <code>era verify roots.txt</code> in the folder to verify the integrity of the data</li>
</ul>
            <p><small>15 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/torrents-and-eip-4444/19788">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 09:35:32 +0000</pubDate>
</item>
<item>
<title>Blobs, Reorgs, and the Role of MEV-Boost</title>
<link>https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783</link>
<guid>https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783</guid>
<content:encoded><![CDATA[
<div> 关键词：blobs、MEV-Boost、reorgs、latency、block propagation

总结:
这篇文章探讨了区块中的大对象（blobs）对以太坊网络延迟和重组（reorgs）的影响，特别是与MEV-Boost（矿工提取价值优化）相关的生态系统。非MEV-Boost用户平均包含更多blobs，导致他们区块被重组的概率较高。MEV-Boost用户由于其低延迟连接和专业性，区块被重组的可能性显著较低。研究还指出不同构建者和中继器可能采用策略来处理blobs，比如Rsync-Builder和Flashbots的平均blob数量较少。未来的研究将关注节点能力的提升和减少非MEV-Boost用户的重组率。随着blob市场的发展，其交易提示可能会追平常规交易。 <div>
<h1><a class="anchor" href="https://ethresear.ch#blobs-reorgs-and-the-role-of-mev-boost-1" name="blobs-reorgs-and-the-role-of-mev-boost-1"></a>Blobs, Reorgs, and the Role of MEV-Boost</h1>
<p><strong>The TL;DR is:</strong></p>
<ul>
<li><strong>Builders</strong> might have an incentive to not include blobs because of the higher latency they cause.</li>
<li><strong>Non-MEV-Boost users</strong> include, on average, more blobs in blocks than MEV-Boost builders.</li>
<li><strong>MEV-Boost users</strong> show a significantly lower probability of being reorged than <em>Non-MEV-Boost</em> users (see section <em>MEV-Boost and Reorgs</em> for details).</li>
<li><strong>Rsync-Builder</strong> and <strong>Flashbots</strong> have a lower average number of blobs per block than other builders.</li>
</ul>
<hr />
<p>In a <a href="https://ethresear.ch/t/big-blocks-blobs-and-reorgs/19674">recent analysis on big blocks, blobs and reorgs</a>, we could see the impact of blobs on the reorg probability.</p>
<p><strong>In the following, I want to expand on this by taking the MEV-Boost ecosystem into account.</strong></p>
<p><strong>The fundamental question is…</strong><br />
-&gt; <strong>“<em>Does MEV-Boost impact reorgs, and if so, by how much?</em>”</strong></p>
<p>Blobs are “<em>big</em>” and big objects cause higher latency. Thus, one might expect builders to not include blobs into their blocks in scenarios in which:</p>
<ul>
<li>The builder is submitting its block late in the slot to minimize latency (see timing games).</li>
<li>The builder wants to capture a high MEV opportunity and doesn’t want to risk unavailable blobs invalidating its block.</li>
<li>The proposer is less well connected (because the gossiping starts later in the slot).</li>
</ul>
<p><strong>Builders</strong> might demand to be <strong>compensated</strong> through priority fees for including transactions which might cause blocks to be propagated with higher latency. Until 4844, such transactions have been those with a lot of calldata. As of 4844, blobs are the main drivers of latency.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/d/8db1993891d52c3c8be9d7c6adde8633810ad15b.png" title="tx_type_prio_fee_all (2)"><img alt="tx_type_prio_fee_all (2)" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/8/d/8db1993891d52c3c8be9d7c6adde8633810ad15b_2_690x345.png" width="690" /></a></div><p></p>
<p><strong>As visible in the above chart, blob transactions don’t tip as much as regular Type-2 transactions.</strong><br />
Based on that, blobs don’t give builders a significant edge over other builders competing for the same slot.<br />
Another explanation could be private deals between builders and rollups to secure timely inclusion of blob transactions for a fee paid through side channels.</p>
<h2><a class="anchor" href="https://ethresear.ch#mev-boost-and-reorgs-2" name="mev-boost-and-reorgs-2"></a>MEV-Boost and Reorgs</h2>
<p>The MEV-Boost ecosystem consists of sophisticated parties, <strong>builders</strong> and <strong>relays</strong>, that are well connected and specialized in having low-latency connections to peers.<br />
Thus, it is expected that proposers using MEV-Boost should be reorged less often than ‘Vanilla Builders’ (i.e., users not using MEV-Boost).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/5/859fee3890096d24a955abd65642fee08ebd141c.png" title="reorgs_mevb_over_blobs (3)"><img alt="reorgs_mevb_over_blobs (3)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/8/5/859fee3890096d24a955abd65642fee08ebd141c_2_690x258.png" width="690" /></a></div><p></p>
<p>This expectation holds true when looking at the above chart.<br />
<strong>We can see that the reorg probability increases with the number of blobs. However, the reorg probability for MEV-Boost users is much lower than the one for Non-MEV-Boost users (Vanilla Builders).</strong></p>
<p><strong>In this context it’s important to not confuse correlation and causation:<br />
-&gt; <em>Non-MEV-Boost users are on average less sophisticated entities which also contributes to the effect we observe in the above chart.</em></strong></p>
<p>In this context it is interesting to compare the <strong>average number of blobs per block</strong> of MEV-Boost users vs. Non-MEV-Boost users.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/c/3cbac65d110bbf6d535ba55d7dfb62f69206a271.png" title="blobs_over_time (3)"><img alt="blobs_over_time (3)" height="373" src="https://ethresear.ch/uploads/default/optimized/3X/3/c/3cbac65d110bbf6d535ba55d7dfb62f69206a271_2_690x373.png" width="690" /></a></div><p></p>
<p><strong>As visible in the above chart, proposers not using MEV-Boost included on average more blobs into their blocks than MEV-Boost users.</strong><br />
This might point towards MEV-Boost ecosystem participants (relays and builders) applying strategies that go beyond the “<em>include it if there’s space</em>” strategy.</p>
<p><strong>First, let’s look at the builders more closely.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4bf0a4fe8bc95e88d122c479fe88cf4f32883fbf.png" title="blobs_over_time_builder (4)"><img alt="blobs_over_time_builder (4)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4bf0a4fe8bc95e88d122c479fe88cf4f32883fbf_2_690x258.png" width="690" /></a></div><p></p>
<p>Vanilla Builders (Non-MEV-Boost proposers) are the ones that have the highest blob inclusion rate, followed by Beaverbuild and Titan Builder.</p>
<p>Rsync-Builder seems to include way less blobs in their blocks.<br />
The same applies to the Flashbots builder that seems to have changed its behavior in early May, with the average number of blobs per block approaching zero.</p>
<p><strong>“Is it fair to say 'Builder XY censors blobs!?”</strong><br />
&gt; <strong>No</strong></p>
<blockquote>
<p><em>Different builders follow different strategies. For example a builder such as Rsync-Builder that is generally competitive in slots where low latency and speed matters might end up with winning those blocks where there are no blobs around (c.f. <em>selection bias</em>)</em></p>
</blockquote>
<br />
<p><strong>Next, let’s shift the focus to the relays:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/7/374ff432477462e6a307a3d83c7da899f3a5b541.png" title="blobs_over_time_relays (4)"><img alt="blobs_over_time_relays (4)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/3/7/374ff432477462e6a307a3d83c7da899f3a5b541_2_690x258.png" width="690" /></a></div><p></p>
<p>As visible above, Vanilla Builders have on average the highest blob inclusion rate.<br />
The Ultrasound and Agnostic Gnosis relays are second and third, followed by the relays of BloXroute.<br />
The Flashbots relay seems to include the lowest number of blobs.</p>
<p><strong>Importantly, relays are dependent on builders and ultimately it’s the builders that impact the above graph.</strong></p>
<h2><a class="anchor" href="https://ethresear.ch#next-steps-3" name="next-steps-3"></a>Next Steps</h2>
<p>In the context of <a href="https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541">PeerDAS</a>, the network will have to rely on nodes that are <em>stronger</em> than others and able to handle way more than 6 blobs per block. Therefore, it’d be super valuable to see more research on that topic happening.</p>
<ul>
<li><strong>Call for reproduction</strong>: It’d be great if someone could verify my results by reproducing this analysis.</li>
<li><strong>Investigate the reasons</strong> why certain builders have a significantly lower blob inclusion rate than others.</li>
<li><strong>Reduce reorg rate for Non-MEV-Boost users</strong>: Relays could offer Non-MEV-Boost users their block propagation services to ensure that fewer of their blocks get reorged.</li>
</ul>
<p>The blob market is still under development and a stable blob price is yet to be discovered. With increasing demand for blob space, tips from blob transaction will likely catch up to regular transactions.</p>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 15:46:12 +0000</pubDate>
</item>
<item>
<title>Block Proposing &amp; Validating Timelines for 1.) MEV-Boost, 2.) ePBS, and 3.) ePBS with MEV-Boost</title>
<link>https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782</link>
<guid>https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Boost、ePBS、block release time、validation time、propagation time

总结:<br />
MEV-Boost与ePBS比较的关键点在于验证时间和块释放时间。MEV-Boost中，由于额外的步骤（如提案者获取头和执行块），导致整体释放时间较长（RT^{mevboost}）。相比之下，ePBS通过共识层和执行层的并行处理，减少了验证时间，特别是对于执行块（VT^{EL} 和 SPT）。验证共识块时，ePBS的条件更为宽松（RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL}），而MEV-Boost可能导致因SPT和VT^{EL}的额外延迟而产生重新排序（reorgs）。因此，使用MEV-Boost进行ePBS会比纯ePBS更慢。 <div>
<p>This writeup summarizes the timeline differences between ePBS and MEV-Boost using inequalities. We analyze three models: 1) MEV-Boost, 2) ePBS, and 3) MEV-Boost with relayers on ePBS. We show that MEV-Boost with relayers on ePBS is slower than ePBS alone, which could lead to reorgs.</p>
<h2><a class="anchor" href="https://ethresear.ch#definitions-1" name="definitions-1"></a>Definitions</h2>
<p><span class="math">VT^{CL}</span>: Consensus layer validation time. The time taken by a node to verify the consensus portion of a block.<br />
<span class="math">VT^{EL}</span>: Execution layer validation time. The time taken by a node to verify the execution portion of a block.<br />
<span class="math">RT^{mevboost}</span>: Mev-boost block release time. The time when a block is released from a node or relayer, assuming the MEV-boost setting.<br />
<span class="math">RT^{epbs,cl}</span>: ePBS consensus block release time. The time when a consensus block is released from a node or relayer, assuming the ePBS setting.<br />
<span class="math">RT^{epbs,el}</span>: ePBS execution block release time. The time when an execution block is released from a node or relayer, assuming the ePBS setting.<br />
<span class="math">PT^{mevboost}</span>: Mev-boost block propagation time. The time taken for a block to propagate across the network, assuming the mev-boost setting.<br />
<span class="math">PT^{epbs,cl}</span>: ePBS consensus block propagation time. The time taken for a consensus block to propagate across the network, assuming ePBS setting.<br />
<span class="math">PT^{epbs,el}</span>: ePBS execution block propagation time. The time taken for an execution block to propagate across the network, assuming ePBS setting.<br />
<span class="math">Attestation\_RT^{beacon}</span>: Beacon attestation release time. The time when a beacon attestation is released from a node.<br />
<span class="math">Attestation\_RT^{ptc}</span>: PTC attestation release time. The time when a payload attestation is released from a node, assuming the ePBS setting.<br />
<span class="math">BBT</span>: Proposer build block time. The time taken for a proposer to build consensus portion of a block.<br />
<span class="math">GHT</span>: Proposer get header time. The time taken for a proposer to obtain a header from a relayer (MEV-boost) or builder (ePBS).<br />
<span class="math">GPT</span>: Proposer get payload time. The time a proposer takes to obtain a payload from a relayer (MEV-boost).<br />
<span class="math">SPT</span>: Builder submit payload time. The time taken for a relayer to receive a payload from the builder (MEV-boost).<br />
<span class="math">SBBT</span>: Proposer submit blind block time. The time a proposer takes to submit blind block to the relayer (MEV-boost).</p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-a-mev-boost-block-2" name="proposing-a-mev-boost-block-2"></a>Proposing a mev-boost block</h2>
<p>In Mev-Boost, proposing a block involves two parts. First, the builder sends the block to the relayer. Second, the proposer requests the header and returns the signed block to the relayer. We break down the time it takes in the following subsections, starting with the non-optimistic relayer and then the optimistic relayer. We also assume that everything starts at the 0-second mark of the slot, including the builder sending the execution block to the relayer.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-optimistic-relayer-3" name="non-optimistic-relayer-3"></a>Non optimistic relayer</h3>
<p><span class="math">BRT</span> defines builder to relayer time. This is how much time takes for a builder to submit a block (ie bid) to the relayer and the relayer verifies the block is valid.<br />
<span class="math">BRT = SPT + VT^{EL}</span></p>
<p><span class="math">PRT</span> defines proposer to relayer time. This is how much time takes for a proposer to build block, request header, request payload, and submit blind block.<br />
<span class="math">PRT = BBT + GHT + GPT + SBBT</span></p>
<p><span class="math">RT^{mevboost} = BRT + PRT</span></p>
<p>This assumes everything happens after the slot start because bids become more valuable. Another model is to assume <span class="math">BRT</span> happens before the slot. Then <span class="math">RT^{mevboost} = PRT</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#optimistic-relayer-4" name="optimistic-relayer-4"></a>Optimistic relayer</h3>
<h4><a class="anchor" href="https://ethresear.ch#relayer-receives-builder-block-time-5" name="relayer-receives-builder-block-time-5"></a>Relayer receives builder block time</h4>
<p><span class="math">BRT = SPT</span></p>
<p><span class="math">PRT</span> is the same as before</p>
<p><span class="math">RT^{mevboost} = BRT + PRT</span></p>
<blockquote>
<p>Using optimistic relayer is faster than non-optimistic relayer by: <span class="math">VT^{EL}</span></p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#validating-a-mev-boost-block-6" name="validating-a-mev-boost-block-6"></a>Validating a mev-boost block</h2>
<p>In MEV-Boost, the block must be processed before <span class="math">Attestation\_RT^{beacon}</span> to be considered canonical. The following equation shows the conditions that need to be met for the block to be considered canonical from the perspective of all nodes.</p>
<p>For a beacon block to be canonical, it should satisfy:<br />
<span class="math">RT^{mevboost} + PT^{mevboost} + VT^{CL} + VT^{EL} &lt; Attestation\_RT^{beacon}</span></p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-an-epbs-block-7" name="proposing-an-epbs-block-7"></a>Proposing an ePBS block</h2>
<p>In ePBS, proposing the consensus block and the execution block are pipelined, where the consensus block commits to the execution block’s header. Block release time becomes two parts 1.) CL block release time and 2.) EL block release time.</p>
<h3><a class="anchor" href="https://ethresear.ch#proposing-the-consensus-block-8" name="proposing-the-consensus-block-8"></a>Proposing the consensus block</h3>
<p>We assume the proposer uses the builder’s RPC to get the header. The proposer could also self-build or use P2P to obtain the header, which is arguably faster. Therefore, there is no need for proposer get header time anymore.</p>
<p><span class="math">RT^{epbs,cl} = GHT + BBT</span></p>
<blockquote>
<p>Using ePBS is faster than mev-boost by: <span class="math">SPT+VT^{EL}+GPT + SBBT</span></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#proposing-the-execution-block-9" name="proposing-the-execution-block-9"></a>Proposing the execution block</h3>
<p><span class="math">RT^{epbs,el}</span> is when fork choice accumulates sufficient weight (~40%) or 6 seconds into the slot. The builder could propose a “withhold” block to try to reorg consensus layer block so builder does not have to pay the proposer.</p>
<h2><a class="anchor" href="https://ethresear.ch#validating-an-epbs-block-10" name="validating-an-epbs-block-10"></a>Validating an ePBS block</h2>
<p>In ePBS, validating the consensus block and the execution block are pipelined in different stages. The beacon attestation cutoff time has been moved from 4 seconds into the slot to 3 seconds into the slot. However, we can assume that the CL block propagation time is shorter than the block propagation time. EL block validation can be delayed until the subsequent slot, as shown in the equations.</p>
<h3><a class="anchor" href="https://ethresear.ch#validating-the-consensus-block-11" name="validating-the-consensus-block-11"></a>Validating the consensus block</h3>
<p><span class="math">PT^{epbs,cl} &lt; PT^{mevboost}</span><br />
<span class="math">Attestation\_RT^{beacon,epbs} &lt; Attestation\_RT^{beacon,mevboost}</span></p>
<p>For a consensus block to be canonical, it should satisfy:<br />
<span class="math">RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL} &lt; Attestation\_RT^{beacon}</span></p>
<blockquote>
<p>Using ePBS is faster than mev-boost by: <span class="math">PT^{mevboost}-PT^{epbs,cl}+VT^{EL}</span></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#validating-the-execution-block-12" name="validating-the-execution-block-12"></a>Validating the execution block</h3>
<h4><a class="anchor" href="https://ethresear.ch#as-a-ptc-voting-for-execution-blocks-presence-13" name="as-a-ptc-voting-for-execution-blocks-presence-13"></a>As a PTC voting for execution block’s presence</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} &lt; Attestation\_RT^{ptc}</span></p>
<h4><a class="anchor" href="https://ethresear.ch#as-a-proposer-proposing-the-next-slots-consensus-block-14" name="as-a-proposer-proposing-the-next-slots-consensus-block-14"></a>As a proposer proposing the next slot’s consensus block</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} + VT^{EL} &lt; Next\_Slot\_Start\_Time</span></p>
<h4><a class="anchor" href="https://ethresear.ch#everyone-else-15" name="everyone-else-15"></a>Everyone else</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} + VT^{EL} &lt; Next\_Slot\_Attestation\_RT^{beacon}</span></p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-an-epbs-block-using-mev-boost-16" name="proposing-an-epbs-block-using-mev-boost-16"></a>Proposing an ePBS block using mev-boost</h2>
<p><span class="math">BRT = SPT + VT^{EL}</span><br />
<span class="math">PRT = BBT + GHT</span><br />
<span class="math">RT^{epbs,cl} = BRT + PRT</span></p>
<blockquote>
<p>Using MEV-Boost for ePBS is slower than ePBS by: <span class="math">SPT + VT^{EL}</span><br />
The additional latency occurs because the trusted party must receive and verify the execution block before releasing it to the proposer.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#validating-the-consensus-block-17" name="validating-the-consensus-block-17"></a>Validating the consensus block</h2>
<p><span class="math">RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL} &lt; Attestation\_RT^{beacon}</span></p>
<blockquote>
<p>Given <span class="math">Attestation\_RT^{beacon}</span> is shorter than ePBS, an extra <span class="math">SPT + VT^{EL}</span> could lead to additional reorgs.</p>
</blockquote>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 13:52:44 +0000</pubDate>
</item>
<item>
<title>SGX as 2FA for FHE/MPC</title>
<link>https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780</link>
<guid>https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780</guid>
<content:encoded><![CDATA[
<div> 关键词：SGX、MPC、FHE、Trusted Execution Environment (TEE)、Collusion Risk

总结:
本文探讨了如何利用SGX（安全多方计算）作为FHE（全同态加密）项目的双重身份验证（2FA），特别是在MPC（多方计算）加密管理中增强安全性。文章指出，FHE项目的关键瓶颈在于MPC节点的密钥管理，而将MPC运行在SGX中可以防止节点间的串通风险。SGX作为2FA的优势包括提高安全性、减少信任依赖、保持低延迟和易于扩展。然而，SGX也有其问题，如声誉不佳、可能的误报安全以及缺乏链上远程证明。尽管如此，随着相关项目的发展，如Phala的进展，SGX在隐私保护技术中的应用前景值得关注。 <div>
<p><em>About me: I am <a href="https://x.com/tolak_eth" rel="noopener nofollow ugc">Wenfeng Wang</a>, a builder and researcher at Phala Network, put this topic here and hope to have a comprehensive discussion with the community.</em></p>
<p><strong>TLDR</strong>: Involving SGX introduces a safeguard against the collusion risk inherent in current MPC and FHE systems.</p>
<p>Continuing from Justin Drake’s well-articulated <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">post</a> about SGX as a 2FA for zk-rollups, I aim to expand on the potential of SGX as 2FA in FHE projects, specifically in their MPC encryption management. Despite their distinct applications, both leverage some fundamental features of SGX.</p>
<h2><a class="anchor" href="https://ethresear.ch#mpc-is-the-bottleneck-of-fhe-1" name="mpc-is-the-bottleneck-of-fhe-1"></a>MPC is the bottleneck of FHE</h2>
<p>Lately, the interest in FHE (Fully Homomorphic Encryption) technologies has rejuvenated, especially in the context of Ethereum Virtual Machines (EVMs). What was once merely a concept is now a tangible tool developers can use to write privacy-preserving smart contracts. Interested readers can refer to Vitalik’s early 2020 <a href="https://vitalik.eth.limo/general/2020/07/20/homomorphic.html" rel="noopener nofollow ugc">post</a> about FHE. Now, let’s look at the general architecture of most current FHE projects.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f17a45e5c32060cd1578a8f2112437f58880327.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f17a45e5c32060cd1578a8f2112437f58880327_2_663x500.png" width="663" /></a></div><p></p>
<p>I will not dive too deep into FHE itself here, but you can find a notable challenge most FHE designs encounter today lies in the MPC node’s key management. Due to the practice of writing an FHE application, the key is globally used by all users to encrypt the data they send to the FHE server, which will execute under an encryption state. Thus, the whole security of the system relies on the security of the MPC network, and as we all know the truths of the MPC network are:</p>
<ul>
<li>The more nodes you have, the more latency you get</li>
<li>The fewer nodes you have, the more trust assumptions you need</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#tee-as-a-2fa-to-mpc-2" name="tee-as-a-2fa-to-mpc-2"></a>TEE as a 2FA to MPC</h2>
<p>We don’t want to give full trust to MPC nodes because of the possibility of collusion if it is run by humans. Instead, we can add SGX as 2FA to hedge the risk by moving the key management to <a href="https://en.wikipedia.org/wiki/Trusted_execution_environment" rel="noopener nofollow ugc">TEE</a> (Trusted Execution Environments, a technology to run the program in an isolated zone inside CPU, prove program immutable and limited-accessible).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/d/1dc05649e162e2e9de3318a6da112754d5a6cd7e.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/d/1dc05649e162e2e9de3318a6da112754d5a6cd7e_2_608x500.png" width="608" /></a></div><p></p>
<p>As illustrated above, MPC nodes of the FHE system are now running inside TEE, instead of producing TEE proof when acting as 2FA for zk-rollups, here SGX is used to protect the key generation progress in the MPC network, and the whole lifecycle of the key is kept inside TEE and never gonna reveal to the outside world, more importantly, the key can not be touched by human even a single piece. TEE itself can guarantee the program it runs is verifiable, it’s impossible for someone can manipulate the state. Also, the data passing between TEE and the client is secured by TLS communication.<br />
With TEE as a 2FA, it can help reduce the risk in an economic way that:</p>
<ul>
<li>If SGX is not compromised, there is no chance that collusion can happen;</li>
<li>If SGX gets compromised, only when collusion happens between nodes that the system is broken.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#advantagesdisadvantages-of-sgx-as-2fa-for-fhe-3" name="advantagesdisadvantages-of-sgx-as-2fa-for-fhe-3"></a>Advantages/Disadvantages of SGX as 2FA for FHE</h2>
<ul>
<li>
<p>Advantages</p>
<ul>
<li>Security: Remove the possibility of collusion, trust is built on top of machinehood + cryptography instead of humanity.</li>
<li>Safety: By running MPC inside SGX, even a small MPC network can be reasonably secure. Even if TEE is broken, e.g. have bugs in SGX or Intel being malicious, we still fall back to ordinary MPC.</li>
<li>Latency: Using SGX, we can get higher security without introducing more workers. This gives more confident to users to run latency sensitive operations on MPC.</li>
<li>Liveness: SGX didn’t provide extra liveness naturally, but projects like Phala have built a decentralized <a href="https://docs.phala.network/tech-specs/blockchain" rel="noopener nofollow ugc">TEE network</a> that can help make it easy to build an unstoppable network.</li>
<li>Scalability: Scaling the MPC network is hard, but there are a bunch of existing TEE networks that are ready to deploy MPC nodes. So it lowers the cost to build a larger MPC network.</li>
<li>Throughout: There also is no throughput lost, but considering the optimization of latency, throughput can be improved theoretically.</li>
<li>More advantages that can be brought by SGX were well addressed by <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">Justin’s post</a>.</li>
</ul>
</li>
<li>
<p>Disadvantage</p>
<ul>
<li>It’s worth mentioning that SGX also has its own problems, a quote from Justin’s post:</li>
</ul>
<blockquote>
<ul>
<li>SGX has a bad reputation, especially within the blockchain space. Association with the technology may be memetically suboptimal.</li>
<li>false sense of security: Easily-broken SGX 2FA (e.g. if the privkey is easily extractable) may provide a false sense of security.</li>
<li>novelty: No Ethereum application that verifies SGX remote attestations on-chain could be found.</li>
</ul>
</blockquote>
<ul>
<li>As for the last one that SGX remote attestation on-chain doesn’t exist, the latest state is we have a couple of projects working on it, including Puffer, Automata, and also Phala’s <a href="https://github.com/tolak/zk-dcap-verifier" rel="noopener nofollow ugc">zk-dcap-verifier</a>. But considering it hasn’t been deployed on the mainnet, I kept it on the list.</li>
</ul>
</li>
</ul>
<p><em>Special thanks Justin Drake for his research of <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">2FA zk-rollups using SGX</a> and Andrew Miller for this research of TEE in Multi-Proof system, check his <a href="https://docs.google.com/presentation/d/1K96G50S8ICdllQDbEW1su1Ik_eOc5bK9Ih3uvoG-P9Y/edit?usp=sharing" rel="noopener nofollow ugc">presentation</a>.</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 03:25:10 +0000</pubDate>
</item>
<item>
<title>Solutions to the Preconf Fair Exchange Problem</title>
<link>https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779</link>
<guid>https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779</guid>
<content:encoded><![CDATA[
<div> 关键词：公平交换、领导预确认、声誉系统、最后权利、执行承诺

总结:
本文探讨了在领导预确认（preconfirmation）框架中解决公平交换问题的方法。首先，通过建立声誉系统，激励预确认者诚实回应，但依赖于经济条件的稳定性。其次，提出“最后权利”方案，根据预确认者的顺序决定PER的处理权，最后一个处理PER的预确认者有权获得交易提示。这解决了公平问题，且成本随技术进步而降低。最后，还讨论了“第一权利”方案，即反向请求承诺，适用于对执行承诺不那么敏感的场景。文章也提出了结合使用这些方法的可能性，以适应不同规模的交易需求。

< br>总结: <div>
<h3><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>tldr</h3>
<p>Solutions for dealing with the fair exchange problem in leader-based preconfirmation setups.</p>
<p>Reputation can incentivize preconfers to act honestly.</p>
<p>Alternatively, use order to dictate who gets the PER tip. One can invalidate a PER by sending it to a preconfer with higher priority.</p>
<h1><a class="anchor" href="https://ethresear.ch#fair-exchange-2" name="fair-exchange-2"></a>Fair Exchange?</h1>
<p>The fair exchange problem can be summarized as two untrusted players blindly giving up something in hopes that the other party will do the same. The goal is to try to find a method to ensure that both will cooperate. In the context of preconfirmations, the requesting party (gateway) has no guarantee that their preconfirmation enforcement request (PER) will receive a signed commitment. The preconfer has every right to not return a commitment, hold onto the PER until the last second, and include it if profitable (pocketing the tip for free).</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-1-reputation-3" name="solution-1-reputation-3"></a>Solution 1: Reputation</h1>
<p>One solution to this is by tracking reputation. More specifically, leveraging the promise of future PERs to incentivize preconfers to respond promptly via either commitments or non-commitments (slash-able promises to NOT include). The gateway can throttle or simply ignore preconfers if they misbehave.</p>
<p>Reputation is a tried method and exists today in mev-boost relays (see <a href="https://ethresear.ch/t/the-preconfirmation-sauna/19762">Switchboard’s Sauna Appendix</a>). While this might work, it still requires certain economic conditions for security. If for whatever reason it becomes really profitable to behave dishonestly, the guarantees fall apart.</p>
<h1><a class="anchor" href="https://ethresear.ch#can-we-do-better-4" name="can-we-do-better-4"></a>Can we do better?</h1>
<p>In an ideal scenario, without any limitations of technology, one would simply invalidate the PER if the preconfer takes too long to respond. With blockchains, this is complicated, and time-based approaches require some sort of additional consensus, breaking the based paradigm. However, we can indirectly access “time” by using order. Blocks are ordered, so preconfers can be as well. If we take advantage of this, we arrive at a new solution that avoids the Fair Exchange problem altogether.</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-2-last-right-5" name="solution-2-last-right-5"></a>Solution 2: Last Right</h1>
<p>Determine an order for preconfers. This can be done per block (or even intra-block). Send the PER optimistically to the first preconfer. If they commit, then great. If they return a non-commitment, or do not respond, then send the PER to the next preconfer.</p>
<p>But wait, they can still include my PER and pocket my tip! Yes, they can but they won’t be able to keep the tip. This is due to the central idea of this solution: <strong>the last preconfer to include the PER has the right to the tips</strong>. If two preconfers attempt to include the PER, the second preconfer has the right to the preconf tip. For example, the last preconfer submits a proof and transfers the PER tip to their balance. Other mechanisms are also possible and should be explored.</p>
<p>One consideration here is the cost. If claiming the tip is more expensive than the tip itself, then the model falls apart. The good news is this cost is directly tied to the technology and should decrease exponentially (e.g. zk proof). Preconfirmation tips on the other hand are tied to the value of the transaction itself, which is not as dependent on the tech. So perhaps this mechanism will become more and more economically favorable.</p>
<p>One great side effect of this method is that it preserves the possibility of execution promises. If the first preconfer acts honestly, then it can guarantee the execution state for the PER. Execution guarantees fall apart if there’s any dishonesty (same as Solution 1).</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-3-first-right-6" name="solution-3-first-right-6"></a>Solution 3: First Right</h1>
<p>If we are willing to forgo execution promises, then the gateway can instead request commitments from preconfers in reverse order. Forward the PER to a preconfer down the list, and then move up until one commits. <strong>The first preconfer to include the PER gets the tip.</strong> In the case where L1 proposers are preconfers, this is enforced by the L1 replay protection. This is a much simpler version of Solution 2.</p>
<p>One downside is the “real” latency before the transaction is actually included since the default preconfer is not the current one. But one could argue that for important transactions where L1 settlement is important (e.g. buying a house), preconfirmations in general are probably not a priority.</p>
<p>Note that execution promises are technically still possible if all the state transitions up to the point of inclusion has already been determined. (e.g. All block space has already been filled by PERs or similar.)</p>
<h1><a class="anchor" href="https://ethresear.ch#final-thoughts-7" name="final-thoughts-7"></a>Final Thoughts</h1>
<p>We can even perhaps use these Solutions in tandem. For smaller preconf tips, we can rely on Solution 1, let the first preconfer pocket it and “slash” their reputation. For larger preconf tips, we can fallback to Solution 2 and let the next preconfer steal it back. Or just use them at the same time.</p>
<p>Thanks to <span class="mention">@mteam</span> for getting me up to speed and providing feedback. We at Spire Labs are actively researching preconfirmations and related topics, and building towards a better, unified Ethereum.</p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 02:55:02 +0000</pubDate>
</item>
<item>
<title>Inactivity Leak unveiled</title>
<link>https://ethresear.ch/t/inactivity-leak-unveiled/19774</link>
<guid>https://ethresear.ch/t/inactivity-leak-unveiled/19774</guid>
<content:encoded><![CDATA[
<div> 关键词：inactivity leak, finalization, Ethereum PoS, Byzantine validators, safety

总结:
本文探讨了以太坊PoS区块链中的"不活动泄漏"问题，这是一种在灾难性网络故障期间恢复最终性的理论分析。不活动泄漏机制导致链的连续增长，优先保证区块的最终性（活性），但可能牺牲安全。当网络中存在拜占庭验证者时，这一问题更加突出，它们可能导致冲突的最终区块，威胁协议的安全。文章详细描述了不活动分数和惩罚机制，以及在不同行为（活跃和不活跃）下的验证者权益变化。研究发现，拜占庭验证者的恶意行为会加速安全丧失，特别是在初始比例较高时。作者强调了对协议设计中潜在问题的认识对于BFT分析和未来改进的重要性。 <div>
<p>We summarize here the <a href="https://arxiv.org/abs/2404.16363" rel="noopener nofollow ugc">article</a> that presents the first theoretical analysis of the inactivity leak, designed to restore finalization during catastrophic network failures. This work is accepted at DSN2024.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h1>
<ul>
<li>The inactivity leak is intrinsically problematic for the safety of the protocol. It favors the constant finalization of blocks (<em>liveness</em>) at the expense of having conflicting finalized blocks (<em>safety</em>).</li>
<li>The presence of Byzantine validators -validators that deviate from the protocol- can accelerate the loss of safety.</li>
</ul>
<hr />
<p>The Ethereum PoS blockchain strives for the continuous growth of the finalized chain. In consequence, the protocol incentivizes validators to finalize blocks actively. The inactivity leak is the mechanism used to regain finality. Specifically, the inactivity leak is initiated if a chain has not undergone finalization for four consecutive epochs. The inactivity leak happened for the first time on the mainnet in May 2023.</p>
<p>A good introduction to the inactivity leak is available thanks to the excellent work of Ben Eddington <a href="https://eth2book.info/capella/part2/incentives/inactivity/" rel="noopener nofollow ugc">here</a> (which motivated this work). We formalize the inactivity leak starting by the inactivity score.</p>
<h2><a class="anchor" href="https://ethresear.ch#inactivity-score-2" name="inactivity-score-2"></a>Inactivity Score</h2>
<p>During an inactivity leak, at epoch <span class="math">t</span>, the inactivity score, <span class="math">I_i(t)</span>, of validator <span class="math">i</span> is:</p>
<div class="math">
\begin{cases}
        I_i(t) = I_i(t-1)+4, \text{if $i$ is inactive at epoch $t$} \\
        I_i(t) = \max(I_i(t-1)-1, 0), \text{ otherwise.}
    \end{cases}
</div>
<p>Thus, a validator’s inactivity score increases by <span class="math">4</span> if it is inactive and decreases by <span class="math">1</span> if it is active. The inactivity score is always positive and will be used to penalize validators during the inactivity leak.</p>
<h2><a class="anchor" href="https://ethresear.ch#inactivity-penalties-3" name="inactivity-penalties-3"></a>Inactivity Penalties</h2>
<p>Let <span class="math">s_i(t)</span> represent the stake of validator <span class="math">i</span> at epoch <span class="math">t</span>, and let <span class="math">I_i(t)</span> denote its inactivity score. The penalty at each epoch <span class="math">t</span> is <span class="math">I_i(t-1)\cdot s_i(t-1)/2^{26}</span>. Therefore, the evolution of the stake is expressed by:</p>
<div class="math">
s_i(t)=s_i(t-1)-\frac{I_i(t-1)\cdot s_i(t-1)}{2^{26}}. 
</div>
<h2><a class="anchor" href="https://ethresear.ch#stake-during-the-inactivity-leak-4" name="stake-during-the-inactivity-leak-4"></a>Stake during the Inactivity Leak</h2>
<p>In this work, we model the stake function <span class="math">s</span> as a continuous and differentiable function, yielding the following differential equation:</p>
<div class="math">
s'(t)=-I(t)\cdot s(t)/2^{26}.
</div>
<p>With this equation, we can determine a validator’s stake according to the time by fixing the evolution of its inactivity score. And that is exactly what we do. We define two types of behavior: Active and Inactive.</p>
<ul>
<li>Active validators: they are always active.</li>
<li>Inactive validators: they are always inactive.</li>
</ul>
<p>Validators with these behaviors experience different evolutions in their inactivity scores: (a) Active validators have a constant inactivity score <span class="math">I(t)=0</span>; (b) Inactive validators’ inactivity score increases by 4 every epoch, <span class="math">I(t)=4t</span>. The stake of each type of validator during an inactivity leak:</p>
<ul>
<li>Active validator’s stake: <span class="math"> s(t) = s_0 = 32. </span></li>
<li>Inactive validator’s stake: <span class="math"> s(t) = s_0e^{-t^2/2^{25}}. </span></li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/496a7e5de461559b800a4d612eacb356a5f3cc84.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/496a7e5de461559b800a4d612eacb356a5f3cc84_2_685x500.png" width="685" /></a></div><p></p>
<p>The graph shows the evolution of the stake of validators depending on their activity during the inactivity leak. The expulsion limit is set by the protocol to eject validators that have accumulated too many penalties.</p>

What is an active validator? <a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774/1">(click for more details)</a>
<hr />
<p>This was the formalization of the protocol. Now we make the analysis of the protocol’s property of safety. To do so, we use the following model.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-5" name="model-5"></a>Model</h2>
<ul>
<li><strong>Network</strong>: We assume a partially synchronous system, which transitions from an asynchronous state to a synchronous state after an apriori unknown Global Stabilization Time (GST).</li>
<li><strong>Fault</strong>: Validators are either <em>honest</em> or <em>Byzantine</em> (deviating from the protocol). A Byzantine validator can deviate arbitrarily from the protocol.</li>
<li><strong>Stake</strong>: Each validator starts with 32 ETH.</li>
</ul>
<p>There is no bound on message transfer delay during the asynchronous state.</p>
<h1><a class="anchor" href="https://ethresear.ch#bound-for-safety-6" name="bound-for-safety-6"></a>Bound for safety</h1>
<h2><a class="anchor" href="https://ethresear.ch#with-only-honest-validators-7" name="with-only-honest-validators-7"></a>With only honest validators</h2>
<p>By construction, the inactivity leak will breach safety if a partition occurs for long enough. The question is, how quickly?</p>
<blockquote>
<p><em>Any network partition lasting longer than 4686 epochs (about 3 weeks) will result in a loss of Safety because of conflicting finalization. This is an upper bound for Safety on the duration of the inactivity leak with only honest validators.</em></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#detailed-analysis-8" name="detailed-analysis-8"></a>Detailed Analysis</h3>
<p>Let us analyze the scenario in which the validators (which are all honest) are partitioned in two. (We are in the asynchronous state according to our model).<br />
The partition will necessarily create a fork, each partition building on the only chain they see. The chains will finalize once the proportion of active validators returns to 2/3rd.</p>
<p>In this case, by understanding the distribution of the validators across the partitions, we can compute the time it takes for the proportion of active validators’ stake to return to 2/3 of the stake on each branch, thus finalizing and breaking safety.</p>
<p>For the analysis, we make the following notations. At the beginning of the inactivity leak:</p>
<ul>
<li><span class="math">n</span> is the total number of validators</li>
<li><span class="math">n_B</span> is the total number of Byzantine validators</li>
<li><span class="math">n_H</span> is the total number of honest validators</li>
<li><span class="math">n_{H_1}</span> is the number of honest validators on branch 1</li>
<li><span class="math">n_{H_2}</span> is the number of honest validators on branch 2</li>
</ul>
<p>There are no Byzantine validators for the first part of our analysis, which implies that <span class="math">n=n_H</span>. Honest validators are only partitioned in two, thus <span class="math">n_H=n_{H_1}+n_{H_2}</span>.</p>
<p><strong>Our goal is to determine when the proportion of honest validators on branch 1 will be superior to 2/3rd of the total stake.</strong>  Which is to say that we look at when the ratio:</p>
<div class="math">
\frac{\text{stake of validator in branch 1}}{\text{stake of validator in branch 1 + stake of validator in branch 2}},
</div>
<p>is superior to 2/3. With our notation, the ratio can be rewritten as:</p>
<div class="math">
\frac{n_{\text H_1}s_{\text H_1}(t)}{n_{\text H_1}s_{\text H_1}(t)+n_{\text H_2}s_{\text H_2}(t)} ,
</div>
<p><span class="math">s_{\text H_1}</span> and <span class="math">s_{\text H_2}</span> are the stakes of honest active and inactive validators, respectively. Since the <span class="math">n_{\text H_1}</span> validators on branch 1 are always active on branch 1, and the <span class="math">n_{\text H_2}</span> validators are always inactive on branch 1 (they are active on branch 2); we know that <span class="math">s_{\text H_1}(t)=s_0</span> and <span class="math">s_{\text H_2}(t)=s_0e^{-t^2/2^{25}}</span>.<br />
Using the notation <span class="math">p_0=n_{\text H_1}/n_H</span>, the ratio of active validators over time is:</p>
<div class="math">
\frac{p_0}{p_0+(1-p_0)e^{-t^2/2^{25}}}. 
</div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7ec6a1a64318159dada408e4cc0365a1663b28d1.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7ec6a1a64318159dada408e4cc0365a1663b28d1_2_668x500.png" width="668" /></a></div><p></p>
<p>This graph shows the ratio of active validators on branch 1 over time. If finalization hasn’t occurred by epoch <span class="math">t=4685</span>, inactive validators are ejected, causing a jump to 100% active validators.</p>
<h2><a class="anchor" href="https://ethresear.ch#byzantine-validators-9" name="byzantine-validators-9"></a>Byzantine validators</h2>
<p>We now add Byzantine validators.</p>

These Byzantine validators can send messages to each partition without restriction. <a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774/1">(click for more details)</a>
<p>The situation we analyze is now as such:</p>
<ul>
<li>Less than one-third of the stake is held by Byzantine validators (<span class="math">\beta_0=n_{\rm B}/n&lt;1/3</span>).</li>
<li>Honest validators are divided into branches <span class="math">1</span> and <span class="math">2</span>; a proportion <span class="math">p_0=n_{\rm H_1}/n_{\rm H}</span> on branch <span class="math">1</span> and <span class="math">1-p_0=n_{\rm H_2}/n_{\rm H}</span> on branch <span class="math">2</span>.</li>
<li>Byzantine validators can communicate with both branches.</li>
</ul>
<p>Byzantine validators can be active on both branches simultaneously, breaching safety faster. The ratio of active validators on branch 1 is:</p>
<div class="math">
\frac{p_0(1-\beta_0)+\beta_0}{p_0(1-\beta_0)+\beta_0+(1-p_0)(1-\beta_0)e^{-t^2/2^{25}}}.
</div>
<p>This table shows the time it takes to break safety depending on the initial proportion of Byzantine validators (<span class="math">\beta_0</span>):<br />
<img alt="image" height="195" src="https://ethresear.ch/uploads/default/original/3X/3/0/30cda7537ed8ab1493f4beadd138924b6b6408f3.png" width="157" /></p>
<p><em>Byzantine validators can expedite the loss of Safety. If their initial proportion is 0.33, they can make conflicting finalization occur approximately ten times faster than scenarios involving only honest participants.</em></p>
<hr />
<p>The original paper provides more details on the assumptions, scenarios, protocol, and other aspects such as:</p>
<ul>
<li>Ways for Byzantine validators to breach safety without committing slashable behavior.</li>
<li>Methods for Byzantine validators to exceed the 1/3 threshold on both branches of the fork.</li>
<li>An analysis of the probabilistic bouncing attack while considering the inactivity leak. Spoiler alert: this aggravates the attack slightly, but the conditions for the attack to start and persist in time make it highly improbable to be a real threat.</li>
</ul>
<p>For an additional quick peek at the paper’s findings, here is a graphic that presents how quickly Byzantine validators can break safety depending on their initial proportion and whether their behavior is slashable or not.  As you can see, they can have a strong impact even without slashable behavior.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/a/8a447d3888021e7cf6ba7c2b99fd1907ad3a5738.png" title="image"><img alt="image" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/8/a/8a447d3888021e7cf6ba7c2b99fd1907ad3a5738_2_500x375.png" width="500" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-10" name="conclusion-10"></a>Conclusion</h1>
<p>Our findings highlight the importance of penalty mechanisms in Byzantine Fault Tolerance (BFT) analysis. By identifying potential issues in protocol design, we aim to provide insights for future improvements and tools for further investigation.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 10 Jun 2024 13:46:18 +0000</pubDate>
</item>
<item>
<title>The contention between preconfs and ePBS</title>
<link>https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770</link>
<guid>https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、preconfirmations、inclusion lists、centralized entity、staked builders

总结:<br />
文章讨论了ePBS（加密预言机拜占庭服务）与不同预确认机制的兼容性。主要观点如下：<br />
1. 使用预确认列表可能会导致交易广播两次，增加网络负担，这与ePBS优化的共识块验证时间不兼容。
2. 预确认系统的中心化性质，通常依赖于集中式实体，如中继，与ePBS的去中心化目标相悖。
3. ePBS下，强制执行预确认可能导致全交易列表广播，挑战了ePBS的优化，即仅验证共识块。
4. 建议利用已有的staked builders作为预确认者，他们在预确认系统中的角色可以像提案者一样受到规则约束。
5. ePBS对restaking（复投）也构成挑战，因为预确认和潜在违规行为可能发生在同一个交易中，需要额外处理。

因此，为保持与ePBS的兼容性，预确认系统的设计需要避免直接在共识块中包含完整交易列表，而是考虑利用staked builders的角色来间接实现预确认。 <div>
<p>This quick note is motivated by a question of <a class="mention" href="https://ethresear.ch/u/hasu.research">@Hasu.research</a> regarding the compatibility of ePBS with the different mechanisms for preconfirmations that are being proposed by independent groups <a href="https://ethresear.ch/t/the-preconfirmation-sauna/19762">1</a> <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">2</a> <a href="https://chainbound.github.io/bolt-docs/" rel="noopener nofollow ugc">3</a> <a href="https://docs.google.com/presentation/d/1a-0rP2knM11g59UmnKn7I7NH8BlFM5wNhczH35sbkSo/edit#slide=id.g2731bc99d1b_0_0" rel="noopener nofollow ugc">4</a> <a href="https://docs.primev.xyz/get-started/introduction" rel="noopener nofollow ugc">5</a>. The only purpose of this note is to leave a quick written record of the fundamental contention between the enshrinements of preconfirmations and the <a href="https://github.com/potuz/consensus-specs/pull/2" rel="noopener nofollow ugc">current proposal for ePBX</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#overloading-inclusion-lists-1" name="overloading-inclusion-lists-1"></a>Overloading inclusion lists.</h2>
<p>Even in the very first post on <a href="https://ethresear.ch/t/based-preconfirmations/17353">based preconfirmations</a>, the idea of using <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">forced inclusion lists</a> was put forward as a way for proposers to signal their intent of honoring preconfirmations, forcing builders to include these transactions. An extrapolation of this idea led, in one of the original designs for ILs, to propose that inclusion lists may essentially include a complete list of transactions the proposer has in its current mempool. One of the problems with these ideas is that the full list of transactions would need to be broadcast over the P2P network twice: once when the inclusion list is broadcast, and the second time within the payload itself. In all known designs for inclusion lists, validators attest for the existence of the full executable transaction list. This implies in particular that</p>
<ol>
<li>The list must be available at the beacon block validation time.</li>
<li>The list must be executed at the beacon block validation time.</li>
</ol>
<p>This section is not meant to be read as <em>inclusion lists aren’t compatible with ePBS</em> but rather any preconfirmation system (and next block forced inclusion lists by definition are such a system) that relies on the execution and distribution of the transactions at the consensus block validation time, necessarily clashes with the main optimization from ePBS.</p>
<h2><a class="anchor" href="https://ethresear.ch#epbs-validation-optimization-2" name="epbs-validation-optimization-2"></a>ePBS validation optimization</h2>
<p>The above two points are in direct opposition with the main optimization that ePBS brings to block processing, that is that the only hot path to validation is that of the consensus block that has to be fully verified before the attestation deadline. All other validations, like transaction execution, data availability, etc. are deferred to the remainder of the slot and into the next slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f3daa474ae131dfbee7c96cfd9f2a7e4035c06a.jpeg" title="ePBS slot"><img alt="ePBS slot" height="364" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f3daa474ae131dfbee7c96cfd9f2a7e4035c06a_2_690x364.jpeg" width="690" /></a></div><p></p>
<p>While ePBS is compatible with inclusion lists, their addition inherently stresses this optimization. Broadcasting a small list of 16 transactions that can be immediately executed in microseconds is not the same as broadcasting a full block, and presumably, even blob transactions as some based rollups would require.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-centralized-nature-of-preconfs-3" name="the-centralized-nature-of-preconfs-3"></a>The centralized nature of preconfs</h2>
<p>There is no current design (that I am aware of) of preconfirmations, that does not rely on a centralized entity. This is natural to expect in the absence of an encrypted public mempool, users can’t send their transactions in the open to the next proposer (although they could <em>encrypt the transactions to the public BLS address of the next proposer</em>), and we can’t enshrine an RPC provider, all systems thus make use on existing centralized entities (for example relays) to act as a preconfer. Decentralization comes in that it is ultimately the proposer who enforces these preconfirmations, by forcing the builder to fullfil them.</p>
<p>Thus, in all proposed systems for preconfirmations, either of L1 transactions or for based rollups, there exist a centralized entity that at the very least is responsible for gathering the transactions and giving out the preconfirmations. Systems differ on how is that these preconfirmations are enforced, they range from new L1 slashing proposals, to restaking proposals (moving the slashing to a separate layer), etc. The point is that preconfirmations can be enforced by the protocol itself, or by a somewhat decentralized party like the subset of validators participating in the preconfirmation scheme. In summary, there is a plethora of options for enforcing the (or penalizing the lack of) inclusion of preconfirmations, in decreasing level of trustlessness:</p>
<ul>
<li>The L1 protocol itself enforces inclusion. For example, forced ILs, with proposer level slashings on missed slots, preconf equivocations, etc.</li>
<li>Some separate committee enforces them. For example a subset of the L1 validators also participate in a sidechain by restaking, and the enforcement/punishment is carried in that sidechain.</li>
<li>A centralized entity enforces them. For example the relay itself only sends bids from builders that have satisfied the required preconfs.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#a-viable-way-compatible-with-epbs-staked-builders-as-preconfirmers-4" name="a-viable-way-compatible-with-epbs-staked-builders-as-preconfirmers-4"></a>A viable way compatible with ePBS: staked builders as preconfirmers.</h2>
<p>Any approach with a full payload being broadcast with the consensus block for preconfirmation enforcement clashes directly with the main scaling optimization of ePBS with regard to block validation. As thus, it seems difficult to expect a working design in which the proposers are in charge of sending and enforcing preconfirmations. The second and third approaches above are fully compatible with ePBS.</p>
<p>One of the features that preconfirmation systems can leverage when ePBS is in place, is that builders themselves are staked validators, thus they can be subject to the same rules that these systems currently require from proposers. For example, those systems that rely on slashings on a restaking scheme could simply add conditions on participating builders. That is, the proposer set participating in the scheme only take bids from builders that are participants of the scheme. The builders and proposers are required to be restaked. There are new penalty conditions for</p>
<ul>
<li>A proposer that does not include a block.</li>
<li>A proposer that includes a block with a commitment to a non-participating builder.</li>
<li>A builder that does not include the payload</li>
<li>A builder that includes a payload does not satisfies the preconf list.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#a-separate-note-on-restaking-5" name="a-separate-note-on-restaking-5"></a>A separate note on restaking</h2>
<p>ePBS also presents a challenge on any restaking scheme: builders can transfer funds in the same payload that they commit a slashable offense. L1 protocol can deal with this by immediately deducting the bid from the builder’s balance at the time of CL block processing, but delaying the credit to the proposer. In case the builder commits a slashable offense, the buffer allows the L1 protocol to implement penalization procedures that can impact those delayed funds accordingly. If the builder is restaked however, the restaking chain does not have access to these funds.</p>
            <p><small>7 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 07:59:33 +0000</pubDate>
</item>
<item>
<title>On block-space distribution mechanisms</title>
<link>https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764</link>
<guid>https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#on-block-space-distribution-mechanisms-1" name="on-block-space-distribution-mechanisms-1"></a>On block-space distribution mechanisms</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/3/c3fa4239ef0f468256ba44d0e860fb3d7edaedcf.jpeg" title="upload_3067440b5b4f752379ddba32df7ecf8b"><img alt="upload_3067440b5b4f752379ddba32df7ecf8b" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/3/c3fa4239ef0f468256ba44d0e860fb3d7edaedcf_2_499x500.jpeg" width="499" /></a></div><br />
<sub><strong>^p.s. yes, we anthropomorphize the protocol as a ghost because <a href="https://arxiv.org/pdf/1710.09437.pdf" rel="noopener nofollow ugc">Casper</a>.</strong></sub><br />
<sub><strong>^^p.p.s. not sure why the auctioneer ghost looks like he is conducting an orchestra, but here we are ¯\_(ツ)_/¯.</strong></sub><br />
<sub><strong>^^^ p.p.p.s. by the way, if you haven’t seen <a href="https://en.wikipedia.org/wiki/Maestro_(2023_film)" rel="noopener nofollow ugc">Maestro</a>, it’s great.</strong></sub><p></p>
<p><span class="math">\cdot</span><br />
<em>by <a href="https://x.com/mikeneuder" rel="noopener nofollow ugc">Mike</a>, <a href="https://x.com/PGarimidi" rel="noopener nofollow ugc">Pranav</a>, &amp; <a href="https://x.com/Tim_Roughgarden" rel="noopener nofollow ugc">Dr. Tim Roughgarden</a> – June 8, 2024.</em><br />
<span class="math">\cdot</span><br />
<strong>Acknowledgements</strong><br />
<em>Special thanks to <a href="https://x.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://x.com/_julianma" rel="noopener nofollow ugc">Julian</a>, <a href="https://x.com/_JonahB_" rel="noopener nofollow ugc">Jonah</a>, <a href="https://x.com/DavideCrapis" rel="noopener nofollow ugc">Davide</a>, <a href="https://x.com/soispoke" rel="noopener nofollow ugc">Thomas</a>, <a href="https://x.com/terencechain" rel="noopener nofollow ugc">Terence</a>, <a href="https://x.com/potuz_eth" rel="noopener nofollow ugc">Potuz</a>, &amp; <a href="https://www.nano210.blog/" rel="noopener nofollow ugc">Nate</a> for comments and discussions.</em><br />
<span class="math">\cdot</span><br />
<strong>tl;dr;</strong> <em>Block space, the capacity for transaction inclusion, is the principal resource exported by blockchains. As the crypto ecosystem scales up and professionalizes, the value produced by efficient usage of block space (<a href="https://arxiv.org/abs/1904.05234" rel="noopener nofollow ugc">MEV</a>) has come to play a significant role in the economics of permissionless consensus mechanisms. An immense amount of ink has been spilled by the research community considering what, if anything, protocols should enshrine in response to MEV (see <a href="https://ethresear.ch#related-work-2">Related Work</a>). Indeed, the past few years resemble a <a href="https://en.wikipedia.org/wiki/Blind_men_and_an_elephant" rel="noopener nofollow ugc">Blind Men and the Elephant</a> narrative arc, where many different perspectives, solutions, and theories have been propounded, but each angle can feel disjoint and difficult to compare. The first half of this article aims to present a broad-strokes painting of the “MEV-ephant” by distilling the design space into a core set of questions and exploring how existing proposals answer them. The second half hones in specifically on allocation mechanisms enabled by execution tickets, demonstrating an important new insight – there is a trade-off between the quality of the in-protocol MEV oracle and the fairness of the mechanism.</em></p>
<p><strong>Organization:</strong> <a href="https://ethresear.ch#h-1-motivation-3">Section 1</a> motivates the need for an in-protocol mechanism to handle block-space distribution as part of the “endgame” for Proof-of-Stake. <a href="https://ethresear.ch#h-2-enumeration-6">Section 2</a> enumerates five axes along which block-space distribution mechanisms may be measured, using a familiar set of questions: <em>who, what, when, where, how</em> (abbr. the <code>W^4H questions</code>). <a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> interrogates how the block builder is selected, focusing on the execution tickets model. <a href="https://ethresear.ch#h-4-extrapolation-18">Section 4</a> extrapolates by concluding and raising open questions that follow from the framework established.</p>
<p><strong>Structural note:</strong> This article is rather long for this format and has some technical elements. We encourage the reader to focus on the portion of the article they are most interested in:</p>
<ul>
<li>Sections <a href="https://ethresear.ch#h-1-motivation-3">1</a>, <a href="https://ethresear.ch#h-2-enumeration-6">2</a>, &amp; <a href="https://ethresear.ch#h-4-extrapolation-18">4</a> provide a broader perspective on the existing proposals and our proposed methodology for analyzing them.</li>
<li><a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> (which is <span class="math">\approx 44\%</span> of the content, but <a href="https://youtu.be/VDvr08sCPOc?t=111" rel="noopener nofollow ugc"><span class="math">100\%</span></a> of the math) provides a detailed analysis of allocation mechanisms enabled by the execution tickets design. This section can be read in sequence, in isolation, or skipped altogether – up to you!</li>
</ul>
<p><span class="math">\cdot</span><br />
<strong>Contents</strong></p>
<ol>
<li><a href="https://ethresear.ch#h-1-motivation-3"><strong>Motivation</strong></a><br />
<a href="https://ethresear.ch#h-1-what-4"><em>1) What</em></a><br />
<a href="https://ethresear.ch#Block-space-distribution-today"><em>Block-space distribution today through <code>mev-boost</code></em></a></li>
<li><a href="https://ethresear.ch#h-2-enumeration-6"><strong>Enumeration</strong></a><br />
<a href="https://ethresear.ch#the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7"><em>The elements of block-space distribution</em></a><br />
<a href="https://ethresear.ch#execution-tickets-and-other-animals-8"><em>Execution tickets and other animals</em></a><br />
<a href="https://ethresear.ch#applying-w4h-a-comparative-analysis-9"><em>Applying W^4H: a comparative analysis</em></a><br />
<a href="https://ethresear.ch#motivational-interlude-10"><em>Motivational interlude</em></a></li>
<li><a href="https://ethresear.ch#h-3-interrogation-11"><strong>Interrogation</strong></a><br />
<a href="https://ethresear.ch#preliminaries-12"><em>Preliminaries</em></a><br />
<a href="https://ethresear.ch#model-13"><em>Model</em></a><br />
<a href="https://ethresear.ch#familiar-allocation-mechanisms-14"><em>Familiar allocation mechanisms</em></a><br />
<a href="https://ethresear.ch#comparing-the-outcomes-15"><em>Comparing the outcomes</em></a><br />
<a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16"><em>Aside #1: Calculating equilibrium bids</em></a><br />
<a href="https://ethresear.ch#aside-2-tullock-contests-17"><em>Aside #2: Tullock Contests</em></a></li>
<li><a href="https://ethresear.ch#h-4-extrapolation-18"><strong>Extrapolation</strong></a></li>
</ol>
<p><span class="math">\cdot</span></p>
<h4><a class="anchor" href="https://ethresear.ch#related-work-2" name="related-work-2"></a><strong>Related work</strong></h4>
<ol>
<li><em>mev-boost &amp; relays</em>
<ul>
<li><a href="https://ethresear.ch/t/mev-boost-merge-ready-flashbots-architecture/11177"><em>MEV-Boost: Merge ready Flashbots Architecture</em></a>; Flashbots team</li>
<li><a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278"><em>Relays in a post-ePBS world</em></a>; Mike, Jon, Hasu, Tomasz, Chris, Toni</li>
</ul>
</li>
<li><em>mev-burn / mev-smoothing</em>
<ul>
<li><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>Burning MEV through block proposer auctions</em></a>; Domothy</li>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn – a simple design</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408"><em>Committee-driven MEV smoothing</em></a>; Francesco</li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384"><em>Dr. changestuff or: how I learned to stop worrying and love mev-burn</em></a>; Mike, Toni, Justin</li>
</ul>
</li>
<li><em>enshrined Proposer-Builder Separation (ePBS)</em>
<ul>
<li><a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980"><em>Two-slot proposer/builder separation</em></a>; Vitalik</li>
<li><a href="https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879"><em>Unbundling PBS: towards protocol-enforced proposer commitments (PEPC)</em></a>; Barnabé</li>
<li><a href="https://barnabe.substack.com/p/pbs" rel="noopener nofollow ugc"><em>Notes on Proposer-Builder Separation</em></a>; Barnabé</li>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>; Barnabé</li>
<li><a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710"><em>Why enshrine Proposer-Builder Separation?</em></a>; Mike, Justin</li>
<li><a href="https://ethresear.ch/t/epbs-design-constraints/18728"><em>ePBS design constraints</em></a>; Potuz</li>
<li><a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg" rel="noopener nofollow ugc"><em>Reconsidering the market structure of PBS</em></a>; Barnabé</li>
</ul>
</li>
<li><em>block-space futures</em>
<ul>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc"><em>Block vs. Slot Auction PBS</em></a>; Julian</li>
<li><a href="https://frontier.tech/ethereums-blockspace-future" rel="noopener nofollow ugc"><em>Opportunities and Considerations of Ethereum’s Blockspace Future</em></a>; Drew, Ankit</li>
<li><a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814" rel="noopener nofollow ugc"><em>When to sell your blocks</em></a>; Quintus, Conor</li>
</ul>
</li>
<li><em>execution tickets</em>
<ul>
<li><a href="https://www.youtube.com/watch?v=MtvbGuBbNqI" rel="noopener nofollow ugc"><em>Attester-proposer separation</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/execution-tickets/17944"><em>Execution tickets</em></a>; Justin, Mike</li>
<li><a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894"><em>Economic Analysis of Execution Tickets</em></a>; Jonah, Davide</li>
<li><a href="https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232"><em>Block-auction ePBS versus Execution Ticket</em></a>; Terence</li>
</ul>
</li>
</ol>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#h-1-motivation-3" name="h-1-motivation-3"></a>(1) – Motivation</h3>
<p>Before descending into this murky rabbit hole, let’s start by simply motivating the necessity of a block-space distribution mechanism. Validators in Proof-of-Stake protocols are tasked with producing and voting on blocks. The figure below, from Barnabé’s excellent “<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>,” describes these as “proposing” and “attesting” rights, respectively.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/d/7d85ca7f1812a5822490fa079365301c99733620.png" title="upload_72dad4dc4f8c77f0d57f8f126b3c2e46"><img alt="upload_72dad4dc4f8c77f0d57f8f126b3c2e46" height="219" src="https://ethresear.ch/uploads/default/optimized/3X/7/d/7d85ca7f1812a5822490fa079365301c99733620_2_690x219.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-what-4" name="h-1-what-4"></a>1) What</h4>
<p>(<span class="math">\uparrow</span> <a href="https://twitter.com/SBF_FTX/status/1591989554881658880?lang=en" rel="noopener nofollow ugc">important cultural ref</a>.)</p>
<p>A block-space distribution mechanism is the process by which the protocol determines the owner of the “proposing” or “block construction” rights. Proof-of-Stake protocols typically use some version of the following rules:</p>
<ul>
<li><strong>block-space (proposing) rights</strong> – A random validator is elected as the leader and permitted to create the next block.</li>
<li><strong>voting (attesting) rights</strong> – All validators vote during some time window for the block they see as the canonical head.</li>
</ul>
<p>Validators perform these tasks because they receive rewards for doing so. We categorize the rewards according to their origin in either the consensus layer (the issuance from the protocol – e.g., newly minted <code>ETH</code>) or the execution layer (transaction fees and MEV):</p>
<ol>
<li><strong>Consensus layer</strong><br />
a. <em>Attestation rewards</em> – see <a href="https://github.com/ethereum/annotated-spec/blob/160764ac180eca2cea3581f731ee96ac7098f9f7/phase0/beacon-chain.md#components-of-attestation-deltas" rel="noopener nofollow ugc">attestation deltas</a>.<br />
b. <em>Block rewards</em> – see <a href="https://github.com/ethereum/annotated-spec/blob/160764ac180eca2cea3581f731ee96ac7098f9f7/phase0/beacon-chain.md#rewards-and-penalties-1" rel="noopener nofollow ugc"><code>get_proposer_reward</code></a>.</li>
<li><strong>Execution layer</strong><br />
a. <em>Transaction fees</em> – see <a href="https://etherscan.io/gastracker" rel="noopener nofollow ugc">gas tracker</a>.<br />
b. <em>MEV (transaction ordering)</em> – see <a href="https://mevboost.pics/" rel="noopener nofollow ugc">mevboost.pics</a>.</li>
</ol>
<p>Rewards <code>1a</code>, <code>1b</code>, &amp; <code>2a</code> are well understood and “<a href="https://barnabe.substack.com/p/seeing-like-a-protocol" rel="noopener nofollow ugc">in the view</a>” of the protocol. MEV rewards present a more serious challenge because fully capturing the value realized by transaction ordering is difficult. Unlike the other rewards, even the amount of MEV in a block is unknowable for all intents and purposes (as a permissionless and pseudonymous system, it’s impossible to trace who controls each account and any corresponding offchain activity that may be profitable in tandem). MEV also changes dramatically over time (e.g., as a function of price volatility), resulting in execution layer rewards having a much higher variance than the consensus layer rewards. Further, the Ethereum protocol, as implemented, has no insight into the MEV being produced and extracted by its transactions. To improve protocol visibility into MEV, many mechanisms try to approximate the MEV in a given block; we refer to these as <em>MEV oracles</em>. Block-space distribution mechanisms generally have the potential to produce such an oracle, making the protocol “MEV-aware.”</p>
<p>This suggests the question, <em>why does the protocol care about being MEV-aware?</em> One answer: <strong>MEV awareness may increase the protocol’s ability to preserve the homogeneity of validator rewards, even if validators have varying degrees of sophistication.</strong> For example, if the protocol could accurately burn all MEV, then the validator incentives would be fully in the protocol’s view (just like <code>1a</code>, <code>1b</code>, &amp; <code>2a</code> above). Alternatively, a mechanism that shares all MEV among validators regardless of their sophistication (e.g., <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">mev-smoothing</a>) would seem to promote a larger, more diverse and decentralized validator set, while keeping the MEV rewards as an extra incentivization to stake. Without MEV awareness, the validators best equipped to extract or smooth MEV (e.g., due to relationships with block builders, proprietary algorithms/software, access to exclusive order flow, &amp; economies of scale) may earn disproportionately high rewards and exert significant centralization pressures on the protocol.</p>
<p>Ethereum protocol design strives to keep a decentralized validator set at all costs. It probably goes without saying, but for completeness: <strong>the protocol’s credible neutrality, censorship resistance, and permissionlessness are directly downstream of a decentralized validator set.</strong></p>
<h4><a class="anchor" href="https://ethresear.ch#block-space-distribution-today-5" name="block-space-distribution-today-5"></a>Block-space distribution today</h4>
<p>In Ethereum today, <a href="https://mevboost.pics/" rel="noopener nofollow ugc"><code>mev-boost</code></a> accounts for <span class="math">\approx 90\%</span> of all blocks. Using <code>mev-boost</code>, proposers (the validator randomly selected as the leader) sell their block-building rights to the highest paying bidder through an auction. The figure below demonstrates this flow (we exclude the <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">relays</a> because they functionally serve as an extension of the builders).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/7/b70bdfef2fd8dc26a478c2b870495ea39ebd07bc.png" title="upload_5f698b1a28978bd8f9779e596c471d9a"><img alt="upload_5f698b1a28978bd8f9779e596c471d9a" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/b/7/b70bdfef2fd8dc26a478c2b870495ea39ebd07bc_2_252x499.png" width="252" /></a></div><br />
.<br />
Proposers are incentivized to outsource their block building because builders (the canonical name for MEV-extracting agents specializing in sequencing transactions) pay them more than they would have earned had they built the block themselves. Circling back to our goal of “<strong>preserving the homogeneity of validator rewards in the presence of MEV</strong>,” we see that <code>mev-boost</code> allows access to the builder market for <em>all validators</em>, effectively preserving near-equivalent MEV rewards among solo stakers and professional staking service providers – great! But…<p></p>
<p>Of course, there is a but… <code>mev-boost</code> has issues that continue to rankle some of the Ethereum community. Without being exhaustive, a few of the negative side-effects of taking the <code>mev-boost</code> medicine are:</p>
<ul>
<li><strong>Relays</strong> – These <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">trusted-third parties</a> broker the sale of blocks between proposers and builders. The immense reliance on relays increases the fragility of the protocol as a whole, as demonstrated through <a href="https://collective.flashbots.net/t/disclosure-mitigation-of-block-equivocation-strategy-with-early-getpayload-calls-for-proposers/1705" rel="noopener nofollow ugc">repeated</a>, <a href="https://research.lido.fi/t/bloxroute-feb-6th-post-mortem/6586" rel="noopener nofollow ugc">incidents</a>, <a href="https://gist.github.com/benhenryhunter/5c397db3985a59d14a52816305a6c1b8" rel="noopener nofollow ugc">involving</a>, <a href="https://gist.github.com/benhenryhunter/7b7d9c9e3218aad52f75e3647b83a6cc" rel="noopener nofollow ugc">relays</a>. Further, since relays have no inherent revenue stream, more exotic (and closed-source) methods of capturing margins (e.g., <a href="https://bloxroute.com/pulse/introducing-the-validator-gateway-boost-your-ethereum-validator-rewards/" rel="noopener nofollow ugc">timing games as a service</a> and <a href="https://twitter.com/sui414/status/1778708084510302445" rel="noopener nofollow ugc">bid adjustments</a>) are being implemented.</li>
<li><strong>Out-of-protocol software is brittle</strong> – Beyond the relays, participation in the <code>mev-boost</code> market requires validators to run additional software. The standard suite for solo staking now involves running four binaries: (i) the consensus beacon node, (ii) the consensus validator client, (iii) the execution client, and (iv) mev-boost. Beyond the significant overhead for solo stakers, reliance on this software also provides another potential point of failure during hard forks. See the <a href="https://collective.flashbots.net/t/impact-of-the-prysm-invalid-signature-bug-on-the-mev-boost-ecosystem-at-the-shapella-fork/1623" rel="noopener nofollow ugc">Shapella incident</a> and the <a href="https://writings.flashbots.net/preparing-for-dencun" rel="noopener nofollow ugc">Dencun upgrade</a> for an example of the complexity induced by having more out-of-protocol software.</li>
<li><strong>Builder centralization and censorship</strong> – While this is likely <a href="https://vitalik.eth.limo/general/2021/12/06/endgame.html" rel="noopener nofollow ugc">inevitable</a>, builder centralization was accelerated by the mass adoption of <code>mev-boost</code>. <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">Three builders</a> account for <span class="math">\approx 95\%</span> of <code>mev-boost</code> blocks (<span class="math">85\%</span> of all Ethereum blocks). <code>mev-boost</code> implements an open-outcry, first-price, winner-takes-all auction, leading to high levels of builder concentration and <a href="https://ethresear.ch/t/game-theoretic-model-for-mev-boost-auctions-mma/16206">strategic</a>, <a href="https://ethresear.ch/t/bid-cancellations-considered-harmful/15500">bidding</a>. Without <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">inclusion lists</a> or another censorship-resistance gadget, builders have extreme influence over transaction inclusion and exclusion – see <a href="https://censorship.pics/" rel="noopener nofollow ugc">censorship.pics</a>.</li>
<li><strong>Timing games</strong> – While <a href="https://arxiv.org/abs/2305.09032" rel="noopener nofollow ugc">timing games</a> are known to be a fundamental issue in Proof-of-Stake protocols, <code>mev-boost</code> pushes staking service providers to compete on thin margins. Additionally, relays (who conduct <code>mev-boost</code> auctions on the proposer’s behalf) serve as sophisticated middlemen facilitating timing games. Thus, we have seen <a href="https://p2p.org/economy/unlock-p2p-orgs-mev-enhancement-feature/" rel="noopener nofollow ugc">marketing</a> endorsing playing timing games to boost the yield from staking with a specific provider.</li>
</ul>
<p><em>“OK, OK … blah blah … we have heard this story before … <a href="https://youtu.be/q8wJqMbr6eY?si=LVryerWbrw3_ge-I" rel="noopener nofollow ugc">tell me something I don’t know</a>.” (<span class="math">\leftarrow</span> h/t Barnabé for the aptly-named, 14k-views on youtube, musical reference.)</em></p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-enumeration-6" name="h-2-enumeration-6"></a>(2) – Enumeration</h3>
<p>Obligatory ‘stage-setting’ out of the way, let’s look a little more carefully at the ~essence~ of a block-space distribution mechanism.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/55cc9892e24d897856dff5e70b48fe8682903b6e.jpeg" title="upload_cdbf47258422c2a96ea2903ce113a113"><img alt="upload_cdbf47258422c2a96ea2903ce113a113" height="367" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/55cc9892e24d897856dff5e70b48fe8682903b6e_2_552x367.jpeg" width="552" /></a></div><br />
<sub><strong>^ “<a href="https://youtu.be/mvy4YH9--Vw?t=108" rel="noopener nofollow ugc"><em>Is that what I think it is?</em></a>”</strong></sub><p></p>
<h4><a class="anchor" href="https://ethresear.ch#the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7" name="the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7"></a>The <a href="https://en.wikipedia.org/wiki/Euclid%27s_Elements" rel="noopener nofollow ugc">elements</a> of block-space distribution</h4>
<p>Consider the game of acquiring block space; MEV incentivizes agents to participate, while the combination of in-protocol and out-of-protocol software defines the rules. When designing this game, what elements should be considered? To answer this question, we use a familiar rhetorical pattern of “who, what, when, where, &amp; how” (hopefully <a href="https://ethresear.ch#h-1-motivation-3">Section 1</a> sufficiently answered “why”), which we refer to as the <code>W^4H questions</code>. (<span class="math">\leftarrow</span> h/t Barnabé pt. 2 for the connection to “<a href="https://www.goodreads.com/book/show/22749723-who-gets-what-and-why" rel="noopener nofollow ugc"><em>Who Gets What – and Why</em></a>”).</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em></li>
<li><em><strong>What</strong> is the good that players are competing for?</em></li>
<li><em><strong>When</strong> does the game take place?</em></li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em></li>
<li><em><strong>How</strong> is the block builder chosen?</em></li>
</ul>
<p>These questions might seem overly simplistic, but when considered in isolation, each can be viewed as an axis in the design space to measure mechanisms. To demonstrate this, we highlight a few different species from the block-space distribution mechanism <a href="https://en.wikipedia.org/wiki/Genus" rel="noopener nofollow ugc">genus</a> that have been explored in the past. While they may feel disjointed and unrelated, their relationship is clarified by understanding how they answer the <code>W^4H questions</code>.</p>
<h4><a class="anchor" href="https://ethresear.ch#execution-tickets-and-other-animals-8" name="execution-tickets-and-other-animals-8"></a>Execution tickets and other animals</h4>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/5/05be4a7b2ce343036ba89733f9371dc1cbaa2b5b.jpeg" title="upload_23e73e8aae1d7223973af83053d41ebc"><img alt="upload_23e73e8aae1d7223973af83053d41ebc" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/0/5/05be4a7b2ce343036ba89733f9371dc1cbaa2b5b_2_328x500.jpeg" width="328" /></a></div><br />
<sub><strong>^ fantastic book.</strong></sub><p></p>
<p>We present a compendium of many different proposed mechanisms. Note that this is only a subset of the rather substantial literature around these designs – cf. <a href="https://notes.ethereum.org/@mikeneuder/infinite-buffet" rel="noopener nofollow ugc">infinite buffet</a>. For each of the following, we summarize only the key ideas (see <a href="https://ethresear.ch#related-work-2">related work</a> for more).</p>
<ul>
<li>Execution tickets
<ul>
<li><strong>Key ideas</strong> – Block building and proposing rights are sold directly through “tickets” issued by the protocol. Ticket holders are randomly sampled to become block builders with a fixed lookahead. The ticket holder has the authority to produce a block at the assigned slot.</li>
</ul>
</li>
<li>Block-auction PBS
<ul>
<li><strong>Key ideas</strong> – The protocol bestows block production rights through a random leader-election process. The selected validator can sell their block outright to the builder market or build it locally. The builder must ~commit to a specific block~ when bidding in the auction. <code>mev-boost</code> is an out-of-protocol instantiation of block-auction PBS; enshrined PBS (ePBS), as <a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980">originally presented</a>, is the in-protocol equivalent.</li>
</ul>
</li>
<li>MEV-burn/mev-smoothing
<ul>
<li><strong>Key ideas</strong> – A committee is tasked with enforcing a minimum value over the bid the proposer selects in an auction. By requiring the proposer to choose a “large enough” bid, an MEV oracle is created. The MEV is either <em>smoothed</em> between committee members or <em>burned</em> (smoothed over all <code>ETH</code> holders).</li>
</ul>
</li>
<li>Slot-auction PBS
<ul>
<li><strong>Key ideas</strong> – Similar to block-auction PBS but instead sells the <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">slot</a> to the builder market ~without~ requiring a commitment to a specific block – sometimes referred to as block space futures. By not requiring the builders to commit to a particular block, future slots may be auctioned off ahead of time rather than waiting until the slot itself.</li>
</ul>
</li>
<li>Partial-block auction
<ul>
<li><strong>Key ideas</strong> – Allows a more flexible unit for selling block-space. Instead of selling the full block or slot, allow proposers to sell <em>some</em> of their block, e.g., the top-of-block (which is the most valuable for arbitrageurs), while retaining the rest-of-block construction. Live in other Proof-of-Stake networks, e.g., Jito’s <a href="https://jito-labs.gitbook.io/mev/searcher-resources/block-engine" rel="noopener nofollow ugc">block engine</a> and Skip <a href="https://docs.skip.money/blocksdk/lanes/existing-lanes/mev" rel="noopener nofollow ugc">MEV lane</a>.</li>
</ul>
</li>
<li>APS-burn a.k.a. Execution Auction (nomenclature in flux &amp; the EA acronym has a bit of … <a href="https://en.wikipedia.org/wiki/Effective_altruism" rel="noopener nofollow ugc">baggage</a>)
<ul>
<li><strong>Key ideas</strong> – A brand new proposal from <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">Barnabé</a> which compels a proposer to auction off the block building and proposing rights ahead of time. The slot is sold ex-ante (a fixed amount of time in advance) without requiring a commitment to a specific block; a committee (à la mev-burn/smoothing) enforces the winning bid is sufficiently large.</li>
</ul>
</li>
</ul>
<p>We know, we know – it’s a lot to keep track of; it’s nearly a full-time job just to stay abreast of all these acronyms. But by comparing these proposals along the axes laid out by the <code>W^4H questions</code>, we can see how they all fit together as different parts of the same design space.</p>
<h4><a class="anchor" href="https://ethresear.ch#applying-w4h-a-comparative-analysis-9" name="applying-w4h-a-comparative-analysis-9"></a>Applying W^4H: a comparative analysis</h4>
<p>For each of the five <code>W^4H questions</code>, we describe different trade-offs made by the aforementioned proposals. For brevity, we don’t analyze each question for each proposal; we instead focus on highlighting key differences arising from each line of questioning.</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em>
<ul>
<li>With execution tickets, the protocol dictates the winner of the game by randomly choosing from the set of ticket holders.</li>
<li>With block-auction PBS, the proposer (protocol-elected leader) unilaterally chooses the winner of the game.</li>
<li>With mev-burn, the proposer still chooses the winner, but the winning bid is constrained by the committee, reducing the proposer’s agency.</li>
</ul>
</li>
<li><em><strong>What</strong> is the good that players are competing for?</em>
<ul>
<li>With block-auction PBS, the entire block is sold, but bids must commit to the block contents.</li>
<li>With slot-auction PBS, the entire block is sold, but without any specific block commitment.</li>
<li>With partial-block PBS, a portion of the block is sold.</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>With block-auction PBS, the auction takes place during the slot.</li>
<li>With slot-auction PBS, the auction may take place many slots (e.g., 32) ahead of time because there is no block-content commitment.</li>
<li>With execution tickets, the tickets are assigned to slots at a fixed lookahead after being sold ex-ante by the protocol (more on the ticket-selling model we use below).</li>
</ul>
</li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em>
<ul>
<li>With mev-burn/smoothing, a committee enforces that a sufficiently large bid is selected as the winner; this bid size is the oracle.</li>
<li>With execution tickets, the total money spent on tickets serves as the oracle.</li>
</ul>
</li>
<li><em><strong>How</strong> is the block builder chosen?</em>
<ul>
<li>In block-auction PBS, any outsourced block production has a winner-take-all allocation, with the highest bidder granted the block-building rights.</li>
<li>Within execution tickets, many different allocation mechanisms can be implemented. In the original proposal, for example, where a random ticket is selected, the mechanism is ‘proportional-to-ticket-count’; in this case, the highest paying bidder (whoever holds the most tickets) merely has the highest probability of being selected, meaning they are not guaranteed the block building rights.</li>
<li>If that (^) seems opaque, don’t worry. The entire following section is a deep dive into these different allocations.</li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#motivational-interlude-10" name="motivational-interlude-10"></a>Motivational interlude</h4>
<p>Before continuing, let’s review our original motivation for block-space distribution mechanisms:</p>
<blockquote>
<p><strong>Block-space distribution mechanisms aim to preserve the homogeneity of validator rewards in the presence of MEV.</strong></p>
</blockquote>
<p>This is a great grounding, but if that is our only goal, why not just continue using <code>mev-boost</code>? Well, remember that <code>mev-boost</code> has some negative side effects that we probably want the endgame protocol to be resilient against. We highlight four other potential design goals of a block-space distribution mechanism:</p>
<ol>
<li><em>Encouraging a wider set of builders to be competitive.</em></li>
<li><em>Allow validators and builders to interact trustlessly.</em></li>
<li><em>Incorporating MEV-awareness into the base layer protocol.</em></li>
<li><em>Removing MEV from validator rewards altogether.</em></li>
</ol>
<p>Note that while (1, 2, &amp; 3) appear relatively uncontroversial (*knock on wood*), (4) is more opinionated (and requires (3) as a pre-condition). The protocol may hope to eliminate MEV rewards from validator rewards as a means to ensure that the consensus layer rewards (what the protocol controls) more accurately reflect the full incentives of the system. This also ties into questions around staking macro-economics and the idea of <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">protocol</a>, <a href="https://notes.ethereum.org/@mikeneuder/iiii" rel="noopener nofollow ugc">issuance</a> – a much more politically-charged discussion. On the other hand, MEV rewards are a byproduct of network usage; MEV could instead be seen as a <a href="https://www.nano210.blog/infinite-blockspace-equilibrium/" rel="noopener nofollow ugc">value capture</a> mechanism for the native token. We aren’t trying to address these questions here but rather explore how different answers to them would shape the design of the mechanism.</p>
<p>What can we do at the protocol-design level to align with these desiderata? As laid out above, there are many trade-offs to consider, but in the following section, we examine “<em>How is the block builder chosen?</em>” to improve on some of these dimensions.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-interrogation-11" name="h-3-interrogation-11"></a>(3) – Interrogation</h3>
<p><strong>Editorial note:</strong> As mentioned earlier, this section is longer and more technical than the others – feel free to skip to <a href="https://ethresear.ch#h-4-extrapolation-18">Section 4</a> if you are time (or interest) constrained!</p>
<p><strong>Section goal:</strong> <em>To demonstrate the quantitative trade-off between MEV-oracle quality and the “fairness” of the two most familiar approaches to allocating block proposer rights, which we call <code>Proportional-all-pay</code> and <code>Winner-take-all</code>.</em></p>
<p>We aim to accomplish this with the following subsections:</p>
<ul>
<li><a href="https://ethresear.ch#preliminaries-12"><em>Preliminaries</em></a> – Motivate the fixed-price, unlimited-quantity execution ticket sale mechanism we use.</li>
<li><a href="https://ethresear.ch#model-13"><em>Model</em></a> - Introduce the notation needed to analyze the model.</li>
<li><a href="https://ethresear.ch#familiar-allocation-mechanisms-14"><em>Familiar allocation mechanisms</em></a> - Describe the <code>Proportional-all-pay</code> and <code>Winner-take-all</code> mechanisms using the established framework.</li>
<li><a href="https://ethresear.ch#comparing-the-outcomes-15"><em>Comparing the outcomes</em></a> - Calculate the resulting equilibria in a two-player example.</li>
<li><a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16"><em>Aside #1: Calculating equilibrium bids</em></a> - Derive the equilibria in the general case.</li>
<li><a href="https://ethresear.ch#aside-2-tullock-contests-17"><em>Aside #2: Tullock Contests</em></a> - Contextualize the model as a Tullock Contest and draw connections to the existing literature.</li>
</ul>
<p>Let’s <a href="https://youtu.be/GLsCR2RMBak?t=119" rel="noopener nofollow ugc">dig</a> in.</p>
<h4><a class="anchor" href="https://ethresear.ch#preliminaries-12" name="preliminaries-12"></a>Preliminaries</h4>
<p>Before diving into the space of allocation mechanisms made possible with execution tickets, we must first set up the model. Consider a protocol that sells execution tickets with the following rules:</p>
<ol>
<li>the price is fixed at <code>1 WEI</code>, and</li>
<li>unlimited tickets can be bought and sold from the protocol.</li>
</ol>
<p><strong>Note:</strong> <em>this version of execution tickets is effectively equivalent to creating two disjoint staking mechanisms – one each for attesting and proposing. Small changes in the design, e.g., not allowing tickets to be resold to the protocol, may have massive implications for how the market plays out, but that isn’t the focus of this article. Instead, we narrowly explore the question of block-space allocation, given an existing ticket holder set.</em></p>
<p>Notably, the set of block producers is disjoint (from the protocol’s perspective) from the set of attesters – individuals must select which part of the protocol they participate in by deciding whether to stake or buy tickets. The secondary ticket market may evolve as a venue for selling the building rights just in time to the builder market (as is done in <code>mev-boost</code> today).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e4f36ef0b6e6e5d80c4a923d9465bf74212af039.png" title="upload_45a1fa23182dd6a28c2c07dc2479f150"><img alt="upload_45a1fa23182dd6a28c2c07dc2479f150" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e4f36ef0b6e6e5d80c4a923d9465bf74212af039_2_486x499.png" width="486" /></a></div><br />
<span class="math">\cdot</span><br />
Separately, builders may choose to interact directly with the protocol by buying execution tickets themselves, but their capital may be better utilized as active liquidity, capturing arbitrage across trading venues. Thus, they may prefer buying block space on the secondary market during the just-in-time auction instead.<p></p>
<p>Why restrict ourselves to this posted-price-unlimited-supply mechanism? Two reasons:</p>
<ol>
<li><em>It’s not clear that a sophisticated market could even be implemented in the consensus layer.</em> The clients are optimized to allow any validator with consumer-grade hardware to participate in the network. This desideratum may be incompatible with fast auctions, bonding curves, or other possible ticket-selling mechanisms. Questions around how many tickets are sold, the MEV around onchain ticket-sale inclusion (meta-MEV?!), and the timing (and timing games) of ticket sales seem closer to execution layer concerns than something that could reasonably be implemented by Ethereum consensus while keeping hardware requirements limited.</li>
</ol>
<blockquote>
<p>“<em>One may imagine the inclusion of ET market-related transactions to possibly induce MEV, whether these transactions are included in the beacon block or the execution payload.</em>” – <strong>Barnabé in</strong> “<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>.”</p>
</blockquote>
<ol start="2">
<li><em>Even if (a big if) the protocol ~could~ implement a more rigid ticket-selling market, the design space for such a mechanism is immense.</em> Many potential pricing mechanisms have been discussed, e.g., bonding curves, 1559-style dynamic pricing, auctions, etc.; making general claims about these remains outside the scope of this post.</li>
</ol>
<p>Therefore, we focus on the “unlimited, 1 <code>WEI</code> posted-price” version of execution tickets, where the protocol internalizes minimal complexity. With this framing, we can ask the question that is probably <a href="https://youtu.be/5KNEZJ6KkLI?t=53" rel="noopener nofollow ugc">burning</a> you up inside, “<em>given a set of execution ticket holders, how should the winner be selected?</em>” … sounds easy enough, right? Turns out there is a good deal we can say, even with such a seemingly simple question; let’s explore a few different options.</p>
<h4><a class="anchor" href="https://ethresear.ch#model-13" name="model-13"></a>Model</h4>
<p>Consider the repeated game of buying execution tickets to earn MEV rewards for your investment.</p>
<ul>
<li>During each period, each player effectively submits a bid, which is the number of tickets they buy. Denote the vector of bids by <span class="math">\mathbf{b}</span>, where <span class="math">b_i</span> is the bid of the <span class="math">i^{th}</span> player.</li>
<li>Each player has a valuation for winning the block production rights. Denote the vector of valuations by <span class="math">\mathbf{v}</span>, where <span class="math">v_i</span> is the value of the <span class="math">i^{th}</span> player.</li>
<li>At each time step, an allocation mechanism determines each player’s allocation based on the vector of bids. Assuming bidders are risk-neutral (i.e., don’t care between winning 2 <code>ETH</code> with probability <span class="math">0.5</span> vs. 1 <code>ETH</code> with probability <span class="math">1</span>), we can equivalently say that they are each allocated “some portion” of the block, which can be alternatively be interpreted as “the probability that they win a given block.” In an <span class="math">n</span> player game, let <span class="math">x: \mathbf{b} \rightarrow [0,1]^n</span> denote the map implementing an allocation mechanism, where <span class="math">x_i(\mathbf{b})</span> is the allocation of the <span class="math">i^{th}</span> player, under the constraint that <span class="math">\sum_i x_i(\mathbf{b}) =1</span> (i.e., the mechanism fully allocates).</li>
<li>Each player’s payment is collected at each round. Let <span class="math">p: \mathbf{b} \rightarrow \mathbb{R}_{\geq 0}^n</span> denote the payment rule determined by the set of bids, where <span class="math">p_i(\mathbf{b})</span> is the payment of the <span class="math">i^{th}</span> player.</li>
<li>The utility function of each player in the game is, <span class="math">U_i(\mathbf{b}) = v_i x_i(\mathbf{b}) - p_i(\mathbf{b})</span>. The intuition is that “a player’s utility is their value for winning multiplied by the amount they won, less their payment.”</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#familiar-allocation-mechanisms-14" name="familiar-allocation-mechanisms-14"></a>Familiar allocation mechanisms</h4>
<p>Consider two (quite different) possible mechanisms.</p>
<p><code>Proportional-all-pay</code> (a slight modification to the <a href="https://ethresear.ch/t/execution-tickets/17944">original</a> execution tickets proposal)</p>
<ul>
<li>During each round, all players submit a bid. Denote the vector of bids by <span class="math">\mathbf{b}</span>.</li>
<li>The probability that a bid wins the game is the value of the bid divided by the sum of all the values of the bids,</li>
</ul>
<div class="math">
x_i(\mathbf{b}) = \frac{b_i}{\sum_j b_j}.
</div>
<ul>
<li>Each player pays their bid, no matter the outcome of the game (hence “all-pay”), <span class="math">p_i(\mathbf{b}) = b_i.</span><a href="https://ethresear.ch#fn1dst"><span class="math">^{[1]}</span></a><a href="https://ethresear.ch" name="fn1"></a></li>
</ul>
<p><code>Winner-take-all</code> (the current implementation of PBS)</p>
<ul>
<li>During each round, all players submit a bid. Denote the vector of bids by <span class="math">\mathbf{b}</span>.</li>
<li>The highest bidder wins the game, so <span class="math">x_i(\mathbf{b}) = 1</span> if <span class="math">\max(\mathbf{b}) = b_i</span> and <span class="math">x_i(\mathbf{b}) = 0</span> otherwise (where ties are broken in favor of the lower index bidder, say).</li>
<li>Only the winning player pays the value of their bid, so <span class="math">p_i(\mathbf{b}) = b_i</span> if <span class="math">\max(\mathbf{b}) = b_i</span> and <span class="math">p_i(\mathbf{b}) = 0</span> otherwise (same tie-breaking as above).<a href="https://ethresear.ch#fn2dst"><span class="math">^{[2]}</span></a><a href="https://ethresear.ch" name="fn2"></a></li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#comparing-the-outcomes-15" name="comparing-the-outcomes-15"></a>Comparing the outcomes</h4>
<p>To demonstrate the different outcomes from these two mechanisms, consider the two-player game where <code>Player 1</code> has a valuation of <span class="math">v_1 = 4</span> and <code>Player 2</code> has a valuation of <span class="math">v_2 = 2.</span> (We consider a complete information setting in which the individual values are common knowledge. To see how the equilibria bid is calculated and for extended discussion, see <a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16">Aside 1</a>.)</p>
<ul>
<li><strong><code>Proportional-all-pay</code> outcome:</strong>
<ul>
<li>Equilibrium Bids: <span class="math">\qquad\,\,\,\;\;\; b_1 = 8/9</span>, <span class="math">\,b_2 = 4/9</span></li>
<li>Equilibrium Allocations: <span class="math">\;\;\; x_1 = 2/3</span>, <span class="math">x_2 = 1/3</span></li>
<li>Equilibrium Payments: <span class="math">\;\;\;\; p_1 = 8/9</span>, <span class="math">\,p_2 = 4/9</span></li>
</ul>
</li>
</ul>
<p>This all should feel intuitively correct; with <span class="math">v_1 = 2 \cdot v_2</span> (<code>Player 1</code> has <code>2x</code> the value for the block), <code>Player 1</code> bids, receives and pays twice as much as <code>Player 2</code>.</p>
<ul>
<li><strong><code>Winner-take-all</code> outcome:</strong>
<ul>
<li>Equilibrium Bids: <span class="math">\qquad\,\,\,\;\;\; b_1 = 2+\epsilon</span>, <span class="math">b_2 = 2</span></li>
<li>Equilibrium Allocations: <span class="math">\;\;\; x_1 = 1</span>, <span class="math">\quad\;\; x_2 = 0</span></li>
<li>Equilibrium Payments: <span class="math">\;\;\;\,\, p_1 = 2+\epsilon</span>, <span class="math">p_2 = 0</span></li>
</ul>
</li>
</ul>
<p>This is pretty different. <code>Player 1</code> bids and pays just over <code>Player 2</code>’s value (we use <span class="math">\epsilon</span> to denote a small amount), receiving the entire allocation. <code>Player 2</code> receives nothing and pays nothing.<a href="https://ethresear.ch#fn3dst"><span class="math">^{[3]}</span></a><a href="https://ethresear.ch" name="fn3"></a></p>
<p>Now consider the “revenue” (or the sum of the bids collected by the mechanism) generated from each case:</p>
<ul>
<li><strong><code>Proportional-all-pay</code> revenue:</strong> <span class="math">b_1 + b_2 = 4/3</span></li>
<li><strong><code>Winner-take-all</code> revenue:</strong> <span class="math">\qquad\quad\,\,\,\;\;\;\; b_1 = 2+\epsilon</span></li>
</ul>
<p><code>Winner-take-all</code> has better revenue, corresponding to a more accurate MEV oracle (and thus more MEV burned or smoothed by the protocol) than <code>Proportional-all-pay</code>. Intuitively, by allocating block-production rights to players with lower values (as <code>Proportional-all-pay</code> does), we forgo revenue we would have received had we simply allocated the entire rights to the player with the highest value. We point the interested reader to <a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16">Aside 1</a> for a more complete treatment.</p>
<p>Another factor to consider is the “fairness” or “distribution” of the allocation mechanism. For example, suppose we agree on the metric: <span class="math">\text{fairness} = \sqrt{x_1 \cdot x_2}</span> (we use the geometric mean because if <span class="math">x_1 + x_2</span> has a fixed sum, the geometric mean is maximized at <span class="math">x_1 = x_2</span> and zero if either <span class="math">x_1,x_2</span> is zero). Now, let’s look at the fairness outcomes of the two candidate mechanisms:</p>
<ul>
<li><strong><code>Proportional-all-pay</code> fairness:</strong> <span class="math">\sqrt{1/3 \cdot 2/3} \approx 0.471</span></li>
<li><strong><code>Winner-take-all</code> fairness:</strong> <span class="math">\qquad\qquad\;\,\;\sqrt{1 \cdot 0} = 0</span></li>
</ul>
<p>Here, the “performance” of the two mechanisms flips – the <code>Winner-take-all</code> is <em>less fair</em> because <code>Player 2</code> has no chance of winning the game with a lower value. In the <code>Proportional-all-pay</code>, <code>Player 2</code> can hope to win some blocks despite bidding a lower value. As another example, consider the case where <span class="math">v_1=v_2+\epsilon</span>. The <code>Winner-take-all</code> mechanism allocates all the rights to <code>Player 1</code>, while the <code>Proportional-all-pay</code> splits the rights approximately in half.</p>
<blockquote>
<p>Brief note: why might the protocol care about fairness? In a decentralized protocol, a single actor having too much power undermines the credible neutrality of the system. As such, the protocol may be willing to “pay” (in the form of reduced revenue) to ensure that a resource is more evenly distributed among players. Alternatively, we could consider this a measure of “entropy” or even simply randomness being injected into the outcome of the game to try to reduce the influence the most dominant player can have.</p>
</blockquote>
<p>This leads to the punchline from this small example: <strong>a fundamental trade-off exists between MEV-oracle quality and fairness.</strong> The <code>Proportional-all-pay</code> mechanism (and hence the original execution tickets proposal) is fairer because both players win the game with some probability, incentivizing them each (but more importantly, the higher value player) to <a href="https://en.wikipedia.org/wiki/Bid_shading" rel="noopener nofollow ugc">shade</a> their bid accordingly, lowering the revenue, and thus the MEV-oracle accuracy, of the mechanism. The first price mechanism elicits higher bids since bidders only pay if they win the entire block production rights, increasing the revenue, but this <code>Winner-take-all</code> dynamic makes the allocation less fair.</p>
<p><em>Open question: is <code>Proportional-all-pay</code> an “optimal” Sybil-proof mechanism?</em> In the permissionless setting, we only consider Sybil-proof mechanisms, where a player doesn’t benefit from splitting their bid into multiple identities. We posit that the <code>Proportional-all-pay</code> mechanism sits in the <a href="https://en.wikipedia.org/wiki/Habitable_zone" rel="noopener nofollow ugc">Goldilock’s Zone</a> of a Sybil-proof mechanism that gets both good revenue/MEV-oracle accuracy and fairness. We leave as an interesting open problem to determine the extent to which the <code>Proportional-all-pay</code> mechanism’s “optimality” (e.g., we were unable to find another Sybil-proof mechanism that dominates it in both revenue and fairness).</p>
<h4><a class="anchor" href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16" name="aside-1-calculating-equilibrium-bids-16"></a>Aside <span class="hashtag-raw">#1</span> – Calculating equilibrium bids</h4>
<p><a href="https://ethresear.ch#h-4-extrapolation-18">Convenience link</a> to skip to the conclusion for the less-keen reader <img alt=":wink:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wink.png?v=12" title=":wink:" width="20" /></p>
<p>In the numerical example above, we provide the equilibrium bids for the <code>Winner-take-all</code> and <code>Proportional-all-pay</code> mechanisms without proof. How can these be determined generally (e.g., continuing to assume that bidders’ values are common knowledge)?<a href="https://ethresear.ch#fn4dst"><span class="math">^{[4]}</span></a><a href="https://ethresear.ch" name="fn4"></a></p>
<p>The <code>Winner-take-all</code> is the familiar <a href="https://www.econport.org/econport/request?page=man_auctions_firstpricesealed" rel="noopener nofollow ugc">First Price Auction</a> setting. In such auctions, the complete information Pure-Nash equilibrium has the two highest-value bidders, each bidding the second-highest bidder’s value, with every other agent bidding below this. In effect, we expect that the highest-value bidder always wins while paying the second highest bidder’s value (we represent this simply as <span class="math">b_1=b_2+\epsilon</span>, though you could equivalently tie-break in favor of the higher-value player).</p>
<p>In the <code>Proportional-all-pay</code> setting, each player has the utility,</p>
<div class="math">
\begin{align}
U_i (\mathbf{b}) &amp;= v_i \cdot x_i(\mathbf{b}) - b_i \\
&amp;= v_i \cdot \frac{b_i}{\sum_j b_j} - b_i.
\end{align}
</div>
<p>To determine the existence of a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" rel="noopener nofollow ugc">Pure Nash Equilibrium</a>, we consider each player’s first- and second-order conditions. Let <span class="math">\mathbf{b}^*</span> denote the candidate equilibrium set of bids.</p>
<ol>
<li><strong>First-order condition</strong>: <span class="math">\partial U_i / \partial b_i (\mathbf{b^*}) = 0</span> (or <span class="math">\partial U_i / \partial b_i (\mathbf{b^*}) \leq 0, \;\forall i \text{ s.t. } b^*_i=0</span>.)
<ul>
<li>Intuitively, this condition checks a non-zero-bidding player is (to first order) locally indifferent to small changes in its bid.</li>
</ul>
</li>
<li><strong>Second-order condition</strong>: <span class="math">\partial^2 U_i / \partial b_i^2 &lt; 0</span>
<ul>
<li>Intuitively, this condition ensures that the utility function is concave, implying that locally best responses are globally best for all players.</li>
</ul>
</li>
</ol>
<p>In our simple two-player example in the <code>Proportional-all-pay</code> setting, we have the following.</p>
<div class="math">
\begin{align}
\frac{\partial U_1}{\partial b_1}(\mathbf{b}) = \frac{v_1 b_2}{(b_1 + b_2)^2} - 1 = 0 \; , \quad \frac{\partial U_2}{\partial b_2}(\mathbf{b}) = \frac{v_2 b_1}{(b_1 + b_2)^2} - 1 = 0
\end{align}
</div>
<p>This system can be solved to find the equilibrium bids, <span class="math">\mathbf{b}^*</span>,</p>
<div class="math">
\begin{align}
b^*_1 = \frac{v_1^2 v_2}{(v_1 + v_2)^2}\; , \quad b^*_2 = \frac{v_2^2 v_1}{(v_1 + v_2)^2}.
\end{align}
</div>
<p>For our toy example, we have <span class="math">v_1=4, \; v_2=2 \implies b_1^* = 32/36, \; b_2^* = 16/36</span>. We can verify our first-order conditions</p>
<div class="math">
\begin{align}
\frac{4 \cdot 16/36}{16/9} - 1 = 0 \; , \quad \frac{2 \cdot 32/36}{16/9} - 1 = 0 \quad \checkmark
\end{align}
</div>
<p>The second-order conditions can also be verified – this is left as an exercise for the reader <img alt=":wink:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wink.png?v=12" title=":wink:" width="20" /></p>
<h4><a class="anchor" href="https://ethresear.ch#aside-2-tullock-contests-17" name="aside-2-tullock-contests-17"></a>Aside <span class="hashtag-raw">#2</span> – Tullock Contests</h4>
<p><a href="https://youtu.be/lL2ZwXj1tXM?t=60" rel="noopener nofollow ugc">Last chance</a> to <a href="https://ethresear.ch#h-4-extrapolation-18">skip to the conclusion</a>. (If you continue, by definition, you are the “interested reader” – <a href="https://www.youtube.com/watch?v=SC4xMk98Pdc&amp;t=35s" rel="noopener nofollow ugc">congrats</a>.)</p>
<p>The model described above is established in the algorithmic game theory literature as a <a href="https://www.chapman.edu/ESI/wp/GeneralizedTullockContest-Sheremeta.pdf" rel="noopener nofollow ugc">Tullock Contest</a> – named for Gordon Tullock, who explored the idea in his seminal work, “<a href="https://link.springer.com/chapter/10.1007/978-3-540-79182-9_6" rel="noopener nofollow ugc"><em>Efficient Rent Seeking</em></a>.” He motivates this study by considering situations where investment is made before the outcome is known and where the investments might not transfer easily between participants, e.g., political spending.</p>
<blockquote>
<p>“<em>Suppose, for example, that we organize a lobby in Washington for the purpose of raising the price of milk and are unsuccessful. We cannot simply transfer our collection of contacts, influences, past bribes, and so forth to the steel manufacturers’ lobby. In general, our investments are too specialized, and, in many cases, they are matters of very particular and detailed goodwill to a specific organization. It is true that we could sell the steel lobby our lobbyists with their connections and perhaps our mailing list. But presumably, all these things have been bought by us at their proper cost. Our investment has not paid, but there is nothing left to transfer.</em>” – <strong>Gordon Tullock (1980)</strong></p>
</blockquote>
<p>This allocation mechanism has been applied in the previous crypto literature as well. Back in 2018 (ancient history in crypto-terms), Arnosti and Weinberg wrote “<a href="https://arxiv.org/abs/1811.08572" rel="noopener nofollow ugc"><em>Bitcoin: A natural oligopoly</em></a>,” which demonstrates that even small operating cost advantages among miners in a Proof-of-Work system lead to surprisingly concentrated equilibria. Similarly, Bahrani, Garimidi, and Roughgarden (these names sound familiar :D) explored the centralization effects of heterogeneity in block building skill in “<a href="https://arxiv.org/abs/2401.12120" rel="noopener nofollow ugc"><em>Centralization in Block Building and Proposer-Builder Separation</em></a>.” There appears to be a deep relationship between permissionless crypto-economic systems, where anti-Sybil mechanisms typically require financial investment for participation, and Tullock Contests – more on this <code>Soon™</code> (maybe).</p>
<h3><a class="anchor" href="https://ethresear.ch#h-4-extrapolation-18" name="h-4-extrapolation-18"></a>(4) – Extrapolation</h3>
<p>Phew, thanks for hanging in there; let’s take stock of what we learned. <strong><a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> demonstrates the fundamental trade-off between MEV-oracle accuracy and fairness of an instantiation of an execution ticket mechanism.</strong> A protocol may be willing to *pay* (in the form of reduced revenue) for more distribution and entropy with the goal of improving and maintaining the protocol’s credible neutrality. Further, using the model to derive equilibrium bids helps inform how we may expect agents to respond to various allocation and payment rules. <a href="https://youtu.be/Hm3JodBR-vs?t=21" rel="noopener nofollow ugc">Neat</a> – our framework led to some interesting and hopefully helpful insights! Maybe we can extend it to other problems in the space as well?</p>
<p>Further questions that this specific model may help answer (returning to three of our <code>W^4 questions</code>):</p>
<ul>
<li><em><strong>What</strong> is the good that players are competing for?</em>
<ul>
<li>Can we extend the model dimensionality, allowing different players to have different values for portions of the block (e.g., an arbitrageur may disproportionately value the top of a block but have zero value for the remainder)?</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>How does the MEV-oracle accuracy change if the game takes place far ahead of time versus during the slot itself (e.g., pricing future expected MEV versus present realizable MEV)?</li>
</ul>
</li>
<li><em><strong>How</strong> is the block builder chosen?</em>
<ul>
<li>Are there other Sybil-proof mechanisms that dominate <code>Proportional-all-pay</code> in both revenue and fairness?</li>
<li>Can we more formally characterize the fundamental trade-offs between revenue and fairness?</li>
<li>Given the Sybil-proofness constraint, what alternative allocation and payment rules should be explored (e.g., Tullock contests where the allocation rule is parameterized by <span class="math">\alpha&gt;1</span> where <span class="math">x_i = b_i^\alpha / \sum_j b_j^\alpha</span>), and can we identify the optimal choice?</li>
</ul>
</li>
</ul>
<p>Zooming back out, other versions of the <code>W^4H questions</code> may require different models to reason about.</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em>
<ul>
<li>In the committee-enforced version of these mechanisms, how could collusive behavior emerge?</li>
<li>If the just-in-time block auction continues to take place out-of-protocol, should we explicitly describe the secondary market?</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>How critical is network latency when considering lookahead block-space sales versus same-slot? Is it worth modeling the <a href="https://dl.acm.org/doi/pdf/10.1145/42282.42283" rel="noopener nofollow ugc">partially-synchronous</a> setting?</li>
<li>How do block builder valuations change if multi-slot MEV is feasible?</li>
</ul>
</li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em>
<ul>
<li>If it comes from the committee, are there incentives for committee members to behave dishonestly?</li>
<li>Do such incentives depend on whether protocol-captured MEV is burned or smoothed?</li>
</ul>
</li>
</ul>
<p>As per usual, open questions abound, but we hope (a) <code>W^4H questions</code> help expand the understanding of block-space distribution mechanisms and (b) the deep dive into allocation mechanisms helps inform the potential design space of execution tickets.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f4ceb270ae099c612cbb2afb4958a9bea1b42d1.jpeg" title="upload_a24cdf5b513fb4e410700573687adcd6"><img alt="upload_a24cdf5b513fb4e410700573687adcd6" height="493" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f4ceb270ae099c612cbb2afb4958a9bea1b42d1_2_690x493.jpeg" width="690" /></a></div><br />
<sub><strong>^ <a href="https://youtu.be/WSLMN6g_Od4?t=92" rel="noopener nofollow ugc">The world once we figure out MEV.</a></strong></sub><p></p>
<p>Excited to be here with y’all.</p>
<p><em>— made with <img alt=":heart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/heart.png?v=12" title=":heart:" width="20" /> by mike, pranav, &amp; dr. tim roughgarden.</em></p>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#footnotes-19" name="footnotes-19"></a>footnotes</h3>
<p><span class="math">^{[1]}</span><a href="https://ethresear.ch" name="fn1dst"></a>: The “all-pay” feature is made possible by burning the price paid for each ticket. <a href="https://ethresear.ch#fn1"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[2]}</span><a href="https://ethresear.ch" name="fn2dst"></a>: The “winner-pay” version could be done by refunding all non-winning ticket holders their payment at the end of each round. <a href="https://ethresear.ch#fn2"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[3]}</span><a href="https://ethresear.ch" name="fn3dst"></a>: As mentioned earlier, simply refunding the non-winning tickets instantiates the “winner-pays” property. <a href="https://ethresear.ch#fn3"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[4]}</span><a href="https://ethresear.ch" name="fn4dst"></a>: This is primarily for tractability in calculating equilibria analytically. Although a strong assumption, it’s not unreasonable in the context of lookahead auctions where bidders might have established prior distributions on their competitor’s valuations. We also view the insights from studying the complete-information equilibria as valuable heuristics for how we may expect these mechanisms to behave in practice. <a href="https://ethresear.ch#fn4"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 12:42:54 +0000</pubDate>
</item>
</channel>
</rss>