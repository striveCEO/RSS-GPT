<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Ethereum Research - Latest topics</title>
<link>https://ethresear.ch/latest</link>


<item>
<title>Execution Consensus Separation</title>
<link>https://ethresear.ch/t/execution-consensus-separation/19964</link>
<guid>https://ethresear.ch/t/execution-consensus-separation/19964</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、共识层、执行层、应用层、多提案者共识（MCP）

总结:<br />
文章讨论了执行一致性分离在解决以太坊上的交易优先权执行问题（MEV）中的关键作用。首先，需要改善共识层的抗审查能力，引入多提案者共识（MCP），允许多个提案者同时提出交易，增强交易的包容性。其次，执行层需实现延迟执行和确定性调度规则，确保交易按照规则有序进行。最后，应用层应发展为无序机制，例如通过链上拍卖避免价格猜测导致的价值损失。这些升级将使以太坊对开发者和用户更加友好，研究者可共同推进这一安全协议的改进。 <div>
<h2><a class="anchor" href="https://ethresear.ch#execution-consensus-separation-1" name="execution-consensus-separation-1"></a>Execution Consensus Separation</h2>
<p><strong></strong></p><div class="lightbox-wrapper"><strong><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b9eb4b7bcec14c8b9a8aee948a332d9d48013e4.jpeg" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b9eb4b7bcec14c8b9a8aee948a332d9d48013e4_2_500x500.jpeg" width="500" /></a></strong></div><br />
MEV is fundamentally about control. The proposer has control of which transactions make it into blocks and which order they appear in. In other words MEV is all about censorship and reordering. All of the goals on the Ethereum roadmap related to MEV are therefore impossible without fixing these things. The good news is that fixing these things is possible, the bad news is that the solution requires us to work together to study and prove the security of some meaningful upgrades to both consensus and execution.<p></p>
<p>Current work on the <a href="https://x.com/VitalikButerin/status/1741190491578810445" rel="noopener nofollow ugc">“Scourge” section</a> of the <a href="https://ethereum.org/en/roadmap/" rel="noopener nofollow ugc">Ethereum roadmap</a> has been siloed. People work on individual problems and sometimes lose the broader scope of what we are ultimately trying to achieve. <a href="https://ethresear.ch/t/epbs-design-constraints/18728">ePBS</a>, <a href="https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474" rel="noopener nofollow ugc">Inclusion Lists</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV Burn</a>, <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">Distributed Block Building</a>, and <a href="https://x.com/VitalikButerin/status/1741190491578810445" rel="noopener nofollow ugc">Application-layer MEV minimization</a>, are examples of ideas that require censorship resistance and control over ordering, but we haven’t yet addressed the pre-requisites. Solving these allows us to kill 5 birds with 1 stone. But to do this we need to think from first principles and work on the underlying root causes rather than tinkering with a thin veneer on top of the protocol.</p>
<p>Solving MEV at the protocol level requires buy in from all three levels of the chain:</p>
<ol>
<li><strong>Consensus Layer:</strong> Multiple concurrent proposers.</li>
<li><strong>Execution Layer:</strong> Delayed execution and deterministic scheduling rules.</li>
<li><strong>Application Layer:</strong> Order-agnostic applications.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#consensus-layer-2" name="consensus-layer-2"></a>Consensus layer</h2>
<p>We cannot get anywhere without vastly improved censorship resistance at the consensus layer. This is what allows us to hold auctions and prevent censorship of competing bids. The root cause of Ethereum’s weak censorship resistance is the fact that only a single entity can include transactions during each 12 second slot. <strong>Multiple concurrent proposers (MCP)</strong> fixes this problem. Instead of coming to consensus on an ordered block of transactions from a single block proposer, each of the K proposers propose a set of transactions at the same time. The protocol then aggregates these proposals using a <strong>common subset</strong> primitive (or a similar algorithm, this is an active area of research), yielding an unordered set of transactions which are to be included in the block.</p>
<p>MCP solves the problem of censorship-resistant inclusion, achieving the goals of <a href="https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474" rel="noopener nofollow ugc">Inclusion Lists</a> in a more natural way. The output is an unordered set of transactions, so it does not solve the problem of reordering. That will be the responsibility of the execution layer.</p>
<p>MCP is an area of active study and we encourage people to get involved. See SMG <a href="https://mechanism.org/spec/01" rel="noopener nofollow ugc">SPEC-01</a> for a theoretical description of MCP. Work is currently underway at SMG to formally specify MCP and create a proposed implementation of a gadget for use in the Ethereum protocol. Contact us if you are interested in working on this.</p>
<h2><a class="anchor" href="https://ethresear.ch#execution-layer-3" name="execution-layer-3"></a>Execution layer</h2>
<p>Ethereum’s execution layer must be upgraded to solve the problem of transaction reordering. To do this, we must delay the calculation of the state root to the next block so that the execution layer has time to implement a deterministic ordering rule.</p>
<p>Once it has the transactions, the execution layer has a new important job: figuring out how to order them. To do this, we need to select a <strong>deterministic scheduling rule</strong>. This is an area of active study where we encourage people to get involved. There are many promising candidates: <a href="https://www.paradigm.xyz/2024/06/priority-is-all-you-need" rel="noopener nofollow ugc">priority fee ordering</a>, as-needed execution, and <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">distributed block building</a>. We will elaborate on the last two in an upcoming article.</p>
<p>With delayed execution and a deterministic scheduling rule, Ethereum’s execution layer will determine the order of transactions in a block, allowing it to achieve the same goals as <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">distributed block building</a> and <a href="https://ethresear.ch/t/epbs-design-constraints/18728">ePBS</a> in a more natural way. In addition, since the ordering is enforced by the logic of the protocol, not by the goodwill of any particular validator, the protocol can burn all the fees at this stage, achieving the goals of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV Burn</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#application-layer-4" name="application-layer-4"></a>Application layer</h2>
<p>Assuming we succeed in the above upgrades, Ethereum’s application layer will be free to upgrade their applications to be natively MEV-resistant while remaining totally onchain. We call the class of things they will do <strong>order-agnostic applications</strong> or order-agnostic mechanisms.</p>
<p>For example take the problem of liquidation MEV. For the sake of argument, suppose we have 1000 ETH that needs to be liquidated for DAI. We don’t know what the appropriate price is for the ETH, so we have two options: we can guess the right price and have a posted price available to the first person who claims it, which is how Compound and Aave work, and leads to tremendous value leaked to liquidation races, reducing UX. Or, we can hold a Dutch auction, which leads to slightly less value leakage, but doesn’t allow us to clear the distressed debt right away. But now, with MCP and deterministic scheduling, these protocols can simply hold an onchain auction for the right to liquidate 1000 ETH and elicit the price that way.</p>
<p>Order agnostic application design has a number of benefits, and there are many more examples of places where MEV leaks that can be solved. Future posts will elaborate on this.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-5" name="conclusion-5"></a>Conclusion</h2>
<p>The successful implementation of these upgrades will result in a much friendlier Ethereum for both developers and users. The first step of this research program is fleshing out and proving the security of a multi proposer design with simultaneous release. Other blockchains have multiple proposers, but are not designed in the same way or for the same purpose. If you are a consensus researcher interested in working on this topic, please reach out, we have funding available for this.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/execution-consensus-separation/19964">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 19:09:20 +0000</pubDate>
</item>
<item>
<title>Fork Choice compliance test suites &amp; test generator</title>
<link>https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954</link>
<guid>https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954</guid>
<content:encoded><![CDATA[
<div> 关键词：Fork Choice、测试生成器、测试套件、性能优化、未来步骤

总结:<br />
Fork Choice合规性测试生成器已完成初步实施，能够为客户端开发团队提供测试模板。已经生成了三个测试套件（Tiny、Small和Standard），涵盖不同规模的测试目的。尽管生成Extended测试套件需要时间，但支持多进程以提高效率。目前的测试速度较慢，未来将优化性能并增加模型灵活性，计划进行覆盖率导向的模糊测试和新的测试向量格式。整体目标是简化测试采用并确保协议的正确实现。 <div>
<p>This is a preliminary announcement, we’ll officially announce during the next All Core Devs call.</p>
<p>We (TxRx team, ConsenSys) have implemented a Fork Choice compliance test generator as well as have generated Fork Choice compliance test suites.</p>
<p>Overall F/C compliance testing methodology is described <a href="https://hackmd.io/@ericsson49/fork-choice-implementation-vs-spec-testing" rel="noopener nofollow ugc">here</a>.</p>
<p>In this report we briefly describe the results of the initial implementation phase (i.e. the F/C test generator and F/C test suites).  A more detailed description of the work is TBD.</p>
<p>This work was supported by a grant from the Ethereum Foundation.</p>
<h1><a class="anchor" href="https://ethresear.ch#implementation-status-1" name="implementation-status-1"></a>Implementation status</h1>
<h2><a class="anchor" href="https://ethresear.ch#test-generator-2" name="test-generator-2"></a>Test generator</h2>
<p>The initial version of the Fork Choice tests generator is implemented and currently available as a draft <a href="https://github.com/ethereum/consensus-specs/pull/3831" rel="noopener nofollow ugc">consensus-specs PR</a>. We have been focusing on minimizing efforts for client implementer teams to adopt the generated tests. The only a small change to the existing <a href="https://github.com/ethereum/consensus-specs/tree/dev/tests/formats/fork_choice" rel="noopener nofollow ugc">FC test format</a> is the addition of a <a href="https://github.com/ericsson49/eth2.0-specs/tree/fc-compliance2/tests/formats/fork_choice#checks-step" rel="noopener nofollow ugc">new check</a>, which is safe to ignore initially.</p>
<h2><a class="anchor" href="https://ethresear.ch#test-suites-3" name="test-suites-3"></a>Test suites</h2>
<p>We have developed test generation parameters for three suites at the moment.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Test suite</th>
<th>size</th>
<th>Purpose</th>
<th>Status</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tiny</td>
<td>135 tests</td>
<td>Demonstration, smoke testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1dWbkJY27fhOVX8i4aUuZ7VBkH3P_Vr1i/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Small</td>
<td>1472 tests</td>
<td>Initial adoption, smoke testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1EAIeTL5F3zelXK5pBkSLuawJjuLWQx3r/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Standard</td>
<td>13240 tests</td>
<td>Main testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1_56JObwYWHARgm5QYmE4vrkcLEru854G/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Extended</td>
<td>about 100K tests</td>
<td>Extended testing</td>
<td>TBD</td>
<td></td>
</tr>
</tbody>
</table>
</div><p><strong>Note</strong>: We are able to generate the Extended test suite. However, it will take significant time (about a week), therefore, we have delayed actual test suite generation until it will be demanded.</p>
<p>It should be possible to generate test suites for any fork (Altair, Capella, Deneb) and preset (mainnet or minimal). However, test generation for mainnet is very slow. We have tested minimal/altair and minimal/deneb.</p>
<p>Test generation currently is slow (about 10-15 seconds per test on average). However, a multiprocessing mode is supported (about 2 seconds per test on Apple M1). Generation of the Standard test suite takes about 8 hours (multiprocessing mode) or two days (single process mode).</p>
<p>The reasons of slow performance are known and are to be alleviated in future. Currently, our top priority is to simplify adoption of the new test suites.</p>
<h2><a class="anchor" href="https://ethresear.ch#testing-the-tests-4" name="testing-the-tests-4"></a>Testing the tests</h2>
<p>We have run the generated tests against <a href="https://github.com/Consensys/teku" rel="noopener nofollow ugc">Teku</a>, using Teku test runner and against the official executable Fork Choice spec (minimal/deneb), using a simple Python <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_run.py" rel="noopener nofollow ugc">test runner</a>.</p>
<h1><a class="anchor" href="https://ethresear.ch#test-generation-approach-5" name="test-generation-approach-5"></a>Test generation approach</h1>
<p>The test generation approach is a mix of model-based and fuzz testing.</p>
<p>Principles:</p>
<ul>
<li>the Fork Choice spec is virtually “decomposed” into two parts: topological sorting of events and actual event processing</li>
<li>tests are generated for the event processing part, the topological sorting part is addressed via event shuffling (time shift plus drop/duplication)</li>
<li>models are used to describe the spec aspects that we want to cover. There are two flavors: trees of various shapes (for block trees and super-majority link trees) and predicates to be covered (<code>filter_block_tree</code>)</li>
<li>for each model there can be multiple solutions, each solution can be seen as a template (e.g. SM link tree + block tree) which can be instantiated in multiple ways (varying validator actions)</li>
<li>each test case can be mutated multiple times</li>
</ul>
<p>Tests are generated with four steps:</p>
<ol>
<li>Models (implemented using MiniZinc), describing abstract coverage aspects that we want to cover. Currently there are three models: <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/SM_links.mzn" rel="noopener nofollow ugc">SM link</a> (super-majority link) tree model, <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/Block_tree.mzn" rel="noopener nofollow ugc">Block tree</a> model and <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/Block_cover3.mzn" rel="noopener nofollow ugc">Block cover</a> model.</li>
<li>For each model a set of solutions is produced. The models are parameterized, which affects the size of solution set generated.
<ul>
<li>SM link and block tree solutions are combined into a single block tree.</li>
</ul>
</li>
<li>Each solution is instantiated using two test instantiators (<a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/block_tree.py" rel="noopener nofollow ugc">block tree</a> and <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/block_cover.py" rel="noopener nofollow ugc">block cover</a>). The instantiation is randomized, i.e. a coin is flipped on each decision point. This results in a complete Fork Choice test case (i.e. <em>anchor state</em> plus a sequence of <em>tick</em> | <em>block</em> | <em>attestation</em> | <em>attester_slashing</em> events).</li>
<li>Each test case is mutated via <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/mutation_operators.py" rel="noopener nofollow ugc">mutation</a> (shuffling) operators. Currently, there are thee mutation operator: time shift, drop and duplicate (with consequent shifting).</li>
</ol>
<p>The models are developed manually.<br />
Solutions to the models are produced with a special <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/generate_test_instances.py" rel="noopener nofollow ugc">generator</a>.<br />
Test instantiators and mutations are performed with <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_gen.py" rel="noopener nofollow ugc">test_gen.py</a>.</p>
<p>After tests are generated, one can validate the produced test steps using <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_run.py" rel="noopener nofollow ugc">test_run.py</a> script, which executes the steps using the pyspecs, performing prescribed checks.</p>
<h1><a class="anchor" href="https://ethresear.ch#test-structure-6" name="test-structure-6"></a>Test structure</h1>
<div class="md-table">
<table>
<thead>
<tr>
<th>Test group</th>
<th>size (standard suite)</th>
<th>parameters (solutions + variations + mutations)</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Block tree</td>
<td>4096 tests</td>
<td>1024*2*(1+1)</td>
<td>focus on trees of varying shapes</td>
</tr>
<tr>
<td>Block weight</td>
<td>2048 tests</td>
<td>8*64*(1+3)</td>
<td>focus on producing block trees with varying weights</td>
</tr>
<tr>
<td>Shuffling</td>
<td>2048 tests</td>
<td>8*4*(1+63)</td>
<td>focus on shuffling/mutation operators</td>
</tr>
<tr>
<td>Attester slashing</td>
<td>1024 tests</td>
<td>8*16*(1+7)</td>
<td>focus on attester slashing</td>
</tr>
<tr>
<td>Invalid messages</td>
<td>1024 tests</td>
<td>8*32*(1+3)</td>
<td>focus on invalid messages</td>
</tr>
<tr>
<td>Block cover</td>
<td>3000 tests</td>
<td>60*5*(1+9)</td>
<td>cover various combinations of predicates from the <code>filter_block_tree</code> method</td>
</tr>
</tbody>
</table>
</div><h1><a class="anchor" href="https://ethresear.ch#future-steps-7" name="future-steps-7"></a>Future steps</h1>
<ul>
<li>improve performance. Performance is adequate right now (for the initial adoption phase). But is the main blocker otherwise.</li>
<li>more flexible test generation. More and better models, better instantiators, better mutation operators.</li>
<li>coverage-guided fuzzing</li>
<li>new test vector format (don’t need full test cases for fuzz testing, as need to compare against the FC spec anyway)</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 20:00:49 +0000</pubDate>
</item>
<item>
<title>Ethereum Node Message Propagation Bandwidth Consumption</title>
<link>https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952</link>
<guid>https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952</guid>
<content:encoded><![CDATA[
<div> 关键词：GossipSub, Bandwidth consumption, Hermes, Optimization, Ethereum P2P network

总结:
GossipSub在以太坊P2P网络中的性能研究发现，SENT_IHAVE和RECV_IHAVE消息消耗了大量带宽，分别占总带宽的23.4%和10%，对出站和入站流量影响显著。研究建议改进机制以减少重复消息，这将节省约42%的总带宽。尽管Hermes节点配置非标准，但研究结果证实了优化空间。与其他节点的比较显示，当前以太坊节点的带宽使用率相对较低，仍有提升余地。总的来说，这项工作旨在通过深入了解GossipSub的性能，为协议优化提供依据。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-tldr-1" name="summary-tldr-1"></a>Summary &amp; TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io </a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the <a class="inline-onebox" href="https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921">Number Duplicate Messages in Ethereum's Gossipsub Network</a>, in this post we investigate bandwidth consumption at the GossipSub level, i.e., bandwidth consumption for message propagation. The target of the study is to identify the protocol components that consume the biggest share of network bandwidth. The study has been co-authored by <a class="mention" href="https://ethresear.ch/u/cortze">@cortze</a> and <a class="mention" href="https://ethresear.ch/u/yiannisbot">@yiannisbot</a>.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer. </a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions. The results reported here are from a 3.5hr trace.</p>
<p><strong>Study Description:</strong> The distributed nature of p2p systems makes them generally less effective in computational, latency, and bandwidth consumption. This is due to the extra interactions between nodes needed to organize a p2p network without a central authority that bridges between peers. Thus, taking care of processes, such as peer or content discovery, content sharing, and message broadcasting often become a challenge, or bottleneck.</p>
<p>Ethereum is not different in that respect. Message propagation takes a large portion of the network bandwidth used by a node in the Ethereum network. This study investigates bandwidth consumption at the GossipSub level. The target is to identify the protocol components that consume the biggest share of network bandwidth.</p>
<p><strong>TL;DR:</strong> Despite the fact that the configuration of our <code>Hermes</code> node, which, in this case, doesn’t represent a standard node in the Ethereum network, the bandwidth consumption numbers of GossipSub validate that there’s plenty of space for optimization.</p>
<p>We observed that a significant portion of bandwidth is spent on <code>SENT_IHAVE</code> messages (23.4% of the total bandwidth and 30% of the total outgoing bandwidth) and <code>RECV_IHAVE</code> messages (10% of the total bandwidth, and 42% of the total inbound bandwidth).</p>
<p>More than anything, these findings validate the improvement recommendations made during our previous study on the “Effectiveness of Gossipsub’s gossip mechanism”: <a class="inline-onebox" href="https://ethresear.ch/t/gossip-iwant-ihave-effectiveness-in-ethereums-gossipsusb-network/19686">Gossip IWANT/IHAVE Effectiveness in Ethereum's Gossipsusb network</a></p>
<p>Taking into account that a node doesn’t only receive duplicated messages but also generates duplicates to others, we strongly recommend pushing the <a href="https://github.com/libp2p/specs/pull/560" rel="noopener nofollow ugc">GossipSub1.2</a> initiative, as it will effectively eliminate the bandwidth wasted on receiving or generating duplicates, which amounts to ~42% of total bandwidth.</p>
<h1><a class="anchor" href="https://ethresear.ch#results-on-bandwidth-consumption-2" name="results-on-bandwidth-consumption-2"></a>Results on Bandwidth Consumption</h1>
<blockquote>
<p><img alt=":eyes:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/eyes.png?v=12" title=":eyes:" width="20" /> NOTES: The bandwidth usage displayed in this study is limited to:</p>
<ul>
<li>The <code>Holesky</code> network</li>
<li>The GossipSub RPC calls</li>
<li>The following GossipSub topics:
<ul>
<li><code>beacon_block</code></li>
<li><code>beacon_aggregate_and_proof</code></li>
<li><code>sync_commmittee_contribution_and_proof</code></li>
<li><code>attester_slashing</code></li>
<li><code>proposer_slashing</code></li>
<li><code>voluntary_exit</code> * (check <code>Hermes</code> issue → <a class="inline-onebox" href="https://github.com/probe-lab/hermes/issues/24" rel="noopener nofollow ugc">Broadcasting of invalid `voluntary_exit` messages to mesh peers · Issue #24 · probe-lab/hermes · GitHub</a>)</li>
<li><code>bls_to_execution_change</code></li>
</ul>
</li>
<li>The bandwidth of <code>SENT_IHAVE</code> and <code>RECV_IHAVE</code> RPC calls has been calculated based on the number of bytes per <code>topic</code>  strings and <code>msg_ids</code> that were inside.</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#netin-vs-netout-3" name="netin-vs-netout-3"></a>NetIn vs NetOut</h2>
<p>The study starts with a general overview of what is the ratio of sent vs received bandwidth consumption. The following graph shows that on the <code>Hermes</code> node, the biggest share of the bandwidth comes from the data that we send out to the connected peers.</p>
<p>The total outbound bandwidth is around 3 to 4 times higher than the inbound. Note that <code>Hermes</code> differs from a standard node in that it keeps more peer connections (around 250 peers). This clearly has a significant impact on bandwidth usage. That said, although the numbers are not representative of the bandwidth usage of a normal node in absolute terms, the percentage split still represents that of a normal node.</p>
<p>Narrowing down, we observe a ratio of 700-800 KB/s for outgoing traffic and 200 KB/s for incoming traffic.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4fb2e194b5b97ea9f84092740d059ad4447d2061.jpeg" title="bandwidth-in-out"><img alt="bandwidth-in-out" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4fb2e194b5b97ea9f84092740d059ad4447d2061_2_517x309.jpeg" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#bandwidth-based-on-each-event-type-4" name="bandwidth-based-on-each-event-type-4"></a>Bandwidth based on each event type</h2>
<p>GossipSub sends multiple types of messages with different purposes. From control messages to keep the mesh stable to pure messages or gossip  <code>IHAVE</code> / <code>IWANT</code>  messages to ensure that the host didn’t miss any message. Each of these message types requires sending RPC calls, adding up to the total of sent and received network traffic.</p>
<p>The following graphs isolate the bandwidth attributed to each of the events. The first one shows the raw KB/s over time, and the second one shows the percentage of each event over the aggregated total.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/3/b352576dc2b9350a99470bde3eb0710d0e710d3c.jpeg" title="bandwidth-by-event"><img alt="bandwidth-by-event" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/3/b352576dc2b9350a99470bde3eb0710d0e710d3c_2_517x309.jpeg" width="517" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/b/ab8bda76fba67303a9b9991902f5ff1805c63175.jpeg" title="bandwidth-ratio-by-event"><img alt="bandwidth-ratio-by-event" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/a/b/ab8bda76fba67303a9b9991902f5ff1805c63175_2_517x309.jpeg" width="517" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#percentage-table-5" name="percentage-table-5"></a>Percentage Table</h3>
<pre><code>| Event | % of total BW | % of Received BW | % of Sent BW |
| --- | --- | --- | --- |
| RECV_GRAFT | 0.000367 | 0.001565 | ———————— |
| RECV_IHAVE | 9.974349 | 42.537746 | ———————— |
| RECV_IWANT | 2.368042 | 10.099021 | ———————— |
| RECV_MSG  (duplicated) | 7.347250 | 31.333920 | ———————— |
| RECV_MSG | 3.640691 | 15.526507 | ———————— |
| RECV_PRUNE | 0.002973 | 0.012678 | ———————— |
| RECV_SUBS | 0.114559 | 0.488562 | ———————— |
| SENT_GRAFT | 0.002863 | ———————— | 0.003740 |
| SENT_IHAVE | 23.404913 | ———————— | 30.573967 |
| SENT_IWANT | 0.094569 | ———————— | 0.123536 |
| SENT_MSG | 53.049257 | ———————— | 69.298539 |
| SENT_PRUNE | 0.000164 | ———————— | 0.000214 |
| SENT_SUBS | 0.000003 | ———————— | 0.000004 |
</code></pre>
<p>From the above graphs, we can observe that:</p>
<ul>
<li>The <code>SENT_MSG</code> event is the one that consumes the most network traffic, with a total of 53% of the total network traffic and 69% of the total sent traffic.<br />
It has a spiky oscillation between 500 to 700 KB/s, and it is clearly the most bandwidth consuming event.<br />
It is hard to define which is the ratio of duplicates that all those sent messages generate on the remote side. However, we could assume that it would follow a similar pattern to the <code>RECV_MSG</code> one (2 duplicate bytes per 1 original byte).</li>
<li>Surprisingly, the <code>SENT_IHAVE</code> event follows <code>SENT_MSG</code>s in terms of consumed bandwidth with a total of 23.4% of the total bandwidth and 30% of the total outgoing bandwidth. Interestingly, subscribing to topics with a high frequency of messages (even if they are small in size), does have an impact on the bandwidth that we use sending those <code>IHAVE</code> messages.<br />
Each <code>IHAVE</code> is limited to <code>5,000</code> message IDs; however, with a message ID of 40 bytes, it still adds up to a maximum of 200KBs in message IDs on every heartbeat (0.7s in the case of Ethereum).</li>
<li><code>RECV_IHAVES</code> represent 10% of the total bandwidth, and 42% of the total inbound bandwidth, with an inbound network bandwidth requirement of 100KB/s.</li>
<li>The above two points showcase that, far from being negligible on the overall value they provide, the total bandwidth used on <code>IHAVE</code> messages represents almost 400KB/s, consuming 23% of the total outgoing bandwidth and more than 40% of the incoming bandwidth.</li>
<li>The <code>RECV_MSG</code> events remain in the fourth position with a representation of 11% of the total consumed bandwidth, where only 3.6% belong to unique or original messages, and the remaining 7.3% belong to duplicates. In terms of the overall inbound bandwidth, they represent 15% and 31%, respectively, for original and duplicated received messages.</li>
<li>On a much lower ratio, the whole list of <code>RECV_IWANT</code> messages stays within a lower 2.3% of the total bandwidth usage, which represents 10% of the total received bytes.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#comparison-with-live-nodes-6" name="comparison-with-live-nodes-6"></a>Comparison with live nodes</h2>
<p>In order to validate the previous measurements taken from the GossipSub module at <code>Hermes</code>, we’ve compared the bandwidth usage ratios with standard running Ethereum nodes:</p>
<ul>
<li>Local Prysm node at home setup (Holesky) reports an average received network traffic of 386KB/s and a sent network traffic of 580KB/s.<br />
Although the numbers might be slightly different, these measurements take the whole traffic of the Beacon Node docker container, which includes:
<ul>
<li>Peer discovery</li>
<li>Requests/Responses like <code>beacon_blocs</code> or <code>blobs</code> by range or by root</li>
</ul>
</li>
</ul>
<p>The MigaLabs <a href="https://monitoreth.io/node_metrics#network-in-out" rel="noopener nofollow ugc">public dashboard</a> at <a href="https://monitoreth.io/node_metrics" rel="noopener nofollow ugc">monitor.eth</a> shows slightly bigger bandwidth usage than the ones we measured. However, it is unclear whether the measurement includes the Execution Layer. The reported bandwidth reports an average of 290KB/s inbound and 1.2MB/s outbound, although it doesn’t include many data points (5 points per hour) and the variation is noticeable.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7cf74da4a25ce8b98d757eeaebf56696d2c6aa6.jpeg" title="migalabs"><img alt="migalabs" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7cf74da4a25ce8b98d757eeaebf56696d2c6aa6_2_517x315.jpeg" width="517" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-7" name="conclusions-and-takeaways-7"></a>Conclusions and takeaways</h1>
<p>Despite the fact that the configuration of our <code>Hermes</code> node, which, in this case, doesn’t represent a standard node in the Ethereum network, the bandwidth consumption numbers of GossipSub validate that there’s plenty of space for optimization.</p>
<p>We observed that <strong>a significant portion of bandwidth is spent on <code>SENT_IHAVE</code> (23.4% of the total bandwidth and 30% of the total outgoing bandwidth) and <code>RECV_IHAVE</code> (10% of the total bandwidth, and 42% of the total inbound bandwidth)</strong>.</p>
<p>More than anything, these findings validate the improvement recommendations made during our previous study on the “Effectiveness of Gossipsub’s gossip mechanism”: <a class="inline-onebox" href="https://ethresear.ch/t/gossip-iwant-ihave-effectiveness-in-ethereums-gossipsusb-network/19686">Gossip IWANT/IHAVE Effectiveness in Ethereum's Gossipsusb network</a></p>
<p>Taking into account that a node doesn’t only receive duplicated messages but also generates duplicates to others, we strongly recommend pushing the <a href="https://github.com/libp2p/specs/pull/560" rel="noopener nofollow ugc">GossipSub1.2</a> initiative, as it will effectively eliminate the bandwidth wasted on receiving or generating duplicates, which amounts to ~42% of total bandwidth.</p>
<p>Even currently though, the network bandwidth usage of a host in the Ethereum network (around 300 KB/s inbound and 1.1 MB/s outbound, including the EL) still constitutes a small percentage of the <a href="https://fairinternetreport.com/research/internet-speed-by-country/" rel="noopener nofollow ugc">average household</a> bandwidth availability, which varies between 8MB/s and 26MB/s depending on the region.</p>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 14:39:15 +0000</pubDate>
</item>
<item>
<title>Fork Choice Attacks and Protections in EPBS</title>
<link>https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951</link>
<guid>https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、fork choice attack、proposer boost、builder boost、ex-anti attack

总结:
本文探讨了ePBS（增强版持久拜占庭容错）中的分叉选择攻击，重点关注新的分叉选择提升参数设计。文章分析了两种主要攻击类型（后抗攻击和外抗攻击），以及在引入builder块后，ePBS中出现的新攻击情景，如攻击者与建设者合谋的情况。作者提到，尽管存在削弱的防御，但攻击者需要更高的恶意比例才能成功，例如40%的proposer boost和20%的attacker committee。文章还讨论了各种攻击的动机、优势和潜在后果，以及相应的防范措施，包括Reveal Boost和Withheld Boost。最后，文章提出了可能的改进方向，如考虑网络同步性和多槽活度的影响。 <div>
<h2><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h2>
<p>This post explores fork choice attacks through the perspective of ePBS, focusing on the new fork choice boost parameters and the rationale behind their design. We’ll begin by examining why these parameters are crucial, followed by a review of the existing designs. For background reading, I recommend reading <a href="https://ethresear.ch/t/payload-boosts-in-epbs/18769">Payload Boosts in ePBS</a> by Potuz. Additionally, for a deeper understanding of how the LMD GHOST fork choice operates today, consider Ben Edgington’s section on fork choice in his book, <a href="https://eth2book.info/capella/part3/forkchoice/" rel="noopener nofollow ugc">Upgrading Ethereum</a>. Let’s dive in!</p>
<h4><a class="anchor" href="https://ethresear.ch#references-2" name="references-2"></a>References</h4>
<p><a href="https://ethresear.ch/t/payload-boosts-in-epbs/18769">Payload boosts in ePBS</a> - Feb/2024 By Potuz<br />
<a href="https://ethresear.ch/t/sandwitch-attacks-on-epbs/19538/1">Sandwitch attacks on ePBS</a> - May/2024 By Potuz</p>
<h2><a class="anchor" href="https://ethresear.ch#fork-choice-attacks-today-3" name="fork-choice-attacks-today-3"></a>Fork choice attacks today</h2>
<p>We analyze these scenarios from both the attacker’s and the victim’s perspectives, focusing on two consecutive proposal slots, each with distinct proposers. Two primary types of attacks can emerge:</p>
<ol>
<li>The proposer of slot <span class="math">n+1</span> attacks the proposer of slot <span class="math">n</span>.</li>
<li>The proposer of slot <span class="math">n</span> attacks the proposer of slot <span class="math">n+1</span>.</li>
</ol>
<p>To clarify, by “attack,” we mean an attempt to reorg the block out of the canonical chain. The motives behind such a reorg typically include:</p>
<ol>
<li>Stealing the content of the block.</li>
<li>Increasing the time available to build the block, making a 24-second block more valuable than a 12-second one.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#post-anti-attack-4" name="post-anti-attack-4"></a>Post-anti attack</h3>
<p>The first type of attack is a post-anti attack, where the proposer of slot <span class="math">n+1</span> attempts to reorg the block from slot <span class="math">n</span>. In this scenario, the proposer of <span class="math">n+1</span> utilizes the <a href="https://eth2book.info/capella/part3/forkchoice/phase0/#proposer-boost" rel="noopener nofollow ugc">proposer boost</a> to gain an advantage and potentially reorg the block from slot <span class="math">n</span>. Currently, the proposer boost is set at 40%. This means that as long as the block at slot <span class="math">n</span> receives votes from more than 40% of the beacon committee, it is safe against a reorg. Typically, we define the percentage of the beacon committee that belongs to the attacker as <span class="math">\delta</span>. An attacker can successfully reorg a block if <span class="math">\delta &gt; 1 - PB</span>, which is 60% under today’s parameters.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/f/3f93dac13fced8dbaa43115f19cd6ae45668406d.png" title="Screenshot 2024-06-26 at 12.57.24 PM"><img alt="Screenshot 2024-06-26 at 12.57.24 PM" height="297" src="https://ethresear.ch/uploads/default/optimized/3X/3/f/3f93dac13fced8dbaa43115f19cd6ae45668406d_2_690x297.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#ex-anti-attack-5" name="ex-anti-attack-5"></a>Ex-anti attack</h3>
<p>The second type of attack is known as the ex-anti attack, where the proposer of slot <span class="math">n</span> attempts to reorg the block from slot <span class="math">n+1</span>. This type of attack is inherently difficult to pull off because the proposer boost grants a 40% advantage to the block at slot <span class="math">n+1</span>. To successfully carry out this attack, the attacker’s beacon committee must withhold their attestations and block then release them synchronously which occurs shortly after the block at slot <span class="math">n+1</span> is published. To reorg the block at slot <span class="math">n+1</span>, the attacker’s beacon committee support must exceed the proposer boost. We can assert that an attacker can reorg a block if <span class="math">\delta &gt; PB</span>, which is 40% under today’s parameter.</p>
<p>It is worth mentioning in ex-anti attack, attackers who propose multiple consecutive slots have an added advantage. For two slots, the effectiveness of the attack can be simplified to the expression <span class="math">\delta / 2 &gt; PB</span>, requiring only 20% of the stake per slot to reorg an honest block.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/ccb28f1581907f015d5780dae95dd78444ba59d8.png" title="Screenshot 2024-06-26 at 12.57.38 PM"><img alt="Screenshot 2024-06-26 at 12.57.38 PM" height="340" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/ccb28f1581907f015d5780dae95dd78444ba59d8_2_690x340.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#fork-choice-attacks-in-epbs-6" name="fork-choice-attacks-in-epbs-6"></a>Fork choice attacks in ePBS</h2>
<p>In the ePBS model, the introduction of a <strong>builder block between two proposer blocks</strong> complicates the landscape of potential attacks beyond what we see today. This addition expands the array of possible attack scenarios:</p>
<h3><a class="anchor" href="https://ethresear.ch#pre-epbs-scenarios-7" name="pre-epbs-scenarios-7"></a>Pre-ePBS Scenarios:</h3>
<ol>
<li><strong>Proposer <span class="math">n+1</span> attacking proposer <span class="math">n</span></strong> - This scenario concerns post-anti reorg safety.</li>
<li><strong>Proposer <span class="math">n</span> attacking proposer <span class="math">n+1</span></strong> - This scenario concerns ex-anti reorg safety.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#post-epbs-scenarios-8" name="post-epbs-scenarios-8"></a>Post-ePBS Scenarios:</h3>
<ol>
<li><strong>Proposer of <span class="math">n+1</span> and builder of <span class="math">n</span> collude and attack proposer of <span class="math">n</span></strong> - This scenario concerns proposer post-anti reorg safety.</li>
<li><strong>Proposer and builder of <span class="math">n</span> collude and attack proposer of <span class="math">n+1</span></strong> - This scenario concerns proposer ex-anti reorg safety.</li>
<li><strong>Proposer of <span class="math">n+1</span> and <span class="math">n</span> collude and attack builder of <span class="math">n</span></strong> - This scenario introduces builder safety, including reorg safety and withholding safety.</li>
</ol>
<p>Before we go into the specific attack scenarios under the ePBS framework, it’s important to establish the incentives for honest builder behavior. Similar to the proposer boost, builders are also incentivized through boosts for honest actions through <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054">payload timeliness committee</a>.</p>
<ul>
<li><strong>Reveal Boost (<span class="math">RB</span>)</strong>: Awarded to builders who timely reveal their payloads.</li>
<li><strong>Withheld Boost (<span class="math">WB</span>)</strong>: Granted if a builder, feeling unsafe about revealing the payload, opts to release a withheld message. This boost gives weight to the parent block of the committed consensus block.</li>
</ul>
<p>These boosts also ensure both builder <strong>reveal</strong> and <strong>withhold</strong> safety. Builder reveal safety means that if the builder acted honestly and revealed a payload in a timely fashion (as attested by the PTC), then the revealed payload should be on-chain. Builder withhold safety means that if a beacon block containing a builder’s header is withheld or revealed late, then that beacon block should not be the canonical head of the blockchain in the view of honest validators.</p>
<p>To ensure clarity and maintain focus throughout our discussion, we will designate the boosts as follows: Reveal Boost (<span class="math">RB</span>), Withheld Boost (<span class="math">WB</span>), and Proposer Boost (<span class="math">PB</span>). The specific values of these boosts will be displayed towards the end of the post. Now, let’s explore the first scenario: the proposer post-anti attack in ePBS.</p>
<h3><a class="anchor" href="https://ethresear.ch#proposer-post-anti-attack-9" name="proposer-post-anti-attack-9"></a>Proposer post-anti attack</h3>
<p>As you may have noted, this scenario is similar to the post-anti attack today, except that the builder of <span class="math">n</span> colludes with the proposer of <span class="math">n+1</span>. We also assume that a portion of the beacon committee is part of the malicious team, represented by <span class="math">\delta</span>. The post-anti attack is successful if <span class="math">WB + PB + \delta &gt; 1 - \delta</span>. This indicates that post-anti attack resistance is weaker in ePBS due to the added power of the withheld boost from the colluding builder.</p>
<p>Let’s examine the benefits for the attacker in a successful attack:</p>
<ul>
<li>The block at <span class="math">n+1</span> gains two slots worth of transactions by reorg out <span class="math">n</span>, resulting in more time and more transactions, thereby increasing its block value.</li>
<li>Since <span class="math">n</span>'s payload was revealed as withheld, and both <span class="math">n</span>'s builder and <span class="math">n+1</span>'s proposer collude, there is no opportunity to steal <span class="math">n</span>'s payload transaction content. They are all on the same team.</li>
<li>From <span class="math">n</span>'s proposer’s perspective, the loss includes the opportunity to propose a beacon block, and from the protocol’s perspective, it results in the loss of one slot worth of consensus liveness.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/c/bceef4d59d54e6590addac9fc886b98f4d419f29.png" title="Screenshot 2024-06-26 at 12.57.48 PM"><img alt="Screenshot 2024-06-26 at 12.57.48 PM" height="225" src="https://ethresear.ch/uploads/default/optimized/3X/b/c/bceef4d59d54e6590addac9fc886b98f4d419f29_2_690x225.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#proposer-ex-anti-attack-10" name="proposer-ex-anti-attack-10"></a>Proposer ex-anti attack</h3>
<p>Let’s move on to the second scenario: the proposer ex-anti attack in ePBS. In this scenario, we will examine the most extreme version where the builder’s Reveal Boost (<span class="math">RB</span>) is leveraged for the ex-anti attack. What does this attack look like?</p>
<p>The proposer of slot <span class="math">n</span> withholds the block and the beacon committee, represented by <span class="math">\delta</span>, withholds the attestations. The attacking builder of slot <span class="math">n</span> releases the payload on time to gain the <span class="math">RB</span>. The ex-anti attack is successful if <span class="math">RB + \delta &gt; PB</span>. However, realistically, the proposer will try to split the beacon committee into portions seen (<span class="math">x</span>) and not seen (<span class="math">1-x</span>). This modifies the equation to <span class="math">RB + x + \delta &gt; PB + 1-x</span>.</p>
<p>Let’s examine the benefits for the attacker in a successful attack:</p>
<ul>
<li>The block at slot <span class="math">n</span> reorgs out slot <span class="math">n+1</span>. Unlike a post-anti attack, the builder of slot <span class="math">n</span> must commit and release the payload on time to gain the <span class="math">RB</span>. Due to this commitment:
<ul>
<li>Even if the attack is successful, it only provides one slot of transactions without leading to more time and more transactions. The proposer of slot <span class="math">n+2</span> benefits here.</li>
<li>It cannot steal slot <span class="math">n+1</span>'s transactions because the payload is pre-committed, leaving nothing to steal from the consensus block.</li>
</ul>
</li>
</ul>
<p>In other words, the ex-anti attack is less valuable than the post-anti attack if we assume the worst-case scenario for both.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/f/0fb72294c98dbb6a1be55419420ebf8144cfaa62.png" title="Screenshot 2024-06-26 at 12.57.58 PM"><img alt="Screenshot 2024-06-26 at 12.57.58 PM" height="263" src="https://ethresear.ch/uploads/default/optimized/3X/0/f/0fb72294c98dbb6a1be55419420ebf8144cfaa62_2_690x263.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#builder-attacks-11" name="builder-attacks-11"></a>Builder attacks</h3>
<p>Finally, let’s move to the last section: proposers of <span class="math">n</span> and <span class="math">n+1</span> collude to attack the builder of <span class="math">n</span>. We will divide this section into two parts. The first part will focus on reorg out the builder’s payload, and the second part will focus on making the payload part of the canonical chain even if the builder chooses to withhold it.</p>
<h4><a class="anchor" href="https://ethresear.ch#payload-reorging-attack-12" name="payload-reorging-attack-12"></a>Payload reorging attack</h4>
<p>Let’s examine the first part. The proposer of slot <span class="math">n</span> releases the block late / attempts to split the beacon committee view, resulting in <span class="math">x</span> beacon committee members voting for the block and <span class="math">1-x</span> not voting for it. The builder reveals the payload on time and gains a <span class="math">RB</span>. The proposer of slot <span class="math">n+1</span> could then reorg the payload by reorg the entire proposer block of slot <span class="math">n</span>, which is more powerful than just reorganizing the payload itself. The attack is successful if <span class="math">PB + 1 - x &gt; RB + x</span>.</p>
<p>What does a successful attack provide to the attacker?</p>
<ul>
<li>Given that proposers of slots <span class="math">n</span> and <span class="math">n+1</span> are colluding, there is no extra slot advantage gained by reorg out the block at slot $n. It is essentially the same as not proposing a block at slot <span class="math">n</span>.</li>
<li>A minor advantage of the collusion between the two proposers is the ability to steal the payload transactions from slot <span class="math">n</span>. This issue is mitigated if transactions are protected by binding them to slot $n. This scenario is known as a next-slot unbundling attack, which differs from same-slot unbundling. Same-slot unbundling is impossible in ePBS.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e50f3d20a2b304825cb05436a2a3e610fbddcf4f.png" title="Screenshot 2024-06-26 at 12.58.35 PM"><img alt="Screenshot 2024-06-26 at 12.58.35 PM" height="210" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e50f3d20a2b304825cb05436a2a3e610fbddcf4f_2_690x210.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#payload-withholding-attack-13" name="payload-withholding-attack-13"></a>Payload withholding attack</h4>
<p>Let’s look at the second part. The proposer of slot <span class="math">n</span> releases the block late or tries to split the beacon committee view, resulting in <span class="math">x</span> beacon committee members voting for the block and <span class="math">1-x</span> not voting for it. The builder withholds the payload on time and gains a Withheld Boost (<span class="math">WB</span>). The proposer of slot <span class="math">n+1</span> could attempt to force the builder to fulfill unconditional payment by making the block at slot <span class="math">n</span> canonical, which from the chain’s perspective, appears as if the builder did not release the payload. The attack is successful if <span class="math">PB + x &gt; WB + 1 - x</span>.</p>
<p>What does a successful attack provide to the attacker?</p>
<ul>
<li>The only plausible scenario for this attack is when the builder is not confident in revealing the payload and hence withholds it. In this case, the proposer of slot <span class="math">n+1</span>, colluding with the proposer of slot <span class="math">n</span>, wants to take the builder’s payment regardless.</li>
<li>Another primary advantage is that the block at slot <span class="math">n+1</span> can contain two slots’ worth of transactions since the builder submits an empty payload by withholding.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/f/5f04c5fc36d5b005e7dcc6c7839e90f40a4a0af7.png" title="Screenshot 2024-06-26 at 12.58.09 PM"><img alt="Screenshot 2024-06-26 at 12.58.09 PM" height="266" src="https://ethresear.ch/uploads/default/optimized/3X/5/f/5f04c5fc36d5b005e7dcc6c7839e90f40a4a0af7_2_690x266.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#boost-numbers-14" name="boost-numbers-14"></a>Boost numbers</h3>
<p>Finally, let’s summarize the equations for each worst-case attack scenario if the attacker wins:</p>
<ol>
<li><strong>Proposers post-anti attack</strong>: <span class="math">WB + PB + \delta &gt; 1 - \delta</span></li>
<li><strong>Proposers ex-anti attack</strong>: <span class="math">RB + x + \delta &gt; PB + 1 - x</span></li>
<li><strong>Builder reorg payload attack</strong>: <span class="math">PB + 1 - x &gt; RB + x</span></li>
<li><strong>Builder withhold payload attack</strong>: <span class="math">PB + x &gt; WB + 1 - x</span></li>
</ol>
<p>Overall, we can derive that the parameters are approximately <span class="math">PB = 20\%</span>, <span class="math">WB = 40\%</span>, <span class="math">RB = 40\%</span>, and <span class="math">\delta = 20\%</span>. This means we can tolerate a malicious beacon committee up to 20%, whereas today, this tolerance is 40%.</p>
<p>The real question to ask is whether the worst-case scenario of a 20% attack even makes sense, as in the ex-anti attack, the builder must release the payload to perform the attack. Nevertheless, it certainly represents a degradation in fork choice. A 20% attack is significantly more dangerous in the post-anti attack than in the ex-anti attack due to the additional time available.</p>
<p>Something we haven’t analyzed here is how multi-slot liveness may play a role in this context. Given (block, slot) voting and under worse network asynchrony conditions, we may experience prolonged empty slots, making recovery difficult. Solutions like a backoff scheme have been proposed, which require further thought and analysis.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 14:24:34 +0000</pubDate>
</item>
<item>
<title>P2P ZK Light Client Bridge between Tron and Ethereum L2s</title>
<link>https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931</link>
<guid>https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931</guid>
<content:encoded><![CDATA[
<div> 关键词：Tron USDT、Ethereum L2、Zero-knowledge proofs、Cross-chain bridge、Decentralization

总结:<br />
这篇文章讨论了Tron网络上的USDT在第三世界国家的广泛应用，但其高度中心化的控制导致高额交易费和生态系统孤立。为解决这些问题，作者提出了一种设计，即利用零知识轻验证的跨链桥，将USDT TRC20与以太坊L2网络低成本连接起来。这种设计旨在减少交易费用、促进去中心化并增强两个生态系统的流动性。通过零知识证明确保交易安全，同时简化用户操作，使得从Tron无缝接入Ethereum成为可能，从而降低集中风险并推动全球去中心化金融基础设施的发展。 <div>
<p><em>By <a href="https://x.com/alexhooketh" rel="noopener nofollow ugc">Alex Hook</a>. Thanks to these people for inspiration, feedback and suggestions: <a href="https://x.com/alexanderchopan" rel="noopener nofollow ugc">accountless.eth</a>, <a href="https://x.com/pseudotheos" rel="noopener nofollow ugc">pseudotheos</a>, <a href="https://x.com/domothy" rel="noopener nofollow ugc">Domothy</a>, <a href="https://x.com/DoganEth" rel="noopener nofollow ugc">Dogan Alpaslan</a>, <a href="https://zkp2p.xyz" rel="noopener nofollow ugc">ZKP2P team</a></em></p>
<hr />
<p><strong>Abstract.</strong> USDT on the Tron Network has emerged as a dominant crypto application in the Third World countries. However, the current cartelized control of the Tron Network results in elevated transaction fees, capital concentration, and an ecosystem isolated from other crypto networks. We propose a design for a cost-effective, peer-to-peer bridge from USDT TRC20 to Ethereum L2 networks, utilizing zero-knowledge light verification of the Tron blockchain.</p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>According to <a href="https://tokenterminal.com/terminal/datasets/stablecoins" rel="noopener nofollow ugc">Token Terminal</a>, USDT on Tron has achieved preeminence by several metrics, including outstanding supply, 30d transfer volume, number of transfers, and number of holders. At the time of writing, the second place by volume, DAI on Ethereum, has only ~20% less volume than it, but two orders of magnitude fewer holders and number of transfers. The second place by number of transfers, USDC on Base, has 5x fewer transfers.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/4/6476c0c44ca7866bfea5a4f35205a47fa7c74204.png" title="Screenshot 2024-06-27 at 8.00.11 PM"><img alt="Screenshot 2024-06-27 at 8.00.11 PM" height="459" src="https://ethresear.ch/uploads/default/optimized/3X/6/4/6476c0c44ca7866bfea5a4f35205a47fa7c74204_2_690x459.png" width="690" /></a></div><p></p>
<p>This shows Tron USDT’s monstrous levels of payment usage among individuals. Unsurprising—Tron team has done an extensive advertisement campaign for its payment solution in Africa and Latin America. Shortly after, the network effect spread it to the developing countries in Asia and Post-Soviet area.</p>
<p>If we look at the areas of the largest prevalence of Tron USDT, a noteworthy pattern can be noticed. Tron USDT is largely used in the countries with weak economies and unsustainable local currencies: Türkiye, Lebanon, Zimbabwe, Venezuela, Argentina, and more. In these countries, traditional banking doesn’t provide people with options for reliable store of value and means of payment, as local currencies are unreliable, and foreign currencies are either banned for payment use or subject to strict control.</p>
<h3><a class="anchor" href="https://ethresear.ch#problems-2" name="problems-2"></a>Problems</h3>
<p>It is fair to say that USDT on Tron is one of the largest crypto applications by usage today. Millions of people around the world are interacting with it every day. It’s massively used as a store of value, acts as a medium of exchange in isolated economies such as Northern Cyprus, Cuba, and Vietnam. <a href="https://mirror.xyz/0x8958D0c419BCDFB8A86b8c0089552bE015fbe364/ODhOuYjK80atc9_jGprXotSo3PNobT1PRLFtorXHBrA" rel="noopener nofollow ugc">Local P2P platforms are building their infrastructure around USDT on Tron</a>. However, its dominance presents certain challenges for the broader Web3 community:</p>
<ul>
<li>
<p><em>A primary concern is the high degree of centralization</em> within the Tron Network. <a href="https://github.com/alexhooketh/tron-light-client/blob/cc3e037c5b71ba5e6216c8d19fee4dfe9d254e69/README.md" rel="noopener nofollow ugc">According to our research</a>, over the past 250 days there were only 28 unique block producers. The same entities are constantly winning the DPoS election due to delegations from the largest TRX holders. Most of these Super Representatives (block producers in Tron) <a href="https://tronscan.org/#/sr/representatives" rel="noopener nofollow ugc">lack any public information</a> beyond their status as block producers.</p>
</li>
<li>
<p>Despite this centralization, <em>transaction fees on Tron remain among the highest in crypto</em>—<a href="https://developers.tron.network/docs/resource-model#energy" rel="noopener nofollow ugc">420 sun</a> (1 sun = 1e-6 TRX) per gas. At the <a href="https://coinmarketcap.com/currencies/tron/" rel="noopener nofollow ugc">TRX’s price of ~0.000035 ETH</a>, this roughly corresponds to Ethereum L1’s gas price of 14.7 gwei. The usual fee for USDT transfers in Tron is <strong>$1-1.5 in TRX</strong>, rendering small transfers barely economical. However, the usage is still very high, as Tron’s ecosystem is isolated and there’s no convenient way to interact with other ecosystems from it.</p>
</li>
</ul>
<p>In contrast, the Ethereum ecosystem continues to thrive. Following the Dencun upgrade, transaction fees on rollups have drastically decreased to <a href="https://www.growthepie.xyz/fundamentals/transaction-costs" rel="noopener nofollow ugc">less than a cent</a> per ERC20 transfer. Combined with L2s, Ethereum DeFi <a href="https://defillama.com/chains" rel="noopener nofollow ugc">now comprises &gt;80% of the entire DeFi TVL</a>. <a href="https://l2beat.com/scaling/activity" rel="noopener nofollow ugc">Rollups alone consistently handle upwards of 100 TPS</a>, <a href="https://mirror.xyz/alexhook.eth/y9PTlM6tVr0H8X68r1LV2UwAnT9D6u1MEEiUFvcpyG0" rel="noopener nofollow ugc">with theoretical limits of 400-800 TPS</a> depending on the specific rollup. OP Mainnet has upgraded to Stage 1 trustlessness with all OP Chains and ZKsync catching up this summer. Arbitrum is working towards Stage 2.</p>
<p>People in developed countries are already integrated with Ethereum. By allowing ones from developing countries to seamlessly move into it from Tron, we can unite these disparate ecosystems and mitigate the risks associated with increasing centralization and monopolization of Sun’s machine.</p>
<h1><a class="anchor" href="https://ethresear.ch#rationale-3" name="rationale-3"></a>Rationale</h1>
<p>The protocol for cross-chain transfers from Tron should ideally possess the following characteristics:</p>
<ul>
<li><strong>Trust-minimized:</strong> The system should preclude the provision of incorrect information about the Tron blockchain or the theft of locked funds, except in the event of an attack on Tron’s consensus. In such a case, the security council authorized to stop the system can be established.</li>
<li><strong>Permissionless liquidity supply:</strong> The protocol should allow any entity to provide liquidity at their preferred rate. This fosters fair competition among providers, potentially resulting in more favorable and flexible exchange rates based on order size.</li>
<li><strong>Permissionless operation:</strong> While a centralized relay for light client updates and order fulfillment is acceptable, provided there exists a self-proposing mechanism in case of liveness failure, the relay must not serve as a source of trust. When feasible, on-chain operations should be implemented instead (e.g., a paymaster for gasless order claims).</li>
<li><strong>As simple as possible from the Tron side:</strong> Gas fees on Tron are extremely high, so it may be not affordable for users to execute more than necessary on-chain. Moreover, USDT Tron users are mostly using wallets such as Trust Wallet, Exodus, hardware wallets, and local exchange accounts, that do not support contract calls or token approvals. The only Tron wallet with these features, TronLink, is not common among USDT Tron users.</li>
<li><strong>Reasonably cheap on the destination side:</strong> Zero-knowledge proofs should be employed where possible to minimize costs. While the system can be more extensive than on the Tron side, it should still be optimized to keep user claim costs low.</li>
<li><strong>Single liquidity hub with enshrined bridging:</strong> The protocol should be deployed on a single L2 network to prevent liquidity fragmentation. To mitigate protocol isolation, cross-chain token bridges can be integrated at the UI level, <a href="https://zkp2p.xyz/send" rel="noopener nofollow ugc">similarly to ZKP2P</a>.</li>
<li><strong>USDC-native:</strong> Given USDC’s prevalence in the Ethereum ecosystem, the protocol can be based on USDC, effectively providing USDT-USDC swaps. However, USDC is virtually unknown in areas of extensive USDT Tron usage, so this difference should be addressed on UX level to reduce user distrust.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#trons-consensus-and-protocol-101-4" name="trons-consensus-and-protocol-101-4"></a>Tron’s consensus and protocol 101</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/1/81e8ead1ee5585f245d51ac55f4f1db43f3785d2.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/1/81e8ead1ee5585f245d51ac55f4f1db43f3785d2_2_540x500.png" width="540" /></a></div><p></p>
<p>Every 6 hours (7200 blocks), network participants delegate their TRX to validator candidates. The 27 candidates accumulating the most votes are elected as Super Representatives (SRs), who are then responsible for block production. Block producer selection follows a deterministic round-robin pattern. A block is considered finalized after receiving 18 confirmations, 2/3 of the SR set.</p>
<p>The block production is an ECDSA signature over the SHA256 hash of the protobuf-encoded block header. That is, one block = one signature. The top 128 representatives, beyond the 27 SRs, are designated as Super Representative Partners, voting on blocks produced by SRs. However, <a href="https://developers.tron.network/docs/concensus#block-generation-mechanism" rel="noopener nofollow ugc">as producers are predictable and the longest-chain rule is applied</a>, there is no necessity in validating votes.</p>
<p>Block header consists of the following elements:</p>
<pre><code class="lang-auto">message BlockHeader {
  message raw {
    int64 timestamp = 1;
    bytes txTrieRoot = 2;
    bytes parentHash = 3;
    int64 number = 7;
    bytes witness_address = 9;
    int32 version = 10;
  }
  raw raw_data = 1;
  bytes witness_signature = 2;
}
</code></pre>
<p>Even though state root is formally specified in the protocol, it’s not added to the header. We assume this is for backward-compatibility purposes, as the current version of Tron Network does not merkleize state.</p>
<p>The signature is made over a SHA256 hash of the serialized <code>raw_data</code> element. That is, by utilizing light verification, we can access only one transaction-specific element—the Merkle root of the transaction tree. However, in Tron, transactions carry their execution status, so we don’t need to access the state to validate the success of one-transaction operations, such as TRC20 transfer().</p>
<pre><code class="lang-auto">message Transaction {
  ...
  message Result {
    enum code {
      SUCESS = 0;
      FAILED = 1;
    }
    enum contractResult {
      DEFAULT = 0;
      SUCCESS = 1;
      REVERT = 2;
      BAD_JUMP_DESTINATION = 3;
      OUT_OF_MEMORY = 4;
      PRECOMPILED_CONTRACT = 5;
      STACK_TOO_SMALL = 6;
      STACK_TOO_LARGE = 7;
      ILLEGAL_OPERATION = 8;
      STACK_OVERFLOW = 9;
      OUT_OF_ENERGY = 10;
      OUT_OF_TIME = 11;
      JVM_STACK_OVER_FLOW = 12;
      UNKNOWN = 13;
      TRANSFER_FAILED = 14;
      INVALID_CODE = 15;
    }
    int64 fee = 1;
    code ret = 2;
    contractResult contractRet = 3;
    ...
}
</code></pre>
<p>Votes for witnesses (representatives) are of a specific transaction type. This means that in order to calculate the votes, the light client has to download all transactions and re-execute ones of this type.</p>
<pre><code class="lang-auto">message Transaction {
  message Contract {
    enum ContractType {
      ...
      VoteWitnessContract = 4;
      ...
}
</code></pre>
<p>However, considering the fact that the SR set is almost static, we believe that it would be computationally cheaper to delegate choosing the canonical set to DAO or enshrine the set into the circuit.</p>
<p>Normal contract calls, such as TRC20 transfer, have the <code>TriggerSmartContract</code> type and are nearly identical to ERC20 transactions. This means that we can prove the USDT transfer on Tron network using only the transaction root, which can be safely accessed on-chain using ZK light client relay.</p>
<h1><a class="anchor" href="https://ethresear.ch#design-proposal-5" name="design-proposal-5"></a>Design proposal</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b4b8d0d74dfe0a7dd5991bce974eac97c8621fc.jpeg" title="image"><img alt="image" height="402" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b4b8d0d74dfe0a7dd5991bce974eac97c8621fc_2_690x402.jpeg" width="690" /></a></div><p></p>
<p>The proposed cross-chain swap mechanism involves three primary entities: the <em>User</em>, the <em>Buyer</em> (or liquidity provider), and the <em>Relayer</em>. The process unfolds as follows:</p>
<ol>
<li>
<p><em>The Buyer</em> locks USDC into the swap contract on the L2, specifying their exchange rate and Tron address for transfers.</p>
</li>
<li>
<p><em>The User</em> selects a <em>Buyer</em> offering the most favorable rate with sufficient liquidity. <em>The User</em> then initiates a transaction on the L2 to temporarily lock a portion of the <em>Buyer’s</em> USDC. This step prevents liquidity depletion before order fulfillment. If supported by the L2, this transaction may be funded by a paymaster.</p>
</li>
<li>
<p><em>The User</em> transfers the corresponding amount of Tron USDT to the <em>Buyer’s</em> specified address.</p>
</li>
<li>
<p>Following 18 block confirmations (~54 seconds, ensuring finality), the <em>Relayer</em> retrieves the latest Tron block headers and generates a ZK proof to them. The circuit for light verification must contain the transaction root from the header as the public input so that it’s known to the relay contract. This proof is needed to efficiently prove the new Tron blocks and their transaction roots <em>to the relay contract</em>.</p>
</li>
<li>
<p><em>The Relayer</em> obtains the finalized transaction from the Tron blockchain and generates a zero-knowledge proof of transaction inclusion against the transaction root. This proof is needed to efficiently prove the order fulfillment <em>to the swap contract</em>. Just like light client proofs, transaction proofs can be aggregated to minimize the costs of on-chain proof verification.</p>
</li>
<li>
<p><em>The Relayer</em> submits these proofs to the respective smart contracts on the L2. Upon verification, the swap contract releases the funds to the <em>User</em> and allocates a small portion to the <em>Relayer</em> as compensation. In case of liveness failure, the <em>User</em> can generate and relay proofs themselves, removing the need for relayer fees.</p>
</li>
<li>
<p><em>The Buyer</em> can exchange their acquired Tron USDT for USDC on the L2 through various means, including direct 1:1 exchange with issuers, and reinvest in the swap contract.</p>
</li>
</ol>
<p>This system streamlines the user experience to just two primary actions: committing to the order on the destination chain and transferring Tron USDT to a specified address. The User receives the equivalent USDC on the L2 within approximately one minute. This system can even be used to accept payments in USDT Tron, requiring only a web browser with a connected wallet for order creation.</p>
<p>For Buyers, liquidity provision is fully automated. They create a Tron wallet, and supply USDC with specified Tron address to the smart contract. When their liquidity is out, it is automatically removed. Received USDT can be spent and exchanged back to USDC at any time. This system is expected to provide higher exchange rates than the existing P2P platforms, as the rate is competitive and there’s no need to cover the costs of KYC and other web2-specific processes.</p>
<p>Relayers require only a server running relayer and ZK prover software. As relayers do not serve as the source of trust, this role can be either permissionless or delegated to the development team, provided self-proposing functionality is supported.</p>
<h1><a class="anchor" href="https://ethresear.ch#zk-light-client-poc-6" name="zk-light-client-poc-6"></a>ZK Light Client PoC</h1>
<p>We’ve written a proof-of-concept of ZK light verification of Tron blocks in Noir language. It receives the previous and new block IDs with a transaction root as the public input, and the block header as the private input. It does not implement round-robin checks and election mechanism for efficiency purposes, and the SR set is hardcoded into the circuit. The proof is generated in about 35 seconds on an M1 machine.</p>
<p>For the production version of this system, it may be necessary to rewrite the circuits to STARK-based proof systems and/or implement GPU proving to improve proving speed.</p>
<p>The source code can be found here: <a class="inline-onebox" href="https://github.com/alexhooketh/zktron" rel="noopener nofollow ugc">GitHub - alexhooketh/zktron: ZK light client for Tron Network written in Noir</a></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-7" name="conclusion-7"></a>Conclusion</h1>
<p>The proposed P2P ZK Light Client Bridge between Tron and Ethereum L2s is a significant advancement in addressing the problems of Tron Network in a Web3 way. By leveraging zero-knowledge proofs and efficient light client verification, this system offers a trust-minimized, permissionless, and cost-effective solution for bridging the gap between these two prominent blockchain ecosystems.</p>
<p>This bridge design addresses several key challenges:</p>
<ol>
<li>It mitigates the risks associated with the centralization of the Tron Network by providing users with seamless access to the more decentralized and robust Ethereum ecosystem.</li>
<li>It significantly reduces transaction costs for users, particularly benefiting those in developing economies who rely heavily on USDT for daily transactions and value storage.</li>
<li>It enhances liquidity and interoperability between Tron and Ethereum, expanding Ethereum ecosystem to the areas of extensive Tron usage.</li>
<li>It maintains a high level of security through the use of ZK proofs, ensuring the integrity of cross-chain transactions without compromising on efficiency.</li>
</ol>
<p>By bridging these ecosystems, we can solve the problem of increasing influence of Tron, taking a significant step towards realizing the vision of a truly global, decentralized financial infrastructure that can benefit users across all economic backgrounds.</p>
<p>We welcome feedback and questions from the community. Feel free to leave your comments, suggestions, or inquiries in the comments section below. <strong>Thank you for reading.</strong></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 20:03:10 +0000</pubDate>
</item>
<item>
<title>Orbit SSF: solo-staking-friendly validator set management for SSF</title>
<link>https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928</link>
<guid>https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928</guid>
<content:encoded><![CDATA[
<p><em>Much of the post came together during a week of in-person whiteboarding with <a href="https://rig.ethereum.org" rel="noopener nofollow ugc">RIG</a> and wannabe RIGs like myself, Ansgar and Toni. Thanks in particular to <a href="https://twitter.com/weboftrees" rel="noopener nofollow ugc">Anders</a>, <a href="https://twitter.com/adietrichs" rel="noopener nofollow ugc">Ansgar</a>, <a href="https://twitter.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://twitter.com/soispoke" rel="noopener nofollow ugc">Thomas</a> for continued discussions and feedback, again to Anders for most of the ideas around individual incentives, and again to Barnabé for the diagrams about finality. The core idea that the post explores was originally proposed by Vitalik in <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">this post</a></em>.</p>
<h2><a class="anchor" href="https://ethresear.ch#where-we-are-1" name="where-we-are-1"></a>Where we are</h2>
<p>The <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality" rel="noopener nofollow ugc">Single Slot Finality (SSF) roadmap</a> has <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#What-are-the-key-questions-we-need-to-solve-to-implement-single-slot-finality" rel="noopener nofollow ugc">three main components</a>:</p>
<ul>
<li>Consensus algorithm</li>
<li>Signature aggregation</li>
<li>Validator set economics</li>
</ul>
<p>Since the previously linked post, there has been a lot of progress on the consensus algorithm side, with <a href="https://ethresear.ch/t/a-simple-single-slot-finality-protocol/14920">multiple</a> <a href="https://arxiv.org/abs/2310.11331" rel="noopener nofollow ugc">candidate</a> <a href="https://notes.ethereum.org/@fradamt/chained-3sf" rel="noopener nofollow ugc">protocols</a> and <a href="https://github.com/fradamt/ssf/tree/main/high_level" rel="noopener nofollow ugc">the beginning of a specification effort</a>. There have also been some effort to explore the design space of signature aggregation, both with a <a href="https://ethresear.ch/t/horn-collecting-signatures-for-faster-finality/14219">networking</a> <a href="https://ethresear.ch/t/flooding-protocol-for-collecting-attestations-in-a-single-slot/17553">focus</a> and a <a href="https://ethresear.ch/t/signature-merging-for-large-scale-consensus/17386">cryptographic focus</a>. Still, we are likely not close to being able to reliably aggregate millions of signatures per slot, without increasing the slot time or validator requirements significantly. On the staking economics side, there has been lots of work over the last year, but for the most part focused on understanding <a href="https://mirror.xyz/barnabe.eth/v7W2CsSVYW6I_9bbHFDqvqShQ6gTX3weAtwkaVAzAL4" rel="noopener nofollow ugc">liquid staking</a> and <a href="https://mirror.xyz/barnabe.eth/96MD_A194uXLLjcOWePW3O2N3P-JG-SHtNxU0b40o50" rel="noopener nofollow ugc">restaking</a>, and on <em>stake</em> capping, i.e., constraining the amount of ETH staked (if you’re reading this, you’re probably already at least at a surface level familiar with the issuance conversation, in which case you might want to dig deeper and check out these posts <a href="https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/1">[1]</a> <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">[2]</a>). Here, we are instead interested in <em>validator capping</em>, i.e., constraining the amount of validator identities in the system, or at least the ones actively participating at any given time, to satisfy technical constraints. Some ideas in this direction can be found in this <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#what-would-8192-signatures-per-slot-under-ssf-look-like-2">recent post</a>, and in fact <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">approach 3</a> from the post provides the foundation for this post. Moreover, a recent important development is that <a href="https://eips.ethereum.org/EIPS/eip-7251" rel="noopener nofollow ugc">EIP-7251 (MaxEB)</a> has been included in the <a href="https://github.com/ethereum/consensus-specs/blob/a3a6c916b236c9e8904090303f0c38ae49db1002/specs/electra/beacon-chain.md" rel="noopener nofollow ugc">Electra fork</a>. Validator effective balances will be allowed to be as high as 2048 ETH, enabling staking pools to <a href="https://notes.ethereum.org/@fradamt/maxeb-consolidation" rel="noopener nofollow ugc">consolidate their validators</a>, a new capability which we can leverage in our designs.</p>

<h2><a class="anchor" href="https://ethresear.ch#goals-2" name="goals-2"></a>Goals</h2>
<p>With the goal of finding a design which can make its way into the protocol in a reasonable timeline, we are here going to focus on solutions that <em>do not</em> rely on large improvements in the signature aggregation process. We also do not think it is very realistic to propose significant increases of the slot time, which have many externalities. Given these technical constraints, let’s focus on a minimal set of properties that we ideally want to achieve:</p>
<ul>
<li><strong>Validator capping</strong>: at most <span class="math">N</span> <em>active</em> validators at a time. For example, <span class="math">N = 2^{15} \approx 32k</span>, which we know we can handle because it is the size of a committee today. If we wanted to completely remove attestation aggregation, we would likely need to drop this number to a few thousands.</li>
<li><strong>Solo staking viability</strong>: staking with 32 ETH is <em>guaranteed</em> to still be possible, <em>and</em> the solo staking yield should still not compare unfavorably to delegated staking yields.</li>
<li><strong>High eventual economic security</strong>: More than <span class="math">D_f</span> stake provides economic security, at least <em>eventually</em>. For example <span class="math">D_f = 20M</span> ETH. Ideally, we also do not have to wait longer than today for it (two epochs).</li>
<li><strong>Fast finality</strong>: at least <em>some</em> amount of economic security is available shortly after a block is proposed (think: 10 to 30 seconds, not over 10 minutes).</li>
<li><strong>Optimally secure consensus protocol</strong>: the consensus protocol is (provably) resilient to ~1/2 adversaries under network synchrony, and 1/3 under partial synchrony.</li>
</ul>
<p>Without solo staking viability as defined here, we could simply raise the minimum balance, or go with approaches that allow for a low minimum balance but do not <em>guarantee</em> it, for example in the face of large stakers intentionally splitting their stake. Such solutions would likely have to lean on <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-1-go-all-in-on-decentralized-staking-pools-3">decentralized staking pools</a> or <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-2-two-tiered-staking-4">two-tier staking</a> to preserve the accessible nature of staking as it is today, or perhaps even to carve out a more tailored role for smaller stakers, as is suggested by <a href="https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683">rainbow staking</a>. While there is merit to these approaches and we believe they (and more generally the role of solo staking/broad consensus participation) deserve further exploration, we are choosing here to only explore designs that are compatible with this narrow interpretation of solo staking viability.</p>
<h2><a class="anchor" href="https://ethresear.ch#overview-of-approaches-3" name="overview-of-approaches-3"></a>Overview of approaches</h2>
<p>Validator capping, solo staking viability and high economic security immediately raise an issue: high economic security requires millions of ETH to participate in finalizing and a minimum balance of 32 ETH then implies a worst case of hundreds of thousands or millions of validators (~1M at the time of writing), which seems to conflict with validator capping. There are two main classes of approaches that attempt to deal with this problem:</p>
<ul>
<li><strong>Validator set rotation</strong>: the full validator set is allowed to be large, but only a subset is actively participating at any given time.</li>
<li><strong>Economic validator set capping</strong>: the size of the full validator set is constrained through economic incentives. To <em>guarantee</em> a small validator set size we can for example <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-validator-count" rel="noopener nofollow ugc">reduce issuance past the target validator count</a>. However, this leaves all stakers open to a cheap griefing attack, where a small amount of stake can have a disproportionate negative impact on issuance.</li>
</ul>
<p>In this post we are not going to focus on the latter approach <em>in isolation</em>, but we are going to propose a way to combine economic incentives with a form of validator set rotation.</p>
<h2><a class="anchor" href="https://ethresear.ch#validator-set-rotation-4" name="validator-set-rotation-4"></a>Validator set rotation</h2>
<p>The current protocol also has to deal with the issue we have outlined in the previous section, and the chosen “solution” is precisely validator set rotation: only 1/32 of the validator set votes in any given slot. This design <a href="https://notes.ethereum.org/@vbuterin/serenity_design_rationale#Why-32-ETH-validator-sizes" rel="noopener nofollow ugc">trades off finality time</a>, and fails to satisfy our desired property of fast finality.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/83646288afbace1b452239618b34e83319531d0a.png" title=""><img alt="" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/8/3/83646288afbace1b452239618b34e83319531d0a_2_690x388.png" width="690" /></a></div><p></p>
<p>Let’s then explore whether we can use validator set rotation without giving up on fast finality or other properties.</p>
<h3><a class="anchor" href="https://ethresear.ch#fast-rotation-5" name="fast-rotation-5"></a>Fast rotation</h3>
<p>One way to go about validator set rotation is to have committees which rotate fast, as in the current protocol. In order to avoid a high time-to-finality, we can use a different consensus protocol allowing for <a href="https://ethresear.ch/t/a-model-for-cumulative-committee-based-finality/10259">committee-based finality</a>, i.e., such that even a committee can provide economic security proportional to its stake. In fact, the post linked above deals with <em>cumulative</em> committee-based finality, where the consensus protocol even allows for accumulation of economic security over multiple finalizations, such that <span class="math">k</span> committees finalizing in a row results in <span class="math">k</span> times the economic security that a single committee can provide. We get two birds with one stone, getting both fast (partial) finality and full <em>eventual</em> economic security. In particular, we could have full finality <em>in the same time as today</em> (which gives enough time for each committee to do its own finalization by voting twice), but with the big improvement that economic security accrues every slot, rather than all at once after two epochs.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/6/b6816fefcf5021bb672ed76029c844d1f311047d.png" title=""><img alt="" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/b/6/b6816fefcf5021bb672ed76029c844d1f311047d_2_690x388.png" width="690" /></a></div><p></p>
<p>This seems like a clear improvement on today’s protocol, so why are we not just doing it? An answer comes from the consensus protocol design space: it is not clear at this point how to have an optimally secure dynamically available protocol with <em>fast</em> rotating committees. In fact, much of the problems with the LMD-GHOST component of today’s protocol, or at least the <a href="https://ethresear.ch/t/reorg-resilience-and-security-in-post-ssf-lmd-ghost/14164#introduction-2">fundamental ones</a>, come precisely from the interaction of multiple committees. In short, an adversary can accumulate weight across multiple committees, and use it to reorg honest blocks that have a single committee supporting them.</p>
<p>For interested readers, there actually are optimally secure dynamically available consensus protocols that allow for committees (<a href="https://arxiv.org/abs/2209.03255" rel="noopener nofollow ugc">[1]</a> <a href="https://eprint.iacr.org/2022/1448.pdf" rel="noopener nofollow ugc">[2]</a> for example), but all known ones suffer from catastrophic failures under even short-lived asynchrony (<a href="https://arxiv.org/abs/2302.11326" rel="noopener nofollow ugc">[1]</a> <a href="https://arxiv.org/abs/2309.05347" rel="noopener nofollow ugc">[2]</a>). It is not known whether this is a fundamental limitation, but at least so far we do not know any protocol that gets around it.</p>
<h3><a class="anchor" href="https://ethresear.ch#slow-rotation-6" name="slow-rotation-6"></a>Slow rotation</h3>
<p>There is however a simple way to avoid the problem altogether: giving up on <em>fast</em> committee rotation, and instead having a committee which rotates out slowly, for example by replacing a small percentage of it every slot. The upshot is that such a committee effectively acts as a full validator set, in the sense that its actions do not interact with those of other committees, as would be the case with fast rotation. We can in principle take any protocol that works when the whole validator set is able to participate at once, and make it work with this mechanism by slowing down the rotation sufficiently.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/c/4c21c0ca0871b1e7c6440325b3a3174df016793f.png" title=""><img alt="" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/4/c/4c21c0ca0871b1e7c6440325b3a3174df016793f_2_690x389.png" width="690" /></a></div><p></p>
<p>At a first glance, one obvious downside is that a full rotation of the validator set would be much slower than today, and thus so would finality. However, we could do things a bit differently, by decoupling the committee which votes for the available chain (LMD-GHOST votes) from those which vote for finality (Casper FFG votes). Only LMD-GHOST has problems with fast committee rotation, so we could have a slowly rotating committee whose votes count for LMD-GHOST and in parallel also fast rotating committees whose votes accumulate economic security over time, up to full finality in no more than today’s two epochs.</p>
<p>Besides some amount of extra complexity in the consensus protocol, one remaining downside is that we leave a single committee “in charge” of LMD-GHOST for extended periods of time. Moreover, while linearly accumulating finality is a strict improvement over today’s step function finality, we do not achieve something even stronger, namely getting a high level of economic security immediately. This is of course impossible to achieve given the constraints we have laid out, <em>unless we make some assumptions about the stake distribution</em>, for example that it is <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#The-good-news-gains-from-enabling-voluntary-validator-balance-consolidation" rel="noopener nofollow ugc">Zipfian</a>, or anyway such that a large portion of the stake is concentrated in the first few thousand entities.</p>

<h2><a class="anchor" href="https://ethresear.ch#orbit-ssf-stable-core-rotating-periphery-7" name="orbit-ssf-stable-core-rotating-periphery-7"></a>Orbit SSF: Stable core, rotating periphery</h2>
<p>Our starting point is <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">approach 3 from this post</a>, where validators are (roughly) sampled by balance, so that validators with a lot of stake are always in the validator set. Contrast this with the previously considered validator set rotation approaches where validators were (implicitly) sampled by indices, as we do today, which results in each committee having small weight regardless of what the stake distribution looks like.</p>
<p>We then consider adding consolidation incentives, to have stronger guarantees about the level of finality that we can reach with a single committee. The rotating parts of the committee can then rotate slowly, and we do not need to take on the extra consensus complexity of decoupling voting for the available chain and for the finality gadget. Moreover, there is never a small committee (in terms of stake) in charge of a critical consensus component: at all times, we can expect the active validator set to hold a meaningful fraction of the whole stake.</p>
<h3><a class="anchor" href="https://ethresear.ch#active-validator-set-management-8" name="active-validator-set-management-8"></a>Active validator set management</h3>
<p>There are two key components here:</p>
<ul>
<li><em>Active validator set selection</em>: We set a stake threshold <span class="math">T</span> (in principle it could also be set dynamically), and then define the probability of validator with stake <span class="math">S</span> to be sampled in the active set to be <span class="math">p(S) = \min(\frac{S}{T}, 1) = 
\begin{cases}
\frac{S}{T} &amp; S \le T \\ 
1 &amp; S \ge T 
\end{cases}</span><br />
A validator with stake <span class="math">S \le T</span> is selected with probability <span class="math">\frac{S}{T}</span> proportional to its stake, whereas validators with stake <span class="math">S \ge T</span> are <em>always</em> in the validator set. The idea here is of course that it is helpful to have a stable core of large validators always in the active set, because they contribute a lot of economic security but still only add the same load as any other validator.</li>
<li><em>Reward adjustment</em>: We adjust attestation rewards so that all validators still get compensated proportionally to their stake, regardless of whether they fall below or above the threshold <span class="math">T</span>. To define the reward function, we take as reference the maximum attestation reward <span class="math">R</span> that the protocol gives to a validator with stake <span class="math">T</span>, for a single attestation (<span class="math">R</span> can of course vary depending on the overall issuance level). Given <span class="math">R</span>, the maximum reward for an attestation by a validator with stake <span class="math">S</span> is <span class="math">r(S) = R\cdot\max(1, \frac{S}{T}) = 
\begin{cases} 
R &amp; S \le T \\
R \cdot \frac{S}{T} &amp;S \ge T
\end{cases}</span><br />
Overall, the <em>expected</em> rewards of a validator with stake <span class="math">S</span> are then <span class="math">p(S)\cdot r(S) = R\cdot\frac{S}{T} = \frac{R}{T} \cdot S</span>. In other words, <span class="math">\frac{R}{T}</span> per unit of stake, regardless of how it is distributed.  To help visualize this, here’s a plot of <span class="math">p(S)</span>, <span class="math">r(S)</span> and <span class="math">p(S)\cdot r(S)</span>, for <span class="math">R = 2</span> (arbitrary value just for the plot) and <span class="math">T = 1024</span>. Validators with less than <span class="math">T</span> stake do have higher variance, because they only participate <span class="math">\frac{S}{T}</span> of the time, but over longer periods of time the variance will still very low, since attestation rewards are constant and very frequent.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/9/69e8f45397940a38df6d146660314fa29c2f790c.png" title=""><img alt="" height="355" src="https://ethresear.ch/uploads/default/optimized/3X/6/9/69e8f45397940a38df6d146660314fa29c2f790c_2_690x355.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#validator-capping-9" name="validator-capping-9"></a>Validator capping</h4>
<p>We can easily compute the expected size of an active validator set <span class="math">V_a</span> that is sampled this way from a full validator set <span class="math">V</span> whose total deposit size is <span class="math">D</span>:<br />
<span class="math">\mathbb{E}[|V_a|] = \sum_{i \in V} p(S_i) = \sum_{i \in V} \min(\frac{S_i}{T}, 1) = \frac{1}{T}\sum_{i \in V} \min(S_i, T) \le \frac{1}{T}\sum_{i \in V} S_i = \frac{D}{T}</span></p>
<p>Basically, any validator with stake <span class="math">S \le T</span> contributes exactly <span class="math">\frac{S}{T}</span> to the expectation. Crucially, these contribution scale linearly in <span class="math">S</span>: the only effect of splitting up to <span class="math">T</span> stake into small validators is to increase the variance of the active validator set size, without affecting the expectation. As for validators with stake <span class="math">S &gt; T</span>, they even decrease the expectation compared to the worst case, which is <span class="math">\frac{D}{T}</span>, equal to the full validator set size if all validators had <span class="math">T</span> stake.</p>
<p>For example, we can set <span class="math">T = 4096</span> ETH, giving us a <em>maximum</em> expected active validator set size of <span class="math">\frac{120M}{4096} \approx 30k</span>. If we were to employ stake capping (we will later discuss how to do so in this context) to ensure (or have high assurances) that <span class="math">D</span> is bounded by (for example) <span class="math">2^{25}M</span> ETH, we could even set <span class="math">T = 1024</span> and still have an expected active validator set size of at most ~32k. There can of course be deviations from this expected size, but with high probability the actual active validator set size would always fall within reasonably narrow bounds, so we can have very strong guarantees about the maximum load that we would need to be able to handle. We look at this in more detail <a href="https://ethresear.ch#Validator-capping-active-validator-set-variance">in the appendix</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#incentivizing-consolidation-10" name="incentivizing-consolidation-10"></a>Incentivizing consolidation</h3>
<p>Let <span class="math">D_a</span> be the active deposit size, i.e., the total stake of the active validator set, contrasted with the total deposit size <span class="math">D</span>, the stake of the whole validator set. Optimistically, as long as there is sufficient consolidation, <span class="math">D_a</span> will be high, a clear improvement over the <a href="https://ethresear.ch#Slow-rotation">previous slow rotation approach</a>. Still, we would like this to be more than an optimistic property. The question we are left to answer is then how we can ensure, or at least highly incentivize, a high <span class="math">\frac{D_a}{D}</span> ratio. For example, we want to prevent that all validators keep 32 ETH balances (no one consolidates), which would result in <span class="math">\mathbb{E}[D_a] = \frac{32}{T} D</span>, e.g., only <span class="math">\frac{D}{32}</span> with <span class="math">T = 1024</span>. With today’s <span class="math">D = 32M</span> ETH, the expected active deposit size would only be <span class="math">1M</span> ETH. On the other hand, we do not want to reward consolidated validators disproportionately compared to small validators.</p>
<p>We explore two complementary approaches:</p>
<ul>
<li><strong>Collective consolidation incentives</strong>, growing the size of the pie for the whole validator set when the set is more consolidated.</li>
<li><strong>Individual consolidation incentives</strong>, accounting for the extra risk accruing from further individual consolidation.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#collective-consolidation-incentives-11" name="collective-consolidation-incentives-11"></a>Collective consolidation incentives</h4>
<p>The first approach we explore is to reward <em>everyone</em> for consolidation, spreading out the benefits beyond the consolidating validators so as to maintain rewards undifferentiated, while still providing an incentive to consolidate.</p>
<p>A first proposal in this direction is to set the rewards based on <span class="math">D_a</span>, rather than <span class="math">D</span>. For example, we could use the same issuance curve <span class="math">I</span> we use today, but where the deposit size used as input is <span class="math">D_a</span> instead of <span class="math">D</span>: the cumulative issuance would then be <span class="math">I(D_a)</span>, and the resulting yield per unit of stake <span class="math">\frac{I(D_a)}{D}</span>. Notably, <span class="math">I</span> is monotonically increasing, so, whenever <span class="math">D_a &lt; D</span>, the cumulative issuance <span class="math">I(D_a)</span> is less than the maximum issuance <span class="math">I(D)</span> that would be possible at this deposit size, with full consolidation. The yield gap <span class="math">\frac{I(D) - I(D_a)}{D}</span> between the current yield and the yield with full consolidation then acts as a consolidation incentive.</p>
<p>Consolidation incentives aside, another way to think about this proposal is that we simply pay for the economic security we get, at least from a single committee: if today our security budget for <span class="math">X</span> amount of deposits is <span class="math">Y</span>, as expressed by <span class="math">I(X) = Y</span>, we would now be wiling to pay <span class="math">Y</span> in order to get <span class="math">X</span> amount of <em>active</em> deposits. To get an idea of what this looks like in practice, here’s a color plot of the yield for <span class="math">(D, \frac{D_a}{D})</span> (starting from <span class="math">D = 1</span> to help the visualization).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/afced2f656e5db107f33e22007ab6b5fdd5859fc.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/a/f/afced2f656e5db107f33e22007ab6b5fdd5859fc_2_623x500.png" width="623" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#individual-consolidation-incentives-12" name="individual-consolidation-incentives-12"></a>Individual consolidation incentives</h4>
<p><em>Credit to Anders for raising the issue of differentiated risk and for proposing the kind of individual incentives we explore here</em></p>
<p>Though our exploration of collective incentives has found them to be decently strong, there is one factor we have not considered: validators with stake <span class="math">\ll T</span> have a better risk profile than validators with stake <span class="math">\ge T</span>. This is because they are in the active only a fraction of the time, which means two things:</p>
<ul>
<li>In a staking pool, accidental slashing caused by a bad setup can be caught early with only a fraction of the validators being subject to it</li>
<li>Tail risk of mass slashing or leaking, for example due to client bugs, is much lower, as in many cases this would only affect the active set. For a staking pool, this effectively caps the pool’s slashing exposure to a fraction of the stake, in almost all scenarios.</li>
</ul>
<p>We might then be unwilling to solely rely on collective incentives, which cannot properly account for the risk differentiation between consolidated and non consolidated validators, itself an individual anti-consolidation incentive. On the other hand, we are hesitant to use individual consolidation incentives, because differentiated rewards threaten our goal of solo staking viability. Faced with this dilemma, a potential approach to mitigate the consequences on solo staking viability is to try to set individual consolidation incentives that just offset the added risk from consolidation. The goal is for risk-adjusted rewards to be roughly equivalent for consolidated and non consolidated validators, so that the available choices of higher risk, higher reward and lower risk, lower rewards are similarly attractive. In particular, it is then at least in principle possible (though not guaranteed) to have a validator set where both setups coexist, so that we can aspire to both have a high consolidation ratio and solo staking viability.</p>
<p>Concretely, here’s a way we could go about this. Given the base yield <span class="math">y(D_a, D) = \frac{I(D_a, D)}{D}</span>, we can adjust the yield of a validator with <span class="math">S</span> stake to be <span class="math">y(D_a, D)(1 + \frac{\min(S,T)}{T}g(\frac{D_a}{D}))</span>, where <span class="math">g(x)</span> is decreasing and <span class="math">g(1) = 0</span>. In other words, a validator with <span class="math">S</span> stake gets additional <em>consolidation yield</em> <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T}g(\frac{D_a}{D})y(D_a, D)</span>, or equivalently its yield increases by a factor of <span class="math">\frac{\min(S,T)}{T}g(\frac{D_a}{D})</span>, up to <span class="math">g(\frac{D_a}{D})</span> for fully consolidated validators with <span class="math">S = T</span>. This factor decreases as <span class="math">\frac{D_a}{D}</span> grows, because there are diminishing returns to further consolidation (same reason why the staking yield falls as the total deposit size grows). In particular, it falls all the way to <span class="math">0</span> if <span class="math">\frac{D_a}{D}</span> goes to <span class="math">1</span>, restoring the base yield <span class="math">y(D_a, D)</span> for everyone, and generally making the rewards less and less differentiated as more consolidation occurs. The idea is that an equilibrium will be reached where <span class="math">g(\frac{D_a}{D})</span> just about compensates for the additional risk from consolidating, and further consolidation is not incentivized. We can even set <span class="math">g</span> to reach <span class="math">0</span> at some lower level of consolidation that we are happy with, leaving more space for staking with non consolidated validators to be economically viable. For example, if <span class="math">g(0.8) = 0</span>, then a validator with 32 ETH gets the same yield, and less risk, as a validator with 1024 ETH, even if 20% of the stake is made up of 32 ETH validators.</p>
<p>Let’s now look at a specific form of <span class="math">g</span>. The simplest possible choice is a linear function, which is fully determined by <span class="math">g(0)</span>, the initial yield increase factor when there is no consolidation at all. The function is then simply <span class="math">g(x) = g(0)(1 - x)</span>. For example <span class="math">g(x) = \frac{1-x}{4}</span>, where the maximum yield increase is 25%. The extra yield of a validator with stake <span class="math">S</span> is:<br />
<span class="math">y_c(D_a, D, S) = g(0)\frac{\min(S,T)}{T} \cdot y(D_a, D) \cdot (1 - \frac{D_a}{D})</span></p>
<p>Let’s see what this looks like in combination with the collective incentives introduced <a href="https://ethresear.ch#Collective-consolidation-incentives">in the previous section</a>, where issuance is based on <span class="math">D_a</span>, i.e., <span class="math">y(D_a, D) = \frac{I(D_a)}{D}</span>, and <span class="math">I</span> is the current issuance curve <span class="math">I(x) = c\sqrt{x}</span>. The maximum consolidation yield, or the yield advantage of a consolidated validator over a regular one, is:</p>
<p><span class="math">y_c(D_a, D, S=T) = g(0) \cdot y(D_a, D) (1 - \frac{D_a}{D})  = \\
= g(0) \cdot c \cdot \frac{\sqrt{D_a}}{D}(1 - \frac{D_a}{D}) = \\ g(0) \cdot c \cdot \frac{1}{\sqrt{D_a}} \frac{D_a}{D}(1 - \frac{D_a}{D})</span></p>
<p>The next color plot shows <span class="math">y_c(D_a, D, S=T)</span> as a function of <span class="math">\frac{D_a}{D}</span> and <span class="math">D_a</span>, for <span class="math">g(0) = \frac{1}{4}</span> (some portion on the upper left corner is infeasible, because <span class="math">D</span> would be <span class="math">&gt; 120M</span>). Horizontally, the function looks like <span class="math">x(1-x)</span>: the consolidation yield is low at low consolidation levels, when collective incentives are strong, and at high consolidation levels, when we don’t have a strong requirement for more consolidation and we are more worried about the economic viability of running non consolidated validators. Vertically it looks like <span class="math">\frac{1}{\sqrt{y}}</span>, with the consolidation yield slowly falling off as <span class="math">D_a</span> grows and we have less need for consolidation in general, since the economic security of the active set is determined by <span class="math">D_a</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/c/fc72bbb9885865bf40afe632e841d2ab2ff06e70.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/f/c/fc72bbb9885865bf40afe632e841d2ab2ff06e70_2_586x500.png" width="586" /></a></div><p></p>
<p>We can of course very easily modify any such function <span class="math">g</span> so that the incentives fall to <span class="math">0</span> after a certain consolidation level <span class="math">r_0 \in [0,1]</span>, by replacing <span class="math">g</span> with <span class="math">\tilde{g}(x) = \max(g(\frac{x}{r_0}), 0)</span>, which squeezes <span class="math">g</span> in the range <span class="math">[0,r_0]</span> and sets the consolidation yield to <span class="math">0</span> afterwards. For example, this is the consolidation yield with <span class="math">r_0 = 80\%</span>, starting from the previous <span class="math">g(x) = \frac{1-x}{4}</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/b/1bf37fb8df61c4442a5054ccdaf8d55b02c351f9.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/b/1bf37fb8df61c4442a5054ccdaf8d55b02c351f9_2_573x500.png" width="573" /></a></div><p></p>



<h2><a class="anchor" href="https://ethresear.ch#appendix-13" name="appendix-13"></a>Appendix</h2>
<h3><a class="anchor" href="https://ethresear.ch#validator-capping-active-validator-set-variance-14" name="validator-capping-active-validator-set-variance-14"></a>Validator capping: active validator set variance</h3>
<p>Let’s also get an upper bound on the variance of the active validator set size. <span class="math">\mathbb{V}[|V_a|] = \mathbb{V}[\sum_{i\in V} \chi_{\{i \in V_a\}}] = \sum_{i\in V} \mathbb{V}[\chi_{\{i \in V_a\}}]</span>, since each validator is sampled independently. Moreover, <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = 0</span> whenever <span class="math">S_i \ge T</span>, since validator <span class="math">i</span> is then always in <span class="math">V_a</span>.<br />
For <span class="math">S_i &lt; T</span>, the variance is <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = p(S_i)(1 - p(S_i)) = \frac{S_i}{T}(1 - \frac{S_i}{T})</span>, which is maximized when <span class="math">p(S_i) = \frac{1}{2}</span>, or equivalently when <span class="math">S_i = \frac{T}{2}</span>, in which case <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = \frac{1}{4}</span>. Therefore, <span class="math">\mathbb{V}[|V_a|] \le \frac{1}{4}|V|</span>.</p>
<p>Concretely, say we keep a minimum balance of 32 ETH, so that the maximum validator set size <span class="math">|V|</span> is ~4M. The standard deviation of <span class="math">|V_a|</span> is then bounded by <span class="math">\frac{\sqrt{|V|}}{2} \approx 1000</span>. The probability of deviations beyond 10k is then vanishingly low. We can then even explicitly cap the active validator set size, say at 40k validators. Doing so introduces only a tiny correlation to the sampling of different validators, because sampling is completely unaffected other than in the exceedingly rare events of massive deviations.</p>
<h3><a class="anchor" href="https://ethresear.ch#collective-incentives-15" name="collective-incentives-15"></a>Collective incentives</h3>
<h4><a class="anchor" href="https://ethresear.ch#quantifying-the-individual-effect-of-collective-consolidation-incentives-16" name="quantifying-the-individual-effect-of-collective-consolidation-incentives-16"></a>Quantifying the individual effect of collective consolidation incentives</h4>
<p>Let’s look into the consolidation incentives a bit more quantitatively. While it is true that there is always some consolidation incentive whenever consolidation is at all possible, we should also consider how strong these incentives are for various stakers. In particular, the strength of the incentives varies based on how large a staker is, because a consolidation increases yield <em>for everyone</em>, not just for the party which peforms it. In other words, the gains of a consolidation are socialized, to avoid having a sort of consolidation reward, which would effectively disadvantage smaller validators that cannot access it. Consolidation incentives are therefore stronger the larger a validator is. On the one hand, this means that sufficiently large validators have a strong incentive to consolidate, which means we should expect <span class="math">D_a</span> to always represent at least a meaningful portion of the total stake <span class="math">D</span>. On the other hand, it means that small but still meaningfully sized stakers (e.g. 1%) might not be particularly incentivized to consolidate.</p>
<p>To quantify this, let’s look at how much of an issuance increase there is in the event of the full consolidation of a staker having a fraction <span class="math">p</span> of the total stake <span class="math">D</span>, when <span class="math">\frac{D_a}{D} = r</span>. Here we assume that the stake <span class="math">pD</span> in question is initially not consolidated at all, and neglect the small effect it has on <span class="math">D_a</span> (e.g. if <span class="math">T = 1024</span>, a minimum balance validator only increases <span class="math">D_a</span> by 1/32 of its stake). Issuance, and thus yield, increases by a factor of <span class="math">\frac{I(D_a + pD) - I(D_a)}{I(D_a)} = \frac{I((r + p)D)}{I(rD)} - 1</span>. Plugging in the definition of <span class="math">I</span>, we can simplify this to <span class="math">\sqrt{1 + \frac{p}{r}} - 1</span>. As expected, the consolidation incentives grow with <span class="math">p</span>. It is also expected that they fall with <span class="math">r</span>, since the issuance curve <span class="math">I</span> is concave. As it turns out, there’s no dependency on <span class="math">D</span> for this particular form of <span class="math">I</span>.</p>
<p>We now plot <span class="math">100(\sqrt{1 + \frac{p}{r}} - 1)</span>, the <em>percentage</em> of yield increase that every validator experiences when a fraction <span class="math">p</span> of the stake is fully consolidated, starting from <span class="math">D_a = rD</span>. We restrict <span class="math">r</span> to the range <span class="math">[0.1, 1]</span> for ease of visualization, because the consolidation incentives blow up for <span class="math">r</span> near <span class="math">0</span>, as we would wish. Notice that the minimum <span class="math">r</span> is actually <span class="math">1/32</span> for <span class="math">T = 1024</span> and minimum balance 32 ETH.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/ccde75a7bf33c1105849424713dceee8fd5b151d.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/ccde75a7bf33c1105849424713dceee8fd5b151d_2_598x500.png" width="598" /></a></div><p></p>
<p>On the other hand, the <em>absolute</em> yield increase <span class="math">100\cdot\frac{I(D_a + pD) - I(D_a)}{D_a}</span> is not independent of <span class="math">D</span>. We plot it here specifically for <span class="math">D = 30M</span> ETH. For lower values of <span class="math">D</span>, the consolidation incentives only get stronger in absolute terms.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/3/53bb8a566b7597b844788fa776551f98df5b36c3.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/3/53bb8a566b7597b844788fa776551f98df5b36c3_2_567x500.png" width="567" /></a></div><p></p>
<p>Finally, we also plot the yearly ETH returns from consolidation, <span class="math">(I(D_a + pD) - I(D_a))\cdot \frac{p}{r}</span>, again for <span class="math">D = 30M</span> ETH.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68a7e7faee22708549d1b4c2738e1016de2cf661.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68a7e7faee22708549d1b4c2738e1016de2cf661_2_578x500.png" width="578" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#generalizing-collective-incentives-17" name="generalizing-collective-incentives-17"></a>Generalizing collective incentives</h4>
<p>When <span class="math">I</span> is our current issuance curve, <span class="math">I(x) = c\sqrt{x}</span>, we have that <span class="math">I(D_a) = c\sqrt{D_a} = c \sqrt{D} \sqrt{\frac{D_a}{D}} = I(D)\sqrt{\frac{D_a}{D}}</span>. In other words, we can think about the previous proposal as incentivizing a high <span class="math">\frac{D_a}{D}</span> ratio by directly a  applying an issuance penalty based on it. More generally, we can let the issuance be <span class="math">I(D_a, D) = I(D) \cdot \delta(\frac{D_a}{D})</span> for any <span class="math">\delta</span> such that <span class="math">\delta(0) = 0</span> and <span class="math">\delta(1) = 1</span>. With this, the yield increase from consolidating is exactly <span class="math">\frac{I(D)}{D} \cdot (\delta(r + p) - \delta(p))</span>, i.e., a fraction <span class="math">\delta(r + p) - \delta(r)</span> of the maximum yield available at deposit size <span class="math">D</span>. The percentage yield increase is instead <span class="math">\frac{\delta(r + p) - \delta(r)}{\delta(r)}</span>. The simplest case is <span class="math">\delta(r) = r</span>, where <span class="math">I(D_a, D) = I(D) \cdot \frac{D_a}{D}</span>, in which case the yield increase is simply <span class="math">p \frac{I(D)}{D}</span>, constant in <span class="math">r</span>, and the percentage yield increase is <span class="math">\frac{p}{r}</span>.</p>
<p>In this form, we can more clearly separate the design of incentives to stake from that of incentives to consolidate the stake: <span class="math">I(D)</span> provides the <em>maximum</em> possible incentive to stake at a given total deposit level <span class="math">D</span>, while <span class="math">\delta</span> regulates the incentive to consolidate at a given ratio <span class="math">\frac{D_a}{D}</span>. We can for example have <span class="math">I</span> being concave, as it is currently, but <span class="math">\delta</span> linear as in the previous example: the protocol then considers stake deposits to have diminishing returns, while it believes consolidation to be equally valuable regardless of where <span class="math">\frac{D_a}{D}</span> currently sits.</p>
<h4><a class="anchor" href="https://ethresear.ch#discouragement-attacks-18" name="discouragement-attacks-18"></a>Discouragement attacks</h4>
<p>At any point, it is possible to increase <span class="math">D</span> while barely increasing <span class="math">D_a</span>, by activating validators with minimum balance. Thus, the issuance <span class="math">I(D_a)</span> is approximately constant, but distributed to more stake. This is the same <a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171#h-53-discouragement-attacks-32">discouragement attack</a> that would be possible with a constant issuance curve, or with issuance capped at some maximum value, where the yield also decreases like <span class="math">\frac{1}{D}</span>. While worse than today, where it decreases like <span class="math">\frac{1}{\sqrt{D}}</span>, this discouragement attack is nothing like the ultra cheap griefing vector that would arise with if we were to <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-validator-count" rel="noopener nofollow ugc">use issuance to target a validator count</a>. For example, say we started reducing issuance past our ideal target of ~30k validators, and were to go negative at 40k. Then, activating a few thousands minimum balance validators, in the order of 0.01% to 0.1% of the stake, would be enough to make yields go negative. On the other hand, in the context of the discouragement attack we are considering here, reducing yield by a factor of <span class="math">k</span> requires increasing the deposit size by a factor of <span class="math">k</span>. For example, halving issuance when <span class="math">D = </span> 20M requires depositing another 20M.</p>
<h4><a class="anchor" href="https://ethresear.ch#stake-capping-19" name="stake-capping-19"></a>Stake capping</h4>
<p>If we were to set the issuance based on <span class="math">D_a</span>, we would not be able to immediately adopt any issuance curve that reduces issuance past some deposit size, like the ones discussed <a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171/1">here</a> and <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">here</a>. The reason for that is simple: if issuance goes down past a certain value of <span class="math">D_a</span>, but it turns out that the yield at that point is still attractive, the incentives are such that <span class="math">D</span> would still grow (more stake wants yield at these levels) while <span class="math">D_a</span> would not (growing <span class="math">D_a</span> lowers yield). In fact, instead of consolidation incentives, we end up having incentives for splitting up stake over multiple validators, so as to decrease <span class="math">D_a</span> and keep it at the point of maximum issuance! Meanwhile, stake capping is not achieved, at least not any more than we would already achieve it by capping issuance at the maximum value, rather than having it decrease afterwards.</p>
<p>If we did want to adopt some form of stake capping, we would then need to do things a bit differently. We could let the issuance be <span class="math">I(D_a, D) = I(D_a) - f(D)</span>, where <span class="math">f</span> acts to reduce the issuance past some critical <em>total</em> deposit size. Intuitively, the goal is to try to ensure two things at once: that we have enough <span class="math">D_a</span>, and that we do not have too much <span class="math">D</span>. For example:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/8/c83ba4769d0fc0c8db841d28c0210dfdd3ab53d2.png" title=""><img alt="" height="227" src="https://ethresear.ch/uploads/default/optimized/3X/c/8/c83ba4769d0fc0c8db841d28c0210dfdd3ab53d2_2_690x227.png" width="690" /></a></div><p></p>
<p>To help visualizing the effect of this further, here are the cumulative issuance and yield while holding <span class="math">\frac{D_a}{D} = 0.8</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/4/044c55ed764d7dfddac4c2df5be73783c8017800.png" title=""><img alt="" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/0/4/044c55ed764d7dfddac4c2df5be73783c8017800_2_690x230.png" width="690" /></a></div><p></p>
<p>Finally, here is a color plot of the yield in the <span class="math">(D, \frac{D_a}{D})</span> space. <span class="math">D</span> starts at 2 to help the visualization be effective.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/4/744db3435b9b033af6e55309e19068c435be1ffb.png" title=""><img alt="" height="463" src="https://ethresear.ch/uploads/default/optimized/3X/7/4/744db3435b9b033af6e55309e19068c435be1ffb_2_690x463.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#individual-incentives-20" name="individual-incentives-20"></a>Individual incentives</h3>
<h4><a class="anchor" href="https://ethresear.ch#total-issuance-21" name="total-issuance-21"></a>Total issuance</h4>
<p>The total <em>extra</em> issuance is:</p>
<p><span class="math">I_c(D_a, D) = \sum_{i \in V} y_c(D_a, D, S_i) S_i = g(0) y(D_a, D)(1 - \frac{D_a}{D}) \sum_{i \in V} p(S_i)S_i = \\ = g(0)y(D_a, D)\cdot D_a(1 - \frac{D_a}{D}) = g(0)I(D_a)\cdot \frac{D_a}{D}(1 - \frac{D_a}{D}) = \\
= g(0) \sqrt{D} \sqrt{\frac{D_a}{D}}\cdot \frac{D_a}{D}(1 - \frac{D_a}{D}) = g(0)I(D) \sqrt{\frac{D_a}{D}}\cdot \frac{D_a}{D}(1 - \frac{D_a}{D})</span></p>
<p>The total issuance then is:</p>
<p><span class="math">I_T(D_a, D) = I(D_a) + I_c(D_a, D) = I(D_a)(1 + g(0) \frac{D_a}{D}(1 - \frac{D_a}{D})) = \\
= c \sqrt{D} \sqrt{\frac{D_a}{D}}(1 + g(0)\cdot \frac{D_a}{D}(1 - \frac{D_a}{D})) = \\
= I(D) \sqrt{\frac{D_a}{D}} (1 + g(0)\frac{D_a}{D}(1 - \frac{D_a}{D})) = I(D) \cdot h(\frac{D_a}{D})</span>, where <span class="math">h(x) = \sqrt{x}(1 + g(0)x(1-x))</span>. For <span class="math">g(0) = \frac{1}{4}</span>, we have that <span class="math">h(x) \le 1</span> for <span class="math">x \in [0,1]</span>, so <span class="math">I(D)</span> remains an upper bound on the total issuance.</p>
<p><img alt="" height="435" src="https://ethresear.ch/uploads/default/original/3X/5/4/543c7981de3b9feeff11aff29ac6556c3f9ad5cf.png" width="547" /></p>
<h4><a class="anchor" href="https://ethresear.ch#generalizing-individual-consolidation-incentives-22" name="generalizing-individual-consolidation-incentives-22"></a>Generalizing individual consolidation incentives</h4>
<p>More generally, we can choose any consolidation yield curve <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} y_c(D_a, D)</span>, not necessarily depending on <span class="math">y(D_a, D)</span>, or even any curve <span class="math">y_c(D_a, D, S)</span> with a different kind of dependency on <span class="math">S</span>. An interesting example of the first kind is the curve <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} (y(D) - y(D_a, D))</span>, where <span class="math">y_c(D_a, D, S)</span> essentially interpolates between the yield <span class="math">y(D) = y(D_a = D, D)</span> that would be paid out to a fully consolidated validator set at deposit size <span class="math">D</span>, and the base yield <span class="math">y(D_a, D)</span> paid out at the current consolidation level. In other words, a validator with <span class="math">T</span> stake always gets paid the maximum possible yield for deposit size <span class="math">D</span>, <span class="math">y(D)</span>, regardless of the consolidation level achieved by the whole validator set, while validators with minimum stake get paid closer to the base yield <span class="math">y(D_a, D)</span>, and their yield linearly increases to <span class="math">y(D)</span> as they consolidate. In this case, the consolidation incentives are quite a bit stronger at lower consolidation levels.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/5229207a5722061af774a3d38e53aa0d28a08a89.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/5229207a5722061af774a3d38e53aa0d28a08a89_2_573x500.png" width="573" /></a></div><p></p>
<p>While the absolute yield increase falls with <span class="math">D_a</span>, the percentage yield increase from consolidating does not. As it turns out, it only depends on <span class="math">\frac{D_a}{D}</span>:<br />
<span class="math">\frac{y_c(D_a, D)}{y(D_a, D)} = \frac{y(D) - y(D_a, D)}{y(D_a, D)} =
\frac{y(D)}{y(D_a, D)} - 1 = \sqrt{\frac{D}{D_a}} - 1 </span></p>
<p>In other words, this also fits the previous form <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} g(\frac{D_a}{D}) y(D_a, D)</span>, with <span class="math">g(x) = \sqrt{\frac{1}{x}} - 1</span> instead of a linear function.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/a/4ab4a1cd832f6644730fd660799e1167f71af570.png" title=""><img alt="" height="293" src="https://ethresear.ch/uploads/default/optimized/3X/4/a/4ab4a1cd832f6644730fd660799e1167f71af570_2_690x293.png" width="690" /></a></div><p></p>
<p>Since <span class="math">y(D_a, D) + y_c(D_a, D, S) \le y(D)</span>, it still holds that <span class="math">I(D)</span> is a bound on the total issuance. In fact, the total issuance can be worked out to be <span class="math">I_T(D_a, D) = I(D_a) + I_c(D_a, D) = I(D) \sqrt{\frac{D_a}{D}}(1 + \sqrt{\frac{D_a}{D}} (1 - \sqrt{\frac{D_a}{D}})) = I(D) h(\frac{D_a}{D})</span>, with <span class="math">h(x) = \sqrt{x}(1 + \sqrt{x}(1 - \sqrt{x})))</span>, which we compare here to the previous example:</p>
<p><img alt="" height="435" src="https://ethresear.ch/uploads/default/original/3X/8/e/8e42613ed48e495edae62b74cecc8f994f7499a9.png" width="547" /></p>
            <p><small>3 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 07:22:10 +0000</pubDate>
</item>
<item>
<title>Number Duplicate Messages in Ethereum's Gossipsub Network</title>
<link>https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921</link>
<guid>https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921</guid>
<content:encoded><![CDATA[
<div> 关键词：GossipSub、Ethereum、消息重复、Hermes、优化建议

总结:<br />
GossipSub是Ethereum P2P网络中的消息广播协议，其设计允许一定程度的消息重复。研究团队使用工具Hermes追踪GossipSub性能，发现正常情况下每个消息最多接收3次重复（不包括通过IHAVE/IWANT控制消息传播的情况）。研究发现，通过网格的重复消息保持在3次或以下，但通过Gossip机制可能会有额外的重复。团队提出两点优化建议：限制并发IWANT请求的数量（类似Kademlia的alpha参数）和降低心跳频率，以减少IHAVE消息和额外重复。最后，尽管存在一些边缘情况，但大部分重复消息并不构成重大问题。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-tldr-1" name="summary-tldr-1"></a>Summary &amp; TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the “<a href="https://ethresear.ch/t/gossipsub-network-dynamicity-through-grafts-and-prunes/19750">Gossipsub Network Dynamicity through GRAFTs and PRUNEs</a>” in this post we investigate the number of messages and duplicated messages seen by our node, per topic. There is no public data on the overhead that broadcasting messages and control data over the network imply on each participating node.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer.</a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions. The results reported here are from a 3.5hr trace.</p>
<p><strong>Study Description:</strong> Gossipsub’s design is inherently allowing for message duplicates. A brief model we develop shows that it’s normal to receive each message up to 3 extra times (as a duplicate). This excludes the gossip mechanism which propagates messages through the IHAVE/IWANT control message sequence.</p>
<p><strong>TL;DR:</strong> We find that indeed duplicates through mesh stay in the order of 3 per message or below, which, however, doesn’t count for duplicates through gossip. For instance, there are edge cases where a message is requested (and responded to) through an IWANT message while the actual message is already in transit. Eventually, this results in an extra duplicate. We make two recommendations:</p>
<ol>
<li><strong>Reduce the number of concurrent <code>IWANT</code> messages we send through a limiting factor</strong> (somewhat similar to kademlia’s <code>alpha</code> parameter).</li>
<li><strong>Lower the current <code>heartbeat</code> frequency (i.e., increasing the <code>heartbeat</code> interval) from 0.7 seconds to 1 second</strong> (as per the original protocol spec and recommendation). This would reduce the excessive <code>IHAVE</code> messages and reduce the chances of generating extra duplicates.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#background-2" name="background-2"></a>Background</h1>
<p><a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.1.md" rel="noopener nofollow ugc">GossipSub</a> is a routing system that can be enabled on libp2p’s <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/README.md" rel="noopener nofollow ugc">PubSub</a> message broadcasting protocol. This protocol organizes the message broadcasting channels on what is commonly known as Topics, where peers subscribed to a given topic keep a particular subset of connected peers for that particular topic. This subset of peer connections per topic is also known as “mesh”.</p>
<p>In the case of GossipSub, the standard broadcasting mechanism of PubSub is extended with a few sets of enhancements that make it:</p>
<ul>
<li>more efficient than what is commonly called flooding, reducing the protocol’s bandwidth usage</li>
<li>more resilient, as the protocol:
<ul>
<li>shares metadata of seen messages over sporadic Gossip messages (for censorship or Sybil attacks)</li>
<li>keeps a local score for each mesh-connected peer to ensure healthy and useful connections, where each peer keeps connections with the highest scoring neighbours</li>
<li>avoids sharing a message with peers that already sent the message to us</li>
</ul>
</li>
</ul>
<p>This all looks good on paper. However, there is still no public data on the overhead that broadcasting messages and control data over the network imply on each participating node. Even more importantly, how much room for improvement exists within the protocol and the implementations to make it more optimal.</p>
<h2><a class="anchor" href="https://ethresear.ch#expected-results-3" name="expected-results-3"></a>Expected Results</h2>
<p>Message propagation through the GossipSub’s mesh considers some occasional duplicates that can arrive as the message might come from different peers within the mesh:</p>
<p>Given:</p>
<ul>
<li><code>n</code> as the number of nodes in the graph</li>
<li><code>k</code> as the mesh degree</li>
<li><code>l</code> as the number of connections (links) between two nodes <span class="math">l = \frac{nk}{2}</span></li>
</ul>
<p>The number of links used to propagate a message to all nodes in the graph can be defined as <code>n-1 ~= n</code>. The links form a spanning tree with the message origin as root (<code>n</code> is big enough compared to the initial sender link, so that it can be considered negligible).</p>
<p>The number of links not used to propagate a specific message corresponds to <span class="math">l-n = \frac{n(k-2)}{2}</span>.</p>
<p>This means that on average each node will have 1 link used to receive a message, 1 to propagate it to a peer that doesn’t have it yet. And the rest <code>k-2</code>, to either send or receive the duplicate message.</p>
<p>Assuming that <span class="math">\frac{k-2}{2}</span> links are used to send the message to peers that already have it, it means that we receive <span class="math">\frac{k-2}{2}</span> duplicate messages.</p>
<p>In the case of Ethereum, <code>k=8</code>, and therefore, it follows that <span class="math">\frac{k-2}{2} = 3</span>. So, <strong>the expected value is to receive 3 duplicate messages for each message</strong>.</p>
<h1><a class="anchor" href="https://ethresear.ch#results-4" name="results-4"></a>Results</h1>
<p>As previously introduced, this report aims to provide insights on:</p>
<ul>
<li>the number of duplicate messages that we receive per each shared message in the network,</li>
<li>the extra bandwidth that we are spending on duplicates,</li>
<li>any existing unexpected behavior or potential optimization that could be applied on GossipSub.</li>
</ul>
<blockquote>
<p>NOTES:<br />
The numbers presented in the following sections belong to the same 3.5 hours run of <code>Hermes</code> as the previous studies, with the following extra configuration:</p>
<ul>
<li>The experiment is ran on the <code>Holesky</code> network</li>
<li>Our node was subscribed to the following topics:
<ul>
<li><code>beacon_block</code></li>
<li><code>beacon_aggregate_and_proof</code></li>
<li><code>sync_commmittee_contribution_and_proof</code></li>
<li><code>attester_slashing</code></li>
<li><code>proposer_slashing</code></li>
<li><code>voluntary_exit</code> * (check <code>Hermes</code> issue → <a class="inline-onebox" href="https://github.com/probe-lab/hermes/issues/24" rel="noopener nofollow ugc">Broadcasting of invalid `voluntary_exit` messages to mesh peers · Issue #24 · probe-lab/hermes · GitHub</a>)</li>
<li><code>bls_to_execution_change</code></li>
</ul>
</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#overall-number-of-messages-5" name="overall-number-of-messages-5"></a>Overall Number of Messages</h2>
<p>To give a little bit of context, the report starts by taking a look at the number of messages and the respective duplicates received over time. The following graph shows the number of <code>HANDLED</code> events by the libp2p-host in comparison with the <code>DELIVERED</code> and <code>DUPLICATED</code> ones.</p>
<blockquote>
<p>NOTE: In this report we will consider the <code>DELIVER</code> events as unique identifier of the arrival of a message. This is because the internal event tracer at the libp2p host notifies of the arrival of a unique message at multiple levels, which in turn, makes the <code>HANDLED</code> and <code>DELIVER</code> events at the arrival of a new message the exact same notification, just at different levels of the host.</p>
</blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65a05809dfbc2915a07ceadedbf9cd8d85f16fe8.jpeg" title="overall-number-of-events"><img alt="overall-number-of-events" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/6/5/65a05809dfbc2915a07ceadedbf9cd8d85f16fe8_2_517x309.jpeg" width="517" /></a></div><p></p>
<ul>
<li>The number of unique messages (i.e., <code>HANDLE_MESSAGE</code>) stays steady around the 3,000 and 3,200 unique messages per minute.</li>
<li>By looking closer into the messages per topic (not shown here), we observe that the topic with the highest message frequency is the <code>beacon_aggregate_and_proof</code> one, receiving over 90% of the tracked unique messages.</li>
<li>There are some duplicated spikes at the <code>beacon_block</code> topic that reach up to 60 duplicates  in some occasions.</li>
<li>The number of duplicates seems to vary quite wildly over time, which can be related to the number of connections per mesh (as per the analysis done further up which showed that 3 duplicates per message are expected).</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#number-of-duplicate-messages-6" name="number-of-duplicate-messages-6"></a>Number of Duplicate Messages</h2>
<p>When it comes to the actual number of <code>DUPLICATE</code> messages, the following figures show that number of duplicates can oscillate over time.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/d/edacb4d1d050448d2a5b17ef6c67ed0cb3ca42e0.png" title="duplicates-per-topic"><img alt="duplicates-per-topic" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/e/d/edacb4d1d050448d2a5b17ef6c67ed0cb3ca42e0_2_517x309.png" width="517" /></a></div><p></p>
<p>Clearly, the <code>beacon_block</code> topic seems to be the only one generating the largest number of spikes at times.</p>
<h2><a class="anchor" href="https://ethresear.ch#cdf-of-duplicate-messages-7" name="cdf-of-duplicate-messages-7"></a>CDF of Duplicate Messages</h2>
<p>The following graph shows the Cumulative Distribution Function (CDF) of the duplicates per message per topic. In the graph, we can see that:</p>
<ul>
<li>smaller but more frequent messages like the <code>beacon_ggregate_and_proof</code> and <code>sync_commitee_contributions</code> do have fewer duplicates.
<ul>
<li>between 32% and 45% of the messages do not have any duplicates.</li>
<li>50% of the messages are received with less than 2 duplicate messages, keeping the mean lower than the theoretical target of <code>3</code> duplicates per message.</li>
<li>the upper tail shows that less than 10% of the messages get more than 4 duplicates, with a cap at 8-10 duplicates (i.e., the node’s mesh size, <code>D</code>).</li>
</ul>
</li>
<li>the case of the <code>beacon_blocks</code> is completely different.
<ul>
<li>there are almost no recorded messages without duplicates (1%-2%).</li>
<li>54% of the messages report the expected <code>3</code>  duplicates from the mesh</li>
<li>Taking look at the tail of the CDF (shown in the dropdown plot further down) there are a few messages that were received up to 34 or 40 times.</li>
</ul>
</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/1/0153b674d22c5c90c7fee45cbf880ec5b865d548.png" title="CDF-duplicates"><img alt="CDF-duplicates" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/0/1/0153b674d22c5c90c7fee45cbf880ec5b865d548_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#correlation-between-message-size-and-number-of-duplicates-8" name="correlation-between-message-size-and-number-of-duplicates-8"></a>Correlation between Message Size and Number of Duplicates</h2>
<p>From the CDF above there seems to be a pattern of “the bigger the size of the message, the more duplicates it has”. So we went a step further to investigate if there is indeed a correlation. The following graph shows that the correlation between the size of a message and the number of duplicates is somewhat present but is not a norm or at least doesn’t follow any fixed pattern.</p>
<p>The figure is complemented by two auxiliary quartile plots or “boxplots”, which represent the given distribution of points of their respective axis, helping us understand that:</p>
<ul>
<li><code>sync_commmittee_contribution_and_proof</code> messages are the smallest ones in size, which also correlates with the smallest ratio of duplicate messages.</li>
<li><code>beacon_aggregate_and_proof</code> messages are the second ones in size, having also a bigger tail of duplicates on the Y concentration plot.</li>
<li><code>beacon_block</code> messages, despite being the ones with the widest variation in size, do not follow any particular pattern that could correlate the message size with the number of duplicates.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb40e85a2381cd48f38c553e329c3f0083a27196.png" title="msg-size-number-of-duplicates"><img alt="msg-size-number-of-duplicates" height="374" src="https://ethresear.ch/uploads/default/optimized/3X/f/b/fb40e85a2381cd48f38c553e329c3f0083a27196_2_383x374.png" width="383" /></a></div><p></p>
<p>As such, we conclude that <strong>there is no correlation between message size and number of duplicates</strong>.</p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-time-of-duplicates-9" name="arrival-time-of-duplicates-9"></a>Arrival Time of Duplicates</h2>
<p>Reducing the number of duplicates has already been a topic of discussion in the community. There are already some proposals like <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2 </a> that spotted this large number of duplicated messages previously, proposing the addition of a new control <code>IDONTWANT</code> message that could not only notify other peers that we already got a message, but also cancel the <code>IWANT</code> ongoing messages.</p>
<p>In order to see how effective the <code>IDONTWANT</code> control message would be, we’ve computed the time between the first delivery of each message and their respective first duplicate. This is done to validate that there is enough time to send the <code>IDONTWANT</code> message once a new message is received (prior to the message validation) and before the duplicate starts being sent over.</p>
<p>The following graph gives the time between the delivery time of a message and the time to the first duplicated message in seconds.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e87ebed2ebacfb8abd79473ceb14e2af58bc7b82.png" title="arrival-cdf"><img alt="arrival-cdf" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e87ebed2ebacfb8abd79473ceb14e2af58bc7b82_2_517x309.png" width="517" /></a></div><p></p>
<p>Results show that 50% of the duplicated beacon blocks arrive within 73 milliseconds, roughly an entire Round Trip Time (RTT) with a well connected peer. In practice, this means that <strong>the <code>IDONTWANT</code> message could prevent at least the other 50% of messages that arrive between 73 milliseconds and 2 seconds of the first arrival</strong>.</p>
<p>We’ve spotted that a big part of the duplicated messages arrive from <code>IWANT</code> messages that we sent milliseconds before the arrival of the same message though the mesh.<br />
The <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2</a> proposal already contemplates <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md#cancelling-iwant" rel="noopener nofollow ugc">this scenario</a>, where the same <code>IDONTWANT</code> message could break or stop any ongoing responses to <code>IWANT</code> messages for that <code>msgID</code>.</p>
<p>In summary, we conclude that <strong>the <code>IDONTWANT</code> control message addition to Gossipsub will be a valuable enhancement that can indeed prevent the vast majority of duplicate messages</strong>.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-10" name="conclusions-and-takeaways-10"></a>Conclusions and takeaways</h1>
<blockquote>
<p>This set of conclusions have been extracted from running the <code>go-libp2p</code>  implementation and, although it also involves the traces of how other implementations interact with Hermes, it might be a biased conclusion from the point of view of the Go implementation.</p>
</blockquote>
<ol>
<li>
<p>We have identified that there is no limit on the number of peers that we simultaneously send <code>IWANT</code> messages to for the same <code>msgID</code>.<br />
We identify that this has some benefits:</p>
<ul>
<li>Concurrently fetches the message from multiple actors.</li>
<li>Bypasses bandwidth limitations of peer(s) we have sent <code>IWANT</code> messages to, since we have forwarded the <code>IWANT</code> message to multiple peers.</li>
</ul>
<p>However, it also has obvious downsides:</p>
<ul>
<li>
<p>We receive multiple duplicates from the peers that respond to our simultaneous <code>IWANT</code> request, consuming more bandwidth on both ends.</p>
</li>
<li>
<p>The message could be already on the wire through the mesh connections, so when the <code>IWANT</code> message responses arrive, the message was already delivered through the mesh.</p>
</li>
<li>
<p>There is no track of who we contacted for a given message, given that Gossipsub is:</p>
<ul>
<li>forwarding the message only the first time we see it, and</li>
<li>removing the peer that sent us the message from the list of peers we’re broadcasting the message to and forgetting about that peer.</li>
</ul>
<p>This makes the entire broadcasting process unaware of who sent us that message in <code>IHAVE</code>s, or who we are already contacting for a particular message - resulting in multiple duplicates.</p>
</li>
</ul>
<p><a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md#cancelling-iwant" rel="noopener nofollow ugc">Canceling ongoing <code>IWANT</code>messages</a> with <code>IDONTWANT</code> messages, which is a proposal included in <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2</a> is a valuable enhancement that will limit the number of duplicates.</p>
<h3><a class="anchor" href="https://ethresear.ch#recommendation-1-11" name="recommendation-1-11"></a><strong>Recommendation 1</strong></h3>
<p>We propose having a limiting factor (somewhat similar to kademlia’s <code>alpha</code> parameter), which would limit the number of concurrent <code>IWANT</code> messages we send for the same <code>msgID</code>.</p>
<hr />
<hr />
</li>
<li>
<p>The gossiping mechanism of Gossipsub acts as a backup mechanism to the broadcasting/mesh propagation part of the protocol for those messages that didn’t manage to reach all nodes in the network. The more frequent gossiping is, the higher its contribution becomes to message propagation (i.e., more messages are being requested through <code>IWANT</code> requests because they have not reached the entirety of the network).</p>
<p>An edge case that results from very frequent gossiping (i.e., small <code>heartbeat</code> interval) is that messages that are already in transit, but have not been downloaded completely, are being requested through an <code>IWANT</code> message. This inevitably results in a duplicate message once both messages arrive at their destination.</p>
<p>It is hard to quantify how often the message responses to <code>IWANT</code> messages are indeed future duplicates, but it is still worth pointing out that high heartbeat frequency increases the chances of those edge cases.</p>
<h3><a class="anchor" href="https://ethresear.ch#recommendation-2-12" name="recommendation-2-12"></a>Recommendation 2</h3>
<p>A quick and straightforward optimization is to <strong>lower the current <code>heartbeat</code> frequency (i.e., increasing the <code>heartbeat</code> interval) from 0.7 seconds to 1 second</strong> (as per the original protocol spec and recommendation). This would reduce the excessive <code>IHAVE</code> messages and reduce the chances of generating extra duplicates.</p>
<hr />
<hr />
</li>
<li>
<p>We have spotted some edge cases that may occur due to the “lack” of control over the triggered events at GossipSub (<code>IHAVE</code>/ <code>IWANT</code>).</p>
<p>It isn’t easy to judge from the logs whether those cases are just a matter of timing, as GossipSub replies to those events as interruptions (at least in the Go implementation), or if some of those cases are caused by a bug in one of the implementations.</p>
<p>We found that <strong>the number of messages where we received multiple duplicates from the same peer to just 1% of the total number of <code>beacon_blocks</code> received</strong>. We, therefore, conclude that this is not critical or an issue that requires further investigation.</p>
</li>
</ol>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 08:48:46 +0000</pubDate>
</item>
<item>
<title>Estimating Validator Decentralization Using p2p Data</title>
<link>https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920</link>
<guid>https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920</guid>
<content:encoded><![CDATA[
<div> 关键词：地理分布、验证器、Ethereum、共识层网络、节点连接

总结:<br />
文章探讨了Ethereum区块链中验证器的地理分布问题，重点关注了验证器客户端与 beacon 节点的分离。研究者通过分析验证器的职责、随机分配的委员会以及使用的网络协议，确定了验证器在短-lived attestation subnets上的活动作为调查核心。方法论包括监听节点订阅请求、收集和分析元数据，尤其是订阅的子网数量。然而，由于某些客户端的行为策略，实际观察到的短-lived子网订阅较少，限制了验证器数量的准确估计。结果仅提供了部分验证器的地理分布信息，且存在一些局限性，如最大估计值为62个验证器等。 <div>
<blockquote>
<p>Written by <a href="https://x.com/mempirate" rel="noopener nofollow ugc">Jonas</a> &amp; <a href="https://x.com/namn_grg" rel="noopener nofollow ugc">Naman</a> from <a href="https://x.com/chainbound_" rel="noopener nofollow ugc">Chainbound</a>.<br /><br />
This research was funded by the Robust Incentives Group at the Ethereum Foundation. This work is specifically related to ROP-8. Additional information can be found <a href="https://www.notion.so/bad7233658cc41f38b26e7b4f6cf6e8b?pvs=21" rel="noopener nofollow ugc">here</a>. We want to thank <a href="https://x.com/soispoke" rel="noopener nofollow ugc">soispoke</a>, the <a href="https://x.com/EthPandaOps" rel="noopener nofollow ugc">EF DevOps team</a>, <a href="https://migalabs.io/" rel="noopener nofollow ugc">MigaLabs</a> and <a href="https://probelab.io/" rel="noopener nofollow ugc">ProbeLab</a> for their advice and contributions!</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#table-of-contents-1" name="table-of-contents-1"></a>Table of Contents</h2>
<ul>
<li><a href="https://ethresear.ch#introduction">Introduction</a></li>
<li><a href="https://ethresear.ch#anatomy-of-a-validator">Anatomy of a validator</a></li>
<li><a href="https://ethresear.ch#attestation-duties-and-committees">Attestation duties and committees</a></li>
<li><a href="https://ethresear.ch#attestation-subnets">Attestation subnets</a>
<ul>
<li><a href="https://ethresear.ch#subnet-types">Subnet types</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#validator-footprints">Validator footprints</a></li>
<li><a href="https://ethresear.ch#methodology">Methodology</a>
<ul>
<li><a href="https://ethresear.ch#long-lived-subnets">Long-lived subnets &amp; node metadata</a></li>
<li><a href="https://ethresear.ch#short-lived-subnets">Short-lived subnets</a></li>
<li><a href="https://ethresear.ch#estimating-validator-counts">Estimating validator counts</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#architecture">Architecture</a>
<ul>
<li><a href="https://ethresear.ch#crawler">Crawler</a></li>
<li><a href="https://ethresear.ch#consumer">Consumer</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#results">Result</a></li>
<li><a href="https://ethresear.ch#limitations">Limitations</a></li>
<li><a href="https://ethresear.ch#references">References</a></li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>The geographical distribution of a validator set is <a href="https://collective.flashbots.net/t/decentralized-crypto-needs-you-to-be-a-geographical-decentralization-maxi/1385" rel="noopener nofollow ugc">one of the most critical factors</a> in determining a blockchain’s level of decentralization. Validator decentralization is vital for Ethereum. It enhances network security, resilience, and censorship resistance by distributing control and minimizing the risk of single points of failure or malicious attacks.</p>
<p>It is well known that Ethereum has a <a href="https://beaconcha.in/charts/validators" rel="noopener nofollow ugc">very large</a> validator set, but <strong>is this validator set geographically distributed?</strong> Ethereum has a substantial amount  of beacon nodes running on the consensus layer network, with current estimates at around ~12,000 active nodes (<a href="https://nodewatch.io/" rel="noopener nofollow ugc">source</a>). A beacon node serves as a <em>potential</em> entrypoint into the network for validators, but it is not representative of the actual validator distribution.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f1dda810cb6cc5f9d3db8c3c592d8167d16710e.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f1dda810cb6cc5f9d3db8c3c592d8167d16710e_2_500x500.jpeg" width="500" /></a></div><br />
<small><em>Probably not.</em></small><p></p>
<p>In this article, we present the methodology and results of an investigation aiming to address this question. We start with some context about the logical components making up a validator, then proceed with some potential methods of identifying validators on the beacon P2P network. We then expand on our chosen methodology and finally present the results.</p>
<h2><a class="anchor" href="https://ethresear.ch#anatomy-of-a-validator-3" name="anatomy-of-a-validator-3"></a>Anatomy of a validator</h2>
<p>An Ethereum validator is a virtual entity that consists of a balance, public key and other properties on the beacon chain. They are roughly responsible for 4 things:</p>
<ol>
<li>Proposing new blocks</li>
<li>Voting on other block proposals (attesting)</li>
<li>Aggregating attestations</li>
<li>Slashing other validators in case they commit faults</li>
</ol>
<p>A <em>validator client</em> is the piece of software that executes these responsibilities for each of its registered validator keys (which can be many). But a validator client on its own cannot connect to the P2P beacon network to talk directly to other validators. Instead, it connects to an entity known as a <em>beacon node</em>, which is a standalone client that maintains the beacon chain and communicates with other beacon nodes.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68536fc182f09a1eb2c1e4b89f380dd4aca9c326.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68536fc182f09a1eb2c1e4b89f380dd4aca9c326_2_495x500.jpeg" width="495" /></a></div><br />
<small><em>Schematic of validator clients and a beacon node</em></small><p></p>
<p>Beacon nodes can have a number of validators attached to them that ranges from zero to thousands. In fact, <a href="https://medium.com/@grandine/grandine-0-4-1-released-fb98daef6d60" rel="noopener nofollow ugc">it’s been reported</a> that in some Ethereum testnets client developers have been running upwards of 50k validators on a single machine. This separation of concerns makes our investigation somewhat harder: a simple crawl of the P2P network might give us a good overview of the set of online beacon nodes in real time, but this is not representative of the overall validator client distribution at all. Before we address this problem, we’ll take a closer look at validator duties and their footprint on the network.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestation-duties-and-committees-4" name="attestation-duties-and-committees-4"></a>Attestation duties and committees</h2>
<p>As mentioned above, one of the main responsibilities of a validator is voting on blocks by broadcasting <em>attestations</em>. These attestations express the view of a validator about which chain they think is correct. In more detail, they actually cast 2 different votes: one to express their view of the current head block, and one to help finalize past blocks. This is because Ethereum’s  consensus is a combination of <a href="https://arxiv.org/pdf/2003.03052" rel="noopener nofollow ugc">2 subprotocols</a>: LMD GHOST, a fork-choice rule, and a finality gadget called Casper FFG.</p>
<p>These duties are assigned randomly every epoch (with some <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/validator.md#lookahead" rel="noopener nofollow ugc">lookahead</a>) with RANDAO as the source of randomness. Validators get assigned to one slot per epoch at which they have to cast their attestation, which is just a message with the votes that is signed over with the validator BLS private key. These votes are then to be packed and stored in the next beacon block. However, if <a href="https://beaconcha.in/charts/validators" rel="noopener nofollow ugc">all 1 million validators</a> were to attest for every block, the network would be flooded with messages, and the proposer that is supposed to pack these attestations into their block would have trouble verifying all of those signatures in time. This would make Ethereum’s design goal of low resource validation unfeasible.</p>
<p>To address these issues, the beacon network is subdivided into <em>committees</em>, which are subsets of the active validator set that distribute the overall workload. Committees have a minimum size of <span class="math">128</span> validators, and there are <span class="math">64</span> committees that are assigned per slot. But how is this achieved in practice? What network primitives do we require to enable such a logical separation?</p>
<h2><a class="anchor" href="https://ethresear.ch#attestation-subnets-5" name="attestation-subnets-5"></a>Attestation subnets</h2>
<p>The Ethereum consensus P2P network is built with <a href="https://github.com/libp2p/specs/tree/master/pubsub/gossipsub" rel="noopener nofollow ugc">GossipSub</a>, a scalable pubsub protocol running on libp2p. Being a pubsub protocol, GossipSub supports publish/subscribe patterns and the segmentation of networks into logical components called <em>topics</em> (aka P2P overlays)<em>.</em> These are the networking primitives that underpin beacon committees.</p>
<p>One example of a topic is the <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_block" rel="noopener nofollow ugc"><code>beacon_block</code></a> topic, which is a <em>global topic</em> on which new beacon blocks are broadcast. Every validator must subscribe to this topic in order to update their local view of the chain and perform their duties.</p>
<p>The attestation overlays look quite a bit different. For each committee, we derive a subnet ID based on the committee index (0-64). The topic for the respective subnets then becomes <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_attestation_subnet_id" rel="noopener nofollow ugc"><code>beacon_attestation_{subnet_id}</code></a>. Every validator knows their upcoming attestation duties at least 1 epoch ahead of time and can join the correct subnet in advance. When they have to make an attestation, they broadcast it on this subnet.</p>
<p>As mentioned before, these attestations are eventually supposed to make it into a beacon block. But since upcoming proposers might not be subscribed to these subnets, how does that work? This is where <em>attestation aggregators</em> come in. These are a subset of the beacon committees that are responsible for <em>aggregating</em> all of the attestations they see and broadcasting the aggregate attestations on the global <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_attestation_subnet_id" rel="noopener nofollow ugc"><code>beacon_aggregate_and_proof</code></a> topic. This topic is again a mandatory global topic that all validators will be subscribed to, thus providing a way for local unaggregated attestations to make it into the global view of the network. Per committee, there’s a target number of aggregators of <span class="math">16</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#subnet-types-6" name="subnet-types-6"></a>Subnet types</h3>
<p>These attestation subnets described above are ephemeral and directly tied to the validator duties. We call these <strong>short-lived</strong> attestation subnets. The problem with these ephemeral subnets is that they are not very robust, and could result in lost messages. To deal with this issue, the notion of a “<a href="https://github.com/ethereum/consensus-specs/issues/2749" rel="noopener nofollow ugc">subnet backbone</a>” was introduced.</p>
<p>This backbone consists of <strong>long-lived</strong>, persistent subnet subscriptions that are not tied to validator duties but rather a <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#attestation-subnet-subscription" rel="noopener nofollow ugc">deterministic function</a> of the beacon node’s unique ID and the current epoch. These long-lived subnets are maintained for <span class="math">256</span> epochs, or around 27 hours, and each beacon node has to subscribe to 2 of them. They are also advertised on the discovery layer, making it easier for beacon nodes with certain duties to find peers on the relevant subnets.</p>
<h2><a class="anchor" href="https://ethresear.ch#validator-footprints-7" name="validator-footprints-7"></a>Validator footprints</h2>
<p>Returning to the separation of the beacon node and validator clients, there’s now a clear footprint that validators leave on the beacon node’s network identity: their short-lived subnet subscriptions. This will be the core of our methodology.</p>
<h2><a class="anchor" href="https://ethresear.ch#methodology-8" name="methodology-8"></a>Methodology</h2>
<p>Generally, the beacon network consists of 3 domains:</p>
<ul>
<li>The discovery domain</li>
<li>The Req/Resp domain</li>
<li>The gossip domain</li>
</ul>
<p>Each of these domains provides some information about a beacon node.</p>
<h3><a class="anchor" href="https://ethresear.ch#long-lived-subnets-node-metadata-9" name="long-lived-subnets-node-metadata-9"></a>Long-lived subnets &amp; node metadata</h3>
<p>At the <strong>discovery layer</strong> (<a href="https://github.com/ethereum/devp2p/blob/5713591d0366da78a913a811c7502d9ca91d29a8/discv5/discv5.md" rel="noopener nofollow ugc">discv5</a>), a beacon node’s identity consists of an <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#enr-structure" rel="noopener nofollow ugc">ENR</a> with some additional metadata. This metadata can roughly be represented as the following object:</p>
<pre><code class="lang-js">{ 
	peer_id, 
	ip, 
	tcp_port, 
	udp_port, 
	attnets, // Important
	fork_digest, 
	next_fork_version, 
	next_fork_epoch 
}
</code></pre>
<p>This metadata helps other peers connect to peers that are relevant to them, indeed, one of the extra metadata fields are the (long-lived) attestation subnets that this node is subscribed to!</p>
<p>The <strong>Req/Resp domain</strong> is where the actual handshake happens. This is where nodes exchange <code>Status</code> messages that look like the following in order to establish a connection:</p>
<pre><code class="lang-js">(
  fork_digest: ForkDigest
  finalized_root: Root
  finalized_epoch: Epoch
  head_root: Root
  head_slot: Slot
)
</code></pre>
<p>The underlying protocol used for the Req/Resp domain is (again) libp2p. On the lower levels, additional information like <code>client_version</code> is also exchanged when connections are set up.</p>
<p>It is at this level that peers can also exchange <code>MetaData</code> objects to identify each other’s most up to date long-lived subnet subscriptions. The <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#metadata" rel="noopener nofollow ugc"><code>MetaData</code></a> object looks like this:</p>
<pre><code class="lang-js">(
  seq_number: uint64
  attnets: Bitvector[ATTESTATION_SUBNET_COUNT]
  ...
)
</code></pre>
<h3><a class="anchor" href="https://ethresear.ch#short-lived-subnets-10" name="short-lived-subnets-10"></a>Short-lived subnets</h3>
<p>So far, we’ve only seen how nodes exchange metadata and their long-lived subnet subscriptions, which tell us nothing about potential validators. For that, we need the short-lived subnets, which we can only collect on the gossip domain. Our initial strategy was doing just that:</p>
<ol>
<li>Listen to incoming topic subscription requests</li>
<li>Save and index them</li>
</ol>
<p>However, on an initial review of the data, we saw way too many beacon nodes that didn’t subscribe to any additional subnets besides their long-lived, mandatory subscriptions.</p>
<p>Our assumption was that in order to publish data on a gossipsub topic, one needed to be subscribed to it. It turns out that this is not the case, and many clients have different behaviour to minimize bandwidth and CPU usage. Rather than subscribing to the subnet directly, the peer finds other peers that are subscribed to the required subnet beforehand and shares the attestation with them. The subscribed peers make sure to verify and forward these attestations. Remember that in theory, only attestation aggregators need to be listening to all incoming attestations in order to do their jobs. This is exactly what was happening, and explains why we had so little short-lived subnet observations.</p>
<p>With this understanding, we could now tune our assumptions:</p>
<ul>
<li>For each subnet, there’s a target of <code>TARGET_AGGREGATORS_PER_COMMITTEE=16</code> aggregators per committee</li>
<li>This means that on average, there will only be <span class="math">16</span> validators per committee that will be subscribed to an additional short-lived subnet for the duration of an epoch</li>
<li>This results in a maximum of <span class="math">16 * 32 * 64 = 32768</span> useful observations per epoch</li>
</ul>
<p>With these assumptions in mind, we can start estimating validator counts.</p>
<h3><a class="anchor" href="https://ethresear.ch#estimating-validator-counts-11" name="estimating-validator-counts-11"></a>Estimating validator counts</h3>
<p>For each observation, we subtract the number of long-lived subnets <span class="math">S_l</span> from all subscribed subnets <span class="math">S_{all}</span> to arrive at the number of short-lived subnets <span class="math">S_s</span>:</p>
<div class="math">
S_s = S_{all} - S_l
</div>
<p>Since we know aggregators are subscribed to one additional subnet per epoch, <span class="math">S_s</span> will result in an estimated validator count for a certain beacon node in this epoch. Note that just one observation will not be enough to get an accurate estimate, because of the following reasons:</p>
<ul>
<li>It could be that a validator is not an aggregator for this epoch, and thus won’t subscribe to any subnets</li>
<li>There could be overlap between the long-lived and short-lived subnets</li>
</ul>
<p>Due to this reason, we continuously try to collect observations for each known beacon node per epoch, and save the maximum estimated validator counts. Note also that the ceiling for validator estimations is at <span class="math">64 - 2</span>, because that’s the maximum amount of short-lived subnets we can record. This is important! It means that for beacon nodes with more than <span class="math">62</span> validators, we can not estimate how many there are, and just record the ceiling. We want to highlight again that this is just an estimation and won’t be a very accurate representation of the total number of validators.</p>
<h2><a class="anchor" href="https://ethresear.ch#architecture-12" name="architecture-12"></a>Architecture</h2>
<p>In this section we’ll dive a bit deeper into the architecture. All the code for this is open source and can be found in this repository: <a class="inline-onebox" href="https://github.com/chainbound/valtrack" rel="noopener nofollow ugc">GitHub - chainbound/valtrack: An Ethereum validator crawler</a>. A lot of the crawler code is based on projects like <a href="https://github.com/probe-lab/hermes" rel="noopener nofollow ugc">Hermes</a> and <a href="https://github.com/migalabs/armiarma/" rel="noopener nofollow ugc">Armiarma</a>. An overview can be seen here:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e856490bf2dd28b100abeb8c0f37e50f389e882b.jpeg" title="image"><img alt="image" height="305" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e856490bf2dd28b100abeb8c0f37e50f389e882b_2_690x305.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#crawler-13" name="crawler-13"></a>Crawler</h3>
<p>The crawler is the core component of the system. It will crawl the discv5 discovery DHT, find nodes that are on the correct network by looking at the metadata in their ENRs, and then try to connect with them. It will keep a local cache of known peers and try to reconnect every epoch to get updated observations.</p>
<p>We outline 2 types of events (observations): <code>PeerDiscoveryEvent</code> and <code>MetadataReceivedEvent</code>. The second one is most relevant and contains the following fields:</p>
<pre><code class="lang-go">type MetadataReceivedEvent struct {
	ENR               string          `json:"enr"`
	ID                string          `json:"id"`
	Multiaddr         string          `json:"multiaddr"`
	Epoch             int             `json:"epoch"`
	MetaData          *eth.MetaDataV1 `json:"metadata"`
	SubscribedSubnets []int64         `json:"subscribed_subnets"`
	ClientVersion     string          `json:"client_version"`
	CrawlerID         string          `json:"crawler_id"`
	CrawlerLoc        string          `json:"crawler_location"`
	Timestamp         int64           `json:"timestamp"` // Timestamp in UNIX milliseconds
}
</code></pre>
<p>Along with some metadata, this contains all of the fields required to apply the previously described methodology: <code>SubscribedSubnets</code> contains the actually subscribed subnets, obtained by listening on the GossipSub domain, and <code>MetaData</code> contains the peer’s long-lived subnets.</p>
<p>All of these events are then sent to a persistent message queue, where they are stored until they’re read by the consumer.</p>
<h3><a class="anchor" href="https://ethresear.ch#consumer-14" name="consumer-14"></a>Consumer</h3>
<p>The consumer turns the event logs into a stateful view of the network by implementing the methodology described above. It parses the short-lived subnets from the metadata events to get the estimated validator counts, and updates any existing entries in its stateful view. This stateful view is saved in a local sqlite database, which we expose over an API. The table schema roughly looks like this:</p>
<pre><code class="lang-sql">validator_tracker (
	peer_id TEXT PRIMARY KEY,
	enr TEXT,
	multiaddr TEXT,
	ip TEXT,
	port INTEGER,
	last_seen INTEGER,
	last_epoch INTEGER,
	client_version TEXT,
	possible_validator BOOLEAN,
	max_validator_count INTEGER,
	num_observations INTEGER,
	hostname TEXT,
	city TEXT,
	region TEXT,
	country TEXT,
	latitude REAL,
	longitude REAL,
	postal_code TEXT,
	asn TEXT,	
	asn_organization TEXT,
	asn_type TEXT
)
</code></pre>
<p>We then join this data together with an IP location dataset to provide more information about geographical distribution.</p>
<h2><a class="anchor" href="https://ethresear.ch#results-15" name="results-15"></a>Results</h2>
<p><a href="https://www.chainbound.io/" rel="noopener nofollow ugc">Chainbound</a> runs a <a class="inline-onebox" href="https://github.com/chainbound/valtrack" rel="noopener nofollow ugc">GitHub - chainbound/valtrack: An Ethereum validator crawler</a> deployment that pushes all data to Dune every 24 hours.</p>
<blockquote>
<p><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> Dune table link: <a href="https://dune.com/data/dune.rig_ef.validator_metadata" rel="noopener nofollow ugc">https://dune.com/data/dune.rig_ef.validator_metadata</a>.</p>
</blockquote>
<p><em>This data has been stripped of sensitive information such as IP addresses and exact coordinates. However, it retains information like city, coordinates with a precision of a 10km radius, and ASN information.</em></p>
<p>An example dashboard leveraging this information can be seen <a href="https://chainbound.grafana.net/dashboard/snapshot/AmuaGRjfOrARoc7BWY9L43dD5jIgsgnf?orgId=1" rel="noopener nofollow ugc">here</a>.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e5a141037b8bcb98e8247ccb94f3daeeb2d143ce.jpeg" title="image"><img alt="image" height="360" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e5a141037b8bcb98e8247ccb94f3daeeb2d143ce_2_690x360.jpeg" width="690" /></a></div><p></p>
<p>We also store the individual event logs, like PeerDiscoveryEvent and MetadataReceivedEvent. These are available on demand by sending an email to <a href="mailto:admin@chainbound.io">admin@chainbound.io</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#limitations-16" name="limitations-16"></a>Limitations</h2>
<ul>
<li>The maximum number of validators we can estimate with this methodology per beacon node is 62, due to that being the maximum amount of short-lived subnet subscriptions. This will result in a significantly underreported total number of validators, but should still be able to provide a reasonable estimation of the geographical distribution.</li>
<li>We failed to gather any meaningful data on Teku nodes over the 30-day period, which could signify an error in our P2P implementation and impact the results.</li>
<li>These results will be skewed towards validators attached to beacon nodes that have opened P2P networking ports in their firewall, which will mostly be beacon nodes running on cloud providers. The reason for this is that our crawler can more easily connect to nodes that have exposed ports.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#references-17" name="references-17"></a>References</h2>
<ul>
<li><a class="inline-onebox" href="https://eth2book.info/capella/" rel="noopener nofollow ugc">Upgrading Ethereum</a></li>
<li><a class="inline-onebox" href="https://hackmd.io/@dmarz/ethereum_overlays" rel="noopener nofollow ugc">The Hitchhiker's Guide to P2P Overlays in Ethereum Consensus - HackMD</a></li>
<li><a class="inline-onebox" href="https://github.com/ethereum/consensus-specs/tree/dev" rel="noopener nofollow ugc">GitHub - ethereum/consensus-specs: Ethereum Proof-of-Stake Consensus Specifications</a></li>
</ul>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 08:33:30 +0000</pubDate>
</item>
<item>
<title>Presenting Klaster - rethinking chain abstraction</title>
<link>https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910</link>
<guid>https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910</guid>
<content:encoded><![CDATA[
<div> 关键词：Klaster、Interchain Transaction (iTx)、Transaction Commitment Layer、Smart Accounts、Cross-chain transaction flow

总结:
Klaster是一个旨在解决区块链碎片化问题的协议，通过引入网络节点（Klaster Nodes）作为用户和链之间的中介。核心概念包括iTx（跨链交易捆绑），它是一系列可能相互依赖的交易，跨越多个链。Klaster利用智能账户和ERC-4337 Entrypoint，通过经济激励建立可靠的节点网络，允许开发者构建链抽象应用，用户只需一次签名即可执行跨链事务。协议提供了一站式服务，简化复杂操作，如资产转移、交换等，提升了用户体验。Klaster正在测试阶段，未来将实现去中心化，增强网络可靠性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>We are witnessing an ever-growing list of new chains popping out, and attracting a high level of activity and transactions. Ethereum is also scaling nicely, and with the EIP-4844 it’s becoming increasingly cheaper to onboard as a user and start interacting with chains.</p>
<p>This introduces fragmentation, which in our opinion is here to stay especially in a world where there will be hundreds of chains, users will demand fragmentation to be solved for. If we build solutions that kind of aggregate different assets in some sort of “centralized” service only to make all chains look like one and make it easy to move across chains, then we haven’t accomplished much.</p>
<p>We propose a solution which abstracts away chains and solves for fragmentation by introducing <strong>Klaster</strong> - a network of nodes placed between the users and chains. This layer wraps multiple blockchain networks and makes it easy for users to execute complex transaction flows spanning across one or more chains - all of that approved by the single off-chain signature.</p>
<p>By introducing the Klaster Nodes as a generic execution network, and defining how cross-chain transactions are being bundled and approved, we hope to set the standard for building chain abstracted applications. This goes beyond just a simple balance abstraction - spend your funds from one chain by interacting on another chain. It provides a “full” chain abstraction by allowing any arbitrary flow to be defined and executed.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-2" name="tldr-2"></a>TL;DR</h1>
<p>Klaster Protocol aims to position itself as a chain abstraction framework which allows dApps or Wallets to build complex cross-chain transaction bundles and let the users sign only once to execute these bundles across one or more blockchain networks.</p>
<p>We introduce two key concepts:</p>
<ul>
<li><strong>iTx bundles</strong>: series of (possibly dependent) transactions spanning across many chains</li>
<li><strong>Transaction Commitment Layer</strong>: network of nodes providing execution guarantees and offering orchestrated iTx execution across many blockchain networks</li>
</ul>
<p>Klaster Protocol leans on Smart Accounts and ERC-4337 EntryPoint and by introducing the economic incentives provides a reliable network of Klaster Nodes which anyone can use to build truly chain abstracted dApps while not sacrificing on the security, or taking the control from the user.</p>
<h1><a class="anchor" href="https://ethresear.ch#klaster-3" name="klaster-3"></a>Klaster</h1>
<p>Klaster provides an infrastructure for building chain abstracted apps. Klaster does this by introducing a network of Nodes, which act as a <strong>Transaction Commitment Layer</strong>. This layer is placed between the dApp and multiple blockchain networks, It talks to the outside world (users, dApps) via <strong>interchain transactions (iTx)</strong>.</p>
<p>Developers can use these primitives to:</p>
<ul>
<li>Build chain abstracted dApps (no switch network button)</li>
<li>Define complex flows involving multiple chains without having to think of the specifics of how the flow will get executed</li>
<li>Automate the execution of the dependent actions spanning across many chains</li>
<li>Onboard the users from different chains and ecosystems into their dApp with a single user signature</li>
</ul>
<p>Users on the other hand:</p>
<ul>
<li>Can interact with chain abstracted dApps using any wallet they prefer</li>
<li>Don’t have to care of where their funds are, the dApp will be able to spend their funds from other chains with a single user signature</li>
<li>Don’t have to “lock” their funds in order for the dApp to consume their funds</li>
<li>Can use any asset on any chain to pay for gas cost of the full iTx execution involving many transactions on different chains</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#core-concepts-4" name="core-concepts-4"></a>Core concepts</h2>
<p>At its core, Klaster leans on its unique approach of <strong>separating transaction signing from<br />
the transaction execution</strong>.</p>
<p>If we think about how the EOA is executing a transaction on an EVM - it’s all bundled in the same operation - sign &amp; execute happening simultaneously with the user having one EOA wallet popup and interacting with the chain/RPC.</p>
<p>A more advanced approach can be seen with the Account Abstraction (ERC-4337), where users can approve their UserOp and then hand it over to the Bundler for execution. This approach is still bounded to one single chain - the one where the user’s smart account is deployed.</p>
<p>Klaster Model breaks the boundaries of a single chain, and allows an account owner to approve a complex series of (possibly dependent) UserOps targeting different blockchain networks - with a single off-chain signature! This signature is then provided to the Klaster Node (what would be a bundler in AA), for orchestrating an execution across all the different chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/5/755b51c20b470de874fc70cf3589d99577681458.jpeg" title="photo_2024-06-26_14-25-17"><img alt="photo_2024-06-26_14-25-17" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/7/5/755b51c20b470de874fc70cf3589d99577681458_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>As seen from the illustration above, if the user wanted to bridge funds and then swap on the destination chain, they would usually execute two transactions, on two different applications (Bridge app &amp; then DEX app), while also having to pay for gas fees on two different chains.</p>
<p>By splitting the signature from the execution, Klaster is able to convert two actions into one <strong>iTx bundle</strong> and then execute them through the Klaster Node. Klaster node will figure out the ordering of transactions, and execute them as user intended, while also covering for execution fees.</p>
<h2><a class="anchor" href="https://ethresear.ch#interchain-transaction-itx-bundle-5" name="interchain-transaction-itx-bundle-5"></a>Interchain Transaction (iTx bundle)</h2>
<p><strong>Interchain Transaction (iTx)</strong> is the fundamental working unit used within the Klaster protocol. It’s a bundle of one or more blockchain transactions spanning across one or more blockchain networks. It fully describes what the user or the dApp is trying to achieve. One iTx, consisting of two transactions, might be: “bridge assets from chain A using some 3rd party bridge to chain B, and then swap bridged assets for something else on chain B”.</p>
<p>From the Klaster Protocol perspective, one iTx bundle is actually a Merkle Tree of all the UserOps as leaves, and is defined by its Merkle Root hash (iTx hash): <strong>one iTx bundle = one unique iTx hash</strong>.</p>
<p>Any on-chain interaction on any blockchain network can be converted to the UserOp and placed as a part of a bigger iTx Merkle Tree - meaning the iTx tree approach can be used to basically define any complex operation spanning across multiple blockchain networks provided that there’s at least some liquidity services connecting the chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/a/2a26e4bc6a55b451b319a567816c3f9fd11c8b5a.jpeg" title="photo_2024-06-26_14-27-23"><img alt="photo_2024-06-26_14-27-23" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/2/a/2a26e4bc6a55b451b319a567816c3f9fd11c8b5a_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>Transaction Commitment Layer takes unsigned iTx requests, and <strong>commits</strong> to execute them in the specific time frame - and therefore provides a reliable execution layer capable of executing the parts of the iTx on different blockchain networks. This involves strategically determining the optimal order for executing the individual transactions within the bundle. For instance, if a transaction on Polygon relies on assets being transferred from Ethereum first, the node will ensure that the Ethereum transfer is finalized before proceeding with the Polygon transaction.</p>
<h2><a class="anchor" href="https://ethresear.ch#high-level-protocol-overview-6" name="high-level-protocol-overview-6"></a>High Level Protocol Overview</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/4/44e74558671473aa21b67bb54151e8dea1ce9070.jpeg" title="photo_2024-06-26_14-28-18"><img alt="photo_2024-06-26_14-28-18" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/4/4/44e74558671473aa21b67bb54151e8dea1ce9070_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>The following steps are involved for the user/dApp to interact with the Klaster Protocol:</p>
<ol>
<li>dApp defines a list of operations to be executed across one or many chains and bundle them together into the iTx</li>
<li>dApp asks the Klaster Network for a quote (fee) for executing an iTx</li>
<li>dApp receives back the iTx with included fee amount and cryptographic execution guarantees given by the Klaster Network</li>
<li>User signs the iTx by signing its root iTx hash and then broadcasts the signed iTx back to the Klaster Network</li>
</ol>
<p>Once the Klaster Network receives the signed iTx, it will charge the user upfront by pulling the fee amount as defined in the quote, and it will start processing the transactions from the iTx bundle, executing them on the different blockchain networks in the correct order. The specifics of how the fee is being calculated and charged upfront is outlined in the technical breakdown section.</p>
<h2><a class="anchor" href="https://ethresear.ch#chain-abstraction-vs-balance-abstraction-aave-example-7" name="chain-abstraction-vs-balance-abstraction-aave-example-7"></a>Chain Abstraction vs Balance Abstraction (AAVE example)</h2>
<p>While balance abstraction is a great step forward in solving for liquidity fragmentation, it’s not covering all bases. Let’s say we want to build a chain abstracted version of AAVE, where users can interact with the dApp not only by having the “balance” abstracted away (supply assets from one chain to AAVE deployed on another chain), but also having an <strong>AAVE “position” abstracted</strong> away which is a more dApp specific use-case.</p>
<p>For example, a user might have 100 USDC supplied on AAVE on Optimism, but they want to switch the position to Base, and supply USDC there, because of better rates. Or there’s a bot that wants to do this periodically, in the user’s name and with the user’s approval.</p>
<p>Right now, the user would have to unwind their position, find a bridge to use, move liquidity to Base and then resupply the USDC. This involves signing multiple transactions and switching between multiple frontends and blockchain networks / RPCs, not to mention also having some gas dust on these chains to be able to execute transactions in the first place. We believe this is unsustainable and there has to be a way of “standardizing” these interactions &amp; making life easier on the user facing side.</p>
<p>By using Klaster protocol, this complicated “position” rebalancing operation can be converted to one simple iTx bundle containing three UserOps:</p>
<ul>
<li>[<em>Optimism</em>] UserOp1: unwinds AAVE USDC position on Optimism</li>
<li>[<em>Optimism</em>] UserOp2: bridges 100 USDC to Base using some third party bridge (across bridge, for example)</li>
<li>[<em>Base</em>] UserOp3: supplies 100 USDC on AAVE</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/a/aaccd85ed18ac9bacdc8cfe3806eb872019b0363.jpeg" title="photo_2024-06-26_14-35-03"><img alt="photo_2024-06-26_14-35-03" height="390" src="https://ethresear.ch/uploads/default/optimized/3X/a/a/aaccd85ed18ac9bacdc8cfe3806eb872019b0363_2_690x390.jpeg" width="690" /></a></div><p></p>
<p>The only thing the user would have to do from their side is provide one signature for the iTx and the balance reposition would be handled by the Klaster Protocol automatically. No gas required on the destination chain. No different apps involved. One simple signature. And we bet that if the developers are provided with tools like Klaster, many more other interesting use-cases might emerge other than the one we’re describing here.</p>
<h1><a class="anchor" href="https://ethresear.ch#technical-breakdown-i-want-to-know-more-8" name="technical-breakdown-i-want-to-know-more-8"></a>Technical Breakdown (I want to know more)</h1>
<h2><a class="anchor" href="https://ethresear.ch#smart-accounts-itx-module-9" name="smart-accounts-itx-module-9"></a>Smart Accounts - iTx Module</h2>
<p>Using an iTx bundle in combination with Smart Contract Accounts allows for one very powerful feature to be implemented - and is there to help on the UX side: <strong>single signature iTx approvals</strong>.</p>
<p>Smart Account modular architecture allows for building a standardized ERC-7579 module which “understands” iTx bundles and can be installed on top of existing smart account wallets or used to initialize new wallets as the UserOp model allows for providing the wallet initialization data as a UserOp parameter.</p>
<p>A smart account owner can approve the whole iTx bundle of many chain transactions by only <strong>signing once</strong> - one off-chain signature of the iTx Merkle Root hash can be used to approve for executing all the transactions across many chains.</p>
<p>As mentioned earlier, the tree is defined by its Merkle root hash - iTx hash. The smart contract owner signs the iTx hash with a signer. This typically is an EOA which is a common owner of all the smart accounts across different chains where the assets are being bridged and consumed, and by providing one signature, all of these operations are immediately executable.</p>
<p>If the user doesn’t have a smart contract account on one or more blockchain networks - the accounts can be “lazy deployed” for the user - meaning, the iTx bundle can contain an operation which bridges some amount of funds to the “not yet created” account as the address of the smart account can be precomputed.</p>
<p>By having the iTx validation module as a standardized module - Klaster protocol remains neutral &amp; unopiniated - it can work with different smart account providers.</p>
<h2><a class="anchor" href="https://ethresear.ch#klaster-fees-node-selection-10" name="klaster-fees-node-selection-10"></a>Klaster Fees &amp; Node Selection</h2>
<p>The Klaster Transaction Commitment Layer consists of many Klaster Nodes - all of them being equal. Every Node is defined by its wallet address, and in order for nodes to join the network, they have to stake capital - this is how the nodes provide uptime &amp; execution guarantees.</p>
<p>Klaster Nodes are taking care of the following:</p>
<ol>
<li>Estimating iTx fees &amp; responding to quote requests</li>
<li>Committing to iTx execution (or rejecting the request)</li>
<li>Executing fully signed iTx (if previously committed to execution)</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#estimating-itx-fees-responding-to-quote-requests-11" name="estimating-itx-fees-responding-to-quote-requests-11"></a>Estimating iTx fees &amp; responding to quote requests</h3>
<p>When the user or the dApp asks the protocol for quotes, every node will estimate the total cost of executing the iTx on different chains. The node adds its own fee on top of the total cost, including the <strong>success execution tip</strong> (more on this in the “optimistic execution” chapter) and responds back with the full cost the user will have to pay in order for the node to do the job.</p>
<h3><a class="anchor" href="https://ethresear.ch#committing-to-itx-execution-or-rejecting-the-request-12" name="committing-to-itx-execution-or-rejecting-the-request-12"></a>Committing to iTx execution (or rejecting the request)</h3>
<p>The user or the dApp chooses the best received quote by taking into account the total execution cost offered by each of the nodes, and their reputation. The dApp then connects directly with the selected node, and asks for a commitment - a guarantee from the node that they are going to execute the iTx in full, provided that the user pays for what the node asks for.</p>
<p>The node commits to the iTx execution by</p>
<ol>
<li>Prepending the payment tx* in the list of the transactions in the iTx bundle</li>
<li>Signing the root iTx hash with its own private key - essentially binding itself to the execution of the iTx</li>
</ol>
<p>*<em>A payment transaction generated and prepended by the node transfers some liquid asset from the user’s account to the node wallet address. The asset is selected by the user and the amount is calculated by the node to cover for all the execution costs + the node fee. This means that the user can pay for the execution on any chain and in any asset supported by the node.</em></p>
<h3><a class="anchor" href="https://ethresear.ch#executing-fully-signed-itx-if-previously-committed-to-execution-13" name="executing-fully-signed-itx-if-previously-committed-to-execution-13"></a>Executing fully signed iTx (if previously committed to execution)</h3>
<p>Once the dApp receives the iTx which includes the payment transaction and the node commitment, the user is finally prompted to approve the full iTx bundle by signing the root iTx hash - essentially approving the execution of all the transactions contained in the bundle. The iTx bundle, whose root iTx hash has been signed by both the node (commitment) &amp; user (execution approval) is sent to back the selected node which:</p>
<ol>
<li>Verifies the iTx bundle integrity (calculates &amp; verifies merkle root)</li>
<li>Verifies the commitment signature (make sure the node really did commit to this iTx)</li>
<li>Verifies the user signature</li>
<li>Collects the payment from the user (the first transaction in the iTx bundle)</li>
<li>Once the payment is complete, proceeds to execute the rest of the operations by performing the optimistic execution algorithm</li>
</ol>
<p>If the node fails to execute the iTx bundle, the user can use the node commitment (node iTx signature) to initiate a slashing request and prove on-chain that the node actually promised to execute the iTx but failed to do so in a given timeframe.</p>
<h2><a class="anchor" href="https://ethresear.ch#meta-paymaster-and-multichain-gas-refunds-14" name="meta-paymaster-and-multichain-gas-refunds-14"></a>Meta Paymaster and Multichain Gas Refunds</h2>
<p>For the node to be fully operational, they have to own the native coin balance on their wallet address for every chain they support - in order to be able to pay for gas and execute UserOps as a part of iTx bundle. By accepting the upfront payment from the user in one token and one chain, and then executing the transactions and subsidizing gas on one or more chains, Klaster Node acts in a way as a Meta Paymaster.</p>
<p>The node executes UserOps contained in the iTx by routing them through the official ERC-4337 EntryPoint on different chains, and after receiving post-operation execution callbacks with the actual gas consumption data, the node will execute refunds for every processed UserOp, that is if actual UserOp cost (including the Klaster Node fee) was less than the maximum UserOp that was prepaid by the user. The process is illustrated below:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/c/9ca11c122eee71670ddf3e95a2ecee88cf427bcb.png" title="klaster-meta-paymaster-latest"><img alt="klaster-meta-paymaster-latest" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/c/9ca11c122eee71670ddf3e95a2ecee88cf427bcb_2_569x500.png" width="569" /></a></div><p></p>
<p>By relying on the official ERC-4337 EntryPoint for UserOp routing, the Klaster Protocol is staying compliant with the AA space, since most of the AA wallets today choose to trust and give control to one EntryPoint contract. Any existing AA wallet could technically activate the Klaster iTx module and gain cross-chain capabilities.</p>
<h2><a class="anchor" href="https://ethresear.ch#optimistic-itx-execution-15" name="optimistic-itx-execution-15"></a>Optimistic iTx Execution</h2>
<p>Klaster Node is incentivized to execute UserOps from a given iTx bundle in the right order of events, without the user having to explicitly provide the order of events.</p>
<p>The right order of events is implicitly deduced by the Klaster Node, by repeatedly simulating every UserOp, between the timestamp deadlines set by the user when defining UserOp, and waiting for the simulation to yield 0 <em>REVERT</em> opcodes in the simulated execution breakdown. Once this happens, Klaster Node “knows” all the preconditions have been met (whatever they may be) and will proceed to execute the UserOp as this maxmizes the profits for the Klaster Node.</p>
<p>In our AAVE example from above, Klaster Node will wait for the bridge action to complete without having to be aware of which bridge is being used and what the estimated bridge time to destination might be. It’s not even aware of the context of any UserOp or the potential dependencies between those. The execution flow would look like this:</p>
<ol start="0">
<li>
<p>The Node executes the Payment UserOp (at index 0 in the list of UserOps). That way the Node charges for the full execution of all the other UserOps upfront and can proceed with the next steps</p>
</li>
<li>
<p>The Node “sees” that out of three UserOps (<strong>unwind, bridge, supply</strong>), the only one with 0 REVERTs is the <strong>unwind</strong> operation, and it proceeds to execute the UserOp successfully (on Optimism)</p>
</li>
<li>
<p>Afterward, another operation that yields 0 REVERTs is the bridge operation as the funds are now there to be bridged (unwinded position), so it proceeds to execute <strong>bridge</strong> action (on Optimism)</p>
</li>
<li>
<p>Finally, once the funds arrive at the user’s dest chain smart account (whenever that may be, depending on the 3rd party bridge being used), the <strong>supply</strong> operation is executed which marks the full iTx execution as complete.</p>
</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/b/bb781b0246065508b7a832ee5060408e61d20a87.jpeg" title="photo_2024-06-26_14-45-59"><img alt="photo_2024-06-26_14-45-59" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/b/b/bb781b0246065508b7a832ee5060408e61d20a87_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>By having this generic approach of not being aware of the context, iTx bundles can express pretty much any complex cross-chain flow. To incentivize the node to wait for the simulation success (0 REVERTs), but then also to execute the UserOp <strong>as soon as 0 REVERT is detected,</strong> Klaster fee will include the <strong>diminishing success tip</strong>. This fee can be collected by the Node only if the UserOp was executed with 0 REVERT status and the tip is fading to 0 as the UserOp execution moment is closing to the upper bound execution timestamp.</p>
<p><em>It is still possible for some of the UserOps to fail, for example, 3rd party bridge not working properly. In that case - the node has fulfilled its obligation, as it’s recorded on-chain that the node “attempted” to execute the UserOp, although the funds haven’t reached the destination chain. In that case, the node is protected from slashing, while the user experienced a partially executed iTx. The funds are still owned by the user, and have remained on their wallet on one of the chains where the UserOp failed.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#integration-16" name="integration-16"></a>Integration</h1>
<p>dApp/Wallet developers will soon have access to the SDK, which in turn will allow for building chain abstracted applications much more efficiently, while staying neutral and not locking the developer to having to use any specific technology.</p>
<p>The developers are free to use any bridges or 3rd party services as a part of the iTx bundle - depending on the level of security/speed they require, and to rely on different AA wallet providers as the smart account wallets used behind the scenes.</p>
<p>On the user side, they have to sign once, and see their cross-chain intent being executed step by step without having to do any other action or even own gas funds on any of the chains they interact with.</p>
<p>This is how we see it developed further and how dApps might integrate the SDK in order to provide cross-chain experience to the end user:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65e8e1fa54439727f6d9a820b1d86e740f228025.jpeg" title="photo_2024-06-18_13-18-43"><img alt="photo_2024-06-18_13-18-43" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/6/5/65e8e1fa54439727f6d9a820b1d86e740f228025_2_690x315.jpeg" width="690" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#demo-use-cases-17" name="demo-use-cases-17"></a>Demo &amp; Use Cases</h1>
<p>At the moment, we’re building a chain abstracted AAVE dApp - to showcase what the protocol can do in terms of UX improvements.</p>
<p>The frontend will only contain two buttons: “supply” &amp; “borrow” without specifying the chains. When executing borrow or supply, user’s funds will be routed to any chain where the AAVE market’s rates are most favorable, regardless of the fact which chain the user’s funds are on.</p>
<p>If the user wants to rebalance the existing position, again, it’s a one-click interaction for the user, but in the background, iTx is being executed by the Klaster Nodes.</p>
<p>Some other interesting use cases:</p>
<ul>
<li>streamlined checkout flows</li>
<li>easier onboarding to the SocialFi L2/L3 apps, as Klaster protocol works with AA by default, and many of these apps choose to have embedded wallets generated for the users behind the scenes</li>
<li>building chain abstracted flavors of dapps that are natively multichain (DEXs, lending markets, NFT marketplaces)</li>
<li>single-chain dApps can use the Klaster Stack to streamline onboarding flows, attracting users from various chains. With Klaster Stack, users can interact with the dApp in just one click, regardless of their original blockchain</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#faq-18" name="faq-18"></a>FAQ</h1>
<p><strong>Q: Is Klaster a Blockchain Network?</strong><br />
A: No.</p>
<p><strong>Q: What’s the current development status?</strong></p>
<p>A: Centralized Klaster Node including the SDK and the docs is in the testing phase and will be launched very soon. The decentralization phase including the slashing and multichain staking which in turn makes the network more reliable will most likely be rolled out later this year.</p>
<p><strong>Q: What are the dangers of using Klaster Protocol?</strong></p>
<p>A: Dangers are mostly related to the impaired UX.</p>
<p>For example, malicous Klaster Node can refuse to process an iTx bundle in full - they only execute the Payment UserOp part of the iTx bundle. The user can still replay their UserOps manually and achieve the same effect but will have to pay for gas execution themselves. Nodes on the other hand get slashed in the decentralized model because the user can submit a proof of Node commiting to execute the iTx but failing to do so in a given timeframe - which is fully verifiable on-chain. As the AA wallets are used behind the scenes, the user is in full control of their funds, and the security is reduced to security of bridges used as an intermediary steps to move assets between chains. Klaster’s iTx-enabled AA wallet module is pending audits and the reports will be shared soon.</p>
<p><strong>Q: Can I run my own node, and what are the advantages of running a node?</strong></p>
<p>A: Klaster Protocol will host its own public node, with the implementation publicly available for everyone to take a look and verify the inner workings of the Node itself. While the initial version of the protocol is not decentralized in a sense of having a p2p networking implemented between public Klaster nodes, anyone can still choose to run their own Klaster Node either for their own purposes (only handling one single dApp) or even providing this node for others to connect to.</p>
<p>New chains can spin up their own Klaster node to easily onboard users from other chains.</p>
<p>Klaster Node if operational earns a % of the total gas processed and is another revenue stream for Node operators. To set up a node, one needs to have a wallet connected to the node, and funded with native coin on every chain which the Node operator decides to support.</p>
<p><strong>Q: How does Klaster compare to other chain abstraction solutions?</strong></p>
<p>A: For a start, we think we have a unique approach here in being highly focused on the UX part. We’re trying to stay as generic and as neutral as possible, and we’ve developed something that can be used today to fix the UX in some ways. Comparing to some other approaches we see being built in this space, Klaster’s main difference is that Klaster doesn’t work with liquidity nor does it require the Node operators to provide liquidity - meaning it’s easier to run the network and gain an initial base of Node operators. It doesn’t try to be “one solution fits all” which hides away blockchains completely, but rather a framework where, given the fact that the cross-chain action details are known upfront - it enables developers to easily define and build the action, and for the user to sign once and see the effects happening on different chains.</p>
<p><strong>Q: Where does Klaster Protocol fit in the CAKE framework?</strong></p>
<p>A: According to the CAKE Layer definitions, we’d say Klaster comes somewhere in the Settlement Layer (Execution part).</p>
<p><strong>Q: Is Klaster Protocol a bridge?</strong></p>
<p>A: Not really. Klaster Protocol can <em>wrap</em> bridges and other services to create a true cross-chain experience by having bridge action only there as a one step of the more comple iTx interaction.</p>
<p><strong>Q: I want to know more about the slashing process. Why do the Nodes have to stake capital, and how does slashing work?</strong></p>
<p>A: Klaster Nodes have to execute iTx bundles if they previously “promised” to the user they will do so. There has to be a way of punishing the Node for not doing their job - or even worse, collecting the fee payment from the user but never executing their desired intent. To make this possible, Klaster Nodes have to stake capital in order to be accepted by the network and allowed to execute iTx bundles on user’s behalf.</p>
<p>Every UserOp contains lower and upper bound timestamps, and the interval between these are when the UserOp is considered valid and can be executed on-chain. When the Node builds a full iTx tree, and signs the root iTx hash with their private key - we say the Node is “commited” to the iTx. The user has received the full quote including the Node commitment, and can use this commitment to initiate a slashing procedure if the nonce of the user’s smart account was not increased by one in the given timeframe, on any chain where their UserOp was <strong>not executed</strong>.</p>
<p><strong>Q: Is Klaster Protocol actually an Intent Solver network?</strong></p>
<p>A: Not really. Intents mean the user describes the end-result state and <em>someone somehow</em> finds the solution to the steps (txs) required to achieve the desired outcome. Klaster takes a completely opposite approach. The design space of the intent solvers is just too big and solving for all cases using intents is simply too complicated. We say - let’s make the system more exact, in a sense that, we assume that the developers of either dApps or wallets will always know upfront what exactly they want to achieve - and then let’s give them tools and means of how to express this interaction (iTx bundle) while making it easy for users to approve and execute these iTx bundles.</p>
<p>Klaster Protocol though is a great tool for Intent Solvers to express &amp; execute their “paths of execution” once they solve for some specific user’s request.</p>
<p><strong>Q: What’s the role of AA Wallets in the Klaster Protocol?</strong></p>
<p>A: AA Wallet is the only viable option for Klaster Protocol to work. Since we need to be able to have the user authorize many actions with only one signature - the only possibility for this to work is to actually use programmable smart contract wallets.</p>
<p><strong>Q: How is the Node protected from users? How are the users protected from the Node?</strong></p>
<p>A: The Node charges for its service fee plus all the other execution gas costs upfront. This way, the node might overcharge for the gas spendings, but the user will still get charged fairly if the actual gas spent was lower than what the node calculated. The Node will not commit to execute the iTx if the iTx looks risky - too short timespans for the UserOp execution, or the UserOp execution window which starts far away in the future (gas price spike risks).</p>
<p>The user is protected from the Node by being the only owner of the AA Wallet which used to execute iTx steps. Even if the Klaster Network dies completely, the user can still access and manage funds. The Klaster Node can only do what the user explicitly signs &amp; approves.</p>
<p><strong>Q: Does the user need to own the funds on the AA Wallet to interact with the Klaster Protocol in the first place?</strong></p>
<p>A: Unfortunately yes. If the user’s coming with an EOA wallet and assets are held by this EOA, the user will have to execute at least one EOA transaction and move funds from this wallet to an iTx enabled AA wallet to be able to use Klaster for chain abstraction / gas abstraction purposes. Luckily, the EIP-7702 which is confirmed will improve this flow substantially.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 13:13:35 +0000</pubDate>
</item>
<item>
<title>Pricing Gas Fee Derivatives</title>
<link>https://ethresear.ch/t/pricing-gas-fee-derivatives/19898</link>
<guid>https://ethresear.ch/t/pricing-gas-fee-derivatives/19898</guid>
<content:encoded><![CDATA[
<p><em>Thanks to Nethermind, <a class="mention" href="https://ethresear.ch/u/tkstanczak">@tkstanczak</a>, <a class="mention" href="https://ethresear.ch/u/swapnilraj">@swapnilraj</a> , <a class="mention" href="https://ethresear.ch/u/dapplion">@dapplion</a>, Martin Koppelmann and <a class="mention" href="https://ethresear.ch/u/drewvanderwerff">@DrewVanderWerff</a> for discussion, feedback and review.</em></p>
<p><strong>This is the first instalment in a series of posts where I will outline a methodology for understanding and pricing gas derivatives. The following approach for pricing will be valuable for gas hedging and can also be applied to develop a subscription model for Ethereum.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/0/2075264e1980cd984ec67a32af4bbe1689af4874.jpeg" title="There-Will-Be-Blood1-ezgif.com-webp-to-jpg-converter"><img alt="There-Will-Be-Blood1-ezgif.com-webp-to-jpg-converter" height="460" src="https://ethresear.ch/uploads/default/optimized/3X/2/0/2075264e1980cd984ec67a32af4bbe1689af4874_2_690x460.jpeg" width="690" /></a></div><p></p>
<p><em>There Will Be Blood” (2007) - are we going to be unwitting extras in the ‘digital oil’ sequel?</em></p>
<p><strong>TLDR:</strong> I show how a two-factor model can be used to price base fee options, of both European and American type. A developed gas derivatives market would be highly beneficial for participants looking to hedge against volatile operational expenses on gas or for those aiming to speculate on future gas fee trends.</p>
<p><strong>Why Price Base Fee Derivatives?</strong></p>
<p>Gas expenditure is a substantial portion of operational costs within blockchain ecosystems. Whether it involves L2 sequencers committing transactions to L1, the running of a DeFi protocols keeper, interacting with oracle contracts, rebalancing liquidity on platforms like Uniswap, verifying proofs, or conducting arbitrage, gas fees are an unpredictable expense. This inherent volatility poses challenges for financial planning and budgeting in blockchain operations. Gas hedging, analogous to its counterpart in traditional financial markets, provides a mechanism to manage and mitigate this uncertainty.</p>
<p>By purchasing gas derivatives, stakeholders can secure current gas fee levels for future transactions, effectively insuring against unforeseen spikes in gas prices. Additionally, with a strike price of zero on a call option, one can fully prepay for gas, paving the way for a ‘gas subscription’ model on Ethereum—assuming a delivery mechanism is established. This research could be particularly useful for pre-confirmations, where blockspace is purchased in advance.</p>
<p>The following post breaks down the importance of understanding base fees, examining their volatility, and proposing a detailed model for pricing base fee derivatives. The first section delves into the calculation of base fees, while the second outlines their structure. In the third section, a model incorporating both deterministic and stochastic components is detailed to simulate base fees using a Monte Carlo process. The fourth and final section explains how to use these Monte Carlo generated paths to price base fee options, including both European and American types. Use cases of this research include participants that want to examine the fair value of a base fee option, a task helpful for those interacting with derivative protocols like Oiler’s Pitch lake <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018" rel="noopener nofollow ugc">[1]</a>.</p>
<p>This post is the first in a series on the topic, aimed at sparking interest among both Ethereum researchers and traders. My goal is to engage quants in the conversation around Ethereum infrastructure.</p>
<p><strong>Understanding Base Fees</strong></p>
<p>Before pricing base fees, we should understand its constituent parts. EIP-1559, implemented in the London hard fork of Ethereum in August 2021, introduced a significant overhaul to the transaction fee mechanism on the Ethereum network. The proposal aimed to improve the predictability and efficiency of transaction fees, addressing several issues inherent in the previous auction-based system. Under EIP-1559, each block has a base fee, which is dynamically adjusted according to network congestion. When demand for block space increases, the base fee rises, and when demand decreases, the base fee falls. This mechanism helps to stabilize transaction fees and makes them more predictable for users.</p>
<p>The specific adjustment rule proposed in the EIP-1559 spec computes the base fee <span class="math">BF_{\text{cur}}</span> for the current block from the base fee <span class="math">BF_{\text{pred}}</span> and size <span class="math">s_{\text{pred}}</span> of the predecessor block using the following formula, where <span class="math">s_{\text{target}}</span> denotes the target block size:</p>
<div class="math">
BF_{\text{cur}} := BF_{\text{pred}} \cdot \left( 1 + \frac{1}{8} \cdot \frac{s_{\text{pred}} - s_{\text{target}}}{s_{\text{target}}} \right)

</div>
<p>In short, the next base fee is adjusted by a percentage that equals one-eighth of the difference to the target percentage - meaning base fees are within the bounds of 12.5% higher or lower than the previous block. As is visible below when comparing gas usage, full blocks of 30M are most frequent, with gas usage of just below 13M second most frequent.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/3/f3ef180d0b94b634c3727e72c56bcf12cb7ccbfa.png" title="Histogram"><img alt="Histogram" height="500" src="https://ethresear.ch/uploads/default/original/3X/f/3/f3ef180d0b94b634c3727e72c56bcf12cb7ccbfa.png" width="657" /></a></div><p></p>
<p><strong>Those Are Some Large Percentage Changes… Why Are Base Fees So Volatile?</strong></p>
<p>Several factors contribute to the high volatility of base fees, with the non-storability of base fees and the limited block-space supply being the most significant. Since block-space has a strict limit to 30M gas, which cannot be stored or transferred over time, supply in each time period is fixed, while demand can fluctuate based on usage needs. Base fees for transactions is thus demand inelastic. Consequently, during periods of low demand, the base fee remains relatively stable. However, during peak times, the relative insensitivity of demand to price changes can lead to significant volatility in short-term base fee prices—‘Jumps’. This situation is similar to the electricity market, where demand remains high regardless of price, causing extreme price volatility during peak usage. In the blockchain context, the necessity of paying the base fee to conduct transactions ensures somewhat steady demand, even as prices fluctuate dramatically.</p>
<p>Additionally, since base fees are influenced by the previous base fee, a block with high demand for blockspace—such as one resulting from the deployment of a large simultaneous smart-contract architecture—will primarily impact users in the following block. Users pay for blockspace based on the previous blocks usage, not the current one. Consequently, in the short term, a deployer will not always experience the negative externalities of increasing gas fees for near-future blockchain users. This creates a scenario where users are indifferent to increasing base fees by the cap of 12.5%. Current discussions, as well researched by SMG <a href="https://www.mechanism.org/spec/04" rel="noopener nofollow ugc">[2]</a>, suggest to minimise this externality, and subsequent short-term volatility by modifying the denominator to a higher value. The change would reduce sensitivity to randomness in gas usage and better align the process with underlying trends, improving stability and predictability.</p>
<p><strong>Characteristics of Base Fees</strong></p>
<p>Base fees can be simulated through understanding the structure of gas usage, before feeding the resulting parameters into the <span class="math">BF_{\text{cur}}</span> equation to find the base fees, or observing base fees themself. The model I propose focuses on the latter, as a result of my focus being on hourly averaged base fees for use in 1 day plus dated options, and a focus on gas usage would also mean accounting for variable gas limits. The model I am proposing is very flexible, and allow us to simultaneously include trends, seasonality, mean reversion, volatility and jumps.</p>
<p><strong>Overarching Trend</strong></p>
<p>Unlike electricity, wherein supply can vary, base fees relate directly to the demand side usage of a product, a blockchain. When a new EIP is passed as to change the structure of base fees, or if gas usage dramatically decreases. Unlike electricity, trends in gas usage are far shorter and dissimilar to one another, trends should thus be likened to regimes. For example, one regime may be a simple horizontal linear trend in periods of stable usage,  where another is an exponential trend downwards as a result of blobs being recently introduced.</p>
<p><strong>Seasonality</strong></p>
<p>Base Fee demand is heavily influenced by varying usage of economic and business activities of agents on the underlying blockchain. Different kinds of seasonality appear in the data; intra-daily and weekly. As it is usual in this type of research, I assume that seasonality is generated by deterministic factors and since I use the average hourly prices.</p>
<p><strong>Mean-reversion</strong></p>
<p>In the short term, during periods of high demand, base fees spike, discouraging excessive gas usage, which in turn reduces congestion and drives fees back down. Conversely, during low demand periods, lower fees encourage more transactions, increasing congestion and pushing fees back up. This cyclical nature of congestion creates a mean-reverting behaviour in base fees. Essentially, despite short-term fluctuations, base fees tend to stabilize around an average level, influenced by the balance of demand and network capacity.</p>
<p><strong>Jumps and volatility</strong></p>
<p>By simple eye inspection of base fees over time, there is clear existence of important jumps in the behaviour of base fees, as a result of sequential filling of blocks. One of the characteristics of evolution of these jumps is that the base fees do not stay in the new level, to which it jumps, but revert to the previous level rapidly. Such a behaviour can be captured by introducing a jump-diffusion component to a simulation model.</p>
<h2><a class="anchor" href="https://ethresear.ch#pricing-base-fees-1" name="pricing-base-fees-1"></a><strong>Pricing Base Fees</strong></h2>
<p>How should one price option premiums? Determining the appropriate pricing model for gas fees involves understanding their nature and selecting an appropriate financial framework. Gas fees could be treated as equities, interest rates, or commodities, each with distinct modelling approaches. Popular analytical models like the Black-Scholes closed-form model, often used for equities, offer theoretical insights into price movements and volatility - but in the case of base fees, the underlying assumption of normality in returns would be too naive, and the mean reversion and seasonality present in base fees wouldn’t be accounted for. Alternatively, numerical methods such as finite difference and Monte Carlo simulations would provide far more flexible and robust techniques for capturing the stochastic and path dependent nature of base fees. I therefore opt for the Monte Carlo simulation approach.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-specification-and-estimation-2" name="model-specification-and-estimation-2"></a><strong>Model Specification and Estimation</strong></h2>
<p><strong>Exponential Trend Examination</strong></p>
<p>I first assess the presence of an exponential trend by computing the weekly statistics of the mean and standard deviation. If the spot price series exhibits an exponential trend, then the means and standard deviations, computed over time periods, should be correlated with a statistically significant slope.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/f/ffd93a4891dbf0193c6c5b3a00494d51f2569a4a.jpeg" title="Figure_1"><img alt="Figure_1" height="449" src="https://ethresear.ch/uploads/default/optimized/3X/f/f/ffd93a4891dbf0193c6c5b3a00494d51f2569a4a_2_690x449.jpeg" width="690" /></a></div><p></p>
<p>Demonstrated by a p-value close to zero (4.43e-18), an exponential trend is evident in the data. When base fees are high, base fees are volatile. Consequently, to simplify modelling and work with linear trends, I from hereon out use the logarithm of the base fee.</p>
<h3><a class="anchor" href="https://ethresear.ch#deterministic-model-specification-3" name="deterministic-model-specification-3"></a><strong>Deterministic Model Specification</strong></h3>
<p>We have seen in the previous section that a reasonable model for base fee prices should allow for the existence of deterministic seasonality, the possibility of mean-reversion, seasonality jumps, and volatility (randomness). Therefore, I propose a model that simultaneously incorporates all these factors in a flexible way.</p>
<p>The combined long-term model can be written as the composite of a deterministic component <span class="math">f(t)</span> and a stochastic component <span class="math">X_t</span>:</p>
<div class="math">
\log(BF_t) = f(t) + X_t
</div>
<p><strong>Estimation of Deterministic Component</strong> <span class="math">f(t)</span></p>
<p>The deterministic component  <span class="math">f(t)</span> is given by the sum of piecewise regime-based quadratic polynomial trends and sinusoidal functions corresponding to different harmonics and periods:</p>
<div class="math">
f(t) = \sum_{i=1}^{m} \mathbb{I}{\{t \in R_i\}} \left( \gamma{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2 \right) + \beta_1 \sin\left(\frac{2\pi t}{24}\right) + \beta_2 \cos\left(\frac{2\pi t}{24}\right) \\
 + \beta_3 \sin\left(\frac{4\pi t}{24}\right) + \beta_4 \cos\left(\frac{4\pi t}{24}\right) + \beta_5 \sin\left(\frac{8\pi t}{24}\right) + \beta_6 \cos\left(\frac{8\pi t}{24}\right) \\
 + \beta_7 \sin\left(\frac{2\pi t}{168}\right) + \beta_8 \cos\left(\frac{2\pi t}{168}\right) + \beta_9 \sin\left(\frac{4\pi t}{168}\right) + \beta_{10} \cos\left(\frac{4\pi t}{168}\right) \\
 + \beta_{11} \sin\left(\frac{8\pi t}{168}\right) + \beta_{12} \cos\left(\frac{8\pi t}{168}\right) + \xi_t
</div>
<p>Where:</p>
<ul>
<li><span class="math">\log BF_t</span> is the logarithm of the base fees per gasat time (t).</li>
<li><span class="math">t</span> is the time in hours since the start of the sample.</li>
<li><span class="math">\beta_1</span> and <span class="math">\beta_2</span> are the coefficients for the fundamental daily seasonal components (1 day period).</li>
<li><span class="math">\beta_3</span> and <span class="math">\beta_4</span>  are the coefficients for the first harmonic daily seasonal components (1 day period).</li>
<li><span class="math">\beta_5</span> and <span class="math">\beta_6</span> are the coefficients for the second harmonic daily seasonal components (1 day period).</li>
<li><span class="math">\beta_7</span> and <span class="math">\beta_8</span> are the coefficients for the fundamental weekly seasonal components (7 day period).</li>
<li><span class="math">\beta_9</span> and <span class="math">\beta_{10}</span>  are the coefficients for the first harmonic weekly seasonal components (7 day period).</li>
<li><span class="math">\beta_{11}</span> and <span class="math">\beta_{12}</span> are the coefficients for the second harmonic weekly seasonal components (7 day period).</li>
<li><span class="math">\mathbb{I}_{\{t \in R_i\}}</span> is an indicator function that equals 1 if <span class="math">t</span> is within regime <span class="math">R_i</span> and 0 otherwise.</li>
<li><span class="math">\gamma_{i,0}</span>, <span class="math">\gamma_{i,1}</span>, and <span class="math">\gamma_{i,2}</span> are the coefficients for the piecewise polynomial trend within regime <span class="math">R_i</span>.</li>
<li><span class="math">\xi_t</span> is the error term.</li>
</ul>
<p>For each regime <span class="math">R_i</span>, I fit a quadratic model of the form:</p>
<div class="math">
z_i(t) = \gamma_{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2
</div>
<p>To discover the boundaries of each regime, I utilise binary segmentation for detection of change points within the time series. This technique employs a piecewise model, identifying changes based on the L2 norm (Euclidean distance). Initially, the algorithm treats the entire time series as a single segment, searching for a point that maximises the cost function by minimising the residual sum of squares. When a significant change point is identified, the segment is split, and the algorithm recursively continues this process until no further significant change points are found.</p>
<p>In our dataset of roughly two years, and discovered partially heuristically, I identify 16 change points, 17 regimes, with an initial regime immediately after EIP-1559’s release. This finding indicates that the underlying trend in base fees shifts approximately every half to two months. Such shifts are likely influenced by market events such as changes in market sentiment, or other critical factors, all of which could warrant their own focused research to fully understand their cause. I then discover the parameters <span class="math">\gamma_{i,0}</span>, <span class="math">\gamma_{i,1}</span>, <span class="math">\gamma_{i,2}</span> for each regime <span class="math">R_i</span>, using the least squares method. This involves minimising the sum of the squared differences between the observed values <span class="math">BF_t</span> and the predicted values <span class="math">z_i(t)</span> within each regime <span class="math">R_i</span>:</p>
<div class="math">
\min_{\gamma_{i,0}, \gamma_{i,1}, \gamma_{i,2}} \sum_{t \in R_i} \left( BF_t - (\gamma_{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2) \right)^2
</div>
<p>To solve this minimisation problem, I set up the following normal equations by taking partial derivatives with respect to each parameter and setting them to zero:</p>
<div class="math">
\frac{\partial}{\partial \hat{\gamma}_{i,0}} \sum{t \in R_i} \left( y_t - (\hat{\gamma_{i,0}} + \hat{\gamma}_{i,1}) + \hat{\gamma}_{i,2} t^2) \right)^2 = 0 \\
\frac{\partial}{\partial \hat{\gamma}_{i,1}} \sum_{t \in R_i} \left( y_t - (\hat{\gamma}_{i,0} + \hat{\gamma}_{i,1} t + \hat{\gamma}_{i,2} t^2) \right)^2 = 0 \\
\frac{\partial}{\partial \hat{\gamma}_{i,2}} \sum_{t \in R_i} \left( y_t - (\hat{\gamma}_{i,0} + \hat{\gamma}_{i,1} t + \hat{\gamma}_{i,2} t^2) \right)^2 = 0
</div>
<p>Solving these equations yields the least squares estimates for <span class="math">\hat{\gamma}_{i,0}</span><em>, <span class="math">\hat{\gamma}_{i,1}</span></em>, <span class="math">\hat{\gamma}_{i,2}</span>  for each regime <span class="math">R_i</span>. The below figure displays the resulting regimes and trend curves. The regression analysis has a low <span class="math">R^2</span> for the majority of regimes, indicating that the trends are well-fitted to the data. Notably, the current regime, characterised by the implementation of EIP-4844, differs markedly from the previous two regimes, as base fees dramatically decrease immediately after the fork, and are recovering upwards, likely due to the recent bull market activity. I eagerly ask for a discussion with respect to the underlying reasons for each trend.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/4935f9d2b9492a72761b825cbab25df5fc18342c.jpeg" title="Trends"><img alt="Trends" height="412" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/4935f9d2b9492a72761b825cbab25df5fc18342c_2_690x412.jpeg" width="690" /></a></div><p></p>
<p>To calibrate the seasonality components, I first analyse the seasonality present within the data. To do so, I performed a spectral analysis using the Fast Fourier Transform (FFT). The FFT decomposes the time-domain signal into its constituent frequencies, allowing us to compute the power spectrum, which represents the signal’s power distribution across different frequencies. I focused on the positive half of the spectrum and converted frequencies to periods in hours. Significant periodic components were identified by locating peaks in the power spectrum. The identified cycles, with the most prominent displaying daily (24 hours) and weekly (168 hours) seasonality, reinforcing the sinusoidal functions specified above. I visualise the results below to highlight the dominant seasonal patterns in the data.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/c/fc3302537e3548a88afc036869c60322fd6efed6.png" title="Period"><img alt="Period" height="413" src="https://ethresear.ch/uploads/default/original/3X/f/c/fc3302537e3548a88afc036869c60322fd6efed6.png" width="690" /></a></div><p></p>
<p>In estimating the <span class="math">\beta</span> parameters, I also use a least squares optimisation method. Given the observed log base fees <span class="math">BF</span> and the seasonality matrix <span class="math">C</span>, the objective is to estimate the seasonality parameters <span class="math">\beta</span> that minimise the sum of squared residuals. This is formulated as:</p>
<div class="math">
\min_{\beta} \| log(BF)_{detrended} - C \beta \|^2

</div>
<p>where:</p>
<ul>
<li><span class="math">log(BF)_{detrended}</span>  is the vector of de-trended log base fees,</li>
<li><span class="math">C</span>  is the matrix containing the seasonality functions (sine, cosine),</li>
<li><span class="math">\beta</span>  is the vector of seasonality parameters to be estimated.</li>
</ul>
<p>The expanded form of the objective function is:</p>
<div class="math">
\min_{\beta} \sum_{I=1}^{n} (log(BF_i)_{detrended} - C_i \beta)^2
</div>
<p>where  <span class="math">log(BF_i)_{detrended}</span> is the <span class="math">i</span> -th observed log base fee and <span class="math">C_i</span>  is the  <span class="math">i</span>-th row of the seasonality matrix. To find the least squares solution, I set the gradient of the objective function with respect to <span class="math">\beta</span> to zero, yielding the normal equations:</p>
<div class="math">
\frac{\partial}{\partial \beta} \left( \sum_{i=1}^{n} (log(BF_i)_{detrended} - C_i \beta)^2 \right) = -2 C^T (log(BF_i)_{detrended} - C \hat{\beta}) = 0
</div>
<p>Simplifying, I obtain:</p>
<div class="math">
C^T C \hat{\beta} = C^T log(BF)_{detrended}
</div>
<p>Solving the normal equations for  \beta  provides the least squares estimates:</p>
<div class="math">
\hat{\beta} = (C^T C)^{-1} C^T log(BF)_{detrended}
</div>
<p>where  <span class="math">(C^T C)^{-1} C^T</span>  is the Moore-Penrose pseudoinverse of <span class="math">C</span>. The de-seasonalized and de-trended log prices are then calculated by subtracting the combined seasonality components from the observed log prices, as is shown in the figure below.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f324d5ecfcda3c65cc3aebdbfbd09ac4e6bf621.png" title="Seasoned"><img alt="Seasoned" height="459" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f324d5ecfcda3c65cc3aebdbfbd09ac4e6bf621_2_690x459.png" width="690" /></a></div><p></p>
<p>Visibly, base fees in the Ethereum network fluctuate due to weekly and daily patterns of usage. During the week, gas usage is typically higher as business activities, market trading, and development deployments peaks. This weekly seasonality contrasts with daily patterns where peak periods of gas usage occur in the morning and evening as global participants, including Europe and North America, overlap in activity.</p>
<p>Despite removing trend and overarching seasonality, I observe that autocorrelative structure is still present in our time series. To address this, I explore the autocorrelation function (ACF) and the partial autocorrelation function (PACF) of the data. The ACF helps identify the correlation between observations at different lags of base fees, providing insights into the persistence of shocks over time. The PACF isolates the direct effect of a lagged observation by controlling for the contributions of intermediate lags, aiding in the identification of the order of the autoregressive (AR) terms in an ARIMA model. By observing the graph below, we observe 34 autocorrelated lags, and 5 partially autocorrelated lags.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/1/519bf7d93d2812acc39ec47dc5879a39ec44dca8.png" title="Autocorrelation"><img alt="Autocorrelation" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/1/519bf7d93d2812acc39ec47dc5879a39ec44dca8_2_532x500.png" width="532" /></a></div><p></p>
<p>To address these lags, I fit an ARIMA(34, 5, 5) model to the de-seasonalized and de-trended data. This model captures the autoregressive and moving average components along with differencing. By fitting this model, we obtain the residuals, which represent the underlying structure of the noise after accounting for these components. Upon examining the residuals, we find that the distribution of the noise is sharply centered around zero with fat tails. The transition between the central peak and the tails appears to follow an exponential pattern. Consequently, we fit a Laplace distribution to the residuals and compare the observed values against the expected values, where the Laplace distribution is defined as:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/520b0b7803ad250ea93fc680b158f762eb2571b0.png" title="StandardisedResidules"><img alt="StandardisedResidules" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/520b0b7803ad250ea93fc680b158f762eb2571b0_2_673x500.png" width="673" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65238658d70c03f7293ed41bb385d7eb95d65c7d.png" title="PDF"><img alt="PDF" height="499" src="https://ethresear.ch/uploads/default/original/3X/6/5/65238658d70c03f7293ed41bb385d7eb95d65c7d.png" width="690" /></a></div><p></p>
<div class="math">
f(x; \mu, b, \kappa) =
\begin{cases}
\frac{\kappa}{b} \exp \left( \frac{x - \mu}{b} \kappa \right), &amp; \text{if } x \leq \mu \\
\frac{1}{b \kappa} \exp \left( -\frac{x - \mu}{b \kappa} \right), &amp; \text{if } x &gt; \mu
\end{cases}
</div>
<ul>
<li><span class="math">\mu</span>  is the location parameter (mean),</li>
<li><span class="math">b &gt; 0</span>  is the scale parameter,</li>
<li><span class="math">\kappa &gt; 0</span>  controls the asymmetry of the distribution. a Kappa equal to 1 produces a symmetrical Laplace distribution.</li>
</ul>
<p>A Laplace distribution is significant because it characterises the distribution as having exponential decay on both sides of the peak. In the context of Ethereum base fees, changes often occur as a percentage of the previous base fee rather than by fixed amounts. This implies that large deviations from the mean are more probable than would be expected under a normal distribution, leading to the characteristic heavy tails of the Laplace distribution. The sharp central peak of the Laplace distribution indicates a high probability of small changes around the long term mean. The fat tails, on the other hand, reflect the occasional large percentage changes, driven by significant network, a series of full block events or structural shifts in demand for block space. One would expect a higher denominator parameter (reducing sensitivity of base fees to gas usage) to create a ‘tighter’ distribution with a lower standard deviation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/8359c539f8d3aae5ec27461b63895a852255410e.png" title="QQ"><img alt="QQ" height="482" src="https://ethresear.ch/uploads/default/original/3X/8/3/8359c539f8d3aae5ec27461b63895a852255410e.png" width="690" /></a></div><p></p>
<p>I plot the theoretical quantiles of the Laplace distribution against the observed residual quantiles in a QQ plot. The plot revealed that a few outlier observations exhibited fatter tails than predicted by the Laplace distribution, indicating that the residuals have more extreme values than our model accounts for. Nevertheless, the majority of the data points followed the expected distribution, suggesting that the Laplace distribution still provides a reasonable fit for the central portion of the residuals.</p>
<p><strong>Stochastic Component Specification</strong></p>
<div class="math">
X_t = \log BF_t - f(t)
</div>
<p><strong>Cox, Ingersoll &amp; Ross Poisson Asymmetrical Laplace calibrated model</strong></p>
<p>Removing the trend and observing the noise, the stochastic component <span class="math">X_t</span>  is modelled as an Ornstein-Uhlenbeck process (mean-reverting) with jumps, incorporating a Laplace distribution for both the noise term and the jump size</p>
<div class="math">
dX_t = (\alpha - \kappa X_t) \, dt + \sigma \, dL_t + J(\mu_J, \sigma_J) \, d\Pi(\lambda),
</div>
<p>where:</p>
<ul>
<li><span class="math">α</span> is the drift parameter,</li>
<li><span class="math">κ</span>  is the rate of mean reversion,</li>
<li><span class="math">σ</span> is the volatility,</li>
<li><span class="math">L_t</span> is a noise term following a Laplace distribution,</li>
<li><span class="math">J(μ_J , σ_J )</span> is the jump size, following a Laplace distribution with mean  <span class="math">μ_J</span> and scale parameter <span class="math">σ_J</span> ,</li>
<li><span class="math">Π(λ)</span> is a Poisson process with jump intensity <span class="math">λ</span>.</li>
</ul>
<p>The transition probabilities for base fee equilibrium prices follow a Poisson-Laplace process. This can be expressed as:</p>
<div class="math">

p(X_t | X_{t-1}) = \lambda \frac{1}{2b} \exp\left(-\frac{|X_t - (a \Delta t + \phi X_{t-1} + \mu_J)|}{\sqrt{v_t (\sigma^2 + \sigma_J^2)}}\right)

</div>
<div class="math">

• (1-\lambda) \cdot \frac{1}{2b} \exp\left(-\frac{|X_t - (a \Delta t + \phi X_{t-1})|}{\sqrt{v_t \sigma^2}}\right)

</div>
<p>where:</p>
<ul>
<li><span class="math">∆t</span> is the time increment,</li>
<li><span class="math">a</span> is the drift term,</li>
<li><span class="math">φ</span> is the autoregressive coefficient,</li>
<li><span class="math">b</span> is the scale parameter of the Laplace distribution.</li>
</ul>
<p>The parameters <span class="math">Q = {α, κ, σ, a, b, μ_J , σ_J , λ}</span> can first be estimated by Maximum Likelihood (ML). This approach ensures that the parameters <span class="math">Q</span> are optimised to best fit the observed data under the specified model. The results of the simulation, displayed below, demonstrate the simulated log base fees for the next month. Notably, considering the most recent regime of exponential increase, I adopt a neutral market approach by assuming a linear (horizontal) trend. For pricing derivative products, consideration of what the future trend will be should be taken into account. After retrieving calibrated parameters, a range of future hourly dates is produced, before trend and seasonality is added back in, and the exponential is taken to revert the log.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/af172a8475671fb615b0494f03c0e53f7d01c0fb.png" title="Simulation"><img alt="Simulation" height="500" src="https://ethresear.ch/uploads/default/original/3X/a/f/af172a8475671fb615b0494f03c0e53f7d01c0fb.png" width="592" /></a></div><p></p>
<p><strong>ARIMA Monte Carlo Method</strong></p>
<p>An alternative method, which requires less computation simulates a monte-carlo process by modelling standardised residuals directly from a Laplace distribution, augmenting these standardised residuals back de-normalising them, before generating future paths as the composite of both this noise and ARIMA forecasts. A simulated residual path is shown below, producing the resulting simulation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/0/70411cba63138e2322e32a338e350acc9dbeebe9.png" title="Residules"><img alt="Residules" height="500" src="https://ethresear.ch/uploads/default/original/3X/7/0/70411cba63138e2322e32a338e350acc9dbeebe9.png" width="651" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/7/a71fae0b0032a14bc4099ebbd6b20f28c69bfd5a.png" title="Sim2"><img alt="Sim2" height="479" src="https://ethresear.ch/uploads/default/optimized/3X/a/7/a71fae0b0032a14bc4099ebbd6b20f28c69bfd5a_2_690x479.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/e/ce326060566053721576245372a025708af87d0b.jpeg" title="Screenshot 2024-06-14 at 12.50.40"><img alt="Screenshot 2024-06-14 at 12.50.40" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/e/ce326060566053721576245372a025708af87d0b_2_687x500.jpeg" width="687" /></a></div><p></p>
<p><strong>Pricing with these simulated values</strong></p>
<p>For the purpose of hedging, pricing a European call or put option based on the simulated paths can be expressed as follows. Let <span class="math">BF_T^i</span> represent base fees per gas at maturity <span class="math">T</span> for the <span class="math">i</span>-th simulated path, where <span class="math">i = 1, 2, \ldots, N</span>, and denote the strike price by <span class="math">K</span>. The payoff for the European call option at maturity for the <span class="math">i</span>-th path is given by <span class="math">\max(BF_T^i - K, 0)</span>, and for the European put option, it is given by <span class="math">\max(K - BF_T^i, 0)</span>. To find the option price, I first calculate the average payoff across all <span class="math">N</span> simulated paths: <span class="math">\frac{1}{N} \sum_{i=1}^N \max(BF_T^i - K, 0)</span> for the call option, and <span class="math">\frac{1}{N} \sum_{i=1}^N \max(K - BF_T^i, 0)</span> for the put option. These average payoffs are then discounted to the present value using the risk-free rate <span class="math">r</span>, giving the price of the European call option at time 0 as <span class="math">C_0 = e^{-rT} \times \frac{1}{N} \sum_{i=1}^N \max(BF_T^i - K, 0)</span> and the price of the European put option at time 0 as <span class="math">P_0 = e^{-rT} \times \frac{1}{N} \sum_{i=1}^N \max(K - BF_T^i, 0)</span>.</p>
<p>In pricing a gas plan where the underwriter subsidises the entire unit of gas at any point before <span class="math">T</span> I can model this as an American call option on gas fees with a strike price of zero and implement the Longstaff and Schwartz Regression Approach. This method involves calculating the payoff at the final period <span class="math">T</span> as the gas fee <span class="math">BF_T^i</span> for each path <span class="math">i</span>, assuming no transaction has been exercised before this time. Moving one time step backward, one regress the discounted future payoffs against the current gas fees <span class="math">BF_t^i</span> to estimate continuation values. This regression, known as a basis function, typically includes terms like a constant, <span class="math">BF_t^i</span>, and <span class="math">(BF_t^i)^2</span>. At each time step <span class="math">t</span>, we compare the immediate exercise value <span class="math">BF_t^i</span> with the estimated continuation value <span class="math">\hat{C}_t^i</span> from the regression. If the exercise value is higher, one updates the cash flow to reflect exercising the option; otherwise, we carry forward the discounted cash flow. Finally, the option price at time 0 (now) is obtained by averaging the discounted cash flows across all paths and all time periods.</p>
<p><strong>Utility in Oiler Pitch Lake</strong><br />
Oiler Pitch Lake is a protocol designed to allow liquidity providers (LPs) by pooling their assets to act as sellers in time-weighted moving average (TWAP) base fee cash-settled call options. Utilizing Starknet STARKS and the Fossil coprocessor for verifiability, Pitch Lake determines option payoffs based on the average base fee over a specified time interval, akin to an Asian option.</p>
<p>Given that LPs put up a limited amount of collateral, there is a cap on each option’s payoff. To protect LPs, a reserve price can be set, which is the minimum price at which the option must be sold. Using the aforementioned methodology, this reserve price can be calculated with both accuracy and verifiability, ensuring that LPs are safeguarded. Pitch Lake is currently in development and is expected to launch in the coming months.</p>
<p><strong>Next Steps</strong></p>
<ul>
<li><strong>Call for reproduction</strong>: Please reproduce my analysis and methodology. Working with complex financial mathematics can be prone to assumptions that may be easily violated. View this as an initial attempt to dive into the gas fee pricing topic</li>
<li><strong>What about the blobs market and L2 fee markets? I</strong> am currently working on similar analysis for the blob fee market place, L2 fees, and other blockchains. Expect more results soon.</li>
</ul>
<p><strong>Bibliography</strong><br />
[1] Oiler Pitch Lake. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018" rel="noopener nofollow ugc">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018</a><br />
[2] SMG Spec <a class="inline-onebox" href="https://www.mechanism.org/spec/04" rel="noopener nofollow ugc">04</a><br />
[3] [2] Lucia, Julio J., Schwartz, Eduaro. “Electricity Prices and Power Derivatives: Evidence from the Nordic Power Exchange.” Review of Derivatives Research. Vol. 5, Issue 1, pp 5-50, 2002. <a class="inline-onebox" href="https://link.springer.com/article/10.1023/A:1013846631785" rel="noopener nofollow ugc">Electricity Prices and Power Derivatives: Evidence from the Nordic Power Exchange | Review of Derivatives Research</a><br />
[4] Seifert, Jan, Uhrig-Homburg, Marliese. “Modelling Jumps in Electricity Prices: Theory and Empirical Evidence.” <em>Review of Derivatives Research</em>. Vol. 10, pp 59-85, 2007. <a class="inline-onebox" href="https://uk.mathworks.com/help/fininst/simulating-electricity-prices-with-mean-reversion-and-jump-diffusion.html" rel="noopener nofollow ugc">Simulating Electricity Prices with Mean-Reversion and Jump-Diffusion - MATLAB &amp; Simulink - MathWorks United Kingdom</a><br />
[5] Escribano, Alvaro, Pena, Juan Ignacio, Villaplana, Pablo. “Modeling Electricity Prices: International Evidence.” Universidad Carloes III de Madrid, Working Paper 02-27, 2002. Modeling Electricity Prices: International Evidence <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=299360" rel="noopener nofollow ugc">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=299360</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pricing-gas-fee-derivatives/19898">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 20:59:59 +0000</pubDate>
</item>
<item>
<title>Execution Auctions as an Alternative to Execution Tickets</title>
<link>https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894</link>
<guid>https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894</guid>
<content:encoded><![CDATA[
<div> 关键词：执行拍卖（Execution Auctions, EAs）、执行门票（Execution Tickets, ETs）、MEV、中央化、价值分配

总结:<br />
文章比较了两种解决以太坊中矿工效用提升（MEV）问题的机制：执行拍卖和执行门票。这两种方法旨在通过出售执行权来解决协议中的代理人问题，提高效率并减少外部性。文章分析了两种机制的经济差异，包括预期现值（NPV）、风险折扣、成本控制和中央化风险。执行拍卖简单易实现，但可能导致集中化；执行门票利用随机性，虽能防止集中，但可能涉及复杂性。最后，文章认为执行拍卖在实践中可能更优，尽管执行门票在某些方面提供保护。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/128696dce49653e3211f52d33f86612013a883c4.jpeg" title="ealien"><img alt="ealien" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/128696dce49653e3211f52d33f86612013a883c4_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><br />
<em>By <a href="https://twitter.com/_JonahB_">Jonah Burian</a> &amp; <a href="https://twitter.com/DavideCrapis">Davide Crapis</a></em></p>
<p><em>Special thanks to <a href="https://x.com/weboftrees">Anders Elowsson</a>, <a href="https://twitter.com/barnabemonnot">Barnabé Monnot</a>, <a href="https://twitter.com/drakefjustin">Justin Drake</a> and <a href="https://twitter.com/mikeneuder">Mike Neuder</a> for the feedback and review.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>There is a principal-agent problem in Ethereum. While the protocol creates MEV, it leaks it to proposers. Moreover, MEV in its current state exposes the protocol to other externalities, such as <a href="https://arxiv.org/abs/2305.09032">timing games</a>. It is widely held in the research community that capturing and properly redistributing MEV is an important step in the evolution of Ethereum, to make the protocol more resilient and efficient (<em>note: there are some people who <a href="https://www.nano210.blog/infinite-blockspace-equilibrium/">disagree</a>)</em>. The only way to solve this principal-agent problem is for the protocol to sell the rights to earn the MEV with a credible and efficient mechanism.</p>
<p>After many years of research, two approaches have recently emerged as potential avenues for solving MEV-burn. These are mechanisms where the right to propose an execution payload is not given for free to the <em>beacon proposer</em>, but it is instead sold separately to an <em>execution proposer</em>.</p>
<ul>
<li><strong>Execution Auctions (EAs):</strong> The right to propose an execution payload is <em>deterministically allocated</em> in advance for each slot, the slot execution proposer can purchase this right by bidding in a slot auction held beforehand, for example <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ#:~:text=introduce%20it%20next.-,Slot%2Dauction%2B32%20ePBS,-We%20suggest%20now">32 slots earlier</a>.</li>
<li><strong>Execution Tickets (ETs):</strong> the execution proposer right is not deterministically allocated, proposers can purchase a lottery ticket in advance and then, before each slot, a winner is drawn at random from the ticket pool and gets the right to propose.
<ul>
<li>The simple version of the protocol gives the winner the right to propose the following block. This was the focus of <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>.</li>
<li>The original execution ticket post <a href="https://ethresear.ch/t/execution-tickets/17944#:~:text=There%20exists%20a,market%20function%20smoothly.">suggested</a> a general version of the protocol where the winner has the right to propose <span class="math">m</span> slots later (e.g., 32). The intuition for why winners are given slots multiple slots in advance as opposed to immediately is that the solution allows for winners to offer preconfs.</li>
</ul>
</li>
</ul>
<p>The mechanisms have the same objective but important differences. The goal of this post is to compare the two solutions.</p>
<h1><a class="anchor" href="https://ethresear.ch#setup-2" name="setup-2"></a>Setup</h1>
<p>We will introduce formulas throughout this post to outline the key economic differences between the protocols. We will also explain the practical nuances, so if you want to skip the math, no worries! For the extra curious, we lay out the proof of the formulas in the appendix.</p>
<h2><a class="anchor" href="https://ethresear.ch#terms-3" name="terms-3"></a>Terms</h2>
<ul>
<li><span class="math">t</span> — discrete time intervals (slot).</li>
<li><span class="math">n</span> — the number of tickets.</li>
<li><span class="math">d</span> is the inter-slot discount rate used to calculate the present value of future prizes.
<ul>
<li>Note: assuming that the vanilla staking rate is the risk-free rate in Ethereum, <span class="math">d \approx 10^{-8}</span></li>
</ul>
</li>
<li><span class="math">\mathcal{R}</span> is a random variable representing the value of controlling an execution payload at time <span class="math">t</span>.
<ul>
<li>We term this the Execution Layer Reward (EL Reward) which equals MEV + fees in slot <span class="math">t</span>.</li>
<li>We assume that <span class="math">\mathcal{R}</span> has a distribution that does not vary with time and that each draw is independent. (This is usually not the case in practice, as EL rewards are time-varying and correlated, but it allows for a less complicated analysis that can be expanded later.)</li>
</ul>
</li>
<li><span class="math">\mu_{\mathcal{R}}</span> is the expected value of <span class="math">\mathcal{R}</span>.</li>
<li><span class="math">V_{ticket}</span> — Net Present Value (NPV) of a single ticket.
<ul>
<li>Note: present value of some value <span class="math">X</span> realized at time <span class="math">t</span> is calculated as <span class="math">\frac{X}{(1+d)^t}</span>.</li>
</ul>
</li>
<li><span class="math">m</span> — number of slots t after winning that the right to propose is given (e.g., <span class="math">m=32</span>).</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#northstar-4" name="northstar-4"></a>Northstar</h2>
<p>The expected net present value of all future EL Rewards is</p>
<div class="math">
NPV_{\mathcal{R}} = \frac{\mu_{\mathcal{R}}}{d}
</div>
<p>This is the total value of all block space from now into the future of Ethereum. Given that the goal of the Execution Auctions and Execution Tickets is to capture the value of block space and redistribute the value to align with the protocol’s goals, all solutions must be analyzed in terms of how well they capture <span class="math">NPV_{\mathcal{R}}</span>.</p>
<p><em>Note: Capturing all the value depends on the selling mechanism. In this analysis, we assume that the selling mechanism is efficient. Detailed analysis of the selling mechanism in a dynamic/repeated strategic interaction context is an open problem currently under research.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#execution-auctions-5" name="execution-auctions-5"></a>Execution Auctions</h1>
<p>Execution Auctions (EAs) are essentially slot auctions carried out in advance:</p>
<ul>
<li><strong>Proposer right allocation:</strong> the <em>execution proposer right</em> for slot <span class="math">k+m</span> is sold <span class="math">m</span> slots in advance, at slot <span class="math">k</span>.</li>
<li><strong>Selling mechanism:</strong> the beacon proposer of slot <span class="math">k</span> receives bids for that right and commits to the highest bid, attesters vote.</li>
</ul>
<p>A <strong>secondary market</strong> will most likely develop where an EA ticket winner can resell their proposer right before their turn to propose. Even if the protocol does not allow them to transfer that right, this can be easily done via an out-of-protocol gadget.</p>
<h1><a class="anchor" href="https://ethresear.ch#execution-tickets-6" name="execution-tickets-6"></a>Execution Tickets</h1>
<p>Execution Tickets (ETs) have a lottery component that adds uncertainty on the specific block a holder will be able to propose in the future, this can be resolved closer to the time of proposing or further ahead of time.</p>
<ul>
<li><strong>Proposer right allocation:</strong> the <em>execution proposer right</em> for <em>a slot</em> in the future is sold in the form of a lottery ticket.</li>
<li><strong>Selling mechanism:</strong> assume there are already <span class="math">n</span> tickets in the lottery pool, at each slot a ticket is selected as lottery winner (e.g., at the end of the slot using RANDAO) and a new ticket is sold to enter the pool starting from the next slot.
<ul>
<li><strong>Pricing:</strong> We assume an English Auction for comparison with EAs.</li>
<li><strong>Uncertainty resolution:</strong> we can have a next-slot execution lottery, where at the end of slot <span class="math">k</span> we select proposer for slot <span class="math">k+1</span> (we term these sETs i.e, simple ETs), or a future-slot execution lottery, where at the end of slot <span class="math">k</span> we select proposer for slot <span class="math">k+m</span> (we term these ETs).</li>
</ul>
</li>
</ul>
<p>Similarly to EAs, a secondary market will likely emerge where a ticket holder or a winning ticket holder can resell their right to participate in the lottery or propose.</p>
<p><em>Note: In the initial post <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a> we did not yet make the distinction between sETs and ETs. That post was about sETs (a special case of ETs).</em></p>
<p><em>Note 2: <a href="https://twitter.com/drakefjustin">Justin </a> perceptively pointed out that we don’t know how to achieve low-latency randomness using RANDAO, and VDFs wouldn’t help either. Low-latency RANDAO would be biasable (as well as fully predictable when you control two slots in a row).</em></p>
<h1><a class="anchor" href="https://ethresear.ch#analysis-7" name="analysis-7"></a>Analysis</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/0/c088b53c1b671ac4704f3ff5c99e4b792264c861.png" title="Chart 1"><img alt="Chart 1" height="174" src="https://ethresear.ch/uploads/default/optimized/3X/c/0/c088b53c1b671ac4704f3ff5c99e4b792264c861_2_690x174.png" width="690" /></a></div><p></p>
<p><em>Note: All approximations assume <span class="math">m</span> (time from when the ticket wins to when the right is conferred) and <span class="math">n</span> (number of ETs) are not large. Given that <span class="math">d</span> is nearly zero, we are able to simplify the equations.</em></p>
<p><em>Note 2: Without using the approximation,</em> EA tickets <em>and ETs have some Dead Weight Loss associated with the fact that winning tickets cannot be immediately used, i.e., there is some loss given the time discount. The intuition for the approximation is that given <span class="math">d</span> is small, this value loss due to the time discount is nominal.</em></p>
<p><em>Note 3: While we assume in the approximation for the variance of sETs and ETs that <span class="math">n</span> is small, we discussed in “<a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>” that a large <span class="math">n</span> leads to less centralization risk and more democratization in terms of who can afford a ticket. That said, a large <span class="math">n</span> creates valuation complexity and adds the additional complexity of having to run a large sale at the beginning of the lottery to bootstrap the ticket pool. (Read the article to learn more.)</em></p>
<p>Here is a simplified version of the chart assuming the approximation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/a/dad825aa8d8c8324d64726716ed5a0fd84508ffe.png" title="Chart 2"><img alt="Chart 2" height="186" src="https://ethresear.ch/uploads/default/optimized/3X/d/a/dad825aa8d8c8324d64726716ed5a0fd84508ffe_2_517x186.png" width="517" /></a></div><p></p>
<p>Notice that all three approaches using the approximation arrive at the same conclusion: we can effectively capture (assuming an efficient auction) all the value associated with block space. Moreover, in each design, the tickets have a simple explanation: they are worth about the value associated with proposing an execution payload.</p>
<p>The variance of the ticket value is the variance of the rewards per slot, which is about as good as you are going to get given that the rights to propose are sold in advance, namely prior to the block’s construction.</p>
<h1><a class="anchor" href="https://ethresear.ch#sure-thing-vs-future-possibility-comparing-eas-and-setsets-8" name="sure-thing-vs-future-possibility-comparing-eas-and-setsets-8"></a>Sure Thing vs Future Possibility: Comparing EAs and sETs/ETs</h1>
<p>We now turn to comparing EAs and sETs/ETs to elucidate trade-offs when thinking about implementing such mechanisms in practice. It should be noted that most of the tradeoffs stand from the fundamental difference between EAs and sETs/ETs - the former is a deterministic protocol while the latter leverages nondeterminism.</p>
<ul>
<li><strong>Implementation Simplicity:</strong> EAs are simpler to implement, the tickets do not require randomness so there is no need to worry about RANDAO bias. Moreover, it is unclear how to implement the randomness for sETs. The secondary market for proposer rights with EA tickets will be much simpler than with sETs/ETs, no need to worry about ticket MEV. Moreover, there seems to be a <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">clear path to implement EAs via ePBS</a> and bypassability not an issue since we’re selling future slots.</li>
<li><strong>Simpler Assets:</strong> It is easier to reason about a deterministic asset than a random one, which makes EA better than sETs and ETS. That said, buyers in the protocol are most likely sophisticated, and the current paradigm for selecting validators relies on randomness, meaning maintaining non-determinism won’t be a substantial break from the status quo. However, a counterargument is that current proposers might not be buyers of tickets.</li>
<li><strong>Variance could affect valuation and EA tickets are less exposed:</strong> It is reasonable for ticket holders to apply a risk discount to the tickets; that is, they might value the tickets less given risk aversion. While EA tickets are only exposed to the variance in the value of the EL rewards in slot <span class="math">t+m</span>, both sETs and ETs are exposed to the variance in EL rewards and the variance in when a ticket wins. Intuitively, EA would therefore have the lowest risk discount.</li>
<li><strong>Efficiency:</strong> From the protocol’s POV, sETs are more efficient because proposer rights are sold closer to the slot of the MEV in expectation while EAs and ETs have dead weight loss in theory. That said, when factoring in risk aversion, EAs might be more efficient.</li>
<li><strong>Preconfs</strong>: Preconfs require there to be a lookahead, meaning the protocol must know in advance who will control the rights to the execution payload. While EAs and ETs allow for preconfs, sETs do not, as winners are decided at each block.</li>
<li><strong>Cost-of-control:</strong>
<ul>
<li><strong>In EA</strong>
<ul>
<li>EAs put <em>transaction liveness</em> risk on Ethereum—namely, the cost of monopolizing block space is disjoint from the security budget of Ethereum, and the cost of controlling consecutive blocks has a fixed value. Controlling <span class="math">x</span> blocks in a row costs approximately <strong><span class="math">\approx x\mu_{\mathcal{R}}</span></strong>. Luckily, new <a href="https://eips.ethereum.org/EIPS/eip-7547">IL designs</a> could rectify this. Even with ILs, relying heavily on them is suboptimal (they are designed to be a last resort, not commonplace—this can be argued). Importantly as well, the ability to consistently control multiple slots means that well-capitalized parties will perpetually win more block space. This could lead to centralization of the execution payload construction pipeline, exacerbating the current centralization challenges within this pipeline. (See the Multi-block MEV section in “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>”).</li>
<li><a href="https://twitter.com/barnabemonnot">Barnabé</a> aptly noted to us that saying the “the cost of monopolizing block space is disjoint from the security budget of Ethereum” is no different from the existing setup where validators can sell building rights. Currently, validators can sell multiple consecutive blocks in a row. <em>This does not mean that the centralization argument is incorrect but indicates that EAs are not a substantial break from the status quo.</em></li>
</ul>
</li>
<li><strong>In sETs (and ETs):</strong>
<ul>
<li>
<p>While the cost of monopolizing block space is disjoint from the security budget with sETs (and ETs), it is substantially more expensive and less likely that a single party can control multiple consecutive blocks in a row. Non-determinism prevents guaranteed control over block space reducing the likelihood of control. Randomness serves as a defense against centralization.</p>
<ul>
<li>
<p>The first chart provides an intuitive understanding of this principle. It shows a scenario with 100 outstanding sETs/ETs. If someone owns 95% of the initial outstanding tickets (remember, one is subsequently minted per block), the probability of winning 20 slots in a row is approximately 4%, while the probability of winning 35 in a row is almost impossible.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/3/63786be4729c8134b1fa101788af325a31fb7427.png" title="Graph 1"><img alt="Graph 1" height="412" src="https://ethresear.ch/uploads/default/optimized/3X/6/3/63786be4729c8134b1fa101788af325a31fb7427_2_690x412.png" width="690" /></a></div><p></p>
</li>
<li>
<p>Moreover, the costs of controlling <span class="math">P\%</span> of the blocks increases in <span class="math">n</span> (See: <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>)<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/5/b5e0ee59790fe044c3adbb4ae4f5ae4408e0694c.png" title="Graph 2"><img alt="Graph 2" height="186" src="https://ethresear.ch/uploads/default/optimized/3X/b/5/b5e0ee59790fe044c3adbb4ae4f5ae4408e0694c_2_690x186.png" width="690" /></a></div><p></p>
</li>
</ul>
</li>
<li>
<p><strong>Where ETs differ:</strong></p>
<ul>
<li>While an attacker in sETs must rely on chance to win consecutive blocks, a clever ETs user can buy a sequence of winning tickets for <span class="math">t+m</span> to <span class="math">t+m+x</span> on the secondary market, making the centralization in ETs similar to the centralization problem with EAs. One can argue that sETs are subject to the same risk as an out-of-protocol auction for control of the sETs winners’ rights can happen. That said, there may be honest actors who don’t sell rights to execution payload construction. If one of these holders wins, they end the sequence of winning blocks for a sET attacker, meaning that a sET attack, even with the out-of-protocol option, is exposed to uncertainty.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#concluding-remarks-9" name="concluding-remarks-9"></a>Concluding Remarks</h1>
<p>EAs dominate in simplicity, while sETs protect from centralization but at the expense of allowing for preconfs. sETs may also be unimplementable in the Ethereum Protocol today given the RANDAO problem. ILs can curb centralization concerns with EAs, and the secondary market for sETs/ETs can nullify their protective benefits. Moreover, EAs are not a substantial break from the status quo in terms of centralization.</p>
<p><em>While there are still open questions around implementing EAs and their efficiency, EAs seem to be superior to sETs and ETs for the Ethereum protocol.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#related-work-10" name="related-work-10"></a><strong>Related work</strong></h1>
<p><em>This list is copied and pasted from</em> <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a> with the addition of <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>. lol</p>
<ol>
<li><em>mev-boost &amp; relays</em>
<ul>
<li><a href="https://ethresear.ch/t/mev-boost-merge-ready-flashbots-architecture/11177"><em>MEV-Boost: Merge ready Flashbots Architecture</em></a>; Flashbots team</li>
<li><a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278"><em>Relays in a post-ePBS world</em></a>; Mike, Jon, Hasu, Tomasz, Chris, Toni</li>
</ul>
</li>
<li><em>mev-burn / mev-smoothing</em>
<ul>
<li><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>Burning MEV through block proposer auctions</em></a>; Domothy</li>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn – a simple design</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408"><em>Committee-driven MEV smoothing</em></a>; Francesco</li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384"><em>Dr. changestuff or: how I learned to stop worrying and love mev-burn</em></a>; Mike, Toni, Justin</li>
</ul>
</li>
<li><em>enshrined Proposer-Builder Separation (ePBS)</em>
<ul>
<li><a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980"><em>Two-slot proposer/builder separation</em></a>; Vitalik</li>
<li><a href="https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879"><em>Unbundling PBS: towards protocol-enforced proposer commitments (PEPC)</em></a>; Barnabé</li>
<li><a href="https://barnabe.substack.com/p/pbs"><em>Notes on Proposer-Builder Separation</em></a>; Barnabé</li>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ"><em>More pictures about proposers and builders</em></a>; Barnabé</li>
<li><a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710"><em>Why enshrine Proposer-Builder Separation?</em></a>; Mike, Justin</li>
<li><a href="https://ethresear.ch/t/epbs-design-constraints/18728"><em>ePBS design constraints</em></a>; Potuz</li>
<li><a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg"><em>Reconsidering the market structure of PBS</em></a>; Barnabé</li>
</ul>
</li>
<li><em>block-space futures</em>
<ul>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ"><em>Block vs. Slot Auction PBS</em></a>; Julian</li>
<li><a href="https://frontier.tech/ethereums-blockspace-future"><em>Opportunities and Considerations of Ethereum’s Blockspace Future</em></a>; Drew, Ankit</li>
<li><a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814"><em>When to sell your blocks</em></a>; Quintus, Conor</li>
</ul>
</li>
<li><em>execution tickets</em>
<ul>
<li><a href="https://www.youtube.com/watch?v=MtvbGuBbNqI"><em>Attester-proposer separation</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/execution-tickets/17944"><em>Execution tickets</em></a>; Justin, Mike</li>
<li><a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894"><em>Economic Analysis of Execution Tickets</em></a>; Jonah, Davide</li>
<li><a href="https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232"><em>Block-auction ePBS versus Execution Ticket</em></a>; Terence</li>
</ul>
</li>
<li><em><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>; Mike, Pranav, &amp; Dr. Tim Roughgarden</em></li>
</ol>
<p><em>This post has a similar goal to</em> <a href="https://x.com/mikeneuder">Mike</a>, <a href="https://x.com/PGarimidi">Pranav</a>, &amp; <a href="https://x.com/Tim_Roughgarden">Tim</a>’s recent work titled <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>: <em>comparing new mechanisms for execution rights allocation.</em> However, there are a few key differences in our analysis that we highlight here:</p>
<ol>
<li>They use a modified ET model (i.e., a model where all tickets are burned between slots). This model, while easier to implement, does not lead to an efficient allocation (as those with lower valuations for block space can still be allocated it).</li>
<li>They focus on a Tullock Contest model, while our model resembles a fixed-income model.</li>
<li>Their analysis focuses on the trade-off between the quality of the in-protocol MEV oracle and the fairness of the mechanism, while we focus on other trade-offs such as implementation ease, risk discounts, centralization control, and economic efficiency.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#appendix-11" name="appendix-11"></a>Appendix</h1>
<p><strong>Calculating the discount rate:</strong></p>
<p>The staking rate at the time of this article is <code>~3.4%</code> (<a href="https://www.coindesk.com/indices/ether/cesr">source</a>).</p>
<p><span class="math">1.34=(1+d)^{\text{number of slots in a year}}=(1+d)^{365 * 24 * 60 * 60 / 12}</span> <img alt=":arrow_right:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/arrow_right.png?v=12" title=":arrow_right:" width="20" />  <span class="math">d=1.27e-08 \approx 10^{-8}</span></p>
<p><strong>The expected net present value of all future EL Rewards:</strong></p>
<p>See this <a href="https://arxiv.org/abs/2404.04262">paper</a> for the proof</p>
<p><strong>Calculating:</strong> <span class="math">E[V_{\text{EA ticket}}]</span></p>
<div class="math">
E[V_{\text{EA ticket}}] =  \frac{\mu_{\mathcal{R}}}{(1+d)^m}
</div>
<p>This is because the value is recognized <span class="math">m</span> slots later so you need to discount the MEV received in <span class="math">m</span> blocks by the discount rate <span class="math">d</span>.</p>
<p><strong>Calculating <span class="math">E[V_{\text{all EA tickets}}]</span></strong></p>
<div class="math">
\begin{align*}
    E[V_{\text{all EA tickets}}] &amp;=
    \sum_{t=1}^{\infty} \frac{ E[V_{\text{EA ticket}}]}{(1+d)^t} \\
    &amp;= \sum_{t=1}^{\infty} \frac{\mu_{\mathcal{R}}}{(1+d)^{m+t}} \\
    &amp;= \frac{1}{(1+d)^{m}} \sum_{t=1}^{\infty} \frac{\mu_{\mathcal{R}}}{(1+d)^{t}} \\
    &amp;= \frac{1}{(1+d)^{m}} NPV_{\mathcal{R}} 
\end{align*}
</div>
<p><strong>Calculating</strong> <span class="math">\text{Var}(V_{\text{EA ticket}})</span></p>
<div class="math">
\text{Var}(V_{\text{EA ticket}}) =  \text{Var}\left(\mathcal{\frac{R}{(1+d)^m}}\right) =  \frac{\text{Var}(\mathcal{R})}{(1+d)^{2m}}
</div>
<p><strong>Calculating</strong> <span class="math">NPV_{\mathcal{R}}</span>, <span class="math">E[V_{\text{sET}}]</span>, <span class="math">E[V_{\text{all sETs}}]</span> and  <span class="math">\text{Var}(V_{\text{sET}})</span></p>
<p>The proofs can be found in Jonah’s “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>” paper. Remember, the paper does not make the sET vs. ET distinction.</p>
<p><strong>Calculating</strong> <span class="math">E[V_{\text{ET}}]</span>, <span class="math">E[V_{\text{all ETs}}]</span> and  <span class="math">\text{Var}(V_{\text{ET}})</span>,</p>
<p>These are simple modifications to the sET calculations using the <span class="math">m</span> slot discount.</p>
<p><strong>Calculating Graph 1:</strong></p>
<p>The probability of winning <span class="math">m</span> consecutive slots when holding <span class="math">p</span> percent of the sETs/ETs initially (without rebuying a ticket each block) is determined by the product of the probabilities of winning each individual draw:</p>
<div class="math">
\begin{align*}W &amp;= \left(\frac{pn}{n}\right) \cdot \left(\frac{pn-1}{n}\right) \cdot \left(\frac{pn-2}{n}\right) \cdots \left(\frac{pn-(m-1)}{n}\right) \\&amp;= \frac{(pn)!}{(pn-m)! n^m}\end{align*}
</div>
<p><strong>Calculating Graph 2:</strong></p>
<p>See section 4.4 in the “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>” paper.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 15:40:47 +0000</pubDate>
</item>
<item>
<title>Avoiding Accidental Liveness Faults for Based Preconfs</title>
<link>https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888</link>
<guid>https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888</guid>
<content:encoded><![CDATA[
<div> 关键词：基于预确认、意外活期性故障、保护、链条化、预验证

总结:<br />
本文讨论了在引入基于预确认（based preconfirmations）的以太坊网络中，如何解决提案者面临的意外活期性故障（liveness faults）导致的潜在损失问题。作者提出了一种利用预验证链条（preconf chaining）的方法，该机制无需修改现有协议设计，旨在防止个体提案者因偶然事件导致的活期性故障被罚。通过链条化的预验证请求，依赖关系和智能的切割条件，可以确保即使一个提案者出现问题，后续的链条也能保证预验证的履行，从而减少误罚。此外，文章还探讨了如何通过激励措施鼓励链条化行为，如共享提示和建立良好的声誉预期。总的来说，链条化预验证为提案者提供了更好的保护，增强了预验证的可靠性，促进了系统的整体稳定性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#avoiding-accidental-liveness-faults-for-based-preconfs-1" name="avoiding-accidental-liveness-faults-for-based-preconfs-1"></a>Avoiding Accidental Liveness Faults for Based Preconfs</h1>
<p><em>thanks to <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin Drake</a>, <a href="https://x.com/jon_charb" rel="noopener nofollow ugc">Jon Charbonneau</a>, <a href="https://x.com/lvdaniels" rel="noopener nofollow ugc">Ladislaus</a>, <a href="https://x.com/aimxhaisse" rel="noopener nofollow ugc">Sébastien Rannou</a>, <a href="https://x.com/lazyleger" rel="noopener nofollow ugc">sacha</a>, <a href="https://x.com/DrewVdW" rel="noopener nofollow ugc">Drew van Der Werff</a>, and Max Wilde from <a href="https://x.com/aestusrelay" rel="noopener nofollow ugc">Aestus</a> for thinking and review</em><br />
.<br />
.<br />
<em><strong>tl;dr:</strong> We solve one of the largest problems with based preconf opt-in from proposers: accidental liveness slashing. The mechanism we introduce requires no changes to existing based preconf protocol designs and has been under our noses the whole time. We use preconf chaining to protect individual proposers from being slashed for liveness failures.</em><br />
.<br />
.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-2" name="background-2"></a>Background</h2>
<p>On Ethereum today, liveness issues with block proposals are largely accepted, and penalties are minimal. When we introduce based preconfirmations, liveness issues can mean different consequences.</p>
<p>When dealing with preconfs: from the user’s perspective, liveness faults (missing a block proposal) and safety faults (proposing a block that does not fulfill preconf commitments) are the same thing. In both scenarios, a user experiences a situation where their preconfirmation is not fulfilled.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/d/9d996b95a0c2f74f54edf8f3d3b89beda26956db.png" title="liveness faults are safety faults"><img alt="liveness faults are safety faults" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/d/9d996b95a0c2f74f54edf8f3d3b89beda26956db_2_406x500.png" width="406" /></a></div><p></p>
<p>Now, from the perspective of the proposer, liveness faults and safety faults are two very different things. Liveness faults may occur from a multitude of external, accidental circumstances (like power outages, wifi downtime, reorgs, spontaneous combustion) that many proposers just aren’t prepared for. On the other hand, safety faults can only occur when some party (the proposer or some delegate) acts maliciously.</p>
<p>Additionally, attributing liveness faults is difficult. Many actors within the block supply chain may be responsible for a liveness fault occurring. The complexity involved with this attribution would be nice to avoid.</p>
<p>To make proposers feel more comfortable with putting up potentially high amounts of collateral, being slashed for accidental liveness faults should be very rare if not impossible.</p>
<h2><a class="anchor" href="https://ethresear.ch#preconf-chaining-3" name="preconf-chaining-3"></a>Preconf Chaining</h2>
<p><img alt="preconf chaining" height="500" src="https://ethresear.ch/uploads/default/original/3X/5/2/524180b5ef3a6673ab62d02d5afdc1a4d0d94fe5.png" width="500" /></p>
<h3><a class="anchor" href="https://ethresear.ch#brief-assumptions-4" name="brief-assumptions-4"></a>Brief Assumptions:</h3>
<ul>
<li>(we are talking about based preconfs here, not L1 preconfs)</li>
<li>slashing conditions are expressive</li>
<li>preconf requests include L2 block number</li>
<li>“active preconfer” refers to the current preconfer (an L1 proposer or delegate in the lookahead), “next active preconfer” refers to the entity who will be the next preconfer.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#slashing-conditions-construction-5" name="slashing-conditions-construction-5"></a>Slashing Conditions Construction:</h3>
<p>We assume a slashing conditions paradigm that is similar to the one presented in <a href="https://ethresear.ch/t/credibly-neutral-preconfirmation-collateral-the-preconfirmation-registry/19634">The Preconf Registry.</a> Specifically, that slashing conditions are “smart” and expressive enough to represent the following constructions.</p>
<p>The slashing conditions are designed so that a preconfer is slashed if:</p>
<ul>
<li>they sign a preconf request about a transaction <code>A</code> and block <code>B</code>, where <code>B</code> is a future L2 block. Also signed is a list of “dependents”, a list of other preconfers (by address or other ID).</li>
<li><code>A</code> is not fulfilled in <code>B</code>, or was not fulfilled in a block prior to <code>B</code></li>
<li>All dependents have signed the same preconf request (commitments/signatures from these are required) and have not been slashed (a challenge/cooldown period is useful here).</li>
</ul>
<p>This dependent design enables a preconfer to conditionally preconfirm a transaction, based on the choices of other preconfer.</p>
<h3><a class="anchor" href="https://ethresear.ch#preconf-flow-6" name="preconf-flow-6"></a>Preconf Flow</h3>
<ul>
<li>Alice (a based L2 user) wants an inclusion preconf for a transaction <code>A</code></li>
<li>Alice <a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812">delivers a preconf request to the active preconfer</a></li>
<li>Some entity who obtains a preconf commitment from the active preconfer (Alice, a gateway, or even the active preconfer itself) forwards Alice’s preconf request to the next active preconfer (with a dependent on the active preconfer added) and also forwards the active preconfer’s commitment.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/4/84a8b7a1158dfc8f844abfc5447b193b3d35f12e.png" title="diagram representing how any actor can send a chained preconf request to the next active preconfer"><img alt="diagram representing how any actor can send a chained preconf request to the next active preconfer" height="387" src="https://ethresear.ch/uploads/default/optimized/3X/8/4/84a8b7a1158dfc8f844abfc5447b193b3d35f12e_2_690x387.png" width="690" /></a></div><p></p>
<p><strong>Any actor with access to a preconf commitment may construct a chained preconf and forward it to the next active preconfer.</strong></p>
<p>Note that incentives for doing this vary:</p>
<ul>
<li><strong>preconf RPC:</strong> aka <a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812">The Preconfirmation Gateway</a> might chain preconfs as a public good for proposers.</li>
<li><strong>gateway:</strong> A gateway might also chain preconfs as a public good for proposers, but may also use this as a feature to attract proposers (maybe called “liveness fault protection”).</li>
<li><strong>proposers:</strong> A proposer (or node operator) might also chain preconfs themselves. Their incentive is obviously to avoid being slashed for liveness faults.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#determining-penalties-7" name="determining-penalties-7"></a>Determining Penalties</h3>
<ul>
<li>In the case where the active preconfer represents a proposer that has a liveness failure and proposes no L2 block, they wouldn’t be slashed because the preconf could still be fulfilled by the next preconfer (and the preconf request block number would match).</li>
<li>If the active preconfer proposes a block and does not fulfill the preconf request, they would be slashed for a safety fault.</li>
<li>If the active preconfer does not propose a block and the next preconfer does but does not fulfill the preconf request, the second preconfer is slashed for a safety fault.</li>
<li>If both preconfers have liveness issues, both are slashed for a safety fault. (This can be avoided by chaining beyond 2.)</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#incentivizing-chaining-8" name="incentivizing-chaining-8"></a>Incentivizing Chaining</h3>
<p>To incentivize a future active preconfer to chain preconfs, an active preconfer might share tips. Also, a reputational expectation to chain preconfs can encourage more chaining.</p>
<p>One possible way to get chaining adoption is to simply require that chaining happens. To make this practical, the future active preconfers must be able to access the preconf commitments of previous preconfers. The DA problem must be solved to make this practical, and this could be done with an external DA layer. Notably, using an external DA layer introduces dependencies on another sequencer: the DA sequencer. TBD how designs of different DA layers can work around this issue and potential censorship that might occur.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-9" name="conclusion-9"></a>Conclusion</h2>
<p>In this post, we focus on the benefits of chaining for proposers. Widespread chaining also increases the guarantees that users get for preconfirmations, making preconfs even more valuable. It’s a win-win!</p>
<p>Whether forced or opt-in, preconf chaining can protect proposers from being slashed for accidental liveness faults. This system can help proposers feel more comfortable opting into higher collateral requirements.</p>
<p><img alt="preconf chaining protects proposers from penalties for liveness faults" height="451" src="https://ethresear.ch/uploads/default/original/3X/c/c/cc0abe035c50a142437976c953764a60e774427a.png" width="553" /></p>
<h4><a class="anchor" href="https://ethresear.ch#references-10" name="references-10"></a>References</h4>
<ul>
<li><a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812#chained-preconfirmations-13">The Preconfirmation Gateway</a> by <a href="https://x.com/mteamisloading" rel="noopener nofollow ugc">mteam (me)</a> mentions chained preconfirmations as better liveness guarantees for users.</li>
<li><a href="https://ethresear.ch/t/based-preconfirmations/17353">Based preconfirmations</a> by <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin Drake</a> introduces a simple design for based preconfs.</li>
<li><a href="https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884">Pre-confirmation Liveness Slashing Penalties from the Proposer’s Perspective</a> by <a href="https://x.com/aimxhaisse" rel="noopener nofollow ugc">Sébastien Rannou</a> touches on the liveness slashing problem and explains how it decreases the economic viability of preconfs for proposers.</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 18:46:11 +0000</pubDate>
</item>
<item>
<title>Pre-confirmation Liveness Slashing Penalties from the Proposer's Perspective</title>
<link>https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884</link>
<guid>https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884</guid>
<content:encoded><![CDATA[
<div> 关键词：liveness penalty, proposer, pre-confirmations, economic viability, missed blocks

总结:
这篇文章探讨了以太坊网络中预确认（pre-confirmations）的预设罚金对提案者（proposer）经济可行性的影响。文章指出，约0.54%的区块在过去7天内被错过，为了收支平衡，提案者需要从预确认接收的额外小费（tip）至少为错过块罚金（0.0054 ETH）的一半。模型显示，随着错过率增加，预确认小费需相应提高。文章提出了几种可能的解决方案，如基于网络错过率自动调整罚金、用户自定义罚金和小费，以及只在经济上可行时才参与预确认。然而，模型缺乏激励机制，不确定是否能鼓励提案者积极参与。 <div>
<p>Current designs around pre-confirmations involve a slashing penalty on liveness, that is if a proposer who commited to pre-confirmations misses its proposal, part of its collateral is burned or redistributed to the user that sent the pre-confirmation as a payback.</p>
<p>This post explores the liveness penalty from the point of view of proposers from an economical perspective.</p>
<h2><a class="anchor" href="https://ethresear.ch#sources-of-liveness-issues-1" name="sources-of-liveness-issues-1"></a>Sources of Liveness Issues</h2>
<p>Liveness issues are complex and can come from different actors or sources, part of them are the result of the proposer’s actions or choices, part of them don’t depend on the proposer. For example:</p>
<ul>
<li>proposing a block in time but being reorg by the next proposer,</li>
<li>failure from the relayer to send the header in time,</li>
<li>failure from the relayer to propagate the signed header in time and reveal the block to the proposer.</li>
</ul>
<p>As a result, the decision on whether to opt-in or not from a proposer perspective has to take into account an <strong>inherent</strong> risk outside of its actions. Using a statistical approach on network history sounds like an easy starting point.</p>
<h2><a class="anchor" href="https://ethresear.ch#economical-minimal-viability-2" name="economical-minimal-viability-2"></a>Economical Minimal Viability</h2>
<p>In the last 7 days on the network, about <code>0.54%</code> of slots were missed, to break-even economically (that is, for an operator to not lose or win anything in the long run), assuming the liveness fault is <code>1 ETH</code>, the minimal extra-tip of a pre-confirmation would be <code>0.0054 ETH</code>.</p>
<p>To put it in perspective, the median execution reward in the last 7 days is <code>~0.048 ETH</code>, so with <code>1 ETH</code> of collateral, the pre-confirmations would need to be about <code>10%</code> of the block’s value with the current network conditions. Using <code>P(miss)</code> as the probability to miss a block, the break-even formula is:</p>
<div class="math">
(1 - (P(miss))) * tip = P(miss) * penalty
</div>
<p>And so the minimal tip:</p>
<div class="math">
tip = {(P(miss) * penalty) \over (1 - P(miss))}
</div>
<p>With <code>1 ETH</code> as a collateral, here is the model for low probabilites of missed block with <code>P(miss) &lt; 0.025</code>:</p>
<p><img alt="download" height="455" src="https://ethresear.ch/uploads/default/original/3X/e/a/ea574d8ff641f0e75064bfc788d672f031b6a3cb.png" width="626" /></p>
<p>Zooming out up with <code>P(miss) &lt; 0.5</code>:</p>
<p><img alt="download" height="455" src="https://ethresear.ch/uploads/default/original/3X/0/6/0638f8a59181327ccce1392f2bd48663d52562aa.png" width="608" /></p>
<h2><a class="anchor" href="https://ethresear.ch#opt-in-if-economically-viable-3" name="opt-in-if-economically-viable-3"></a>Opt-in if Economically Viable</h2>
<p>One idea to make it viable at scale with little effort from proposers would be for the pre-confirmation sidecar on the proposer side to opt-in to pre-confirmations only it if the tip is above what’s economically sound given the current rate of misses on the network. For example, if in the last 24 hours the average missed block proposal is <code>0.5%</code>, only commit to pre-confirmations which tip is above <code>0.005 ETH</code>.</p>
<p>This approach requires the relayer to pass the pre-confirmation tip information to the proposer to decide whether or not to commit to pre-confirmations, or the proposer to send the minimal-tip to the builder so it can provide a block that match it.</p>
<p>The advantage of this approach is if the network is struggling at scale, the risk for a proposer to miss a slot increases, and so it makes sense for proposers to opt-out of pre-confirmations until the situation resolves. Increasing the pre-confirmer bid under such conditions makes sense as more risk is taken.</p>
<p>A disavantage is that the missed block proposal rate is an approximation: it doesn’t account for totally offline validators, or for the extra-cost involved in validating the pre-confirmation on the proposer side which can take time and increase the risks of missing the slot.</p>
<h2><a class="anchor" href="https://ethresear.ch#alternatives-4" name="alternatives-4"></a>Alternatives</h2>
<h4><a class="anchor" href="https://ethresear.ch#adjusted-liveness-penalty-5" name="adjusted-liveness-penalty-5"></a>Adjusted Liveness Penalty</h4>
<p>Instead of using a minimal tip as a way to decide if it’s viable, the liveness penalty could be dynamically adjusted to what is the minimal viable condition. The tip could then be a fixed value.</p>
<h4><a class="anchor" href="https://ethresear.ch#user-defined-liveness-penalty-6" name="user-defined-liveness-penalty-6"></a>User-Defined Liveness Penalty</h4>
<p>The user sending the pre-confirmation could also decide both the liveness penalty and the tip as suggested in <a href="https://ethresear.ch/t/user-defined-penalties-ensuring-honest-preconf-behavior/19545">User-Defined Penalties: Ensuring Honest Preconf Behavior</a>, and adjust it to what the current state of the network is/what validators accept. The assumption here is maybe for some pre-confirmations the goal is to be as soon as possible on the L1, and so, reducing the liveness penalty would increase their probabilities of being pre-confirmed. On the other hand an arbitrage pre-confirmation could prefer to opt-in for a larger liveness penalty as its opportunity would be lost if the block is missed.</p>
<h2><a class="anchor" href="https://ethresear.ch#caveats-7" name="caveats-7"></a>Caveats</h2>
<p>This simple break-even model on the proposer side has no incentive, it is unclear if it will motivate proposers to opt-in.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 11:44:23 +0000</pubDate>
</item>
<item>
<title>Blob Usage Strategies by Rollups and Non-rollup Applications</title>
<link>https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874</link>
<guid>https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874</guid>
<content:encoded><![CDATA[
<div> 关键词：rollup, non-rollup, blobs, type 3 transactions, cost-effectiveness

总结:
这篇文章深入研究了以太坊升级后type 3交易中携带blob的应用策略，主要关注rollup和non-rollup应用的差异。rollup应用倾向于根据自身需求选择不同的blob使用策略，如blob数量、利用率和提交频率，以平衡可用数据费用和延迟成本。非-rollup应用通常用于上传完整内容，其blob策略与rollup不同，交易频繁且单blob利用率较高。

文章分析了blob成本效益、gas价格波动对不同应用的影响，以及blob与块重组的关系。结果表明，虽然blob作为数据可用性解决方案通常更经济，但在某些情况下，calldata可能更便宜。此外，blob gas价格的短期波动主要受non-rollup应用驱动，而非rollup应用对价格变动的响应并不明显。

总结:<br />rollup和non-rollup应用的blob策略各有特点，rollup通过调整blob数量和利用率来平衡成本；non-rollup则以高频次、低利用率的方式使用blob。文章还探讨了blob成本、gas价格和块重组之间的关系，发现blob滥用的识别对设计反滥用机制至关重要。 <div>
<p><a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc">Full Report</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tdlr-1" name="tdlr-1"></a>TDLR</h2>
<ol>
<li>The main applications using blobs are rollups, accounting for approximately 87%. Non-rollup applications mainly include <a href="https://blobscan.com/tx/0x3ff787f16ad6d65dc8d6e45a3ea95440fca2da2c0e344e76a6e509857673da01" rel="noopener nofollow ugc">Blobscriptions</a> and <a href="https://blobscan.com/tx/0x1956039b71bbc1c5de31ceafb27782eb2e8a07c9299d1d534e470bcf35f9835a" rel="noopener nofollow ugc">customized type 3 transactions</a>.</li>
<li>Rollup applications choose different blob usage strategies according to their own situations. The strategies will consider the number of blobs carried by type 3 transactions, blob utilization, and blob submission frequency to balance the costs of availability data fees and delay costs.</li>
<li>Non-rollup applications can be characterized and distinguished from rollup applications by the number of blobs carried by type 3 transactions, blob utilization, and blob submission frequency. These features help identify scenarios of blob abuse, allowing for the design of corresponding anti-abuse mechanisms.</li>
<li>In most cases, using blobs as a data availability solution is more cost-effective than calldata. However, there are a few scenarios where calldata is cheaper: blob gas price spikes and blob utilization is extremely low.</li>
<li>Short-term fluctuations in blob gas price is mainly influenced by the demand from non-rollup applications. Rollup applications have a relatively inelastic demand for blobs, so they do not significantly impact short-term fluctuations in blob gas prices.</li>
<li>Currently, rollup applications do not seem to consider blob gas price as a reference factor in their blob usage strategies.</li>
<li>The probability of blocks containing type 3 transactions being reorganized is extremely low. Additionally, carrying more blobs does not increase the probability of block reorganization. However, there is a clustering phenomenon in block height for blocks containing type 3 transactions.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>This report provides an in-depth analysis of type 3 transactions used for carrying blobs from the time of the Ethereum Decun upgrade until May 22, 2024. It focuses on blob usage strategies of rollup and non-rollup applications. The dataset, data processing programs, and visualization code for this report are <a href="https://github.com/doublespending/EIP-4844-Data-Analysis" rel="noopener nofollow ugc">open source</a>, detailed in the following “Dataset” section.</p>
<h2><a class="anchor" href="https://ethresear.ch#type-3-transactions-blobs-share-by-applications-3" name="type-3-transactions-blobs-share-by-applications-3"></a>Type 3 Transactions &amp; Blobs Share by Applications</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/1/9101b16c984217aa1e5a51a59e7c0024aa6e8e18.jpeg" title="image"><img alt="image" height="363" src="https://ethresear.ch/uploads/default/optimized/3X/9/1/9101b16c984217aa1e5a51a59e7c0024aa6e8e18_2_690x363.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#rollup-applications-4" name="rollup-applications-4"></a>Rollup Applications</h3>
<p>Observations from Figure 1 on the proportion of type 3 transactions:</p>
<ul>
<li>Base, Scroll, Linea, and Starknet are in the same tier, having the highest transaction proportions.</li>
<li>Arbitrum, Optimism, and Zksync are in the next tier, having the second-highest transaction proportions.</li>
</ul>
<p>This phenomenon seems counterintuitive as Arbitrum and Optimism have higher TPS than Scroll, Linea, and Starknet and should have a higher proportion of type 3 transactions.</p>
<p>Figure 2 shows that counterintuitive phenomenon is caused by different rollup strategies in the number of blobs carried by type 3 transactions.</p>
<p>Observations from Figure 2 on the proportion of blobs:</p>
<ul>
<li>Base stands alone, having the highest proportion of blobs.</li>
<li>Arbitrum and Optimism are in the same tier, having the second-highest proportion of blobs.</li>
<li>Scroll, Linea, Starknet, and Zksync are in the same tier, having a medium proportion of blobs.</li>
</ul>
<p>This phenomenon aligns more with intuition: blob proportions are directly related to the scale of rollup’s availability data, thus showing a positive correlation with rollup TPS.</p>
<p>The difference between the proportion of type 3 transactions (31%) and blobs (14%) for non-rollup applications indicates that non-rollup applications and rollup applications have different needs.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-rollup-applications-5" name="non-rollup-applications-5"></a>Non-Rollup Applications</h3>
<ul>
<li>Rollup applications are B2B businesses aiming to fill fine-grained Layer 2 transaction availability data, so their type 3 transactions are not limited to carrying only 1 blob.</li>
<li>Non-rollup applications are B2C businesses aiming to upload complete text, images, etc., so their type 3 transactions usually carry only 1 blob to meet their needs.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#rollup-blob-usage-strategies-6" name="rollup-blob-usage-strategies-6"></a>Rollup Blob Usage Strategies</h2>
<h3><a class="anchor" href="https://ethresear.ch#rollup-strategy-model-7" name="rollup-strategy-model-7"></a>Rollup Strategy Model</h3>
<p>This section models the rollup blob usage strategies with</p>
<ol>
<li><code>blobNumber</code>, i.e. the number of blobs carried by type 3 transactions</li>
<li><code>blobUtilization</code>, i.e. blob space utilization</li>
<li><code>blobInterval</code>, i.e. the blob submission interval</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#fee-cost-8" name="fee-cost-8"></a>Fee Cost</h4>
<p>The fee cost per transaction for rollups is expressed as:</p>
<div class="math">
\begin{equation}
feeCost = \frac{1}{k}(\frac{blobCost}{blobUtilization}+\frac{fixedCost}{blobNumber*blobUtilization})
\end{equation}
</div>
<ul>
<li><code>fixedCost</code>: the fixed cost of a type 3 transaction</li>
<li><code>blobCost</code>: the cost of a single blob</li>
<li>The larger the <code>blobUtilization</code>, the lower the amortized cost of the blob fee <span class="math">\frac{blobCost}{blobUtilization}</span> and the fixed cost <span class="math">\frac{fixedCost}{blobNumber*blobUtilization}</span>, resulting in a lower fee cost <code>feeCost</code>.</li>
<li>The larger the <code>blobNumber</code>, the lower the amortized cost of the fixed cost <span class="math">\frac{fixedCost}{blobNumber*blobUtilization}</span>, resulting in a lower fee cost <code>feeCost</code>.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#delay-cost-9" name="delay-cost-9"></a>Delay Cost</h4>
<p><strong>The delay cost per transaction for rollups is expressed as:</strong></p>
<div class="math">
\begin{equation}
delayCost = F(\frac{blobNumber*blobUtilization*k}{tps})
\end{equation}
</div>
<ul>
<li>The larger the <code>blobUtilization</code>, the larger the delay cost <code>delayCost</code>.</li>
<li>The larger the <code>blobNumber</code>, the larger the delay cost <code>delayCost</code>.</li>
<li>The larger the <code>tps</code>, the smaller the delay cost <code>delayCost</code>.</li>
</ul>
<blockquote>
<p>The derivation of the formula can be found in the <a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc">full version</a>.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#rollup-strategy-analysis-10" name="rollup-strategy-analysis-10"></a>Rollup Strategy Analysis</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced.png" title="image"><img alt="image" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced_2_690x260.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/2/32521830fd7aab2cbd7f19d504720344afb2eff7.jpeg" title="image"><img alt="image" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/3/2/32521830fd7aab2cbd7f19d504720344afb2eff7_2_574x499.jpeg" width="574" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#non-rollup-blob-strategies-11" name="non-rollup-blob-strategies-11"></a>Non-Rollup Blob Strategies</h3>
<p>Rollup applications are B2B, while non-rollup applications are B2C. Therefore, non-rollup applications differ from the rollup strategy model. For non-rollup applications:</p>
<ul>
<li>The number of blobs carried by type 3 transactions depends on the size of the content (texts/images) stored in the blobs.</li>
<li>Blob utilization depends on the size of the content (texts/images) stored in the blobs.</li>
<li>Blob submission intervals depend on the immediate needs of C-end users, with no delay costs involved.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced.png" title="image"><img alt="image" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced_2_690x260.png" width="690" /></a></div><p></p>
<ul>
<li>
<p>According to Figure 5 (<strong>Others</strong> ), 1 blob can meet the needs of most non-rollup applications.</p>
</li>
<li>
<p>According to Figure 6 (<strong>Others</strong> ), the blob utilization is concentrated between 20% and 40%, indicating that non-rollup applications generally cannot fill the blob, with the data size mainly between 25.6 kB and 51.2 kB.</p>
</li>
<li>
<p>According to Figure 7 (<strong>Others</strong> ), about 83% of blobs have a submission interval of less than 1 minute, indicating a relative high frequency of user demand for non-rollup applications.</p>
</li>
</ul>
<p>In summary, the type 3 transactions for non-rollup applications can be characterized as: <strong>high-frequency transactions carrying 1 low-utilization blob</strong> .</p>
<p>The essence of this characterization is that non-rollup applications are driven by immediate needs and are less concerned about the fee cost per data byte compared to rollup applications.</p>
<p>This characterization allows for the identification of non-rollup applications, which in turn helps design mechanisms to limit blob abuse by non-rollup applications.</p>
<h2><a class="anchor" href="https://ethresear.ch#is-using-blobs-always-more-cost-effective-than-calldata-12" name="is-using-blobs-always-more-cost-effective-than-calldata-12"></a>Is Using Blobs Always More Cost-effective than Calldata?</h2>
<p>Introducing <code>feeRatio</code> to measure the relative advantages of the two solutions:</p>
<div class="math">
\begin{equation}
feeRatio = \frac{calldataFeeCost }{blobFeeCost}
\end{equation}
</div>
<ul>
<li>When <code>feeRatio</code> ≥ 1, it indicates that using blobs as a data availability solution is not worse than calldata.</li>
<li>When <code>feeRatio</code> &lt; 1, it indicates that using blobs as a data availability solution is worse than calldata.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/5/b5e1ca6b02490795bf2e742ecb92586d1b18e685.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/5/b5e1ca6b02490795bf2e742ecb92586d1b18e685_2_472x500.jpeg" width="472" /></a></div><p></p>
<p>Figure 8 also shows a few cases where <code>feeRatio</code> &lt; 1 (red), indicating that calldata is more cost-effective than blobs:</p>
<ul>
<li>Mostly in non-Rollup applications (<strong>Others</strong>):
<ul>
<li>Non-rollup applications generally do not care about the cost differences between blobs and calldata; they care about using blobs itself, such as in Blobscriptions.</li>
</ul>
</li>
<li>A few in Metal rollup:
<ul>
<li>Rollup application Metal seems not to have considered switching between blobs and calldata in its strategy, leading to suboptimal choices in some extreme cases.</li>
<li>Extreme cases are mainly due to Metal’s low blob utilization (see Figure 6) coinciding with a spike in blob gas prices.</li>
<li>However, given that extreme scenarios are rare and maintaining two data availability solutions is costly, Metal’s suboptimal strategy in extreme cases seems acceptable.</li>
</ul>
</li>
</ul>
<blockquote>
<p>The analysis of blob and calldata solutions in this section only considers fee costs and not delay costs. Considering delay costs, calldata has an actual advantage.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#blob-gas-price-and-blob-usage-strategies-13" name="blob-gas-price-and-blob-usage-strategies-13"></a>Blob Gas Price and Blob Usage Strategies</h2>
<h3><a class="anchor" href="https://ethresear.ch#analysis-of-blob-gas-price-fluctuations-14" name="analysis-of-blob-gas-price-fluctuations-14"></a>Analysis of Blob Gas Price Fluctuations</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/8/58dd45e0e206936eb5eb2b32fc343a70322254c1.jpeg" title="image"><img alt="image" height="363" src="https://ethresear.ch/uploads/default/optimized/3X/5/8/58dd45e0e206936eb5eb2b32fc343a70322254c1_2_690x363.jpeg" width="690" /></a></div><br />
Figures 9 and 10 show that in scenarios of high blob gas prices (&gt; 10), the proportion of non-rollup applications (<strong>Others</strong>) is significantly higher than in scenarios of low blob gas prices (&lt; 10).<p></p>
<p>Therefore, it can be concluded that the surge in blob gas prices is mainly driven by the demand from non-rollup applications, rather than rollup applications. Otherwise, the proportion of rollup and non-rollup applications should remain stable.</p>
<h3><a class="anchor" href="https://ethresear.ch#how-rollups-respond-to-blob-gas-price-fluctuations-15" name="how-rollups-respond-to-blob-gas-price-fluctuations-15"></a>How Rollups Respond to Blob Gas Price Fluctuations</h3>
<p><em>Hypothesis 1: The higher the blob gas price, to reduce fee costs, applications should carry more blobs in type 3 transactions, i.e., the number of blobs should be positively correlated with blob gas prices.</em><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb34ad1ab0fcf6250662d82b007a763309889ef7.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/f/b/fb34ad1ab0fcf6250662d82b007a763309889ef7_2_505x500.jpeg" width="505" /></a></div><p></p>
<p>Figure 14 shows that the hypothesis does not hold.</p>
<p><em>Hypothesis 2: The higher the blob gas price, to reduce fee costs, applications should increase blob utilization, i.e., blob utilization should be positively correlated with blob gas prices.</em><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/521bb465406b224d50b0117150169a5991c5029c.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/521bb465406b224d50b0117150169a5991c5029c_2_498x500.jpeg" width="498" /></a></div><p></p>
<p>Figure 15 shows that the hypothesis does not hold.</p>
<p><em>Hypothesis 3: The higher the blob gas price, to reduce fee costs, applications should delay blob submissions, i.e., blob submission intervals should be positively correlated with blob gas prices.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/e/9e1dd1bbb0bad1163b9eaf7f8d61f340279bb0fd.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/e/9e1dd1bbb0bad1163b9eaf7f8d61f340279bb0fd_2_514x500.jpeg" width="514" /></a></div><p></p>
<p>Figure 16 shows that the hypothesis does not hold.</p>
<blockquote>
<p>In Figures 9 and 10, readers might notice that some rollup applications seem to respond to high blob gas prices. Scroll seems to suspend blob submissions under high blob gas prices. However, this conclusion is incorrect. The reason is that not all rollups immediately used blobs after the EIP-4844 upgrade.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#blobs-and-block-reorg-16" name="blobs-and-block-reorg-16"></a>Blobs and Block Reorg</h2>
<p>From the Decun upgrade to May 22, there were 171 type 3 transactions included in the forked blocks and 348,121 included in the canonical blocks. Therefore, the proportion of type 3 transactions being forked is approximately 0.049%. This section explores the relationship between block reorg and blob.</p>
<h3><a class="anchor" href="https://ethresear.ch#blob-number-distribution-in-the-canonical-and-forked-blocks-with-blobs-17" name="blob-number-distribution-in-the-canonical-and-forked-blocks-with-blobs-17"></a>Blob Number Distribution in the Canonical and Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bef1c025b4ae7c6990e2c7968acf12a6eccba1a2.jpeg" title="image"><img alt="image" height="403" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bef1c025b4ae7c6990e2c7968acf12a6eccba1a2_2_690x403.jpeg" width="690" /></a></div><p></p>
<p><em>Hypothesis: More blobs increase the probability of block reorganizations.</em></p>
<p>If the hypothesis holds, the following inequality should be satisfied:</p>
<div class="math">
\begin{equation}
P(reorg|blob=n)  &gt; P(reorg|blob=n-1)
\end{equation}
</div>
<p>According to <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener nofollow ugc">Bayes’ theorem</a>, inequality above is equivalent to:</p>
<div class="math">
\begin{equation}
\frac{P(blob=n|reorg)}{P(blob=n)}  &gt; \frac{P(blob=n-1|reorg)}{P(blob=n-1)}
\end{equation}
</div>
<p>We check whether the actual data satisfies inequality and obtain the following table:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/c/ec253f7881bbf00cf3b5a37a8635dfb0181309ee.png" title="image"><img alt="image" height="201" src="https://ethresear.ch/uploads/default/optimized/3X/e/c/ec253f7881bbf00cf3b5a37a8635dfb0181309ee_2_690x201.png" width="690" /></a></div><p></p>
<p>The table above shows that equation (10) does not hold for all <code>n</code>. Therefore, the hypothesis does not hold, indicating that more blobs are not significantly related to block reorganizations.</p>
<h3><a class="anchor" href="https://ethresear.ch#distribution-of-type-3-transactions-and-blobs-by-applications-in-the-canonical-and-forked-blocks-with-blobs-18" name="distribution-of-type-3-transactions-and-blobs-by-applications-in-the-canonical-and-forked-blocks-with-blobs-18"></a>Distribution of Type 3 Transactions and Blobs by Applications in the Canonical and Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/d/ddfc7f0d5d5b2a90aaf6efff87b6d7a3733c2aff.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/d/d/ddfc7f0d5d5b2a90aaf6efff87b6d7a3733c2aff_2_425x500.jpeg" width="425" /></a></div><br />
Figures 18 and 19 show that the proportion of type 3 transactions/blobs for Zksync and Scroll in forked blocks is significantly higher than in the canonical blocks.<p></p>
<p>Applications seem to have some connection with block reorganizations, possibly related to differences in blob usage strategies by applications:</p>
<ul>
<li>Zksync and Scroll are less strategic in selecting the timing of submitting type 3 transactions, targeting block heights prone to reorganization.</li>
<li>The unique characteristics of Zksync and Scroll’s type 3 transactions make the blocks containing them more likely to be reorganized.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#clustering-phenomenon-of-forked-blocks-with-blobs-19" name="clustering-phenomenon-of-forked-blocks-with-blobs-19"></a>Clustering Phenomenon of Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/8/281e3d3c49f900b77406ef467f2c32a1b08331eb.jpeg" title="image"><img alt="image" height="286" src="https://ethresear.ch/uploads/default/optimized/3X/2/8/281e3d3c49f900b77406ef467f2c32a1b08331eb_2_690x286.jpeg" width="690" /></a></div><br />
If each block has the same probability of being reorganized, the forked blocks should be evenly distributed across the block height range. However, Figure 20 shows a clustering phenomenon in block heights for forked blocks, possibly related to network conditions.<p></p>
<p>In addition, the clustering phenomenon that occurs in block reorganization seems to be somewhat related to the applications that submit blobs. For example, type 3 transactions for non rollup applications are only included in forked blocks between 19500000 and 19600000.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="64" src="https://ethresear.ch/uploads/default/original/3X/3/0/30aea33d55bd45ce96fab5bf70ecd7a3d0178f9d.png" width="64" />

      <a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc" target="_blank">0xpantarhei.substack.com</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image"><img class="thumbnail" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/f/7/f7108d3b335a7303d071fa1c0b9afa898ea3fa24_2_690x345.jpeg" width="690" /></div>

<h3><a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc" target="_blank">Blob Usage Strategies by Rollups and Non-rollup Applications</a></h3>

  <p>This report provides an in-depth analysis of type 3 transactions used for carrying blobs.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 03:39:04 +0000</pubDate>
</item>
<item>
<title>Block Building is not just knapsack!</title>
<link>https://ethresear.ch/t/block-building-is-not-just-knapsack/19871</link>
<guid>https://ethresear.ch/t/block-building-is-not-just-knapsack/19871</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、块构建、NP-hard、贪婪算法、交易冲突

总结:
本文探讨了区块链中块构建的复杂性，通过将问题与背包问题和最大独立集问题关联，揭示其NP-hard性质。研究者提出几种贪婪算法，包括经典和改进版本，以及如何考虑交易间的冲突。实验结果显示，通过结合背包约束优化的贪婪算法比现有方法能多赚约15%的费用。文章还讨论了模型对以太坊矿工的实际意义，以及未来研究方向，如更精确的序列化问题和交易效用影响的建模。 <div>
<p>Authors: <a class="mention" href="https://ethresear.ch/u/mikerah">@Mikerah</a> Afonso <a class="mention" href="https://ethresear.ch/u/sarisht">@sarisht</a></p>
<p>Shoutout to Gabearro Ventalitan Nerla Yun Qi and Surya for all the vibes and discussions!</p>
<p>This project was done as a Hackathon Project at IC3 camp last week.</p>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h2>
<p>We present a formal model or block building in blockchains. We show that block building is at least a combination of the Knapsack problem and the Maximum Independent Set problem, thus showing that block building is an NP-hard problem. Next, we provide various greedy algorithms with different tradeoffs. Then, we show simulation results to justify the algorithms and benchmarks. Our results show that tweaking the greedy solution with the results of the known knapsack constraint outperforms the currently used greedy algorithm by ~15% in terms of fee earned. Finally, we discuss how this is relevant for block builders in Ethereum in practice and directions for future research.</p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>Block building in Ethereum has evolved into a multimillion-dollar industry, particularly with the introduction of MEV-Boost. This has significantly increased the revenue earned by the builders. However, the builders’ algorithm for selecting transactions and transaction bundles needs more study. In collaboration with Flashbots, Mikerah (group lead for the project) has recently worked on a project that <a href="https://collective.flashbots.net/t/frp-10-distributed-blockbuilding-networks-via-secure-knapsack-auctions/1955" rel="noopener nofollow ugc">formalizes the model for block building as a knapsack problem</a>. This model considers each transaction’s utility (the fee offered by the transaction) and cost (the gas used by the transaction), with a budget for the maximum price that can be paid (the gas limit for the block). The practical relevance of this research is evident, as it addresses a significant limitation of the current model, where not all transactions are independent of each other.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-problem-3" name="the-problem-3"></a>The Problem</h2>
<p>Let’s delve into the heart of the matter by examining why transactions are not independent, a key challenge in block building.</p>
<h3><a class="anchor" href="https://ethresear.ch#bitcoin-blockchain-4" name="bitcoin-blockchain-4"></a>Bitcoin Blockchain</h3>
<p>The most critical problem described in the Satoshi Nakamoto blockchain paper was catching double-spending. If two transactions try to spend the same UTXO, only one of them should make it on-chain. Thus, we can see that some transactions are dependent on each other. However, that is not all; some transactions that interact with Bitcoin’s OP-Code design can also depend on each other. A classic example of this would be that in an HTLC, either a refund transaction (released by revealing a pre-image of a hash) or payment (released when the timelock on the transaction expires) can go through. If both transactions are simultaneously in the mempool, then the transactions conflict with each other.</p>
<h3><a class="anchor" href="https://ethresear.ch#ethereum-blockchain-5" name="ethereum-blockchain-5"></a>Ethereum Blockchain</h3>
<p>Ethereum inherits the double-spending transaction problem, but owing to its smart contract and gas fee design, it only partially suffers from the other type of conflict since the fee is paid based on the gas used. This causes the model to shift slightly, where the fee paid and the gas used depends on other chain transactions. Further, in the presence of searchers, some transactions are bundled such that multiple bundles contain the same transaction and thus cannot be included in the block simultaneously.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-6" name="model-6"></a>Model</h2>
<p>We first introduce the assumptions we make before describing the mathematical formulations.</p>
<h4><a class="anchor" href="https://ethresear.ch#assumptions-7" name="assumptions-7"></a>Assumptions</h4>
<ul>
<li>Dependent fees and gas are hard to model since we cannot have a boolean representation. Thus, we only consider “Conflicts” and touch upon “Dependency.” Conflicts are situations in which the transactions cannot occur together, and dependency is when one transaction requires another transaction to be executed before it is valid.</li>
<li>We further ignore the optimal ordering of transactions inside a block. Ordering transactions in a particular order can lead to higher profits due to MEV, which we ignore for the same reason as above.</li>
<li>For Ethereum, under the conditions of EIP 1559, the fee considered is the part above the base fee. Any transaction with a negative fee is ignored.</li>
</ul>
<p>Given these assumptions, we now model the binary allocation problem with constraints and dependencies as follows:<br />
Let <span class="math">T</span> be the set of transactions. A transaction in <span class="math">T</span> is denoted by <span class="math">tx_i</span>.<br />
Let <span class="math">f_i</span> denote the fee associated with a transaction <span class="math">tx_i</span>.<br />
Let <span class="math">g_i</span> denote the gas associated with a transaction <span class="math">t_i</span><br />
Let <span class="math">B</span> be the maximum block gas limit.</p>
<p>Then, we have the following optimization problem<br />
Maximise</p>
<div class="math">
\sum_{i\in n} f_ix_i 
</div>
<p>Subject to</p>
<div class="math">
\begin{align*}
 &amp;\sum_{i\in n} x_ig_i \leq B \\
 &amp; x_i+x_j \leq C_{ij}, \forall i\neq j \in n\\
 &amp; x_j - x_i \leq M_{ij}, \forall i\neq j \in n\\
 &amp; x_i \in \{0,1\}
 \end{align*}
</div>
<p>where,</p>
<ul>
<li><span class="math">C_{ij} = 1</span> if <span class="math">t_i</span> and <span class="math">t_j</span> are conflicting transactions, 2 otherwise</li>
<li><span class="math">M_{ij} = 0</span> if <span class="math">t_j</span> depends on <span class="math">t_i</span> and can only be allocated after <span class="math">t_i</span>, 1 otherwise</li>
</ul>
<p>Since, in practice, it is hard for a block builder to infer the 3rd condition (without executing all of the transactions) within a limit snapshot of the transactions within their order flow pools, we can omit the 3rd constraint to simplify the problem. If the builder comes across such a transaction, it would be considered invalid.</p>
<p>As such, we can obtain the following simplified optimization problem<br />
Maximise</p>
<div class="math">
\sum_{i\in n} f_ix_i
</div>
<p>Subject to</p>
<div class="math">
\begin{align*}
 &amp;\sum_{i\in n} x_ig_i \leq BL \\
 &amp; x_i+x_j \leq C_{ij}, \forall i\neq j \in n\\
 &amp; x_i \in \{0,1\}
 \end{align*}
</div>
<p>where,</p>
<ul>
<li><span class="math">C_{ij} = 1</span> if <span class="math">t_i</span> and <span class="math">t_j</span> are conflicting transactions, 2 otherwise</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#reductions-8" name="reductions-8"></a>Reductions</h3>
<p>Now, we present formal arguments as to why block building is an instance of the knapsack problem and the maximum independent set problem.</p>
<h4><a class="anchor" href="https://ethresear.ch#reduction-to-knapsack-9" name="reduction-to-knapsack-9"></a>Reduction to knapsack</h4>
<p>The reduction of the above problem to knapsack is easy to see. We assume no conflicts arise amongst any transactions. In that case, the problem is the same as solving a knapsack problem, with the utility as the fee paid by the transaction, space occupied as the gas used by a transaction, and finally, the block’s gas limit determines the knapsack size. Thus, the block-building problem is at least as hard as the knapsack problem.</p>
<h4><a class="anchor" href="https://ethresear.ch#reduction-to-maximum-independent-set-10" name="reduction-to-maximum-independent-set-10"></a>Reduction to Maximum Independent Set</h4>
<p>If we can solve the above instance of block building problem without any constraint that limits the size of the block in polynomials, then consider the following instance where the block gas limit is set to the sum of gas of all transactions in the mempool. This would imply enough space for all the transactions in the mempool to fit in the block. This problem is now equivalent to finding the maximum weighted independent set because we can consider all transactions as vertices, and an edge exists between two vertices if the corresponding transactions conflict. The above reduction creates the instantiation of the maximum weighted independent set problem, which is again known as NP-hard.</p>
<h2><a class="anchor" href="https://ethresear.ch#algorithms-for-approximate-result-11" name="algorithms-for-approximate-result-11"></a>Algorithms for approximate result</h2>
<p>As we mentioned above, block building is an NP-hard problem with reductions to both the knapsack problem and the maximum weighted independent set problem. Since we know that the maximum weighted independent set problem doesn’t have a C-approximation, this implies that the block-building problem also doesn’t have a C-approximation.</p>
<p>As such, we devise several greedy algorithms in order to solve the block-building problem in practice.</p>

<h3><a class="anchor" href="https://ethresear.ch#greedy-classic-gc-12" name="greedy-classic-gc-12"></a>Greedy Classic (GC)</h3>
<p>We expect today’s builders to use the first algorithm we present. It follows the most widely used knapsack greedy solution, where all objects are sorted according to the ratio of their utility to cost, and then greedily allocate space to each object until you can no longer allocate more space. Due to the added conflict constraint, the builder must check for conflict with any transaction already added to the block. Thus, the algorithm works as follows:</p>
<p>Algorithm input: <span class="math">T = \{t_i\}, F = \{f_i\}, G = \{g_i\}</span><br />
Algorithm output: An ordered block with gas used less than BL<br />
Algorithm description:</p>
<pre><code class="lang-auto">Sort T by corresponding F/G
Let B  := {}
Let BS := 0
For each t in T, f in F, g in G do:
    if t has any conflict with tx in B: continue;
    if g + BS &lt; BL: B.append(t); BS += g
return B
</code></pre>
<p>In practice, the conflict between transactions is only known if simulated sequentially. We propose two constraints on how this conflict can be modeled.</p>
<ul>
<li>Two transactions <span class="math">t_1</span> and <span class="math">t_2</span> conflict if the transactions cannot be executed together. This can happen if some address is trying to double-spend some money it has or if two searcher bundles try to extract MEV from the transaction. We call this conflict a “Real” conflict.</li>
<li>Two transactions <span class="math">t_1</span> and <span class="math">t_2</span> conflict if they interact with the same address. We call this conflict an “All” condition. These transactions do not necessarily invalidate each other. Still, we keep this as a potential conflict condition since this conflict is more straightforward to determine (constant size operation) than the other constraint (gas size operation), and thus can be helpful for builders optimizing based on the time computing is used.</li>
</ul>
<p>Note: In the solution simulation, we assume that <span class="math">p=0.95</span> of transactions in the “All” conflict are not in the “Real” conflict.</p>
<p>Based on the definition of conflicts, we present the two baseline greedy solutions, which we label CG All and CG Real.</p>
<h2><a class="anchor" href="https://ethresear.ch#knapsack-greedy-13" name="knapsack-greedy-13"></a>Knapsack Greedy</h2>
<p>The greedy solution described above is not a good approximation solution. Looking back at the knapsack problem, we get a 1/2 approximation over the optimal solution by comparing the above classic greedy with the utility of the first object that was not allocated.</p>
<p>The algorithm begins by running an instance of the greedy classic. It then finds the highest paying (highest f/g) transaction and adds it to the block. Adding this transaction would require modification of the block since some transactions in block (B) conflicted with this transaction, or the transaction could not be inserted due to insufficient space. Thus, we remove transactions that conflict with this new addition and then make enough space to add this transaction. After inserting the transaction, we repeat the greedy insertion until the block is again full. We repeat the above algorithm until we have seen each transaction at least once over the greedy solution.</p>
<p>The pseudocode for the solution is as follows:</p>
<pre><code class="lang-auto">Sort T by corresponding F/G
Let B  := {}
Let B_f:= {}
Let S  := {}
Let BS := 0
while S != T: 
    let t := t in T, not in S, with maximum f/g:
    remove any transaction from B that conflicts with t.
    remove smallest f/g txs until there is space to insert t.
    B.append(t)
    S.append(t)
    For each t in T, f in F, g in G do:
        if t has any conflict with tx in B: continue;
        if g + BS &lt; BL: B.append(t); BS += g; S.append(t)
    if sum(B.f) &gt; sum(B_f.f): B_f = B

return B_f

# B.f is the fee corresponding to each transaction in B
</code></pre>
<p>In this greedy protocol, we attempt to enforce the inclusion of a transaction every time. It is still distinct from the greedy knapsack 1/2 approximation, but it tries to replicate what was accomplished by the knapsack greedy but for all items not picked by the greedy algorithm.</p>
<p>This solution will outperform its classic greedy counterpart since it computes maximum over all solutions, one of which is the classic greedy solution. Like the classic greedy solution, we analyze this when conflicts are “Real” and “All”.</p>
<h2><a class="anchor" href="https://ethresear.ch#classic-greedy-informed-solutions-14" name="classic-greedy-informed-solutions-14"></a>Classic Greedy Informed Solutions</h2>
<p>Solving the knapsack problem is very easy compared to all known NP-Hard problems, especially the maximum independent set condition we have been imposing. Thus, we allow the builder to solve the knapsack reasonably accurately and quickly via a BLP solver. The knapsack solution gives the builder some idea about how to build the block, and then when there are conflicting transactions in the chosen block, the “later” transactions are discarded. In this solution, we run a knapsack LP solution. On the output of the LP, we sort the output based on i) f/g ratio ii) f, and finally iii) g. The way greedy works here is that the transactions are picked in the order of the metric, and whenever there is a conflict, the LP solver is recalled, but removing constraints on the already added and the conflicting transaction (<span class="math">x_i</span> is set to 1 for all that have already been chosen and <span class="math">x_i</span> is set to 0 for the conflicting transaction). This is repeated until the block is full.</p>
<pre><code class="lang-auto">Let B  := {}
Let B_c:= {nil}
Let BS := 0
Let C  := {}
while B_c != B:
    B_c = LP.solve(sum(x.f), x.g &lt;= BL, C)
    Sort B_c by "heuristic"
    for t in B_c:
        if t has any conflict with tx in B: 
            C.add(x_t = 0)
            break;
        B.append(t)
        C.add(x_t = 1)

return B


# Replace "heurestic" by f/g for standard, 
                       f for high-value 
# Sorting is in descending order 
</code></pre>
<p>We label these transactions as CGI-f/g and CGI-f. We only analyze the “All” conflicts for this since the time to run the algorithm is potentially higher than for the other Greedy Algorithms.</p>
<h2><a class="anchor" href="https://ethresear.ch#simulation-15" name="simulation-15"></a>Simulation</h2>
<p>Due to our limited time to work on the project, we tried to replicate the transaction data synthetically instead of working with real transactions. To properly simulate Ethereum mempool transactions, we choose the following dataset:</p>
<h3><a class="anchor" href="https://ethresear.ch#dataset-16" name="dataset-16"></a>Dataset</h3>
<p>We choose 2000 transactions under this distribution.</p>
<ul>
<li>80%: SMALL: g ~ N(24k, 3k)  f/g ~ N(16,4) - These low gas-consuming transactions have minimal smart contract interactions and thus use less gas. In almost all cases, the gas fees for these transactions are small since they are usually never a priority transaction.</li>
<li>18%  : LARGE1: g ~ N(200k, 20K)  f/g ~ N(16,4) - These represent transactions that have a significant contract execution; however, in this case, these are still not priority transactions, since the user is okay to wait for some time for the contract execution.</li>
<li>2%  : LARGE2: g ~ N(200k, 20K)  f/g ~ N(40,10) - These are the priority transactions. Usually, these have high gas usage since they mostly interact with, for example, DeFi contracts and want to be executed as soon as possible.</li>
</ul>
<p>We simulate the conflicts among these transactions by randomly choosing transactions such that each transaction has a <span class="math">\sigma</span> number of conflicts. While our preliminary results constitute the same <span class="math">\sigma</span> across all types of transactions, in practice, the larger transactions, especially the high-paying ones, would have a more significant number of conflicts since usually MEV extracting bundles would be constructed around them.</p>
<h3><a class="anchor" href="https://ethresear.ch#results-17" name="results-17"></a>Results</h3>
<p>We ran our simulation over 100 blocks with the mempool created as above.</p>
<p>When we consider <span class="math">\sigma=2</span> number of conflicts per transaction, we see the following results:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/5/45d6ba5351f45cbc8f51bd30a3637d3f1554c6f5.png" title="s2feeratio"><img alt="s2feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/4/5/45d6ba5351f45cbc8f51bd30a3637d3f1554c6f5_2_668x499.png" width="668" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/4/1430b955e746ba6faf056ac169b049c0e3dded9a.png" title="s2wastedgas"><img alt="s2wastedgas" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/1/4/1430b955e746ba6faf056ac169b049c0e3dded9a_2_668x499.png" width="668" /></a></div><p></p>
<p>Increasing the number of conflicts each transaction had increases the problem’s difficulty. Therefore, the various greedy algorithms have a larger separation in performance:</p>
<p>For <span class="math">\sigma = 10</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/e/ae043667cfb292234612d06e14e402d2cc86b268.png" title="s10feeratio"><img alt="s10feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/a/e/ae043667cfb292234612d06e14e402d2cc86b268_2_668x499.png" width="668" /></a></div><p></p>
<p>For <span class="math">\sigma = 20</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/9/79e0d8ad31f56fcb617c858775285e5e6b5b28fb.png" title="s20feeratio"><img alt="s20feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/7/9/79e0d8ad31f56fcb617c858775285e5e6b5b28fb_2_668x499.png" width="668" /></a></div><p></p>
<p>For <span class="math">\sigma = 40</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/3/e333c84dc6daa57f54481113545d081b8bb2af91.png" title="s40feeratio"><img alt="s40feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/e/3/e333c84dc6daa57f54481113545d081b8bb2af91_2_668x499.png" width="668" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#future-research-direction-18" name="future-research-direction-18"></a>Future Research Direction</h2>
<p>Based on our results, solving the block-building problem is an NP-Hard problem, and as long as conflicts exist amongst the transactions, it remains a complex problem.</p>
<p>However, this does not mean that all hope is lost. The block-building problem may have more potential than the Maximum Independent Set problem. Combining the space of Knapsack and Maximum Independent Set gives us a smaller search space to find a satisfactory approximate solution for the issue at hand.</p>
<p>Further, for Ethereum bundles from searchers, if <span class="math">tx_i</span> and <span class="math">tx_j</span> conflict, as well as <span class="math">tx_j</span> and <span class="math">tx_k</span> conflict, then there is a high likelihood that <span class="math">tx_i</span> and <span class="math">tx_k</span> also conflict. This eases the constraints on the solution since, amongst an all-2-all graph of transactions, for MIS, you only need to pick the transaction with the highest utility (also satisfying knapsack).</p>
<p>Another thing to note is that our algorithms can inform how block builders construct blocks in practice. Notably, the Classical Greedy Informed algorithm, in which we sort the transactions by highest fee, is closest to the optimal solution.</p>
<p>That being said, the most exciting extension to this research would be modeling the block-building problem as a job sequencing problem instead and somehow estimating how utility (fee+MEV) from one transaction affects the utility of other transactions sequenced after the first transaction.</p>
<p>On that note, we invite potential collaborators to explore new ideas for building blocks that maximize the builders’ utility.</p>
            <p><small>7 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/block-building-is-not-just-knapsack/19871">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 17:35:36 +0000</pubDate>
</item>
<item>
<title>Fork-Choice enforced Inclusion Lists (FOCIL): A simple committee-based inclusion list proposal</title>
<link>https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870</link>
<guid>https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870</guid>
<content:encoded><![CDATA[
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/3/639a5b7de796701a13a5759e8f5a1fe393f067f3.jpeg" title="DALL·E 2024-06-05 14.58.08 - A highly realistic illustration of a rock with the Ethereum symbol fossilized into it, set in a cave. The rock should appear weathered and ancient, wi"><img alt="DALL·E 2024-06-05 14.58.08 - A highly realistic illustration of a rock with the Ethereum symbol fossilized into it, set in a cave. The rock should appear weathered and ancient, wi" height="394" src="https://ethresear.ch/uploads/default/optimized/3X/6/3/639a5b7de796701a13a5759e8f5a1fe393f067f3_2_690x394.jpeg" width="690" /></a></div><br />
<em>^focil =&gt; fossil =&gt; protocol ossification</em><p></p>
<p><em>by <a href="https://ethresear.ch/u/soispoke/summary">Thomas</a>, <a href="https://ethresear.ch/u/fradamt/summary">Barnabé</a>, <a href="https://ethresear.ch/u/fradamt/summary">Francesco</a> and <a href="https://ethresear.ch/u/julian/summary">Julian</a></em> - June 19th, 2024</p>
<p><em>This design came together during a small, week long, in-person gathering in Berlin with RIG and friends to discuss censorship resistance, issuance, and Attester-Proposer-Builder-Consensus-Execution-[insert here] Separation.</em></p>
<p><em>Thanks to Luca, Terence, Toni, Ansgar, Alex, Caspar and Anders for discussions, feedback and comments on this proposal.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a><strong>tldr</strong></h1>
<p>In this post, we introduce Fork-Choice enforced Inclusion Lists (FOCIL), a simple committee-based IL design.</p>
<p>FOCIL is built in three simple steps:</p>
<ol>
<li>Each slot, a set of validators is selected to become <strong>IL committee members.</strong> Each member gossips one <em>local inclusion list</em> according to their subjective view of the mempool.</li>
<li><strong>The block proposer</strong> collects and aggregates available local inclusion lists into a concise <em>aggregate</em>, which is included in its block.</li>
<li><strong>The attesters</strong> evaluate the quality of the <em>aggregate</em> given their own view of the gossiped local lists to ensure the block proposer accurately reports the available local lists.</li>
</ol>
<p>This design ensures a robust and reliable mechanism to uphold Ethereum’s censorship resistance and <a href="https://ethresear.ch/t/uncrowdable-inclusion-lists-the-tension-between-chain-neutrality-preconfirmations-and-proposer-commitments/19372">chain neutrality</a> properties, by guaranteeing timely transaction inclusion.</p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h1>
<p>In an effort to shield the Ethereum validator set from centralizing forces, the right to build blocks has been auctioned off to specialized entities known as builders. Over the past year, this has resulted in a few sophisticated builders dominating the network’s block production. Economies of scale have further entrenched their position, making it increasingly difficult for new entrants to gain significant market share. A direct consequence of oligopolistic block production is a deterioration of the network’s (weak) censorship resistance properties. Today, <a href="https://censorship.pics/" rel="noopener nofollow ugc">two of the top three builders</a> are actively filtering out transactions interacting with sanctioned addresses from their blocks. In contrast, 90% of the <a href="https://www.ethernodes.org/countries" rel="noopener nofollow ugc">more decentralized and heterogeneous validator set</a> is not engaging in censorship.</p>
<p>This has driven <a href="https://github.com/michaelneuder/mev-bibliography?tab=readme-ov-file#censorship-resistance" rel="noopener nofollow ugc">research</a> toward ways that allow validators to impose constraints on builders by force-including transactions in their blocks. These efforts recently culminated in the first practical implementation of forward <span class="math">\text{ILs}</span> (<span class="math">\text{fILs}</span>) being considered for inclusion in the upcoming Pectra fork (see <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">design</a>, <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP</a>, and <a href="https://notes.ethereum.org/@mikeneuder/il-spec-overview" rel="noopener nofollow ugc">specs</a> <a href="https://gist.github.com/michaelneuder/ba32e608c75d48719a7ecba29ec3d64b" rel="noopener nofollow ugc">here</a>). However, some concerns were raised about the specific mechanism proposed in <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a>, leading to its rejection.</p>
<p>Here, we introduce FOCIL, a simple committee-based design improving upon previous IL mechanisms (<a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">Forward ILs</a>, <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a>) or co-created blocks (<a href="https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777">CBP</a>) and addressing issues related to <a href="https://ethresear.ch/t/fun-and-games-with-inclusion-lists/16557">bribing/extortion attacks</a>, IL equivocation, <a href="https://ethereum.org/en/roadmap/account-abstraction/" rel="noopener nofollow ugc">account abstraction</a> (AA) and incentive incompatibilities. Note also Vitalik’s recent proposal “<a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">One-bit-per-attester inclusion lists</a>”, where the committee chosen to build the list is essentially the whole set of attesters.</p>
<h1><a class="anchor" href="https://ethresear.ch#design-3" name="design-3"></a><strong>Design</strong></h1>
<p>In this section, we introduce the core properties of the FOCIL mechanism (see <strong>Figure 1.</strong>).</p>
<h2><a class="anchor" href="https://ethresear.ch#high-level-overview-4" name="high-level-overview-4"></a><strong>High-level overview</strong></h2>
<p>Each slot, a set of validators is randomly selected to become part of an inclusion list (<span class="math">\text{IL}</span>) committee. <span class="math">\text{IL}</span> committee members are responsible for creating local inclusion lists (<span class="math">\text{IL}_\text{local}</span>) of transactions pending in the public mempool. Local <span class="math">\text{ILs}</span> are then broadcast over the global topic, and the block producer must include a canonical aggregate (<span class="math">\text{IL}_\text{agg}</span>) of transactions from the collected local <span class="math">\text{ILs}</span> in its block <span class="math">B</span>. The quality of <span class="math">\text{IL}_\text{agg}</span> is checked by attesters, and conditions the validity of block <span class="math">B</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bedfe43a4319b8ef24f99db6089793aeda7dc3fb.png" title="Screenshot 2024-06-04 at 15.58.51"><img alt="Screenshot 2024-06-04 at 15.58.51" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bedfe43a4319b8ef24f99db6089793aeda7dc3fb_2_690x375.png" width="690" /></a></div><p></p>
<blockquote>
<p><strong>Figure 1.</strong> Diagram illustrating the FOCIL mechanism.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#mechanism-5" name="mechanism-5"></a><strong>Mechanism</strong></h2>
<ul>
<li><strong>Validator Selection and Local Inclusion Lists</strong>
<ul>
<li>A set of validators is selected from the beacon committee to become <span class="math">\text{IL}</span> committee members for slot <span class="math">n</span>. This set is denoted as <span class="math">\text{IL}_\text{committee}(n) = \{ 1, \dots, m \}</span>, where <span class="math">m</span> is the number of <span class="math">\text{IL}</span> committee members.</li>
<li>Each <span class="math">\text{IL}</span> committee member <span class="math">i \in \text{IL}_\text{committee}(n)</span> releases a local <span class="math">\text{IL}</span>, resulting in a set of local <span class="math">\text{ILs}</span> for slot <span class="math">n</span>, defined as <span class="math">\text{IL}_\text{local}(n) = \{ \text{IL}_1, \dots, \text{IL}_m \}</span>.</li>
<li>Each local <span class="math">\text{IL}_i</span> contains transactions: <span class="math">\text{IL}_i = \{ \text{tx}^1_i, \dots, \text{tx}^{j_i}_i \}</span>, where each <span class="math">\text{tx}</span> is represented as  <span class="math">\text{tx} = (\text{tx}[\text{From}], \text{tx}[\text{Gas Limit}])</span>, and  <span class="math">j_i</span> indicates the number of transactions in <span class="math">\text{IL}_i</span>. The <code>From</code> field represents the sender’s address, and the <code>Gas Limit</code> field represents the maximum gas consumed by a transaction. This is used to check whether a transaction can be included in a block given the <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">conditional</a> IL property.</li>
</ul>
</li>
<li><strong>Block Producer’s Role</strong>
<ul>
<li>The block producer of slot <span class="math">n</span>, denoted <span class="math">\text{BP}(n)</span>, must include an <span class="math">\text{IL}</span> aggregate denoted <span class="math">\text{IL}_\text{agg}</span> and a payload in their block  <span class="math">B = (B[\text{IL}_\text{agg}], B[\text{payload}])</span>.</li>
<li><span class="math">\text{IL}_\text{agg}</span> consists of transactions: <span class="math">\text{IL}_\text{agg} = \{ \text{tx}^1_\text{agg}, \dots, \text{tx}^{t_\text{agg}}_\text{agg} \}</span> where each transaction <span class="math">\text{tx}_\text{agg}</span> is defined as <span class="math">(\text{tx}_\text{agg}[\text{tx}], \text{tx}_\text{agg}[\text{bitlist}])</span>, and the <span class="math">\text{payload}</span> must include transactions present in the <span class="math">\text{IL}_\text{agg}</span>.</li>
<li>The bitlist <span class="math">\text{tx}_\text{agg}[\text{bitlist}] \in \{0, 1\}^m</span> indicates which local $\text{IL}$s included a given transaction.</li>
<li>The function <span class="math">\text{Agg}</span> takes the set of available local ILs <span class="math">\text{IL}_\text{local}(n)</span> and outputs a “canonical” aggregate. The proposer aggregate <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> is included in block <span class="math">B</span>, and each attester evaluates it quality by comparing it against its own <span class="math">\text{IL}_\text{agg}^\text{attester}</span>, using the function <span class="math">\text{Eval}(\text{IL}_\text{agg}^\text{attester}, \text{IL}_\text{agg}^\text{proposer}, Δ) \in \{ \text{True}, \text{False} \}</span>.</li>
</ul>
</li>
<li><strong>Attesters’ Role</strong>
<ul>
<li>Attesters for slot <span class="math">n</span> receive the block <span class="math">B</span> and apply a function <span class="math">\text{Valid}(B)</span> to determine the block validity.</li>
<li><span class="math">\text{Valid}</span> encodes the block validity according to the result of <span class="math">\text{Eval}</span>, as well as core IL properties such as <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">conditional vs. unconditional</a>.</li>
<li>Here are some scenarios to illustrate <span class="math">\text{IL}</span>-dependent validity conditions:
<ul>
<li>If local <span class="math">\text{ILs}</span> are made available before deadline <span class="math">d</span>, but the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is considered invalid.</li>
<li>If no local <span class="math">\text{ILs}</span> are made available before deadline <span class="math">d</span>, and the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is considered valid.</li>
<li>If block <span class="math">B</span> is full, local $\text{IL}$s were available before <span class="math">d</span>, and the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is still considered valid.</li>
<li>If <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> doesn’t overlap with most of attesters’ <span class="math">\text{IL}_\text{agg}^\text{attester}</span> according to <span class="math">\text{Eval}</span>, block <span class="math">B</span> is considered invalid.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>The core FOCIL mechanism could be defined as:</strong></p>
<div class="math">
\mathcal{M}_\text{FOCIL}= (\text{Agg}, \text{Eval}, \text{Valid})
</div>
<h2><a class="anchor" href="https://ethresear.ch#timeline-6" name="timeline-6"></a>Timeline</h2>
<p>The specific timing is given here as an example, but more research is required to figure out which numbers make sense.</p>
<ul>
<li><strong>Slot</strong> <span class="math">n-1</span><strong>,</strong> <span class="math">t = 6</span><strong>:</strong> The <span class="math">\text{IL}</span> committee releases their local <span class="math">\text{ILs}</span>, knowing the contents of block <span class="math">n-1</span>.</li>
<li><strong>Slot</strong> <span class="math">n-1</span><strong>,</strong> <span class="math">t=9</span><strong>:</strong> There is a local <span class="math">\text{IL}</span> freeze deadline <span class="math">d</span> after which everyone locks their view of the observed local <span class="math">\text{ILs}</span>. The proposer broadcast the <span class="math">\text{IL}_\text{agg}</span> over the global topic.</li>
<li><strong>Slot</strong> <span class="math">n</span><strong>,</strong> <span class="math">t=0</span><strong>:</strong> The block producer of slot <span class="math">n</span> releases their block <span class="math">B</span> which contains both the payload and aggregated <span class="math">\text{IL}_\text{agg}</span>.</li>
<li><strong>Slot</strong> <span class="math">n</span><strong>,</strong> <span class="math">t=4</span><strong>:</strong> The attesters of slot <span class="math">n</span> vote on block <span class="math">B</span>, deciding whether <span class="math">\text{IL}_\text{agg}</span> is “good enough” by comparing the result of computing the <span class="math">\text{Agg}</span> function over their local view of available local <span class="math">\text{ILs}</span> (applying <span class="math">\text{Eval}</span>) and checking if block <span class="math">B</span> is <span class="math">\text{Valid}</span>.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#aggregation-evaluation-and-validation-functions-7" name="aggregation-evaluation-and-validation-functions-7"></a><strong>Aggregation, Evaluation and Validation Functions</strong></h2>
<p>As mentioned in the mechanism section, FOCIL relies on three core functions. Each of these needs to be specified to ensure the mechanism fulfils its purpose.</p>
<ul>
<li>
<p><strong>The <span class="math">\text{Agg}</span> function</strong> is probably the most straightforward to define: Transactions from all collected local <span class="math">\text{ILs}</span> should be deterministically aggregated and deduplicated to construct <span class="math">\text{IL}_\text{agg}</span>. We let:</p>
<ul>
<li><span class="math">\text{IL}_\text{local} = \{\text{IL}_1, \text{IL}_2, \ldots, \text{IL}_m\}</span> be the set of local inclusion lists collected from committee members <span class="math">m</span>.</li>
<li>Each <span class="math">\text{IL}_i = \{\text{tx}_i^1, \text{tx}_i^2, \ldots, \text{tx}_i^{t_i}\}</span><br />
be the transactions in the local inclusion list of the <span class="math">i</span>-th committee member.</li>
<li>Each transaction <span class="math">\text{tx}</span> be defined by <span class="math">(\text{hash}, \text{sender}, \text{nonce})</span></li>
</ul>
<p><span class="math">\text{Agg}(\text{IL}_\text{local})</span>  can be thus defined as:</p>
<div class="math">
\text{Agg}(\text{IL}_\text{local}) = {\text{tx} | \text{tx} \in \bigcup_{i \in m} \text{tx}_{i} }
</div>
</li>
<li>
<p><strong>The <span class="math">\text{Eval}</span> function</strong> is used by each slot <span class="math">n</span> attester to assess the quality of the <span class="math">\text{IL}_\text{agg}</span> included in block <span class="math">B</span>. Each attester calculates the <span class="math">\text{Agg}</span> function over all local <span class="math">\text{ILs}</span> they have observed in their view and then compares their generated <span class="math">\text{IL}_\text{agg}^\text{attester}</span> to the one included by the proposer <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>. The <strong><span class="math">\text{Eval}</span></strong> function can then be defined so that the proposer’s <span class="math">IL_{\text{agg}}^{\text{proposer}}</span> is valid if it includes a sufficient proportion of transactions observed by the attesters, as defined by the parameter <span class="math">Δ</span>:</p>
<div class="math">
\text{Eval}(IL_{\text{agg}}^{\text{attester}}, IL_{\text{agg}}^{\text{proposer}}, \Delta) = 
\begin{cases} 
\text{True} &amp; \text{if } \frac{|IL_{\text{agg}}^{\text{attester}} \cap IL_{\text{agg}}^{\text{proposer}}|}{|IL_{\text{agg}}^{\text{attester}}|} \geq \Delta \\
\text{False} &amp; \text{otherwise}
\end{cases}
</div>
<p><em>Note that the <span class="math">\text{Eval}</span> function, and especially its parameter <span class="math">Δ</span>, will determine the trade-off between <strong>(1) the quality</strong> of the <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> and the agency we are willing to give to proposers, and <strong>(2)</strong> <strong>liveness</strong>, as we might see an increase in missed slots if the criteria are set too strictly.</em></p>
</li>
<li>
<p><strong>The <span class="math">\text{Valid}</span> function</strong> encodes whether the  <span class="math">\text{IL}_\text{agg}</span> conforms to pre-defined core <span class="math">\text{IL}</span> properties, such as:</p>
<ul>
<li><strong>Conditional vs. Unconditional</strong>: Should the proposer include as many <span class="math">\text{IL}</span> transactions in the block as possible as long as there is space left, or is there dedicated block space reserved for <span class="math">\text{IL}</span> transactions?</li>
<li><strong>Where-in-block</strong>: Where should <span class="math">\text{IL}</span> transactions be included in the block? Should they be placed anywhere, at the top of the block, or at the end of the block?</li>
<li><strong>Expiry</strong>: How long do transactions remain in the <span class="math">\text{IL}</span> once they have been included? What happens if a slot is skipped?</li>
</ul>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#more-rules-8" name="more-rules-8"></a><strong>More rules</strong></h2>
<p>In the following section, we introduce other rules that could be added to the core mechanism to specify:</p>
<ul>
<li>How users should pay for having their transactions included (<span class="math">\text{Payment}</span>)</li>
<li>How rewards can be distributed across FOCIL participants (<span class="math">\text{Reward}</span>)</li>
<li>How local <span class="math">\text{ILs}</span> are constructed (<strong><span class="math">\text{Inclusion}</span></strong>)</li>
<li>Interactions between <span class="math">\text{IL}</span> and payload transactions (<span class="math">\text{Priority}</span>).</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#user-bidding-textpayment-and-textreward-rules-9" name="user-bidding-textpayment-and-textreward-rules-9"></a><strong>User Bidding,</strong> <span class="math">\text{Payment}</span> <strong>and</strong> <span class="math">\text{Reward}</span> <strong>rules</strong></h3>
<ul>
<li>Users place bids based on the value they assign to having their transactions included in block <span class="math">B</span>. They need to take into consideration the FOCIL mechanism <span class="math">\mathcal{M}_\text{FOCIL}</span>, but also how the <a href="https://eips.ethereum.org/EIPS/eip-1559" rel="noopener nofollow ugc">EIP-1559</a> mechanism works to set their base fees, denoted <span class="math">\mathcal{M}_\text{1559}</span>. For instance, a user <span class="math">t</span> makes a bid <span class="math">b^t(v^t, \mathcal{M}_\text{FOCIL},\mathcal{M}_\text{1559}) = (\delta^t, f^t)</span>, where <span class="math">\delta^t</span> is the maximum priority fee and <span class="math">f^t</span> is the maximum total fee (i.e., base fee <span class="math">r</span> + priority fee <span class="math">\delta^t</span>).</li>
<li>The vector of bids from all users is denoted as <span class="math">\mathbf{b} = (b^1, b^2, \dots, b^T)</span>, where each <span class="math">b^t</span> represents the bid from user <span class="math">t</span>.</li>
<li>The <span class="math">\text{Payment}</span> rule <span class="math">p(\mathbf{b}) = (p_0(\mathbf{b}), p_1(\mathbf{b}), \dots, p_t(\mathbf{b}), \dots, p_m(\mathbf{b}))</span> ensures that users pay no more than their priority fee <span class="math">\hat{\delta}^t = \min(\delta^t, f^t - r)</span>. Here, <span class="math">p_0(\mathbf{b}</span>) represents the payment to the block producer, and <span class="math">p_t(\mathbf{b}</span>) represents the payment made by user <span class="math">t</span> to all other <span class="math">\text{IL}</span> committee members, where the set of users has size <span class="math">m</span> and the block producer is indexed by 0.</li>
</ul>
<p>The <span class="math">\text{Payment}</span> rule defined above is meant to give a general view of how the value paid by users’ transactions can be redistributed across FOCIL participants (e.g., <span class="math">\text{IL}</span> committee members, block producer) to incentivize behavior that is considered good for the network, in this case preserving its censorship-resistant properties. Incentivizing <span class="math">\text{IL}</span> committee members for including transactions strengthens the robustness of the mechanism by increasing the <a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">cost of censorship</a>, or the amount a censoring party would have to pay for <span class="math">\text{IL}</span> committee members to exclude transactions from their local <span class="math">\text{ILs}</span>. Delving into the specifics of how the builder and <span class="math">\text{IL}</span> committee members should be rewarded is beyond the scope of this post as distributing rewards in an incentive-compatible way, especially during congestion, gets quite complex.</p>
<p>However, here are three high-level options to consider:</p>
<ul>
<li><strong>Option 1</strong>: All transaction priority fees go to the builder, and <span class="math">\text{IL}</span> committee members are just not incentivized to include transactions in their local <span class="math">\text{ILs}</span>. This simple option doesn’t require any changes to the existing fee market, but entirely relies on altruism from <span class="math">\text{IL}</span> committee members. We could even consider an opt-in version of FOCIL, where validators can choose to be part of a list that may be elected to become <span class="math">\text{IL}</span> committee members and participate in building <span class="math">\text{ILs}</span> altruistically. However, it wouldn’t increase the cost of censorship nor would it make it very appealing for validators to participate in the mechanism. This could also lead to out-of-band payments from users wanted to have their transactions included in local <span class="math">\text{ILs}</span>.</li>
<li><strong>Option 2</strong>: Priority fees from transactions included in the block are given to the <span class="math">\text{IL}</span> committee members. To distribute rewards among members, we could implement a weighted incentive system by defining a <span class="math">\text{Reward}</span> rule to calculate and distribute rewards for each member, considering the quantity (i.e., count) and uniqueness of transactions included in their local lists (see Appendix 1 of the <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS post</a> for more details). If transactions are not part of the <span class="math">\text{IL}_\text{agg}</span>, priority fees go to the builder. However, this approach could be problematic during congestion periods with the conditional <span class="math">\text{IL}</span> property, as builders might be incentivized to fill the block with transactions that are not in the <span class="math">\text{IL}_\text{agg}</span>, even if <span class="math">\text{IL}</span> transactions have higher priority fees. To address this, we might need to design a mechanism that redirects priority fees to the builder during congestion. However, the practical implementation and potential secondary effects need further investigation.</li>
<li><strong>Option 3</strong>: A third option is to introduce a new, separate inclusion fee that always go to IL committee members while priority fees always go to the builder. This would likely address the concerns of <strong>Option 2</strong> related to congestion but would introduce a whole other variable that users need to set. A useful distinction between Option 2 and Option 3 is whether the complexity is pushed upon the IL committee members or the end users.</li>
</ul>
<p>Another interesting question to explore is the impact of fee distribution across <span class="math">\text{IL}</span> committee members on mechanisms like <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">MEV-burn</a>. <strong>Options 2</strong> and <strong>3</strong> would effectively “reduce the burn” and produce a similar effect as <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV-smoothing</a>, but on a smaller scale limited to the size of the <span class="math">\text{IL}</span> committee (h/t Anders).</p>
<h3><a class="anchor" href="https://ethresear.ch#textinclusion-rule-10" name="textinclusion-rule-10"></a><span class="math">\text{Inclusion}</span> <strong>Rule</strong></h3>
<p>The <span class="math">\text{Inclusion}</span> rule determines the criteria according to which <span class="math">\text{IL}</span> committee members should build their local <span class="math">\text{ILs}</span>. In FOCIL, we define it with the premise that IL committee members will try to maximize their rewards. Assuming <strong>Option 2</strong> for the <span class="math">\text{Payment}</span> rule, the <span class="math">\text{Inclusion}</span> rule could be to include all transactions seen in the public mempool, ordered by priority fees.</p>
<h3><a class="anchor" href="https://ethresear.ch#textpriority-rule-11" name="textpriority-rule-11"></a><span class="math">\text{Priority}</span> <strong>Rule</strong></h3>
<p>We assume the block will be made of two components: a payload and an  <span class="math">\text{IL}_\text{agg}</span> included by the proposer to impose constraints on transactions that need to be included in the builder’s payload. Imposing constraints to the block payload via the  <span class="math">\text{IL}_\text{agg}</span> thus requires a priority rule to determine what happens during congestion. Generally, the priority rule in FOCIL states that transactions in the  <span class="math">\text{IL}_\text{agg}</span> might be excluded if the block can be filled with the builder’s payload transactions. In other words, the block will still be valid even if some transactions in the <span class="math">\text{IL}_\text{agg}</span> are not included, as long as the block is completely full (i.e., the <code>30 M</code> gas limit is reached).</p>
<p><em>Note: Rules are not set in stone and should be interpreted as candidates for FOCIL. Rules also don’t necessarily have to be made explicit. For instance, we can define the <span class="math">\text{Reward}</span> such that the dominant strategy of the <span class="math">\text{IL}</span> committee is to adhere to the <span class="math">\text{Inclusion}</span> rule without any kind of enforcement by the protocol.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#improvements-and-mitigations-12" name="improvements-and-mitigations-12"></a>Improvements and Mitigations</h2>
<p>In this section, we discuss improvements over previous  <span class="math">\text{IL}</span> proposals, focusing on simplification and addressing specific implementation concerns.</p>
<h3><a class="anchor" href="https://ethresear.ch#commitment-attacks-13" name="commitment-attacks-13"></a><strong>Commitment attacks</strong></h3>
<p>One of the main differences between FOCIL and the forward IL (<span class="math">\text{fIL}</span>) design proposed in <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> is that FOCIL relies on a committee of multiple validators, rather than a single proposer, to construct and broadcast the <span class="math">\text{IL}</span>. This approach imposes stricter constraints on creating a “good” aggregate list and significantly reduces the surface for bribery attacks. Instead of targeting a single party to influence the exclusion of transactions from the <span class="math">\text{IL}</span>, attackers would now need to bribe an entire <span class="math">\text{IL}</span> committee (e.g., <code>256</code> members), substantially increasing the cost of such attacks. Previous designs (e.g., <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a> and <a href="https://ethresear.ch/t/anonymous-inclusion-lists-anon-ils/19627">anon-IL</a>), also involved multiple parties in building inclusion lists but still relied on an aggregator to collect, aggregate, and deduplicate local <span class="math">\text{ILs}</span>. In FOCIL, the entire set of attesters now participates in enforcing and ensuring the quality of the <span class="math">\text{IL}</span> included in the proposer’s block, thus removing single-party dependency other than the proposer. Additionally, it is worth noting that a censoring proposer would have to forego all consensus and execution layer rewards and cause a missed slot to avoid including transactions in the <span class="math">\text{IL}</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#splitting-attacks-and-il-equivocation-14" name="splitting-attacks-and-il-equivocation-14"></a><strong>Splitting attacks and IL equivocation</strong></h3>
<p>Another concern with <span class="math">\text{fILs}</span> focused on possible “splitting” attacks using <span class="math">\text{ILs}</span>. <a href="https://eprint.iacr.org/2021/1413.pdf" rel="noopener nofollow ugc">Splitting attacks</a> like timed release or “equivocation” occur when malicious participants attempt to divide the honest view of the network to stall consensus. On Ethereum, a validator equivocating by contradicting something it previously advertised to the network is a <a href="https://eth2book.info/capella/part2/incentives/slashing/" rel="noopener nofollow ugc">slashable offense</a>. If there is evidence of the offence being included in a beacon chain block, the malicious validator gets ejected from the validator set. Quick reminder that in the <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> design, the proposer for slot <span class="math">n-1</span> is responsible for making the <span class="math">\text{IL}</span> to constrain proposer <span class="math">n</span>, and can broadcast multiple <span class="math">\text{ILs}</span> (check out the <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">No-free lunch</a> post to see why, and how it relates to solving the free data availability problem). This means a malicious proposer could split the honest view of the network through <span class="math">\text{IL}</span> equivocation without being slashed. However, this is not a concern with FOCIL, since <span class="math">\text{IL}_\text{agg}</span> has to be part of proposer $n$’s block. An <span class="math">\text{IL}</span> equivocation would thus be equivalent to a block equivocation, which is a known, slashable offense from the protocol’s perspective.</p>
<h3><a class="anchor" href="https://ethresear.ch#incentives-incompatibilities-15" name="incentives-incompatibilities-15"></a>Incentives incompatibilities</h3>
<p>Previous <span class="math">\text{fILs}</span> proposals did not consider incentivizing the <span class="math">\text{IL}</span> proposer(s) for including “good” transactions. Relying on altruistic behavior might be fine, but there is always the risk that only very few validators will choose to participate in the mechanism if there is no incentive to gain. There is a strong argument to be made that the adoption of any <span class="math">\text{IL}</span> mechanism might be very low if validators risk being flagged as either non-censoring or censoring entities by revealing their preferences (see the <a href="https://ethresear.ch/t/anonymous-inclusion-lists-anon-ils/19627">Anonymous Inclusion Lists post</a>), and if they are not rewarded for contributing to preserving the network’s censorship resistance properties. In FOCIL, we consider mechanisms to distribute rewards across <span class="math">\text{IL}</span> committee members and mention two options (<strong>Option 2</strong> and Option 3 in the <span class="math">\text{Payment}</span> rule section) for sharing transaction fees based on the quantity (i.e., count) and uniqueness of transactions included in their local lists. We hope to continue working in this direction and to find incentive-compatible ways to increase the costs of censorship.</p>
<h3><a class="anchor" href="https://ethresear.ch#same-slot-censorship-resistance-16" name="same-slot-censorship-resistance-16"></a>Same-slot censorship resistance</h3>
<p>By having FOCIL run in parallel with block building during slot  <span class="math">n-1</span>, we can impose constraints on the block by including transactions submitted during the same slot in local <span class="math">\text{ILs}</span>. This is a strict improvement over <span class="math">\text{fILs}</span> designs, where the forward property imposes a 1-slot delay on <span class="math">\text{IL}</span> transactions. This property is particularly useful for time-sensitive transactions that might be censored for MEV reasons (see <a href="https://cdn.prod.website-files.com/642f3d0236c604d1022330f2/6499f35e0bd0f43471a95adc_MEV_Auctions_ArXiV_6.pdf" rel="noopener nofollow ugc">Censorship resistance in onchain auctions</a> paper). Admittedly, the mechanism is not exactly real-time because we still need to impose the “local <span class="math">\text{IL}</span> freeze” deadline <span class="math">d</span> so block producers have time to consider <span class="math">\text{IL}_\text{agg}</span> transactions before proposing their block.</p>
<h3><a class="anchor" href="https://ethresear.ch#textil-conditionality-17" name="textil-conditionality-17"></a><span class="math">\text{IL}</span> conditionality</h3>
<p>A core property of <span class="math">\text{ILs}</span> is their conditionality, which determines whether ILs should have dedicated block space for their transactions (<a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">unconditional</a>) or share block space with the payload and only being included if the block isn’t full (conditional). For FOCIL, we’re leaning towards using conditional <span class="math">\text{ILs}</span> for a couple of reasons. Firstly, it might generally be best to give sophisticated entities like builders the maximum amount of freedom in organizing block space as long as they include <span class="math">\text{IL}</span> transactions. Allowing them to order transactions and fill blocks as they prefer, rather than imposing too many restrictions on their action space, reduces the risk of them using side channels to circumvent overly rigid mechanisms. Specifically, the unconditional property just couldn’t really be enforced effectively with FOCIL, since builders wanting to use <span class="math">\text{IL}</span> dedicated block space could simply “buy up <span class="math">\text{IL}</span> committee seats” from the elected validators to include their transactions via local <span class="math">\text{ILs}</span>. Another reason to opt for conditional <span class="math">\text{ILs}</span> is the flexibility in the size of the list. With unconditional ILs, an added block space must strictly set an arbitrary maximum <span class="math">\text{IL}</span> gas limit (e.g., <code>3M</code> gas). In contrast, conditional <span class="math">\text{ILs}</span> allow for a much more flexible <span class="math">\text{IL}</span> size, depending on the remaining space in the block. The known tradeoff with conditional <span class="math">\text{ILs}</span> is block stuffing: censoring builders might fill their blocks up to the gas limit to keep <span class="math">\text{IL}</span> transactions out. More research is needed to determine the sustainability of block stuffing, as <a href="https://timroughgarden.org/papers/eip1559.pdf" rel="noopener nofollow ugc">consecutive full blocks exponentially increase base fees</a> and the overall cost of this strategy.</p>
<h3><a class="anchor" href="https://ethresear.ch#account-abstraction-accounting-18" name="account-abstraction-accounting-18"></a><strong>Account Abstraction accounting</strong></h3>
<p>In previous proposals, <span class="math">\text{IL}</span> summaries were constructed as structures to constrain blocks without committing to specific raw transactions. Each <span class="math">\text{IL}</span> summary —or <span class="math">\text{IL}_\text{agg}</span> for FOCIL— entry represents a transaction by including the following fields: <code>From</code> and <code>Gas Limit</code>. Satisfying an entry in the <span class="math">IL</span> summary requires that at least <em>some</em> transaction from the <code>From</code> address has been executed, <em>unless</em> the remaining gas in the block is less than <code>Gas Limit</code> . The idea is simple: if a transaction was previously valid and had a sufficiently high basefee, the only two things preventing its inclusion are the lack of sufficient gas in the block or its invalidation, which would require a transaction from the same sender to have been previously executed. Here we rely on a property of Ethereum EOAs: the <code>nonce</code> and <code>balance</code> of an EOA determine the validity of any transaction originating from that EOA, and can only be modified by such a transaction.</p>
<p>However, even limited forms of Account Abstraction that have been considered for inclusion in Electra (e.g., <a href="https://github.com/ethereum/EIPs/blob/43fb1e0ca950c42a09efdf9a85d8acfe260efac1/EIPS/eip-3074.md" rel="noopener nofollow ugc">EIP-3074</a> or <a href="https://github.com/ethereum/EIPs/blob/43fb1e0ca950c42a09efdf9a85d8acfe260efac1/EIPS/eip-7702.md" rel="noopener nofollow ugc">EIP-7702</a>) allow a transaction to trigger a change in an EOA’s balance, <em>without originating from that EOA</em>. This <a href="https://hackmd.io/@potuz/BkWngLly0#Transactions-that-become-invalid" rel="noopener nofollow ugc">raised concerns</a> regarding previous <span class="math">\text{fIL}</span> proposals, as proposer <span class="math">n</span> is not aware of what is included in builder $n$’s payload when proposing its <span class="math">\text{IL}</span>. This could lead to a scenario where proposer <span class="math">n</span> includes a transaction <span class="math">txn_A</span> from address <span class="math">A</span> in the <span class="math">\text{IL}</span>, while builder <span class="math">n</span> includes an EIP-7702 transaction <span class="math">txn_B</span>, originating from address <span class="math">B</span> but sweeping out all the <code>ETH</code> from address <span class="math">A</span>, and thus invalidating  <span class="math">txn_A</span>. Consequently, builder <span class="math">n+1</span> would no longer be able to include <span class="math">txn_A</span>, though no other transaction from address <span class="math">A</span> has been previously executed. In other words, the <span class="math">IL</span> summary would be unsatisfiable.</p>
<p>In FOCIL, one simplification is that the constraints from the <span class="math">\text{IL}_\text{agg}</span> apply to the block that is being built concurrently. This means a transaction in the <span class="math">\text{IL}_\text{agg}</span> can’t be invalidated because of a transaction in the previous block, as it can in <span class="math">\text{fIL}</span> designs. In other words, we do not need to worry about what happened in the previous block in order to check for satisfaction of the <span class="math">\text{IL}_\text{agg}</span>. However, a builder could still insert EIP-7702 transactions in its payload that invalidate <span class="math">\text{IL}_\text{agg}</span> transactions. To handle this case, we can do the following when validating a block:</p>
<ul>
<li>Before executing the block’s transactions, we store <code>nonce</code> and <code>balance</code> of all <code>From</code> addresses that appear in the <span class="math">\text{IL}_\text{agg}</span>.</li>
<li>After execution, we check the <code>nonce</code> and <code>balance</code> of all <code>From</code> addresses from the <span class="math">\text{IL}_\text{agg}</span> again, and for each (<code>From</code>, <code>Gas Limit</code>) pair in the <span class="math">\text{IL}_\text{agg}</span> we require that either the <code>nonce</code> or the <code>balance</code> has changed, or the <code>Gas Limit</code> is more than the remaining gas.</li>
</ul>
<p>If the <code>nonce</code> has changed, some transaction from that address has been executed. If the <code>balance</code> has changed but the <code>nonce</code> has not, some AA transaction has touched that address. In either case, that address has transacted in the block, and the entry is satisfied.</p>
<p><em>Note: With "full” AA, transactions could have validity that depends on arbitrary state (e.g., the price changing in a Uniswap pool). In such cases, relying on a reduced form of transactions (i.e., entries with <code>From</code> and <code>Gas limit</code> fields) is insufficient, as the full validation logic of the transaction is needed. Due to the <a href="https://notes.ethereum.org/@vbuterin/pbs_censorship_resistance#What-are-the-design-goals-of-any-anti-censorship-scheme" rel="noopener nofollow ugc">free data-availability</a> problem, putting raw transactions on-chain is not an option. Instead, attesters could check this locally since they need to construct their own <span class="math">\text{IL}_\text{agg}^\text{attester}</span> and could, therefore, evaluate the full validation logic. This allows them to verify if the transaction has been invalidated and if its inclusion should be enforced. However, attesters might have <span class="math">\text{IL}_\text{agg}^\text{attester}\text{s}</span> that contain different transactions from the same <code>From</code> address, leading to a situation where one transaction might be invalidated while another is not. This would result in split views and potential attacks</em></p>
            <p><small>10 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 15:42:04 +0000</pubDate>
</item>
<item>
<title>Burn incentives in MEV pricing auctions</title>
<link>https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856</link>
<guid>https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV定价拍卖、公共利益、竞争、贿赂、共识机制

总结:
本文分析了MEV定价拍卖中的五种潜在激励，包括公有利益建设者、营利性公有利益建设者、敲诈勒索、攻击性竞争（包括单个和联合攻击）以及与共识机制的风险。这些因素促使参与者竞相烧掉MEV，以确保自身或竞争对手的收益。文章指出，尽管存在对晚投标和缺乏公平性的担忧，但实际博弈中，特别是通过与验证者服务提供商（SSP）的紧密合作，MEV燃烧的动机变得更加强烈。此外，作者提醒要警惕MEV定价拍卖可能对共识机制产生的负面影响，比如attester-builder的整合可能导致共识形成过程中的竞争失衡。因此，设计MEV机制时需平衡各方利益，防止意外破坏网络稳定。 <div>
<h1><a class="anchor" href="https://ethresear.ch#burn-incentives-in-mev-pricing-auctions-1" name="burn-incentives-in-mev-pricing-auctions-1"></a>Burn incentives in MEV pricing auctions</h1>
<p><em>Thanks to Barnabé Monnot, Thomas Thiery and Caspar Schwarz-Schilling for feedback and comments.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/7/1703882e171fbc76c500a2799ebea0ad8dfe61d7.jpeg" title="The process of burning MEV"><img alt="The process of burning MEV" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/1/7/1703882e171fbc76c500a2799ebea0ad8dfe61d7_2_375x375.jpeg" width="375" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<h3><a class="anchor" href="https://ethresear.ch#overview-3" name="overview-3"></a>Overview</h3>
<p>This post presents a rudimentary review of incentives for burning MEV under the <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">“simple” MEV burn mechanism</a> presented by Justin, as well as its slot auction counterpart, <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">“execution auctions”</a> presented by Barnabé. The analysis is also applicable to Francesco’s original <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a> design. These auctions—involving builders bidding, attesters enforcing a base fee floor, and proposers selecting a winning bid—will be defined as MEV pricing auctions (in the author’s view, the “execution auction” moniker could also be extended to cover all MEV pricing auctions).</p>
<p>The post highlights how incentives to drive up the price floor (and thus burn more MEV) can emerge in these designs regardless of any direct profit motive among builders for doing so. Importantly, stakers and staking service providers wish to ensure that competitors do not attain more rewards for selling MEV capture rights than them. They may therefore integrate with builders to bid away competing stakers’ profits. Auctions that set a price floor on proposers’ MEV capture rights will thus be influenced by the overarching staking <a href="https://en.wikipedia.org/wiki/Metagame">metagame</a>. It is only at this layer that griefing attacks against proposers to burn their MEV capture rights can be understood. Adverse competition during the consensus formation process might hypothetically lead attesters to bias their MEV base fee floor during split views, rejecting or admitting blocks depending on how it impacts their bottom line (in their roles as both builders and stakers). This is something to be attentive to. Naturally, burning MEV might also be considered a public good, and such incentives are reviewed in the text as well.</p>
<h3><a class="anchor" href="https://ethresear.ch#mev-pricing-auctions-4" name="mev-pricing-auctions-4"></a>MEV pricing auctions</h3>
<p>In <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn–a simple design</em></a>, Justin formulated an add-on to <a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710">enshrined proposer–builder separation</a> (ePBS), modifying the <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a> design.  Builders can specify a base fee and a tip in their block bids. At some specific time before the slot begins (e.g., 2 seconds), attesters observe the highest base fee among the bids (“observation deadline”) and impose it as a subjective base fee floor when attesting to the proposer’s block. Only bids with a base fee above the floor are accepted, and the base fee is burned.</p>
<p>If builders bid before the observation deadline with the same timing as today, then the mechanism will <a href="https://ethresear.ch/t/in-a-post-mev-burn-world-some-simulations-and-stats/17092">burn substantial MEV</a>. Concerns have however been raised over the risk of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">collusion between proposers and builders</a> and lack of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">proper incentivization</a>. A <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">recent write-up</a> on the benefits of the design and MEV burn in general generated similar worries of a <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">stable equilibrium of late bidding</a>.</p>
<p>The design can be further modified to involve auctioning off the rights to the entire slot, 32 slots in advance (“<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">execution auction</a>”). A benefit of this design is the ability to offer long-lived preconfirmations and—hypothetically—the reduced value-in-flight during the auction. The same concerns raised for the block auction design can be applied to the slot auction design, because the beacon proposer might still benefit from colluding with builders to form late-bidding cartels when selecting the execution proposer.</p>
<p>A modified MEV pricing auction, <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">MEV burn with builder kickbacks</a>, attempts to compensate builders for bidding early. That design is not the focus of this post, but incentives and side effects in uncompensated MEV pricing auctions will affect its relevance.</p>
<h2><a class="anchor" href="https://ethresear.ch#five-burn-incentives-in-mev-pricing-auctions-5" name="five-burn-incentives-in-mev-pricing-auctions-5"></a>Five burn incentives in MEV pricing auctions</h2>
<p>The outlined concerns of late bidding are valid, but it turns out that it is not possible to analyze MEV burn without incorporating stakers as participating agents. In such an analysis, competition for attaining the most yield will—under equilibrium—drive participants to burn each other’s MEV. Other incentives for burning MEV also exist. The analysis starts from the most idealistic public good example in (A) and gradually builds toward a metagame of active collusion to discourage other stakers in (E) (see Figure 1).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/a/7a0cc1b660d8b22ac81aff0bbc070505e6f30e7e.jpeg" title="Figure 1"><img alt="Figure 1" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/a/7a0cc1b660d8b22ac81aff0bbc070505e6f30e7e_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><strong>Figure 1.</strong> Five types of builders potentially burning MEV in MEV pricing auctions: (A) Public good builder, (B) For-profit public good builder, (C) Extortion racket, (D) Staker-initiated griefing, (E) Staker-initiated griefing cartel. The incentives behind (D) are important to understand (indicated by an arrow).</p>
<h3><a class="anchor" href="https://ethresear.ch#a-public-good-builder-6" name="a-public-good-builder-6"></a>(A) Public good builder</h3>
<p>The first example is a builder that dedicates resources to burning MEV without a direct profit motive. If Ethereum’s users believe that burning MEV is a public good, and in particular if no other incentive is sufficient, they may come together to fund the development and operation of a public good builder. Initiatives to fund public goods are fairly <a href="https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c">prevalent</a> within the Ethereum ecosystem. The public good builder can for example consistently bid according to guaranteed MEV at the observation deadline in the block auction design. This ensures that the MEV is burned while the builder will not suffer any direct losses from the bid. In the slot auction design, the builder would instead need to bid according to its expected MEV for the entire slot and might bid slightly below to stay safe.</p>
<p>The public good builder will likely not be the best and will often be outbid in terms of tips from other builders in the proposer auction (taking place after the observation deadline), in which the proposer selects a winning bid. But the operation can still be very impactful. After all, priority fees are a significant portion of all value (in this post these fees are also treated as MEV), and some further “low-hanging MEV fruits” are potentially available without dedicating too large resources for extraction. While the builder may use any public goods funding received diligently and not strive for any profit, pursuing an idealistic path can still raise the originators’ public profile and provide significant economic benefits in the future (perhaps not even directly related to building blocks).</p>
<h3><a class="anchor" href="https://ethresear.ch#b-for-profit-public-good-builder-7" name="b-for-profit-public-good-builder-7"></a>(B) For-profit public good builder</h3>
<p>A builder that positions itself as providing a public good may also enjoy direct economic benefits from its operation if some validators sympathize with the mission. There may for example be a market fit for builders that do not censor, nor extract various types of toxic MEV. In the block auction design, the builder could keep the MEV base fee in line with the available (non-censorship/non-toxic) MEV during the attester auction, and then pivot to tipping afterward, retaining some small profit margin. The MEV in some blocks is not particularly geared towards specialized searchers, and stakers may not lose that much in tips for some blocks by selecting the public good builder. Therefore, the public good builder could have higher profit margins in the blocks it does eventually get to build than builders that have not positioned themselves as providing a public good. A builder bidding before the observation deadline might of course also hope that its bids are the only ones to reach the proposer in times of degraded network conditions.</p>
<h3><a class="anchor" href="https://ethresear.ch#c-extortion-racket-8" name="c-extortion-racket-8"></a>(C) Extortion racket</h3>
<p>Given the lower effort required for extracting some of the MEV, it seems like (A) and (B) could have a natural position and high impact within the Ethereum ecosystem. But it may very well be that no successful public good builder can be sustained over the long run. After all, many stakers will not be particularly enthusiastic over a builder that burns their MEV opportunities.</p>
<p>Still, consider the importance of a dedicated MEV-burning builder within the staking ecosystem. If the builder is operational, proposers will lose out on a lot of value relative to if it does not operate. Is there a business opportunity here? Perhaps a builder could commit to burning the maximum possible MEV but abstain from doing so if it receives a bribe from the proposer? It seems natural that proposers would be willing to pay for this, since the proposer stands to capture most value from the available MEV if none is burned. But the prospect of competition makes the business model perilous. If a sole extortive builder is profitable, then a few more may try to enter the market as well. There is not much use in paying off two builders if it turns out that a third burned the MEV anyway through a bid. A mechanism for reconciling this ex-post would become rather complex. The validator may then be better off by simply not negotiating with any extortion racket.</p>
<p>While the extortion racket seems unsustainable, it helps to underscore the power that builders have over proposers. The ultimate incentive for burning MEV then emerges when changing the responsible actor from one unaffected by the staking equilibrium (extorting builder) to one that is not (other stakers). The auction will eventually become part of the <a href="https://en.wikipedia.org/wiki/Metagame">metagame</a> of the overarching staking equilibrium.</p>
<h3><a class="anchor" href="https://ethresear.ch#d-metagame-staker-initiated-griefing-9" name="d-metagame-staker-initiated-griefing-9"></a>(D) Metagame—staker-initiated griefing</h3>
<p>Staking service providers (SSPs) compete for delegated stake and derive income by taking a cut of the staking yield when they pass it back to the delegators. An SSP must ensure that the yield it offers delegating stakers is competitive relative to offers from other SSPs. The MEV pricing auction may therefore lead SSPs to burn competing proposers’ MEV by tightly integrating with builders or running them in-house. If a competitor burns an SSP’s MEV, then the SSP must respond in kind or will lose out on delegators and thus income. When considering the metalevel of SSPs, this equilibrium seems more stable than an equilibrium of late bidding leading to little or no MEV burn. All it takes to break the late-bidding cartel is one defecting SSP builder, forcing others to respond.</p>
<p>An SSP that through a builder griefs other stakers without taking any loss executes something comparable to a <a href="https://github.com/ethereum/research/blob/d1d465f658e0024a2010b0a6ad960a76d9c40cac/papers/discouragement/discouragement.pdf">discouragement attack</a> with an infinite griefing factor. This is a very advantageous attack, primarily because delegators will flow to the best performing SSP. In addition, a reduction in overall yield for other stakers pushes down the quantity of supplied stake, bringing up the equilibrium yield. Thus, even if some delegators do not flow to the SSP that burns its competitor’s MEV, the expected staking yield (that the SSP will share in the profit from) will still go up, if the competitor’s customers simply stop delegating. Of course, the cost of running the builder must be accounted for. But large SSPs can amortize that cost across a vast amount of yield-bearing validators.</p>
<p>Yet, directly profiting from the MEV is almost always better than burning it. When an SSP’s builder is able to extract more MEV in a competitor’s slot than any other builder, it will still be better off only bidding to a level that ensures it wins the auction. The SSP must thus make a probabilistic judgment as to the uniqueness of its MEV opportunity in the particular slot before deciding how to proceed (or more precisely, any edge in MEV value <span class="math">V_e</span> relative to the second best builder). An SSP builder must in essence bid before the observation deadline up to the point where the expected payoff from burning the marginal MEV is equal to the expected payoff from waiting and hoping to extract it. There are some game-theoretic nuances to this that here will be set aside, with some aspects discussed in the next section. The point is to assert that there are stronger incentives for builders to bid before the observation deadline than what has been previously understood, because a builder might be run by an SSP that indirectly profits from burning other stakers’ potential MEV revenue.</p>
<p>What happens in the metagame to smaller SSPs and solo stakers? They may not afford to run a builder of their own to ensure that their competitors’ MEV is burned. It is of course possible for solo stakers to try to come together to form a union around a builder, where each contributor is guaranteed to see their validators excluded from MEV base fee bids by the specific builder (and receive full tips during the proposer auction). There is then a question of if they will be able to organize such a union, but also if it really would be necessary. On the one hand, if there are several “griefing builders” running concurrently among the largest SSPs, parties holding less stake may not need to run their own griefing builder. Everyone will see their MEV burned anyway, since the big SSPs burn each other’s and everyone else’s MEV. On the other hand, a party not having a griefing builder readily available may be suboptimally positioned when considering the prospect of cartelization.</p>
<h3><a class="anchor" href="https://ethresear.ch#e-metagame-staker-initiated-griefing-cartel-10" name="e-metagame-staker-initiated-griefing-cartel-10"></a>(E) Metagame—staker-initiated griefing cartel</h3>
<p>Can builders operating at the metalevel collude to selectively burn or selectively <em>not</em> burn MEV, depending on the identity of the slot’s validator? The cartel would strive to ensure that all participating SSPs (or any union of solo stakers) receive the MEV in their validators’ proposed blocks, while minimizing MEV in all other validators’ blocks.</p>
<p>However, if attesters are honest, builders can only cartelize to selectively burn or not burn MEV that they uniquely are able to extract. As long as competing builders are operational, this substantially limits the power of any cartel. Therefore, the advantage of (E) over (D) is not substantial.</p>
<h4><a class="anchor" href="https://ethresear.ch#proposer-is-part-of-the-cartel-11" name="proposer-is-part-of-the-cartel-11"></a>Proposer is part of the cartel</h4>
<p>When the beacon proposer is part of the cartel, members will abstain from bidding before the observation deadline to ensure that as much value as possible flows to the proposer. This type of cartelization has been highlighted as a concern (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">2</a>) in the debate around MEV pricing auctions. The idea is that participants come to an explicit or implicit agreement to not bid before the observation deadline. Yet the incentive to burn MEV is stronger than previously understood, since stakers outside the cartel will wish to grief cartel members by bidding early (D), and so from this perspective, the risk of late-bidding-cartelization is lower than feared.</p>
<p>It might also be difficult to efficiently uphold cartelization, because it is not possible for members to know which, if any, defected in pursuit of (D). One avenue would be to try to share the profits from every slot to give all participants incentives to hold back bids before the observation deadline. Yet overall, the existence of (A), (B), and (D) means that some value will still reasonably be burned by public good builders or any competitors not part of the cartel.</p>
<h4><a class="anchor" href="https://ethresear.ch#proposer-is-not-part-of-the-cartel-12" name="proposer-is-not-part-of-the-cartel-12"></a>Proposer is not part of the cartel</h4>
<p>When the beacon proposer is outside the cartel, the goal is to deprive it of revenue while still capturing as much of the MEV as possible. It will still be more profitable for the cartel to extract any unique MEV opportunity rather than burn it. Define <span class="math">V_s</span> as the value a builder can attain in the slot auction and <span class="math">V_b</span> as its value for the block auction (from a block built at the observation deadline). When a builder can extract the most MEV, it has an edge <span class="math">V_e</span> over the second-best builder (kept constant for simplicity). Just as in (D), the cartel can bid up to <span class="math">V_b-V_e</span> or <span class="math">V_s-V_e</span>, with the difference that <span class="math">V_e</span> expands if the cartel collectively gains a larger edge against the best builder outside of the cartel. This expansion is what the cartel tries to capitalize on, both when the proposer is part of the cartel (expanding <span class="math">V_e</span> to lower the burn) and when not (expanding <span class="math">V_e</span> to increase builder profits). A challenge—just as in (D)—is that the cartel might not be able to properly estimate <span class="math">V_e</span>. After the observation deadline, the cartel attempts to extract as much value as possible, leaving the MEV either burned or in their hands.</p>
<h4><a class="anchor" href="https://ethresear.ch#collusion-at-other-levels-13" name="collusion-at-other-levels-13"></a>Collusion at other levels</h4>
<p>The presentation so far has been somewhat simplistic. It bears mentioning that collusion need not happen at the level of the builders, but can for example happen at the level of searchers or any out-of-protocol relay that the cartel still finds beneficial to maintain before posting to the P2P layer. In all scenarios of successful cartelization, if some stakers (for example solo stakers) are unable to act collectively, they may end up at the short end of the discouragement dynamic.</p>
<h2><a class="anchor" href="https://ethresear.ch#risks-associated-with-attester-builder-integration-14" name="risks-associated-with-attester-builder-integration-14"></a>Risks associated with attester–builder integration</h2>
<p>The analysis so far indicates that (D) may have a significant effect on its own but that it does not necessarily lead to the riskier cartelization in (E). But what might happen when we give SSPs tools for depriving each other of revenue? While SSPs will always compete, competition in MEV pricing auctions is on the verge of seeping into the consensus formation process. At the consensus level, all participants are expected to behave honestly and are rewarded for good behaviour. Through staker–builder integration in (D)-(E), SSPs will come to actively influence each other’s rewards, cooperating or griefing each other. A risk is that SSPs might navigate down perilous paths in this landscape.</p>
<p>It has been noted that MEV pricing auctions suffer from attesters potentially having <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">split views</a> of the MEV base fee floor. Biasing the outcome in a split view one way or the other might benefit one builder over another, result in a block being forked out to deprive the beacon proposer of all rewards, or allow the proposer to reap higher rewards when selling MEV capture rights. One concern is that SSPs might eventually try to profit by tuning their attestations of the MEV base fee floor to produce favorable outcomes. This can also be done as part of a cartel. The honest majority assumption need not be broken to derive profits, due to split views. It is only necessary to put a thumb on the scale, and a competitive consensus formation might make such behavior more likely.</p>
<p>Of course, stakers who do not honestly attest to which bids they have observed at which specific time point subject themselves to risks of social slashing if malicious behavior can be uncovered. This is always a potential final resort under proof of stake. In essence, just as it is prudent to be cautious of MEV or excessive issuance as strata for cartelization, it also seems prudent to be cautious of MEV pricing auctions as a stratum for consensus adversity.</p>
<h2><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-in-terms-of-mev-pricing-15" name="block-vs-slot-auctions-in-terms-of-mev-pricing-15"></a>Block vs. slot auctions in terms of MEV pricing</h2>
<p>Will block auctions or slot auctions burn more MEV? Is one more centralizing than the other? These questions are not easy to answer, because it depends on which burn incentive that comes to dominate, the likelihood of cartelization under different designs, etc. This section will discuss some differences (previous writings on <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ">block vs. slot auctions</a> provide a broader perspective).</p>
<h3><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-concerning-d-16" name="block-vs-slot-auctions-concerning-d-16"></a>Block vs. slot auctions concerning (D)</h3>
<p>Assume that (D) becomes an important incentive for burning MEV. Further, assume a competitive market without cartelization and perfect information about how much MEV each participant can extract. In the block auction design, the builder can bid <span class="math">V_b-V_e</span> for the block at the observation deadline to maximize burn while retaining opportunities to extract value. It then updates its block and bid through tips in the proposer auction up until the slot boundary. There is <span class="math">V_s-V_b</span> worth of value that the proposer hopes to attain through tips, and <span class="math">V_e</span> worth of value left for the builder (under these simplified conditions).</p>
<p>In the slot auction design, the builder can instead bid <span class="math">V_s-V_e</span> already at the observation deadline. It is just buying the rights to build the block, not committing to its content, and that value is an entire slot’s worth of MEV. Naturally, <span class="math">V_s</span> will here just be an estimate, and the risk that builders take on by bidding on an expected value instead of a tangible value might be worth some fraction of the total bid value. But incomplete information around competitors’ eventual final bids will likely serve to pull down the bid value at the observation deadline more. The staker–builder can ideally burn <span class="math">V_s-V_e</span> of a competing beacon proposer’s auctionable MEV, and again retain <span class="math">V_e</span> for itself. The difference in MEV burn between the two designs is then <span class="math">V_s-V_b</span>.</p>
<p>If the staker–builder could estimate <span class="math">V_s</span> also in the block auction design (which nominally is easier since it bids much closer to the deadline), it could bid <span class="math">V_s-V_e-V_g</span> already at the observation deadline. Since the bid is attached to a block containing only <span class="math">V_b</span> of MEV, <span class="math">V_g</span> is reserved as a tip for the proposer auction. If there is no tip, the proposer might elect to pick the block from the observation deadline, depriving the builder of <span class="math">V_s-V_b</span>. However, while the proposer might specifically wish to do so if the same builder bids with low tips also in the proposer auction, a staker can obfuscate its identity by running several builders (the kickback design disincentivizes obfuscation).</p>
<p>In either design, it seems most likely that the burn ends up being lower than these theoretical maxima due to incomplete information in combination with the fact that capturing the MEV is more valuable than burning it. The staker–builder will therefore operate with quite some margin to maximize expected profits.</p>
<h3><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-concerning-a-b-17" name="block-vs-slot-auctions-concerning-a-b-17"></a>Block vs. slot auctions concerning (A)-(B)</h3>
<p>The analysis for (D) is to some extent also applicable for (A) and (B). The public good builder could theoretically bid higher in the slot auction than in the block auction. However, the risk associated with overbidding in the slot auction design might be more serious for these builders. In the block auction design, the available value will be much clearer, making it easier for an unsophisticated builder to make low-risk bids.</p>
<h3><a class="anchor" href="https://ethresear.ch#value-of-preconfirmations-18" name="value-of-preconfirmations-18"></a>Value of preconfirmations</h3>
<p>As previously mentioned, the slot auction design facilitates execution layer preconfirmations, which can provide a welfare gain to Ethereum. In addition, their value can be burnt (just as in <a href="https://ethresear.ch/t/execution-tickets/17944#roadmap-compatibility-6">execution tickets</a>), since builders are bidding to attain that value. This increases the burn of the slot auction design.</p>
<h3><a class="anchor" href="https://ethresear.ch#builder-centralization-under-competition-over-expected-mev-19" name="builder-centralization-under-competition-over-expected-mev-19"></a>Builder centralization under competition over expected MEV</h3>
<p>If builders have different strengths and weaknesses, they will intermittently attain the highest <span class="math">V_b</span> in the block auction design. While one builder might be able to extract the highest MEV in expectation, not all blocks will play to its strengths. However, in the slot auction, builders bid on expected MEV, and one specific builder might then always have the highest expected <span class="math">V_s</span>. <a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814">This could potentially be a centralizing force</a>, depending on how secondary markets evolve.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-20" name="conclusion-20"></a>Conclusion</h2>
<p>There are strong incentives for burning MEV even in designs that do not directly compensate for it, for example to provide a public good service or to ensure that other participants in the staking metagame do not attain a higher yield. Uncompensated MEV pricing auctions accommodates these incentives. Of particular relevance is staker-initiated griefing (D). It seems clear that SSPs will seek to influence builders’ bidding strategies, and this can lead to staker–builder integration. Still, this form of integration does not necessarily lead to censorship or higher MEV profits; thus not negating sought benefits of proposer–builder separation. If it is desirable to give an outside party an independent incentive to burn MEV, then <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">builder kickbacks</a> are an option. They can also be applied to the slot auction design.</p>
<p>When implementing a MEV burn mechanism, it is important to ensure that the burn mechanism does not accidentally set fire to Ethereum’s consensus mechanism. Giving SSPs tools for griefing each other could lead to adverse competition during the consensus formation process. A particular concern is then if emerging attester–builder integration leads attesters to bias their MEV base fee floor, rejecting or admitting blocks depending on how it impacts their bottom line (in their roles as both builders and stakers). Which of the different scenarios (A-E) that would predominate is seemingly a more important parameter when evaluating the merits of MEV pricing auctions than the mechanism’s ability to burn substantial MEV (which this post suggests it can).</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 20:58:14 +0000</pubDate>
</item>
<item>
<title>Preconfirmations: On splitting the block, mev-boost compatibility and relays</title>
<link>https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837</link>
<guid>https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837</guid>
<content:encoded><![CDATA[
<div> 关键词：Preconfirmation, XGA-style, Ethereum, Block Splitting, Relay

总结:
本文讨论了一种名为XGA-style的预确认机制，它为非优先级交易提供有限时间内（2个epoch后）的区块底部预留空间。这种机制将区块分为顶部和底部两部分，顶部用于传统MEV竞拍，底部通过预确认拍卖分配。预确认通过多单位拍卖进行，买家可以锁定区块容量确保交易成功纳入。文章还提到，这有助于缓解竞争性建块者压力，简化预确认定价，以及对Relay角色的重新思考，提出通过保险和奖励机制来保障预确认平台的稳定运行。XGA是首个实现这一设计的L2平台，目前已有主网版本，但正在进行进一步开发以支持更多功能。 <div>
<p>Thanks to <a class="mention" href="https://ethresear.ch/u/fabrizioromanogenove">@FabrizioRomanoGenove</a>, <a class="mention" href="https://ethresear.ch/u/meridian">@meridian</a> and Philipp Zahn for helpful comments and feedback on this post.</p>
<h2><a class="anchor" href="https://ethresear.ch#what-is-a-preconfirmation-1" name="what-is-a-preconfirmation-1"></a><img alt=":question:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/question.png?v=12" title=":question:" width="20" /> What is a Preconfirmation?</h2>
<p>There have been a lot of variations on the definition of preconfirmation going around recently in the Ethereum community. In this post we will keep the definition as simple and broad as possible in order to generate the least amount of confusion and avoid arguing on semantics as much as possible:</p>
<blockquote>
<p>We call a <strong><em>preconfirmation mechanism</em></strong> any mechanism that ensures (non-positional) inclusion of a (bundle of) transaction(s), if execution is successful, in a finite and bounded amount of time from the emission of the preconfirmation.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#xga-style-preconfirmations-2" name="xga-style-preconfirmations-2"></a><img alt=":mag:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/mag.png?v=12" title=":mag:" width="20" /> XGA-Style Preconfirmations</h3>
<p>We will analyze a specific kind of preconfirmation mechanism – as hinted to in <a href="https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800/3">this post on ethresearch</a> – that we came up with some time ago and have been building since then:</p>
<blockquote>
<p>An <strong><em>XGA-style preconfirmation mechanism</em></strong> is a preconfirmation mechanism that guarantees (non-positional) inclusion of a sized bundle of transactions <strong>in the bottom portion of a predetermined block to be minted 2 epochs after the preconfirmation was emitted</strong>. Maximum bundle size is determined at the time of emission of the preconfirmation.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#splitting-the-block-3" name="splitting-the-block-3"></a><img alt=":scissors:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/scissors.png?v=12" title=":scissors:" width="20" /> Splitting the Block</h2>
<p>Looking at the previous definition, I assume the first couple of questions that would come to mind is “what do you mean exactly by the bottom portion of a block?” and “how is the block to include the bundle predetermined?”. Our idea is pretty simple: Partition the block in such a way to keep a top-of-the-block (ToB)<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-1" id="footnote-ref-48655-1">[1]</a></sup>, high-priority section, in which traditional builders do their usual thing and is allocated through a traditional mev-boost auction or whatever the relay running it prefers; and a reserved bottom-of-the-block (BoB) section, which will serve as allocation space for preconfirmations. In this design, preconfirmation bundles will be allocated via a separate auction in the form of <strong><em>forward contracts</em></strong>.</p>
<h3><a class="anchor" href="https://ethresear.ch#a-two-auction-format-4" name="a-two-auction-format-4"></a><img alt=":busts_in_silhouette:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/busts_in_silhouette.png?v=12" title=":busts_in_silhouette:" width="20" /> A Two-Auction Format</h3>
<p>As briefly mentioned above, in the XGA-style split-block design, preconfirmations are allocated in a completely separate way from the traditional mev-boost auction, allowing them to coexist without excessively disrupting the ecosystem. Traditional builders will be able to do their own thing with minimal adjustments, while everyone else can still enjoy the benefits of preconfirmations.</p>
<p>In simple terms: An XGA-style BoB auction is a multi-unit auction selling gas tokens for a specific block <span class="math">B</span> in fixed-size units (e.g. <span class="math">100</span> K gas). These tokens can then be used to submit a bundle<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-2" id="footnote-ref-48655-2">[2]</a></sup> that is guaranteed inclusion in <span class="math">B</span> if execution is successful.</p>
<p>As an example, picture this scenario:</p>
<ul>
<li><img alt=":clock2:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/clock2.png?v=12" title=":clock2:" width="20" /> At the start of epoch <span class="math">N-2</span> we know that the validator <span class="math">V</span>, serving XGA-style preconfirmations, will be the proposer for the <span class="math">K</span>-th slot of epoch <span class="math">N</span>.</li>
<li><img alt=":oil_drum:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/oil_drum.png?v=12" title=":oil_drum:" width="20" /> $5$M gas out of the standard <span class="math">30</span> M will be auctioned off into <span class="math">50</span> gas tokens, each representing a capacity of <span class="math">100</span> K gas.</li>
<li><img alt=":shopping_cart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/shopping_cart.png?v=12" title=":shopping_cart:" width="20" /> At some fixed time <span class="math">t</span> before the start of slot <span class="math">K</span>, a multi-unit auction allocating the tokens is run. Aki manages to win 5 tokens for <span class="math">K</span>, for a combined capacity of <span class="math">500</span> K.</li>
<li><img alt=":alarm_clock:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/alarm_clock.png?v=12" title=":alarm_clock:" width="20" /> Within the deadline fixed at some time <span class="math">d</span> before the end of <span class="math">K</span>, Aki uses the <span class="math">5</span> tokens to submit a bundle of size just over <span class="math">400</span> K gas.</li>
<li><img alt=":outbox_tray:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/outbox_tray.png?v=12" title=":outbox_tray:" width="20" /> In the meantime, other BoB auction winners submit their own bundles.</li>
<li><img alt=":dollar:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/dollar.png?v=12" title=":dollar:" width="20" /> At the start of <span class="math">K</span>, a traditional mev-boost auction for <span class="math">25</span> M gas is run as usual by all relays, and is won by Bogdan via relay <span class="math">R</span>.</li>
<li><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> After deadline <span class="math">d</span> is reached and the mev-boost auction is over, the BoB part is assembled and attached at the bottom of the max-<span class="math">25</span> M block submitted by Bogdan via relay <span class="math">R</span>.</li>
<li><img alt=":tada:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/tada.png?v=12" title=":tada:" width="20" /> Since Aki’s bundle contained no reverting transactions, it is included without any problem – together with the non-reverting bundles submitted by the other BoB winners – somewhere after the portion built by Bogdan.</li>
<li><img alt=":satellite:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/satellite.png?v=12" title=":satellite:" width="20" /> The block for <span class="math">K</span> gets broadcasted as usual.</li>
<li><img alt=":x:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/x.png?v=12" title=":x:" width="20" /> Excess tokens for <span class="math">K</span> that didn’t get spent can no longer be used.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#who-builds-the-blocks-then-5" name="who-builds-the-blocks-then-5"></a><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> Who Builds the Blocks, then?</h3>
<p>Block building, in the case of XGA-style preconfirmations, is handled by multiple parties:</p>
<ul>
<li><img alt=":package:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/package.png?v=12" title=":package:" width="20" /> The ToB part is built by traditional mev-boost builders as usual.</li>
<li><img alt=":gift:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/gift.png?v=12" title=":gift:" width="20" /> The BoB part is assembled by the party running the BoB auction.</li>
<li><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> Merging the two parts and sending the block over is handled by the relay.</li>
</ul>
<p>In this setup, the relay takes on more work and responsibilities than it currently does. We will explore a potentially beneficial approach to this change later.</p>
<h3><a class="anchor" href="https://ethresear.ch#what-are-the-economic-advantages-of-preconfirmations-6" name="what-are-the-economic-advantages-of-preconfirmations-6"></a><img alt=":money_with_wings:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/money_with_wings.png?v=12" title=":money_with_wings:" width="20" /> What Are the Economic Advantages of Preconfirmations?</h3>
<p>Well… In general, for the whole range of designs that are being discussed right now this is not clear yet! <strong>Conjecturally</strong>, some of the proposed preconfirmation mechanisms will allow more value to trickle down to validators, but since the preconfirmation design landscape is so broad and confused right now it’s hard to take into account all the possible market effects that could come out of such designs. For example, most of the preconf mechanisms currently being discussed are pretty unfriendly towards what has been one of the main APY-cows for validators since the dawn of mev-boost: competitive builder/searchers.</p>
<h4><a class="anchor" href="https://ethresear.ch#why-are-we-betting-on-xga-style-preconfs-7" name="why-are-we-betting-on-xga-style-preconfs-7"></a><img alt=":game_die:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/game_die.png?v=12" title=":game_die:" width="20" /> Why Are We Betting on XGA-Style Preconfs?</h4>
<p>It seems clear to us that reserving a spot for non-priority-sensitive transactions can offer several benefits:</p>
<ul>
<li>Users and platforms (e.g. rollups) that are not involved in competitive building/searching just doesn’t care about running HFT operations on L1 can greatly benefit from separating their concerns from those of competitive builder/searchers.</li>
<li>On the other end, it eases some of the pressure on the competitive builder/searcher side by removing some of the burden of having to include <em>“filler transactions”</em> to keep their blocks competitive. E.g. freeing them from needing to include blob-bearing transactions that could negatively impact latency.</li>
<li>It makes actually pricing inclusion preconfirmations simpler, since it is still regulated by the usual gas pricing model, and at the same time the preconf inclusion market is kept separate from the traditional priority market for position-sensitive transactions.</li>
<li>Moreover, we believe in gradual change, allowing time for everyone to adapt to and observe the effects of new, potentially disruptive features in a controlled manner. A split-block design compatible with traditional mev-boost block building offers a less intrusive path to adoption.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#rethinking-relays-8" name="rethinking-relays-8"></a><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> Rethinking Relays</h2>
<p>At the moment running a relay naively is mostly a non remunerative gig. Under XGA-style preconfirmations, the relay does significantly more work and takes on more risk than before, e.g. if a block is missed and/or already sold preconfirmation tokens end up not getting included due to the relay malfunctioning, whoever bought them incurs an active loss of assets. While this sounds scary, it is also a good opportunity to rethink the role of relays in the Ethereum ecosystem.</p>
<h3><a class="anchor" href="https://ethresear.ch#insurance-and-reward-mechanisms-for-relays-9" name="insurance-and-reward-mechanisms-for-relays-9"></a><img alt=":shield:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/shield.png?v=12" title=":shield:" width="20" /> Insurance and Reward Mechanisms for Relays</h3>
<p>What we are proposing is that a relay can subscribe to an XGA-style preconf platform by staking a collateral that could be used to offer the damaged parties a refund in case of the relay malfunctioning, while sharing a percentage of the platform revenue each time it submits a successful block that includes XGA-enabled preconfirmations<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-3" id="footnote-ref-48655-3">[3]</a></sup>.</p>
<h2><a class="anchor" href="https://ethresear.ch#introducing-xga-10" name="introducing-xga-10"></a><img alt=":mega:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/mega.png?v=12" title=":mega:" width="20" /> Introducing XGA</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/4/448bd42d21b7642cd38d003f7cec9cb82adfc3b6.png" title="image"><img alt="image" height="99" src="https://ethresear.ch/uploads/default/optimized/3X/4/4/448bd42d21b7642cd38d003f7cec9cb82adfc3b6_2_690x99.png" width="690" /></a></div><br />
XGA – eXtensible Gas Auctions – is the first L2 platform for XGA-style preconfirmations (lol), designed and built by the combined efforts of <a href="https://www.manifoldfinance.com/" rel="noopener nofollow ugc">Manifold Finance</a> and <a href="https://20squares.xyz/" rel="noopener nofollow ugc">20Squares</a>. We’re very willing to make this an open and collaborative effort, so if you have any feedback and/or are interested in building this together with us, please reach out!<p></p>
<p>Right now we have released on mainnet our v1.0 (yes, this is not a beta, <strong>we’re ready to go</strong> and currently onboarding validators), with the caveat that in v1.0, the ToB mev-boost auction can only be run on a single relay. We’re currently working on shipping v2.0, which will allow a <strong>relay-agnostic</strong> auction to be run in the ToB part. You can find more about it at <a href="https://docs.xga.com/" rel="noopener nofollow ugc">docs.xga.com</a>.</p>
<hr class="footnotes-sep" />

<ol class="footnotes-list">
<li class="footnote-item" id="footnote-48655-1"><p>We have specific terms for ToB and BoB auctions, namely α and β-auctions respectively. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-1">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-48655-2"><p>Note that this doesn’t exclude the possibility of overwriting an already submitted bundle, if re-submitted before the deadline. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-2">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-48655-3"><p>We are already iterating on designs for captive insurance mechanisms for XGA-style platforms. We will upload a new post detailing some of the possible designs soon. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-3">↩︎</a></p>
</li>
</ol>
            <p><small>4 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 09:40:41 +0000</pubDate>
</item>
<item>
<title>IPv6 vs Ethereum?</title>
<link>https://ethresear.ch/t/ipv6-vs-ethereum/19829</link>
<guid>https://ethresear.ch/t/ipv6-vs-ethereum/19829</guid>
<content:encoded><![CDATA[
<div> 关键词：IPv6、CGA、BCA、Subnet ID、Interface ID

总结: 这篇文章探讨了IPv6地址结构与以太坊区块链网络之间的类比。作者提出将IPv6 Subnet ID和Interface ID的概念应用于以太坊，形成类似VPC（虚拟私有云）的结构，每个链对应不同的Subnet。使用加密技术如Cryptographically Generated Addresses (CGA) 和 Bitcoin Address-based Addresses (BCA)，可以增强节点身份验证和隐私保护。这种设想旨在通过利用IPv6的发现协议和现有机制，简化Solano节点设置，解决网络碎片问题，并增强跨链通信的安全性。 <div>
<p>I started writing this after a few days of unsuccessful attempts to run solo node behind CGNAT, as just a brainbreeze on whether it could be somehow done differently to ease up solo node setup.<br />
So far It does not seem to be an answer, however I want to share some thoughts on analogies seen with ipv6 networking to see if anyone has ideas on how this can be useful . .</p>
<h2><a class="anchor" href="https://ethresear.ch#ipv6-101-1" name="ipv6-101-1"></a>ipv6 101</h2>
<p>An IPv6 address consists of 128 bits, represented as eight groups of four hexadecimal digits separated by colons. Each group is called a hextet. For example:</p>
<p><code>2001:0db8:85a3:0000:0000:8a2e:0370:7334</code></p>
<p>where</p>
<ul>
<li>Global Routing Prefix: 2001:0db8 (Assigned by the Regional Internet Registry)</li>
<li>Subnet ID: 85a3:0000 (Identifies a specific subnet within the network)</li>
<li>Interface ID: 0000:8a2e:0370:7334 (identify the individual interface or device on the subnet)</li>
</ul>
<p>This hierarchical structure allows for efficient routing of IPv6 packets. Routers can quickly determine the destination network based on the global routing prefix, then further refine the path based on the subnet ID.</p>
<p><em>Multiple gateways</em> from ipv6 subnet may exist to public ipv6 space. Addresses within ipv6 sub network may access global ipv6 address space. Routing protocols such as <a href="https://datatracker.ietf.org/doc/html/rfc5340" rel="noopener nofollow ugc">OSPFv3</a> or <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol" rel="noopener nofollow ugc">BGP</a> may be used.</p>
<h2><a class="anchor" href="https://ethresear.ch#subnet-gateway-analogy-2" name="subnet-gateway-analogy-2"></a>Subnet Gateway analogy</h2>
<p>Just as an IPv6 router directs traffic to devices within its subnet, an RPC node facilitates communication with nodes and smart contracts within its respective blockchain network.</p>
<p>When we consider the concept of Chain IDs. In blockchain, Chain IDs are unique identifiers for different networks (e.g., Ethereum Mainnet has Chain ID 1, while various testnets have different IDs). Similarly, in IPv6, a subnet is identified by its unique prefix, which is a portion of the IPv6 address.</p>
<h2><a class="anchor" href="https://ethresear.ch#address-analogy-3" name="address-analogy-3"></a>Address analogy</h2>
<p>Since Interface Ids in IPv6 are only 64 bits long, they are too small to fit in 160 bits address of Eth.</p>
<p>However, what could be useful is using InterfaceIds to identify the nodes in the P2P network, forming VPC for Ethereum.</p>
<p>In IPv6, organizations or individuals can assign themselves a unique subnet prefix, effectively creating their own independent addressing space.</p>
<h3><a class="anchor" href="https://ethresear.ch#cryptography-for-ipv6-address-generation-4" name="cryptography-for-ipv6-address-generation-4"></a>Cryptography for IPv6 address generation</h3>
<p><a href="https://en.wikipedia.org/wiki/Secure_Neighbor_Discovery" rel="noopener nofollow ugc">Secure Neighbor Discovery (SEND)</a> is a security extension to the Neighbor Discovery Protocol (NDP) in IPv6, designed to address the vulnerabilities in the original NDP.</p>
<p>There are several papers and RFCs (Requests for Comments) relevant to cryptography for IPv6 address generation, particularly focusing on enhancing privacy and security:</p>
<p><strong><a href="https://datatracker.ietf.org/doc/html/rfc3972" rel="noopener nofollow ugc">RFC 3972</a> - Cryptographically Generated Addresses (CGA)</strong>: This RFC introduces the concept of CGA, where the interface identifier of an IPv6 address is generated using a cryptographic hash function from a public key and other parameters. This approach aims to bind a public key to an address securely, deterring address theft and enhancing authentication.</p>
<p><strong><a href="https://datatracker.ietf.org/doc/html/rfc7721" rel="noopener nofollow ugc">RFC 7721</a> - Security and Privacy Considerations for IPv6 Address Generation Mechanisms</strong>: This RFC discusses the security and privacy implications of different IPv6 address generation mechanisms, including SLAAC, privacy extensions, and CGAs. It provides recommendations for mitigating potential risks and improving privacy protection.</p>
<p><strong><a href="https://www.researchgate.net/publication/350518202_IPv6_Cryptographically_Generated_Address_Analysis_Optimization_and_Protection" rel="noopener nofollow ugc">IPv6 Cryptographically Generated Address: Analysis, Optimization and Protection</a></strong>:  This paper delves into the details of CGAs, analyzing their security and performance characteristics. It proposes optimizations to improve the efficiency of CGA generation and suggests additional security measures to strengthen the protection they offer.</p>
<p><strong><a href="https://arxiv.org/pdf/2311.15842" rel="noopener nofollow ugc">IPv6 Bitcoin-Certified Addresses, Mathieu Ducroux</a></strong>: proposes mechanism for enhancing the security and privacy of IPv6 addresses by leveraging the Bitcoin blockchain.<br />
In essence, BCAs are IPv6 addresses where the interface identifier is derived from a Bitcoin address.</p>
<h2><a class="anchor" href="https://ethresear.ch#how-could-this-be-beneficial-5" name="how-could-this-be-beneficial-5"></a>How could this be beneficial?</h2>
<p>If we can think of ethereum ecosystem as one big VPN where chains are subnet addressable that potentially solves fragmentation issues, allowing to use already established discovery protocols to route traffic between different nodes, use features like <a href="https://en.wikipedia.org/wiki/Multicast_address" rel="noopener nofollow ugc">multicast</a> etc.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/ipv6-vs-ethereum/19829">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 21:28:45 +0000</pubDate>
</item>
<item>
<title>Slot Inclusion Rates and Blob Market Combinatorics</title>
<link>https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817</link>
<guid>https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817</guid>
<content:encoded><![CDATA[
<div> 关键词：slot inclusion rate, blob market, integer packing problem, reorg risk, builder censorship

总结:<br />本文探讨了blob市场的slot inclusion rate（区块包含率）问题，指出其存在高波动性和某些Rollup（如Optimism和Base）的高值。文章分析了当前blob提交策略导致的竞争和整数打包问题（integer packing problem），这可能导致更高的slot inclusion rate而非建设者审查。研究发现，虽然市场容量未充分利用，但大blob交易的策略（如Base一次提交多个）导致平均slot inclusion rate较高。文章还提出了优化建议，如调整最大blob数量、动态投标策略和预确认机制，以提高效率并减少竞争中的潜在延迟审查。总的来说，文章强调了blob市场设计对slot inclusion rate影响的重要性，并呼吁进一步研究来改善市场动态。 <div>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TLDR</h2>
<ul>
<li><strong>Slot inclusion rate</strong>, the number of slots required for a blob to be included in the beacon chain, has a high variance and is higher for some rollups than others.</li>
<li>The current combinatorics of the blob market has an <strong>integer packing problem</strong>. This is a type of combinatorial optimization that generally involves packing objects of different sizes into a finite number of containers or bins.</li>
<li>Data suggests that the integer packing problem is contributing more to higher slot inclusion rates than builder censorship.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>This post offers a fresh perspective on the current design and constraints of the blob market, presenting additional data (<a href="https://blobs.primev.xyz/dashboard" rel="noopener nofollow ugc">from a blob tracking dashboard created at Primev</a>) on slot inclusion concerning reorg risks, and a combinatorial analysis of the blob market design, revealing an integer packing problem.</p>
<p>The key metric in this post is the <strong>slot inclusion rate</strong>. The slot inclusion rate indicates the number of slots required for a blob to be included in the beacon chain,<br />
with a higher rate signifying a longer inclusion time.</p>
<p>Recent research on the blob market <a href="https://ethresear.ch/t/big-blocks-blobs-and-reorgs/19674">[1]</a>, <a href="https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783">[2]</a>, <a href="https://mirror.xyz/preconf.eth/cxUO8pPBfqnqAlzFUzoEUa6sgnr68DRmsNhBWPb2u-c" rel="noopener nofollow ugc">[3]</a> has focused on how larger blobs increase reorg risk due to higher latency. This could incentivize builder censorship to reduce latency by excluding blobs from blocks.</p>
<p>Despite the blob market being under capacity and the base fee remaining at 1 wei, research <a href="https://mirror.xyz/preconf.eth/6lZYL62DR9U14KC7wCC4RHReVdHcBeMy5PKeHVbPq5k" rel="noopener nofollow ugc">[4]</a> shows that rollups like Optimism and Base often have high slot inclusion rates, taking more than five slots to be included. Given the underutilized market, this seems counterintuitive, suggesting possible latency censorship. However, the current blob submission strategies and blob market combinatorics suggest that higher slot inclusion rates may indicate increased competition between blob producers rather than builder censorship.</p>
<h2><a class="anchor" href="https://ethresear.ch#blob-submission-strategies-3" name="blob-submission-strategies-3"></a>Blob Submission Strategies</h2>
<p>The below table <a href="https://analytics.mev-commit.xyz/dashboard" rel="noopener nofollow ugc">from the dashboard</a> shows a 7 day snapshot of the largest blob market participants.</p>
<p>There are now 3 major strategies across the number of blobs:</p>
<ul>
<li>submit the max 5-6 blobs at a time (blast, base, linea, optimism)</li>
<li>submit 3-4 blobs at a time (arbitrum, zksync)</li>
<li>submit 1-2 blobs at a time (taiko, metal, paradex, scroll)<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7e768a0ed198c966965d14171b97d1c2600eea7d.png" title="image"><img alt="image" height="244" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7e768a0ed198c966965d14171b97d1c2600eea7d_2_690x244.png" width="690" /></a></div></li>
</ul>
<p>Aggregating blobs into fewer transactions reduces transaction expenses (base fee, blob fee, priority fee) but increases slot inclusion times. In contrast, smaller blob transactions improve slot inclusion times at the cost of higher transaction expenses.</p>
<h2><a class="anchor" href="https://ethresear.ch#slot-inclusion-rates-4" name="slot-inclusion-rates-4"></a>Slot Inclusion Rates</h2>
<p>The next chart displays a time series overlay of base block demand (total transaction fees and base fee in gwei) with the slot inclusion rate for each blob transaction. It shows high slot inclusion rates, up to 30 slots, even during periods of low blockspace demand.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/832319c888134f3fe0b465411923147c0c85c5fa.png" title="image"><img alt="image" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/8/3/832319c888134f3fe0b465411923147c0c85c5fa_2_690x258.png" width="690" /></a></div><p></p>
<p>The table mentioned earlier above contains the average slot inclusion rate for each rollup. Base, which submits the largest blobs in each transaction has the highest, averaging 13 slots. Taiko has the lowest average at 1.7 slots and submits only single blobs for each transaction right now.</p>
<p><strong>Base slot inclusion rate:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/5/a5f9d2f0d94388d88993444ae9da999347121e7e.png" title="image"><img alt="image" height="300" src="https://ethresear.ch/uploads/default/optimized/3X/a/5/a5f9d2f0d94388d88993444ae9da999347121e7e_2_690x300.png" width="690" /></a></div><p></p>
<p>taiko slot inclusion rate<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/e/ce84eb73e15b668adaa7dc811f23e8c3606000ee.png" title="image"><img alt="image" height="300" src="https://ethresear.ch/uploads/default/optimized/3X/c/e/ce84eb73e15b668adaa7dc811f23e8c3606000ee_2_690x300.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#builder-slot-inclusion-rates-5" name="builder-slot-inclusion-rates-5"></a>Builder Slot Inclusion Rates</h2>
<p>This table examines slot inclusion rates from the builder’s perspective, including the number of blocks, blob transactions, average blob count, and priority fees collected.</p>
<p>A higher slot inclusion rate means a blob has waited longer to be included in a block. An efficiency metric would be to have the lowest possible slot inclusion rate, indicating that builders are including blobs sooner rather than later.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/f/9fe6938327d570742a8b7f278788cacfa4df81ca.png" title="image"><img alt="image" height="211" src="https://ethresear.ch/uploads/default/original/3X/9/f/9fe6938327d570742a8b7f278788cacfa4df81ca.png" width="690" /></a></div><p></p>
<p>Builders like Titan and Beaverbuild have more efficient blob slot inclusion rates than vanilla builders. They also have the lowest average blobs per block. This could be due to their efficiency in accepting strategies like Taiko blobs over other block builders.</p>
<h2><a class="anchor" href="https://ethresear.ch#combinatorics-6" name="combinatorics-6"></a>Combinatorics</h2>
<p><a href="https://colab.research.google.com/drive/1EeRpWjb0meIi53IyyyZu7QWmg8HqVAMr#scrollTo=PDAJADyB24Jv" rel="noopener nofollow ugc">This notebook</a> uses dynamic programming to count the number of combinations of blobs for the current blob market. Given the current 6 blob per block capacity and 6 blobs per block, there are 11 possible combinations.</p>
<p><strong>Occurrences of each number:</strong><br />
1: 19<br />
2: 8<br />
3: 4<br />
4: 2<br />
5: 1<br />
6: 1</p>
<p>A trivial observation is that there is only one combination in which a block can fit 5 or 6 blobs. Since 4 out of 10 rollups submit these 5 and 6 blob transactions, there will only be one winner. Additionally, a single 1-blob transaction can “censor” a 6-blob transaction for an entire slot by being accepted first.</p>
<p>The combinatorics of the current blob market size suggest that the small size itself is causing higher slot inclusion problems, rather than blob censorship latency. This indicates that censorship is not from builders but from competition among blob users.</p>
<p>This raises an important question: what is the optimal maximum number of blobs allowed in a block relative to the maximum number that can fit in a block? Would the combinatorics be more favorable if the maximum blob size were 3 instead of 6? Would it be better to allow 9 blobs per block instead of 8? There is an economic incentive to group blobs as large as possible to save on costs, which disproportionately favors larger rollups over smaller ones until blob sharing becomes feasible.</p>
<h2><a class="anchor" href="https://ethresear.ch#bidding-strategies-7" name="bidding-strategies-7"></a>Bidding Strategies</h2>
<p>Currently, blobs use static bidding strategies, generally resubmitting their blobs if their bids sit in the mempool for too long. This shows a certain level of insensitivity to slot inclusion for each rollup. If a blob is delayed for 100 slots, there seem to be no consequences or incentives to increase slot inclusion rates at this time.</p>
<p>The two charts below show sample bidding strategies used by Base and Taiko, just two examples of the rollup strategies available on the dashboard. Base averages a priority fee of 4.5 gwei, while Taiko averages 2.9 gwei. There is no correlation between priority bids and base fee fluctuations.</p>
<p><strong>base:</strong><br />
<img alt="image" height="336" src="https://ethresear.ch/uploads/default/original/3X/8/7/8785ccb0b147a318d6426a694bf7697d3f1a5383.png" width="501" /></p>
<p><strong>taiko:</strong><br />
<img alt="image" height="336" src="https://ethresear.ch/uploads/default/original/3X/9/1/91bab571ac6836399edf78b7c7ce757ad62cf2ed.png" width="501" /></p>
<p>Resubmitting blobs through the mempool is expensive and generally not recommended as a good practice. This creates the problem of how blob producers can become more competitive in their bidding strategies if they need to make their slot inclusion rates more efficient.</p>
<p>One solution is to use preconfirmations. For example, using a protocol such as mev-commit to attach preconf bids to blob transactions would allow rollups to dynamically adjust their bids without having to resubmit blobs into the mempool. A stronger solution would be <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">to receive preconfirmations from proposers</a> to guarantee that builders wouldn’t be able to censor blobs.</p>
<h3><a class="anchor" href="https://ethresear.ch#conclusion-8" name="conclusion-8"></a>Conclusion</h3>
<p>Analysis of slot inclusion rates and blob market combinatorics reveals a complex interplay between efficient slot inclusion, competition, and potential censorship. While current data suggests that high slot inclusion rates are primarily driven by competition among blob users, there remain several unanswered questions:</p>
<ul>
<li>What is the optimal maximum number of blobs per block to balance efficiency and fairness?</li>
<li>How can blob producers develop more competitive bidding strategies?</li>
<li>Could the implementation of dynamic bidding strategies or preconfirmations significantly reduce slot inclusion times?</li>
<li>What long-term effects might increased competition and potential latency censorship have on the blob market?</li>
</ul>
<p>The combinatorics of the blob market are a fundamental factor affecting slot inclusion efficiency and cost. By understanding and optimizing these combinatorial constraints, it is possible to enhance market dynamics, reduce costs, and improve transaction efficiency for all participants. Further research and experimentation are needed to address these questions and optimize the blob market for all participants.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 16:47:05 +0000</pubDate>
</item>
<item>
<title>A simple, small, mev-boost compatible preconfirmation idea</title>
<link>https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800</link>
<guid>https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-boost、preconfs、proposer、relayer、merging policies

总结:<br />
本文提出了一种扩展MEV-boost以支持预配置交易（preconfs）的机制。该想法保持了现有MEV-boost流程的稳定性，仅改变提案阶段，让提案者在开始投票前提供预配置交易列表。提案者发送包含交易要求的签名JSON对象给中继器，如必须包含或排除的交易。中继器根据合并策略处理这些信息，同时保持传统MEV-boost拍卖的兼容性。尽管存在一些挑战，如中继器的额外计算负担和预配置信息的一致性问题，但作者认为这个设计有助于减少生态系统分裂，且具有渐进式替代MEV-boost的潜力。 <div>
<p><strong>Disclaimer</strong>: This post will not contain any nice images, because I am artistically inept.</p>
<p>The reasons why I’m writing this are the following:</p>
<ol>
<li>Preconfs are a very hot topic right now and many people are working on them;</li>
<li>As usual, some of the proposed solutions advocate for punching changes all the way into the main Ethereum protocol. I’m personally not a fan of this, since life is already full of <em>oh my God, what have I done?™</em> moments and <em>more drama™</em> is the least thing everyone probably needs.</li>
<li>MEV-boost is probably the <em>only</em> thing this community has really almost universally agreed upon since MEV has been a thing. So I’d very much try to preserve backwards-compatibility with MEV-boost and generalize on this than coming up with more innovative ways to balkanize our ecosystem even further.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#a-primer-on-mev-boost-1" name="a-primer-on-mev-boost-1"></a>A primer on MEV-boost</h2>
<p>This section exists just so that everyone is on the same page. Feel free to skip it or to insult me if you think I summarised things stupidly.</p>
<p>In layman terms, MEV-boost works like this:</p>
<ol>
<li>Proposer polls the relayer(s) for their best blocks;</li>
<li>Relayer(s) send their best block headers to proposer;</li>
<li>Proposer picks the best block by comparing the block headers received and the block built in-house.</li>
<li>For an in-house block, proposer just signs and broadcasts. For a mev-boost block, proposer signs the header. Relay will broadcast the complete block revealing the payload.</li>
</ol>
<p>This mechanism is nice because the only party that builders have to trust is relayer: Proposer cannot unbundle blocks and scam builders.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-actual-idea-2" name="the-actual-idea-2"></a>The actual idea</h2>
<p>The idea I have in mind works towards extending mev-boost by allowing for preconfs (and most likely for a lot of other stuff if one wants to). Notably, it does not change points 2,3,4 in the previous section, but only point 1.</p>
<p>Suppose proposer has a stash of preconfed txs on the side. The only thing the idea assumes is the following:</p>
<blockquote>
<p>By the time Proposer starts polling, it needs to have a finalized lists of preconfed txs to include.</p>
</blockquote>
<p>The reason for this will become clear shortly. Having this list at hand, proposer sends a signed JSON object to the relayer when it polls, containing the preconfed txs. This object could look, for instance, like this:</p>
<pre><code class="lang-JSON">{
    proposer: address,
    slotNumber: int,
    gasUsed: int,
    blobsUsed: int.
    mergingPolicy: int,
    mustBeginWith: txBundle,
    mustContain: txBundle,
    mustOmit: txBundle,
    mustEndWith: txBundle,
    otherStuff: JSON,
    signature : signature
}
</code></pre>
<p><strong>This design is just an idea. It is by no means fixed yet and most likely can be improved upon both in conceptual and performance terms, so take it with a grain of salt.</strong><br />
The fields <code>proposer</code> and <code>slotNumber</code> are obvious. The fields <code>mergingPolicy</code>, <code>mustBeginWith</code>, <code>mustContain</code>, <code>mustOmit</code>, <code>mustEndWith</code> can all be empty: They contain bundles of transactions that must (or must not) be included in the block. These fields are, effectively, the ones that proposer can use to signal relayer that 'hey, I need the block to respect these requirements, because of previous agreement I made with other parties."</p>
<p>How the proposer comes to define this json object is not our concern, and is outside of the scope of this idea. Just for the sake of clarity though, let’s consider some examples: For instance, <a href="https://docs.xga.com" rel="noopener nofollow ugc">XGA</a>, one of the projects <code>20[ ]</code> is contributing to, provides preconfs as tokenized bottom-of-block space. As such, XGA-style preconfs will produce objects where only <code>mustEndWith</code> is not empty.</p>
<p>The fields <code>gasUsed</code> and <code>blobsUsed</code> tell the relay how much gas and blobs the ‘preconf space’ already claimed. <code>otherStuff</code> exists to be able to extend this standard in the future without <em>more drama™</em>.</p>
<h3><a class="anchor" href="https://ethresear.ch#merging-policies-3" name="merging-policies-3"></a>Merging policies</h3>
<p>The <code>mergingPolicy</code> fields instructs the relay about how to deal with all this information. This is fundamental because, in the end, the relay will still run a traditional mev-boost auction for the remaining blockspace. As soon as a block is built by more than one party there’s a risk that different parties may step up on each other’s toes. As such, <code>mergingPolicy</code> serves as a well-defined conflict resolution policy. If you need a mental reference, think about git conflicts and automated ways to solve them if you so like.</p>
<p>How to define merging policies is up for debate. The community could agree on a common repository where merging policies are defined, voted and agreed upon, and where merging algos are explicitly provided. So, for instance, one merging policy could be:</p>
<blockquote>
<p>If the payload coming from the builder contains a transaction that also appears in the preconf bundle, deal with it in the following way:</p>
</blockquote>
<p>As said above, XGA sells BOB as preconfs, and leaves TOB open for traditional mev-boost auctions. As such, it has already defined and implemented a merging policy for its bottom of the block case, which will hopefully be open sourced soon.</p>
<h3><a class="anchor" href="https://ethresear.ch#what-does-the-relay-do-4" name="what-does-the-relay-do-4"></a>What does the relay do?</h3>
<p>This is probably already kinda clear at this point, but to make it explicit: The relay receives this signed JSON object when the proposer polls. What should it do with it? First of all, it should make some of these fields public to the builders, such as <code>mergingPolicy</code>, <code>gasUsed</code>, <code>blobsUsed</code> and <code>mustOmit</code>. This way builders will know what they can build.</p>
<p>When a block from a builder is received, the relayer will <strong>unbundle</strong> the block and apply the merging policy to merge it with the preconfed txs. The <strong>relay</strong> will sign the block header, and send it to the proposer.</p>
<p>From the POV of a builder, everything is kinda the same. They create their block using the info provided by the relay (in the simplest case this just means using slightly less gas than limit), and submit it as their bid.</p>
<p>From this point on, everything works as in traditional MEV-boost.</p>
<h2><a class="anchor" href="https://ethresear.ch#analysis-5" name="analysis-5"></a>Analysis</h2>
<p>Ok, so let’s run a rapid analysis of this thing.</p>
<h3><a class="anchor" href="https://ethresear.ch#pros-6" name="pros-6"></a>Pros</h3>
<ol>
<li>
<p>Changes to MEV-boost proper are really minimal. We just need to define an API that MEV-boost must listen to to build the polling payload, and redefine the polling logic.</p>
</li>
<li>
<p>Very little work from Proposer’s side. More work may be needed depending on the preconf system a given proposer wants to use, but then again this is out of the scope of this idea.</p>
</li>
<li>
<p>Very little work from builder’s side unless people go overly crazy with merging policies. I do not think this is necessarily a problem tho as an overly deranged merging policy would result in builders not submitting anything, and most likely in relayers not taking bets in the first place. So I’d bet that this could pretty much evolve as a ‘let the markets decide’ thing.</p>
</li>
<li>
<p>This idea is straightforwardly backwads-compatible with traditional MEV-boost: If the polling payload is empty, we collapse to a traditional MEV-boost auction with no other requisites.</p>
</li>
<li>
<p>This idea allows for gradual phasing out of MEV-boost if the community so decides. For instance, proposers may agree to produce bundles where <code>usedGas</code> is a very low parameter in the beginning (it won’t exceed 5M for XGA, for instance), meaning that the majority of blockspace would come from traditional building, with only a tiny part being preconfs or more generally ‘other stuff’. This parameter may then be increasingly crancked up or varied with time if the community so decides, effectively phasing out traditional block building in favor of ‘something else’. In this respect yes, I know I’m being vague here but when it comes to how this thing could be adopted I can only speculate.</p>
</li>
<li>
<p>This system can be extended in many ways, and it is flexible. Merging policies could be defined democratically, and the polling info could be extended effectively implementing something akin to PEPSI, for instance. Another possible extension/evolution can be using <code>otherStuff</code> to define Jito-style auctions. I mean, there’s really a plethora of ways to go from here.</p>
</li>
<li>
<p>The polling payload is signed by the proposer, and the block header is signed by the relayer. This keeps both parties in check as we accumulate evidence for slashing both. For instance:</p>
<ul>
<li>Imagine I get some preconf guarantee from proposer and that I have evidence of this. Again how this happens is outside of the scope of this post, as this mechanism is agnostic wrt how preconfs are negotiated.</li>
<li>Now suppose furthermore than my preconfed tx does <strong>not</strong> land in the block.</li>
<li>I can use the chain of signed objects to challenge both relayer and proposer. If my tx wasn’t in the polling info signed by proposer, that’s proposer’s fault. On the other hand, if it was, but it wasn’t in the block, then it’s relayer’s fault. I think this is enough to build a slashing mechanism of sorts, which could for instance leverage some already available restaking solution.</li>
</ul>
<p><strong>Note:</strong> If there’s enough interest in this idea, we as 20[  ] can throw some open games at it and simulate the various scenarios. Let me know!</p>
</li>
<li>
<p><strong>Ethereum protocol doesn’t see any of this.</strong> So if it fucks up, we just call it a day and retire in good order without having caused the apocalypse: Relays will only accept empty payloads, proposers will only send empty payloads, and we’ll essentially revert to mev-boost without anyone having to downgrade their infra. I think this is the main selling point of this idea: The amount of ways to make stuff explode in mev-related infraland are countless, so this whole idea was built with a ‘it has to be failsafe’ idea in mind.</p>
</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#cons-7" name="cons-7"></a>Cons</h3>
<ol>
<li>
<p>Relayer must unbundle builder blocks to do the merging. I do not think this creates a huge trust issue as relayer can already do this as of now: In general, a relayer that scams builders is a relayer that won’t be used again, and will go out of business quickly.</p>
</li>
<li>
<p>Relayer must do computational work. This is probably the major pain point. This idea entails slightly more latency, as an incoming bid cannot be relayed instantly because <code>mergingPolicy</code> has to be applied. The computational penalty is furthermore heavily dependent on how deranged the merging policy is. As a silver lining, this computational work is <em>provable</em> as both the merging info and the resulting block are signed. The result is that we have <strong>provable evidence to remunerate a relay for its work if we want to</strong>, possibly solving a major pain point for relayers in traditional mev-boost.</p>
</li>
<li>
<p>Relayer is slashable if it screws up. Again, how this should be implemented is outside of the scope of this idea as this mechanism only accounts for the needed trail of evidence to implement slashing, but does not deal with the slashing per sé. Anyway, it is still worth reasoning on the possible consequences of this: If slashing policies are implemented, Relayers will most likely need to provide some collateral or implement some form of captive insurance. Again, this may signify more complexity on one hand but also opportunity on the other, as relayers may for instance decide to tokenize said collateral and develop mechanisms to make money out of these newly created financial instruments. As relayers are private enterprises I’ll leave these considerations to the interested parties.</p>
</li>
<li>
<p><strong>Polling info must stay fixed</strong>. This is related to point 3 above and point 6 of the <a href="https://ethresear.ch#pros">Pros</a> subsection: If the polling info changes all the time, this means huge computational stress for the relayer, and it furthermore allows for malicious behavior from the proposer: For instance, a proposer could send two different polling payloads, and include a given preconfed tx only in one of them. How to resolve these inconsistencies is an open question. In my opinion, the wisest and simplest thing to do would be requiring the polling info to be fixed, meaning that if proposer signs conflicting payloads for the same slot this should be considered akin to equivocation, and thus a slashable offence.</p>
<p>By the way, the consequence of this is that the idea proposed here necessarily excludes some preconf use cases. This is related to my comment <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695/2">here</a> and I think it is unavoidable if we want to keep MEV-boost around. As the majority  of revenue from MEV comes precisely from the bids of very refined, high-time frame searchers, and as I am quite sure that validators don’t want to give this money up at least for now, ‘leaving these players be’ by ruling out such preconf use-cases is in my opinion the most practical option, and exactly the rationale motivating this idea.</p>
</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#closing-remarks-8" name="closing-remarks-8"></a>Closing remarks</h2>
<p>That’s it. If the idea is interesting enough let me know, I’ll be happy to start a discussion around it.  The <code>20[ ]</code> team will also be around at EthCC if you want to discuss this in person.</p>
            <p><small>8 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 13:33:55 +0000</pubDate>
</item>
<item>
<title>One-bit-per-attester inclusion lists</title>
<link>https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797</link>
<guid>https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797</guid>
<content:encoded><![CDATA[
<div> 关键词：Inclusion lists, transaction selection, RANDAO_REVEAL, Reed-Solomon decoding, fork choice rule.

总结:
本文提出了一种新的机制，用于在区块链中实现更去中心化的交易入选列表（Inclusion lists）。机制的核心是利用RANDAO_REVEAL生成随机种子，将验证者分为小组，每个小组负责查找优先级高、费用支付的交易，并通过Erasure编码提供与种子相关联的交易部分。如果多数验证者诚实，Reed-Solomon解码可以确定交易；否则，可能需要使用更复杂的方法恢复交易。验证者的选择和交易的入选受制于区块生产者的决定，但通过调整时间权重和fork choice规则，可以增加对长期未被选中的交易的包容性。这种机制旨在减少集中化风险，提高去中心化程度。 <div>
<p>Inclusion lists are a technology for distributing the authority for choosing which transactions to include into the next block. Currently, the best idea for them is to have an actor that is from a set that is likely to be highly decentralized (eg. consensus block proposers) generate the list. This authority is decoupled from the right to <em>order</em> (or <em>prepend</em>) transactions, which is an inherently economies-of-scale-demanding and so likely to be highly concentrated in practice.</p>
<p>But what if we could avoid putting the responsibility onto a <em>single</em> actor, and instead put it on a <em>large set of actors</em>? In fact, we can even do it in such a way that it’s semi-deniable: from each attester’s contribution, there is no clear evidence of which transaction they included, because one individual piece of provided data could come from multiple possible transactions.</p>
<p>This post proposes a possible way to do this.</p>
<h3><a class="anchor" href="https://ethresear.ch#mechanism-1" name="mechanism-1"></a>Mechanism</h3>
<p>When the block for slot N is published, let <code>seed</code> be the RANDAO_REVEAL of the block. Suppose for convenience that each transaction is under <code>T</code> bytes (eg. <code>T = 500</code>); we can say in this initial proposal that larger transactions are not supported. We put all attesters for that slot into groups of size <code>2 * T</code>, with <code>k = attesters_per_slot / (2 * T)</code> groups.</p>
<p>Each attester is chosen to be the j’th attester of the i’th group. They identify the highest-priority-fee-paying valid transaction which was published before the slot N block, and where <code>hash(seed + tx)</code> is between <code>2**256 / k * i</code> and <code>2**256 / k * (i+1)</code>. They erasure-code that transaction to <code>2T</code> bits, and publish the j’th bit of the erasure encoding as part of their attestation.</p>
<p>When those attestations are included in the next block, an algorithm such as <a href="https://en.wikipedia.org/wiki/Berlekamp%E2%80%93Welch_algorithm">Berlekamp-Welch</a> is used to try to extract the transaction from the provided attester bits.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/e/deedccb04e5bb133ccacdbe2c2c17d1e5abdc3ce.png" title="attester_inclusion_list.drawio"><img alt="attester_inclusion_list.drawio" height="271" src="https://ethresear.ch/uploads/default/optimized/3X/d/e/deedccb04e5bb133ccacdbe2c2c17d1e5abdc3ce_2_690x271.png" width="690" /></a></div><p></p>
<p>The Reed-Solomon decoding will fail in two cases:</p>
<ol>
<li>If too many attesters are dishonest</li>
<li>If attesters have different views about whether a particular transaction was published before or after the block, and so they are split between providing bits for two or more different transactions.</li>
</ol>
<p>Note that in case (2), if the transactions are sufficiently small, advanced <a href="https://www.cs.cmu.edu/~venkatg/teaching/codingtheory/notes/notes10.pdf">list decoding algorithms</a> may nevertheless be able to recover several or all of the transactions!</p>
<p>The next block proposer will be able to see which transactions the attestations imply, and so they will be able to block transactions from the list by selectively failing to include attestations. This is an unavoidable limitation of the scheme, though it can be mitigated by having a fork choice rule discount blocks that fail to include enough attestations.</p>
<p>Additionally, the mechanism can be modified so that if a transaction has not been included for 2+ slots, <em>all</em> attesters (or a large fraction thereof) attempt to include it, and so any block that fails to include the transaction would lose the fork choice. One simple way to do this is to score transactions not by <code>priority_fee</code>, but by <code>priority_fee * time_seen</code>, and at the same time have a rule that a transaction that has been seen for <code>k</code> slots is a candidate not just for attester group <code>i</code>, but also for attester group <code>i...i+k-1</code> (wrapping around if needed).</p>
            <p><small>8 posts - 7 participants</small></p>
            <p><a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 09:33:36 +0000</pubDate>
</item>
<item>
<title>Torrents and EIP-4444</title>
<link>https://ethresear.ch/t/torrents-and-eip-4444/19788</link>
<guid>https://ethresear.ch/t/torrents-and-eip-4444/19788</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP-4444、Torrents、Ethereum、Pre-merge data、Merkle roots

总结:
EIP-4444目标是减少以太坊节点所需存储的历史数据。文章介绍了使用BitTorrent技术来分发历史数据的方法，通过在geth v1.14.3版本上创建era文件并验证根文件（roots.txt）来实现。这个过程产生了427GB的torrent文件，用于同步pre-merge数据。虽然torrent有依赖多个活跃节点和增加节点网络需求的缺点，但它提供了一种可能的解决方案。客户端可以选择不预下载数据，用户可以通过命令行或特定标志获取。要重现或验证torrent，需同步geth节点、执行era文件导出和创建torrent，以及使用era工具验证数据完整性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#torrents-and-eip-4444-1" name="torrents-and-eip-4444-1"></a>Torrents and EIP-4444</h1>
<h3><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h3>
<p>EIP-4444 aims to limit the historical data that Ethereum nodes need to store. This EIP has two main problems that require solutions: Format for history archival and Methods to reliably retrieve history. The client teams have agreed on a common <a href="https://ethresear.ch/t/era-archival-files-for-block-and-consensus-data/13526">era files</a> format, solving one half of the problem. The second half of the problem, i.e Method to reliably retrieve history will likely not rely on a single solution. Some client teams may rely on the <a href="https://ethereum.org/en/developers/docs/networking-layer/portal-network/" rel="noopener nofollow ugc">Portal network</a>, some rely on torrents, others might rely on some form of snapshot storage.</p>
<h3><a class="anchor" href="https://ethresear.ch#torrents-for-eip-4444-3" name="torrents-for-eip-4444-3"></a>Torrents for EIP-4444</h3>
<p>Torrents offer us a unique way to distribute this history, torrents as a technology have existed since 2001 and have withstood the test of time. Some client teams, such as <a href="https://github.com/ledgerwatch/erigon" rel="noopener nofollow ugc">Erigon</a> already include a method to sync via torrents that has run in production systems.</p>
<p>In order to make some progress on the Torrent approach of history retrieval, the files would first be required. So an era file export was made on a <a href="https://github.com/ethereum/go-ethereum/" rel="noopener nofollow ugc">geth</a> running version <code>v1.14.3</code> . To explore the initial idea, the torrent approach chose pre-merge data as a target. The merge occurred at block height <a href="https://etherscan.io/block/15537393" rel="noopener nofollow ugc">15537393</a>, meaning all pre-merge data could be archived by choosing a range of 0 to block 15537393. The era files were then created using the command <code> geth --datadir=/data export-history /data/erafiles 0 15537393</code>.</p>
<p>Once the era files were created, they were verified using the command <code>era verify roots.txt</code>, with the source of the <code>roots.txt</code> file being <a href="https://gist.githubusercontent.com/lightclient/528b95ffe434ac7dcbca57bff6dd5bd1/raw/fd660cfedb65cd8f133b510c442287dc8a71660f/roots.txt" rel="noopener nofollow ugc">this</a>. The entire process has been outlined in <a href="https://github.com/ethereum/go-ethereum/pull/26621#issuecomment-1434023464" rel="noopener nofollow ugc">this PR comment</a>. The verification output was found to be this log message: <code>Verifying Era1 files             verified=1896,  elapsed=5h21m49.184s</code></p>
<p>The output era files were then uploaded onto a server and a torrent was created using the software <code>mktorrent</code>. An updated list of trackers was found using the github repo <a href="https://github.com/ngosang/trackerslist" rel="noopener nofollow ugc">trackerslist</a>. The trackers chosen were a mix of http/https/udp in order to allow for maximal compatibility. The chunk size of the torrent was chosen to be 64MB, which was the max allowed and recommended value for a torrent of this size.</p>
<p>The result of this process is now a torrent of size 427GB. This torrent can be imported with <a href="https://ethresear.ch">this magnet link</a>  and a torrent client would be able to pull the entire pre-merge history as era files.</p>
<h4><a class="anchor" href="https://ethresear.ch#tradeoffs-4" name="tradeoffs-4"></a>Tradeoffs</h4>
<p>There are of course some tradeoffs with torrents, as with many of the other EIP-4444 approaches:</p>
<ul>
<li>Torrents rely on a robust set of peers to share the data, there is however no way to incentivise or ensure that this data is served by peers</li>
<li>A torrent client would need to be included in the client releases and some client languages might not have a torrent library</li>
<li>Torrents would de-facto expect the nodes to also seed the content they leech, this would increase node network requirements if they choose to store history</li>
<li>The JSON-RPC response needs to take into account that it may not have the data to return a response in case the user decides to not download pre-merge data</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#conclusion-5" name="conclusion-5"></a>Conclusion</h3>
<p>A client could potentially include this torrent into their releases and avoid syncing pre-merge data by default, which could then be fetched via torrent if a user requests it (perhaps with a flag similar to <code>--preMergeData=True</code>). The client could also hardcode the hash of the expected data, ensuring that the data retrieved matches what they expect.</p>
<h3><a class="anchor" href="https://ethresear.ch#instructions-for-re-creating-torrent-6" name="instructions-for-re-creating-torrent-6"></a>Instructions for re-creating torrent:</h3>
<ul>
<li>Sync a geth node using the latest release</li>
<li>Stop the geth node and run <code>geth --datadir=/data export-history /data/erafiles 0 15537393</code> to export the data in a folder called <code>data/erafiles</code>(Warning, this will use ~427GB of additional space)</li>
<li>Use the <code>mktorrent</code> tool or the <code>rutorrent</code> GUI to create a torrent. Choose the <code>/data/erafiles/</code> folder as the source for the data. Next, obtain the latest open trackers from <a href="https://github.com/ngosang/trackerslist?tab=readme-ov-file" rel="noopener nofollow ugc">this github repository</a>. Choose a healthy mix of udp/http/https trackers and choose the chunk size of the torrent to be 64MB.</li>
<li>The tool should output a <code>.torrent</code> file, the GUI will also allow you to copy a magnet link if that is required</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#instructions-for-download-and-verification-of-torrent-data-7" name="instructions-for-download-and-verification-of-torrent-data-7"></a>Instructions for download and verification of torrent data:</h3>
<ul>
<li>Download the torrent data with this magnet link and in a torrent client of your choice: <a href="https://ethresear.ch">link</a></li>
<li>Clone the latest release of <a href="https://github.com/ethereum/go-ethereum/" rel="noopener nofollow ugc">geth</a> and install the dependencies</li>
<li>Run <code>make all</code> in the geth repository to build the <code>era</code> binary</li>
<li>Fetch the <code>roots.txt</code> file with the command: <code>wget https://gist.githubusercontent.com/lightclient/528b95ffe434ac7dcbca57bff6dd5bd1/raw/fd660cfedb65cd8f133b510c442287dc8a71660f/roots.txt</code></li>
<li>Run <code>era verify roots.txt</code> in the folder to verify the integrity of the data</li>
</ul>
            <p><small>15 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/torrents-and-eip-4444/19788">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 09:35:32 +0000</pubDate>
</item>
<item>
<title>Blobs, Reorgs, and the Role of MEV-Boost</title>
<link>https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783</link>
<guid>https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783</guid>
<content:encoded><![CDATA[
<div> 关键词：blobs、MEV-Boost、reorgs、latency、block propagation

总结:
这篇文章探讨了区块中的大对象（blobs）对以太坊网络延迟和重组（reorgs）的影响，特别是与MEV-Boost（矿工提取价值优化）相关的生态系统。非MEV-Boost用户平均包含更多blobs，导致他们区块被重组的概率较高。MEV-Boost用户由于其低延迟连接和专业性，区块被重组的可能性显著较低。研究还指出不同构建者和中继器可能采用策略来处理blobs，比如Rsync-Builder和Flashbots的平均blob数量较少。未来的研究将关注节点能力的提升和减少非MEV-Boost用户的重组率。随着blob市场的发展，其交易提示可能会追平常规交易。 <div>
<h1><a class="anchor" href="https://ethresear.ch#blobs-reorgs-and-the-role-of-mev-boost-1" name="blobs-reorgs-and-the-role-of-mev-boost-1"></a>Blobs, Reorgs, and the Role of MEV-Boost</h1>
<p><strong>The TL;DR is:</strong></p>
<ul>
<li><strong>Builders</strong> might have an incentive to not include blobs because of the higher latency they cause.</li>
<li><strong>Non-MEV-Boost users</strong> include, on average, more blobs in blocks than MEV-Boost builders.</li>
<li><strong>MEV-Boost users</strong> show a significantly lower probability of being reorged than <em>Non-MEV-Boost</em> users (see section <em>MEV-Boost and Reorgs</em> for details).</li>
<li><strong>Rsync-Builder</strong> and <strong>Flashbots</strong> have a lower average number of blobs per block than other builders.</li>
</ul>
<hr />
<p>In a <a href="https://ethresear.ch/t/big-blocks-blobs-and-reorgs/19674">recent analysis on big blocks, blobs and reorgs</a>, we could see the impact of blobs on the reorg probability.</p>
<p><strong>In the following, I want to expand on this by taking the MEV-Boost ecosystem into account.</strong></p>
<p><strong>The fundamental question is…</strong><br />
-&gt; <strong>“<em>Does MEV-Boost impact reorgs, and if so, by how much?</em>”</strong></p>
<p>Blobs are “<em>big</em>” and big objects cause higher latency. Thus, one might expect builders to not include blobs into their blocks in scenarios in which:</p>
<ul>
<li>The builder is submitting its block late in the slot to minimize latency (see timing games).</li>
<li>The builder wants to capture a high MEV opportunity and doesn’t want to risk unavailable blobs invalidating its block.</li>
<li>The proposer is less well connected (because the gossiping starts later in the slot).</li>
</ul>
<p><strong>Builders</strong> might demand to be <strong>compensated</strong> through priority fees for including transactions which might cause blocks to be propagated with higher latency. Until 4844, such transactions have been those with a lot of calldata. As of 4844, blobs are the main drivers of latency.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/d/8db1993891d52c3c8be9d7c6adde8633810ad15b.png" title="tx_type_prio_fee_all (2)"><img alt="tx_type_prio_fee_all (2)" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/8/d/8db1993891d52c3c8be9d7c6adde8633810ad15b_2_690x345.png" width="690" /></a></div><p></p>
<p><strong>As visible in the above chart, blob transactions don’t tip as much as regular Type-2 transactions.</strong><br />
Based on that, blobs don’t give builders a significant edge over other builders competing for the same slot.<br />
Another explanation could be private deals between builders and rollups to secure timely inclusion of blob transactions for a fee paid through side channels.</p>
<h2><a class="anchor" href="https://ethresear.ch#mev-boost-and-reorgs-2" name="mev-boost-and-reorgs-2"></a>MEV-Boost and Reorgs</h2>
<p>The MEV-Boost ecosystem consists of sophisticated parties, <strong>builders</strong> and <strong>relays</strong>, that are well connected and specialized in having low-latency connections to peers.<br />
Thus, it is expected that proposers using MEV-Boost should be reorged less often than ‘Vanilla Builders’ (i.e., users not using MEV-Boost).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/5/859fee3890096d24a955abd65642fee08ebd141c.png" title="reorgs_mevb_over_blobs (3)"><img alt="reorgs_mevb_over_blobs (3)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/8/5/859fee3890096d24a955abd65642fee08ebd141c_2_690x258.png" width="690" /></a></div><p></p>
<p>This expectation holds true when looking at the above chart.<br />
<strong>We can see that the reorg probability increases with the number of blobs. However, the reorg probability for MEV-Boost users is much lower than the one for Non-MEV-Boost users (Vanilla Builders).</strong></p>
<p><strong>In this context it’s important to not confuse correlation and causation:<br />
-&gt; <em>Non-MEV-Boost users are on average less sophisticated entities which also contributes to the effect we observe in the above chart.</em></strong></p>
<p>In this context it is interesting to compare the <strong>average number of blobs per block</strong> of MEV-Boost users vs. Non-MEV-Boost users.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/c/3cbac65d110bbf6d535ba55d7dfb62f69206a271.png" title="blobs_over_time (3)"><img alt="blobs_over_time (3)" height="373" src="https://ethresear.ch/uploads/default/optimized/3X/3/c/3cbac65d110bbf6d535ba55d7dfb62f69206a271_2_690x373.png" width="690" /></a></div><p></p>
<p><strong>As visible in the above chart, proposers not using MEV-Boost included on average more blobs into their blocks than MEV-Boost users.</strong><br />
This might point towards MEV-Boost ecosystem participants (relays and builders) applying strategies that go beyond the “<em>include it if there’s space</em>” strategy.</p>
<p><strong>First, let’s look at the builders more closely.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4bf0a4fe8bc95e88d122c479fe88cf4f32883fbf.png" title="blobs_over_time_builder (4)"><img alt="blobs_over_time_builder (4)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4bf0a4fe8bc95e88d122c479fe88cf4f32883fbf_2_690x258.png" width="690" /></a></div><p></p>
<p>Vanilla Builders (Non-MEV-Boost proposers) are the ones that have the highest blob inclusion rate, followed by Beaverbuild and Titan Builder.</p>
<p>Rsync-Builder seems to include way less blobs in their blocks.<br />
The same applies to the Flashbots builder that seems to have changed its behavior in early May, with the average number of blobs per block approaching zero.</p>
<p><strong>“Is it fair to say 'Builder XY censors blobs!?”</strong><br />
&gt; <strong>No</strong></p>
<blockquote>
<p><em>Different builders follow different strategies. For example a builder such as Rsync-Builder that is generally competitive in slots where low latency and speed matters might end up with winning those blocks where there are no blobs around (c.f. <em>selection bias</em>)</em></p>
</blockquote>
<br />
<p><strong>Next, let’s shift the focus to the relays:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/7/374ff432477462e6a307a3d83c7da899f3a5b541.png" title="blobs_over_time_relays (4)"><img alt="blobs_over_time_relays (4)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/3/7/374ff432477462e6a307a3d83c7da899f3a5b541_2_690x258.png" width="690" /></a></div><p></p>
<p>As visible above, Vanilla Builders have on average the highest blob inclusion rate.<br />
The Ultrasound and Agnostic Gnosis relays are second and third, followed by the relays of BloXroute.<br />
The Flashbots relay seems to include the lowest number of blobs.</p>
<p><strong>Importantly, relays are dependent on builders and ultimately it’s the builders that impact the above graph.</strong></p>
<h2><a class="anchor" href="https://ethresear.ch#next-steps-3" name="next-steps-3"></a>Next Steps</h2>
<p>In the context of <a href="https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541">PeerDAS</a>, the network will have to rely on nodes that are <em>stronger</em> than others and able to handle way more than 6 blobs per block. Therefore, it’d be super valuable to see more research on that topic happening.</p>
<ul>
<li><strong>Call for reproduction</strong>: It’d be great if someone could verify my results by reproducing this analysis.</li>
<li><strong>Investigate the reasons</strong> why certain builders have a significantly lower blob inclusion rate than others.</li>
<li><strong>Reduce reorg rate for Non-MEV-Boost users</strong>: Relays could offer Non-MEV-Boost users their block propagation services to ensure that fewer of their blocks get reorged.</li>
</ul>
<p>The blob market is still under development and a stable blob price is yet to be discovered. With increasing demand for blob space, tips from blob transaction will likely catch up to regular transactions.</p>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 15:46:12 +0000</pubDate>
</item>
<item>
<title>Block Proposing &amp; Validating Timelines for 1.) MEV-Boost, 2.) ePBS, and 3.) ePBS with MEV-Boost</title>
<link>https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782</link>
<guid>https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Boost、ePBS、block release time、validation time、propagation time

总结:<br />
MEV-Boost与ePBS比较的关键点在于验证时间和块释放时间。MEV-Boost中，由于额外的步骤（如提案者获取头和执行块），导致整体释放时间较长（RT^{mevboost}）。相比之下，ePBS通过共识层和执行层的并行处理，减少了验证时间，特别是对于执行块（VT^{EL} 和 SPT）。验证共识块时，ePBS的条件更为宽松（RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL}），而MEV-Boost可能导致因SPT和VT^{EL}的额外延迟而产生重新排序（reorgs）。因此，使用MEV-Boost进行ePBS会比纯ePBS更慢。 <div>
<p>This writeup summarizes the timeline differences between ePBS and MEV-Boost using inequalities. We analyze three models: 1) MEV-Boost, 2) ePBS, and 3) MEV-Boost with relayers on ePBS. We show that MEV-Boost with relayers on ePBS is slower than ePBS alone, which could lead to reorgs.</p>
<h2><a class="anchor" href="https://ethresear.ch#definitions-1" name="definitions-1"></a>Definitions</h2>
<p><span class="math">VT^{CL}</span>: Consensus layer validation time. The time taken by a node to verify the consensus portion of a block.<br />
<span class="math">VT^{EL}</span>: Execution layer validation time. The time taken by a node to verify the execution portion of a block.<br />
<span class="math">RT^{mevboost}</span>: Mev-boost block release time. The time when a block is released from a node or relayer, assuming the MEV-boost setting.<br />
<span class="math">RT^{epbs,cl}</span>: ePBS consensus block release time. The time when a consensus block is released from a node or relayer, assuming the ePBS setting.<br />
<span class="math">RT^{epbs,el}</span>: ePBS execution block release time. The time when an execution block is released from a node or relayer, assuming the ePBS setting.<br />
<span class="math">PT^{mevboost}</span>: Mev-boost block propagation time. The time taken for a block to propagate across the network, assuming the mev-boost setting.<br />
<span class="math">PT^{epbs,cl}</span>: ePBS consensus block propagation time. The time taken for a consensus block to propagate across the network, assuming ePBS setting.<br />
<span class="math">PT^{epbs,el}</span>: ePBS execution block propagation time. The time taken for an execution block to propagate across the network, assuming ePBS setting.<br />
<span class="math">Attestation\_RT^{beacon}</span>: Beacon attestation release time. The time when a beacon attestation is released from a node.<br />
<span class="math">Attestation\_RT^{ptc}</span>: PTC attestation release time. The time when a payload attestation is released from a node, assuming the ePBS setting.<br />
<span class="math">BBT</span>: Proposer build block time. The time taken for a proposer to build consensus portion of a block.<br />
<span class="math">GHT</span>: Proposer get header time. The time taken for a proposer to obtain a header from a relayer (MEV-boost) or builder (ePBS).<br />
<span class="math">GPT</span>: Proposer get payload time. The time a proposer takes to obtain a payload from a relayer (MEV-boost).<br />
<span class="math">SPT</span>: Builder submit payload time. The time taken for a relayer to receive a payload from the builder (MEV-boost).<br />
<span class="math">SBBT</span>: Proposer submit blind block time. The time a proposer takes to submit blind block to the relayer (MEV-boost).</p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-a-mev-boost-block-2" name="proposing-a-mev-boost-block-2"></a>Proposing a mev-boost block</h2>
<p>In Mev-Boost, proposing a block involves two parts. First, the builder sends the block to the relayer. Second, the proposer requests the header and returns the signed block to the relayer. We break down the time it takes in the following subsections, starting with the non-optimistic relayer and then the optimistic relayer. We also assume that everything starts at the 0-second mark of the slot, including the builder sending the execution block to the relayer.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-optimistic-relayer-3" name="non-optimistic-relayer-3"></a>Non optimistic relayer</h3>
<p><span class="math">BRT</span> defines builder to relayer time. This is how much time takes for a builder to submit a block (ie bid) to the relayer and the relayer verifies the block is valid.<br />
<span class="math">BRT = SPT + VT^{EL}</span></p>
<p><span class="math">PRT</span> defines proposer to relayer time. This is how much time takes for a proposer to build block, request header, request payload, and submit blind block.<br />
<span class="math">PRT = BBT + GHT + GPT + SBBT</span></p>
<p><span class="math">RT^{mevboost} = BRT + PRT</span></p>
<p>This assumes everything happens after the slot start because bids become more valuable. Another model is to assume <span class="math">BRT</span> happens before the slot. Then <span class="math">RT^{mevboost} = PRT</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#optimistic-relayer-4" name="optimistic-relayer-4"></a>Optimistic relayer</h3>
<h4><a class="anchor" href="https://ethresear.ch#relayer-receives-builder-block-time-5" name="relayer-receives-builder-block-time-5"></a>Relayer receives builder block time</h4>
<p><span class="math">BRT = SPT</span></p>
<p><span class="math">PRT</span> is the same as before</p>
<p><span class="math">RT^{mevboost} = BRT + PRT</span></p>
<blockquote>
<p>Using optimistic relayer is faster than non-optimistic relayer by: <span class="math">VT^{EL}</span></p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#validating-a-mev-boost-block-6" name="validating-a-mev-boost-block-6"></a>Validating a mev-boost block</h2>
<p>In MEV-Boost, the block must be processed before <span class="math">Attestation\_RT^{beacon}</span> to be considered canonical. The following equation shows the conditions that need to be met for the block to be considered canonical from the perspective of all nodes.</p>
<p>For a beacon block to be canonical, it should satisfy:<br />
<span class="math">RT^{mevboost} + PT^{mevboost} + VT^{CL} + VT^{EL} &lt; Attestation\_RT^{beacon}</span></p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-an-epbs-block-7" name="proposing-an-epbs-block-7"></a>Proposing an ePBS block</h2>
<p>In ePBS, proposing the consensus block and the execution block are pipelined, where the consensus block commits to the execution block’s header. Block release time becomes two parts 1.) CL block release time and 2.) EL block release time.</p>
<h3><a class="anchor" href="https://ethresear.ch#proposing-the-consensus-block-8" name="proposing-the-consensus-block-8"></a>Proposing the consensus block</h3>
<p>We assume the proposer uses the builder’s RPC to get the header. The proposer could also self-build or use P2P to obtain the header, which is arguably faster. Therefore, there is no need for proposer get header time anymore.</p>
<p><span class="math">RT^{epbs,cl} = GHT + BBT</span></p>
<blockquote>
<p>Using ePBS is faster than mev-boost by: <span class="math">SPT+VT^{EL}+GPT + SBBT</span></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#proposing-the-execution-block-9" name="proposing-the-execution-block-9"></a>Proposing the execution block</h3>
<p><span class="math">RT^{epbs,el}</span> is when fork choice accumulates sufficient weight (~40%) or 6 seconds into the slot. The builder could propose a “withhold” block to try to reorg consensus layer block so builder does not have to pay the proposer.</p>
<h2><a class="anchor" href="https://ethresear.ch#validating-an-epbs-block-10" name="validating-an-epbs-block-10"></a>Validating an ePBS block</h2>
<p>In ePBS, validating the consensus block and the execution block are pipelined in different stages. The beacon attestation cutoff time has been moved from 4 seconds into the slot to 3 seconds into the slot. However, we can assume that the CL block propagation time is shorter than the block propagation time. EL block validation can be delayed until the subsequent slot, as shown in the equations.</p>
<h3><a class="anchor" href="https://ethresear.ch#validating-the-consensus-block-11" name="validating-the-consensus-block-11"></a>Validating the consensus block</h3>
<p><span class="math">PT^{epbs,cl} &lt; PT^{mevboost}</span><br />
<span class="math">Attestation\_RT^{beacon,epbs} &lt; Attestation\_RT^{beacon,mevboost}</span></p>
<p>For a consensus block to be canonical, it should satisfy:<br />
<span class="math">RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL} &lt; Attestation\_RT^{beacon}</span></p>
<blockquote>
<p>Using ePBS is faster than mev-boost by: <span class="math">PT^{mevboost}-PT^{epbs,cl}+VT^{EL}</span></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#validating-the-execution-block-12" name="validating-the-execution-block-12"></a>Validating the execution block</h3>
<h4><a class="anchor" href="https://ethresear.ch#as-a-ptc-voting-for-execution-blocks-presence-13" name="as-a-ptc-voting-for-execution-blocks-presence-13"></a>As a PTC voting for execution block’s presence</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} &lt; Attestation\_RT^{ptc}</span></p>
<h4><a class="anchor" href="https://ethresear.ch#as-a-proposer-proposing-the-next-slots-consensus-block-14" name="as-a-proposer-proposing-the-next-slots-consensus-block-14"></a>As a proposer proposing the next slot’s consensus block</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} + VT^{EL} &lt; Next\_Slot\_Start\_Time</span></p>
<h4><a class="anchor" href="https://ethresear.ch#everyone-else-15" name="everyone-else-15"></a>Everyone else</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} + VT^{EL} &lt; Next\_Slot\_Attestation\_RT^{beacon}</span></p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-an-epbs-block-using-mev-boost-16" name="proposing-an-epbs-block-using-mev-boost-16"></a>Proposing an ePBS block using mev-boost</h2>
<p><span class="math">BRT = SPT + VT^{EL}</span><br />
<span class="math">PRT = BBT + GHT</span><br />
<span class="math">RT^{epbs,cl} = BRT + PRT</span></p>
<blockquote>
<p>Using MEV-Boost for ePBS is slower than ePBS by: <span class="math">SPT + VT^{EL}</span><br />
The additional latency occurs because the trusted party must receive and verify the execution block before releasing it to the proposer.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#validating-the-consensus-block-17" name="validating-the-consensus-block-17"></a>Validating the consensus block</h2>
<p><span class="math">RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL} &lt; Attestation\_RT^{beacon}</span></p>
<blockquote>
<p>Given <span class="math">Attestation\_RT^{beacon}</span> is shorter than ePBS, an extra <span class="math">SPT + VT^{EL}</span> could lead to additional reorgs.</p>
</blockquote>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 13:52:44 +0000</pubDate>
</item>
<item>
<title>SGX as 2FA for FHE/MPC</title>
<link>https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780</link>
<guid>https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780</guid>
<content:encoded><![CDATA[
<div> 关键词：SGX、MPC、FHE、Trusted Execution Environment (TEE)、Collusion Risk

总结:
本文探讨了如何利用SGX（安全多方计算）作为FHE（全同态加密）项目的双重身份验证（2FA），特别是在MPC（多方计算）加密管理中增强安全性。文章指出，FHE项目的关键瓶颈在于MPC节点的密钥管理，而将MPC运行在SGX中可以防止节点间的串通风险。SGX作为2FA的优势包括提高安全性、减少信任依赖、保持低延迟和易于扩展。然而，SGX也有其问题，如声誉不佳、可能的误报安全以及缺乏链上远程证明。尽管如此，随着相关项目的发展，如Phala的进展，SGX在隐私保护技术中的应用前景值得关注。 <div>
<p><em>About me: I am <a href="https://x.com/tolak_eth" rel="noopener nofollow ugc">Wenfeng Wang</a>, a builder and researcher at Phala Network, put this topic here and hope to have a comprehensive discussion with the community.</em></p>
<p><strong>TLDR</strong>: Involving SGX introduces a safeguard against the collusion risk inherent in current MPC and FHE systems.</p>
<p>Continuing from Justin Drake’s well-articulated <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">post</a> about SGX as a 2FA for zk-rollups, I aim to expand on the potential of SGX as 2FA in FHE projects, specifically in their MPC encryption management. Despite their distinct applications, both leverage some fundamental features of SGX.</p>
<h2><a class="anchor" href="https://ethresear.ch#mpc-is-the-bottleneck-of-fhe-1" name="mpc-is-the-bottleneck-of-fhe-1"></a>MPC is the bottleneck of FHE</h2>
<p>Lately, the interest in FHE (Fully Homomorphic Encryption) technologies has rejuvenated, especially in the context of Ethereum Virtual Machines (EVMs). What was once merely a concept is now a tangible tool developers can use to write privacy-preserving smart contracts. Interested readers can refer to Vitalik’s early 2020 <a href="https://vitalik.eth.limo/general/2020/07/20/homomorphic.html" rel="noopener nofollow ugc">post</a> about FHE. Now, let’s look at the general architecture of most current FHE projects.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f17a45e5c32060cd1578a8f2112437f58880327.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f17a45e5c32060cd1578a8f2112437f58880327_2_663x500.png" width="663" /></a></div><p></p>
<p>I will not dive too deep into FHE itself here, but you can find a notable challenge most FHE designs encounter today lies in the MPC node’s key management. Due to the practice of writing an FHE application, the key is globally used by all users to encrypt the data they send to the FHE server, which will execute under an encryption state. Thus, the whole security of the system relies on the security of the MPC network, and as we all know the truths of the MPC network are:</p>
<ul>
<li>The more nodes you have, the more latency you get</li>
<li>The fewer nodes you have, the more trust assumptions you need</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#tee-as-a-2fa-to-mpc-2" name="tee-as-a-2fa-to-mpc-2"></a>TEE as a 2FA to MPC</h2>
<p>We don’t want to give full trust to MPC nodes because of the possibility of collusion if it is run by humans. Instead, we can add SGX as 2FA to hedge the risk by moving the key management to <a href="https://en.wikipedia.org/wiki/Trusted_execution_environment" rel="noopener nofollow ugc">TEE</a> (Trusted Execution Environments, a technology to run the program in an isolated zone inside CPU, prove program immutable and limited-accessible).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/d/1dc05649e162e2e9de3318a6da112754d5a6cd7e.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/d/1dc05649e162e2e9de3318a6da112754d5a6cd7e_2_608x500.png" width="608" /></a></div><p></p>
<p>As illustrated above, MPC nodes of the FHE system are now running inside TEE, instead of producing TEE proof when acting as 2FA for zk-rollups, here SGX is used to protect the key generation progress in the MPC network, and the whole lifecycle of the key is kept inside TEE and never gonna reveal to the outside world, more importantly, the key can not be touched by human even a single piece. TEE itself can guarantee the program it runs is verifiable, it’s impossible for someone can manipulate the state. Also, the data passing between TEE and the client is secured by TLS communication.<br />
With TEE as a 2FA, it can help reduce the risk in an economic way that:</p>
<ul>
<li>If SGX is not compromised, there is no chance that collusion can happen;</li>
<li>If SGX gets compromised, only when collusion happens between nodes that the system is broken.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#advantagesdisadvantages-of-sgx-as-2fa-for-fhe-3" name="advantagesdisadvantages-of-sgx-as-2fa-for-fhe-3"></a>Advantages/Disadvantages of SGX as 2FA for FHE</h2>
<ul>
<li>
<p>Advantages</p>
<ul>
<li>Security: Remove the possibility of collusion, trust is built on top of machinehood + cryptography instead of humanity.</li>
<li>Safety: By running MPC inside SGX, even a small MPC network can be reasonably secure. Even if TEE is broken, e.g. have bugs in SGX or Intel being malicious, we still fall back to ordinary MPC.</li>
<li>Latency: Using SGX, we can get higher security without introducing more workers. This gives more confident to users to run latency sensitive operations on MPC.</li>
<li>Liveness: SGX didn’t provide extra liveness naturally, but projects like Phala have built a decentralized <a href="https://docs.phala.network/tech-specs/blockchain" rel="noopener nofollow ugc">TEE network</a> that can help make it easy to build an unstoppable network.</li>
<li>Scalability: Scaling the MPC network is hard, but there are a bunch of existing TEE networks that are ready to deploy MPC nodes. So it lowers the cost to build a larger MPC network.</li>
<li>Throughout: There also is no throughput lost, but considering the optimization of latency, throughput can be improved theoretically.</li>
<li>More advantages that can be brought by SGX were well addressed by <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">Justin’s post</a>.</li>
</ul>
</li>
<li>
<p>Disadvantage</p>
<ul>
<li>It’s worth mentioning that SGX also has its own problems, a quote from Justin’s post:</li>
</ul>
<blockquote>
<ul>
<li>SGX has a bad reputation, especially within the blockchain space. Association with the technology may be memetically suboptimal.</li>
<li>false sense of security: Easily-broken SGX 2FA (e.g. if the privkey is easily extractable) may provide a false sense of security.</li>
<li>novelty: No Ethereum application that verifies SGX remote attestations on-chain could be found.</li>
</ul>
</blockquote>
<ul>
<li>As for the last one that SGX remote attestation on-chain doesn’t exist, the latest state is we have a couple of projects working on it, including Puffer, Automata, and also Phala’s <a href="https://github.com/tolak/zk-dcap-verifier" rel="noopener nofollow ugc">zk-dcap-verifier</a>. But considering it hasn’t been deployed on the mainnet, I kept it on the list.</li>
</ul>
</li>
</ul>
<p><em>Special thanks Justin Drake for his research of <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">2FA zk-rollups using SGX</a> and Andrew Miller for this research of TEE in Multi-Proof system, check his <a href="https://docs.google.com/presentation/d/1K96G50S8ICdllQDbEW1su1Ik_eOc5bK9Ih3uvoG-P9Y/edit?usp=sharing" rel="noopener nofollow ugc">presentation</a>.</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 03:25:10 +0000</pubDate>
</item>
<item>
<title>Solutions to the Preconf Fair Exchange Problem</title>
<link>https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779</link>
<guid>https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779</guid>
<content:encoded><![CDATA[
<div> 关键词：公平交换、领导预确认、声誉系统、最后权利、执行承诺

总结:
本文探讨了在领导预确认（preconfirmation）框架中解决公平交换问题的方法。首先，通过建立声誉系统，激励预确认者诚实回应，但依赖于经济条件的稳定性。其次，提出“最后权利”方案，根据预确认者的顺序决定PER的处理权，最后一个处理PER的预确认者有权获得交易提示。这解决了公平问题，且成本随技术进步而降低。最后，还讨论了“第一权利”方案，即反向请求承诺，适用于对执行承诺不那么敏感的场景。文章也提出了结合使用这些方法的可能性，以适应不同规模的交易需求。

< br>总结: <div>
<h3><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>tldr</h3>
<p>Solutions for dealing with the fair exchange problem in leader-based preconfirmation setups.</p>
<p>Reputation can incentivize preconfers to act honestly.</p>
<p>Alternatively, use order to dictate who gets the PER tip. One can invalidate a PER by sending it to a preconfer with higher priority.</p>
<h1><a class="anchor" href="https://ethresear.ch#fair-exchange-2" name="fair-exchange-2"></a>Fair Exchange?</h1>
<p>The fair exchange problem can be summarized as two untrusted players blindly giving up something in hopes that the other party will do the same. The goal is to try to find a method to ensure that both will cooperate. In the context of preconfirmations, the requesting party (gateway) has no guarantee that their preconfirmation enforcement request (PER) will receive a signed commitment. The preconfer has every right to not return a commitment, hold onto the PER until the last second, and include it if profitable (pocketing the tip for free).</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-1-reputation-3" name="solution-1-reputation-3"></a>Solution 1: Reputation</h1>
<p>One solution to this is by tracking reputation. More specifically, leveraging the promise of future PERs to incentivize preconfers to respond promptly via either commitments or non-commitments (slash-able promises to NOT include). The gateway can throttle or simply ignore preconfers if they misbehave.</p>
<p>Reputation is a tried method and exists today in mev-boost relays (see <a href="https://ethresear.ch/t/the-preconfirmation-sauna/19762">Switchboard’s Sauna Appendix</a>). While this might work, it still requires certain economic conditions for security. If for whatever reason it becomes really profitable to behave dishonestly, the guarantees fall apart.</p>
<h1><a class="anchor" href="https://ethresear.ch#can-we-do-better-4" name="can-we-do-better-4"></a>Can we do better?</h1>
<p>In an ideal scenario, without any limitations of technology, one would simply invalidate the PER if the preconfer takes too long to respond. With blockchains, this is complicated, and time-based approaches require some sort of additional consensus, breaking the based paradigm. However, we can indirectly access “time” by using order. Blocks are ordered, so preconfers can be as well. If we take advantage of this, we arrive at a new solution that avoids the Fair Exchange problem altogether.</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-2-last-right-5" name="solution-2-last-right-5"></a>Solution 2: Last Right</h1>
<p>Determine an order for preconfers. This can be done per block (or even intra-block). Send the PER optimistically to the first preconfer. If they commit, then great. If they return a non-commitment, or do not respond, then send the PER to the next preconfer.</p>
<p>But wait, they can still include my PER and pocket my tip! Yes, they can but they won’t be able to keep the tip. This is due to the central idea of this solution: <strong>the last preconfer to include the PER has the right to the tips</strong>. If two preconfers attempt to include the PER, the second preconfer has the right to the preconf tip. For example, the last preconfer submits a proof and transfers the PER tip to their balance. Other mechanisms are also possible and should be explored.</p>
<p>One consideration here is the cost. If claiming the tip is more expensive than the tip itself, then the model falls apart. The good news is this cost is directly tied to the technology and should decrease exponentially (e.g. zk proof). Preconfirmation tips on the other hand are tied to the value of the transaction itself, which is not as dependent on the tech. So perhaps this mechanism will become more and more economically favorable.</p>
<p>One great side effect of this method is that it preserves the possibility of execution promises. If the first preconfer acts honestly, then it can guarantee the execution state for the PER. Execution guarantees fall apart if there’s any dishonesty (same as Solution 1).</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-3-first-right-6" name="solution-3-first-right-6"></a>Solution 3: First Right</h1>
<p>If we are willing to forgo execution promises, then the gateway can instead request commitments from preconfers in reverse order. Forward the PER to a preconfer down the list, and then move up until one commits. <strong>The first preconfer to include the PER gets the tip.</strong> In the case where L1 proposers are preconfers, this is enforced by the L1 replay protection. This is a much simpler version of Solution 2.</p>
<p>One downside is the “real” latency before the transaction is actually included since the default preconfer is not the current one. But one could argue that for important transactions where L1 settlement is important (e.g. buying a house), preconfirmations in general are probably not a priority.</p>
<p>Note that execution promises are technically still possible if all the state transitions up to the point of inclusion has already been determined. (e.g. All block space has already been filled by PERs or similar.)</p>
<h1><a class="anchor" href="https://ethresear.ch#final-thoughts-7" name="final-thoughts-7"></a>Final Thoughts</h1>
<p>We can even perhaps use these Solutions in tandem. For smaller preconf tips, we can rely on Solution 1, let the first preconfer pocket it and “slash” their reputation. For larger preconf tips, we can fallback to Solution 2 and let the next preconfer steal it back. Or just use them at the same time.</p>
<p>Thanks to <span class="mention">@mteam</span> for getting me up to speed and providing feedback. We at Spire Labs are actively researching preconfirmations and related topics, and building towards a better, unified Ethereum.</p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 02:55:02 +0000</pubDate>
</item>
<item>
<title>Inactivity Leak unveiled</title>
<link>https://ethresear.ch/t/inactivity-leak-unveiled/19774</link>
<guid>https://ethresear.ch/t/inactivity-leak-unveiled/19774</guid>
<content:encoded><![CDATA[
<div> 关键词：inactivity leak, finalization, Ethereum PoS, Byzantine validators, safety

总结:
本文探讨了以太坊PoS区块链中的"不活动泄漏"问题，这是一种在灾难性网络故障期间恢复最终性的理论分析。不活动泄漏机制导致链的连续增长，优先保证区块的最终性（活性），但可能牺牲安全。当网络中存在拜占庭验证者时，这一问题更加突出，它们可能导致冲突的最终区块，威胁协议的安全。文章详细描述了不活动分数和惩罚机制，以及在不同行为（活跃和不活跃）下的验证者权益变化。研究发现，拜占庭验证者的恶意行为会加速安全丧失，特别是在初始比例较高时。作者强调了对协议设计中潜在问题的认识对于BFT分析和未来改进的重要性。 <div>
<p>We summarize here the <a href="https://arxiv.org/abs/2404.16363" rel="noopener nofollow ugc">article</a> that presents the first theoretical analysis of the inactivity leak, designed to restore finalization during catastrophic network failures. This work is accepted at DSN2024.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h1>
<ul>
<li>The inactivity leak is intrinsically problematic for the safety of the protocol. It favors the constant finalization of blocks (<em>liveness</em>) at the expense of having conflicting finalized blocks (<em>safety</em>).</li>
<li>The presence of Byzantine validators -validators that deviate from the protocol- can accelerate the loss of safety.</li>
</ul>
<hr />
<p>The Ethereum PoS blockchain strives for the continuous growth of the finalized chain. In consequence, the protocol incentivizes validators to finalize blocks actively. The inactivity leak is the mechanism used to regain finality. Specifically, the inactivity leak is initiated if a chain has not undergone finalization for four consecutive epochs. The inactivity leak happened for the first time on the mainnet in May 2023.</p>
<p>A good introduction to the inactivity leak is available thanks to the excellent work of Ben Eddington <a href="https://eth2book.info/capella/part2/incentives/inactivity/" rel="noopener nofollow ugc">here</a> (which motivated this work). We formalize the inactivity leak starting by the inactivity score.</p>
<h2><a class="anchor" href="https://ethresear.ch#inactivity-score-2" name="inactivity-score-2"></a>Inactivity Score</h2>
<p>During an inactivity leak, at epoch <span class="math">t</span>, the inactivity score, <span class="math">I_i(t)</span>, of validator <span class="math">i</span> is:</p>
<div class="math">
\begin{cases}
        I_i(t) = I_i(t-1)+4, \text{if $i$ is inactive at epoch $t$} \\
        I_i(t) = \max(I_i(t-1)-1, 0), \text{ otherwise.}
    \end{cases}
</div>
<p>Thus, a validator’s inactivity score increases by <span class="math">4</span> if it is inactive and decreases by <span class="math">1</span> if it is active. The inactivity score is always positive and will be used to penalize validators during the inactivity leak.</p>
<h2><a class="anchor" href="https://ethresear.ch#inactivity-penalties-3" name="inactivity-penalties-3"></a>Inactivity Penalties</h2>
<p>Let <span class="math">s_i(t)</span> represent the stake of validator <span class="math">i</span> at epoch <span class="math">t</span>, and let <span class="math">I_i(t)</span> denote its inactivity score. The penalty at each epoch <span class="math">t</span> is <span class="math">I_i(t-1)\cdot s_i(t-1)/2^{26}</span>. Therefore, the evolution of the stake is expressed by:</p>
<div class="math">
s_i(t)=s_i(t-1)-\frac{I_i(t-1)\cdot s_i(t-1)}{2^{26}}. 
</div>
<h2><a class="anchor" href="https://ethresear.ch#stake-during-the-inactivity-leak-4" name="stake-during-the-inactivity-leak-4"></a>Stake during the Inactivity Leak</h2>
<p>In this work, we model the stake function <span class="math">s</span> as a continuous and differentiable function, yielding the following differential equation:</p>
<div class="math">
s'(t)=-I(t)\cdot s(t)/2^{26}.
</div>
<p>With this equation, we can determine a validator’s stake according to the time by fixing the evolution of its inactivity score. And that is exactly what we do. We define two types of behavior: Active and Inactive.</p>
<ul>
<li>Active validators: they are always active.</li>
<li>Inactive validators: they are always inactive.</li>
</ul>
<p>Validators with these behaviors experience different evolutions in their inactivity scores: (a) Active validators have a constant inactivity score <span class="math">I(t)=0</span>; (b) Inactive validators’ inactivity score increases by 4 every epoch, <span class="math">I(t)=4t</span>. The stake of each type of validator during an inactivity leak:</p>
<ul>
<li>Active validator’s stake: <span class="math"> s(t) = s_0 = 32. </span></li>
<li>Inactive validator’s stake: <span class="math"> s(t) = s_0e^{-t^2/2^{25}}. </span></li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/496a7e5de461559b800a4d612eacb356a5f3cc84.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/496a7e5de461559b800a4d612eacb356a5f3cc84_2_685x500.png" width="685" /></a></div><p></p>
<p>The graph shows the evolution of the stake of validators depending on their activity during the inactivity leak. The expulsion limit is set by the protocol to eject validators that have accumulated too many penalties.</p>

What is an active validator? <a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774/1">(click for more details)</a>
<hr />
<p>This was the formalization of the protocol. Now we make the analysis of the protocol’s property of safety. To do so, we use the following model.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-5" name="model-5"></a>Model</h2>
<ul>
<li><strong>Network</strong>: We assume a partially synchronous system, which transitions from an asynchronous state to a synchronous state after an apriori unknown Global Stabilization Time (GST).</li>
<li><strong>Fault</strong>: Validators are either <em>honest</em> or <em>Byzantine</em> (deviating from the protocol). A Byzantine validator can deviate arbitrarily from the protocol.</li>
<li><strong>Stake</strong>: Each validator starts with 32 ETH.</li>
</ul>
<p>There is no bound on message transfer delay during the asynchronous state.</p>
<h1><a class="anchor" href="https://ethresear.ch#bound-for-safety-6" name="bound-for-safety-6"></a>Bound for safety</h1>
<h2><a class="anchor" href="https://ethresear.ch#with-only-honest-validators-7" name="with-only-honest-validators-7"></a>With only honest validators</h2>
<p>By construction, the inactivity leak will breach safety if a partition occurs for long enough. The question is, how quickly?</p>
<blockquote>
<p><em>Any network partition lasting longer than 4686 epochs (about 3 weeks) will result in a loss of Safety because of conflicting finalization. This is an upper bound for Safety on the duration of the inactivity leak with only honest validators.</em></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#detailed-analysis-8" name="detailed-analysis-8"></a>Detailed Analysis</h3>
<p>Let us analyze the scenario in which the validators (which are all honest) are partitioned in two. (We are in the asynchronous state according to our model).<br />
The partition will necessarily create a fork, each partition building on the only chain they see. The chains will finalize once the proportion of active validators returns to 2/3rd.</p>
<p>In this case, by understanding the distribution of the validators across the partitions, we can compute the time it takes for the proportion of active validators’ stake to return to 2/3 of the stake on each branch, thus finalizing and breaking safety.</p>
<p>For the analysis, we make the following notations. At the beginning of the inactivity leak:</p>
<ul>
<li><span class="math">n</span> is the total number of validators</li>
<li><span class="math">n_B</span> is the total number of Byzantine validators</li>
<li><span class="math">n_H</span> is the total number of honest validators</li>
<li><span class="math">n_{H_1}</span> is the number of honest validators on branch 1</li>
<li><span class="math">n_{H_2}</span> is the number of honest validators on branch 2</li>
</ul>
<p>There are no Byzantine validators for the first part of our analysis, which implies that <span class="math">n=n_H</span>. Honest validators are only partitioned in two, thus <span class="math">n_H=n_{H_1}+n_{H_2}</span>.</p>
<p><strong>Our goal is to determine when the proportion of honest validators on branch 1 will be superior to 2/3rd of the total stake.</strong>  Which is to say that we look at when the ratio:</p>
<div class="math">
\frac{\text{stake of validator in branch 1}}{\text{stake of validator in branch 1 + stake of validator in branch 2}},
</div>
<p>is superior to 2/3. With our notation, the ratio can be rewritten as:</p>
<div class="math">
\frac{n_{\text H_1}s_{\text H_1}(t)}{n_{\text H_1}s_{\text H_1}(t)+n_{\text H_2}s_{\text H_2}(t)} ,
</div>
<p><span class="math">s_{\text H_1}</span> and <span class="math">s_{\text H_2}</span> are the stakes of honest active and inactive validators, respectively. Since the <span class="math">n_{\text H_1}</span> validators on branch 1 are always active on branch 1, and the <span class="math">n_{\text H_2}</span> validators are always inactive on branch 1 (they are active on branch 2); we know that <span class="math">s_{\text H_1}(t)=s_0</span> and <span class="math">s_{\text H_2}(t)=s_0e^{-t^2/2^{25}}</span>.<br />
Using the notation <span class="math">p_0=n_{\text H_1}/n_H</span>, the ratio of active validators over time is:</p>
<div class="math">
\frac{p_0}{p_0+(1-p_0)e^{-t^2/2^{25}}}. 
</div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7ec6a1a64318159dada408e4cc0365a1663b28d1.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7ec6a1a64318159dada408e4cc0365a1663b28d1_2_668x500.png" width="668" /></a></div><p></p>
<p>This graph shows the ratio of active validators on branch 1 over time. If finalization hasn’t occurred by epoch <span class="math">t=4685</span>, inactive validators are ejected, causing a jump to 100% active validators.</p>
<h2><a class="anchor" href="https://ethresear.ch#byzantine-validators-9" name="byzantine-validators-9"></a>Byzantine validators</h2>
<p>We now add Byzantine validators.</p>

These Byzantine validators can send messages to each partition without restriction. <a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774/1">(click for more details)</a>
<p>The situation we analyze is now as such:</p>
<ul>
<li>Less than one-third of the stake is held by Byzantine validators (<span class="math">\beta_0=n_{\rm B}/n&lt;1/3</span>).</li>
<li>Honest validators are divided into branches <span class="math">1</span> and <span class="math">2</span>; a proportion <span class="math">p_0=n_{\rm H_1}/n_{\rm H}</span> on branch <span class="math">1</span> and <span class="math">1-p_0=n_{\rm H_2}/n_{\rm H}</span> on branch <span class="math">2</span>.</li>
<li>Byzantine validators can communicate with both branches.</li>
</ul>
<p>Byzantine validators can be active on both branches simultaneously, breaching safety faster. The ratio of active validators on branch 1 is:</p>
<div class="math">
\frac{p_0(1-\beta_0)+\beta_0}{p_0(1-\beta_0)+\beta_0+(1-p_0)(1-\beta_0)e^{-t^2/2^{25}}}.
</div>
<p>This table shows the time it takes to break safety depending on the initial proportion of Byzantine validators (<span class="math">\beta_0</span>):<br />
<img alt="image" height="195" src="https://ethresear.ch/uploads/default/original/3X/3/0/30cda7537ed8ab1493f4beadd138924b6b6408f3.png" width="157" /></p>
<p><em>Byzantine validators can expedite the loss of Safety. If their initial proportion is 0.33, they can make conflicting finalization occur approximately ten times faster than scenarios involving only honest participants.</em></p>
<hr />
<p>The original paper provides more details on the assumptions, scenarios, protocol, and other aspects such as:</p>
<ul>
<li>Ways for Byzantine validators to breach safety without committing slashable behavior.</li>
<li>Methods for Byzantine validators to exceed the 1/3 threshold on both branches of the fork.</li>
<li>An analysis of the probabilistic bouncing attack while considering the inactivity leak. Spoiler alert: this aggravates the attack slightly, but the conditions for the attack to start and persist in time make it highly improbable to be a real threat.</li>
</ul>
<p>For an additional quick peek at the paper’s findings, here is a graphic that presents how quickly Byzantine validators can break safety depending on their initial proportion and whether their behavior is slashable or not.  As you can see, they can have a strong impact even without slashable behavior.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/a/8a447d3888021e7cf6ba7c2b99fd1907ad3a5738.png" title="image"><img alt="image" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/8/a/8a447d3888021e7cf6ba7c2b99fd1907ad3a5738_2_500x375.png" width="500" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-10" name="conclusion-10"></a>Conclusion</h1>
<p>Our findings highlight the importance of penalty mechanisms in Byzantine Fault Tolerance (BFT) analysis. By identifying potential issues in protocol design, we aim to provide insights for future improvements and tools for further investigation.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 10 Jun 2024 13:46:18 +0000</pubDate>
</item>
<item>
<title>The contention between preconfs and ePBS</title>
<link>https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770</link>
<guid>https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、preconfirmations、inclusion lists、centralized entity、staked builders

总结:<br />
文章讨论了ePBS（加密预言机拜占庭服务）与不同预确认机制的兼容性。主要观点如下：<br />
1. 使用预确认列表可能会导致交易广播两次，增加网络负担，这与ePBS优化的共识块验证时间不兼容。
2. 预确认系统的中心化性质，通常依赖于集中式实体，如中继，与ePBS的去中心化目标相悖。
3. ePBS下，强制执行预确认可能导致全交易列表广播，挑战了ePBS的优化，即仅验证共识块。
4. 建议利用已有的staked builders作为预确认者，他们在预确认系统中的角色可以像提案者一样受到规则约束。
5. ePBS对restaking（复投）也构成挑战，因为预确认和潜在违规行为可能发生在同一个交易中，需要额外处理。

因此，为保持与ePBS的兼容性，预确认系统的设计需要避免直接在共识块中包含完整交易列表，而是考虑利用staked builders的角色来间接实现预确认。 <div>
<p>This quick note is motivated by a question of <a class="mention" href="https://ethresear.ch/u/hasu.research">@Hasu.research</a> regarding the compatibility of ePBS with the different mechanisms for preconfirmations that are being proposed by independent groups <a href="https://ethresear.ch/t/the-preconfirmation-sauna/19762">1</a> <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">2</a> <a href="https://chainbound.github.io/bolt-docs/" rel="noopener nofollow ugc">3</a> <a href="https://docs.google.com/presentation/d/1a-0rP2knM11g59UmnKn7I7NH8BlFM5wNhczH35sbkSo/edit#slide=id.g2731bc99d1b_0_0" rel="noopener nofollow ugc">4</a> <a href="https://docs.primev.xyz/get-started/introduction" rel="noopener nofollow ugc">5</a>. The only purpose of this note is to leave a quick written record of the fundamental contention between the enshrinements of preconfirmations and the <a href="https://github.com/potuz/consensus-specs/pull/2" rel="noopener nofollow ugc">current proposal for ePBX</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#overloading-inclusion-lists-1" name="overloading-inclusion-lists-1"></a>Overloading inclusion lists.</h2>
<p>Even in the very first post on <a href="https://ethresear.ch/t/based-preconfirmations/17353">based preconfirmations</a>, the idea of using <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">forced inclusion lists</a> was put forward as a way for proposers to signal their intent of honoring preconfirmations, forcing builders to include these transactions. An extrapolation of this idea led, in one of the original designs for ILs, to propose that inclusion lists may essentially include a complete list of transactions the proposer has in its current mempool. One of the problems with these ideas is that the full list of transactions would need to be broadcast over the P2P network twice: once when the inclusion list is broadcast, and the second time within the payload itself. In all known designs for inclusion lists, validators attest for the existence of the full executable transaction list. This implies in particular that</p>
<ol>
<li>The list must be available at the beacon block validation time.</li>
<li>The list must be executed at the beacon block validation time.</li>
</ol>
<p>This section is not meant to be read as <em>inclusion lists aren’t compatible with ePBS</em> but rather any preconfirmation system (and next block forced inclusion lists by definition are such a system) that relies on the execution and distribution of the transactions at the consensus block validation time, necessarily clashes with the main optimization from ePBS.</p>
<h2><a class="anchor" href="https://ethresear.ch#epbs-validation-optimization-2" name="epbs-validation-optimization-2"></a>ePBS validation optimization</h2>
<p>The above two points are in direct opposition with the main optimization that ePBS brings to block processing, that is that the only hot path to validation is that of the consensus block that has to be fully verified before the attestation deadline. All other validations, like transaction execution, data availability, etc. are deferred to the remainder of the slot and into the next slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f3daa474ae131dfbee7c96cfd9f2a7e4035c06a.jpeg" title="ePBS slot"><img alt="ePBS slot" height="364" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f3daa474ae131dfbee7c96cfd9f2a7e4035c06a_2_690x364.jpeg" width="690" /></a></div><p></p>
<p>While ePBS is compatible with inclusion lists, their addition inherently stresses this optimization. Broadcasting a small list of 16 transactions that can be immediately executed in microseconds is not the same as broadcasting a full block, and presumably, even blob transactions as some based rollups would require.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-centralized-nature-of-preconfs-3" name="the-centralized-nature-of-preconfs-3"></a>The centralized nature of preconfs</h2>
<p>There is no current design (that I am aware of) of preconfirmations, that does not rely on a centralized entity. This is natural to expect in the absence of an encrypted public mempool, users can’t send their transactions in the open to the next proposer (although they could <em>encrypt the transactions to the public BLS address of the next proposer</em>), and we can’t enshrine an RPC provider, all systems thus make use on existing centralized entities (for example relays) to act as a preconfer. Decentralization comes in that it is ultimately the proposer who enforces these preconfirmations, by forcing the builder to fullfil them.</p>
<p>Thus, in all proposed systems for preconfirmations, either of L1 transactions or for based rollups, there exist a centralized entity that at the very least is responsible for gathering the transactions and giving out the preconfirmations. Systems differ on how is that these preconfirmations are enforced, they range from new L1 slashing proposals, to restaking proposals (moving the slashing to a separate layer), etc. The point is that preconfirmations can be enforced by the protocol itself, or by a somewhat decentralized party like the subset of validators participating in the preconfirmation scheme. In summary, there is a plethora of options for enforcing the (or penalizing the lack of) inclusion of preconfirmations, in decreasing level of trustlessness:</p>
<ul>
<li>The L1 protocol itself enforces inclusion. For example, forced ILs, with proposer level slashings on missed slots, preconf equivocations, etc.</li>
<li>Some separate committee enforces them. For example a subset of the L1 validators also participate in a sidechain by restaking, and the enforcement/punishment is carried in that sidechain.</li>
<li>A centralized entity enforces them. For example the relay itself only sends bids from builders that have satisfied the required preconfs.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#a-viable-way-compatible-with-epbs-staked-builders-as-preconfirmers-4" name="a-viable-way-compatible-with-epbs-staked-builders-as-preconfirmers-4"></a>A viable way compatible with ePBS: staked builders as preconfirmers.</h2>
<p>Any approach with a full payload being broadcast with the consensus block for preconfirmation enforcement clashes directly with the main scaling optimization of ePBS with regard to block validation. As thus, it seems difficult to expect a working design in which the proposers are in charge of sending and enforcing preconfirmations. The second and third approaches above are fully compatible with ePBS.</p>
<p>One of the features that preconfirmation systems can leverage when ePBS is in place, is that builders themselves are staked validators, thus they can be subject to the same rules that these systems currently require from proposers. For example, those systems that rely on slashings on a restaking scheme could simply add conditions on participating builders. That is, the proposer set participating in the scheme only take bids from builders that are participants of the scheme. The builders and proposers are required to be restaked. There are new penalty conditions for</p>
<ul>
<li>A proposer that does not include a block.</li>
<li>A proposer that includes a block with a commitment to a non-participating builder.</li>
<li>A builder that does not include the payload</li>
<li>A builder that includes a payload does not satisfies the preconf list.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#a-separate-note-on-restaking-5" name="a-separate-note-on-restaking-5"></a>A separate note on restaking</h2>
<p>ePBS also presents a challenge on any restaking scheme: builders can transfer funds in the same payload that they commit a slashable offense. L1 protocol can deal with this by immediately deducting the bid from the builder’s balance at the time of CL block processing, but delaying the credit to the proposer. In case the builder commits a slashable offense, the buffer allows the L1 protocol to implement penalization procedures that can impact those delayed funds accordingly. If the builder is restaked however, the restaking chain does not have access to these funds.</p>
            <p><small>7 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 07:59:33 +0000</pubDate>
</item>
<item>
<title>On block-space distribution mechanisms</title>
<link>https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764</link>
<guid>https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#on-block-space-distribution-mechanisms-1" name="on-block-space-distribution-mechanisms-1"></a>On block-space distribution mechanisms</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/3/c3fa4239ef0f468256ba44d0e860fb3d7edaedcf.jpeg" title="upload_3067440b5b4f752379ddba32df7ecf8b"><img alt="upload_3067440b5b4f752379ddba32df7ecf8b" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/3/c3fa4239ef0f468256ba44d0e860fb3d7edaedcf_2_499x500.jpeg" width="499" /></a></div><br />
<sub><strong>^p.s. yes, we anthropomorphize the protocol as a ghost because <a href="https://arxiv.org/pdf/1710.09437.pdf" rel="noopener nofollow ugc">Casper</a>.</strong></sub><br />
<sub><strong>^^p.p.s. not sure why the auctioneer ghost looks like he is conducting an orchestra, but here we are ¯\_(ツ)_/¯.</strong></sub><br />
<sub><strong>^^^ p.p.p.s. by the way, if you haven’t seen <a href="https://en.wikipedia.org/wiki/Maestro_(2023_film)" rel="noopener nofollow ugc">Maestro</a>, it’s great.</strong></sub><p></p>
<p><span class="math">\cdot</span><br />
<em>by <a href="https://x.com/mikeneuder" rel="noopener nofollow ugc">Mike</a>, <a href="https://x.com/PGarimidi" rel="noopener nofollow ugc">Pranav</a>, &amp; <a href="https://x.com/Tim_Roughgarden" rel="noopener nofollow ugc">Dr. Tim Roughgarden</a> – June 8, 2024.</em><br />
<span class="math">\cdot</span><br />
<strong>Acknowledgements</strong><br />
<em>Special thanks to <a href="https://x.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://x.com/_julianma" rel="noopener nofollow ugc">Julian</a>, <a href="https://x.com/_JonahB_" rel="noopener nofollow ugc">Jonah</a>, <a href="https://x.com/DavideCrapis" rel="noopener nofollow ugc">Davide</a>, <a href="https://x.com/soispoke" rel="noopener nofollow ugc">Thomas</a>, <a href="https://x.com/terencechain" rel="noopener nofollow ugc">Terence</a>, <a href="https://x.com/potuz_eth" rel="noopener nofollow ugc">Potuz</a>, &amp; <a href="https://www.nano210.blog/" rel="noopener nofollow ugc">Nate</a> for comments and discussions.</em><br />
<span class="math">\cdot</span><br />
<strong>tl;dr;</strong> <em>Block space, the capacity for transaction inclusion, is the principal resource exported by blockchains. As the crypto ecosystem scales up and professionalizes, the value produced by efficient usage of block space (<a href="https://arxiv.org/abs/1904.05234" rel="noopener nofollow ugc">MEV</a>) has come to play a significant role in the economics of permissionless consensus mechanisms. An immense amount of ink has been spilled by the research community considering what, if anything, protocols should enshrine in response to MEV (see <a href="https://ethresear.ch#related-work-2">Related Work</a>). Indeed, the past few years resemble a <a href="https://en.wikipedia.org/wiki/Blind_men_and_an_elephant" rel="noopener nofollow ugc">Blind Men and the Elephant</a> narrative arc, where many different perspectives, solutions, and theories have been propounded, but each angle can feel disjoint and difficult to compare. The first half of this article aims to present a broad-strokes painting of the “MEV-ephant” by distilling the design space into a core set of questions and exploring how existing proposals answer them. The second half hones in specifically on allocation mechanisms enabled by execution tickets, demonstrating an important new insight – there is a trade-off between the quality of the in-protocol MEV oracle and the fairness of the mechanism.</em></p>
<p><strong>Organization:</strong> <a href="https://ethresear.ch#h-1-motivation-3">Section 1</a> motivates the need for an in-protocol mechanism to handle block-space distribution as part of the “endgame” for Proof-of-Stake. <a href="https://ethresear.ch#h-2-enumeration-6">Section 2</a> enumerates five axes along which block-space distribution mechanisms may be measured, using a familiar set of questions: <em>who, what, when, where, how</em> (abbr. the <code>W^4H questions</code>). <a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> interrogates how the block builder is selected, focusing on the execution tickets model. <a href="https://ethresear.ch#h-4-extrapolation-18">Section 4</a> extrapolates by concluding and raising open questions that follow from the framework established.</p>
<p><strong>Structural note:</strong> This article is rather long for this format and has some technical elements. We encourage the reader to focus on the portion of the article they are most interested in:</p>
<ul>
<li>Sections <a href="https://ethresear.ch#h-1-motivation-3">1</a>, <a href="https://ethresear.ch#h-2-enumeration-6">2</a>, &amp; <a href="https://ethresear.ch#h-4-extrapolation-18">4</a> provide a broader perspective on the existing proposals and our proposed methodology for analyzing them.</li>
<li><a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> (which is <span class="math">\approx 44\%</span> of the content, but <a href="https://youtu.be/VDvr08sCPOc?t=111" rel="noopener nofollow ugc"><span class="math">100\%</span></a> of the math) provides a detailed analysis of allocation mechanisms enabled by the execution tickets design. This section can be read in sequence, in isolation, or skipped altogether – up to you!</li>
</ul>
<p><span class="math">\cdot</span><br />
<strong>Contents</strong></p>
<ol>
<li><a href="https://ethresear.ch#h-1-motivation-3"><strong>Motivation</strong></a><br />
<a href="https://ethresear.ch#h-1-what-4"><em>1) What</em></a><br />
<a href="https://ethresear.ch#Block-space-distribution-today"><em>Block-space distribution today through <code>mev-boost</code></em></a></li>
<li><a href="https://ethresear.ch#h-2-enumeration-6"><strong>Enumeration</strong></a><br />
<a href="https://ethresear.ch#the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7"><em>The elements of block-space distribution</em></a><br />
<a href="https://ethresear.ch#execution-tickets-and-other-animals-8"><em>Execution tickets and other animals</em></a><br />
<a href="https://ethresear.ch#applying-w4h-a-comparative-analysis-9"><em>Applying W^4H: a comparative analysis</em></a><br />
<a href="https://ethresear.ch#motivational-interlude-10"><em>Motivational interlude</em></a></li>
<li><a href="https://ethresear.ch#h-3-interrogation-11"><strong>Interrogation</strong></a><br />
<a href="https://ethresear.ch#preliminaries-12"><em>Preliminaries</em></a><br />
<a href="https://ethresear.ch#model-13"><em>Model</em></a><br />
<a href="https://ethresear.ch#familiar-allocation-mechanisms-14"><em>Familiar allocation mechanisms</em></a><br />
<a href="https://ethresear.ch#comparing-the-outcomes-15"><em>Comparing the outcomes</em></a><br />
<a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16"><em>Aside #1: Calculating equilibrium bids</em></a><br />
<a href="https://ethresear.ch#aside-2-tullock-contests-17"><em>Aside #2: Tullock Contests</em></a></li>
<li><a href="https://ethresear.ch#h-4-extrapolation-18"><strong>Extrapolation</strong></a></li>
</ol>
<p><span class="math">\cdot</span></p>
<h4><a class="anchor" href="https://ethresear.ch#related-work-2" name="related-work-2"></a><strong>Related work</strong></h4>
<ol>
<li><em>mev-boost &amp; relays</em>
<ul>
<li><a href="https://ethresear.ch/t/mev-boost-merge-ready-flashbots-architecture/11177"><em>MEV-Boost: Merge ready Flashbots Architecture</em></a>; Flashbots team</li>
<li><a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278"><em>Relays in a post-ePBS world</em></a>; Mike, Jon, Hasu, Tomasz, Chris, Toni</li>
</ul>
</li>
<li><em>mev-burn / mev-smoothing</em>
<ul>
<li><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>Burning MEV through block proposer auctions</em></a>; Domothy</li>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn – a simple design</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408"><em>Committee-driven MEV smoothing</em></a>; Francesco</li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384"><em>Dr. changestuff or: how I learned to stop worrying and love mev-burn</em></a>; Mike, Toni, Justin</li>
</ul>
</li>
<li><em>enshrined Proposer-Builder Separation (ePBS)</em>
<ul>
<li><a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980"><em>Two-slot proposer/builder separation</em></a>; Vitalik</li>
<li><a href="https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879"><em>Unbundling PBS: towards protocol-enforced proposer commitments (PEPC)</em></a>; Barnabé</li>
<li><a href="https://barnabe.substack.com/p/pbs" rel="noopener nofollow ugc"><em>Notes on Proposer-Builder Separation</em></a>; Barnabé</li>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>; Barnabé</li>
<li><a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710"><em>Why enshrine Proposer-Builder Separation?</em></a>; Mike, Justin</li>
<li><a href="https://ethresear.ch/t/epbs-design-constraints/18728"><em>ePBS design constraints</em></a>; Potuz</li>
<li><a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg" rel="noopener nofollow ugc"><em>Reconsidering the market structure of PBS</em></a>; Barnabé</li>
</ul>
</li>
<li><em>block-space futures</em>
<ul>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc"><em>Block vs. Slot Auction PBS</em></a>; Julian</li>
<li><a href="https://frontier.tech/ethereums-blockspace-future" rel="noopener nofollow ugc"><em>Opportunities and Considerations of Ethereum’s Blockspace Future</em></a>; Drew, Ankit</li>
<li><a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814" rel="noopener nofollow ugc"><em>When to sell your blocks</em></a>; Quintus, Conor</li>
</ul>
</li>
<li><em>execution tickets</em>
<ul>
<li><a href="https://www.youtube.com/watch?v=MtvbGuBbNqI" rel="noopener nofollow ugc"><em>Attester-proposer separation</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/execution-tickets/17944"><em>Execution tickets</em></a>; Justin, Mike</li>
<li><a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894"><em>Economic Analysis of Execution Tickets</em></a>; Jonah, Davide</li>
<li><a href="https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232"><em>Block-auction ePBS versus Execution Ticket</em></a>; Terence</li>
</ul>
</li>
</ol>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#h-1-motivation-3" name="h-1-motivation-3"></a>(1) – Motivation</h3>
<p>Before descending into this murky rabbit hole, let’s start by simply motivating the necessity of a block-space distribution mechanism. Validators in Proof-of-Stake protocols are tasked with producing and voting on blocks. The figure below, from Barnabé’s excellent “<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>,” describes these as “proposing” and “attesting” rights, respectively.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/d/7d85ca7f1812a5822490fa079365301c99733620.png" title="upload_72dad4dc4f8c77f0d57f8f126b3c2e46"><img alt="upload_72dad4dc4f8c77f0d57f8f126b3c2e46" height="219" src="https://ethresear.ch/uploads/default/optimized/3X/7/d/7d85ca7f1812a5822490fa079365301c99733620_2_690x219.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-what-4" name="h-1-what-4"></a>1) What</h4>
<p>(<span class="math">\uparrow</span> <a href="https://twitter.com/SBF_FTX/status/1591989554881658880?lang=en" rel="noopener nofollow ugc">important cultural ref</a>.)</p>
<p>A block-space distribution mechanism is the process by which the protocol determines the owner of the “proposing” or “block construction” rights. Proof-of-Stake protocols typically use some version of the following rules:</p>
<ul>
<li><strong>block-space (proposing) rights</strong> – A random validator is elected as the leader and permitted to create the next block.</li>
<li><strong>voting (attesting) rights</strong> – All validators vote during some time window for the block they see as the canonical head.</li>
</ul>
<p>Validators perform these tasks because they receive rewards for doing so. We categorize the rewards according to their origin in either the consensus layer (the issuance from the protocol – e.g., newly minted <code>ETH</code>) or the execution layer (transaction fees and MEV):</p>
<ol>
<li><strong>Consensus layer</strong><br />
a. <em>Attestation rewards</em> – see <a href="https://github.com/ethereum/annotated-spec/blob/160764ac180eca2cea3581f731ee96ac7098f9f7/phase0/beacon-chain.md#components-of-attestation-deltas" rel="noopener nofollow ugc">attestation deltas</a>.<br />
b. <em>Block rewards</em> – see <a href="https://github.com/ethereum/annotated-spec/blob/160764ac180eca2cea3581f731ee96ac7098f9f7/phase0/beacon-chain.md#rewards-and-penalties-1" rel="noopener nofollow ugc"><code>get_proposer_reward</code></a>.</li>
<li><strong>Execution layer</strong><br />
a. <em>Transaction fees</em> – see <a href="https://etherscan.io/gastracker" rel="noopener nofollow ugc">gas tracker</a>.<br />
b. <em>MEV (transaction ordering)</em> – see <a href="https://mevboost.pics/" rel="noopener nofollow ugc">mevboost.pics</a>.</li>
</ol>
<p>Rewards <code>1a</code>, <code>1b</code>, &amp; <code>2a</code> are well understood and “<a href="https://barnabe.substack.com/p/seeing-like-a-protocol" rel="noopener nofollow ugc">in the view</a>” of the protocol. MEV rewards present a more serious challenge because fully capturing the value realized by transaction ordering is difficult. Unlike the other rewards, even the amount of MEV in a block is unknowable for all intents and purposes (as a permissionless and pseudonymous system, it’s impossible to trace who controls each account and any corresponding offchain activity that may be profitable in tandem). MEV also changes dramatically over time (e.g., as a function of price volatility), resulting in execution layer rewards having a much higher variance than the consensus layer rewards. Further, the Ethereum protocol, as implemented, has no insight into the MEV being produced and extracted by its transactions. To improve protocol visibility into MEV, many mechanisms try to approximate the MEV in a given block; we refer to these as <em>MEV oracles</em>. Block-space distribution mechanisms generally have the potential to produce such an oracle, making the protocol “MEV-aware.”</p>
<p>This suggests the question, <em>why does the protocol care about being MEV-aware?</em> One answer: <strong>MEV awareness may increase the protocol’s ability to preserve the homogeneity of validator rewards, even if validators have varying degrees of sophistication.</strong> For example, if the protocol could accurately burn all MEV, then the validator incentives would be fully in the protocol’s view (just like <code>1a</code>, <code>1b</code>, &amp; <code>2a</code> above). Alternatively, a mechanism that shares all MEV among validators regardless of their sophistication (e.g., <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">mev-smoothing</a>) would seem to promote a larger, more diverse and decentralized validator set, while keeping the MEV rewards as an extra incentivization to stake. Without MEV awareness, the validators best equipped to extract or smooth MEV (e.g., due to relationships with block builders, proprietary algorithms/software, access to exclusive order flow, &amp; economies of scale) may earn disproportionately high rewards and exert significant centralization pressures on the protocol.</p>
<p>Ethereum protocol design strives to keep a decentralized validator set at all costs. It probably goes without saying, but for completeness: <strong>the protocol’s credible neutrality, censorship resistance, and permissionlessness are directly downstream of a decentralized validator set.</strong></p>
<h4><a class="anchor" href="https://ethresear.ch#block-space-distribution-today-5" name="block-space-distribution-today-5"></a>Block-space distribution today</h4>
<p>In Ethereum today, <a href="https://mevboost.pics/" rel="noopener nofollow ugc"><code>mev-boost</code></a> accounts for <span class="math">\approx 90\%</span> of all blocks. Using <code>mev-boost</code>, proposers (the validator randomly selected as the leader) sell their block-building rights to the highest paying bidder through an auction. The figure below demonstrates this flow (we exclude the <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">relays</a> because they functionally serve as an extension of the builders).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/7/b70bdfef2fd8dc26a478c2b870495ea39ebd07bc.png" title="upload_5f698b1a28978bd8f9779e596c471d9a"><img alt="upload_5f698b1a28978bd8f9779e596c471d9a" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/b/7/b70bdfef2fd8dc26a478c2b870495ea39ebd07bc_2_252x499.png" width="252" /></a></div><br />
.<br />
Proposers are incentivized to outsource their block building because builders (the canonical name for MEV-extracting agents specializing in sequencing transactions) pay them more than they would have earned had they built the block themselves. Circling back to our goal of “<strong>preserving the homogeneity of validator rewards in the presence of MEV</strong>,” we see that <code>mev-boost</code> allows access to the builder market for <em>all validators</em>, effectively preserving near-equivalent MEV rewards among solo stakers and professional staking service providers – great! But…<p></p>
<p>Of course, there is a but… <code>mev-boost</code> has issues that continue to rankle some of the Ethereum community. Without being exhaustive, a few of the negative side-effects of taking the <code>mev-boost</code> medicine are:</p>
<ul>
<li><strong>Relays</strong> – These <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">trusted-third parties</a> broker the sale of blocks between proposers and builders. The immense reliance on relays increases the fragility of the protocol as a whole, as demonstrated through <a href="https://collective.flashbots.net/t/disclosure-mitigation-of-block-equivocation-strategy-with-early-getpayload-calls-for-proposers/1705" rel="noopener nofollow ugc">repeated</a>, <a href="https://research.lido.fi/t/bloxroute-feb-6th-post-mortem/6586" rel="noopener nofollow ugc">incidents</a>, <a href="https://gist.github.com/benhenryhunter/5c397db3985a59d14a52816305a6c1b8" rel="noopener nofollow ugc">involving</a>, <a href="https://gist.github.com/benhenryhunter/7b7d9c9e3218aad52f75e3647b83a6cc" rel="noopener nofollow ugc">relays</a>. Further, since relays have no inherent revenue stream, more exotic (and closed-source) methods of capturing margins (e.g., <a href="https://bloxroute.com/pulse/introducing-the-validator-gateway-boost-your-ethereum-validator-rewards/" rel="noopener nofollow ugc">timing games as a service</a> and <a href="https://twitter.com/sui414/status/1778708084510302445" rel="noopener nofollow ugc">bid adjustments</a>) are being implemented.</li>
<li><strong>Out-of-protocol software is brittle</strong> – Beyond the relays, participation in the <code>mev-boost</code> market requires validators to run additional software. The standard suite for solo staking now involves running four binaries: (i) the consensus beacon node, (ii) the consensus validator client, (iii) the execution client, and (iv) mev-boost. Beyond the significant overhead for solo stakers, reliance on this software also provides another potential point of failure during hard forks. See the <a href="https://collective.flashbots.net/t/impact-of-the-prysm-invalid-signature-bug-on-the-mev-boost-ecosystem-at-the-shapella-fork/1623" rel="noopener nofollow ugc">Shapella incident</a> and the <a href="https://writings.flashbots.net/preparing-for-dencun" rel="noopener nofollow ugc">Dencun upgrade</a> for an example of the complexity induced by having more out-of-protocol software.</li>
<li><strong>Builder centralization and censorship</strong> – While this is likely <a href="https://vitalik.eth.limo/general/2021/12/06/endgame.html" rel="noopener nofollow ugc">inevitable</a>, builder centralization was accelerated by the mass adoption of <code>mev-boost</code>. <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">Three builders</a> account for <span class="math">\approx 95\%</span> of <code>mev-boost</code> blocks (<span class="math">85\%</span> of all Ethereum blocks). <code>mev-boost</code> implements an open-outcry, first-price, winner-takes-all auction, leading to high levels of builder concentration and <a href="https://ethresear.ch/t/game-theoretic-model-for-mev-boost-auctions-mma/16206">strategic</a>, <a href="https://ethresear.ch/t/bid-cancellations-considered-harmful/15500">bidding</a>. Without <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">inclusion lists</a> or another censorship-resistance gadget, builders have extreme influence over transaction inclusion and exclusion – see <a href="https://censorship.pics/" rel="noopener nofollow ugc">censorship.pics</a>.</li>
<li><strong>Timing games</strong> – While <a href="https://arxiv.org/abs/2305.09032" rel="noopener nofollow ugc">timing games</a> are known to be a fundamental issue in Proof-of-Stake protocols, <code>mev-boost</code> pushes staking service providers to compete on thin margins. Additionally, relays (who conduct <code>mev-boost</code> auctions on the proposer’s behalf) serve as sophisticated middlemen facilitating timing games. Thus, we have seen <a href="https://p2p.org/economy/unlock-p2p-orgs-mev-enhancement-feature/" rel="noopener nofollow ugc">marketing</a> endorsing playing timing games to boost the yield from staking with a specific provider.</li>
</ul>
<p><em>“OK, OK … blah blah … we have heard this story before … <a href="https://youtu.be/q8wJqMbr6eY?si=LVryerWbrw3_ge-I" rel="noopener nofollow ugc">tell me something I don’t know</a>.” (<span class="math">\leftarrow</span> h/t Barnabé for the aptly-named, 14k-views on youtube, musical reference.)</em></p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-enumeration-6" name="h-2-enumeration-6"></a>(2) – Enumeration</h3>
<p>Obligatory ‘stage-setting’ out of the way, let’s look a little more carefully at the ~essence~ of a block-space distribution mechanism.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/55cc9892e24d897856dff5e70b48fe8682903b6e.jpeg" title="upload_cdbf47258422c2a96ea2903ce113a113"><img alt="upload_cdbf47258422c2a96ea2903ce113a113" height="367" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/55cc9892e24d897856dff5e70b48fe8682903b6e_2_552x367.jpeg" width="552" /></a></div><br />
<sub><strong>^ “<a href="https://youtu.be/mvy4YH9--Vw?t=108" rel="noopener nofollow ugc"><em>Is that what I think it is?</em></a>”</strong></sub><p></p>
<h4><a class="anchor" href="https://ethresear.ch#the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7" name="the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7"></a>The <a href="https://en.wikipedia.org/wiki/Euclid%27s_Elements" rel="noopener nofollow ugc">elements</a> of block-space distribution</h4>
<p>Consider the game of acquiring block space; MEV incentivizes agents to participate, while the combination of in-protocol and out-of-protocol software defines the rules. When designing this game, what elements should be considered? To answer this question, we use a familiar rhetorical pattern of “who, what, when, where, &amp; how” (hopefully <a href="https://ethresear.ch#h-1-motivation-3">Section 1</a> sufficiently answered “why”), which we refer to as the <code>W^4H questions</code>. (<span class="math">\leftarrow</span> h/t Barnabé pt. 2 for the connection to “<a href="https://www.goodreads.com/book/show/22749723-who-gets-what-and-why" rel="noopener nofollow ugc"><em>Who Gets What – and Why</em></a>”).</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em></li>
<li><em><strong>What</strong> is the good that players are competing for?</em></li>
<li><em><strong>When</strong> does the game take place?</em></li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em></li>
<li><em><strong>How</strong> is the block builder chosen?</em></li>
</ul>
<p>These questions might seem overly simplistic, but when considered in isolation, each can be viewed as an axis in the design space to measure mechanisms. To demonstrate this, we highlight a few different species from the block-space distribution mechanism <a href="https://en.wikipedia.org/wiki/Genus" rel="noopener nofollow ugc">genus</a> that have been explored in the past. While they may feel disjointed and unrelated, their relationship is clarified by understanding how they answer the <code>W^4H questions</code>.</p>
<h4><a class="anchor" href="https://ethresear.ch#execution-tickets-and-other-animals-8" name="execution-tickets-and-other-animals-8"></a>Execution tickets and other animals</h4>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/5/05be4a7b2ce343036ba89733f9371dc1cbaa2b5b.jpeg" title="upload_23e73e8aae1d7223973af83053d41ebc"><img alt="upload_23e73e8aae1d7223973af83053d41ebc" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/0/5/05be4a7b2ce343036ba89733f9371dc1cbaa2b5b_2_328x500.jpeg" width="328" /></a></div><br />
<sub><strong>^ fantastic book.</strong></sub><p></p>
<p>We present a compendium of many different proposed mechanisms. Note that this is only a subset of the rather substantial literature around these designs – cf. <a href="https://notes.ethereum.org/@mikeneuder/infinite-buffet" rel="noopener nofollow ugc">infinite buffet</a>. For each of the following, we summarize only the key ideas (see <a href="https://ethresear.ch#related-work-2">related work</a> for more).</p>
<ul>
<li>Execution tickets
<ul>
<li><strong>Key ideas</strong> – Block building and proposing rights are sold directly through “tickets” issued by the protocol. Ticket holders are randomly sampled to become block builders with a fixed lookahead. The ticket holder has the authority to produce a block at the assigned slot.</li>
</ul>
</li>
<li>Block-auction PBS
<ul>
<li><strong>Key ideas</strong> – The protocol bestows block production rights through a random leader-election process. The selected validator can sell their block outright to the builder market or build it locally. The builder must ~commit to a specific block~ when bidding in the auction. <code>mev-boost</code> is an out-of-protocol instantiation of block-auction PBS; enshrined PBS (ePBS), as <a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980">originally presented</a>, is the in-protocol equivalent.</li>
</ul>
</li>
<li>MEV-burn/mev-smoothing
<ul>
<li><strong>Key ideas</strong> – A committee is tasked with enforcing a minimum value over the bid the proposer selects in an auction. By requiring the proposer to choose a “large enough” bid, an MEV oracle is created. The MEV is either <em>smoothed</em> between committee members or <em>burned</em> (smoothed over all <code>ETH</code> holders).</li>
</ul>
</li>
<li>Slot-auction PBS
<ul>
<li><strong>Key ideas</strong> – Similar to block-auction PBS but instead sells the <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">slot</a> to the builder market ~without~ requiring a commitment to a specific block – sometimes referred to as block space futures. By not requiring the builders to commit to a particular block, future slots may be auctioned off ahead of time rather than waiting until the slot itself.</li>
</ul>
</li>
<li>Partial-block auction
<ul>
<li><strong>Key ideas</strong> – Allows a more flexible unit for selling block-space. Instead of selling the full block or slot, allow proposers to sell <em>some</em> of their block, e.g., the top-of-block (which is the most valuable for arbitrageurs), while retaining the rest-of-block construction. Live in other Proof-of-Stake networks, e.g., Jito’s <a href="https://jito-labs.gitbook.io/mev/searcher-resources/block-engine" rel="noopener nofollow ugc">block engine</a> and Skip <a href="https://docs.skip.money/blocksdk/lanes/existing-lanes/mev" rel="noopener nofollow ugc">MEV lane</a>.</li>
</ul>
</li>
<li>APS-burn a.k.a. Execution Auction (nomenclature in flux &amp; the EA acronym has a bit of … <a href="https://en.wikipedia.org/wiki/Effective_altruism" rel="noopener nofollow ugc">baggage</a>)
<ul>
<li><strong>Key ideas</strong> – A brand new proposal from <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">Barnabé</a> which compels a proposer to auction off the block building and proposing rights ahead of time. The slot is sold ex-ante (a fixed amount of time in advance) without requiring a commitment to a specific block; a committee (à la mev-burn/smoothing) enforces the winning bid is sufficiently large.</li>
</ul>
</li>
</ul>
<p>We know, we know – it’s a lot to keep track of; it’s nearly a full-time job just to stay abreast of all these acronyms. But by comparing these proposals along the axes laid out by the <code>W^4H questions</code>, we can see how they all fit together as different parts of the same design space.</p>
<h4><a class="anchor" href="https://ethresear.ch#applying-w4h-a-comparative-analysis-9" name="applying-w4h-a-comparative-analysis-9"></a>Applying W^4H: a comparative analysis</h4>
<p>For each of the five <code>W^4H questions</code>, we describe different trade-offs made by the aforementioned proposals. For brevity, we don’t analyze each question for each proposal; we instead focus on highlighting key differences arising from each line of questioning.</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em>
<ul>
<li>With execution tickets, the protocol dictates the winner of the game by randomly choosing from the set of ticket holders.</li>
<li>With block-auction PBS, the proposer (protocol-elected leader) unilaterally chooses the winner of the game.</li>
<li>With mev-burn, the proposer still chooses the winner, but the winning bid is constrained by the committee, reducing the proposer’s agency.</li>
</ul>
</li>
<li><em><strong>What</strong> is the good that players are competing for?</em>
<ul>
<li>With block-auction PBS, the entire block is sold, but bids must commit to the block contents.</li>
<li>With slot-auction PBS, the entire block is sold, but without any specific block commitment.</li>
<li>With partial-block PBS, a portion of the block is sold.</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>With block-auction PBS, the auction takes place during the slot.</li>
<li>With slot-auction PBS, the auction may take place many slots (e.g., 32) ahead of time because there is no block-content commitment.</li>
<li>With execution tickets, the tickets are assigned to slots at a fixed lookahead after being sold ex-ante by the protocol (more on the ticket-selling model we use below).</li>
</ul>
</li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em>
<ul>
<li>With mev-burn/smoothing, a committee enforces that a sufficiently large bid is selected as the winner; this bid size is the oracle.</li>
<li>With execution tickets, the total money spent on tickets serves as the oracle.</li>
</ul>
</li>
<li><em><strong>How</strong> is the block builder chosen?</em>
<ul>
<li>In block-auction PBS, any outsourced block production has a winner-take-all allocation, with the highest bidder granted the block-building rights.</li>
<li>Within execution tickets, many different allocation mechanisms can be implemented. In the original proposal, for example, where a random ticket is selected, the mechanism is ‘proportional-to-ticket-count’; in this case, the highest paying bidder (whoever holds the most tickets) merely has the highest probability of being selected, meaning they are not guaranteed the block building rights.</li>
<li>If that (^) seems opaque, don’t worry. The entire following section is a deep dive into these different allocations.</li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#motivational-interlude-10" name="motivational-interlude-10"></a>Motivational interlude</h4>
<p>Before continuing, let’s review our original motivation for block-space distribution mechanisms:</p>
<blockquote>
<p><strong>Block-space distribution mechanisms aim to preserve the homogeneity of validator rewards in the presence of MEV.</strong></p>
</blockquote>
<p>This is a great grounding, but if that is our only goal, why not just continue using <code>mev-boost</code>? Well, remember that <code>mev-boost</code> has some negative side effects that we probably want the endgame protocol to be resilient against. We highlight four other potential design goals of a block-space distribution mechanism:</p>
<ol>
<li><em>Encouraging a wider set of builders to be competitive.</em></li>
<li><em>Allow validators and builders to interact trustlessly.</em></li>
<li><em>Incorporating MEV-awareness into the base layer protocol.</em></li>
<li><em>Removing MEV from validator rewards altogether.</em></li>
</ol>
<p>Note that while (1, 2, &amp; 3) appear relatively uncontroversial (*knock on wood*), (4) is more opinionated (and requires (3) as a pre-condition). The protocol may hope to eliminate MEV rewards from validator rewards as a means to ensure that the consensus layer rewards (what the protocol controls) more accurately reflect the full incentives of the system. This also ties into questions around staking macro-economics and the idea of <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">protocol</a>, <a href="https://notes.ethereum.org/@mikeneuder/iiii" rel="noopener nofollow ugc">issuance</a> – a much more politically-charged discussion. On the other hand, MEV rewards are a byproduct of network usage; MEV could instead be seen as a <a href="https://www.nano210.blog/infinite-blockspace-equilibrium/" rel="noopener nofollow ugc">value capture</a> mechanism for the native token. We aren’t trying to address these questions here but rather explore how different answers to them would shape the design of the mechanism.</p>
<p>What can we do at the protocol-design level to align with these desiderata? As laid out above, there are many trade-offs to consider, but in the following section, we examine “<em>How is the block builder chosen?</em>” to improve on some of these dimensions.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-interrogation-11" name="h-3-interrogation-11"></a>(3) – Interrogation</h3>
<p><strong>Editorial note:</strong> As mentioned earlier, this section is longer and more technical than the others – feel free to skip to <a href="https://ethresear.ch#h-4-extrapolation-18">Section 4</a> if you are time (or interest) constrained!</p>
<p><strong>Section goal:</strong> <em>To demonstrate the quantitative trade-off between MEV-oracle quality and the “fairness” of the two most familiar approaches to allocating block proposer rights, which we call <code>Proportional-all-pay</code> and <code>Winner-take-all</code>.</em></p>
<p>We aim to accomplish this with the following subsections:</p>
<ul>
<li><a href="https://ethresear.ch#preliminaries-12"><em>Preliminaries</em></a> – Motivate the fixed-price, unlimited-quantity execution ticket sale mechanism we use.</li>
<li><a href="https://ethresear.ch#model-13"><em>Model</em></a> - Introduce the notation needed to analyze the model.</li>
<li><a href="https://ethresear.ch#familiar-allocation-mechanisms-14"><em>Familiar allocation mechanisms</em></a> - Describe the <code>Proportional-all-pay</code> and <code>Winner-take-all</code> mechanisms using the established framework.</li>
<li><a href="https://ethresear.ch#comparing-the-outcomes-15"><em>Comparing the outcomes</em></a> - Calculate the resulting equilibria in a two-player example.</li>
<li><a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16"><em>Aside #1: Calculating equilibrium bids</em></a> - Derive the equilibria in the general case.</li>
<li><a href="https://ethresear.ch#aside-2-tullock-contests-17"><em>Aside #2: Tullock Contests</em></a> - Contextualize the model as a Tullock Contest and draw connections to the existing literature.</li>
</ul>
<p>Let’s <a href="https://youtu.be/GLsCR2RMBak?t=119" rel="noopener nofollow ugc">dig</a> in.</p>
<h4><a class="anchor" href="https://ethresear.ch#preliminaries-12" name="preliminaries-12"></a>Preliminaries</h4>
<p>Before diving into the space of allocation mechanisms made possible with execution tickets, we must first set up the model. Consider a protocol that sells execution tickets with the following rules:</p>
<ol>
<li>the price is fixed at <code>1 WEI</code>, and</li>
<li>unlimited tickets can be bought and sold from the protocol.</li>
</ol>
<p><strong>Note:</strong> <em>this version of execution tickets is effectively equivalent to creating two disjoint staking mechanisms – one each for attesting and proposing. Small changes in the design, e.g., not allowing tickets to be resold to the protocol, may have massive implications for how the market plays out, but that isn’t the focus of this article. Instead, we narrowly explore the question of block-space allocation, given an existing ticket holder set.</em></p>
<p>Notably, the set of block producers is disjoint (from the protocol’s perspective) from the set of attesters – individuals must select which part of the protocol they participate in by deciding whether to stake or buy tickets. The secondary ticket market may evolve as a venue for selling the building rights just in time to the builder market (as is done in <code>mev-boost</code> today).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e4f36ef0b6e6e5d80c4a923d9465bf74212af039.png" title="upload_45a1fa23182dd6a28c2c07dc2479f150"><img alt="upload_45a1fa23182dd6a28c2c07dc2479f150" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e4f36ef0b6e6e5d80c4a923d9465bf74212af039_2_486x499.png" width="486" /></a></div><br />
<span class="math">\cdot</span><br />
Separately, builders may choose to interact directly with the protocol by buying execution tickets themselves, but their capital may be better utilized as active liquidity, capturing arbitrage across trading venues. Thus, they may prefer buying block space on the secondary market during the just-in-time auction instead.<p></p>
<p>Why restrict ourselves to this posted-price-unlimited-supply mechanism? Two reasons:</p>
<ol>
<li><em>It’s not clear that a sophisticated market could even be implemented in the consensus layer.</em> The clients are optimized to allow any validator with consumer-grade hardware to participate in the network. This desideratum may be incompatible with fast auctions, bonding curves, or other possible ticket-selling mechanisms. Questions around how many tickets are sold, the MEV around onchain ticket-sale inclusion (meta-MEV?!), and the timing (and timing games) of ticket sales seem closer to execution layer concerns than something that could reasonably be implemented by Ethereum consensus while keeping hardware requirements limited.</li>
</ol>
<blockquote>
<p>“<em>One may imagine the inclusion of ET market-related transactions to possibly induce MEV, whether these transactions are included in the beacon block or the execution payload.</em>” – <strong>Barnabé in</strong> “<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>.”</p>
</blockquote>
<ol start="2">
<li><em>Even if (a big if) the protocol ~could~ implement a more rigid ticket-selling market, the design space for such a mechanism is immense.</em> Many potential pricing mechanisms have been discussed, e.g., bonding curves, 1559-style dynamic pricing, auctions, etc.; making general claims about these remains outside the scope of this post.</li>
</ol>
<p>Therefore, we focus on the “unlimited, 1 <code>WEI</code> posted-price” version of execution tickets, where the protocol internalizes minimal complexity. With this framing, we can ask the question that is probably <a href="https://youtu.be/5KNEZJ6KkLI?t=53" rel="noopener nofollow ugc">burning</a> you up inside, “<em>given a set of execution ticket holders, how should the winner be selected?</em>” … sounds easy enough, right? Turns out there is a good deal we can say, even with such a seemingly simple question; let’s explore a few different options.</p>
<h4><a class="anchor" href="https://ethresear.ch#model-13" name="model-13"></a>Model</h4>
<p>Consider the repeated game of buying execution tickets to earn MEV rewards for your investment.</p>
<ul>
<li>During each period, each player effectively submits a bid, which is the number of tickets they buy. Denote the vector of bids by <span class="math">\mathbf{b}</span>, where <span class="math">b_i</span> is the bid of the <span class="math">i^{th}</span> player.</li>
<li>Each player has a valuation for winning the block production rights. Denote the vector of valuations by <span class="math">\mathbf{v}</span>, where <span class="math">v_i</span> is the value of the <span class="math">i^{th}</span> player.</li>
<li>At each time step, an allocation mechanism determines each player’s allocation based on the vector of bids. Assuming bidders are risk-neutral (i.e., don’t care between winning 2 <code>ETH</code> with probability <span class="math">0.5</span> vs. 1 <code>ETH</code> with probability <span class="math">1</span>), we can equivalently say that they are each allocated “some portion” of the block, which can be alternatively be interpreted as “the probability that they win a given block.” In an <span class="math">n</span> player game, let <span class="math">x: \mathbf{b} \rightarrow [0,1]^n</span> denote the map implementing an allocation mechanism, where <span class="math">x_i(\mathbf{b})</span> is the allocation of the <span class="math">i^{th}</span> player, under the constraint that <span class="math">\sum_i x_i(\mathbf{b}) =1</span> (i.e., the mechanism fully allocates).</li>
<li>Each player’s payment is collected at each round. Let <span class="math">p: \mathbf{b} \rightarrow \mathbb{R}_{\geq 0}^n</span> denote the payment rule determined by the set of bids, where <span class="math">p_i(\mathbf{b})</span> is the payment of the <span class="math">i^{th}</span> player.</li>
<li>The utility function of each player in the game is, <span class="math">U_i(\mathbf{b}) = v_i x_i(\mathbf{b}) - p_i(\mathbf{b})</span>. The intuition is that “a player’s utility is their value for winning multiplied by the amount they won, less their payment.”</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#familiar-allocation-mechanisms-14" name="familiar-allocation-mechanisms-14"></a>Familiar allocation mechanisms</h4>
<p>Consider two (quite different) possible mechanisms.</p>
<p><code>Proportional-all-pay</code> (a slight modification to the <a href="https://ethresear.ch/t/execution-tickets/17944">original</a> execution tickets proposal)</p>
<ul>
<li>During each round, all players submit a bid. Denote the vector of bids by <span class="math">\mathbf{b}</span>.</li>
<li>The probability that a bid wins the game is the value of the bid divided by the sum of all the values of the bids,</li>
</ul>
<div class="math">
x_i(\mathbf{b}) = \frac{b_i}{\sum_j b_j}.
</div>
<ul>
<li>Each player pays their bid, no matter the outcome of the game (hence “all-pay”), <span class="math">p_i(\mathbf{b}) = b_i.</span><a href="https://ethresear.ch#fn1dst"><span class="math">^{[1]}</span></a><a href="https://ethresear.ch" name="fn1"></a></li>
</ul>
<p><code>Winner-take-all</code> (the current implementation of PBS)</p>
<ul>
<li>During each round, all players submit a bid. Denote the vector of bids by <span class="math">\mathbf{b}</span>.</li>
<li>The highest bidder wins the game, so <span class="math">x_i(\mathbf{b}) = 1</span> if <span class="math">\max(\mathbf{b}) = b_i</span> and <span class="math">x_i(\mathbf{b}) = 0</span> otherwise (where ties are broken in favor of the lower index bidder, say).</li>
<li>Only the winning player pays the value of their bid, so <span class="math">p_i(\mathbf{b}) = b_i</span> if <span class="math">\max(\mathbf{b}) = b_i</span> and <span class="math">p_i(\mathbf{b}) = 0</span> otherwise (same tie-breaking as above).<a href="https://ethresear.ch#fn2dst"><span class="math">^{[2]}</span></a><a href="https://ethresear.ch" name="fn2"></a></li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#comparing-the-outcomes-15" name="comparing-the-outcomes-15"></a>Comparing the outcomes</h4>
<p>To demonstrate the different outcomes from these two mechanisms, consider the two-player game where <code>Player 1</code> has a valuation of <span class="math">v_1 = 4</span> and <code>Player 2</code> has a valuation of <span class="math">v_2 = 2.</span> (We consider a complete information setting in which the individual values are common knowledge. To see how the equilibria bid is calculated and for extended discussion, see <a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16">Aside 1</a>.)</p>
<ul>
<li><strong><code>Proportional-all-pay</code> outcome:</strong>
<ul>
<li>Equilibrium Bids: <span class="math">\qquad\,\,\,\;\;\; b_1 = 8/9</span>, <span class="math">\,b_2 = 4/9</span></li>
<li>Equilibrium Allocations: <span class="math">\;\;\; x_1 = 2/3</span>, <span class="math">x_2 = 1/3</span></li>
<li>Equilibrium Payments: <span class="math">\;\;\;\; p_1 = 8/9</span>, <span class="math">\,p_2 = 4/9</span></li>
</ul>
</li>
</ul>
<p>This all should feel intuitively correct; with <span class="math">v_1 = 2 \cdot v_2</span> (<code>Player 1</code> has <code>2x</code> the value for the block), <code>Player 1</code> bids, receives and pays twice as much as <code>Player 2</code>.</p>
<ul>
<li><strong><code>Winner-take-all</code> outcome:</strong>
<ul>
<li>Equilibrium Bids: <span class="math">\qquad\,\,\,\;\;\; b_1 = 2+\epsilon</span>, <span class="math">b_2 = 2</span></li>
<li>Equilibrium Allocations: <span class="math">\;\;\; x_1 = 1</span>, <span class="math">\quad\;\; x_2 = 0</span></li>
<li>Equilibrium Payments: <span class="math">\;\;\;\,\, p_1 = 2+\epsilon</span>, <span class="math">p_2 = 0</span></li>
</ul>
</li>
</ul>
<p>This is pretty different. <code>Player 1</code> bids and pays just over <code>Player 2</code>’s value (we use <span class="math">\epsilon</span> to denote a small amount), receiving the entire allocation. <code>Player 2</code> receives nothing and pays nothing.<a href="https://ethresear.ch#fn3dst"><span class="math">^{[3]}</span></a><a href="https://ethresear.ch" name="fn3"></a></p>
<p>Now consider the “revenue” (or the sum of the bids collected by the mechanism) generated from each case:</p>
<ul>
<li><strong><code>Proportional-all-pay</code> revenue:</strong> <span class="math">b_1 + b_2 = 4/3</span></li>
<li><strong><code>Winner-take-all</code> revenue:</strong> <span class="math">\qquad\quad\,\,\,\;\;\;\; b_1 = 2+\epsilon</span></li>
</ul>
<p><code>Winner-take-all</code> has better revenue, corresponding to a more accurate MEV oracle (and thus more MEV burned or smoothed by the protocol) than <code>Proportional-all-pay</code>. Intuitively, by allocating block-production rights to players with lower values (as <code>Proportional-all-pay</code> does), we forgo revenue we would have received had we simply allocated the entire rights to the player with the highest value. We point the interested reader to <a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16">Aside 1</a> for a more complete treatment.</p>
<p>Another factor to consider is the “fairness” or “distribution” of the allocation mechanism. For example, suppose we agree on the metric: <span class="math">\text{fairness} = \sqrt{x_1 \cdot x_2}</span> (we use the geometric mean because if <span class="math">x_1 + x_2</span> has a fixed sum, the geometric mean is maximized at <span class="math">x_1 = x_2</span> and zero if either <span class="math">x_1,x_2</span> is zero). Now, let’s look at the fairness outcomes of the two candidate mechanisms:</p>
<ul>
<li><strong><code>Proportional-all-pay</code> fairness:</strong> <span class="math">\sqrt{1/3 \cdot 2/3} \approx 0.471</span></li>
<li><strong><code>Winner-take-all</code> fairness:</strong> <span class="math">\qquad\qquad\;\,\;\sqrt{1 \cdot 0} = 0</span></li>
</ul>
<p>Here, the “performance” of the two mechanisms flips – the <code>Winner-take-all</code> is <em>less fair</em> because <code>Player 2</code> has no chance of winning the game with a lower value. In the <code>Proportional-all-pay</code>, <code>Player 2</code> can hope to win some blocks despite bidding a lower value. As another example, consider the case where <span class="math">v_1=v_2+\epsilon</span>. The <code>Winner-take-all</code> mechanism allocates all the rights to <code>Player 1</code>, while the <code>Proportional-all-pay</code> splits the rights approximately in half.</p>
<blockquote>
<p>Brief note: why might the protocol care about fairness? In a decentralized protocol, a single actor having too much power undermines the credible neutrality of the system. As such, the protocol may be willing to “pay” (in the form of reduced revenue) to ensure that a resource is more evenly distributed among players. Alternatively, we could consider this a measure of “entropy” or even simply randomness being injected into the outcome of the game to try to reduce the influence the most dominant player can have.</p>
</blockquote>
<p>This leads to the punchline from this small example: <strong>a fundamental trade-off exists between MEV-oracle quality and fairness.</strong> The <code>Proportional-all-pay</code> mechanism (and hence the original execution tickets proposal) is fairer because both players win the game with some probability, incentivizing them each (but more importantly, the higher value player) to <a href="https://en.wikipedia.org/wiki/Bid_shading" rel="noopener nofollow ugc">shade</a> their bid accordingly, lowering the revenue, and thus the MEV-oracle accuracy, of the mechanism. The first price mechanism elicits higher bids since bidders only pay if they win the entire block production rights, increasing the revenue, but this <code>Winner-take-all</code> dynamic makes the allocation less fair.</p>
<p><em>Open question: is <code>Proportional-all-pay</code> an “optimal” Sybil-proof mechanism?</em> In the permissionless setting, we only consider Sybil-proof mechanisms, where a player doesn’t benefit from splitting their bid into multiple identities. We posit that the <code>Proportional-all-pay</code> mechanism sits in the <a href="https://en.wikipedia.org/wiki/Habitable_zone" rel="noopener nofollow ugc">Goldilock’s Zone</a> of a Sybil-proof mechanism that gets both good revenue/MEV-oracle accuracy and fairness. We leave as an interesting open problem to determine the extent to which the <code>Proportional-all-pay</code> mechanism’s “optimality” (e.g., we were unable to find another Sybil-proof mechanism that dominates it in both revenue and fairness).</p>
<h4><a class="anchor" href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16" name="aside-1-calculating-equilibrium-bids-16"></a>Aside <span class="hashtag-raw">#1</span> – Calculating equilibrium bids</h4>
<p><a href="https://ethresear.ch#h-4-extrapolation-18">Convenience link</a> to skip to the conclusion for the less-keen reader <img alt=":wink:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wink.png?v=12" title=":wink:" width="20" /></p>
<p>In the numerical example above, we provide the equilibrium bids for the <code>Winner-take-all</code> and <code>Proportional-all-pay</code> mechanisms without proof. How can these be determined generally (e.g., continuing to assume that bidders’ values are common knowledge)?<a href="https://ethresear.ch#fn4dst"><span class="math">^{[4]}</span></a><a href="https://ethresear.ch" name="fn4"></a></p>
<p>The <code>Winner-take-all</code> is the familiar <a href="https://www.econport.org/econport/request?page=man_auctions_firstpricesealed" rel="noopener nofollow ugc">First Price Auction</a> setting. In such auctions, the complete information Pure-Nash equilibrium has the two highest-value bidders, each bidding the second-highest bidder’s value, with every other agent bidding below this. In effect, we expect that the highest-value bidder always wins while paying the second highest bidder’s value (we represent this simply as <span class="math">b_1=b_2+\epsilon</span>, though you could equivalently tie-break in favor of the higher-value player).</p>
<p>In the <code>Proportional-all-pay</code> setting, each player has the utility,</p>
<div class="math">
\begin{align}
U_i (\mathbf{b}) &amp;= v_i \cdot x_i(\mathbf{b}) - b_i \\
&amp;= v_i \cdot \frac{b_i}{\sum_j b_j} - b_i.
\end{align}
</div>
<p>To determine the existence of a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" rel="noopener nofollow ugc">Pure Nash Equilibrium</a>, we consider each player’s first- and second-order conditions. Let <span class="math">\mathbf{b}^*</span> denote the candidate equilibrium set of bids.</p>
<ol>
<li><strong>First-order condition</strong>: <span class="math">\partial U_i / \partial b_i (\mathbf{b^*}) = 0</span> (or <span class="math">\partial U_i / \partial b_i (\mathbf{b^*}) \leq 0, \;\forall i \text{ s.t. } b^*_i=0</span>.)
<ul>
<li>Intuitively, this condition checks a non-zero-bidding player is (to first order) locally indifferent to small changes in its bid.</li>
</ul>
</li>
<li><strong>Second-order condition</strong>: <span class="math">\partial^2 U_i / \partial b_i^2 &lt; 0</span>
<ul>
<li>Intuitively, this condition ensures that the utility function is concave, implying that locally best responses are globally best for all players.</li>
</ul>
</li>
</ol>
<p>In our simple two-player example in the <code>Proportional-all-pay</code> setting, we have the following.</p>
<div class="math">
\begin{align}
\frac{\partial U_1}{\partial b_1}(\mathbf{b}) = \frac{v_1 b_2}{(b_1 + b_2)^2} - 1 = 0 \; , \quad \frac{\partial U_2}{\partial b_2}(\mathbf{b}) = \frac{v_2 b_1}{(b_1 + b_2)^2} - 1 = 0
\end{align}
</div>
<p>This system can be solved to find the equilibrium bids, <span class="math">\mathbf{b}^*</span>,</p>
<div class="math">
\begin{align}
b^*_1 = \frac{v_1^2 v_2}{(v_1 + v_2)^2}\; , \quad b^*_2 = \frac{v_2^2 v_1}{(v_1 + v_2)^2}.
\end{align}
</div>
<p>For our toy example, we have <span class="math">v_1=4, \; v_2=2 \implies b_1^* = 32/36, \; b_2^* = 16/36</span>. We can verify our first-order conditions</p>
<div class="math">
\begin{align}
\frac{4 \cdot 16/36}{16/9} - 1 = 0 \; , \quad \frac{2 \cdot 32/36}{16/9} - 1 = 0 \quad \checkmark
\end{align}
</div>
<p>The second-order conditions can also be verified – this is left as an exercise for the reader <img alt=":wink:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wink.png?v=12" title=":wink:" width="20" /></p>
<h4><a class="anchor" href="https://ethresear.ch#aside-2-tullock-contests-17" name="aside-2-tullock-contests-17"></a>Aside <span class="hashtag-raw">#2</span> – Tullock Contests</h4>
<p><a href="https://youtu.be/lL2ZwXj1tXM?t=60" rel="noopener nofollow ugc">Last chance</a> to <a href="https://ethresear.ch#h-4-extrapolation-18">skip to the conclusion</a>. (If you continue, by definition, you are the “interested reader” – <a href="https://www.youtube.com/watch?v=SC4xMk98Pdc&amp;t=35s" rel="noopener nofollow ugc">congrats</a>.)</p>
<p>The model described above is established in the algorithmic game theory literature as a <a href="https://www.chapman.edu/ESI/wp/GeneralizedTullockContest-Sheremeta.pdf" rel="noopener nofollow ugc">Tullock Contest</a> – named for Gordon Tullock, who explored the idea in his seminal work, “<a href="https://link.springer.com/chapter/10.1007/978-3-540-79182-9_6" rel="noopener nofollow ugc"><em>Efficient Rent Seeking</em></a>.” He motivates this study by considering situations where investment is made before the outcome is known and where the investments might not transfer easily between participants, e.g., political spending.</p>
<blockquote>
<p>“<em>Suppose, for example, that we organize a lobby in Washington for the purpose of raising the price of milk and are unsuccessful. We cannot simply transfer our collection of contacts, influences, past bribes, and so forth to the steel manufacturers’ lobby. In general, our investments are too specialized, and, in many cases, they are matters of very particular and detailed goodwill to a specific organization. It is true that we could sell the steel lobby our lobbyists with their connections and perhaps our mailing list. But presumably, all these things have been bought by us at their proper cost. Our investment has not paid, but there is nothing left to transfer.</em>” – <strong>Gordon Tullock (1980)</strong></p>
</blockquote>
<p>This allocation mechanism has been applied in the previous crypto literature as well. Back in 2018 (ancient history in crypto-terms), Arnosti and Weinberg wrote “<a href="https://arxiv.org/abs/1811.08572" rel="noopener nofollow ugc"><em>Bitcoin: A natural oligopoly</em></a>,” which demonstrates that even small operating cost advantages among miners in a Proof-of-Work system lead to surprisingly concentrated equilibria. Similarly, Bahrani, Garimidi, and Roughgarden (these names sound familiar :D) explored the centralization effects of heterogeneity in block building skill in “<a href="https://arxiv.org/abs/2401.12120" rel="noopener nofollow ugc"><em>Centralization in Block Building and Proposer-Builder Separation</em></a>.” There appears to be a deep relationship between permissionless crypto-economic systems, where anti-Sybil mechanisms typically require financial investment for participation, and Tullock Contests – more on this <code>Soon™</code> (maybe).</p>
<h3><a class="anchor" href="https://ethresear.ch#h-4-extrapolation-18" name="h-4-extrapolation-18"></a>(4) – Extrapolation</h3>
<p>Phew, thanks for hanging in there; let’s take stock of what we learned. <strong><a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> demonstrates the fundamental trade-off between MEV-oracle accuracy and fairness of an instantiation of an execution ticket mechanism.</strong> A protocol may be willing to *pay* (in the form of reduced revenue) for more distribution and entropy with the goal of improving and maintaining the protocol’s credible neutrality. Further, using the model to derive equilibrium bids helps inform how we may expect agents to respond to various allocation and payment rules. <a href="https://youtu.be/Hm3JodBR-vs?t=21" rel="noopener nofollow ugc">Neat</a> – our framework led to some interesting and hopefully helpful insights! Maybe we can extend it to other problems in the space as well?</p>
<p>Further questions that this specific model may help answer (returning to three of our <code>W^4 questions</code>):</p>
<ul>
<li><em><strong>What</strong> is the good that players are competing for?</em>
<ul>
<li>Can we extend the model dimensionality, allowing different players to have different values for portions of the block (e.g., an arbitrageur may disproportionately value the top of a block but have zero value for the remainder)?</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>How does the MEV-oracle accuracy change if the game takes place far ahead of time versus during the slot itself (e.g., pricing future expected MEV versus present realizable MEV)?</li>
</ul>
</li>
<li><em><strong>How</strong> is the block builder chosen?</em>
<ul>
<li>Are there other Sybil-proof mechanisms that dominate <code>Proportional-all-pay</code> in both revenue and fairness?</li>
<li>Can we more formally characterize the fundamental trade-offs between revenue and fairness?</li>
<li>Given the Sybil-proofness constraint, what alternative allocation and payment rules should be explored (e.g., Tullock contests where the allocation rule is parameterized by <span class="math">\alpha&gt;1</span> where <span class="math">x_i = b_i^\alpha / \sum_j b_j^\alpha</span>), and can we identify the optimal choice?</li>
</ul>
</li>
</ul>
<p>Zooming back out, other versions of the <code>W^4H questions</code> may require different models to reason about.</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em>
<ul>
<li>In the committee-enforced version of these mechanisms, how could collusive behavior emerge?</li>
<li>If the just-in-time block auction continues to take place out-of-protocol, should we explicitly describe the secondary market?</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>How critical is network latency when considering lookahead block-space sales versus same-slot? Is it worth modeling the <a href="https://dl.acm.org/doi/pdf/10.1145/42282.42283" rel="noopener nofollow ugc">partially-synchronous</a> setting?</li>
<li>How do block builder valuations change if multi-slot MEV is feasible?</li>
</ul>
</li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em>
<ul>
<li>If it comes from the committee, are there incentives for committee members to behave dishonestly?</li>
<li>Do such incentives depend on whether protocol-captured MEV is burned or smoothed?</li>
</ul>
</li>
</ul>
<p>As per usual, open questions abound, but we hope (a) <code>W^4H questions</code> help expand the understanding of block-space distribution mechanisms and (b) the deep dive into allocation mechanisms helps inform the potential design space of execution tickets.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f4ceb270ae099c612cbb2afb4958a9bea1b42d1.jpeg" title="upload_a24cdf5b513fb4e410700573687adcd6"><img alt="upload_a24cdf5b513fb4e410700573687adcd6" height="493" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f4ceb270ae099c612cbb2afb4958a9bea1b42d1_2_690x493.jpeg" width="690" /></a></div><br />
<sub><strong>^ <a href="https://youtu.be/WSLMN6g_Od4?t=92" rel="noopener nofollow ugc">The world once we figure out MEV.</a></strong></sub><p></p>
<p>Excited to be here with y’all.</p>
<p><em>— made with <img alt=":heart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/heart.png?v=12" title=":heart:" width="20" /> by mike, pranav, &amp; dr. tim roughgarden.</em></p>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#footnotes-19" name="footnotes-19"></a>footnotes</h3>
<p><span class="math">^{[1]}</span><a href="https://ethresear.ch" name="fn1dst"></a>: The “all-pay” feature is made possible by burning the price paid for each ticket. <a href="https://ethresear.ch#fn1"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[2]}</span><a href="https://ethresear.ch" name="fn2dst"></a>: The “winner-pay” version could be done by refunding all non-winning ticket holders their payment at the end of each round. <a href="https://ethresear.ch#fn2"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[3]}</span><a href="https://ethresear.ch" name="fn3dst"></a>: As mentioned earlier, simply refunding the non-winning tickets instantiates the “winner-pays” property. <a href="https://ethresear.ch#fn3"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[4]}</span><a href="https://ethresear.ch" name="fn4dst"></a>: This is primarily for tractability in calculating equilibria analytically. Although a strong assumption, it’s not unreasonable in the context of lookahead auctions where bidders might have established prior distributions on their competitor’s valuations. We also view the insights from studying the complete-information equilibria as valuable heuristics for how we may expect these mechanisms to behave in practice. <a href="https://ethresear.ch#fn4"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 12:42:54 +0000</pubDate>
</item>
</channel>
</rss>