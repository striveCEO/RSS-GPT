<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Ethereum Research - Latest topics</title>
<link>https://ethresear.ch/latest</link>


<item>
<title>AUCIL: An Auction-Based Inclusion List Design for Enhanced Censorship Resistance on Ethereum</title>
<link>https://ethresear.ch/t/aucil-an-auction-based-inclusion-list-design-for-enhanced-censorship-resistance-on-ethereum/20422</link>
<guid>https://ethresear.ch/t/aucil-an-auction-based-inclusion-list-design-for-enhanced-censorship-resistance-on-ethereum/20422</guid>
<content:encoded><![CDATA[
<div> 关键词：AUCIL、输入列表创建机制、聚合策略、拍卖机制、抗审查能力

总结:
本文介绍了一种基于竞拍的纳入列表设计（AUCIL），旨在通过理性参与者的竞争来解决以太坊网络中中央化构建生态系统导致的审查问题。AUCIL设计了两个关键组件：

1. **输入列表创建机制**：允许委员会成员在不重复选择交易的同时最大化费用。这确保了许多被屏蔽的交易有机会被考虑纳入。

2. **拍卖机制**：鼓励参与者尽可能多地纳入输入列表，从而形成最终的输出纳入列表。这一机制旨在通过竞争激励，确保尽可能多的交易被纳入。

在AUCIL中，首先通过算法生成输入列表，每个参与者根据特定的概率分布选择交易，以避免贪婪策略带来的非均衡状态。接着，通过拍卖机制确定哪个参与者将获得构建下一个区块的权利，该参与者需要提交最大的交易集合，以此作为赢得拍卖的代价。

此外，文章还讨论了抗审查能力，分析了外部对手可能采取的贿赂策略，包括直接从输入列表中移除交易或减少聚合者的投标，以阻止特定交易的执行。为了应对这些攻击，文章提出使用随机偏置和证明机制来确保至少有p个参与者能够输出无审查的纳入列表。

总的来说，AUCIL通过创新的输入列表生成和聚合策略，结合拍卖机制，为以太坊网络提供了一种抵抗审查的方法，同时保持了系统的公平性和效率。 <div>
<p>By <a class="mention" href="https://ethresear.ch/u/sarisht">@sarisht</a> <a class="mention" href="https://ethresear.ch/u/kartik1507">@kartik1507</a> <a class="mention" href="https://ethresear.ch/u/voidp">@voidp</a> <a class="mention" href="https://ethresear.ch/u/soispoke">@soispoke</a> <a class="mention" href="https://ethresear.ch/u/julian">@Julian</a><br />
In collaboration with <a class="mention" href="https://ethresear.ch/u/barnabe">@barnabe</a> <a class="mention" href="https://ethresear.ch/u/luca_zanolini">@luca_zanolini</a> <a class="mention" href="https://ethresear.ch/u/fradamt">@fradamt</a> - <span class="discourse-local-date">2024-09-12T04:00:00Z UTC</span></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49946-tldr-1" name="p-49946-tldr-1"></a>TLDR;</h2>
<p>In this post, we introduce an <ins>AUC</ins>tion-based-<ins>I</ins>nclusion <ins>L</ins>ist design, AUCIL, that leverages competition within an inclusion list committee consisting of rational parties. The protocol design leverages two key components: (i) an input list creation mechanism allowing committee members to pick non-overlapping transactions while maximizing their fees, and (ii) an auction mechanism allowing parties to ensure most of these input lists are included in the final output inclusion list. The former ensures many censored transactions are considered for inclusion, and the latter employs competition where including as many of the input lists as possible is incentivized to produce the output inclusion list.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-introduction-2" name="p-49946-introduction-2"></a>Introduction</h1>
<p>The centralized builder ecosystem of Ethereum today has led to ~2 builders with the power to decide <em>which</em> transactions are posted on Ethereum. This centralization leads to censorship concerns since the builders have complete authority over which transactions are included. The current solution proposed (and rejected) by Ethereum (<a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP 7547</a>) requires the current proposer to determine the <em>inclusion list</em> (or the set of censored transactions) to be included by the next proposer. Such a proposer also acts as a single point of failure, which can easily be bribed to exclude transactions. This has led to proposals such as <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a> and <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a> that require inputs from multiple proposers to be aggregated to form the inclusion list.</p>
<p>Intuitively, using multiple proposers implies the need to bribe multiple parties for a transaction to be excluded. However, do all parties include the transaction in the first place? Since the resulting inclusion list is finite (limited to block size), <em>how do each of these parties decide which transactions to include in their local list such that maximizing the utility also increases the system’s throughput?</em> Moreover, when aggregating the transactions to produce the inclusion list, how many points of failure can be bribed to exclude transactions? This post introduces a multi-proposer design called AUCIL to address these questions.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-motivation-3" name="p-49946-motivation-3"></a>Motivation</h1>
<p>Let’s first motivate the first part as to how the inclusion lists should be created. For existing inclusion list designs, the intricate assumption is that an IL Proposer can include as many transactions as it sees. While <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a> or <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a>, leave the proposal of transactions in Local Inclusion List underspecified, <a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Fox et al.</a> assumes that there is no network congestion. However, including all the transactions could lead to a scenario where the size of the inclusion list is larger than the block size. In such a scenario, the builder (constrained by transactions in the Inclusion List) would add as many transactions as possible, dropping any leftover transactions in the inclusion list.</p>
<p>The first thing to note above is that for an IL Proposer, it never makes sense to add more transactions than the block size, and thus, there could be an implicit block space size constraint (<span class="math">\mathcal{L}</span>) on the Local Inclusion List (We would refer to these as Input Lists).</p>
<p>Now, consider that the proposer is passive (i.e., rational but does not accept a bribe). Since each input could be size <span class="math">\mathcal{L}</span>, the resulting union of lists could be of size <span class="math">\geq \mathcal{L}</span>. Now, the builder (or proposer without the PBS) is constrained to pick transactions from the Inclusion List; it would pick the top <span class="math">\mathcal{L}</span> paying transactions, and the rest would not execute. Thus, the inclusion list proposers would only want to include the top <span class="math">\mathcal{L}</span> transactions. Thus, all the previous analysis made for inclusion lists with a scale factor of the number of inclusion list proposers holds in this case (<a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Fox et al.</a>, <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a>, <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a>).</p>
<p>However, things look very different in the presence of a bribing adversary. Consider that one party is bribed enough (we will quantify this at the end of paragraph) to exclude a top <span class="math">\mathcal{L}</span> paying transaction and instead replace it with <span class="math">(\mathcal{L}+1)^{th}</span> transaction. The builder now receives an inclusion list with <span class="math">\mathcal{L}+1</span> transactions and can choose any transaction to exclude. The adversary can further bribe the builder to exclude the target transaction. Since there is one extra transaction in the list, the block can be formed without violating the properties of an inclusion list (All transactions are executed, or the block space is full). Coming back to the incentives for the party, if it is the only party that deviates from picking top <span class="math">\mathcal{L}</span> transactions, then it would be the only recipient of the fee from <span class="math">(\mathcal{L}+1)^{th}</span> transaction. This may be larger than the utility received (if <span class="math">f_t</span> for the target transaction is not <span class="math">n</span> times larger than <span class="math">f_{\mathcal{L}+1}</span> for the inserted transaction). Even in the worst case, the bribe required would be slightly larger than <span class="math">f_t/n</span>.</p>
<p>All in all, the property of inclusion list that allows the transaction to be excluded if the block is full is a property the design in this post wishes to avoid. Thus, we would restrict the size of input lists to less than <span class="math">\mathcal{L}/n</span> such that even if all parties propose unique transactions, the size of the inclusion list is less than the available block size.<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49946-1" id="footnote-ref-49946-1">[1]</a></sup></p>
<p>There could exist other solutions to this problem like cumulative non-expiring inclusion list and unconditional inclusion lists, however, these require additional state support, where parties would have to keep track of previous inclusion lists.<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49946-2" id="footnote-ref-49946-2">[2]</a></sup></p>
<p>As for the other question of how many points of failure exist while using multi-proposer designs, aggregation of lists from all parties is the most critical point of failure, which hasn’t yet been adequately studied. Fox et al. sidestep this by never truly aggregating and assuming that the proposer’s inputs would be included without truly analyzing the problem. In COMIS, the aggregator role is formalized, and they assume that this role is trusted for their analysis. FOCIL removes this assumption by using the proposer of the next block and keeping the point of failure in check with the committee of attesters. However, relying on attesters comes with its share of problems. Attesters are not incentivized to verify; as long as they vote with other attesters, they receive rewards without the risk of a penalty. Using attesters to compute is thus more unreliable than relying on the attesters to confirm the existence of the block or verify a proof as used in this post.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-model-4" name="p-49946-model-4"></a>Model</h1>
<p>In this post, we consider all parties involved in consensus as rational, i.e., trying to maximize the value they receive through transaction fees, consensus, or bribery. We will call each party collectively proposing the inclusion list as an IL Proposer and their input as an input list. We will refer to the aggregator as the party that computes a union of these input lists to create an inclusion list. Differing from previous proposals, we assume that the input list size of each party is constrained. The size of an input list can be at most <span class="math">k \leq \mathcal{L}/n</span>, as mentioned in the previous section. The total number of IL proposers is considered to be <span class="math">n</span>. Each transaction <span class="math">tx_i</span> pays a fee of <span class="math">f_i</span> for inclusion in the inclusion list, which is paid to the IL Proposer(s) that include it (chosen by the user independently from the base fee and Ethereum transaction fee). If the transaction repeats across multiple input lists, the fee is equally divided amongst all the IL Proposers that included it tracably on-chain.</p>
<p>We assume an external adversary with a budget such that it can bribe parties to take adversarial actions.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-problem-statement-5" name="p-49946-problem-statement-5"></a>Problem Statement</h1>
<p>The problem setting consists of <span class="math">n</span> rational parties who locally have access to a set of censored transactions (<span class="math">M_i</span>) that are continually updated (their mempool). Let <span class="math">M = \cap_i M_i</span>. The problem is to create a list of <em>valid</em> transactions with each party contributing a share of transactions it observes. </p>
<p><strong>Adversarial model.</strong> We assume each of the <span class="math">n</span> parties is rational, i.e., they maximize their utility. We assume a bribing adversary will bribe these parties to censor one or more transactions.</p>
<p><strong>Definition (<span class="math">(b,p,T)</span>-Censorship Resistance.)</strong> We say that a protocol is <em><span class="math">(b,p,T)</span>-censorship resistant</em> if given a budget <span class="math">b</span> to an external adversary for bribing parties, for all transactions <span class="math">t \in T(M)</span> at least <span class="math">p</span> parties output a list which contains all the transactions in <span class="math">T(M)</span>.</p>
<p>The protocol design aims to maximize <span class="math">b</span> for a fixed <span class="math">p</span> and <span class="math">|T(M)|</span>. More concretely, in non-multi-proposer inclusion list design schemes, <span class="math">b</span> is typically <span class="math">O(f)</span>, but our protocol aims to obtain <span class="math">b = O(n\cdot f)</span>.</p>
<p>To facilitate understanding of the goal, <span class="math">T(M)</span> can be considered the “feasible” subset of transactions in <span class="math">M</span>, e.g., those paying sufficiently high fees subject to a space limit. The definition of <span class="math">T</span> depends on the protocol we implement, and it is justified why such a <span class="math">T</span> is used.</p>
<p>In our protocol, we assume that <span class="math">M_i = M</span>. When <span class="math">M_i \neq M</span>, our protocol does not satisfy the definition since it may output a higher paying transaction that appears in some <span class="math">M_i</span> at the expense of some lower paying transaction in the intersection</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-input-list-creation-mechanism-6" name="p-49946-input-list-creation-mechanism-6"></a>Input List Creation Mechanism</h1>
<p>The first question we address is how IL Proposers select transactions for their input lists. A simple approach is for IL Proposers to naively choose the transactions that pay the highest fees, regardless of the actions of others. However, this greedy approach is not a Nash equilibrium. If all other IL Proposers are greedily selecting transactions, the rational choice for any IL Proposer might not be to do the same. <strong>Table 1</strong> illustrates this point.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Objects Picked</th>
<th>Utility</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pick Top Paying</td>
<td><span class="math">(o_1,o_2)</span></td>
<td>7</td>
</tr>
<tr>
<td>Alternate</td>
<td><span class="math">(o_3,o_4)</span></td>
<td>15</td>
</tr>
</tbody>
</table>
</div><p><strong>Table 1</strong>: Picking top-paying objects is not a Nash equilibrium. Consider transactions <span class="math">(\{o_1,o_2,o_3,o_4,o_5,o_6\})</span> with utilities <span class="math">(\{11, 10, 9, 6, 4, 3\})</span> respectively and three players with max size input list of 2. Other players are assumed to follow the strategy of picking the top-paying transaction.</p>
<p>A more viable approach is to use mixed strategies, where each party selects transactions based on a predefined probability distribution. Deviating from this distribution would result in lower expected revenue. However, a mixed Nash equilibrium may not be sufficient, especially in games where players can wait to observe others’ actions before deciding. Thus, this post explores a correlated equilibrium instead.</p>
<p>A correlated equilibrium is a situation where each player is suggested specific actions, and deviating from these suggestions leads to lower utility, assuming others follow the suggestions. To prevent centralization (by asking a single known party to send recommendations), we propose a well-known algorithm that each party can run locally to simulate these suggested actions. Deviating from the algorithm would result in lower utility for the deviating party.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49946-algorithm-1-a-greedy-algorithm-for-transaction-inclusion-7" name="p-49946-algorithm-1-a-greedy-algorithm-for-transaction-inclusion-7"></a>Algorithm 1: A Greedy Algorithm for Transaction Inclusion</h3>
<p><strong>Input</strong>: <span class="math">( n \geq 0 )</span>, <span class="math">( m \geq 0 )</span>, <span class="math">( k \geq 0 )</span>  (number of players, transactions, input list size)</p>
<p><strong>Output</strong>: <span class="math">( L_i )</span> arrays for all <span class="math">( i \in P )</span> (final inclusion lists for each player)</p>
<ol>
<li><span class="math">P \gets [1,\dots,n]</span></li>
<li><span class="math">U \gets [u_1,\dots, u_m]</span></li>
<li><span class="math">N \gets [1,\dots,1]</span></li>
<li><span class="math">\forall i \in P: L_i \gets [1,\dots,1]</span></li>
<li><span class="math">l \gets 0</span></li>
<li><strong>while</strong> <span class="math">l &lt; k</span>  <strong>do</strong>
<ol>
<li><span class="math">i \gets 0</span></li>
<li><strong>while</strong> <span class="math">i &lt; n</span> <strong>do</strong>
<ol>
<li><span class="math">U_{curr} \gets (U \otimes L_i) \oslash N</span></li>
<li><span class="math">s \gets argmax(U_{curr})</span></li>
<li><span class="math">L_{i}[s] \gets 0</span></li>
<li><span class="math">N[s] \gets N[s] + 1</span></li>
<li><span class="math">i \gets i + 1</span></li>
</ol>
</li>
<li><strong>end while</strong></li>
<li><span class="math">l \gets l + 1</span></li>
</ol>
</li>
<li><strong>end while</strong></li>
<li><strong>return</strong> <span class="math">\forall i \in P: L_i</span></li>
</ol>
<hr />
<p>This algorithm iteratively updates each player’s transaction inclusion status. Each player’s input list <span class="math">(L_i)</span> indicates whether a transaction has been included (0) or not (1). The algorithm aims to maximize utility values greedily, including transactions based on their current utility and the number of times each transaction has been included.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49946-description-of-the-algorithm-8" name="p-49946-description-of-the-algorithm-8"></a>Description of the algorithm</h3>
<p>Consider the following simulation protocol. All parties are first numbered randomly. Since the randomness needs to be the same across all parties, a random seed is agreed upon before the start of the protocol. All parties are assigned items greedily, one at a time. Each party picks the item that gives the maximum utility at that instant. To do so, it computes the current utility of all objects yet to be chosen <span class="math">\left((U \otimes L_i) \oslash N\right)</span>. The first <span class="math">(U \otimes L_i)</span> makes the utility of all objects already chosen by <span class="math">i</span> as 0, and then <span class="math">\oslash N</span> divides by the number of parties sharing the object if party <span class="math">i</span> decides to pick that object. The list of objects the party picks is updated (0 implies the object is chosen), and the number of parties picking the object is also updated. The procedure is repeated <span class="math">k</span> times such that each party picks <span class="math">k</span> objects. This protocol achieves a correlated equilibrium. Note that while the protocol assigns objects to parties one at a time, in practice, the output recommends all transactions to the parties at once.</p>
<p>This protocol provably achieves a correlated equilibrium while also achieving a notion of game-theoretic-fairness properties (almost equal distribution of fee) (Paper to follow soon). The set of all transactions chosen by the input list creation algorithm is <span class="math">T(M)</span>, for which we achieve <span class="math">(b,p, T)</span>-censorship resistance through AUCIL, which follows.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-aggregation-of-input-lists-9" name="p-49946-aggregation-of-input-lists-9"></a>Aggregation of input lists</h1>
<p>After creating input lists, the next step is to aggregate the lists to create an inclusion list for the next block. If a transaction appears in the inclusion list, it is constrained to appear in the next block. Since the space occupied by the input list is fixed, it cannot suffer from spam transactions since each transaction is confirmed valid (with an adequate base fee) right before the block that includes it.</p>
<p>A standard way to approach this problem is to assign a party the role of an <em>aggregator</em>. This aggregator would compute the union of all the input lists and add it to the inclusion list. However, this aggregator is now a single point of failure. For instance, it may be the case that the aggregator may not receive input lists from all IL proposers and thus cannot be expected to add all input lists. However, if we consider this and only require it to include some threshold number of input lists, then the aggregator can strategically omit specific input lists and significantly reduce the required budget to censor transactions.</p>
<p>So, what can be done in this case? <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a> requires the proposer of the following block to include an inclusion list, a superset of local input lists. However, it still allows for some transactions to not be on the inclusion list (due to the threshold). Instead, we look at a different way to deal with this problem. We auction off the role of the aggregator; however, instead of paying a bid to win the role of the aggregator, the bids are the size of the inclusion list. Thus, if a party <span class="math">P</span> proposes a larger inclusion list than all other parties, then <span class="math">P</span> would be rewarded with the aggregator role and reward.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49946-algorithm-aucil-outline-10" name="p-49946-algorithm-aucil-outline-10"></a>Algorithm: AUCIL Outline</h3>
<p><strong>Participants:</strong> All IL proposers <span class="math">P_1, P_2, \ldots, P_n</span></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-1-il-proposers-broadcast-input-lists-11" name="p-49946-step-1-il-proposers-broadcast-input-lists-11"></a>Step 1: IL Proposers Broadcast Input Lists</h4>
<ul>
<li>For each proposer <span class="math">P_i</span>:
<ul>
<li><span class="math">P_i \rightarrow_B</span> (broadcasts to all parties): <span class="math">\text{inpL}_i</span></li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-2-parties-aggregate-input-lists-into-an-inclusion-list-and-broadcast-it-12" name="p-49946-step-2-parties-aggregate-input-lists-into-an-inclusion-list-and-broadcast-it-12"></a>Step 2: Parties Aggregate Input Lists into an Inclusion List and Broadcast It</h4>
<ul>
<li>For each party <span class="math">P_j</span>:
<ul>
<li><span class="math">\text{incL}_j = \bigcup_{i=1}^{n} \text{inpL}_i</span></li>
<li><span class="math">P_j \rightarrow_B</span> (broadcasts to all parties):<span class="math">\left(\text{incL}_j, \ell_j = \text{size}(\text{incL}_j)\right)</span></li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-3-proposer-selects-the-highest-bid-inclusion-list-13" name="p-49946-step-3-proposer-selects-the-highest-bid-inclusion-list-13"></a>Step 3: Proposer Selects the Highest Bid Inclusion List</h4>
<ul>
<li>Proposer receives: <span class="math">\{(\text{incL}_1, \ell_1), (\text{incL}_2,\ell_2), \ldots, (\text{incL}_n,\ell_n)\}</span></li>
<li>Proposer selects the highest bid.</li>
</ul>
<p>While <strong>Step 2</strong> has its incentives clear by introducing aggregation rewards (<span class="math">u_a</span>), <strong>Step 1</strong> and <strong>Step 3</strong> are not incentive compatible. If all other parties broadcast their input lists, then it is dominant not to broadcast its input list for a party. This way, it can create the largest inclusion list and thus win the auction. Thus, <strong>Step 1</strong> is not incentive-compatible. Similarly, the proposer is not incentivized to pick the largest bid. Censorship in auctions (<a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Fox et al.</a>) has been studied and is easily applicable here. Thus, <strong>Step 3</strong> is also not incentive-compatible.</p>
<p>Recall the definition of censorship resistance. If some protocol satisfies the definition of <span class="math">(b,p, T)</span>-censorship resistance, then at least <span class="math">p</span> parties output a non-censored inclusion list. Thus, we require the proposer to include proof of the included bid being greater than <span class="math">n-p</span> other bids (e.g., including <span class="math">n-p</span> bids). If the proposer fails to add such proof, the block would be considered invalid, thus making <strong>Step 3</strong> incentive compatible.</p>
<p>We make the auction biased to deal with the problem of not broadcasting. First, observe that if no party is broadcasting its input list, then the probability of winning the auction for any party is very low; thus, broadcasting its input list at least yields the rewards from including the input list in making the inclusion list. Thus, if more people believe that keeping its input list private does not lead to a significant increase in the probability of winning, then parties would be incentivized to broadcast its input list.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/5/d5699e95fe4dfa9c4562533d720b3400e0a1805b.png" title="AUCIL-Outline"><img alt="AUCIL-Outline" height="420" src="https://ethresear.ch/uploads/default/optimized/3X/d/5/d5699e95fe4dfa9c4562533d720b3400e0a1805b_2_690x420.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49946-algorithm-aucil-14" name="p-49946-algorithm-aucil-14"></a>Algorithm: AUCIL</h3>
<p><strong>Participants:</strong> All IL proposers <span class="math">P_1, P_2, \ldots, P_n</span></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-0-il-proposers-generate-their-auction-bias-15" name="p-49946-step-0-il-proposers-generate-their-auction-bias-15"></a>Step 0: IL Proposers Generate Their Auction Bias</h4>
<ul>
<li>For each proposer <span class="math">P_i</span>:
<ul>
<li><span class="math">P_i</span> generates a random bias: <span class="math">\text{bias} \gets \text{VRF}(P_i, \text{biasmax})</span></li>
<li><em>(The bias is uniformly distributed between 0 and <span class="math">\text{biasmax}</span> and is added to the bid.)</em></li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-1-il-proposers-broadcast-input-lists-16" name="p-49946-step-1-il-proposers-broadcast-input-lists-16"></a>Step 1: IL Proposers Broadcast Input Lists</h4>
<ul>
<li>For each proposer <span class="math">P_i</span>:
<ul>
<li><span class="math">P_i \rightarrow_B</span> (broadcasts to all parties): <span class="math">\text{inpL}_i</span></li>
<li><em>(Proposers broadcast their input lists to all parties.)</em></li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-2-parties-aggregate-input-lists-into-an-inclusion-list-and-broadcast-it-17" name="p-49946-step-2-parties-aggregate-input-lists-into-an-inclusion-list-and-broadcast-it-17"></a>Step 2: Parties Aggregate Input Lists into an Inclusion List and Broadcast It</h4>
<ul>
<li>For each party <span class="math">P_j</span>:
<ul>
<li><span class="math">\text{incL}_j = \bigcup_{i=1}^{y_j} \text{inpL}_i</span>
<ul>
<li><em>(where <span class="math">y_j</span> is the number of input lists party <span class="math">P_j</span> receives.)</em></li>
</ul>
</li>
<li><span class="math">P_j \rightarrow_B</span> (broadcasts to all parties): <span class="math">\left(\text{incL}_j, \ell_j = y_j + \text{bias}\right)</span></li>
<li><em>(Parties declare their bid with the added bias.)</em></li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-3-proposer-selects-the-highest-bid-inclusion-list-18" name="p-49946-step-3-proposer-selects-the-highest-bid-inclusion-list-18"></a>Step 3: Proposer Selects the Highest Bid Inclusion List</h4>
<ul>
<li>Proposer receives: <span class="math">\{(\text{incL}_1, \ell_1), (\text{incL}_2,\ell_2), \ldots, (\text{incL}_n,\ell_n)\}</span></li>
<li>Proposer selects the highest bid and adds it to the block <span class="math">(\text{incL},\ell)</span>.</li>
<li>Proposer adds proof that the highest bid is greater than <span class="math">n-p</span> other bids.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#p-49946-step-4-attesters-vote-on-the-validity-of-the-block-19" name="p-49946-step-4-attesters-vote-on-the-validity-of-the-block-19"></a>Step 4: Attesters Vote on the Validity of the Block</h4>
<ul>
<li>For each attester:
<ul>
<li>Attester receives: <span class="math">\{(\text{incL}_1, \ell_1), (\text{incL}_2,\ell_2), \ldots, (\text{incL}_n,\ell_n)\}</span> and <span class="math">(\text{incL},\ell)</span></li>
<li>Attester verifies the attached proof and votes only if the proof is correct.</li>
</ul>
</li>
<li>Block is considered valid if it receives more than a threshold of votes.</li>
</ul>
<p>With the above algorithm, we claim that the party is incentivized to broadcast the input list unless the bias drawn is greater than <span class="math">\text{biasmax} -1</span>. Even when the bias is greater than <span class="math">\text{biasmax} -1</span>, a mixed Nash equilibrium still exists, and parties could still choose to broadcast.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-censorship-resistance-20" name="p-49946-censorship-resistance-20"></a>Censorship Resistance</h1>
<h3><a class="anchor" href="https://ethresear.ch#p-49946-censorship-by-bribery-to-il-proposers-21" name="p-49946-censorship-by-bribery-to-il-proposers-21"></a>Censorship by bribery to IL Proposers</h3>
<p>The first attack step an adversary can take is removing a transaction from the input lists. For this, assume that a bribe is given to those IL Proposers who are assigned to include the target transaction. This bribe should be enough to ensure that the target transaction is excluded from each input list with probability 1. It is assumed (for now) that each of these IL Proposers would compute the union of all observed input lists in <strong>Step 3</strong>.</p>
<p>Fox et al. analyze the bribe required for a multi-proposer scenario. In their case, it is assumed that the transaction repeats across all proposers. If a transaction pays a fee (higher fee for them) of <span class="math">f_i</span>, then the adversary would have to pay <span class="math">n</span> times the fee to censor the transaction.</p>
<p>In our case, the analysis is similar. If the transaction repeats across <span class="math">\kappa_i</span> input lists, then the expected bribe required is <span class="math">\kappa_i f_i</span>. The parameter <span class="math">\kappa_i</span> is directly proportional to <span class="math">\frac{n\cdot f_i\cdot k}{\sum f_i}</span>, where <span class="math">\sum f_i</span> is the sum of fees paid by all transactions chosen by the protocol. As an intuition for this number, one of our results ensures that the revenue distribution from each transaction is <em>fair</em>, and thus, assumes that each transaction gives the same utility. (Let’s say there exist two transactions paying a fee of 15 and 5, respectively, then the former transaction would be included in thrice as many input lists as the latter transaction. Thus, revenue is the same). <span class="math">n\cdot k</span> represents the total available slots out of which a transaction with fee <span class="math">f_i</span> would occupy <span class="math">\frac{f_i}{\sum f_i}</span> off the total space to maintain the same revenue assumption. Thus, if bribing the IL Proposers to exclude the transaction from the input list is the dominant action (as compared to bribery by aggregator we will mention next), then the protocol would be <span class="math">(b=O(\frac{nkf_i^2}{\sum f_i}),n, T</span>)-censorship resistant.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49946-censorship-by-bribery-to-aggregator-22" name="p-49946-censorship-by-bribery-to-aggregator-22"></a>Censorship by bribery to aggregator</h3>
<p>In an alternate bribery attack, the adversary could bribe a party to reduce its bid by excluding all input lists that contain the target transaction. Thus, the bid for each party decreases by <span class="math">\kappa_i</span>. This would be the same as drawing a bias <span class="math">\kappa_i</span> less than what is drawn. A bias of <span class="math">\text{biasmax}-1</span> is supposed to have almost <span class="math">0</span> probability of winning, and thus, reduction of a party bias to <span class="math">\text{biasmax}-\kappa_i</span>, essentially means the adversary is bribing the party to not participate in the auction. From our analysis, the adversary would have to pay in expectation <span class="math">\frac{\kappa_i n}{biasmax}</span> parties (Each with a bias greater than <span class="math">n-\kappa_i</span>) a bribe of <span class="math">u_a</span> each in order for them not to include the input lists containing the target transaction. Setting <span class="math">\text{biasmax}</span> and <span class="math">u_a</span> to be <span class="math">\sqrt n</span> and <span class="math">\sqrt n \cdot u_{il} \geq \sqrt n \cdot f_i</span>, we achieve <span class="math">(b = O(\frac{n^2kf_i^2}{\sum f_i}),n-\kappa_i\sqrt n+1,T)</span>-censorship resistant.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49946-conclusion-23" name="p-49946-conclusion-23"></a>Conclusion</h1>
<p>We outline an input list building scheme that all parties are incentivized to follow. Working within the confines of limited-size inclusion lists, we achieve significant censorship resistance guarantees (proportional to the number of parties, including the transaction). Then, we looked at an aggregation scheme, AUCIL, that utilizes auctions to incentivize parties to include the largest inclusion list. AUCIL ensures that the aggregator is incentivized to add all input lists to the transaction. We are also analyzing how coalition affects the censorship resistance guarantees and will publish the results soon. Meanwhile, it would be amazing to hear thoughts on AUCIL and the inclusion list building mechanism.</p>
<hr class="footnotes-sep" />

<ol class="footnotes-list">
<li class="footnote-item" id="footnote-49946-1"><p>Note that with <a href="https://eips.ethereum.org/EIPS/eip-1559" rel="noopener nofollow ugc">EIP-1559</a>, the cost to fill the block scales when the block space is full. And so, if the network is not congested, and the adversary is inserting artificial transactions to raise the congestion, then the cost of bribery would be high across multiple blocks. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49946-1">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49946-2"><p>We achieve the same “unconditional” property as Unconditional ILs without assigning exclusive Inclusion List space. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49946-2">↩︎</a></p>
</li>
</ol>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/aucil-an-auction-based-inclusion-list-design-for-enhanced-censorship-resistance-on-ethereum/20422">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 17:45:11 +0000</pubDate>
</item>
<item>
<title>Pricing Ethereum Blocks with Vol Markets with Implications for Preconfirmations</title>
<link>https://ethresear.ch/t/pricing-ethereum-blocks-with-vol-markets-with-implications-for-preconfirmations/20419</link>
<guid>https://ethresear.ch/t/pricing-ethereum-blocks-with-vol-markets-with-implications-for-preconfirmations/20419</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、Block Pricing、Volatility、Arbitrage、Preconfs

总结：

文章探讨了以太坊区块定价的问题，将区块链网络视为金融工具，提出了一个基于期权定价理论的模型来确定购买连续区块的最低价格。该模型结合了传统金融市场波动率（Vol）和以太坊网络中的交易费用、流动性等因素。通过分析历史数据和市场行为，文章发现以太坊短期波动率远高于长期均值，最高可达273%，并提出了一种策略，即在中心化交易所（CEX）卖出波动率期权（Strangles），同时在以太坊网络上购买预确认区块（Preconfs），以此获得无风险利润。

文章进一步指出，随着未来以太坊区块空间承诺合同的推出，这种策略将更加可行，可以覆盖多个区块，从而更精确地定价预确认区块。此外，文章还讨论了与不同交易场所（如中心化交易所、去中心化交易所）之间的套利机会，以及如何利用这些机会构建对冲策略或进行相对价值交易。

总的来说，文章提供了一种创新的方法，通过结合金融市场波动性和区块链技术特性，为以太坊预确认区块定价提供了新的视角和策略。这种方法不仅能够帮助交易者进行有效套利，还可能成为未来区块链金融领域的一个重要研究方向。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49938-ethereum-block-pricing-in-the-context-of-vol-markets-1" name="p-49938-ethereum-block-pricing-in-the-context-of-vol-markets-1"></a>Ethereum Block Pricing in the Context of Vol Markets</h1>
<p><em>by <a href="https://x.com/lepsoe">Lepsoe </a> (<a href="https://www.ethgas.com/">@ETHGas</a>)</em></p>
<p><em>With thanks to the <a href="https://x.com/Commit_Boost">Commit Boost</a>, and <a href="https://x.com/titanbuilderxyz">Titan </a> teams for making Preconfs a near-term open and scalable possibility, and <a href="https://x.com/DrewVdW">Drew</a> for prompting the market sizing exploration</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49938-tldr-2" name="p-49938-tldr-2"></a><em>TL;DR</em></h2>
<ul>
<li>With the forthcoming gas markets and the ability to buy Entire Blocks, we look at how to price these taking into account prevailing market Volatility, Token prices, Transaction Fees, and Liquidity</li>
<li>Treating the Blockchain/Network as a financial instrument, Block purchases are effectively Options on this network. If one can buy 5 blocks of Ethereum (e.g. 1 minute), one can observe prices in CEXs over this time with an option to monetize the difference between CEX and DEX prices (e.g. latency arb trade)</li>
<li>Buying a block is analogous to buying a Straddle on the Network, and all its DEXs. Taking into account transaction fees, liquidity and slippage, however, this is more analogous to a Strangle.</li>
<li>We then employ an arbitrage trade that involves Shorting European Strangles in CEX (e.g. Deribit, Binance, OKX), and Buying Blocks or Preconfs of Ethereum. This implies a minimum or floor price for one or many consecutive blocks</li>
<li>We can then draw a direct, real-time connection between the current implied Vol for ETH, BTC, SOL, etc… and Preconfs prices</li>
<li>We conclude that if ETH Vol is 75%, and transaction fees are 0.10%, then buying 5 consecutive blocks of Ethereum should be no lower than 6.9 Gwei</li>
<li>Historically, very short-end vol appears to rise dramatically higher than 75% with a Mean of 273%, although the median remains at 75% over the last 2 years</li>
<li>With the current PBS flow and prior to blockspace commitment contracts, this strategy is possible but limited to only the current/next block. With the ability to buy two or more blocks, it becomes easier to execute on and thus price Preconfs with confidence</li>
<li>Connecting the two markets, Vol and Macro traders may therefore trade the Preconf markets, in some cases, with little care as to how these instruments are used or valued with respect to the underlying physical gas markets themselves (e.g. typical orderflow, MEV)</li>
<li>The terms Preconfs and Blocks are used interchangeable for readability</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49938-background-3" name="p-49938-background-3"></a>Background</h2>
<p>How much are Ethereum’s blocks worth?</p>
<p>Arbitrage, often referred to as ‘arb’ trading, typically involves quantitative strategies that exploit pricing discrepancies or minor imbalances between closely related financial instruments. These instruments may be similar in nature or expected to exhibit similar behaviors over time - they can be priced with models or priced using dynamic replication (such as options replicated through dynamic hedging).</p>
<p>One such arb is statistical arbitrage (‘stat arb’) that frequently employs mean reversion models to capitalize on short-term pricing inefficiencies. Another one is latency arbitrage that takes advantage of minute price variations across different trading venues. In the cryptocurrency, a common form of arbitrage is known as CEX/DEX arb, a type of latency arbitrage where decentralized exchanges (DEXs) respond more slowly to market changes than centralized exchanges (CEXs), largely due to differing block or settlement times. In such scenarios, traders engage in relative-value or pairs trading between centralized exchanges (such as Binance and OKX) and decentralized exchanges (such as Uniswap and Curve).</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-the-network-as-a-financial-instrument-4" name="p-49938-the-network-as-a-financial-instrument-4"></a>The Network As a Financial Instrument</h3>
<p>In this article, we look to delineate, and quantify such an arbitrage trade between two seemingly different instruments: the Vol markets on CEX vs the Ethereum Blockchain itself (i.e. the Network, not DEXs).</p>
<p>The purpose of this article is to introduce a closed-form solution to price a floor price for Ethereum Blocks drawing a direct relationship between Vol markets and the minimum price one should pay for Ethereum Blocks. More specifically, we will look at the effect of selling Strangles on ETH (and other tokens) in CEX, while buying Blockspace Commitments (or Preconfirmations) on Ethereum.</p>
<p>While this type of relationship may exist with limited effect today for 12 seconds, the burgeoning space of preconfirmations and validator commitments will enable this to exist for much longer periods turning what may be a theoretical exercise today into a practical exercise tomorrow.</p>
<p>Through this exercise, we position the Blockchain or Network itself as a financial instrument that can be used for macro hedging or relative value trading purposes.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-what-is-a-strangle-5" name="p-49938-what-is-a-strangle-5"></a>What is a Strangle?</h3>
<p>The building blocks of options markets or ‘Vol’ markets are ‘vanilla’ options known as calls and puts. Combining such vanilla options together at the same strike produces a ‘V-shaped’ payoff known as a ‘Straddle’. A Straddle will always have a positive intrinsic value or payoff enabling the buyer to monetize any movement of the underlying instrument.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/1/71515733c74792ef64bb5afa1456f44c8a078678.png" title="image"><img alt="image" height="399" src="https://ethresear.ch/uploads/default/optimized/3X/7/1/71515733c74792ef64bb5afa1456f44c8a078678_2_690x399.png" width="690" /></a></div><br />
<em>Figure 1: Straddles vs Strangles</em><p></p>
<p>When the strikes are apart from one another, in the above example by a distance of ‘z’, they are called a ‘Strangle’. For example:</p>
<ul>
<li>A Put and Call both with strikes of 100 (i.e. X) would collectively be called a Straddle</li>
<li>A Put and Call with strikes of 90 (i.e. X - z) and 110 (i.e. X + z) respectively, would collectively be a Strangle</li>
</ul>
<p>Strangles payoff or have an intrinsic value only when the underlying spot price has moved by a sufficient distance, in this case ‘z’.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-what-are-preconfirmations-6" name="p-49938-what-are-preconfirmations-6"></a>What Are Preconfirmations?</h3>
<p>Preconfirmations and Blockspace Commitments are part of a new field of Ethereum Research and Development focused on giving Validators (called Proposers, i.e. those that Propose the next epoch of blocks) expanded abilities to sell blockspace in a way that gives them more flexibility than they are currently afforded within the current PBS (Proposer-Builder- Separation) flow.</p>
<p>Such an initiative is intended broadly to bring more control in-protocol (as opposed to externally with Block Builders), and streamline scaling technology for the new field of Based Rollups.</p>
<p>While there are different forms of Blockspace Commitments, the general form has Proposers providing commitments to buyers - typically Searchers, Market Makers, Block Builders, and others looking to use the blockspace for transactions, among other purposes. For example, there are:</p>
<ul>
<li>Inclusion Preconfirmations: Where Proposers issue guarantees to include transactions within a specified block, anywhere in the block</li>
<li>Execution Preconfirmations: Where Proposers issue guarantees to include transactions within a specific block, with a specific state or result</li>
<li>Whole Block Sales which may be called Entire Blocks or Execution Tickets: Where Proposers sell their block en masse to an intermediary who then engages in some form of pseudo block building consisting perhaps of a mix of their own trades, Inclusion Preconfirmations, Execution Preconfirmations, private order flow, and public order flow.</li>
</ul>
<p>For the purposes of this paper, we will be referring to Whole Block Sales by Proposers, but may refer to them generically as Preconfirmations or Preconfs for ease of reading and consistency with some current nomenclature.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-current-preconf-and-blockspace-pricing-7" name="p-49938-current-preconf-and-blockspace-pricing-7"></a>Current Preconf and Blockspace Pricing</h3>
<p>The value of Ethereum blocks are often associated with the Maximum Extractable Value (MEV), that is, the largest amount of value that one could extract or monetize within a 12 second period. This may include a mix of the public’s willingness to pay for transactions (financial and non-financial), private order flow, as well as other MEV trades including sandwich attacks, atomic arbitrage, CEX/DEX arb, or other.</p>
<p>Extending into the Multi-block MEV (MMEV) or Consecutive Block valuation, MMEV valuation is often performed in the context of TWAP oracle manipulation attacks producing forced liquidations by price manipulation. While there is an intersection between longer-term CEX/DEX arb captured in single-block pricing discussions vs the relative value vol markets, we prefer the simplicity and forward-looking nature of the vol markets for the purpose of our pricing exercise.</p>
<p>Putting this together, there are multiple ways to value a single or multiple set of Ethereum blocks. From our analysis, we present a floor price for Ethereum blocks driven by non-arbitrage pricing and the Vol markets in CeFi. From this floor price one may additionally then consider encompassing other forms of value capture to arrive at a true mid-market price of an Ethereum Block.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49938-the-trade-8" name="p-49938-the-trade-8"></a>The Trade</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-historical-background-9" name="p-49938-historical-background-9"></a>Historical Background</h3>
<p>Buying a block, or multiple blocks of Ethereum enables one more control over order execution and states. Simply, if it were possible to buy 12.8 minutes of Ethereum (i.e. 64 blocks or two epoch) one could watch prices as they move in CEX during this time, and at any time during this 12 minute period, one could put on a relative value trade capturing the difference in prices between the CEXs and DEXs. If, for example, prices rose 5% in CEX during this time, one could sell assets in CEX, and buy those same assets in DEX (where the prices haven’t moved) earning 5% in the process. While this may not be currently feasible, it is the starting point for discussion.</p>
<p>Historically, we can look at these dynamics measuring the maximum price movements over 12 secs, 1 min, or more. We can then take into account the liquidity on DEXs and calculate a historical breakeven between the profitability of such transactions with the number of blocks for a given period. For more on this see this article: <a class="inline-onebox" href="https://greenfield.xyz/2024/09/10/statistical-arbitrage-on-amms-and-block-building-on-ethereum-part-1/">| Greenfield</a></p>
<p>While possible to calculate, we’re more interested in looking forward, not backward. Enter the Vol markets.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-vol-markets-strangles-10" name="p-49938-vol-markets-strangles-10"></a>Vol Markets &amp; Strangles</h3>
<p>To execute the trade above, one must cross bid-offer, paying transaction fees on both the CEX and DEX side as well as ‘time’ the market accordingly to maximize the arbitrage. One furthermore has to factor in the liquidity or depth of the market. That is, for the strategy to pay off, prices need to move beyond a certain minimum threshold or in our case, a Strike price different from the current Spot price.</p>
<p>Let us assume that the “sum of transaction fees and slippage between CEX/DEX” - our ‘threshold’ or Strike is 0.10%. If we have the Vol of the asset, and a time horizon, we can now price this using Black-Scholes as a simple Strangle.</p>
<p>Assume the following:</p>
<ul>
<li>Trade Size: $10mm</li>
<li>Token: ETH</li>
<li>Spot Price: 100 || to keep things simple</li>
<li>Interest Rates: 4.00%</li>
<li>Dividend Yield: 0.00%</li>
<li>Vol: 75%</li>
<li>Expiry: 32 Blocks (12.8mins)</li>
<li>Fees: 0.10 as accounted for in the following Strikes:
<ul>
<li>Strike 1: 100 + 0.10 = 100.10 - for the Call Option</li>
<li>Strike 2: 100 - 0.10 = 99.90 - for the Put Option</li>
</ul>
</li>
</ul>
<p>Result:</p>
<ul>
<li>Call Price: 0.0620%</li>
<li>Put Price: 0.0619%</li>
<li>Strangle Price: 0.0620% + 0.0619% = 0.1239%</li>
<li>Price in USD Terms: $12,388</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/a/ca508d8bddc9793de7b6326ed95552f760925a2e.jpeg" title="image"><img alt="image" height="376" src="https://ethresear.ch/uploads/default/optimized/3X/c/a/ca508d8bddc9793de7b6326ed95552f760925a2e_2_690x376.jpeg" width="690" /></a></div><br />
<em>Figure 2: A Strangle on Ethereum and all its DEXs combined</em><p></p>
<p>Per the diagram above, if one could trade this Strangle in CEX for $12,388 (see <a href="https://docs.google.com/spreadsheets/d/1wwhe-O8L0eG72Mb0PJGLhlDi1Fxe1E0CSzpX0sAaz2U/edit?usp=sharing">spreadsheet</a> for calculations), one should equivalently be able to trade Preconfs on Ethereum for the same price. If the underlying spot market in CEX moves up or down more than 0.10, whilst DEX prices stay the same, then these options become in-the-money…</p>
<p>Putting CEX and DEX together below, one would sell the Strangle on ETH in CEX but buy Preconfs on Ethereum giving them an almost identical payoff where z represents both the expected transaction fees and the distance to the Strike price for pricing purposes:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/b/9bf362500aa612b87a9254ea96544495005030a3.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/b/9bf362500aa612b87a9254ea96544495005030a3_2_422x500.jpeg" width="422" /></a></div><br />
<em>Figure 3: Short CEX Strangle + Long Ethereum Preconf</em><p></p>
<p>If the Vol markets imply a price of $12,399 for 12.8mins (i.e. 32 blocks) then this is the amount (less one dollar) that one would be willing to pay to buy up 32 consecutive blocks (i.e. 12.8mins) of Ethereum. Given the assumptions above, the expected value is always positive and we thus have a closed-form solution to Floor pricing for Preconfs.</p>
<p>The arbitrage carries two scenarios:</p>
<ul>
<li>Prices are between 99.90 and 100.10: Both the Strangle and Preconf Expire ‘out-of-the-money’ without any cash settlement</li>
<li>Prices are beyond 99.90 and 100.10 with options expiring ‘in-the-money’. The Trader incurs a loss on the CEX Strangle, but then monetizes the gain in DeFi by entering into an off-market spot trade (with respect to CEX) crystallizing the in-the-money value of the option</li>
</ul>
<p>Vol Traders do this 1000s of times a day, with automated systems and razor-sharp precision. Trading Vol vs Preconfs opens up an entirely new relative-value asset class for them to potentially buy vol or gamma much more cheaply.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-scenario-analyses-and-sensitivities-11" name="p-49938-scenario-analyses-and-sensitivities-11"></a>Scenario Analyses and Sensitivities</h3>
<p>Turning to Gas Market terminology, the price of $12,399 translates into a Gwei price of 165 Gwei ($12,399 / 2,500 * 1e9 / 30e6) assuming the ETH price is 2,500 in this example. Using the Strangle pricing method, we can then infer from the ETH Vol markets (75% vol in this case) the price of 1 block, all the way up to 32 consecutive blocks or slots as follows:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/7/57defb97d1f6360692afa2c53920481469468872.png" title="image"><img alt="image" height="285" src="https://ethresear.ch/uploads/default/optimized/3X/5/7/57defb97d1f6360692afa2c53920481469468872_2_690x285.png" width="690" /></a></div><br />
<em>Figure 4: Price for N-Consecutive Blocks of Ethereum</em><p></p>
<p>Comparing the difference in Strangle prices between a period of N(0,1), to a Strangle with a period of length N(0,2), we can then price the Strangle for Slot 2 N(1,2), as follows for the entire curve. We can furthermore take the ‘average preconf price’ for N slots.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/d/cd5b4a440fe65ad5649f789572044f132c3a152f.jpeg" title="image"><img alt="image" height="379" src="https://ethresear.ch/uploads/default/optimized/3X/c/d/cd5b4a440fe65ad5649f789572044f132c3a152f_2_690x379.jpeg" width="690" /></a></div><p></p>
<p><em>Figure 5: Slot N Price vs Avg Price for N-Slots</em></p>
<p>The following table highlights the fees in Gwei that validators would get paid for specific blocks/slots with 5.16 Gwei as the average. This may be compared, for example, to historical Priority Fees that one receives via MEV-Boost where 4.04 Gwei is the average:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/3/c3625c9aef9793341f69e2c496ba4151b8ba8a06.jpeg" title="image"><img alt="image" height="369" src="https://ethresear.ch/uploads/default/optimized/3X/c/3/c3625c9aef9793341f69e2c496ba4151b8ba8a06_2_690x369.jpeg" width="690" /></a></div><br />
<em>Figure 6: Historical Priority Fees from MEV-Boost. Priority Fees from 24 Jan 2024 to 9 Sep 2024.</em><p></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49938-transaction-costs-impact-on-pricing-12" name="p-49938-transaction-costs-impact-on-pricing-12"></a>Transaction Costs Impact on Pricing</h4>
<p>The difference between the Strike Prices and Spot Price or transaction costs above are taken to be uniform at 0.10%. In practice however, transaction costs encompass i) actual transaction fees, and ii) liquidity/slippage in execution. Below, we see that Transaction Costs have a significant impact on Preconf pricing especially where there is a shorter time-to-maturity.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/b/bb067308cb50d9cac678fffc4c4df056a7b697c3.jpeg" title="image"><img alt="image" height="395" src="https://ethresear.ch/uploads/default/optimized/3X/b/b/bb067308cb50d9cac678fffc4c4df056a7b697c3_2_690x395.jpeg" width="690" /></a></div><br />
<em>Figure 7: Preconf Pricing for varying levels of Transaction Costs</em><p></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49938-volatility-impact-on-pricing-13" name="p-49938-volatility-impact-on-pricing-13"></a>Volatility Impact on Pricing</h4>
<p>Finally, as the CEX leg of the trade uses Volatility as the primary market input, we now consider the impact that volatility has on Preconf pricing with Vega close to 0.1 Gwei at the 4th slot, and ~0.06 Gwei at the 32nd slot. That is, <strong>at Slot 4, a 10% change in Vol is impacts Block prices by 1 Gwei.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/c/6c7b2d7c8762d69423e0fc605cd9d64cd9f85dbc.jpeg" title="image"><img alt="image" height="406" src="https://ethresear.ch/uploads/default/optimized/3X/6/c/6c7b2d7c8762d69423e0fc605cd9d64cd9f85dbc_2_690x406.jpeg" width="690" /></a></div><br />
<em>Figure 8: Preconf Prices for Different levels of Volatility</em><p></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49938-refinements-market-sizing-14" name="p-49938-refinements-market-sizing-14"></a>Refinements &amp; Market Sizing</h2>
<p>For market sizing, we look exclusively at the CEX Strangle vs Preconf on Ethereum L1.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-consecutive-blocks-15" name="p-49938-consecutive-blocks-15"></a>Consecutive Blocks</h3>
<p>The exercise considers buying multiple blocks, potentially up to 32 or 64 blocks depending on the lookahead window. In reality however, this is extremely difficult due to the diversity of Validators.</p>
<p>There is a subset of Validators that, for ideological reasons or other, do not adopt MEV-Boost, and would be unlikely to adopt a framework that captures more MEV. In economic terms, they are not rational. It could be that they do not ‘believe’ in MEV, or they simply could be an at-home staker that hasn’t upgraded to MEV-Boost. Either way, these Vanilla or self-built blocks account for slightly less than 10% (and decreasing) of blocks (see realtime with ETHGas’ <a href="http://www.ethgas.com">GasExplorer</a>, and research with <a href="https://www.blocknative.com/blog/how-self-built-blocks-unintentionally-introduce-base-fee-volatility">Blocknative</a>).</p>
<p>Let’s assume the other 90% are rational (i.e. they are economically motivated) and that they are somehow able to coordinate among one another through some unifying medium for the sale of consecutive blocks. In this case, we can then model the frequency of single vs consecutive blocks where about half of the time there are less than 7 consecutive blocks, and the other half have somewhere between 8 and 32 consecutive blocks.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/9/a96d126f31fbaa6afded0e3cdd01172eceba7b03.png" title="image"><img alt="image" height="401" src="https://ethresear.ch/uploads/default/optimized/3X/a/9/a96d126f31fbaa6afded0e3cdd01172eceba7b03_2_690x401.png" width="690" /></a></div><br />
<em>Figure 9: Frequency of Consecutive Blocks</em><p></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-historical-volatility-analysis-16" name="p-49938-historical-volatility-analysis-16"></a>Historical Volatility Analysis</h3>
<p>Looking at almost 2 years of trades from 10 Sep 2022 to 10 Sep 2024 on Deribit, we uncover some fascinating dynamics for short-dated transactions.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49938-h-1-hour-to-expiry-17" name="p-49938-h-1-hour-to-expiry-17"></a>1 Hour to Expiry</h4>
<p>For those transactions with less than 1 hour to expiry, we find approx 13,500 trades over this period, a mean Vol of 107.52%, a Median of 63%, and 75th Percentile as 102%. Note that Deribit’s Vols are capped at 999 suggesting that the mean may be higher than that which is indicated.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/af0a574ea2876081224b6e7b6ecd012ff163221a.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/a/f/af0a574ea2876081224b6e7b6ecd012ff163221a_2_655x500.jpeg" width="655" /></a></div><br />
<em>Figure 10: Distribution of Implied Vol on ETH Options with less than 1 Hour to Expiry</em><p></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49938-h-12-mins-to-expiry-18" name="p-49938-h-12-mins-to-expiry-18"></a>12 Mins to Expiry</h4>
<p>For transactions with less than 12 mins to expiry (or approx 64 blocks), we find almost 1,400 trades over this period with a mean of 273% Vol, median of 75% Vol, and 75th Percentile as 395% Vol.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/e/deede16e86a88239a6ecc6e13c99cd93778fa614.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/d/e/deede16e86a88239a6ecc6e13c99cd93778fa614_2_662x500.jpeg" width="662" /></a></div><br />
<em>Figure: 11: Distribution of Implied Vol on ETH Options 12 Mins to Expiry</em><p></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49938-h-12-minutes-to-expiry-19" name="p-49938-h-12-minutes-to-expiry-19"></a>&lt;12 Minutes to Expiry</h4>
<p>Across these 1,400 trades, we then split them into their 1-minute buckets to view distributions across times more closely associated with Preconf Block timeframes.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/4/14686bf48d5c989a80356631a03434fa70bca82f.jpeg" title="image"><img alt="image" height="493" src="https://ethresear.ch/uploads/default/optimized/3X/1/4/14686bf48d5c989a80356631a03434fa70bca82f_2_690x493.jpeg" width="690" /></a></div><br />
<em>Figure 13: Distribution of ETH Implied Vol for the last 12 mins to Expiry</em><p></p>
<p>The Vol numbers are far larger than we expected warranting further research into this area. While liquidity will need to be analyzed, we have provided some Preconf-implied Pricing given Vols of a much higher magnitude for convenience:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/f/df84a11dc4575ba83d2836af936004045965d8a4.jpeg" title="image"><img alt="image" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/d/f/df84a11dc4575ba83d2836af936004045965d8a4_2_690x411.jpeg" width="690" /></a></div><br />
<em>Figure 14: Preconf Implied Prices for very high levels of Volatility</em><p></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49938-vol-smile-20" name="p-49938-vol-smile-20"></a>Vol Smile</h4>
<p>As you may recall, we’re not looking for at-the-money Vol (used for a Straddle) but rather for Vol as it may relate to Strangles. The Vol for out-of-the-money options is almost always higher than at-the-money options. To this effect, we have provided a heat map below providing some color on the smile accordingly.</p>
<p><em>Figure 15: Vol Smile for 0 to 12 minutes</em></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-market-sizing-21" name="p-49938-market-sizing-21"></a>Market Sizing</h3>
<p>Bringing the above information together, we decide to take the combined Vol set and use that as a proxy for Strangle pricing. To account for illiquidity, we then provide different scenarios at lower volatilities assuming that as we sell more Strangles, the Vol would decrease accordingly.</p>
<p>We can now size the market considering:</p>
<ul>
<li>The historical mean Vol: 275%</li>
<li>The frequency of Consecutive Blocks: Per the above</li>
<li>The implied preconf Floor pricing as a function of Vol: Black-Scholes</li>
<li>And, making some adjustment for Liquidity: Reducing Vol by up to 200%</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/7/b7472612ce4624f0df42973ca84c9800c70d6792.jpeg" title="image"><img alt="image" height="369" src="https://ethresear.ch/uploads/default/optimized/3X/b/7/b7472612ce4624f0df42973ca84c9800c70d6792_2_690x369.jpeg" width="690" /></a></div><br />
<em>Figure 16: Preconf Pricing Based on Frequency of Consecutive Blocks, Historical Volatility and adjusted for Liquidity</em><p></p>
<p>The annual market size for Blockspace could equal approximately 419,938 ETH per year historically (~$1bln equiv) and with approx 33 million Staked ETH, this amounts to 5.33 Gwei per block or an extra 1.25% in Validator Yields as a floor above Base Fees.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Vol</th>
<th>275% Vol</th>
<th>225% Vol</th>
<th>175% Vol</th>
<th>125% Vol</th>
<th>75% Vol</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gwei Total</td>
<td>282,615</td>
<td>218,322</td>
<td>155,081</td>
<td>93,997</td>
<td>38,350</td>
</tr>
<tr>
<td>Gwei per Block</td>
<td>39.25</td>
<td>30.32</td>
<td>21.54</td>
<td>13.06</td>
<td>5.33</td>
</tr>
<tr>
<td>ETH Total Fees</td>
<td>3,094,638</td>
<td>2,390,631</td>
<td>1,698,137</td>
<td>1,029,270</td>
<td>419,938</td>
</tr>
<tr>
<td>Increase to APYs</td>
<td>9.10%</td>
<td>7.03%</td>
<td>4.99%</td>
<td>3.03%</td>
<td>1.24%</td>
</tr>
<tr>
<td>$ Total Fees</td>
<td>7,736,594,273</td>
<td>5,976,577,160</td>
<td>4,245,342,208</td>
<td>2,573,176,209</td>
<td>1,049,844,310</td>
</tr>
</tbody>
</table>
</div><h2><a class="anchor" href="https://ethresear.ch#p-49938-other-considerations-22" name="p-49938-other-considerations-22"></a>Other Considerations</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-liquidity-23" name="p-49938-liquidity-23"></a>Liquidity</h3>
<p>On the CEX side, we would like to assume there is infinite liquidity but this is not realistic. In the example immediately above, we bump the Vol downward to adjust for this but in reality, we would need more order book information. Looking forward, this market could also be illiquid because there was never another market to trade it against, e.g. Preconfs. We furthermore would need to run the analysis considering tokens other than ETH.</p>
<p>Everyday there is a 12-minute direct overlap where a set of option expiries for BTC, ETH, SOL, XRP on Deribit (and other exchanges) roughly match the time-frame for preconfs enabling one to recalibrate and reconcile any intraday Vol positions vs the actual Preconf markets with more accuracy. For the rest of the day, traders would need to run basis-risk between the Vol positions on their books, with their Preconf positions accordingly. As such, execution in the Vol markets and direct one-for-one pairs trading may be limited on a regular basis and only possible sporadically.</p>
<p>As an alternative to directly offsetting the Short Strangle positions with Long Preconfs, a trader may approach this on a portfolio basis and trade the greeks. In this instance, a preconf buyer may consider selling longer-dated, more liquid straddles, and buying them back up to 12 mins later or whenever the preconf is exercised. The gamma profile there is much less sharp meaning any moves in Spot will have a lesser impact on option price. There is additional Vol/Vega to consider (although less impactful for a short-dated option) and the time decay (which is in the arbitrageur’s favor here as they would be Short the options and theta decays faster closer to expiry). If one could seemingly buy Vol 5-10% cheaper via Preconfs over time, then this would indeed be attractive to options traders.</p>
<p>On the DEX side, liquidity across ETH, and other tokens is limited to about $4-5mm at the time of this article. Taking into account the total volume on major DEXs, we’d additionally expect about $200k of additional demand every block from general order flow. Although most of this typically may not be seen in the public mempool, over 32 blocks this would be $6.4mm which one could either use to estimate option expiration liquidity and/or capture via other conventional MEV approaches (i.e. front/back-runs).</p>
<p>More research on liquidity, and execution is warranted.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-inventory-24" name="p-49938-inventory-24"></a>Inventory</h3>
<p>To execute trades on two different venues, traders will need to hold sufficient inventory on both locations. For this reason, an additional cost of capital is not considered in this exercise.</p>
<p>For example, if the Call part of the Strangle ends up in-the-money (ITM), when the Preconf is exercised, the user will:</p>
<ul>
<li>Buy, let’s say, ETH in the DEX and sell it in the CEX. That is, the user needs USDT/C inventory onchain, and ETH inventory in the CEX, to avoid any transfer lag.</li>
</ul>
<p>Larger market makers should have sufficient liquidity on both sides making this lesser of an issue.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-european-vs-american-options-25" name="p-49938-european-vs-american-options-25"></a>European vs American Options</h3>
<p>The CEX Strangle (i.e. where the Arbitrageur is ‘Short’) is a European Option unlike the Preconfirmation (i.e. where the Arbitrageur is ‘Long’) which is more an American Option. This gives the Arbitrageur positive basis such that the instrument they are ‘Long’ has more optionality or upside built into it. If the Preconf is early exercised, the trader receives the intrinsic value while the Strangle still has some time value (although minimal), therefore, the PNL is equal to the Net Premium minus the time value difference.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49938-what-about-other-mev-and-mmev-26" name="p-49938-what-about-other-mev-and-mmev-26"></a>What About Other MEV and MMEV?</h3>
<p>While there is some intersection between conventional MEV and the Strangle strategy as highlighted above, there is still the value to the everyday deal-flow, alongside significant other forms of MEV that are not captured. Monetization of such flows would be separate to, and in addition to, that of the Floor price.</p>
<p>The Strangle exercise above suggests that some types of single-block MEV may currently be constrained by transaction costs which would indicate a non-linear MMEV for when multi-block purchases are possible (at least within the first few blocks).</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49938-conclusions-27" name="p-49938-conclusions-27"></a>Conclusions</h2>
<p>The purpose of this paper is to open up a discussion and illustrate a novel approach for the pricing of preconfs - one that importantly responds in real-time to prevailing market conditions. While the execution of such a strategy is difficult, it is not insurmountable for sophisticated players to automate.</p>
<p>Perhaps the most important consideration is that the Price of the Preconfs is a function of the Size of the Markets. If both the Options markets on Deribit and DEX liquidity are 10x larger than they are today, the Preconf Price Floors would be 10x those indicated above. Financial markets often look for inflection points where trades that were almost-possible suddenly become mainstream. With Gas Markets opening up, Macro traders now able to hedge Vol with Preconfs, Based Rollups increasing liquidity, and a trend towards lower transaction fees, this is indeed an interesting area of research.</p>
<p>We believe that highlighting a seemingly odd relationship between token Vol and the Ethereum Blockchain itself will help to further the study of risk-neutral block pricing and are excited to discuss and explore this, and other approaches, with any other parties who may be interested.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49938-references-28" name="p-49938-references-28"></a>References</h1>
<p>[ 1 ] Pascal Stichler, <a href="https://ethresear.ch/t/does-multi-block-mev-exist-analysis-of-2-years-of-mev-data/20345">Does multi-block MEV exist? Analysis of 2 years of MEV Data</a></p>
<p>[ 2 ] Öz B, Sui D, Thiery T, Matthes F. Who Wins Ethereum Block Building Auctions and Why?. arXiv preprint arXiv:2407.13931. 2024 Jul 18.</p>
<p>[ 3 ] Jensen JR, von Wachter V, Ross O. Multi-block MEV. arXiv preprint arXiv:2303.04430. 2023 Mar 8.</p>
<p>[ 4 ] Christoph Rosenmayr, Mateusz Dominiak - Statistical Arbitrage on AMMs and Block Building On Ethereum - <a href="https://greenfield.xyz/2024/09/10/statistical-arbitrage-on-amms-and-block-building-on-ethereum-part-1/">Part 1</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pricing-ethereum-blocks-with-vol-markets-with-implications-for-preconfirmations/20419">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 11:55:19 +0000</pubDate>
</item>
<item>
<title>Resolving the Dichotomy: DeFi Compliance under Zero Knowledge</title>
<link>https://ethresear.ch/t/resolving-the-dichotomy-defi-compliance-under-zero-knowledge/20413</link>
<guid>https://ethresear.ch/t/resolving-the-dichotomy-defi-compliance-under-zero-knowledge/20413</guid>
<content:encoded><![CDATA[
<div> 关键词：DeFi、合规挑战、区块链、零知识证明、智能合约

总结:
这篇文章探讨了去中心化金融(DeFi)协议面临的合规挑战，尤其是由于交易资产的特性及其分散的治理方式。为了解决这一问题，文章提出利用区块链原生的合规机制，特别是智能合约和基于链上的可验证零知识证明，以确保合规性、风险管理和必要的交易报告，同时保护用户隐私。该框架通过将与合规相关的辅助信息(CRAI)附加到链上交易，实现了实时的合规监控/验证，并使用零知识证明以隐私保护的方式进行。框架还规定了合规安全的DeFi交互模式，包括使用智能合约钱包、合规智能合约、合规智能合约系统以及零知识证明来执行由合规智能合约系统定义的合规规则。

文章提出了几个关键的研究问题：
1. 实施此框架在现有DeFi协议中可能遇到的挑战和限制。
2. 如何增强框架的隐私功能，以适应复杂合规场景中的多个合规断言，例如使用证明聚合和证明递归。
3. 如何扩展框架以支持更广泛的合规要求，超越KYC/AML，例如集成DAO和代理权。
4. 管理和更新框架内的合规政策时可能出现的治理挑战。
5. 如何利用框架的透明度和问责制特性进一步增强DeFi，如自定义钩子。
6. 如何根据不同的监管环境和司法管辖区调整框架。
7. 实施此框架对DeFi用户和协议的经济影响。

文章旨在激发关于该框架及其建议的研究问题的进一步讨论，期待来自以太坊研究社区的反馈。 <div>
<p>This is a summary and enumeration of relevant research questions based on the recent <a href="https://entethalliance.org/2024-08-20-resolving-the-dichotomy-defi-compliance-under-zero-knowledge/" rel="noopener nofollow ugc">EEA Article by the same title as this post</a>.</p>
<p><strong>Bulleted Summary</strong></p>
<ul>
<li>DeFi protocols face a compliance challenge due to the type of assets traded and their often decentralized governance.</li>
<li>A solution is leveraging blockchain-native compliance mechanisms, specifically smart contracts, and onchain verifiable zero-knowledge proofs.</li>
<li>This approach ensures regulatory compliance, weighted risk management, and required transaction reporting while preserving user privacy.</li>
<li>The framework attaches Compliance-Relevant Auxiliary Information (CRAI) to onchain transactions, enabling real-time compliance monitoring/verification, in a privacy-preserving way using zero-knowledge proofs.</li>
<li>The framework also specifies compliance-safe DeFi interaction patterns involving using smart contract wallets, DeFi compliance contracts, a compliance smart contract system, and zero-knowledge proofs to enforce compliance rules specified in the compliance smart contract system that defines compliance policies, attestation providers, and compliant assets.</li>
<li>The framework offers benefits like regulatory compliance, risk management, privacy protection, security, versatility, transparency, and accountability.</li>
<li>By adopting such a framework, DeFi protocols could navigate the regulatory landscape while maintaining their core principles.</li>
<li>Some of this solution already exists (compliance smart contract system, compliant assets, etc.) and need to be further expanded (smart contract wallets, compliance wrapper contracts, DeFi-specific custom hooks, etc.)</li>
</ul>
<p>Below is a list of open research questions in no particular order:</p>
<ul>
<li>What are the potential challenges and limitations of implementing this framework in existing DeFi protocols?</li>
<li>How can the framework’s privacy features be further enhanced to accommodate complex compliance scenarios with many compliance assertions as zkps e.g. using proof aggregation and proof recursion?</li>
<li>How can the framework be extended to support a broader range of compliance requirements beyond KYC/AML e.g. incorporated DAOs, Power-of-Attorney?</li>
<li>What are the potential governance challenges associated with managing and updating compliance policies within the framework?</li>
<li>How can the framework’s transparency and accountability features be leveraged to further enhance DeFi e.g. custom hooks?</li>
<li>How can the framework be adapted to different regulatory environments and jurisdictions?</li>
<li>What are the economic implications of implementing this framework for DeFi users and protocols?</li>
</ul>
<p>Given that part of the framework already exists, this post is to stimulate further discussion on the framework itself, and its suggested open research questions.</p>
<p>Looking forward to the feedback from the Ethereum research community.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/resolving-the-dichotomy-defi-compliance-under-zero-knowledge/20413">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 21:51:53 +0000</pubDate>
</item>
<item>
<title>Lookup argument and its tweaks</title>
<link>https://ethresear.ch/t/lookup-argument-and-its-tweaks/20409</link>
<guid>https://ethresear.ch/t/lookup-argument-and-its-tweaks/20409</guid>
<content:encoded><![CDATA[
<div> 关键词：Placeholder Proof系统、Aztec研究、Plookup技术、Join-and-Split算法、Selector列

总结:
本文讨论了构建名为Placeholder的证明系统的过程，该系统用于验证等式是否为nil。系统的核心在于一种基于查找的论证方法，其灵感来源于Aztec研究人员的工作。该方法通过将原始表格与输入列和查找表列进行连接和分割来实现，允许验证者证明特定约束是否满足。连接和分割算法是Plookup技术的基础，它通过重新排列原始列与输入列和查找表列来创建一个大矢量，然后将此矢量分割回原始大小的部分。

为了适应更复杂的电路设计需求，作者对Plookup技术进行了改进，包括支持多个查找表和任意行/列约束。他们修改了连接和分割算法以支持多个输入列，这使得能够高效地处理大量查找表，即使这些表的大小超过原始行的数量。此外，引入了选择器列的概念，允许设计者精确控制哪些行受约束以及哪些行用于存储查找表。

文章还指出，Plookup论文中描述的方法限制了查找表的总数不能超过原始行的数量总和。作者通过结合查找表标识符的使用与他们的选择器列构造方法，克服了这一限制，使得查找表可以更灵活地存储和使用，而无需受到论证方法的约束。这一改进使得查找论证成为一种通用且灵活的工具。

为了详细阐述这些修改的具体内容，读者可以访问相关页面获取更多信息。 <div>
<p>In building the Placeholder proof system for =nil; Foundation, we use a lookup argument based on the <a href="https://eprint.iacr.org/2020/315.pdf" rel="noopener nofollow ugc">Plookup paper</a> by Aztec researchers. We took Plookup technique as a starting point and then made some practical improvements for writing large PLONK circuits with a complex logic.</p>
<p>Lookup argument allows prover to prove that some table over prime field (hereafter assignment table) satisfies specific constraints: some cells computed from assignment table (lookup input) belong to list of values that is also computed from the assignment table (lookup table).</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49919-join-and-split-algorithm-1" name="p-49919-join-and-split-algorithm-1"></a>Join-and-split algorithm</h2>
<p>The core of Plookup techinque is a sorting algorithm. We call it <strong>join-and-split</strong> because it includes two steps:</p>
<ul>
<li><strong>join</strong> — lookup table columns are joined together with input columns into single large vector using special reordering algorithm.</li>
<li><strong>split</strong> — constructed vector is split again into original size parts.</li>
</ul>
<p>The case with the single lookup table and single input column is described in the Plookup paper in detail. But it wasn’t enough for our use-cases. We needed lots of efficiently packed lookup tables and lookup constraints applied to arbitrary rows and columns, and we didn’t want to repeat lookup argument for each <code>(input, table)</code> pair.</p>
<p>So, we modified join-and-split algorithm to be able to join more than two columns. It allows us to use multiple lookup constraints even if they are applied on same rows and use a large lookup table, even if its size is greater than the whole assignment table rows amount by appending columns to assignment table instead of rows. Balance between assignment table rows and columns amounts helps to find a perfect balance for the best prover performance and verification cost.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49919-selector-columns-2" name="p-49919-selector-columns-2"></a>Selector columns</h2>
<p>Original article contains technique to lookup tuples of values that are placed in the same or neighboring rows. It constructs linear combinations of columns with a random factor. Combining this approach with polynomial expressions usage for lookup tables and input columns both we achieved selector columns full support. Circuit designer now can manage which rows exactly are constrained and what rows are reserved for lookup tables storing.</p>
<p>Plookup paper also describes technique for multiple lookup tables support. They propose to associate each lookup table with its unique identifier and fill tag column to mark what rows contains lookup tables with which identifier. Tag column for input helps to mark what constraints are applied to marked row. Tag columns should be a part of the random linear combination constructed for the lookup table and input columns respectively. This approach is obviously limited. Sum of lookup tables sizes should be less than the whole table rows amount.</p>
<p>We combined lookup table identifier usage with our selector columns construction and algorithms for large lookup tables. These modifications allow lookup tables to be stored and used without regard to lookup argument restrictions, but according to the best circuit design. It made our lookup argument into a universal and flexible tool.</p>
<p>Detailed description of our modifications can be found on our <a href="https://hackmd.io/@nil-research/rkjJFAtiC" rel="noopener nofollow ugc">HackMD</a> page. Feel free to share your comments!</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/lookup-argument-and-its-tweaks/20409">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 15:14:26 +0000</pubDate>
</item>
<item>
<title>The Shape of Issuance Curves to Come</title>
<link>https://ethresear.ch/t/the-shape-of-issuance-curves-to-come/20405</link>
<guid>https://ethresear.ch/t/the-shape-of-issuance-curves-to-come/20405</guid>
<content:encoded><![CDATA[
<div> 关键词：有效收益率、真实收益率、发行曲线、中心化风险、发行削减

总结：

本文探讨了以太坊网络中发行曲线形状对验证者集分散化的影响。首先引入了有效收益率的概念，即考虑了新发行导致的稀释后的实际收益。接着定义了真实收益率，即在所有成本（如电费、网络费、税费等）后的实际收益。

文章指出，随着质押率接近100%，新发行会导致非质押持有者的有效收益率降低，而质押者的有效收益率则趋向于零。这可能导致中心化趋势，因为高质押率下，小规模、不相关质押者可能会因低真实收益率而退出。

为了减少中心化风险，文章提出了发行曲线应具备的几个属性：鼓励最低限度的质押量以确保网络安全；增加对非相关节点的激励，以保持验证者集的分散性；设定一个质押率阈值，使持有和质押的收益相等，以防止过度质押；设定一个质押率阈值，使得不同质押类型（如个人质押者、大型运营商）达到负真实收益率的时间相近，避免单一类型的验证者主导网络。

文章还展示了通过引入负发行削减机制（即发行减量），可以实现上述目标，同时保护网络免受过度质押的风险。此外，通过加入非相关激励机制，可以进一步引导质押者分散其质押资源，增强网络的安全性和抗审查性。

最后，文章强调了关注发行曲线或收益曲线的特性而非其具体数学形式的重要性，关键在于提供适当的经济激励，以维持理想的质押率水平和分散的验证者集。 <div>
<p>In this post we will analyze the consequences that the shape of the issuance curve has for the decentralization of the validator set.</p>
<p>The course of action is the following:</p>
<p>First, we will introduce the concept of effective yield as the yield observed after taking into account the dilution generated by issuance.</p>
<p>Second, we will introduce the concept of real yield as the effective yield that a validator obtains post expenses (OpEx, CapEx, taxes…).</p>
<p>Armed with these definitions we will be able to make some observations about how the shape of the issuance curve can result in centralization forces, as the real yield observed can push out small uncorrelated stakers at high stake rates.</p>
<p>Then, we will propose a number of properties we would expect the issuance curve to satisfy to minimize these centralization forces. And explore some alternative issuance curves that could deal with the aforementioned issues.</p>
<p>Finally, some heuristic arguments on how to fix a specific choice of issuance and yield curves.</p>
<p>Source Code for all plots can be found here: <a class="inline-onebox" href="https://github.com/pa7x1/ethereum-issuance" rel="noopener nofollow ugc">GitHub - pa7x1/ethereum-issuance</a></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-effective-yield-1" name="p-49913-effective-yield-1"></a>Effective Yield</h2>
<p>By effective yield we mean the yield observed by an Ethereum holder after taking into account circulating supply changes. For instance, if everyone were to be a staker, the yield observed would be <em>effectively</em> 0%. As the new issuance is split evenly among all participants, the ownership of the circulating supply experienced by each staker would not change. Pre-taxes and other associated costs this situation resembles more a token re-denomination or a fractional stock split. So we would expect the effective yield to progressively reach 0% as stake rates grow to 100%.</p>
<p>On the other hand, non-staking holders are being diluted by the newly minted issuance. This causes holders to experience a negative effective yield due to issuance. We would expect this effect to be more and more acute as stake rates grow closer and closer to 100%.</p>
<p>These ideas can be put very simply in math terms.</p>
<p>Let’s call <span class="math">s</span> the amount of ETH held by stakers, <span class="math">h</span> the amount of ETH held by non-stakers (holders), and <span class="math">t</span> the total circulating supply. Then:</p>
<p><span class="math">s + h = t</span></p>
<p>After staking for certain period of time, we will reach a new situation <span class="math">s' + h' = t'</span>. Where <span class="math">s'</span> and <span class="math">t'</span> have been inflated by the new issuance <span class="math">i</span> are obviously related to the nominal staking yield <span class="math">y_s</span>:</p>
<p><span class="math">s' = s + i = s \cdot y_s</span></p>
<p><span class="math">h' = h</span></p>
<p><span class="math">t' = t + i = t + s \cdot (y_s - 1)</span></p>
<p>Now, let’s introduce the normalized quantities <span class="math">s_n</span> and <span class="math">h_n</span>. They simply represent the proportion of total circulating supply that each subset represents:</p>
<p><span class="math">s_n \equiv \frac{s}{t}</span></p>
<p><span class="math">h_n \equiv \frac{h}{t}</span></p>
<p>We can do the same for <span class="math">s'_n</span> and <span class="math">h'_n</span>:</p>
<p><span class="math">s'_n \equiv \frac{s'}{t'} = \frac{sy_s}{s(y_s - 1) +t}</span></p>
<p><span class="math">h'_n \equiv \frac{h'}{t'} = \frac{t-s}{s(y_s - 1) + t}</span></p>
<p>With these definitions we can now introduce the effective yield as the change in the proportion of the total circulating supply observed by each subset.</p>
<p><span class="math">y_s^{eff} \equiv \frac{s'_n}{s_n} = \frac{y_s}{\frac{s}{t}(y_s-1) + 1}</span></p>
<p><span class="math">y_h^{eff} \equiv \frac{h'_n}{h_n} = \frac{1}{\frac{s}{t}(y_s-1) + 1} </span></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/f/6f2aac4b14043e89f4a7b2722d58ad5d288fc5c4.png" title="effective_yield"><img alt="effective_yield" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/6/f/6f2aac4b14043e89f4a7b2722d58ad5d288fc5c4_2_690x414.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-net-yield-2" name="p-49913-net-yield-2"></a>Net Yield</h2>
<p>Staking has associated costs. A staker must acquire a consumer-grade PC, it must pay some amount (albeit small) for electricity, it must have a high-speed internet connection. And they also must put their own labor and time to maintain the system operational and secure, or must pay someone to do that job for them. Stakers also observe other forms of costs that eat away from the nominal yield they observe, e.g. taxes. We would like to model this net yield observed after all forms of costs, because it can give us valuable information on how different stakers are impacted by changes in the nominal stake yield.</p>
<p>To model this we will introduce two types of costs; costs that scale with the nominal yield (e.g. taxes or fees charged by an LST would fit under this umbrella), and costs that do not (i.e. HW, electricity, internet, labor…).</p>
<p>With our definitions, after staking for a reference period stakers would have earned <span class="math">s' = y_s s = s + s(y_s - 1)</span></p>
<p>But if we introduce costs that eat away from the nominal yield (let’s call them <span class="math">k</span>), and costs that eat away from the principal (let’s call them <span class="math">c</span>). We arrive to the following formula for the net stake:</p>
<p><span class="math">s' = s(1-c) + s(y_s - 1) - \max(0, sk(y_s - 1))</span></p>
<p>NOTE: The max simply prevents that a cost that scales with yield becomes a profit if yield goes negative. For instance, if yield goes negative it’s unlikely that an LST will pay the LST holders 10%. Or if yield goes negative you may not be able to recoup in taxes as if it were negative income. In those cases we set it to 0. This will become useful later on when we explore issuance curves with negative issuance regimes.</p>
<p>This represents the net stake our stakers observe after all forms of costs have been taken into account. To be noted that this formula can be easily modified to take into account other types of effects like validator effectiveness (acts as multiplicative factor on the terms <span class="math">(y_s - 1)</span>) or correlation/anti-correlation incentives (which alter <span class="math">y_s</span>).</p>
<p>To fix ideas, let’s estimate the net yield observed by 3 different types of stakers. A home staker, an LST holder, and an institutional large-scale operator. The values proposed are only orientative and should be tuned to best reflect the realities of each stakeholder.</p>
<p>A home staker will have to pay for a PC that they amortize over 5 years and costs around 1000 USD, so 200 USD/year. Pay for Internet, 50 USD per month, for around 600 USD/year. Something extra for electricity, less than 100 USD/year for a typical NUC. Let’s assume they are a hobbyist and decide to do this with their spare time, valuing their time at 0 USD/year. This would mean that his staking operation has a cost of around 1000 USD/year for them. If they have 32 ETH, with current ETH prices we can round that at ~100K USD. This would mean that for this staker, <span class="math">c = \frac{1}{1000}</span>. As their costs represent around 1 over 1000 their stake value.</p>
<p>Now for the costs that scale with the yield. They will have to pay taxes, these are highly dependent on their tax jurisdiction, but may vary between 20% and 50% in most developed countries. Let’s pick 35% as an intermediate value. In that case, their stake after costs looks like:</p>
<p><span class="math">s' = s\left(1-\frac{1}{1000}\right) + s(1-0.35)(y_s - 1)</span></p>
<p>We can do the same exercise for a staker using an LST. In this case, <span class="math">c=0</span> and <span class="math">k</span> is composed of staking fees (10-15%) and taxes (20-50%) which depend on the tax treatment. Rebasing tokens have the advantage of postponing the realization of capital gains. If we assume a 5 year holding period, equivalent to the amortization time we assumed for solo staking, it could look something like this:</p>
<ul>
<li>Fixed costs: 0</li>
<li>Staking fees: 10%</li>
<li>Capital gains tax: 20%</li>
<li>Holding period: 5 years</li>
</ul>
<p><span class="math">s' = s(1-0) + s(1-0.14)(y_s - 1)</span></p>
<p>Finally, for a large scale operator. They have higher fixed costs, they will have to pay for labor, etc… But also will run much higher amount of validators. In that case, c can get much smaller as it’s a proportion of s. Perhaps 1 or 2 orders of magnitude smaller. And taxes will be typical of corporate tax rates (20-30%).</p>
<p><span class="math">s' = s\left(1-\frac{1}{10000}\right) + s(1-0.25)(y_s - 1)</span></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-net-effective-yield-aka-real-yield-3" name="p-49913-net-effective-yield-aka-real-yield-3"></a>Net Effective Yield (a.k.a Real Yield)</h2>
<p>Finally, we can blend the two concepts together to understand what’s the real yield a staker or holder obtains net of all forms of costs and after supply changes dilution. I would suggest calling this <em>net effective yield</em> as the <em>real yield</em>, because well, that’s the yield you are <em>really</em> getting.</p>
<p><span class="math">y_s^{real} = \frac{(1-c) + (y_s - 1) - \max(0,k(y_s - 1))}{\frac{s}{t}(y_s-1)+1}</span></p>
<p><span class="math">y_h^{real} = y_h^{eff} = \frac{1}{\frac{s}{t}(y_s-1) + 1}</span></p>
<p>In the second equation we are simply stating the fact that there is no cost to holding, so the real yield (after costs) of holding is the same as the effective yield of holding.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-the-issuance-curve-and-centralization-4" name="p-49913-the-issuance-curve-and-centralization-4"></a>The Issuance Curve and Centralization</h2>
<p>Up to here all the equations presented are agnostic of Ethereum’s specificities and in fact are equally applicable to any other scenario where stakeholders observe a yield but that yield is coming from new issuance.</p>
<p>To bring this analysis back to Ethereum-land it suffices to substitute <span class="math">y_s</span> by Ethereum’s issuance yield as a function of the total amount staked <span class="math">s</span>. And substitute <span class="math">t</span> by the total circulating supply of ETH.</p>
<p><span class="math">t \approx 120\cdot 10^6 \quad \text{ETH}</span></p>
<p><span class="math">i(s) = 2.6 \cdot 64 \cdot \sqrt{s} \quad \text{ETH}\cdot\text{year}^{-1}</span></p>
<p><span class="math">y_{s}(s) = 1 + \frac{2.6 \cdot 64}{\sqrt{s}} \quad \text{year}^{-1}</span></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/9/d91eba03c4aa2412aea2ad66fade8b7328651aa0.png" title="ethereum_issuance_plot"><img alt="ethereum_issuance_plot" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/d/9/d91eba03c4aa2412aea2ad66fade8b7328651aa0_2_690x414.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7cd4df4c27030c8209dfb921fb4deae6cd9218a.png" title="ethereum_nominal_yield_plot"><img alt="ethereum_nominal_yield_plot" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7cd4df4c27030c8209dfb921fb4deae6cd9218a_2_690x414.png" width="690" /></a></div><p></p>
<p>We can plot the real yield for the 4 different types of ETH stakeholders we introduced above, as a way to visualize the possible centralization forces that arise due to economies scale, and exogenous factors like taxes.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/7/0767a5fc8d2f7667fc9050a1c7d3a9a173b72ce6.png" title="ethereum_real_yield_plot"><img alt="ethereum_real_yield_plot" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/0/7/0767a5fc8d2f7667fc9050a1c7d3a9a173b72ce6_2_690x414.png" width="690" /></a></div><p></p>
<p>We can make the following observations, from which we will derive some consequences.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49913-observations-5" name="p-49913-observations-5"></a>Observations</h3>
<ul>
<li>
<p><strong>Observation 0</strong>: The economic choice to participate as a solo staker, LST holder, ETH holder or any other option is made on the gap between the real yields observed and the risks (liquidity, slashing, operational, regulatory, smart contract…) of each option. Typically higher risks demand a higher premium.</p>
</li>
<li>
<p><strong>Observation 1</strong>: Holding always has a lower real yield than staking, at least for the assumptions taken above for costs. But the gap shrinks with high stake rates.</p>
</li>
<li>
<p><strong>Observation 2</strong>: Different stakers cross the 0% real yield at different stake rate. Around 70M ETH staked solo validators start to earn negative real yield. At around 90M ETH institutional stakers start to earn negative real yield. At around 100M LST holders start to earn negative real yield.</p>
</li>
<li>
<p><strong>Observation 3</strong>: When every staker and every ETH holder is becoming diluted (negative real yield), staking is a net cost for everyone.</p>
</li>
<li>
<p><strong>Observation 4</strong>: There is quite a large gap between the stake levels where different stakers cross the 0% real yield.</p>
</li>
<li>
<p><strong>Observation 5</strong>: Low nominal yields affect disproportionately home stakers over large operators. From the cost structure formula above we can see that as long as nominal yields are positive, the only term that can make the real yield negative is <span class="math">c</span>. This term is affected by economies of scale, and small operators will suffer larger <span class="math">c</span>.</p>
</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#p-49913-implications-6" name="p-49913-implications-6"></a>Implications</h3>
<p><strong>Observation 0</strong> and <strong>Observation 1</strong> imply that as the gap between real yields becomes sufficiently small, participating in the network as some of those subsets may become economically irrational. For example, solo staking may be economically irrational given the operational risks, liquidity risks, slashing risks if the yield premium becomes sufficiently small vs holding. In that case solo stakers may become holders or switch to other forms of staking (e.g. LSTs) where the premium still satisfies the risk.</p>
<p>Together with <strong>Observation 2</strong> and <strong>Observation 4</strong> implies that as stake rates become higher and higher the chain is at risk of becoming more centralized, as solo stakers (which are the most uncorrelated staking set) must continue staking when it may be economically irrational to do so. Given the above assumptions LSTs will always observe at least 1% real yield higher than holding even at extreme stake rates (~100%), this may mean that there is always an incentive to hold an LST instead of ETH. Furthermore, when solo stakers cross to negative real yield but other stakers do not, other stakers are slowly but steadily gaining greater weight.</p>
<p>From <strong>Observation 3</strong> we know that the very high stake rate regime, where everyone is observing a negative real yield, is costly for everyone. Everyone observes dilution. The money is going to the costs that were included in the real yield calculation (tax, ISPs, HW, electricity, labor…).</p>
<p><strong>Observation 5</strong> implies that nominal yield reductions need to be applied with care and certainly not in isolation without introducing uncorrelation incentives at the same time. As they risk penalizing home solo stakers disproportionately.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49913-recommendations-7" name="p-49913-recommendations-7"></a>Recommendations</h3>
<p>Given the above analysis, we can put forward a few recommended properties the yield curve (respectively the issuance curve) should have. The idea of establishing these properties is that we should be able to discuss them individually and agree or disagree on their desirability. Once agreed they constrain the set of functions we should consider. At a minimum, it will make the discussion about issuance changes more structured.</p>
<ul>
<li>
<p><strong>Property 0</strong>: Although this property is already satisfied with the current issuance curve, it is worth stating explicitly. The protocol should incentivize some minimum amount of stake, to ensure the network is secure and the cost to attack much larger than the potential economic reward of doing so. This is achieved by defining a yield curve that ramps up the nominal yield as the total proportion of stake (<span class="math">s_n</span>) is reduced.</p>
</li>
<li>
<p><strong>Property 1</strong>: The yield curve should contain uncorrelation incentives such that stakers are incentivized to spin-up uncorrelated nodes and to stake independently, instead of joining large-scale operators. From a protocol perspective the marginal value gained from another ETH staked through a large staking operation is much smaller than if that same ETH does so through an uncorrelated node. The protocol should reward uncorrelation as that’s what allows the network to achieve the extreme levels of censorship resistance, liveness/availability and credible neutrality the protocol expects to obtain from its validator set. The economic incentives must be aligned with the expected outcomes, therefore the yield curve must contain uncorrelation incentives.</p>
</li>
<li>
<p><strong>Property 2</strong>: The issuance curve (resp. yield curve) should have a regime where holding is strictly more economically beneficial than staking, at sufficiently high stake rates. This means that the real yield of holding is greater than the real yield of staking if the stake rate is sufficiently high. As explained above it’s the real yield gap the defining characteristic that establishes the economically rational choice to join one subset or another. If the holding real yield can be greater than the staking real yield at sufficiently high stake rates there is an economic incentive to hold instead of continue staking. To be noted, up to here we are not making an argument at what stake rate this should be set. It suffices to agree that 99.9% stake rate is unhealthy for the protocol (it’s a cost for everyone, LSTs will displace ETH as pristine collateral, etc…). If that’s the case, then we can prevent this outcome by setting the holding real yield to be higher than staking at that level. Unhealthy levels are likely found at much lower values of stake rate.</p>
</li>
<li>
<p><strong>Property 3</strong>: To prevent centralization forces, the stake rates at which uncorrelated validators vs correlated validators cross to negative real yield should be small, as small as possible. A large gap between the thresholds to negative real yields of uncorrelated (e.g. home stakers) and correlated sets (e.g. large operators) creates a regime where the validator set can become more and more centralized. To make the case more clear, if uncorrelated validators reach 0 real yield at 30M ETH staked, while holding an LST composed of large operators (e.g. cbETH, wstETH) does so at 100M ETH. The regime where the stake ranges between 30M and 100M is such that solo stakers will tend to disappear, either quickly (they stop staking) or slowly (they become more and more diluted), the outcome in either case is a more centralized validator set.</p>
</li>
<li>
<p><strong>Property 4</strong>: The yield curve should taper down relatively quick to enter the regime of negative real yields. From <strong>Property 2</strong> and <strong>Property 3</strong> we know we should build-in a regime where the real yield from issuance goes negative, but we want this regime to occur approximately at the same stake rate for the different types of stakers, to prevent centralization forces. <strong>Observation 5</strong> implies that if the slope of this nominal yield reduction is slow, stakers with different cost structures will be pushed out at much different stake rates. Hence, we need to make this yield reduction quick.</p>
</li>
<li>
<p><strong>Property 5</strong>: The issuance yield curve should be continuous. It’s tempting to play with discontinuous yield curves, but yield is the main incentive to regulate the total stake of the network. We would like that the changes induced to the total stake <span class="math">s</span> are continuous, therefore the economic incentive should be a continuous function.</p>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-exploring-other-issuance-curves-8" name="p-49913-exploring-other-issuance-curves-8"></a>Exploring Other Issuance Curves</h2>
<p>The desired properties can be summarized very succinctly:</p>
<ul>
<li>The yield curve should be continuous.</li>
<li>The yield curve should go up as stake rate goes to 0.</li>
<li>The yield curve should go to 0 as the stake rate goes up, crossing 0 at some point that bounds from above the desired stake rate equilibrium.</li>
<li>The yield curve should have uncorrelation incentives such that spinning up uncorrelated validators is rewarded and incentivized over correlated validators.</li>
<li>The real yield curves of correlated and uncorrelated stakers should become negative relatively close to each other.</li>
</ul>
<p>A very simple solution to meet the above is to introduce a negative term to Ethereum’s issuance yield and uncorrelation incentives.</p>
<p>The negative term should grow faster than the issuance yield as the stake grows, so that it eventually overcompensates issuance and makes the yield go negative quickly at sufficiently high stake rates. This negative term can be thought of as a stake burn, and should be applied on a slot or epoch basis such that it’s unavoidable (thanks to A. Elowsson for this observation).</p>
<p>Uncorrelation incentives are being explored in other posts. We will simply leave here the recommendation of adopting them as part of any issuance tweaks. Read further: <a href="https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114/4">Anti-Correlation Penalties by Wahrstatter et al.</a></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49913-ethereums-issuance-with-stake-burn-9" name="p-49913-ethereums-issuance-with-stake-burn-9"></a>Ethereum’s Issuance with Stake Burn</h3>
<p>The following is an example of how such a negative term can be introduced.</p>
<p><span class="math">i(s) = 2.6 \cdot 64 \cdot \sqrt{s} - 2.6 \cdot \frac{s \ln s}{2048} \quad \text{ETH} \cdot \text{year}^{-1}</span></p>
<p><span class="math">y_{s}(s) = 1 + \frac{2.6 \cdot 64}{\sqrt{s}} - \frac{2.6 \ln s}{2048} \quad \text{year}^{-1}</span></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/7/5734f552fcad604fd70816d71a7b1af07c067f7c.png" title="ethereum_issuance_with_burn_plot"><img alt="ethereum_issuance_with_burn_plot" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/5/7/5734f552fcad604fd70816d71a7b1af07c067f7c_2_690x414.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/3/e345685acc94592ba49432571ae51c9c72286588.png" title="ethereum_nominal_yield_with_burn_plot"><img alt="ethereum_nominal_yield_with_burn_plot" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/e/3/e345685acc94592ba49432571ae51c9c72286588_2_690x414.png" width="690" /></a></div><p></p>
<p>The negative stake burn term eventually dominates issuance and can make it go negative. There is complete freedom deciding where this threshold occurs, by simply tweaking the constant pre-factors. In this particular case, the parameters have been chosen so they are rounded in powers of 2 and so that the negative issuance regime roughly happens around 50% stake rate.</p>
<p>This negative issuance regime induces a positive effective yield on holders, which provides the protocol with an economic incentive to limit the stake rate. As the real yield will eventually be greater holding ETH than staking. It also serves to protect the network from overloading its consensus layer, as it provides the protocol with a mechanism to charge exogenous sources of yield that occur on top of it. If priority fees, MEV, or restaking provide additional yield that would push stake rates above the desired limit, the protocol would start charging those extra sources of yield by making issuance go negative. Hence redistributing exogenous yield onto ETH holders.</p>
<p>To understand better the impact that this stake burn has on the different stakeholders we can plot the real yield curves.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/6/b664771684f7f8abc3d591b6b6acdaae46a63cbe.png" title="ethereum_real_yield_with_burn_plot"><img alt="ethereum_real_yield_with_burn_plot" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/b/6/b664771684f7f8abc3d591b6b6acdaae46a63cbe_2_690x414.png" width="690" /></a></div><p></p>
<p>We can see how the introduction of a negative issuance yield regime has helped achieve most of the properties we desired to obtain. Particularly, we can notice the stake rates at which different stakeholders reach 0 real yield have compressed and are much closer to each other. And we can appreciate how when stake rates get close to 50% (given the choice of parameters) holders start to observe a positive real yield which disincentivizes additional staking. Holding real yields can become quite large so even large exogenous sources of yield can be overcome.</p>
<p>Given that we haven’t touched the positive issuance term, this results in a large reduction of the staking yield. We can increase the yield trivially while respecting the same yield curve shape. Here the same curve with larger yield:</p>
<p><span class="math">i(s) = 2.6 \cdot 128 \cdot \sqrt{s} - 2.6 \cdot \frac{s \ln s}{1024} \quad \text{ETH} \cdot \text{year}^{-1}</span></p>
<p><span class="math">y_{s}(s) = 1 + \frac{2.6 \cdot 128}{\sqrt{s}} - \frac{2.6 \ln s}{1024} \quad \text{year}^{-1}</span></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/b/3b1b509db61e4ede02779c912e6abaabd9f83019.png" title="ethereum_issuance_with_burn_plot_2"><img alt="ethereum_issuance_with_burn_plot_2" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/3/b/3b1b509db61e4ede02779c912e6abaabd9f83019_2_690x414.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/2/b22b3240440e4855aff51d30c28097545bf16400.png" title="ethereum_real_yield_with_burn_plot_2"><img alt="ethereum_real_yield_with_burn_plot_2" height="414" src="https://ethresear.ch/uploads/default/optimized/3X/b/2/b22b3240440e4855aff51d30c28097545bf16400_2_690x414.png" width="690" /></a></div><p></p>
<p>This shows the target yield that is observed at a specific stake rate is a separate consideration to the curve shape discussion. So if you dislike this particular example because of the resulting yield at current stake rates. Fear not, that has an easy fix.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49913-adding-uncorrelation-incentives-to-the-mix-10" name="p-49913-adding-uncorrelation-incentives-to-the-mix-10"></a>Adding Uncorrelation Incentives to the Mix</h3>
<p>We will not cover the specifics of how uncorrelation incentives should be introduced nor how they should be sized, but we will illustrate how the introduction of a correlation penalty can help align the economic incentives with the network interest of maintaining an uncorrelated validator set.</p>
<p>To do so we will simulate what would happen to the real yields observed by the following stakeholders:</p>
<ul>
<li>Home Validator (Very Uncorrelated): -0.0% subtracted to the nominal yield through correlation penalties</li>
<li>LST Holder through a decentralized protocol (Quite Uncorrelated): -0.2% subtracted to the nominal yield through correlation penalties</li>
<li>LST Holder through staking through large operators (Quite Correlated): -0.4% subtracted to the nominal yield through correlation penalties</li>
<li>Large Institutional Operator (Very Correlated): -0.6% subtracted to the nominal yield through correlation penalties</li>
</ul>
<p>The following figure zooms in to the area where negative real yields are achieved:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/5/c5272375fa151b1e666bb07feb5f5a9112fbc457.png" title="ethereum_real_yield_with_burn_uncorrelation_plot"><img alt="ethereum_real_yield_with_burn_uncorrelation_plot" height="377" src="https://ethresear.ch/uploads/default/optimized/3X/c/5/c5272375fa151b1e666bb07feb5f5a9112fbc457_2_690x377.png" width="690" /></a></div><p></p>
<p>Important Note: The above values for correlation penalties are not based on any estimation or study. They have been chosen arbitrarily to showcase that the inclusion of uncorrelation incentives in the issuance curve can be used to disincentivize staking through large correlated operators. We refer the analysis of the right incentives to other papers.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-fixing-the-issuance-yield-curve-11" name="p-49913-fixing-the-issuance-yield-curve-11"></a>Fixing the Issuance Yield Curve</h2>
<p>Up until now the focus has been on the shape of the yield curve (respectively the issuance curve) but very little has been said about the specific yield we should target at different stake rates. As illustrated above, by simply applying a multiplicative factor we can keep the same curve shape but make yields be higher or lower as wished.</p>
<p>In this section we will provide some heuristic properties to address this problem and be able to specify the prefactors that allow us to define a concrete yield curve.</p>
<p>These heuristic properties are orientative. There is no hard science behind them, just some soft arguments that provide reasonable justification for these choices.</p>
<p><strong>Heuristic 0</strong>: The nominal issuance yield should become negative at 50% stake rate or lower. Higher stake rates start to become problematic, above those levels the majority of circulating supply is staking. In case of supermajority bug the majority of ETH holders could be incentivized to break the consensus rules. The negative yield regime can be seen as a protection mechanism from the protocol to prevent this type of situations from happening, it sets an economic incentive to align the social layer with the protocol interests.</p>
<p><strong>Heuristic 1</strong>: Target 3% yield at 25% stake rate. When PoS was released there was no idea what would be the expected staking yield the market would consider appetizing. Would 5% be enough? Or 3%?</p>
<p>Now we have data points, current staking yield is 3% as measured by <a href="https://beaconcha.in" rel="noopener nofollow ugc">https://beaconcha.in</a> (issuance, MEV, and priority fees included). So we know the market certainly has appetite for ETH yield at 3%. There is also some soft-arguments by V. Buterin, J. Drake et al. that 25% stake rate should provide enough security.</p>
<p>And finally, the current issuance curve happens to provide 3% yield at 25% stake rate. So by fixing the new curve to meet that same yield at 25% we anchor the same yield (and issuance) at the target rate. But any extra amount of stake will be met with a reduction in yield and issuance that makes it go to 0 before hitting 50%.</p>
<p>As current stake rate is a tad over 25% the proposed change to the issuance curve would imply a bit of issuance reduction, nothing very significant. But most importantly it avoids the ever growing issuance increase as stake rates become higher.</p>
<p>In conjunction with well designed uncorrelation incentives it could help the protocol ensure it does not overpay for security, stake rates are self-limiting, and the validator set very uncorrelated.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49913-final-words-12" name="p-49913-final-words-12"></a>Final Words</h2>
<p>The analytic form of the yield curve or the issuance curve matter much less than we may think. It might be tempting to spend time tinkering with its concrete analytic form but for all it matters it could be equally defined with a piece-wise continuous function.</p>
<p>Its purpose is to provide an economic incentive to get stake rates where the protocol needs them to be (not too high, not too low) and maintaining a large uncorrelated validator set.</p>
<p>This post is an invitation to steer the discussion towards said properties instead of getting lost with the fine details. If we nail down the properties we will constrain the solution space enough so that almost any function we choose will do the job.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/the-shape-of-issuance-curves-to-come/20405">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 21:11:48 +0000</pubDate>
</item>
<item>
<title>Introducing CCTP Express: a faster and cheaper way to use CCTP</title>
<link>https://ethresear.ch/t/introducing-cctp-express-a-faster-and-cheaper-way-to-use-cctp/20396</link>
<guid>https://ethresear.ch/t/introducing-cctp-express-a-faster-and-cheaper-way-to-use-cctp/20396</guid>
<content:encoded><![CDATA[
<div> 关键词：CCTP Express、USDC、Cross-Chain Transfer Protocol（CCTP）、off-chain attestation、trustless design

总结：
CCTP Express 是一种旨在增强 CCTP（Cross-Chain Transfer Protocol）并提供更快、更低成本体验的跨链桥接系统。它基于意图进行桥接，通过采用“填空支付优先”机制加速交易过程。CCTP Express 设计为信任无碍的系统，允许任何人都可以作为填空者或数据守护人参与其中，无需许可。为了降低填空者面临的风险，CCTP Express 引入了保险费，该费用根据用户定义的发起截止时间变化。通过优化交易成本和数据传输，CCTP Express 降低了用户和填空者的交易费用，同时通过将偿还和重新平衡交易打包来节约成本，并利用哈希形式传输跨链消息以减少数据大小。

CCTP Express 采用中心化与分散化的架构，由请求报价机制、填空网络以及结算层组成，确保用户、填空者和 CCTP 的共赢。其设计遵循 ERC-7683 标准，强调行业标准的一致性，促进不同跨链意图系统之间的互操作性和资源共享。通过这种设计，CCTP Express 增强了用户体验，提高了服务效率，并促进了市场的竞争性。 <div>
<p>By <a href="https://twitter.com/wels_eth" rel="noopener nofollow ugc">Wel</a> and <a href="https://twitter.com/alau1218" rel="noopener nofollow ugc">Alan</a> on behalf of CCTP Express<br />
<em>For most recent information about CCTP Express, please visit <a href="https://twitter.com/cctpexpress" rel="noopener nofollow ugc">our X</a>.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-motivation-1" name="p-49895-motivation-1"></a>Motivation</h1>
<p>We recognize the vital role stablecoins play in the Web3 ecosystem, especially within DeFi. Among them, USDC stands out for its high transparency and regulatory compliance. Circle, the issuer of USDC, introduced the Cross-Chain Transfer Protocol (CCTP) to securely transfer USDC across chains using a native burn-and-mint mechanism.</p>
<p>CCTP is a game-changing tool that drives USDC adoption in the multichain world, allowing developers to create applications that offer secure, 1:1 USDC transfers across blockchains. This eliminates the added risks of using bridges.</p>
<p>However, CCTP has a key limitation: wait time. Its off-chain attestation service requires block confirmations on the source chain to ensure finality before minting USDC on the destination chain. This process can take anywhere from 20 seconds to 13 minutes, which is not ideal for users needing instant transfers. To address this, CCTP Express was designed to provide instant USDC bridging while leveraging CCTP. We position CCTP Express as a booster tool of CCTP, enabling users to benefit from faster and cheaper transactions.</p>
<p>We believe CCTP Express is an essential tool to achieve chain abstraction by providing an instant USDC bridging experience.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-tldr-2" name="p-49895-tldr-2"></a>TL;DR</h1>
<ul>
<li>CCTP Express is positioned as a booster tool to use CCTP, where users enjoys a faster and cheaper experience;</li>
<li>It is an intent-base bridging system built upon CCTP, instant USDC bridging is enabled by the “Filler-Pay-First” mechanism;</li>
<li>CCTP Express is a trustless design, allowing anyone to participate as a filler or datadaemon without permission;</li>
<li>To mitigate the reorg risk exposed to the fillers, CCTP Express introduces an insurance fee that varies based on the user-defined initiateDeadline.;</li>
<li>In order to lower the transaction costs, repayment and rebalancing transactions are bundled, cross-chain messages are transmitted as hashes to reduce data size.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-primary-principles-3" name="p-49895-primary-principles-3"></a>Primary principles</h1>
<p><strong>1. CCTP Dependency</strong><br />
CCTP Express is specifically designed to enhance CCTP. All fund rebalancing must be done exclusively through CCTP to avoid exposure to potential risks associated with other bridges.</p>
<p><strong>2. Decentralization</strong><br />
The system must be trustless to ensure maximum protection for everyone’s assets. Players in the system, including Fillers and Datamaemon, are permissionless.</p>
<p><strong>3. Win-Win-Win</strong><br />
The design should benefit all stakeholders — users, fillers, and CCTP. Users gain a faster and more cost-effective experience, fillers receive satisfactory rewards while their funds are safeguarded, and CCTP grows stronger through the support of CCTP Express.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-key-concepts-4" name="p-49895-key-concepts-4"></a>Key concepts</h1>
<p>CCTP Express is an intent based cross-chain bridging system built upon CCTP. The key to speed up the transaction is the adoption of the “Filler-pay-first” mechanism.</p>
<p>When a user submits a bridging intent, fillers initiate an order on the origin chain, then immediately call a fillOrder on the destination chain and transfer funds to the user accordingly.</p>
<p>The system periodically validates the payments and repays to fillers in batches. Rebalancing across domains is done across CCTP if needed. This settlement process is out of the scene of the users, the repayments and rebalancing are bundled to save costs.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-dive-deeper-5" name="p-49895-dive-deeper-5"></a>Dive Deeper</h1>
<p>CCTP Express adopts a Hub-and-Spoke architecture, it can be broken down into a 3-layered system: a request for quote mechanism to obtain users’ bridging intent, enabling a filler network to claim and fill those orders, and lastly a settlement layer periodically repay fillers through CCTP and utilizing attestation service from Iris (Circle’s off-chain attestation service).</p>
<p>Our design adheres to ERC-7683, emphasizing the importance of aligning with industry standards. This ensures that cross-chain intent systems can interoperate and share infrastructure like order dissemination services and filler networks. By fostering this interoperability, we enhance the end-user experience by increasing competition for fulfilling user intents. Below is a diagram of the architecture of CCTP Express:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/3/037c645827e04b44e5ed2f79fedaddff4f92eab3.jpeg" title="Architecture of CCTP Express"><img alt="Architecture of CCTP Express" height="451" src="https://ethresear.ch/uploads/default/optimized/3X/0/3/037c645827e04b44e5ed2f79fedaddff4f92eab3_2_690x451.jpeg" width="690" /></a></div><p></p>
<p><strong>Order initiation</strong></p>
<ol>
<li>User signs an off-chain message defining the parameters of an order:</li>
</ol>
<pre><code class="lang-auto"> function deposit(
        bytes32 recipient,
        bytes32 inputToken,
        bytes32 outputToken,
        uint256 inputAmount,
        uint256 outputAmount,
        uint32 destinationDomainId,        
        bytes32 exclusiveFiller,
        uint32 exclusivityDeadline,
        uint32 initiateDeadline,
        uint32 fillDeadline,
        bytes calldata message
    ) external;
</code></pre>
<ol start="2">
<li>The order is disseminated to Fillers. The Filler calls <code>initiate</code> on the origin chain SpokePool. A <code>CrossChainOrder</code> will be created and the user’s funds are transferred to the SpokePool for escrow.</li>
<li>The SpokePool on origin chain submits a <code>Deposit</code> message to Circle’s off-chain attestation service, Iris, for attestation and subsequently a <code>DepositAttestation</code> will be generated.</li>
</ol>
<p><strong>Filler Network Fills Order</strong></p>
<ol start="4">
<li>
<p>Fillers call <code>fillOrder</code> on the destination SpokePool with their own assets which are then transferred to the user from the SpokePool.</p>
</li>
<li>
<p>The SpokePool on destination chain submits a <code>Fill</code> message to Iris and a <code>FillAttestation</code> will be generated.</p>
</li>
</ol>
<p><strong>Settlement</strong></p>
<ol start="6">
<li>
<p>A permissionless Datadaemon retrieves the <code>DepositAttestation</code> and <code>FillAttestation</code> and relays to the Hub Pool on the Settlement Chain.</p>
</li>
<li>
<p>Periodically, the Datadaemon calls <code>repayFunds</code> and <code>rebalanceFunds</code> at the Hub Pool, which would collect all the attestations and perform the following steps:</p>
</li>
</ol>
<ul>
<li>
<p>Iterate through a list of attestations, a valid filled order is supported by both <code>Deposit</code> and <code>Fill</code> attestation.</p>
</li>
<li>
<p>Determine the aggregate settlement sum from all valid fills for each filler.</p>
</li>
<li>
<p>If there is sufficient funds on SpokePool to repay filler, a <code>repayFunds</code> message in the form of merkle root hash is sent to Iris.</p>
</li>
<li>
<p>For the remaining outstanding payment, the Hub Pool will send a <code>rebalanceFunds</code> message in the form of merkle root hash to Iris, which indicates how much a SpokePool with surplus funds would send to another pool in deficit to fulfill the need for repayment.</p>
</li>
</ul>
<ol start="8">
<li>
<p>Once the <code>repayFunds</code> and <code>rebalanceFunds</code> messages get attested by Iris, they are sent to respective SpokePools. Datamaemon will call <code>repayFunds</code> and <code>rebalanceFunds</code> on SpokePools with merkle root hash and their respective transaction details. Accordingly, funds would be repaid to fillers and sent to other SpokePools to ensure sufficient funds for handling repayments.</p>
</li>
<li>
<p>Repay funds to fillers from the SpokePool on destination chain, and rebalance funds across SpokePools on different chains via CCTP.</p>
</li>
</ol>
<p><strong>Cctp Fill Settlement</strong></p>
<ol start="10">
<li>
<p>In case of an order initiated by Fillers not being filled, anyone can call <code>cctpFill</code> and mark the order status on destination chain SpokePool to <code>RequestCctpFill</code> and block any filler from filling it. At the same time, the SpokePool will emit a <code>CctpFill</code> message to Iris for attestation.</p>
</li>
<li>
<p>The <code>CctpFillAttestation</code> will be used to replace the <code>FillAttestation</code> mentioned in 5. and allow the user fund to be transferred via the CCTP route.</p>
</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-risk-and-solutions-6" name="p-49895-risk-and-solutions-6"></a>Risk and solutions</h1>
<p><strong>Reorg risk</strong><br />
The reorg risk is uniquely borne by fillers. If the filler fills the intent too fast without waiting for the finality on the source chain, the source chain may reorg and cause a loss to the filler since the intent has been filled on the destination chain and the filler would end up in empty hand.</p>
<p>The reorg risk is effectively mitigated by the <strong>Insurance Fee</strong>, which varies based on the <code>initiateDeadline</code> specified by the user. If the <code>initiateDeadline</code> is sufficiently long, the filler can reinitiate the <code>CrossChainOrder</code> on the origin chain in the event of a reorg, ensuring the user’s funds are transferred again. The insurance fee is calculated using below formula:</p>
<p><img alt="Formula of Insurance Fee" height="96" src="https://ethresear.ch/uploads/default/original/3X/8/f/8f2626d45b13f0ec864c696fa581f0af9f7491b6.png" width="244" /></p>
<p>Where:<br />
<em>f(t)</em> is the insurance fee which is a function varies with <em>t</em><br />
<em>V</em> is the trading volume, representing the maximum insurance fee<br />
<em>e</em> is the base of the natural logarithm<br />
<em>k</em> is a constant that control the descending rate of the fee<br />
<em>t</em> is the time between order creation time and the initiateDeadline<br />
<em>T</em> is the time required for finality on the origin chain</p>
<p>The insurance fee varies with the <code>initiateDeadline</code>- it decreases with the increment of time between the order creation time and the <code>initiateDeadline</code>:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/6/1626648dc74ed8b71e5d3e7f66c0b1d9731baba1.png" title=""><img alt="" height="250" src="https://ethresear.ch/uploads/default/optimized/3X/1/6/1626648dc74ed8b71e5d3e7f66c0b1d9731baba1_2_321x250.png" width="321" /></a></div><p></p>
<p>Since the insurance fee decreases significantly when the <code>initiateDeadline</code> is long (it drops to nearly zero if it is 2x of the time needed for finality on the origin chain), a normal user is likely to set a long initiateDeadline to avoid paying the fee, minimizing the reorg risk for the filler.</p>
<p><strong>High system costs</strong><br />
The complexity of the design apparently implies higher costs compared to bridging directly using CCTP. To align with our goal of providing a faster and cheaper way to use CCTP, we mitigate costs through two key strategies: <em><strong>transaction bundling</strong></em> and <em><strong>data compression</strong></em>.</p>
<p>Transactions bundling-</p>
<p>Datadaemon works periodically to call repayment and rebalancing on the hub pool. This interval is adjustable to make sure a sufficient number of transactions are processed in each batch.</p>
<p>In this architecture design, gas costs are primarily incurred in rebalancing via CCTP and fund transfers. By processing rebalancing in batches and handling repayments in aggregate sums to the fillers, these costs are distributed across multiple transactions, reducing the costs on any single transaction.</p>
<p>Data Compression-</p>
<p>Cross-chain messages are transmitted between spoke pools and the hub pool via Iris, Circle’s off-chain attestation service. To minimize data size and reduce gas costs, these messages are sent in the form of a hash.</p>
<p>For a detailed comparison of gas consumption between CCTP and CCTP Express, check out <a href="https://medium.com/@cctpexpress/cctp-express-is-cheaper-than-cctp-2c527e0afa62" rel="noopener nofollow ugc">this article</a>.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-faq-7" name="p-49895-faq-7"></a>FAQ</h1>
<p><strong>1. What does it mean to the end user?</strong><br />
When using CCTP Express’s front end or applications integrated with CCTP Express, users benefit from a significantly faster and cheaper way to bridge USDC across chains. By leveraging CCTP as the underlying asset bridge, the system enhances user experience while maintaining robust security.</p>
<p><strong>2. What are the possible use cases?</strong><br />
We believe CCTP Express is essential to achieve chain abstraction by providing an instant USDC bridging experience. Possible use cases included-</p>
<p><em>USDC-denominated dApps</em><br />
USDC is widely adopted in various dApps, e.g. dYdX and Polymarket. dApps can integrate CCTP Express SDK to offer their users instant transfer in and out from all CCTP supported chains without the usual waiting time.</p>
<p><em>Payment Network</em><br />
CCTP Express can offer instant settled transaction experience for users across chains, enabling them to pay their USDC for a coffee from any CCTP supported chain.</p>
<p><em>Money Lego</em><br />
Arbitragers and Solvers can utilize CCTP Express to be the backbone of their cross chain actions. It’s highly undesirable for arbitragers or solvers to wait for long in the high speed crypto world, CCTP Express can offer them superior speed without worrying about security as CCTP Express is using CCTP as the underlying bridge.</p>
<p><strong>3. With a similar idea of providing cross chain bridging powered by off chain agents, how is CCTP Express different from other intent-based bridges, say Across?</strong></p>
<p>The primary distinction between CCTP Express and Across are: positioning and settlement mechanism.</p>
<p><em>Positioning -</em></p>
<p>While both protocols are intent-based bridges powered by fillers/relayers, CCTP Express is positioned to be a booster tool to use CCTP.</p>
<p>Given this focus, CCTP Express is closely integrated with CCTP and evolves in tandem with it. For instance, if CCTP supports EURC, CCTP Express will promptly support it as well.</p>
<p>And this alignment also applies to the choice of picking which chain CCTP Express supports. CCTP Express aims to cover all EVM and non-EVM chains CCTP operates. And like<a href="https://developers.circle.com/stablecoins/docs/message-format#message-header" rel="noopener nofollow ugc"> CCTP</a>, CCTP Express adopts the bytes32 address format, instead of the 20 byte address used in EVM, to handle 32 byte addresses in many non-EVM chains.</p>
<p>In contrast, Across is limited to EVM chains only, as it has a<a href="https://docs.across.to/resources/new-chain-requests" rel="noopener nofollow ugc"> hard requirement</a> to support EVM- chains only.</p>
<p><em>Settlement mechanism -</em></p>
<p>In CCTP Express, the Hub Pool smart contract utilizes the Iris attestation service used in CCTP to relay and verify messages. Deposit and Filled messages from various Spoke Pools are sent to Iris for attestation and then collected in the Hub Pool, which processes repayments on-chain.</p>
<p>In contrast, Across uses canonical bridges to relay messages and utilizes<a href="https://docs.across.to/use-cases/settle-cross-chain-intents" rel="noopener nofollow ugc"> UMA</a> to optimistically verify fill events off-chain. Since UMA works off-chain, an interval is needed as a dispute window.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49895-discuss-with-us-8" name="p-49895-discuss-with-us-8"></a>Discuss with Us</h1>
<p>To shape a better product, we are keen to discuss with fillers and teams who need instant USDC bridging. If anyone is interested in CCTP Express, we have a public telegram group here to discuss about it: <a href="https://t.me/cctpexpress" rel="noopener nofollow ugc">Join Group Chat</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/introducing-cctp-express-a-faster-and-cheaper-way-to-use-cctp/20396">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:14:12 +0000</pubDate>
</item>
<item>
<title>Fake GLV: You don't need an efficient endomorphism to implement GLV-like scalar multiplication in SNARK circuits</title>
<link>https://ethresear.ch/t/fake-glv-you-dont-need-an-efficient-endomorphism-to-implement-glv-like-scalar-multiplication-in-snark-circuits/20394</link>
<guid>https://ethresear.ch/t/fake-glv-you-dont-need-an-efficient-endomorphism-to-implement-glv-like-scalar-multiplication-in-snark-circuits/20394</guid>
<content:encoded><![CDATA[
<div> 关键词：GLV算法、非标准椭圆曲线、SNARK电路、P-256曲线、ECDSA验证优化

总结:

本文探讨了在没有有效共轭的情况下，如何在SNARK电路中实现类似GLV的标量乘法技术。GLV算法通常用于具有有效共轭的椭圆曲线，以加速标量乘法操作。然而，对于像P-256这样的曲线，由于缺乏有效共轭，传统的GLV方法不可用。文章提出了一种“假GLV”技巧，通过引入辅助参数u和v来实现优化。

1. **传统标量乘法**: 文章首先介绍了标准的标量乘法算法，如双倍加算法，以及在SNARK电路中的实现挑战，特别是对于条件分支的处理。

2. **GLV算法介绍**: 接着，文章解释了GLV算法的工作原理，特别强调了当椭圆曲线具有有效共轭时，如何利用该特性加速标量乘法计算。

3. **假GLV技巧**: 为了克服P-256等曲线缺乏有效共轭的问题，文章提出了“假GLV”技巧，通过引入辅助参数u和v，使得即使在没有有效共轭的情况下，也能实现类似的加速效果。

4. **实施与性能比较**: 通过在gnark库中的实现，文章展示了该技术在P-256和其他曲线上的性能提升，特别是在ECDSA验证过程中的应用，相比于传统方法，性能显著提高。

5. **案例研究与应用**: 最后，文章引用了实际应用案例，如基于zk-SNARKs的WebAuthn和P-256签名验证，展示了该技术的实际效益，特别是在减少证明大小和验证时间方面的优势。

通过上述技巧和实施，文章提供了一种在缺乏有效共轭的椭圆曲线上进行高效标量乘法的新途径，这对于依赖于P-256或其他类似曲线的系统具有重要意义，特别是在需要在SNARK电路中执行ECDSA验证的场景中。 <div>
<pre><code class="lang-auto"> _____     _           ____ _ __     __
|  ___|_ _| | _____   / ___| |\ \   / /
| |_ / _` | |/ / _ \ | |  _| | \ \ / /  
|  _| (_| |   &lt;  __/ | |_| | |__\ V /   
|_|  \__,_|_|\_\___|  \____|_____\_/   
</code></pre>
<h1><a class="anchor" href="https://ethresear.ch#p-49892-you-dont-need-an-efficient-endomorphism-to-implement-glv-like-scalar-multiplication-in-snark-circuits-1" name="p-49892-you-dont-need-an-efficient-endomorphism-to-implement-glv-like-scalar-multiplication-in-snark-circuits-1"></a>You don’t need an efficient endomorphism to implement GLV-like scalar multiplication in SNARK circuits</h1>
<ul>
<li><a href="https://ethresear.ch#Introduction">Introduction</a>
<ul>
<li><a href="https://ethresear.ch#Other-applications">Other applications</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#Background">Background</a></li>
<li><a href="https://ethresear.ch#The-fake-GLV-trick6">The fake GLV trick</a>
<ul>
<li><a href="https://ethresear.ch#Implementation7">Implementation</a>
<ul>
<li><a href="https://ethresear.ch#Benchmark">Benchmark</a></li>
<li><a href="https://ethresear.ch#Comparison">Comparison</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49892-introduction-2" name="p-49892-introduction-2"></a>Introduction</h2>
<p>P-256, also known as secp256r1 and prime256v1, is a 256-bit prime field Weierstrass curve standardized by the NIST. It is widely adopted in internet systems, which explains its myriad use cases in platforms such as TLS, DNSSEC, Apple’s Secure Enclave, Passkeys, Android Keystore, and Yubikey. The key operation in elliptic curves based cryptography is the scalar multiplication. When the curve is equipped with an efficient endomorphism it is possible to speed up this operation through the well-known <a href="https://www.iacr.org/archive/crypto2001/21390189.pdf" rel="noopener nofollow ugc">GLV</a> algorithm. P-256 does unfortunately not have an efficient endomorphism (see <a href="https://neuromancer.sk/std/nist/P-256#" rel="noopener nofollow ugc">parameters</a>) to enjoy this speedup.</p>
<p>Verifying ECDSA signatures on Ethereum through precompiled contracts, i.e. smart contracts built into the Ethereum protocol (there are only 9) is only possible with the <em>secp256k1</em> curve and not the P-256.<br />
Verifying ECDSA signatures on P-256 requires computing scalar multiplications in Solidity and is especially useful for smart-contract wallets, enabling hardware-based signing keys and safer, easier self-custody. Different solutions can bring P-256 signatures on-chain. There are primarily three interesting approaches: (zk)-SNARK based verifiers, smart contract verifiers (e.g. <a href="https://eprint.iacr.org/2023/939.pdf" rel="noopener nofollow ugc">[Dubois23]</a>, <a>Ledger/FCL</a> (deprecated), <a href="https://github.com/get-smooth/crypto-lib" rel="noopener nofollow ugc">smoo.th/SCL</a> and <a href="https://daimo.com/blog/p256verifier" rel="noopener nofollow ugc">daimo/p256verifier</a>), and native protocol precompiles (<a href="https://github.com/ethereum/RIPs/blob/196f28d2164f30333b503481e7da954d4bf32ea3/RIPS/rip-7212.md" rel="noopener nofollow ugc">EIP/RIP 7212</a>).</p>
<p>Using SNARK (succinctness) properties, provides a great way to reduce gas cost for computation on Ethereum (e.g. ~232k gas for <a href="https://eprint.iacr.org/2016/260.pdf" rel="noopener nofollow ugc">Groth16</a>, ~285k gas for <a href="https://eprint.iacr.org/2019/953.pdf" rel="noopener nofollow ugc">PLONK</a> and ~185k gas for <a href="https://eprint.iacr.org/2021/1167" rel="noopener nofollow ugc">FFLONK</a>). This is very competitive with (and sometimes better that) the currently gas-optimal smart contract verifier. Moreover one can batch many ECDSA verifications in a single proof, amortizing thus the gas cost. However verifying P-256 signatures in a SNARK circuit can be very expensive i.e. long proving time. This is because the field where the points on the P-256 curve lie is different than the field where the SNARK computation is usually expressed. To be able to verify the proof onchain through the procompile the SNARK field needs to be the <a href="https://hackmd.io/@jpw/bn254" rel="noopener nofollow ugc">BN254</a> scalar field. Different teams tried to implement the ECDSA verification on P-256 in a BN254 SNARK circuit efficiently. Among these: <a href="https://github.com/zkwebauthn/webauthn-halo2" rel="noopener nofollow ugc">zkwebauthn/webauthn-halo2</a>, <a href="https://github.com/zkwebauthn/webauthn-circom" rel="noopener nofollow ugc">https://github.com/zkwebauthn/webauthn-circom</a> and <a href="https://github.com/privacy-scaling-explorations/circom-ecdsa-p256" rel="noopener nofollow ugc">PSE/circom-ecdsa-p256</a>.</p>
<p><em>If P-256 had an efficient endomorphism we could have optimized the proving time a great deal!</em></p>
<p>In this note we show a way to implement a GLV-like scalar multiplications in-circuit without having an efficient endomorphism.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49892-other-applications-3" name="p-49892-other-applications-3"></a>Other applications</h3>
<ul>
<li>This technique can be applied to any elliptic curve without an efficient endomorphism (e.g. <a href="https://en.wikipedia.org/wiki/Curve25519" rel="noopener nofollow ugc">Curve25519</a>, <a href="https://en.wikipedia.org/wiki/P-384" rel="noopener nofollow ugc">P-384</a>, MNT-753 (<a href="https://coinlist.co/build/coda/pages/MNT4753" rel="noopener nofollow ugc">k=4</a>, <a href="https://coinlist.co/build/coda/pages/MNT6753" rel="noopener nofollow ugc">k=6</a>), <a href="https://docs.starknet.io/architecture-and-concepts/cryptography/stark-curve/" rel="noopener nofollow ugc">STARK curve</a>, <a href="https://eprint.iacr.org/2024/869" rel="noopener nofollow ugc"><span class="math">\mathcal{B}</span> of “cycle5”</a>, …). See this <a href="https://neuromancer.sk/std/" rel="noopener nofollow ugc">database</a> for other curves.</li>
<li>This would question the choice of <a href="https://eprint.iacr.org/2021/1152" rel="noopener nofollow ugc">Bandersnatch</a> (<em>an embedded endomorphism-equipped curve over BLS12-381</em>) over <a href="https://github.com/zkcrypto/jubjub" rel="noopener nofollow ugc">Jubjub</a> (<em>an embedded curve over BLS12-381 without endomorphism</em>) for <a href="https://verkle.info/" rel="noopener nofollow ugc">Ethereum Verkle trees</a>.</li>
<li>This can speedup ECDSA verification in <a href="https://docs.cairo-lang.org/hello_starknet/signature_verification.html" rel="noopener nofollow ugc">Starknet</a> and <a href="https://www.cairo-lang.org/" rel="noopener nofollow ugc">Cairo</a> (through the <a href="https://docs.starknet.io/architecture-and-concepts/cryptography/stark-curve/" rel="noopener nofollow ugc">STARK curve</a>).</li>
<li>This can speedup natively the folding step (à la Nova) of Ed25519 signatures through the 2-cycles proposed <a href="https://moderncrypto.org/mail-archive/curves/2024/001050.html" rel="noopener nofollow ugc">here</a> by Aurore Guillevic.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49892-background-4" name="p-49892-background-4"></a>Background</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49892-standard-scalar-multiplication-5" name="p-49892-standard-scalar-multiplication-5"></a>Standard scalar multiplication</h3>
<p>Let <span class="math">E</span> be an elliptic curve defined over the prime field <span class="math">\mathbb{F}_p</span> and let <span class="math">r</span> be a prime divisor of the curve order <span class="math">\#E(\mathbb{F}_p)</span> (i.e. the number of points).<br />
Let <span class="math">s \in \mathbb{F}_r</span> and <span class="math">P(x,y) \in E(\mathbb{F}_p)</span>, we are interested in proving scalar multiplication <span class="math">s\cdot P</span> over the <span class="math">r</span>-torsion subgroup of <span class="math">E</span>, denoted <span class="math">E[r]</span> (i.e. the subset of points of order <span class="math">r</span>).</p>
<p>The simplest algorithm is the standard left-to-right <em>double-and-add</em>:</p>
<pre><code class="lang-auto">INPUT: s = (s_{t−1},..., s_1, s_0), P ∈ E(Fp).
OUTPUT: sP.
1. Q ← ∞.
2. For i from t−1 downto 0 do
    2.1 Q ← 2Q.
    2.2 If s_i = 1 then Q ← Q + P.
3. Return(Q).
</code></pre>
<p>If/else branching is not possible in SNARK circuits so this is replaced by constant window table lookups inside the circuit. This can be achieved using polynomials which vanish at the constants that aren’t being selected, i.e. a 1-bit table lookup <code>Q ← s_i * Q + (1 - s_i) * (Q+P)</code>. Hence this double-and-add algorithm requires <span class="math">t</span> doublings, <span class="math">t</span> additions and <span class="math">t</span> 1-bit table lookup.<br />
This can be extended to <em>windowed</em> double-and-add, i.e. scanning more than a bit per iteration using larger window tables, but the multiplicative depth of the evaluation increases exponentially. We use affine coordinates for doubling/adding points because inverses cost as much as multiplications, i.e. instead of checking that <span class="math">1/x</span> is <span class="math">y</span> we provide <span class="math">y</span> out-circuit and check in-circuit that <span class="math">x\cdot y = 1</span>. However since we start with <span class="math">Q ← ∞</span> it is infeasible to avoid conditional branching since affine formulas are incomplete. Instead, we scan the bits right-to-left and assume that the first bit <code>s_0</code> is 1 (so that we start at <code>Q ← P</code>), we double the input point <code>P</code> instead of the accumulator <code>Q</code> in this algorithm and finally conditionally subtract (using the 1-bit lookup) <code>P</code> if <code>s_0</code> was 0.</p>
<pre><code class="lang-auto">INPUT: s = (s_{t−1},..., s_1, s_0), P ∈ E(Fp).
OUTPUT: sP.
1. Q ← P.
2. For i from 1 to t−1 do
    2.1 If s_i = 1 then Q ← Q + P.
    2.2 P ← 2P.
3. if s_0 = 0 then Q ← Q - P
4. Return(Q).
</code></pre>
<h3><a class="anchor" href="https://ethresear.ch#p-49892-glv-scalar-multiplication-6" name="p-49892-glv-scalar-multiplication-6"></a>GLV scalar multiplication</h3>
<p>However it is well known that if the curve is equipped with an efficient endomorphism then there exists a faster algorithm known as <a href="https://www.iacr.org/archive/crypto2001/21390189.pdf" rel="noopener nofollow ugc">[GLV]</a>.</p>
<p><strong>Example 1 :</strong> suppose that <span class="math">E</span> has Complex Multiplication (CM) with discrimant <span class="math">-D=-3</span>, i.e. <span class="math">E</span> is of the form <span class="math">y^2=x^3+b</span>, with <span class="math">b \in \mathbb{F}_p</span>. This is the case of <code>BN254</code>, <code>BLS12-381</code> and <code>secp256k1</code> elliptic curves used in Ethereum. There is an efficient endomorphism <span class="math">\phi: E \rightarrow E</span> defined by <span class="math">(x,y)\mapsto (\omega x,y)</span> (and <span class="math">\mathcal{O} \mapsto \mathcal{O}</span>) that acts on <span class="math">P \in E[r]</span> as <span class="math">\phi(P)=\lambda \cdot P</span>. Both <span class="math">\omega</span> and <span class="math">\lambda</span> are cube roots of unity in <span class="math">\mathbb{F}_p</span> and <span class="math">\mathbb{F}_r</span> respectively, i.e. <span class="math">\omega^2+\omega+1 \equiv 0 \pmod p</span> and <span class="math">\lambda^2+\lambda+1 \equiv 0 \pmod r</span>.</p>
<p><strong>Example 2 :</strong> suppose that <span class="math">E</span> has Complex Multiplication (CM) with discrimant <span class="math">-D=-8</span>, meaning that the endomorphism ring is <span class="math">\mathbf{Z}[\sqrt{−2}]</span>. This is the case of the <code>Bandersnatch</code> elliptic curves specified in Ethereum Verkle trie. There is an efficient endomorphism <span class="math">\phi: E \rightarrow E</span> whose kernel is generated by a 2-torsion point. The map can be found by looking at 2-isogeneous curves and applying Vélu’s formulas. For Bandersnatch it is defined by <span class="math">(x,y)\mapsto (u^2\cdot \frac{x^2+wx+t}{x+w},u^3\cdot y\cdot \frac{x^2+2wx+v}{(x+w)^2})</span> for some constants <span class="math">u,v,w,t</span> (and <span class="math">\mathcal{O} \mapsto \mathcal{O}</span>) that acts on <span class="math">P \in E[r]</span> as <span class="math">\phi(P)=\lambda \cdot P</span> where <span class="math">\lambda^2+2 \equiv 0 \pmod r</span>.</p>
<p>The GLV algorithm starts by decomposing <span class="math">s</span> as <span class="math">s = s_0 + \lambda s_1</span> and then replacing the scalar multiplication <span class="math">s \cdot P</span> by <span class="math">s_0 \cdot P + s_1 \cdot \phi(P)</span>. Because <span class="math">s_0</span> and <span class="math">s_1</span> are guaranteed to be <span class="math">\leq \sqrt{r}</span> (see Sec.4 of <a href="https://www.iacr.org/archive/crypto2001/21390189.pdf" rel="noopener nofollow ugc">[GLV]</a> and Sec.4 of <a href="https://eprint.iacr.org/2015/565.pdf" rel="noopener nofollow ugc">[FourQ]</a> for an optimization trick), we can halve the size of the for loop in the double-and-add algorithm. We can then scan simultaenously the bits of <span class="math">s_0</span> and <span class="math">s_1</span> and apply the <a href="https://crypto.stackexchange.com/questions/99975/strauss-shamir-trick-on-ec-multiplication-by-scalar" rel="noopener nofollow ugc">Strauss-Shamir trick</a>. This results in a significant speed up but only when an endomorphism is available. For example the left-to-right double-and-add would become:</p>
<pre><code class="lang-auto">INPUT: s and P ∈ E(Fp).
OUTPUT: sP.
1. Find s1 and s2 s.t. s = s1 + 𝜆 * s2 mod r 
    1.1 let s1 = (s1_{t−1},..., s1_1, s1_0) 
    1.2 and s2 = = (s2_{t−1},..., s2_1, s2_0)
2. P1 ← P, P2 ← 𝜙(P) and Q ← ∞.
3. For i from t−1 downto 0 do
    3.1 Q ← 2Q.
    3.2 If s1_i = 0 and s2_i = 0 then Q ← Q.
    3.3 If s1_i = 1 and s2_i = 0 then Q ← Q + P1.
    3.4 If s1_i = 0 and s2_i = 1 then Q ← Q + P2.
    3.5 If s1_i = 1 and s2_i = 1 then Q ← Q + P1 + P2.
4. Return(Q).
</code></pre>
<p>Using the efficient endomorphism in-circuit is also possible (see <a href="https://eprint.iacr.org/2019/1021.pdf" rel="noopener nofollow ugc">[Halo, Sec. 6.2 and Appendix C]</a> or <a href="https://github.com/Consensys/gnark/blob/ea53f373f45d2f9ad9cc1639c34359a35f771191/std/algebra/emulated/sw_emulated/point.go#L530" rel="noopener nofollow ugc">[gnark implementation]</a> for short Weierstrass curves and <a href="https://github.com/zhenfeizhang/bandersnatch-glv" rel="noopener nofollow ugc">[arkworks]</a> and <a href="https://github.com/Consensys/gnark/blob/dc04a1d3b221dbe7571b5a8394b55d02c2872700/std/algebra/native/twistededwards/scalarmul_glv.go" rel="noopener nofollow ugc">[gnark]</a> implementations for twisted Edwards). But one should be careful about some extra checks of the decomposition <span class="math">s = s_0 + \lambda s_1 \mod r</span> (not the SNARK modulus). The integers <span class="math">s_0, s_1</span> can possibly be negative in which case they will be reduced in-circuit modulo the SNARK field and not <span class="math">r</span>.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49892-the-fake-glv-trick-7" name="p-49892-the-fake-glv-trick-7"></a>The fake GLV trick</h2>
<p>Remember that we are proving that <span class="math">s\cdot P = Q</span> and not computing it. We can “hint” the result <span class="math">Q</span> and check in-circuit that <span class="math">s\cdot P - Q = \mathcal{O}</span>. Now, if we can find <span class="math">u,v \leq \sqrt{r}</span> such that <span class="math">v\cdot s = u \pmod r</span> then we can check instead that</p>
<p><span class="math">(v\cdot s)\cdot P - v\cdot Q = \mathcal{O}</span></p>
<p>which is equivalent to</p>
<p><span class="math"> u\cdot P - v\cdot Q = \mathcal{O}</span></p>
<p>The thing now is that <span class="math">u</span> and <span class="math">v</span> are “small” and we can, similarly to the GLV algorithm, halve the size of the double-and-add loop and apply the Strauss-Shamir trick.</p>
<p><strong>Solution</strong>: running the half-GCD algorithm (i.e. running GCD half-way) is sufficient to find <span class="math">u</span> and <span class="math">v</span>. We can apply the exact same trick for finding the lattice basis as in the GLV paper (Sec. 4). For completeness we recall the algorithm hereafter.<br />
We apply the extended Euclidean algorithm to find the greatest common divisor of <span class="math">r</span> and <span class="math">s</span> (This gcd is 1 since <span class="math">r</span> is prime.) The algorithm produces a sequence of equations</p>
<p><span class="math">w_i \cdot r + v_i \cdot s = u_i</span></p>
<p>for <span class="math">i = 0, 1, 2, \dots</span>  where <span class="math">w_0 = 1, v_0 = 0, u_0 = r, w_1 = 0, v_1 = 1, u_1 = s</span>, and <span class="math">u_i \geq 0</span> for all <span class="math">i</span>. We stop at the index <span class="math">m</span> for which <span class="math">u_m \geq \sqrt{r}</span> and take <span class="math">u = u_{m+1}</span> and <span class="math">v = -v_{m+1}</span>.<br />
<em>Note:</em> By construction <span class="math">u</span> is guaranteed to be a positive integer but <span class="math">v</span> can be negative, in which case it would be reduced in-circuit modulo the SNARK modulus and not <span class="math">r</span>. To circumvent this we return in the hint <span class="math">u</span>, <span class="math">v</span> and a <span class="math">\texttt{b}=1</span> if <span class="math">v</span> is negative and <span class="math">\texttt{b}=0</span> otherwise. In-circuit we negate <span class="math">Q</span> instead when <span class="math">\texttt{b}=1</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49892-implementation-8" name="p-49892-implementation-8"></a>Implementation</h3>
<p>A generic implementation in the gnark library is available at <a href="https://github.com/Consensys/gnark/feat/fake-GLV" rel="noopener nofollow ugc">gnark.io (feat/fake-GLV branch)</a>. For Short Weierstrass (e.g. P256) look at the <code>scalarMulFakeGLV</code> <a href="https://github.com/Consensys/gnark/blob/62c89cb10cff1413e9d68cce054c7e711d04c726/std/algebra/emulated/sw_emulated/point.go#L1263" rel="noopener nofollow ugc">method</a> in the emulated package and for twisted Edwards (e.g. Bandersnatch/Jubjub) look at the <code>scalarMulFakeGLV</code> <a href="https://github.com/Consensys/gnark/blob/62c89cb10cff1413e9d68cce054c7e711d04c726/std/algebra/native/twistededwards/point.go#L261" rel="noopener nofollow ugc">method</a> in the native package.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49892-benchmark-9" name="p-49892-benchmark-9"></a>Benchmark</h4>
<p>The best algorithm to implement scalar multiplication in a non-native circuit (i.e. circuit field ≠ curve field) when an efficient endomorphism is <em>not</em> available is an adaptation of <a href="https://www.iacr.org/archive/ches2007/47270135/47270135.pdf" rel="noopener nofollow ugc">[Joye07]</a> (implemented in <a href="https://github.com/Consensys/gnark/blob/fdb2b0de422b1c4fc5c6d08e81e788095ac818a6/std/algebra/emulated/sw_emulated/point.go#L748" rel="noopener nofollow ugc">gnark here</a>).<br />
Next we compare this scalar multiplication with our fake GLV in a PLONKish vanilla (i.e. no custom gates) circuit (scs) over the BN254 curve (Ethereum compatible). We also give benchmarks in R1CS.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: left;">P-256</th>
<th style="text-align: center;">Old (Joye07)</th>
<th style="text-align: right;">New (fake GLV)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="math">[s]P</span></td>
<td style="text-align: center;">738,031 scs <br /> 186,466 r1cs</td>
<td style="text-align: right;">385,412 scs <br /> 100,914 r1cs</td>
</tr>
<tr>
<td style="text-align: left;">ECDSA verification</td>
<td style="text-align: center;">1,135,876 scs <br /> 293,814 r1cs</td>
<td style="text-align: right;">742,541 scs <br /> 195,266 r1cs</td>
</tr>
</tbody>
</table>
</div><blockquote>
<p>Note here that the old ECDSA verification uses Strauss-Shamir trick for computing <span class="math">[s]P+[t]Q</span> while the new version is merely two fake GLV multiplications and an addition.</p>
</blockquote>
<h4><a class="anchor" href="https://ethresear.ch#p-49892-comparison-10" name="p-49892-comparison-10"></a>Comparison</h4>
<p><a href="https://www.p256wallet.org/" rel="noopener nofollow ugc">p256wallet.org</a> is an ERC-4337 smart contract wallet that leverages zk-SNARKs for WebAuthn and P-256 signature verification. It uses <a href="https://github.com/privacy-scaling-explorations/circom-ecdsa-p256" rel="noopener nofollow ugc">PSE/circom-ecdsa-p256</a> to generate the webAuthn proof, and underneath <a href="https://github.com/privacy-scaling-explorations/circom-ecdsa-p256" rel="noopener nofollow ugc">PSE/circom-ecdsa-p256</a> to generate the ECDSA proof on P-256 curve. The github README reports <code>1,972,905 R1CS</code>. Compiling our circuit in R1CS results in <strong><code>195,266 R1CS</code></strong>. This is more than a <strong>10x</strong> reduction, which is not only due to the fake GLV algorithm but also to optimized non-native field arithmetic in gnark.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49892-other-curves-11" name="p-49892-other-curves-11"></a>Other curves</h4>
<p>Similar results are noticed for other curves in short Weirstrass, e.g. P-384 and STARK curve:</p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: left;">P-384</th>
<th style="text-align: center;">Old (Joye07)</th>
<th style="text-align: right;">New (fake GLV)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="math">[s]P</span></td>
<td style="text-align: center;">1,438,071 scs</td>
<td style="text-align: right;">782,674 scs</td>
</tr>
<tr>
<td style="text-align: left;">ECDSA verification</td>
<td style="text-align: center;">2,174,027 scs</td>
<td style="text-align: right;">1,419,929 scs</td>
</tr>
</tbody>
</table>
</div><div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: left;">STARK curve</th>
<th style="text-align: center;">Old (Joye07)</th>
<th style="text-align: right;">New (fake GLV)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="math">[s]P</span></td>
<td style="text-align: center;">727,033 scs</td>
<td style="text-align: right;">380,210 scs</td>
</tr>
<tr>
<td style="text-align: left;">ECDSA verification</td>
<td style="text-align: center;">1,137,459 scs</td>
<td style="text-align: right;">732,131 scs</td>
</tr>
</tbody>
</table>
</div><p>and also in twisted Edwards e.g. Jubjub vs. Bandersnatch:</p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: left;">Jubjub</th>
<th style="text-align: center;">Old (2-bit double-and-add)</th>
<th style="text-align: right;">New (fake GLV)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="math">[s]P</span></td>
<td style="text-align: center;">5,863 scs <br /> 3,314 r1cs</td>
<td style="text-align: right;">4,549  scs <br /> 2,401 r1cs</td>
</tr>
</tbody>
</table>
</div><div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: left;">Bandersnatch</th>
<th style="text-align: center;">Old (GLV)</th>
<th style="text-align: right;">New (fake GLV)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="math">[s]P</span></td>
<td style="text-align: center;">4,781 scs <br />  2,455 r1cs</td>
<td style="text-align: right;">4,712 scs <br /> 2,420 r1cs</td>
</tr>
</tbody>
</table>
</div><h2><a class="anchor" href="https://ethresear.ch#p-49892-acknowledgement-12" name="p-49892-acknowledgement-12"></a>Acknowledgement</h2>
<p>I would like to thank Arnau Cube, Aard Vark, Holden Mui, Olivier Bégassat and Thomas Piellard for fruitful discussions.</p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/fake-glv-you-dont-need-an-efficient-endomorphism-to-implement-glv-like-scalar-multiplication-in-snark-circuits/20394">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 19:48:29 +0000</pubDate>
</item>
<item>
<title>Embedded fee markets and ERC-4337 (part 2)</title>
<link>https://ethresear.ch/t/embedded-fee-markets-and-erc-4337-part-2/20384</link>
<guid>https://ethresear.ch/t/embedded-fee-markets-and-erc-4337-part-2/20384</guid>
<content:encoded><![CDATA[
<div> 关键词：ERC-4337、用户操作（UserOps）、捆绑者（Bundlers）、交易费用、链下成本

总结：

本文主要探讨了以太坊生态中ERC-4337模型及其在处理用户操作（UserOps）时的挑战与改进方法。ERC-4337模型概述了捆绑者（Bundlers）的费用市场结构和链上发布成本与链下聚合成本的关联。文章引入了“捆绑者游戏”的概念，强调了捆绑者与用户之间的信息不对称问题，这导致了用户处于明显的不利地位。

文章分析了当前ERC-4337状态，指出P2P mempool尚未在主网上线，主要在Sepolia测试网上进行测试。Kofi开发的工具提供了有关当前状态的统计数据，显示大多数捆绑者倾向于打包多个用户操作，而那些同时提供赞助服务（Paymaster）的大型捆绑者占主导地位。文章讨论了用户为何需要支付费用给捆绑者，并推测随着采用率的提高，未来用户可能需要自行承担费用。

文章还探讨了ERC-4337与其他变体（如结合捆绑者与构建者角色的方案）的比较，强调了保持这两个角色分离的优势，包括促进竞争和增强抗审查性。通过保持分离，可以实现更高效的市场动态，其中竞争促使捆绑者降低费用以吸引用户，从而为用户提供更具竞争力的价格和服务。

最后，文章讨论了Layer2解决方案中的账户抽象（Account Abstraction）和签名聚合技术如何帮助优化交易费用和数据可用性成本。通过使用签名聚合，可以在不牺牲安全性的情况下显著减少交易大小和链上成本。此外，文章提出了一些机制，如使用预言机提供内存池信息或由Layer2自身作为捆绑者，以帮助用户更好地估算费用并确保公平性。

综上所述，文章深入分析了ERC-4337及其变体在处理用户操作时的复杂性和挑战，并提出了几种改进策略，旨在提升用户体验和效率，同时维护系统的安全性和公平性。 <div>
<p>by: Davide Rezzoli (<a class="mention" href="https://ethresear.ch/u/daviderezzoli">@DavideRezzoli</a>) and Barnabé Monnot (<a class="mention" href="https://ethresear.ch/u/barnabe">@barnabe</a>)</p>
<p>Many thanks to Yoav Weiss (<a class="mention" href="https://ethresear.ch/u/yoavw">@yoavw</a>) for introducing us to the problem, Dror Tirosh (<a class="mention" href="https://ethresear.ch/u/drortirosh">@drortirosh</a>) for helpful comments on the draft, and the 4337 team for their support. Reviews ≠ endorsements; all errors are the authors’ own.</p>
<p>This work was done for <a href="https://efdn.notion.site/ROP-7-Economic-models-of-signature-aggregation-in-account-abstraction-ec5390efab864ed49a8535e8bdfff182" rel="noopener nofollow ugc">ROP-7</a>.</p>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#p-49870-introduction-1" name="p-49870-introduction-1"></a>Introduction</h3>
<p>In our previous <a href="https://ethresear.ch/t/embedded-fee-markets-and-erc-4337-part-1/19542">post</a>, we introduced the ERC-4337 model. This model outlines the fee market structure for bundlers and details the cost function related to the on-chain publishing cost and the off-chain (aggregation costs) of a bundle.</p>
<p>We also introduced the concept of the “<em>Bundler Game</em>”. This game will be the primary focus of the second part. Given a set of transactions, a bundler can choose which transactions to include in their bundle. This creates an asymmetry of information between the bundlers and the user, as the user doesn’t know how many transactions will be included in the bundle. This leads to a zero-sum game where the user is at a clear disadvantage.</p>
<p>This research aims to explore methods to improve the UX by ensuring that users do not need to overpay for inclusion in the next bundle. Instead, users should be able to pay a fee based on the actual market demand for inclusion.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49870-current-state-of-erc-4337-2" name="p-49870-current-state-of-erc-4337-2"></a>Current state of ERC-4337</h2>
<p>In today’s market, the P2P mempool is not live on mainnet and it’s being tested on the Sepolia testnet. Companies building on ERC-4337 are currently operating in a private mode, the users connect via an RPC to a private bundler which will than work with a buidler to publish onchain your useroperation. <a href="https://www.bundlebear.com/overview/all" rel="noopener nofollow ugc">Bundle Bear app</a>, developed by Kofi, provides some intriguing statistics on the current state of ERC-4337.</p>
<p>In the <a href="https://www.bundlebear.com/bundlers/all" rel="noopener nofollow ugc">Weekly % Multi-UserOp Bundles</a> metric, we observe the percentage of bundlers creating bundles that include multiple userops. From the beginning of 2024 to June 2024, this percentage has not exceeded 6.6%. This data becomes even more interesting when considering that many bundlers run their own paymasters, entities that sponsor transactions on behalf of users. Notably, the two largest bundlers who also operate as a paymaster, in terms of user operations published, <a href="https://www.bundlebear.com/paymasters/all" rel="noopener nofollow ugc">sponsored 97%</a> of the user operations using their services. The paymaster pays for some parts of the useroperation and the rest is paid by the dapps or other <a href="https://www.coinbase.com/en-de/developer-platform/solutions/account-abstraction-kit" rel="noopener nofollow ugc">entity</a>.</p>
<p>The question that arises is why paymasters, dApps, etc., are paying for the user operations. Will the user pay them back in the future? We can’t be sure what will happen, but my personal guess is that currently, dApps are covering the fees to increase usage and adoption of their apps. Once adoption is high, users will likely have to pay for the transactions themselves. It’s worth mentioning that for the user to pay for a user operation with the current model is not the best option, since a basic ERC-4337 operation costs ~42,000 gas, while a normal transaction costs ~21,000 gas.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49870-variations-on-erc-4337-3" name="p-49870-variations-on-erc-4337-3"></a>Variations on ERC-4337</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-overview-of-erc-4337-4" name="p-49870-overview-of-erc-4337-4"></a>Overview of ERC-4337</h3>
<p>The mempool is still in a testing phase on Sepolia and is not live on the mainnet. Without the mempool, users have limited options for using account abstraction. Users interact with an RPC, which may be offered by a bundler that bundles UserOps, or with an RPC service that doesn’t bundle, similar to services like Alchemy or Infura, which receive and propagate transactions to other bundlers.</p>
<p><img alt="High level of a transaction in ERC-4337 without the mempool" height="111" src="https://ethresear.ch/uploads/default/original/3X/5/c/5cfa750fc581f313b031ca060a05d21cc3379214.jpeg" width="497" /></p>
<p>Once the mempool is live, the transaction flow will resemble the diagram below, which is similar to the current transaction flow. A mempool enhances censorship resistance for users because, unlike the RPC model, it reduces the chances of a transaction being excluded. However, even with a mempool, there is still a risk that an RPC provider might not forward the transaction, but the mempool model is particularly beneficial for users who prefer to run their own nodes, as it mitigates this risk.</p>
<p><img alt="High level of a normal transaction using an EOA" height="136" src="https://ethresear.ch/uploads/default/original/3X/7/7/779c484a5068fcd2a4df86e24c5ede85cb6af781.png" width="631" /></p>
<p><img alt="High level of an userop type of transaction" height="126" src="https://ethresear.ch/uploads/default/original/3X/f/9/f9ab02c182e4af4e72324eddfc31b93c5555f115.jpeg" width="621" /></p>
<p>While bundlers have the potential to act as builders, we prefer to keep the roles separate due to the competitive landscape. Bundlers would face significant competition from existing, sophisticated builders, making building less attractive and potentially less profitable. As a result, bundlers are more incentivized to collaborate with established builders rather than building independently and risking losses.</p>
<p>Combining the roles of bundler and builder into a single entity implies significant changes to the current system. Bundlers would need to compete with existing <a href="https://etherscan.io/dashboards/block-producers" rel="noopener nofollow ugc">sophisticated builders</a>, or alternatively, current builders will need to horizontally integrate and assume the bundler role as well. The latter scenario, while more plausible, raises concerns about market concentration and the potential negative impact on censorship resistance.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-bundlers-and-builders-as-two-different-entities-5" name="p-49870-bundlers-and-builders-as-two-different-entities-5"></a>Bundlers and builders as two different entities</h3>
<p>With the users connecting directly to an RPC, everything runs in a more private environment, which doesn’t help with market competition. In the near future the mempool will be on the mainnet increasing competition.</p>
<p>Using a mempool, in which userops are public to different bundlers increases competition, in the case of non native account abstraction having a separation between bundler and builder is needed, in the case of native account abstraction the separation might not be needed since the builder can interpret the userops as normal transactions.</p>
<p>For our model we believe that having a separation between the bundler and the builder also offers some advantages, especially in terms of competition and censorship resistance. Imagine a scenario where all the bundlers are offering a cost <span class="math">\textbf{v}</span> for getting included in their bundle. There will be a bundler who wants to attract more users to achieve higher profits, so they will offer a cost <span class="math">\textbf{v’}</span>  where <span class="math">\textbf{v’} &lt; \textbf{v}</span>  with enough competition among bundlers, <span class="math">\textbf{v'}</span> will get close to <span class="math">\omega</span>, the aggregation cost for the bundle. In this case, the bundlers who can search more efficiently and have better hardware to include more transactions in a bundle will earn higher fees and in return makes the useroperation for the user cheaper.</p>
<p>This could lead to the following outcome: In a <strong>competitive environment</strong>, bundlers will lower their prices to be selected by users, who will, in turn, seek the lowest price for the inclusion of their user operation in a bundle. This competition will create a system where the bundler who offers the best price will be selected more often than the bundler who is only trying to maximize their profit by creating smaller bundles. Separating the roles of the bundler and builder can also enhance censorship resistance. A bundler can create a bundle of aggregated user operations and send it to different builders. If the bundle includes operations that could be censored, a non-censoring builder can accept it and proceed with construction. However, it’s worth noting that from a user’s perspective, this setup could increase costs, as the introduction of a bundler adds an additional party, leading to higher expenses.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-rip-7560-6" name="p-49870-rip-7560-6"></a>RIP-7560</h3>
<p>Native account abstraction isn’t a novel concept; it’s been under research for years. While ERC-4337 is gaining traction, its implementation outside the protocol offers distinct advantages alongside trade-offs. Notably, existing EOAs can’t seamlessly transition to SCWs, and various types of censorship-resistant lists are harder to utilize. As previously mentioned, the gas overhead of a userOp cost escalates significantly compared to a normal transaction. <a href="https://github.com/ethereum/RIPs/blob/196f28d2164f30333b503481e7da954d4bf32ea3/RIPS/rip-7560.md" rel="noopener nofollow ugc">RIP-7560</a> won’t inherently resolve the ongoing issue concerning off-chain costs, but it substantially reduce transaction expenses. From the initial ~42000 gas, it’s possible to reduce the cost by <a href="https://youtu.be/sZ1UO4VN1GI?si=x7Tu22Oqxr7x-KAb&amp;t=554" rel="noopener nofollow ugc">~20000 gas</a>.</p>
<p><img alt="High level of a type4 transaction with RIP-7560" height="136" src="https://ethresear.ch/uploads/default/original/3X/f/a/fadf929aca9a2378a70f5456501dedf5da00358b.jpeg" width="491" /></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-layer2s-account-abstraction-7" name="p-49870-layer2s-account-abstraction-7"></a>Layer2s Account Abstraction</h3>
<p>Account abstraction can be utilized in Layer 2 (L2) solutions. Some L2s already implement it natively, while others follow the L1 approach and are waiting for a new proposal similar to RIP-7560. In L2, the L1 is used for data availability to inherit security, while most of the computation occurs off-chain on the L2, providing cheaper transactions and scalability.</p>
<p><img alt="High level of Account abstraction in Layer 2" height="136" src="https://ethresear.ch/uploads/default/original/3X/b/2/b2a8d1ebfceef37ab62f0db834e7ee6135441741.jpeg" width="611" /></p>
<p>In scenarios where computation on L2 is significantly cheaper than the cost of calldata for data availability (DA) on the mainchain, the use of signature aggregation proves highly beneficial. For instance, pairing for BLS on the mainnet is facilitated by the <a href="https://www.evm.codes/precompiled" rel="noopener nofollow ugc"><em>0x08</em></a> precompile from the EVM, which costs approximately ~45000k gas. Consequently, using BLS on L1 is more expensive than traditional transactions.</p>
<p>Compression techniques on L2s are already being used, such as 0-byte compression, which reduces the cost from ~188 bytes to ~154 bytes for an ERC20 transfer. With signature aggregation, the compression efficiency can be further enhanced by using a single signature, reducing the size to ~128 bytes.</p>
<p>In Layer 2s, signature aggregation is a crucial innovation that enhances both transaction efficiency and cost-effectiveness. By combining multiple signatures into a single one, the overall data payload is significantly reduced, which lowers the costs associated with data availability on Layer 1. This advancement not only improves scalability but also reduces transaction costs for users, making the system more economical and efficient.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49870-signature-aggregation-economics-in-layer2s-8" name="p-49870-signature-aggregation-economics-in-layer2s-8"></a>Signature Aggregation economics in Layer2s</h2>
<p>When using an L2 service, the user incurs several costs, including a fee for the L2 operator, a cost based on network congestion, and the cost of data availability on L1.</p>
<p>From a previous research on ”<a href="https://barnabe.substack.com/p/understanding-rollup-economics-from#footnote-3-48535841" rel="noopener nofollow ugc"><strong>Understanding rollup economics from first principles</strong></a>”, we can outline the costs a user faces when using L2 services as follows:</p>
<p>When a user interatcs with a layer 2 he has some costs that we can define as follow:</p>
<ul>
<li><strong>User fee</strong> = L1 data publication fee + L2 operator fee + L2 congestion fee</li>
<li><strong>Operator cost</strong> = L2 operator cost + L1 data publication cost</li>
<li><strong>Operator revenue =</strong> User fees + MEV</li>
<li><strong>Operator profit = Operator revenue - Operator cost</strong> = L2 congestion fee + MEV</li>
</ul>
<p>In the case of non-native account abstraction, an additional entity, the bundler, may introduce a fee for creating bundles of userops.</p>
<p>Considering the bundler, the costs and profits are extended as follows:</p>
<ul>
<li><strong>User fee</strong> = L1 data publication fee + L2 operator fee + L2 congestion fee + Bundler Fee</li>
<li><strong>Bundler Cost</strong> = Quoted(L1 data publication fee + L2 operator fee + L2 congestion fee)</li>
<li><strong>Bundler Revenue</strong> = User fee</li>
<li><strong>Bundler profit</strong> = Bundler Revenue - Bundler cost = Difference between L1 and L2 costs and quoted prices from the bundler + Bundler fee</li>
<li><strong>Operator Cost</strong> = L1 data publication fee + L2 operator fee</li>
<li><strong>Operator profit = Operator revenue - Operator cost</strong> = L2 congestion fee + MEV</li>
</ul>
<p>The bundler earns its fee from the user for their services, while the remainder of the user’s payment covers the L2 operator’s costs. If the user is unaware of the bundle size, estimating the actual cost of sending userops becomes challenging, potentially leading to the bundler charging higher fees than the one necessary to cover the operator cost.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-incentive-alignment-in-l2-9" name="p-49870-incentive-alignment-in-l2-9"></a>Incentive Alignment in L2</h3>
<p>The interaction between the bundler and L2 helps address this issue, as L2s are incentivized to keep user costs low due to competition. Overcharging users can drive them to switch to other L2s offering fairer prices.</p>
<p>Let’s redefine our model by introducing the operator. The user bids to the bundler for inclusion in the next L2 block by bidding a value <span class="math">V</span>. The user aims to minimize the data publication fee, while the bundler seeks to maximize their fee or gain a surplus from L2 interaction costs and user fees.</p>
<p>The costs associated with creating a bundle and publishing it on-chain can be divided into two parts:</p>
<p><strong>On-chain cost function:</strong> A bundler issuing bundle <span class="math">\mathbf{B}</span> when the base fee is <span class="math">r</span> expends a cost:</p>
<div class="math">
C_\text{on-chain}(\mathbf{B}, r) = F \times r + n \times S \times r
</div>
<p><strong>Aggregated cost function:</strong> The bundler has a cost function for aggregating <span class="math">n</span> transactions in a single bundle <strong><span class="math">\mathbf{B}</span></strong> with base fee of <span class="math">r</span>:</p>
<div class="math">
C_\text{agg}(\mathbf{B}, r) = F' \times r + n \times S' \times r + n \times \omega
</div>
<p>with  <span class="math">S' &lt; S</span> the reduced size of a transaction and the pre-verification gas use <span class="math">F' &gt; F</span>, which contains the publication and verification of the single on-chain aggregated signature.</p>
<p>If the user can obtain a reliable estimate for <span class="math">n</span>, they can calculate their cost using the <code>estimateGas</code> function, available in most L2 solutions. Having a good estimation can make the user bid accordingly without having to overestimate their bid for inclusion. This function determines the necessary cost to ensure inclusion. Having a good estimate for <span class="math">n</span> and the <code>estimateGas</code> function can avoid the user to pay for a higher <code>preVerificationGas</code>. In the next section, we will explore various mechanisms to ensure a reliable estimation of <span class="math">n</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-layer2s-operate-an-oracle-10" name="p-49870-layer2s-operate-an-oracle-10"></a>Layer2s operate an oracle</h3>
<p>The oracle’s role is to monitor the mempool and estimate the number of transactions present. The process works as follows: the Layer 2 deploys an oracle to check the mempool and then informs the user about the number of transactions in the mempool. This enables the user to estimate their bid for inclusion in a bundle. The Layer 2 can request the bundler to include at least a specified number of transactions (<span class="math">n</span>) in a bundle, or else the bundle will be rejected. Once the bundler gathers enough transactions to form a bundle, it sends the bundle to the Layer 2, which then forwards it to the mainnet as calldata for data availability.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/5/155c138c7fac1f1d415836ca20e488c9ad49fa73.jpeg" title="Watcher proposal"><img alt="Watcher proposal" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/5/155c138c7fac1f1d415836ca20e488c9ad49fa73_2_538x500.jpeg" width="538" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-layer2s-with-shared-sequencer-11" name="p-49870-layer2s-with-shared-sequencer-11"></a>Layer2s with shared sequencer</h3>
<p>An interesting approach is to have multiple Layer 2 (L2) networks running a shared sequencer. This setup can provide a more accurate estimate of the mempool, as the sequencer reaches an agreement through consensus facilitated by the shared sequencer.</p>
<p>In this configuration, different L2 networks operate independently but share a common sequencer. At regular intervals, these networks check the number of user operations (userops) in the shared mempool. The shared sequencer helps synchronize and aggregate data from these networks. Once they reach an agreement, the information is communicated to the user, allowing them to bid based on the number of userops present.</p>
<p>This approach offers several advantages. Firstly, it provides a decentralized method to determine the number of userops in the mempool, enhancing resistance to collusion. Secondly, it eliminates the single point of failure that could occur if only one system were managing the communication between the user and the mempool. Thirdly, the shared sequencer ensures consistency and reduces discrepancies between the different L2 solutions.</p>
<p>By leveraging the shared sequencer, this method ensures a robust and reliable system for estimating and communicating the state of the mempool to users, thus improving the overall efficiency and security of the process.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/6/d6c85557ef46c934ff99f11c86e081107333e050.jpeg" title="Shared Sequencer"><img alt="Shared Sequencer" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/d/6/d6c85557ef46c934ff99f11c86e081107333e050_2_486x500.jpeg" width="486" /></a></div><p></p>
<p>In the two explained approaches by using an oracle, there is a potential attack vector where an adversary could generate multiple user operations in the mempool, knowing that they will revert if aggregated together. As a result, the oracle sees that there are <span class="math">n</span>  transactions and requires a large bundle, but the bundler cannot create the bundle. This issue could stall the network for many blocks.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49870-layer2s-operate-their-own-bundler-12" name="p-49870-layer2s-operate-their-own-bundler-12"></a>Layer2s operate their own bundler</h3>
<p>In this proposal, the Layer 2 itself assumes the role of the bundler, while another entity handles the aggregation of signatures (this could be current bundler services). The process works as follows: the Layer 2 operates its own bundler, and users send their operations (userops) to the mempool. The Layer 2 selects some of these userops from the mempool and sends them “raw” to the aggregator, compensating the aggregator for aggregating the signatures. Once the aggregator produces the bundle, it sends it to the bundler, which then forwards it to the mainnet as calldata for data availability.</p>
<p>The main idea is that the Layer 2 handles the collection of userops and then outsources the aggregation to another entity. The Layer 2 pays for the aggregation and charges the user a fee for the service.</p>
<p>There are two different options:</p>
<ol>
<li>
<p><strong>Flat Fee Model:</strong> The bundler (Sequencer) selects some transactions and charges the user a flat fee. This flat fee is calculated similarly to current Layer 2 transactions, predicting the future cost of L1 data publication. Alternatively, the Layer 2 could charge the user a flat fee based on the cost of bundling <span class="math">n</span>  aggregated userops,  the layer 2 still have to predict how many transactions will be present in the bundle he will contruct to correctly quote the user, this can be made in the same way is now where the . As it is now where the l2 charge the best comeptitive price to the user that it is in the Layer 2’s best interest to keep the prices as competitive as possible for the user.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/a/2ad21c4d7917c11d2c90e9f0f2b4e027466730f7.png" title="Flat Fee"><img alt="Flat Fee" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/2/a/2ad21c4d7917c11d2c90e9f0f2b4e027466730f7_2_477x500.png" width="477" /></a></div><p></p>
</li>
<li>
<p><strong>Requesting Refunds:</strong> If the Layer 2 wants to enhance its credibility, it could enable automatic refunds. This would involve a mechanism that checks how many userops are published in a single block and whether the transactions could have been aggregated. If a userop that could have been aggregated wasn’t, and no automatic refund was issued, the user can request a refund. In this scenario, the Layer 2 could stake some assets, and if the refund isn’t provided, the user could enforce the refund, ensuring fairness and accountability.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/8/28b9021118bfcafbcc024f1efe0dcd3c1184c5de.png" title="Request Refund"><img alt="Request Refund" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/2/8/28b9021118bfcafbcc024f1efe0dcd3c1184c5de_2_477x500.png" width="477" /></a></div><p></p>
</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#p-49870-conclusion-13" name="p-49870-conclusion-13"></a>Conclusion</h2>
<p>In these two different posts, we outline the difficulties users experience when bidding to be included in the next bundle. In the first part, we presented the ERC-4337 model, explaining the costs a bundler incurs when posting a bundle on-chain and the associated off-chain costs. We also outlined the fee markets for bundlers and began discussing the issue of formatting the bundler. Users experience difficulties with bidding due to a lack of knowledge about the number of transactions present in the mempool at the time of bundling.</p>
<p>In the second part, we explained ERC-4337 and RIP-7560. We then discussed why signature aggregation is more likely to occur on Layer 2 solutions rather than directly on Layer 1. We demonstrated how Layer 2 solutions could address the asymmetric knowledge that users experience in different ways. The first one is to use oracles to signal to the user how many transactions are present in the mempool, with this approach the users knows how much they should bid and can force the bundler to make larger bundles. The third approach which is the simplest is that the L2 acts as a bundler and outsources the aggregation to a third party and lets the users pay a fee for it.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/embedded-fee-markets-and-erc-4337-part-2/20384">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 10:23:10 +0000</pubDate>
</item>
<item>
<title>Timestamp Ordering in MCP for Timing Games</title>
<link>https://ethresear.ch/t/timestamp-ordering-in-mcp-for-timing-games/20372</link>
<guid>https://ethresear.ch/t/timestamp-ordering-in-mcp-for-timing-games/20372</guid>
<content:encoded><![CDATA[
<div> 关键词：MCP、MEV、POD、公平性、安全性和去中心化

总结：

文章主要探讨了在以太坊中引入多个并发提议者（MCP）机制的重要性以及其对解决现有共识问题的潜在影响。MCP旨在通过分散区块提议过程来减少单一提议者在某一时间槽中的垄断权力，从而解决由基于领导者的共识机制带来的问题，如某些交易的短期审查。

文中提出了经济秩序的多提案者模型，其中考虑了确定性区块排序，即根据交易的优先费用或执行标志对区块进行排序。然而，文章也指出了一种可能的策略游戏——利用时间游戏和抢先行为的机会，这可能导致提议者通过延迟区块提议来最大化奖励。为了应对这一问题，文章提出采用部分有序数据集（POD），一种基于客户端记录的交易时间戳的排序方法。这种机制允许在保证公平性的同时，避免了严格的交易顺序，并通过惩罚恶意操作来保护诚实节点。

POD还引入了一种新的数据结构，允许客户端与网络中的验证者交互，请求特定轮次的交易记录，并通过识别证书来确认交易的最终化。这种方法有助于实现交易的去中心化，防止中央化风险，并确保网络的安全性。

最后，文章讨论了POD在缓解最大可提取价值（MEV）问题方面的潜力，通过改变交易排序策略，限制了恶意行为，特别是前向运行和夹击攻击的可能性。同时，POD机制也引发了关于如何检测不良行为的新问题，以及如何提供更好的激励措施来促进非集中化的思考。 <div>
<blockquote>
<p>Thanks to <a class="mention" href="https://ethresear.ch/u/julian">@Julian</a> and <a href="https://twitter.com/_ddiaconescu_" rel="noopener nofollow ugc">@denisa</a> for the corrections, suggestions and discussions!</p>
</blockquote>
<p>Multiple Concurrent Proposers (MCP) has recently become a significant topic of discussion within the community, particularly following the introduction of the <a href="https://x.com/danrobinson/status/1820506643739615624" rel="noopener nofollow ugc">BRAID protocol</a> and the rise of DAG consensus. Max’s argument in favor of MCP for Ethereum centers on the monopoly created by leader-based <a href="https://ethresear.ch/t/execution-consensus-separation/19964">consensus mechanisms</a>, where the leader for a given slot is granted substantial monopolistic power. This concentration of power leads to issues such as short censorship for some transactions.</p>
<p>In leader-based consensus, the designated leader for each slot has the exclusive authority to propose blocks, which allows them to exploit their position for profit maximization, such as through transaction reordering or frontrunning. MCP aims to mitigate these issues by decentralizing the block proposal process, reducing the influence any single proposer can exert over the network during a given slot.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49846-multiple-concurrent-proposers-economic-order-1" name="p-49846-multiple-concurrent-proposers-economic-order-1"></a>Multiple Concurrent Proposers Economic Order</h1>
<p>Let <span class="math">n</span> represent the number of validators in the network. A subset of validators maintains a local chain, denoted by <span class="math"> k &lt; n</span>. The protocol at some step will need to pick the union of all local blockchains at slot <span class="math">i</span> and an ordering rule must be applied between transactions of each local chain.</p>
<p><strong>Deterministic Block Ordering</strong>: A deterministic rule is applied to order the blocks and its transactions. In the context of <a href="https://www.youtube.com/live/PhsJnEnsLN4?si=_Wd_RzjXLzgdyeaZ" rel="noopener nofollow ugc">MEV-SBC ‘24</a> event, <a href="https://www.youtube.com/watch?v=SBOGdofF4u8" rel="noopener nofollow ugc">Max proposes</a> two approaches:</p>
<ol>
<li><strong>Sorting by Priority Fee</strong>: Blocks are sorted based on the priority fee of transactions. MEV (Maximal Extractable Value) taxes can be applied, where a percentage of the priority fee is extracted and redistributed by the application. This approach is detailed in the proposal <a href="https://www.paradigm.xyz/2024/06/priority-is-all-you-need" rel="noopener nofollow ugc">“Priority is All You Need”</a>.</li>
<li><strong>Execution Flags</strong>: Transactions can set an “execution flag” that indicates specific actions, such as interacting with a particular liquidity pool (e.g., trading ETH/USDC in the UNIv5 pool). When the block ordering rule encounters a transaction with such a flag, it pulls all flagged transactions attempting to interact with that pool and executes them as a batch.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#p-49846-timing-games-with-frontrunning-incentive-2" name="p-49846-timing-games-with-frontrunning-incentive-2"></a>Timing Games with Frontrunning Incentive</h1>
<p>Let <span class="math">p</span> be a proposer participating in the MCP protocol, who is responsible for proposing a block in their local chain during slot <span class="math">i</span>. We acknowledge that there exists an inherent delay and processing time required to propose this block. Specifically, the protocol permits a maximum allowable delay of <span class="math">\Delta</span> time units before <span class="math">p</span> incurs penalties.</p>
<p><span class="math">p</span> may strategically opt to delay their block proposal until <span class="math">\Delta - \epsilon</span> (where <span class="math">\epsilon &gt; 0 </span>) time units. This delay enables <span class="math">p</span> to potentially exploit a frontrunning opportunity by observing and computing a partial order of transactions submitted by other proposers. By strategically placing their block proposal just before the misslot penalty (no block has been proposed and it’s no going to be accepted for slot <span class="math">i</span>), <span class="math">p</span> could include transactions with higher gas fees, a situation that provides a clear incentive for engaging in frontrunning behavior and the main incentive for playing timing games in this post.</p>
<p>Under the current deterministic protocol rules, such a timing strategy is incentivized as it allows proposers to maximize their rewards through manipulation of transaction order. This situation underscores the need for an effective mechanism. However, a more robust solution may involve revisiting the transaction ordering rules to eliminate this concrete incentive for timing games that lead to such exploitative behaviors, thereby ensuring a fairer and more secure protocol.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49846-partially-ordered-dataset-pod-3" name="p-49846-partially-ordered-dataset-pod-3"></a>Partially Ordered Dataset (POD)</h1>
<p>One of the main concerns regarding MCP is the absence of a clearly defined method for determining the order of transactions. It remains uncertain how the sequence and the underlying criteria for ordering will be established, as well as how the influence of clients will be exercised—whether through mechanisms such as auctions, latency considerations, or the risk of spam attacks, as highlighted by <a href="https://www.youtube.com/watch?v=SBOGdofF4u8" rel="noopener nofollow ugc">Phil at SBC '24</a>.</p>
<p>The team of Common Prefix has conducted a thorough <a href="https://www.commonprefix.com/static/clients/flashbots/flashbots_report.pdf" rel="noopener nofollow ugc">analysis of various consensus protocols</a>, including leader-based, inclusion list, and leaderless consensus models, with a focus on their resistance to censorship. As a result of their research, they developed the concept of a Partially Ordered Dataset. In this model, the order of transactions is determined by the timestamps recorded by the clients, which may lead to a lack of strict ordering when two transactions are recorded simultaneously. The implications of relinquishing strict ordering in transaction processing have not been extensively explored in the existing literature, or at least, I am not aware of any comprehensive studies on the matter.</p>
<p>A POD is a finite sequence of pair <span class="math">\{(r, T), …, (r’, T’)\}</span> s.t. <span class="math">r</span> is round (slot) and <span class="math">T</span> a set of transactions.</p>
<p>A round is perfect <span class="math">r_{perf}</span> if no new transactions can appear with recorded round <span class="math">r_{rec} \leq r_{perf}</span>, which means there is no conflict in the ordering before <span class="math">r_{perf}</span>.</p>
<p>A <strong>POD protocol</strong> exposes the following methods.</p>
<ul>
<li>input event <code>write(tx)</code> : Clients call <code>write(tx)</code> to write a transaction <code>tx</code> .</li>
<li>output event <code>write_return(tx, π)</code> : after <code>write(tx)</code> the protocol outputs <code>write_return(tx, π)</code>, where <code>π</code> is a record certificate.</li>
<li>input event <code>read_perfect()</code>: Clients call <code>read_perfect()</code> to read the transactions in the bulletin.</li>
<li>output event <code>read_perfect_return(r, D, Π)</code> : after <code>read_perfect()</code> protocol outputs <code>read_perfect_return(r, D, Π)</code>, where <code>r</code> is a round, called the past perfect round, <code>L</code> is a set of transactions, <code>D</code> is a POD, and <code>Π</code> is a past-perfect certificate. For each entry <code>(r', T)</code> in <code>D</code>, we say that transactions in <code>T</code> became finalized at round <code>r'</code>.</li>
<li>input event <code>read_all()</code> : returns all transactions up to the current round without past-perfection guarantees, hence it can return faster than <code>read_perfect()</code>.</li>
<li>output event <code>read_all_return(D, Π)</code></li>
<li><code>identify(π, Π) → P' ⊆ P</code> : Clients call <code>identify(π, Π) → P' ⊆ P</code> to identify the set <code>P'</code> of parties who vouched for the finalization of a transaction, where <code>Π</code> is a POD and <code>π</code> is the certificate returned by <code>write_return(tx, π)</code>.</li>
</ul>
<p>The properties of Liveness and Security are detailed in the original work, and the following will be utilized in subsequent arguments:</p>
<p>Fair punishment: No honest replica gets punished as a result of malicious operation. If <code>identify(π, Π) → P'</code>, where <code>π</code> is a record certificate for transaction <code>tx</code> and <code>Π</code> is a past-perfect certificate for a POD <code>D</code>, can only be created if all parties in <code>P'</code> sign <code>tx</code> and <code>D</code>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/4/74ea9a2fbbcf46cdb5da2f6898d698da4c404c6a.png" title="Construction of Partially Ordered Datasets"><img alt="Construction of Partially Ordered Datasets" height="330" src="https://ethresear.ch/uploads/default/optimized/3X/7/4/74ea9a2fbbcf46cdb5da2f6898d698da4c404c6a_2_690x330.png" width="690" /></a></div><p></p>
<p>The construction of the POD is as follows: The client will send a transaction to all the validators in the network and will have to wait for <span class="math">n - f</span> signatures to confirm his transaction has been received by the network, where <span class="math">f</span> is the amount of allowed byzantine validators. Once the client received the signature he will record the median of all the signatures he has received, as there is going to be some latency and difference between the validators when they received the transaction.</p>
<p>For the reading set of transactions for some round the client will have two options:</p>
<ul>
<li>Believe in synchrony on the txs received: Request all the recorded transactions from the validators for some specific round <span class="math">r</span>. Once obtains the  <span class="math">n- f</span> signatures of all the transactions computes the median of the set of transactions based on their timestamps.</li>
<li>Past-perfect guarantees, no-synchrony believer: Assume <span class="math">r_{perf}</span> to be the minimum of the received <span class="math">r</span> values, then we will not have any transaction with lower timestamp. Now takes the union of all the upcoming transactions. Now the client will have to wait some <span class="math">\delta</span> time to ensure through the gossip mechanism there is no lower <span class="math">r_{perf}</span> and no more transaction for the upcoming round.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#p-49846-pods-mitigating-mev-in-mcp-4" name="p-49846-pods-mitigating-mev-in-mcp-4"></a>PODs mitigating MEV in MCP</h1>
<p>Adopting Partially Ordered Datasets (PODs) as the primary data structure for MCP introduces a novel approach that hasn’t been extensively studied, particularly regarding its potential to mitigate the types of MEV games previously described.</p>
<p>In PODs, transactions are ordered deterministically based on their timestamps. While this approach necessitates handling cases where multiple transactions share the same timestamp—or evaluating the likelihood of such occurrences—it fundamentally alters the dynamics of the fronturunning incentive of timing games previously described against other proposers block transactions.</p>
<p>Consider a scenario in slot <span class="math">m</span> where a malicious proposer attempts to front-run or sandwich another transaction. Under the previous deterministic ordering, which was based on auctions and priority fees, such attacks were feasible because proposers could manipulate their position in the ordering by outbidding others or exploiting latency. However, with timestamp-based ordering as implemented in PODs, this strategy changes significantly. An open question is still to know which strategies can be applied with PODs or timestamp ordering to extract MEV and if they are worse in wellfare of the network compared with the described game.</p>
<p>In this new setup, being the last proposer in a slot would actually place that proposer in the final position within the transaction order, limiting their ability to engage in front-running or sandwiching assuming honesty in all nodes. Instead, they would only be able to perform back-running, which is generally considered less harmful than front-running or sandwiching. This shift in ordering strategy could effectively reduce the risk of these more dangerous forms of MEV exploitation.</p>
<p>If a malicious validator attempts to manipulate the order of transactions by bribing proposers, slashing should be applied to the validator. By imposing such penalties, the protocol discourages malicious behavior and ensures that the integrity of the transaction ordering process is maintained. One of the future next questions it’s how can we detect a bad behaviour in the transaction record, maybe applying Turkey’s Method it’s a posible option and assume that outliers are malicious records.</p>
<p>However, the situation is more complex than it appears. The shift to a new game for validators, where transaction ordering is influenced by latency, introduces additional challenges. Validators may now engage in latency games, where geographical proximity to other validators or network nodes becomes a crucial factor in gaining an advantage. To mitigate this, it is essential to ensure that validators are well decentralized across different regions.</p>
<p>Decentralizing validators geographically helps reduce the impact of latency-based advantages. Validators clustered in the same location could lead to centralization risks, where a few validators might dominate the network due to their low-latency connections. This centralization could undermine the fairness of transaction ordering and potentially reintroduce the risk of censorship.</p>
<p>Moreover, validators are incentivized to avoid sharing the same location because doing so decreases the uniqueness of the transactions they can access for a possible backrunning and taking such opportunities. The more validators operate from the same region, the fewer unique transactions each can capture, leading to lower profits from transaction fees, as these would have to be split among more validators. This dynamic encourages validators to spread out, fostering a more decentralized and resilient network that is better protected against latency-based games and the centralization of power. However, the current incentive is still weak and future work will reside in how to provide better incentives for non-centralization.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/timestamp-ordering-in-mcp-for-timing-games/20372">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 03 Sep 2024 08:17:06 +0000</pubDate>
</item>
<item>
<title>Interpreting MPT branch node values</title>
<link>https://ethresear.ch/t/interpreting-mpt-branch-node-values/20368</link>
<guid>https://ethresear.ch/t/interpreting-mpt-branch-node-values/20368</guid>
<content:encoded><![CDATA[
<div> 关键词：MPT、分支节点、NULL、空字符串、终结节点

总结:

本文探讨了在默克尔树（MPT）中区分两种不同类型的分支节点情况。第一种情况是分支节点被视为非“终结”节点，其第17项列表应为空（NULL），表示该节点继续指向其他子节点。而第二种情况则是当分支节点作为终结节点使用时，第17项列表实际上包含了数据值，即使这个值恰好是空字符串。

为了区分这两种不同的节点类型，关键在于理解它们在列表中的预期内容。非终结节点的列表应该在该位置上留有空位或NULL表示后续数据的存在，而终结节点则会填充实际的数据值。尽管在随后的RLP编码过程中，NULL会被表示为空字符串，但原始列表中NULL和非NULL（即使是空字符串）的区别是本质的。因此，识别节点类型的关键在于查看列表本身的结构而非其编码后的形式。 <div>
<p>Consider a branch node for an MPT.<br />
Suppose the 17’th item in the branch node list is supposed to be NULL, because the branch node is not a “terminator” node. Ethereum documentation says NULL is encoded as the empty string.<br />
Suppose the 17’th item in the list is supposed to be a value because the branch node is a terminator node. Suppose this value happens to be the empty string.<br />
How to distinguish these two cases?<br />
Note this question should be independent of RLP encoding, which only concerns how we encode the list. I’m asking what’s in the list itself, before considering how the list is subsequently encoded.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/interpreting-mpt-branch-node-values/20368">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 31 Aug 2024 14:57:04 +0000</pubDate>
</item>
<item>
<title>Exploring Verifiable Continuous Sequencing with Delay Functions</title>
<link>https://ethresear.ch/t/exploring-verifiable-continuous-sequencing-with-delay-functions/20362</link>
<guid>https://ethresear.ch/t/exploring-verifiable-continuous-sequencing-with-delay-functions/20362</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、Verifiable Delay Functions（VDF）、Transaction Deadlines、Ethereum作为全球时钟、Sequencer

总结：

文章探讨了在去中心化的设置中，如何解决时间同步的问题，特别是在不可信的第二层（L2）序列器环境中。在这样的环境下，墙上的时钟可能在不同机器间漂移，代理可能会谎报本地时间，而且很难区分恶意行为与不一致的时钟或网络延迟。以太坊被视为一个每约12秒跳动一次的全球时钟，其共识协议软性强制规定，过早或过晚生成的区块和验证不会被认为是有效的。

文章提出了一种机制，用于在去中心化汇总中实现对序列器的及时性、安全性和非剥削性排序的强制执行，而无需额外的共识协议、诚实多数假设或利他主义。这种机制包括三个关键原语：

1. 客户端优先级交易顺序，
2. 以太坊作为具有12秒周期的全球时钟，
3. 可验证延迟函数（VDF）。

通过引入交易截止日期、利用以太坊作为时间基准以及使用VDF，文章提供了一种方法来确保序列器遵守时间规定，同时防止提取用户价值的行为（如夹击攻击），并在分布式环境中保持系统的可靠性和安全性。文章还展示了MR-MEV-Boost案例研究，这是一种对MEV-Boost的修改，允许基于多个轮次的预确认交易，同时应用了上述构建来减少提案者的时机游戏行为。 <div>
<p><em>Thanks to Conor, Lin and Swapnil from the Switchboard team, Cecilia and Brecht from the Taiko team, Alex Obadia, Justin Drake, Artem Kotelskiy and the Chainbound team for review.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-abstract-1" name="p-49826-abstract-1"></a>Abstract</h2>
<p>Agreeing on time in a decentralized setting can be challenging: wall clocks may drift between machines, agents can lie about their local times, and it is generally hard to distinguish between malicious intent and just unsynchronized clocks or network latencies.</p>
<p>Ethereum can be thought of as a global clock that ticks at a rate of 1 tick per ~12 seconds. This tick rate is soft-enforced by the consensus protocol: blocks and attestations produced too early or too late will not be considered valid. But what should we do in order to achieve a granularity lower than 12 seconds? Do we always require a consensus protocol to keep track of time?</p>
<p>We want to explore these questions in the context of untrusted L2 sequencers, who don’t have any incentive to follow the L2 block schedule that is currently maintained by trusted L2 sequencers, and will likely play various forms of timing games in order to maximize their revenue.</p>
<p>In this article, we introduce mechanisms to enforce the timeliness, safety and non-extractive ordering of sequencers in a decentralized rollup featuring a <strong>rotating leader mechanism</strong>, without relying on additional consensus, honest majority assumptions or altruism. To do so, we use three key primitives:</p>
<ol>
<li>Client-side ordering preferences,</li>
<li>Ethereum as a global 12s-tick clock,</li>
<li>Verifiable Delay Functions.</li>
</ol>
<p>Lastly, we show the case study of MR-MEV-Boost, a modification of MEV-Boost that enables a variation of based preconfirmations, where the same construction explored can be applied to reduce the timing games of the proposer.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-rationale-2" name="p-49826-rationale-2"></a>Rationale</h2>
<p>Rollup sequencers are entities responsible for ordering (and in most cases, executing) L2 transactions and occasionally updating the L2 state root on the L1. Currently, centralized sequencers benefit from the reputational collateral of the teams building them to maintain five properties:</p>
<ul>
<li><strong>Responsiveness</strong>: responding to user transactions with soft commitments / preconfirmations in a <em>timely</em> manner. We want to highlight that this definition includes the timely broadcast of unsafe heads on the rollup peer-to-peer network.</li>
<li><strong>Non-equivocation (safety)</strong>: adhering to preconfirmation promises when submitting the ordered batch on the L1, which is what will ultimately determine the total ordering of transactions.</li>
<li><strong>Non-extractive ordering</strong>: not extracting MEV from users by front-running or sandwiching, or by accepting bribes for front-running privileges.</li>
<li><strong>Liveness</strong>: posting batches to L1 and updating the canonical rollup state regularly.</li>
<li><strong>Censorship-resistance:</strong> ensuring that no valid transactions are deliberately excluded by the sequencer regardless of the sender, content, or any external factors.</li>
</ul>
<p>In this piece we are concerned with how the first four properties can be maintained in a permissionless, untrusted setting. Note that censorship-resistance is ensured by construction: by introducing multiple organizationally distinct sequencers in different geographies and jurisdictions we have a strong guarantee that any transaction will be accepted eventually.</p>
<p>Consider a decentralized sequencer set <span class="math">S := \{S_1,\dots,S_n\}</span>  with a predictable leader rotation mechanism and a sequencing window corresponding to a known amount of L1 slots. For simplicity, let’s assume <span class="math">S_{i}</span> is the current leader and <span class="math">S_{i+1}</span> is the next one. At any point in time, only one sequencer is active and has a lock over the rollup state.</p>
<p>Here are two strategies that sequencer <span class="math">S_i</span> can explore to maximize its expected value:</p>
<p><strong>1. Delaying the inclusion of transactions</strong></p>
<p>Suppose a user sends a transaction to <span class="math">S_i</span> at a certain L2 slot. Then, the sequencer could wait some time before inserting the transaction into a block in order to extract more MEV with sandwich attacks in collaboration with searchers or by directly front-running the user. In particular, <a href="https://www.youtube.com/watch?v=01dnINiLhAk&amp;t=287s" rel="noopener nofollow ugc">since MEV grows superlinearly with time</a>, it’s not in the sequencer’s best interest to commit early to a transaction. The worst case scenario would be the sequencer delaying inclusion until the sequencer rotation <span class="math">^1</span>.</p>
<p><strong>2. Not publishing unsafe heads in the rollup peer-to-peer network</strong></p>
<p>In this setting the sequencer has low incentives to publish the unsafe heads in the rollup network: since L2 blocks are signed by the sequencer (e.g. in <a href="https://docs.optimism.io/builders/node-operators/configuration/consensus-config#p2psequencerkey" rel="noopener nofollow ugc">Optimism</a>), they act as a binding commitment which can be used by users to slash it in case of equivocations.</p>
<p>This has a major downstream consequence on the UX of the rollup: both the next sequencer and users need to wait until a batch is included to see the latest transactions. For users it means they won’t know the status of their transactions in a timely manner, while the next sequencers risks building blocks on invalid state.</p>
<p>We will now explore mechanisms to mitigate these behaviours and introduce slashing conditions for sequencers.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-primitive-1-transaction-deadlines-3" name="p-49826-primitive-1-transaction-deadlines-3"></a>Primitive 1: Transaction Deadlines</h2>
<p>We introduce a new EIP-2718 transaction type with an additional field:</p>
<ul>
<li><code>deadline</code> - <code>uint256</code> indicating the last L2 block number for which the transaction is considered valid.</li>
</ul>
<p>This idea is not entirely new. For instance, the <a href="https://limechain.tech/" rel="noopener nofollow ugc">LimeChain</a> team has explored this in their <a href="https://github.com/LimeChain/based-preconfirmations-research/blob/cfc3830c685965fad5e5843533c5586dcb92e873/docs/preconfirmations-for-vanilla-based-rollups.md#preconfirmation-deadline" rel="noopener nofollow ugc">Vanilla Based Sequencing</a> article. However, in our variant the <code>deadline</code> field is signed as part of the transaction payload and it is not expressed in L1 slots.</p>
<p>The reasoning behind it is that the sequencer cannot tamper with either the <code>deadline</code> field or <code>block.number</code> (because it is a monotonically increasing counter), and therefore it is easy to modify the L2 derivation pipeline to attribute a fault in case the sequencer inserts the user transaction in a block where <code>block.number &gt; deadline</code>.</p>
<p>This approach mitigates problem <span class="hashtag-raw">#1</span>. However, it does not in any way solve the <em>responsiveness</em> issue, since sequencers can still delay proposing the block in order to extract more MEV.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-primitive-2-ethereum-as-a-global-clock-4" name="p-49826-primitive-2-ethereum-as-a-global-clock-4"></a>Primitive 2: Ethereum as a Global Clock</h2>
<p>A simple rotating sequencer design would be one where <span class="math">S_i</span> loses the power to settle batches after the end of its sequencing window <span class="math">W_i</span>, which is dictated by an L1 smart contract. However, the sequencer still needs some time to post the batch with the latest L2 blocks. We therefore introduce an <em>inclusion window</em> that is shifted <span class="math">n \geq 1</span> slots ahead of <span class="math">W_i</span>, where <span class="math">S_i</span> still has time to land rollup batches on L1 with the last L2 blocks, even if the responsibility of sequencing has shifted to <span class="math">S_{i+1}</span>.</p>
<p>In case of any safety fault, the sequencer should be slashed. If the sequencer has not managed to post all their assigned L2 blocks by the end of its inclusion window, it will forego all associated rewards. Optionally, there could also be penalties for liveness faults. This also helps with the problem of collaboration with the next sequencer, by ensuring that the latest blocks will be known to it within <span class="math">n\cdot12</span> seconds. Ideally, we’d like to keep <span class="math">n</span> as small as possible with a value of <span class="math">1</span>.</p>
<p>There are still some potential issues here: getting a transaction included on Ethereum is probabilistic, meaning that you can’t be sure that a transaction you send will actually be included in time. In this context it means that the last batch sent by an honest leader may not be included in the L1 by the end of its inclusion window. This can be helped with two approaches:</p>
<ul>
<li>A “based” setup, where the sequencer is also the L1 block proposer and can include any transactions right up to the point they have to propose, or</li>
<li>Using proposer commitments with a protocol like <a href="https://boltprotocol.xyz" rel="noopener nofollow ugc">Bolt</a>. We expand more on this in the <em>”Further work”</em> section below.</li>
</ul>
<p>Note that we assume there is a registry smart contract that can be consulted for the currently active sequencer, i.e. it implements some leader election mechanism and takes care of sequencer bonds along with rewards and penalties. It is up to the rollup governance to decide whether the registry can be fully permissionless or if it should use an allowlist. In case of any misbehaviour, governance would be used to temporarily or permanently remove the sequencer from the allowlist.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-primitive-3-verifiable-delay-functions-5" name="p-49826-primitive-3-verifiable-delay-functions-5"></a>Primitive 3: Verifiable Delay Functions</h2>
<p><a href="https://medium.com/iovlabs-innovation-stories/verifiable-delay-functions-8eb6390c5f4" rel="noopener nofollow ugc">Verifiable Delay Functions</a> (VDFs henceforth) are a cryptographic primitive that allows a prover to show a verifier that a certain amount of time was spent running a function, and do it in a way that the verifier can check the result quickly.</p>
<p>For instance, consider a cryptographic hash function <span class="math">h</span> and define the application</p>
<div class="math">
H(n,s) := (h \circ \underset{n\ times}\dots \circ h)(s),
</div>
<p>where <span class="math">s</span> is a byte array an <span class="math">n</span> is a natural number.</p>
<p>Composing (or chaining) hash functions like SHA-256 cannot be trivially sped up using parallel computations, but the solution lacks efficient verification <span class="math">^2</span> as the only way to verify the result is to recompute the composition of functions. This solution appeared as a naïve VDF in <a href="https://eprint.iacr.org/2018/601.pdf" rel="noopener nofollow ugc">Boneh’s paper</a>, and for this reason it is referred to as <em>weak</em>.</p>
<p>Another example of VDF is <a href="https://people.csail.mit.edu/rivest/pubs/RSW96.pdf" rel="noopener nofollow ugc">iterated squaring over a group of hidden order</a>, with which it is possible to construct time-lock puzzles. We’ll explore the usage of the latter in the next sections.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49826-why-vdfs-tho-6" name="p-49826-why-vdfs-tho-6"></a>Why VDFs tho?</h3>
<p>VDFs are very useful in the context of sequencing because they can act as a <em>proof of elapsed time</em> for the duration of the block (specifically <code>block_time</code> / <code>max_adversary_speedup</code>, see <em>“Security Considerations”</em>). Consider the following algorithm for the block production pipeline:</p>
<ol>
<li>At the beginning of L2 block <span class="math">N</span>, the sequencer starts computing a VDF that takes an L2 block time (or slightly less) to compute for honest players, using the previous block hash as its input.</li>
<li>After the end of the L2 slot the sequencer builds a block <span class="math">B_N</span> where the header contains the result of the VDF, denoted <span class="math">V_N</span>. We call this <em>sealing</em> a block. This means the block hash digest contains <span class="math">V_N</span>.</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/6802ae3a20554489b1de7ccb7a9ecda502a79c39.png" title=""><img alt="" height="317" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/6802ae3a20554489b1de7ccb7a9ecda502a79c39_2_690x317.png" width="690" /></a></div><p></p>
<p>This algorithm has the nice property of creating a chain of VDF computations, in some sense analogous to <a href="https://solana.com/news/proof-of-history" rel="noopener nofollow ugc">Solana’s Proof of History</a> from which we inherit the security guarantees. What does this give us in the sequencer context? If we remember that a sequencer has a certain deadline by which it has to post batches set by the L1 slot schedule, we can have the L1 enforce that <em>at least</em> some number of L2 blocks need to be settled. This has two downstream results:</p>
<ul>
<li>The sequencer <em>must</em> start producing and sealing blocks as soon as their sequencing window starts. Pairing this with the transaction deadline property results in an upper bound of time for when a transaction can be confirmed. If they don’t follow the block schedule set by the VDF and the L1, they risk not being able to post <em>any</em> batch.</li>
<li>We mitigate problem <span class="hashtag-raw">#2</span> by taking away the incentive to withhold data (not considering pure griefing attacks): this is because the sequencer cannot tamper with an existing VDF chain, which would require recomputing all the subsequent VDFs and result in an invalid batch.</li>
</ul>
<p>In general, for the sake of this post we will consider a generic VDF, provided as a “black box” while keeping the hash chain example in mind which currently has stronger guarantees against ad-hoc hardware such ASICs. See <em>“Security Considerations”</em> below for more insights.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49826-proving-correct-vdfs-7" name="p-49826-proving-correct-vdfs-7"></a>Proving correct VDFs</h3>
<p>If a sequencer provides an invalid VDF in an L2 block header it should be slashed, and ideally we’d like to ensure this at settlement time. However, recalculating a long hash chain on the EVM is simply unfeasible due to gas costs.</p>
<p>How to show then that the number of iterations of the VDF is invalid? One way could be to enforce it optimistically (or at settlement, in case of ZK-rollups) by requiring a valid VDF chain output in the derivation pipeline of the rollup. In case of equivocation in an optimistic rollup the sequencer can be challenged using fraud proofs.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49826-hardware-requirements-8" name="p-49826-hardware-requirements-8"></a>Hardware requirements</h3>
<p>Since by definition VDFs cannot be sped up using parallelism, it follows that computing a VDF can be done by only using a single core of a CPU, and so it does in our block production algorithm.</p>
<p>This makes it different and way more lightweight compared to most Proof-of-Work consensus algorithms such as Bitcoin’s which requires scanning for a value such that, when hashed with SHA-256, the hash begins with a certain number of zero bits.</p>
<p>It’s also worth to note that modern CPUs are optimized to compute the SHA-256 hash function. Since 2016 Intel, starting with the <em>Goldmount</em> family of chips, is offering <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sha-extensions.html" rel="noopener nofollow ugc">SHA Extensions</a> in the <em>Core</em> and <em>Xeon</em> line-ups on selected models which introduces three new instructions specialized in computing different steps of the hash function algorithm more efficiently.</p>
<p>Lastly, <a href="https://www.man.com/single-core-stagnation-and-the-cloud" rel="noopener nofollow ugc">single-core performance has stagnated over the years</a> indicating that there is a minor benefit in investing in the latest generation of CPUs, thus lowering down the requirements of the system.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-case-study-mr-mev-boost-9" name="p-49826-case-study-mr-mev-boost-9"></a>Case Study: MR-MEV-Boost</h2>
<p><a href="https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091">Multi-Round-MEV-Boost</a>, is a modification of MEV-Boost that enables based preconfirmations by running multiple rounds of MEV-Boost auctions within a single L1 slot. The usage of this primitive is to output after each round a based rollup block built by L2 block builders. As shown in the article, this approach inherits the L1 PBS pipeline and mitigates some of the negative externalities of based preconfirmations as a result.</p>
<p>Like MEV-Boost, this fork relies on the opted-in proposer to be an auctioneer which ends the sealed auction by calling the <code>getHeader</code> (<a class="inline-onebox" href="https://ethereum.github.io/builder-specs/#/Builder/getHeader" rel="noopener nofollow ugc">Builder-API</a>) endpoint of the relays. After having signed the sealed bid, the <code>getPayload</code> (<a class="inline-onebox" href="https://ethereum.github.io/builder-specs/#/Builder/submitBlindedBlock" rel="noopener nofollow ugc">Builder-API</a>) is called by the proposer to receive the actual content of the winning bid and to publish the block in the based rollup network.</p>
<p>In the original protocol, the end of the auction usually coincides with the end of the L1 slot (more precisely, <a href="https://mevboost.pics/" rel="noopener nofollow ugc">near one second after it</a>); delaying it results in a high risk of not being able to broadcast the block in time to gather all the needed attestation and forgo all its associated rewards. As such, a block time is proposed every twelve seconds with consistency, enforced by Ethereum consensus.</p>
<p>In contrast, given it consists of multiple rounds happening <em>during</em> the slot, in MR-MEV-Boost an <em>untrusted proposer is incentivized to end the auction seconds later or earlier <span class="math">^{3}</span> according to the incoming bids,</em> in order to extract more more MEV. In the worst case, MR-MEV-Boost will reflect L1 block times. Another consequence of this is an inconsistent slot time for the based rollup. This can be seen as a much more serious form of timing games.</p>
<p>In the article, the discussed possible solutions to this problem are the following:</p>
<ol>
<li>Introduce user incentives: if users determine that a proposer is misbehaving, they stop sending transactions to said proposer.</li>
<li>Introduce a committee (consensus) to attest to timeliness and maintain slot durations.</li>
</ol>
<p>We now argue that a trustless solution that strongly limits the proposer without requiring actions from the user does exist, and it leverages the same construction we used for the VDF-powered block production algorithm in the context of decentralized sequencing.</p>
<p>The construction is fairly simple and consists of computing a VDF that lasts <span class="math">x := 12/r</span> seconds, where <span class="math">r</span> is the number of rounds in an L1 slot (the L2 block time). The proposer must calculate this VDF using the previous based rollup block hash as public input and, at the end of the round, sending it along with the body of a modified <code>getPayload</code> call. The output of the VDF is then stored in the rollup block header and if invalid can result in slashing the proposer after a successful fraud proof.</p>
<p>With this approach the amount of time a proposer can delay the end of a round is limited: for instance if the first auction ended one second later then during the last round it won’t be able to provide three seconds of computation for the VDF but two, resulting in an invalid block and consequent slashing <span class="math">^4</span>. This is because in order to start computing a valid VDF, it requires the previous block hash as its input, implying a sealed block.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-security-considerations-10" name="p-49826-security-considerations-10"></a>Security Considerations</h2>
<p><strong>Are VDFs really safe for this purpose?</strong><br />
Suppose an adversary owns hardware which is capable of computing the VDF faster compared to the baseline of honest players <em>without getting noticed</em> (otherwise the number of iterations for the VDF is adjusted by the protocol). Then, the faster the attacker (<code>max_adversary_speedup</code>), the less our construction would constrain the space of its possible actions. In particular, the sequencer would be able to commit a bit later to blocks and be able to re-organize some of them for extracting more value.</p>
<p>However, given we don’t need the “fast proving” property, hash-chains have proven to be robust with Solana’s Proof of History and will continue to be at least in the short-term. Also, our security requirements will not be as strict as something that <a href="https://ethresear.ch/t/statement-regarding-the-public-report-on-the-analysis-of-minroot/16670">needs to be enshrined in Ethereum</a> forever.</p>
<p>Some solutions and directions to get stronger safety guarantees can be found in the <em>”Further work”</em> section below.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-current-limitations-11" name="p-49826-current-limitations-11"></a>Current limitations</h2>
<p><strong>Sequencer credibility</strong></p>
<p>As with many new services which leverage (re)staking, the credibility of the sequencer has an upper bound which is the amount it has staked: if a MEV opportunity exceeds that, then a rational untrusted actor would prefer to get slashed and take the MEV reward.</p>
<p><strong>Leader rotation can be a critical moment</strong></p>
<p>As discussed in the batcher and registry smart contract section, the inclusion window is shifted of one slot forward at minimum compared to the sequencing window. This is needed because of the time required to settle the last batch before rotating leader, but leaves an additional slot time of at least 12 seconds in which the sequencer has room to re-organize the last L2 blocks before publishing them on the rollup peer-to-peer network. As a consequence, liveness is harmed temporarily because <span class="math">S_{i+1}</span> might be building blocks on invalid state if it starts to sequence immediately.</p>
<p>Lastly, one additional slot might not be enough to settle a batch according to recent data on <a href="https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817">slot inclusion rates for blobs</a>. This can be mitigated by leveraging new inclusion preconfirmation protocols, as explained below.</p>
<p><strong>Sequencer last-look</strong></p>
<p>Our construction makes very difficult for a sequencer to reorg a block after it has been committed to, however it doesn’t solve front-running in its entirety. In particular, the sequencer may extract value from users transactions while building the block with associated <code>deadline</code> field. A possible solution along with its limitations is explored in the section below.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-conclusion-12" name="p-49826-conclusion-12"></a>Conclusion</h2>
<p>In this article, we explored mechanisms to enforce the timeliness, safety, and non-extractive ordering of untrusted L2 sequencers in a decentralized rollup environment.<br />
The primitives discussed ensure that sequencers can act more predictably and fairly, mitigating issues such as transaction delays and data withholding. Moreover, these techniques can reduce trust assumptions for existing single-sequencer rollups, aligning with the concept of rollups functioning as <a href="https://vitalik.eth.limo/general/2024/06/30/epochslot.html#what-should-l2s-do" rel="noopener nofollow ugc">“servers with blockchain scaffolding”</a>. These findings provide a robust framework for the future development of decentralized, secure rollup architectures.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49826-further-work-13" name="p-49826-further-work-13"></a>Further work</h2>
<p><strong>Trusted Execution Environments (TEEs) to ensure the sequencer is not running an ASIC</strong></p>
<p>A <a href="https://en.wikipedia.org/wiki/Trusted_execution_environment" rel="noopener nofollow ugc">Trusted Execution Environment</a> is a secure area of a CPU, often called <em>enclave</em>, that helps the code and data loaded inside it be protected with respect to confidentiality and integrity.<br />
Its usage in blockchain protocols is an active area of research, with the main concerns being trusting the hardware manufacturer and the <a href="https://en.wikipedia.org/wiki/Software_Guard_Extensions" rel="noopener nofollow ugc">various vulnerabilities found in the past</a> of some implementations (here’s the <a href="https://x.com/_markel___/status/1828112469010596347" rel="noopener nofollow ugc">latest</a>).<br />
Depending on the use case these trust assumptions and vulnerabilities might be a deal-breaker. However, in our setting we just need a guarantee that the sequencer is not using specialized hardware for computing the VDF, without caring about possible leakage of confidential data from the enclave or manipulation of the wall clock / monotonic clock.</p>
<p><strong>Adapt existing anti-ASICs Proof-of-Work algorithms</strong></p>
<p>The <a href="https://www.getmonero.org/resources/about/" rel="noopener nofollow ugc">Monero</a> blockchain, launched in 2014 as a privacy and untraceable-focused alternative to Bitcoin, uses an ASIC-resistant Proof-of-Work algorithm called <a href="https://github.com/tevador/RandomX" rel="noopener nofollow ugc">RandomX</a>. Quoting their <code>README</code>:</p>
<blockquote>
<p>RandomX is a proof-of-work (PoW) algorithm that is optimized for general-purpose CPUs. RandomX uses random code execution (hence the name) together with several memory-hard techniques to minimize the efficiency advantage of specialized hardware.</p>
</blockquote>
<p>The algorithm however leverages <a href="https://github.com/tevador/RandomX/blob/102f8acf90a7649ada410de5499a7ec62e49e1da/README.md#cpu-performance" rel="noopener nofollow ugc">some degree of parallelism</a>; it is an interesting research direction whether it can adapted into a single-core version, leading to a new weak-VDF.<br />
This approach, while orthogonal to using a TEE, can potentially achieve the same result which is having a guarantee that the sequencer is not using sophisticated hardware.</p>
<p><strong>Time-lock puzzles to prevent front-running</strong></p>
<p>As mentioned in the <em>“Current limitations”</em> section, our construction doesn’t limit the problem of sequencer front-running the users. Luckily, this can be solved by requiring users to encrypt sensitive transactions using <a href="https://people.csail.mit.edu/rivest/pubs/RSW96.pdf" rel="noopener nofollow ugc">time-lock puzzles</a>, as we will show in more detail in a separate piece. However, this solution doesn’t come free: encrypted transactions or encrypted mempools can incentive spamming and statistical arbitrage, <a href="https://collective.flashbots.net/t/it-s-time-to-talk-about-l2-mev/3593" rel="noopener nofollow ugc">especially when the protocol fees are not very high</a>.</p>
<p><strong>Inclusion Preconfirmations and Data Availability layers</strong></p>
<p>Batch submissions to an L1 contract could be made more efficient by leveraging some of the new preconfirmations protocol like <a href="https://boltprotocol.xyz" rel="noopener nofollow ugc">Bolt</a> by Chainbound or <a href="https://docs.primev.xyz/concepts/what-is-mev-commit" rel="noopener nofollow ugc">MEV-Commit</a> by Primev to have guaranteed inclusion in the same slot. In particular, sequencing windows should end precisely in the slot before one where the proposer is running the aforementioned protocols in order to leverage inclusion commitments.</p>
<p>Additionally, the batch could be posted into an efficient and lightweight Data Availability layer run by proposers to enforce a deadline of a configurable amount of seconds in the beginning of the slot, otherwise the sequencer would be slashed.</p>
<p><img alt="" height="190" src="https://ethresear.ch/uploads/default/original/3X/b/e/bed5956f14947f6e30a081e3064cd2a196897c95.png" width="328" /></p>
<hr />
<h2><a class="anchor" href="https://ethresear.ch#p-49826-footnotes-14" name="p-49826-footnotes-14"></a>Footnotes</h2>
<ol>
<li>More precisely, if an operator controls multiple subsequent sequencers it could delay inclusion until the last sequencer rotation.</li>
<li>In Solana, the verification of a SHA-256 chain is actually parallelised but requires dividing a block associated to a ~400ms computation into 32 shreds which are forwarded to the rest of the validators as soon as they’re computed. As such, verification is sped up by computing the intermediate steps of the hash chain in parallel.</li>
<li>In general, the proposer will end some rounds earlier as a side effect of delaying other rounds. For example, it could force a longer last round to leverage possible L1 &lt;&gt; L2 arbitrage opportunities.</li>
<li>There is an edge case where the proposer might not be able to compute all the VDFs even if honest, and it is due to the rotation mechanism: since the public input of the VDF must be the previous rollup block hash, during rotation the next leader will need some time before hearing the block from the rollup network, potentially more than 1s. This could lead the next proposer to be late in computing the VDFs.<br />
To reduce this risk, the next proposer could rely on various parties to receive this information such as streaming services and/or trusted relays.</li>
</ol>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/exploring-verifiable-continuous-sequencing-with-delay-functions/20362">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 30 Aug 2024 14:29:49 +0000</pubDate>
</item>
<item>
<title>PeerDas Documentation</title>
<link>https://ethresear.ch/t/peerdas-documentation/20361</link>
<guid>https://ethresear.ch/t/peerdas-documentation/20361</guid>
<content:encoded><![CDATA[
<div> 关键词：PeerDAS、数据可用性、协议整合、安全保证、加密社区

总结:

这篇文章的主要内容围绕着PeerDAS——即将被集成到以太坊共识层中的数据可用性解决方案。其核心目标是向加密社区清晰地阐述PeerDAS所使用的加密技术，以此激发新的创新与改进，同时明确阐述PeerDAS的安全和效率保证。

文章首先强调了理解PeerDAS安全性的重要性，特别是随着它即将成为以太坊共识层的一部分。为了实现这一目标，文章提供了一个易于加密社区理解的PeerDAS加密技术描述，旨在为未来可能的改进奠定基础。

接下来，文章提出了一个关键的定理（定理1），即在可接受的加密假设下，PeerDAS被认为是一个在代数群模型中符合特定定义的数据可用性采样方案。这个定理是文章关于PeerDAS安全性的主要声明，表明了其在理论上是安全可靠的。

最后，文章邀请加密社区对文档提出反馈，以便进一步优化和改进，体现了作者对社区合作和持续发展的重视。这表明PeerDAS的发展不仅基于当前的技术理解，还考虑到了未来的适应性和改进空间。 <div>
<p>Joint work with <a class="mention" href="https://ethresear.ch/u/b-wagn">@b-wagn</a>, <a href="https://eprint.iacr.org/2024/1362.pdf" rel="noopener nofollow ugc">A Documentation of Ethereum’s PeerDAS</a></p>
<p>The long-term vision of the Ethereum community includes a comprehensive data availability protocol using polynomial commitments and tensor codes. As the next step towards this vision, an intermediate solution called PeerDAS is about to integrated, to bridge the way to the full protocol. With PeerDAS soon becoming an integral part of Ethereum’s consensus layer, understanding its security guarantees is essential.</p>
<p>The linked document aims to describe the cryptography used in PeerDAS in a manner accessible to the cryptographic community, encouraging innovation and improvements, and to explicitly state the security guarantees of PeerDAS. We focus on PeerDAS as described in Ethereum’s consensus specifications [<a href="https://github.com/ethereum/consensus-specs/commit/54093964c95fbd2e48be5de672e3baae8531a964" rel="noopener nofollow ugc">Eth24a</a>, <a href="https://github.com/ethereum/consensus-specs/tree/dev/specs/_features/eip7594" rel="noopener nofollow ugc">Eth24b</a>].</p>
<p>Our intention is two-fold: first, we aim to provide a description of the cryptography used in PeerDAS that is accessible to the cryptographic community, potentially leading to new ideas and<br />
improvements that can be incorporated in the future. Second, we want to explicitly state the security and efficiency guarantees of PeerDAS. In terms of security, this document justifies the following claim:<br />
<strong>Theorem 1</strong> (Main Theorem, Informal): <em>Assuming plausible cryptographic hardness assumptions, PeerDAS is a secure data availability sampling scheme in the algebraic group model, according to the definition in [<a href="https://eprint.iacr.org/2023/1079" rel="noopener nofollow ugc">HASW23</a>].</em></p>
<p>We hope to receive feedback from the community to make further improvements to this document</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/peerdas-documentation/20361">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 30 Aug 2024 12:56:35 +0000</pubDate>
</item>
<item>
<title>Accessible Encryption for Ethereum Rollups with Fairomon</title>
<link>https://ethresear.ch/t/accessible-encryption-for-ethereum-rollups-with-fairomon/20349</link>
<guid>https://ethresear.ch/t/accessible-encryption-for-ethereum-rollups-with-fairomon/20349</guid>
<content:encoded><![CDATA[
<div> 关键词：Fairomon、Monomer、Fairblock、FairyRing、MPC加密

总结:

本文介绍了Fairomon，一种结合了Fairblock和Monomer技术的特别精灵型宝可梦。Fairomon旨在通过Fairblock提供的阈值多点计算（MPC）加密功能，为Monomer构建的以太坊卷积提供内置加密解决方案。以下是Fairomon的主要工作原理和可能的应用：

1. **FairyRing与密钥生成**：FairyRing使用去中心化的密钥生成方式，为每个周期（每100个区块）生成主秘密密钥（MSK）。从MSK中派生出主公钥（MPK），并将其传输至Monomer链用于加密请求的交易。同时，MSK被分割成参与网络的FairyRing验证者的等份。

2. **阈值身份基加密（IBE）**：Fairomon支持阈值IBE，允许用户或开发人员根据特定条件（如区块高度、资产价格、智能合约调用、ZK证明验证或治理投票结束）编程解密交易。这种解密可以通过“ID”触发，这些“ID”可以是链上条件、链上/下链标识符或属性，某些钱包可以证明其所有权。

3. **安全应用可能性**：MPC加密使许多以前无法在卷积中实现的应用成为可能，包括加密内存池、抗审查排序、以及DeFi和游戏应用中的加密订单、无领袖NFT拍卖、身份受限内容和最高手赢的纸牌游戏（如黑杰克）。

4. **交易流程**：用户将加密交易和解密条件提交给应用程序，链接收加密交易并在内存池中处理。交易按照目标高度排序，并在x/pep模块内部对区块内的顺序进行承诺。当达到目标高度或解密条件时，应用程序链接收来自Fairyring链的解密密钥，然后对加密交易进行解密并执行。

5. **架构集成**：Fairomon通过与Monomer链的集成展示了其工作流程，确保了加密交易的安全性和功能性，同时利用了Monomer的OP堆栈和ABCI接口优势。

Fairomon和Fairblock的结合为以太坊生态系统提供了强大的加密功能，使得敏感数据处理更加安全可靠，同时为开发者打开了创新应用的大门。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/f/5fa5f78d2b4b44708e03133cf29d1de097113e36.jpeg" title="690x435"><img alt="690x435" height="435" src="https://ethresear.ch/uploads/default/optimized/3X/5/f/5fa5f78d2b4b44708e03133cf29d1de097113e36_2_690x435.jpeg" width="690" /></a></div><p></p>
<p>Co-authored by <a class="mention" href="https://ethresear.ch/u/pememoni">@pememoni</a> and <a class="mention" href="https://ethresear.ch/u/shakeshack">@shakeshack</a>. With special thanks to the rest of the Fairblock team!</p>
<p>Fairomon is a special fairy type pokemon that combines the work of Fairblock and Monomer - a framework that enables builders to create Ethereum rollups with built-in encryption with minimal lift.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49798-background-1" name="p-49798-background-1"></a>Background</h1>
<p>Monomer is a rollup framework that enables Cosmos SDK app chains to be deployed as rollups on Ethereum. Internally, Monomer is built on top of the OP stack relying on it for chain derivation and settlement while supporting an ABCI interface for a Cosmos SDK app chain to be deployed on top. Fairblock provides threshold MPC encryption that can be utilized in Monomer rollups through a module built for Cosmos SDK chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/3/2311821ac2a3b134e2df081bbf12f2d71f2c31cc.png" title="451x500"><img alt="451x500" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/2/3/2311821ac2a3b134e2df081bbf12f2d71f2c31cc_2_451x500.png" width="451" /></a></div><p></p>
<p>Fairblock enables blockchain developers to integrate pre-execution encryption. This pre-execution encryption is made possible through their threshold MPC network that delivers identity-based encryption (IBE), and soon custom encryption schemes, to partner chains. Fairblock’s MPC network, called Fairyring, generates threshold encryption and decryption keys for each supported Monomer rollup, while the rollups themselves receive and process encrypted transactions natively.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49798-how-it-works-2" name="p-49798-how-it-works-2"></a>How it Works</h1>
<p>FairyRing uses decentralized key generation to issue a master secret key (MSK) for each epoch (every 100 blocks). From each MSK, a master public key (MPK) can be derived. Once the MPK is derived, it is relayed to a Monomer chain where it will be used to encrypt each requested transaction. In parallel, the MSK is split into equal shares for the amount of FairyRing validators participating in the network. For each request for decryption, FairyRing validators use their share of the MSK to collectively derive the associated private keys.</p>
<p>In threshold IBE, users or developers can program the decryption conditions for transactions. Onchain conditions that could trigger decryption could be a block height, the price of an asset, a smart contract call, verification of a ZK proof, or the end of a governance poll, for example. Identity-based encryption allows for the programmability of decryption and allows for decryption to be triggered by “IDs,” which can be either onchain conditions or on/offchain identifiers or attributes that certain wallets prove ownership of.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49798-whats-possible-with-fairomon-3" name="p-49798-whats-possible-with-fairomon-3"></a>What’s Possible with Fairomon</h1>
<p>MPC encryption can make a number of previously inaccessible applications possible within rollups, most notably encrypted mempools, censorship-resistant sequencing, and DeFi and gaming apps such as encrypted orders, leaderless NFT auctions, ID-gated content, and highest-hand-wins card games like blackjack.</p>
<p>The transaction flow for an application is as follows:</p>
<ul>
<li>User submits an encrypted tx and decryption condition (e.g. target height) to an app</li>
<li>Chain receives encrypted txs in mempool</li>
<li>Encrypted txs are sorted by target heights and ordering within a block is committed to inside of the integrated x/pep module</li>
<li>When target height or decryption condition is reached, the app chain receives decryption key from the Fairyring chain</li>
<li>Encrypted txs are decrypted and executed inside the BeginBlock method of the x/pep module</li>
</ul>
<p>See the architecture diagram below for a detailed description of how Fairyring integrates with a Monomer appchain.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/2/723cc342b05947059263449d26d5e63a0010c14a.png" title="690x147"><img alt="690x147" height="147" src="https://ethresear.ch/uploads/default/optimized/3X/7/2/723cc342b05947059263449d26d5e63a0010c14a_2_690x147.png" width="690" /></a></div><p></p>
<p>Monomer links:</p>
<ul>
<li><a href="https://github.com/polymerdao/monomer" rel="noopener nofollow ugc">Github</a></li>
<li><a href="https://github.com/polymerdao/monomer/tree/main/doc" rel="noopener nofollow ugc">Docs</a></li>
</ul>
<p>Fairblock links:</p>
<ul>
<li>
<p><a href="https://www.fairblock.network/" rel="noopener nofollow ugc">Website</a></p>
</li>
<li>
<p><a href="https://github.com/Fairblock" rel="noopener nofollow ugc">Github</a></p>
</li>
<li>
<p><a href="https://docs.fairblock.network/docs/basics/overview" rel="noopener nofollow ugc">Docs</a></p>
</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/accessible-encryption-for-ethereum-rollups-with-fairomon/20349">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 15:45:36 +0000</pubDate>
</item>
<item>
<title>Outdated encryption stored on blockchain</title>
<link>https://ethresear.ch/t/outdated-encryption-stored-on-blockchain/20346</link>
<guid>https://ethresear.ch/t/outdated-encryption-stored-on-blockchain/20346</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据存储、安全性、加密算法、SHA-1

总结:

区块链技术在医疗、建筑等领域的应用中，强调其能提供安全的数据存储。但若用于加密的算法（如SHA-1）被证明存在安全漏洞，即所谓的“被破解”，这会引发对存储在其上的数据安全性的担忧。因为一旦加密算法被破解，理论上就可以通过计算手段获取原本被加密保护的数据内容，使得原本被认为安全的数据突然间变得公开。

为避免这一情况导致的数据泄露，有几种可能的应对策略：

1. **重新加密**：最直接的方法是重新加密受影响的数据。这意味着使用新的、安全的加密算法对数据进行加密，从而将原有的加密层去除或覆盖。这样，即使原加密算法存在漏洞，新的加密层也能保护数据的安全。

2. **数据迁移**：将数据从使用不安全算法的区块链系统转移到使用更安全算法的新系统上。这种方法需要确保数据迁移过程中的安全性，防止在迁移过程中数据被窃取或损坏。

3. **更新系统配置**：对于仍在运行的系统，可以考虑更新系统配置，启用或升级到更安全的加密算法版本。这通常需要对现有系统进行一定程度的改造和测试，以确保过渡过程平稳无误。

4. **定期审计与评估**：建立一套定期对使用的加密算法进行安全审计和评估的机制，以便及时发现并应对潜在的安全威胁。这包括监控新出现的安全漏洞，以及评估现有系统的安全性。

5. **法律与合规性**：在数据保护和隐私法规日益严格的背景下，确保数据处理符合相关法律法规的要求，对于维护数据安全至关重要。这可能涉及数据加密、访问控制、备份策略等多个方面。

综上所述，面对加密算法被证明存在安全风险的情况，关键在于采取有效的措施来保护数据的安全，这包括但不限于重新加密、数据迁移、系统配置更新、定期安全审计与评估，以及遵守相关的法律与合规要求。 <div>
<p>Please pardon my ignorance. I’ve read several publications related to blockchain being used in healthcare, construction and the like. Many of these publications state that blockchain allows the storage of secured data.</p>
<p>My question is this: If data is “securely” stored on blockchain (I assume encrypted) and the encryption algorithm LATER (after long-term usage) is proven to be “cryptographically broken” (e.g., SHA-1) …</p>
<ul>
<li>does this not mean all “secured” data on the blockchain using that algorithm is suddenly public?</li>
<li>are there steps that can be taken to re-encrypt the data to avoid the massive leak of data?</li>
</ul>
<p>Kind regards.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/outdated-encryption-stored-on-blockchain/20346">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 12:21:08 +0000</pubDate>
</item>
<item>
<title>Does multi-block MEV exist? Analysis of 2 years of MEV Data</title>
<link>https://ethresear.ch/t/does-multi-block-mev-exist-analysis-of-2-years-of-mev-data/20345</link>
<guid>https://ethresear.ch/t/does-multi-block-mev-exist-analysis-of-2-years-of-mev-data/20345</guid>
<content:encoded><![CDATA[
<div> 关键词：多区块MEV、MEV-Boost支付、序列长度、序列位置、自相关性

总结:

本文通过分析自合并以来的提案构建数据和MEV-Boost支付数据，旨在识别多区块MEV的模式。主要发现如下：

1. **序列频率**：观察到相同构建者提出多个连续区块的序列比随机蒙特卡罗模拟预测的要少。最长的序列为25个区块。

2. **支付增加**：对于更长连续序列的平均MEV-Boost支付增加，从单个区块的大约0.05 ETH增加到九个连续区块的大约0.08 ETH。

3. **序列位置价值**：在较长序列中，每个区块位置的平均支付略有增加，这可能表明构建者愿意为较后的区块支付更多费用以确保捕获早先准备的机会。

4. **自相关性**：MEV-Boost支付之间存在较低的自相关性，这意味着历史数据无法预测未来的MEV，也未显示出低MEV或高MEV的时期。

5. **专业化趋势**：没有证据表明构建者根据基础费用波动环境进行专业化。在当前的PBS机制下，创建多区块MEV机会存在固有风险，这可能是导致这种现象的原因之一。

通过这些发现，研究揭示了合并后多区块MEV的出现频率低于预期，支付模式与序列长度有关，但未显示系统性的多区块策略应用，以及构建者并未显示出对特定波动环境的偏好。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49786-does-multi-block-mev-exist-analysis-of-2-years-of-mev-data-1" name="p-49786-does-multi-block-mev-exist-analysis-of-2-years-of-mev-data-1"></a>Does multi-block MEV exist? Analysis of 2 years of MEV Data</h1>
<p><em>by <a href="https://x.com/pascalstichler" rel="noopener nofollow ugc">Pascal Stichler</a> (<a href="https://www.ephema.io/" rel="noopener nofollow ugc">ephema labs</a>)</em></p>
<p><em>Many thanks to <a href="https://x.com/nero_eth" rel="noopener nofollow ugc">Toni</a>, <a href="https://x.com/_julianma" rel="noopener nofollow ugc">Julian</a>, <a href="https://x.com/sui414" rel="noopener nofollow ugc">Danning</a> and <a href="https://x.com/marc_nitzsche" rel="noopener nofollow ugc">Marc</a> for feedback and especially to <a href="https://x.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a> for nudging the research in the first place and continuous feedback.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-tldr-2" name="p-49786-tldr-2"></a><em>TL;DR</em></h2>
<ul>
<li>We looked at proposer-builder data and MEV-Boost payment data since the merge (September 2022) to identify patterns of multi-block MEV.</li>
<li>We observe fewer multi-slot sequences of builders than a random Monte Carlo simulation would predict. The longest observed multi-slot sequence is 25 slots.</li>
<li>Average MEV-Boost payments increase for longer consecutive sequences by the same builder from ~0.05 ETH for single slots to ~0.08 ETH for nine consecutive slots.</li>
<li>In longer sequences, the payment per slot increases slightly with later slots. This indicates that builders bid higher to get longer sequences or the first slot after a longer sequence.</li>
<li>There is a weak positive autocorrelation between subsequent MEV-Boost payments. This contradicts the hypothesis that there are generally periods of low and high MEV.</li>
<li>Comparing builders with periods of low and high base fee volatility shows a low correlation. This indicates that no builder specialization based on base fee volatility has developed yet.</li>
</ul>
<p><em>The detailed results can be found in the Jupyter notebook on <a href="https://github.com/ephema/MEVBoost-Analysis/blob/762b7626c57cc6a1c350059b41e272a70cda49cf/%5Bephema%5D_MEV_Boost_Multi_Slot_MEV_Analysis.ipynb" rel="noopener nofollow ugc">Github </a>or <a href="https://colab.research.google.com/drive/1kKM-da6xP7St8puzPuyn1Ndag6a6wsg3?usp=sharing" rel="noopener nofollow ugc">Google Colab</a>.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-background-3" name="p-49786-background-3"></a>Background</h2>
<p>Multi-block Maximal Extractable Value (MMEV) occurs when one party controls more than one consecutive block. It was first introduced in 2021 by [<a href="https://arxiv.org/pdf/2109.04347" rel="noopener nofollow ugc">1</a>] as k-MEV and further elaborated by [<a href="https://eprint.iacr.org/2022/445.pdf" rel="noopener nofollow ugc">2</a>]. It is commonly assumed that controlling multiple slots in a sequence allows to capture significantly more MEV than controlling them individually. This derives from MEV accruing superlinearly over time. The <a href="https://collective.flashbots.net/t/multi-block-mev/457" rel="noopener nofollow ugc">most discussed</a> multi-block MEV strategies include <a href="https://eprint.iacr.org/2022/445.pdf" rel="noopener nofollow ugc">TWAP oracle manipulation attacks</a> on DEXes and producing forced liquidations by price manipulation.</p>
<p>After the merge, [<a href="https://arxiv.org/pdf/2303.04430" rel="noopener nofollow ugc">3</a>] have looked into the first four months of data on multi-block MEV and summarized it as <em>“preliminary and non-conclusive results, indicating [that] builders employ super-linear bidding strategies to secure consecutive block space"</em>.</p>
<p>With the recent Attester-Proposer-Separation (APS) and pre-confirmation discussions, multi-block MEV has become more of a pressing issue again as it might be prohibitive for some of the proposed designs (For a more in-depth overview, we’ve created a <a href="https://miro.com/app/board/uXjVK07aBCU=/?share_link_id=220296247588" rel="noopener nofollow ugc">diagram of recently proposed mechanism designs</a> and also <a href="https://x.com/mikeneuder" rel="noopener nofollow ugc">Mike Neuder</a> lately gave a <a href="https://www.youtube.com/watch?v=ToVi-zsiE4M" rel="noopener nofollow ugc">comprehensive overview</a>).</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-methodology-4" name="p-49786-methodology-4"></a>Methodology</h2>
<p>In order to get a better understanding of the historical prevalence of multi-block MEV, we decided to look at all slots from the Merge in September ‘22 until May ‘24 (totalling roughly 4.3 million slots) and analyze the corresponding data on validators and builders and on MEV-boost payments (if applicable). The scope was to identify patterns of unusual consecutive slot sequences and accompanying MEV values. <a href="https://mevboost.pics/data.html" rel="noopener nofollow ugc">The data</a> has been kindly provided by Toni Wahrstätter and contains information per slot on relay, builder pubkey, proposer pubkey and MEV-Boost value as well as a builder pubkey and validator pubkey mapping. In the labeling of validators for our purposes staking pool providers such as Lido or Rocket Pool are treated as one entity.</p>
<p>MEV-Boost payments are used as a proxy for the MEV per block. We acknowledge that this is only a non-perfect approximation. The ascending MEV-Boost first-price auction by its nature of being public essentially functions like a second price + 1 wei auction (thanks to Julian for pointing this out!). Hence, we strictly speaking only get an estimate of the intrinsic value of the second highest bidder. However, as [<a href="https://arxiv.org/pdf/2405.01329" rel="noopener nofollow ugc">4</a>] have observed more than 88% of MEV-Boost auctions were competitive and [<a href="https://arxiv.org/pdf/2407.13931" rel="noopener nofollow ugc">5</a>] concluded that the average profit margin per top three builder is between 1% and 5.4%, further indicating a competitive market between the top builders. Based on this, despite the limitations we deem it feasible to use the MEV-Boost payments as an approximation for the generated MEV per block.</p>
<p>To establish a baseline of expected multi-slot sequences, a Monte Carlo simulation was conducted. In this simulation, builders were randomly assigned to each slot within the specified time period, based on their observed daily market share during that period. The frequency of consecutive slots, ranging in length from 1 to 25 (the longest observed sequence in the empirical data), was recorded. This procedure was repeated 100 times, and the average was taken. We decided to use daily market shares for the main analysis as in the investigated time period market shares have strongly shifted [4]. For comparison we also ran the analysis on monthly and overall market shares.</p>
<p>Further, base fee volatility data has been included to cross-check effects of low and high-volatility periods. Previous research (e.g. [<a href="https://arxiv.org/pdf/2305.19150" rel="noopener nofollow ugc">6</a>] &amp; [<a href="https://arxiv.org/pdf/2401.01622" rel="noopener nofollow ugc">7</a>]) has focused on token price volatility effects based on CEX-prices. As we are interested in low- and high-MEV environments, we deem base fee volatility for our use case more fitting, as it is driven by empty or full blocks which are at least partially a result of the prevalence of MEV opportunities.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-empirical-findings-5" name="p-49786-empirical-findings-5"></a>Empirical Findings</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49786-finding-1-fewer-multi-slot-sequences-exist-than-assumed-by-random-distribution-6" name="p-49786-finding-1-fewer-multi-slot-sequences-exist-than-assumed-by-random-distribution-6"></a>Finding 1: Fewer multi-slot sequences exist than assumed by random distribution</h3>
<p><strong></strong></p><div class="lightbox-wrapper"><strong><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/6/b6ab4921507e70c619d5121b5abf611e67e2138f.png" title=""><img alt="" height="426" src="https://ethresear.ch/uploads/default/optimized/3X/b/6/b6ab4921507e70c619d5121b5abf611e67e2138f_2_533x426.png" width="533" /></a></strong></div><br />
<em>Figure 1: Comparison of statistically expected vs. observed multi-slot sequences (note that slots &gt; 25 have been summarized in slot 25 for brevity)</em><p></p>
<p>Firstly, the prevalence of multi-slot sequences with the same builder proposing the block was investigated to determine if they are more common than would be expected by chance.</p>
<p>Comparing the results of the Monte Carlo simulation as a baseline in expected distribution (blue) with the observed distribution (orange), it can be seen that significantly fewer multi-slot sequences occur than expected (Figure 1). The longest observed sequence was 25 slots and the longest sequence with the same validator (Lido) and builder (BeaverBuild) was 11 consecutive slots on March 4th, 2024 (more details with descriptive statistics in the <a href="https://colab.research.google.com/drive/1kKM-da6xP7St8puzPuyn1Ndag6a6wsg3#scrollTo=5bje4mIWzELq" rel="noopener nofollow ugc">notebook</a>). Running the same simulation on monthly or total market shares in the time period, the observation shifts to having more longer sequences than expected, however we attribute this to the statistical effect of changing market shares. A detailed analysis can be run in the <a href="https://colab.research.google.com/drive/1kKM-da6xP7St8puzPuyn1Ndag6a6wsg3#scrollTo=mz4CTqCQInTv" rel="noopener nofollow ugc">notebook</a> or be provided upon request.</p>
<p>In the next step, to understand this in a more-fine-grained manner, the values are compared for each of the top 10 builders based on market shares. Therefore, for each builder, the difference between expected and observed occurrences of multi-slot sequences are plotted with the size of the bubble indicating the delta in Figure 2. The expected occurrences are based on the results of the Monte Carlo simulation. Red bubbles indicate a positive deviation (more observed slots than expected), while blue indicates a negative deviation. Green dots indicate values in line with the expectation. In Figure 2 it is shown in absolute numbers, in the <a href="https://colab.research.google.com/drive/1kKM-da6xP7St8puzPuyn1Ndag6a6wsg3#scrollTo=cd07f078-f646-450c-b610-9e91012111f2&amp;line=3&amp;uniqifier=1" rel="noopener nofollow ugc">notebook</a> it can also be seen on a relative scale.</p>
<p><strong></strong></p><div class="lightbox-wrapper"><strong><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/9/e94454973c4bf844c96e0a1735409a130a0983dd.png" title=""><img alt="" height="419" src="https://ethresear.ch/uploads/default/optimized/3X/e/9/e94454973c4bf844c96e0a1735409a130a0983dd_2_628x419.png" width="628" /></a></strong></div><br />
<em>Image 2: Deviations between expected (Monte Carlo simulation) and observed multi-slot frequencies per builder</em><p></p>
<p>It can be observed in the relative as well as in the absolute deviation that for the top builders there are more single slot sequences than expected with the exception of ETH-Builder, f1b and Blocknative. For multi-slot sequences with two or more slots, almost all top 10 builders have less than expected. This shows that the trend is not limited to singular entities but derives more from the general market structure.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49786-finding-2-payments-for-multi-slot-sequences-are-higher-on-average-than-for-single-slots-7" name="p-49786-finding-2-payments-for-multi-slot-sequences-are-higher-on-average-than-for-single-slots-7"></a>Finding 2: Payments for multi-slot sequences are higher on average than for single slots</h3>
<p>To understand if multi-slot sequences are valuable, we looked into MEV-Boost payments and compared single-slot to multi-slot sequences (Figure 3).</p>
<p><strong><img alt="" height="342" src="https://ethresear.ch/uploads/default/original/3X/b/5/b570ac276a9b9dc76883e6e89489c8792b0186e3.png" width="467" /></strong><br />
<em>Figure 3: Average MEV-Boost payments per Sequence Length</em></p>
<p>It can be observed that in accordance with previous work of [3], we observe higher average MEV payouts for longer consecutive sequences (from about 0.05 ETH for single slot sequences to around 0.08 ETH for sequences with nine consecutive slots). Note that the gray numbers in Figure 3 provide the sample size for each slot length. So it can be observed that the longer the sequence, almost linearly the average MEV-boost payment per slot in the sequence rises. At this stage of the research we can only speculate why this is the case. It could be driven by a higher value in longer consecutive sequences, but also by alternative effects. For example, Julian rightfully pointed out it could also be driven by an increasing intrinsic value for the second highest-bidder due to accumulating MEV in private order flow and the intrinsic valuation of the winning bidder remains constant. Or as Danning suggested, it might be driven by certain types of proprietary order flow (e.g. CEX-DEX arbitrage) being more valuable in certain time periods (e.g. volatile periods) leading to more consecutive sequences as well as higher MEV-Boost payments on average. For a more comprehensive answer and a more in-depth understanding, an analysis on the true block value (builder profits plus proposer payments) and potentially on individual tx level is necessary. We leave this open for future research.</p>
<p>This trend also holds when plotting the average payments for each individual builder. The results on this are shown in the <a href="https://colab.research.google.com/drive/1kKM-da6xP7St8puzPuyn1Ndag6a6wsg3#scrollTo=e673f535-1bad-41aa-b617-fcdeee234f01&amp;line=3&amp;uniqifier=1" rel="noopener nofollow ugc">notebook</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49786-finding-3-per-slot-payments-also-increase-with-longer-sequences-8" name="p-49786-finding-3-per-slot-payments-also-increase-with-longer-sequences-8"></a>Finding 3: Per Slot Payments also increase with longer sequences</h3>
<p>Supplementary to the absolute average payment, we also looked into the payment per slot position in longer sequences (Figure 4). E.g. how much was on average paid for the third position in a longer sequence.</p>
<p><strong><img alt="" height="333" src="https://ethresear.ch/uploads/default/original/3X/3/9/3910c4ca760a17b0ae0a9ec76bb90d27155b5e42.png" width="428" /></strong><br />
<em>Figure 4: Average MEV-Boost payments per Sequence Position</em></p>
<p>Also in the payment per slot analysis a similar trend can be observed, however less prevalent. This suggests that there is slight value in longer sequences, however builders are not willing to bid significantly more for longer consecutive sequences or the first slot after a longer sequence.</p>
<p>This indicates for us that, at least so far, multi-slot strategies are not applied systematically. In this case, we expect builders would need to pay significantly higher values for later slots to ensure to capture the MEV opportunity prepared earlier.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49786-finding-4-low-auto-correlation-between-consecutive-mev-boost-payments-9" name="p-49786-finding-4-low-auto-correlation-between-consecutive-mev-boost-payments-9"></a>Finding 4: Low auto-correlation between consecutive MEV-Boost payments</h3>
<p><strong></strong></p><div class="lightbox-wrapper"><strong><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/d/9db050ae9f5aa540ea6f3c5b6270dee27e111380.png" title=""><img alt="" height="321" src="https://ethresear.ch/uploads/default/optimized/3X/9/d/9db050ae9f5aa540ea6f3c5b6270dee27e111380_2_533x321.png" width="533" /></a></strong></div><br />
<em>Figure 5: Auto-correlation of MEV-Boost Payments</em><p></p>
<p>We examined auto-correlation in the MEV boost payments to understand if historical MEV data allows us to forecast future MEV and to see if there are low- and high-MEV periods (Figure 5).</p>
<p>Overall, it can be observed that within the first few slots the correlation strongly decreases until an offset of 2 to 3 slots (we tested for Pearson Correlation Coefficient, Spearman’s Rank Correlation Coefficient and Kendall’s Rank Correlation Coefficient). Based on this we can conclude that not more than one to three slots in advance the MEV value can be moderately predicted based on historical data.</p>
<p>Further interesting observations can be made. As expected, the Spearman and Kendall correlation coefficients are significantly higher than the Pearson correlation coefficient, underlining that the data is not following a normal distribution but being skewed and having large outliers. Additionally, it is interesting to note that for the Pearson correlation coefficient, the complete data set and the top 50% quantile dataset behave similarly, which is not the case for the Spearman and Kendall coefficients. This might be an indicator that the rank ordering for the lower 50% quantile can be more reliably predicted, further underlying that high MEV values are volatile and spiky, hence difficult to predict.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49786-finding-5-no-indication-of-builder-specialization-on-low-or-high-base-fee-volatility-environment-10" name="p-49786-finding-5-no-indication-of-builder-specialization-on-low-or-high-base-fee-volatility-environment-10"></a>Finding 5: No indication of builder specialization on low- or high base fee volatility environment</h3>
<p>Previous research (e.g. [6] &amp; [7]) has found that certain builders specialize in low- or high token price volatility environments, with volatility being measured on CEX-price changes. Further, [5] observe that different builders have different strategies with some focusing on high-value blocks while others on gaining market share in low-MEV blocks.</p>
<p>Complementary, to determine whether low or high base fee volatility impacts (multi-block) MEV, we analyzed changes in base fee data to identify periods of high volatility. The base fee fluctuations are driven by whether the gas usage in the previous block was below or above the gas target, as defined by <a href="https://eips.ethereum.org/EIPS/eip-1559" rel="noopener nofollow ugc">EIP-1559</a>. To identify high volatility environments, we employed two methods: (i) a more naive approach that calculated price changes per slot, classifying the highest and lowest (negative) 10% of these changes as high volatility periods, with the remaining 80 % of slots being categorized as low volatility. Consequently, high volatility blocks occur following a block with either minimal or significant MEV and/or priority tips. (ii) Secondly, the Garman-Klass volatility [<a href="https://arxiv.org/pdf/0807.3492" rel="noopener nofollow ugc">8</a>] was calculated on an epoch basis, with slots in the top 20% of GK values designated as high volatility. This approach allows us to examine longer periods characterized by minimal or significant MEV and/or priority tips.</p>
<p>Initial correlation analysis shows only a low correlation between low and high volatile periods and the respective builders (<a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V" rel="noopener nofollow ugc">Cramér’s V</a> for the naive approach 0.0664 and for the Garman-Klass 0.0772). This indicates that there seems to be no builder specialization based on the volatility environment of the base fee. So, it can be observed that in contrast to token price volatility for base price volatility there seems to not have a specialization of builders developed (yet). Further research is needed to elaborate on this first finding.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-limitations-11" name="p-49786-limitations-11"></a>Limitations</h2>
<p>The research presented here is intended as an initial exploratory analysis of the data rather than a comprehensive study. It is important to note several limitations that affect the scope and conclusions of this analysis. Firstly, it is limited by the considered data set being publicly available MEV-Boost payments data. This leaves out roughly 10 % of non-MEV-Boost facilitated blocks and it does not reflect potential private off-chain agreements. Additionally, the data was partially incomplete and in other parts contained duplicate information (see the <a href="https://colab.research.google.com/drive/1kKM-da6xP7St8puzPuyn1Ndag6a6wsg3#scrollTo=0d986969-2492-49ac-ad92-8ff78e2a7fe1&amp;line=2&amp;uniqifier=1" rel="noopener nofollow ugc">notebook</a> for details). Further, missed slots have been excluded so far, a more detailed analysis in the future might focus on the particular effects missed slots have on the subsequent MEV. Lastly, as outlined in the methodology section, using MEV-Boost payments is only a proxy for captured MEV and the competitive metric used in [4] is only partially applicable for our use case.</p>
<p>As outlined in section Finding 2 it currently can only be speculated about the causation of the increasing average MEV-Boost payouts. Furthermore, running the analysis on the true block value (proposer payment plus builder profits) might generate further insights and solidify the research findings.</p>
<p>On the frequency analysis, the approach contains somewhat a chicken and egg-problem. The Monte Carlo simulation is run on market shares, while the market shares potentially derive from multi-slot sequences. We see a daily time window as an appropriate balance between precision and the need to filter out isolated effects, although this can be critically challenged.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-conclusions-12" name="p-49786-conclusions-12"></a>Conclusions</h2>
<p>Analyzing block meta-data since the merge, we observe that multi-slot sequences occur less frequently than statistically expected. Further, we observe that the average payments for longer multi-slot sequences increase with the sequence length. Similarly, the payments per slot position in longer sequences also slightly rise. This might indicate that there is generally value in longer consecutive sequences. However, considering the only slight increase in value and the fewer observed multi-slot sequences than expected we so far see no indication of deliberate multi-slot MEV strategies being deployed. Also on individual builder level we currently don’t observe strong deviations from expected distributions. This may also stem from the fact that in the current PBS mechanism, with MEV-Boost operating as a just-in-time (JIT) block auction, creating multi-block MEV opportunities carries inherent risk. This risk arises as creating these opportunities typically requires an upfront investment, and the opportunity might be captured by a competing builder in the next slot, assuming no off-chain collusion between the proposer and builder. This element of risk is a critical factor that could be eliminated by some of the proposed changes to the mechanism (e.g. some APS designs), making it an essential consideration when defining future mechanisms.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49786-references-13" name="p-49786-references-13"></a>References</h2>
<p>[1] Babel K, Daian P, Kelkar M, Juels A. Clockwork finance: Automated analysis of economic security in smart contracts. <em>In 2023 IEEE Symposium on Security and Privacy (SP)</em> 2023 May 21 (pp. 2499-2516). IEEE.</p>
<p>[2] Mackinga T, Nadahalli T, Wattenhofer R. Twap oracle attacks: Easier done than said?. <em>In 2022 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)</em> 2022 May 2 (pp. 1-8). IEEE.</p>
<p>[3] Jensen JR, von Wachter V, Ross O. Multi-block MEV. arXiv preprint arXiv:2303.04430. 2023 Mar 8.</p>
<p>[4] Yang S, Nayak K, Zhang F. Decentralization of Ethereum’s Builder Market. arXiv preprint arXiv:2405.01329. 2024 May 2.</p>
<p>[5] Öz B, Sui D, Thiery T, Matthes F. Who Wins Ethereum Block Building Auctions and Why?. arXiv preprint arXiv:2407.13931. 2024 Jul 18.</p>
<p>[6] Gupta T, Pai MM, Resnick M. The centralizing effects of private order flow on proposer-builder separation. arXiv preprint arXiv:2305.19150. 2023 May 30.</p>
<p>[7] Heimbach L, Pahari V, Schertenleib E. Non-atomic arbitrage in decentralized finance. arXiv preprint arXiv:2401.01622. 2024 Jan 3.</p>
<p>[8] Meilijson I. The Garman-Klass volatility estimator revisited. arXiv preprint arXiv:0807.3492. 2008 Jul 22.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/does-multi-block-mev-exist-analysis-of-2-years-of-mev-data/20345">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 10:31:36 +0000</pubDate>
</item>
<item>
<title>An Automatic Technique to Detect Storage Collisions and Vulnerabilities within Solidity Smart Contract</title>
<link>https://ethresear.ch/t/an-automatic-technique-to-detect-storage-collisions-and-vulnerabilities-within-solidity-smart-contract/20328</link>
<guid>https://ethresear.ch/t/an-automatic-technique-to-detect-storage-collisions-and-vulnerabilities-within-solidity-smart-contract/20328</guid>
<content:encoded><![CDATA[
<div> 关键词：存储碰撞、漏洞检测、Solidity智能合约、静态分析、Ethereum网络

总结:

本文提出了一种改进的、全面的技术，旨在检测Ethereum Solidity智能合约中的存储漏洞和碰撞。该技术基于高级静态分析方法，目标是识别部署在以太坊网络上的智能合约中的存储碰撞问题，尤其是复杂的代理合约，如ERC-2535（钻石/多面体代理）、ERC-1822、升级代理模式等。相比于现有技术仅通过合约字节码检测存储碰撞，本文方法利用源代码进行准确分析，同时考虑动态数组、映射变量及复杂嵌套结构的存储布局。

文中通过示例展示了存储碰撞可能导致的问题，即在合同升级后，原本不同数据类型的变量由于存储槽位重叠而发生数据错乱。为解决此问题，作者计划开发一套自动化工具，自动检测智能合约中的所有状态变量并计算其存储槽位布局。此外，工具将扩展功能，精确分析复杂变量及其元素的存储槽位，以及映射变量的键值预测，以提高检测精度和覆盖范围。最终，将实现一个碰撞检测器，能识别任何类型的状态变量及其关联变量或值的潜在碰撞或冲突。

通过此解决方案，开发者可以在部署前确保智能合约无存储碰撞风险，同时帮助检测已部署合约中深层存储的碰撞问题，保护价值数百万美元的资产免受攻击。 <div>
<p>Storage collisions and vulnerabilities within Ethereum smart contracts can lead to unexpected issues like freezing funds, escalating privileges, and financial asset theft. A storage collision occurs when two different storage structs unintentionally use same storage slot(s), or the slot layout is changed during the upgrade of implementation contract. These collision vulnerabilities have been detected in large numbers (worth millions of dollars) in a <a href="https://www.ndss-symposium.org/ndss-paper/not-your-type-detecting-storage-collision-vulnerabilities-in-ethereum-smart-contracts/" rel="noopener nofollow ugc">recent study</a> within smart contracts deployed on the Ethereum network.</p>
<p>In this topic, we propose a more accurate and complete technique to detect storage vulnerabilities and collisions in Solidity smart contracts. And encourage the Ethereum community to <strong>provide feedback on the proposed technique</strong>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49742-introduction-1" name="p-49742-introduction-1"></a>Introduction</h3>
<p>We are working on a solution based on advanced static analysis techniques that can identify vulnerabilities within the deep storage of Ethereum Solidity smart contracts. We aim to detect storage collisions in proxy contracts deployed on the Ethereum network like ERC-2535 (Diamond/Multi-Facet Proxy), ERC-1822, upgrade proxy pattern, etc., as complex proxy contracts are more likely to experience a storage collision, like during the upgrade of implementation or facet contracts.</p>
<p><a href="https://www.ndss-symposium.org/ndss-paper/not-your-type-detecting-storage-collision-vulnerabilities-in-ethereum-smart-contracts/" rel="noopener nofollow ugc">N. Ruaro et al.</a> analyzed Ethereum contracts using contract bytecode to detect storage collisions and reported 14,891 vulnerable contracts. Their technique was able to identify storage slot types correctly with an accuracy of 87.3%. Whereas, we aim to build a solution that will use source code to accurately analyze the storage layout and slot types of the contract. Furthermore, we will also analyze dynamic arrays, mapping variables, and complex nested structs in our analysis.</p>
<p>Suppose a collision occurs on the state variables’ base slots, our approach will allow us to identify the impact of the collision on dynamic arrays and mapping variables declared consecutively, and arrays data type or mappings key types are same which is a common practice in large contracts like gaming contracts.</p>
<p>As shown in the below example code, the slot layout was changed during the contract upgrade, and since <code>token_uris</code> and <code>token_version</code> have same key types and data types, both variables will return each other’s data after the upgrade due to collision.</p>
<pre><code class="lang-auto">library ImplementationStorage1 {
    struct AddressSlot {
        address owner; // slot n+0
        mapping(uint256 =&gt; string) token_uris; // slot n+1
        mapping(uint256 =&gt; string) token_versions; // slot n+2
    }

    function getAddressSlot(bytes32 slot) internal pure returns (AddressSlot storage r) {
        assembly {
            r.slot := slot
        }
    }
}

// updated code
library ImplementationStorage2 {
    struct AddressSlot {
        address owner; //slot n+0
        mapping(uint256 =&gt; string) token_versions; // slot n+1 (shld be token_uris)
        mapping(uint256 =&gt; string) token_uris; // slot n+2 (shld be token_versions)
    }

    function getAddressSlot(bytes32 slot) internal pure returns (AddressSlot storage r) {
        assembly {
            r.slot := slot
        }
    }
}
</code></pre>
<p><code>token_uris</code> accessing <code>token_versions</code> and vice-versa after the upgrade.</p>
<pre><code class="lang-auto">       (before upgrade)                        (after upgrade)   
      _________________                      _________________
     |     Proxy       |                     |     Proxy       |
     |_________________|                     |_________________|
     | * IMPLEMENT_SLOT| --&gt; NFTManager1     | * IMPLEMENT_SLOT| --&gt; NFTManager2
     | * ADMIN_SLOT    |                     | * ADMIN_SLOT    |
     |_________________|                     |_________________|
     | + upgradeTo()   |                     | + upgradeTo()   |
     | + changeAdmin() |                     | + changeAdmin() |
     |_________________|                     |_________________|
              |                                       |
              v                                       v
      _________________                       _________________
     |   NFTManager1   |                     |   NFTManager2   |
     |_________________|                     |_________________|
     | - owner         |                     | - owner         |
     | - token_uris    | **** collision **** | - token_versions|
     | - token_versions| **** collision **** | - token_uris    |
     |_________________|                     |_________________|

</code></pre>
<p>We plan to build a technology that will automatically detect all storage collisions within a Solidity smart contract.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49742-methodology-2" name="p-49742-methodology-2"></a>Methodology</h4>
<p>We have structured our development plan into three distinct phases, outlined as follows:</p>
<ul>
<li><strong><strong>Automatic State Variable Detector and Slot Layout Calculator</strong></strong></li>
</ul>
<p>In this phase, we focus on developing an automatic state variable detector and slot layout calculator. This component will facilitate the identification of state variables within smart contracts and determine their corresponding slot layout. By automating this process, we aim to streamline the initial analysis procedures.</p>
<p>Sample output of Slot Calculator</p>
<pre><code class="lang-auto">slot 0 - mapping ds.selectorToFacetAndPosition[bytes4] = FacetAddressAndPosition;
slot 1 - mapping ds.facetFunctionSelectors[address] = FacetFunctionSelectors;
slot 2 - address [] ds.facetAddresses;
slot 3 - mapping ds.supportedInterfaces[bytes4] = bool;
slot 4 - address ds.contractOwner;
slot 5 - mapping ds.tempSelectorsNested[uint256] = FacetAddressAndPosition;
slot 6 - FacetAddressAndPosition [] ds.FacetAddressAndPositionArray;
slot 7 - mapping ds.tempMapping[uint256] = uint256;
slot 8 - mapping ds.tempMapping2[address] = uint256;
</code></pre>
<ul>
<li><strong><strong>Mapping Keys Analyzer and Slot Calculator of Complex Variables</strong></strong></li>
</ul>
<p>Building upon the foundation established in phase 1, in this phase we will first extend the slot calculator capability to calculate the slots of complex variables and their entries (for all data types) i.e. slots of mapping keys, dynamic array, complex struct, mappings with complex struct as value.</p>
<p>This component will also include the approximation of all keys used in mapping variables for saving data using advanced static analysis techniques. By accurately approximating keys and calculating entries, we seek to enhance the precision and breadth of storage slot calculation methodology, which will help detect storage collision within deep storage data of a smart contract.</p>
<ul>
<li><strong><strong>Collision Detector for State Variables and Complex Variables All Entries Slots</strong></strong></li>
</ul>
<p>The final phase of our methodology focuses on implementing a collision detector for both state variables and complex variable slots. This critical component will identify any potential collisions or conflicts within any type of state variables and their associated variable(s)/value(s) slots. By detecting and addressing collisions, we aim to ensure the integrity and reliability of smart contracts.</p>
<p>We aim to develop a robust and comprehensive methodology for smart contract storage collision detectors, by systematically progressing through above discussed three development phases.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49742-conclusion-3" name="p-49742-conclusion-3"></a>Conclusion</h4>
<p>The development of our solution will allow developers to ensure that their contract has no potential storage collisions before deployment. It will also be able to detect storage collisions within deep storage of deployed smart contracts and can help in securing contracts worth millions of dollars.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/an-automatic-technique-to-detect-storage-collisions-and-vulnerabilities-within-solidity-smart-contract/20328">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 23 Aug 2024 09:35:11 +0000</pubDate>
</item>
<item>
<title>A Note on Equivocation in Slot Auction ePBS</title>
<link>https://ethresear.ch/t/a-note-on-equivocation-in-slot-auction-epbs/20331</link>
<guid>https://ethresear.ch/t/a-note-on-equivocation-in-slot-auction-epbs/20331</guid>
<content:encoded><![CDATA[
<div> 关键词：槽拍卖、ePBS、分叉选择安全性、构建者欺骗、执行数据可用性

总结:
这篇文章探讨了在以太坊并行区块链系统(ePBS)中实现槽拍卖的潜在问题和解决方案。主要关注点在于分叉选择安全性和构建者欺骗。

1. **槽拍卖与ePBS**: 在槽拍卖中，信标提案者承诺特定构建者，该构建者将在适当时间提交执行负载。这与区块拍卖不同，后者要求提案者承诺执行负载哈希。构建者可能通过提交多个负载来欺骗系统，即构建者欺骗。

2. **构建者欺骗的影响**: 构建者欺骗可能导致分叉选择不安全，因为这可能导致不确定的执行负载被纳入链中。文章提出两种草稿方案来解决这个问题。

3. **草稿方案1：投票执行负载哈希**:
   - 提案涉及将“PAYLOAD_PRESENT”替换为“执行负载哈希”，并在没有达到共识的情况下，让诚实的下一轮验证者使用空块作为头部。
   - 这种方法确保了诚实构建者的构建安全，但可能引发免费数据可用性问题。

4. **草稿方案2：假装负载不存在**:
   - 如果下一轮提议者观察到至少两个冲突的负载，那么它会忽略任何空或满块的分叉选择权重。
   - 这种方法避免了数据可用性问题，但也可能使构建者更容易进行游戏。

5. **结论与进一步研究**:
   - 这两种草稿方案都试图在槽拍卖中保持与区块拍卖相同的分叉选择安全性，尽管它们各有优缺点。
   - 文章鼓励有兴趣的参与者继续探索同时解决这两个问题的设计。 <div>
<p><em>Thanks to Francesco D’Amato, Barnabé Monnot, Mike Neuder, and Thomas Thiery for feedback and review. Thanks again to Francesco for coming up with the second proposal.</em></p>
<p>Whether we want to implement slot auctions into ePBS is an <a href="https://www.notion.so/Arguments-in-Favor-and-Against-Slot-Auctions-in-ePBS-c7acde3ff21b4a22a3d41ac4cf4c75d6?pvs=21" rel="noopener nofollow ugc">active discussion area</a>, and support for slot auctions was signaled in the <a href="https://youtu.be/fQx_UbaPX-E?si=C8ALtI4zOSmFjRpN" rel="noopener nofollow ugc">seventh ePBS breakout call</a>. Currently, the ecosystem lacks knowledge about the fork choice safety of slot auctions in the <a href="https://ethereum-magicians.org/t/eip-7732-enshrined-proposer-builder-separation-epbs/19634" rel="noopener nofollow ugc">current ePBS proposal</a>. This note presents two strawman proposals to start discussing the forkchoice safety of slot auction ePBS.</p>
<p>This note presupposes the reader is familiar with the ePBS proposal (<a href="https://ethereum-magicians.org/t/eip-7732-enshrined-proposer-builder-separation-epbs/19634" rel="noopener nofollow ugc">EIP-7732</a>).  An essential part of this EIP is that a <em>payload boost</em> is applied to a beacon block if the <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054#proposer-initiated-splitting-18">Payload-timeliness committee (PTC)</a> reaches a quorum. If an execution payload is seen on time by a majority of the PTC, the beacon block that corresponds to the execution payload receives additional fork-choice weight (Reveal Boost). If the PTC observes a timely message from the builder stating that it withholds its payload, the additional fork-choice weight is given to the parent block of the beacon block corresponding with the withhold message (Withholding Boost).</p>
<p>In <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">slot auction</a> ePBS, the beacon proposer does not commit to an execution payload hash, unlike in block auction ePBS. Instead, it commits to a specific builder that can submit an execution payload when it is time to reveal. The first problem is that a builder could submit multiple execution payloads. In this note, we will refer to this as a builder equivocation.</p>
<p>In block auction ePBS, something similar to equivocation is possible. The builder could wait for at least one PTC member to vote <code>PAYLOAD_ABSENT</code> and then release a withhold message and an execution payload to split the PTC’s view such that none of the three vote options (<code>PAYLOAD_ABSENT</code>, <code>PAYLOAD_WITHHELD</code>, <code>PAYLOAD_PRESENT</code>) reaches the <a href="https://discord.com/channels/595666850260713488/874767108809031740/1272916231250382939" rel="noopener nofollow ugc">quorum of 50%</a> of the votes.</p>
<p>In block auction ePBS, this equivocation does not benefit the builder much. If the PTC does not reach a quorum, no payload boost is applied, and the honest next-slot validator will take the payload as head. If the builder equivocates, the protocol does not need to guarantee Builder Reveal Safety since the builder does not act as the protocol expects. Still, the builder does not have the flexibility to submit a different execution payload since the beacon block commits to the execution payload hash.</p>
<p>It could be that the builder is incentivized to play a <a href="https://arxiv.org/abs/2305.09032" rel="noopener nofollow ugc">timing game</a> and eventually decides that it is best if the block were withheld. The builder could submit a withhold message and see if the PTC will reach a quorum on <code>PAYLOAD_WITHHELD</code>. If the PTC does not seem to do so, and the PTC also has not yet reached a quorum on <code>PAYLOAD_ABSENT</code>, the builder reveals its payload after all. This attack seems difficult to pull off, but it allows the builder to check whether it can renege on its promised payment to the proposer while still landing its payload on-chain if it has to pay (assuming an honest next-slot proposer).</p>
<p>In slot auction ePBS, a builder may be more incentivized to equivocate because it can change the contents of its execution payload. For example, the builder could broadcast a particular execution payload, but a short time later, a significant MEV opportunity appears, and the builder now wants to broadcast a new execution payload.</p>
<p>Preventing equivocations in slot auction ePBS would be desirable because equivocations would cause insecurity in fork choice. Specifically, we want to obtain the following properties with minimal changes.</p>
<blockquote>
<p><img alt=":bulb:" class="emoji only-emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /><strong>Desiderata</strong></p>
<ol>
<li>If the builder reveals precisely one timely execution payload, it should retain the same Builder Reveal Safety guarantees as in block auction eBPS</li>
<li>If the builder reveals multiple timely and equivocating execution payloads,<br />
a. no execution payload should go on-chain,<br />
b. but the Unconditional Payment should be as strong as in block auction ePBS</li>
</ol>
</blockquote>
<p>Should slashing or a penalty be applied to equivocating execution payload messages? This question is relevant to block and slot auction ePBS, although the potential benefits of equivocation are likely to be higher in slot auction ePBS. Since ePBS still allows local block construction, it seems unwise to apply harsh slashing or penalties if there is equivocation because this may disincentivize local block construction. Moreover, since it is not clear that there are significant gains to be made from equivocating execution payloads, and if gains are to be made, slashing or penalties do not qualitatively change this, so slashing or penalties are not immediately necessary.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49750-proposal-1-vote-for-execution-payload-hash-1" name="p-49750-proposal-1-vote-for-execution-payload-hash-1"></a>Proposal 1: Vote for Execution Payload Hash</h2>
<p>The first strawman proposal to obtain these properties involves changing the block auction ePBS fork-choice specification as follows.</p>
<blockquote>
<p><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> <strong>Proposal 1: Vote for Execution Payload Hash</strong></p>
<ol>
<li>Replace <code>PAYLOAD_PRESENT</code> with <code>execution_payload_hash</code></li>
<li>If no PTC quorum is reached, let the honest next-slot validator use an empty block as its head instead of a full block.</li>
</ol>
</blockquote>
<p>A PTC member would now vote for the <code>execution_payload_hash</code> it has observed instead of simply voting whether a payload is present. Reveal boost is applied if a quorum is reached on <code>execution_payload_hash</code>. Intuitively, this is necessary for slot auctions since the PTC now indicates which execution payload should be used if the block is full and not just that the block is full.</p>
<p>It seems like desideratum 1—the same Builder Reveal Safety as in block auction ePBS—is immediately satisfied since an honest builder does not release equivocating execution payloads. A PTC member’s <code>execution_payload_hash</code> vote functions the same as a <code>PAYLOAD_PRESENT</code> vote.</p>
<p>If the builder equivocates but the PTC still reaches a quorum on <code>execution_payload_hash</code>, then the execution payload will make it on-chain in the same way a payload would have made it on-chain if the builder did not equivocate. I believe this is fine because the builder released an equivocating payload that did not split the view of the PTC (sufficiently). This indicates that this equivocating payload is a minor threat to the fork-choice security. Although this outcome contradicts desideratum 2a, the timely requirement in desideratum 2 should be read as the execution payload intends to split the view of the PTC sufficiently.</p>
<p>If the builder equivocates and the PTC does not reach a quorum, then the next-slot honest proposer should see an empty block as its head. The builder loses some of its Builder Reveal Safety because it could be that the builder reveals only one payload (does not equivocate), yet the PTC does not reach a quorum. However, Builder Reveal Safety is not very strong in block auction ePBS either because a next-slot rational proposer would prefer to build on an empty block than a full block since these are more valuable (the ex-post reorg safety is low if reveal boost is not applied). Changing the default next-slot honest proposer behavior from seeing a full block to an empty block as its head does not change much in Builder Reveal Safety, and the system then satisfies desideratum 2.</p>
<p>What if the next-slot proposer is dishonest? The builder could collude with the next-slot proposer and broadcast messages such that the PTC does not reach a quorum and include an execution payload late. This is similar to the attack in block auction eBPS, where a builder tries to get Withhold Boost to apply but releases an execution payload if it does not succeed. The builder and next-slot proposer collusion allows the builder to play aggressive timing games while ensuring Builder Reveal Safety. These timing games come at the expense of the execution validation time of the attesting committee. It is not immediately apparent what this attack would gain for the builder and next-slot proposer collusion since the builder timing game gain comes almost entirely from the next-slot proposer’s revenues.</p>
<p>The downside of this proposal is the problem of free data availability. The PTC could now reach a quorum on an <code>execution_payload_hash</code>. These PTC votes would end up on-chain, and an adversary could use them to show that a piece of data was available to the PTC. Yet the adversary would not have to pay the base fee needed to provide the data on-chain; it only has to pay the proposer to commit to the adversary as the builder.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49750-proposal-2-pretend-payload-absent-2" name="p-49750-proposal-2-pretend-payload-absent-2"></a>Proposal 2: Pretend Payload Absent</h2>
<p>The second strawman proposal does not suffer from the free data availability problem and achieves the desiderata as follows.</p>
<blockquote>
<p><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> <strong>Proposal 2: Pretend Payload Absent</strong><br />
If the next-slot proposer/attesters observe(s) at least two equivocating payloads, it/they assign(s) no additional fork-choice weight to any empty or full block</p>
</blockquote>
<p>The behavior of a PTC member does not change from the block auction ePBS specification. However, suppose a proposer sees that the block producer in the previous slot released equivocating execution payloads. In that case, it ignores the fork-choice weight the PTC may have given to any fork.</p>
<p>If the builder is honest, this does not change its Builder Reveal Safety since the system works exactly as it does in block auction ePBS. Desideratum 1 is thus immediately satisfied.</p>
<p>If the builder equivocates, an honest-but-rational proposer will choose to build on an empty block since it allows the proposer to extract the MEV from two slots of time instead of one. The attesters will not object to this since they observed the equivocating payloads and assigned no additional fork-choice weight to any forks. Therefore, if the next-slot proposer and attesters are honest, desideratum 2 is also satisfied.</p>
<p>The next-slot proposer could collude with the builder. The builder could equivocate, and the next-slot proposer could choose to build on a full block. Similarly to the collusion situation described in the first proposal, though, the gain that a builder gets from this equivocation seems to primarily come from the profits the next-slot proposer could make. It is not clear that the joint utility of the collusion increases by enough to justify the collusion.</p>
<p>A builder and a next-slot proposer could collude to ensure an execution payload does not become canonical. Consider a builder that submits an execution payload, and the PTC reaches a quorum on whether this payload is timely. Later, the builder regrets the contents of its execution payload and aims to remove it from the canonical chain. It could then release an equivocation payload so the next-slot proposer will not build on the undesirable execution payload. This is similar to a builder not revealing its block in block auction ePBS.</p>
<p>In conclusion, these strawman proposals seem to achieve the same fork-choice safety under slot auctions as under block auctions with minimal changes. While the first proposal has a problem with free data availability, the second proposal may be more susceptible to builder games, such as reorging its execution payload. The lack of free data availability and being less susceptible to builder games are advantages of slot auctions in ePBS. Further research on a design that simultaneously solves both problems would be very valuable. If you are interested in working on (slot auctions in) ePBS, please see this <a href="https://www.notion.so/ePBS-EIP-7732-tracker-9f85f7b086994bd79192bc72bae703a1?pvs=21" rel="noopener nofollow ugc">page</a>!</p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/a-note-on-equivocation-in-slot-auction-epbs/20331">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 23 Aug 2024 16:52:02 +0000</pubDate>
</item>
<item>
<title>The Role of the P2P Market in ePBS</title>
<link>https://ethresear.ch/t/the-role-of-the-p2p-market-in-epbs/20330</link>
<guid>https://ethresear.ch/t/the-role-of-the-p2p-market-in-epbs/20330</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、两层市场、P2P市场、可信中立性、价值反映

总结:

文章探讨了以太坊并行区块系统(ePBS)中的两层市场结构及其对生态系统的影响。ePBS采用了一种双层拍卖机制，其中大型区块构建者倾向于使用直接连接的点对点(P2P)市场，而小型构建者则依赖于更传统的P2P市场。文章重点讨论了P2P市场在可信中立性中的作用和价值反映能力。

1. **P2P市场的角色与价值**：P2P市场允许任何人设定底价，有助于发现市场中潜在的高价值区块构建者，尤其是在可信中立性方面。它通过允许提案者与构建者直接互动，减少了对第三方的信任依赖，同时提高了构建者参与度，特别是对于那些不经常参与拍卖的小型构建者。

2. **价值反映的挑战**：尽管P2P市场在信任无虞方面表现出色，但其在价值反映方面的表现较差。由于网络需要抵御分布式拒绝服务(DOS)攻击，因此无法处理大量投标，导致构建者可能需要策略性地进行投标，早期投标不能被取消，这可能影响市场效率。

3. **替代方案：bid curation relay**：文章提出了一种名为“bid curation relay”的外部解决方案，该方案允许提案者连接到具有高信誉的节点，以发现潜在的构建者。这种模式下，信任要求较低，且能提供更好的价值反映，通过允许频繁投标、投标取消等功能，提高市场效率。

4. **可信中立性的重要性**：可信中立性是指确保分配执行负载构建权利的实体是基于最高估值的构建者。P2P市场或bid curation relay等机制的存在有助于实现这一目标，通过促进构建者的多样性和高效匹配，确保提案者能够公平地选择最有价值的构建者。

5. **实施与未来工作**：尽管P2P市场存在一些局限性，但其易于实施且无需硬叉，允许客户端自由迭代。因此，从实用性和未来潜在的MEV-Burn优化角度来看，实施P2P市场是一个有益的决策。进一步的工作可以细化P2P市场的规则，并探索构建者RPC端点的链上注册机制，以优化其功能和效率。

通过上述分析，可以看出P2P市场在ePBS中扮演着关键角色，旨在增强可信中立性、促进价值发现与提高市场效率。尽管面临挑战，通过适当的机制设计和优化，P2P市场可以为以太坊生态系统带来显著益处。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/1/d178209b1bebdec57cfa0665bfacea6970512e8c.jpeg" title="role_of_p2p"><img alt="role_of_p2p" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/d/1/d178209b1bebdec57cfa0665bfacea6970512e8c_2_690x389.jpeg" width="690" /></a></div><br />
<em>A two-tier auction market: the right resembles the less sophisticated publicly observable P2P market, and the left resembles the more sophisticated private RPC market.</em><p></p>
<p><em>Thanks to Potuz, Barnabé Monnot, Terence Tsao, and Thomas Thiery for comments and discussion.</em></p>
<p>The current ePBS proposal, <a href="https://eips.ethereum.org/EIPS/eip-7732" rel="noopener nofollow ugc">EIP-7732</a>, suggests operating a two-tier market where builders can bid to obtain the execution payload construction rights. Large block builders are expected to use the pull-based direct connection market. This market allows for lower latency and more flexibility for the builder, as the builder only needs to commit to its bid once the proposer asks for it. This market, however, requires the proposer to connect to the builder’s RPC and actively pull bid(s) from it. Smaller builders who lack this connectivity with the validator set can use the push-based P2P market. This market has stricter rules for what bidders can do but does not need the proposer to pull bid(s) from it since bids are pushed to the proposer.</p>
<p>This note explores the role of the P2P market in ePBS. Although there has been some <a href="https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129">initial</a> <a href="https://hackmd.io/@potuz/HyhN0Nt9A" rel="noopener nofollow ugc">exploration</a> on the topic, this note presents a clear counterfactual of a world where the P2P market were not included in EIP-7732. This note also emphasizes <a href="https://collective.flashbots.net/t/tee-boost/3741/5" rel="noopener nofollow ugc">multiplexing</a>—the ability of proposers to discover builders—as the most important aspect of the P2P market.</p>
<p>The three arguments in favor of the P2P market that the author has seen in previous work are: 1) it allows anyone to set a floor price for the auction, 2) it can be used for MEV-Burn in future protocol upgrades, and 3) it lowers entry barriers for new entrants or long-tail builders.</p>
<p>The first argument is that allowing anyone to bid via the publicly observable P2P market gives all validators the ability to set a floor price for the auction. Validators can bid based on the block that they could locally build. Builders must then bid at least above the bid of these validators to obtain the execution payload construction rights. It has been argued that this is valuable if a cartel of builders intends to keep bids low. The floor price, however, would not break up a cartel. Although proposers would make slightly more revenue in this case, it is unclear what the value of such a floor price is to the protocol.</p>
<p>The beacon proposer selling the rights may be the ideal party to set a reserve price. As I argue in <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/8aCbi_a-Gh5DWnkJWstm8zA5fvtoQB-QR5we7C8XC90" rel="noopener nofollow ugc">this post</a>, a proposer may want to put a higher reserve price than its valuation for the execution payload construction rights to attract higher bids from builders. The P2P market allows the proposer to signal its reserve price to the market. In this sense, the P2P market allows the validator and other participants to express their preferences.</p>
<p>The second argument states that the P2P market may facilitate <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV-Burn</a> in future protocol upgrades. MEV-Burn aims to decouple the rewards from selling execution payload construction rights from being a validator. This has numerous benefits; for example, it decreases the value of using a staking service provider (SSP) since MEV-Burn decreases the variance of validator payoffs. MEV-Burn requires that builder bids be legible to the protocol. Most designs achieve this by having a committee that observes the best available bids. If ePBS would only have the direct connection market, the MEV-Burn designs need to be revisited since a proposer selling the execution rights is incentivized to understate the amount that will be burnt. Still, the P2P market is expected to only reflect a small portion of the value of the execution payload construction rights, hence even ePBS with the P2P market may not be satisfactory for an effective MEV-Burn solution.</p>
<p>The last reason for the P2P market is that it would allow builders from which proposers are unlikely to pull bids to still compete in the market. Proposers may be unlikely to pull bids from builders that infrequently participate in the auction because they are very specialized or from new builders unknown to the proposer. This could be because proposers have an outdated whitelist of builders from which to pull bids. Allowing these proposers to participate in the push-based P2P market will result in more builder diversity in block construction, which may benefit the protocol.</p>
<p>This last reason is what we will explore in this post. Specifically, what does the Ethereum ecosystem gain by enshrining the push-based P2P market aside from an out-of-protocol solution that facilitates small builders’ participation in the market?</p>
<p>Shea Ketsdever recently released a post on <a href="https://collective.flashbots.net/t/tee-boost/3741" rel="noopener nofollow ugc">TEE-Boost</a>, an adaptation of MEV-Boost that uses Trusted Execution Environments. In this post, she highlights the different roles a relay plays. One of the roles is multiplexing, allowing proposers to discover builders who may want to participate in the auction.</p>
<p>The ePBS P2P market aims to achieve multiplexing. In the context of ePBS, multiplexing has at least two facets: trustlessness and value reflection. Trustlessness is important because ePBS removes the trust that proposers and builders must place in a relay to facilitate the fair exchange. Value reflection is essential because a multiplexing tool that poorly reflects the value bidders assign to the auctioned item will not efficiently match an auctioneer with the correct bidder.</p>
<p>The ePBS P2P market scores very well on the trustlessness front. Neither a proposer nor a builder must trust anyone since bids are broadcast via the P2P network, and the winning bid is committed to on-chain. The P2P market, however, scores poorly on the value reflection front. Since the P2P network must be DOS resistant, it cannot handle too many bids, so bidders will likely not be allowed to bid as often as they could in MEV-Boost, meaning they have to be strategic about when they bid. Moreover, early bids will not be able to be canceled, which could lead to strategic builders only winning via the P2P market if the valuation of other builders that operate via the direct connection market has decreased (<a href="https://www.youtube.com/watch?v=-PXGPFFneMI" rel="noopener nofollow ugc">adverse selection</a>). Finally, the value reflection of the P2P market relative to the RPC market will worsen as the RPC market becomes more sophisticated while the P2P market becomes stale.</p>
<p>How would an out-of-protocol actor facilitate multiplexing if ePBS were deployed? In MEV-Boost, relays facilitate multiplexing because submitting blocks to relays is (largely) permissionless, and relays are well-connected to validators. In ePBS, a relay - from no one referred to as a bid curation relay - would look different. A bid curation relay could open an RPC endpoint that proposers connect to and host an auction where builders submit bids, like in MEV-Boost. Bids, however, do not need to contain transaction data since the bid curation relay would not be responsible for the fair exchange problem that is solved via ePBS. Bids in ePBS are a bid value and the hash of the execution payload. A proposer then pulls the highest bid from the bid curation relay and, if it so desires, commits to the highest bid via the in-protocol ePBS system. A winning builder then sees this in-protocol commitment and publishes the block via ePBS.</p>
<p>It becomes clear that the trust assumptions that proposers and builders must place in a bid curation relay are vastly lower than in MEV-Boost. Essentially, the proposer and builders must trust the bid curation relay to forward the highest-paying bid when the proposer asks for it. The bid curation relay is not trusted with the block contents (<a href="https://collective.flashbots.net/t/tee-boost/3741" rel="noopener nofollow ugc">builder privacy</a> is preserved) and is not responsible for unconditional payment (<a href="https://collective.flashbots.net/t/tee-boost/3741" rel="noopener nofollow ugc">data availability and validation</a> are enforced via the protocol).</p>
<p>The ePBS relay scores worse on the trustlessness front than the P2P market since the proposer and builders must trust the relay not to censor its bids. On the other hand, the value reflection of such a bid curation relay could be far better. The relay could offer bid cancellations and high-frequency bidding to builders. Moreover, relays could invest in latency reductions and charge for this, as some do in MEV-boost. If a relay successfully reduces latency, more prominent builders may connect to it. This means the value reflection of relays relative to directly connected builders may remain stable or improve over time.</p>
<p><a href="https://collective.flashbots.net/t/tee-boost/3741/5?u=julian" rel="noopener nofollow ugc">Shea also highlights</a> another option that has been discussed widely before: next to the P2P market; there could be an on-chain registry of builders. There could be a smart contract that any builder could write its RPC endpoint to. Any validator could then see the available RPC endpoints and pull bids from it during its slot. This alternative scores well on the trustlessness front since no trust is required, and it scores well on the value reflection point since it allows all builders to compete on a similar level. The proposer could pull from this registry every time it is supposed to propose a block.</p>
<p>Why do we care about multiplexing? Multiplexing contributes to the credible neutrality of the network. In the context of ePBS, credible neutrality may mean something like this: the builder with the highest valuation for the execution payload construction rights is allocated these rights. If proposers were to rely solely on directly connected builders, some long-tail builders who happened to have an exceptionally high value for a specific block might be excluded. If proposers rely on bid curation relays, they may not forward the highest-paying bid because they prefer to forward another bid for whatever reason. If proposers rely on an on-chain registry of builders, it may not connect to the newer or smaller builders.</p>
<p>Allowing multiplexing to contribute to credible neutrality is a trade-off between trustlessness and value reflection. If a completely trustless market is so poor at value reflection that it never surfaces a winning bid, it does not contribute much to credible neutrality. If a perfectly value-reflecting market puts a lot of trust in one party, the benefit of credible neutrality is also nonexistent.</p>
<p>To conclude, the P2P market is easy to implement, and its maintenance does not require a hard fork so clients can iterate freely. Although the P2P market only contributes a little to the core functionality of ePBS, there are virtually no downsides to implementing it, and it is a nice feature that may benefit some users and could be beneficial for proposers as it increases their revenues and may be helpful for MEV-Burn in the future. Further work could specify the P2P market rules and how an on-chain registry of builder RPC endpoints could work.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/the-role-of-the-p2p-market-in-epbs/20330">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 23 Aug 2024 16:01:14 +0000</pubDate>
</item>
<item>
<title>[Feedback Needed] A technique to Automatically Detect Storage Collisions and Vulnerabilities within Solidity Smart Contract</title>
<link>https://ethresear.ch/t/feedback-needed-a-technique-to-automatically-detect-storage-collisions-and-vulnerabilities-within-solidity-smart-contract/20328</link>
<guid>https://ethresear.ch/t/feedback-needed-a-technique-to-automatically-detect-storage-collisions-and-vulnerabilities-within-solidity-smart-contract/20328</guid>
<content:encoded><![CDATA[
<div> 关键词：存储碰撞、漏洞检测、Solidity智能合约、静态分析技术、安全性提升

总结：

本文提出了一种基于高级静态分析技术的解决方案，旨在检测Ethereum Solidity智能合约中的存储漏洞和碰撞。与先前研究使用合约字节码来检测存储碰撞不同，本方案将采用源代码来准确分析合约的存储布局和槽类型。该方法不仅识别存储碰撞，还考虑动态数组、映射变量以及复杂嵌套结构体的影响。

具体而言，当基础槽位发生碰撞时，该方案能识别紧随其后的动态数组和映射变量之间的碰撞影响，特别是当这些变量具有相同的数据类型或键类型时，如大型游戏合约中常见的情况。通过精确分析存储布局和槽类型，该技术能够检测到存储碰撞并避免因升级实施或特性合约导致的状态变量基槽布局改变而产生的数据错误。

此外，该方法计划自动检测智能合约中的所有状态变量及其对应的槽布局，扩展到更复杂的变量（如映射键、动态数组和复杂结构体）的槽计算，并最终实现状态变量和复杂变量所有条目的碰撞检测器。通过这三个阶段的系统开发，旨在为智能合约提供全面的存储碰撞检测能力，确保部署前的安全性，并帮助锁定数百万美元级别的合同免受潜在攻击。

最后，该方案的实施将使开发者能够在部署前验证其合同不存在潜在的存储碰撞风险，同时对已部署的智能合约进行定期审计以发现并修复存储碰撞问题，从而显著提高智能合约的整体安全性和可靠性。 <div>
<p>Storage collisions and vulnerabilities within Ethereum smart contracts can lead to unexpected issues like freezing funds, escalating privileges, and financial asset theft. A storage collision occurs when two different storage structs unintentionally use same storage slot(s), or the slot layout is changed during the upgrade of implementation contract. These collision vulnerabilities have been detected in large numbers (worth millions of dollars) in a <a href="https://www.ndss-symposium.org/ndss-paper/not-your-type-detecting-storage-collision-vulnerabilities-in-ethereum-smart-contracts/" rel="noopener nofollow ugc">recent study</a> within smart contracts deployed on the Ethereum network.</p>
<p>In this topic, we propose a more accurate and complete technique to detect storage vulnerabilities and collisions in Solidity smart contracts. And encourage the Ethereum community to <strong>provide feedback on the proposed technique</strong>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49742-introduction-1" name="p-49742-introduction-1"></a>Introduction</h3>
<p>We are working on a solution based on advanced static analysis techniques that can identify vulnerabilities within the deep storage of Ethereum Solidity smart contracts. We aim to detect storage collisions in proxy contracts deployed on the Ethereum network like ERC-2535 (Diamond/Multi-Facet Proxy), ERC-1822, upgrade proxy pattern, etc., as complex proxy contracts are more likely to experience a storage collision, like during the upgrade of implementation or facet contracts.</p>
<p><a href="https://www.ndss-symposium.org/ndss-paper/not-your-type-detecting-storage-collision-vulnerabilities-in-ethereum-smart-contracts/" rel="noopener nofollow ugc">N. Ruaro et al.</a> analyzed Ethereum contracts using contract bytecode to detect storage collisions and reported 14,891 vulnerable contracts. Their technique was able to identify storage slot types correctly with an accuracy of 87.3%. Whereas, we aim to build a solution that will use source code to accurately analyze the storage layout and slot types of the contract. Furthermore, we will also analyze dynamic arrays, mapping variables, and complex nested structs in our analysis.</p>
<p>Suppose a collision occurs on the state variables’ base slots, our approach will allow us to identify the impact of the collision on dynamic arrays and mapping variables declared consecutively, and arrays data type or mappings key types are same which is a common practice in large contracts like gaming contracts.</p>
<p>As shown in the below example code, the slot layout was changed during the contract upgrade, and since <code>token_uris</code> and <code>token_version</code> have same key types and data types, both variables will return each other’s data after the upgrade due to collision.</p>
<pre><code class="lang-auto">library ImplementationStorage1 {
    struct AddressSlot {
        address owner; // slot n+0
        mapping(uint256 =&gt; string) token_uris; // slot n+1
        mapping(uint256 =&gt; string) token_versions; // slot n+2
    }

    function getAddressSlot(bytes32 slot) internal pure returns (AddressSlot storage r) {
        assembly {
            r.slot := slot
        }
    }
}

// updated code
library ImplementationStorage2 {
    struct AddressSlot {
        address owner; //slot n+0
        mapping(uint256 =&gt; string) token_versions; // slot n+1 (shld be token_uris)
        mapping(uint256 =&gt; string) token_uris; // slot n+2 (shld be token_versions)
    }

    function getAddressSlot(bytes32 slot) internal pure returns (AddressSlot storage r) {
        assembly {
            r.slot := slot
        }
    }
}
</code></pre>
<p><code>token_uris</code> accessing <code>token_versions</code> and vice-versa after the upgrade.</p>
<pre><code class="lang-auto">       (before upgrade)                        (after upgrade)   
      _________________                      _________________
     |     Proxy       |                     |     Proxy       |
     |_________________|                     |_________________|
     | * IMPLEMENT_SLOT| --&gt; NFTManager1     | * IMPLEMENT_SLOT| --&gt; NFTManager2
     | * ADMIN_SLOT    |                     | * ADMIN_SLOT    |
     |_________________|                     |_________________|
     | + upgradeTo()   |                     | + upgradeTo()   |
     | + changeAdmin() |                     | + changeAdmin() |
     |_________________|                     |_________________|
              |                                       |
              v                                       v
      _________________                       _________________
     |   NFTManager1   |                     |   NFTManager2   |
     |_________________|                     |_________________|
     | - owner         |                     | - owner         |
     | - token_uris    | **** collision **** | - token_versions|
     | - token_versions| **** collision **** | - token_uris    |
     |_________________|                     |_________________|

</code></pre>
<p>We plan to build a technology that will automatically detect all storage collisions within a Solidity smart contract.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49742-methodology-2" name="p-49742-methodology-2"></a>Methodology</h4>
<p>We have structured our development plan into three distinct phases, outlined as follows:</p>
<ul>
<li><strong><strong>Automatic State Variable Detector and Slot Layout Calculator</strong></strong></li>
</ul>
<p>In this phase, we focus on developing an automatic state variable detector and slot layout calculator. This component will facilitate the identification of state variables within smart contracts and determine their corresponding slot layout. By automating this process, we aim to streamline the initial analysis procedures.</p>
<p>Sample output of Slot Calculator</p>
<pre><code class="lang-auto">slot 0 - mapping ds.selectorToFacetAndPosition[bytes4] = FacetAddressAndPosition;
slot 1 - mapping ds.facetFunctionSelectors[address] = FacetFunctionSelectors;
slot 2 - address [] ds.facetAddresses;
slot 3 - mapping ds.supportedInterfaces[bytes4] = bool;
slot 4 - address ds.contractOwner;
slot 5 - mapping ds.tempSelectorsNested[uint256] = FacetAddressAndPosition;
slot 6 - FacetAddressAndPosition [] ds.FacetAddressAndPositionArray;
slot 7 - mapping ds.tempMapping[uint256] = uint256;
slot 8 - mapping ds.tempMapping2[address] = uint256;
</code></pre>
<ul>
<li><strong><strong>Mapping Keys Analyzer and Slot Calculator of Complex Variables</strong></strong></li>
</ul>
<p>Building upon the foundation established in phase 1, in this phase we will first extend the slot calculator capability to calculate the slots of complex variables and their entries (for all data types) i.e. slots of mapping keys, dynamic array, complex struct, mappings with complex struct as value.</p>
<p>This component will also include the approximation of all keys used in mapping variables for saving data using advanced static analysis techniques. By accurately approximating keys and calculating entries, we seek to enhance the precision and breadth of storage slot calculation methodology, which will help detect storage collision within deep storage data of a smart contract.</p>
<ul>
<li><strong><strong>Collision Detector for State Variables and Complex Variables All Entries Slots</strong></strong></li>
</ul>
<p>The final phase of our methodology focuses on implementing a collision detector for both state variables and complex variable slots. This critical component will identify any potential collisions or conflicts within any type of state variables and their associated variable(s)/value(s) slots. By detecting and addressing collisions, we aim to ensure the integrity and reliability of smart contracts.</p>
<p>We aim to develop a robust and comprehensive methodology for smart contract storage collision detectors, by systematically progressing through above discussed three development phases.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49742-conclusion-3" name="p-49742-conclusion-3"></a>Conclusion</h4>
<p>The development of our solution will allow developers to ensure that their contract has no potential storage collisions before deployment. It will also be able to detect storage collisions within deep storage of deployed smart contracts and can help in securing contracts worth millions of dollars.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/feedback-needed-a-technique-to-automatically-detect-storage-collisions-and-vulnerabilities-within-solidity-smart-contract/20328">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 23 Aug 2024 09:35:11 +0000</pubDate>
</item>
<item>
<title>Mechan-stein (alt. Franken-ism)</title>
<link>https://ethresear.ch/t/mechan-stein-alt-franken-ism/20321</link>
<guid>https://ethresear.ch/t/mechan-stein-alt-franken-ism/20321</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、block production、MEV、validator sophistication、chain neutrality

总结：

文章主要讨论了如何优化以太坊区块构建过程，以实现三个关键设计目标：鼓励区块构建者的竞争、限制验证者复杂性的价值以及维护区块链空间的中立性。文章首先概述了区块空间市场设计的基本原则，强调了区块生产中心化、验证去信任和高分散性，以及防止审查的重要性。

接着，文章介绍了三种提案机制：
1. **嵌入式块拍卖与MEV销毁（Enshrined PBS & MEV-burn via PTC）**：通过引入即时块拍卖机制，确保任何区块构建者都能参与竞争，同时通过验证者执行的阈值来限制区块构建者的优势。
2. **前置区块拍卖（Ahead-of-time slot auction）**：提前进行区块拍卖，减少验证者复杂性的价值，因为拍卖不是实时进行的。
3. **FOCIL（Focus on Constraints List）**：允许多个共识参与者共同创建区块模板，增加系统中立性，但不涉及MEV的权力分配。

文章提出了结合上述机制的“Mecahn-stein”概念，旨在综合考虑三个设计目标，通过在区块构建过程中引入双重拍卖机制（一个预先拍卖，一个即时拍卖）来平衡区块构建的效率、公平性和中立性。该机制试图通过让区块构建者购买区块构建的权利，同时在区块构建时再次竞拍区块的顶部交易，来实现对区块构建过程的控制与透明度，从而达到鼓励竞争、限制验证者复杂性价值并维护区块链中立性的目的。

文章最后指出，虽然这种结合机制可能面临复杂性、可能扭曲MEV市场以及区块构建者仍然具有一定程度的决策权等挑战，但通过合理设计和实施，可以在一定程度上解决当前存在的问题，为以太坊网络提供更高效、公平和中立的区块构建流程。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49714-mechan-stein-alt-franken-ismbrp-classsmallsmall-choose-your-own-adventurehttpsxcomvitalikbuterinstatus1788489148183019929-either-way-just-trying-to-portmanteau-frankenstein-and-mechanismsmallp-1" name="p-49714-mechan-stein-alt-franken-ismbrp-classsmallsmall-choose-your-own-adventurehttpsxcomvitalikbuterinstatus1788489148183019929-either-way-just-trying-to-portmanteau-frankenstein-and-mechanismsmallp-1"></a>Mechan-stein (alt. Franken-ism)<br /><p><small><em>^ <a href="https://x.com/VitalikButerin/status/1788489148183019929" rel="noopener nofollow ugc">choose your own adventure</a> – either way, just trying to portmanteau ‘Frankenstein’ and ‘Mechanism.’</em></small></p></h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/d/3d13edb2750f779fb39f38e943038de48a692422.jpeg" title="upload_2936c4a8e65027883c0cacec063f9ea2"><img alt="upload_2936c4a8e65027883c0cacec063f9ea2" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/3/d/3d13edb2750f779fb39f38e943038de48a692422_2_498x500.jpeg" width="498" /></a></div><br />
<sub><em><strong>^“don’t worry bro, just one more auction, i swear. check it out.” h/t Mallesh for the relevant <a href="https://x.com/malleshpai/status/1748026472923623619" rel="noopener nofollow ugc">tweet</a>.</strong></em><br />
</sub><p></p>
<p><span class="math">\cdot</span><br />
<em>by <a href="https://twitter.com/mikeneuder" rel="noopener nofollow ugc">mike</a> – wednesday; august 21, 2024.</em><br />
<sub><em>^hbd <a href="https://en.wikipedia.org/wiki/Bo_Burnham" rel="noopener nofollow ugc">Bo</a>. if you, dear reader, haven’t seen <a href="https://en.wikipedia.org/wiki/Bo_Burnham:_Inside" rel="noopener nofollow ugc">“Inside”</a> or <a href="https://www.youtube.com/watch?v=5XWEVoI40sE" rel="noopener nofollow ugc">“Inside Outtakes,”</a> watching them is your homework assignment.</em></sub><br />
<span class="math">\cdot</span><br />
<em>Many thanks to <a href="https://x.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://x.com/_julianma" rel="noopener nofollow ugc">Julian</a>, <a href="https://x.com/soispoke" rel="noopener nofollow ugc">Thomas</a>, <a href="https://x.com/jacobykaufmann" rel="noopener nofollow ugc">Jacob</a>, <a href="https://x.com/mteamisloading" rel="noopener nofollow ugc">mteam</a>, <a href="https://x.com/nero_eth" rel="noopener nofollow ugc">Toni</a>, <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin</a>, <a href="https://x.com/vitalikbuterin" rel="noopener nofollow ugc">Vitalik</a>, <a href="https://x.com/MaxResnick1" rel="noopener nofollow ugc">Max</a>, and <a href="https://x.com/malleshpai" rel="noopener nofollow ugc">Mallesh</a> for discussions around these topics and comments on the draft!</em><br />
<span class="math">\cdot</span><br />
<em>The idea for the combined mechanism explored in <a href="https://ethresear.ch#p-49714-h-2-mechan-stein-9">Part 2</a> of this post came from a Baranbé-led whiteboarding session and accompanying <a href="https://x.com/barnabemonnot/status/1808444733305258047" rel="noopener nofollow ugc">tweet thread</a>. These ideas are also explored in the <a href="https://efdn.notion.site/Block-construction-session-bd611621250f45948eff05fcf6a34067?pvs=4" rel="noopener nofollow ugc">this doc</a>, which inspired <a href="https://github.com/michaelneuder/talks/blob/268e273b55cf2c753b2479c3ebbb826d41811754/misc2024/sbc.pdf" rel="noopener nofollow ugc">this talk</a>.</em><br />
<span class="math">\cdot</span><br />
<strong>tl;dr;</strong> <em>We sketch a high-level framing for Ethereum block construction centered around the design goals of encouraging builder competition, limiting the value of validator sophistication, and preserving the neutrality of block space. We then highlight three proposed mechanisms and how they interface with the established desiderata. We conclude by exploring the potential synergies of combining these designs into a single flow, called <code>Mechan-stein</code>.</em><br />
<span class="math">\cdot</span><br />
<strong>Contents</strong><br />
(1) <a href="https://ethresear.ch#p-49714-h-1-the-building-blocks-pun-intended-of-block-space-market-design-2">The building blocks of block-space market design</a><br />
&nbsp;&nbsp;  <a href="https://ethresear.ch#p-49714-enshrined-pbs-mev-burn-via-ptc-3">Enshrined PBS &amp; MEV-burn via PTC</a><br />
&nbsp;&nbsp;  <a href="https://ethresear.ch#p-49714-execution-auctions-an-attester-proposer-separation-instatiation-5">Execution Auctions (an Attester-Proposer Separation instantiation)</a><br />
&nbsp;&nbsp;  <a href="https://ethresear.ch#p-49714-focil-7">FOCIL</a><br />
(2) <a href="https://ethresear.ch#p-49714-h-2-mechan-stein-9">Mechan-stein</a><br />
&nbsp;&nbsp;  <a href="https://ethresear.ch#p-49714-potential-issues-with-mechan-stein-10">Potenital Issues with Mechan-stein</a><br />
<span class="math">\cdot</span></p>
<p><strong>Related work</strong></p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Article</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More words on Proposer-Builder Separation</em></a></td>
</tr>
<tr>
<td><a href="https://efdn.notion.site/Block-construction-session-bd611621250f45948eff05fcf6a34067?pvs=4" rel="noopener nofollow ugc"><em>Notes from block construction session</em></a></td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>MEV-burn</em></a></td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054"><em>PTC</em></a></td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870"><em>FOCIL</em></a></td>
</tr>
</tbody>
</table>
</div><hr />
<h1><a class="anchor" href="https://ethresear.ch#p-49714-h-1-the-building-blocks-pun-intended-of-block-space-market-design-2" name="p-49714-h-1-the-building-blocks-pun-intended-of-block-space-market-design-2"></a>[1] The building blocks (pun intended) of block-space market design</h1>
<p>Since before the Merge, <a href="https://github.com/michaelneuder/mev-bibliography" rel="noopener nofollow ugc">much</a> has been (and continues to be) written about Ethereum’s transaction supply chain and block-space market design. I still think Vitalik’s <a href="https://vitalik.eth.limo/general/2021/12/06/endgame.html" rel="noopener nofollow ugc"><em>Endgame</em></a> summarizes the best-case outcome most succinctly with,</p>
<blockquote>
<p><em>“Block production is centralized, block validation is trustless and highly decentralized, and censorship is still prevented.”</em></p>
</blockquote>
<p>We can operationalize each of these statements into a design goal for our system:</p>
<ol>
<li><em>“Block production is centralized.”</em> <span class="math">\rightarrow</span> MEV is a fact of life in financial systems, and some actors will inevitably specialize in its extraction. We can’t expect solo-stakers to run profitable builders, but we can encourage competition and transparency in the MEV markets. When discussing <code>MEV-boost</code>, we usually describe it as aiming to democratize access to MEV for all proposers (which it does extremely well), but one under-discussed element of the existing system is that it <em>encourages builder competition</em> by creating a transparent market for buying block space. There are (and always will be) advantages and economies of scale for being a big builder (e.g., colocation with relays, acquiring exclusive order flow deals, and holding large inventory on various trading venues – for more, see this <a href="https://arxiv.org/pdf/2407.13931" rel="noopener nofollow ugc">recent paper</a> from Burak, Danning, Thomas, and Florian), but anyone can send blocks and compete in the auction. Another important element of <code>MEV-boost</code> is that the auction happens Just-In-Time (JIT) for the block proposal, making <a href="https://ethresear.ch/t/on-attestations-block-propagation-and-timing-games/20272">timing games</a> around the block proposal deadline valuable to the proposer who serves as the auctioneer. Still, the real-time nature of the auction ensures that the builder with the highest value <em>for this specific slot</em> wins the auction (rather than, e.g., the builder with the highest average value for any slot – see <a href="https://arxiv.org/pdf/2408.03116" rel="noopener nofollow ugc">Max &amp; Mallesh’s argument</a> for why ahead-of-time auctions are more centralized). This leads to <strong>design goal <span class="hashtag-raw">#1:</span> encourage builder competition.</strong><a href="https://ethresear.ch#fn1dst"><span class="math">^{[1]}</span></a><a name="fn1"></a></li>
<li><em>“Block validation is trustless and highly decentralized”</em><a href="https://ethresear.ch#fn2dst"><span class="math">^{[2]}</span></a><a name="fn2"></a> <span class="math">\rightarrow</span> Ethereum’s primary focus has been preserving the validator set’s decentralization (why this is important in item <span class="hashtag-raw">#3</span> below). This fundamental tenet instantiates itself in both the engineering/technical design and the economic/incentive design. On the engineering front, the <a href="https://github.com/ethereum/consensus-specs/tree/dev" rel="noopener nofollow ugc">spec</a> is written with the <a href="https://docs.ethstaker.cc/ethstaker-knowledge-base/hardware/hardware-requirements" rel="noopener nofollow ugc">minimum hardware requirements</a> in mind. This constraint ensures that participation in Ethereum’s consensus is <em>feasible</em> given (relatively) modest resources. On the economic level, the goal is to minimize the disparity in financial outcomes between at-home stakers and professional operators. Beyond feasibility, this aims to make at-home staking <em>not too irrational.</em> This double negative is tongue-in-cheek but hopefully conveys the message of trying to ensure there is some economic viability to at-home staking rather than staking through a centralized provider. Another lens for interpreting this is keeping the marginal value of sophistication low. We can’t expect at-home operators to have the exact same rewards as Coinbase and Lido (e.g., because they may have higher network latency), but the centralized staking providers shouldn’t benefit greatly from sophistication. This leads to <strong>design goal <span class="hashtag-raw">#2:</span> limit the value of validator sophistication.</strong></li>
<li><em>“Censorship is prevented.”</em> <span class="math">\rightarrow</span> Credible neutrality is what differentiates crypto-economic systems from FinTech. If centralized entities determine which transactions land on chain and which do not, it’s over. To ensure the anti-fragility and neutrality of Ethereum, we must rely on a <a href="https://collective.flashbots.net/t/decentralized-crypto-needs-you-to-be-a-geographical-decentralization-maxi/1385" rel="noopener nofollow ugc">geographically distributed</a> validators; the validator set is the most decentralized part of the block production pipeline. In my opinion, (i) the main point of having a decentralized validator set is to allow those validators to express different preferences over the transactions that land on chain (“high preference entropy” – <a href="https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683">h/t Dr. Monnot</a>), and (ii) relying on this decentralization is the only way to preserve neutrality of the chain (c.f., <a href="https://ethresear.ch/t/uncrowdable-inclusion-lists-the-tension-between-chain-neutrality-preconfirmations-and-proposer-commitments/19372"><em>Uncrowdable Inclusion Lists</em></a> for more discussion on chain neutrality). This leads to <strong>design goal <span class="hashtag-raw">#3:</span> preserve the neutrality of Ethereum block space.</strong></li>
</ol>
<p>Right. To summarize:</p>
<ol>
<li><em>“Block production is centralized.”</em> <span class="math">\rightarrow</span> <strong>design goal <span class="hashtag-raw">#1:</span> encourage builder competition.</strong></li>
<li><em>“Block validation is trustless and highly decentralized”</em> <span class="math">\rightarrow</span> <strong>design goal <span class="hashtag-raw">#2:</span> limit the value of validator sophistication.</strong></li>
<li><em>“Censorship is prevented.”</em> <span class="math">\rightarrow</span> <strong>design goal <span class="hashtag-raw">#3:</span> preserve the neutrality of Ethereum block space.</strong></li>
</ol>
<p>Ok. This is all great, but let’s talk specifics. Many proposals aim to accomplish some of the design goals above. I am going to focus on three:</p>
<ol>
<li><strong>Enshrined <a href="https://barnabe.substack.com/p/pbs" rel="noopener nofollow ugc">Proposer-Builder Separation</a> &amp; <a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><code>MEV-burn</code></a> via <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054">Payload-Timeliness Committee</a></strong> (abbr. <code>PTC</code> onwards).</li>
<li><strong><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">Execution Auctions</a>/Attester-Proposer Separation</strong>.</li>
<li><strong><a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870/5">Fork-Choice Enforced Inclusion Lists</a></strong> (abbr. <code>FOCIL</code> onwards).</li>
</ol>
<p>This may seem jargon-laden, and I apologize; please check out the links for the canonical article on each topic; for even more legibility, I will present a high-level view of each proposal below.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49714-enshrined-pbs-mev-burn-via-ptc-3" name="p-49714-enshrined-pbs-mev-burn-via-ptc-3"></a>Enshrined PBS &amp; <code>MEV-burn</code> via <code>PTC</code></h3>
<p>This design enshrines a JIT block auction into the Ethereum consensus layer. The diagram below summarizes the block production pipeline <em>during the slot</em>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/2/22560b81c3e436b0a3524b9c52a1b6b5aa277003.png" title="upload_a40f44ea2cb5821c889733125eb53260"><img alt="upload_a40f44ea2cb5821c889733125eb53260" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/2/2/22560b81c3e436b0a3524b9c52a1b6b5aa277003_2_423x500.png" width="423" /></a></div><p></p>
<ol>
<li><strong>The builder bids</strong> in the auction by sending <code>(block header, bid value)</code> pairs to the proposer and the committee members.</li>
<li><strong>The proposer commits</strong> to the highest bid value by signing and publishing the winning bid.</li>
<li><strong>The committee enforces</strong> that the proposer selected a sufficiently high bid according to their view.</li>
<li><strong>The builder publishes</strong> the block.</li>
<li><strong>The committee enforces</strong> the timeliness of the builder’s publication.</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#p-49714-analysis-4" name="p-49714-analysis-4"></a>Analysis</h4>
<ul>
<li><code>PTC</code> allows the protocol (through the enforcement of the committee) to serve as the trusted third-party in the <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=208b22c7a094ada20736593afcc8c759c7d1b79c" rel="noopener nofollow ugc">fair-exchange</a> of the sale of the block building rights. <code>MEV-burn</code> (maybe more aptly denoted as “block maximization” because burning isn’t strictly necessary for the bids) asks the attesters to enforce a threshold for the bid selected as the winner by the proposer.</li>
<li><span><code>PTC</code> primarily implements <strong>design goal <span class="hashtag-raw">#1:</span> encourage builder competition.</strong></span> <code>PTC</code> enshrines <code>MEV-boost</code>, fully leaning into creating a competitive marketplace for block building. As in <code>MEV-boost</code>, the real-time block auction allows any builder to submit bids and encourages competition during each slot. Additionally, the JIT auction and bid-threshold enforcement of <code>MEV-burn</code> reduces the risk of multi-slot MEV by forcing each auction to take place during the slot. Lastly, <code>PTC</code> and other ePBS designs historically were aimed at <a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710#reasons-to-enshrine-4">removing relays</a>. With bid thresholds from <code>MEV-burn</code>, the <a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278">bypassability of the protocol</a> becomes less feasible (even if the best builder bypasses, the second best can go through the protocol and ensure their bid wins).</li>
<li><span><code>PTC</code> marginally addresses <strong>design goal <span class="hashtag-raw">#2:</span> limit the value of validator sophistication.</strong></span> By creating an explicit market for MEV-aware blocks, <code>PTC</code> ensures that all validators can access a large portion of the MEV available in their slot. <code>MEV-burn</code> also smooths out the variance in the validator rewards. However, one of the major limitations of this auction design is the “value-in-flight” (h/t Barnabé for <a href="https://www.youtube.com/watch?v=KHw7gdJ14uQ" rel="noopener nofollow ugc">coining</a> the <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">term</a>) problem of the auction taking place during the slot. Because the value of the sold item changes dramatically throughout a slot, the auctioneer’s role benefits from sophistication. Beyond simple <a href="https://dataalways.mirror.xyz/-m0-bp3aZpcqa15_QbMX3MD1v9xg7VCcfGtZBR7I9Bg" rel="noopener nofollow ugc">timing games</a>, more exotic strategies around the fork-choice rule (e.g., using extra fork-choice weight to <a href="https://ethresear.ch/t/on-attestations-block-propagation-and-timing-games/20272">further delay block publication</a>, h/t Toni) are possible, and we are just starting to see these play out.</li>
<li><span> <code>PTC</code> does not address <strong>design goal <span class="hashtag-raw">#3:</span> Preserve the neutrality of Ethereum block space.</strong></span> Neither <code>PTC</code> nor PBS generally are designed to encourage censorship resistance. The fact that a few builders account for most of Ethereum’s blocks is not surprising, and we should not count on those builders to uphold the credible neutrality of the chain (even if they are right now). While it is true that <code>PTC</code> aims to maintain a decentralized validator set, the fact that the full block is sold counter-acts that effect by still giving discretionary power of the excluded transactions to the builder (e.g., consider the hypothetical where 100% of validators are at-home stakers (maximally decentralized), but they all outsource to the same builder <span class="math">\implies</span> the builder fully determines the transactions that land onchain).</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#p-49714-execution-auctions-an-attester-proposer-separation-instatiation-5" name="p-49714-execution-auctions-an-attester-proposer-separation-instatiation-5"></a>Execution Auctions (an Attester-Proposer Separation Instatiation)</h3>
<p>In contrast to the JIT block auction enabled by <code>PTC</code>, this design enshrines an ahead-of-time slot auction into the Ethereum consensus layer. A <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">slot auction</a> still allocates the entire block to the winner of the auction, but they no longer need to commit to the specific contents of the block when bidding (e.g., they are buying future block space) – this allows the auction to take place well in advance of the slot itself. The diagram below summarizes the block production pipeline <em>32 slots ahead of time</em> (the 32 is just an arbitrary number; you could run the auction any time in advance or even during the slot itself; the key distinction is the fact that the bids don’t contain commitments to the contents of the block).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/6/36fa041386a05b37b3dad9e959dad6c329d506ba.png" title="upload_ba33d4610c47000f0ac60a5273f91f61"><img alt="upload_ba33d4610c47000f0ac60a5273f91f61" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/3/6/36fa041386a05b37b3dad9e959dad6c329d506ba_2_505x500.png" width="505" /></a></div><p></p>
<p>N.B., the first three steps are nearly identical to the <code>PTC</code> process. The only differences are (a) the auction for the <code>Slot N+32</code> block production rights takes place during <code>Slot N</code> and (b) the bid object is a single <code>bid value</code> rather than the <code>(block header, bid value)</code> tuples. The actual building and publication of the block happen during <code>Slot N+32</code>, and <code>Execution Auctions</code> are agnostic to that process.</p>
<ol>
<li><strong>The builder bids</strong> in the auction by sending <code>bid value</code> to the proposer and the committee members.</li>
<li><strong>The proposer commits</strong> to the highest bid value by signing and publishing the winning bid.</li>
<li><strong>The committee enforces</strong> that the proposer selected a sufficiently high bid according to their view.</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#p-49714-analysis-6" name="p-49714-analysis-6"></a>Analysis</h4>
<ul>
<li><code>Execution Auctions</code> allow the protocol (through the enforcement of the committee) to serve as the trusted third party in the <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=208b22c7a094ada20736593afcc8c759c7d1b79c" rel="noopener nofollow ugc">fair-exchange</a> of the sale of the block building rights for a future slot.</li>
<li><span><code>Execution Auctions</code> primarily support <strong>design goal <span class="hashtag-raw">#2:</span> limit the value of validator sophistication.</strong></span> With the real-time auction of <code>PTC</code>, we described how the value-in-flight problem results in value from the sophistication of the validators who conduct the auction. In <code>Execution Auctions</code>, the auction occurs apriori, making the value of the object sold less volatile. The validator conducting the auction has a much simpler role that doesn’t benefit from timing games in the way they do in the JIT auction, thereby reducing their value from sophistication.</li>
<li><span><code>Execution Auctions</code> do not address <strong>design goal <span class="hashtag-raw">#1:</span> encourage builder competition.</strong></span> By running the auction ahead of time, the highest value bidder will always be the builder who is best at producing blocks (h/t Max and Mallesh for <a href="https://arxiv.org/pdf/2408.03116" rel="noopener nofollow ugc">formalizing this</a>). The builder may still choose to sell the block production rights on the secondary market, but only at a premium over the amount they can extract.<a href="https://ethresear.ch#fn3dst"><span class="math">^{[3]}</span></a><a name="fn3"></a></li>
<li><span><code>Execution Auctions</code> do not address <strong>design goal <span class="hashtag-raw">#3:</span> Preserve the neutrality of Ethereum block space.</strong></span> <code>Execution Auctions</code> are <em>not designed to encourage censorship resistance</em>. We fully expect the future block space and builder markets to remain centralized. Another major concern with <code>Execution Auctions</code> is the risk of multi-slot MEV. Because the auction is not real-time, it is possible to acquire multiple consecutive future slots and launch multi-slot MEV strategies without competing in any auction during the slot itself. (We could try to mitigate this by making the look-ahead only a single slot – e.g., <code>Slot N+1</code> auction during <code>Slot N</code>, but this may open up the same value-in-flight issues around JIT block auctions. More research is needed (and actively being done h/t Julian) here.)</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#p-49714-focil-7" name="p-49714-focil-7"></a>FOCIL</h3>
<p>This design allows multiple consensus participants to construct lists of transactions that must be included in a given slot. In contrast to the previous designs, this <em>is not</em> an auction and <em>does not</em> aim to enshrine a MEV marketplace into the protocol. Instead, the focus here is improving the system’s neutrality by allowing multiple parties to co-create a template (in the form of a set of constraints) for the produced block. The diagram below describes the block production process <em>during the slot itself.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/c/bc6cae7b07f724344d704a6bd035e33e82f7500f.png" title="upload_badb6db529bdfb2640abe1ce4d767dd2"><img alt="upload_badb6db529bdfb2640abe1ce4d767dd2" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/c/bc6cae7b07f724344d704a6bd035e33e82f7500f_2_455x500.png" width="455" /></a></div><p></p>
<ol>
<li><strong>The IL committee publishes</strong> their inclusion lists to the builder (clumping this together with the proposer for this diagram because the builder must follow the block template) and the attesters.</li>
<li><strong>The builder publishes</strong> a block that includes an aggregate view of the ILs they received and conforms to the constraints therein.</li>
<li><strong>The attesters enforce</strong> the block validity conditions, which now check that the builder included a sufficient threshold of observed inclusion lists.</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#p-49714-analysis-8" name="p-49714-analysis-8"></a>Analysis</h4>
<ul>
<li><code>FOCIL</code> increases the protocol’s neutrality by allowing multiple validators to express their preferences in the block co-creation.</li>
<li><span><code>FOCIL</code> primarily contributes to <strong>design goal <span class="hashtag-raw">#3:</span> preserve the neutrality of Ethereum blockspace.</strong></span> This is the direct goal; more inputs to the block construction seems like a no-brainer (very much in line with the latest thread of <a href="https://www.youtube.com/watch?v=mJLERWmQ2uw" rel="noopener nofollow ugc">concurrent proposer research</a>). Critically, <code>FOCIL</code> intentionally does not give any MEV power to the inclusion list constructors (see <a href="https://ethresear.ch/t/uncrowdable-inclusion-lists-the-tension-between-chain-neutrality-preconfirmations-and-proposer-commitments/19372"><em>Uncrowdability</em></a> for more) to avoid the economic capture of that role. In particular, <code>FOCIL</code> <em>does not</em> aim to constrain the builder’s ability to extract MEV generally; the builder can still reorder and insert transactions at will in their block production process. Instead, it’s their ability to <em>arbitrarily exclude</em> transactions, which <code>FOCIL</code> reduces.</li>
<li><span><code>FOCIL</code> does not address <strong>design goal <span class="hashtag-raw">#1:</span> encourage builder competition.</strong></span> <code>FOCIL</code> is agnostic to the exact block production process beyond enforcing a block template for transactions that cannot be excluded arbitrarily.</li>
<li><span><code>FOCIL</code> does not address <strong>design goal <span class="hashtag-raw">#2:</span> limit the value of validator sophistication.</strong></span> <code>FOCIL</code> is agnostic to the exact block production process beyond enforcing a block template for transactions that cannot be excluded arbitrarily.</li>
</ul>
<p>Right. That was the “vegetable eating” portion of this article. The critical takeaway is <strong>each of the above proposals primarily addresses one of the cited design goals, but none address all three simultaneously.</strong> This makes it easy to point out flaws in any specific design.<br />
…<br />
You probably see where we are going with this. Let’s not bury the lede. What if we combine them? Each serves a specific role and operates on a different portion of the slot duration; why not play it out?</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49714-h-2-mechan-stein-9" name="p-49714-h-2-mechan-stein-9"></a>[2] Mechan-stein</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/0/508d35ee9a4052135205628aa738a64cbcdd4c51.png" title="upload_bc314953eed471a97f9afd50b068bb14"><img alt="upload_bc314953eed471a97f9afd50b068bb14" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/0/508d35ee9a4052135205628aa738a64cbcdd4c51_2_440x500.png" width="440" /></a></div><p></p>
<p>With the groundwork laid, we can ~nearly~ combine the three mechanisms directly. There is one issue, however, which arises from both auctions selling the same object – the proposing rights for <code>Slot N+32</code>. The resulting bids in the first auction (the slot auction sale of <code>Slot N+32</code> during <code>Slot N</code>) would thus not carry any economic meaning because bidders would be competing for the slot but would then be forced sellers by the time the slot arrived. To resolve this, the second auction (which happens JIT during the slot) could instead be a Top-of-Block auction (e.g., the first 5mm gas consumed in the block). There are many articles exploring the Top-of-Block/Rest-of-Block split (sometimes called block prefix/suffixes) (see, e.g., <a href="https://ethresear.ch/t/how-much-can-we-constrain-builders-without-bringing-back-heavy-burdens-to-proposers/13808">here</a>, <a href="https://github.com/bharath-123/pepc-boost-relay" rel="noopener nofollow ugc">here</a>, <a href="https://ethresear.ch/t/state-lock-auctions-towards-collaborative-block-building/18558">here</a>), so we won’t go into the details of the consensus changes required to facilitate this exchange. Taking its feasibility for granted, the double-auction design of Mechan-stein makes more sense.<br />
- <strong>Auction 1 during <code>Slot N</code></strong> sells the block proposing rights for <code>Slot N+32</code> and is conducted by the proposer of <code>Slot N</code>.<br />
- <strong>Auction 2 during <code>Slot N+32</code></strong> sells the Top-of-Block to a (potentially different) builder who specifies the specific set of transactions to be executed first in the block. This auction is conducted just in time by the builder/winner of Auction 1.</p>
<p>With this framing, the winner of Auction 1 effectively bought the option to build (or sell) the Rest-of-Block for <code>Slot  N+32</code> – thus the expected value of the bids in that auction would be the average amount of MEV extractable in the block suffix (aside: this might play nicely with <a href="https://x.com/barnabemonnot/status/1808444762376020121" rel="noopener nofollow ugc">preconfs</a>). The diagram below shows the flow at a high level (leaving off many back-and-forths for legibility).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/d/8dd0b952112b0f09ac63c9b1a5fba3e4c718dc60.jpeg" title="upload_95efb121f762fdc00a15aecb64fe6e54-1"><img alt="upload_95efb121f762fdc00a15aecb64fe6e54-1" height="373" src="https://ethresear.ch/uploads/default/optimized/3X/8/d/8dd0b952112b0f09ac63c9b1a5fba3e4c718dc60_2_690x373.jpeg" width="690" /></a></div><p></p>
<ol>
<li><strong>The <code>Slot N</code> proposer auctions off</strong> the <code>Slot N+32</code> proposing rights.</li>
<li><strong>The <code>Slot N</code> attesters enforce</strong> the bid threshold of the slot auction.</li>
<li><em>[32 slots later]</em> <strong>The <code>Slot N+32</code> IL committee publishes</strong> their ILs.</li>
<li><strong>The <code>Slot N+32</code> builder auctions off</strong> the Top-of-Block for <code>Slot N+32</code>.</li>
<li><strong>The <code>Slot N+32</code> <code>PTC</code> enforces</strong> the bid threshold of the Top-of-Block auction.</li>
<li><strong>The <code>Slot N+32</code> <code>PTC</code> enforces</strong> the timeliness of the block publication from the winning builder.</li>
<li><strong>The <code>Slot N+32</code> attesters enforce</strong> the IL threshold of the final block.</li>
</ol>
<p>Yeah, yeah – it’s a lot of steps, but the pitch is pretty compelling.</p>
<ul>
<li><span>Mechan-stein addresses <strong>design goal <span class="hashtag-raw">#1:</span> encourage builder competition.</strong></span> The permissionless, JIT Top-of-Block auction helps mitigate the risk of multi-slot MEV in <code>Execution Auctions</code> by <em>forcing</em> the slot auction winner to sell a portion of the block or at least pay a threshold to build the full block themselves.</li>
<li><span>Mechan-stein addresses <strong>design goal <span class="hashtag-raw">#2:</span> limit the value of validator sophistication.</strong></span> The role of an average validator in block production is now the simple combination of (1) conducting the ahead-of-time slot auction and (2) publishing their inclusion list when part of an IL committee. This greatly reduces the power bestowed on the validator because (1) they are now conducting an auction apriori (thus, latency and timing games play a smaller role) and (2) the inclusion list intentionally does not generate much value for MEV-carrying transactions (because it only guarantees inclusion rather than ordering).</li>
<li><span>Mechan-stein addresses <strong>design goal <span class="hashtag-raw">#3:</span> preserve the neutrality of Ethereum block space.</strong></span> By allowing many participants to co-create the set of constraints enforced on the builder of each block, high preference entropy is achieved without unduly benefiting the transactions that land in an inclusion list, as block builders can still reorder and insert at their leisure. However, the builder’s ability to exclude is limited, removing some of their monopolist power over the transactions in the block.</li>
</ul>
<p>The combined mechanism creates a set of checks and balances where the weaknesses of one design in isolation are the strengths of another. Everything is perfect, right?</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49714-potential-issues-with-mechan-stein-10" name="p-49714-potential-issues-with-mechan-stein-10"></a>Potential issues with Mechan-stein</h3>
<p>It might not be only rainbows and butterflies. Without being comprehensive (neither in the list of potential issues nor the responses to said issues), let’s run down a few of the most obvious questions with Mechan-stein and some initial counter-points.</p>
<ul>
<li><span><strong>Point <span class="hashtag-raw">#1</span></strong> – complexity, complexity, complexity.</span> This could (and maybe should) count for multiple points (h/t Mallesh for the relevant <a href="https://x.com/malleshpai/status/1748026472923623619" rel="noopener nofollow ugc">tweet</a>). Each of these proposals involves massive changes to the consensus layer of Ethereum with wide-ranging impact (particularly on the fork-choice rule). The devil is truly in the details, and getting something like this spec’ed out and implemented would be an immense research and engineering lift – let’s just say <a href="https://en.wikipedia.org/wiki/Occam%27s_razor" rel="noopener nofollow ugc">William of Ockham</a> would not be impressed.
<ul>
<li><span><strong>Counter-point <span class="hashtag-raw">#1</span></strong> – building the future of finance in a permissionless and hyper-financialized world wasn’t going to be simple (“Rome wasn’t built in a day”).</span> It shouldn’t be shocking that there doesn’t seem to be a silver bullet for building an MEV-aware, decentralized, credibly neutral blockchain. Maybe eating the complexity now can leave the chain in a more stable equilibrium. Also, there may be significant synergies in combining designs (e.g., using the same committee for <code>FOCIL</code> and <code>PTC</code>). You could probably do a subset of Mechan-stein and still get some benefits (e.g., <code>FOCIL</code> + <code>PTC</code>).</li>
</ul>
</li>
<li><span><strong>Point <span class="hashtag-raw">#2</span></strong> – how may the ahead-of-time slot auction distort the MEV market?</span> Mostly just reciting <a href="https://arxiv.org/pdf/2408.03116" rel="noopener nofollow ugc">Max and Mallesh’s</a> argument (3rd time referencing that paper in this article lol). By removing the real-time nature of the initial auction, you bias it towards a winner-take-all for the best builder (or the “Best Block Space Future Value Estimator™”). I’d say this is similar in spirit to the Phil Daian view of making the competition as deterministic as possible (e.g., <a href="https://youtu.be/SBOGdofF4u8?t=620" rel="noopener nofollow ugc">“deterministic vs statistical opportunities”</a>).
<ul>
<li><span><strong>Counter-point <span class="hashtag-raw">#2</span></strong> – that is the point of still having the <code>PTC</code> conduct a JIT Top-of-Block auction.</span> I think this feels reasonable. However, there is still a slight edge that the auctioneer (who may be a builder themselves) has in the JIT auction, which is they can benefit from the sophistication and latency investments as they are the auctioneer and a participant. As mentioned above, you could consider skipping the <code>Execution Auctions</code> part of Mechan-stein and just going with <code>FOCIL</code> + <code>PTC</code> (or even leave <code>MEV-boost</code> alone as the primary PBS market and just do <code>FOCIL</code>). (h/t Justin for pointing out that you could try to do <code>Execution Auctions</code> where multiple proposers (more than one auction winner) are selected – another combined mechanism that tries to mitigate the multi-slot MEV risk.)</li>
</ul>
</li>
<li><span><strong>Point <span class="hashtag-raw">#3</span></strong> – there is still power in being the block producer.</span> As pointed out in this <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870/3">comment</a> and <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870/4">its response</a> on the <code>FOCIL</code> post, there is still some discretionary power in being the block builder. Namely, they can choose which ILs they exclude from their aggregate up to some protocol-enforced tolerance. This notion of having an IL “aggregator” is the main difference between <code>FOCIL</code> and a leaderless approach like <a href="https://www.youtube.com/watch?v=mJLERWmQ2uw" rel="noopener nofollow ugc">Braid</a>.
<ul>
<li><span><strong>Counter-point <span class="hashtag-raw">#3</span></strong> – this seems like a fundamental feature.</span> Again, I find myself leaning on Phil’s comment and mental model for “how economic power expresses itself in the protocol.” In a distributed system with network latency and geographic decentralization, some parties will have advantages over others. Suppose the protocol doesn’t explicitly imbue some participants with power during some period (e.g., by electing a leader). In that case, that power will still manifest somewhere else, likely in a more implicit (thus more sophisticated) way. This is more of a meta point, and I am happy to be convinced otherwise.</li>
</ul>
</li>
</ul>
<p>All right, going to cut it here; hope you found it interesting. Lot’s to think on still.</p>
<p><em>thank for reading <img alt=":heart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/heart.png?v=12" title=":heart:" width="20" /> -mike</em></p>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#p-49714-footnotes-11" name="p-49714-footnotes-11"></a>footnotes</h3>
<p><span class="math">^{[1]}</span><a name="fn1dst"></a>: It is worth noting that, conditioned on having strong censorship resistance properties, the difference between a monopolist builder and a competitive marketplace of builders isn’t so vital. As discussed with Barnabé and Julian, perhaps a more important property is the “replace-ability” of a monopolist builder if they begin abusing their power. All else being equal, I still prefer the outcome where we have multiple builders, even if just for the memetic reality of having a single block builder looks highly centralized, even if the other consensus participants heavily constrain them. Hence, builder competition still feels like a fair desiderata.<a href="https://ethresear.ch#fn1"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[2]}</span><a name="fn2dst"></a>: Vitalik pointed out that when he originally wrote this, he was referring more to the act of validating the blocks (e.g., by verifying a ZK proof) rather than explicitly participating in consensus. The name “validator” denotes someone who engages in consensus, which has been a nomenclatural pain point since the launch of the beacon chain. Despite this, I still like the framing of keeping some form of consensus participation decentralized (mainly as a means to better chain neutrality), so I will slightly abuse the naming confusion. xD <a href="https://ethresear.ch#fn2"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[3]}</span><a name="fn3dst"></a>: It is worth noting that validators could also choose to only sell their block at a premium in the more general case through the use of the <a href="https://writings.flashbots.net/the-cost-of-resilience" rel="noopener nofollow ugc"><code>min-bid</code></a> feature of <code>MEV-boost</code>. See more on <code>min-bid</code> from <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/8aCbi_a-Gh5DWnkJWstm8zA5fvtoQB-QR5we7C8XC90" rel="noopener nofollow ugc">Julian</a> and <a href="https://hackmd.io/@dataalways/resilience" rel="noopener nofollow ugc">Data Always</a>. <a href="https://ethresear.ch#fn3"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
            <p><small>3 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/mechan-stein-alt-franken-ism/20321">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 21 Aug 2024 13:23:40 +0000</pubDate>
</item>
<item>
<title>L2 sequencer proving on weak hardware; parallelization and decentralization</title>
<link>https://ethresear.ch/t/l2-sequencer-proving-on-weak-hardware-parallelization-and-decentralization/20313</link>
<guid>https://ethresear.ch/t/l2-sequencer-proving-on-weak-hardware-parallelization-and-decentralization/20313</guid>
<content:encoded><![CDATA[
<div> 关键词：Linea、Risc0、zkVM、p2p网络、证明时间

总结:
文章主要探讨了如何通过使用Risc0和zkVM技术来减少区块链验证时间，并同时实现去中心化。首先，作者指出大部分L2（Layer 2）序列器采用闭源方式运行，这需要强大的集中式计算能力。为了实现去中心化，需要接受去中心化网络固有的延迟和噪音。

文章进一步解释了Risc0与zkVM结合使用的方法。zkVM限制了一次能证明的最大计算周期数，大约为16.78百万周期。通过递归将大型程序分割成多个子程序（称为Risc0中的“段”），并分别证明这些子程序，最后聚合证明以模拟整个程序的一次性证明。例如，要证明一个1百万周期的程序，理论上需要分割成大约60个段。

文章提出了分段、并行证明和去中心化策略。通过适当的节点配置，即使在较弱的硬件上，也可以快速证明大型程序。假设有一个去中心化的验证计算网络，可以实现至少840个节点来处理证明工作，并且考虑到冗余因素，这个网络可以处理相当于10个类似于Linea的L2区块链的证明任务。

结论：
通过上述方法，理论上可以显著减少证明时间，并同时提供去中心化的解决方案。然而，为了验证这一设想的有效性，需要实际测试这种设置。如果成功，10,000个较弱节点组成的去中心化网络可以处理多达10个类似Linea的L2区块链的验证任务。 <div>
<p><a href="https://ethresear.ch/t/vortex-building-a-prover-for-the-zk-evm/14427">Linea’s sequencer</a> proves a 30m gassed block of transactions in 5 minutes. Here’s its setup:</p>
<blockquote>
<ul>
<li>On a 96 cores machine with 384 GB of RAM (hpc6a.48xlarge on AWS)</li>
<li>In 5 minutes (only including the inner-proof)</li>
</ul>
</blockquote>
<p>So is it possible to reduce the proving time and, at the same time, obtain decentralization guarantees? We have an idea.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49694-overview-1" name="p-49694-overview-1"></a>Overview</h3>
<p>Almost all of the L2 sequencers are closed-source, intellectual property, and thus protected behind centralized setups. To cram that much power into an entity requires a great deal of justification today. To decentralize the flow, on the other hand, one has to accept certain amounts of delay and noise usually found in decentralized compute networks.</p>
<h4><a class="anchor" href="https://ethresear.ch#p-49694-zkvms-recursion-and-risc0s-approach-2" name="p-49694-zkvms-recursion-and-risc0s-approach-2"></a>zkVMs, recursion, and Risc0’s approach</h4>
<p>Any zkVM toolset puts a certain upper bound on the maximum number of cycles(roughly speaking 1 cycle equals 1 operation) it can prove in one go. This is usually done for efficiency reasons. For <a href="https://github.com/risc0" rel="noopener nofollow ugc">Risc0</a>, a RISC-V general zkVM, it is 2^24 ~ 16.78m cycles. With recursion, proving infinitely sized programs are made possible. So the solution is to divide a large program into individual sub-programs(called segment in Risc0 jargon) and have them proved one by one and aggregate the proofs into a final proof as if the whole program was proved in one go. For example, consider proving a 1b cycles program. With 16.78M maximum segment size limit, one ends up proving 60 segments. The upper bound for segment size limit is not the end of story however and one can customize it into a well-known range of [2^13 - 2^24]. Each segment limit size needs specific memory requirements shown on Table 1:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/7/b790b7f5fb18cec94d0e621383844425862ba9fb.png" title="Screenshot from 2024-07-18 14-37-34"><img alt="Screenshot from 2024-07-18 14-37-34" height="387" src="https://ethresear.ch/uploads/default/optimized/3X/b/7/b790b7f5fb18cec94d0e621383844425862ba9fb_2_690x387.png" width="690" /></a></div><br />
Extrapolating Table 1’s values, we get 50m cycles for a program that needs 384gb of memory, in order to be proved in Risc0. Recall that Linea’s prover uses 384gb of memory to generate proofs. This is a naive 1-1 translation, but we can treat it as baseline for further testing. So, with this assumption, should one write Linea’s sequencer logic in Risc0, she would end up with a program that is 50m cycles long. Doubling cycles to ~90m, to account for aggregation won’t hurt here.<p></p>
<h4><a class="anchor" href="https://ethresear.ch#p-49694-segmentation-parallel-proving-and-decentralization-3" name="p-49694-segmentation-parallel-proving-and-decentralization-3"></a>Segmentation, parallel proving, and decentralization</h4>
<p>Recursion is a powerful idea in zkVM proving. With recursion once can get to prove seemingly large programs very quickly assuming she has a prove-ready network of machines. Table 2 shows a segmented prove session for a 90m cycles program on a pretty weak machine(8+ years old, Intel core i7 5500U(2C 4T), 16gb memory):<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/9/091af39f1eb4b3465f1de18222eed6c4d1051edb.png" title="Screenshot from 2024-07-18 14-47-06"><img alt="Screenshot from 2024-07-18 14-47-06" height="235" src="https://ethresear.ch/uploads/default/optimized/3X/0/9/091af39f1eb4b3465f1de18222eed6c4d1051edb_2_690x235.png" width="690" /></a></div><p></p>
<p>As you can see, different segment size limits result in varied proving regimes. In Table 2, two columns are colored in green, 2^18 and 2^19. Consulting Table 1, we would get 2gb and 4gb of required memory to prove them respectively. These columns are sweet spots for any zkVM proving network whose nodes are presumably weak. Focusing on the 2^19 segment size limit, to prove a 90m cycles program, one would need at least 168 nodes in order to prove the program in 4 minutes and 9 seconds. But 168 nodes is a faulty assumption. In reality, if a p2p network is to undertake the proving job, it needs to have redundancy values of 1:4 and above. The redundancy accounts for noise that is a feature of any p2p network. With 1:4 redundant nodes, 1 in every 5 nodes is assumed to be honest and the rest are time wasters. So, a 1:4 redundant p2p network needs at least of 840 nodes to get the job done.<br />
Assuming that the proving network is p2p, one can expect to obtain decentralized guarantees en route.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49694-conclusion-4" name="p-49694-conclusion-4"></a>Conclusion</h3>
<p>Here we introduced an imaginary setup to decentralize and improve L2 sequencer proving times. If the claim turns out to be legit, we would expect to improve the overall proving time for any zkVM application area. In addition, the setup provides decentralization guarantees as a side effect. While everything looks nice, we, at <a href="https://github.com/WholesumNet" rel="noopener nofollow ugc">Wholesum network</a> would like to put this setup to test and see if it works in action. If successful, a p2p verifiable compute network of 10,000 weak nodes can handle up to 10 Linea like L2s.</p>
<p>A somewhat more expanded version of this post is also available <a href="https://github.com/WholesumNet/docs/blob/779942cf6f650d24fcedf2d8da5a6dd2033a9fee/parallelization/parallelized-proving/report.pdf" rel="noopener nofollow ugc">here</a>.</p>
<p>We appreciate your feedback.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/l2-sequencer-proving-on-weak-hardware-parallelization-and-decentralization/20313">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 15:18:35 +0000</pubDate>
</item>
<item>
<title>On Proposer Timing Games and Economies of Scale</title>
<link>https://ethresear.ch/t/on-proposer-timing-games-and-economies-of-scale/20309</link>
<guid>https://ethresear.ch/t/on-proposer-timing-games-and-economies-of-scale/20309</guid>
<content:encoded><![CDATA[
<div> 关键词：提案者时机游戏、经济规模、验证器市场份额、累积投票、网络影响

总结：

文章主要探讨了在以太坊等区块链系统中，验证器如何通过“提案者时机游戏”来影响区块构建过程，以及经济规模对这类游戏的影响。关键发现如下：

1. **累积投票与时机选择**：在任何给定时刻，累积投票百分比代表了网络上已确认的投票比例。提案者需要确保在他们决定提交区块时，累积投票百分比至少达到40%，以避免区块被后续提案者重新组织。

2. **经济规模影响**：拥有更高验证器市场份额的提案者可以更长时间地推迟区块提交，因为他们的投票量足够大，可以在最后阶段补充足够的支持，而不会面临被重新组织的风险。具体而言，每增加1%的验证器市场份额，提案者可以额外延迟大约0.03秒。

3. **市场占有率与延时关系**：一个拥有30%市场占有率的提案者理论上可以比5%市场占有率的提案者多延迟约0.8秒，同时仍能保持安全的区块提交时间，避免被重新组织。

4. **策略与风险**：高市场份额的节点可以通过更晚提交区块来最大化自己的利益，这要求节点间有协调机制，确保在提交区块前，未投票的验证器将支持该区块，而不是其父区块。这体现了经济规模带来的优势和相应的风险管理策略。

5. **网络影响与限制**：过度依赖提案者时机游戏可能会对网络稳定性产生负面影响，包括导致验证器间的不协调或竞争，以及潜在的系统效率下降。因此，研究和实践应侧重于减少此类游戏的负面影响，鼓励公平和稳定的网络运作。

通过上述分析，文章强调了经济规模在区块链网络中的作用，以及在设计和优化网络机制时需要考虑的复杂因素，以平衡效率、公平性和安全性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49689-on-proposer-timing-games-and-economies-of-scale-1" name="p-49689-on-proposer-timing-games-and-economies-of-scale-1"></a>On Proposer Timing Games and Economies of Scale</h1>
<p><a href="https://timing.pics">Timing games</a> are a known phenomenon (<a href="https://eprint.iacr.org/2023/760">[1]</a>, <a href="https://arxiv.org/abs/2305.09032">[2]</a> and <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">[3]</a>). The concern is that proposer timing games come with a negative impact on the network.</p>
<p>In the following, I want to show how the success of playing proposer timing games is also a function of economies of scale.</p>
<p><strong>The main finding is:</strong><br />
<em><strong> → An entity with 30% market share can delay 0.8s longer than a 5% entity.</strong></em><br />
<em><strong> → For every 1% increase in validator market share, the delay in block proposals can increase by 0.03 seconds without facing additional reorg risk.</strong></em></p>
<p><img alt="tgeos" height="318" src="https://ethresear.ch/uploads/default/original/3X/c/5/c58fec82d848d1fb7ae0352e8c50c4e8071253c5.png" width="456" /></p>
<p><em>Special thanks to <a href="https://x.com/weboftrees">Anders</a>, <a href="https://x.com/mikeneuder">Mike</a> and <a href="https://x.com/casparschwa">Caspar</a> for feedback!</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49689-introduction-2" name="p-49689-introduction-2"></a>Introduction</h2>
<p>A proposer must gather at least 40% of these votes to ensure their block is accepted and not reorged by the following proposer. It’s 40% because that’s the proposer boost threshold. Blocks with less than 40% attestations can be reorged by the next proposer leveraging proposer boost. The challenge for a timing-gamer lies in determining the optimal time to propose (or call getHeader). An economically rational validator would want to wait as long as possible (providing the builder with the longest possible time window) without risking a reorg.</p>
<p>First, let’s revisit the following chart from <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">this analysis</a>:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/2/42fe46361f7b2a22bd61c0195f719a57df04d64d.png" title="42fe46361f7b2a22bd61c0195f719a57df04d64d"><img alt="42fe46361f7b2a22bd61c0195f719a57df04d64d" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/4/2/42fe46361f7b2a22bd61c0195f719a57df04d64d_2_690x304.png" width="690" /></a></div><p></p>
<p><strong>~80% of all attestations are seen until second 5 in the slot</strong>. The <strong>40% threshold is reached somewhere around second 3.8</strong>. Thus, assuming zero latency, a block published at second 3.8 should still be able to receive 60% of attestations.</p>
<p><strong>In the following, we refer to this curve as <span class="math">C(t)</span>.</strong></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49689-initial-setup-3" name="p-49689-initial-setup-3"></a>Initial Setup</h2>
<p>The core idea is to determine how the cumulative votes cast by validators evolve over a slot and how a proposer’s control over a portion of these validators may influence the optimal timing of their block proposal.</p>
<p>Given that <span class="math">C(t)</span> represents the cumulative percentage of votes cast by time <span class="math">t</span>, the proposer controls <span class="math">x\%</span> of validators, and needs to ensure that they can still reach at least 40% by the time they propose, we start with the following condition:</p>
<div class="math">
x + (1 - C(t)) \times (1 - x) \geq 0.4
</div>
<p>In this equation:</p>
<ul>
<li><strong><span class="math">(1 - C(t)) \times (1 - x)</span>:</strong> The remaining uncast votes from validators not controlled by the proposer, which could support the proposer’s block.</li>
</ul>
<blockquote>
<p>Note that <strong><span class="math">x \times C(t)</span></strong> would be the portion of votes from the proposer’s validators already included in <span class="math">C(t).</span></p>
</blockquote>
<p>Two assumptions are important to stress:</p>
<ul>
<li><strong>Coordination</strong>: It is assumed that validators coordinate when attesting, e.g. using a central oracle that provides the commands.</li>
<li><strong>Honest Validators</strong>: All validators who have not yet voted at the time of the block proposal will vote for the proposed block (and not the parent block). See <a href="https://github.com/ethereum/consensus-specs/blob/b2f2102dad0cd8b28a657244e645e0df1c0d246a/specs/phase0/validator.md#phase-0----honest-validator">honest validator specs</a>.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#p-49689-simplifying-the-equation-4" name="p-49689-simplifying-the-equation-4"></a>Simplifying the Equation</h3>
<p>We rearrange the initial equation to find the threshold for <span class="math">C(t)</span>, the cumulative percentage of votes that can be cast before the proposer must act:</p>
<div class="math">
x + (1 - C(t)) \times (1 - x) \geq 0.4
</div>
<p>Expanding and simplifying:</p>
<div class="math">
(1−C(t))×(1−x) = 1 - x - C(t) + C(t) \times x 
</div>
<div class="math">
1 - C(t) + C(t) \times x \geq 0.4
</div>
<p>Finally, solving for <span class="math">C(t)</span>:</p>
<div class="math">
C(t) \leq \frac{0.6}{1 - x}
</div>
<p>Find the complete derivation <a href="https://hackmd.io/L0A6zeBZSzGew2Ni0AzFVQ">here</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49689-interpretation-5" name="p-49689-interpretation-5"></a>Interpretation</h3>
<p>This simplified equation <span class="math">C(t) \leq \frac{0.6}{1 - x}</span> means that the proposer can safely propose as long as the cumulative attestations <span class="math">C(t)</span> remain below the threshold defined by <span class="math">\frac{0.6}{1 - x}</span>.</p>
<ul>
<li><strong><span class="math">C(t)</span>:</strong> The cumulative percentage of votes cast by time <span class="math">t</span>.</li>
<li><strong><span class="math">x \%</span>:</strong> The percentage of total validators controlled by the proposer.</li>
<li><strong><span class="math">0.4</span>:</strong> The 40% threshold needed to secure a majority (<span class="math">1-0.4=0.6)</span>.</li>
</ul>
<p>The equation ensures that the proposer, with their share of validators, can still influence the outcome favorably by proposing before the cumulative attestations exceed this threshold.</p>
<p>A node operator with many validators can risk a few seconds more than a small-size operator, knowing that their own validators will never vote against them.</p>
<p><strong>The following chart shows the effects of economies of scale and answers the question of <em>how long a node operator with <em>x%</em> market share can maximally wait until the point it won’t be able to receive at least 40% of all attestations anymore</em>.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/2/e24d2c92d6d6e9a6965edcac0b21f454c6404795.png" title="timing_games_proposer_share"><img alt="timing_games_proposer_share" height="383" src="https://ethresear.ch/uploads/default/optimized/3X/e/2/e24d2c92d6d6e9a6965edcac0b21f454c6404795_2_690x383.png" width="690" /></a></div><p></p>
<p>The “<em>seconds in slot</em>” values on the y-axis are <code>attestation_seen</code> timestamps that are not corrected by the time required for block propagation and verification. Since those numbers are just constants impacting the absolute values on the y-axis, this doesn’t matter in making the relative impact of market share on the limits of timing games visible.</p>
<p><strong>We can see that a node operator with 30% of the market share can potentially wait 0.8 seconds longer than a node operator with 5% market share while risking the same.</strong></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49689-in-python-6" name="p-49689-in-python-6"></a>In Python</h2>
<p>Using Python, we can calculate the latest “safe” proposal time for different percentages of validator control. Here’s the key part of the implementation:</p>
<pre><code class="lang-python">import numpy as np
from scipy.interpolate import interp1d

# Provided cumulative attestation data (seconds, % of casted attestations)
data = [
     (0.791, 0.0005390835579514825),
     # (additional data points omitted for brevity)
     (2.228, 0.05444743935309973),
     (2.464, 0.10835579514824797),
     (2.639, 0.16226415094339622),
     (2.777, 0.21617250673854446),
     (2.932, 0.27008086253369273),
     (3.104, 0.323989218328841),
     (3.308, 0.3778975741239892),
     (3.627, 0.43180592991913747),
     (4.069, 0.4857142857142857),
     (4.25, 0.539622641509434),
     (4.407, 0.5935309973045823),
     (4.576, 0.6474393530997304),
     (4.723, 0.7013477088948787),
     (4.898, 0.7552560646900269),
     (5.039, 0.8091644204851752),
     (5.245, 0.8630727762803234),
     (5.521, 0.9169811320754717),
     (6.187, 0.9708894878706199)
]

# Extracting the times and cumulative attestation percentages
times = np.array([point[0] for point in data])
cumulative_attestations = np.array([point[1] for point in data])

# Interpolating the cumulative attestation function
cumulative_attestation_func = interp1d(times, cumulative_attestations, kind='linear', fill_value="extrapolate")

# Function to calculate the latest time a proposer with x% control can safely propose a block
def calculate_latest_proposal_time(x):
    threshold = 0.5 / (1 - x)
    
    for t in np.linspace(times[0], times[-1], 1000):
        if cumulative_attestation_func(t) &gt; threshold:
            return t
    return None

</code></pre>
<h1><a class="anchor" href="https://ethresear.ch#p-49689-conclusion-7" name="p-49689-conclusion-7"></a>Conclusion</h1>
<p>By understanding and calculating the relationship between validator market share and cumulative attestations, proposers can optimize their proposal timing to minimize the likelihood of reorgs while maximizing profits.</p>
<p>Such strategies could be improved by checking which CL client the subsequent validator runs, or, even simpler, the slot index in an epoch. Based on that information one can better estimate the chances of getting reorged (e.g. if it’s Teku, Nimbus, Lodestar, or the last slot in an epoch, then the reorg probability is significantly lower because no honest reorg strategy is implemented).</p>
<p>Pushing proposer timing games to their limits has a <a href="https://ethresear.ch/t/on-attestations-block-propagation-and-timing-games/20272">negative impact on attesters</a> and can have cascading effects: If validators realize they miss out on profits because they vote for the wrong block too often, they might start delaying their attestation.</p>
<p><strong>Ultimately, pushing timing games to their limits can have a detrimental impact on the network. Furthermore, validator coordination that goes beyond running multiple validators from a single node shouldn’t be tolerated/supported. Now, it is important to follow/contribute to block construction research and find ways to <a href="https://eips.ethereum.org/EIPS/eip-7716">reduce the profitability of timing games</a> or prevent them entirely.</strong></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/on-proposer-timing-games-and-economies-of-scale/20309">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 05:48:59 +0000</pubDate>
</item>
<item>
<title>Decentralized and Verifiable Cloud Service on Ethereum</title>
<link>https://ethresear.ch/t/decentralized-and-verifiable-cloud-service-on-ethereum/20292</link>
<guid>https://ethresear.ch/t/decentralized-and-verifiable-cloud-service-on-ethereum/20292</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、去中心化云服务、验证性、计算密集型服务、区块链探索器

总结:

本文提出了一种基于以太坊的去中心化验证云服务协议，旨在为Web2或Web3应用提供计算密集型服务。该协议通过将前端和后端组件全栈迁移至去中心化云端，推动构建完全去中心化、可验证的Web3应用程序成为可能。其核心设计包括：

1. **服务合约**：以类似gRPC protobuf的方式在以太坊上存在，定义服务和方法，供用户调用。

2. **服务提供商注册与质押**：服务提供者需注册并质押以参与服务，多个提供者为每项服务提供服务。

3. **用户请求流程**：用户发起请求（如AI推理）时，首先通过以太坊可验证轻客户端获取可用服务提供商列表，随机选择几方并发执行请求，并验证结果一致性。

4. **仲裁机制**：当结果不一致时，触发链上仲裁过程，确保至少有一个诚实节点的存在，以保证服务正确性。

5. **收费机制**：支持订阅模型、链上支付机制和免费服务模型，以适应不同需求和预算。

此协议旨在降低成本、提高速度、增强信任度、实现可验证性，并最终推动构建更去中心化的Web3应用生态系统，例如去中心化的区块链探索器、AI平台和云游戏服务。通过集成零知识证明等技术，进一步保护用户隐私。 <div>
<p><em>by <a href="https://x.com/0x_1cc" rel="noopener nofollow ugc">KD.Conway</a></em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-tldr-1" name="p-49659-tldr-1"></a>TL;DR</h2>
<ul>
<li>
<p>We propose a decentralized and verifiable cloud service protocol on Ethereum, which can provide computationally intensive service to all web2 or web3 applications, making decentralized ChatGPT, decentralized blockchain explorer reality. By migrating the full stack, including frontend and backend components, to the decentralized cloud, we move toward fully decentralized and verifiable end-to-end Web3 applications.</p>
</li>
<li>
<p>The protocol operates under a minority trust assumption, requiring only one honest node to guarantee service quality. Additionally, the correctness of the cloud service is verifiable on Ethereum.</p>
</li>
<li>
<p>With near-zero on-chain costs, our decentralized cloud service platform can be even more affordable than traditional centralized options.</p>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-protocol-overview-2" name="p-49659-protocol-overview-2"></a>Protocol Overview</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/8/d816db0bb6bbc127b1a5f2fa1f320e7c923dbb77.png" title="ecs"><img alt="ecs" height="331" src="https://ethresear.ch/uploads/default/optimized/3X/d/8/d816db0bb6bbc127b1a5f2fa1f320e7c923dbb77_2_690x331.png" width="690" /></a></div><p></p>
<p>A service contract exists on Ethereum, functioning similarly to a gRPC protobuf. This contract defines the service, and the functions within it specify the methods that can be invoked.</p>
<p>Each service provider must register and stake on the service contract. For each service, multiple providers will be available to offer the service.</p>
<p>When a user initiates a service request, such as requesting an AI inference from an LLM model:</p>
<ul>
<li>
<p>The user first utilizes a verifiable Ethereum light client, such as Helios, to retrieve the list of available service providers from the on-chain service contract.</p>
</li>
<li>
<p>The user randomly selects several providers from this list.</p>
</li>
<li>
<p>The user then sends off-chain transactions to these selected providers in parallel. These off-chain transactions are essentially the same as calling the corresponding service function in the smart contract, but they use a different chain ID. This specific chain ID indicates that the transaction is intended to call a cloud service rather than perform an on-chain transaction on Ethereum.</p>
</li>
<li>
<p>The service providers execute the required computations in their local environments according to the program defined in the corresponding function in the service contract. They then return the responses to the user. Each response is signed by the service provider and includes the user’s transaction hash and the results.</p>
</li>
<li>
<p>Upon receiving the responses from the selected providers, the user first verifies the signatures and checks the consistency of the results.</p>
<ul>
<li>
<p>If the results are consistent, the service is considered to have functioned correctly, and no further action is required.</p>
</li>
<li>
<p>If there is a discrepancy in the results, this indicates the presence of at least one malicious service provider. In this case, the user submits the providers’ responses to the on-chain arbitration contract. This triggers a process where the service providers must defend the accuracy of their results. The on-chain arbitration process is detailed in the following section.</p>
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-service-contract-3" name="p-49659-service-contract-3"></a>Service Contract</h2>
<p>The design of the service contract is akin to the design of gRPC. A new service contract corresponds to a new service in gRPC, and the functions defined in the service contract specify the methods that can be invoked. Due to the constraints of smart contracts, we cannot implement complex computations, such as AI computations, directly within the smart contract. Instead, we define a standard for writing a program, which is then uploaded to decentralized DA services, with the program’s hash stored in the on-chain smart contract.</p>
<p>Following the design principle of “Separate Execution from Proving,” there are two implementations for the service program. One is compiled for native execution, optimized for speed, and can leverage multithreaded CPUs and GPUs to accelerate execution. The other implementation is for proving; the service program is compiled into machine-independent code, allowing us to use zkVM (zero-knowledge virtual machine) or fpVM (fraud-proof virtual machine) to generate proofs. This dual-target approach ensures fast execution, while proving is based on the machine-independent code.</p>
<p>For example, consider matrix multiplication. Native execution utilizes GPU computation (e.g., CUDA) for acceleration. During the proving phase, the service program is compiled into machine-independent instructions, which can be executed in zkVM or fpVM. Both implementations ensure consistent execution results.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/1/b1ccfdf9e6f994151293a835a4619dca5e974865.png" title="output"><img alt="output" height="151" src="https://ethresear.ch/uploads/default/optimized/3X/b/1/b1ccfdf9e6f994151293a835a4619dca5e974865_2_690x151.png" width="690" /></a></div><p></p>
<p>When processing user requests, service providers will run the program in the native execution environment and return the results to the users. Only when on-chain arbitration is required will the service providers run the program for proving. This approach allows service providers to handle requests as quickly as possible in most cases.</p>
<p>Additionally, the service program can be configured to read data from trustworthy sources, such as Ethereum or other blockchains, as well as from decentralized, trustworthy data storage providers. This flexibility allows the service program to function as a blockchain explorer, an AI service, or a decentralized search engine.</p>
<p>A demo version of the service contract is shown below.</p>
<pre><code class="lang-solidity">contract Service {

    // address =&gt; web2 domain
    mapping(address =&gt; string) serviceProviderHost;

    address[] serviceProviders;

    // function selector =&gt; programHash
    mapping(bytes4 =&gt; bytes32) programHashs;

    event Request(
        address account,
        bytes4 functionSelector,
        bytes32 programHash,
        bytes input
    );

    function func1(bytes calldata input) public {
        emit Request(msg.sender, this.func1.selector, programHashs[this.func1.selector], input);
    }
}
</code></pre>
<p>Note that <code>func1</code> specifies the method that can be called. When a user wants to call <code>func1</code>, instead of sending an on-chain transaction on Ethereum, the user needs to send an off-chain transaction directly to the service providers. Besides, the user can obtain the list of service provider addresses, along with their corresponding Web2 domains using Ethereum verifiable light client.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-onchain-arbitration-4" name="p-49659-onchain-arbitration-4"></a>Onchain Arbitration</h2>
<p>We support multiple proving systems for on-chain arbitration, including zero-knowledge proofs, Trusted Execution Environments (TEE), and fraud-proof systems. For demonstration purposes, we focus on the fraud-proof system, as it offers lower generation costs compared to zero-knowledge proofs and does not require specific hardware. In previous work, we demonstrated the ability to generate fraud proofs for extremely large AI models. For more details, please refer to opML (<a class="inline-onebox" href="https://arxiv.org/abs/2401.17555" rel="noopener nofollow ugc">[2401.17555] opML: Optimistic Machine Learning on Blockchain</a>).</p>
<p>The on-chain arbitration process using the fraud-proof system proceeds as follows:</p>
<ul>
<li>
<p>If a user receives inconsistent results from the service providers, they submit the providers’ responses to the on-chain arbitration contract, initiating an interactive dispute game with all the involved providers.</p>
</li>
<li>
<p>At this point, the service providers must run the proving-version of the service program in their local fraud-proof VMs to generate the fraud proof, which they then submit to the on-chain arbitration contract to defend their results. For more details on the interactive dispute game, refer to the fraud-proof system design.</p>
</li>
<li>
<p>Service providers who supplied incorrect results will lose the dispute game, resulting in their staked amount being slashed. The slashed stake will be distributed to the winners of the dispute game, as well as to the user, as compensation.</p>
</li>
</ul>
<p>This on-chain arbitration mechanism ensures that only one honest node is required to guarantee the correctness of the provided service. As a result, the protocol relies on a minority trust assumption and inherits security from Ethereum. Assuming at least one honest node and the safety of Ethereum, the protocol can guarantee the correctness of the service.</p>
<p>It’s important to note that on-chain arbitration only occurs when some service providers produce incorrect results. In typical cases, no on-chain interaction is needed, which allows the service to operate as quickly as current centralized cloud service providers.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-charging-mechanism-5" name="p-49659-charging-mechanism-5"></a>Charging Mechanism</h2>
<p>There are several possible charging mechanisms:</p>
<ul>
<li>
<p><strong>Subscription Model:</strong> This is similar to the Web2 approach, where the charging mechanism can be conducted off-chain. For example, to use ChatGPT via an API for commercial purposes, you would pay OpenAI a monthly fee to access their services. Multiple service providers can offer the service, allowing for competition and choice.</p>
</li>
<li>
<p><strong>On-Chain Payment Mechanism:</strong> Paying for each request on-chain can be costly due to transaction fees. Batching and rolling up these requests and payments can significantly reduce on-chain transaction costs. One possible approach is to use payment channels to pay for requests. Alternatively, service providers could generate service proofs and claim fees as follows:</p>
<ul>
<li>
<p>A service agreement contract specifies the price for each service request.</p>
</li>
<li>
<p>Users first stake funds into the service agreement contract.</p>
</li>
<li>
<p>Service providers can claim their fees by submitting service proofs to the on-chain service agreement contract. To minimize transaction costs, providers can batch and roll up user requests.</p>
</li>
<li>
<p>The on-chain service proof is a zk-proof, which verifies that the service provider has delivered a certain number of responses to users. The provider can then claim the corresponding service fees according to the agreement contract. This proof ensures the correctness of the user’s request transaction signature, the service provider’s response signature, and the transaction nonce.</p>
</li>
</ul>
</li>
<li>
<p><strong>Free Service Model:</strong> Another approach is for companies to cover the service fees by the themselves (currently, the web2 companies pay the cloud service fee by themselves), offering free services to users while generating revenue through other means, such as advertising or VIP services.</p>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-advantages-6" name="p-49659-advantages-6"></a>Advantages</h2>
<ul>
<li>
<p>This decentralized cloud service can be cheaper than centralized cloud services while maintaining similar speed.</p>
<ul>
<li>
<p><strong>Cost-Effectiveness:</strong> Decentralized servers can be significantly cheaper than centralized cloud servers. For example, <a href="http://io.net" rel="noopener nofollow ugc">io.net</a> has shown that the cost of decentralized GPUs can be as low as one-third of the cost of AWS. For services with lower security requirements, such as using LLMs for personal queries, using just two nodes is often sufficient. Additionally, a random check mechanism can be adopted, querying one node most of the time and occasionally checking another to verify correctness. This setup can be more cost-effective than centralized platform.</p>
</li>
<li>
<p><strong>Scalability and Speed:</strong> This platform can outperform centralized systems, especially for computationally intensive tasks. A decentralized cloud service platform operates on an N-to-M model (N users with M servers, where the number of servers can be infinite), whereas centralized platforms use an N-to-1 model (N users with a single super server). This allows a decentralized cloud service platform to scale more effectively. For instance, a centralized AI platform like ChatGPT may slow down during peak times because it can’t scale its computing power quickly enough. In contrast, decentralized platform can dynamically distribute the load across many servers, ensuring faster response times even during heavy usage.</p>
</li>
</ul>
</li>
<li>
<p><strong>Trustless and Verifiable:</strong> The protocol operates under a minority trust assumption, requiring only one honest node to guarantee service quality. Additionally, the correctness of the cloud service is verifiable on Ethereum.</p>
</li>
<li>
<p><strong>Censorship-Resilient:</strong> This platform contributes to a more robustly decentralized Web3, enhancing censorship resistance.</p>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-toward-fully-decentralized-and-verifiable-web3-application-7" name="p-49659-toward-fully-decentralized-and-verifiable-web3-application-7"></a>Toward Fully Decentralized and Verifiable Web3 Application</h2>
<p>With this protocol, we can move toward fully decentralized and verifiable Web3 applications.</p>
<p><strong>Decentralized and Verifiable Blockchain Explorer:</strong> Currently, blockchain explorers like Etherscan are hosted by centralized entities, and the results they present are not verifiable. If such an explorer were hacked, it could display malicious and misleading information, such as fake transactions or contracts, potentially leading to phishing scams. By migrating the entire blockchain explorer—including both the frontend and backend services—to our platform, we can ensure full verifiability and robust security for the blockchain explorer.</p>
<p><strong>Decentralized, Verifiable, Faster, and Cheaper AI Platform:</strong> This protocol enables the creation of a fully decentralized, verifiable, and cost-effective AI platform. By moving the entire stack, including both frontend and backend services as well as AI computation, to a decentralized cloud, we can build an AI platform that is not only more affordable but also potentially faster than centralized alternatives.</p>
<p><strong>Decentralized Cloud Gaming:</strong> Some games require high-end hardware, such as powerful GPUs and CPUs, leading game companies to move their games to cloud services, reducing the hardware requirements for customers. We can similarly bring Web3 games to our platform. Since our platform is verifiable on Ethereum, game reward settlements can be easily managed through smart contracts.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-further-discussion-8" name="p-49659-further-discussion-8"></a>Further Discussion</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49659-updating-the-state-9" name="p-49659-updating-the-state-9"></a>Updating the State</h3>
<p>In the previous discussion, the service program operates under a stateless design, meaning it does not modify its internal state. However, the data source used by the service program is upgradable. For instance, if a service program uses Ethereum as its data source, users can interact with smart contracts on Ethereum to update the state. The service program can then utilize the latest Ethereum state as its data source, enabling the implementation of a decentralized explorer.</p>
<p>If updating the internal state of the service program is required, a state machine replication network must be established among the service providers. In this case, each service program would correspond to a layer 2 or layer 3 blockchain on Ethereum. When users invoke a method that updates the internal state, they would send the transaction to the corresponding layer 2 or layer 3 blockchain. The service providers would then reach a consensus on the execution results of that transaction and update the internal state accordingly. Periodically, the layer 2 blockchain would roll up the transactions and its latest state back to Ethereum.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49659-verifiable-fhe-10" name="p-49659-verifiable-fhe-10"></a>Verifiable FHE</h3>
<p>To ensure user privacy, Fully Homomorphic Encryption (FHE) can be integrated into our protocol. In this case, the FHE computation would be incorporated into the service program. Instead of sending plaintext data to the service providers, users would encrypt their input and send only the ciphertext, thereby preserving their privacy. Additionally, if on-chain arbitration is triggered, the FHE service program would be compiled into machine-independent instructions, and a fraud proof or zk-proof would be generated to make the FHE computation fully verifiable.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49659-related-work-and-comparison-11" name="p-49659-related-work-and-comparison-11"></a>Related Work and Comparison</h2>
<p><strong>Comparison with Web3URL</strong></p>
<p>Web3URL (<a href="https://w3url.w3eth.io/" rel="noopener nofollow ugc">https://w3url.w3eth.io/</a>) is an interesting project that transforms Ethereum into an unstoppable decentralized web server. Our protocol can be seen as a significant extension of Web3URL. In Web3URL, service functions must be written within smart contracts, which naturally limits large-scale applications. In contrast, our protocol supports complex service programs, such as AI computations, and provides flexible access to large-scale data, making decentralized ChatGPT and decentralized explorers a reality.</p>
<p><strong>Comparison with ICP</strong></p>
<p>The Internet Computer (ICP: <a href="https://internetcomputer.org/" rel="noopener nofollow ugc">https://internetcomputer.org/</a>) hosts decentralized serverless compute, similar to our goal of creating a decentralized cloud service platform. However, we differ from ICP in several key aspects:</p>
<ul>
<li>
<p><strong>Ethereum Integration:</strong> We are building on Ethereum, allowing us to inherit its security features.</p>
</li>
<li>
<p><strong>Higher Security:</strong> We achieve a higher level of security compared to ICP. While ICP operates in a Byzantine Fault Tolerance (BFT) network under a majority trust assumption—requiring that most nodes in the subnet are honest—we adopt an approach similar to rollups, with on-chain arbitration ultimately reverting to Ethereum. This allows us to guarantee correctness under a minority trust assumption, where just one honest node can ensure the integrity of our protocol.</p>
</li>
<li>
<p><strong>Complex Computation:</strong> Following the design principle of “Separate Execution from Proving,” we can handle complex computations natively, such as LLM inference or even fine-tuning. In contrast, service programs in ICP always run within canisters, which significantly limits their applicability for large-scale computations.</p>
</li>
</ul>
<p>If you are interested in this project or have suggestions for improvements, please feel free to reach out to me.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/decentralized-and-verifiable-cloud-service-on-ethereum/20292">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 17 Aug 2024 11:48:03 +0000</pubDate>
</item>
<item>
<title>Censorship Insurance Markets for BRAID</title>
<link>https://ethresear.ch/t/censorship-insurance-markets-for-braid/20288</link>
<guid>https://ethresear.ch/t/censorship-insurance-markets-for-braid/20288</guid>
<content:encoded><![CDATA[
<div> 关键词：BRAID、流动性要求、用户体验、Censorship Insurance（Censorship保险）、市场解决方案

总结:

文章探讨了BRAID（一种旨在通过条件性打赏机制提高以太坊去中心化程度的多提案机制）在提升 censorship resistance（审查抗性）方面的创新，同时也指出了其在用户体验（UX）上的挑战，特别是由于流动性需求导致的问题。文章提出了两种潜在的解决方案：一种是“Proof of Post-State Liquidity”（后状态流动性证明），即用户需要提供证明，证明在交易执行后他们有足够的流动性来支付Censorship保险费用；另一种是引入Censorship Insurance（Censorship保险）市场，用户可以通过购买保险来降低实际支付的费用，并由第三方机构来承担额外的风险。

BRAID机制通过将交易分发到多个子链中并采用特定的排序规则，使得用户能够在不显著增加交易费用的情况下获得更高的去中心化程度。然而，为了确保交易能够被包括在区块链中，用户需要有足够的流动性来支付潜在的Censorship保险费用，这在大额交易时会成为负担。文章提出通过Censorship保险市场，可以降低用户为保证交易成功而需要准备的流动性，同时市场本身也能通过竞争机制调整保险费率，为用户提供更合理的价格。

文章最后指出，虽然Censorship保险市场的构建可能面临初期的挑战，但通过与应用或钱包平台的合作，或者建立基于请求报价（RFQ）的市场机制，可以有效地解决这一问题，从而为用户提供更好的交易体验，同时保持BRAID机制的去中心化优势。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/f/bf7665c93b36acdfa0cb7c8ed757aa3ef87f101f.jpeg" title="BRAID"><img alt="BRAID" height="500" src="https://ethresear.ch/uploads/default/original/3X/b/f/bf7665c93b36acdfa0cb7c8ed757aa3ef87f101f.jpeg" width="500" /></a></div><p></p>
<p>By: <a href="https://x.com/_jonahb_">Jonah Burian</a> and <a href="https://x.com/BenLevy0">Ben Levy</a></p>
<p><em>Tl;dr: We point out that BRAID’s liquidity requirements lead to poor user UX and suggest censorship insurance markets as a potential solution.</em></p>
<p><em>Thanks to <a href="https://x.com/maxresnick1">Max Resnick</a> and <a href="https://x.com/davidecrapis">Davide Crapis</a> for the feedback.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49651-intro-1" name="p-49651-intro-1"></a>Intro</h2>
<blockquote>
<p>“The greatness of <s>America</s> <em>Ethereum</em> lies not in being more enlightened than any other <s>nation</s> <em>blockchain</em>, but rather in her ability to repair her faults.” <em>- Alexis de Tocqueville</em></p>
</blockquote>
<p>Censorship resistance (CR) is one of the core security properties of a blockchain.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7e58a93fe9b45a91ecf29a6aefa91567c310262.png" title="CR"><img alt="CR" height="180" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7e58a93fe9b45a91ecf29a6aefa91567c310262_2_690x180.png" width="690" /></a></div><p></p>
<p>Ethereum gifts proposers with one-slot monopolies on transaction inclusion, creating a principal-agent problem and a single point of failure. A censoring party can bribe the current proposer to censor a transaction.</p>
<p>There has been considerable work to mitigate this problem. A key insight is that the weak link problem of a single proposer results in weak CR. Multi-proposer schemes like <a href="https://www.youtube.com/watch?v=mJLERWmQ2uw">BRAID</a> and <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870/1">FOCIL</a> can correct this principal-agent problem.</p>
<p>In this piece, we focus on BRAID, a multi-proposer mechanism that has garnered significant recent attention. It aims to increase CR in a capital-efficient way via a conditional tipping mechanism (explained below).</p>
<p>One challenge in this approach, the need for a deterministic ordering rule, is already well understood. <em><strong>In this piece we identify another challenge—liquidity requirements that adversely affect UX—and propose a few potential solutions.</strong></em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49651-braid-at-a-high-level-2" name="p-49651-braid-at-a-high-level-2"></a>BRAID at a High Level:</h2>
<p>BRAID runs <span class="math">k</span> subchains in parallel, each with a unique proposer. Block <span class="math">n</span> of Ethereum is the union of transactions from block <span class="math">n</span> of the <span class="math">k</span> subchains, with a special ordering rule applied to order this unordered set.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49651-tipping-in-braid-3" name="p-49651-tipping-in-braid-3"></a>Tipping in BRAID</h3>
<p>Bidders submit a conditional twin tip <span class="math">(t,T)</span> which depends on the number of proposers who include the transaction. If only a single proposer includes a transaction, they receive <span class="math">T</span>; if multiple proposers include the transaction, they split <span class="math">t</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49651-tipping-properties-4" name="p-49651-tipping-properties-4"></a>Tipping Properties</h3>
<p>Let <span class="math">ϕ(t,T)</span> be the minimum cost to censor a BRAID transaction. It has been <a href="https://arxiv.org/abs/2301.13321">shown</a> that <span class="math">ϕ(t,T)=kT</span>.</p>
<p>The goal of BRAID is that users will most likely never actually have to pay <span class="math">T</span>; instead, they pay <span class="math">t</span>, which can be much lower than <span class="math">T</span>.</p>
<p>This multi-dimensional tip disentangles the cost of inclusion (for the transacting party) from the cost of censoring such that <span class="math">t&lt;&lt;T</span>.</p>
<p>Simply put, a user get’s <span class="math">kT</span> worth of CR while (usually) only paying <span class="math">t</span>.</p>
<p><strong>How Users Will Tip:</strong></p>
<ul>
<li><span class="math">T</span>: From a user’s perspective, they set <span class="math">T=\frac{V}{k}</span> where <span class="math">V</span> is the value the user places in their transaction not being censored.</li>
<li><span class="math">t</span>: In current BRAID specs, the ordering of transactions depends on <span class="math">t</span>, with more favorable ordering (i.e., coming first) given to those with the highest <span class="math">t</span>. Therefore, a user will choose their <span class="math">t</span> based on where they want to be in the ordering.</li>
</ul>
<p><em>Note that if a user does not care about CR, they can set <span class="math">T=t</span> and send their transaction to just one proposer.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49651-the-ux-challenge-5" name="p-49651-the-ux-challenge-5"></a>The UX Challenge:</h2>
<p>While a user will only pay <span class="math">t</span> for their transaction, they need to have <span class="math">T</span> available to make a credible promise to the protocol that they can pay <span class="math">T</span>. Hence a user needs to have <span class="math">T</span> of additional available liquidity to make a transaction. We saw before that <span class="math">T \propto V</span>: <span class="math">T</span> tends to scale with the value of the transaction. This burdens users with a liquidity requirement.</p>
<p>For example, say a user wants to sell $5M of ETH due to impending interest rate fears and values censorship resistance at $1M. Let’s say there are 4 shards, i.e., <span class="math">k=4</span>. The user needs to have $250k of additional unpledged liquidity available just to exit their position. This hampers the UX of on-chain finance by placing additional and obscure liquidity requirements on participants that scale with the value of their positions.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49651-fixes-6" name="p-49651-fixes-6"></a>Fixes:</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49651-proof-of-post-state-liquidity-7" name="p-49651-proof-of-post-state-liquidity-7"></a><strong>Proof of Post-State Liquidity</strong></h3>
<p><strong>Idea:</strong> A user submits a transaction with a proof that they will have enough liquidity to pay <span class="math">T</span> if necessary after their transaction. In the case before, the proof will show that the transaction will give the user $1M of liquidity so they could afford the <span class="math">T=</span> $250k if necessary.</p>
<p><strong>Problem:</strong> This assumes that a proposer has a good understanding of the post-state of a transaction. Most financial transactions interact with shared state, and as a result, transaction ordering is needed to know the post-state. This knowledge relies on the final ordering so we can’t include it as an input to the transaction. Even when there is a reasonable lower bound on post-state available liquidity, establishing it would (unrealistically) require bespoke proofs for each transaction type.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49651-censorship-insurance-ci-8" name="p-49651-censorship-insurance-ci-8"></a>Censorship Insurance (CI)</h3>
<p><strong>Idea:</strong> A third party–the CI provider–can sponsor the escrow of <span class="math">T</span> for the transaction. Users will have to pay an insurance premium of <span class="math">rT</span> to the CI provider, where <span class="math">r</span> represents the rate (mostly) based on the likelihood of censorship. CI providers are thus assessing the rewards of censoring the transaction in real time to ensure it is below <span class="math">kT</span>.</p>
<p>To prevent an attack where a user purchases insurance and then only sends their tx to one proposer whom they are colluding with, the CI should be (one of) the relayer(s) for the tx. This mirrors how gas sponsorship works and indeed CI insurance should likely just be included in a gas sponsorship service.</p>
<p>Effectively a user pays a total of <span class="math">t + rT</span> for their transaction and only needs to have <span class="math">t + rT</span> on hand as opposed to <span class="math">T</span>, which is frequently more than <span class="math">t + rT</span>.</p>
<p>An additional benefit of this scheme is that a marketplace of at least two CI providers will conveniently alert users when their <span class="math">T</span> is too low and there is a high risk of censorship because they’ll refuse to censorship-insure the transaction at a reasonable rate.</p>
<p><strong>Problem:</strong> It will be difficult to bootstrap a two-sided marketplace for this from scratch.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49651-ci-market-structure-9" name="p-49651-ci-market-structure-9"></a>CI Market Structure</h3>
<p>In practice applications or wallets will likely claim jurisdiction over this issue. One possible solution to the bootstrapping problem, therefore, is for applications and/or wallets to sign wholesale agreements with CI providers à la PFOF.</p>
<p>While the above solution likely works fine, another option is to create a proper on-chain market with e.g. an RFQ for each transaction whose sender wishes to purchase censorship resistance for.</p>
<p><img alt="snake" height="240" src="https://ethresear.ch/uploads/default/original/3X/0/4/049237e341dc88cd24cde968c71e70ce689c3444.png" width="240" /></p>
<p>This market, fittingly, would benefit from the CR properties of BRAID.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49651-conclusion-10" name="p-49651-conclusion-10"></a>Conclusion</h2>
<p>BRAID is still in its early days as a proposal. The UX issue of liquidity requirements has not been sufficiently explored, though there are promising signs that we can reasonably punt the issue to the application layer. For next steps, we suggest further exploration of the feasibility of CI markets.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49651-previous-work-11" name="p-49651-previous-work-11"></a>Previous work:</h2>
<ul>
<li><a href="https://arxiv.org/abs/2301.13321">Censorship Resistance in On-Chain Auctions</a>: Elijah, Max, Mallesh</li>
<li><a href="https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777">Concurrent Block Proposers in Ethereum</a>: Mike, Max</li>
<li><a href="https://blog.duality.xyz/introducing-multiplicity/">Introducing Multiplicity</a>: Duality blog</li>
<li><a href="https://efdn.notion.site/ROP-9-Multiplicity-gadgets-for-censorship-resistance-7def9d354f8a4ed5a0722f4eb04ca73b">ROP-9: Multiplicity gadgets for censorship-resistance</a> RIG</li>
<li><a href="https://www.youtube.com/watch?v=mJLERWmQ2uw">BRAID: Implementing Multiple Concurrent Block Proposers</a>: Max</li>
<li><a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870/1">Fork-Choice enforced Inclusion Lists (FOCIL): A simple committee-based inclusion list proposal</a>: Thomas, Barnabé, Francesco and Julian</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/censorship-insurance-markets-for-braid/20288">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 16 Aug 2024 15:36:38 +0000</pubDate>
</item>
<item>
<title>Ethereum discv5 DHT Network Health Weekly Reports</title>
<link>https://ethresear.ch/t/ethereum-discv5-dht-network-health-weekly-reports/20282</link>
<guid>https://ethresear.ch/t/ethereum-discv5-dht-network-health-weekly-reports/20282</guid>
<content:encoded><![CDATA[
<div> 关键词：ProbeLab团队、Nebula爬虫、discv5 DHT网络、健康报告、每周更新

总结:

本文概述了ProbeLab团队为监控Ethereum CL discv5 DHT网络的关键指标而开发并部署的基础设施。团队通过将Nebula爬虫适配为兼容discv5基于的网络，并收集反映P2P网络DHT层面健康状况的结果。

- **监控与报告**：每周一发布上一周的最新报告，涵盖了网络结构、规模和客户端采用率的概览，以及地理分布、版本更新趋势、基础设施设置（数据中心或非数据中心）、特定网络层协议支持情况等。
  
- **数据分析**：提供关于网络结构和设置变化的实时洞察，易于识别关键结构变化，帮助理解网络的稳健性和多样性，以及特定地区的趋势和优势。

- **贡献与参与**：鼓励社区成员提出他们认为应包含在每周报告中的重要指标，并通过评论或直接与团队联系进行反馈。

- **透明度与公开性**：报告可在线访问，详细展示了数据收集方法、过滤策略、节点分类差异及其与市场中其他工具的比较。

- **可复用资源**：提供的爬虫工具不仅用于生成报告，也便于社区成员根据自身需求进行调整和利用。

本文强调了ProbeLab团队通过持续监控和分析Ethereum CL discv5 DHT网络的关键指标，为维护网络健康和促进社区发展做出的贡献。通过定期更新的报告，不仅提供了当前网络状态的详细视图，也为改进策略和决策提供了数据基础。鼓励社区参与和反馈机制体现了对开放合作和持续优化的承诺。 <div>
<blockquote>
<p><em>Work presented here has been carried out by the <a href="https://probelab.network" rel="noopener nofollow ugc">ProbeLab</a> team and in particular <a class="mention" href="https://ethresear.ch/u/guillaumemichel">@guillaumemichel</a> <a class="mention" href="https://ethresear.ch/u/cortze">@cortze</a> <a class="mention" href="https://ethresear.ch/u/dennis-tra">@dennis-tra</a> and Steph.</em></p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#p-49640-high-level-description-1" name="p-49640-high-level-description-1"></a>High Level Description</h2>
<p>The ProbeLab team has developed and deployed infrastructure to monitor several critical metrics for Ethereum’s CL discv5 DHT network. In particular, we have adapted the Nebula crawler (<a class="inline-onebox" href="https://github.com/dennis-tra/nebula/" rel="noopener nofollow ugc">GitHub - dennis-tra/nebula: 🌌 A network agnostic DHT crawler, monitor, and measurement tool that exposes timely information about DHT networks.</a>) to be compatible with discv5-based networks and are gathering results that reflect the health of the P2P network at the DHT level.</p>
<p>In this post we’re presenting a summary of what is included in the reports, but for a more complete picture of what’s there, head to: <a href="https://probelab.io/ethereum/discv5/2024-29/" rel="noopener nofollow ugc">https://probelab.io/ethereum/discv5/2024-29/</a> for the latest report.</p>
<ul>
<li>
<p>Reports are produced every Monday for the preceding week.</p>
</li>
<li>
<p>The methodology we follow for DHT Crawling, Data Filtering, Node Classification as well as the differences of our tool to alternatives in the space is given in the Methodology section: <a href="https://probelab.io/ethereum/discv5/methodology/" rel="noopener nofollow ugc">https://probelab.io/ethereum/discv5/methodology/</a>.</p>
</li>
<li>
<p>The crawler used to produce the reports can be found (and can be reused) here: <a class="inline-onebox" href="https://github.com/dennis-tra/nebula/" rel="noopener nofollow ugc">GitHub - dennis-tra/nebula: 🌌 A network agnostic DHT crawler, monitor, and measurement tool that exposes timely information about DHT networks.</a>.</p>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49640-why-you-should-care-2" name="p-49640-why-you-should-care-2"></a>Why you should care</h2>
<p>The metrics included in the reports:</p>
<ul>
<li>
<p>give an overview of the network structure, size and client adoption breakdown. This helps in understanding the robustness and diversity of the network,</p>
</li>
<li>
<p>provide accurate geographic distribution of nodes in the network per client implementation over time, which can highlight regional trends and potential vulnerabilities or strengths in specific areas,</p>
</li>
<li>
<p>make it easy to spot drastic changes in the structure and setup of the network,</p>
</li>
<li>
<p>allow for monitoring of new protocol version uptake/adoption, and provide insights on whether there are adoption barriers,</p>
</li>
<li>
<p>reveal the infrastructure setup (e.g., data center-hosted vs non-data center-hosted) and cloud provider distribution per client implementation,</p>
</li>
<li>
<p>show the breakdown of nodes supporting particular network-layer protocols,</p>
</li>
<li>
<p>depict the percentage of reachable vs unreachable node records in the DHT network.</p>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49640-overview-of-results-3" name="p-49640-overview-of-results-3"></a>Overview of Results</h2>
<p>We’re presenting a small fraction of the results given at <a href="https://probelab.io" rel="noopener nofollow ugc">https://probelab.io</a> to give an idea of the metrics listed. Please head there for the complete reports from Week 11 (mid-March), 2024.</p>
<p><strong>Client Diversity</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/3/433c4aecd269c5dfd9291dc03bbf58624414061c.png" title="discv5-agents-overall"><img alt="discv5-agents-overall" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/4/3/433c4aecd269c5dfd9291dc03bbf58624414061c_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Client Diversity Over Time</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/6/2664514f07b9b5aa0f4dea5319bc82fe047fa27b.png" title="discv5-agents-overall-stacked"><img alt="discv5-agents-overall-stacked" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/2/6/2664514f07b9b5aa0f4dea5319bc82fe047fa27b_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Agent version adoption over time - Example: Lighthouse</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/0/a081c5b9376d2f17792caaa6b6d91b9f2e4353a0.png" title="discv5-versions-distribution"><img alt="discv5-versions-distribution" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/a/0/a081c5b9376d2f17792caaa6b6d91b9f2e4353a0_2_489x375.png" width="489" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/1/61739999c2d736e11817cf8f417008e2c88869dc.png" title="discv5-agents-versions"><img alt="discv5-agents-versions" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/6/1/61739999c2d736e11817cf8f417008e2c88869dc_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Country distribution of all nodes</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/4/34aa9fb69b64bdf785073d62f018a4c78cbad033.png" title="discv5-geo-agent-all-bars"><img alt="discv5-geo-agent-all-bars" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/3/4/34aa9fb69b64bdf785073d62f018a4c78cbad033_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Client-specific country distribution - Example: Prysm</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/9/c92579370dcf03c6358536d0a358da2d79aeaa51.png" title="discv5-geo-agents-lines-prysm"><img alt="discv5-geo-agents-lines-prysm" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/c/9/c92579370dcf03c6358536d0a358da2d79aeaa51_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Cloud provider distribution of all nodes</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/55ffef8626b07b1f21845591817184f663c7c88f.png" title="discv5-cloud-agent-all-bars"><img alt="discv5-cloud-agent-all-bars" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/55ffef8626b07b1f21845591817184f663c7c88f_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Cloud vs non-cloud distribution of nodes over time</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/7/47638e6a177376cd847949f006ddd6ad91a73368.png" title="discv5-cloud-rate-agent-all-lines"><img alt="discv5-cloud-rate-agent-all-lines" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/4/7/47638e6a177376cd847949f006ddd6ad91a73368_2_489x375.png" width="489" /></a></div><p></p>
<p><strong>Stale Peer Records over time</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/9/d941c8d07f12784b4d26214ce100dcfbb8f1e99e.png" title="discv5-stale-records-mainnet-stacked"><img alt="discv5-stale-records-mainnet-stacked" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/d/9/d941c8d07f12784b4d26214ce100dcfbb8f1e99e_2_489x375.png" width="489" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49640-how-to-contribute-4" name="p-49640-how-to-contribute-4"></a>How to contribute</h2>
<p>Overall, we believe this set of results give an accurate view of the structure and health of the discv5 DHT network. We hope you’ll find the reports useful.</p>
<p>If there are important metrics that you believe should be part of these weekly reports, comment below, or get in touch with the team: <a href="https://www.probelab.network/contact" rel="noopener nofollow ugc">probelab.network/contact</a>.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/ethereum-discv5-dht-network-health-weekly-reports/20282">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 15 Aug 2024 16:10:39 +0000</pubDate>
</item>
<item>
<title>Autonomous Competence Identification Protocol</title>
<link>https://ethresear.ch/t/autonomous-competence-identification-protocol/20281</link>
<guid>https://ethresear.ch/t/autonomous-competence-identification-protocol/20281</guid>
<content:encoded><![CDATA[
<div> 关键词：协议、主观决策、共识、DAO、协作工具

总结:
本文探讨了一种旨在优化DAO（去中心化自治组织）和研究与开发过程中的主观决策制定的协议。该协议通过建立一套评分系统来解决常见的治理问题，促进更高效、合作的环境。其核心功能包括：
1. **量化提案者评分**：参与者对决策情境进行定义，进行多轮讨论，提供反馈，直至最终阶段匿名投票，以避免身份相关的偏见。
2. **减少沟通复杂性**：简化讨论流程，自动分配决策执行者，为后续投票系统创建议程，有效应对信息过载和决策延迟问题。
3. **激励参与与客观评价**：通过将个人贡献与组织目标直接关联，确保所有成员的活动都能推动组织向前发展，同时采用非集中化决策机制，避免内部政治影响。
4. **抵抗操纵与中央集权**：设计机制防止影响力累积和Sybil攻击，确保财务贡献与治理权力相匹配，促进组织的自我进化与分散化。
5. **适应性与扩展性**：满足不同背景和兴趣的参与者需求，即使在AI代理和自动化基础设施的背景下，也能保持高效运行。

此协议旨在革新传统组织结构，通过引入现代技术手段，增强组织决策效率和透明度，同时保护组织免受中心化倾向和外部攻击的影响，从而实现其潜力的最大化。 <div>
<p>I’m excited to share my ongoing research on a protocol designed to streamline communication and decision-making around subjective matters, particularly within DAOs and R&amp;D processes. This protocol establishes a ranking system that counters common governance issues, fostering a more collaborative and effective environment.</p>
<p>I’m posting this in the meta-innovation category because it has implications both for DAO/Consensus research and for potential collaboration tools within the Ethereum community.</p>
<p><em>Link to paper in progress: <a class="inline-onebox" href="https://github.com/peersky/papers/blob/main/acid/whitepaper.pdf" rel="noopener nofollow ugc">papers/acid/whitepaper.pdf at main · peersky/papers · GitHub</a></em></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49639-tldr-1" name="p-49639-tldr-1"></a>TL’DR</h2>
<p>The protocol enables subjective decision-making and quantifies proposer ratings. Participants define a context and engage in rounds of discussion, providing and receiving feedback without revealing identities until the round concludes. This mitigates biases like the <a href="https://en.wikipedia.org/wiki/Halo_effect" rel="noopener nofollow ugc">Halo effect</a>, and collusion (sybil attack) risks.</p>
<p>Protocol streamlines discussions and enables autonomously assign competent decision makers as well as create pre-arranged agenda for any follow up voting systems (hence addresses <a href="https://www.sciencedirect.com/science/article/abs/pii/0022053176900405" rel="noopener nofollow ugc">Agenda Manipulation</a>,  ( casually explained in <a href="https://www.youtube.com/watch?v=goQ4ii-zBMw" rel="noopener nofollow ugc">this youtube video</a> ) problem</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49639-motivation-2" name="p-49639-motivation-2"></a>Motivation</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49639-communication-complexities-hinder-decision-making-3" name="p-49639-communication-complexities-hinder-decision-making-3"></a>Communication Complexities Hinder Decision-Making</h3>
<p>Effective decision-making is hindered by communication complexities.</p>
<ul>
<li>Traditional methods (meetings, chats): don’t scale, leading to information overload and delays.</li>
<li>More stakeholders exponentially increase communication complexity, leaving less time for effective decisions.</li>
<li>Individual contributions can get lost, leading to under-appreciation and high turnover.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#p-49639-traditional-organizations-are-sub-optimally-managed-4" name="p-49639-traditional-organizations-are-sub-optimally-managed-4"></a>Traditional Organizations are Sub-optimally Managed</h3>
<p>Despite modern networking and project management technologies, the primary, basis of hierarchical communication hasn’t changed much over centuries. Decisions still require large centralization force, which will step in and cut opinions to shape performance capable decision.</p>
<ul>
<li>Centralized decision-making prioritizes efficiency over diverse input, fostering internal politics and biased decisions.</li>
<li>This breeds internal politics, leading to biased decisions that may harm the organization.</li>
<li>Current methods lack objective ways to measure and reward valuable contributions, limiting organizational potential.</li>
<li>Does not let organizations reach their full potential</li>
</ul>
<p>This touches every organization, including Ethereum R&amp;D.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49639-icos-do-not-work-well-for-daos-5" name="p-49639-icos-do-not-work-well-for-daos-5"></a>ICOs do not work well for DAOs</h3>
<p>Research shows that many DAOs are highly centralized, with low participation rates and vulnerability to governance attacks. The incentive structures in Proof of Stake (PoS) and Proof of Work (PoW) systems can lead to centralization.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/e/1edd6c487afe9524d47e660bb04cf7872abb6008.jpeg" title="img"><img alt="img" height="274" src="https://ethresear.ch/uploads/default/optimized/3X/1/e/1edd6c487afe9524d47e660bb04cf7872abb6008_2_690x274.jpeg" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/e/4e7ea5b4ee785ee33c7f3664e698a915d71867f8.jpeg" title="img2"><img alt="img2" height="374" src="https://ethresear.ch/uploads/default/optimized/3X/4/e/4e7ea5b4ee785ee33c7f3664e698a915d71867f8_2_690x374.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49639-cyber-physical-social-systems-6" name="p-49639-cyber-physical-social-systems-6"></a>Cyber-Physical-Social-Systems</h3>
<p>There’s a growing need for DAOs to bridge traditional management with AI agents and automated infrastructure, as highlighted by research in Cyber-Physical-Social Systems (CPSS).</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49639-approach-7" name="p-49639-approach-7"></a>Approach</h2>
<p>The protocol aims to incentivize participation without enabling influence compounding. It builds on a real-world game where participants propose and vote on ideas (like music tracks) without revealing identities until the round ends.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49639-key-requirements-for-the-protocol-8" name="p-49639-key-requirements-for-the-protocol-8"></a>Key requirements for the protocol:</h3>
<ul>
<li><strong>Mission aligned:</strong> Participant activity directly impacts organizational goals.</li>
<li><strong>Highly performant</strong>: Organizations using the protocol should outperform traditional structures.</li>
<li><strong>Centralization resilient</strong>: Financial contributions shouldn’t lead to disproportionate influence.</li>
<li><strong>Multidimensional</strong>: Support diverse participant interests.</li>
<li><strong>Rational</strong>: Function even when agents act in their self-interest.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#p-49639-key-features-9" name="p-49639-key-features-9"></a>Key features:</h3>
<ul>
<li><strong>Competence-based participation</strong>: Participants earn governance rights through demonstrated competence, not just financial contributions.</li>
<li><strong>Sybil attack resistance</strong>: A tournament ladder structure imposes costs and time requirements, making manipulation difficult.</li>
<li><strong>Progressive decentralization</strong>: Organizations can evolve by adding governance layers, increasing overall governance surface area.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#p-49639-current-state-10" name="p-49639-current-state-10"></a>Current State</h2>
<ul>
<li><strong>Research paper in progress</strong>: Seeking feedback and potential co-authors.</li>
<li><strong>Basic prototype and testing</strong>: Exploring use cases beyond music, such as manage-less code writing.</li>
<li><strong>Website with Telegram group</strong>: <a href="https://rankify.it" rel="noopener nofollow ugc">https://rankify.it</a></li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/autonomous-competence-identification-protocol/20281">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 15 Aug 2024 12:41:30 +0000</pubDate>
</item>
<item>
<title>A Threshold Network for “Human Keys” to solve privacy and custody issues</title>
<link>https://ethresear.ch/t/a-threshold-network-for-human-keys-to-solve-privacy-and-custody-issues/20276</link>
<guid>https://ethresear.ch/t/a-threshold-network-for-human-keys-to-solve-privacy-and-custody-issues/20276</guid>
<content:encoded><![CDATA[
<div> 关键词：Mishti网络、阈值网络设计、零知识证明、身份验证、合规性

总结:

本文探讨了在区块链和公钥基础设施（PKI）中，为何不直接将个人映射到密钥，而是通过一种称为Mishti网络的创新阈值网络设计来实现这一目标。Mishti网络的核心理念在于，它允许将个人的知识和属性与高熵伪随机数建立一种碰撞抵抗的映射关系，从而生成密钥。这种设计解决了ZK身份验证、合规性和用户注册过程中的一些关键问题。

首先，Mishti网络通过基于阈值验证的模糊随机函数（tVOPRF）在私有数据上构建了一种解决方案，使得密钥能够从个人的身份信息中生成。这不仅包括生物识别信息，也包括密码、安全问题等人类可记忆的数据，从而避免了仅使用随机数生成密钥可能带来的安全风险。

其次，Mishti网络为解决以太坊面临的用户注册复杂性和隐私保护问题提供了新思路。它通过提供自托管密钥管理方式，确保用户对密钥的唯一控制权，同时支持密钥恢复机制，增强了用户体验。此外，Mishti网络还展示了如何利用其基础加密技术解决ZK身份应用中需要从用户身份生成不可追踪nullifiers的问题，从而保护用户的隐私。

最后，Mishti网络还提出了将同态加密和零知识证明结合，以满足合规需求的方法。通过构造基于阈值椭圆曲线乘法的同态加密方案，Mishti网络允许在ZK证明中包含加密数据，并实现灵活的数据访问控制，这为解决ZK身份验证中的合规性挑战提供了新的可能性。

综上所述，Mishti网络通过创新的阈值网络设计和零知识证明技术，不仅解决了区块链和PKI领域中的身份验证和隐私保护问题，还为合规性管理提供了新的解决方案，展示了其在数字身份管理和合规性控制方面的潜力。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-introduction-1" name="p-49627-introduction-1"></a>Introduction</h1>
<p>In blockchain and PKI more generally, people are represented by keys. A somewhat strange question to ask might be “why don’t keys represent people?” I will argue this is actually an important question and the crux of major privacy and onboarding challenges. We present a a threshold network design dubbed Mishti Network to derive keys from people rather than arbitrary randomness. This network solves a number of problems in ZK identity, compliance, and onboarding.</p>
<p>What does it mean for a key to be a representation of a person? There are two conditions that should be met:</p>
<ul>
<li>A person’s knowledge and/or attributes can always map to the private key</li>
<li>This person is the sole controller of the key</li>
</ul>
<p>In other words, it is a collision-resistant map of personal data and attributes to a high-entropy pseudorandom number. Without collision resistance, multiple people could have the same key. Without high entropy, the key is not secure. Keys can be both standard private keys or also a nullifier that’s useful for secure ZK credentials.</p>
<p>Human keys are not solely biometrics. They could be from human-friendly data such as security questions, passwords, or any unique knowledge belonging to an individual rather than arbitrary randomness.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-solution-oblivious-pseudorandom-function-2" name="p-49627-solution-oblivious-pseudorandom-function-2"></a>Solution: Oblivious Pseudorandom Function</h1>
<p>This solution is based on a threshold verifiable oblivious pseudorandom function (tVOPRF) on private data. An oblivious pseudorandom function (OPRF) takes a private input and computes a pseudorandom function (PRF). PRFs take low-entropy input and create high-entropy output. Adding verifiability via a ZKP makes it into a VOPRF. Verifying individual node contributions is important to decentralizing the network.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-why-it-is-helpful-to-ethereum-pki-3" name="p-49627-why-it-is-helpful-to-ethereum-pki-3"></a>Why it is helpful to Ethereum + PKI</h1>
<p>Some of the outstanding issues in Ethereum are onboarding and privacy. Onboarding requires not just simplicity but also self-custody, and recovery. Current onboarding solutions such as social logins and passkeys do not have self-custody (as they can be recovered by web2 accounts), while self-custodial solutions can’t have recovery without extra onboarding step like electing gaurdians.</p>
<p>A similar need is for ZK identity applications that need to derive nullifiers from their users’ identities, in a way nobody can trace back to the user. This is a common need in proof-of-personhood solutions to ensure that each person only has one corresponding nullifier without a central database or key that links users to their nullifiers.</p>
<p>Furthermore, the underlying cryptography and network can be repurposed to tackle another pressing challenge: that of satisfying compliance rules with ZK identity. The same underlying elliptic curve multiplication primitive that underlies this design can be used to construct threshold ElGamal decryption over ZK-friendly curves, which can allow ZK proofs to contain encrypted data with flexible access control.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-oblivious-pseudorandom-function-4" name="p-49627-oblivious-pseudorandom-function-4"></a>Oblivious Pseudorandom Function</h1>
<p>To generate keys from identities, an oblivious pseudorandom function (OPRF) can be constructed with distributed EC scalar multiplication. This allows private user data such as security questions, biometrics, passwords, or social security numbers, etc. to deterministically generate secret keys. The resulting pseudorandom value is computationally impractical to reverse despite it being from low-entropy input. One can thereby create wallet or nullifier from any (or a combination) of these low-entropy “human” factors. In the 2HashDH OPRF [1], a server or network’s secret is used to give randomness to the client’s input. The oblivious property prevents any server or set of nodes from seeing see this input.</p>
<p>2HashDH is the following algorithm between a user with a private input <span class="math">x</span> and a server (or network) with a private key <span class="math">s</span>. For a subgroup <span class="math">G</span> of an elliptic curve there are two hash functions:</p>
<p><span class="math">hashToCurve: \{0,1\}^* \rightarrow G</span><br />
<span class="math">hashToScalar: G \rightarrow F_q</span>.</p>
<p>The 2HashDH OPRF proceeds as follows</p>
<ol>
<li>User samples a random mask <span class="math">r</span> and sends <span class="math">M = r * hashToCurve(x)</span></li>
<li>Server multiplies by its secret, returning <span class="math">s * M</span></li>
<li>User computes the output by unmasking the server’s response and hashing it: <span class="math">o = HashToScalar(r^{-1} * s * M)</span></li>
</ol>
<p><span class="math">o</span> is uniformly pseudorandom in <span class="math">F_q</span>, and the server is information-theoretically blinded from the user’s input.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49627-decentralizing-the-server-5" name="p-49627-decentralizing-the-server-5"></a>Decentralizing the server</h2>
<p>To decentralize the OPRF server, only the step with a server must be decentralized:</p>
<blockquote>
<ol start="2">
<li>Server multiplies by its secret, returning <span class="math">s * M</span></li>
</ol>
</blockquote>
<p>For threshold elliptic curve multiplication, first a linear secret sharing, such as Shamir’s scheme, must be used. The secret key is generated through distributed key generation (DKG) such that each node with index <span class="math">i</span> receives share <span class="math">f(i)</span> for some secret polynomial <span class="math">f</span> known to nobody. There is no node at the <span class="math">0</span> index and <span class="math">f(0)</span> is the secret key of the network. The secret key <span class="math">f(0)</span> can be computed by a set <span class="math">Q</span> of <span class="math">t</span> nodes where <span class="math">t</span> is one more than the degree of <span class="math">f</span>.</p>
<p><span class="math">f(0) = \sum_{i \in Q}{L_{0, Q}(i)*f(i)}</span></p>
<p>where <span class="math">L_{0,Q}(i)</span> is the Lagrange basis for index <span class="math">i</span> in set <span class="math">Q</span> evaluated at zero.</p>
<p>Instead of reconstructing <span class="math">f(0)</span>, the nodes can collaborate to construct <span class="math">f(0) * M</span></p>
<p><span class="math">f(0) * M = \sum_{i \in Q}{L_{0, Q}(i)*f(i) * M}</span></p>
<p>This is sufficient for step</p>
<blockquote>
<ol start="2">
<li>Server multiplies by its secret, returning <span class="math">s * M</span></li>
</ol>
</blockquote>
<p>if the nodes are honest. But if one lies, the result will be wrong and there will be no way of knowing who lied. Thus, each node should prove their individual multiplication using a lightweight zero-knowledge DLEQ proof.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-other-interesting-use-case-provable-encryption-with-programmable-privacy-6" name="p-49627-other-interesting-use-case-provable-encryption-with-programmable-privacy-6"></a>Other interesting use case: Provable encryption with programmable privacy</h1>
<p>The same decentralized EC scalar primitive can be used not just for VOPRF but also for ElGamal decryption over ZK-friendly curves. This is helpful when identities must be revealed in certain conditions.</p>
<p>For example, many private DeFi protocols are interested in ensuring that bad actors do not get the benefits of anonymity, while the average user typically does. Governments are not satisfied with solely ZK because they need access to user data, but currently the only alternative is honeypots where all user data is stored to be turned over to authorities if needed.</p>
<p>Another use of revealing provably encrypted identities under certain conditions is undercollateralized lending – what if you want an identity or private key to be revealed if a DeFi loan is defaulted on? In this case, you need to prove the proper data is encrypted correctly, then have a smart contract control decryption rights.</p>
<p>To modify this threshold EC point multiplication to such use cases, little is needed.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49627-encryption-7" name="p-49627-encryption-7"></a>Encryption</h3>
<p>ElGamal encryption is client-side:</p>
<ol>
<li>Create an ephemeral keypair <span class="math">(a, A = aG)</span></li>
<li>Encode the message as an EC point <span class="math">P</span></li>
<li>Compute Diffie-Hellman shared secret with network public key: <span class="math">aB</span></li>
<li>Compute the ciphertext <span class="math">(A, aB+P)</span></li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#p-49627-decryption-8" name="p-49627-decryption-8"></a>Decryption</h3>
<p>Unlike encryption, decryption requires a server or decentralized network.</p>
<ol>
<li>Server/network multiply ephemeral public key <span class="math">A</span> by its secret key <span class="math">b</span> to get <span class="math">bA</span> = <span class="math">aB</span></li>
<li>Decryptor subtracts this value from <span class="math">aB+P</span> to get <span class="math">P</span></li>
</ol>
<p>The server/network’s step can be handled by the same threshold multiplication protocol as before!</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-network-setup-and-collusion-protection-9" name="p-49627-network-setup-and-collusion-protection-9"></a>Network Setup and Collusion Protection</h1>
<p>The team at Holonym has implemented this as as an AVS on Eigenlayer called Mishti Network. High reputation is common among Eigenlayer operators despite the permissionless nature, so it is ideal for threshold networks where collusion is a concern. To further mitigate collusion risk, there is the idea of parallel networks:</p>
<p>The asynchronous and homomorphic nature of the computations means users can permissionlessly add nodes outside of Mishti Network that they trust to not collude with Mishti Network. E.g. instead of splitting a secret between Mishti Network, half of the secret is between the Mishti Network and the other half in a semi-trusted node elected by the user. Since the whole network just does an EC multiplication, exactly what its individual does do, nodes and networks can be treated the same. A 2/2 scheme could be done between a semi-trusted node and Mishti network, simply by</p>
<ul>
<li>Adding their public keys to get the joint public key</li>
<li>Adding their responses to get a joint response to the computation</li>
</ul>
<p>Note this requires no consent from the network and is not limited to 2/2 schemes; it can be done with any combination of semi-trusted nodes and/or independent networks via threshold schemes.</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-references-10" name="p-49627-references-10"></a>References</h1>
<p>[1] S. Jarecki, A. Kiayias, and H. Krawczyk, “Round-optimal<br />
password-protected secret sharing and T-PAKE in the password only model,” in International Conference on the Theory and Application of Cryptology and Information Security. Springer, 2014 pp. 233–253</p>
<h1><a class="anchor" href="https://ethresear.ch#p-49627-concluding-notes-11" name="p-49627-concluding-notes-11"></a>Concluding Notes</h1>
<p>If you have any ideas on how to improve or elaborate on this network design for either ZK identity, self-custody, or any other relevant use cases, please reply or reach out.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/a-threshold-network-for-human-keys-to-solve-privacy-and-custody-issues/20276">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 14 Aug 2024 23:38:38 +0000</pubDate>
</item>
<item>
<title>On Attestations, Block Propagation, and Timing Games</title>
<link>https://ethresear.ch/t/on-attestations-block-propagation-and-timing-games/20272</link>
<guid>https://ethresear.ch/t/on-attestations-block-propagation-and-timing-games/20272</guid>
<content:encoded><![CDATA[
<div> 关键词：Attestations, Block Propagation, Timing Games, Node Operators, Ethereum Consensus

总结：

文章主要探讨了在以太坊网络中验证者的行为变化、区块传播机制及其对共识的影响。文章通过具体案例研究了节点运营商Lido、Coinbase和Kiln在区块提议时间上的策略与行为，并分析了这些策略如何影响网络共识。

1. **区块构建市场的演变**：文章指出，目前大部分区块构建工作外包给特定的区块构建者，其中两个主要构建者负责生成大约三分之二的区块。Kiln等实体则通过延迟区块提议时间来最大化其策略空间，将其提议时间精确到每槽的3-3.5秒。

2. **区块传播与控制权转移**：虽然提案者仍然负责从转发器接收并传播区块，但实际传播速度往往由转发器决定，因为它们通常拥有更好的网络连接。然而，提案者仍能通过延迟操作来参与时间游戏，影响区块的传播速度。

3. **验证行为的分析**：文章详细分析了不同节点运营商在面对来自不同提案者的区块时的验证行为。例如，Kiln验证者显示出一种独特的“U”型分布，这可能是由于不同的地理位置或客户端软件导致。此外，文章还讨论了验证者如何处理自己的区块，即“本地区块”，以避免区块重组。

4. **协调行为的讨论**：文章探讨了节点运营商之间可能存在的协调行为，以及这种协调行为如何影响网络共识。例如，Kiln验证者被发现试图通过投票支持自己的区块来避免区块重组，这在以太坊社区中被视为不适当的行为。

5. **解决方案与未来方向**：文章提出了通过增加对关联验证者惩罚的措施来对抗复杂协调行为的可能性，以维护网络的公平性和安全性。同时，文章鼓励研究者和开发者继续探索如何平衡提高效率与保护网络免受恶意协调行为的影响。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49615-on-attestations-block-propagation-and-timing-games-1" name="p-49615-on-attestations-block-propagation-and-timing-games-1"></a>On Attestations, Block Propagation, and Timing Games</h1>
<p>By now, <a href="https://timing.pics/">proposer timing games</a> are no longer a new phenomenon and have been analyzed, <a href="https://eprint.iacr.org/2023/760">here</a>, <a href="https://arxiv.org/abs/2305.09032">here</a> and <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">here</a>.</p>
<p>In the following research piece, I want to show the <strong>evolution of <a href="https://timing.pics/">proposer timing games</a></strong> and analyze their impact on attesters. Through a case study of the node operators of Lido, Coinbase, and Kiln, we dive deep into block proposal timing and its impact on Ethereum’s consensus.</p>
<p><img alt="kilnmeme" height="413" src="https://ethresear.ch/uploads/default/original/3X/1/5/152baa9c8da23d4524a4e75101c4a1c0967ebf83.png" width="456" /></p>
<p>As of August 2024, the <strong>block building market is largely outsourced</strong>, with <a href="https://mevboost.pics/">~90%</a> handled by <a href="https://github.com/flashbots/mev-boost">mevboost</a> block builders. In practice, two builders, <a href="https://www.titanbuilder.xyz/">Titan Builder</a> and <a href="https://beaverbuild.org/">Beaverbuild</a>, produce approximately <a href="https://mevboost.pics/">80%</a> of all blocks that make it on-chain.</p>
<p><strong>Kiln is among the entities pushing timing games the furthest</strong>, delaying block proposals to the <strong>3-3.5 second</strong> mark within the slot.</p>
<blockquote>
<p>In today’s environment with mevboost, <strong>block propagation is primarily handled by relays.</strong> Although proposers still propagate the block after receiving it from the relay, relays typically have better network connectivity and can therefore do it faster. <strong>However, the timing remains under the control of proposers</strong>, who can delay their <code>getHeader</code> calls to engage in timing games.</p>
</blockquote>
<p>This chart shows the <strong>evolution of timing games</strong>. We can see that blocks from Kiln validators appear later and later over time.</p>
<p><img alt="proposer_timing_games" class="animated" height="383" src="https://ethresear.ch/uploads/default/original/3X/8/2/82cad8533f90505055f8eced73ae89d774a96111.gif" width="690" /></p>
<p><strong>This comes with an impact on the network: for blocks proposed by Kiln proposers, the missed/wrong head vote rate is significantly higher:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/d/8d3a31d4dd9d8856d2baaf1b7ad1528312b72923.png" title="missed_head_votes_over_proposers"><img alt="missed_head_votes_over_proposers" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/8/d/8d3a31d4dd9d8856d2baaf1b7ad1528312b72923_2_690x316.png" width="690" /></a></div><p></p>
<p><a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Previous analysis</a> showed that <strong>the longer one waits, the higher the expected number of missed head votes</strong> (<em>“80% of attestations seen by the second 5 in the slot”</em>). Kiln proposes blocks very late, causing some attesters to miss them and instead vote for the parent block. <strong>Given that there are approximately 32,000 validators assigned to each slot, this results in about 10% of them voting for the wrong block.</strong></p>
<p>Let’s examine the attesting behavior of three large node operators and compare how they respond to <strong>blocks proposed at different times within a slot.</strong> The chart below illustrates the distribution of correct and timely head votes across the seconds within a slot.<br />
<img alt="attestations_seen_late" class="animated" height="383" src="https://ethresear.ch/uploads/default/original/3X/5/e/5eb241fefdf5cecb08a41d95fbf6d0263dbb573d.gif" width="690" /><br />
For early blocks, we observe that both <strong>Lido and Coinbase display a characteristic “U”-shape</strong> in their voting patterns that might be caused by different geo locations or client software. In contrast, <strong>Kiln shows a single prominent peak</strong> that slightly lags behind the first peaks of Coinbase and Lido. <strong>However, for late blocks, Kiln attesters also show the “U”-shape pattern.</strong></p>
<p><strong>When blocks are first seen at the 4-second mark in the p2p network during a slot, most Lido attesters attest up to 2 seconds earlier than most of the Kiln or Coinbase attesters.</strong> This pattern doesn’t necessarily suggest that Kiln is executing “individual strategies.” Instead, it could be attributed to running different clients or using different geographical locations.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49615-but-who-affects-whom-2" name="p-49615-but-who-affects-whom-2"></a><em><strong>But who affects whom?</strong></em></h3>
<p>In the following chart, we compare a node operator’s performance over different proposers. A bar above y=1, for example, the green bar at Lido, indicates that Lido attesters miss more head votes for blocks from Kiln proposers. At the same time, Lido attesters do better for Lido blocks. The dashed line at 1 indicates the average share in missed head votes over all entities as proposers. A bar below 1 means the specific entity misses fewer head votes in conjunction with the respective proposer compared to the average.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/8/786e634d534692c6bcef1859d4baf99b6490a363.png" title="missed_head_votes_over_proposers_percentage"><img alt="missed_head_votes_over_proposers_percentage" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/8/786e634d534692c6bcef1859d4baf99b6490a363_2_690x316.png" width="690" /></a></div><p></p>
<blockquote>
<p>Importantly, it is expected that each node operator does best with its local blocks. This is expected even without a coordination oracle, simply by co-locating nodes.</p>
</blockquote>
<p>To quickly summarize what we see:</p>
<ul>
<li>Most node operators are rather stable across different proposers.</li>
<li><strong>Figment performs significantly worse for Kiln proposers.</strong> The same applies to Lido, Kraken, and EtherFi attesters.</li>
<li><strong>Kiln and Binance are the only entities performing better for Kiln blocks</strong> (which are, as a reminder, very late).</li>
</ul>
<p><strong>Kiln attesters generally do well.</strong> <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Earlier analysis</a> showes that Kiln does a more than good job when it comes to running high-performing validators. Refer to <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">this analysis</a> for further details of Kiln’s attestation performance.</p>
<p><strong>Kiln causes stress.</strong> Now, we know that Kiln blocks cause stress to other attesters but not necessarily to Kiln’s attesters.</p>
<p><strong>Explaining how.</strong> The “<em>how</em>?” is difficult to respond to at this point. A possible explanation might be that Kiln’s validators are heavily co-located, with many validators running on the same machine, or have very dense peering. Another reason might be coordinated behavior across multiple nodes, either through custom peering/private mesh networks or through another additional communication layer connecting their validators. The latter is regarded as more centralizing as it leverages economies of scale even more.</p>
<p>A similar pattern can be observed when examining the (correct &amp; timely) attestation timing of Lido and Coinbase for the blocks proposed by each respective entity (26.07.2024-03.08.2024).<br />
<img alt="attestations_seen_late_by_proposer_misses" class="animated" height="383" src="https://ethresear.ch/uploads/default/original/3X/5/a/5acb3eda53b7f342972637ae3d881d9e7cb44983.gif" width="690" /></p>
<p>Interestingly, Kiln develops a “U”-shape distribution ranging from <span class="math">3.8 \Rightarrow
 6.1</span> for their own late blocks, Lido a peak at 4.2s, and Coinbase a plateau starting at second 4 with a small peak at second 6 in the slot.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49615-prevent-reorgs-of-my-own-proposed-blocks-3" name="p-49615-prevent-reorgs-of-my-own-proposed-blocks-3"></a>“Prevent reorgs of my own proposed blocks”</h2>
<p>Let’s shift our focus to reorged blocks. One strategy from the perspective of a node operator might be to <strong>never</strong> vote for reorging out one’s own block. Simply speaking, “<em>never vote for the parent block as the head if the proposer is me</em>”.</p>
<p>Instead of calling it <em>an entity’s own block</em>, I will use <em>local block</em> in the following.</p>
<p>The following chart shows the percentage of attesters voting for the reorged block vs voting for the parent block. The red part displays the % of all attesters from that entity that voted for a reorged block built by that entity.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/5/f580dddb61ad6a3e4f577516f312475182d980d7.png" title="votes_for_local_reorged_block"><img alt="votes_for_local_reorged_block" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/f/5/f580dddb61ad6a3e4f577516f312475182d980d7_2_690x316.png" width="690" /></a></div><p></p>
<p>Kiln shows outlier behavior. While most node operators’ attesters correctly vote for the parent block rather than the local block, Kiln’s attesters appear to disregard this norm. <strong>Over 10% of Kiln attesters attempt to keep the local block on-chain by voting for it.</strong> If such strategies are adopted, they might justify the losses from incorrect head votes if they prevent the local block from being reorged. However, these tactics are generally frowned upon within the Ethereum community: “<em>don’t play with consensus</em>”.</p>
<blockquote>
<p>The chart uses 365 days of data. Thus, if some sophisticated strategy was implemented during the last year, the red portion would be proportionately smaller.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#p-49615-but-how-do-we-feel-about-any-additional-level-of-coordination-4" name="p-49615-but-how-do-we-feel-about-any-additional-level-of-coordination-4"></a>But how do we feel about any additional level of coordination?</h2>
<p>Regarding coordinated attesting, we, as community, seem to accept that validators run on the same node vote for the same checkpoints.</p>
<p>We probably don’t want any additional efforts that cross the boundaries of physical machines to improve coordination across validators. It’s something that everyone can build that goes beyond <a href="https://github.com/ethereum/consensus-specs/blob/b2f2102dad0cd8b28a657244e645e0df1c0d246a/specs/phase0/validator.md#attesting">what the specs describe</a>. Such coordination could have different forms:</p>
<ul>
<li><strong>Level 1 - Fall-backs &amp; Static Peering</strong>: Have a central fall-back/back-up node for multiple physical machines. This can also be a circuit breaker, some particularly fault-tolerant machine acting as a private relayer for information. Setups with improved peering, private mesh networks, or similar might also fall into this category.</li>
<li><strong>Level 2 - If-else rules</strong>: Have hard-coded rules waiting longer in certain slots. Those would be installed on multiple physical machines, allowing them to “coordinate” based on predefined rules.</li>
<li><strong>Level 3 - Botnet</strong>: Have a centralized oracle that communicates with all validators and delivers the checkpoints to vote for and the timestamp when they should be published.</li>
</ul>
<p>In my opinion, crossing the line into the latter form of coordination (<em>level 2 and 3</em>) is problematic, and node operators should be held accountable. Finally, there may be a <strong>gray area</strong> for strategies involving <strong>static peering</strong> and <strong>private mesh networks</strong>.</p>
<p><strong>Such setups could be used to run (malicious) strategies such as:</strong></p>
<ul>
<li>ensuring to never vote for different checkpoints across multiple physical machines.</li>
<li>ensuring to never vote for reorging out a block from one’s own proposer.</li>
<li>coordinating based on the consecutive proposer (<a href="https://github.com/ethereum/consensus-specs/pull/3034">honest reorg client</a> (y/n)).</li>
<li>censoring attestations of a certain party.</li>
<li>not voting for the blocks of a certain party.</li>
<li>etc.</li>
</ul>
<p><strong>When discussing <em>coordination</em>, it’s important to distinguish between two types:</strong></p>
<ol>
<li>Coordinated behavior that occurs when validators are <strong>run from the same physical machine</strong>.</li>
<li>Coordinated behavior that arises from running the same <strong>modified client software</strong> or relying on the same <strong>centralized oracle</strong>.</li>
</ol>
<p>A potential solution to counter sophisticated coordinated validator behavior is <a href="https://ethereum-magicians.org/t/eip-7716-anti-correlation-attestation-penalties/20137">EIP-7716: Anti-Correlation Penalties"</a>, which proposes to scale penalties with the correlation among validators.</p>
<p><em><strong>Find the code for this analysis <a href="https://github.com/nerolation/timing-games-and-economies-of-scale">here</a>.</strong></em></p>
<h1><a class="anchor" href="https://ethresear.ch#p-49615-more-on-that-topics-5" name="p-49615-more-on-that-topics-5"></a>More on that topics</h1>
<div class="md-table">
<table>
<thead>
<tr>
<th>Title</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://timing.pics">Timing.pics</a></td>
<td>DotPics Website</td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612">Timing Games: Implications and Possible Mitigations</a></td>
<td>Caspar &amp; Mike</td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Deep Diving Attestations - A quantitative analysis</a></td>
<td>Toni</td>
</tr>
<tr>
<td><a href="https://www.paradigm.xyz/2023/04/mev-boost-ethereum-consensus">Time, slots, and the ordering of events in Ethereum Proof-of-Stake</a></td>
<td>Georgios &amp; Mike</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2305.09032">Time is Money: Strategic Timing Games in Proof-of-Stake Protocols</a></td>
<td>Caspar et al.</td>
</tr>
<tr>
<td><a href="https://eprint.iacr.org/2023/760">Time to Bribe: Measuring Block Construction Market</a></td>
<td>Toni et al.</td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847">The cost of artificial latency in the PBS context</a></td>
<td>Chorus One</td>
</tr>
<tr>
<td><a href="https://ethresear.ch/t/empirical-analysis-of-the-impact-of-block-delays-on-the-consensus-layer/17888">Empirical analysis of the impact of block delays on the consensus layer</a></td>
<td>Kiln</td>
</tr>
<tr>
<td><a href="https://youtu.be/J_N13erDWKw?t=1061">P2P Presentation on Timing Games (Youtube)</a></td>
<td>P2P_org</td>
</tr>
<tr>
<td><a href="https://www.youtube.com/watch?v=gsFU-inKRQ8">Time is Money (Youtube)</a></td>
<td>Caspar</td>
</tr>
</tbody>
</table>
</div>
            <p><small>6 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/on-attestations-block-propagation-and-timing-games/20272">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 14 Aug 2024 13:04:48 +0000</pubDate>
</item>
<item>
<title>A Node-Based Solution to Execution Sharding: The KRNL Protocol</title>
<link>https://ethresear.ch/t/a-node-based-solution-to-execution-sharding-the-krnl-protocol/20268</link>
<guid>https://ethresear.ch/t/a-node-based-solution-to-execution-sharding-the-krnl-protocol/20268</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、KRNL协议、执行碎片化、证明来源（PoP）、去中心化注册表

总结：

本文探讨了Web3生态系统所面临的挑战，包括网络碎片化、可扩展性限制、跨链集成复杂性和安全漏洞。为解决这些问题，文章提出了一种名为KRNL协议的解决方案，它是一个集成引擎，能够无缝地在以太坊交易生命周期中整合无许可和可组合功能，跨越多个区块链网络。KRNL通过将功能转换为称为“内核”的执行碎片来优化资源使用、增强模块化并加速部署，从而改进去中心化应用程序的响应速度并缩短其上市时间。

文章进一步介绍了执行碎片的概念，即通过将智能合约的执行分散到多个区块链网络中，以提高区块链系统的可扩展性和效率。KRNL协议作为这一概念的一部分，旨在成为Web3框架中的关键工具，通过引入社区构建、无许可、可货币化和可组合的执行碎片，实现跨链应用的开发。

此外，文章提出了“内核”作为执行碎片的代表，它们具有状态无状态、轻量级设计、韧性和独立部署能力等特征，旨在提供一个去中心化的云环境，允许用户在分布式环境中运行应用程序。KRNL协议还包括证明来源（PoP）机制，确保内核成功执行后才能执行交易，以及去中心化注册表，用于激活和货币化由社区构建的内核。

最后，文章概述了DeFaaS系统，这是一个利用区块链技术和去中心化API管理的新型去中心化FaaS系统，旨在提供比传统FaaS解决方案更好的可扩展性、灵活性、安全性和可靠性。同时，文章还提出了一个基于以太坊区块链特性的模型，用于执行不同服务并根据服务质量差异性地交付可靠性，以应对多服务网络中的成本降低需求。文章还讨论了去中心化数字身份的实现，提出了一个统一的钱包解决方案，以管理区块链和自主权两种类型的去中心化身份，并通过实际案例进行了验证。 <div>
<p>By <a href="https://x.com/asim_eth" rel="noopener nofollow ugc">Asim Ahmad</a> and <a href="https://x.com/Tahir_Mahmood" rel="noopener nofollow ugc">Tahir Mahmood</a> on behalf of <a href="https://krnl.xyz" rel="noopener nofollow ugc">KRNL</a>.</p>
<p><strong>1. Abstract</strong></p>
<p>The evolution of the Web3 ecosystem confronts pivotal challenges such as network fragmentation, scalability constraints, cross-chain integration complexities, and security vulnerabilities. To address these issues, we introduce the KRNL Protocol—an orchestration and verification engine that seamlessly integrates permissionless and composable functions across multiple blockchain networks within the Ethereum transaction lifecycle. By transforming both on-chain and off-chain functions into execution shards called “kernels,” KRNL offers a distributed runtime environment that optimizes resource utilization, enhances modularity, and accelerates deployment. This approach not only improves the responsiveness of decentralized applications (dApps) but also reduces their time-to-market. Our proposal positions KRNL as part of the fabric of the Web3 framework.</p>
<p><strong>2. Motivation</strong></p>
<p>The Web3 ecosystem faces several significant challenges, including fragmentation, scalability limitations, cross-chain friction, and security concerns.</p>
<p><strong>Fragmentation</strong>: The emergence of numerous Layer 1 and Layer 2 solutions has led to the creation of isolated silos. This fragmentation impedes seamless interaction between applications and smart contracts across different environments, undermining the foundational principle of composability in decentralized systems.</p>
<p><strong>Scalability Constraints</strong>: Ethereum grapples with network congestion and high gas fees. These scalability issues deter the widespread adoption of dApps and erode user experience.</p>
<p><strong>Cross-Chain Friction</strong>: Facilitating interoperability between Ethereum and other blockchains often demands intricate integrations. The absence of standardized cross-chain communication protocols exacerbates development complexities, stifling innovation and efficiency.</p>
<p><strong>Security Vulnerabilities</strong>: Ensuring transaction integrity, provenance, and security in a decentralized manner remains a challenge. The proliferation of bridges and interoperability solutions introduces novel attack vectors, heightening security risks.</p>
<p>To address these challenges, we reimagine the execution paradigm by introducing the concept of kernels - community-built, permissionless, monetizable, and composable execution shards across Web3. We also introduce the KRNL protocol, an orchestration and verification engine that enables smart contracts to integrate execution shards, enriching the logic and state of traditional smart contract operations without the creation of custom infrastructure. With this proposal, we aim to become an essential tool for the development of cross-chain applications.</p>
<p><strong>3. TL;DR</strong></p>
<p>Execution Sharding refers to the approach of dividing and distributing the execution of smart contracts across multiple blockchain networks, or “shards”, to enhance scalability and efficiency in blockchain systems. Instead of executing every transaction on a single chain, execution sharding allows transactions and smart contract states to be distributed across multiple chains, each handling a portion of the overall workload.</p>
<p>Execution sharding is critical for Ethereum’s scalability. The KRNL Protocol integrates permissionless and composable kernels (execution shards) across multiple networks, seamlessly into the native Ethereum transaction lifecycle.</p>
<p>KRNL manages resources to provide a secure and optimal execution environment for smart contracts. This enables a distributed runtime environment that determines transaction outcome based on selected kernels, operating across different environments. KRNL’s open framework enhances modularity, optimizes resources, ensures stable operations, and accelerates deployment, ultimately improving responsiveness and reducing time to market for applications.</p>
<p><strong>4. Introducing Kernels</strong></p>
<p>Within the KRNL Protocol framework, kernels represent execution shards. These kernels transform both on-chain and off-chain functions into modular units characterized by the following attributes:</p>
<ul>
<li><strong>Statelessness</strong>: Kernels maintain no intrinsic state, ensuring flexibility and facilitating seamless migration across environments.</li>
<li><strong>Lightweight Design</strong>: To minimize computational overhead, kernels promote efficient execution.</li>
<li><strong>Resilience</strong>: Engineered to withstand operational failures, ensuring reliable performance.</li>
<li><strong>Independent Deployability</strong>: Allowing for deployment across various environments.</li>
</ul>
<p>The defining features of kernels include:</p>
<ul>
<li><strong>Infrastructure Agnosticism</strong>: Kernels are not tethered to specific infrastructures; they possess the agility to migrate across environments as necessitated.</li>
<li><strong>Enhanced Modularity and Composability</strong>: By deconstructing applications into discrete kernels, modularity is enhanced, enabling permissionless sharing across multiple applications.</li>
<li><strong>Accelerated Deployment</strong>: Simplifying the deployment process improves responsiveness and reduces time-to-market for applications.</li>
</ul>
<p><strong>5. Vision</strong></p>
<p><strong>The Pre-Cloud Paradigm</strong></p>
<p>Before cloud computing, developers bore the burden of constructing, operating, and maintaining all requisite programs and services. This paradigm engendered prohibitive costs, scalability constraints, accessibility challenges, and resource limitations. Cloud computing revolutionized this landscape, introducing managed services where back-end infrastructures are handled by cloud providers.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/f/5fe5cbe3446592ada1eea874797faf006e20d182.png" title="Before and After Cloud Computing"><img alt="Before and After Cloud Computing" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/5/f/5fe5cbe3446592ada1eea874797faf006e20d182_2_690x315.png" width="690" /></a></div><p></p>
<p><strong>KRNL’s Transformative Potential</strong></p>
<p>KRNL seeks to catalyze a comparable paradigm shift within the Web3 domain—a permissionless Web3 cloud environment built by the community through contributions of monetizable kernels. This vision aligns with the Function as a Service (FaaS) model, reimagined to suit the decentralized and heterogeneous fabric of blockchain ecosystems.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/3/03a9e2f49a0d71e30f39b7ce9368173d25a7b5a6.jpeg" title="Before and After KRNL"><img alt="Before and After KRNL" height="301" src="https://ethresear.ch/uploads/default/optimized/3X/0/3/03a9e2f49a0d71e30f39b7ce9368173d25a7b5a6_2_690x301.jpeg" width="690" /></a></div><p></p>
<p><strong>Functions as a Service (FaaS) in the Web3 Context</strong></p>
<p>FaaS is a category of cloud computing services that provide a platform enabling customers to develop, run and manage applications without the complexity of building and maintaining the infrastructure associated with developing and launching an app. Examples of a traditional FaaS include AWS Lambda, Google Cloud Functions, Microsoft Azure Functions, etc.</p>
<p>The conventional FaaS model does not fit well in distributed and heterogeneous blockchain environments, where each blockchain is a silo and not efficient in the context of the whole Web3 ecosystem. To adapt this concept to Web3, it is essential to ensure decentralized registry, management, and execution of kernels.</p>
<p><strong>6. Core Concepts</strong></p>
<p><strong>The Computing Engine</strong></p>
<p>KRNL enhances an Ethereum Remote Procedure Call (RPC) node with a verification and orchestration-enabled computing engine. This engine abstracts the intricacies associated with integrating smart contract interdependencies.</p>
<p>The computing engine creates an application and technology agnostic framework that offers a runtime environment to user applications in a distributed manner. It sits between a transaction initiated on any chain and its propagation into a block, determining a transaction’s outcome based on the kernels selected. This approach allows for flexible, efficient scaling and optimization of distributed applications.</p>
<p><strong>Proof of Provenance (PoP)</strong></p>
<p>PoP validates that prescribed kernels have run successfully before a transaction is executed, ensuring reliability and security of the KRNL Protocol.</p>
<p>The KRNL Protocol achieves this by utilizing various schemes including a decentralized token authority that issues a signature token, ERC-1271, cryptography and proof systems. The implementation requires the application developer to implement a Software Development Kit (SDK) as well as the token authority. PoP works with existing standards within the Ethereum ecosystem, combining multiple schemes to ensure an anti-fragile system.</p>
<p><strong>Decentralized Registry</strong></p>
<p>An Ethereum based registry for activating and monetizing community built kernels. This registry serves as the definitive repository, maintaining critical information about registered kernels, including their pathways, monetization schemes, and other customizable parameters. Core to the design of KRNL is the concept of a two-sided marketplace where kernels are built and monetized, while being utilized by applications across Web3.</p>
<p><strong>7. Architecture</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/2/d2b12fc5edd69ae351e74dda8a31b3f6e57a5311.png" title="Architecture Overview of the KRNL Protocol"><img alt="Architecture Overview of the KRNL Protocol" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/d/2/d2b12fc5edd69ae351e74dda8a31b3f6e57a5311_2_690x388.png" width="690" /></a></div><p></p>
<p><strong>Use Case Scenario</strong></p>
<p>In a hypothetical scenario, a DeFi protocol on Ethereum would like to allow users to trade RWA assets if they are an approved user on Company 1’s RWA platform (and if not, to reject the transaction from this wallet). Say Company 1 has built an RWA platform on Blockchain 2, with dynamic off-chain metadata corresponding to approved users. Additionally, these users need to have an identity score of X as determined by a on-chain DID smart contract on Blockchain 3. In the past, implementing these solutions across various chains would have required multiple complex integrations and in many cases require direct communication with vendors. However, with KRNL, builders now only need to perform a single, one-time permissionless integration.</p>
<p>There is not currently any application layer that facilitates the conditional logic before state changes are executed, and this is generally built ground-up by builders. Ideally, this would be done in a plug-and-play, permissionless manner that would be reproducible by protocols that want to utilize the RWA platform and identifiers from the DID system.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/6/869c6dc2fe0c134bfb17f32f1b481fadcd6e2704.png" title="Limitations of Existing Solutions"><img alt="Limitations of Existing Solutions" height="323" src="https://ethresear.ch/uploads/default/optimized/3X/8/6/869c6dc2fe0c134bfb17f32f1b481fadcd6e2704_2_690x323.png" width="690" /></a></div><p></p>
<p><strong>8. Decentralization and Security Considerations</strong></p>
<p><strong>Upholding Decentralization</strong></p>
<p>KRNL leverages the intrinsic decentralization of existing native blockchains. By integrating with a standard Ethereum RPC node, any Ethereum RPC node can function as a KRNL node without interfering with consensus mechanisms of the underlying network. Node operators are incentivized through the accrual of a proportion of fees generated from kernels, fostering a decentralized and participatory ecosystem.</p>
<p><strong>Mitigating Malicious Activities</strong></p>
<p>To preempt and mitigate potential malicious activities, such as replicating KRNL node code to fabricate counterfeit signatures, KRNL employs multiple cryptographic schemes that ensure security by design. The security architecture is flexible, customizable, and predominantly under the control of the dApp developer. This approach ensures that the KRNL Protocol remains permissionless, resilient, and secure.</p>
<p><strong>Explore more in our <a href="https://github.com/KRNL-Labs/krnl-node-sandbox-public" rel="noopener nofollow ugc">KRNL Developer Sandbox</a></strong></p>
<p><strong>Learn more about <a href="https://docs.krnl.xyz/" rel="noopener nofollow ugc">KRNL</a></strong></p>
<p><strong>Supporting Research Papers</strong></p>
<p><a href="https://arxiv.org/html/2404.08151v1" rel="noopener nofollow ugc">Decentralized FaaS over Multi-Clouds with Blockchain based Management for Supporting Emerging Applications</a></p>
<p>DeFaaS is a novel decentralized Function-as-a-Service (FaaS) system proposed to address the limitations of centralized FaaS solutions. This system leverages blockchain technology and decentralized API management to create a distributed FaaS platform that offers improved scalability, flexibility, security, and reliability. DeFaaS is designed to support various distributed computing scenarios beyond FaaS, including decentralized applications (dApps), volunteer computing, and multi-cloud service mesh. The proposed system aims to mitigate issues associated with centralized FaaS, such as vendor lock-in and single points of failure.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0306457321000340?ref=pdf_download&amp;fr=RR-2&amp;rr=89e00464f80d773d" rel="noopener nofollow ugc">Multi-Service Model for Blockchain Networks</a></p>
<p>Multi-service networks aim to efficiently supply distinct goods within the same infrastructure by relying on a (typically centralized) authority to manage and coordinate their differential delivery at specific prices. In turn, final customers constantly seek to lower costs whilst maximizing quality and reliability. This paper proposes a decentralized business model for multi-service networks using Ethereum blockchain features – gas, transactions, and smart contracts – to execute multiple services at different prices. By employing Ether, to quantify the quality of service and reliability of distinct private Ethereum networks, their model concurrently processes streams of services at different gas prices while differentially delivering reliability and service quality.</p>
<p><a href="https://www.researchgate.net/publication/372662346_Orchestrating_Digital_Wallets_for_On-_and_Off-chain_Decentralized_Identity_Management" rel="noopener nofollow ugc">Qualified Digital Certificates within Blockchain Networks</a></p>
<p>This paper examines decentralized digital identities, which use asymmetric cryptography without centralized oversight, focusing on both on-chain (blockchain) and off-chain (self-sovereign) types. Currently, no single wallet manages both types of decentralized identities. To address this, the paper proposes an orchestration solution for a universal wallet that combines both types and validates it using a real-life use case.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/a-node-based-solution-to-execution-sharding-the-krnl-protocol/20268">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 14 Aug 2024 11:56:25 +0000</pubDate>
</item>
<item>
<title>DoS on block proposers in PoS and block builders in PBS</title>
<link>https://ethresear.ch/t/dos-on-block-proposers-in-pos-and-block-builders-in-pbs/20262</link>
<guid>https://ethresear.ch/t/dos-on-block-proposers-in-pos-and-block-builders-in-pbs/20262</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum 2.0、PoS、DoS攻击、区块提议者、保护机制

总结:

在以太坊2.0的权益证明（PoS）系统中，区块提议者在创建下一个区块前约12秒就已知，这为攻击者提供了机会，可能通过拒绝服务（DoS）攻击来阻止提议者创建新块并失去奖励。类似地，这种担忧也出现在Algorand的基于VRF的领导者选举机制中，该机制通过避免此类攻击来解决这一问题。

在以太坊2.0的分片（PBS）系统中，构建者首先揭示密封块投标（承诺），然后稍后揭示块内容。如果未按时揭示内容，构建者将受到惩罚。这意味着攻击者可以通过DoS攻击受害者，导致其因未能及时揭示块而遭受严重处罚，并可能被重复利用。

为了保护免受这类攻击，以太坊2.0采取了多种措施。首先，通过引入信标链和分片技术，网络设计了复杂的共识算法，旨在确保安全性和去中心化。其次，针对区块提议者的DoS攻击，以太坊2.0采用了多重验证和备份机制，确保即使某个提议者遭到攻击或离线，系统也能正常运行并选择其他提议者继续进行区块生成。此外，通过实施惩罚机制，如罚款和出块延迟，以太坊激励节点保持在线和积极参与网络活动，从而减少DoS攻击的有效性。最后，以太坊的网络设计还包括了自我修复能力，能够在检测到攻击行为时自动调整和恢复系统的稳定性和安全性。这些综合措施共同构成了以太坊2.0对DoS攻击的防御策略，确保网络的健壮性和可靠性。 <div>
<ol>
<li>
<p>In Ethereum 2.0 PoS, the block proposer of the next block is known a certain time (~12s) before she creates the block. It might create an opportunity for attackers to DoS the next proposer who will therefore not create the new block and lose the reward. This might be systematically repeated again. We know that something similar was of concern for Algorand PoS and its VRF-based leader election that avoided this kind of attack.</p>
</li>
<li>
<p>In PBS, the builder reveals the sealed block bid (commitment), and then later reveals the block contents. If the contents are not revealed, the builder will be penalized. So, the attacker already knowing the network address of victim can DoS her and cause severe penalties for not revealing the block on time. This might be systematically repeated again.</p>
</li>
</ol>
<p>My question or point to discuss is how Ethereum protects against this kind of attack?</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/dos-on-block-proposers-in-pos-and-block-builders-in-pbs/20262">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 13 Aug 2024 10:28:43 +0000</pubDate>
</item>
<item>
<title>A trustless on-chain anti-MEV solution for Layer2/3</title>
<link>https://ethresear.ch/t/a-trustless-on-chain-anti-mev-solution-for-layer2-3/20260</link>
<guid>https://ethresear.ch/t/a-trustless-on-chain-anti-mev-solution-for-layer2-3/20260</guid>
<content:encoded><![CDATA[
<div> 关键词：MEVless协议、L2链、Tx-Order-commitment、DA-layers、隐私保护

总结:

本文提出了一种解决Layer2矿工提取价值（MEV）问题的方案，称为MEVless协议。该协议的主要创新在于：

1. **用户发送txHash而非完整交易内容**：用户仅需向L2链发送交易哈希值和预付费用以防止分布式拒绝服务（DOS）攻击。

2. **基于提示排序txHash**：链接收这些txHash并根据提供的提示金额进行排序，生成Tx-Order-commitment并广播给其他节点，同时允许用户订阅此承诺。

3. **确保交易执行顺序**：当用户看到订单承诺后，可发送交易内容至L2链。链会接受这些内容并根据先前的承诺顺序打包交易。如果交易内容与先前的哈希不符，则将其置于已承诺交易之后。

4. **去中心化和数据可用性层（DA-layers）**：通过去中心化链节点和使用DA-layers来确保交易安全，防止单个节点不接受交易的情况发生。

5. **隐私保护**：MEVless协议设计使得交易内容在打包前无法被观察，因此用户无需依赖隐私节点或MEVA来保护交易免受攻击，确保了交易的私密性和安全性。

该方案旨在提供一种信任无界的解决方案，消除对特定机构的信任需求，同时通过去中心化和透明的交易流程，增强交易的安全性和隐私保护。 <div>
<p>We have a solution to resolve the Layer2 MEV onchain trustlessly.<br />
Here is the arch:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/e/aeec6e16bbf3b6864d66ae84ecf5b663f9c55ce5.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/a/e/aeec6e16bbf3b6864d66ae84ecf5b663f9c55ce5_2_336x500.jpeg" width="336" /></a></div><p></p>
<ol>
<li>Users only send their txHash to the L2 chain with some advance charge (to prevent DOS attack)</li>
<li>The chain accepts these txHashes, sort them based on the amount of tips, and then make a Tx-Order-commitment and broadcast it to the other chain nodes.  Also, user can subscribe this commitment.</li>
<li>When users see the order-commitments, they will send their tx-content to the L2 chain and the DA-layers.</li>
<li>Chain accepts the tx-content from users, and also fetch txs from DA-layers ,  pack them according to the previously promised order. If the tx-content does not match the previously tx-hash, chain will put them behind the txs which made order-commitment.<br />
<strong>All promised txs will be sorted before the unpromised txs.</strong><br />
NOTICE: In this way, the chain may deduct tx-content and pretend not to receive it.  To prevent this situation. We have to:<br />
i. Decentralise chain node.<br />
ii. Use DA to complete the txs if one node does not accept the txs.</li>
</ol>
<p>In this case, we call it MEVless protocol,   it means you don’t have to trust any group and institution.  You do not have to depend on a privacy node, not through MEVA, to protect your transactions from MEV attack.  Because all the attackers(besides miners themselves) cannot see your tx-content when it orders.   Once the tx-content is packed and executed, it must be packed by the previously commitment, attackers cannot front-run and sandwich attack you.</p>
<p>We have developed some of it and you can see the running effect:</p><aside class="onebox githubfolder">
  <header class="source">
      <img class="site-icon" height="32" src="https://ethresear.ch/uploads/default/original/2X/b/bad3e5f9ad67c1ddf145107ce7032ac1d7b22563.svg" width="32" />

      <a href="https://github.com/yu-org/nine-tripods/tree/main/MEVless" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <h3><a href="https://github.com/yu-org/nine-tripods/tree/main/MEVless" rel="noopener nofollow ugc" target="_blank">nine-tripods/MEVless at main · yu-org/nine-tripods</a></h3>


  <p><span class="label1">Contribute to yu-org/nine-tripods development by creating an account on GitHub.</span></p>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>
<aside class="onebox githubfolder">
  <header class="source">
      <img class="site-icon" height="32" src="https://ethresear.ch/uploads/default/original/2X/b/bad3e5f9ad67c1ddf145107ce7032ac1d7b22563.svg" width="32" />

      <a href="https://github.com/VersechainLabs/versechain/tree/mevless" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <h3><a href="https://github.com/VersechainLabs/versechain/tree/mevless" rel="noopener nofollow ugc" target="_blank">GitHub - VersechainLabs/versechain at mevless</a></h3>

  <p><a href="https://github.com/VersechainLabs/versechain/tree/mevless" rel="noopener nofollow ugc" target="_blank">mevless</a></p>

  <p><span class="label1">A high performance decentralized modular sequencer for Starknet</span></p>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/f/bfa58e407bea18228ba10bbc90f904aca2c776aa.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/f/bfa58e407bea18228ba10bbc90f904aca2c776aa_2_607x500.jpeg" width="607" /></a></div><p></p>
<p>You can see the txHash order-commitment in the above red box and you can try MEV-attacking these txs when they are completed by tx-contents later, then you will find you cannot insert your tx into their order at all.</p>
            <p><small>9 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/a-trustless-on-chain-anti-mev-solution-for-layer2-3/20260">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 13 Aug 2024 04:02:59 +0000</pubDate>
</item>
<item>
<title>Enabling truly encrypted DeFi in FHE rollups</title>
<link>https://ethresear.ch/t/enabling-truly-encrypted-defi-in-fhe-rollups/20259</link>
<guid>https://ethresear.ch/t/enabling-truly-encrypted-defi-in-fhe-rollups/20259</guid>
<content:encoded><![CDATA[
<div> 关键词：文章、提取、5个、中文、总结

---

总结: 这篇文章要求从一段文本中提取出五个关键点，并用中文进行总结。首先，需要识别出文本中的核心信息或主题，这通常包括最重要的事实、观点或论点。然后，将这五个关键点归纳出来，确保它们覆盖了文本的主要内容和重点。

具体操作步骤如下：

1. **阅读与理解**：仔细阅读原文，确保理解其主要论点和细节。
2. **识别关键点**：找出文本中最重要、最能代表其主旨的部分，这些可能是论据、结论、主要事件或人物等。
3. **提炼概括**：将这些关键点以简洁的语言表述出来，确保每个关键点都能独立反映原文的一部分核心信息。
4. **整合总结**：将提炼出的五个关键点整合成一个连贯的段落，确保整体内容完整地涵盖了原文的主题和要点。

通过这样的过程，可以有效地对复杂文本进行简化和归纳，帮助读者快速掌握文章的核心内容。 <div>
<p>(topic deleted by author)</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/enabling-truly-encrypted-defi-in-fhe-rollups/20259">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 12 Aug 2024 13:53:24 +0000</pubDate>
</item>
<item>
<title>Proof of Service Integrity (PoSI): Trustless measurement of service integrity</title>
<link>https://ethresear.ch/t/proof-of-service-integrity-posi-trustless-measurement-of-service-integrity/20255</link>
<guid>https://ethresear.ch/t/proof-of-service-integrity-posi-trustless-measurement-of-service-integrity/20255</guid>
<content:encoded><![CDATA[
<div> 关键词：PoSI、服务完整性、去中心化验证、可信计算、智能合约

总结：

本文主要介绍了Proof of Service Integrity（PoSI）协议，一种用于验证离链服务完整性的去中心化验证机制。PoSI协议旨在解决现代区块链架构中增长的服务量、规模和复杂性与传统信任部署模式之间的不兼容问题。其核心目标是确保离链服务的正确性、完整性和可验证性。

1. **服务完整性定义**：PoSI协议关注于测量离链服务的完整性，包括正确部署了授权和验证的软件版本以及未进行未经授权的更改。这与互联网系统中的服务完整性不同，后者通常由服务的所有者或管理者负责，而PoSI允许任何人均可无权限验证服务的完整性。

2. **去中心化验证的重要性**：在区块链系统中，通过精心设计的激励机制和共识算法，确保了链上逻辑的安全性。然而，离链服务由于其在信任环境中运行，且无法在链上归因，因此存在多种风险，如内部威胁、未经授权的修改、审查风险和数据/资金安全风险。

3. **PoSI协议概述**：PoSI协议通过实现认证部署、持续完整性监控和完整性证明来验证服务的完整性。它确保只有经过验证的代码被部署，并定期监控服务以检测未经授权的修改或篡改。用户可以通过无权限接口请求服务完整性证明。

4. **架构工作流程**：PoSI协议涉及三个关键工作流程，包括服务开发者的工作流、运营商的工作流和验证工作流。服务开发者注册服务图像、设置预期指标并触发部署；运营商注册并执行任务，如托管服务图像或执行测量；应用程序或链外链请求服务完整性证明。

5. **多层安全模型**：PoSI协议采用多层次安全模型，结合共识机制、可信计算和经济激励，提供全面的安全保障。该模型要求参与的服务具有开源代码、公开可验证的服务映像、可复现的构建过程和容器化部署。

通过以上五个关键词的总结，我们可以看到PoSI协议在解决离链服务完整性验证方面的重要性和创新性，它通过去中心化的方法，结合多种技术手段，为构建更加安全、可靠和透明的区块链生态系统提供了新的思路和实践路径。 <div>
<h1><a class="anchor" href="https://ethresear.ch#p-49574-proof-of-service-integrity-posi-trustless-measurement-of-service-integrity-1" name="p-49574-proof-of-service-integrity-posi-trustless-measurement-of-service-integrity-1"></a>Proof of Service integrity (PoSI) : Trustless measurement of service integrity</h1>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-tldr-2" name="p-49574-tldr-2"></a>TL;Dr</h2>
<p><strong>Proof of Service Integrity (PoSI)</strong> is a byzantine fault tolerant verification protocol for offchain activities.</p>
<p>It performs three main tasks in a decentralised fashion - <em>deployment</em> of approved service images, <em>measurements</em> of deployed services, and <em>attestation</em> of the integrity of these services in production.</p>
<p>The problem PoSI solves is that offchain services are growing in volume, size and complexity in modern chain architectures, but they are largely centralised and run in trusted environments while handling millions of dollars of transaction flows. This is incompatible with the goals of crypto systems. Permissionless verification of offchain services using PoSI protocol provides a real-time integrated security view for emerging hybrid crypto protocols that have a mix of on-chain and off-chain activities.</p>
<p>Offchain services that are verified by PoSI protocol are called <strong>Integrity Verified services</strong> (IVS).</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-preface-3" name="p-49574-preface-3"></a>Preface</h2>
<p>This post builds on the earlier proposal on integrity proofs (<a class="inline-onebox" href="https://ethresear.ch/t/integrity-proofs-to-improve-rollup-security/19437">Integrity proofs to improve rollup security</a>) with the following main differences:</p>
<ol>
<li>Focus on measuring integrity of any off-chain service, rather than just rollup services</li>
<li>Earlier design was TEE-based, current protocol is primarily BFT-based but uses TEEs as a <em>defense-in-depth</em> mechanism.</li>
<li>Changes to the architecture</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-prelude-4" name="p-49574-prelude-4"></a>Prelude</h2>
<p>Traditional distributed systems monitoring/observability involves collecting and analyzing data in order to gain insights into the functioning, performance, security and health of software systems and applications. It involves systematically observing and tracking various metrics, events, logs and distributed traces to construct a visual representation of a system’s hardware and software performance and health. While there are multiple types of distributed systems monitoring data, one  dimension in particular that is not measured in traditional web2 distributed systems is service integrity.</p>
<p>For this post, let’s define <em>service integrity</em> as the following:</p>
<ol>
<li>The correct (authorised and verified) software version has been deployed</li>
<li>No unauthorised changes have been made to the deployed software in production.</li>
<li>Anyone can permissionlessly verify proof of <span class="hashtag-raw">#1</span> and <span class="hashtag-raw">#2</span> for any given service either through data provided over a user interface or API, or through verification of a zero-knowledge proof.</li>
</ol>
<p>In internet/online systems (web2), <em>services integrity</em> (particularly <span class="hashtag-raw">#1</span> and <span class="hashtag-raw">#2</span>) is the responsibility of the organisation or entity that centrally owns and manages the distributed service, <em>aka trusted deployments</em>. As a consequence, <span class="hashtag-raw">#3</span> is simply not possible.</p>
<p>When we talk about web3 systems, <em>service integrity</em> becomes paramount. Services are deployed in <em>untrusted environments</em> managed by operators that we do not know or have legal contracts with.</p>
<p>The way this problem has been solved in blockchain-based systems (Proof-of-stake in particular) is through a carefully designed set of incentives to encourage external operators to run the distributed software with desired behaviours, coupled with a clever mechanism for the distributed network to reach a consensus such that if an operator that is part of the consensus set is detected to perform any malicious action, they can be financially penalised (through onchain mechanisms or social governance).</p>
<p>This worked reasonably in the early days of evolution of onchain systems where all the logic for onchain protocols were on smart contracts on a single chain, which was invoked from offchain clients. Censorship resistance was largely handled by allowing anyone to run the Json-RPC nodes (which are the user transaction entry points) that communicate with the other distributed network nodes over P2P protocols. This ensured eventual censorship-resistance.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-evolution-of-crypto-protocol-architectures-5" name="p-49574-evolution-of-crypto-protocol-architectures-5"></a>Evolution of crypto protocol architectures</h2>
<p>Recent developments in blockchain systems have seen an explosion in the number of layer-1 and layer-2 chains, and the rise of modular architectures with innovations in application protocols, core infrastructure, scaling and interop solutions, developer &amp; user tools. These innovations are aimed at solving problems with scaling throughput, reducing latency, lowering transaction costs, offering greater sovereignty to builders over design choices, solving for both synchronous and async interoperability, unifying liquidity, mev optimisation, and improving user experience in crypto.</p>
<p>These developments have resulted in increased complexity and sophistication of onchain protocols involving a mix of smart-contract logic and offchain logic. Emerging use cases such as cross-chain swaps involve a mix of smart contract and offchain logic on both the source and destination chains.</p>
<p>Let’s look at a few of the hybrid onchain-offchain architectures in popular crypto protocols.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/491a30b1c361107e65615618ea2b29c226245e4d.jpeg" title="Fig 1: Hybrid onchain-offchain design in crypto protocols"><img alt="Fig 1: Hybrid onchain-offchain design in crypto protocols" height="474" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/491a30b1c361107e65615618ea2b29c226245e4d_2_690x474.jpeg" width="690" /></a></div><p></p>
<p>Fig A shows onchain logic on a single chain encoded as smart contracts. The onchain logic is accessed from a regular web or mobile client application through RPC calls.</p>
<p>Fig B shows an example of crypto protocol containing a mix of onchain smart contract logic on a single chain and offchain component attached to it. The offchain component typically either supplies data from an online system (eg price feeds through oracle) or performs compute-heavy operations on behalf of the smart contract (eg co-processor). The offchain component can also be a regular web backend of the dapp, if the app developer chooses to keep a portion of the business logic offchain (which is not uncommon in most modern dapps).</p>
<p>Fig C shows an example of a cross-chain transaction that involves two chains - source and destination chain (e.g., cross-chain swaps or bridging). Here, smart contract logic is present on both the chains, and there are corresponding offchain components.</p>
<blockquote>
<p>The main challenge that is being addressed in this post is that a big proportion of the off-chain components that are part of these hybrid onchain-offchain crypto protocols are run in trusted environments. This is incompatible with the main goals of crypto protocols which are trustlessness, censorship resistance and permission-less participation and verifiability.</p>
</blockquote>
<p>While the onchain components (aka smart contracts) are secured by consensus, economic incentives and permissionless verification, the same cannot be said about offchain services whose actions cannot be attributed onchain.  These services are, in most cases, centralised,  owned and run by trusted entities, but play critical role in the overall transaction workflows. They are vulnerable to censorship, tampering and other kinds of attacks. Note that only the on-chain logic of the crypto protocols is secured by the blockchain consensus, not the supporting off-chain infrastructure and services which have varying levels of trust assumptions. In some cases, it is not even possible to detect malicious actions performed by such offchain components <em>(non-attributable faults)</em>.</p>
<p>Figure 2 shows a non-exhaustive list of popular categories of offchain services that are an integral part of many crypto protocols.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b764f4c7ce39d7b0d4769c441ff37392c08d505.png" title="Fig 2: Common categories of off-chain services"><img alt="Fig 2: Common categories of off-chain services" height="350" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b764f4c7ce39d7b0d4769c441ff37392c08d505_2_690x350.png" width="690" /></a></div><p></p>
<p>What are the types of risks to crypto protocols with such centralised offchain services?</p>
<p><em>Insider Threats</em>: Employees or contractors within the service development team or the cloud platform provider may misuse their privileged access.<br />
<em>Unauthorized Modifications</em>: Malicious actors might attempt to alter the service code logic or configuration without detection, leading to unintended consequences inconsistent with the protocol goals.<br />
<em>Censorship Risks</em>: In case of offchain services, bad actors might attempt to censor certain transactions or user interactions.<br />
<em>Data and Fund Security</em>: There’s a risk of unauthorized access to sensitive data or funds managed by the service. e.g. a dapp backend managing an embedded wallet may view/steal user wallet keys.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-we-need-a-decentralised-verification-protocol-6" name="p-49574-we-need-a-decentralised-verification-protocol-6"></a>We need a decentralised verification protocol</h2>
<p>Hence, a critical requirement for the success of these modular hybrid onchain-offchain architectures is the ability to prove offchain service integrity at scale in a decentralised trustless manner, i.e. a <em>Byzantine fault tolerant service integrity verification system</em>.</p>
<p>In this post, we present <em>Proof of Service Integrity</em> (<strong>PoSI</strong>), a verification protocol that performs three main tasks - <em>deployment of publicly-identifiable code images</em>, <em>measurement of the correctness  of code deployed periodically</em>, and  <em>attestation of service integrity</em> in the production environment. These correspond respectively to the properties of <em>correctness</em>, <em>integrity</em> and <em>verifiability</em> for the monitored services. Figure 3 shows the key desired properties and relationships between the PoSI nodes that are part of the verification network, and the monitored services.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/3/135c0d620ec8bd53705bf83f07fd11c3aff47d42.jpeg" title="Fig 3: Verification layer for off-chain services"><img alt="Fig 3: Verification layer for off-chain services" height="163" src="https://ethresear.ch/uploads/default/optimized/3X/1/3/135c0d620ec8bd53705bf83f07fd11c3aff47d42_2_690x163.jpeg" width="690" /></a></div><p></p>
<p>The PoSI nodes that implement the verification protocol itself satisfy the following  properties: 1) <em>Trustless:</em> Service integrity measurements are secure against byzantine attacks by collaborations among the monitoring services and the monitored services. 2) <em>Tamper-proof</em>: The service monitoring service while verifying the tamper-resistance of the monitored services, is itself tamper-resistant  3) <em>Open</em>: The protocol allows anyone to register and provide measurement data , by using cryptographic primitives to ensure that a subset of actors cannot maliciously modify results in their favour.</p>
<p>A formal security model allows us to establish guarantees of accurate service measurements in the presence of malicious actors. The security guarantees of the PoSI protocol are composable with the onchain state commitments on blockchain ledgers to provide a comprehensive view of protocol security which is not possible by just focusing on smart-contract &amp; consensus-based security.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/2/f2a8e22a3c90dfb18ded2bfa3c371ef147452247.png" title="Fig 4: Integrated view of security of crypto protocols with PoSI"><img alt="Fig 4: Integrated view of security of crypto protocols with PoSI" height="201" src="https://ethresear.ch/uploads/default/optimized/3X/f/2/f2a8e22a3c90dfb18ded2bfa3c371ef147452247_2_690x201.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-proof-of-service-integrity-posi-protocol-overview-7" name="p-49574-proof-of-service-integrity-posi-protocol-overview-7"></a>Proof of Service Integrity (PoSI) protocol overview</h2>
<p>PoSI enables verifiable service integrity through the following:</p>
<p><em>Authenticated Deployment</em>: PoSI ensures that only authorized and verified code is deployed to the production environment. This prevents the introduction of malicious or unauthorized code during the deployment process.</p>
<p><em>Continuous Integrity Monitoring</em>: Once deployed, PoSI nodes continuously monitor the service to detect any unauthorized modifications or tampering. Any discrepancies between the running service and its expected state are immediately detected and reported.</p>
<p><em>Integrity Attestation</em>: Users or dApps can request integrity proofs for any PoSI-enabled service through a permissionless, public interface. Two types of integrity checks can be done on a given service - <em>measurements-based</em> and <em>proof-based</em>. <em>Measurements-based</em> checks involve deriving service integrity from the onchain measurements for the service. <em>Proof-based</em> checks can be done by requesting a SNARK proof of integrity  for the service, which can then be verified either on-chain (SNARK verification) or off-chain (in a web or mobile app).</p>
<p>Services that are verified by PoSI protocol are called <em>Integrity-verified services</em> (IVS).</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-architecture-workflows-8" name="p-49574-architecture-workflows-8"></a>Architecture workflows</h2>
<p>PoSI protocol involves the following three workflows:</p>
<ol>
<li>Service developer workflow</li>
<li>Operator workflow</li>
<li>Verification workflow</li>
</ol>
<p>Figure 5 shows an overview of the key actors and actions in the protocol.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/2/929487f88493ab7c774f428b5bed736328ff9f72.jpeg" title="Fig 5: Overview of PoSI protocol"><img alt="Fig 5: Overview of PoSI protocol" height="268" src="https://ethresear.ch/uploads/default/optimized/3X/9/2/929487f88493ab7c774f428b5bed736328ff9f72_2_690x268.jpeg" width="690" /></a></div><p></p>
<p>The architecture of PoSI involves the following components and actors:</p>
<p><strong>1. Human/Organisational actors:</strong></p>
<p><em>Service developer</em>: This refers to the developer and owner of the distributed software service. The service developer is the main ‘customer’ for the integrity-verified service, and is the person or entity that is ready to pay a fee to have their service integrity-verified.</p>
<p><em>Operator:</em> This refers to the provider of the computational infrastructure. The service developer can themselves choose to be the operator by deploying the IVS on a cloud account controlled by them or they can choose to deploy their service on an external operator’s VM through a DePIN service.</p>
<p><strong>2. PoSI Platform:</strong></p>
<p><em>PoSI platform onchain:</em> This contains the core smart contracts of the  protocol.</p>
<p><em>PoSI Offchain</em>: This comprises core offchain services that are part of the protocol.</p>
<p><strong>3. Applications/ Other chains:</strong></p>
<p><em>Application</em>:  A web or mobile application that verifies the proof for an IVS.</p>
<p><em>Other chain:</em> Any other chain can verify the zk proofs generated by the PoSI protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#p-49574-service-developer-workflow-9" name="p-49574-service-developer-workflow-9"></a>Service developer workflow</h3>
<ol>
<li>Service developer builds the service and registers the service image in a public repository.</li>
<li>Service developer registers the service image along with other service metadata with the PoSI onchain smart contracts. They also deposit rewards amount, along with service level expectations (e.g. frequency of measurements).</li>
<li>Service developer can trigger the PoSI smart contract to trigger the service deployment either on their self-hosted VM, their cloud VM or on a DePIN VM.</li>
<li>The PoSI protocol pays out the rewards to the operators based on the tasks performed by them, from the service developer’s account.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#p-49574-operator-workflow-10" name="p-49574-operator-workflow-10"></a>Operator workflow</h3>
<ol>
<li>Operator registers their VM with the PoSI registration service. The operator can choose to perform two kinds of tasks - host <em>service images</em>, or host the <em>PoSI host program</em> that performs measurements on other services. For the former, any regular VM of the configuration required by service developers would be accepted. For the latter, TEE-based VMs will be required.</li>
<li>Note that service developer can choose to deploy their service on their own VM, in which case they need to register it like other external operators. For TEE-based VMs, the quote has to be generated by the operator and submitted to the registration service along with in-enclave generated public key.</li>
<li>Operator stakes the minimum specified tokens as part of registration. If the service developer hosts the service on their own VM, this step is not required.</li>
<li>The PoSI registration service verifies the registered VM and registers it with the PoSI onchain contract. The PoSi registration service itself runs within a TEE enclave.</li>
<li>When the service developer triggers deployment of a service, the PoSI host program retrieves the registered service image from public repository and deploys the service on the service developer (or external operator’s VM based on the configuration).</li>
<li>If an operator has registered to host the PoSI protocol, the PoSI master  deploys the PoSI host program on the operator’s VM. This enables the operator to then perform service measurements on other services.</li>
<li>Based on the specification of the service developer, the operator set is established for verifying that service, which runs the consensus mechanism to determine the final service measurements. The votes of all  operators in the operator set are aggregated and recorded onchain, along with the measurements.</li>
<li>At periodic intervals, measurements of the performance of the verious operators are taken by the PoSI measurement service, and rewards are computed for the operators. Any incorrect measurements attributable to any of the operators in operator set is penalized through slashing of their stake, in a manner defined in the PoSI protocol.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#p-49574-verification-workflow-11" name="p-49574-verification-workflow-11"></a>Verification workflow</h3>
<ol>
<li>Any web or mobile application can ask the PoSI protocol servers for attestation of any particular service. The PoSI protocol returns the proof to the web/mobile application.</li>
<li>Two kinds of proofs can be requested from the PoSI protocol for a service: <em>state proofs</em> and <em>SNARK-proofs</em>. <em>State proofs</em> simple return the onchain state of a service computed from the measurements submitted by operators. SNARK proofs that are returned by the PoSI protocol can be verified either off-chain within the web/mobile application, or submitted to another on-chain smart contract for verification.</li>
</ol>
<p>An integrated view of the various workflows for the PoSI protocol is shown in figure.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/2/32045a0a10edcc50ab33324a649080621d79a8ac.jpeg" title="Fig 6: Integrated view of PoSI workflows"><img alt="Fig 6: Integrated view of PoSI workflows" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/3/2/32045a0a10edcc50ab33324a649080621d79a8ac_2_690x309.jpeg" width="690" /></a></div><p></p>
<p>Note: Figure 6 shows only a single host program taking the service measurements (for reducing clutter in diagram), but it can be visualised as a set of nodes that participate and arrive at a consensus before posting the measurements on-chain.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-conclusion-12" name="p-49574-conclusion-12"></a>Conclusion</h2>
<p>Trustfree measurement of offchain service integrity is an unsolved problem in decentralised networks. <strong>Proof of Service Integrity (PoSI)</strong> addresses this core requirement by providing a secure, byzantine resistant verification layer for offchain services while allowing open participation for operators and service developers to benefit from the protocol. All components of the protocol can be operated by community-run protocol nodes controlled by the onchain protocol smart contracts. PoSI incorporates a layered security model that includes <em>consensus-based</em>, <em>hardware-based</em> and <em>crypto-economic security</em>. PoSI requires the participating offchain services to have open source code, a publicly verifiable service image, reproducible build process and dockerized deployment.</p>
<h2><a class="anchor" href="https://ethresear.ch#p-49574-faq-13" name="p-49574-faq-13"></a>FAQ</h2>
<h3><a class="anchor" href="https://ethresear.ch#p-49574-what-kind-of-services-can-benefit-from-the-posi-protocol-14" name="p-49574-what-kind-of-services-can-benefit-from-the-posi-protocol-14"></a>What kind of services can benefit from the PoSI protocol?</h3>
<p>Any in-protocol or out-of-protocol offchain service can benefit from PoSI protocol. A non-exhaustive list of offchain services was mentioned earlier in the post, and is reproduced here:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b764f4c7ce39d7b0d4769c441ff37392c08d505.png" title="Fig 7: Popular categories of off-chain services"><img alt="Fig 7: Popular categories of off-chain services" height="350" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b764f4c7ce39d7b0d4769c441ff37392c08d505_2_690x350.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#p-49574-what-are-the-alternative-architectures-available-to-secure-offchain-services-15" name="p-49574-what-are-the-alternative-architectures-available-to-secure-offchain-services-15"></a>What are the alternative architectures available to secure offchain services?</h3>
<p>For offchain services to transition from <em>trusted</em> to <em>trust-minimised</em> / <em>trustless</em> architectures, here is a comparison of the various design approaches.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Design approach</th>
<th>Description</th>
<th>Pros</th>
<th>Cons</th>
<th>Security model</th>
</tr>
</thead>
<tbody>
<tr>
<td>Consensus-based</td>
<td>Build a BFT-consensus with own operator set</td>
<td>Trustless</td>
<td>It is expensive and cumbersome for a service developer</td>
<td>Depends on size of the operator set</td>
</tr>
<tr>
<td>ZK-based</td>
<td>Build a custom zk circuit or a program that can be proven in a general purpose zkVM</td>
<td>Trustless</td>
<td>Involves rewrite of the service using zk DSLs or using Rust. Expensive to generate zk-proofs</td>
<td>Restricted to what can be proven in zk circuits</td>
</tr>
<tr>
<td>EigenLayer AVS-based</td>
<td>Convert the service into Eigenlayer AVS</td>
<td>Inherit Ethereum security without bootstrapping an operator set</td>
<td>Requires rewrite of the code to comply with AVS protocol. Also AVS can only detect and penalise operator faults if they are observable on-chain.</td>
<td>Economic security</td>
</tr>
<tr>
<td>PoSI IVS-based</td>
<td>Deploy existing code in docker containers with no code rewrite.</td>
<td>Ability to detect non-attributable faults (those that are not normally visible on-chain such as censorship, or unauthorized upgrades of service algorithms). Small, configurable cost.</td>
<td>Services should meet pre-requisites: open-source code, a publicly verifiable service image, a reproducible build process and dockerized deployment</td>
<td>Multi-layered security model incorporating <em>consensus-based</em>, <em>TEE</em>, and <em>crypto-economic security</em> constructs.</td>
</tr>
</tbody>
</table>
</div><h2><a class="anchor" href="https://ethresear.ch#p-49574-credits-16" name="p-49574-credits-16"></a>Credits</h2>
<p>The concept and design for PoSI protocol and Integrity-verified services was initially developed as a collaboration between <a class="mention" href="https://ethresear.ch/u/peshwar9">@peshwar9</a> and <a class="mention" href="https://ethresear.ch/u/mohsinriaz17">@mohsinriaz17</a> with contribution from several others to refine and enhance it.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/proof-of-service-integrity-posi-trustless-measurement-of-service-integrity/20255">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 11 Aug 2024 17:44:55 +0000</pubDate>
</item>
<item>
<title>Pls ignore. New post available</title>
<link>https://ethresear.ch/t/pls-ignore-new-post-available/20251</link>
<guid>https://ethresear.ch/t/pls-ignore-new-post-available/20251</guid>
<content:encoded><![CDATA[
<div> 关键词：文章、提取、5个、中文、总结

---

总结: 这篇文章要求从一段文本中提取出五个关键点，并用中文进行总结。首先，需要识别出文本中的核心信息或主题，这通常包括最重要的事实、观点或论点。然后，将这五个关键点归纳出来，确保它们覆盖了文本的主要内容和重点。

具体操作步骤如下：

1. **阅读与理解**：仔细阅读原文，确保理解其主要论点和细节。
2. **识别关键点**：找出文本中最重要、最能代表其主旨的部分，这些可能是论据、结论、主要事件或人物等。
3. **提炼概括**：将这些关键点以简洁的语言表述出来，确保每个关键点都能独立反映原文的一部分核心信息。
4. **整合总结**：将提炼出的五个关键点整合成一个连贯的段落，确保整体结构清晰，逻辑性强，能够全面地反映原文的主要内容。

通过以上步骤，可以有效地完成从原文到精炼中文总结的过程，确保信息的准确性和完整性。 <div>
<p>(topic deleted by author)</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pls-ignore-new-post-available/20251">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 11 Aug 2024 08:56:36 +0000</pubDate>
</item>
<item>
<title>Proof of Service integrity</title>
<link>https://ethresear.ch/t/proof-of-service-integrity/20251</link>
<guid>https://ethresear.ch/t/proof-of-service-integrity/20251</guid>
<content:encoded><![CDATA[
<div> 关键词：文章、提取、5个、中文、总结

---

总结: 这篇文章要求从一段文本中提取出五个关键点，并用中文进行总结。首先，需要识别出文本中的核心信息或主题，这通常包括最重要的事实、观点或论点。然后，将这五个关键点归纳出来，确保它们覆盖了文本的主要内容和重点。

为了实现这一目标，第一步是仔细阅读并理解原始文本，确定其主要论点和关键信息。接着，选择五个最能代表文本核心内容的元素进行提炼。这些关键点可能是主要事件、重要人物的观点、统计数据、对比分析或是结论等。

在进行中文总结时，应确保语言简洁明了，同时保持对原始信息的准确传达。总结应该清晰地列出上述五个关键点，并简要阐述每个点与整体文本的关系，以帮助读者快速理解文本的核心内容。在整个过程中，注意保持逻辑连贯性和信息的完整性，使得总结既全面又易于理解。 <div>
<p>(topic deleted by author)</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/proof-of-service-integrity/20251">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 11 Aug 2024 08:56:36 +0000</pubDate>
</item>
<item>
<title>Efficient Data Distribution with Reed-Solomon Codes for Sharded Storage</title>
<link>https://ethresear.ch/t/efficient-data-distribution-with-reed-solomon-codes-for-sharded-storage/20232</link>
<guid>https://ethresear.ch/t/efficient-data-distribution-with-reed-solomon-codes-for-sharded-storage/20232</guid>
<content:encoded><![CDATA[
<div> 关键词：Reed-Solomon编码、区块链存储、数据分布、O(N log n)解码复杂度、M31域

总结：

本文介绍了一种利用Reed-Solomon（RS）编码高效分配N个数据元素至n个节点的方法，旨在解决区块链存储的扩展问题。与简单地将数据放大至bN倍的直觉方法不同，本文提出的方法通过将数据表示为表格并创建数据碎片，实现了O(N log n)的解码复杂度。

首先，对于2-adicity域的情况，我们以BabyBear域为例进行说明。假设有一个长度为N的向量{a_i}，目标是将其在n个服务器间分布，确保任何k个服务器都能恢复原始数据。通过使用RS编码，我们将向量表示为大小为m×k的表格，并构建了一个双变量多项式f(x,y)，其中f(x,y) = ∑_{ij} a_{ij} L_i(x) λ_j(y)。通过快速傅里叶变换（FFT）对表格的每一行进行操作，我们得到了多项式的特定形式，从而可以为每个节点分配唯一的线性组合的列。为了验证数据碎片的有效性，我们引入了替换y=x^m的技巧，这有效地将所有列连接起来，便于进行多项式承诺计算。

对于M31域的情况，我们采用类似的方法，但使用了环傅里叶变换（CFFT）。在环表示中，多项式f(x,y)被定义为f(x,y)=f_0(x)+yf_1(x)，其中f_0(x)和f_1(x)的次数分别为N/2-1。通过对表格的每一行执行CFFT，我们得到了大小为n的m个向量。然后，我们定义f(x,y,u,v) = ∑_{ij} a_{ij} L_i(x,y) Λ_j(u)，其中Λ_j(u)是围绕圆的偶数拉格朗日基函数。通过替换u=x^{m/2}，我们能够将所有一维组件合并为单个多项式，同时保持结构f_0(x)+yf_1(x)，从而实现数据碎片化。

此方法适用于数据恢复、存储以及零知识证明（zk）应用。在数据恢复过程中，任何k个碎片都足够恢复原始数据。在存储方面，这种方法允许直接存储多项式承诺，而不仅仅是中间表示形式的数据。此外，算法描述部分详细介绍了如何生成碎片及其承诺，并将数据分布到集群中的节点上。通过这种方法，即使客户端的带宽有限，也能有效处理大数据文件的分布。

总之，本文通过引入RS编码和FFT/CFFT技术，提供了一种优化的数据分布式存储方案，特别适用于需要整体节点失败保护的区块链系统。尽管多项式承诺的计算复杂度保持不变，但这种方法在数据处理流程中提供了显著的优化，使其成为区块链存储扩展的有力解决方案。 <div>
<h2><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h2>
<p>This writeup presents an efficient method for distributing N data elements across n nodes using Reed-Solomon (RS) encoding, specifically designed for blockchain <a href="https://ethresear.ch/t/blockchain-sharded-storage-web2-costs-and-web3-security-with-shamir-secret-sharing/18881">sharded storage</a> solutions. We address the challenge of scaling blockchain storage by introducing techniques that achieve O(N log n) decoding complexity, where N is the total amount of data and n is the number of nodes.</p>
<p>A naive approach would be to simply blow up the data from N to bN, where b is the blowup factor. However, this would result in O(N log N) decoding complexity. Our method, by representing data as a table and creating data shards, achieves O(N log n) decoding complexity, which is significantly faster.</p>
<p>It’s crucial to note that we don’t need to apply RS codes to all data together. This is because a node can only go offline as a whole - there can’t be a situation where two nodes lose half of their data each, requiring RS codes to recover the data. A node either loses all its data or provides it entirely.</p>
<p>While our method doesn’t significantly improve the speed of calculating polynomial commitments (which remains O(N log N) for FRI), it greatly optimizes the data encoding-decoding procedure.</p>
<h3><a class="anchor" href="https://ethresear.ch#naive-approach-2" name="naive-approach-2"></a>Naive approach</h3>
<p><img alt="" height="150" src="https://ethresear.ch/uploads/default/original/3X/6/9/691031aaa0990298d3f1755f55e1cc286cb49197.svg" width="600" /></p>
<h3><a class="anchor" href="https://ethresear.ch#our-approach-3" name="our-approach-3"></a>Our approach</h3>
<p><img alt="" height="240" src="https://ethresear.ch/uploads/default/original/3X/6/a/6a6eea46c44a4be6f7311ec8edbab96cf8f81cd0.svg" width="600" /></p>
<h2><a class="anchor" href="https://ethresear.ch#notation-and-definitions-4" name="notation-and-definitions-4"></a>Notation and Definitions</h2>
<p>Before proceeding with the detailed description of our method, let’s define the key terms and symbols used throughout this writeup:</p>
<ul>
<li>N: Total amount of data elements</li>
<li>n: Number of nodes in the network</li>
<li>k: Minimum number of nodes required to recover the original data</li>
<li>b: Blowup factor, defined as b = n/k</li>
<li>m: Number of rows in the data table representation</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#h-2-adicity-fields-case-5" name="h-2-adicity-fields-case-5"></a>2-Adicity Fields Case</h2>
<p>We consider a 2-adic prime field, specifically the BabyBear field with prime p = 15 * 2^27 + 1.</p>
<p>Let’s consider we have a vector <span class="math">{a_i}</span> of N elements of field <span class="math">F_p</span>. We want to distribute this vector among n servers, such that any k servers can recover the original vector. We use Reed-Solomon codes to achieve this.</p>
<p>We represent the vector <span class="math">{a_i}</span> as a table <span class="math">{a_{ij}}</span> of size <span class="math">m \times k</span> with <span class="math">m</span> rows and <span class="math">k</span> columns.</p>
<p>We define a bivariate polynomial <span class="math">f(x,y)</span> to represent our data:</p>
<p><span class="math">f(x,y) = \sum\limits_{ij} a_{ij} L_i(x) \lambda_j(y)</span></p>
<p>where <span class="math">L_i(x)</span> is a Lagrange polynomial of degree <span class="math">m-1</span> and <span class="math">\lambda_j(y)</span> is a Lagrange polynomial of degree <span class="math">k-1</span>.</p>
<p>After performing FFT over each row of the table, <span class="math">f(x,y)</span> takes the following form:</p>
<p><span class="math">f(x,y) = \sum\limits_{ij} b_{ij} L_i(x) y^j = \sum\limits_{j} f_j(x) y^j</span></p>
<p>where <span class="math">f_j(x)=\sum\limits_{i} b_{ij} L_i(x)</span> is a polynomial of degree <span class="math">m-1</span>.</p>
<p>Each node should receive a unique linear combination of the columns of the table. Then we can recover the original vector by solving a system of linear equations. Let’s represent the data shard as <span class="math">f(x,y_0)</span>, where <span class="math">y_0</span> is a fixed value for each shard.</p>
<p><span class="math">f(x,y) - f(x,y_0) = \sum\limits_{j} (y^j - y_0^j) f_j(x) = (y-y_0) q(x,y)</span></p>
<p>where <span class="math">q(x,y)</span> is a quotient polynomial.</p>
<p>We make the substitution <span class="math">y=x^m</span> without loss of any inner polynomial structure. This substitution effectively concatenates all columns of the table, one after another, which is convenient for creating a polynomial commitment.</p>
<p>After the substitution, we get the following polynomial equation to check that the shard is a valid part of the original data:</p>
<p><span class="math"> f(x,x^m) - f(x, y_0) = (x^m - y_0) q(x,x^m) </span></p>
<h2><a class="anchor" href="https://ethresear.ch#circle-fields-case-6" name="circle-fields-case-6"></a>Circle Fields Case</h2>
<p>We now consider the M31 field with p = 2^32 - 1. [HLP24] proposed a method called CFFT (Circular Fast Fourier Transform), which is analogous to FFT but works with polynomials defined on a complex circle.</p>
<p>In the circle representation, the polynomial takes the form <span class="math">f(x,y)=\Re(f(z))</span>, where <span class="math">|z|=1</span>.</p>
<p>Due to the circle constraint <span class="math">|z|^2 = x^2 + y^2 = 1</span>, the polynomial can be represented as:</p>
<p><span class="math">f(x,y) = f_0(x) + y f_1(x)</span></p>
<p>where <span class="math">f_0(x)</span> and <span class="math">f_1(x)</span> are polynomials of degree <span class="math">N/2-1</span>. Note that we have two polynomials of this degree, providing sufficient degrees of freedom.</p>
<p>Let’s represent the data vector <span class="math">{a_i}</span> as a table <span class="math">{a_{ij}}</span> of size <span class="math">m \times k</span> with <span class="math">m</span> rows and <span class="math">k</span> columns. We perform circle FFT (CFFT) on each row of the table, resulting in <span class="math">m</span> vectors of size <span class="math">n</span>.</p>
<p><span class="math">f(x,y,u,v) = \sum\limits_{ij} a_{ij} L_i(x,y) \lambda_j(u,v)</span></p>
<p>It’s important to note that the function <span class="math">f(x,y,u,v)</span> is defined on a torus: <span class="math">x^2+y^2=1</span>, <span class="math">u^2+v^2=1</span>.</p>
<p>Let’s consider <span class="math">f(x,y,u,v)</span> as <span class="math">v</span>-even function. This approach is not useful directly for SNARKs, because then we have even constraint on function values and next row could be dependent on the previous one. However, it’s useful for data distribution.</p>
<p>Then</p>
<p><span class="math">f(x,y,u,v) = f(x,y,u) = \sum\limits_{ij} a_{ij} L_i(x,y) \Lambda_j(u) </span>,<br />
where <span class="math">\Lambda_j(u)</span> is even Lagrange basis on the circle.</p>
<p>After applying CFFT over each row, we get:</p>
<p><span class="math">f(x,y,u) = \sum\limits_{ij} b_{ij} L_i(x,y) u^j = \sum\limits_{j} f_j(x,y) u^j</span></p>
<p>where <span class="math">f_j(x,y)=\sum\limits_{i} b_{i} L_i(x,y)=f_{j,0}(x) + y f_{j,1}(x)</span> and each polynomial is <span class="math">(m/2-1)</span>-ordered.</p>
<p>Let’s consider <span class="math">f(x,y,u_0)</span> as a data shard, where <span class="math">u_0</span> is a fixed value for each shard.</p>
<p><span class="math">f(x,y,u) - f(x,y,u_0) = \sum\limits_{j} (u^j - u_0^j) f_j(x,y) = (u-u_0) q(x,y,u)</span></p>
<p>where <span class="math">q(x,y,u)</span> is a quotient polynomial.</p>
<p>We make the substitution <span class="math">u=x^{m/2}</span> in <span class="math">f(x,y,u)</span>. This substitution does not result in information loss because <span class="math">f_j(x,y)=f_{j,0}(x) + y f_{j,1}(x)</span>, where the degrees of <span class="math">f_{j,0}(x)</span> and <span class="math">f_{j,1}(x)</span> are <span class="math">m/2-1</span>. The resulting polynomial <span class="math">f(x,y,x^{m/2})</span> maintains the structure <span class="math">f_0(x) + y f_1(x)</span> and remains defined on a circle, albeit with each one-dimensional component now of degree <span class="math">N/2-1</span>. This substitution effectively concatenates all columns of the table, similar to the 2-adicity case.</p>
<p>After the substitution, we get the following polynomial equation to check that the shard is a valid part of the original data:</p>
<p><span class="math">f(x,y,x^{m/2}) - f(x,y,u_0) = (x^{m/2}-u_0)q(x,y,x^{m/2})</span></p>
<h2><a class="anchor" href="https://ethresear.ch#applications-7" name="applications-7"></a>Applications</h2>
<h3><a class="anchor" href="https://ethresear.ch#recovering-the-source-data-8" name="recovering-the-source-data-8"></a>Recovering the source data</h3>
<p>Any <span class="math">k</span> shards are enough to recover the original data.</p>
<p><span class="math">f(x,y,u) = \sum\limits_{j} c_{ij} L_i(x,y) \mu(u),</span></p>
<p>where <span class="math">\{\mu_i(u)\}</span> is a Lagrange polynomial basis on the evaluation domain <span class="math">H=\{u_i\}</span>, and <span class="math">u_i</span> are fixed values for each shard.</p>
<p><span class="math"> \mu_i(u) = d_i Z_{H}(u)/(u-u_i),</span><br />
where <span class="math">Z_{H}(u)</span> is a polynomial that is zero at all points of <span class="math">H</span>, <span class="math">d_i</span> is a normalization factor, so</p>
<p><span class="math"> \mu_i(u) = \begin{cases}
1, &amp; u = u_i \\
0 &amp; u \neq u_i
\end{cases}
</span></p>
<p>The source values could be computed as<br />
<span class="math">a_{ij} = f(g^i.x, g^i.y, g^j.x)</span></p>
<h3><a class="anchor" href="https://ethresear.ch#polynomial-storing-9" name="polynomial-storing-9"></a>Polynomial storing</h3>
<p>In some cases, we want to store something directly related to the polynomial commitment of <span class="math">f</span> instead of <span class="math">a_{ij}</span>. This is important for zk applications, like rollups.</p>
<p>Due to the inner structure of coefficient representation, we can represent <span class="math">g(x,y)</span> as <span class="math">f(x,y,x^{m/2})</span>. That means that we can store rollup block data as a set of shards, keeping the source polynomial structure, keeping the source commitment. Then <span class="math">a_{ij}</span> will be some kind of intermediate representation of the committed data.</p>
<h2><a class="anchor" href="https://ethresear.ch#algorithm-description-10" name="algorithm-description-10"></a>Algorithm description</h2>
<pre><code class="lang-python">
def get_shards_and_commitments(data: List[M31], m:int, n:int, k:int, cd:Domain, rd:Domain, xrd:Domain)
    # data is a list of N elements
    # m is the number of rows in the table
    # n is the number of nodes
    # k is the number of nodes required to recover the original data
    # cd is the evaluation domain for the columns
    # rd is the evaluation domain for the rows
    # xrd is evaluation domain for the shards (blown up rows)
    # Returns polynomial commitments and prover data for all the data and shards
    
    # create a table of size m x k, fulfilled row by row
    table = create_table(data, m, k)
    
    # perform cfft on each row of the table
    for row in table:
        row[:] = cfft(row, rd)
    
    # create shards
    shards = [icfft(fit_to_domain_with_zeros(row, rd, xrd), xrd) for row in table]
    
    # convert to col-ordered table
    shards = to_col_ordered(shards)

    # convert table to col_ordered
    table = to_col_ordered(table)

    # compute monomial representation of $f(x,y,x^{m/2})$
    f = concat([cfft(col, cd) for col in table])

    return pcs_monomial_repr(f), [pcs(shard) for shard in shards]

</code></pre>
<h2><a class="anchor" href="https://ethresear.ch#distributing-the-data-over-a-cluster-of-nodes-11" name="distributing-the-data-over-a-cluster-of-nodes-11"></a>Distributing the data over a cluster of nodes</h2>
<p>In practice, the client should deliver the data to <span class="math">n</span> nodes, and the total amount of data is <span class="math">bN</span>. However, for big files, it could be inefficient due to the client’s limited bandwidth.</p>
<p>Instead of this client-centralized approach, <span class="math">b</span> nodes could deliver <span class="math">N \cdot (1-1/k)</span> total data to <span class="math">k-1</span> nodes. There is no bottleneck at the client side (the client sends just <span class="math">N</span> data to one node), but total network data bandwidth is <span class="math">b N \cdot (2-1/k) \approx 2bN</span>.</p>
<p><img alt="" height="493" src="https://ethresear.ch/uploads/default/original/3X/3/b/3be891968cd29eb75294d6219b0d063ddb3bb8f2.svg" width="195" /></p>
<p>There is no valuable computational overhead to compute the shards vectors because with fft or cfft each node can perform a unique coset shift instead of blowup (and the sum of all shifted evaluation domains is the evaluation domain for the blowup).</p>
<p><img alt="" height="250" src="https://ethresear.ch/uploads/default/original/3X/2/0/2015d84ea59b9b3aea04f0aa12ff6cc33087367f.svg" width="340" /></p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-12" name="conclusion-12"></a>Conclusion</h2>
<p>We have extended our method of data representation to the M31 field, providing a robust framework for efficient data distribution in blockchain storage. By representing data as a table and using FFT/CFFT techniques, we achieve O(N log n) decoding complexity, significantly optimizing the data encoding-decoding procedure. This approach is particularly valuable in blockchain systems where nodes can only fail as a whole, and efficient data recovery is crucial.</p>
<p>While the complexity of polynomial commitment calculations remains O(N log N) for FRI, our method provides substantial benefits in the overall data handling process, making it a promising solution for scalable blockchain storage.</p>
<h2><a class="anchor" href="https://ethresear.ch#references-13" name="references-13"></a>References</h2>
<p><a href="https://eprint.iacr.org/2024/278" rel="noopener nofollow ugc">HLP24</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/efficient-data-distribution-with-reed-solomon-codes-for-sharded-storage/20232">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 07 Aug 2024 22:32:41 +0000</pubDate>
</item>
<item>
<title>Aligning DAO contributions with objectives</title>
<link>https://ethresear.ch/t/aligning-dao-contributions-with-objectives/20204</link>
<guid>https://ethresear.ch/t/aligning-dao-contributions-with-objectives/20204</guid>
<content:encoded><![CDATA[
<div> 关键词：DAO、Objective Alignment Engine（OAE）、Jury、Dispute Resolution、Rewards Distribution

文章主要探讨了如何通过建立Objective Alignment Engine（OAE）来优化DAO（去中心化自治组织）中贡献者的激励机制，以确保贡献与DAO的既定目标保持一致。以下是文章的主要内容总结：

1. **动机**：当前的DAO激励机制往往基于规则，如按投票数排名支付固定金额，这可能导致资源分配不合理，无法保证贡献的质量与目标的一致性。引入OAE机制旨在通过客观评估贡献与目标的关联度来改进激励机制。

2. **背景**：在区块链协议中，通常缺乏有效手段将贡献者的激励与网络目标对齐。OAE机制尝试将这一过程纳入协议设计范畴，以实现“利益相关”和“未来决策”等类似解决方案的目标。

3. **假设与基础**：文章假定DAO已经明确定义了其目标，例如以太坊聚焦于安全性，而Optimism则关注可扩展性。基于此明确的目标，可以设计依赖于信息收集而非仅依赖个人偏好的激励机制。

4. **核心组件**：OAE机制的核心包括组建一个能够评估贡献与目标一致性程度的“陪审团”。陪审团成员需要投入代币作为抵押，以获得奖励，并通过机制如SchellingCoin或元市场等确保其报告的真实性。

5. **问题与挑战**：尽管OAE机制提供了一种潜在的解决方案，但仍面临几个挑战，包括明确目标定义的难度、陪审团可能的共谋行为、以及防止操纵预测市场或同伴预测的风险。

总结：
文章提出了Objective Alignment Engine（OAE）的概念，旨在通过构建一个能够评估贡献与DAO目标一致性程度的机制，优化DAO中的激励分配。该机制的核心是组建一个陪审团，负责对贡献进行评价，并通过机制设计确保陪审团的公正性和激励的有效性。然而，实施此类机制仍需解决目标定义的清晰度、陪审团的诚实性和抵抗操纵等问题。通过引入明确的目标定义和有效的激励机制，OAE有望在一定程度上解决DAO治理中的激励对齐问题，促进资源的合理分配和目标的高效实现。 <div>
<h1><a class="anchor" href="https://ethresear.ch#aligning-dao-contributions-with-objectives-1" name="aligning-dao-contributions-with-objectives-1"></a>Aligning DAO contributions with objectives</h1>
<p>In this post, we’re approaching how to align DAO contributions in a setting where a clear goal is already defined.</p>
<p>We will define an Objective Alignment Engine (OAE) as a class of mechanisms that fulfill this objective. We aim to define the contour of such mechanisms so that they optimize resource allocation and provide economic guarantees on the efficacy of incentives.</p>
<p><em>A more complete description along with more concrete examples is available at <a href="https://www.notion.so/r-ag-oae-Objective-Alignment-Engine-6984df3b33cc468e85264a9b975437eb?pvs=21" rel="noopener nofollow ugc">[r.ag.oae] Objective Alignment Engine</a>.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#motivation-2" name="motivation-2"></a>Motivation</h2>
<p>Suppose a DAO where governance contributors are compensated based on a simple rule, like “the top 10 delegates by total votes delegates are paid $10k / month”. As protocol designers, this sounds suboptimal as we have no guarantees that the treasury is spent on the delegates who produce the most useful contributions to governance (e.g. produce the most complete proposals, or vote most consistently). Also, any such rules-based process inevitably becomes gameable under <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" rel="noopener nofollow ugc">Goodhart’s law</a>.</p>
<p>We’d prefer that contributions were picked individually and reward contributors based on how aligned these contributions are with the overarching goals of the network (e.g., how much are such contributions participating in growth? or decentralization?).</p>
<p>Importantly, we’d also prefer that there is an objective notion of alignment, enabling a mechanism that relies not only on individual preferences but as much as possible on eliciting information (as suggested in <a href="https://ethresear.ch/t/governance-mixing-auctions-and-futarchy/10772">this post on mixing auctions and futarchy</a>).</p>
<h2><a class="anchor" href="https://ethresear.ch#background-3" name="background-3"></a>Background</h2>
<p>On-chain protocols often struggle to align contributor incentives with network goals. While blockchains are designed to optimize resource spending for security, producing alignment with agreed-upon goals is typically left to external governance systems. OAE mechanisms bring contributions and incentives within the purview of the protocol designer.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc4f46fea1dfde8237a19aac23844864e00fd24f.jpeg" title="image"><img alt="image" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc4f46fea1dfde8237a19aac23844864e00fd24f_2_690x389.jpeg" width="690" /></a></div><p></p>
<p>This approach aligns with the “skin in the game” and futarchy-like solutions suggested in <a class="inline-onebox" href="https://vitalik.eth.limo/general/2021/08/16/voting3.html" rel="noopener nofollow ugc">Moving beyond coin voting governance</a>. We’ll rely on the notion that there is a jury that is incentivized to produce a good judgment of whether contributions are aligned and scale this with additional mechanisms.</p>
<h2><a class="anchor" href="https://ethresear.ch#assumptions-objective-definition-4" name="assumptions-objective-definition-4"></a>Assumptions: objective definition</h2>
<p>A central assumption that we take is that the DAO has a clearly defined objective. While this is theoretically difficult to achieve in a decentralized setting, most protocol values and visions are set initially by the core team and steered by a Foundation.</p>
<p>For example, Ethereum focuses today on <a href="https://ethereum.org/en/roadmap/vision/" rel="noopener nofollow ugc">Scalability, Security, and Sustainability</a>, whereas Optimism has the <a href="https://optimism.io/vision" rel="noopener nofollow ugc">Superchain vision</a>.</p>
<p>In the rest of this post, we assume an existing process produces a clear definition of an objective <span class="math">o</span> (hence, the <em>Objective</em> part of the Alignment Engine).</p>
<p>The existence of such an objective enables designing mechanisms that rely only on eliciting information from participants, namely whether a contribution is aligned or not with the objective.</p>
<h2><a class="anchor" href="https://ethresear.ch#alignment-engine-5" name="alignment-engine-5"></a>Alignment engine</h2>
<h3><a class="anchor" href="https://ethresear.ch#jury-6" name="jury-6"></a>Jury</h3>
<p>Once an objective is defined, we want to set up a jury that can review any contribution and evaluate how aligned it is with the objective. This is the central part of this design.</p>
<p>The main function of the jury is to produce ratings “aligned” / “misaligned” on contributions that are produced on the protocol.</p>
<p>To produce alignment within the jury itself, we rely on mechanisms that incentivize truthful reporting but don’t rely on verifiable outcomes (like, BTC/USD quote). Possible such mechanisms are SchellingCoin or <a href="https://arxiv.org/abs/2306.04305" rel="noopener nofollow ugc">self-resolving prediction markets for unverifiable outcomes</a> (Srinivasan et al, 2023).</p>
<p>To enable incentivization and notably negative rewards, we expect jurors to stake tokens ($ALIGN) and receive token emissions as rewards.</p>
<h3><a class="anchor" href="https://ethresear.ch#dispute-resolution-7" name="dispute-resolution-7"></a>Dispute resolution</h3>
<p>Here we assume that most contributions can be unequivocally qualified as “aligned” or “misaligned” (ie there is a <em>clear</em> way to rate most contributions, as long as <span class="math">o</span> is well defined).</p>
<p>But equivocal cases will inevitably appear. When a contestable result is produced, a dispute resolution mechanism needs to be enforced (either an external one like a Kleros court or an Augur-style ALIGN token fork).</p>
<h3><a class="anchor" href="https://ethresear.ch#calibration-8" name="calibration-8"></a>Calibration</h3>
<p>In general, a juror can be an agent making use of any tools available, including AI and prediction markets, to produce the best evaluations. But this leaves open the question of how to incentivize jurors to get better at their jobs so the jury doesn’t degenerate into a static committee.</p>
<p>If part of the contributions have a ground truth to which their ratings can be compared (e.g. growth contributions that aim at increasing a key metric like TVL for a DeFi protocol or fees for an L2), jurors can be rewarded accordingly. This way, the mechanism can still leverage objective outcomes to improve its accuracy (or <em>be <a href="https://www.overcomingbias.com/p/meta-jury-markets" rel="noopener nofollow ugc">calibrated</a></em>).</p>
<h3><a class="anchor" href="https://ethresear.ch#scaling-9" name="scaling-9"></a>Scaling</h3>
<p>Armed with such a jury, DAO contributions can theoretically be evaluated. To handle large numbers of contributions, two scaling options are available:</p>
<ul>
<li>Prediction markets: bettors predict jury decisions, creating “Aligned” and “Misaligned” tokens.</li>
<li>Peer prediction: raters evaluate contributions, with a small percentage reviewed by the jury.</li>
</ul>
<p>Spam protection through staked curation or auctions ensures only valuable contributions are evaluated.</p>
<h2><a class="anchor" href="https://ethresear.ch#rewards-distribution-10" name="rewards-distribution-10"></a>Rewards distribution</h2>
<p>With contribution evaluation in place, the last bit is to distribute contribution rewards to incentivize the most aligned contributions to be produced in the future.</p>
<p>Aligned contributions receive rewards from treasury or token emissions, proportional to their alignment rating. Highly aligned contributions may be automatically implemented in proposal-like scenarios</p>
<p>This produces a positive feedback loop where:</p>
<ol>
<li>Better-aligned contributions receive more rewards</li>
<li>This incentivizes more aligned contributions in the future</li>
<li>The protocol becomes more resistant to misaligned or captured governance over time.</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7e67510d59620761b9c2941d8a4067b859bc6ebb.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7e67510d59620761b9c2941d8a4067b859bc6ebb_2_543x500.jpeg" width="543" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#attacks-11" name="attacks-11"></a>Attacks</h2>
<p>Some potential limitations and related attacks include:</p>
<ol>
<li><strong>Equivocal objective definition.</strong> Attackers may exploit ambiguous objectives to reward misaligned contributions. This can be mitigated by updating the objective when the DAO observes that equivocation happens.</li>
<li><strong>Jurors collusion and bribing.</strong> This can be countered with staking mechanisms, reputation systems, random juror selection, or shielded voting.</li>
<li><strong>Peer prediction and prediction markets manipulation.</strong> Usual caveats and mitigations apply.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#questions-12" name="questions-12"></a>Questions</h2>
<p>Such OAE mechanisms rely on the existence of an objective <span class="math">o</span>. We haven’t answered how such an objective can be defined in a general setting. There is an argument that leaving it to regular token-voting just pushes the problem around and the overall mechanism inherits some of the issues of both sub-mechanisms. However, it appears that splitting the problem in two has benefits, as, once an objective is defined, more deterministic outcomes can be achieved through mechanism design.</p>
<p>Also, other kinds of mechanisms can be devised that rely on subjective evaluations. Including subjective evaluations might render objective definition superfluous. But relying on a jury whose jurors input their own preferences leaves the question open of how the jury achieves legitimacy. A solution would be to rely on a measure of juror reputation, as pioneered by Backfeed.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/aligning-dao-contributions-with-objectives/20204">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 23:46:47 +0000</pubDate>
</item>
<item>
<title>ShardDAG: Ordering and Exploitation in Sharded Blockchains</title>
<link>https://ethresear.ch/t/sharddag-ordering-and-exploitation-in-sharded-blockchains/20203</link>
<guid>https://ethresear.ch/t/sharddag-ordering-and-exploitation-in-sharded-blockchains/20203</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、shardDAG、cross-shard transactions、data availability、transaction ordering

总结:
文章探讨了在状态分片区块链中如何通过shardDAG（状态分片有向无环图）架构来解决跨分片交易数据可用性和交易顺序问题。shardDAG架构旨在通过将不同分片链连接成一个有向无环图，为跨分片交易提供可执行的处理顺序，从而限制操纵、利用和审查行为。关键点如下：

1. **数据可用性**：为了确保跨分片交易数据的可用性，shardDAG架构引入了一种机制，要求验证者参与同步链，该链聚合并最终确定来自不同分片的更新状态。这确保了数据能够在分片间流动。

2. **交易和跨分片交易的顺序**：shardDAG通过链接分片块来定义分片块之间的部分顺序，这为跨分片交易提供了可执行的处理顺序。这种顺序防止了跨分片交易被恶意插入以进行利用或审查。

3. **验证数据接收**：为了确保分片接收和处理所需的数据，shardDAG提出了“父条件”和“同步父条件”，这些条件要求分片块的子图包含来自多个分片的数据，从而确保数据接收。

4. **经济激励**：shardDAG设计考虑了经济激励，通过“子条件”确保分片块能在同步链中最终确定，以此来鼓励分片分发其交易数据。

5. **处理限制与优先级**：在处理容量受限的情况下，shardDAG允许通过优先级费用和最大效率价值（MEV）来选择要包含在分片块中的交易和跨分片交易，同时保证未处理的交易和跨分片交易在后续块中得到处理。

综上所述，shardDAG架构通过确保数据可用性和合理的交易顺序，为状态分片区块链提供了一种有效的方式来减少审查和利用风险，同时通过经济激励机制促进数据共享和分发，从而增强系统的整体安全性和公平性。 <div>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>tl;dr</h2>
<p>Ethereum’s design has moved away from state sharding; however, L2 architectures like zkSharding provide a unified protocol in which L2 dApps are composable yet scalable via state sharding, avoiding the need for state fragmentation emerging across distinct L2s. However, sharded systems are not without challenges. In particular, state sharding amplifies MEV exploitation and censorship problems that exist in non-sharded blockchains.</p>
<p>We propose a shardDAG architecture for state sharded blockchains or multi-chain systems, combining protocol rules, rewards and penalties that constrain transaction exploitation [<a class="inline-onebox" href="https://arxiv.org/abs/1904.05234" rel="noopener nofollow ugc">[1904.05234] Flash Boys 2.0: Frontrunning, Transaction Reordering, and Consensus Instability in Decentralized Exchanges</a>] and external influences like regulatory censorship  [<a href="https://www.mevwatch.info/" rel="noopener nofollow ugc">https://www.mevwatch.info/</a>, <a class="inline-onebox" href="https://home.treasury.gov/news/press-releases/jy0916" rel="noopener nofollow ugc">U.S. Treasury Sanctions Notorious Virtual Currency Mixer Tornado Cash | U.S. Department of the Treasury</a>]. Constraints on exploitation and censorship are achieved using a DAG architecture that links shard blocks to each other. The DAG provides an enforceable order in which cross-shard transactions must be processed by each shard, thereby constraining manipulation of transaction processing order.</p>
<h2><a class="anchor" href="https://ethresear.ch#motivation-2" name="motivation-2"></a>Motivation</h2>
<p>State sharded blockchains inherit magnified MEV exploitation and censorship problems that exist in non-sharded blockchains because transaction completion can require block proposers in many distinct shards, and each block proposer could exploit or censor transactions. Further, more severe transaction exploits are possible via inserting other exploitative transactions in intermediate blocks that occur between starting and finishing transaction processing.</p>
<p>To understand this, the example below demonstrates a simple exploit scenario.</p>
<p><em><strong>Exploit Example</strong></em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/b/db208f14e2f3355a7d1d888bbc8b90e969102b97.jpeg" title="BasicExploit"><img alt="BasicExploit" height="445" src="https://ethresear.ch/uploads/default/optimized/3X/d/b/db208f14e2f3355a7d1d888bbc8b90e969102b97_2_690x445.jpeg" width="690" /></a></div><br />
Figure 1: Two shard chains. Blocks 0 and 1 of shard <em>A</em> each contain cross-shard transactions <em>t</em> and <em>u</em>  respectively, whose destinations are shard <em>B</em>. Suppose <em>t</em> can be exploited if in shard <em>B</em> <em>u</em> is processed earlier than <em>t</em>. Then the system is dangerous for <em>t</em>’s user without enforceable ordering rules that ensure <em>t</em> must be processed before <em>u</em> in shard <em>B</em>.<p></p>
<h2><a class="anchor" href="https://ethresear.ch#why-cross-shard-transaction-data-availability-matters-3" name="why-cross-shard-transaction-data-availability-matters-3"></a>Why Cross-Shard Transaction Data Availability Matters</h2>
<p>Punishment for censoring a cross-shard transaction (CST), or processing in an incorrect, exploitative order can only be enforced provided that</p>
<p>i) It can be established that all the required data was available to the shard, and</p>
<p>ii) The shard subsequently failed to process the data correctly.</p>
<p>Therefore, a mechanism is required for establishing <em>verifiable</em> cross-shard (or cross-chain, or cross-rollup) transaction data availability. The broad steps in achieving this are illustrated in Fig. 2. Preventing exploitation requires enforceable rules for ordering the processing of transactions and CSTs; however, enforcing processing order requires that each shard receives the CSTs that it is required to process. To be able to receive CSTs, that CST data must be available. Thus, constraining exploitation rests upon ensuring CST data availability.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/b/7bee56e632f92d068ac45ccb5bf63a201b085725.jpeg" title="ShardDAG StrategySteps"><img alt="ShardDAG StrategySteps" height="154" src="https://ethresear.ch/uploads/default/optimized/3X/7/b/7bee56e632f92d068ac45ccb5bf63a201b085725_2_690x154.jpeg" width="690" /></a></div><br />
Figure 2: Goal: ShardDAG ordering aims to constrain manipulation, exploitation and censorship of transactions and cross-shard transactions. Step 3: These constraints require enforceable protocol rules for ordering the processing of transactions and cross-shard transactions. Step 2: Fairly enforcing ordering rules requires on-chain acknowledgement of receipt of cross-shard transactions. Step 1: Receipt of cross-shard transactions requires cross-shard transaction data availability.<p></p>
<h2><a class="anchor" href="https://ethresear.ch#step-3-a-preview-how-dags-provide-order-4" name="step-3-a-preview-how-dags-provide-order-4"></a>Step 3. A Preview: How DAGs Provide Order</h2>
<p>Our solution to the transaction and cross-shard transaction ordering problem involves linking shard chains into a shard directed acyclic graph or shardDAG, and then ordering processing according to the partial order specified within shard block subgraphs.</p>
<p>ShardDAG ordering is previewed in Fig. 3. The distinct shard chains are connected to form a shardDAG, providing an enforceable ordering of cross-shard transactions amongst the shard chains. Unlike in Fig. 1, in Fig. 3’s shardDAG, an exploitative CST in a later block cannot be processed before a CST in an earlier block.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/8/48bb4910acfa00365d8e0b97b45be64b0e32e732.jpeg" title="ShardDAG NonOverloaded Ordering"><img alt="ShardDAG NonOverloaded Ordering" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/8/48bb4910acfa00365d8e0b97b45be64b0e32e732_2_193x500.jpeg" width="193" /></a></div><br />
Figure 3: Unlike the distinct shard chains in Fig. 1, the shardDAG (top) depicted here defines a partial ordering of shard blocks that fall under any particular block (here shard B block 2) and the cross-shard transactions that the blocks contain. (Middle) A Hasse diagram can be constructed to visualise a partial ordering of the shard blocks (for clarity lines connecting blocks have not been included). The shardDAG is topologically sorted (bottom) to produce a block containing an ordered set of transactions and CSTs. In general many topological sorts are possible, the block builder selects one, likely based on MEV.<p></p>
<h2><a class="anchor" href="https://ethresear.ch#a-sharddag-for-data-availability-5" name="a-sharddag-for-data-availability-5"></a>A ShardDAG for Data Availability</h2>
<p>To establish cross-shard transaction data availability, the simple set of shard chains in Fig. 1 is extended to become a shardDAG that is crafted to incentivize data sharing. In this system all validators participate in a synchronization chain which aggregates and finalises state updates from shards that are each operated by distinct subsets of the total validator set. Transaction and CST processing is performed within shards only, hence the synchronization chain is not a processing bottleneck. Here the details of the synchronization chain are restricted to its involvement in the shardDAG—the broader function of the synchronization chain in the sharded system is beyond the scope of this post.</p>
<p>To form a shardDAG, shard blocks include links to other shard blocks in the form of:</p>
<ul>
<li><strong>a hash to the previous shard block in the same shard, as in a typical blockchain,</strong></li>
<li><strong>a set of hashes to other shards blocks in other shards,</strong></li>
<li><strong>a hash to a (valid) synchronization block, equal to or later than the most recent synchronization block already used by prior shard blocks that are included in the subgraph.</strong></li>
</ul>
<p>The formation of a shardDAG is illustrated in Fig. 4, where for clarity only edges in the subgraph of the white block are shown. The thick arrows are the white block’s hashes to other blocks.</p>
<p>The following is a central concept in the function of the shardDAG.</p>
<p><strong>When a shard <span class="math">A</span> creates a shard block that includes the hash <span class="math">h</span> of another shard block or synchronization block, this inclusion acts as an acknowledgement that shard <span class="math">A</span> has received the block headers and outboxes of cross-shard transactions for <span class="math">h</span> and <span class="math">h</span><em>’s</em> entire subgraph in the shardDAG.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/2/b2ba419c59a01907d08a616eb2b464634114c1d3.jpeg" title="SubGraphLowDetail"><img alt="SubGraphLowDetail" height="469" src="https://ethresear.ch/uploads/default/optimized/3X/b/2/b2ba419c59a01907d08a616eb2b464634114c1d3_2_690x469.jpeg" width="690" /></a></div><br />
Figure 4: Illustration of the white block’s subgraph in the shard DAG. The white block’s header contains a list of hashes to other shard blocks (thick white arrows), and well as a single hash to a synchronization block (thick grey arrow). Thin grey edges trace the subgraph of the white block, beyond the blocks explicitly included in its header.<p></p>
<h2><a class="anchor" href="https://ethresear.ch#step-2-enforcing-cst-receipt-6" name="step-2-enforcing-cst-receipt-6"></a>Step 2. Enforcing CST Receipt</h2>
<h3><a class="anchor" href="https://ethresear.ch#enforcing-cst-receipt-via-shard-chains-7" name="enforcing-cst-receipt-via-shard-chains-7"></a>Enforcing CST Receipt via Shard Chains</h3>
<p>To enforce shards to continually acknowledge receipt of new shard block data, the protocol specifies conditions on block validity. Suppose we have a shard block <span class="math">b_i</span> and <span class="math">b_i</span><em>’s</em> prior shard block <span class="math">b_{i-1}</span> in the same shard as <span class="math">b_i</span>.</p>
<ul>
<li><strong>[PARENT CONDITION]: For <span class="math">b_i</span> to be a valid shard block, the graph difference of <span class="math">b_i</span><em>’s</em> subgraph minus <span class="math">b_{i-1}</span><em>’s</em> subgraph must contain shard blocks created by more than <span class="math">F&gt;1</span> shards, where <span class="math">F</span> is a system parameter controlling the branching of the DAG.</strong></li>
</ul>
<p><em>Example:</em></p>
<p><em>In Fig. 4, the subgraph of the white shard A block only contains two blocks that are not in the subgraph of the previous shard A block, i.e. the white block itself, and the middle shard B block. If in this example F=1, then the white block is valid; however, if F&gt;1 then the white block is invalid.</em></p>
<h3><a class="anchor" href="https://ethresear.ch#enforcing-cst-receipt-via-the-synchronization-chain-8" name="enforcing-cst-receipt-via-the-synchronization-chain-8"></a>Enforcing CST Receipt Via the Synchronization Chain</h3>
<p>The parent condition enforces receipt of CSTs, but does not guarantee that each CST reaches its destination so that transactions complete. Without additional rules it is possible (though unlikely) for sets of shards to create shard blocks whose subgraphs do not span all shards and therefore do not acknowledge receipt of CSTs from all shards, as illustrated in Fig. 6.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/9/c95bce910ccff1c8dbd9ffbaa913b546c5db043d.jpeg" title="consensusParentCondition"><img alt="consensusParentCondition" height="444" src="https://ethresear.ch/uploads/default/optimized/3X/c/9/c95bce910ccff1c8dbd9ffbaa913b546c5db043d_2_690x444.jpeg" width="690" /></a></div><br />
Figure 6: Despite the parent condition for valid shard blocks, it is possible (though unlikely) for shard subgraphs to not acknowledge receipt of CSTs from some other shards via shard block edges, indicated by the vertical dashed line. However, the synchronization parent condition eventually forces all shards to acknowledge all CSTs via synchronization block edges. Here the synchronization parent condition forces shard 4 to acknowledge receipt of the red CST (via the red edges) and therefore process it, because the dashed blue edge exceeds the limit (here <em>S</em>=2) of consecutive synchronization block hashes. For clarity only the subset of synchronization blocks edges that are relevant to illustrating the above point are shown.<p></p>
<p>This is unlikely to occur in the shardDAG; however, the synchronization chain is used to ensure that it <em>cannot</em> occur via a further block validity condition:</p>
<ul>
<li><strong>[SYNCHRONIZATION PARENT CONDITION]: A valid shard block <em>b</em> cannot have more than <span class="math">S</span> prior blocks from the same shard using the same synchronization block hash.</strong></li>
</ul>
<p>The value of <span class="math">S</span> should be chosen depending on the ratio of rates of synchronization block to shard block creation. It is expected that synchronization blocks will be produced at a slower rate compared to shard blocks.</p>
<p>A malicious shard can only produce <span class="math">S</span> shard blocks before being forced to acknowledge receipt of new shard blocks via the synchronization chain. In Fig. 5, the red CST shard block will eventually be included in a synchronization block, in a worst case scenario waiting until a shard 1 validator becomes the synchronization block proposer. Thus, eventually all shards will acknowledge receiving the red CST, including the red CST’s destination shard, as indicated by the red arrows. The dashed blue arrow indicates that shard 4 block 3 would be invalid if it used this hash because more than <span class="math">S</span> (here 2) consecutive shard blocks would hash to the same synchronization block.</p>
<p>In this way, economically motivated validators (and especially synchronization block proposers) are motivated to share data so that finality can be reached and economic rewards can be distributed.</p>
<h2><a class="anchor" href="https://ethresear.ch#step-1-enforcing-cst-data-availability-via-dag-edges-between-shards-9" name="step-1-enforcing-cst-data-availability-via-dag-edges-between-shards-9"></a>Step 1. Enforcing CST Data Availability Via DAG Edges Between Shards</h2>
<p>While the parent, and synchronization parent conditions force shards to acknowledge receipt of data, these rules do not force shards to <em>distribute</em> shard block data and establish data availability. Thus, the protocol specifies a rule on shard block finality to align data availability with economic incentives.</p>
<ul>
<li><strong>[CHILD CONDITION]: For a shard block <span class="math">b</span> to be finalised within the synchronization chain, within the subgraph of any synchronization block, <span class="math">b</span> must have child shard blocks created by more than <span class="math">F</span> shards.</strong></li>
</ul>
<p>When a block satisfies the child condition its CSTs have been acknowledged as received by more than <em>F</em> other shards and the shard has therefore distributed its CST data.</p>
<p>The child condition is illustrated in Fig. 5. For a shard block to acquire child shard blocks, other (honest) shards must first receive its subgraph data. Thus, shards are economically incentivised to possess and distribute data in their subgraphs.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/b/1b0c569adc1421ca246f774a9b776cda2aaa6465.jpeg" title="ChildConditionEthREsearch"><img alt="ChildConditionEthREsearch" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/b/1b0c569adc1421ca246f774a9b776cda2aaa6465_2_688x500.jpeg" width="688" /></a></div><br />
Figure 5: Illustration of the child condition for the subgraph of the upper left synchronization block. In this example <em>F</em>=2. The white block in finalised because it has child shard blocks from three shards, indicated by thick white arrows. In contrast, the bottom right shard block is not finalised because it only has one child shard block indicated by the thick grey arrow.<p></p>
<h2><a class="anchor" href="https://ethresear.ch#step-3-an-enforceable-dag-partial-order-of-transaction-and-cst-processing-10" name="step-3-an-enforceable-dag-partial-order-of-transaction-and-cst-processing-10"></a>Step 3. An Enforceable DAG Partial Order of Transaction and CST Processing</h2>
<p>The shardDAG provides a verifiable, enforceable ordering of transactions and CSTs, which constrains exploits and guarantees (eventual) transaction processing. Transactions and cross-shard transactions must be processed in an order consistent with the partial order of the shard blocks that they are each created in.</p>
<p>Suppose that shard <em>B</em> creates a new shard block <em>b</em>. As illustrated in Fig.3, the the steps involved in ordering the processing of CSTs and transactions are:</p>
<ol>
<li>First <span class="math">b</span><em>’s</em> hashes (DAG edges) to other shard blocks and a synchronization block are chosen. Hashes are only chosen if corresponding subgraph CST data is available, otherwise correct ordering cannot be known and penalties may ensue.</li>
<li>The protocol rules described earlier require that the validator creating and proposing <span class="math">b</span> has all the CST data from <span class="math">b</span><em>’s</em> subgraph, call these <span class="math">T</span>. The set of pending CSTs <span class="math">P</span> whose destination is shard <span class="math">B</span>, and which have not already been processed in an existing shard <span class="math">B</span> block are extracted from <span class="math">T</span> and any new transactions are added to <span class="math">P</span>.</li>
<li>The set of pending transactions and CSTs, <span class="math">P</span> are (partially) ordered according to the shardDAG ordering of the shard blocks that they were created in, retaining the order of multiple CSTs created within a single block. <span class="math">P</span> is topologically sorted to create a totally ordered set of transactions and CSTs.</li>
<li>Block size limits may constrain the number of transactions and cross-shard transactions included in a shard block. If this occurs, it is optional to introduce priority of transactions and CSTs as illustrated in Fig. 7, whereby block proposers select transactions and CSTs to include based on priority fees, and MEV. However, this comes at the cost of potentially allowing exploitative transaction insertion. Pending transactions and CSTs must be processed if allowed by block size limits; any unused block space must be too small to contain any unprocessed transaction or CST.</li>
<li>New transactions that do not fit into block processing can be included in a shard block’s outbox of CSTs. Such transactions enter the shardDAG for ordering and will therefore be processed in a later block along with other pending transactions and CSTs not included in <span class="math">b</span>.</li>
</ol>
<p>Validators should only sign a proposed block once they have verified that the block proposer has followed this protocol ordering. If an invalid ordering is used then the block is invalid and/or the signing validators are subjected to penalties. We reiterate that because ordering rules involve only on-chain data, data availability of CSTs and block headers enables any validator or node to verify correctness of ordering.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/9/09afd7f7cf81fd6dacfe88bcc2f4b6c7eab46c0f.jpeg" title="ShardDAG Overloaded Ordering Only"><img alt="ShardDAG Overloaded Ordering Only" height="407" src="https://ethresear.ch/uploads/default/optimized/3X/0/9/09afd7f7cf81fd6dacfe88bcc2f4b6c7eab46c0f_2_690x407.jpeg" width="690" /></a></div><br />
Figure 7: An extension of Fig.3 when shard B is overloaded and unprocessed transactions and CSTs exceed maximum block size (left). The block builder selects transactions and CSTs to remove from the topological sort for the new block (middle), so that the remaining transactions and CSTs do not exceed block size limits (right). Removed CSTs will be processed in later blocks. This removal of transactions and CSTs is expected to be based on priority fees and MEV. Unprocessed new transactions (b2’) may be included in an outbox as data so that they enter shardDAG ordering for processing in a later block, like b0 and b1 in earlier blocks, but these outboxed transactions are not processed in the current block.<p></p>
<h2><a class="anchor" href="https://ethresear.ch#summary-11" name="summary-11"></a>Summary</h2>
<p>In state-sharded blockchains, censorship and insertion of exploitative transactions part-way through transaction processing can be constrained by shardDAG transaction and CST ordering. These shardDAG constraints are derived from ordering, which enforces processing of earlier transactions and CSTs before later ones. ShardDAG ordering rests upon economic incentives that motivate validators to suitably participate in the shardDAG to receive block rewards and avoid penalties.</p>
<p>DAGs are a natural tool to be used in ordered systems. The shardDAG broadens the use of DAGs in blockchain, beyond their more common application in consensus mechanisms. The shardDAG has been presented here in a unified state sharded system, but the ideas can be applied to sets of distinct rollups or blockchains.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/sharddag-ordering-and-exploitation-in-sharded-blockchains/20203">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 23:12:07 +0000</pubDate>
</item>
<item>
<title>Inclusion List Timing Constraints</title>
<link>https://ethresear.ch/t/inclusion-list-timing-constraints/20198</link>
<guid>https://ethresear.ch/t/inclusion-list-timing-constraints/20198</guid>
<content:encoded><![CDATA[
<div> 关键词：包括 "包括"、"时间限制"、"安全考虑"、"可行性"、"不同设计比较"

总结：

本文深入探讨了在以太坊中实现包括列表（ILs）所涉及的各种权衡，重点关注时间、安全性和可实施性方面的限制。ILs允许块构建者承诺在特定区块中包含交易，但其实现需要考虑到多种因素：

1. **时间限制**：每个以太坊“槽”固定为12秒，块构建者需在此时间窗口内准备区块。IL的创建和传播需要严格的时间控制，确保不会影响链的活性。

2. **安全性**：IL的存在要求诚实验证者能够识别并拒绝不符合要求的区块。这涉及到如何平衡验证器的责任和效率，避免DoS攻击的可能性。

3. **可行性**：IL的实现可能涉及多个参与方，包括构建者、验证者和执行者。需要定义明确的依赖关系，确保所有参与者都能履行其角色，同时考虑到网络的传播时间和节点验证时间。

4. **不同设计比较**：文章讨论了几种IL设计，如EIP-7547和FOCIL，每种设计都有其优势和局限性，特别是在时间、安全性和可实施性方面的权衡。

5. **内容争端**：IL可能与其他机制（如较短的槽时间、更高的gas限制、分布式验证技术或活跃验证服务）产生冲突，需要权衡以优化整个系统的性能和稳定性。

总的来说，实现有效的IL系统需要细致地规划和协调，确保所有关键组件在有限的时间框架内高效协同工作，同时保持系统的安全性和可靠性。 <div>
<p>Special thanks to <a class="mention" href="https://ethresear.ch/u/julian">@Julian</a>, <a class="mention" href="https://ethresear.ch/u/barnabe">@barnabe</a> and <a class="mention" href="https://ethresear.ch/u/manav2401">@manav2401</a> for the reviews</p>
<h2><a class="anchor" href="https://ethresear.ch#background-1" name="background-1"></a>Background</h2>
<p>Inclusion list have been an active topic since the <a href="https://notes.ethereum.org/@vbuterin/pbs_censorship_resistance" rel="noopener nofollow ugc">early</a> <a href="https://ethresear.ch/t/how-much-can-we-constrain-builders-without-bringing-back-heavy-burdens-to-proposers/13808">days</a>. <a href="https://notes.ethereum.org/@fradamt/forward-inclusion-lists" rel="noopener nofollow ugc">Various</a> <a href="https://notes.ethereum.org/@fradamt/H1TsYRfJc" rel="noopener nofollow ugc">designs</a> have emerged over time, each with inevitable trade-offs concerning <strong>What can be constrained within a single Ethereum slot?</strong>.<br />
This post explores these trade-offs from the perspectives of <strong>different actors</strong> involved in ILs and defines the dependencies required for each actor to fulfill their role in integrating ILs into the protocol. We will compare and contrast multiple designs, focusing on the limitations related to <strong>timing, security, and feasibility</strong>.</p>
<p>First, we will outline some definitions.</p>
<h2><a class="anchor" href="https://ethresear.ch#il-definitions-2" name="il-definitions-2"></a>IL Definitions</h2>
<p><strong>Slot Time</strong>: In the context of Ethereum, a slot refers to a fixed interval currently set at 12 seconds. During each slot, the proposer/builder proposes a block, attesters vote on the block, and an aggregator aggregates the votes. The proposer of subsequent slot includes aggregated votes in their block, and the cycle repeats. Today out-of-protocol builders have an ~8-second window to prepare for the next slot’s block. All actions are synchronized with these validator duty intervals, and <strong>IL should not extend the current slot time</strong>.</p>
<p><strong>Inclusion List:</strong> An inclusion list (IL) is a list of transactions that a block proposer commits to including in a block. Depends on the conditional vs unconditional constraint, if these transactions are not included in the block, then the block cannot be considered canonical, assuming honest attesters who will vote against the block. The IL consists of the following options and requirements.</p>
<ol>
<li><strong>Satisfactory Requirement</strong>:
<ul>
<li><strong>Conditional</strong>: The IL does not need to be satisfied if the target block is full.
<ul>
<li><strong>Forward-Looking</strong>: If the IL cannot be satisfied in the current target block, does it still apply to subsequent blocks? <a href="https://ethresear.ch/t/cumulative-non-expiring-inclusion-lists/16520">More in this post</a></li>
</ul>
</li>
<li><strong>Unconditional</strong>: The IL needs to be satisfied. This typically means the IL has its own gas limit.</li>
</ul>
</li>
<li><strong>Satisfactory Time</strong>:
<ul>
<li><strong>Same Slot IL</strong>: The IL is satisfied within the same slot, similar to users sending a transactions wanting to be included on chain. With sufficient base fee and tip, we can expect the transaction to be included the slot of. For example, an IL transaction for slot <code>n+1</code> is satisfied in slot <code>n+1</code>.</li>
<li><strong>Next Slot IL</strong>: The IL is satisfied in the subsequent slot with one slot delay. For example, an IL transaction for slot <code>n+1</code> is satisfied in slot <code>n+2</code>.</li>
</ul>
</li>
<li><strong>IL constructor</strong>: The actor responsible for preparing and broadcasting the IL to the network. This role can be fulfilled by a single entity (like a proposer) or by a committee where the protocol reaches consensus on individual ILs from its members. The consensus of IL may be reached by IL aggregate which represents IL committee’s vote.</li>
<li><strong>IL Gas Limit</strong>: IL gas limit has an implication on the size of IL which dirrectly affects the network propagation time and node’s verification time.</li>
<li><strong>IL Ordering In Block</strong>: When the IL becomes part of the block, the transactions may be required to be placed in a specific order. This order could be:
<ul>
<li><strong>Top of the Block</strong>: Transactions are placed at the beginning of the block.</li>
<li><strong>Anywhere in the Block</strong>: Transactions are placed anywhere within the block.</li>
<li><strong>Bottom of the Block</strong>: Transactions are placed at the end of the block.</li>
</ul>
</li>
<li><strong>Liveness Guarantee</strong> The IL must be made available to the block builder to avoid stalling the chain’s liveness. The delivery method of the IL to the builder varies based on the trust model. If a single person constructs the IL, stricter requirements may be necessary, such as additional attester validation along with the block.</li>
<li><strong>No Free DA</strong> An IL that has not been satisfied in execution cannot be part of the consensus, as it would grant free DA. Free DA has to be tightly coupled with consensus and should not be mistaken for free bandwidth or temporary data storage. While nodes can use a small amount of bandwidth or store temporary data with anti-dos measures in place, this should not be conflated with free DA.</li>
</ol>
<p><strong>Block Builder</strong>: The actor tasked with fulfilling the IL and broadcasting the resulting product (ie. a block that fulfills the IL) over the network. In the case of a solo validator, the block proposer serves as the block builder, and the product is the execution payload of the block. For a MEV-boost validator, the block builder handles the fulfillment, which returns the signed header to proposer, and the relay broadcasts the final block to the network. It is often the case that the block proposer cannot verify the satisfactory fulfillment of the IL when signing the header request. Relays have to verify the payload satisfies IL ahead of time or assume optimistic.</p>
<p><strong>IL Transaction Invalidation</strong>: Transactions in an IL may become <strong>not includable</strong> at the time of inclusion due to invalidations, such as an incorrect nonce or insufficient balance. This situation can arise under different conditions. For example, when multiple parties are involved in constructing their version of ILs, the transactions from each party might render each other not includable. Similarly, if one party constructs the IL while another party broadcasts the block at the same moment, there can also be invalidations, leading to mutual exclusion of the IL transactions and block transactions.</p>
<p><strong>Head Block</strong>: Often referred to as the parent block, the IL should be constructed on top of the chain’s head from the perspective of the node. The builder, responsible for constructing the block and satisfying the IL, should also build on top of the head block in order to make sure that block and inclusion list are aligned.<br />
<strong>Constraint</strong>: If an IL is built on head <code>a</code>, then to satisfy the IL, the builder’s block must also be built on top of head <code>a</code>.</p>
<h2><a class="anchor" href="https://ethresear.ch#il-timings-3" name="il-timings-3"></a>IL Timings</h2>
<p><strong>IL Preparation Time</strong>: This is the time required for a party to prepare the IL, which is constructed on top of the head block. The larger the IL may require longer time to prepare.</p>
<p><strong>IL Propagation Time</strong>: This is the time required for the IL to propagate across the network to other nodes. Factors influencing this time include the size of the IL, the number of ILs (committee size), and the network’s gossip rules.</p>
<p><strong>IL Verification Time</strong>: This is the time required to verify the IL. The IL must be valid, otherwise builders can get grieved. In some scenarios, attesters must verify the IL before considering the current slot block as the head (. In other cases, the proposer must verify the IL before proposing the next slot block. The point is that some parties must verify the IL beforehand, and it’s crucial to consider who is bearing this cost.</p>
<p><strong>Block Preparation Time</strong>: This is the time required to build an execution block. The block can be constructed either by the proposer or the builder. The IL’s satisfactory requirements must be met in the block. This means the block builder must verify the IL, parent block and ensure that the block satisfies IL requirements.</p>
<p><strong>Block Propagation Time</strong>: This is the time taken for a block to be transmitted across the network and received by all participants. It’s crucial that the block is received and verified by attesters promptly, as delays can lead to the block not being considered as the head of the chain, increasing the risk of reorg.</p>
<p><strong>Block Verification Time</strong>: This is the time taken for a node to verify the block and IL. The focus here is on execution verification time, as consensus verification is typically fast. A block must be verified as execution valid and meet the IL requirements before it can be considered the head of the chain.</p>
<p>Based on the timing definition provided, we can outline the following dependencies:</p>
<ul>
<li>The parent head block <code>n</code> must be released before attestation cut off. The difference is between start of the slot. Head release time = <span class="math">T_{HR}</span></li>
<li>The head block must be propagated to peers on time. Head propagation time = <span class="math">T_{HP}</span></li>
</ul>
<ul>
<li>The IL constructor must see and validate the parent head block before creating the IL. Head validator time = <span class="math">T_{HV}</span></li>
<li>The IL must be constructed and released using for example a local mem pool. IL construction time = <span class="math">T_{ILC}</span></li>
<li>The IL must propagate through the network to reach the builders. IL propagation time = <span class="math">T_{ILP}</span></li>
<li>The block builder needs to verify the IL before submitting a bid.  IL verification time = <span class="math">T_{ILV}</span>
<ul>
<li>This requirement may change in the context of slot auctions.</li>
</ul>
</li>
<li>The proposer must see the bids before submitting a block. Bid propagation time = <span class="math">T_{BP}</span></li>
<li>The attester must verify the block <code>n+1</code> before considering it as the head. We can reuse head verification time above.</li>
</ul>
<p>In short, we could summarize: A single Ethereum slot should not exceed the following durations, ensuring that the end-to-end IL is applied, and the block remains canonical on the chain: <span class="math">SLOT &gt;= T_{HR}+T_{HP}+2 * T_{HV}+T_{ILC}+T_{ILP}+T_{ILV}+T_{BP}</span></p>
<h1><a class="anchor" href="https://ethresear.ch#different-versions-of-il-4" name="different-versions-of-il-4"></a>Different versions of IL</h1>
<p>Different versions of IL have varying constraint trade-offs. Some examples taken from <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> and <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a>.</p>
<h4><a class="anchor" href="https://ethresear.ch#eip-7547-in-mev-boost-5" name="eip-7547-in-mev-boost-5"></a>EIP-7547 in MEV-Boost</h4>
<ul>
<li>The block builders for slot <code>n</code> constructs a block for slot <code>n</code> after verifying the block for slot <code>n-1</code>.</li>
<li>The block proposer of slot <code>n</code> constructs an IL for slot <code>n+1</code> after verifying the block for slot <code>n-1</code>.</li>
<li>The IL for slot <code>n+1</code> and the block for slot <code>n</code> may invalidate each other if they are sent by different parties.</li>
<li>The block proposer/builder of slot <code>n+1</code> requires the IL and the block for slot <code>n</code> to build a block.</li>
<li>The block proposer of slot <code>n+1</code> needs the IL and the block for slot <code>n</code> to build an IL.</li>
<li>Attesters for slot <code>n+1</code> need the IL and the block for slot <code>n</code> to attest to the block. The block for slot <code>n+1</code> must link to a valid IL <code>n+1</code>, or it cannot be canonical.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#eip-7547-in-epbs-eip-7732-6" name="eip-7547-in-epbs-eip-7732-6"></a>EIP-7547 in ePBS (EIP-7732)</h4>
<ul>
<li>The block proposer of slot <code>n</code> selects the builder’s bid of slot <code>n</code> after verifying the execution block for slot <code>n-1</code>.</li>
<li>The block proposer of slot <code>n</code> constructs an IL for slot <code>n+1</code> after verifying the execution block for slot <code>n-1</code>.</li>
<li>Since the bid commits to the transactions, the IL for slot <code>n+1</code> and the bid for slot <code>n</code> may conflict. This is different in slot auction.</li>
<li>The builder reveals the execution block at slot <code>n</code>’s 6-seconds mark.</li>
<li>Subsequent block builders require the execution block at slot <code>n</code> and the IL for slot <code>n+1</code> to place bids for slot <code>n+1</code>. This is different in slot auction.</li>
<li>Attesters for slot <code>n+2</code> verify that the execution block for slot <code>n+1</code> satisfies the IL and is valid. We gain an extra slot time for validation due to <a href="https://ethresear.ch/t/advantage-of-pipelining-consensus-and-execution-delayed-execution/19668">delayed execution property</a>.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#focil-in-mev-boost-ignoring-il-aggregation-step-7" name="focil-in-mev-boost-ignoring-il-aggregation-step-7"></a>FOCIL in MEV-Boost (Ignoring IL Aggregation Step)</h4>
<ul>
<li>The block builder of slot <code>n</code> constructs a block for slot <code>n</code> after verifying the block for slot <code>n-1</code>.</li>
<li>The IL committee builds the IL for slot <code>n</code> after verifying the block for slot <code>n-1</code>.</li>
<li>The IL committee for slot <code>n</code> releases the IL during slot <code>n-1</code>.</li>
<li>Attesters for slot <code>n</code> lock their view on the ILs.</li>
<li>The builder of slot <code>n</code> includes the IL transactions into the block for slot <code>n</code></li>
<li>At the start of slot <code>n</code>, the proposer requests the builder’s head, signs it, and broadcasts it.</li>
<li>Attesters for slot <code>n</code> verify that the block satisfies the IL committee’s requirements according to their locked view in slot <code>n-1</code>.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#focil-in-epbs-same-slot-version-8" name="focil-in-epbs-same-slot-version-8"></a>FOCIL in ePBS (Same Slot Version)</h4>
<ul>
<li>The block proposer of slot <code>n</code> selects the builder’s bid for slot <code>n</code> after verifying the execution block for slot <code>n-1</code>.</li>
<li>The IL committee for slot <code>n+1</code> constructs the IL for slot <code>n+1</code> after the builder reveals the execution block for slot <code>n</code>.</li>
<li>Builders for slot <code>n+1</code> verify the IL and make bids for slot <code>n+1</code>.</li>
<li>The block proposer of slot <code>n+1</code> selects the builder’s bid for slot <code>n+1</code>.</li>
<li>Attesters for slot <code>n+2</code> verify that the execution block for slot <code>n+1</code> satisfies the IL and is valid, providing close to an extra slot time due to delayed execution.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#focil-in-epbs-next-slot-version-9" name="focil-in-epbs-next-slot-version-9"></a>FOCIL in ePBS (Next Slot Version)</h4>
<ul>
<li>The block proposer of slot <code>n</code> selects the builder’s bid for slot <code>n</code> after verifying the execution block for slot <code>n-1</code>.</li>
<li>The IL committee for slot constructs the IL for slot <code>n+2</code> after the builder reveals the execution block for slot <code>n</code>.</li>
<li>Builders for slot <code>n+2</code> verify the IL and make bids for slot <code>n+2</code>.</li>
<li>The block proposer of slot <code>n+2</code> selects the builder’s bid for slot `n+2.</li>
<li>Attesters for slot <code>n+3</code> verify that the execution block for slot <code>n+2</code> satisfies the IL and is valid, providing close to an extra slot time due to delayed execution.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#il-contentions-10" name="il-contentions-10"></a>IL Contentions</h2>
<p>ILs may compete with initiatives as the following:</p>
<p><strong>Shorter Slot Time Contentions with IL</strong>: With shorter slot times, ILs may not be constructed and fulfilled on time. A proposer that cannot fulfill an IL results in a liveness fault. One way to address this is to extend the IL satisfactory rule to the next slot or to multiple subsequent slots, but this approach introduces risks of denial-of-service (DoS) attacks and more transaction invalidation concerns. There is a trade-off here.</p>
<p><strong>Higher Gas Limit Contentions with IL</strong>: With a higher block gas limit, it takes longer to verify the block, which reduces the time available to construct the IL after verifying the block. Additionally, with a higher IL gas limit, it takes longer to propagate and verify the IL, reducing the time available to fulfill the IL by building the block.</p>
<p><strong>DVT Contentions with IL</strong>: Distributed Validator Technology (DVT) requires more exchanges between validators before signing. This process includes beacon chain duties such as attesting, proposing, and submitting ILs. These additional exchanges require time, and there is a need to ensure that the IL, especially in more complex forms, does not make DVT operations impractical.</p>
<p><strong>AVS Contentions with IL</strong>: Active Validator Service (AVS) also require more actions from validators. The specific details depend on the AVS implementation, but generally, requiring more time from validators to perform certain tasks can create contention with fulfilling IL obligations.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/inclusion-list-timing-constraints/20198">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 16:02:42 +0000</pubDate>
</item>
<item>
<title>Cross-rollup Synchronous Atomic Execution</title>
<link>https://ethresear.ch/t/cross-rollup-synchronous-atomic-execution/20193</link>
<guid>https://ethresear.ch/t/cross-rollup-synchronous-atomic-execution/20193</guid>
<content:encoded><![CDATA[
<div> 关键词：Radius、同步原子执行、共享分发器、数据可用性层、验证层

总结:
这篇文章详细阐述了Radius设计的跨rollup组合体同步原子执行解决方案。该方案旨在提升跨rollup交易的协同性和用户体验，通过引入共享分发器，允许不同rollup之间创建共享的序列层，为用户提供便捷服务。共享分发器负责协调和确保多个交易同时原子性执行，提高执行效率并减少延迟。

关键点包括：
1. **同步原子执行**：允许多个交易并发执行，以降低总延迟时间，提供即时的交易体验。
2. **安全与便捷**：通过快速执行组合交易并确保其原子性，用户可以更高效地规划后续操作，同时减少对网络关键参与者（如共享分发器和执行者）的信任需求。
3. **架构设计**：提出了一种基于共享分发器、数据可用性层和验证层的架构，确保交易的安全性和执行效率。
4. **角色与责任**：明确定义了各实体（如用户、共享分发器、执行者等）的角色和职责，确保系统稳定运行。
5. **实施与验证**：通过具体场景展示如何实现和验证同步原子执行过程，包括交易流程、智能合约功能、协调机制以及验证逻辑。

此解决方案通过优化跨rollup交易的执行流程，增强了区块链网络的整体性能和用户体验，同时确保了交易的安全性和可信度。 <div>
<ul>
<li><em>by Hankyung Ko(<a href="https://ethresear.ch/u/hankyungko">@HankyungKo</a>) and Chanyang Ju(<a href="https://ethresear.ch/u/wooju">@wooju</a>), Researcher at <a href="https://twitter.com/radius_xyz" rel="noopener nofollow ugc">Radius</a> . Thanks to</em> <a href="https://twitter.com/Hyunxukee" rel="noopener nofollow ugc"><em>Tariz</em></a> <em>and</em> <a href="https://twitter.com/ZeroKnight_eth" rel="noopener nofollow ugc"><em>AJ</em></a> <em>for reviewing this post.</em></li>
<li><em>Your feedback and opinions are highly valued.</em></li>
</ul>
<p><em>Radius has designed a synchronous atomic execution solution for cross-rollup composability. This development is driven by our commitment to support rollups seeking improved composability and enhanced user experience. We will enable rollups to create their own shared sequencing layer, offering this as a service to make it widely accessible. By doing so, we ensure that atomic execution of bundled transactions is coordinated effectively across participating rollups.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#h-1-introduction-1" name="h-1-introduction-1"></a>1. Introduction</h1>
<hr />
<p>Synchronous atomic execution allows multiple transactions from different rollups to be executed simultaneously and atomically in an all-or-nothing manner, significantly reducing latency compared to sequential execution. A naive approach to executing multiple cross-rollup transactions require each transaction to be finalized sequentially on L1. For <span class="math">n</span> transactions, the total latency would be <span class="math">n</span> times the L1 finalization period. In contrast, <strong><code>synchronous atomic execution</code></strong> enables all transactions to be executed at the same time, significantly reducing latency.</p>
<p>While executing transactions simultaneously can reduce latency, it may raise concerns about security. For example, in a bundled transaction involving minting-and-burning across different rollups, there’s a risk that the burn could fail while the mint succeeds. To address this, we’ve designed our system to verify the atomicity of bundled transactions faster than the time it takes for block finalization. This approach ensures that security is maintained even with simultaneous execution. Our innovation improves composability across multiple rollups, providing a seamless, efficient, and secure user experience with real-time, all-or-nothing execution of cross-rollup transactions without delays.</p>
<p>To implement this convenient and secure solution, Radius introduces a shared sequencer for rollups to guarantee the atomic execution of bundled transactions. Users create bundled transactions that depend on transactions across multiple rollups, and the shared sequencer manages the sequencing of bundled transactions for successful execution.</p>
<blockquote>
<p><img alt=":point_right:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/point_right.png?v=12" title=":point_right:" width="20" /> It’s important to note that this shared sequencer is not a single entity controlled by Radius, but rather a set formed by aggregating existing sequencers from each rollup. A leader is selected from this set through a predefined process (<a href="https://docs.theradius.xyz/testnets/loggia-testnet-with-radius-avs/decentralized-sequencing" rel="noopener nofollow ugc">reference</a>) to manage sequencing.</p>
<p>To prevent potential power abuse by the shared sequencer, Radius employs decentralized sequencing techniques, including encrypted mempool (<a href="https://ethresear.ch/t/mev-resistant-zk-rollups-with-practical-vde-pvde/12677">PVDE</a> and <a href="https://ethresear.ch/t/radius-skde-enhancing-rollup-composability-with-trustless-sequencing/19185">SKDE</a>). The shared sequencer has two main functions: determining transaction order and enforcing transaction reverts to maintain bundle atomicity.</p>
<p>This article details on how our architecture addresses the second function, ensuring atomicity. Preventing potential abuse of the first function, transaction ordering, is also crucial. Radius addresses this concern through the encrypted mempool, ensuring that the shared sequencer cannot abuse its power regarding transaction ordering.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#h-1-requirements-of-the-synchronous-atomicity-solution-2" name="h-1-requirements-of-the-synchronous-atomicity-solution-2"></a>1) Requirements of the synchronous atomicity solution</h2>
<ul>
<li><strong><code>Convenience</code>:</strong> Users can achieve greater benefits by utilizing atomic execution of cross-rollup bundled transactions, without compromising security.
<ul>
<li><strong>Bundle transactions</strong>: Users can bundle and execute multiple transactions across different rollups as one.</li>
<li><strong>Atomic execution:</strong> The bundle transaction is guaranteed to execute simultaneously without failures. If a failure occurs, it is guaranteed to fail simultaneously.</li>
<li><strong>Fast execution for bundle while maintaining security</strong>: Transactions are guaranteed to be executed faster than sequential execution (where each transaction waits for the previous one to finish). This allows users to strategize their next transactions more quickly. Additionally, atomic execution is cryptographically verified before finalization, ensuring that the security of the transactions is maintained even though they are executed more quickly.</li>
</ul>
</li>
<li><strong><code>Security</code></strong>
<ul>
<li><strong>Minimized trust level</strong>: Aims to minimize the amount of trust users must place in key network participants like the shared sequencer and executors by:
<ul>
<li>Minimizing the number of parties that need to be trusted.</li>
<li>Minimizing the duration for which trust is necessary.</li>
<li>Ensuring early detection and verification of any malicious behavior by the shared sequencer and executors before blockchain finalization.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#h-2-main-idea-3" name="h-2-main-idea-3"></a>2) Main Idea</h2>
<p>We propose an architecture for synchronous atomic execution using the <code>shared sequencer</code>, <code>data availability (DA)</code>, and a <code>verification layer</code>.</p>
<h3><a class="anchor" href="https://ethresear.ch#why-shared-sequencer-4" name="why-shared-sequencer-4"></a>Why shared sequencer?</h3>
<ul>
<li>To satisfy the desired properties of convenience and security, it is necessary to handle bundled transactions across multiple rollups. Therefore, we propose a new entity called the shared sequencer, which is responsible for confirming the blocks of multiple rollups.</li>
<li>The shared sequencer receives a cross-chain bundle and determines the block order for atomic execution.</li>
<li>The shared sequencer is responsible to ensure the atomic execution of bundled transactions before confirming the block.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#new-responsibility-of-the-executor-5" name="new-responsibility-of-the-executor-5"></a>New responsibility of the executor</h3>
<ul>
<li><strong>The executor, in agreement with the shared sequencer, has an added constraint:</strong> it must execute the transaction list committed by the shared sequencer.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/553162b8f7a0148ceedbd7bddbf19ce91d944f58.png" title="SAE_figure1"><img alt="SAE_figure1" height="130" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/553162b8f7a0148ceedbd7bddbf19ce91d944f58_2_690x130.png" width="690" /></a></div><br />
[Figure 1] The definition of roles and responsibilities of shared sequencer and executors<p></p>
<h3><a class="anchor" href="https://ethresear.ch#conditions-for-synchronous-atomicity-6" name="conditions-for-synchronous-atomicity-6"></a>Conditions for synchronous atomicity</h3>
<ul>
<li>Synchronous atomicity for bundle transaction is achieved if the following two conditions are independently verified:
<ol>
<li>All bundled transaction in the block committed by the shared sequencer should be atomic.</li>
<li>The executor executes the same block as committed by the shared sequencer.</li>
</ol>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#h-3-our-contributions-7" name="h-3-our-contributions-7"></a>3) Our Contributions</h2>
<ul>
<li><strong>Designed a synchronous atomic execution solution</strong>:
<ul>
<li><strong>Security requirements definition</strong>: We have defined the security requirements for each entity involved in synchronous atomic execution, ensuring that all components operate securely and reliably.</li>
<li><strong>Architecture design</strong>: We have designed a robust architecture that ensures security and efficiency. This architecture includes:
<ul>
<li><strong>User’s bundle transaction</strong>: We defined the structure and format of bundle transactions that users can create. These bundled transactions enable users to execute multiple transactions across different rollups simultaneously, ensuring atomic execution.</li>
<li><strong>The bundler contract</strong>: We designed and implemented the bundler contract, which is responsible for handling and processing bundled transactions. This contract is called by the shared sequencer, and performs several critical functions:
<ul>
<li>Acts as a gateway smart contract for users to call the actual contracts they intend to execute.</li>
<li>Allows the shared sequencer to enforce transaction reverts to guarantee the atomicity of the bundle transactions.</li>
<li>Verifies the legitimacy of transactions initially created by the user.</li>
<li>Charges transaction fees to users.</li>
</ul>
</li>
<li><strong>Coordination process for the shared sequencer</strong>:  We developed a coordination process for the shared sequencer, which includes interaction with the full nodes (simulators) of each rollup. This process ensures that the shared sequencer can effectively manage and sequence transaction across multiple rollups, guaranteeing atomic execution.</li>
<li><strong>Verification logic</strong>: We defined the verification logic to ensure that all transactions within a bundle meet the defined security requirements before finalization.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Demonstrated the feasibility of the architecture:</strong>
<ul>
<li><strong>Implementation</strong>: We have implemented the entire architecture, demonstrating its feasibility and effectiveness. Our implementation includes all components of the synchronous atomic execution solution, from the user’s bundle transaction creation to the coordination process for the shared sequencer.
<ul>
<li>The user’s bundled transaction is signed using MetaMask.</li>
<li>Implemented on two Polygon CDKs:
<ul>
<li>Each Polygon CDK has an API that responds to the shared sequencer’s simulation requests.</li>
<li>Each Polygon CDK has a deployed Bundler contract.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Demo</strong>: The demo scenario involves transferring tokens from Rollup A to Rollup B. In this scenario, the bundled transaction consists of two operations: burning the wrapped token on Rollup A and mint it on Rollup B. This demonstrates the practical application of our solution. (<a href="https://x.com/radius_xyz/status/1809120936270123468" rel="noopener nofollow ugc">Check out our Demo here!</a>)</li>
</ul>
</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#h-2-definition-8" name="h-2-definition-8"></a>2. Definition</h1>
<hr />
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/b/0bec5c1463e929939d860e125c34e05cbc6b4c34.jpeg" title="SAE_figure2"><img alt="SAE_figure2" height="243" src="https://ethresear.ch/uploads/default/optimized/3X/0/b/0bec5c1463e929939d860e125c34e05cbc6b4c34_2_690x243.jpeg" width="690" /></a></div><br />
[Figure 2] Overview of transaction flow<p></p>
<blockquote>
<p><img alt=":pushpin:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/pushpin.png?v=12" title=":pushpin:" width="20" /> <strong>The proposed architecture is based on the following assumptions.</strong></p>
<ul>
<li><strong>Scenario</strong>
<ul>
<li>Each Bundle Tx consists of two transactions: a <strong>Burn</strong> transaction and a <strong>Mint</strong> transaction of ERC20 contract (rToken), occurring on different chains (inspired by Hyperlane bridge scenario).</li>
</ul>
</li>
<li><strong>Rollups</strong>
<ul>
<li>Each rollup has a simulation API implemented.</li>
<li>The <code>Radius’ Bundler contract</code> is deployed on each rollup.</li>
<li>The ERC20 rToken contract is also implemented on each rollup.</li>
<li>The execute function of the Radius’ Bundler contract is accessible only by whitelisted <code>shared sequencers</code>.</li>
<li>The ERC20 contract (rToken) grants burn and mint access rights to the Radius’ Bundler contract.</li>
</ul>
</li>
<li><strong>Incentives and Penalties</strong> (Future work)
<ul>
<li>There are sufficient incentives for correct behavior and penalties for incorrect behavior for the <code>shared sequencer</code> and <code>Executor</code>.</li>
</ul>
</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#h-1-operational-roles-and-security-requirements-of-entities-9" name="h-1-operational-roles-and-security-requirements-of-entities-9"></a>1) Operational Roles and Security Requirements of Entities</h2>
<p>In this section, we define the correct behavior and adversarial behavior of each entity in the architecture. The adversarial behaviors defined here will be analyzed in Section 4.</p>
<ul>
<li><strong><code>User</code>:</strong> The entity that generates cross-rollup bundled transactions and sends them to the shared sequencer for atomic execution.
<ul>
<li><strong>Adversarial behaviors</strong>
<ul>
<li>Creates invalid Bundle Tx:
<ul>
<li>The value of the BURN Tx and the MINT Tx do not match.</li>
<li>Insufficient account balance for the tokens intended to be burned.</li>
<li>Lacks the ability to pay the gas fee required for executing the transaction on at least one chain.</li>
<li>Incorrectly signs the Bundle Tx.</li>
</ul>
</li>
<li>Calls the MINT function without the shared sequencer’s assistance:
<ul>
<li>Attempts to execute the MINT Tx without creating a Bundle Tx.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong><code>Shared sequencer</code>:</strong> The entity responsible for receiving bundled transactions from users, creating and submitting blocks for multiple rollups, and ensuring the atomic execution of bundled transactions.
<ul>
<li><strong>Adversarial behaviors</strong>
<ul>
<li>Calls bundler contract without user’s consent.</li>
<li>Fails to verify whether the Bundle Tx is executed atomically across all rollups.</li>
<li>Forces the valid Bundle Tx to revert unnecessarily.</li>
<li>Sends a different transaction list to the executor than the one committed to the DA after confirming the block.</li>
</ul>
</li>
</ul>
</li>
<li><strong><code>Executor</code>:</strong> The entity specific to each rollup that executes the transaction list determined by the shared sequencer and uploads the resulting blocks to the Data Availability layer.
<ul>
<li><strong>Adversarial behaviors</strong>
<ul>
<li>Does not execute the transaction list as confirmed and provided by the shared sequencer.</li>
</ul>
</li>
</ul>
</li>
<li><strong><code>Shared Prover</code>:</strong> The entity that generates zero-knowledge proofs to validate the atomic execution of bundled transactions across different chains based on data from the Data Availability layer.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#h-2-additional-components-10" name="h-2-additional-components-10"></a>2) Additional Components</h2>
<ul>
<li><strong><code>Simulator</code>:</strong> The simulator refers to the full node of each rollup that the shared sequencer communicates with to validate the atomicity of bundled transactions before committing the block. This entity could be the same as the executor mentioned above.</li>
<li><strong><code>Data Availability Layer (DA)</code>:</strong> The DA is a layer for storing data committed by the shared sequencer and executor to prove their honesty. The shared prover uses this information to verify the honesty of both entities.
<ul>
<li>Given a reliable <code>DA</code>, if the shared sequencer and executor each commit the minimum necessary information for the verification of synchronous atomicity to the DA, it can be quickly <code>verified</code> based on that information.</li>
</ul>
</li>
<li><strong><code>Verification layer</code>:</strong> The verification layer is responsible for verifying the proofs generated by the shared prover and assisting with the appropriate actions if verification fails. This layer can either be part of the settlement layer or a dedicated layer focused solely on verification.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#h-3-synchronous-atomic-execution-architecture-11" name="h-3-synchronous-atomic-execution-architecture-11"></a>3. Synchronous atomic execution architecture</h1>
<hr />
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/a/ea8cbd6739d8f45ec741d82a13f6f55f94907b38.jpeg" title="SAE_figure3"><img alt="SAE_figure3" height="349" src="https://ethresear.ch/uploads/default/optimized/3X/e/a/ea8cbd6739d8f45ec741d82a13f6f55f94907b38_2_690x349.jpeg" width="690" /></a></div><br />
[Figure 3] The process of synchronous atomic execution architecture<p></p>
<p>The architecture of Radius’s synchronous atomic execution ensures that bundled transactions are executed in an all-or-nothing manner within the same cycle, coordinated by the shared sequencer. Initially, the shared sequencer’s coordination is trusted optimistically, allowing each transaction to be executed independently on its respective rollup. Subsequently, the atomicity of these transactions is verified before the rollup blocks are finalized on L1.</p>
<p>It can be divided into three main components: <strong>the bundler contract</strong>, <strong>the coordination process</strong>, and <strong>the verification process</strong>. This section will describe each of these components in detail.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-1-smart-contract-for-bundle-transaction-radiuss-bundler-contract-12" name="h-1-smart-contract-for-bundle-transaction-radiuss-bundler-contract-12"></a>1) Smart <strong>Contract for Bundle Transaction (Radius’s Bundler contract)</strong></h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/b/0bec5c1463e929939d860e125c34e05cbc6b4c34.jpeg" title="SAE_figure2"><img alt="SAE_figure2" height="243" src="https://ethresear.ch/uploads/default/optimized/3X/0/b/0bec5c1463e929939d860e125c34e05cbc6b4c34_2_690x243.jpeg" width="690" /></a></div><br />
[Figure 4] Overview of transaction flow<p></p>
<p>We introduce a new smart contract called <code>Radius’s bundler contract</code>, designed to handle and process the users’ bundled transactions. It acts as a gateway to execute the users’ intended contracts.</p>
<p>For example, as shown in the figure, suppose a user creates a bundled transaction that includes calling the Burn function of the rToken contract on Rollup A and the Mint function of the rToken contract on Rollup B. The shared sequencer receives this bundle and wraps it into a transaction that calls the Radius’s bundler contract. Each rollup then processes the transaction through a series of verification via the Radius contract, ultimately executing the user’s intended contract calls.</p>
<h3><a class="anchor" href="https://ethresear.ch#key-features-of-the-bundler-contract-13" name="key-features-of-the-bundler-contract-13"></a>Key features of the Bundler contract</h3>
<ul>
<li>Acts as a gateway smart contract for users to call the actual contracts they intend to execute.</li>
<li>Allows the shared sequencer to enforce transaction reverts to guarantee the atomicity of the bundle transactions.</li>
<li>Verifies the legitimacy of transactions initially created by the user.</li>
<li>Charges transaction fees to users.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#how-is-the-bundler-contract-implemented-14" name="how-is-the-bundler-contract-implemented-14"></a>How is the Bundler contract implemented?</h3>
<p>The Bundler contract includes the following functions:</p>
<ul>
<li><code>execute</code>: Called by the shared sequencer, this function executes the user’s transaction after a series of verifications.</li>
<li><code>deposit</code>: Allows users to deposit transaction fees in advance.</li>
<li><code>withdraw</code>: Allows users to withdraw their deposited funds.</li>
<li><code>addWhitelist</code>: Adds a sequencer to the whitelist.</li>
<li><code>removeWhitelist</code>: Removes a specific sequencer from the whitelist</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#how-is-the-execute-function-implemented-15" name="how-is-the-execute-function-implemented-15"></a>How is the <code>execute</code> function implemented?</h3>
<blockquote>
<p><img alt=":pushpin:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/pushpin.png?v=12" title=":pushpin:" width="20" /> The input parameters for the execute function are as follows:</p>
<ul>
<li><code>from</code>: User address</li>
<li><code>bundle_tx_list</code>: Information of all transactions within the Bundle Tx</li>
<li><code>index</code>: Current transaction’s index within the <code>bundle_tx_list</code></li>
<li><code>bundle_tx_signature</code>: User’s signature for the Bundle Tx</li>
<li><code>revert_flag</code>: Flag for enforcing revert
<ul>
<li>The sequencer includes a <strong>“revert_flag”</strong> in the data, which is set by the sequencer to forcibly revert the user’s transaction. If this value is set to true, the Bundler contract will revert the user’s transaction. This mechanism is designed to ensure the atomicity of the transactions defined in the bundle, preventing the execution of the remaining transactions if even one included in the bundle fails to execute.</li>
</ul>
</li>
</ul>
</blockquote>
<ol>
<li>Access control:
<ul>
<li>Verify that the call is made by a shared sequencer listed in the whitelist.</li>
</ul>
</li>
<li>Check <code>revert_flag</code>:
<ul>
<li>If <code>revert_flag</code> == true, forcibly reverts the transaction.</li>
</ul>
</li>
<li>Verify user’s transaction:
<ul>
<li>Decode the transaction’s data field.</li>
<li>Ensure the user’s deposit is greater than the transaction fee.</li>
<li>Verify the user’s bundled transaction signature.</li>
<li>Check the Bundle Transaction validity
<ul>
<li>(In this scenario) Verify that the values to be minted and burned are identical.</li>
</ul>
</li>
</ul>
</li>
<li>Deduct transaction fee from user’s deposit (Exception handling required for early reverts):
<ul>
<li>Transfer the transaction fee to the shared sequencer from the contract’s deposited assets.</li>
<li>Deduct the transaction fee from the user’s deposit.</li>
</ul>
</li>
<li>Execute user’s intended contract:
<ul>
<li>Call the contract that the user intended to execute.</li>
</ul>
</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#h-2-coordination-process-for-the-shared-sequencer-16" name="h-2-coordination-process-for-the-shared-sequencer-16"></a>2) Coordination process for the shared sequencer</h2>
<p>Radius’s shared sequencing technique separates the roles of sequencing and execution. The shared sequencer is responsible for deciding the block that atomically executes the user’s bundle transactions, while the block is built by each rollup’s executor. Therefore, if it can be ensured that the shared sequencer has coordinated the atomic execution of the bundle transactions and the executor has executed the block as determined by the shared sequencer, synchronous atomic execution is achieved.</p>
<p>Coordination involves requesting simulations to the full nodes of each rollup for the respective transaction lists, collecting the simulated results, and, if some transactions within the bundle need to be reverted to maintain atomicity, forcibly reverting the remaining transactions to produce a transaction list that will be executed atomically. In other words, if the simulation results of the two transaction defined in the bundle are not the same (i.e., one is a revert and the other is a success), the transaction that yields a successful result is modified by setting its <code>revert_flag</code> to 1 to forcibly revert it. The transaction list is then updated with the modified transaction.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/d/4d77403de3cd9cacd9e96500481eda982fd6f53f.jpeg" title="SAE_figure5"><img alt="SAE_figure5" height="493" src="https://ethresear.ch/uploads/default/optimized/3X/4/d/4d77403de3cd9cacd9e96500481eda982fd6f53f_2_690x493.jpeg" width="690" /></a></div><br />
[Figure 5] Example of a Simulation Process<p></p>
<p>After finalizing the block, the shared sequencer commits to it. Later, the block information committed by the shared sequencer can be compared with the block executed by the executor to verify that the executor executed the block as agreed. The atomicity of the bundle transactions can be verified by examining the receipt committed by the executor after building the block, which shows the success status of each transaction and ensures that the shared sequencer did not forcibly revert all transactions. These two processes can be verified off-chain using ZKP systems such as RiscZero or SP1. This process is detailed in section 3.3.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-3-verification-process-for-the-shared-prover-17" name="h-3-verification-process-for-the-shared-prover-17"></a>3) Verification process for the shared prover</h2>
<p>We design a zk prover called  “Shared Prover” which allows us to verify that the shared sequencer and executor acted in accordance with the protocol’s intentions. The shared prover generates proof for the <strong>atomicity of the bundle transactions</strong> and their <strong>valid execution result</strong> according to the commitment.</p>
<p>We leverage the DA layer to facilitate the sharing of the sequencer’s commitments and execution data across different chains. Utilizing the DA layer for data storage offers enhanced transparency and accessibility. Based on the DA (Data Availability) data, it can be confirmed that the user’s bundle transactions were executed atomically, and the validity of the execution result on different chains can be verified.</p>
<p>The shared sequencer communicates with simulators to finalize the the list of transactions to be performed while ensuring atomicity, and the executor processes this list and then it uploads the resulting data to the DA layer.</p>
<h3><a class="anchor" href="https://ethresear.ch#information-stored-in-the-da-18" name="information-stored-in-the-da-18"></a>Information stored in the DA</h3>
<ul>
<li>
<p><strong>Shared sequencer’s transactions list commitment</strong></p>
<p>To settle transaction list, shared sequencer commits the following data with signature to the DA:</p>
<ul>
<li><code>chain ID</code></li>
<li><code>block height</code></li>
<li><code>transaction MPT root</code></li>
<li><code>bundle transaction list</code></li>
</ul>
</li>
<li>
<p><strong>Executed Block data</strong></p>
<p>After a block is executed on each chain, the entity who executed the block uploads the results to the DA.</p>
</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#atomicity-proofs-shared-sequencers-honesty-19" name="atomicity-proofs-shared-sequencers-honesty-19"></a>Atomicity proofs (Shared sequencer’s honesty)</h3>
<p>The shared prover retrieves the block execution results stored in the DA by the executor. In the atomicity proof, the following aspects are verified using zero-knowledge proofs:</p>
<ul>
<li>
<p><strong>All-or-Nothing execution</strong></p>
<ul>
<li>
<p>The receipt status for the bundle transactions must have the same value.</p>
<p><span class="math">assert! (\text{receipt}(\text{tx}_A).\text{status} = \text{receipt}(\text{tx}_B).\text{status})</span></p>
</li>
</ul>
</li>
<li>
<p><strong>Prevention of arbitrary manipulation of the shared sequencer’s revert flag</strong></p>
<ul>
<li>
<p>There is a potential attack where a valid bundled transaction is reverted entirely, collecting fees from the user without executing the transaction. To prevent this, the atomicity proof checks that not all revert flags for the transactions are set to 1.</p>
</li>
<li>
<p>Therefore, revert flags cannot be set to 1 simultaneously.</p>
<p><span class="math">\text{assert!}~(\text{tx}_A.\text{revert_flag} \times \text{tx}_B.\text{revert_flag} = 0)</span></p>
</li>
</ul>
</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#proof-of-rollup-executors-honesty-20" name="proof-of-rollup-executors-honesty-20"></a>Proof of Rollup executor’s honesty</h3>
<p>To verify that the executor has honestly executed the block according to the transaction list committed be the shared sequencer, the shared prover also includes the relationship between the values committed by the shared sequencer and the MPT root of the transactions uploaded by the executor.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-4-security-analysis-21" name="h-4-security-analysis-21"></a>4. Security analysis</h1>
<hr />
<ul>
<li><strong>Individual Transaction Validity</strong>: The validity of individual transactions (e.g., insufficient user’s balance) is verified by the Bundler Contract, and transactions will fail if they do not pass this check.</li>
<li><strong>Bundle Transaction Validity</strong>: The validity of the bundled transaction (e.g., discrepancy between mint and burn amounts) is also verified by the Bundler Contract, and the bundle will fail if it does not pass this check.</li>
<li><strong>Atomicity of Successful Bundle Transactions</strong>: The shared sequencer is responsible for ensuring the atomicity of successfully executed bundled transactions. The honesty of the shared sequencer is verified by the shared prover and the verification layer.</li>
<li><strong>Honesty of the Executor</strong>: If the shared sequencer has legitimately determined and committed the blocks for each rollup, the honesty of the executor is verified by the shared prover and the verification layer.</li>
<li><strong>Prevention of Manipulation</strong>: Additionally, neither the shared prover nor the rollup executor can manipulate the user’s bundle transaction. The user’s signature prevents such tampering.</li>
<li><strong>Integrity of Proofs and Verification</strong>: The shared prover and the verification layer perform proofs and verification based on authenticated data available in the Data Availability (DA) layer. As a result, they cannot alter the proof content. The worst they can do is to withhold performance.</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/cross-rollup-synchronous-atomic-execution/20193">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 08:57:29 +0000</pubDate>
</item>
<item>
<title>Preconfirmation Bidding Increased Block Values on Holesky</title>
<link>https://ethresear.ch/t/preconfirmation-bidding-increased-block-values-on-holesky/20190</link>
<guid>https://ethresear.ch/t/preconfirmation-bidding-increased-block-values-on-holesky/20190</guid>
<content:encoded><![CDATA[
<div> 关键词：Mev-commit、Holesky、预确认、竞标行为、区块价值

总结:
文章主要探讨了自7月10日以来，Mev-commit 0.4.3版本在Holesky tesnet上启用预确认功能的情况。在这段时间里，预确认功能参与度逐渐增加，目前有1个转接器、3个提供者、9个竞标者参与其中。从7月10日至7月29日期间，提供者共发布了807次预确认，涉及415个Holesky区块。预确认交易数量较少（815次），但价值相对较高，平均每个预确认交易的价值为0.0049 ETH，而平均优先费用仅为0.0045 ETH。这表明预确认交易对整体区块价值的贡献显著。

此外，文章还指出，预确认交易平均为区块贡献的价值（0.0093 ETH）远高于常规区块（0.0044 ETH）。这表明预确认机制可以有效提升区块价值，从而增加验证者的奖励。同时，文章也提到，由于Holesky作为测试网与主网存在差异，其预确认功能的使用情况可能与主网有所不同。为了进一步研究和优化预确认机制，计划进行更多在模拟主网环境下的测试，并邀请更多的参与者加入到Mev-commit生态系统中。 <div>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TLDR</h1>
<ul>
<li>Since July 10, mev-commit 0.4.3 has enabled over 800 execution preconfirmations on Holesky, with increasing network participation.</li>
<li>Providers issued 807 preconfirmations across 415 blocks. Bidders sent 4.24 ETH worth of bids.</li>
<li>Average mev-commit block value was 0.0093 ETH compared to 0.0044 ETH for a vanilla block.</li>
<li>Average preconfirmation bid was 0.0049 ETH, slightly higher than the average priority fee of 0.0045 ETH.</li>
<li>Data shows that preconf bids contribute significantly to overall block value, despite limited participation for the nascent network.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#overview-2" name="overview-2"></a>Overview</h1>
<p>Since July 10, mev-commit 0.4.3 has been facilitating execution preconfirmations on Holesky tesnet. There has been an upwards trend of participation with currently 1 relay, 3 providers, 9 bidders, and <a href="https://validators.mev-commit.xyz/" rel="noopener nofollow ugc">27,000 validators</a> participating. From July 10 to July 29 (Holesky block range 1902173 to 2027932), providers have issued 807 preconfirmations across 415 Holesky blocks. Some examples of preconfirmation blocks:</p>
<ul>
<li><a href="https://holesky.etherscan.io/block/1943039" rel="noopener nofollow ugc">1943039</a> with 21 preconfs and .016 ETH worth of bids</li>
<li><a href="https://holesky.etherscan.io/block/1986732" rel="noopener nofollow ugc">1986732</a> with 7 preconfs and .04 ETH worth of bids</li>
<li><a href="https://holesky.etherscan.io/block/1986963" rel="noopener nofollow ugc">1986963</a> with 5 preconfs and .022 ETH worth of bids</li>
</ul>
<p>There are two caveats to these initial results. The first is that network participation is still growing. As more actors onboard or opt in to the network, the flow of preconfs is likely to increase. The second caveat is that Holesky does not have the same competitive use cases for preconfs as mainnet, and does not mirror mainnet Ethereum transacting behavior as closely as desired.</p>
<p>The notebook used for analytics <a href="https://github.com/Evan-Kim2028/preconf_analytics/blob/e6fdb9886c600315d531b59cb13e6efccc7d56bd/notebooks/preconfs.ipynb" rel="noopener nofollow ugc">can be found here</a>. The data for these results can be replicated using the <a href="https://github.com/primev/mev_commit_sdk_py" rel="noopener nofollow ugc">mev-commit-sdk-py</a> repository to collect mev-commit events powered by Hypersync indexer. There is also <a href="http://explorer.testnet.mev-commit.xyz/app/discover" rel="noopener nofollow ugc">an explorer</a>, which is currently in development.</p>
<h1><a class="anchor" href="https://ethresear.ch#bidding-behavior-3" name="bidding-behavior-3"></a>Bidding Behavior</h1>
<p>We observe 815 preconfirmation transactions, indicating a niche but valuable market segment compared to 4 million regular transactions. This significant difference suggests preconfs are currently used by a smaller subset of users who are testing preconfirmations.</p>
<p>A total of 9 bidders participated, sending 4.24 ETH in bids compared to 0.13 ETH in priority fees, with an average preconfirmation bid of 0.005 ETH versus 0.00016 ETH for priority fees on the same transaction, indicating a heavier bidding preference for preconfirmations over priority fees.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/4/04d6296e99153e73f2e018b8c21b727582d0c89e.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/0/4/04d6296e99153e73f2e018b8c21b727582d0c89e_2_563x500.png" width="563" /></a></div><p></p>
<p>Overall, priority fees totaled 544 ETH with the average preconfirmation bid being 0.0049 ETH, slightly higher than the average priority fee of 0.0045 ETH.</p>
<h1><a class="anchor" href="https://ethresear.ch#block-value-4" name="block-value-4"></a>Block Value</h1>
<p>We hypothesized that preconfs would add an increase in block value, resulting in higher validator rewards per mev-commit block. On average, we observe 1.95 preconfirmation transactions per block compared to 42.3 total transactions. Average mev-commit block value was 0.0093 ETH compared to 0.0044 ETH for a vanilla block.</p>
<p><img alt="image" height="474" src="https://ethresear.ch/uploads/default/original/3X/d/9/d97a557eefe85c83cef80122c55b8695d60307b1.png" width="542" /></p>
<p>One limitation in comparing mev-commit blocks to vanilla Holesky blocks is that there are only ~400 mev-commit blocks compared to ~50,000 Holesky blocks. This is primarily due to the nascent mev-commit network participation rates. Additionally the average bid amount at 0.005 ETH seems on the higher side for Holesky blocks and may not accurately reflect mainnet amounts. However accurately pricing preconfirmations is a difficult task and has to be balanced with the presence of mev spikes on mainnet that can greatly skew results. We are actively researching how to price preconfirmations more effectively.</p>
<p>We illustrate the block revenue breakdown over several days in the chart below for mev-commit blocks, showing the breakdown between preconfirmation bids and priority fees:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/0/c04ec97bff2be44d3e1f79915157487def6eb685.png" title="image"><img alt="image" height="409" src="https://ethresear.ch/uploads/default/optimized/3X/c/0/c04ec97bff2be44d3e1f79915157487def6eb685_2_690x409.png" width="690" /></a></div><p></p>
<p>Preconfirmation bids significantly contributed to increasing block value. On days such as July 11th, 18th, and 24th, preconfirmation bids markedly boosted total block value, highlighting their substantial impact.</p>
<p>The charts below illustrate an outsized impact that preconfirmation bids on block value:</p>
<ul>
<li><strong>Preconf Bids per Block</strong>: Despite a smaller number of transactions, preconfirmation bids are consistently higher, often reaching up to 0.02 ETH.</li>
<li><strong>Priority Fees per Block</strong>: While more frequent, priority fees are generally lower, seldom exceeding 0.01 ETH.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/3/43fe06dfdd10788ec3344bc9e8592e3773cf34a6.png" title="image"><img alt="image" height="312" src="https://ethresear.ch/uploads/default/optimized/3X/4/3/43fe06dfdd10788ec3344bc9e8592e3773cf34a6_2_690x312.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/0/1078d70fc113dfd6d3a0d5a291ef56a81a12f361.png" title="image"><img alt="image" height="317" src="https://ethresear.ch/uploads/default/optimized/3X/1/0/1078d70fc113dfd6d3a0d5a291ef56a81a12f361_2_690x317.png" width="690" /></a></div><p></p>
<p>A notable example is block <a href="https://holesky.etherscan.io/block/1943039" rel="noopener nofollow ugc">1943039</a>, which had the highest number of preconfs with 21 out of 48 transactions. In this block, preconf bid revenue was 0.008 ETH, vastly outpacing the 0.0009 ETH from priority fees.</p>
<p>These observations demonstrate that even a few preconfirmation transactions can substantially enhance block value due to their higher bid amounts.</p>
<h1><a class="anchor" href="https://ethresear.ch#limitations-5" name="limitations-5"></a>Limitations</h1>
<p>As mentioned earlier, the caveats to our initial findings is that Holesky is a testnet and does not have the same types of competitive opportunities as Mainnet. Users tend to have less urgency on Holesky and this is reflected in smaller block sizes and lower priority fees.</p>
<p>As a result, the preconf bids may not have the same relationship to priority fees on mainnet compared to testnet and may not accurately reflect the user’s true bidding preferences since testnet tokens are being used.</p>
<h1><a class="anchor" href="https://ethresear.ch#closing-remarks-6" name="closing-remarks-6"></a>Closing Remarks</h1>
<p>This report initially touches on some preconfirmation bidding behavior observed through early mev-commit usage and offers insights into how preconf bids can increase validator rewards. We plan to follow up with a more detailed report on mev-commit protocol details such as the decay mechanism, rewards and slashing, settlement process, and revenue.</p>
<p>We plan to onboard more bidders, providers and validators into the mev-commit ecosystem and conduct more tests in an environment that mimics mainnet more closely. We invite you to participate starting at <a class="inline-onebox" href="https://docs.primev.xyz/get-started/welcome-to-primev" rel="noopener nofollow ugc">Welcome to Primev - Documentation</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmation-bidding-increased-block-values-on-holesky/20190">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 02:58:46 +0000</pubDate>
</item>
<item>
<title>Affiliated AMMs and permissionless solving for uniform price batch auctions</title>
<link>https://ethresear.ch/t/affiliated-amms-and-permissionless-solving-for-uniform-price-batch-auctions/20187</link>
<guid>https://ethresear.ch/t/affiliated-amms-and-permissionless-solving-for-uniform-price-batch-auctions/20187</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、批拍卖、AMM、公正执行、分散化

总结:

本文探讨了通过批拍卖机制降低矿工提取费用(MEV)的可能性及其潜在应用。MEV是区块链交易中的一个重要议题，它涉及到交易排序、删除和插入带来的经济利益。批拍卖通过确保交易执行顺序的中立性以及统一清算价格来尝试解决这一问题。

文章首先强调了批拍卖的概念和其在减少MEV方面的潜力。批拍卖允许在区块构建阶段进行交易批量处理，以确保所有交易在同一时间以相同价格执行，这有助于接近理想状态下的公平市场环境。

接着，文章提出了“公正执行”概念，即批拍卖合同执行时不依赖于交易顺序，且统一清算价格保证了交易双方获得一致的价格。CoW协议是当前实现批拍卖机制的一个实例，但作者指出，仅依靠批拍卖机制并不足以完全消除MEV，因为仍然存在数据被忽略或插入的风险。因此，文章提出了一种折衷策略，即在正常市场条件下，通过激励机制让特权行为者不进行数据篡改，并享受仅有的微小优势。

文章进一步讨论了批拍卖系统与自动做市商（AMM）的集成，尤其是引入“附属AMM”，这些AMM可以参与批拍卖并设定特定的交易规则，以此来减少流动性提供者的损失和MEV。

此外，文章还提出了“无许可解决”策略，即允许任何实体执行批拍卖，以最大化去中心化程度。这需要建立信任执行环境，确保诚实解决者能够通过最大化收入来优化执行过程，从而防止恶意操纵价格的行为。

最后，文章讨论了批拍卖系统的实施细节，如费用覆盖、流动性迁移和监管机制等，并强调了系统稳定性的关键因素，包括市场流动性、价格波动范围以及解决者之间的竞争平衡。文章认为，通过引入多级AMM和附属AMM，以及优化解决者激励机制，批拍卖系统可以在一定程度上降低MEV，从而促进更公平、更透明的交易环境，为Dex交易提供更多便利，最终提升区块链的价值。 <div>
<p>The idea of mitigating MEV through batch auctions is as old as the concept of MEV itself. They can both be traced back to <a href="https://www.reddit.com/r/ethereum/comments/2d84yv/miners_frontrunning/" rel="noopener nofollow ugc">this Reddit post</a> from August 2014<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-1" id="footnote-ref-49420-1">[1]</a></sup>. Today, ten years later, this is still an ongoing discussion (see for instance <a href="https://ethresear.ch#references">[UNIX]</a>, <a href="https://ethresear.ch#references">[COW]</a>). To what extent can we reduce MEV by using batch auctions? Can we build batch auction protocols that are better than those existing today? In this article we propose an optimistic point of view for the first question and a candidate affirmative answer to the second question through concrete mechanisms.</p>
<p><strong>Note:</strong> This article was primarily conceived while working at Flashbots Research for a year spanning 2023 and 2024. Special thanks to Christoph Schlegel.</p>
<p>The article assumes that the reader is familiar with the concepts of MEV, batch auctions and AMMs in the context of decentralized exchange (DEX).</p>
<h3><a class="anchor" href="https://ethresear.ch#a-cooperative-endeavour-between-traders-1" name="a-cooperative-endeavour-between-traders-1"></a>A cooperative endeavour between traders</h3>
<p>In the long term, on-chain traders will use those DEX protocols that are most convenient for them. Ideally, they would trade at market prices with no fee other than the gas cost, equalling the gas price of a transfer. Even though Ethereum’s reality is far from this, in my opinion we shouldn’t rush to dismiss the possibility. Carefully designed smart contracts jointly with off-chain mechanisms might help traders get close to this ideal<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-2" id="footnote-ref-49420-2">[2]</a></sup>. It is likely that these clever designs are not out there yet.</p>
<p>A very powerful idea is that the smart contract that settles trade orders does so in batches, enforcing uniform clearing prices. This has two fundamental properties:</p>
<p>(a) The execution does not depend on the ordering of the trade orders.</p>
<p>(b) Uniform clearing prices ensure that a user trading in one direction receives the same price as the other users trading in that same direction, and is a direct counterpart to the users trading in the other directions, with no room for intermediaries between them.</p>
<p>The most famous (or even the only) live system implementing this mechanism on a blockchain is CoW protocol <a href="https://ethresear.ch#references">[COW]</a> (see also <a href="https://ethresear.ch#references">[SPEEDEX]</a>). Unfortunately, the sole existence of a uniform price batch auction mechanism is not enough to reach the ideal situation described above. MEV occurs through the reordering, censoring, or insertion of data by a privileged player. While according to (a) reordering trade orders has no effect in our case, it is still possible that privileged players censor and insert data. As a matter of fact, for the players who write a transaction or a block, it will always be physically possible to ignore some data and to include their own data, maybe even pretending that this new data was produced by someone else. Therefore, here we will simply abandon the search of a protocol that logically guarantees no censorship nor privileged insertions. Nevertheless, we will not rule out the possibility of a mechanism such that in normal market conditions and assuming wide adoption, the privileged players will be incentivized not to censor, and enjoy only a marginal advantage from last moment inclusions.</p>
<p>While CoW protocol has achieved an interesting degree of adoption, it represents only a small fraction of Ethereum DEX activity —<a href="https://defillama.com/aggregators/chains/ethereum" rel="noopener nofollow ugc">around 1% these days</a>. CoW runs a centralized solving protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#uniform-clearing-prices-and-walrasian-equilibrium-2" name="uniform-clearing-prices-and-walrasian-equilibrium-2"></a>Uniform clearing prices and Walrasian equilibrium</h3>
<p>A trade order can be understood as a mathematical function of the clearing prices. The output of the function is the traded amounts for each asset. Given a set of trade orders, there is typically only a limited set of valid clearing price vectors, maybe even only one. This situation perfectly corresponds to the concept of Walrasian equilibrium in a pure exchange market (see <a href="https://ethresear.ch#references">[RGGM]</a>, <a href="https://ethresear.ch#references">[FY]</a> and references therein). A Walrasian equilibrium is a vector of prices at which the supply of each good equals the demand for that good.</p>
<p>Under very mild hypothesis, we can guarantee the existence of at least one equilibrium. The computational problem of finding equilibrium price vectors translates to the search of fixed points of a certain mapping.</p>
<h3><a class="anchor" href="https://ethresear.ch#affiliated-amms-3" name="affiliated-amms-3"></a>Affiliated AMMs</h3>
<p>Decentralized exchange predominantly occurs through automated market makers (AMMs). Many researchers and industry actors have pointed out that AMM liquidity providers (LPs) typically receive worse prices than what the market has to offer at each time. This phenomenon is usually referred to as loss vs. rebalancing (LVR) and described as MEV suffered by the liquidity providers <a href="https://ethresear.ch#references">[LVR]</a>, <a href="https://ethresear.ch#references">[WLVR]</a>.</p>
<p>There is a natural mechanism to attack this issue that no one seems to have considered yet<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-3" id="footnote-ref-49420-3">[3]</a></sup>. Special AMMs may participate in a uniform price batch auction just like any other trader. These would be the affiliated AMMs. They would allow certain swaps depending on their state and execution price, only admitting the price from the batch. We can think of the allowed swaps as preprogrammed trade orders. To implement this, the contract that executes batches should be prepared to call affiliated swaps passing the batch prices. From now on, let us call <em>W</em> the smart contract that executes batches, i.e. the main contract of the system under consideration. Specially designed affiliated AMMs may be added <em>a posteriori</em> following specifications determined by the <em>W</em> contract<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-4" id="footnote-ref-49420-4">[4]</a></sup>. It is possible that affiliated AMMs benefit by only allowing swaps coming from <em>W</em>. However, we do not need to discuss it at this point: the scheme allows to decouple the problem of choosing a specific AMM design. A multiplicity of them may coexist, and liquidity migration can happen seamlessly at any time. The existence of multiple AMMs affiliated to the same <em>W</em> contract does not entail liquidity fragmentation.</p>
<p>Assuming wide adoption of the <em>W</em> contract and low incidence of censorship, we have clearing prices that are actual market prices, thus mitigating LVR and MEV.</p>
<p>
<br />
</p><p><img alt="diagram" height="451" src="https://ethresear.ch/uploads/default/original/3X/4/8/4824aef76acd0078806fd0c5418d95c44555a648.png" width="642" /></p>
<p></p>
<h3><a class="anchor" href="https://ethresear.ch#permissionless-solving-4" name="permissionless-solving-4"></a>Permissionless solving</h3>
<p>Once we have truly accepted that we cannot enforce censorship resistance for trade orders at code level, we may reasonably conjecture that the best we can do is to open the gates as much as possible in order to minimize censorship and democratize the system. The proposal is to let <em>W</em> allow anyone to execute a batch. The block proposers, as always, will exercise their right to choose the transactions they prefer, possibly through a PBS mechanism <a href="https://ethresear.ch#references">[PBS]</a>, <a href="https://ethresear.ch#references">[MEV-BOOST]</a>. This feature achieves the maximum degree of decentralization possible at smart contract level for a batch auction system. The auction will occur at block building level. This is analogous to the usual permissionless access to AMMs, which is only regulated by the PBS apparatus or whatever mechanism adopted by the block proposers. Another example is UniswapX: their reactors allow anyone to be a <a href="https://docs.uniswap.org/contracts/uniswapx/guides/createfiller" rel="noopener nofollow ugc">filler</a>, though they don’t enforce uniform clearing prices.</p>
<p>Let us explain why it is reasonable to expect that this mechanism will work well, i.e., that potential price manipulations by censoring orders are expected to be under control. The flow of the reasoning is as follows. We will first imagine the system flourished, running a large portion of Ethereum’s DEX volume. We will try to visualize this scenario and assess whether it is stable or if we should expect frequent price manipulations. Let us list some properties of the flourished scenario:</p>
<p><strong>(1)</strong> Since there are many important tokens on Ethereum blockchain, we expect to have a main cluster of several tokens interconnected by swaps at each batch. This is desirable because it means the liquidity in one pair can benefit traders in other pairs (e.g., an order in pair A/B can be settled against orders in pairs B/C and C/A).</p>
<p><strong>(2)</strong> By looking at how prices vary, it turns out that very-short-term volatility is easy to estimate. Only as an example, on a normal day the price of ETH measured in USD typically varies less than 0.1% in a 12s period, with some larger jumps occasionally. Uninformed traders may use this kind of magnitude for the slippage tolerance. Furthermore, public tools that monitor real time price movements can aid users to reduce the slippage tolerance depending on their preferences. Meanwhile, informed traders doing statistical arbitrage or plain arbitrage are expected to use very low values for the slippage tolerance when trading liquid assets. This will set a tight bound on the bounty that a malicious solver can obtain by deviating the price.</p>
<p><strong>(3)</strong> We may assume the existence of honest solvers. As usual, the batch that generates more income for the block proposer should make it to the chain. Honest solvers will aim to maximize that income by maximizing inclusion. They will frequently need to discard some orders for various reasons, such as limited block space, or computation deadlines. As a result, we will often have more than one honest proposed batch. Trusted execution environments can be useful in increasing the transparency of honest solvers.</p>
<p>When a malicious solver tries to manipulate the price, they have to beat the best honest solution. To this end, they will censor every order in one direction for a given pair A/B exceeding certain price threshold. By doing so, they will not only miss out on the gas fees of the censored orders, but also on orders in other pairs due to operating away from the market equilibrium prices (recall (1)). Because of this and (2) it is possible that in most cases it will not be profitable to manipulate the prices of the batch. In addition, we may have other off-chain mechansims to further prevent malicious solving. One such mechanism can be to use private channels between traders and honest solvers in certain cases.</p>
<h3><a class="anchor" href="https://ethresear.ch#mev-a-zoom-out-analysis-5" name="mev-a-zoom-out-analysis-5"></a>MEV: a zoom-out analysis</h3>
<p>Total MEV extraction from Ethereum has been stable during the last two years, at levels above 250 kETH per year<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-49420-5" id="footnote-ref-49420-5">[5]</a></sup>. During this period, there haven’t been many innovations generating optimism about MEV reduction. This has led many people to believe that such levels of MEV are inevitable. The fundamental economic reason for the existence of MEV can be summarized by the concept of block proposer monopoly. If traders want to improve their situation, they need to coordinate by adopting a mechanism that gives them more bargaining power, a trade union. This is the principle underlying the concrete proposals presented here. A system that integrates the different types of liquidity and unifies the execution prices helps traders coordinate their orders around true market prices as described in (2).</p>
<p>Reducing the incidence of MEV would be a great achievement, since it would allow the DEX volume to grow. On-chain trading would become more convenient than centralized alternatives in many cases, thus increasing the global value of the blockchain.</p>
<h3><a class="anchor" href="https://ethresear.ch#final-remarks-6" name="final-remarks-6"></a>Final remarks</h3>
<p>(I) The above description of <em>W</em> is incomplete. Possibly the most important undefined aspect is how to cover gas and trade fees (by <em>gas fee</em> we mean the cost of gas usage as if it were a transfer). What kind of regulations should <em>W</em> implement regarding the operational cost or trade fees? Can the system work well at zero trade fee? See footnote [2]. These questions don’t seem very easy to answer. Fortunately, we will be able to continue iterating theory and practice.</p>
<p>(II) If there are non-affiliated AMMs coexisting with <em>W</em>, the solvers of <em>W</em> can extract profit from them. Every time there is a price movement, it will be possible to find surplus-generating solutions. To find them, they need to consider non-affiliated AMMs as virtual agents of the batch, following a procedure explained in <a href="https://ethresear.ch#references">[FY]</a>. This mathematical fact should act as an attractor of liquidity from traditional to affiliated AMMs.</p>
<h3><a class="anchor" href="https://ethresear.ch#references-7" name="references-7"></a>References</h3>
<p><strong>[COW]</strong> CoW protocol, <a class="inline-onebox" href="https://docs.cow.fi/cow-protocol" rel="noopener nofollow ugc">CoW Protocol | CoW Protocol Documentation</a>;</p>
<p>Felix Leupold, <em>Gnosis Protocol v2 Fighting the MEV Crisis with Batch Auctions one CoW at a time</em>, <a href="https://www.youtube.com/watch?v=6MfcZGVeQsQ" rel="noopener nofollow ugc">https://www.youtube.com/watch?v=6MfcZGVeQsQ</a></p>
<p><strong>[CF]</strong> Andrea Canidio, Robin Fritsch, <em>Arbitrageurs’ profits, LVR, and sandwich attacks: batch trading as an AMM design response</em>, <a class="inline-onebox" href="https://arxiv.org/abs/2307.02074" rel="noopener nofollow ugc">[2307.02074] Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response</a></p>
<p><strong>[FB2]</strong> Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li, Xueyuan Zhao, Iddo Bentov, Lorenz Breidenbach, Ari Juels, <em>Flash Boys 2.0: Frontrunning, Transaction Reordering, and Consensus Instability in Decentralized Exchanges</em> <a class="inline-onebox" href="https://arxiv.org/abs/1904.05234" rel="noopener nofollow ugc">[1904.05234] Flash Boys 2.0: Frontrunning, Transaction Reordering, and Consensus Instability in Decentralized Exchanges</a></p>
<p><strong>[FY]</strong> Sergio Yuhjtman, Flashbots, <em>Walraswap: a solution to uniform price batch auctions</em>, <a class="inline-onebox" href="https://arxiv.org/abs/2310.12255" rel="noopener nofollow ugc">[2310.12255] Walraswap: a solution to uniform price batch auctions</a></p>
<p><strong>[LVR]</strong> Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden, Anthony Lee Zhang, <em>Automated Market Making and Loss-Versus-Rebalancing</em>, <a href="https://arxiv.org/pdf/2208.06046" rel="noopener nofollow ugc">https://arxiv.org/pdf/2208.06046</a></p>
<p><strong>[MEV-BOOST]</strong> Flashbots, <em>MEV-Boost in a Nutshell</em>, <a href="https://boost.flashbots.net/" rel="noopener nofollow ugc">https://boost.flashbots.net/</a></p>
<p><strong>[PBS]</strong> Ethereum Foundation, <em>Proposer-builder separation</em>, <a class="inline-onebox" href="https://ethereum.org/en/roadmap/pbs/" rel="noopener nofollow ugc">Proposer-builder separation | ethereum.org</a></p>
<p><strong>[RGGM]</strong> Geoffrey Ramseyer, Mohak Goyal, Ashish Goel, David Mazières,</p>
<p><em>Augmenting Batch Exchanges with Constant Function Market Makers</em>, <a class="inline-onebox" href="https://arxiv.org/abs/2210.04929" rel="noopener nofollow ugc">[2210.04929] Augmenting Batch Exchanges with Constant Function Market Makers</a></p>
<p><strong>[SPEEDEX]</strong> Geoffrey Ramseyer, Ashish Goel, and David Mazières, <em>SPEEDEX: A Scalable, Parallelizable, and Economically Efficient Decentralized EXchange</em>, <a href="https://www.usenix.org/conference/nsdi23/presentation/ramseyer" rel="noopener nofollow ugc">https://www.usenix.org/conference/nsdi23/presentation/ramseyer</a>, <a class="inline-onebox" href="https://stellar.org/blog/developers/building-speedex-a-novel-design-for-decentralized-exchanges" rel="noopener nofollow ugc">Stellar | Building SPEEDEX – A Novel Design for a Scalable Decentralized Exchange</a></p>
<p><strong>[UNIX]</strong> Hayden Adams, Noah Zinsmeister, Mark Toda, Emily Williams, Xin Wan, Matteo Leibowitz, Will Pote, Allen Lin, Eric Zhong, Zhiyuan Yang, Riley Campbell, Alex Karys, Dan Robinson, <em>UniswapX</em> <a href="https://uniswap.org/whitepaper-uniswapx.pdf" rel="noopener nofollow ugc">https://uniswap.org/whitepaper-uniswapx.pdf</a></p>
<p><strong>[WLVR]</strong> Cow DAO, <em>What is Loss-Versus-Rebalancing (LVR)?</em>, <a class="inline-onebox" href="https://cow.fi/learn/what-is-loss-versus-rebalancing-lvr" rel="noopener nofollow ugc">What is Loss-Versus-Rebalancing (LVR)? - CoW DAO</a></p>
<hr class="footnotes-sep" />

<ol class="footnotes-list">
<li class="footnote-item" id="footnote-49420-1"><p>Though the origin of the name MEV and its systematic study started at <a href="https://ethresear.ch#references">[FB2]</a>. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-1">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-2"><p>An example of a scenario close to this ideal is to allow a small trade fee that is sublinear in the traded amount. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-2">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-3"><p>The same general approach can be found in <a href="https://ethresear.ch#references">[CF]</a>, as is apparent from the title. However the concrete mechanism described there is different from the one proposed here. Additionally, <a href="https://ethresear.ch#references">[RGGM]</a> studies uniform price batches where AMMs swap at the prices of the batch. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-3">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-4"><p>This can be implemented without calling ERC20 approvals between contracts. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-4">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-49420-5"><p>Most of the extracted MEV is being distributed through MEV-BOOST. See some numbers at <a href="https://mevboost.pics/" rel="noopener nofollow ugc">https://mevboost.pics/</a> and <a href="https://eigenphi.io/" rel="noopener nofollow ugc">https://eigenphi.io/</a>. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-49420-5">↩︎</a></p>
</li>
</ol>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/affiliated-amms-and-permissionless-solving-for-uniform-price-batch-auctions/20187">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 31 Jul 2024 22:17:33 +0000</pubDate>
</item>
<item>
<title>Ethereum + Industry of Integrations (IOI)</title>
<link>https://ethresear.ch/t/ethereum-industry-of-integrations-ioi/20167</link>
<guid>https://ethresear.ch/t/ethereum-industry-of-integrations-ioi/20167</guid>
<content:encoded><![CDATA[
<div> 关键词：IPSME、IOI、Ethereum、智能合约、集成

文章主要探讨了通过将集成系统（Integration of Integrations, IOI）概念应用于以太坊（Ethereum）网络的可能性。以下是文章的主要要点总结：

1. **IPSME与IOI**：IPSME是一种由社区开发的集成系统演进架构，而IOI则提出，只要两个系统的接口（APIs）已知且可访问，就能通过特定方式创建翻译来实现集成，并且这种集成可以商业化。

2. **以太坊与智能合约**：文章指出，以太坊已经支持发布/订阅（Pub/Sub）机制，这是实现IOI概念的基础。通过将集成逻辑封装为智能合约，可以在以太坊上创建可重用的集成，从而可能实现原开发者对集成的商业化。

3. **去中心化集成**：通过将集成作为智能合约执行，可以减少与外部系统集成的复杂性，特别是通过传递性（transitivity），即如果A与B集成，B与C集成，那么理论上A可以直接与C集成，减少了对中心化或去中心化Oracle服务的需求。

4. **智能合约的潜力**：文章讨论了智能合约在协议通信中的强大能力，认为它们不仅能够实现自动化集成，还能够在无需信任第三方的情况下确保数据的一致性和完整性。

5. **对Oracle服务的影响**：通过智能合约实现的集成，理论上可以降低对依赖Oracle服务的需求，因为智能合约能够提供一种更直接、更安全的方式来获取和处理外部数据。

总结：将集成系统（如IPSME定义的IOI）概念应用到以太坊网络中，通过利用智能合约实现集成，不仅能够简化与外部系统的集成过程，提高效率，同时还能通过集成的可重用性和潜在的商业化途径，降低对传统Oracle服务的依赖，实现更加去中心化、安全和高效的集成解决方案。 <div>
<p>(This is my first post here, so I hope that I have not missed any protocol)</p>
<p>I’ve been integrating systems using IPSME, which lead to the Industry of Integrations concept <a href="https://root-interface.se/IOI" rel="noopener nofollow ugc">IOI</a>. IPSME defines an evolutionary architecture for integrations developed by the community.</p>
<p>Demos of my work can be found here:<br />
            
</p>
<p>The concept of the IOI is such that: if any two system interfaces (APIs) are known and accessible, that (via the conventions of <a href="https://ipsme.dev" rel="noopener nofollow ugc">IPSME</a>) a translation can be created integrating the two APIs …​ And! That that translation can be monetized.</p>
<p>The Ethereum blockchain is often linked to Oracles or Oracles services that are off-chain. AFAIK, Ethereum already support a pubsub (the basis for IPSME). The question is then if an IOI can be created within the Ethereum network. Namely, can integrations to external services be smart contracts so that integrations are on-chain and are re-usable by other developers. Is it possible that smart contract integration contains the logic so that the original developer can possibly monetize off building the integration. If the integrations can be reused, then the complexity for integrating with external systems can be reduced through the property of transitivity i.e., if A integrates with B and B with C, then A is integrated with C.</p>
<p>I’m interested in doing exploratory research to see if IOI can be applied to Web3. I would like to ask here:</p>
<ul>
<li>Does this idea sound feasible with the Ethereum network?</li>
<li>Are smart contacts powerful enough for protocol communication?</li>
<li>Is it correct that Ethereum supports pubsub and can it be utilized for this?</li>
<li>Would this idea alleviate the need for Oracle services/networks?</li>
</ul>
<p>I’m looking forward to your feedback.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/ethereum-industry-of-integrations-ioi/20167">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 28 Jul 2024 19:52:10 +0000</pubDate>
</item>
<item>
<title>ePBS Metagame: SSP peacekeeping and alternative public service</title>
<link>https://ethresear.ch/t/epbs-metagame-ssp-peacekeeping-and-alternative-public-service/20162</link>
<guid>https://ethresear.ch/t/epbs-metagame-ssp-peacekeeping-and-alternative-public-service/20162</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Burn、公共利益建设者(PGB)、有机建设者、SSP、社会层

总结:文章深入探讨了MEV-Burn背景下公共利益建设者(PGB)的策略和影响。首先，介绍了五种潜在的MEV-Burn参与者类型，其中重点分析了公共利益建设者与有机建设者的角色及其动机。公共利益建设者通过高燃烧率或排除有害行为为网络做出贡献，而有机建设者则侧重于维护网络的纯净与实用价值。文章还提出了一种可能的提名机制，即验证者在考虑其声誉和社会信誉的同时选择PGB进行区块构建。

其次，文章通过案例研究探讨了SSP如何通过竞标和恶意攻击来维持其市场地位，以及PGB如何通过减少燃烧率和包括所有MEV（包括有害的）来实现盈利并促进网络改进。这表明PGB可以通过牺牲部分利润来增加其被选中构建区块的机会，从而提高其效率并提升社会信誉。

最后，文章强调了MEV-Burn的社会影响，包括可能形成的利益集团和网络中的动态变化。尽管存在潜在的负面影响，但文章认为有道德的建设者和验证者将找到方法来抵消不法行为，并保持网络的平衡与健康。文章呼吁继续对这一领域进行深入研究，以全面理解MEV-Burn带来的复杂社会影响。 <div>
<h3><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a><strong>Introduction</strong></h3>
<p>Alongside Enshrined Proposer-Builder Separation, MEV-Burn is expected to produce a major shift in many on-chain economic and social dynamics. From reducing rugpool incentives to making ReOrg’s even less profitable, this rollout is sure to provide some tangible improvements to the Ethereum protocol, but what seems to get all too frequently overlooked is the on-chain behavioral impact.</p>
<p>If you haven’t already, I would <em>strongly</em> recommend taking a peek at both <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">how i learned to stop worrying and love mev-burn</a> by <a href="https://ethresear.ch/u/mikeneuder">Mike Neuder</a>, and <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Burn incentives in MEV pricing auctions</a> by <a href="https://ethresear.ch/u/aelowsson">aelowsson</a> as they both inspired me to write this piece and may help decipher some of the more technical details.</p>
<p>As stated in <a href="https://ethresear.ch/u/aelowsson">aelowsson</a>’s <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Burn incentives in MEV pricing auctions</a> there are five types of potential MEV-Burners within pricing auctions:</p>
<aside class="quote no-group">
<div class="title">
<div class="quote-controls"></div>
<img alt="" class="avatar" height="24" src="https://ethresear.ch/user_avatar/ethresear.ch/aelowsson/48/7611_2.png" width="24" /><a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856/1">Burn incentives in MEV pricing auctions</a></div>
<blockquote>
<p>(A) Public good builder, (B) For-profit public good builder, (C) Extortion racket, (D) Staker-initiated griefing, (E) Staker-initiated griefing cartel.</p>
</blockquote>
</aside>
<h3><a class="anchor" href="https://ethresear.ch#pgb-overview-2" name="pgb-overview-2"></a><strong>PGB Overview</strong></h3>
<p>Narrowing in on the Public Goods division, there are several ways to be considered a Public Goods Builder; one being burn rates. Simply put, the more profits a builder dedicates to burning, the more ‘ultrasound’ Ethereum gets, the more deflationary Ether is, and ultimately, the more service is done to the public. This could be a strategy chosen over a For-Profit Builder if the operator determines that the potential social credit outweighs the mere profit a For-Profit Builder would contribute. Once again this motivation would apply to another type of Public Good Builder, an ‘Organic’ Builder. Instead of contributing high burn rates, this builder would rather exclude toxic MEV such as Sandwitching or even swear off censorship, creating a stronger Ethereum protocol rather than just making Ether more economically plausible. Both would be critical to maintaining the integrity and utility of Ethereum, and both can be used in harmony or to different degrees.</p>
<p>In order for a PGB to be nominated to build a block, both a validator would need to value its reputation/social credit over its slot profit and a builder would go through the trouble to construct a public service block. Due to the random nature of POS, even if a validator were to choose a PGB for its block construction it would <em>not</em> experience a epoch-over-epoch profit increase, but a builder may. This is touched on later, but the social credit a PGB acquires could bring in more <em>business</em> while the randomness of validation ensures that a validator would not.</p>
<p>Some of these public service examples have already been theorized, and many tend to restrict public good opportunities to <em>just</em> these examples. If you take anything away from this article, know that this ePBS social layer may be more dynamic than many predict it to be.</p>
<h3><a class="anchor" href="https://ethresear.ch#case-study-3" name="case-study-3"></a><strong>Case Study</strong></h3>
<p>When choosing a block builder, validators have a choice; a choice of image; a choice of profit; and ultimately a choice that will contribute to the ePBS social layer. Once again, public service can be attractive to many builders still establishing their image. Potential for this public service can be found even in the ePBS vulnerability of Staker-initiated griefing. (theorized by <a href="https://ethresear.ch/u/aelowsson">aelowsson</a>) Simply put, SSPs will do anything to remain the most profitable staking model, even if they need to sabotage or grief competing validators. By outbidding other builders, SSP-sponsored builders can achieve the slot held by an opposing validator and tank opposing SSP rewards. This then reduces the average user rewards for competing SSPs and drives users (and fees) to their own platform. One example of alternative public service resides within SSP peacekeeping. By reducing burn rates and including all MEV (including toxic) a for-profit model can be derived. Using liquidity developed via this method can then be used to outbid suspected SSP griefers or even direct bidding aggression at any SSP-sponsored builder, further enforcing ePBS and preventing large validators and builders from being run together again. However, looking past technical difficulties such as identifying SSP builders, this method also proves to be inefficient, as it offers minimal public credit, due to the fact it leverages harmful building practices to enforce SSP unity.</p>
<h3><a class="anchor" href="https://ethresear.ch#pgb-efficiency-4" name="pgb-efficiency-4"></a><strong>PGB Efficiency</strong></h3>
<p>The efficiency of a public goods builder or PGB is multidimensional, to say the least. Two sections I’ll touch on are popularity efficiency and network improvement-based efficiency.</p>
<p>PBE or Population-Based Efficiency is the simpler of the two and can be represented by the following equation:</p>
<div class="math">
E = \frac{pq}{ra}
</div>
<p>This equation combines a popularity index (<span class="math">\frac{q}{a}</span>) and a profit margin (<span class="math">\frac{p}{r}</span>); where <span class="math">E</span> is relative efficiency, <span class="math">p</span> is average slot profits, <span class="math">q</span> is average builder pick rate, <span class="math">r</span> is average slot revenue and a is average builder pick rate.</p>
<p>This equation represents the efficiency of a PGB’s ‘social marketing’. By sacrificing some slot profit a PGB can increase its pick rates and potentially increase its epoch-over-epoch profit or even just control more of the builder market. <em>Of course, all the while serving the Ethereum public.</em></p>
<p>Another form of efficiency modeling is NIBE or Network Improvement Based Efficiency. This model bases the efficiency of a PGB on its actual public service. However, the idea is harder to put an equation behind, as each public service action contributes varying improvements to the network and each have their own relative values.</p>
<h3><a class="anchor" href="https://ethresear.ch#the-social-layer-5" name="the-social-layer-5"></a><strong>The Social Layer</strong></h3>
<p>As ePBS rolls out and additional features like MEV burn hit the network, it’s clear that countless social impacts will arise. From SSP sabotage to even the PGB social dynamic, there are many opportunities for cliques, groups, and cartels to form. However, no matter what social problems may arise, any reputable builder will find a way to negate any nefarious builder patterns, and any reputable validators will find a way to support any honest builders. Ultimately, the idea of social credibility and the value of PGB’s may balance the many Immiscible groups that are predicted to form after the introduction of ePBS and MEV burn.</p>
<p>Concluding this paper I would like to, once again, thank both <a href="https://ethresear.ch/u/aelowsson">aelowsson</a> and <a href="https://ethresear.ch/u/mikeneuder">Mike Neuder</a> for their wonderful research on MEV burn and pricing auctions respectively. Between PGB dynamics and ePBS metagame, there’s so much more to uncover in this field, so I would like to end by wrapping up this research on PGB dynamics and the resulting social layer by reminding everyone that there is still a world of research to be done.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/epbs-metagame-ssp-peacekeeping-and-alternative-public-service/20162">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 27 Jul 2024 18:47:18 +0000</pubDate>
</item>
<item>
<title>Rollup-Centric Considerations of Based Preconfimations</title>
<link>https://ethresear.ch/t/rollup-centric-considerations-of-based-preconfimations/20160</link>
<guid>https://ethresear.ch/t/rollup-centric-considerations-of-based-preconfimations/20160</guid>
<content:encoded><![CDATA[
<div> 关键词：基于链、预确认、盈利性、时间性、领导者选举

总结:
本文详细阐述了基于链（Taiko链）的构建与优化策略。首先，文章介绍了基于链的基本架构，包括去中心化提案者同步至L2内存池，以及如何通过预确认机制来提升盈利性和时间效率。预确认允许节点周期性地对较小的序列化批次进行确认，从而减少数据发布成本，并通过设置预确认间隔T来确保L2块的定期发布。

接着，文章讨论了数据发布问题，当前Taiko链采用将所有编码的L2交易列表打包成blob的方式，这导致提案者需要支付整个blob的L1 Gas费用，降低了块的盈利能力。Gwyneth引入预确认后，可以实现更高效的数据打包和发布，通过预确认者批量提交块到L1，同时分离了序列化承诺和数据可用性。

文章还分析了预确认带来的非确定性提案问题，即多个预确认者并行构建链会导致链的非确定性。为解决这一问题，文章提出领导者选举作为解决方案之一，以确保在任何给定时间点只有一个节点有权限更新链的状态。领导者选举有助于维护链的确定性和安全性，同时不影响其基础特性。

最后，文章强调了基于链在继承L1安全性和最终性的同时，面临的一些实际挑战，如提案者的盈利性、链启动时的活力建设以及块时间配置。通过预确认机制的优化，基于链可以在不牺牲安全性和最终性的情况下，提供快速的交易确认时间和高效的盈利能力，从而接近理论上可能达到的最大去中心化水平。

综上所述，本文围绕基于链的构建、预确认机制的实施、非确定性提案的解决方案以及面对的实际挑战，提供了一套全面的优化策略，旨在提升基于链的性能和用户体验，同时保证系统的安全性和稳定性。 <div>
<p><em>Special thanks to <a href="https://x.com/Brechtpd" rel="noopener nofollow ugc">Brecht Devos</a>, <a href="https://twitter.com/linoscope" rel="noopener nofollow ugc">Lin Oshitani</a>, <a href="https://twitter.com/ConorMcMenamin9" rel="noopener nofollow ugc">Conor McMenamin</a>, <a href="https://medium.com/@jonas.bostoen" rel="noopener nofollow ugc">Jonas Bostoen</a>, <a href="https://twitter.com/ccpamatt" rel="noopener nofollow ugc">Christian Matt</a> for the reviews <img alt=":tada:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/tada.png?v=12" title=":tada:" width="20" /></em></p>
<p>TLDR;<br />
This article presents <a href="https://x.com/gwyneth_taiko" rel="noopener nofollow ugc">Gwyneth</a> from the <a href="https://x.com/taikoxyz" rel="noopener nofollow ugc">Taiko Labs</a>.  We outline the Taiko chain setup, discuss the profitability and timeliness of L2 block building, and explore how implementations of preconfirmations can configure blocktime and more efficient data publishing. We also address the issue of nondeterministic proposals caused by multiple preconfirmers through leader election, which affect UX for builders and users. The designs in this article are subject to change.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-the-simplest-taiko-chain-1" name="background-the-simplest-taiko-chain-1"></a>Background: The Simplest Taiko Chain</h2>
<p>At present, Taiko Labs is subsidizing block production by running proposers, effectively burning ETH to maintain a fast and inexpensive network. With that in mind, our effort on preconfirmations needs to be expedited, as we aim to facilitate profitable block building in the community without compromising security and throughput. This is the basic setup of the Taiko chain:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/1/f196c6e6be939ac54173b7e6802df9776c2728b6.png" title="Untitled (4)"><img alt="Untitled (4)" height="294" src="https://ethresear.ch/uploads/default/optimized/3X/f/1/f196c6e6be939ac54173b7e6802df9776c2728b6_2_517x294.png" width="517" /></a></div><p></p>
<ul>
<li>
<p>Decentralized proposers run their <a href="https://docs.taiko.xyz/core-concepts/taiko-nodes/" rel="noopener nofollow ugc">taiko-geth</a> to sync with the L2 mempool.</p>
</li>
<li>
<p>When a batch of Tx constitutes a <strong>profitable block</strong>, the rational proposer <a href="https://github.com/taikoxyz/taiko-mono/blob/b89e97b1cd7795753bba57b8ca6caf8a77e22613/packages/protocol/contracts/L1/ITaikoL1.sol#L14" rel="noopener nofollow ugc">submits this block</a> to L1.</p>
<ul>
<li>The profitable criteria is the total tip collected from all Tx plus their MEV covers the costs to interact with L1 and prover:<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/6/261274c74370de26d6ec593f649377533be6ea83.png" title="Screen Shot 2024-07-05 at 12.54.04 PM"><img alt="Screen Shot 2024-07-05 at 12.54.04 PM" height="50" src="https://ethresear.ch/uploads/default/optimized/3X/2/6/261274c74370de26d6ec593f649377533be6ea83_2_690x50.png" width="690" /></a></div></li>
</ul>
</li>
<li>
<p>Taiko smart contract on L1 contains the decentralized ledger of L2 Tx batches. These batches will, inevitably, contain invalid Tx with vanilla proposing strategy, since the sequencing is not coordinated. For example:</p>
<ul>
<li>L2-75 has a Tx transferring 100 ETH from Alice to Bob without Alice’s correct signature</li>
<li>L2-76 and 77 both contain a Tx from Cassy with nonce equaling 9;</li>
</ul>
<p>In such cases,  <a href="https://github.com/taikoxyz/taiko-mono/tree/ec6c179967b9ac93cd967ff3a1fe8b331fdb8256/packages/taiko-client" rel="noopener nofollow ugc">taiko-client</a>, similar to Ethereum’s consensus client, will witness the invalid Txs from the L1 ledger and exclude them from the actual block being synced to L2.</p>
</li>
<li>
<p>Back to L2, each <a href="https://github.com/taikoxyz/taiko-mono/tree/ec6c179967b9ac93cd967ff3a1fe8b331fdb8256/packages/taiko-client" rel="noopener nofollow ugc">taiko-client</a> (fork of Ethereum’s consensus client), witnesses the L1 ledger and applies a deterministic rule that invalidates the above Txs. Subsequently, the client can form a correct batch constituting the next block and construct the blockhash.</p>
</li>
<li>
<p>This blockhash is considered finalized when a prover submits proof of the execution of valid Txs, as well as the exclusion of invalid Txs from the state of the ledger.</p>
</li>
</ul>
<p>As Vitalik noted, a based rollup can be a <a href="https://vitalik.eth.limo/general/2021/01/05/rollup.html" rel="noopener nofollow ugc">“total anarchy”</a> amid the chaos, but it remains functional as long as the decentralized ledger persists and the L2 network maintains synchronization. Taiko will continue to progress by inheriting <strong>L1 security and finality</strong>. However, proposers may still encounter challenges, resulting in a <strong>liveness</strong> issue due to lack of profitability.</p>
<h2><a class="anchor" href="https://ethresear.ch#challenges-and-solutions-2" name="challenges-and-solutions-2"></a>Challenges and Solutions</h2>
<h3><a class="anchor" href="https://ethresear.ch#profitability-timing-game-in-l2-block-building-3" name="profitability-timing-game-in-l2-block-building-3"></a>Profitability &amp; Timing Game in L2 Block Building</h3>
<p>In the diagram below proposer Alice observes L2-75 upon confirming L1-100, and she creates L2-76 with blockhash 0xabc. Proposer Bob, attempting the same, causes a fork with an alternate blockhash 0xf3c. Both submit proposals to L1-100 and pay the current L1 transaction fee. However, since Alice’s transactions were incorporated first, Bob’s transaction reverts due to L1_UNEXPECTED_PARENT(), causing Bob to lose his proposing fee. Alice successfully earns the tip and MEV of L2-76, but she still needs to compensate the prover to validate her block afterward.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/8/c8a72e51d5473fb6e20d1824d69e4a3baf4c6921.png" title="Untitled (5)"><img alt="Untitled (5)" height="303" src="https://ethresear.ch/uploads/default/optimized/3X/c/8/c8a72e51d5473fb6e20d1824d69e4a3baf4c6921_2_517x303.png" width="517" /></a></div><p></p>
<p>An L2 block is proposed to the rollup Contract as a raw transaction batch. Consequently, each node subscribing to the event derives the blockhash in their own execution clients. Despite this, the <strong>rollup state is finalized when the proposal is confirmed on L1 because block hash derivation is deterministic.</strong> We still need a proof to validate the block hash to rollup’s L1 ledger, enabling light clients to fetch the states and users to perform withdrawals. Hence, real-time proving solutions such as SGX are important because they enforce L2 state finality with high probability. Let’s recall:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/6/261274c74370de26d6ec593f649377533be6ea83.png" title="Screen Shot 2024-07-05 at 12.54.04 PM"><img alt="Screen Shot 2024-07-05 at 12.54.04 PM" height="50" src="https://ethresear.ch/uploads/default/optimized/3X/2/6/261274c74370de26d6ec593f649377533be6ea83_2_690x50.png" width="690" /></a></div><p></p>
<p>Solving for MEV is a knapsack problem - the larger the knapsack, the more value extracted. It’s been well-studied that L1 proposers will play <a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612">the timing game</a> to extend the MEV solving window as much as possible; the same logics apply to L2. Even worse, because L2 users typically tip much lower in an ecosystem with significantly less liquidity, the current 12s block time on Taiko is far less than enough for anyone to profit, which results in a <strong>liveness issue for decentralized proposing</strong>. This is why Taiko Labs operates an unprofitable proposer to sustain the 12s block time. Without taking measures, the L2 blocktime would be arbitrarily long if rational proposers play the timing game.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/e/9ea87c99a3e43e4879c1d6de369b3bb71d885276.png" title="Untitled (6)"><img alt="Untitled (6)" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/9/e/9ea87c99a3e43e4879c1d6de369b3bb71d885276_2_495x375.png" width="495" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#solving-blocktime-data-publishing-with-preconfirmations-4" name="solving-blocktime-data-publishing-with-preconfirmations-4"></a>Solving Blocktime &amp; Data Publishing with Preconfirmations</h3>
<p>Essentially, we’re facing a conflict in a <strong>UX property of L2 (blocktime) versus decentralized block building</strong>. In centralized L2, timeliness is easily managed by the centralized sequencer, while on L1, the beacon attestation enforces the time to publish the execution payload. Thus, we observe that timeliness must be enforced by some mechanism other than builders in the game. Whoever facilitates preconfirmations could also mandate blocktime.</p>
<p><strong>A preconfirmer can periodically issue preconfirmations to builders for smaller sequenced batches, then batch publish the batches to reduce the data publishing costs.</strong> The periodic issuance of batches now constitutes L2 blocks. The L2 protocol, which allows the preconfirmer to opt in, can facilitate timeliness by ensuring preconfirmed blocks are released every T second. Now, we define <strong>T as the L2 blocktime</strong>, which can be adjusted faster to improve user experience.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/2/d204bb354780b7e25543312984493e2f719d2f72.png" title="Untitled (7)"><img alt="Untitled (7)" height="387" src="https://ethresear.ch/uploads/default/optimized/3X/d/2/d204bb354780b7e25543312984493e2f719d2f72_2_690x387.png" width="690" /></a></div><p></p>
<p>Regarding data publishing, Taiko currently publishes all encoded L2 transaction lists in blobs. This requires the proposer to cover the L1 gas fee for a whole blob regardless how much data is actually necessary, further reducing the block’s profitability. In Gwyneth, preconfirmations will allow for <strong>more batching of L2 blocks into blobs</strong> if the preconfirmer is assigned multiple L1 slots, which also implies the separation of sequencing commitment and data availability:</p>
<ul>
<li><strong>Preconfirmations Issuance ⇒ commit L2 sequencing</strong></li>
<li><strong>Preconfirmations Delivery ⇒ data publishing to L1</strong></li>
</ul>
<p>Now we can characterize the L1 preconfirmer as the de facto L2 proposer, and the existing decentralized sequencer who submits batches as L2 builders - we just migrate the PBS architecture to L2. Moreover, this L2 PBS mechanism can use a similar pipeline as on L1, because the L2 proposer is exactly an L1 validator who runs something like <a href="https://github.com/flashbots/mev-boost.git" rel="noopener nofollow ugc">MEV-boost</a> with a preconfirmation add-on. The new fee model functions as follows:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7f1262f29380aea940d4c5152693be272949797.png" title="Screen Shot 2024-07-11 at 2.46.47 AM (1)"><img alt="Screen Shot 2024-07-11 at 2.46.47 AM (1)" height="212" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7f1262f29380aea940d4c5152693be272949797_2_460x212.png" width="460" /></a></div><p></p>
<p>For clarification, L2 proposers are the preconfirmers who opt into the Gwyneth protocol to propose L2 blocks, and the preconfrmers are the L1 validators who can issue preconfirmations.</p>
<p><img alt="Screen Shot 2024-07-11 at 2.47.22 AM (1)" height="32" src="https://ethresear.ch/uploads/default/original/3X/f/0/f01ebd831084ad709d4805fe4ff1b83327b3ce73.png" width="372" /></p>
<p>Overall, preconfirmations enable Gwyneth blocks to be built in short and steady intervals by decentralized participants, while not compromising profitability. A deficiency of liveness caused by lacking liquidity on L2 will not jeopardize blocktime; in other words, users can always enjoy fast transaction confirmation. It also provides a clear model for L2 MEV compatible with the existing PBS pipeline.</p>
<h3><a class="anchor" href="https://ethresear.ch#decentralized-block-proposing-with-pbs-5" name="decentralized-block-proposing-with-pbs-5"></a>Decentralized Block Proposing with PBS</h3>
<p>We have discussed how preconfirmation benefits L2 proposers. Now, let’s consider <strong>proposal inclusion</strong> from the perspective of L1 validators.</p>
<p>Initially, we have a distinct group of L2 participants who compete to propose the next L2 batch by calling the <code>ProposeBlock</code> function in the Taiko smart contract. Their proposal transactions with encoded L2 batches are exposed in the public mempool, and L1 validators or builders will choose to include these proposals. Apparently, t<strong>he L1 parties can easily capture the transactions, stealing the L2 tip and MEV when producing the L1 block.</strong> We’re revisiting the PBS playbook. Rollup with permissionless sequencing can implement similar mechanisms to mitigate block stealing.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/1/d17ee918d3b13e915483a110c04c22af49e6fe0e.png" title="Untitled (8)"><img alt="Untitled (8)" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/d/1/d17ee918d3b13e915483a110c04c22af49e6fe0e_2_517x260.png" width="517" /></a></div><p></p>
<p>However, there’s no need for mitigation following the <a href="https://ethresear.ch/t/based-preconfirmations/17353">definition</a> of base rollup:</p>
<blockquote>
<p>A rollup is said to be based, or L1-sequenced, when its sequencing is driven by the base L1.</p>
</blockquote>
<p>In other words, all L2 proposers are L1 validators. Given access to both mempools, a builder can incorporate L2 batches in her L1 bundles, which is by far the most <strong>efficient paradigm for Gwyneth block-building</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68eae50a088bf3c631d1fb23e52d49855f0a0ad5.png" title="Untitled (9)"><img alt="Untitled (9)" height="249" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68eae50a088bf3c631d1fb23e52d49855f0a0ad5_2_517x249.png" width="517" /></a></div><p></p>
<p>Recall also in PBS, validators have a choice to build the block natively without using <a href="https://github.com/flashbots/mev-boost.git" rel="noopener nofollow ugc">MEV-boost</a> connecting to external builders. The L1 validator, who’s also an L2 proposer, can issue consecutive preconfirmations to self-produce L2 blocks until her slot to propose. In this case, we may also omit the separate role of builders, and rewrite the fee model for L2 proposers:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/1291f379205c49d484fda26e97169d2671738cdd.png" title="Screen Shot 2024-07-11 at 2.46.17 AM"><img alt="Screen Shot 2024-07-11 at 2.46.17 AM" height="90" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/1291f379205c49d484fda26e97169d2671738cdd_2_517x90.png" width="517" /></a></div><p></p>
<p>With the inclusion model much simplified, we note that the L1 validator who includes the L2 proposal is the deterministic proposer of L2. Given Taiko’s current 12s blocktime, there is a one-to-one correspondence between each L1 and L2 block, hence the state of the chain at any slot is deterministic.</p>
<h3><a class="anchor" href="https://ethresear.ch#nondeterministic-proposer-and-leader-election-6" name="nondeterministic-proposer-and-leader-election-6"></a>Nondeterministic Proposer and Leader Election</h3>
<p>Now, as we decouple the L1-to-L2 block correspondence with preconfirmation, we argue that <strong>nondeterminism is also introduced because, during the L1 epoch, multiple preconfirmers exist to perform sequencing concurrently.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/2/b24f24e1ef4885e714897d2f95d25f8c1f2582fb.jpeg" title="Untitled (10)"><img alt="Untitled (10)" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/2/b24f24e1ef4885e714897d2f95d25f8c1f2582fb_2_660x500.jpeg" width="660" /></a></div><p></p>
<p>If these preconfirmers are the subset of L2 proposers who produce blocks natively, everyone will start building on top of the latest finalized parent. This continues until the set of preconfirmations is settled, updating the head of the chain. Then, a proposer will restart with the new head and <strong>abandon their local ledger, resulting in previous preconfirmed transactions being reverted upon delivery</strong>. If the proposer does not restart and proposes the local fork with data publishing during their slot, <strong>that proposal will also revert</strong>. In such a case, the L2 will miss a slot to update; users will experience the <strong>chain halting</strong> until the next proposer comes on board. The malfunctioning proposer might be slashed depending on the protocol implementation.</p>
<p>Considering builders in the PBS setting, who can send their sequenced batches to all L2 proposers in the current epoch, <strong>the head of the chain will appear nondeterministic</strong> to them, as all proposers will endorse different forks simultaneously. However, only the next-in-line proposer holds the source of truth, since her ledger will be settled first. <strong>Therefore, a rational builder should request preconfirmation only from the next-in-line proposer</strong>. Nonetheless, the protocol cannot prevent a malicious proposer from forcing his fork proposal through a regular transaction on Ethereum.</p>
<p>There are two possible solutions: 1)  <strong>define the ledger held by the next-in-line proposer as canonical, which yields a leader selection protocol;</strong> 2) disable block proposals at the non-preconfirmed L1 slots, then fork proposals will likely be excluded by a rational next-in-line preconfirmer. The latter solution is sub-optimal because we still want to preserve the option of non-preconfirmed block proposals unless there are enough preconfirmers to achieve our desirable liveness.</p>
<h4><a class="anchor" href="https://ethresear.ch#on-leader-election-7" name="on-leader-election-7"></a>On Leader Election</h4>
<p>In a decentralized setting at anytime, <strong>only one L1 validator should have exclusive write access to the L2 state</strong>, even if all opt-in participants can issue preconfirmations. <strong>Such systems are inherently finalized without any external finality gadget</strong>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/3/23c6258764b5d1c0ec9df8be0a3db5b6cd2132a8.png" title="Untitled (11)"><img alt="Untitled (11)" height="231" src="https://ethresear.ch/uploads/default/optimized/3X/2/3/23c6258764b5d1c0ec9df8be0a3db5b6cd2132a8_2_690x231.png" width="690" /></a></div><p></p>
<p>On the other hand, an L2 builder who’s building the latest Gwyneth chain can only write to preconfirmed L1 block space from the next opt-in validator. Requesting preconfirmations from others is strictly prohibited because that creates a gap in the slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/d/3d2b9b203eda188c0ebc6520cdb249d14b114b14.png" title="Untitled (12)"><img alt="Untitled (12)" height="251" src="https://ethresear.ch/uploads/default/optimized/3X/3/d/3d2b9b203eda188c0ebc6520cdb249d14b114b14_2_690x251.png" width="690" /></a></div><p></p>
<p>Essentially, we create a just-in-time market for exchanging L1/L2 block space. Instead of a JIT auction, Some suggest using <a href="https://ethresear.ch/t/execution-tickets/17944">execution tickets</a> for an ahead-of-time auction, which means in the diagram above, the L1-104 proposer can sell L2-79 block space simultaneously while the L1-102 proposer sells L2-78. This establishes a one-to-one correspondence between L1/L2 slots in a more controlled manner, and since it allows all participants to buy and sell these rights, an ahead-of-time auction aligns better with the preconfirmation market. From the L2 perspective, the protocol’s sale of execution tickets can imply new fee models for value-capturing. <a href="https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837">XGA-style preconfirmations</a> can be a good implementation.</p>
<h2><a class="anchor" href="https://ethresear.ch#summary-8" name="summary-8"></a>Summary</h2>
<p>Taiko started as a rollup with decentralized proposers, with a protocol that deterministically derives L2 state as long as the ledger is finalized on L1. We realized that based sequencing, which unites L1 and L2 proposers, transforms our framework into something more simple and powerfull. Based sequencing will work, naively, with finality and security inherited from L1.</p>
<p>Based sequencing may not work, in practice, considering builder profitability, bootstrapping liveness, and the configuration of fast blocktime. We discuss preconfirmations to tackle these challenges with some tweaks on timeliness and proposal mechanisms. However, having multiple validators who issue preconfirmations can cause the concurrent building of L2 forks. This introduces nondeterminism for the spectators of chains including builders, exchanges, and users, although fortunately, nondeterministic sequencing does not affect finality - <strong>most obstacles in based sequencing relate to essential UX properties for builders and users.</strong></p>
<p>Despite some controversy, leader election could be a practical middle-ground solution. We anticipate a significant number of L1 proposers opting in as preconfirmations gain adoption. Consequently, <strong>proposer decentralization still remains close to the (at least theoretically) maximal achievable decentralization offered by a vanilla based rollup.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/0/40dd31cbef98940c5ba5f843d943f08e9ab8a7e2.png" title="Untitled (13)"><img alt="Untitled (13)" height="339" src="https://ethresear.ch/uploads/default/optimized/3X/4/0/40dd31cbef98940c5ba5f843d943f08e9ab8a7e2_2_690x339.png" width="690" /></a></div><p></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/rollup-centric-considerations-of-based-preconfimations/20160">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 27 Jul 2024 14:41:46 +0000</pubDate>
</item>
<item>
<title>Notes on the LVR of FM-AMM</title>
<link>https://ethresear.ch/t/notes-on-the-lvr-of-fm-amm/20151</link>
<guid>https://ethresear.ch/t/notes-on-the-lvr-of-fm-amm/20151</guid>
<content:encoded><![CDATA[
<div> 关键词：FM-AMM、LVR、CEX-DEX、交易成本、流动性池大小

总结:
本文详细介绍了改进后的自动做市商（FM-AMM）的额外特性，通过找到纯粹策略纳什均衡来解决CEX-DEX套利商之间的博弈问题。文中计算了理论设置下的FM-AMM的渐近LVR，并将其性能与Uniswap V2风格的固定费率CPMM进行了对比。观察结果表明，FM-AMM的性能受到价格波动、交易成本和流动性池规模的影响，在特定条件下，它对套利商的损失较小。

文章首先回顾了LVR在自动做市商领域的重要性及其在减少LVR方面的努力。接着，作者详细阐述了FM-AMM的设计，并通过修改原始设计解决了更广泛情况下的批量交易执行问题。随后，通过建立模型分析了具有固定交易成本和零售订单流不存在条件下的FM-AMM性能，发现其纳什均衡存在并具有对称性，且LVR随参与者数量成反比衰减。进一步地，文章考虑了交易成本由参与者决定的情况，指出FM-AMM的优势取决于跳动大小、频率和成本，而数值模拟显示FM-AMM与基于rollup的解决方案相匹配。

最后，通过对比FM-AMM和CPMM的LVR，文章指出FM-AMM在高波动率、低交易成本和较大流动性池的情况下表现出色。同时，文章讨论了在不同参数下的性能比较，发现FM-AMM在L2环境中以及低交易成本的L1环境中具有优势，这解释了之前研究结果的混杂性。此外，文章还提出了未来研究应考虑更宽松条件以提供更全面评估的建议。

总的来说，本文提供了对FM-AMM在不同市场条件下的性能分析，强调了其在特定场景下的优越性，同时也指出了现有模型的局限性和未来研究方向。 <div>
<h1><a class="anchor" href="https://ethresear.ch#h-0-tldr-1" name="h-0-tldr-1"></a>0. TL;DR</h1>
<p>We introduced and detailed the additional features of FM-AMM, as presented in [CF23]. We modeled the game between CEX-DEX arbitrageurs for arbitrage profit on FM-AMM and then solved it by finding the pure strategy Nash equilibrium. Lastly, we calculated the asymptotic LVR of FM-AMM in theoretical settings and compared its performance against the Uniswap V2-style fixed-rate fee CPMM through numerical simulations. Our observations indicated that the performance is heavily influenced by price volatility, transaction costs, and the size of the liquidity pool, with FM-AMM showing a reduced loss to arbitrageurs under specific conditions.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-1-introduction-2" name="h-1-introduction-2"></a>1. Introduction</h1>
<p>Since LVR was introduced in [MMRZ22] and [MMR23], it has quickly become the standard for measuring the performance of AMMs. Numerous attempts have been made to reduce LVR through dynamic fee policies, and this research continues actively. However, batch trade execution has not received much attention, except in [CF23] and [GGMR22]. In [CF23], the authors proposed a function-maximizing automated market maker (FM-AMM), asserting it effectively eliminates LVR, and provided numerical simulations comparing its performance with various Uniswap V3 pools. They later <a href="https://forum.cow.fi/t/4-months-of-cow-amm-what-we-have-learned-and-the-next-steps/2432" rel="noopener nofollow ugc">claimed</a> that CoW-AMM (their implementation of FM-AMM) performed well in live settings too, which led to <a href="https://x.com/0x94305/status/1813690004331438306" rel="noopener nofollow ugc">debate</a> on Twitter regarding the legitimacy of their measurement methods. Although the debate focused more on whether markout is a useful metric for measuring performance, the existence of retail order flow and fluctuating transaction costs are also obstacles to precisely comparing their performance. In this article, we analyze the performance of FM-AMM and compare it to CPMM under fixed transaction costs and in the absence of retail order flow conditions like those in [N22] and [E24].</p>
<p>In detail, we slightly modified their design and found a Nash equilibrium in a game where arbitrageurs strategically submit orders to the (slightly modified) FM-AMM to maximize their returns. The game is similar to the liquidity provision game introduced in [MC24], which is a special form of the generalized Tullock contest. The resulting equilibrium has many favorable properties: the solution always uniquely exists, and it is symmetric. Moreover, LVR decays inversely proportionally to the number of participants. This model assumes that the number of arbitrageurs, <span class="math">N</span>, is pre-determined and transaction cost, <span class="math">c</span>, is zero. We proceed to a model where the number of participants is determined endogenously according to <span class="math">c</span>. In this setting, FM-AMM is not always superior; the result now depends on jump size, frequency, and cost. We provide numerical simulation results and suggest that FM-AMM fits well with rollup-based solutions.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-2-fm-amm-3" name="h-2-fm-amm-3"></a>2. FM-AMM</h1>
<p>In this section we fill the omitted details of FM-AMM introduced in [CF23] to handle the more general case. The underlying AMM curve introduced in [CF23] is:</p>
<div class="math">
y_\text{out} = \frac{x_\text{in}}{X + 2x_\text{in}}Y,
</div>
<p>where <span class="math">x_\text{in}</span> is the amount of token <span class="math">X</span> the trader is willing to sell, and <span class="math">y_\text{in}</span> is the amount of token <span class="math">Y</span> that she will receive. However, this is the simplest case where only a single side of order is submitted in batch. Authors of original paper handled the case such that both side of orders exist in the same batch by assuming users only specify the amount of token X to buy or sell. Unfortunately, this is hard to implement in fully on-chain manner since whether the trader has enough capital to buy specified amount of token X is not guaranteed before the batch is settled (Selling is not problematic; we can pull the token from trader and keep it by settlement). We generalize the formula to handle broader range of cases. Let <span class="math">X, Y</span> be reserves of pool, <span class="math">T</span> be total supply of LP tokens before batch settlement, <span class="math">x_\text{in}, y_\text{in}</span> be aggregate amount of each token that traders are willing to sell, and <span class="math">x_\text{mint}, y_\text{mint}</span> be aggregate amount of each token provided from LPs. The fundamental equation we will start with is:</p>
<div class="math">
\begin{align}\begin{bmatrix}x_{\text{mint}} \\y_{\text{mint}}\end{bmatrix}&amp;=x_{\text{mint}} \begin{bmatrix}1 \\p\end{bmatrix}+\begin{bmatrix}0 \\2\alpha\end{bmatrix}\\\begin{bmatrix}x_{\text{in}} \\y_{\text{in}}\end{bmatrix}&amp;=x_{\text{in}} \begin{bmatrix}1 \\p\end{bmatrix}+\begin{bmatrix}0 \\\beta\end{bmatrix}\\\begin{bmatrix}x_1 \\y_1\end{bmatrix}&amp;=\begin{bmatrix}x_0 \cdot \frac{y_0 + \alpha + \beta}{y_0 + 2(\alpha + \beta)} \\y_0 + \alpha + \beta\end{bmatrix}\end{align}
</div>
<p>Here, the <span class="math">p</span> is the clearing price, and <span class="math">\alpha, \beta</span> are the net swap amount for swapping and minting, respectively. In short, among the submitted orders, we swap only part of them, <span class="math">\alpha</span> and <span class="math">\beta</span>, then exchange the rest via p2p without changing the spot price. The fact that</p>
<div class="math">
\begin{bmatrix}x_{\text{mint}} \\y_{\text{mint}} - 2\alpha\end{bmatrix}, \begin{bmatrix}x_{\text{in}} \\y_{\text{in}} - \beta\end{bmatrix}, \begin{bmatrix}x_1 \\y_1\end{bmatrix}
</div>
<p>are all parallel gives us following matrix equation:</p>
<div class="math">
\begin{equation}\begin{bmatrix}2x_0 + 2x_{\text{mint}} &amp; 2x_{\text{mint}} \\2x_{\text{in}} &amp; 2x_{\text{in}} + x_0\end{bmatrix}\begin{bmatrix}\alpha \\\beta\end{bmatrix}=\begin{bmatrix}x_0 y_{\text{mint}} - x_{\text{mint}} y_0 \\x_0 y_{\text{in}} - x_{\text{in}} y_0\end{bmatrix}\end{equation}
</div>
<p>Note that the determinant of matrix in LHS is always strictly positive so above equation is not singular. <span class="math">\alpha, \beta</span>  are:</p>
<div class="math">
\begin{align} (\alpha, \beta) = \left( \frac{\frac{x_{0} y_{mint}}{2} + x_{in} y_{mint} - \frac{x_{mint} y_{0}}{2} - x_{mint} y_{in}}{x_{0} + 2 x_{in} + x_{mint}}, \  \frac{x_{0} y_{in} - x_{in} y_{0} - x_{in} y_{mint} + x_{mint} y_{in}}{x_{0} + 2 x_{in} + x_{mint}}\right) \end{align}
</div>
<p>The clearing price, <span class="math">p_c</span>, is:</p>
<div class="math">
\begin{align} 
p_c = \frac{y_{0} + 2 y_{in} + y_{mint}}{x_{0} + 2 x_{in} + x_{mint}}
\end{align}
</div>
<p><span class="math">x_\text{out}, y_\text{out}</span> are:</p>
<div class="math">
\begin{align}
(x_\text{out}, y_\text{out}) &amp;= 
\left( \frac{y_{in} \left(x_{0} + 2 x_{in} + x_{mint}\right)}{y_{0} + 2 y_{in} + y_{mint}}, \  \frac{x_{in} \left(y_{0} + 2 y_{in} + y_{mint}\right)}{x_{0} + 2 x_{in} + x_{mint}}\right) \\
&amp;= \left(\frac{y_\text{in}}{p_c}, p_c x_\text{in} \right) \\
\end{align} 
</div>
<p>It is straight forward to find <span class="math">x_2, y_2</span>, the reserves after minting LP tokens, and <span class="math">t</span>, the newly issued LP token amount, so we would skip on them here.</p>
<p>Above construction charges no fee. To keep price same even after charging fee, we will take <span class="math">1/(1 + \gamma)</span> portion of input and <span class="math">\gamma</span> portion of output as fee. So the effective fee rate will be   <span class="math">\frac{2 \gamma}{1+ \gamma}</span>, which is approximately <span class="math">2 \gamma</span>. Considering arbitrageurs it may better to take fee fully on input, though.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-3-model-4" name="h-3-model-4"></a>3. Model</h1>
<p>In this section, we describe the model upon which our analysis is based. We model a normal form game involving strategic arbitrageurs. This means that each player is unaware of the bids of others, and all bids are submitted simultaneously. Additionally, each player’s bid is never censored. Although this assumption does not perfectly reflect the current state of blockchains, ongoing cryptographic developments and improved market designs, such as inclusion lists, will help bridge the gap between theory and reality. This formulation is almost the same as that of [CM24]; the only difference is that players now “take” mispriced liquidity instead of providing it to the AMM.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-31-automated-market-maker-5" name="h-31-automated-market-maker-5"></a>3.1. Automated Market Maker</h2>
<p>For the AMM, we will use the FM-AMM introduced in Section 2. Note that the AMM itself is not a player; we assume that the LPs of the AMM are passive investors who will not take any action in the short term.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-32-arbitrageurs-6" name="h-32-arbitrageurs-6"></a>3.2. Arbitrageurs</h2>
<p>We assume that all players are homogeneous. They are risk-neutral and can execute trades of any size and in any direction on CEX without any slippage. Their sole goal is to maximize profit.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-33-strategic-game-of-liquidity-taking-7" name="h-33-strategic-game-of-liquidity-taking-7"></a>3.3. Strategic Game of Liquidity Taking</h2>
<p>First, we solve the game with <span class="math">N</span> players where <span class="math">N</span> is given exogenously, without considering transaction costs. Then, we introduce a strictly positive transaction cost <span class="math">c</span> and derive <span class="math">N</span> from the equilibrium condition. We will restrict our interest to conditions with positive trading fees, which guarantees the uniqueness of the equilibrium. Players observe the pool reserves <span class="math">X</span>, <span class="math">Y</span>, and the external true price <span class="math">P</span>. Then, they submit bids <span class="math">(x_i, y_i)</span>, which are the amounts of tokens to sell to the pool. The clearing price will be:</p>
<div class="math">
\begin{align}
P_c = \frac{Y + 2\sum^N_{i=1} y_i }{X + 2\sum^N_{i=1} x_i} \tag{1} \\
\end{align}
</div>
<p>The utility function is the arbitrage profit after charging the swap fee (and transaction cost, if applicable). The utility of player <span class="math">i</span>, <span class="math">U_i</span>, is:</p>
<div class="math">
\begin{align}
R_i = -(1 + \gamma)(P x_i + y_i) + (1 - \gamma)\left(\frac{P}{P_c}y_i + P_c x_i\right) \tag{2}
\end{align}
</div>
<p>Now, we are ready to find the equilibrium.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-4-equilibrium-analysis-8" name="h-4-equilibrium-analysis-8"></a>4. Equilibrium Analysis</h1>
<h2><a class="anchor" href="https://ethresear.ch#h-41-n-is-determined-exogenously-and-transaction-cost-c-is-zero-9" name="h-41-n-is-determined-exogenously-and-transaction-cost-c-is-zero-9"></a>4.1. <span class="math">N</span> is Determined Exogenously, and Transaction Cost <span class="math">c</span> is Zero</h2>
<p>We first introduce the following lemma:</p>
<div class="math">
\text{Lemma. The player } i\text{'s best response is submitting a bid with at least one 0 component, that is, either } (x_i, 0) \text{ or } (0, y_i).
</div>
<p>The proof is straightforward. Assume <span class="math">(x_i, y_i)</span> and <span class="math">(x'_i, y'_i)</span> result in the same clearing price. Then <span class="math">x_i \leq x'_i</span> if and only if <span class="math">y_i \leq y'_i</span>. Combining these and subtracting the utility of one from the other yields the desired result.</p>
<p>Meanwhile, the first order condition and the profitability condition give us that the best response is, when <span class="math">P_{-i}</span> is defined as <span class="math">P_{-i} = \frac{Y + 2\sum^N_{j \neq i} y_j }{X + 2\sum^N_{j \neq i} x_j}</span>, submitting <span class="math">x_i</span> or <span class="math">y_i</span> such that the following holds:</p>
<div class="math">
\begin{align}
P_c = 
\begin{cases} 
\sqrt{\frac{1 - \gamma}{1 + \gamma} P P_{-i}} &amp; \text{if } \frac{1 - \gamma}{1 + \gamma} P \geq P_{-i} \\
\sqrt{\frac{1 + \gamma}{1 - \gamma} P P_{-i}} &amp; \text{if } \frac{1 + \gamma}{1 - \gamma} P \leq P_{-i}
\end{cases}. \tag{3}
\end{align}
</div>
<p>Otherwise, it is better not to submit any order (i.e., bid). One can think of <span class="math">\frac{1+\gamma}{1-\gamma}P_{-i}</span> and <span class="math">\frac{1-\gamma}{1+ \gamma}P_{-i}</span> as the threshold prices such that arbitrage becomes profitable. Note that this holds for every <span class="math">i</span>, so <span class="math">P_{-i} = P_{-j}</span> for every <span class="math">i</span> and <span class="math">j</span>, which tells us the equilibrium is symmetric and always exists.</p>
<p>From now on, we only consider the external price to be sufficiently higher than the pool’s spot price, <span class="math">Y/X</span>. The opposite case can be solved in a similar manner. It is clear that <span class="math">x_\text{eq} = 0</span> for the case we are dealing with. Then, <span class="math">(3)</span> is equivalent to:</p>
<div class="math">
\begin{align}
\frac{Y + 2Ny_\text{eq}}{X} = \sqrt{\frac{1-\gamma}{1+\gamma}P\cdot \frac{Y + 2 (N-1) y_\text{eq}}{X}} \tag{4}
\end{align}
</div>
<p>Solving <span class="math">(4)</span> yields that</p>
<div class="math">
\begin{align}
y_\text{eq} = \frac{1}{4N^2}\left[ (N - 1) \cdot \frac{1-\gamma}{1+\gamma} \cdot PX -2NY +  \sqrt{(N-1)^2 + 4N \cdot \frac{Y}{X} \cdot \frac{1+\gamma}{1-\gamma} \cdot \frac{1}{P}} \cdot \frac{1-\gamma}{1+\gamma}\cdot PX \right] \tag{5}
\end{align}
</div>
<p>From now on, we will proceed with radical approximations due to its complexity. Although we do not provide any rigorous proof for the validity of such approximations, we will see it works well in the simulations later. Let <span class="math">P_0 = \frac{Y}{X}</span> and <span class="math">\varepsilon = \frac{1-\gamma}{1+\gamma} \cdot \frac{P}{P_0} - 1</span>, that is, the price difference between the threshold price and the external price. Approximating <span class="math">y_\text{eq}</span> with <span class="math">\varepsilon</span> through a Taylor series gives us a simpler form:</p>
<div class="math">
\begin{align}
y_\text{eq} &amp;=  \frac{Y}{4N^2}\left[ (N-1) \cdot (1+ \varepsilon) - 2N +(1+\varepsilon)\sqrt{(N-1)^2 +\frac{4N}{1+\varepsilon}}\right] \tag{6} \\
&amp;\approx \frac{Y}{2(N+1)} \varepsilon + o(\varepsilon^2) \tag{7}
\end{align}
</div>
<p>Using <span class="math">(7)</span>, one can compute the profit of individual arbitrageurs and the total loss of the AMM against arbitrageurs:</p>
<div class="math">
\begin{align}
ARB &amp;\approx L\sqrt{P_0}\cdot\left(\frac{1+\gamma}{2(N+1)^2}\right)\cdot\varepsilon^2 \tag{8} \\
LVR &amp;\approx (1+\gamma)\cdot L\sqrt{P_0}\cdot\left(\frac{N}{2(N+1)^2}\right)\cdot\varepsilon^2 \tag{9}
\end{align}
</div>
<p>Thus, assuming the transaction cost is <span class="math">0</span>, for any <span class="math">N</span>, every <span class="math">N</span> arbitrageur will submit identical bids and they will share the profit equally, while each individual arbitrageur’s profit will decay by <span class="math">O(N^{-2})</span>. Moreover, as <span class="math">N </span> goes to infinity the clearing price <span class="math">P_c</span> converges to threshold price, and therefore the stationary distribution of price discrepancy will be as same as that of fixed fee rate CPMM in [MMR23].</p>
<h2><a class="anchor" href="https://ethresear.ch#h-42-transaction-cost-is-not-free-and-the-number-of-arbitrageurs-is-determined-endogenously-10" name="h-42-transaction-cost-is-not-free-and-the-number-of-arbitrageurs-is-determined-endogenously-10"></a>4.2. Transaction Cost is Not Free, and the Number of Arbitrageurs is Determined Endogenously</h2>
<p>Now we extend the model in 4.1 to a more realistic one by adopting a nonzero transaction cost <span class="math">c</span>. The utility function remains the same as in <span class="math">(2)</span>, except we have an additional term <span class="math">-c</span>. Since this term disappears when we take the derivative, the best response remains the same as long as it is profitable. Thus, the solution is not much different from <span class="math">(7)</span>, except <span class="math">N</span> is replaced with <span class="math">N^{*}</span>, where <span class="math">N^{*}</span> is the largest integer that satisfies <span class="math">L\sqrt{P_0}\cdot\left(\frac{1+\gamma}{2(N^{*}+1)^2}\right)\cdot\varepsilon^2 \geq c</span>. Then, the LVR will be:</p>
<div class="math">
\begin{align}
LVR &amp;\approx (1+\gamma) \cdot  L \sqrt{P_0} \cdot\varepsilon^2 \cdot \frac{N^{*}}{2(N^{*}+1)^2} \tag{10} \\
&amp;\approx cN^{*} \tag{11} \\
&amp;\approx c \left \lfloor \varepsilon\sqrt{\frac{1+\gamma}{2c} \cdot L \sqrt{P_0}}- 1 \right\rfloor \tag{12} \\
&amp;\leq \varepsilon\sqrt{(1+\gamma)2c \cdot L \sqrt{P_0}} \tag{13}
\end{align}
</div>
<h2><a class="anchor" href="https://ethresear.ch#h-43-comparison-with-cpmm-11" name="h-43-comparison-with-cpmm-11"></a>4.3. Comparison with CPMM</h2>
<p>The derivation of the LVR for CPMM has already been studied extensively, so we will simply present the result:</p>
<div class="math">
\begin{align}
LVR_\text{CPMM} \approx \frac{1}{1-\gamma} \cdot L \sqrt{P_0} \cdot \frac{\varepsilon^2}{4}, \tag{14}
\end{align}
</div>
<p>where <span class="math">\gamma</span> is the fee rate taken from the input and <span class="math">\varepsilon</span> is again the price difference between the external price and the threshold price, in this case, <span class="math">\frac{P_0}{1-\gamma}</span>. In short, the LVR of CPMM grows faster than that of FM-AMM as <span class="math">\varepsilon</span> (the price difference) and <span class="math">L\sqrt{P_0}</span> (the initial pool size) grow. From this, we can predict that the performance of FM-AMM will be better in larger pools compared to CPMM.</p>
<p>FM-AMM performance is affected by the transaction cost <span class="math">c</span>, while CPMM is not affected as long as the arbitrageur’s profit is greater than <span class="math">c</span>. This implies that FM-AMM suits well with rollup settings that have longer block times (resulting in higher volatility between blocks) and low transaction costs.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-5-simulations-12" name="h-5-simulations-12"></a>5. Simulations</h1>
<p>Due to the nonzero transaction cost, finding an analytic solution for instantaneous LVR or the stationary distribution of price discrepancy is no longer straightforward. Therefore, we proceed with numerical simulations. You can check the code used <a href="https://github.com/kosunghun317/FMAMM_LVR/tree/main/notebooks" rel="noopener nofollow ugc">here</a>. This code is largely copy-pasted with minor tweaks from <a href="https://github.com/alexnezlobin/simulations/tree/main" rel="noopener nofollow ugc">this source</a>. Swap fees are fixed at 0.3% across all simulations (i.e., <span class="math">\gamma_\text{FMAMM} = 0.0015</span>, <span class="math">\gamma_\text{CPMM} = 0.003</span>).</p>
<h2><a class="anchor" href="https://ethresear.ch#h-51-distribution-of-lvr-13" name="h-51-distribution-of-lvr-13"></a>5.1. Distribution of LVR</h2>
<p>In this section, we observe the distribution of LVR under several cases without iterating over many parameters. Note that the variance is always greater in FM-AMM; this is because the price is not corrected perfectly under the nonzero transaction cost condition.</p>
<p>The conditions of the first case are L1 (12-second block time), $10 transaction cost, with 5% daily volatility and $100M pool size.<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/1/0/101edc5f8de31543cda7c084f2d7e98e3e522ebf.png" width="604" /></p>
<p>The second is L1, $10 transaction cost, with 10% volatility and $100M pool size.<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/a/4/a49fb0096777435725991cf46954abd43c9a26a8.png" width="597" /><br />
As predicted, FM-AMM outperforms CPMM as volatility increases.</p>
<p>Next one is L1 with congestion; transaction cost went up to $30.<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/f/3/f3a2fc79c45044e5ef9c61b01a5ae50b913299d7.png" width="597" /><br />
This fits to our prediction well, too. As tx cost increases FM-AMM loses more than CPMM.</p>
<p>The last result is L1 with congestion, but with smaller liquidity ($10M).<br />
<img alt="image" height="450" src="https://ethresear.ch/uploads/default/original/3X/f/8/f82923769edf0a3f8df22d9c2327ee0473eae369.png" width="597" /><br />
This result is a bit contradictory to our initial guess: usually, smaller liquidity conditions are more favorable to CPMM, as LVR per pool value of FM-AMM increases as the pool value gets smaller. To clarify this, we will run simulations over various parameters and compare the performances.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-52-performance-comparisons-14" name="h-52-performance-comparisons-14"></a>5.2. Performance Comparisons</h2>
<p>Below are the numerical simulations of LVR for CPMM and FM-AMM under various parameters. Swap fees are set at 0.3% for both of them. Blue regions indicate where CPMM performs better, while grey regions indicate where FM-AMM performs better. Note that the results in the low volatility and high-cost regions are not as reliable due to the very few trades occurring in these conditions.</p>
<p>First is the cases for L1:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/f/3f4b7c4f8afa28b742eb494cce687ca245b9ded3.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/3/f/3f4b7c4f8afa28b742eb494cce687ca245b9ded3_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/c/2c339052835747c3057c1c6d6b4456033db13814.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/2/c/2c339052835747c3057c1c6d6b4456033db13814_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/1/21678b78eb6b694ff0938209d8de97d84a713df9.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/2/1/21678b78eb6b694ff0938209d8de97d84a713df9_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/b/7b8453c6492353e30665d40174ad349c53cc73da.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/7/b/7b8453c6492353e30665d40174ad349c53cc73da_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/a/ba04ccc1440d5207217bb4056c6d9cc2e2d03291.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/b/a/ba04ccc1440d5207217bb4056c6d9cc2e2d03291_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/f/cf2266ce32541a90a009ee96c05f24714ebf7da6.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/c/f/cf2266ce32541a90a009ee96c05f24714ebf7da6_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/a/daec56f47b5ff0e9cfe26e087f4588f0ce99ebe5.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/d/a/daec56f47b5ff0e9cfe26e087f4588f0ce99ebe5_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f7211259a315e71a052cac3a52055de1eabbda8.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f7211259a315e71a052cac3a52055de1eabbda8_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc23d7506e2cc23e5b29ae96faee7ed609588d70.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc23d7506e2cc23e5b29ae96faee7ed609588d70_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/2/a2153b4ce8fb4ee42360ccff33df0b311aa457e4.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/a/2/a2153b4ce8fb4ee42360ccff33df0b311aa457e4_2_690x196.png" width="690" /></a></div><p></p>
<p>Following are the special cases for based rollup (tx cost = $0.05, block time = 12 sec) and typical L2s (tx cost = 0.01, block time = 2 sec), respectively:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e463cf577f86a2492c5fb4e0f15d30284212bf6d.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e463cf577f86a2492c5fb4e0f15d30284212bf6d_2_690x196.png" width="690" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/55c066b2d8b4c15d67d1eb5eb9ad1008d4840ecd.png" title="image"><img alt="image" height="196" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/55c066b2d8b4c15d67d1eb5eb9ad1008d4840ecd_2_690x196.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#h-53-discussion-15" name="h-53-discussion-15"></a>5.3. Discussion</h2>
<p>It is clear that FM-AMM performs better under certain conditions, including L2s and L1 with low transaction costs, and this partially explains why the results in [CF23] was rather mixed and defer by each pair. Due to its nature of forcing competition over price between arbitrageurs, it performs well even in high volatility conditions. Notably, this is achieved without raising the swap fee, which typically results in losing retail order flow. Thus, FM-AMM can lose less to arbitrageurs while not sacrificing retail order flow.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-6-conclusion-16" name="h-6-conclusion-16"></a>6. Conclusion</h1>
<p>As the authors of [CF23] claimed, FM-AMM indeed achieves superior performance under certain conditions, even without raising swap fees. It suits L2s particularly well. However, our analysis is based on several non-realistic assumptions, especially the (short-term) censorship resistance assumption and simultaneous bid submission. Future research will focus on more relaxed conditions to provide a more comprehensive evaluation.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-7-references-17" name="h-7-references-17"></a>7. References</h1>
<p>[MMRZ22] J. Milionis, C. C. Moallemi, T. Roughgarden, and A. L. Zhang. Automated Market Making and Loss-Versus-Rebalancing, <em>arXiv preprint <a href="https://arxiv.org/abs/2208.06046" rel="noopener nofollow ugc">arXiv:2208.06046</a></em>, 2022.<br />
[MMR23] J. Milionis, C. C. Moallemi, and T. Roughgarden. Automated Market Making and Arbitrage Profits in the Presence of Fees, <em>arXiv preprint <a href="https://arxiv.org/abs/2305.14604" rel="noopener nofollow ugc">arXiv:2305.14604</a></em>, 2023.<br />
[GGMR22] G. Ramseyer, M. Goyal, A. Goel, and D. Mazières. Augmenting Batch Exchanges with Constant Function Market Makers, <em>arXiv preprint <a href="https://arxiv.org/abs/2210.04929" rel="noopener nofollow ugc">arXiv:2210.04929</a></em>, 2022.<br />
[CF23] A. Canidio and A. Fritsch. Arbitrageurs’ profits, LVR, and sandwich attacks: batch trading as an AMM design response, <em>arXiv preprint <a href="https://arxiv.org/abs/2307.02074" rel="noopener nofollow ugc">arXiv:2307.02074</a></em>, 2023.<br />
[CM24] D. Crapis and J. Ma. The Cost of Permissionless Liquidity Provision in Automated Market Makers, <em>arXiv preprint <a href="https://arxiv.org/abs/2402.18256" rel="noopener nofollow ugc">arXiv:2402.18256</a></em>, 2024.<br />
[N22] A. Nezlobin. Ethereum Block Times, MEV, and LP returns, <em>Medium article <a href="https://medium.com/@alexnezlobin/ethereum-block-times-mev-and-lp-returns-5c13dc99e80" rel="noopener nofollow ugc">Ethereum Block Times, MEV, and LP returns</a></em>, 2022<br />
[E24] A. Elsts. CEX/DEX arbitrage, transaction fees, block times, and LP profits, <em>Ethresearch Forum article <a href="https://ethresear.ch/t/cex-dex-arbitrage-transaction-fees-block-times-and-lp-profits/19444">CEX/DEX arbitrage, transaction fees, block times, and LP profits</a></em>, 2024</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/notes-on-the-lvr-of-fm-amm/20151">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 26 Jul 2024 06:21:02 +0000</pubDate>
</item>
<item>
<title>A design for APS-burn in the context of a Decentralized L2</title>
<link>https://ethresear.ch/t/a-design-for-aps-burn-in-the-context-of-a-decentralized-l2/20146</link>
<guid>https://ethresear.ch/t/a-design-for-aps-burn-in-the-context-of-a-decentralized-l2/20146</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#aps-burn-in-the-context-of-a-decentralized-l2-1" name="aps-burn-in-the-context-of-a-decentralized-l2-1"></a>APS-burn in the context of a Decentralized L2</h1>
<h1><a class="anchor" href="https://ethresear.ch#overview-2" name="overview-2"></a>Overview</h1>
<p>We propose a design for Attester-Proposer-Separation that is tailored for the context of a decentralized L2. This design is intended to operate in the context of an L2 with its own validator set, running some sort of BFT consensus protocol, with single slot finality.</p>
<p>This design is based on the <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">APS-burn design</a> from <a class="mention" href="https://ethresear.ch/u/barnabe">@barnabe</a>, but with some notable differences. It assumes that there are short block times, preferably one second, and no longer than 2 seconds, and that each block is final within the scope of the canonical L2 chain (prior to being finalized on L1) . This design aims to obtain the benefits of APS in an L2 context, while aiming to mitigate censorship, and mitigate the negative externalities of multi-block MEV. These properties are achieved using a sealed-bid auction, similar in principle to the <a href="https://ethresear.ch/t/sealed-execution-auction/20060">Sealed execution auction</a> proposal from Anders, but in an L2 context.</p>
<p>To understand the motivation behind this design, as well as its trade-offs, see the “benefits” and “risks” sections below.</p>
<p>DO NOT read this post if:</p>
<ul>
<li>You are trying to keep up with the important developments in Ethereum and attempting to determine which posts are important and which aren’t. This post is intended for soliciting early feedback on a design that is specific to decentralized rollups, and is not a finalized proposal.</li>
</ul>
<p>DO read this post if:</p>
<ul>
<li>You are trying to decentralize a rollup, and are considering adopting an PoS consensus protocol, and are interested in exploring ideas within the design space.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#related-reading-3" name="related-reading-3"></a>Related Reading</h1>
<ul>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">More pictures about proposers and builders - Barnabé Monnot</a></li>
<li><a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Censorship Resistance in On-Chain Auctions - Elijah Fox, Mallesh Pai, Max Resnick</a></li>
<li><a href="https://ethresear.ch/t/sealed-execution-auction/20060">Sealed execution auction - Anders Elowsson</a></li>
<li><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms - Mike Neuder</a></li>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">Block vs. Slot Auction PBS - Julian Ma<br />
</a></li>
</ul>
<p>MEV Burn related reading:</p>
<ul>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV burn—a simple design</a></li>
<li><a href="https://ethresear.ch/t/the-price-is-right-realigning-proposer-builder-incentives-with-predictive-mev-burn/18656">The price is right: Realigning proposer-builder incentives with predictive MEV-burn</a></li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">Dr. changestuff or: how i learned to stop worrying and love mev-burn</a></li>
<li><a href="https://ethresear.ch/t/in-a-post-mev-burn-world-some-simulations-and-stats/17092">In a post MEV-Burn world - Some simulations and stats</a></li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#description-4" name="description-4"></a>Description</h1>
<p>We propose a method whereby the right to propose a future block is obtained via an on-chain auction.</p>
<p>For every slot <span class="math">n</span>, the auction for block proposal rights starts at slot <span class="math">n - t</span> and runs for <span class="math">k</span> slots. The auction closes at slot <span class="math">(n - t) + k</span>. During the period between <span class="math">n - t</span> and <span class="math">(n - t) + k</span>, bids are submitted to an on-chain smart contract. Each bid specifies an amount of some defined token that will be burned as part of the block that will be proposed at slot <span class="math">n</span>. The winning bid is the bid that burns the most tokens.</p>
<p>During the auction between slot <span class="math">n - t</span> and <span class="math">(n - t) + k</span>, bids are posted on-chain as sealed commitments. After the auction closes at slot <span class="math">k</span>, there is a buffer period of <span class="math">b</span> blocks in which no new bids are accepted by the smart contract for slot <span class="math">n</span>. After this buffer period, and up to slot <span class="math">n</span>, bidders post their opened commitments, which reveal the amount they are bidding. The block that is proposed to the network at slot <span class="math">n</span>, must be from the same address specified in the highest bid in the auction for slot <span class="math">n</span>, and also burn the amount of tokens specified in the bid.</p>
<p>Each bid is composed of the height of the slot being bidded on, the address that will propose the block, and an amount of MEV that will be burned in the block.</p>
<h3><a class="anchor" href="https://ethresear.ch#mitigating-multi-block-mev-5" name="mitigating-multi-block-mev-5"></a>Mitigating multi-block MEV</h3>
<p>By incorporating a sealed bid auction, we can mitigate concerns around multi-block MEV. One of the main concerns with various APS designs is that it allows bidders to bid on block proposal rights for a contiguous segment of slots. If a bidder knows that they have the rights to slot <span class="math">n</span>, then they can bid higher than anyone else for slot <span class="math">n+1</span>, because they know that they can employ lucrative multi-block MEV strategies such as censoring price oracle updates or censoring sell orders on a trading pair to drive up the price etc.</p>
<p>In order to mitigate this concern, it is imperative that the bidders have no guarantee of having won the auction for slot <span class="math">n</span> while the auction for slot <span class="math">n+1</span> is open.</p>
<p>As an illustrative example, consider the following instantiation where bidders bid for the right to propose a block 12 slots in the future <span class="math">(t = 12)</span>, and they have 4 slots in which to submit bids <span class="math">(k = 4)</span>, followed by a buffer phase in which the on-chain auction will not accept bids <span class="math">(b = 2)</span> followed by the reveal phase.</p>
<p>As you can see from the following visualization, is we assume that all bids for the slot <span class="math">n</span> auction are revealed at slot <span class="math">(n - t) + k + b</span> then the bidder for slot <span class="math">n</span> only finds out that they have won block proposal rights for slot <span class="math">n</span> after the auction for slot <span class="math">n+1</span> and slot <span class="math">n+2</span> have already closed.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/12de37869ca318f21a59cb84c3ddab8f309c90ee.png" title="L2_APS-burn"><img alt="L2_APS-burn" height="280" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/12de37869ca318f21a59cb84c3ddab8f309c90ee_2_690x280.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#censorship-6" name="censorship-6"></a>Censorship</h3>
<p>Censorship is a concern with any on-chain auction (ref: <a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">Censorship Resistance in On-Chain Auctions</a>). Obviously block builders are highly incentivized to censor any transactions to the on-chain auction that that carry bids that aren’t their own, which means that the only bids that will make it to the on-chain contract are from block builders that already have proposal rights to slots, as these builders will likely only include their own transactions to the auction contract.</p>
<p>The only way to fully mitigate censorship is through some form of <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">inclusion lists</a>, or a design that facilitates <a href="https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777">multiple concurrent block proposers</a>. We propose that this sort of mechanism is an integral part of this design, but the exact details of the mechanism employed are out of scope for this piece.</p>
<p>However, even without an inclusion list / MCP mechanism, censorship of auction transactions becomes prohibitively expensive quite quickly. This is because every transaction that is censored has associated transaction fees that can be collected by some other block builder, which they can use to increase their bids with. The censoring block builder will therefore incur a competitive disadvantage for every bid they censor. Moreover, the censoring block builder will incur the cost of each bid they censor for every block they propose, resulting in a linear increase in cost over time. In other words, If <span class="math">n</span> blocks are proposed, and <span class="math">k</span> transactions are censored per block, the total cost incurred by the censoring block builder becomes:</p>
<p><span class="math">CoC=n\times\sum_{i=1}^{k}C_{i}</span></p>
<h3><a class="anchor" href="https://ethresear.ch#collateralization-and-penalties-7" name="collateralization-and-penalties-7"></a>Collateralization and Penalties</h3>
<p>This design requires that bidders are collateralized in order to submit bids, and that this collateral is slashed under certain circumstances:</p>
<ul>
<li>If bid commitments are not revealed, this can incur penalties. The reason for this is to prevent bidders from submitting multiple bids and then just revealing them conditionally based on what other bidders reveal (as detailed in <a href="https://arxiv.org/pdf/2301.12532" rel="noopener nofollow ugc">this paper</a> - h/t <a class="mention" href="https://ethresear.ch/u/quintuskilbourn">@quintuskilbourn</a> for this). Obviously censorship resistance is important in order to prevent these penalties from being used for griefing attacks.</li>
<li>If the winner of an auction for slot <span class="math">n</span>, does not propose a block for slot <span class="math">n</span>, they are slashed.</li>
<li>If the winner of an auction for slot <span class="math">n</span>, equivocates and proposes more than one block for slot <span class="math">n</span>, they are slashed.</li>
<li>If the proposed block is valid, and is from the auction winner, but does not burn the amount of MEV that was stipulated in the winning bid, the collateral is slashed.</li>
</ul>
<p>There are two ways to approach collateralization:</p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-per-bidder-collateralization-8" name="h-1-per-bidder-collateralization-8"></a>1 | Per-Bidder-Collateralization</h4>
<p>This requires that a block builders / bidders posts some collateral on-chain, and that this will be subject to slashing conditions. Once the collateral is posted, the bidder can participate in any number of auctions and submit any number of bids. The collateral can be withdrawn at any stage, but is subject to some defined delay period.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-2-per-bid-bonding-9" name="h-2-per-bid-bonding-9"></a>2 | Per-Bid-Bonding</h4>
<p>Bidders do not need to be collateralized, but each individual bid will require a bond. In the case of the winning bid, the bond is returned when the block for the slot is delivered. In the case of not winning the bid, the bond is returned only if the bid commitment was revealed.</p>
<p>As a side note: per-bid-bonding can also potentially be used to prevent bids being revealed earlier through some side-channel, by allowing anyone to cancel their bid before the auction closes and withdraw their bond if they reveal the pre-image. Once the auction is closed, then only the original bidder can withdraw the bond.</p>
<p>There are subtle trade-offs between the two approaches:</p>
<ul>
<li>
<p>Per-bid-bonding could potentially be more centralizing, as it favors better capitalized bidders. With a slot <span class="math">n+t</span> auction with a per-bid bond of <span class="math">S</span>, then bidders will need <span class="math">t \times S</span> to participate in every auction.</p>
</li>
<li>
<p>On the other hand, this potentially improves censorship resistance to a degree, as the same bidder can bid from different addresses, reducing the scope for targeted censorship of specific rival block builders.</p>
</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#preventing-bids-from-being-revealed-early-10" name="preventing-bids-from-being-revealed-early-10"></a>Preventing bids from being revealed early</h3>
<p>It’s not entirely clear what the incentives would be for bidders to reveal their bids early, but the effect of revealing bids early will undermine the value of a sealed-bid auction, and will allow for multi-block MEV strategies to be employed. We can imagine a scenario whereby somebody constructs a mechanism employing ZKPs to allow bidders to reveal their bids, in order to understand if their bid is lower than another bid, which would give them the option to bid higher. This could be a useful tool for participants in the auction.</p>
<p>To mitigate against the risks of bidders revealing their bids early, it should be impossible, or very hard, to prove what the bid was. There are a number of ways of accomplishing this:</p>
<h4><a class="anchor" href="https://ethresear.ch#using-threshold-encryption-11" name="using-threshold-encryption-11"></a>Using threshold encryption</h4>
<p>The validators will use distributed-key-generation (DKG) to create a threshold encryption key, which is part of the headers for every block. The BFT round leader will also be responsible for collecting the keys from validators, posting the encryption key, and also gossipping the decryption key at the right time, so that it can also be included in the block headers. This will allow bidders to encrypt their bids when they are posted on-chain. It will also allow them to decrypt their bids locally to ascertain if they have won the block proposal rights for slot <span class="math">n</span>. At this stage it should be deterministically known to all parties who have won the slot <span class="math">n</span> auction.</p>
<p>Upon receiving a new block for slot <span class="math">n</span>, validators will examine the amount of MEV burned in the block as well as the address of the proposer. They will take these two pieces of data and encrypt them using the threshold encryption key for the auction for slot <span class="math">n</span>. If there is a bid that exactly matches the ciphertext, and that bid is from the proposer that is proposing the block, and is correctly collateralized, and most importantly, if there is no higher bid in the auction, then that block is accepted. This construction can be strengthened by imposing slashing conditions on entities that propose blocks that do not have a winning bid associated with it.</p>
<p>The benefit of this approach is that it precludes any possibility of revealing bids early, assuming an honest majority of validators. However, it does add some extra complexity to the consensus layer, as well as the overhead of establishing clear and reliable public transmission of threshold encryption keys.</p>
<h4><a class="anchor" href="https://ethresear.ch#using-a-verifiable-delay-function-12" name="using-a-verifiable-delay-function-12"></a>Using a Verifiable Delay Function</h4>
<p>In order to reveal a commitment, the smart contract must verify an accompanying Verifiable Delay Function (VDF) proof. The VDF ensures that any bid must take at least <span class="math">d</span> seconds to produce a proof for. While there is nothing to stop bidders revealing their bids, it makes it difficult for bidders to prove what they bid, as the proof will take approximately <span class="math">d</span> seconds to produce.</p>
<p>There are multiple VDF schemes that can be employed. Such a scheme was proposed by Nomadic Labs (see <a href="https://eprint.iacr.org/2023/977.pdf" rel="noopener nofollow ugc">Timed Commitments Revisited</a>).</p>
<p>Note that in this scheme, the commit binding is deterministic, so not completely resilient to revealing bids. In the specific scheme, if the bidder shares the values used to generate the commitment (i.e., <span class="math">G</span>, <span class="math">g</span>, <span class="math">e</span>, <span class="math">k</span>, and <span class="math">ct</span>), others can reproduce the commitment <span class="math">\psi</span>, thereby revealing the bid. Further work is needed to understand the complexity involved in doing this in a ZKP, in order to understand whether the complexity is sufficient to discourage revealing of bids. If needed, we would change the scheme to use a key derivation function that is suboptimal for use within zk circuits, resulting in inefficient proof generation, and therefore a similar level of effort required to create the actual VDF proof.</p>
<p>Note that while it is possible to just use VDFs by themselves without the complexity of a commit-reveal scheme, this has the drawback of allowing bidders to produce multiple VDFs concurrently in order to retain the option of conditional bidding.</p>
<h1><a class="anchor" href="https://ethresear.ch#risks-concerns-13" name="risks-concerns-13"></a>Risks / Concerns</h1>
<h4><a class="anchor" href="https://ethresear.ch#reduced-competitiveness-in-bidding-14" name="reduced-competitiveness-in-bidding-14"></a>Reduced Competitiveness in Bidding</h4>
<p>Bids are a bet on averages, this can potentially have more centralizing effects than a JIT block auction, because it precludes any opportunistic MEV strategies that capitalize on MEV spikes, which could prevent block builders that exist on these strategies from participating. Also, because it is a bet on averages, the system may favor the most well capitalized block builders.</p>
<p>Also, because we are using a sealed-bid auction, participants are not bidding in response to each other’s bids. This removes the natural competitiveness that drives up prices, and so the overall level of bidding is likely to be somewhat lower.</p>
<h4><a class="anchor" href="https://ethresear.ch#l2-reorg-resistance-15" name="l2-reorg-resistance-15"></a>L2 reorg resistance</h4>
<p>This design assumes a BFT consensus protocol with single-slot-finality, wherein reorgs do not occur in the normal case. If reorgs are a concern, one can adapt the above design to include a second buffer phase at the end of the reveal phase but before slot <span class="math">n</span>. This would force any incentivized reorg to be at least as deep as the size of the second buffer phase, making it much more expensive, and so disincentivizing malicious reorgs.</p>
<h1><a class="anchor" href="https://ethresear.ch#benefits-16" name="benefits-16"></a>Benefits</h1>
<h4><a class="anchor" href="https://ethresear.ch#the-benefit-of-aps-is-that-there-is-no-longer-a-requirement-for-mev-boost-relays-17" name="the-benefit-of-aps-is-that-there-is-no-longer-a-requirement-for-mev-boost-relays-17"></a>The benefit of APS is that there is no longer a requirement for mev-boost relays</h4>
<p>The reason is that there is no negotiation between proposers and relayers (in terms of the proposer being the BFT round leader, who proposes blocks to the validator set). In the mev-boost scenario, the relayers are required in order to give some assurance to the builder that the proposer will not unbundle their block and steal the MEV, and also to give assurance to the proposer that the builder will in fact release the block on time, and not cause the proposer to get slashed. This is necessary to maintain PBS (unless ePBS is implemented), without which searcher bots will engage in PGAs which will cause significant and adverse network congestion.</p>
<h4><a class="anchor" href="https://ethresear.ch#it-reduces-the-centralizing-effects-of-mev-on-the-validator-set-18" name="it-reduces-the-centralizing-effects-of-mev-on-the-validator-set-18"></a>It reduces the centralizing effects of MEV on the validator set</h4>
<p>While mev-boost already does this in terms of democratizing access to MEV, there are still some centralizing effects from having MEV flowing to validators. For example, co-locating validator nodes close to relays means that validators can benefit from reduced latency and the higher bids that emerge in the final milliseconds of the slot. This latency advantage has compelling economies of scale for larger staking pools, which drives both economic and geographic centralization.</p>
<h4><a class="anchor" href="https://ethresear.ch#strengthens-pos-tokenomic-design-19" name="strengthens-pos-tokenomic-design-19"></a>Strengthens PoS tokenomic design</h4>
<p>For L2s that maintain their own gas token, APS simplifies the modeling of token rewards and penalties with regards to the validator set. This is because MEV no longer flows to the validators, which makes the validator risk/reward profile more deterministic and easier to reason about. Validators will just receive rewards as designed by the protocol and nothing more, which makes it easier to design PoS tokenomics. APS-burn also acts as a natural token sink, strengthening the tokenomics by having a deflationary effect on the token itself.</p>
<hr />
<h1><a class="anchor" href="https://ethresear.ch#future-work-20" name="future-work-20"></a>Future Work</h1>
<p>As well as soliciting early feedback and peer review, we plan to work on determining how best to model this design so that we can understand the trade-offs in the design choices such as threshold encryption or VDFs, parameterization of the on-chain auction, per-bidder-collateralization or per-bid-bonding, and to understand the extent to which we can confidently predict the behavior of participants.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/a-design-for-aps-burn-in-the-context-of-a-decentralized-l2/20146">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 25 Jul 2024 10:16:16 +0000</pubDate>
</item>
<item>
<title>The case for decentralization increasing efficiency is overstated</title>
<link>https://ethresear.ch/t/the-case-for-decentralization-increasing-efficiency-is-overstated/20140</link>
<guid>https://ethresear.ch/t/the-case-for-decentralization-increasing-efficiency-is-overstated/20140</guid>
<content:encoded><![CDATA[
<p>Block-building on Ethereum has become quite centralized. 90% of blocks are auctioned off through MEV-Boost. Numerous solutions have been proposed, including anonymous inclusion lists and execution tickets. People are concerned about this, both for essentially ideological reasons, and for reasons of efficiency. Blockchains have an ethos of being open to all people, whether or not that is maximally efficient. There is a tradeoff between efficiency (in the sense of getting each block built in the most efficient way, by the most efficient builders) and “fairness”, or including all transactions, if people’s use of the chain is unaffected by the degree of centralization. If blockchain users are concerned their transactions will eventually be sanctioned and rendered worthless, they may avoid that blockchain, or avoid cryptocurrencies altogether. Thus, seemingly inefficient decentralization may be optimal for the blockchain as a whole, and would be unanimously preferred by all blockbuilders to the present equilibrium.</p>
<p>I am concerned, however, that the efficiency case is overstated. Imagine there is a firm so efficient at MEV extraction that they build all of the blocks on chain. If them doing so would cause people to leave the blockchain altogether, then they are incentivized to not bid on some blocks at all.</p>
<p>In “<a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>”, Neuder, Garavmidi, and Roughgarden propose execution-tickets as a mechanism for distributing block-building rights, using a proportional all-pay auction. Bidders buy lottery tickets for the right to build a block. In the example given, they have two buyers, buyer 1 with value 4, and buyer 2 with value 2. Under a perfectly efficient system, buyer one always gets the block, at price 2+epsilon. Under their all-pay system, buyer 1 bids 8/9th and buyer 2 bids 4/9th, with them receiving the block rights 2/3rds and 1/3rd of the time, respectively.</p>
<p>Under the description of the example, however, this necessarily <em>cannot</em> improve efficiency. If excessive centralization would scare away some users from using the chain at all, the winning monopolist is incentivized to give away some of the block. The value of efficiency is already reflected in their valuations. If you assume that their valuation is always higher, then you are assuming that there is no efficiency case whatsoever. You only have an ideological case, which is fine on its own terms — but you should not mix and match arguments which overstate your case. Note too that we are only caring about one side of the ledger, those who want their transactions to be included. Mightn’t it be possible that some people are repulsed by crypto’s shady reputation?</p>
<p>Nor should this necessarily apply in cases of monopolistic competition. To simply not bid is not the only way to redistribute blocks. If it were the case, the main block-builders would indeed be stuck in a prisoner’s dilemma — they could choose not to bid, but they would have to all do it. If, however, the winners hold another auction for the block, with some of the fairness raising characteristics as before, they can decentralize to the extent which is optimal for them.The drawback is that now the builders internalize a smaller portion of the gains. There is a free-rider problem with decentralization. However, as the market becomes more decentralized, doubtless people will be less concerned about censorship.</p>
<p>The efficiency argument for decentralization therefore much smaller than it would appear. There should probably be a split between allocatively efficient auctions for blocks, and allocatively fair but inefficient markets. What is the right split between the two? It is highly unlikely that it is optimal to only sell blocks in one way all the time.</p>
<p>I think that this is an ideal question for a prediction market. The right amount of decentralization is a macro question. You’re not going to be able to A/B test it in a couple days. Your choices are trying to influence people’s choice in the long run, and answer the question: what is the long run amount of decentralization that maximizes the amount of capital put on the chain. Is there any better use of prediction markets than this? I am somewhat agnostic to the exact method of determining the split — and have no opinions whatsoever as to the proper proportion.</p>
<p><em>This post was first posted on my blog <a href="https://nicholasdecker.substack.com/p/the-case-for-blockchain-decentralization" rel="noopener nofollow ugc">here</a>. Thank you for reading this, please tell me if you disagree.</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/the-case-for-decentralization-increasing-efficiency-is-overstated/20140">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 24 Jul 2024 18:48:55 +0000</pubDate>
</item>
<item>
<title>Builder Bidding Behaviors in ePBS</title>
<link>https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129</link>
<guid>https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129</guid>
<content:encoded><![CDATA[
<p>Special thanks to <a class="mention" href="https://ethresear.ch/u/soispoke">@soispoke</a> for the review</p>
<h1><a class="anchor" href="https://ethresear.ch#background-1" name="background-1"></a>Background</h1>
<p>Builder bidding strategies in the MEV-Boost world have been studied extensively over some time. Numerous <a href="https://arxiv.org/html/2312.14510v3" rel="noopener nofollow ugc">excellent resources</a>, <a href="https://arxiv.org/abs/2407.13931" rel="noopener nofollow ugc">literature</a>, <a href="https://ethresear.ch/t/game-theoretic-model-for-MEV-Boost-auctions-mma/16206">game-theoretic models</a>, and <a href="https://collective.flashbots.net/t/MEV-Boost-builder-bids-archive/3561" rel="noopener nofollow ugc">archives</a> capture the current builder bidding behaviors on how to win block building right for an Ethereum slot. Today, builder bidding war for MEV-Boost is a complex interplay between latencies, relays, and strategy effectiveness. In this post, we argue that builder bidding strategies become simpler in ePBS world and we highlight the key differences in how bidding strategies change under the new ePBS market space rules, strategy limitations, and reduced latency benefits in ePBS.</p>
<h1><a class="anchor" href="https://ethresear.ch#market-spaces-2" name="market-spaces-2"></a>Market Spaces</h1>
<p>Here, we summarize three types of market spaces. The first one is MEV-Boost. The second and third ones are ePBS. MEV-Boost is push + pull based market space, meaning the builders push the bids to the relays, and the proposer pulls the bids from the relays. ePBS contains two types of market spaces: the P2P Bid Gossip Netwok, which is push-based, and the Builder RPC Endpoint, which is pull-based.</p>
<ul>
<li><strong>MEV-Boost market space</strong>
<ul>
<li><strong>Push + pull-based</strong>: The builders push bids to the relay, and the proposer pulls the bids from the relay.</li>
</ul>
</li>
<li><strong>ePBS market spaces</strong>
<ul>
<li><strong>P2P market space</strong>
<ul>
<li><strong>Push-based</strong>. The builder pushes the bid to the p2p network.</li>
</ul>
</li>
<li><strong>Builder RPC market space</strong>
<ul>
<li><strong>Pull-based</strong>. The proposer pulls the bids from the builder RPC end points.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We define the following market space characteristics given how the consensus <a href="https://github.com/ethereum/consensus-specs/pull/3828" rel="noopener nofollow ugc">spec</a> is written today. Builder-API is still <strong>TBD</strong> for ePBS.</p>
<h2><a class="anchor" href="https://ethresear.ch#mev-boost-market-space-3" name="mev-boost-market-space-3"></a>MEV-Boost Market Space</h2>
<ul>
<li><strong>Open auction</strong>: Builders that subscribe to the relay’s feed can see the every builder’s latest bid.</li>
<li><strong>Continuous auction</strong>: Builders can bid multiple times and cancel previous bids.</li>
<li><strong>Auction termination</strong>: The auction terminates when the proposer calls <code>getHeader</code> and when the relay returns the header to the proposer to sign. The relay may delay the header response for a timing game. This means the relayer has the final control over when the auction terminates.</li>
<li><strong>Profit sharing</strong>: Some relays take the difference between the winning bid and the second-highest bid received from builders. This difference goes to the relay, with a portion potentially refunded to the builder. This transforms the auction dynamic into a second-price auction. However, not all relays adopt this approach, and complete trust in the relay is mandatory.</li>
<li>We assume the market space doesn’t verify block contents from the builder, hence it is an <a href="https://github.com/michaelneuder/optimistic-relay-documentation/blob/4fb032e92080383b7b5d8af5675ef2bf9855adc3/towards-ePBS.md" rel="noopener nofollow ugc"><strong>optimistic market space</strong></a>. The only delay is when the builder sends the block to the relay.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#epbs-p2p-market-space-4" name="epbs-p2p-market-space-4"></a>ePBS P2P Market Space</h2>
<ul>
<li><strong>Open auction</strong>: Anyone can subscribe and listen to the P2P network for gossiped builder bids.</li>
<li><strong>Single bid auction</strong>: To prevent DOS attacks on the P2P network, the current spec only allows builders to submit a single bid and above a certain minimum value. Any subsequent bid will be dropped by the nodes. There is no cancellation support over the P2P network.</li>
<li><strong>Auction termination</strong>: The auction terminates when the proposer proposes the block which includes the builder’s bid. The proposer could play a timing game here and has the final control over when the auction terminates.</li>
<li><strong>Profit sharing</strong>: The bid specifies the value, and the proposer gets the full value on the consensus layer as long as the consensus block that includes the bid remains canonical. There’s no profit sharing with 3rd parties.</li>
<li>The market space is still <strong>optimistic</strong> and doesn’t need to verify the execution contents at inclusion time. If the execution block later becomes invalid or fails to reveal, the proposer still gets unconditional payment. The only delay here is the builder sending the bid to the P2P network. This delay is argubly <strong>longer</strong> than using a relay in MEV-Boost market space.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#epbs-builder-rpc-market-space-5" name="epbs-builder-rpc-market-space-5"></a>ePBS Builder RPC Market Space</h2>
<p>Note: The <a href="https://github.com/ethereum/builder-specs" rel="noopener nofollow ugc">Builder API</a> is undefined at this moment. This section is based on what we think the ePBS Builder API might look like, but it’s highly subjective to change and open for feedback. Below outlines one version of Builder API which we have been thinking.</p>
<ul>
<li><strong>Private auction</strong>: Only the proposer can request a bid from the builder. The proposer will sign the <code>getHeader</code> request using the builder’s public key. The builder’s bid remains private until requested by the proposer. Builders can’t sniff other builders’ bids unless the builder API allows this or the builder voluntarily opens their bids to the public.</li>
<li><strong>Single</strong> (maybe multiple?) <strong>bid auction</strong>: Builders allow proposers to request a bid once, and any subsequent requests will result in an error. Builders may also allow proposers to request bids multiple times without error; this specific detail is undefined, and it’s unclear what the Nash outcome is here. If builders allow multiple requests, then the builder must ensure previous bids are canceled.</li>
<li><strong>Auction termination</strong>: The auction terminates when the proposer requests the header and the proposer receives the header. The builder can play a timing game, but this may backfire and lead to the proposer using another builder’s bid. Builder timing game will not work here, but proposer timing games are still relevant.</li>
<li><strong>Profit sharing</strong>: Same as the P2P market space.</li>
<li>The market space is still <strong>optimistic</strong>, and the delay here is the builder returning the bid to the proposer. This delay is shorter than the P2P market space and likely the same as MEV-Boost if the builder is well co-located.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#builder-bidding-profiles-under-epbs-6" name="builder-bidding-profiles-under-epbs-6"></a>Builder Bidding Profiles under ePBS</h1>
<p>In the <a href="https://arxiv.org/abs/2312.14510" rel="noopener nofollow ugc">Strategic Bidding Wars in On-chain Auctions</a>, four profiles of builder behavior are listed in MEV-Boost auction:</p>
<ul>
<li><strong>Naive Behavior</strong>: Aggressively updates bids based on their valuation as long as the aggregated signal surpasses their profit margin.</li>
<li><strong>Adaptive Behavior</strong>: Monitors the current highest bid and places a bid if able to outbid by a small constant. Defaults to the naive strategy if unable to outbid.</li>
<li><strong>Last Minute Behavior</strong>: Reveals valuation at the final possible moment before auction termination to minimize the reaction window for other players.</li>
<li><strong>Bluff Behavior</strong>: Initially places high bids (bluff) and later reverts to actual valuation, leveraging bid cancellation to compel other players to disclose their valuations.</li>
</ul>
<p>Given the new market space in ePBS, we will examine which strategies are viable under the auction rules.</p>
<h3><a class="anchor" href="https://ethresear.ch#p2p-market-space-7" name="p2p-market-space-7"></a>P2P Market Space</h3>
<ul>
<li><strong>Naive, Adaptive, and Bluff Behaviors</strong>: These strategies are harder to execute since bids can only be sent once. The builder might use different staked addresses, each sending one bid. However, this requires staking on the consensus layer for each address, assuming payment is handled on the consensus layer. Additionally, bluffing is not possible because bids cannot be canceled.</li>
<li><strong>Last Minute Behavior</strong>: This is the <strong>only</strong> possible strategy. Builders will reveal their valuation at the final moment before auction termination to minimize the reaction window for other players.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#builder-rpc-market-space-8" name="builder-rpc-market-space-8"></a>Builder RPC Market Space</h3>
<ul>
<li><strong>Naive, Adaptive, Bluff, and Last Minute Behavior</strong>: For similar reasons to the P2P market space, these strategies are not possible. Additionally, the auction is private, meaning builders cannot see each other’s bids. Most importantly, the auction has shifted from push-based to pull-based, so the builder no longer has control over when to submit bids. The only way for builders to get their bids to the proposer is through the proposer’s request.</li>
</ul>
<p>We conclude that builders’ bidding strategies are heavily limited under ePBS. For P2P, only last-minute bidding is possible. For Builder RPC, builders can only respond to the proposer as it is a pull-based model.</p>
<h1><a class="anchor" href="https://ethresear.ch#market-space-considerations-9" name="market-space-considerations-9"></a>Market Space Considerations</h1>
<p>We add a few more concerns in this section that was emphasized in the MEV-Boost market space but may no longer be relevant in ePBS market space.</p>
<h2><a class="anchor" href="https://ethresear.ch#latency-and-dos-concerns-10" name="latency-and-dos-concerns-10"></a>Latency and DOS Concerns</h2>
<p>Different market spaces impose varying latency constraints. In the P2P market space, builders push bids to the proposers, and the market operates as a large P2P gossip network constrained by anti-DOS measures. With 1 million validators, the worst-case scenario could mean 1 million bids. Due to these concerns, rules like disallowing multiple bids and ensuring bids are above certain values are necessary. The P2P network is inherently slow, so we don’t foresee serious bidders using it to win bids. However, the P2P market space is valuable for maintaining a good <strong>baseline for competitive bids</strong> that isn’t latency-sensitive. If builders using RPC collude to drive bid prices low, an <strong>altruistic builder</strong> over P2P can ensure the bid value baseline remains healthy and competitive with minimal effort. The baseline P2P bid value may also be used for burning in future iterations, as it only requires a 1/n honest assumption.</p>
<p>In the builder RPC market space, which is pull-based, latency matters significantly. Instead of two latencies (global and individual) defined in the MEV-Boost market space, there’s only one individual delay to consider: how fast the builder can return the bids to the proposer. Delaying the return of <code>getHeader</code> may result in proposer missing builder’s bid.</p>
<h2><a class="anchor" href="https://ethresear.ch#auction-interval-uncertainty-11" name="auction-interval-uncertainty-11"></a>Auction Interval Uncertainty</h2>
<p>The auction interval uncertainty becomes clearer in ePBS because MEV-Boost middleware and relays no longer control the timing of when the block gets returned to the proposer or released to the network. The proposer either uses the pushed bids from the P2P network or pulls bids from the builders RPC. The proposer has the final say on the auction interval cut-off. From the builder RPC market space perspective, it will keep updating its bids until the proposer requests them.</p>
<h3><a class="anchor" href="https://ethresear.ch#new-bluff-behavior-under-epbs-12" name="new-bluff-behavior-under-epbs-12"></a>New: Bluff Behavior under ePBS</h3>
<p>In ePBS, proposers or builders may attempt to bluff other builders. This may not be scalable given the nature of the single bid auction over P2P and the fact that every builder is a validator and needs to have a stake on the beacon chain. One bluff strategy is for the proposer of next slot to reveal a high value P2P bid, intentionally stating that this is the bid it will include for the next slot unless others can beat it. This helps set the base price and forces everyone else to beat it. However, the proposer doesn’t have to include its bid.</p>
<p>Although it’s obvious that anyone can see that the bid comes from the proposer and just ignore it, the proposer may use sybil validators to perform the same bluff. However, it’s still unclear how scalable this strategy is, given that one bid equals one validator.</p>
<h1><a class="anchor" href="https://ethresear.ch#open-questions-13" name="open-questions-13"></a>Open questions</h1>
<p>The current ePBS market space design and requirements leave some open questions. We will summarize the open questions here for feedback:</p>
<ul>
<li>
<p><strong>P2P Market Space Conditions</strong>:</p>
<ul>
<li>Every builder can only submit one bid, and the subsequent bids get dropped. Are there any advantages to allowing multiple bids here? If yes, then how many?</li>
<li>Every builder’s bid needs to be above a certain value to deter DOS attacks. What should the value be?
<ul>
<li>We can look at current or past empirical data here.</li>
</ul>
</li>
<li>There’s a tradeoff between the number of bids allowed and the minimal values. If we set the values high, we may allow multiple bids.</li>
<li>Is there a strong argument for requiring bid cancellation?</li>
</ul>
</li>
<li>
<p><strong>Builder RPC Market Space’s Builder API Interface</strong>:</p>
<ul>
<li>What does the Builder API interface look like?
<ul>
<li>We want to leverage the existing Builder API and aim for minimal changes.</li>
<li>When the proposer makes a header request to the builder, what should the request look like? Can we use the current get header request with a signature, or should we modify it?</li>
<li>Do we allow multiple getHeader requests, such as continuous polling from the proposer, or do we enforce a common standard?</li>
</ul>
</li>
<li>What kind of auction is most ideal?
<ul>
<li>Sealed second-price auction may be most ideal.</li>
<li>How to design this over Builder API?</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Comparing MEV-Boost Market Space to ePBS Market Space</strong>:</p>
<ul>
<li>Do we lose anything in the ePBS market space that is important to maintain from the MEV-Boost market space?</li>
</ul>
</li>
<li>
<p><strong>Implications of staking pools also bidding:</strong></p>
<ul>
<li>Pools that hold a significant chunk of validators could be in a privileged position for submitting bids and manipulating the market extensively compared to a builder that doesn’t hold as many keys.
<ul>
<li>Is there an advantage to this asymmetry?</li>
<li>Will we see staking pools and builders teaming up, and how will this dynamic play out?</li>
</ul>
</li>
</ul>
</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/builder-bidding-behaviors-in-epbs/20129">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 23 Jul 2024 13:44:07 +0000</pubDate>
</item>
<item>
<title>Enabling standardized on chain executions through modular accounts</title>
<link>https://ethresear.ch/t/enabling-standardized-on-chain-executions-through-modular-accounts/20127</link>
<guid>https://ethresear.ch/t/enabling-standardized-on-chain-executions-through-modular-accounts/20127</guid>
<content:encoded><![CDATA[
<div> 关键词：标准化执行、Modular Accounts、Verifiable Credentials (VCs)、Zero-Knowledge Proofs (ZKPs)、Validation Module

总结:<br />
这篇文章讨论了通过Modular Accounts实现区块链上标准执行的过程。它提出了一种框架，结合ERC 7579提案，将用户身份验证和交易授权分离，使用zk证明验证VC以确保操作的合法性和隐私。该系统利用智能合约、账户抽象和接口检测来提升安全性、隐私和用户体验。文章列举了几个关键应用领域，如DeFi、DAOs和供应链管理，以展示这种标准化执行的价值。未来，文章还关注了账户灵活性和安全性的增强，如P-256椭圆曲线签名验证、Keystore合同和passkeys在提高用户体验中的作用。整体而言，这个框架旨在为大规模企业服务提供一个安全、合规和高效的区块链执行环境。 <div>
<p><strong>Enabling standardized on chain executions through Modular Accounts</strong></p>
<p><strong>Introduction</strong></p>
<p>This blogpost is intended to be an extension from a previous work “ <a href="https://ethresear.ch/t/self-sovereign-identity-and-account-abstraction-for-privacy-preserving-cross-chain-user-operations-across-roll-ups/19599">Self-sovereign identity and account abstraction for privacy preserving cross chain user operations across roll ups</a> ” with the intent of proposing a system implementation of network features. In the previous work I tried to envision a system combining a three-layered architecture that I will briefly summarize here:</p>
<ol>
<li>An application layer comprises wallets and other service apps to facilitate the generation and management of Verifiable Credentials, set a permission logic for compiling user operation objects through apps.</li>
<li>A network layer based on different L2s, which include a Keystore contract and Smart Contract Accounts. This layer is responsible for generating Zero-Knowledge Proofs (ZKPs) and Merkle proofs for Sequencers. The Keystore contract manages encryption keys and user authentication, ensuring the correct key pairing for Verifiable Credentials and Operations. Smart Contract Accounts verify user operations, by validating ZK cryptographic proofs to ensure the integrity of the signatures of the transactions before they are executed.</li>
<li>A sequencing layer which interconnects L2s with Ethereum main-net and manages the execution of batches of transactions anchoring Roll-up IDs to sequencing networks batching, validation cross chain atomic transactions via the Keystore roll-up, and the Roll-up contract within Ethereum’s slots.</li>
</ol>
<p>Today, I am trying to focus on some elements on the 1 and 2 layer, sitting in the conjunction between External Owned Accounts and Contract Accounts trying to envision an implementation pathway for the adoption of standardized on chain execution.</p>
<p><strong>The concept</strong></p>
<p>To facilitate the adoption of blockchain based services globally there is a need for standardizing secure, privacy and regulatory-compliant on chain executions to scale. As we move towards a more decentralized future, ensuring cyber security, data minimization from origination to processing, and improving UX in executing on chain operations is crucial.</p>
<p>This blog post introduces a framework based on the ERC 7579 proposal, which integrates a module to lavage onchain verifiable credentials and zero-knowledge (zk) proofs in the context of modular smart accounts. This framework aims to standardize onchain executions by separating user authentication and transaction authorization while preserving privacy and regulatory requirements throughout the transaction lifecycle.</p>
<p>The core function of the system described involves validating zk proofs generated by VCs to authenticate users and authorize operations. This makes the Validation Module the most appropriate choice, as it is designed to validate user operations before they are executed.</p>
<p>The Validation Module allows for checking the validity and authenticity of zk proofs, ensuring that only legitimate user operations are processed.</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/c/1c3ddecf471befecea0769a9e94397e93d1a0bb7.png" title=""><img alt="" height="153" src="https://ethresear.ch/uploads/default/optimized/3X/1/c/1c3ddecf471befecea0769a9e94397e93d1a0bb7_2_455x153.png" width="455" /></a></div><p></p>
<p>For reference, the framework considers a minimal set of ERC for implementation:</p>
<ul>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-7579#modules">ERC 7579</a> - Minimal Modular Smart Accounts: to set a module to validate user operations by verifying ZK proofs derived from verifiable credentials (VCs) ensuring that user operations are authenticated and authorized before execution.</p>
</li>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-1271">ERC 1271</a> - Standard Signature Validation Method for Contracts: to standardize how smart contracts validate signatures, defining the function to verify the validity of a signature, crucial for transaction authorization.</p>
</li>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-4337">ERC 4337</a> - Account Abstraction Using Alt Mempool: to abstract account management and operations, enabling more complex and user-friendly interactions allowing smart contract accounts to handle user operations and transaction executions.</p>
</li>
<li>
<p><a href="https://eips.ethereum.org/EIPS/eip-165">ERC 165</a> - Standard Interface Detection: to allow contracts to declare support for certain interfaces and enabling smart contracts to query and interact with other contracts that implement specific interfaces.</p>
</li>
</ul>
<p><strong>High-level process flow</strong></p>
<p>The framework leverages the strengths of different proposals to create a robust, secure, and privacy-preserving onchain execution environment.</p>
<p>I list here a high-level overview:</p>
<ol>
<li>Users issue on chain merklized Verifiable Credentials (VCs) through a contract identifier operated by an issuer. These credentials are stored in the user’s identity wallet (EOA)</li>
<li>Users generate and validate ZK proofs derived from their VCs through a contract verifier to access service apps and compile User Operation objects.</li>
<li>Smart Contract Account entry point perform canonical verification loop according ERC 4337.</li>
<li>The validation module verifies the zk proofs against the VCs in the execution loop and upon successful validation, the module calls the isValidSignature function as defined by ERC 1271 to authorize entry point to executeUserOps.</li>
<li>Smart contract Account entry point executes onchain operations and distributes the fees to the Bundler address.</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/0/8054bf5b0b25390eb19a159f9c698f66c091eb2f.jpeg" title=""><img alt="" height="237" src="https://ethresear.ch/uploads/default/optimized/3X/8/0/8054bf5b0b25390eb19a159f9c698f66c091eb2f_2_643x237.jpeg" width="643" /></a></div><p></p>
<p><strong>Market &amp; Business Considerations</strong></p>
<p>This framework offers significant value for large-scale enterprise services requiring validation logic before authorizing onchain operations. By integrating SSI and zk proofs, enterprises can ensure privacy and regulatory compliance while enhancing security and efficiency. The separation of authentication and authorization further strengthens the system’s robustness.</p>
<p>Here a short list of valuable use cases that would fit nicely with this logic:</p>
<ol>
<li><strong>Trading</strong>: A DeFi platform allows users to interact with various financial services such as lending, borrowing, and trading. The platform issues VCs containing user identity and KYC information. Whenever a user wants to execute a financial transaction, they submit a zk proofs on VC and compile user operations objects along as operation request. The Validation Module verifies the zk proof against the stored VC and upon successful verification, the entry point is executing the operations on chain.</li>
<li><strong>DAOs</strong>: a decentralized voting system allows DAO members to vote for grants allocation privacy preserving and reducing conflict of interest. Voters authenticate themselves using VCs and zk proofs to cast their votes and upon the voting completion the entry point executes grants allocations on chain according to the voting results.</li>
<li><strong>Supply chain</strong>: a management system tracks the manufacturing and logistics of goods, participants in the supply chain authenticate using VCs and zk proofs to update and access the status of goods up to the distributor and at the moment of the sale the entry point execute onchain rewards, or payment premiums, to the different members.</li>
</ol>
<p><strong>Conclusion &amp; further thoughts</strong></p>
<p>When we look forward to what kind of functionalities we would like to have as user for the future I believe there has been a big trend in providing standardization through native abstraction, modularity, and functional collaboration between EOAs and SCAs. Considering the future road map of Ethereum in Pectra, <a href="https://github.com/ethereum/EIPs/blob/master/EIPS/eip-7702.md">EIP 7702</a> sets the way for a new transaction type which enables account properties of both externally owned accounts (EOAs) and Smart Contract Accounts (SCAs). Furthering looking ahead, there is a way to set “native account abstraction” by <a href="https://github.com/ethereum/RIPs/blob/master/RIPS/rip-7560.md">RIP 7560</a> and <a href="https://eips.ethereum.org/EIPS/eip-7562">ERC 7562</a> which align with ERC 4337 rules at least on validation rules.</p>
<p>A side of this is also important <a href="https://eips.ethereum.org/EIPS/eip-7212">EIP 7212</a> proposes a precompiled contract to perform signature verifications using the secp256r1 elliptic curve. This curve, also known as P-256, is widely supported in modern devices like Apple’s Secure Enclave, Webauthn, and Android Keychain, and Passkeys. This would allows more efficient and flexible management of accounts by transaction signs in mobile devices. Both EIP 7702 and EIP 7212 are potentially taking place in Pectra.</p>
<p>Network harmonization is a key capability of every growing community, in this context personally I see value in further exploring the use of keystore contracts, session keys and passkeys as additional features to provide security, flexibility and usability to the product experience.</p>
<p>Passkeys can be used to authenticate users providing a smoother UX while combining strong user authentication. Session keys can improve security of communication at application level, meaning when users are interacting with dapps for using market services, and keystore contract could represent an reliable solution for setting a functional framework for operating key sessions.</p>
<p>The shared focus on improving account flexibility and security through different methods highlights the committment of the community’s to address scalability, usability, and security concerns within the Ethereum network. In this setting collaboration between EOAs and SCAs, and additional features as passkeys keystore contracts can live in a modular setting where specific modules enforce optional rules for executions, and different cryptographic tecniques could ensure data minimization for controllers and processors.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/enabling-standardized-on-chain-executions-through-modular-accounts/20127">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 22 Jul 2024 12:43:52 +0000</pubDate>
</item>
<item>
<title>Diseconomies of Scale: Anti-Correlation Penalties (EIP-7716)</title>
<link>https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114</link>
<guid>https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114</guid>
<content:encoded><![CDATA[
<div> 关键词：Diseconomies of Scale、Anti-Correlation Penalties、EIP-7716、Proposer Timing Games、Centralization

总结:
这篇文章讨论了以太坊共识机制中的中心化问题，尤其是经济规模效应导致的不平衡和集中风险。EIP-7716提案旨在通过实施反相关惩罚来抵消这些影响，通过调整奖励和罚款，鼓励小型和分散的参与者，同时抑制大型运营商可能滥用的优势。反相关惩罚会根据验证者之间行为的相关性动态调整，例如对源投票错误的惩罚会根据网络中未参与或错误投票的总余额来调整。文章还提到，虽然惩罚可能会对单个验证者造成短期影响，但长期来看，它有利于提高网络的抗风险能力并促进去中心化。 <div>
<h1><a class="anchor" href="https://ethresear.ch#diseconomies-of-scale-anti-correlation-penalties-eip-7716-1" name="diseconomies-of-scale-anti-correlation-penalties-eip-7716-1"></a>Diseconomies of Scale: Anti-Correlation Penalties (EIP-7716)</h1>
<blockquote>
<p>Special thanks to <a href="https://x.com/dapplion">DappLion</a> and <a href="https://x.com/VitalikButerin">Vitalik</a> for their collaborative effort on the overall concept, and <a href="https://x.com/weboftrees">Anders</a> and <a href="https://x.com/_julianma">Julian</a> for their valuable feedback on this post!</p>
</blockquote>
<p>Ethereum relies on a decentralized set of validators to ensure properties like credible neutrality and censorship resistance. Validators <a href="https://ethereum.org/en/staking/">stake</a> a certain amount of ETH to participate in Ethereum’s consensus and secure the network. In return, validators receive rewards directly from the protocol (<a href="https://ethresear.ch/t/faq-ethereum-issuance-reduction/19675">#issuance</a>) as well as execution layer rewards when proposing a block, which include transaction fees and <a href="https://ethereum.org/en/developers/docs/mev/">MEV</a> from the blocks they propose (<a href="https://boost.flashbots.net/">#mevboost</a>). As of today, thousands, if not tens of thousands, of small-sized entities run validators from their homes despite several disadvantages. These include the risk and responsibility of operating and maintaining a node, the technical burden associated with setup and upkeep, potential downtime, and the lack of a liquid staking token that would otherwise provide flexibility and liquidity.</p>
<p>With the ongoing maturation of Ethereum’s PoS, we’ve encountered various <strong>centralizing forces</strong> inherent to the current protocol:</p>
<ul>
<li><strong>EL Reward Variance</strong>: While attestation rewards are distributed fairly evenly, the rewards for proposing a block can vary significantly. This variation arises because <a href="https://ethereum.org/en/developers/docs/mev/">MEV</a> is extremely spiky, resulting in a few outlier blocks with proposer profits exceeding 10 ETH. Large operators running many validators have better chances of capturing these “juicy” blocks. Although over many years the earnings of individual validators should average out, the future remains uncertain. Assuming 1 million validators and 2,628,000 slots per year, the probability of being selected as a proposer is ~0.0001%. On average, a validator can expect to propose <span class="math">\frac{1,000,000}{365.25 \times 7200} = 2.628</span> blocks per year (there are 7200 slots per day). From April 2023 to April 2024, the percentage of blocks with more than 10 ETH was 0.004041%. Statistically, a single validator will eventually propose a block with more than 10 ETH of MEV, but it’s unknown whether this will happen this year or in ten years, and by then, MEV issues might be resolved. While solo stakers literally participate in a lottery, large operators can average their profits and plan for the future with greater certainty.<br />
Over 1 year, the probability of a random validator getting at least one block with &gt;10 ETH profits is 0.1%:</li>
</ul>
<div class="math">
P(\text{at least one 10} \, \text{ETH} \, \text{block}) = 1 - (1 - 0.0004041)^n = 1 - (1 - 0.0004041)^{2.628}
</div>
<p>If you control 1% of all validators (~10k validators), the probability of getting at least one block with more than 10 ETH of MEV climbs to approximately 99.99% over one year.</p>
<p>The following chart shows the <strong>cumulative sum of MEV-Boost payments</strong> on the y-axis and the <strong>cumulative number of MEV-Boost payments</strong> on the x-axis. We can see that 90% of all blocks distribute around 44% of the total value, leaving 56% to be distributed to the lucky 10% of proposers.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/e/aed0a28f0f91206549c0993488907698504ef2dc.png" title="Bk31ssG_R.png"><img height="428" src="https://ethresear.ch/uploads/default/optimized/3X/a/e/aed0a28f0f91206549c0993488907698504ef2dc_2_600x428.png" width="600" /></a></div>
<p></p>
</div>
<ul>
<li>
<p><strong>Reorgs</strong>: “<em><a href="https://ethresear.ch/t/change-fork-choice-rule-to-mitigate-balancing-and-reorging-attacks/11127">Honest reorgs</a></em>” occur when the proposer of slot <span class="math">n_{1}</span> orphans the block of the proposer of slot <span class="math">n_{0}</span> because that block hasn’t received at least 40% of the slot’s committee members’ votes. By using <a href="https://notes.ethereum.org/@casparschwa/H1T0k7b85">proposer boost</a>, these “<em>weak</em>” blocks (those with less than 40% attestations) can be reorged by the next proposer to penalize the previous proposer for poor performance, such as being late and therefore rugging some attesters for their correct head votes. Reorgs can have centralizing forces and the more stake an entity holds, the more strategically it can decide whether to reorg a particular block. Large-scale operators have more safety because they can ensure their own validators never vote to reorg their own blocks. Essentially, all nodes of an entity can coordinate to always vote for the current slot’s block rather than its parent if the current block comes from that entity. This coordination potentially allows large entities to risk broadcasting their block later in the slot while still having a high probability of the block becoming canonical. <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Analysis has shown</a> that <strong>by second 4</strong> of the slot, <strong>40% of all attestations</strong> for that slot <strong>have been seen</strong>. A large operator, who controls many validators and knows that these validators will never vote to reorganize its blocks, can slightly delay block propagation without significantly increasing its risk. The same principle applies when a single entity owns consecutive slots. In theory, this entity could wait until the end of the slot (or even longer) before publishing its block. Then, it could use the next slot to solidify that weak block into the chain by leveraging proposer boost.</p>
</li>
<li>
<p><strong>Proposer Timing Games</strong>: <a href="https://timing.pics/">Proposer timing games</a> (also see <a href="https://eprint.iacr.org/2023/760">[1]</a>, <a href="https://arxiv.org/abs/2305.09032">[2]</a>) is a term that summarizes a strategy applied by some block proposers in which they delay their proposal to give the builder more time for extracting MEV. This leads to increased profits for the proposer but <a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">evidently</a> comes with a negative impact on other proposers and especially attesters. Proposer timing games are risky because late blocks have an increased chance of being reorged. In general, large-size operators face lower risks when playing timing games than small-size entities. This stems from the fact that larger operators are on average more sophisticated and have better connectivity in the P2P network: What might be a late block for an Australian validator (go <a href="https://x.com/sassal0x">sassal</a> <img alt=":crown:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/crown.png?v=12" title=":crown:" width="20" />) might be just in time for a US-based Coinbase validator. Thus, the lower the latency, the more a validator can risk delaying.</p>
</li>
</ul>
<div class="math">
\textbf{The above symptoms are all exacerbated by one thing, namely...}
</div>
<div class="math">
\underline{\mathbf{economies\ of\ scale.}}
</div>
<p><a href="https://en.wikipedia.org/wiki/Economies_of_scale">Economies of scale</a> are nothing new and the crypto landscape isn’t immune either. Looking at Wikipedia, it is defined as “<em>the cost advantages that enterprises obtain due to their scale of operation […]</em>”, and the same applies to Ethereum staking:</p>
<div align="center">
  <div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e548616102366792be17847ac823b351c9f94170.png" title="ryZMFz-_R.png"><img height="359" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e548616102366792be17847ac823b351c9f94170_2_400x359.png" width="400" /></a></div>
</div>
<p>Large operators like Coinbase, Kraken, or Kiln can leverage economies of scale to make staking even more profitable. This allows them to offer rewards competitive with those of solo stakers, even after taking their cut. To illustrate this, consider a simple example (the exact numbers are not important here):</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Entity</th>
<th>Validators on one Node</th>
<th>Hardware Costs</th>
<th>Other Costs</th>
<th>Total Cost ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Solo Staker</td>
<td>1 validator</td>
<td>1 Intel NUC ($ 1,200)</td>
<td>$ 5,000</td>
<td>$ 6,200</td>
</tr>
<tr>
<td>Coinbase</td>
<td>1,000 validators</td>
<td>1 Intel NUC ($ 1,200)</td>
<td>$ 50,000</td>
<td>$ 51,200</td>
</tr>
</tbody>
</table>
</div><blockquote>
<p>For more realistic numbers, refer to the latest EthStaker survey published <a href="https://paragraph.xyz/@ethstaker/staking-survey-2024">here</a>. By allocating 10x as much in <em>Other Costs</em> for large operators, we account for the increased complexity of setting up multiple validators on one machine. This is realistic enough for the point we’re making here.</p>
</blockquote>
<p>We can see the effects of economies of scale: the machine used by Coinbase will generate 1,000 times the profits compared to solo stakers, while the costs are only eight times higher. As a result, the ROI for large-scale operators is significantly better.</p>
<p>Using one hardware device for multiple validators is just one piece of the puzzle. Others include:</p>
<ul>
<li>Cloud service provider</li>
<li>ISPs</li>
<li>Geographical locations</li>
<li>Maintenance responsibilities</li>
<li>Client software</li>
<li>And many more…</li>
</ul>
<p>In all these categories, the goal is maximum diversity to minimize the risk of external factors degrading or damaging the network. Despite this goal, economically rational players might prefer a one-stop-shop solution, such as running a Lighthouse + Geth node on a Google/AWS/Hetzner instance located in central Europe, maintained by a dedicated team of specialists. While this setup may perform well in terms of efficiency, Ethereum should not create incentives that further exacerbate centralization.</p>
<div align="center">
<p>
  <img height="392" src="https://ethresear.ch/uploads/default/original/3X/b/a/bac447c3b4a914807987ea637a010bceb40febef.png" width="400" />
</p>
</div>
<p><strong>But who is large-scale and whose not?</strong></p>
<p>The protocol itself does not know which validator is operated by which entity. From the protocol’s perspective, a Coinbase validator looks the same as a solo staker. Therefore, to prevent correlations from emerging, we cannot simply scale rewards and penalties based on the market share of the entity behind a validator. For more on this topic, I recommend Barnabé’s post, <em><a href="https://barnabe.substack.com/p/seeing-like-a-protocol">“Seeing Like a Protocol”</a></em>.</p>
<p>Fortunately, <strong>economies of scale inherently come with correlations</strong>, which is something the protocol can be made aware of. Leveraging economies of scale may linearly scale with correlations, thus we can implement rules to dynamically scale economic incentives and steer the validator set toward diversification.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/9/697934a0c70e654fbc603e570f422269f8116551.png" title="BJbZ1XWuR.png"><img height="358" src="https://ethresear.ch/uploads/default/optimized/3X/6/9/697934a0c70e654fbc603e570f422269f8116551_2_400x358.png" width="400" /></a></div>
<p></p>
</div>
<p>Penalizing correlated faults isn’t something new to Ethereum. In the current <a href="https://eth2book.info/capella/part2/incentives/slashing/">slashing</a> mechanism, a “malicious” validator is initially penalized by a reduction of 1/32 of their effective balance when they are slashed. After being halfway through the withdrawal period, they are subject to an additional penalty (the <em><a href="https://eth2book.info/capella/part2/incentives/slashing/">correlation penalty</a></em>) that scales with the number of validators (specifically their stake) who were slashed around the same time (+/- 18 days). Therefore, a solo staker accidentally voting for two different head blocks, which is a slashable offense, would lose significantly less than a party with a 20% market share (assuming all 20% collectively fail).</p>
<p>In the end, the goal must be to incentivize validators to diversify their setup. As shown in the following example, we want validators to reduce their correlation with other validators, making the whole network more robust against external influences.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/7/678299142da4a042b47e07270b8ccfc7c644e393.png" title="ry5bkuMO0.png"><img height="229" src="https://ethresear.ch/uploads/default/optimized/3X/6/7/678299142da4a042b47e07270b8ccfc7c644e393_2_690x229.png" width="690" /></a></div>
<p></p>
</div>
<h2><a class="anchor" href="https://ethresear.ch#eip-7716-2" name="eip-7716-2"></a>EIP-7716</h2>
<p>The goal of “<a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716: Anti-Correlation Attestation Penalties</a>” is to get us closer to diseconomies of scale. The more homogeneous an entity’s staking setup, the more it should be penalized while non-correlated setups profit from the proposed changes.</p>
<p>With anti-correlation penalties, the previous “<em>economies of scale vs number of validators</em>” might be more like the following:</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/0/e0a2bcab530fcb98384c27b1765434ef0121fdd3.png" title="S179FsfOA.png"><img height="359" src="https://ethresear.ch/uploads/default/optimized/3X/e/0/e0a2bcab530fcb98384c27b1765434ef0121fdd3_2_400x359.png" width="400" /></a></div>
<p></p>
</div>
<p>Anti-correlation penalties were first described by Vitalik in an <a href="https://ethresear.ch/t/supporting-decentralized-staking-through-more-anti-correlation-incentives/19116">ethresearch post</a>. After some <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">initial analyses</a> and a more <a href="https://ethresear.ch/t/a-concrete-proposal-for-correlated-attester-penalties/19341">concrete proposal</a> available, the <a href="https://eips.ethereum.org/EIPS/eip-7716">EIP</a> is now at the point where everyone is invited to look into the inner workings of correlated penalties and leave feedback.</p>
<p>In short, the EIP proposes to multiply the missed (source) vote penalty by a penalty factor that ranges from 0 to 4 but equals 1 on average <em>(notably, this is important to not touch the issuance policy)</em>.</p>
<h4><a class="anchor" href="https://ethresear.ch#how-does-7716-work-3" name="how-does-7716-work-3"></a>How does 7716 work?</h4>
<div class="md-table">
<table>
<thead>
<tr>
<th>Variable</th>
<th>Symbol</th>
<th>Description</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>penalty_factor</code></td>
<td><span class="math">p</span></td>
<td>Penalty scaling factor</td>
<td>dynamic</td>
</tr>
<tr>
<td><code>net_excess_penalties</code></td>
<td><span class="math">p_{exc}</span></td>
<td>Net excess penalties</td>
<td>dynamic</td>
</tr>
<tr>
<td><code>non_participating_balance</code></td>
<td><span class="math">balance_{non\_attesting}</span></td>
<td>Sum balance of not/wrong attesting validators</td>
<td>dynamic</td>
</tr>
<tr>
<td><code>PENALTY_ADJUSTMENT_FACTOR</code></td>
<td><span class="math">p_{adjustment}</span></td>
<td>Penalty adjustment factor</td>
<td>2**12</td>
</tr>
<tr>
<td><code>MAX_PENALTY_FACTOR</code></td>
<td><span class="math">p_{max}</span></td>
<td>Maximum penalty factor</td>
<td>4</td>
</tr>
<tr>
<td><code>EXCESS_PENALTY_RECOVERY_RATE</code></td>
<td><span class="math">p_{recovery}</span></td>
<td>Rate by which the excess penalty decreases</td>
<td>1</td>
</tr>
</tbody>
</table>
</div><blockquote>
<p>The final values for the constants are still to be decided.</p>
</blockquote>
<p>The penalty factor <span class="math">p</span> scales the slot penalties to a maximum of <code>MAX_PENALTY_FACTOR</code>, or down. It’s determined the following:</p>
<div class="math">
p = \min\left(\frac{balance_{non\_attesting}\ \times\ p_{adjustment}}{\max(p_{excess},\ 0.5)\times\ balance_{total}\ +\ 1},\ p_{max} \right)
</div>
<p>and from the <a href="https://github.com/ethereum/consensus-specs/blob/816d338bd09ffc8e83097c4db1764ba834f3adca/specs/_features/correlated_penalties/beacon_chain.md">pyspec implementation</a>; h/t <a href="https://x.com/dapplion">dapplion</a>:</p>
<pre><code class="lang-python">penalty_factor = min(
    ((total_balance - participating_balance) * PENALTY_ADJUSTMENT_FACTOR) // 
    (max(self.net_excess_penalties, 0.5) * total_balance + 1),
    MAX_PENALTY_FACTOR
)
</code></pre>
<p>The formula calculates the penalty factor as a ratio of the “penalty weight” of non-attesting validators to the net excess penalty scaled by the balance of all validators. A higher penalty adjustment factor increases the sensitivity of the penalty factor. Conversely, a higher net excess penalty leads to a lower penalty factor.</p>
<p>Finally, this is how the <code>penalty_factor</code> variable would be used:</p>
<pre><code class="lang-auto">def get_flag_index_deltas(state: BeaconState, flag_index: int) -&gt; Tuple[Sequence[Gwei], Sequence[Gwei]]:
    """
    Return the deltas for a given ``flag_index`` by scanning through the participation flags.
    """
    ...
    for index in get_eligible_validator_indices(state):
        base_reward = get_base_reward(state, index)
        if index in unslashed_participating_indices:
            if not is_in_inactivity_leak(state):
                reward_numerator = base_reward * weight * unslashed_participating_increments
                rewards[index] += Gwei(reward_numerator // (active_increments * WEIGHT_DENOMINATOR))
        elif flag_index != TIMELY_SOURCE_FLAG_INDEX:
            # [New in correlated_penalties]
            slot = committee_slot_of_validator(state, index, previous_epoch)
            penalty_factor = compute_penalty_factor(state, slot) 
            penalties[index] += Gwei(penalty_factor * base_reward * weight // WEIGHT_DENOMINATOR)
    return rewards, penalties
</code></pre>
<p>We check if we are dealing with source votes (line 12), derive the slot in which the validator was supposed to vote (line 14), compute the penalty factor (line 15), and multiply it by the base reward (line 16).</p>
<blockquote>
<p>Although source votes might be a good starting point, the concept can be equally appied to head and target votes.</p>
</blockquote>
<p>The <span class="math">p_{exc}</span> is updated at the end of each slot using:</p>
<div class="math">
p_{exc} = \max(p_{recovery},\ p_{exc} + p) - p_{recovery}
</div>
<p>Which equals to:</p>
<pre><code class="lang-python">net_excess_penalties = max(
        EXCESS_PENALTY_RECOVERY_RATE, 
        net_excess_penalties + penalty_factor
    ) - EXCESS_PENALTY_RECOVERY_RATE
</code></pre>
<p>We can observe the following dynamics:</p>
<ul>
<li>If the balance of non-attesting validators increases, the penalty factor also increases.</li>
<li>If the balance of non-attesting validators remains the same, the penalty factor approaches 1.</li>
<li>If the balance of non-attesting validators decreases, the penalty factor can go below 1 for a while and then approach 1 afterward.</li>
</ul>
<p>When the <code>non_participating_balance</code> continuously increases for several rounds, the <code>penalty_factor</code> and the <code>net_excess_penalties</code> also increase. This continues until the <code>non_participating_balance</code> stops increasing. Then, the <code>net_excess_penalties</code> and the <code>penalty_factor</code> start decreasing together.</p>
<p>With the <code>net_excess_penalties</code> keeping track of the excess penalties of past epochs, the formula can self-regulate what constitutes a “large” number of misses and what does not.</p>
<p>This mechanism ensures that the sum of penalties doesn’t change with this EIP—only the distribution does.</p>
<h2><a class="anchor" href="https://ethresear.ch#some-faqs-4" name="some-faqs-4"></a>Some FAQs</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-1-wouldnt-that-be-even-worse-for-solo-stakers-5" name="h-1-wouldnt-that-be-even-worse-for-solo-stakers-5"></a>1. Wouldn’t that be even worse for solo stakers?</h3>
<p>No. Solo stakers, commonly referred to as small-scale operators or individuals running 1-10 validators from home, are expected to behave in a very uncorrelated manner compared to larger operators. Although factors like geographical location and client software can impact correlations, solo stakers are likely to be offline at different times than large-scale operators such as Coinbase or Kraken. As a result, the penalties solo stakers receive are smaller than those in the current system. In contrast, if a large-scale operator’s staking setup has a bug causing all their validators to fail to attest, the correlation is clear and the penalties are higher.</p>
<p>This expectation was first confirmed in an <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">initial analysis</a> on anti-correlation penalties, which showed that solo stakers and Rocketpool operators would have been better off, while large-scale operators would have received higher penalties on average.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-wouldnt-that-discourage-people-from-using-minority-clients-6" name="h-2-wouldnt-that-discourage-people-from-using-minority-clients-6"></a>2. Wouldn’t that discourage people from using minority clients?</h3>
<p>No. The opposite is the case, as using the majority client leads to even greater correlations. For example, if the Lighthouse client has a bug that causes attesters to vote for the wrong source, then the correlation is super high, and so is the penalty. On the other hand, all Lodestar attesters failing is regarded as a much smaller collective fault. In the case of minority clients being expected to have more bugs, then this would also balance out better because if it’s only a small minority, then the correlation penalty is more forgiving than if it had been some majority client.</p>
<p>No. In fact, it encourages using minority clients. Using the majority clients leads to higher correlations. For example, if the Lighthouse client has a bug causing attesters to vote for the wrong source, the correlation is high and the penalty increases. Conversely, if all Lodestar attesters fail, it is considered a much smaller collective fault. The correlation penalty is more forgiving to a small minority than to a majority client. So, even if minority clients are expected to have more bugs, correlation penalties can steer validators toward using them.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-why-would-it-benefit-decentralization-7" name="h-3-why-would-it-benefit-decentralization-7"></a>3. Why would it benefit decentralization?</h3>
<p>Anti-correlation penalties effectively differentiate between small and large operators without relying on validators that have consolidated their stake or other out-of-protocol solutions. By introducing economic incentives for diversified behavior, we benefit small players who are already “anti-correlated” while encouraging large players to reduce the impact of external factors such as one-node setups, or cloud providers on their staking operations.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-4-wouldnt-that-just-lead-to-big-parties-investing-in-increased-fault-tolerance-while-even-increasing-the-correlations-8" name="h-4-wouldnt-that-just-lead-to-big-parties-investing-in-increased-fault-tolerance-while-even-increasing-the-correlations-8"></a>4. Wouldn’t that just lead to big parties investing in increased fault tolerance while even increasing the correlations?</h3>
<p>If big parties invest in increased fault tolerance, it’s still beneficial. Enhancing fault tolerance is difficult and expensive. At some point, it becomes cheaper to invest in anti-correlation than in further fault tolerance improvements. While large operators might have to move validators from popular cloud platforms to different environments, solo stakers running their nodes from home can continue as they are. Anything that costs large operators money but is free for solo stakers (=diseconomies of scale) fosters decentralization.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/5/25f018bc53924b32c0a7c1deb29b0a0f3075daf1.jpeg" title="HyW84oMdA.jpg"><img height="216" src="https://ethresear.ch/uploads/default/optimized/3X/2/5/25f018bc53924b32c0a7c1deb29b0a0f3075daf1_2_690x216.jpeg" width="690" /></a></div>
<p></p>
</div>
<p>The main argument is, that no matter how big operators react, either going for anti-correlation or, doing the opposite, putting all validators on a single extremely robust node, both cost money and reduce their APY. As fault tolerance has its limits, there is no escape from harsher penalties other than diversifying.</p>
<div align="center">
<p>
  </p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/2/72c96a75749cc73c7789fac6f4fd97834924d1d5.png" title="BJL374W_0.png"><img height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/2/72c96a75749cc73c7789fac6f4fd97834924d1d5_2_328x500.png" width="328" /></a></div>
<p></p>
</div>
<h3><a class="anchor" href="https://ethresear.ch#h-5-this-sounds-super-dangerous-as-i-could-be-penalized-for-32-eth-just-by-missing-a-single-source-vote-9" name="h-5-this-sounds-super-dangerous-as-i-could-be-penalized-for-32-eth-just-by-missing-a-single-source-vote-9"></a>5. This sounds super dangerous, as I could be penalized for 32 ETH just by missing a single source vote.</h3>
<p>This is incorrect since the penalty_factor variable is capped at 4 (to be analyzed). Capping ensures that the correlation penalties never get out of hand.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-6-why-only-focus-on-source-votes-and-not-do-the-same-for-head-and-target-votes-10" name="h-6-why-only-focus-on-source-votes-and-not-do-the-same-for-head-and-target-votes-10"></a>6. Why only focus on source votes and not do the same for head and target votes?</h3>
<p>This is a good question and since research on that topic is still at the very beginning this isn’t decided yet. An argument against head and target votes is the fact that they depend on external factors: as shown in <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">previous analysis</a>, head votes are sensitive to proposer timing games. So, if those timing games become more and more the standard, less well-connected validators (oftentimes solo stakers) could potentially be worse off. However, <a href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">this</a> analysis showed that it would be the opposite and in the long run, small-size stakers would profit from anti-correlation penalties. The same applies to target votes that are harder to get right in the first slot of an epoch compared to every other slot. Nevertheless, in the long run, this should smooth out across validators, allowing us to do anti-correlation penalties for all parts of an attestation, source-, target-, and head votes.</p>
<h2><a class="anchor" href="https://ethresear.ch#useful-links-11" name="useful-links-11"></a>Useful links:</h2>
<div class="md-table">
<table>
<thead>
<tr>
<th>Url</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a class="inline-onebox" href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716: Anti-correlation attestation penalties</a></td>
<td>EIP-7716 (draft)</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://ethresear.ch/t/a-concrete-proposal-for-correlated-attester-penalties/19341">A concrete proposal for correlated attester penalties</a></td>
<td>Original Proposal</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://ethereum-magicians.org/t/eip-7716-anti-correlation-attestation-penalties/20137">EIP-7716: Anti-correlation attestation penalties - EIPs - Fellowship of Ethereum Magicians</a></td>
<td>EthMagicians Post</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://github.com/dapplion/anti-correlation-penalties-faq">GitHub - dapplion/anti-correlation-penalties-faq: Anti correlation penalties FAQ</a></td>
<td>EthBerlin Project</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://github.com/igorline/lighthouse/pull/1">Impement anti-correlation attestation penalties eip by igorline · Pull Request #1 · igorline/lighthouse · GitHub</a></td>
<td>Lighthouse Implementation</td>
</tr>
<tr>
<td><a class="inline-onebox" href="https://ethresear.ch/t/analysis-on-correlated-attestation-penalties/19244">Analysis on ''Correlated Attestation Penalties''</a></td>
<td>Quantitative Analysis</td>
</tr>
</tbody>
</table>
</div>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/diseconomies-of-scale-anti-correlation-penalties-eip-7716/20114">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 20 Jul 2024 08:56:40 +0000</pubDate>
</item>
<item>
<title>EIP 648 for Parallel Rollup</title>
<link>https://ethresear.ch/t/eip-648-for-parallel-rollup/20103</link>
<guid>https://ethresear.ch/t/eip-648-for-parallel-rollup/20103</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP 648, 交易类型, 并行处理, 范围限制, 兼容性问题

总结:<br />
EIP 648是一项2017年的提议，旨在通过引入新的交易类型来提升以太坊网络中交易的并发处理。该提案允许用户指定读写范围，非重叠范围的交易可并行执行。然而，它存在一些问题。首先，用户可能难以预知交易将访问的具体账户，这称为合同预知识问题。其次，它采用悲观并发控制，以账户为单位，可能导致粗粒度的同步，限制了实际的并行性。因此，虽然EIP 648有其优点，但在实际应用到如Rollup等技术时，需要解决这些兼容性和性能优化的问题。 <div>
<h3><a class="anchor" href="https://ethresear.ch#what-is-eip-648-1" name="what-is-eip-648-1"></a>What is EIP 648?</h3>
<p>EIP 648 was proposed back in 2017. The proposal introduces a new transaction type to facilitate parallel transaction processing.</p>
<p>The new type allows users to specify both the read and write ranges of accounts that the transaction will access. Transactions with no overlapping ranges will be executed in parallel. If the ranges overlap, transactions will conflict unless they are all read-only.</p>
<h3><a class="anchor" href="https://ethresear.ch#issues-2" name="issues-2"></a>Issues</h3>
<p>While the proposal is favorable for its simplicity in some cases, it also has some issues that make it difficult to use directly in rollups.</p>
<ol>
<li>
<p><strong>Contract Pre-knowledge:</strong> It is not always straightforward for users to know exactly which accounts their transactions will access beforehand.</p>
</li>
<li>
<p><strong>Account-level:</strong> The approach uses pessimistic concurrency control at the account level. The statements of the ranges act as synchronization primitives, but this has very coarse concurrency granularity (account-level), which can seriously reduce parallelism in many cases.</p>
</li>
</ol>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/eip-648-for-parallel-rollup/20103">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 07:14:22 +0000</pubDate>
</item>
<item>
<title>Commit-Boost: Proposer Platform to Safely Make Commitments</title>
<link>https://ethresear.ch/t/commit-boost-proposer-platform-to-safely-make-commitments/20107</link>
<guid>https://ethresear.ch/t/commit-boost-proposer-platform-to-safely-make-commitments/20107</guid>
<content:encoded><![CDATA[
<div> 关键词：Commit-Boost, Ethereum, Validator Sidecar, Proposer Commitments, Open-Source

总结:<br />
Commit-Boost是一个由社区驱动的开放源代码项目，旨在为Ethereum开发一个通用的验证者平台，以处理与承诺相关的事务。它解决了当前碎片化问题，通过统一标准，让核心开发者能处理升级和故障情况，同时支持MEV-Boost和其他承诺协议。Commit-Boost不依赖于单一侧车，允许验证者安全地参与不同类型的承诺，减少风险和复杂性。团队由非营利实体支持，致力于透明度、安全性和持续发展，没有VC资金，确保软件作为公共利益存在。目前处于MVP阶段，正在进行测试，预计Q3末将进行审计并逐步完善功能。 <div>
<p><em>The following post is an introduction to some and an update to others on a community effort called <a href="https://x.com/Commit_Boost" rel="noopener nofollow ugc">Commit-Boost</a>. Much of this has already been discussed in various public domains / presentations / documentation. Thank you to all the countless teams that already have contributed / committed to contributing to this effort including researchers, validators, builders, relays, client teams, consulting firms, teams building commitment protocols, L2s, restaking platforms, shared sequencers, wallets, and countless others. Please reach out if you would like to contribute to this effort for Ethereum.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/d/adc1d52f519c3c2bb0d61cd00f9c796e249eba81.png" title="Commit-Boost"><img alt="Commit-Boost" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/a/d/adc1d52f519c3c2bb0d61cd00f9c796e249eba81_2_408x375.png" width="408" /></a></div><p></p>
<p><strong>TL;DR</strong></p>
<ul>
<li>Due to the risks developing for Ethereum, core development, and its validator set, a group of teams / individuals are working on developing a public good called Commit-Boost</li>
<li><a href="https://github.com/Commit-Boost/commit-boost-client" rel="noopener nofollow ugc">Commit-Boost</a> is an open-source public good that is fully compatible with <a href="https://github.com/flashbots/mev-boost" rel="noopener nofollow ugc">MEV-Boost</a> but acts as a light-weight validator platform to safely make commitments</li>
<li>Specifically, Commit-Boost is a new Ethereum validator sidecar that is focused on standardizing the last mile of communication between validators and proposer commitment protocols</li>
<li>Commit-Boost has been designed with safety and modularity at its core, with the goal of not limiting the market downstream including stakeholders, flows, proposer commitments, enforcement mechanisms, etc.</li>
<li>While we should always be skeptical of out-of-protocol solutions that directly impact infrastructure this close to the Ethereum protocol layer, if we are going to rely on these solutions, we believe they should be developed, sustained, and governed in a way that encompasses many of the views <a href="https://collective.flashbots.net/t/toward-an-open-research-and-development-process-for-mev-boost/464" rel="noopener nofollow ugc">previously voiced</a> by the community. We have tried to embrace this and strive to model Commit-Boost after it</li>
</ul>
<p><strong>Background</strong></p>
<ul>
<li>Proposer commitments have been an important part of Ethereum’s history. Today, we already see the power of commitments where over 90% of validators give up their autonomy and make a wholesale commitment that outsources block building to a sophisticated actor called a block builder</li>
<li>However, most are starting to agree on a common denominator: in the future, beacon proposers will face a broader set of options of what they may “commit" to–be it inclusions lists or preconfs or other types of commitments such as long-dated blockspace futures–compared to just an external or local payload they see today</li>
<li>A <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">post</a> from Barnabe captures this well; during block construction, the validator “…creates the specs, or the template, by which the resulting block must be created, and the builders engaged by the proposer are tasked with delivering the block according to its specifications”</li>
<li>While this all seems great, the challenge is that many teams building commitments are creating new sidecars driving fragmentation and risks for Ethereum</li>
<li>For Ethereum, there are going to be significant challenges and increased risks during upgrades if there are a handful of sidecars that validators are running</li>
<li>For validators, these risks potentially take us to a world where proposers will need to make decisions on which teams to “bet on” and which sidecars they will need to run to participate in what those teams are offering</li>
<li>For homestakers, this is difficult and they likely will be unable to participate in more than one of these commitments</li>
<li>For sophisticated actors, this increases the attack vector and operational complexity as more and more sidecars are required to be run</li>
<li>Another side effect of this is validators are somewhat locked into using a specific sidecar due to limited operational capacity and the switching costs of running a different sidecar (i.e., vendor lock-in). The higher the switching costs, the more embedded network effects could become if these sidecars only support certain downstream actors / proposer commitment protocols</li>
<li>This also could create a dynamic where core out-of-protocol infrastructure supporting Ethereum which should be a public good, starts being used for monetization, distribution, or other purposes</li>
<li>Due to these dynamics, various teams and individuals across the community are driving the development and testing of open-source / public good software called Commit-Boost. This effort includes researchers, validators, builders, relays, client teams, consulting firms, protocols building commitments, L2s, restaking platforms, and countless others across the community</li>
</ul>
<p><strong>Commit-Boost Overview</strong></p>
<p>Commit-Boost is a community-driven, open-source project developing an unopinionated validator platform to enable safe interactions with commitments. Some of its features include:</p>
<ul>
<li>Unification: Core devs will be able to interact and work with one standard during Ethereum forks / upgrades / when and if things go wrong</li>
<li>Backward compatibility + more: Commit-Boost is not only backward compatible with MEV-Boost, but will improve the life of validators who only run MEV-Boost through increased reporting, telemetry / other off-the-shelf tools validators can employ</li>
<li>Opt-in without running more sidecars: Commit-Boost will allow proposers who want to opt into other commitments do so without having to run multiple sidecars</li>
<li>Robust support: Commit-Boost the software is supported by a not-for-profit entity. This team will be focused on security and robustness through policies and procedures with follow-the-sun type models where there is support 24/7 if / when things go wrong. This team will also be focused on testing and adjustments needed during hard forks and have a team to interact with to help during adoption, improvements, and sustainment</li>
<li>Not VC-backed public good: This team and effort will not be VC-backed. There is no monetization plan. The entity will not be able to sell itself and will not start any monetizable side businesses</li>
</ul>
<p><strong>Robustness, Sustainability, and Security</strong></p>
<ul>
<li>Commit-Boost is being developed as a fully open-source project with contributions from teams across the Ethereum tech stack including from validators, client teams, relays, builders, consulting firms, researchers, and many others. This effort with input and support from these teams will help develop a robust product integrating many perspectives</li>
<li>Commit-Boost will go through code reviews and audits once fully developed</li>
<li>As noted below, there also will be a full-time team that helps maintain and upgrade the software with their core focus on 100% uptime and when there are bugs, robust processes to quickly address and fix</li>
<li>The software stack is also built with the validator at the core and includes off-the-shelf tools for monitoring as well as reducing and proactively addressing any risks that may arise</li>
<li>Last, this public good software will have minimal, but critical open governance around future upgrades with input across the Ethereum</li>
</ul>
<p><strong>Team Supporting / Governance of Commit-Boost Software</strong></p>
<ul>
<li>Entity supporting the software: Not-for-profit entity</li>
<li>Multiple-person team: Multiple devs that focus on transparency, sustainment / development, and research with an initial focus around Commit-Boost the software</li>
<li>Transparency: Open-source <a href="https://github.com/Commit-Boost/commit-boost-client" rel="noopener nofollow ugc">repo</a> and governance calls (see below)</li>
<li>Sustainment / Development: 24/7 follow-the-sun coverage and highly engaged with client teams around upgrades / early in getting testnet support</li>
<li>Research: Helping with open-source research across Ethereum</li>
<li>Governance: This is still a WIP, but at a minimum will run a Commit-Boost, ACD-like calls (first one coming soon) to engage with stakeholders and drive consensus on upgrades / help coordinate around hard forks. A credibly neutral community member will lead these calls / this process that has experience with running governance processes over critical software within the Ethereum community</li>
<li>Funding: All grants</li>
</ul>
<p><strong>Where Will the Grants Come From</strong></p>
<p>The team is in the process of applying for grants from across the ecosystem. We are initially applying to a few organizations across the community that are supporting grants across research organizations and firms focused on PBS and staking. If teams are interested in providing a grant, feel free to comment below / reach out.</p>
<p><strong>Technical Roadmap</strong></p>
<p>Commit-Boost is currently in the MVP phase with <a href="http://holesky.beaconcha.in/slot/2022891" rel="noopener nofollow ugc">testing</a> underway in Holesky with multiple validators. This includes the full functionality of a PBS Module implementing MEV-Boost with additional telemetry and metrics collection. We are continuing the development and feature set of Commit-Boost targeting production-ready software and audits kicking off at the end of Q3. More details are in the Commit-Boost <a href="https://github.com/Commit-Boost/commit-boost-client/issues" rel="noopener nofollow ugc">repo</a> and we are keen to get feedback / engage with the community around these.</p>
<p>Some near-term high-level highlights from the roadmap include:</p>
<ul>
<li>Optimized and functional MEV-Boost module including multiple metrics for reporting and extensions such as configurable timing for get_header / get_payload calls</li>
<li>Pre-made dashboards on Grafana for all core services</li>
<li>Improved reliability and integrations for incident response</li>
<li>R&amp;D / spec signing mechanism to fit as many validator set-ups as possible</li>
<li>Expanding modularity and optionality (i.e., supporting different types of signatures and modules)</li>
</ul>
<p><strong>Commit-Boost Design Principles</strong></p>
<ul>
<li>Built for validators: Platform that not only can help validators today (i.e., can improve the lives of validators even if they just run an MEV-Boost module) but allows validators to be ready for the market of tomorrow (i.e., preconfs, inclusion lists, etc)</li>
<li>Neutrality: No opinions, the platform will be proposer commitment agnostic, relay agnostic, transaction flow agnostic, etc. The goal is to build a platform that doesn’t limit the design space downstream while reducing risks of fragmentation for validators and Ethereum</li>
<li>Unified: Validators run one core sidecar with the ability to opt into many different commitments</li>
<li>Safety: Open-source code developed with input by the community with community reviews / audits</li>
<li>Reduce risks: Modularized and transparency are core to reducing risk / overhead for the proposer to manage commitments and their broader operational processes</li>
<li>Values aligned: Public good with no plans for monetization. We will continuously ask ourselves: would Vitalik run Commit-Boost and can this be designed in a way to increase the decentralization of Ethereum block construction</li>
</ul>
<p><strong>From the Perspective of the Proposer</strong></p>
<p>More details on what it takes to run Commit-Boost as a node operator can be found <a href="https://commit-boost.github.io/commit-boost-client/get_started/overview" rel="noopener nofollow ugc">here</a>. Please note that this has not been finalized and over the next few weeks we will be making updates (see roadmap / milestones above).</p>
<ul>
<li>Run a single sidecar with support for MEV-Boost and other proposer commitments protocols, such as precons / other commitments</li>
<li>Out-of-the-box support for metrics reporting and dashboards to have clear insight around what is happening in your validator seen through dashboards such as Grafana</li>
<li>Plug-in system to add custom modules, i.e., receive a notification on Telegram if a relay fails to deliver a block</li>
<li>Standardized way to provide a signature to opt into a commitment</li>
<li>Creates constraints / condition sets and pass these constraints downstream</li>
</ul>
<p><strong>From the Perspective of the Proposer Commitment Protocol / Module Creator</strong></p>
<p>More details on what it takes to build a module / metrics can be found <a href="https://commit-boost.github.io/commit-boost-client/category/developing" rel="noopener nofollow ugc">here</a>. Please note that this has not been finalized and over the next few weeks we will finalize moving parts that impact module creators (see roadmap / milestones above).</p>
<ul>
<li>A modular platform to develop and distribute proposer commitments protocols</li>
<li>A single API to interact with validators</li>
<li>Support for hard-forks and new protocol requirements</li>
</ul>
<p><strong>Architecture of Commit-Boost</strong></p>
<p>More details can be found in the Commit-Boost <a href="https://commit-boost.github.io/commit-boost-client/" rel="noopener nofollow ugc">documentation</a>. However, below is a schematic of Commit-Boost. This proposed architecture allows proposers to run one sidecar, but still retain the ability to opt into a network of proposer commitment modules. More specifically, with this middleware, the proposer will only need to (in the case of delegation / light weight commitments) run one sidecar and limit their responsibilities to only selecting which module / proposer commitment protocol they would like to subscribe to.</p>
<p>It is important to note that the below depiction contains just a few examples of proposer commitment modules that can run on Commit-Boost. The design space for modules is completely open / not gated by the Commit-Boost software and proposers will be responsible for opting into the commitments they wish to subscribe to (i.e., a proposer is responsible for which modules they will subscribe to).</p>
<p><strong>Terminology</strong></p>
<ul>
<li>Proposer: entity, staking pool NoOp, or DVT cluster with the right to propose the next block</li>
<li>Commitment: a constraint or condition that the proposer choses and agrees to via a signature</li>
<li>Key Manager: some proposers use key managers or remote signers as part of their proposer / validator duties. Please note, that Commit-Boost is being designed in a way where it does not require validators to run key managers and working on solutions for monolithic set-ups</li>
<li>Consensus Client: for example, Lighthouse or Teku (see <a href="https://ethereum.org/en/developers/docs/nodes-and-clients/" rel="noopener nofollow ugc">here</a> for more details)</li>
<li>Commitment Modules: community-built modules allowing proposers to make commitment, including some of the logic of the proposer commitment protocol</li>
<li>Signer API: The signer API is one of the core components around Commit-Boost. This is used to provide signatures from the proposer to the proposer commitment protocol. This is still in the design but proxy signatures will be used in nearly all cases (there are some outlier cases). For more details on the API please see <a href="https://commit-boost.github.io/commit-boost-client/api/" rel="noopener nofollow ugc">here</a>. For an example of how to communicate with the Signer API, please see <a href="https://commit-boost.github.io/commit-boost-client/developing/commit-module" rel="noopener nofollow ugc">here</a></li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/a/ca4fdf7f738261cf46b1505dc56198da182592dc.png" title="Schematic"><img alt="Schematic" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/c/a/ca4fdf7f738261cf46b1505dc56198da182592dc_2_690x411.png" width="690" /></a></div><p></p>
<p>Using this as a middleware instead of direct modification to the consensus client or running a sidecar per commitment will allow for each component to be sustained independently and will provide for cross proposer commitment compatibility. This will also allow for a bit of time for the market to play out, but via a public good, standardize the last mile of communication to help address the risks (discussed in the background section above) developing. Once the market does play out, and the community is able to observe some dynamics (the good and the bad), we can and should push for CL changes.</p>
<p><strong>Resources</strong></p>
<ul>
<li><a href="https://github.com/Commit-Boost" rel="noopener nofollow ugc">Commit-Boost Repo</a></li>
<li>Commit-Boost <a href="https://commit-boost.github.io/commit-boost-client/" rel="noopener nofollow ugc">documentation</a></li>
<li>List of presentations</li>
<li>Original post on ETH Research, read more <a href="https://ethresear.ch/t/based-proposer-commitments-ethereum-s-marketplace-for-proposer-commitments/19517">here</a></li>
<li>First presentation to the community can be found <a href="https://www.youtube.com/watch?v=jrm4ZUoj9xY&amp;list=PLJqWcTqh_zKHDFarAcF29QfdMlUpReZrR&amp;index=11" rel="noopener nofollow ugc">here</a></li>
<li>Second presentation at zuBerlin can be found <a href="https://streameth.org/zuberlin/watch?session=66681afef9b8e98b1ec95fdd" rel="noopener nofollow ugc">here</a></li>
<li>zuBerlin Devnet notion can be found <a href="https://twisty-wednesday-4be.notion.site/ZuBerlin-Preconfs-Devnet-b693047f41e7407cadac0170a6711dea" rel="noopener nofollow ugc">here</a></li>
<li>Mev-Boost Community call <a href="https://www.youtube.com/watch?v=UgoFjNkkTac" rel="noopener nofollow ugc">here</a></li>
<li>Espresso / One Balance Sequencing day here (this will be updated when the link is ready)</li>
<li>Gattaca MEV Day here (this will be updated when the link is ready)</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/commit-boost-proposer-platform-to-safely-make-commitments/20107">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 14:33:05 +0000</pubDate>
</item>
<item>
<title>What is "RealTPS" in Blockchain</title>
<link>https://ethresear.ch/t/what-is-realtps-in-blockchain/20098</link>
<guid>https://ethresear.ch/t/what-is-realtps-in-blockchain/20098</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、TPS、透明度、交易定义、测量工具

总结:<br />这篇文章讨论了区块链中TPS（交易每秒）指标的不透明性问题。传统上，TPS被模糊地定义和测量，与区块链的透明性原则相冲突。文章指出，应以确认交易（ConfirmedTransactions）为基础来计算TPS，质疑现有的高TPS宣称可能未经详细说明。文章提到Hyperledger的Caliper和Quorum推荐的测量工具存在局限，如只考虑单节点性能，未充分反映分布式网络特性。作者团队开发了新的工具AnTPS，旨在提供透明的多节点、多账户测量，支持不同场景和环境，以改进对区块链TPS的准确评估。 <div>
<p>Authors: <a href="https://x.com/Kyungmin7984" rel="noopener nofollow ugc">@Kyungmin</a> <a href="https://github.com/bicoCrypto" rel="noopener nofollow ugc">@bicoCrypto</a> <a href="https://github.com/solmingming" rel="noopener nofollow ugc">@solmingming</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h2>
<p>The current concept of TPS (Transactions Per Second) in blockchain is being disclosed in an ambiguous and opaque manner, conflicting with blockchain’s core value of transparency. This article reconsiders the definition of transactions in blockchain, compares theoretical figures with actual measurements, evaluates existing measurement tools, introduces our self-developed tool, and proposes a more accurate and transparent TPS measurement method.</p>
<h2><a class="anchor" href="https://ethresear.ch#problem-2" name="problem-2"></a>Problem</h2>
<p>The biggest change in the transition from Web2 to Web3 is decentralization. This has led to improved system accessibility and increased information transparency. However, there is still opaque information in the blockchain ecosystem, with TPS being a prime example.</p>
<p>In transaction processing systems, especially financial systems, TPS is a crucial performance indicator. However, the TPS information currently provided in blockchain is limited to simple figures, with detailed information about measurement methods and processes remaining opaque.</p>
<p>While blockchain smart contracts are operated transparently through verification and auditing, we still rely on the foundation’s system for the blockchain nodes themselves, lacking verification procedures similar to smart contracts.</p>
<h2><a class="anchor" href="https://ethresear.ch#tps-in-traditional-web2-3" name="tps-in-traditional-web2-3"></a>TPS in traditional Web2</h2>
<p>When discussing blockchain TPS, VISA’s processing capability is often mentioned as a comparison. <a href="https://www.reddit.com/r/nanocurrency/comments/82438o/visa_is_capable_of_performing_24000_transactions/" rel="noopener nofollow ugc">VISA officially announced a processing capability of 24,000 TPS</a>, but <a href="https://news.bitcoin.com/no-visa-doesnt-handle-24000-tps-and-neither-does-your-pet-blockchain/" rel="noopener nofollow ugc">this has been questioned</a>:</p>
<p>In centralized Web2 systems, it’s difficult to verify such issues. However, blockchain (Web3) systems are decentralized and their code is managed as open source, making it possible to verify TPS.</p>
<h2><a class="anchor" href="https://ethresear.ch#tps-in-web3-4" name="tps-in-web3-4"></a>TPS in Web3</h2>
<p>In blockchain systems with public nodes and permissionless nodes, anyone can participate in the network, operate nodes, and access the system. Even without connecting to the mainnet or testnet, the source code is publicly available, allowing independent network construction or modification after forking.</p>
<p>Ethereum and most EVM-compatible blockchains publish high TPS figures. For example, Avalanche C-Chain is introduced as capable of achieving 4,500 TPS. However, information on how this figure was measured is not provided.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/4/748ee3c646e8c2964dd294eefe5aa1491ce65b45.jpeg" title="Image"><img alt="Image" height="378" src="https://ethresear.ch/uploads/default/optimized/3X/7/4/748ee3c646e8c2964dd294eefe5aa1491ce65b45_2_690x378.jpeg" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#time-to-define-transaction-5" name="time-to-define-transaction-5"></a>Time to Define Transaction</h2>
<p>In EVM blockchains, the term “Transaction” is used in various contexts:</p>
<ul>
<li>SendTransaction: Simply refers to the act of sending a transaction, without guaranteeing the final state or completeness of the transaction.</li>
<li>PendingTransaction: The state where a transaction is waiting in the node’s memory pool (Mempool).</li>
<li>QueuedTransaction: Similar to Pending, waiting in the node’s memory pool, but distinguished in the serialization process through Nonce.</li>
<li>ConfirmedTransaction: The state where a transaction receipt has been issued, indicating the transaction has succeeded or failed.</li>
</ul>
<p>We believe that TPS should be calculated based on ConfirmedTransactions when measuring. Based on this, we propose the following formula for calculating TPS:<br />
TPS = BlockGasLimit / (TxGasUsed * BlockCreationTime)</p>
<p>Currently, Avalanche C-Chain’s BlockGasLimit is 15,000,000<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/9/c909ced7994a754fc7875e8dd1730093faedad3e.png" title="Tx Gaslimit"><img alt="Tx Gaslimit" height="225" src="https://ethresear.ch/uploads/default/optimized/3X/c/9/c909ced7994a754fc7875e8dd1730093faedad3e_2_690x225.png" width="690" /></a></div><p></p>
<p>Even assuming the simplest transaction (TxGasUsed = 21,000) and the shortest block creation time (BlockCreationTime = 1 second), the theoretical maximum TPS is 715. This shows a significant difference from the officially announced 4,500 TPS. (The actual measured value would naturally be even lower)</p>
<p>We speculate that this difference may occur due to:</p>
<ul>
<li>The transaction standard used in TPS calculation may not be ConfirmedTransaction</li>
<li>The Avalanche version that achieved 4,500 TPS may differ from the version currently used in public nodes</li>
<li>Differences in TPS measurement methods and methodologies</li>
</ul>
<p>Such opaque information raises questions about the reliability and accuracy of TPS figures.<br />
Monad has published a critical analysis of these limitations of blockchain TPS: <a href="https://www.monad.xyz/wtf-is-tps" rel="noopener nofollow ugc">WTF is TPS?</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tps-benchmark-tools-6" name="tps-benchmark-tools-6"></a>TPS Benchmark Tools</h2>
<p>There are currently two main blockchain TPS benchmark tools in use:</p>
<ol>
<li><a href="https://github.com/hyperledger/caliper" rel="noopener nofollow ugc">Hyperledger Caliper</a>: Developed by the Hyperledger Foundation</li>
<li><a href="https://github.com/drandreaskrueger/chainhammer" rel="noopener nofollow ugc">ChainHammer</a>: Recommended by Quorum (a private blockchain developed by ConsenSys)<br />
Note: ChainHammer’s most recent commit was 2 years ago, making it essentially outdated.</li>
</ol>
<p>Caliper is written in JavaScript and is a highly complete project. However, there are doubts about whether it is optimized for measuring “blockchain” TPS:</p>
<ol>
<li>TPS measurement on a single node:<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/7/67bd0b50a563472ac93dafc3fa2e17effa0919e8.png" title="Figure2"><img alt="Figure2" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/6/7/67bd0b50a563472ac93dafc3fa2e17effa0919e8_2_690x389.png" width="690" /></a></div></li>
</ol>
<p>The core of blockchain is distributed storage of data through consensus. However, Caliper only conducts TPS measurements on a single node, which can measure the TPS of individual nodes but does not accurately reflect the TPS of the entire blockchain network. (The transaction propagation process is not considered)</p>
<ol>
<li>Limitation of measurement from a single account:<br />
In EVM, EOA (Externally Owned Account) has a Nonce value, causing transactions to be processed sequentially.<br />
While 2024 was predicted to be the era of parallel EVM, current parallel processing technology still proceeds in an optimistic manner, requiring re-execution in case of conflicts. (Cases requiring re-execution can hardly be considered true parallel execution.)<br />
Therefore, execution from a single account versus multiple accounts can have a significant impact on TPS.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#antpsan-ti-tps-7" name="antpsan-ti-tps-7"></a>AnTPS(An-ti TPS)</h2>
<p>To improve these limitations, we have developed our own blockchain benchmark tool, AnTPS, using Golang: <a href="https://github.com/decipherhub/AnTPS" rel="noopener nofollow ugc">Github</a><br />
Features include:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/0/f0cff11ba6f328b500e85b78f194763580ca940c.png" title="image"><img alt="image" height="283" src="https://ethresear.ch/uploads/default/optimized/3X/f/0/f0cff11ba6f328b500e85b78f194763580ca940c_2_690x283.png" width="690" /></a></div><p></p>
<ul>
<li>Transparently providing measurement environment/results.</li>
<li>Conducting measurements on at least two or more nodes.</li>
<li>Supporting measurement cases for both single and multiple accounts.</li>
<li>Supporting various scenarios during measurement (ERC20/721/1155/NativeToken).</li>
<li>Supporting not only local environment measurements but also Cloud environments through IaC.</li>
</ul>
<p>Our goal is to overcome the limitations of existing tools while providing information transparently.<br />
We welcome your opinions and feedback. Thank you.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/what-is-realtps-in-blockchain/20098">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 03:52:11 +0000</pubDate>
</item>
<item>
<title>Based Preconfirmations with Multi-round MEV-Boost</title>
<link>https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091</link>
<guid>https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091</guid>
<content:encoded><![CDATA[
<div> 关键词：基于预确认、多轮MEV-Boost、L1 PBS管道、外部性、区块链安全

总结:
本文探讨了基于预确认的 rollup 模型存在的问题，尤其是其12秒的区块时间所导致的负面效应。作者提出了多轮MEV-Boost（MR-MEV-Boost）的概念，通过在一个槽位内运行多次MEV-Boost拍卖来实现快速预确认，从而保持了基于预确认rollup的优点如同步兼容性和L1抗审查性，同时减轻了预确认带来的负面影响。文章分析了MR-MEV-Boost的优势和挑战，如减少了延迟竞赛、缓解拥堵、改进定价机制，并讨论了用户和协议设计中的公平交换问题。尽管存在一些限制，如较慢的预确认速度和对-relayer负担的增加，但该方案为解决基于预确认的rollup问题提供了新的思路。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb1798cc79775d7958124717d6ba5cc97c1aa008.jpeg" title="image"><img alt="image" height="394" src="https://ethresear.ch/uploads/default/original/3X/f/b/fb1798cc79775d7958124717d6ba5cc97c1aa008.jpeg" width="690" /></a></div><p></p>
<p>By <a href="https://twitter.com/linoscope" rel="noopener nofollow ugc">Lin Oshitani</a> (<a href="https://switchboard.nethermind.io/" rel="noopener nofollow ugc">Nethermind Switchboard</a>, <a href="https://www.nethermind.io/nethermind-research" rel="noopener nofollow ugc">Nethermind Research</a>). Many thanks to <a href="https://twitter.com/ConorMcMenamin9" rel="noopener nofollow ugc">Conor</a> for the detailed back-and-forth on crafting this document and to <a href="https://www.linkedin.com/in/aikaterini-panagiota-stouka/" rel="noopener nofollow ugc">Aikaterini</a>, <a href="https://x.com/ElenaPetreska0x" rel="noopener nofollow ugc">Elena</a>, <a href="https://twitter.com/smartprogrammer" rel="noopener nofollow ugc">Ahmad</a>, <a href="https://twitter.com/aj_jalan" rel="noopener nofollow ugc">Anshu</a>, <a href="https://twitter.com/swp0x0" rel="noopener nofollow ugc">Swapnil</a>, <a href="https://twitter.com/tkstanczak" rel="noopener nofollow ugc">Tomasz</a>, <a href="https://twitter.com/totorovirus" rel="noopener nofollow ugc">Jinsuk</a>, <a href="https://twitter.com/0xQuintus" rel="noopener nofollow ugc">Quintus</a>, <a href="https://x.com/ceciliaz030" rel="noopener nofollow ugc">Ceciliaz</a>, and <a href="https://twitter.com/Brechtpd" rel="noopener nofollow ugc">Brecht</a> for the helpful comments and/or review. This work was partly funded by Taiko. The views expressed are my own and do not necessarily reflect those of the reviewers or Taiko.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h1>
<p>As we outlined in our previous post <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695">Strawmanning Based Preconfirmations</a>, naive implementations of based preconfirmations introduce many negative externalities that require thoughtful consideration.</p>
<p>In this post, we will expand on the negative externalities of based preconfirmations by examining them through the lens of the L1 PBS pipeline. Then, we propose <em>multi-round MEV-Boost</em>, a modification of MEV-Boost that enables based preconfirmations by running multiple rounds of MEV-Boost auctions within a single slot. This approach inherits the L1 PBS pipeline and mitigates the negative externalities of based preconfirmations as a result.</p>
<h1><a class="anchor" href="https://ethresear.ch#motivation-2" name="motivation-2"></a>Motivation</h1>
<p>As Justin Drake <a href="https://ethresear.ch/t/based-rollups-superpowers-from-l1-sequencing/15016#:~:text=a%20based%20rollup%20is%20one%20where%20the%20next%20L1%20proposer%20may%2C%20in%20collaboration%20with%20L1%20searchers%20and%20builders%2C%20permissionlessly%20include%20the%20next%20rollup%20block%20as%20part%20of%20the%20next%20L1%20block">defines</a> in the original post, based rollups are rollups “where the next L1 proposer may, in collaboration with L1 searchers and builders, permissionlessly include the next rollup block as part of the next L1 block”. Using the <a href="https://flashbots.mirror.xyz/bqCakwfQZkMsq63b50vib-nibo5eKai0QuK7m-Dsxpo" rel="noopener nofollow ugc">MEV supply chain</a> diagram, based rollups can be illustrated below:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1.png" title="Based Rollups (5) (1)"><img alt="Based Rollups (5) (1)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1_2_690x346.png" width="690" /></a></div><p></p>
<p>Notice that the L2 transactions, represented as the red line, go through the same process as the L1 transactions, represented as the black line. By effectively “piggybacking” the L1 PBS pipeline, based rollups provide two key benefits:</p>
<ul>
<li><strong>Benefit 1</strong>: Since no additional actors (and thus no additional choke points) are introduced for L2 sequencing, based rollups fully inherit L1 censorship resistance, liveness, and credible neutrality.</li>
<li><strong>Benefit 2</strong>: Since the L1 and L2 transactions are sequenced by the same entity (the builder), based rollups enable not only synchronous L2-L2 composability but also synchronous L1-L2 composability.</li>
</ul>
<p>Based rollups are great. They solve L2 fragmentation and sequencer decentralization while enabling L1 composability and inheriting L1’s censorship resistance, liveness, and credible neutrality. They are the only rollups that can have these properties simultaneously.</p>
<p>However, they have one large drawback: they also inherit the 12-second L1 block time. To address the slow confirmation time, Justin introduced <a href="https://ethresear.ch/t/based-preconfirmations/17353">base preconfirmations</a>. In this approach, L1 proposers can opt into providing preconfirmations for based rollup L2 transactions, as shown below:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/e/6e65221a830715cead4428b2724688ce66d7520c.png" title="Based Preconf (2) (1)"><img alt="Based Preconf (2) (1)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/6/e/6e65221a830715cead4428b2724688ce66d7520c_2_690x346.png" width="690" /></a></div><p></p>
<p>Since providing preconfirmations requires technical sophistication, most based preconfirmation designs include a delegation mechanism that allows validators to outsource the preconfirmation duty to a designated preconfer, as illustrated below:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/9/f9346fd068da5aa3ae0e57fceccc6c2af223b958.png" title="Based Preconf with delegation (2)"><img alt="Based Preconf with delegation (2)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/f/9/f9346fd068da5aa3ae0e57fceccc6c2af223b958_2_690x346.png" width="690" /></a></div><p></p>
<p>Notice that L2 and L1 transactions no longer share the block-building pipeline. As such, the benefits of based rollups are diminished:</p>
<ul>
<li>On benefit 1: We introduced an additional choke point to the system, the preconfer, which can censor L2 transactions or degrade L2 liveness by going down. As a result, the inheritance of L1 censorship resistance and liveness are degraded.</li>
<li>On benefit 2: We now have two parallel block-building entities: one for L1 (the builder) and another for L2 (the preconfer). Consequently, L1-L2 composability now requires coordination between the builder and the preconfer. This adds complexity and can lead to <em>builder-preconfer integration</em>, where the proposer delegates not only their preconfirmation right but also the whole block-building right to the preconfer ahead of their slot.</li>
</ul>
<p>In summary, by introducing preconfirmations, we lost the below structure:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1.png" title="Based Rollups (5) (1)"><img alt="Based Rollups (5) (1)" height="346" src="https://ethresear.ch/uploads/default/optimized/3X/a/c/ac29f931cf332c1b1b38334158920d6807f499f1_2_690x346.png" width="690" /></a></div><p></p>
<p>As a result, many of the benefits of based rollups are diminished.</p>
<p>So, what if we keep this pipeline but run it multiple times within a slot to achieve fast preconfirmations? This brings us to the main contribution of this document: <em>Multi-round MEV-Boost</em>.</p>
<h1><a class="anchor" href="https://ethresear.ch#multi-round-mev-boost-3" name="multi-round-mev-boost-3"></a>Multi-round MEV-Boost</h1>
<p>At a high level, Multi-round MEV-Boost, or <em>MR-MEV-Boost</em> (pronounced “<em>mister-mev-boost</em>”, h/t <a href="https://twitter.com/ConorMcMenamin9" rel="noopener nofollow ugc">Conor</a> for the idea on the pronounciation :)) for short, works as follows:</p>
<ul>
<li>Split each slot into a fixed number of <em>rounds, e</em>.g., 4 rounds with 3 seconds each.</li>
<li>Within each round, run a single MEV-Boost auction. As a result of the auction, a single <em>partial block</em> (a.k.a <em>partial payload</em>) will be signed and published, i.e., the partial block will be <em>preconfirmed</em>.</li>
<li>The full block is created and published at the end of the slot. The full block should contain the partial blocks in the exact order they were preconfirmed without inserting any transactions before or in between.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#refresher-mev-boost-4" name="refresher-mev-boost-4"></a>Refresher: MEV-Boost</h2>
<p>Before diving deeper into the proposed protocol, let’s quickly review today’s <a href="https://docs.flashbots.net/flashbots-mev-boost/introduction" rel="noopener nofollow ugc">MEV-Boost</a> PBS pipeline used in L1 Ethereum.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/e/fe199d4c844c9230a675292724deb29c9e03a3df.png" title="MEV-Boost"><img alt="MEV-Boost" height="500" src="https://ethresear.ch/uploads/default/original/3X/f/e/fe199d4c844c9230a675292724deb29c9e03a3df.png" width="609" /></a></div><p></p>
<ol>
<li>Builders send the <code>header</code>, <code>payload</code>, and <code>bid</code> to the relayer.</li>
<li>The relayer checks the validity (the <code>bid</code> is correct, the <code>payload</code> does not contain invalid transactions, etc), stores the <code>payload</code>, and then sends the <code>header</code> and <code>bid</code> to the proposer.</li>
<li>The proposer selects the header with the highest bid, signs it, and then sends the signed header to the relayer.</li>
<li>The relayer propagates the signed header and corresponding payload to the network.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#protocol-description-5" name="protocol-description-5"></a>Protocol Description</h2>
<p>In this section, we describe the MR-MEV-Boost protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#protocol-flow-overview-6" name="protocol-flow-overview-6"></a>Protocol Flow Overview</h3>
<p>To incentivize proposers to provide preconfirmations, we introduce a <em>preconf transaction</em>, where the payment of a <em>preconf tip</em> is conditioned on being preconfirmed. It will include the following information on top of the transaction payload itself:</p>
<ul>
<li><code>tip</code>: The preconfirmation tip paid for being preconfirmed.</li>
<li><code>target_slot</code>: The latest slot in which the preconf transaction can be included.</li>
<li><code>target_round</code>: The latest round within the <code>target_slot</code> in which the preconf transaction can be included.</li>
</ul>
<p>The <a href="https://ethresear.ch#preconf-transaction">Preconf Transaction</a> section will discuss the encoding and enforcement of these conditions.</p>
<p>Using this new transaction type, MR-MEV-Boost works as follows:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/a/7a4dc3f4c38b4184016390e2e48dc44e5630da74.png" title="MR-MEV-Boost"><img alt="MR-MEV-Boost" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/a/7a4dc3f4c38b4184016390e2e48dc44e5630da74_2_252x500.png" width="252" /></a></div><p></p>
<ol>
<li>Users submit preconf transactions to the builders. The submission can be through any order flow pipeline used in current L1, such as:
<ul>
<li>Public mempool.</li>
<li>Private order flow.</li>
<li>Order flow auctions on <a href="https://mevblocker.io/" rel="noopener nofollow ugc">MEVBlocker</a>, <a href="https://docs.flashbots.net/flashbots-protect/mev-share" rel="noopener nofollow ugc">MEV-Share</a>, <a href="https://writings.flashbots.net/the-future-of-mev-is-suave" rel="noopener nofollow ugc">SUAVE</a>, etc.</li>
</ul>
</li>
<li>The builders build <code>partial_payload</code>s. The partial payload built by the builders should only include preconf transactions with <code>target_slot</code> and <code>target_round</code> at or after the current block/round. To commit to this, the builder signs the <code>merkle_root</code> (denoted as <code>sig_b</code> ) and becomes subject to builder slashing condition 1, described in the <a href="https://ethresear.ch#slashing-conditions">slashing condition section</a>.</li>
<li>The relayer checks the validity (e.g., the <code>bid</code> is correct, the <code>partial_payload</code> does not contain invalid transactions, etc.), stores the <code>partial_payload</code>, and then sends the <code>merkle_root</code> and <code>bid</code> to the proposer.</li>
<li>Proposer signs (denoted as <code>sig_p</code>) and returns the selected <code>merkle_root</code> together with the current <code>round</code>.</li>
<li>The relay publishes the selected <code>partial_payload</code> and the associated round and signatures to the preconf network. Note that the preconf network is different from the existing L1 p2p network. Only entities interested in the preconfirmed state (partial block builders, relays, full-node providers, etc.) must subscribe to the preconf network.</li>
<li>End users—or, more precisely, the L2/L1 full nodes to which they are connected—verify that the <code>merkle_root</code> is signed by the proposer and is associated with the current <code>round</code>. Upon confirmation, they accept the <code>partial_payload</code> as preconfirmed and execute it to update to the latest preconfirmed state.</li>
<li>
<ol>
<li>to 6. is repeated multiple rounds within the slot. The number of rounds within each slot will be fixed. The final round will run concurrently with the full block MEV-Boost auction at 8.-11.</li>
</ol>
</li>
<li>to 11. The MEV-Boost auction is conducted for the full block. An important difference with the usual L1 MEV-Boost auction is that the <code>merkle_proofs</code> are propagated from the builder to the proposer. These proofs prove that the <code>partial_payload</code>s are included in the full block in the order they were preconfirmed without any other transaction being inserted before or between them. By validating these proofs, the proposer can ensure that the proposer slashing condition 2, described in the <a href="https://ethresear.ch#slashing-conditions">slashing conditions section</a>, is not violated without needing to trust the relayer (h/t to <a href="https://twitter.com/Brechtpd" rel="noopener nofollow ugc">Brecht</a> for the idea of using Merkle proofs here).</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#preconf-transaction-7" name="preconf-transaction-7"></a>Preconf Transaction</h3>
<p>Let’s consider the encoding of the preconf transactions. For L2s, the additional fields can be introduced as custom encodings of the transactions. For L1, they can be implemented through an <a href="https://eips.ethereum.org/EIPS/eip-4337" rel="noopener nofollow ugc">ERC-4337</a>-style entry point contract that wraps the contract calls with additional information.</p>
<p>To enforce the expiration, the L2 execution layer (or <a href="https://github.com/ethereum-optimism/specs/blob/b1c9b7985b65bd2d065a414f5ad0552f36e48540/specs/protocol/derivation.md#deriving-the-transaction-list" rel="noopener nofollow ugc">derivation layer</a>) and L1 entry point contract will filter out preconf transactions with expired <code>target_slot</code>. On the other hand, since the L1 is unaware of the concept of rounds, expiration based on <code>target_round</code> will be enforced via builder slashing condition 1, explained in the next section.</p>
<h3><a class="anchor" href="https://ethresear.ch#slashing-conditions-8" name="slashing-conditions-8"></a>Slashing Conditions</h3>
<p>To ensure that the full block matches with the preconfed partial blocks, the proposer will be subject to:</p>
<ul>
<li><strong>Proposer slashing condition 1</strong>: The proposer must not sign two conflicting <code>merkle_root</code>s within the same round.</li>
<li><strong>Proposer slashing condition 2</strong>: The final <code>full_payload</code> should contain all the <code>partial_payload</code>s in the order they are signed and published without any other transaction being inserted before or in between.</li>
</ul>
<p>Furthermore, to crypto-economically enforce the expiration of preconf transactions, the builder will be subject to:</p>
<ul>
<li><strong>Builder slashing condition 1:</strong> Each <code>partial_payload</code> must only include preconf transactions with <code>target_slot</code> and <code>target_round</code> at or after the current slot/round.</li>
</ul>
<p>We impose this condition on the builder rather than the proposer because the proposer does not see the partial payload when signing. An alternative approach would be to make this a proposer slashing condition and require the relayer to ensure the condition is not violated. However, this would necessitate the proposer trusting the relayer to avoid being slashed rather than only relying on the relayer to avoid missing a slot, as is currently done in L1 MEV-Boost.</p>
<h3><a class="anchor" href="https://ethresear.ch#user-actions-9" name="user-actions-9"></a>User Actions</h3>
<p>To mitigate the <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695#problem-4-fair-exchange-7">fair exchange problem</a>, wallets or full nodes to which end users are connected should take the actions below:</p>
<ul>
<li><strong>User action 1</strong>: Stop submitting preconf transactions if preconfirmed <code>partial_payload</code>s are not published in a timely manner. For example, if we have 4 rounds in a slot, then stop submitting preconf transactions if a <code>partial_payload</code> is not published every 3 seconds.</li>
<li><strong>User action 2</strong>: Set <code>target_slot</code> and <code>target_round</code> to a reasonably close block and round (e.g., one or two rounds ahead). By doing so, builders are required to respond in a timely manner to preconfirmation transactions to avoid the preconfirmation transactions being invalidated.</li>
</ul>
<p>More on how the fair exchange is addressed is described in the <a href="https://ethresear.ch#analysis">analysis section</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#l1-l2-composability-10" name="l1-l2-composability-10"></a>L1-L2 Composability</h3>
<p>Since the partial payloads can contain both L1 and L2 transactions, builders can ensure L1-L2 composability by including L1-L2 transaction bundles in the partial payloads.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-opted-in-slots-11" name="non-opted-in-slots-11"></a>Non-opted-in Slots</h3>
<p>When the current L1 slot’s proposer has not opted in as a preconfer, L1 transactions will be proposed by the current proposer, while L2 transactions will be proposed by the next opted-in preconfer in the lookahead (we follow Justin’s <a href="https://ethresear.ch/t/based-preconfirmations/17353#:~:text=proposer%20lookahead%E2%80%94higher%20precedence%20for%20smaller%20slot%20numbers">original based preconfirmation design</a> here). This results in two simultaneous MEV-Boost auctions: the usual L1 MEV-Boost auction signed by the current L1 proposer and the MR-MEV-Boost auction signed by the next preconfer. As a result, L1-L2 composability and L1 preconfirmation will be lost during these non-opted-in slots. Note that this limitation applies to all off-protocol preconfirmation designs.</p>
<h1><a class="anchor" href="https://ethresear.ch#analysis-12" name="analysis-12"></a>Analysis</h1>
<p>In this section, we will perform an initial analysis of the proposed protocol and identify its drawbacks.</p>
<h3><a class="anchor" href="https://ethresear.ch#have-we-solved-the-problems-13" name="have-we-solved-the-problems-13"></a>Have we solved the problems?</h3>
<p>Let’s revisit the problems raised in the <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695">Strawmanning Based Preconfirmations</a> post and see if and how MR-MEV-Boost addresses them.</p>
<p><strong>Problem 1: Latency race</strong></p>
<p>Latency races are when searchers fight to be the first to access the preconfer, leading to colocation or vertical integration. With MR-MEV-Boost, this issue is largely mitigated by preconfirming batches and conducting auctions within the batch, as it promotes competition based on price rather than speed. It is generally acknowledged that batch auctions help reduce latency wars compared to continuous first-come, first-served ordering, as described in <a href="https://academic.oup.com/qje/article/130/4/1547/1916146" rel="noopener nofollow ugc">this paper</a> and <a href="https://ethresear.ch/t/latency-arms-race-concerns-in-blockspace-markets/14957">this post</a>.</p>
<p><strong>Problem 2: Congestion</strong></p>
<p>Congestion issues arise when searchers flood the rollup with probabilistic arbitrage attempts. With MR-MEV-Boost, this issue is mitigated as searchers are incentivized to participate in auctions rather than resort to spam.</p>
<p><strong>Problem 3: Tip pricing</strong></p>
<p>The MEV-Boost auction will handle the tip pricing of the preconfirmation. Furthermore, by introducing batching and auctions within the batch, proposers can price the preconfirmation tips more effectively (hence capturing revenue) than by providing a continuous stream of per-transaction preconfirmations.</p>
<p><strong>Problem 4: Fair exchange</strong></p>
<p>Let’s see how MR-MEV-Boost addresses the <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695#problem-3-tip-pricing-6">fair exchange problem</a>, where the proposer withholds publishing preconfirmations to the user. Note that preconfers are incentivized to withhold preconf promises as much as possible to maximize their opportunity to reorder and insert transactions, thereby increasing their MEV.</p>
<p>There are two cases to consider:</p>
<ul>
<li>If the proposer withholds preconfirming partial payload (i.e., stops signing <code>merkle_root</code>s of <code>partial_payload</code>s), users will stop sending preconfirmation requests (user action 1), reducing the proposer’s order flow and, consequently, revenue.</li>
<li>If the proposer intentionally publishes empty partial payloads, pending preconf transactions will expire after a few rounds (user action 2 and builder slashing condition 1), reducing the proposer’s order flow and, consequently, revenue.</li>
</ul>
<p>In summary, end users monitor and enforce proposers’ honest behavior by linking the proposers’ revenue to the timely preconfirmation of partial payloads.</p>
<p>A potential alternative would be to introduce a committee to monitor and attest to the timely releases of partial payloads. However, this would require additional trust assumption to an external committee unless we enshrine the protocol into the L1. More on enshrinement in the <a href="https://ethresear.ch#future-direction">future direction section</a>.</p>
<p><strong>Problem 5: Liveness</strong></p>
<p>With existing based preconfirmation designs where preconfirmation duties are delegated ahead of the slot, liveness relies on this single external entity for the duration of the preconfer’s slot(s). On the other hand, with MR-MEV-Boost, liveness concerns are reduced as we do not introduce such “lock-in” to a specific entity before the slot. If some builders or relayers are unavailable, others can step in to maintain functionality. Moreover, even if the entire multi-round MEV-Boost pipeline fails, proposers still have the option to construct their own partial blocks and preconfirm them independently.</p>
<p><strong>Problem 6: Early auctions</strong></p>
<p>Early auctions are not introduced as preconfirmations are provided through the MEV-Boost JIT auctions.</p>
<h2><a class="anchor" href="https://ethresear.ch#round-interval-14" name="round-interval-14"></a>Round Interval</h2>
<p>How short can each round in MR-MEV-Boost be? If it is too long, it will degrade the user experience; if it is too short, it will impose excessive network and hardware requirements on builders and relays, thus hurting decentralization.</p>
<p>In each round, the relayer has two tasks:</p>
<ul>
<li>(A) Run the partial block auction.</li>
<li>(B) Propagate the partial block.</li>
</ul>
<p>Task (A) consists of the time it takes the builder to construct the block, the time it takes the relay to validate the block, and two network round-trips: one between the builder and the relay and another between the relay and the proposer. Assuming that <a href="https://x.com/SheaKetsdever/status/1808509437700665543" rel="noopener nofollow ugc">block construction</a>, validation, and network round-trips take 500 milliseconds each, we get a ballpark estimate of 2 seconds.</p>
<p>For task (B), considering L1 allocates 4 seconds for block propagation and 8 seconds for consensus, and no consensus is needed for partial blocks, a good upper bound for propagation time is 4 seconds. In practice, it should be much shorter because only block builders, relays, and full-node providers need to receive these partial blocks, and they have better network bandwidth and lower latency than average validators. Let’s assume 1-2 seconds for this analysis.</p>
<p>Combining 2 seconds for (A) and 1-2 seconds for (B) gives us 3-4 seconds per round.</p>
<p>These estimates are highly approximate, and further research and analysis are needed. Additionally, making the interval too short will intensify latency races toward the end of the batch duration, as described <a href="https://ethresear.ch/t/latency-arms-race-concerns-in-blockspace-markets/14957#auction-designs-for-transaction-ordering-2">here</a>, and should be considered.</p>
<h2><a class="anchor" href="https://ethresear.ch#drawbacks-15" name="drawbacks-15"></a>Drawbacks</h2>
<p>Next, we will outline the drawbacks of this protocol when compared to existing based preconfirmation designs, such as the one described in the <a href="https://ethresear.ch/t/based-preconfirmations/17353">original post</a>. An analysis of more general drawbacks of preconfirmations will be reserved for future work.</p>
<h3><a class="anchor" href="https://ethresear.ch#no-speed-of-light-continuous-preconfirmations-16" name="no-speed-of-light-continuous-preconfirmations-16"></a>No Speed-of-light Continuous Preconfirmations</h3>
<p>MR-MEV-Boost does not provide speed-of-light preconfirmations with hundreds of milliseconds latency, like <a href="https://docs.arbitrum.io/how-arbitrum-works/sequencer" rel="noopener nofollow ugc">Arbitrum’s first-come-first-serve sequencer</a>. Instead, it offers preconfirmations in batches with a few seconds of latency between them, similar to <a href="https://docs.optimism.io/connect/resources/glossary#time-slot" rel="noopener nofollow ugc">Optimism’s approach</a>.</p>
<p><a href="https://solana.com/" rel="noopener nofollow ugc">Solana</a> and <a href="https://www.jito.wtf/" rel="noopener nofollow ugc">Jito</a> provide an interesting case study on continuous versus batched preconfirmations. In Solana’s “continuous block building,” the leader streams (i.e., preconfirms) processed transactions continuously. Combined with Solana’s fixed low fee, continuous block building led to network spamming and latency races, causing validators to <a href="https://www.jito.network/blog/solving-the-mev-problem-on-solana-a-guide-for-stakers/" rel="noopener nofollow ugc">waste 58% of their time processing failed arbitrages</a>. Jito addressed this by introducing a 200ms “speed bump” (batches) and a mev-geth style bundle auction for batches, achieving an 80% share with their Jito validator client. This example indicates that that continuous preconfirmations are likely unsustainable due to spam and that batching and some auction for each batch are required. For more details, watch this informative talk by Zano Sherwani, co-founder of Jito, <a href="https://www.youtube.com/watch?v=c-O_JZI2QAA" rel="noopener nofollow ugc">here</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#relay-burden-17" name="relay-burden-17"></a>Relay Burden</h3>
<p>MR-MEV-Boost introduces additional burdens to the relays without incentives. Instead of managing a single round of MEV-Boost auctions, relayers must handle multiple rounds within a single slot, each within a limited timeframe. If the cost of operating a relayer increases too much, it may lead to further relayer centralization and <a href="https://collective.flashbots.net/t/builderelay/2688/1" rel="noopener nofollow ugc">builder-relay integration</a>, or alternatively, no relayer may opt to support MR-MEV-Boost. Relayer incentives are a <a href="https://www.gate.io/learn/articles/the-pursuit-of-relay-incentivization/1257" rel="noopener nofollow ugc">long-lasting problem</a> in L1, and MR-MEV-Boost likely worsen this situation.</p>
<p>One way to mitigate the issue is to incorporate <a href="https://frontier.tech/optimistic-relays-and-where-to-find-them" rel="noopener nofollow ugc">optimistic relay</a> schemes to reduce the relayer’s operational costs. With this approach, relayers optimistically assume the honesty of the block-builder and skip the validation work for payloads sent from the builder. If the builder is later found to deviate from honest behavior, their collateral will be used to refund the proposer. Optimistic relaying would be especially helpful as it allows relayers to bypass the need to validate the based rollup transactions when verifying partial blocks.</p>
<p>Another potential solution is for the proposers to share the preconfirmation tip revenue with the relay to compensate for the additional workload.</p>
<h3><a class="anchor" href="https://ethresear.ch#blob-efficiency-18" name="blob-efficiency-18"></a>Blob Efficiency</h3>
<p>So far, we have blurred the line between L1 and L2 preconfirmations. This is somewhat intentional, as L2 transactions are included within L1 transactions. However, there are cases where the difference becomes important.</p>
<p>Consider a scenario where the L2 transactions within a round cannot fill an entire blob. If we only support preconfirmations for L2 transactions by preconfirming the L1 transactions that contain them, we face a problem. Proposers would either have to preconfirm partially filled blob transactions at the end of the round or wait for another round to collect enough transactions to fill the blob.</p>
<p>One solution is to allow proposers to commit to a batch of L2 transactions without linking them to a specific L1 transaction. This would let the builder of the final full block aggregate the L2 transactions into one or more L1 blobs at the end of the slot.</p>
<h3><a class="anchor" href="https://ethresear.ch#issues-with-mev-boost-19" name="issues-with-mev-boost-19"></a>Issues with MEV-Boost</h3>
<p>MR-MEV-Boost inherits the existing L1 MEV-Boost pipeline, which also means that we inherit many of MEV-Boost’s downsides, such as <a href="https://arxiv.org/pdf/2305.19037" rel="noopener nofollow ugc">reliance on a handful of relays and builders</a>. However, based rollups aim to inherit the security of L1, not to exceed it. Therefore, being “as bad as” L1 is the best we can do as a based solution.</p>
<h1><a class="anchor" href="https://ethresear.ch#future-direction-20" name="future-direction-20"></a>Future Direction</h1>
<p>MR-MEV-Boost can be generalized as <em>partial-block preconfirmations</em>, where the proposer incrementally builds the block by committing to and publishing partial blocks during their slot.</p>
<p>One future direction would be to enshrine partial-block preconfirmations into the L1 protocol to achieve faster block times. This aligns with Vitalik’s <a href="https://vitalik.eth.limo/general/2024/06/30/epochslot.html" rel="noopener nofollow ugc">recent post</a> and offers several benefits over off-protocol designs like MR-MEV-Boost:</p>
<ul>
<li>Removes “non-opted-in” proposers, enabling L1 preconfirmations and L1-L2 composability for all slots.</li>
<li>Fully utilizes Ethereum’s validator set, potentially introducing lightweight <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054">PTC</a>-like attestations for timely partial payload releases.</li>
<li>Opens doors to increase the block times without degrading UX, which may help enable <a href="https://ethereum.org/en/roadmap/single-slot-finality/" rel="noopener nofollow ugc">single-slot finality</a>.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#related-work-21" name="related-work-21"></a>Related Work</h1>
<p>In his <a href="https://dba.xyz/were-all-building-the-same-thing/" rel="noopener nofollow ugc">latest post</a>, Jon Charbonneau explains in great detail how based rollups/preconfirmations work and the centralization risk of based preconfirmations.</p>
<p>Furthermore, partial-block preconfirmations are closely related to <a href="https://ethresear.ch/t/how-much-can-we-constrain-builders-without-bringing-back-heavy-burdens-to-proposers/13808">inclusion list</a> research, as both can be viewed under the broader concept of “partial-block building,” where different parts of a block are constructed at different times by different entities. For example, the <a href="https://research.eigenlayer.xyz/t/mev-boost-liveness-first-relay-design/15" rel="noopener nofollow ugc">MEV-Boost++ proposal</a> from Kyodo (EigenLayer) resembles MR-MEV-Boost, as both enable early commitment to partial blocks by imposing additional slashing conditions on the proposer.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-22" name="conclusion-22"></a>Conclusion</h1>
<p>We introduce MR-MEV-Boost, a design that enables based preconfirmations by running multiple rounds of MEV-Boost auctions within a single slot. By inheriting the L1 PBS pipeline, MR-MEV-Boost mitigates many of the negative externalities of based preconfirmations while retaining the benefits of based rollups.</p>
<p>At <a href="https://switchboard.nethermind.io/" rel="noopener nofollow ugc">Nethermind Switchboard</a>, we actively research and tackle the open challenges of based preconfirmations. We are also collaborating closely with Taiko to develop <a href="https://github.com/NethermindEth/Taiko-Preconf-AVS/blob/6b21d85d329986a2a9725048e56be3a45d463dcc/Docs/design-doc.md" rel="noopener nofollow ugc">a PoC for based preconfirmations</a> compatible with L2 PBS, including MR-MEV-Boost. Stay tuned for more updates!</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/based-preconfirmations-with-multi-round-mev-boost/20091">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 18 Jul 2024 06:47:13 +0000</pubDate>
</item>
<item>
<title>A Note On Securely Finding Minimum Mean Cycle</title>
<link>https://ethresear.ch/t/a-note-on-securely-finding-minimum-mean-cycle/20073</link>
<guid>https://ethresear.ch/t/a-note-on-securely-finding-minimum-mean-cycle/20073</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、Minimum Mean Cycle (MMC)、Multi-Party Computation (MPC)、Karp算法、Chaturvedi-McConnell方法

总结:
本文研究了在执行图优化算法，如Minimum Mean Cycle (MMC)，同时保护用户和公司之间敏感信息的问题。先前的工作中，Aly等人的方法基于Karp算法，但存在周期检测问题。作者提出了一种改进的协议，解决了这个问题并提高了效率。新协议使用MP-SPDZ实现，时间复杂度从O(|V|^5)降低到O(|V|^3)，空间复杂度从O(|V|^4)减小到O(|V|^2)。研究着重于在保证隐私的同时，提高MM <div>
<p>This study is supported by an Ethereum Foundation R&amp;D grant and is a collaborative work with Enrico ( <a class="mention" href="https://ethresear.ch/u/enricobottazzi">@enricobottazzi</a> ), Masato ( <a class="mention" href="https://ethresear.ch/u/0xvon">@0xvon</a> ) and Nam ( <a class="inline-onebox" href="https://github.com/namnc" rel="noopener nofollow ugc">namnc (Nam Ngo) · GitHub</a> ) from Ethereum Foundation.</p>
<p><strong>Abstract</strong></p>
<p>Executing graph optimization algorithms such as the Minimum Mean Cycle (MMC) while preserving privacy has significant potential for handling sensitive information between users and companies. For example, it enables multilateral netting to solve the Minimum Cost Flow (MCF) problem without disclosing mutual debts, making it highly relevant for processes like netting among multinational corporations. Aly et. al. [2] proposed an algorithm using Multi-Party Computation (MPC) to execute the MMC problem. However, this approach is based on Karp’s algorithm [1], which was found by Chaturvedi et al. [3] to occasionally fail to detect cycles. In this study, we propose a revised protocol that corrects this issue and enhances its efficiency. We implemented our protocol using MP-SPDZ and confirmed that it correctly identifies the MMC, similar to traditional protocols. Our findings indicate that our proposed protocol operates correctly and more efficiently than Aly’s protocol, which reduces the time/round complexity from <span class="math">O(|V|^5)</span> to <span class="math">O(|V|^3)</span> and the space complexity from <span class="math">O(|V|^4)</span> to <span class="math">O(|V|^2)</span>. Furthermore, we discuss potential improvements for even more efficient algorithms.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-1-introduction-1" name="h-1-introduction-1"></a>1. Introduction</h1>
<h3><a class="anchor" href="https://ethresear.ch#h-1-1-importance-of-graph-theory-optimization-2" name="h-1-1-importance-of-graph-theory-optimization-2"></a>1-1. Importance of Graph Theory Optimization</h3>
<p>Graph theory optimization problems play a crucial role in various domains, from computer science and engineering to economics and finance. These problems involve finding the most efficient way to navigate, connect, or utilize network structures, and solutions to these problems have far-reaching implications for improving systems and processes.</p>
<p>One of the representative problems in graph theory optimization is the Minimum Cost Flow (MCF) problem, which aims to find the least costly way to send a certain amount of flow through a network. The MCF problem is foundational in numerous applications, providing critical insights and optimizations.</p>
<p>In the financial sector, particularly in Netting, the Minimum Cost Flow (MCF) problem is often addressed to optimize the settlement of transactions and reduce systemic risk. Netting involves aggregating multiple financial obligations to streamline transactions, minimize risk, and enhance efficiency. However, one of the critical challenges in this context is maintaining the privacy and confidentiality of sensitive financial data. Traditional methods for solving the MCF problem may require exposing transaction details, leading to significant privacy concerns and potential security risks.</p>
<p>Beyond netting, the MMC problem and its solutions have a wide array of applications across various fields:</p>
<ul>
<li><strong>Network Security:</strong> Enhancing security measures by optimizing the flow of information and resources while minimizing potential points of vulnerability.</li>
<li><strong>Supply Chain Management</strong>: Streamlining logistics and distribution networks to reduce costs and improve delivery times.</li>
<li><strong>Urban Planning</strong>: Developing efficient transportation systems by optimizing traffic flow and reducing congestion.</li>
</ul>
<p>The Minimum Mean Cycle (MMC) problem is a crucial component in solving the MCF problem. The MMC problem focuses on identifying cycles in directed graphs with the minimum average weight, which is essential for detecting inefficient paths and optimizing network performance. By incorporating the MMC problem into the solution of the MCF problem, we can achieve more accurate and efficient outcomes.</p>
<p>To address the privacy concerns inherent in solving the MCF problem, we explore the use of Multi-Party Computation (MPC) to securely solve the MMC problem. MPC is a cryptographic approach that allows multiple parties to collaboratively compute a function over their inputs while keeping those inputs private. By applying MPC techniques, we can solve the MMC problem without exposing sensitive data, thus preserving the privacy of financial transactions and other confidential information.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-1-2-previous-work-3" name="h-1-2-previous-work-3"></a>1-2. Previous Work</h3>
<p>Aly et al. [2] proposed a method to solve Karp’s MMC algorithm [1] using Multi-Party Computation. However, this approach has some problems and suffers from significant computational complexity and time consumption. Additionally, the Karp’s algorithm [1] was found by Chaturvedi et al . [3] to occasionally fail to detect cycles.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-1-3-our-contribution-4" name="h-1-3-our-contribution-4"></a>1-3. Our Contribution</h3>
<p>in this study, we propose a novel approach that not only addresses these shortcomings but also offers a more efficient and practical solution for securely solving the MMC problem using MPC. Our proposed protocol aims to reduce computational and time complexities, enhance cycle detection accuracy, and ensure robust privacy protection. Our experimental results demonstrate a significant improvement in efficiency, with a reduction in time complexity from <span class="math">O(|V|^5)</span> to <span class="math">O(|V|^3)</span> and space complexity from <span class="math">O(|V|^4)</span> to <span class="math">O(|V|^2)</span>.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-2-minimum-mean-cycle-problem-5" name="h-2-minimum-mean-cycle-problem-5"></a>2. Minimum Mean Cycle Problem</h1>
<p>Minimum Mean Cycle Problem and its solution is defined by Karp in 1978 [1].</p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-1-problem-definition-6" name="h-2-1-problem-definition-6"></a>2-1. Problem Definition</h3>
<p>Given a connected graph <span class="math">G(V,E)</span> where <span class="math">V</span> is a set of nodes and <span class="math">E</span> is a set of edges, with defining these parameters:</p>
<ul>
<li><span class="math">c_{i,j} \in C</span> denotes the <strong>cost</strong> on the edge <span class="math">(i,j)</span>.</li>
<li><span class="math">d^k(i)</span> denotes the minimum cost from node <span class="math">s</span> to <span class="math">i</span> that contains exactly <span class="math">k</span> edges.</li>
</ul>
<p>First of all, for any cycle <span class="math">X</span>, the mean cycle is defined by:</p>
<div class="math">
\begin{equation}
\mu (X) = \frac{\sum_{uv \in X} c_{uv}}{|X|}
\end{equation}
</div>
<p>Thus, the minimum mean cycle is:</p>
<div class="math">
\begin{equation}
\mu ^* = \min_{cycle X} \mu (X)
\end{equation}
</div>
<p>Minimum Mean Cycle (MMC) Problem is the problem to find this <span class="math">\mu ^*</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-2-efficient-mmc-7" name="h-2-2-efficient-mmc-7"></a>2-2. Efficient MMC</h3>
<p>The MMC problem is known as NP-hard, and Karp introduces an efficient algorithm for solving it. The solution is followed by 2 steps.</p>
<p>The first step, we call it as <strong>Walk</strong>, is to calculates <span class="math">d^k(i)</span>, which denotes minimum cost from node <span class="math">s</span> to <span class="math">i</span> that contains exactly <span class="math">k</span> edges. Walk can be computed via the recurrence:</p>
<div class="math">
\begin{equation}
d^k(j) = \min_{(i,j) \in E} d^{k-1}(i)+c_{ij}
\end{equation}
</div>
<p>Initially, <span class="math">d^0(j)=\infty</span>, except for the source node <span class="math">d^0(s)=0</span></p>
<p>The second step is to calculate the minimum mean cycle by:</p>
<div class="math">
\begin{equation}
\mu^* = \min_{j \in V} \max_{0 \leq k \leq |V|-1} \left[ \frac{d^V(j) - d^k(j)}{|V| - k} \right]
\end{equation}
</div>
<p>See Karp’s paper [1] for a proof of equation (4). Overall algorithmic complexity is <span class="math">O(|V| \cdot |E|)</span>, and the first step has a significant impact on the entire algorithm.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-3-alys-secure-mmc-protocol-8" name="h-3-alys-secure-mmc-protocol-8"></a>3. Aly’s Secure MMC Protocol</h1>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math">[a]</span> denotes secret shared or encrypted values of <span class="math">a</span></li>
<li><span class="math">[z] = _{[c]} [x]:[y]</span> denotes the assignment that if <span class="math">[c]</span> is one, <span class="math">[x]</span> is assigned to <span class="math">[z]</span> or <span class="math">[y]</span> otherwise.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-3-1-protocol-9" name="h-3-1-protocol-9"></a>3-1. Protocol</h3>
<p>Aly et. al. [2] provide algorithmic solutions to MMC problem in a secure multi-party and distributed setting. This protocol is constructed by 2 sub-protocols:</p>
<ol>
<li><span class="math">walk([C],[b]) \rightarrow [A],[walks]</span></li>
<li><span class="math">mmc([A],[walks]) \rightarrow [\text{min-cost}], [\text{min-cycle}]</span></li>
</ol>
<p>This corresponds to Steps 1 and 2 of Karp’s Algorithm in section 2.</p>
<p>In first sub-protocol, we have two inputs. The cost matrix <span class="math">[C]_{ij}</span> denotes the cost of edge <span class="math">(i,j)</span>. It represents <span class="math">[\infty]</span> for non-existing edges. The viable matrix <span class="math">[b]_{ij}</span> denotes 1 if edge <span class="math">(i,j)</span> doesn’t exist, and 0 otherwise.</p>
<p>From these inputs, we outputs two values. One is the 2-dimensional walk cost matrix <span class="math">[A]</span> which <span class="math">[A]_{jk}</span> records <span class="math">d^k(j)</span>. The other is 4-dimensional walk path matrix <span class="math">[walks]</span> which <span class="math">[walks]_{ijkl}</span> records the number of times the edge <span class="math">(i,j)</span> is traversed by the shortest walk of length <span class="math">k</span> from <span class="math">s</span> to <span class="math">l</span>. The algorithm is detailed as Protocol 3-1.</p>
<hr />
<p><strong>Protocol 3-1. Aly’s Walk Protocol</strong></p>
<hr />
<p><strong>Input</strong>: A matrix of shared costs <span class="math">[C]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>, a binary matrix on viable adges <span class="math">[b]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,1,...,|V|\}</span>, a wak matrix <span class="math">[walks]_{ijkl}</span> for <span class="math">i,j,k,l \in \{1,2,...,|V|\}</span> encoding these walks.</p>
<ol>
<li><span class="math">[A] \leftarrow [\infty], [A]_{00} \leftarrow [0], [C] \leftarrow [C] + [\infty](1-[b])</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow 1</span> to <span class="math">|V|+1</span> do
<ol>
<li><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><strong>for</strong> <span class="math">i \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><span class="math">[c] \leftarrow [A]_{ik-1} + [C]_{ij} &lt; [A]_{jk}</span></li>
<li><span class="math">[A]_{jk} \leftarrow _{[c]} [A]_{ik-1} + [C]_{ij} : [A]_{jk}</span></li>
<li><span class="math">[walks]_{..kj} \leftarrow _{[c]} [walks]_{..k-1i} : [walks]_{..kj}</span></li>
<li><span class="math">[walks]_{ijkj} \leftarrow _{[c]} [walks]_{ijkj} + 1 : [walks]_{ijkj}</span></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
<hr />
<p>In second sub-protocol, we have two outputs. <span class="math">[\text{min-cost}]</span> is the minimum mean cost. <span class="math">[\text{min-cycle}]</span> denotes the 2-dimensional cycle matrix which <span class="math">[\text{min-cycle}]_{jk}</span> is 1 if edge <span class="math">(j,k)</span> is included in the cycle achieving <span class="math">\mu ^*</span> and 0 otherwise. Here, <span class="math">\text{min-cycle}</span> is s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span>, minus the s-j path with k edges whose cost is <span class="math">d^{k}(j)</span>. The details are provided as protocol 3-2. We note that we use the theorem that <span class="math">\frac{a}{b}&gt;\frac{c}{d} \iff ad&gt;bc</span> to make a comparison of <span class="math">\frac{d^V(j) - d^k(j)}{|V| - k}</span> without calculating the inverse.</p>
<hr />
<p><strong>Protocol 3-2. Aly’s MMC Protocol</strong></p>
<hr />
<p><strong>Input:</strong> A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,2,...,|V|\}</span>, a walk matrix <span class="math">[walks]_{ijkl}</span> for <span class="math">i,j,k,l \in \{1,2,...,|V|\}</span> encoding these walks.</p>
<p><strong>Output</strong>: The cost of the minimum mean cycle <span class="math">[\text{min-cost}]</span>, a matrix with the minimum mean cycle <span class="math">[\text{min-cycle}]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span></p>
<ol>
<li>
<p><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do</p>
<ol>
<li><span class="math">[\text{max-cycle}],[\text{max-cost}] \leftarrow \phi</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do
<ol>
<li><span class="math">[\text{a-num}] \leftarrow [A]_{j(|V|+1)} - [A]_{jk}</span></li>
<li><span class="math">[\text{a-den}] \leftarrow |V|-k</span></li>
<li><span class="math">[c] \leftarrow [\text{k-num}] \cdot [\text{a-den}] &lt; [\text{a-num}] \cdot [\text{k-den}]</span></li>
<li><span class="math">[\text{k-num}] \leftarrow _{[c]} [\text{a-num}]  : [\text{k-num}]</span></li>
<li><span class="math">[\text{k-den}] \leftarrow _{[c]} [\text{a-den}]  : [\text{k-den}]</span></li>
<li><span class="math">[\text{max-cycle}] \leftarrow _{[c]} [walks]_{..|V|j} - [walks]_{..kj} : [\text{max-cycle}]</span></li>
<li><span class="math">[\text{max-cost}] \leftarrow _{[c]} [A]_{jk} : [\text{max-cost}]</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><span class="math">[c] \leftarrow [\text{j-num}] \cdot [\text{k-den}] &lt; [\text{k-num}] \cdot [\text{j-den}]</span></li>
<li><span class="math">[\text{j-num}] \leftarrow _{[c]} [\text{k-num}]  : [\text{j-num}]</span></li>
<li><span class="math">[\text{j-den}] \leftarrow _{[c]} [\text{k-den}]  : [\text{j-den}]</span></li>
<li><span class="math">[\text{min-cycle}] \leftarrow _{[c]} [\text{max-cycle}] : [\text{min-cycle}]</span></li>
<li><span class="math">[\text{min-cost}] \leftarrow _{[c]} [\text{max-cost}] : [\text{min-cost}]</span></li>
</ol>
</li>
<li>
<p><strong>end</strong></p>
</li>
</ol>
<hr />
<p><strong>Complexity</strong></p>
<p>This method requires <span class="math">O(|V|^5)</span> time/round complexity, from the conditional assignments to <span class="math">|V| \times |V|</span> elements in <span class="math">[walks]</span> matrix for <span class="math">|V|^3</span> loops (line i-3~4 of Protocol 1). And this method requires <span class="math">O(|V|^4)</span> space complexity, due to 4-dimensional <span class="math">[walks]</span> matrix.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-2-problem-in-alys-protocol-10" name="h-3-2-problem-in-alys-protocol-10"></a>3-2. Problem in Aly’s Protocol</h3>
<p>Aly’s protocol implements Karp algorithm [1] in the secure manner. In karp’s alrogithm, we determine <span class="math">\text{min-cycle}</span> like s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span>, minus the s-j path with k edges whose cost is <span class="math">d^{k}(j)</span>. However, Chaturvedi and McConnell [3] provides an counterexample which the cycle couldn’t detected with this method. Furthermore, they prove the following lemma.</p>
<p><strong>Lemma 1</strong><br />
Let <span class="math">j</span> be a vertex such that there exists <span class="math">k</span>, where <span class="math">j</span> and <span class="math">k</span> are a minimizing pair. Every cycle on the length <span class="math">|V|</span> edge progression from <span class="math">s</span> to <span class="math">j</span> of cost <span class="math">d^{|V|}(j)</span> is a cycle of minimum mean cost. (See the proof on their paper [3].)</p>
<p>This lemma means that the cycle can be detected by traversing the edge progression from the last edge and marking the vertices visited by the walk until a previous marked vertex is encountered, from s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span>.</p>
<h1><a class="anchor" href="https://ethresear.ch#h-4-cm-based-secure-mmc-protocol-11" name="h-4-cm-based-secure-mmc-protocol-11"></a>4. CM-based Secure MMC Protocol</h1>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math">[a]</span> denotes secret shared or encrypted values of <span class="math">a</span></li>
<li><span class="math">[z] = _{[c]} [x]:[y]</span> denotes the assignment that if <span class="math">[c]</span> is one, <span class="math">[x]</span> is assigned to <span class="math">[z]</span> or <span class="math">[y]</span> otherwise.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-4-1-protocol-12" name="h-4-1-protocol-12"></a>4-1. Protocol</h3>
<p>We propose a protocol that converts the minimum mean cycle detection from Aly’s protocol to one with Lemma1. In addition, a few changes have been made to the data structure. We name it “<strong>CM-based Securely MMC Protocol</strong>”, taking the initials of Chaturvedi and McConnell, who proposed Lemma 1.</p>
<p>CM-based protocol is constructed by 3 sub-protocols:</p>
<ol>
<li><span class="math">walk([C],[b]) \rightarrow [A],[ep]</span></li>
<li><span class="math">mmc</span>
<ol>
<li><span class="math">mmcn([A],[ep]) \rightarrow [\text{min-cost}],[\text{minimizing-node}]</span></li>
<li><span class="math">extract\text{-}cycle([\text{minimizing-node}],[ep]) \rightarrow [\text{min-cycle}]</span></li>
</ol>
</li>
</ol>
<p>Here, Aly’s second sub-protocol is divided into CM-based second and third sub-protocols.</p>
<p>In fist sub-protocol, For the most part, it is the same as Protocol 3-1, with one difference: Instead of <span class="math">[walks]</span>, we record the edge progression in a 2-dimensional matrix called <span class="math">[ep]</span>, which <span class="math">[ep]_{jk}</span> means the edge that passes before one of <span class="math">j</span> in the shortest s-j path with k edges. This change eliminates the need for extra <span class="math">|V|^2</span> loops to update <span class="math">[walks]_{..kj}</span>. The algorithm is detailed as Protocol 4-1.</p>
<hr />
<p><strong>Protocol 4-1. CM-based Walk Protocol</strong></p>
<hr />
<p><strong>Input</strong>: A matrix of shared costs <span class="math">[C]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>, a binary matrix on viable adges <span class="math">[b]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,1,...,|V|\}</span>, a matrix of walk edge progressions <span class="math">[ep]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<ol>
<li><span class="math">[A] \leftarrow [\infty], [A]_{00} \leftarrow [0], [C] \leftarrow [C] + [\infty](1-[b])</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow 1</span> to <span class="math">|V|+1</span> do
<ol>
<li><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><strong>for</strong> <span class="math">i \leftarrow 1</span> to <span class="math">|V|</span> do
<ol>
<li><span class="math">[c] \leftarrow [A]_{ik-1} + [C]_{ij} &lt; [A]_{jk}</span></li>
<li><span class="math">[A]_{jk} \leftarrow _{[c]} [A]_{ik-1} + [C]_{ij} : [A]_{jk}</span></li>
<li><span class="math">[ep]_{jk} \leftarrow _{[c]} i : [ep]_{jk}</span></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
<hr />
<p>In (a) of the 2nd sub-protocol, instead of computing <span class="math">[\text{min-cycle}]</span>, we detect the node <span class="math">j</span> that achieves mmc. We call it minimizing node.</p>
<p>The algorithm is detailed as Protocol 4-2-a.</p>
<hr />
<p><strong>Protocol 4-2-a. CM-based MMCN Protocol</strong></p>
<hr />
<p><strong>Input:</strong> A matrix of walk costs <span class="math">[A]_{ik}</span> for <span class="math">i \in \{1,2,...,|V|\}</span> and <span class="math">k \in \{0,2,...,|V|\}</span>, a matrix of walk progressions <span class="math">[ep]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: The cost of the minimum mean cycle <span class="math">[\text{min-cost}]</span>, the node achieving the minimum mean cycle <span class="math">[\text{minimizing-node}]</span>.</p>
<ol>
<li>
<p><strong>for</strong> <span class="math">j \leftarrow 1</span> to <span class="math">|V|</span> do</p>
<ol>
<li>
<p><span class="math">[\text{max-cost}] \leftarrow \phi</span></p>
</li>
<li>
<p><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do</p>
<ol>
<li><span class="math">[\text{a-num}] \leftarrow [A]_{j(|V|+1)} - [A]_{jk}</span></li>
<li><span class="math">[\text{a-den}] \leftarrow |V|-k</span></li>
<li><span class="math">[c] \leftarrow [\text{k-num}] \cdot [\text{a-den}] &lt; [\text{a-num}] \cdot [\text{k-den}]</span></li>
<li><span class="math">[\text{k-num}] \leftarrow _{[c]} [\text{a-num}]  : [\text{k-num}]</span></li>
<li><span class="math">[\text{k-den}] \leftarrow _{[c]} [\text{a-den}]  : [\text{k-den}]</span></li>
<li><span class="math">[\text{max-cost}] \leftarrow _{[c]} [A]_{jk} : [\text{max-cost}]</span></li>
</ol>
</li>
<li>
<p><strong>end</strong></p>
</li>
<li>
<p><span class="math">[c] \leftarrow [\text{j-num}] \cdot [\text{k-den}] &lt; [\text{k-num}] \cdot [\text{j-den}]</span></p>
</li>
<li>
<p><span class="math">[\text{j-num}] \leftarrow _{[c]} [\text{k-num}]  : [\text{j-num}]</span></p>
</li>
<li>
<p><span class="math">[\text{j-den}] \leftarrow _{[c]} [\text{k-den}]  : [\text{j-den}]</span></p>
</li>
<li>
<p><span class="math">[\text{minimizing-node}] \leftarrow _{[c]} j : [\text{minimizing-node}]</span></p>
</li>
<li>
<p><span class="math">[\text{min-cost}] \leftarrow _{[c]} [\text{max-cost}] : [\text{min-cost}]</span></p>
</li>
</ol>
</li>
<li>
<p><strong>end</strong></p>
</li>
</ol>
<hr />
<p>In (b) of the 2nd sub-protocol, from <span class="math">[\text{minimizing-node}]</span>, we construct a back pointer which indicates s-j path with <span class="math">|V|</span> edges whose cost is <span class="math">d^{|V|}(j)</span> and extract a cycle from the back pointer. Compared to Protocol 3-2, instead of expanding <span class="math">[\text{min-cycle}]</span> directly from <span class="math">[walks]</span>, the additional protocol is required. We follow Lemma 1 and consider any cycle included in the back pointer as a minimum mean cycle. The algorithm is detailed as Protocol 4-2-b.</p>
<hr />
<p><strong>Protocol 4-2-b. CM-based Extract-Cycle Protocol</strong></p>
<hr />
<p><strong>Input:</strong> A minmizing node <span class="math">[\text{minimizing-node}]</span>, a matrix of walk progressions <span class="math">[ep]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span>.</p>
<p><strong>Output</strong>: A matrix with the minimum mean cycle <span class="math">[\text{min-cycle}]_{ij}</span> for <span class="math">i,j \in \{1,2,...,|V|\}</span></p>
<ol>
<li><span class="math">[\text{backpointers}]_{0} \leftarrow [\text{minimizing-node}]</span>, <span class="math">[\text{next-index}] \leftarrow [\text{minimizing-node}]</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do
<ol>
<li><span class="math">[\text{val}] \leftarrow [0]</span></li>
<li><strong>for</strong> <span class="math">j \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[match] = j == [\text{next-index}]</span></li>
<li><span class="math">[\text{val}] = _{[\text{match}]} [ep]_{jk}:[\text{val}]</span></li>
<li><span class="math">[\text{match-index-matrix}]_{jk} = [match]</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><span class="math">[\text{next-index}] = [\text{val}]</span></li>
<li><span class="math">[\text{backpointers}].append([\text{val}])</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><strong>for</strong> <span class="math">i \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[\text{counter}] \leftarrow [0]</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow 0</span> to <span class="math">|V|</span> do
<ol>
<li><span class="math">[\text{counter}] = [\text{counter}] + [\text{match-index-matrix}]_{ik}</span></li>
</ol>
</li>
<li><span class="math">[c] = [\text{counter}] &gt;= 2</span></li>
<li><span class="math">[\text{cycle-node}] = _{[c]} i : [\text{cycle-node}]</span></li>
</ol>
</li>
<li><strong>end</strong></li>
<li><span class="math">[\text{min-cycle}] \leftarrow [0],[\text{counter}] \leftarrow [0]</span></li>
<li><strong>for</strong> <span class="math">k \leftarrow |V|</span> to <span class="math">1</span> do
<ol>
<li><span class="math">[\text{edge-from}] \leftarrow [\text{backpointers}]_k</span></li>
<li><span class="math">[c] = [\text{edge-from}] [\text{cycle-node}]</span></li>
<li><span class="math">[\text{counter}] = [\text{counter}] + [c]</span></li>
<li><span class="math">[c_0] = [\text{counter}] + 1</span></li>
<li><strong>for</strong> <span class="math">j \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[c_1] = [\text{match-index-matrix}]_{jn-k}</span></li>
<li><span class="math">[c_2] = [c_0]*[c_1]</span></li>
<li><strong>for</strong> <span class="math">i \leftarrow 0</span> to <span class="math">|V|-1</span> do
<ol>
<li><span class="math">[c_3] = [\text{match-index-matrix}]_{jn-k+1}</span></li>
<li><span class="math">[\text{min-cycle}]_{ji} = [\text{min-cycle}]_{ji} + ([c_2] * [c_3])</span></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
</li>
<li><strong>end</strong></li>
</ol>
<hr />
<p><strong>Complexity</strong><br />
This ****method requires <span class="math">O(|V|^3)</span> multiplications or communication rounds, from the conditional assignments of <span class="math">[A],[ep],[\text{min-cycle}]</span> for <span class="math">|V|^3</span> loops (line i-2~3 of Protocol 4-1 and like iii-3 of Protocol 4-2-b). And this method requires <span class="math">O(|V|^2)</span> space complexity, largely due to 2-dimensional matrixes. A table comparing the Complexity of each protocol is shown in Table 4-1 below.</p>
<p><strong>Table 4-1. Complexity Analysis of Secure MMC Protocols</strong></p>
<div class="md-table">
<table>
<thead>
<tr>
<th></th>
<th>multiplications/communication rounds complexity</th>
<th>space complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td>Aly’s</td>
<td><span class="math">O(|V|^5)</span></td>
<td><span class="math">O(|V|^4)</span></td>
</tr>
<tr>
<td>CM-based</td>
<td><span class="math">O(|V|^3)</span></td>
<td><span class="math">O(|V|^2)</span></td>
</tr>
</tbody>
</table>
</div><h3><a class="anchor" href="https://ethresear.ch#h-4-2-implementation-13" name="h-4-2-implementation-13"></a>4-2. Implementation</h3>
<p>We have implemented CM-based Securely MMC protocol in naive secret sharing scheme using Python MP-SPDZ. And we confirmed that the minimum mean cycle was found reliably in a number of random edges, including the counterexamples shown by Chaturvedi et al [3].</p>
<h1><a class="anchor" href="https://ethresear.ch#h-5-conclusion-14" name="h-5-conclusion-14"></a>5. Conclusion</h1>
<p>In this study, we have proposed a more efficient protocol for solving the Minimum Mean Cycle (MMC) problem using Multi-Party Computation (MPC). Our CM-based approach not only addresses but also significantly improves upon the issues identified in Aly’s protocol. Specifically, our protocol reduces the time/round complexity from <span class="math">O(|V|^5)</span> to <span class="math">O(|V|^3)</span> and the space complexity from <span class="math">O(|V|^4)</span> to <span class="math">O(|V|^2)</span> compared to Aly’s protocol.</p>
<p>Despite these advancements, the complexity remains super-quadratic in terms of the number of nodes, which can pose practical challenges for very large graphs. To mitigate this limitation, we propose the following strategies:</p>
<ul>
<li>By exposing the graph’s topography, we can optimize the edge search to include only the minimum necessary edges, thereby reducing the time/round complexity to <span class="math">O(|V|^2 \cdot |E|)</span>. This approach, however, requires a trade-off with some degree of privacy.</li>
<li>Implementing simpler algorithms that provide approximate or sub-optimal solutions, such as Greedy Algorithms and Distributed Algorithms, can further enhance practicality. These algorithms can significantly reduce computational overhead while delivering sufficiently accurate results for many applications.</li>
</ul>
<p>In summary, our protocol offers a substantial improvement over existing methods, paving the way for more efficient and practical solutions to the MMC problem in secure computation settings. Future work will focus on refining these strategies to further balance the trade-offs between efficiency, accuracy, and privacy.</p>
<h1><a class="anchor" href="https://ethresear.ch#reference-15" name="reference-15"></a>Reference</h1>
<ol>
<li>Richard M. Karp, “A characterization of the minimum cycle mean in a digraph”, Discrete Mathematics, Volume 23, Issue 3, 1978, Pages 309-311, ISSN 0012-365X, <a href="https://doi.org/10.1016/0012-365X(78)90011-0" rel="noopener nofollow ugc">https://doi.org/10.1016/0012-365X(78)90011-0</a>.</li>
<li>Aly, A., Van Vyve, M. (2015). Securely Solving Classical Network Flow Problems. In: Lee, J., Kim, J. (eds) Information Security and Cryptology - ICISC 2014. ICISC 2014. Lecture Notes in Computer Science(), vol 8949. Springer, Cham. <a class="inline-onebox" href="https://doi.org/10.1007/978-3-319-15943-0_13" rel="noopener nofollow ugc">Securely Solving Classical Network Flow Problems | SpringerLink</a></li>
<li>Mmanu Chaturvedi, Ross M. McConnell, “A note on finding minimum mean cycle”, Information Processing Letters, Volume 127, 2017, Pages 21-22, ISSN 0020-0190, <a class="inline-onebox" href="https://doi.org/10.1016/j.ipl.2017.06.007" rel="noopener nofollow ugc">Redirecting</a>.</li>
</ol>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/a-note-on-securely-finding-minimum-mean-cycle/20073">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 15 Jul 2024 07:09:02 +0000</pubDate>
</item>
<item>
<title>Sealed execution auction</title>
<link>https://ethresear.ch/t/sealed-execution-auction/20060</link>
<guid>https://ethresear.ch/t/sealed-execution-auction/20060</guid>
<content:encoded><![CDATA[
<div> 关键词：密封拍卖、执行提案人、密封投标、公开竞标、MEV问题。

总结:<br />
本文提出了一种名为密封执行拍卖（SEA）的新机制，旨在分离执行提案权和验证者角色，避免MEV问题。该机制包括两个阶段：第一阶段，建设者匿名提交密封投标；第二阶段，建设者公开投标，最高投标者支付第二高投标作为费用。通过这种方式，可以防止建设者与提案者之间的勾结，确保拍卖的公正性。文章还讨论了可能的合谋情况及应对策略，如对提案者错过区块的惩罚和后续拍卖流程设计。总的来说，SEA为区块链执行权拍卖提供了一个潜在的解决方案，以实现更有效的分离和减少激励冲突。 <div>
<h1><a class="anchor" href="https://ethresear.ch#sealed-execution-auction-1" name="sealed-execution-auction-1"></a>Sealed execution auction</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/e/3e0cf08f2021a1cbbe0156d52c8482dba0a00ba6.jpeg" title="Sealed execution auction"><img alt="Sealed execution auction" height="394" src="https://ethresear.ch/uploads/default/optimized/3X/3/e/3e0cf08f2021a1cbbe0156d52c8482dba0a00ba6_2_690x394.jpeg" width="690" /></a></div><p></p>
<p>By <a href="https://x.com/weboftrees">Anders</a>.</p>
<p><em>While working on the <a href="https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024">dynamic pricing auction</a> I though of another way to hold the auction that also seems interesting. Posting a rough sketch here, although I am not yet certain of its viability. Thanks to <a href="https://x.com/drakefjustin">Justin</a>, <a href="https://x.com/barnabemonnot">Barnabé</a> and <a href="https://x.com/terencechain">Terence</a>.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>In the process of enshrining proposer–builder separation (<a href="https://github.com/ethereum/EIPs/pull/8711">ePBS</a>), it has been <a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg">suggested</a> that attesting and execution proposing should be more fully separated. Proposals such as <a href="https://ethresear.ch/t/execution-tickets/17944">execution tickets</a> (ETs) and <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">execution auctions</a> (EAs) strive to allocate the right to propose execution blocks to entities other than the validators. This also facilitates <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV burn</a>. There have been concerns (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">2</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">3</a>) around insufficient early bidding in the MEV pricing auctions with a base fee floor used in EA. By <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">considering the staking metagame</a>, this issue is potentially resolved, but the resulting attester–builder integration can then by itself be <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856#risks-associated-with-attester-builder-integration-14">problematic</a>. There is also a general concern that the decided-upon auction design will <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">induce MEV</a>, and no definite specification among <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764#preliminaries-12">several alternatives</a> for the auction design in ET. For this reason, it seems fruitful to explore an auction that facilitates true separation and does not induce MEV. One such mechanism recently proposed is the <a href="https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024">MEV resistant dynamic pricing auction</a>. In the context of Vickrey auctions of execution rights, <a href="https://forum.arbitrum.foundation/t/constitutional-aip-proposal-to-adopt-timeboost-a-new-transaction-ordering-policy/25167">Timeboost</a> under consideration by Arbitrum can also be mentioned.</p>
<p>This post proposes a <a href="https://en.wikipedia.org/wiki/Vickrey_auction">Vickrey</a> slot auction in two rounds to select a forthcoming execution proposer (akin to EA), referred to as a sealed execution auction (SEA). Staked builders make sealed bids for the right to propose an execution block. Bids are observed by attesters and then collated by the beacon proposer. In subsequent steps, builders reveal their bids, attesters observe the revealed bids, and the proposer once again collates them. The right to propose a forthcoming execution block is awarded to the highest bidder, paying according to the second-highest bid, with the payment burned.</p>
<h2><a class="anchor" href="https://ethresear.ch#auction-3" name="auction-3"></a>Auction</h2>
<h3><a class="anchor" href="https://ethresear.ch#staked-builders-4" name="staked-builders-4"></a>Staked builders</h3>
<p>Builders are staked at a level sufficient for the protocol to penalize them if they fail to reveal committed bids. The stake can also serve as a deposit account to pay for winning bids, or this account can be managed separately.</p>
<h3><a class="anchor" href="https://ethresear.ch#sealed-bids-5" name="sealed-bids-5"></a>Sealed bids</h3>
<p>Figure 1 gives an overview of the auction. In the first round, each builder has the opportunity to make one sealed bid over a public P2P layer. There might be a small fee for making a bid, as a further anti-Sybil measure. Attesters observe the sealed bids that have come in at time <span class="math">T_1</span>. Around two seconds later, at <span class="math">T_2</span>, the beacon proposer collates sealed bids (including any bids it finds after <span class="math">T_1</span>), and broadcasts them in a structure. This structure may be a beacon block if the auction proceeds over two slots (see <a href="https://ethresear.ch/t/sealed-execution-auction/20060#timeline-15">Timeline</a>). At <span class="math">T_3</span>, attesters observe the structure and make sure that all previously observed bids at <span class="math">T_1</span> have been included. If the bids were included in a beacon block, they will attest to the block contingent on correct and timely collation. If not included in a beacon block and the proposer equivocates on the structure, the subsequent block must be rejected.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/9/e9efaf529cceda171c770e9160ed477ff7093303.png" title="Figure 1"><img alt="Figure 1" height="347" src="https://ethresear.ch/uploads/default/optimized/3X/e/9/e9efaf529cceda171c770e9160ed477ff7093303_2_690x347.png" width="690" /></a></div><p></p>
<p><strong>Figure 1.</strong> Sealed execution auction. Staked builders submit sealed bids before <span class="math">T_1</span> and the proposer collates them at <span class="math">T_2</span>. At <span class="math">T_3</span> attesters ensure that all bids they observed at <span class="math">T_1</span> are part of the collated structure. Builders unseal the bids after <span class="math">T_3</span> and attesters observe them at <span class="math">T_4</span>. The proposer then collates bids in a beacon block at <span class="math">T_5</span> and attesters attests to the block at <span class="math">T_6</span> contingent on correct collation. The highest unsealed bid wins, paying a fee corresponding to the second highest bid. The fee is burned. Builders that did not unseal their bids are penalized.</p>
<h3><a class="anchor" href="https://ethresear.ch#revealed-bids-6" name="revealed-bids-6"></a>Revealed bids</h3>
<p>In the second round, after the <span class="math">T_3</span> deadline, builders unseal their bids. They should not release before <span class="math">T_3</span>, because then the proposer can collude with other builders to release a bid structure with some bids placed after other bids were revealed. However, they do not need to observe the proposer’s structure before release, and can proceed right after the <span class="math">T_3</span> mark.</p>
<p>Attesters observe unsealed bids at <span class="math">T_4</span>. The proposer collates all unsealed bids it can find, including them in the beacon block at around <span class="math">T_5</span>. It may also include bids that were never unsealed, so that the associated builder can be penalized (this is a strict requirement in the single-slot design, because then the sealed bids have not been included in a previous beacon block). The highest bid is selected as the forthcoming execution proposer, and the second highest bid value is deducted from the winner’s balance and burned. At <span class="math">T_6</span>, attesters attest to the beacon block, contingent on a correct collation by the beacon proposer.</p>
<h2><a class="anchor" href="https://ethresear.ch#rationale-7" name="rationale-7"></a>Rationale</h2>
<p>Collusion between builders and proposers to reduce the burn as in the MEV burn design is arguably resolved; without stakers actively burning each others’ MEV revenue.</p>
<ul>
<li>There is no longer a stable equilibrium to rely on for colluding parties, such as late bidding.</li>
<li>The proposer no longer has leverage to punish early bidders by electing another builder.</li>
<li>Chiseling at a cartel is trivial, simply by truthful bidding.</li>
<li>Every bid fulfills a real purpose, as opposed to early bids in MEV pricing auctions.</li>
<li>There is no avenue for discouragement attacks, since there is no substantial proposer revenue to remove.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#penalization-8" name="penalization-8"></a>Penalization</h2>
<p>Several actions must be penalized. If the proposer omits an observed sealed bid in the first round or an observed revealed bid in the second round, the proposer’s block must be rejected by attesters. If the proposer fails to release the structure of the sealed bids in the first round or the revealed bids in the second round in a timely manner (reaching attesters before <span class="math">T_3</span> and <span class="math">T_6</span> respectively), the proposer’s block must also be rejected by attesters.</p>
<p>It is possible that a builder made a mistake and will be unable to pay for its bid, if the bid is higher than its staked amount. This will be penalized by burning some proportion of the stake, for example corresponding to the amount of the actual winning bid, some fixed amount of ETH, or its entire stake. In any case, if its unbacked bid is the highest, the builder will not win the auction. The second highest bid will instead be selected as the execution proposer, paying the third highest bid, etc. If the bid underpinning the fee (normally the second highest bid) lacks funds, the bid below it will be set to underpin the fee.</p>
<h2><a class="anchor" href="https://ethresear.ch#builder-proposer-collusion-and-possible-remedies-9" name="builder-proposer-collusion-and-possible-remedies-9"></a>Builder–proposer collusion and possible remedies</h2>
<p>A potential cause for concern is the following scenario: a builder determines that it would not like to unseal its bid (potentially after observing other builders’ unsealed bids). It does not want to subject itself to a penalty, so it colludes with the proposer to have it miss the slot. Is this a cause for concern? This ultimately depends on if the builder benefits more by <em>not</em> revealing its bid than the proposer loses from a missed proposal. This could be the case when bidding for the right to propose the current or next slot, and the expected MEV falls drastically between bid commit and reveal (i.e., a <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">value-in-flight</a> problem). Another potential cause for concern is if the value instead increases drastically. The proposer might then pose an ultimatum to the winning builder: “send me some part of expected profits, or I will fail to propose”. A failed proposal would leave the builder without rights for the slot. An <a href="https://en.wikipedia.org/wiki/Ultimatum_game">ultimatum game</a> emerges. The other builders might also be inclined to pay the proposer, in order to starve off competition, and the winning builder would then also need to pay the proposer to ensure it proposes.</p>
<p>While the outlined collusion scenarios may be a bit speculative, it can still be interesting to explore possible remedies. A few directions then spring to mind:</p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-penalize-beacon-proposers-for-missed-beacon-blocks-10" name="h-1-penalize-beacon-proposers-for-missed-beacon-blocks-10"></a>1. Penalize beacon proposers for missed beacon blocks</h4>
<p>Proposers already lose out on revenue if they miss their block. However, this loss might not be a sufficient deterrent. It would therefore be beneficial to also penalize proposers if they miss their blocks. Otherwise, if the penalty applied to a builder is substantially higher than the loss from missed proposals for the proposer, that builder penalty will be less meaningful. Builders could seek to collude to let the proposer take the fall. In essence, if the value to the builder, its competitors, or the proposer, of having the builder not win the auction, is higher than the loss to the proposer of not proposing, then collusion or an ultimatum game may emerge.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-2-require-subsequent-beacon-proposers-to-conclude-the-auction-11" name="h-2-require-subsequent-beacon-proposers-to-conclude-the-auction-11"></a>2. Require subsequent beacon proposers to conclude the auction</h4>
<p>Is it possible to have the next beacon proposer conclude the auction? This depends to some extent on the <a href="https://ethresear.ch/t/sealed-execution-auction/20060#timeline-15">Timeline</a> of the auction.</p>
<ul>
<li><strong>Single-slot design:</strong> In the single-slot design, attesters do not signal if they rejected a block because of an incorrect initial structure, a late structure, or an incorrect or missing beacon block. A way to deal with this is that the next proposer presents the correct outcome of the auction, in its own view, and that the attesters of <span class="math">n+2</span> either reject or confirm the new block based on the proposed outcome. But this means that these attesters must also have tracked events in the previous slot as they unfolded, and any split views (e.g., from a rather late sealed builder bid) may persist for several blocks in a row.</li>
<li><strong>Two-slot design:</strong> If the auction commences over two slots, there will be an agreed-upon set of committed sealed bids, or the first beacon block will have been rejected. The second step of the auction can then be concluded in a subsequent slot without requiring attesters to have observed the commit-phase. The requirement is to still have attesters make an observation of unsealed bids sometime before the proposer deadline. But that point need not necessarily be taken from the earlier slot. A benefit is that this might starve off split views.</li>
</ul>
<p>One thing to note is that if a builder finds it worthwhile to pay the first proposer to not propose, in order to avoid revealing a bid without being penalized, it might be willing to pay also a second proposer for not proposing. However, the price will go up, and the number of potential collusion partners scheduled to propose in a row may not be too large. It should also be noted that when auctioning off rights for slot <span class="math">n+i</span>, there is a requirement that the delay until the conclusion of the auction does not surpass <span class="math">i</span>. In other words, it will only be possible to repeat a failed auction around <span class="math">i</span> times. Note that this requirement is also due to the fact that the order in which auctioned off execution rights are provided cannot be altered ex post, since the expected MEV for slots may vary.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-3-skip-the-beacon-proposal-reveal-12" name="h-3-skip-the-beacon-proposal-reveal-12"></a>3. Skip the beacon proposal reveal</h4>
<p>Is it possible to skip the beacon proposal reveal? If all bids are unsealed, the outcome will be evident to every participant. The mechanism can then be designed such that the winning builder safely can propose its block at the assigned slot, even if a proposer has not collated the outcome and presented a winner. The previous option 2 is focused on concluding the auction via a beacon proposal in time before the execution proposal, but the point here is that the auction does not need to be concluded by the proposer as long as the outcome is evident to the builder and can be verified by attesters when the builder proposes its block. The sealed bids must then have been included in a beacon block, as in the two-slot design.</p>
<p><a href="https://en.wikipedia.org/wiki/Threshold_cryptosystem">Threshold decryption</a> via a committee of attesters (h/t Barnabé) is one option here. The bids are decrypted by a committee, and the winner made evident to the builders/forthcoming proposer and attesters. There would still be liveness concerns, but collusion would be more difficult. It can be noted that as long as all builders unseal their bids in a timely manner (even without threshold decryption), the winning builder can proceed with the proposal. Always penalizing builders that do not unseal their bids before <span class="math">T_4</span> could then seem sufficient, but the issue is that split views would emerge in potential designs. In any case, the outcome would also at some point need to be included in a block, to process payment and penalties.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-4-auction-of-a-future-slot-to-reduce-value-in-flight-13" name="h-4-auction-of-a-future-slot-to-reduce-value-in-flight-13"></a>4. Auction of a future slot to reduce value-in-flight</h4>
<p>The Vickrey auction is truthful, allowing builders to bid their true value at the commit deadline. Since value-in-flight is the most likely cause for collusion, auctioning off a slot further removed from the present will temper the issue.</p>
<h4><a class="anchor" href="https://ethresear.ch#auctioning-off-multiple-slots-14" name="auctioning-off-multiple-slots-14"></a>Auctioning off multiple slots</h4>
<p>Note that to avoid having a failed beacon proposal result in a missing execution proposal, there is also the option to sell the right to two execution proposals in the subsequent slot (with builders bidding their <a href="https://en.wikipedia.org/wiki/Vickrey_auction">inverse demand curve</a> and paying according to the second and third highest bids).</p>
<h2><a class="anchor" href="https://ethresear.ch#timeline-15" name="timeline-15"></a>Timeline</h2>
<p>This section presents two hypothetical timelines for the auction, either when only including unsealed bids in the beacon block (single-slot auction) or when including both sealed and unsealed bids in separate beacon blocks (two-slot auction).</p>
<h3><a class="anchor" href="https://ethresear.ch#single-slot-auction-16" name="single-slot-auction-16"></a>Single-slot auction</h3>
<p>Example of a slot auction with a tight schedule enacted mostly during a single slot <span class="math">n</span>, auctioning off execution proposal rights for a later slot <span class="math">n+i</span>.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th><span class="math">T_x</span></th>
<th>Time</th>
<th>Overview</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">T_1</span></td>
<td>4s</td>
<td><strong>Sealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe all sealed bids. Builders must have broadcast them some time before this point to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_2</span></td>
<td>6s</td>
<td><strong>Proposer collates bids</strong></td>
<td>The proposer of slot <span class="math">n+1</span> releases a structure containing all sealed bids it can find.</td>
</tr>
<tr>
<td><span class="math">T_3</span></td>
<td>8s</td>
<td><strong>Attesters observe collation</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe the proposer’s structure to ensure it contains all bids they had seen at <span class="math">T_1</span> and that the release of this structure is timely.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><span class="math">T_4</span></td>
<td>10s</td>
<td><strong>Revealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe unsealed bids. Builders must have broadcast them some time before this point (but after <span class="math">T_3</span>) to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_5</span></td>
<td>0s (12s)</td>
<td><strong>Proposer collates in beacon block</strong></td>
<td>The proposer of slot <span class="math">n+1</span> includes every unsealed bid it can find in the  block, also indicating sealed bids that were never unsealed. A winner is declared.</td>
</tr>
<tr>
<td><span class="math">T_6</span></td>
<td>4s (12+4s)</td>
<td><strong>Attesters confirm collation</strong></td>
<td>Attesters of slot <span class="math">n+1</span> confirm that the proposer fulfilled its role and collated bids in a timely manner by attesting to the block.</td>
</tr>
</tbody>
</table>
</div><p>Note that builders can unseal their bids directly after <span class="math">T_3</span>. This should allow attesters of slot <span class="math">n+1</span> to observe revealed bids at 10s. However, if needed, the entire schedule could be pushed back slightly.</p>
<h3><a class="anchor" href="https://ethresear.ch#two-slot-auction-17" name="two-slot-auction-17"></a>Two-slot auction</h3>
<p>Here is an example of a schedule for the two-slot auction:</p>
<div class="md-table">
<table>
<thead>
<tr>
<th><span class="math">T_x</span></th>
<th>Time</th>
<th>Overview</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">T_1</span></td>
<td>10s</td>
<td><strong>Sealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+1</span> observe all sealed bids. Builders must have broadcast them some time before this point to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_2</span></td>
<td>0s (12s)</td>
<td><strong>Proposer collates bids</strong></td>
<td>The proposer of slot <span class="math">n+1</span> includes all sealed bids it can find in its beacon block.</td>
</tr>
<tr>
<td><span class="math">T_3</span></td>
<td>4s (12+4s)</td>
<td><strong>Attesters confirm collation</strong></td>
<td>Attesters of slot <span class="math">n+1</span> confirm that the proposer fulfilled its role and collated bids in a timely manner by attesting to the block.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><span class="math">T_4</span></td>
<td>8s (12+8s)</td>
<td><strong>Revealed bid deadline</strong></td>
<td>Attesters of slot <span class="math">n+2</span> observe unsealed bids. Builders must have broadcast them some time before this point (but after <span class="math">T_3</span>) to ensure eligibility.</td>
</tr>
<tr>
<td><span class="math">T_5</span></td>
<td>0s (12+12s)</td>
<td><strong>Proposer collates in beacon block</strong></td>
<td>The proposer of slot <span class="math">n+2</span> includes every unsealed bid it can find in the  block, potentially indicating sealed bids that were never unsealed. A winner is declared.</td>
</tr>
<tr>
<td><span class="math">T_6</span></td>
<td>4s (12+12+4s)</td>
<td><strong>Attesters confirm collation</strong></td>
<td>Attesters of slot <span class="math">n+2</span> confirm that the proposer collated all unsealed bids by attesting to the block.</td>
</tr>
</tbody>
</table>
</div>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/sealed-execution-auction/20060">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 13 Jul 2024 16:30:07 +0000</pubDate>
</item>
<item>
<title>Staking Rights Auctions</title>
<link>https://ethresear.ch/t/staking-rights-auctions/20059</link>
<guid>https://ethresear.ch/t/staking-rights-auctions/20059</guid>
<content:encoded><![CDATA[
<div> 关键词：Staking Rights Auctions, Ethereum, Issuance, MEV, Inflation Control

总结: 这篇文章讨论了作者过去为Cartesi和CTSI提出的一种名为"Staking Rights Auctions"的机制，旨在解决以太坊发行（包括ether的质押和MEV问题）中的挑战。该机制通过拍卖赋予节点操作员参与权益，用户可以根据风险偏好支付不同的价格，从而实现更精细的激励分配。文章提到，这有助于平衡MEV差距、控制通胀并允许用户表达不同的投资时间周期。尽管需要进一步研究和生态系统的参数决策，但作者认为这个系统能提高参与度，同时限制通胀，促进更健康的网络环境。 <div>
<p>This post was written by <a class="mention" href="https://ethresear.ch/u/pedroargento">@pedroargento</a> but his account seems unable to post it, so he asked me to do it. I’m not too aware of the necessities/constraints of the ether issuance debate - but this seems quite interesting for defi protocols as well. Anyway, here it goes:</p>
<hr />
<p>Hey everyone,</p>
<p>A friend of mine just watched the “What’s the Issue with Issuance?” talk by Christine Kim, Caspar Schwarz-Schilling, and Ansgar Dietrichs at EthCC. They said that the key points discussed around Ethereum’s issuance reminded them of a proposal I wrote in the past for Cartesi and CTSI.</p>
<p>The significant issues mentioned were the high (and growing) percentage of ether staked, how having too much ether staked isn’t necessarily beneficial for the network, how LST providers might be in a "winner take all ‘’ situation and etc. Both Ansgar and Justin Drake suggested aiming for around 20-25% staked ether (ball park estimates).</p>
<p>It seems to me that the auction mechanism I proposed for the CTSI staking economy could really help to address these issues, by making the staking system much more expressive. The idea also allows participants to pay negative issuance for the right to earn MEV, which not only tackles the problem of excessive ether staking, but might also helps to balance MEV discrepancies.</p>
<p>I’m not an expert in this research area, but based on the feedback from the EthCC talk, it seems like my proposal aligns well with the direction Ethereum is aiming to take. I’m sharing this here on the Ethereum Research forum in hopes that it can contribute to the ongoing conversation and possibly offer a viable solution to the current challenges with Ethereum’s issuance models.</p>
<p>Looking forward to your thoughts and feedback!</p>
<h1><a class="anchor" href="https://ethresear.ch#staking-rights-auctions-1" name="staking-rights-auctions-1"></a>Staking Rights Auctions</h1>
<p>A popular solution to reward users for staking is to mint new tokens and distribute them among stakers. Besides the obvious incentive to gain extra tokens, the inflation created penalizes those who choose not to participate. The challenge is how to measure the opportunity costs of users and how to choose the appropriate issuance amount to achieve a target participation rate, while avoiding exceedingly high inflation rates.</p>
<p>Some projects have a fixed emission rate while others have a dynamic inflation function, which is higher when the participation is below desired and lower otherwise. There are three key problems with these methods:</p>
<ul>
<li>
<p>You need strong assumptions about users’ risk preferences to tailor the parameters of the function;</p>
</li>
<li>
<p>Users have little information about the mining income they will get as it depends on the number of total staked funds.</p>
</li>
<li>
<p>The methods don’t allow for differentiation between players with different risk preferences;</p>
</li>
<li>
<p>It is hard to determine a balanced inflation target.</p>
</li>
</ul>
<p>As a countermeasure to these three issues, I’m proposing a staking system based on a novel mechanism called staking rights, detailed in the sections below.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-mechanism-of-staking-rights-2" name="the-mechanism-of-staking-rights-2"></a>The Mechanism of Staking Rights</h2>
<p>Staking rights give node operators the right to participate in staking. Without the rights, operators cannot be selected in the lottery that chooses the node that will generate the next block.</p>
<p>Rights are transitory. At the end of each staking cycle, a set of rights expires and ceases to exist. Conversely, new rights are created and made available for purchase through an auction.</p>
<p>Staking rights always have a final value of 1 token, which is delivered to the account that purchased it at the precise time of their expiry. When users buy a staking right for a price of less than 1 token, the difference between the price paid and the unit value is proportional to their perceived opportunity of the staking right. In that case, the difference is minted and locked in staking together with the price paid, totaling 1 token staked per right sold.</p>
<p>Here is an example. Suppose that the desired staking participation rate is 50% of the circulating supply of 1 thousand tokens. In this case, the system creates and auctions 500 staking rights, each scheduled to pay 1 token at the end of the cycle.</p>
<blockquote>
<p>Circulating supply: 1000<br />
Target participation: 500 (50%)<br />
Staking rights issued: 500<br />
Auction price = 0.97</p>
</blockquote>
<p>Assume that each staking right is sold for <span class="math">0.97</span> in the auction, thereby generating <span class="math">0.03</span> new tokens. The staking rights buyer at the end of the staking cycle would be rewarded 1 token obtaining a <span class="math">3.09\%</span> return <span class="math">(0.03/0.97)</span>. The total inflation generated for the network would be <span class="math">15</span> tokens (<span class="math">0.03</span> per right * <span class="math">500</span> rights) or <span class="math">1.5\%</span>.</p>
<p>With this system, the user knows exactly how much return they will get for their staked tokens, independent of how many rights are sold or how many other stakers exist. There are also no assumptions about risk preferences, buyers will state them through bidding. This method also allows for bigger differentiation between users: instead of asking for a binary decision (stake or not to stake), we allow users to signal at what price they would be willing to stake.</p>
<p>The system can offer staking rights with different staking cycle periods: 2 weeks, 1 month, 3 months, etc. This achieves two objectives (1) differentiate between users who are willing to stake long term from short term players and, mainly, (2) decrease volatility in token emission. After all, if all staking cycles end at the same time, all new staking rights will be subjected to the same market conditions that may not represent the average behavior of stakers.</p>
<p>With different staking periods, in each cycle only a small number of staking rights will need to be created to replace the expired ones. This is because in each cycle there is going to be a mix of active staking rights bought at different points in time.</p>
<p>User risk preferences can be stated in the form of a discount rate, the rate used to convert future values (promises of payouts) to the present. The discount rate is the income that makes one indifferent between gaining money in the present or in the future. For example, with a discount rate of 10% a year, one would be indifferent between receiving 100 dollars today or 110 dollars a year from now.</p>
<p>The discount rate of a user can be translated to a staking right value using it to compute the present value of all incentives that can be paid by staking the right.</p>
<p>Staking rights give the owner three sources of incentives, provided that the owner remained active within the network:</p>
<ul>
<li>
<p>Staking right’s unit value (paid at the end of the cycle)</p>
</li>
<li>
<p>Block producer’s tips</p>
</li>
<li>
<p>Mine extractable Value</p>
</li>
</ul>
<p>Below is an example of staking rights holder cash flows for a six month locked period.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/8/28063c3ac2b9e1cd18ed0e7aa69be283c8125261.png" title="Chart"><img alt="" height="385" src="https://ethresear.ch/uploads/default/optimized/3X/2/8/28063c3ac2b9e1cd18ed0e7aa69be283c8125261_2_624x385.png" title="Chart" width="624" /></a></div><p></p>
<p>The price to be paid for the staking can be easily calculate based on the return demanded by the staker</p>
<blockquote>
<p>Given:<br />
a staking right in a staking cycle of 12 weeks that pays rewards every 2 weeks<br />
<span class="math">MEV_t</span> the expected mine reward for time <span class="math">t</span><br />
<span class="math">NF_t</span> the expected network fees for time <span class="math">t</span><br />
<span class="math">UV</span> the staking right unit value<br />
<span class="math">i</span> the 2-week return expected by the user<br />
The price <span class="math">P</span> will be calculated as:</p>
<div class="math">
P= \frac {UV} {(1+i)^6} + \sum_ {t=1}^{6} \frac {MEV_t + NF_t} {(1+i)^t}
</div>
</blockquote>
<p>The staking rights can be sold through a closed price auction of Nth price, which means that the higher bid wins the token but will pay the price of the highest loser bid. For example, If 500 tokens are sold and the 501st highest bid was 0.98, all 500 tokens will cost 0.98. This type of auction, also known as a Vickrey auction (or Dutch auction), ensures all players bid their true valuation of the staking right, revealing their true risk preferences.</p>
<blockquote>
<p><strong>Proof</strong><br />
Its not 100% applicable to this specific auction, but a classical proof from Game Theory can give the intuition why the paid price being the lowest winning bid incentivizes truthfully reporting:</p>
<p>Given user <span class="math">i</span> has a valuation <span class="math">B_i</span> for a staking right. They can bid <span class="math">B_+ &gt;B_i</span> or <span class="math">B_- &lt; B_i</span> and the <span class="math">N</span>-th price of the auction ends up being <span class="math">B_n</span>.</p>
<p>If they bids <span class="math">B_+</span> there are two possibilities:</p>
<ol>
<li>
<p><span class="math">B_n &lt; B_i</span></p>
</li>
<li>
<p><span class="math">B_+ &gt; B_n &gt; B_i</span></p>
</li>
</ol>
<p>In (1) they would get <span class="math">(B_i - B_n)</span> independent of bidding <span class="math">B_+</span> or <span class="math">B_i</span> and in (2) they would lose <span class="math">(B_i — B_+)</span> that would be larger than <span class="math">(B_n — B_i)</span>. In neither case they have incentive to bid <span class="math">B_+</span>.</p>
<p>If they bids <span class="math">B_-</span> there are two possibilities:</p>
<ol start="3">
<li>
<p><span class="math">B_n &lt; B_-</span></p>
</li>
<li>
<p><span class="math">B_- &lt; B_n &lt; B_i</span></p>
</li>
</ol>
<p>In (3) they would get <span class="math">(B_i — B_n)</span> independent of bidding <span class="math">B_-</span> or <span class="math">B_i</span> and in (4) they would not get the token, making it better to bid <span class="math">Bi</span> and have the chance to win.</p>
<p>In all possible cases there is no incentive to bid <span class="math">B_+</span> or <span class="math">B_-</span>, making <span class="math">B_i</span> the dominant Nash-Bayesian equilibrium.</p>
</blockquote>
<p>This system also allows for deflation, if the value of the auction ends up above 1 unit. This would make sense if people are expecting such a high reward from the fees and MEV that they are willing to burn a certain amount of tokens in order to participate.</p>
<h2><a class="anchor" href="https://ethresear.ch#inflation-control-mechanisms-3" name="inflation-control-mechanisms-3"></a>Inflation Control Mechanisms</h2>
<p>Besides the burning possibility, its possible to add parameters in the auction to help manage inflation. Although its unclear to me at this time how those parameters could be decided by the Ethereum ecosystem, I’m presenting them anyway. Contributions are welcomed as always.</p>
<p><strong>First</strong>. Auction reserve prices: In the worst-case scenario, where all rights are sold in the auction with a price close to zero, the inflation will be the number of rights sold, divided by the total supply (50% in our previous example).</p>
<p>A reserve price means that only bids above a certain value will be considered valid. If we choose a reserve price of 0.7, the worst-case scenario in our example would be an inflation of 15%.</p>
<p>With a reserve price, it is possible to choose an acceptable inflation range and guarantee it will be complied with at all times.</p>
<p><strong>Second</strong>. The number of issued tokens: The number of tokens directly affects the inflation. If only 100 tokens are issued (out of a total supply of one thousand), the worst-case scenario for inflation would be 10%.</p>
<p>These two variables need to be controlled dynamically in order to make sure the inflation is never higher than a previously determined ceiling. The number of tokens issued will depend not only on the target participation rate but also on the value of bids from the auction. This number will be capped so that the total newly minted tokens are limited to the maximum inflation. The total newly minted tokens can be calculated as the difference between the face value and the highest bid not honored (the Dutch auction price) times the number of tokens issued.</p>
<blockquote>
<p>Let <span class="math">CAP</span> be the maximum number of minted ETH desired</p>
<p>Let <span class="math">N_ {max}</span> be the maximum number of staking rights necessary to achieve the target participation rate</p>
<p>Let <span class="math">B(i)</span> be the <span class="math">i</span>-th largest bid from the auction results</p>
<p>Let <span class="math">N</span> be the number of staking rights issued</p>
<p><span class="math">N</span> will be chosen as the result of the optimization problem:</p>
<div class="math">
\begin{aligned}
\max_{} \quad &amp; N\\
\textrm{s.t.} \quad &amp; N * (1-B(N+1)) \le CAP\\
\quad &amp; N \le N_ {max} \\
\end{aligned}
</div>
</blockquote>
<p>More precisely, suppose that we sort all the bids made during the auction in decreasing order and plot them as in the figure below.</p>
<p><img alt="m1" height="318" src="https://ethresear.ch/uploads/default/original/3X/f/4/f4dd92342507c13ba5e872d205c15c90bf308b60.png" width="477" /></p>
<p>Then N staking rights will be issued in order to preserve the maximum number of ETH issued (CAP). Therefore, we can dynamically choose the minimum value B(N+1) such that the inflation is within the predetermined bounds.</p>
<p>The deflation case is depicted in the figure below:</p>
<p><img alt="m2" height="318" src="https://ethresear.ch/uploads/default/original/3X/7/3/736de5fac6d3efefd1b613297221521da4f9d64b.png" width="459" /></p>
<p>It is important to note that there is no way around the tradeoff between participation rate and inflation, to control the later there is the need to sacrifice the former. The advantage brought by the system of staking rights auction is that we maximize participation, while limiting the inflation and allowing workers to express their economic preferences.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/staking-rights-auctions/20059">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 13 Jul 2024 14:53:13 +0000</pubDate>
</item>
<item>
<title>Bitfinity: A new sharded blockchain</title>
<link>https://ethresear.ch/t/bitfinity-a-new-sharded-blockchain/20054</link>
<guid>https://ethresear.ch/t/bitfinity-a-new-sharded-blockchain/20054</guid>
<content:encoded><![CDATA[
<div> 关键词: 
1. 基于阈值BLS签名
2. 分片（sharding）
3. 无缝跨-shard通信
4. 跨链结算
5. Bitcoin-EVM桥接

总结:
Bitfinity是一个运用了分片技术的新型区块链，通过阈值BLS签名实现线性可扩展性和高速度。它将代币与EVM处理器分离，支持跨-shard通信，实现了顺畅的跨链资产转移，包括与比特币的连接。作为比特币和其它资产的Layer Two，Bitfinity特别适合部署复杂Solidity智能合约，提供极致的性能和效率。<br /><br />总结: Bitfinity利用分片和阈值签名技术，打造高性能的EVM，连接比特币和其他资产，实现跨链交易和智能合约部署。 <div>
<p>Using threshold BLS signatures we design a new blockchain that implements sharding, separating tokens from EVM processors. Bitfinity is linearly scalable and fast.<br />
Bitfinity implements seamless cross-shard communication.</p>
<aside class="onebox pdf">
  <header class="source">

      <a href="https://github.com/bitfinity-network/whitepapers/blob/163145326e321c87956b2f881159f73b7a6409fb/Bitfinity_Network.pdf" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <a href="https://github.com/bitfinity-network/whitepapers/blob/163145326e321c87956b2f881159f73b7a6409fb/Bitfinity_Network.pdf" rel="noopener nofollow ugc" target="_blank"><span class="pdf-onebox-logo"></span></a>

<h3><a href="https://github.com/bitfinity-network/whitepapers/blob/163145326e321c87956b2f881159f73b7a6409fb/Bitfinity_Network.pdf" rel="noopener nofollow ugc" target="_blank">Bitfinity_Network.pdf</a></h3>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>
<p>
Using sharding techniques we also implement seamless cross-chain settlement and can bridge over Bitcoin to the EVM.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="32" src="https://ethresear.ch/uploads/default/original/3X/9/6/966040c1403c32d7669b160eb35a33dc860db193.png" width="32" />

      <a href="https://bitfinity.network/" rel="noopener nofollow ugc" target="_blank">bitfinity.network</a>
  </header>

  <article class="onebox-body">
    

<h3><a href="https://bitfinity.network/" rel="noopener nofollow ugc" target="_blank">Bitfinity EVM</a></h3>

  <p>Bitfinity is a blazingly-fast, next-gen EVM, serving as a Layer Two for Bitcoin and other assets - utilising threshold signature schemes and built on the IC. Use Bitfinity to deploy advanced Solidity smart contracts.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/bitfinity-a-new-sharded-blockchain/20054">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 12 Jul 2024 23:34:33 +0000</pubDate>
</item>
<item>
<title>Searcher Competition in Block Building</title>
<link>https://ethresear.ch/t/searcher-competition-in-block-building/20044</link>
<guid>https://ethresear.ch/t/searcher-competition-in-block-building/20044</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV奖励、验证者、搜索者、合作博弈论、核心

总结:<br />本文探讨了在区块链中，验证者和搜索者之间的MEV（矿工提取价值）收益分配。通过合作博弈论模型，研究了验证者（具有否决权）与可替代或互补的搜索者之间的互动。核心部分分析了可能的支付向量，发现当搜索者竞争激烈时，验证者的奖励增加，符合理论预测。在随机模型中，高概率下搜索者独立发现机会时，验证者独占全部收益；而在低概率或搜索者互补情况下，验证者可能得到零支付。研究还扩展到了有限大小区块的情况。实证结果证实了理论的预测。 <div>
<p>In a new paper with Christoph Schlegel (<a class="mention" href="https://ethresear.ch/u/jcschlegel">@jcschlegel</a>), Benny Sudakov and Danning Sui(<a class="mention" href="https://ethresear.ch/u/sui414">@sui414</a>), we look at the distribution of MEV rewards between the validator and searchers. We model the interaction between all players using tools from cooperative game theory. Namely, for any coalition of players, we define a (maximum achievable) value the coalition can derive by creating the best block together. The validator is a special player, that is needed to create any value. In other words, it has a veto power. However, searchers are the ones that find (arbitrage) opportunities which derive a value. Searchers can be substitutes or complements of each other into finding opportunities. The outcome of this interaction is payoff vector, specifying how much each player gets. In the core of the game payoffs are such that any coalition gets paid at least as much as the value they produce themselves.<br />
First, we study a structure of the core, which is always non-empty set of payoff vectors. Then, we focus on the searcher-optimum allocation and show that each searcher obtains its marginal contribution. In a stochastic model, where each opportunity is independently found with the same probability by each searcher, we show that if this probability is mildly high in the number of searchers, validator gets all rewards. In other words, core is just a single payoff vector. While if this probability is low, with a constant probability the validator can get zero payment, as the searchers are complements of each other. We extend some results to the blocks with bounded size.<br />
On the empirical side, we observe that if there is a high competition of searchers, validator rewards are increasing (in absolute terms), which aligns with our theoretical predictions.<br />
For more details check out the paper: <a class="inline-onebox" href="https://arxiv.org/abs/2407.07474" rel="noopener nofollow ugc">[2407.07474] Searcher Competition in Block Building</a>. Any feedback is welcome.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/searcher-competition-in-block-building/20044">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 11 Jul 2024 11:00:11 +0000</pubDate>
</item>
<item>
<title>L2 Asset Interoperability via Two-way Canonical Bridges</title>
<link>https://ethresear.ch/t/l2-asset-interoperability-via-two-way-canonical-bridges/20039</link>
<guid>https://ethresear.ch/t/l2-asset-interoperability-via-two-way-canonical-bridges/20039</guid>
<content:encoded><![CDATA[
<div> 关键词：L2资产、两向桥接、ERC-1155接口、L2结算合同、跨链流动性

总结:<br />
文章讨论了L2资产桥接问题，强调了现有的L2解决方案如L2之间共享结算层的局限性，导致生态系统碎片化。为解决这一问题，提出了一种两向桥接的概念，即资产能在L2和L1之间双向流动。L2结算合同作为记录，采用ERC-1155接口，用户通过发送资产到系统地址实现转移。返回L2时，使用特殊函数进行销毁并存入。这种设计确保资产安全，用户自行承担风险。同时，用户可利用快速流动性桥，而跨链流动性提供者则用于资产重平衡。该机制还可扩展至L3。总的来说，两向桥接旨在打破链间壁垒，促进资产流动性与互操作性。 <div>
<h2><a class="anchor" href="https://ethresear.ch#motivation-1" name="motivation-1"></a>Motivation</h2>
<p>One key problem with the L2 scaling solutions is that assets natively minted on L2s can only be used on the L2 of issuance but it cannot be bridged back to L1 or other L2s, without utilizing external bridges. This creates fragmentation. At the time of writing, there is already half as much natively-minted assets ($12b) on Eth L2s compared to canonical bridged assets ($24b), according to L2Beat.</p>
<p>Shared settlement layers only solve this problem for L2s using the same shared settlement layer. The ecosystem remain fragmented once more shared settlement layer show up.</p>
<p>We propose <strong>two-way canonical bridges</strong> as a solution, where L2-minted assets can be <strong>reverse-canonically bridged</strong> to L1. It is simply an ERC-1155-like interface that an L2 settlement contracts adopt, plus additional precompiles added to the L2 execution environment.</p>
<h2><a class="anchor" href="https://ethresear.ch#two-way-canonical-bridges-2" name="two-way-canonical-bridges-2"></a>Two-way Canonical Bridges</h2>
<p>Below is a highlevel description of two-way canonical bridging.</p>
<ul>
<li>The L2 settlement contract becomes the ledger of record for all native assets issued on it (that have been reverse-canonically-bridged). The settlement contract (on L1) shall implement the ERC-1155 interface, where the asset id field denotes the L2 asset address.</li>
<li>To send an L2-native asset to an L1 address, the L2 users simply send the asset to a prespecified system address, which shall results in the L2 settlement contract on L1 issuing ERC-1155 tokens to itself. Next, L2-&gt;L1 call mechanisms can be utilized to move the newly-issued asset to any desired destination. This is done within the same L2 transaction.</li>
<li>To send a reverse-canonically-wrapped asset back to its L2 of origin, a special <code>burnAndDeposit</code> function on the L2 settlement contract can be called.</li>
<li>Since the L2 settlement contract is an ERC-1155 contract, L1 EOAs and other L2s can simply hold assets or wrap them as normal. This requires the L2 canonical bridge to support wrapping of ERC-1155 assets.</li>
<li>In normal usage, it is expected that the only holders of the ERC-1155 tokens issued by an L2 settlement contract are other L2 settlement contracts. This means that the state overhead on L1 is small.</li>
</ul>
<p>Additional consideration:</p>
<ul>
<li>The safety of an asset is maintained without additional trust assumptions because the L2 settlement contract acts as the ledger of record for all outstanding assets (those owned by other L1 addresses).</li>
<li>It is assumed that any assets that is reverse-canonically-bridged to L1 addresses is done at the risk of the user initiating the bridging.</li>
<li>In practice, end-users can utilize fast liquidity bridges while crosschain liquidity providers utilize the two-way canonical bridges to rebalance.</li>
<li>This mechanism can extend to L3s on L2s. An asset issued on an L3 can be reverse canonically-bridged to L2 and then reverse canonically-bridged back to L1. We’d need the 1155 ids on the settlement contract to be able to represent the 1155 asset id on L2 alongside with the asset address–this can be done via hashing for example.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#acknowledgements-3" name="acknowledgements-3"></a>Acknowledgements</h3>
<p>Thanks to Shumo Chu for review and comments.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/l2-asset-interoperability-via-two-way-canonical-bridges/20039">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Jul 2024 22:20:35 +0000</pubDate>
</item>
<item>
<title>MEV resistant dynamic pricing auction of execution proposal rights</title>
<link>https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024</link>
<guid>https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV抵抗、动态定价拍卖、执行提案权、随机抽取机制（RANDAO）、票池拍卖（ET）

总结:
这篇文章提出了一种MEV抵抗的动态定价拍卖机制，用于销售执行提案权。这种机制旨在减少 Beacon 验证者在提案选择过程中的影响，通过公开的P2P层接受建造者购买订单，订单由共识层的债务账户支持。购买过程由 attesters 观察并确保其有效性，避免了过多的MEV。设计有执行票拍卖(ETA)和集体铸造两种版本，其中 ETA 利用RANDAO随机排序。文章讨论了价格调整策略、动态定价的复杂性以及如何平衡价格变化与市场需求。尽管存在多块交易MEV和审查抵抗等未解决的问题，但该机制为执行提案权的拍卖提供了一个潜在的、MEV抵抗的解决方案。 <div>
<h1><a class="anchor" href="https://ethresear.ch#mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights-1" name="mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights-1"></a>MEV resistant dynamic pricing auction of execution proposal rights</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/9/3903954c39a134bc9b9fc6b919977da400390b97.jpeg" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/3/9/3903954c39a134bc9b9fc6b919977da400390b97_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><em>Execution proposal of marriage between EA and ET through an auction sequenced by RANDAO (she said yes).</em></p>
<p>By <a href="https://x.com/weboftrees">Anders</a>. Special thanks to <a href="https://x.com/barnabemonnot">Barnabé</a> for helping me improve the clarity of this post. Thanks also for valuable feedback to <a href="https://x.com/soispoke">Thomas</a>, <a href="https://x.com/_julianma">Julian</a>, and <a href="https://x.com/fradamt">Francesco</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-1-introduction-2" name="h-1-introduction-2"></a>1. Introduction</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-11-background-3" name="h-11-background-3"></a>1.1 Background</h3>
<p>As part of the effort to enshrine proposer–builder separation (<a href="https://ethresear.ch/t/minimal-epbs-beacon-chain-changes/18653">ePBS</a>), the role of beacon validators as execution proposers has come under <a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg">scrutiny</a>. <a href="https://ethresear.ch/t/execution-tickets/17944">Execution tickets</a> (ET), first introduced as <a href="https://www.youtube.com/watch?v=IrJz4GZW-VM">attester–proposer separation</a>, is a mechanism for selecting the execution proposer by random draw from a ticket pool, aiming to detach beacon validators from the selection process. However, the mechanism for selling tickets has not been settled, with several <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764#preliminaries-12">alternatives</a> under consideration. A notable <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">concern</a> is that the sale of execution tickets may induce maximal extractable value (MEV). If the mechanism is administered by the consensus layer and the beacon proposer is given too much influence over the price or over the selection of purchasers, the design risks repeating one of the issues it was intended to resolve, with a new source of MEV becoming a concern. An execution layer vending machine raises similar <a href="https://x.com/barnabemonnot/status/1805859642213269739">questions</a>. Therefore, a MEV resistant auction mechanism could be desirable if pursuing ETs.</p>
<p><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">Execution auctions</a> (EA) is a related mechanism for selecting a future execution proposer, omitting the ticket pool. It  relies on a <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">MEV pricing auction</a>, where bidders first make bids that set a <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">floor to the MEV burn</a>, and finally bid through tips in order to be selected by the proposer. Concerns have been raised (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">2</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">3</a>) regarding the viability of MEV pricing auctions due to insufficient bid incentives in the initial phase. It has <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">recently been suggested</a> that this concern is resolved by considering the staking metagame, in which stakers must bid early to deprive other stakers of revenue. However, this resolution implies that EAs will lead to increased staker–builder integration, which might also be a <a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856#risks-associated-with-attester-builder-integration-14">cause for concern</a>. For this reason, it seems fruitful to explore an alternative auction mechanism also when selecting the execution proposer without leveraging a ticket pool.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-12-overview-of-proposal-4" name="h-12-overview-of-proposal-4"></a>1.2 Overview of proposal</h3>
<p>This post introduces a dynamic pricing auction with MEV resistance to sell execution proposal rights. Builders hold reserves in a debit account and place binding purchase order for a ticket (ET) or an execution proposal slot (similar to EA). The final price adapts dynamically based on the total outstanding as well as currently incoming orders/tickets, with some similarities to, e.g., <a href="https://github.com/ethereum/EIPs/blob/f93b530c60dc7a88e5b811f9cbdf865ecc1b9b97/EIPS/eip-1559.md">EIP-1559</a>, and the payment is burned. Orders are delimited at the slot level through attester observations to remove agency from the beacon proposers facilitating the auction, thus inducing less new MEV. This produces a high aggregate MEV burn. In one version of the design, dubbed execution ticket auction (ETA), orders that came in during the same slot are sequenced for proposal by leveraging the <a href="https://eth2book.info/capella/part2/building_blocks/randomness/#the-randao">RANDAO</a>. In another version only applicable to ETs, orders that came in during the same slot are minted collectively into tickets. Due to the current limitations of the RANDAO, the mechanism is only capable of auctioning off proposal rights at least one epoch in advance.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-2-purchase-process-5" name="h-2-purchase-process-5"></a>2. Purchase process</h2>
<p>Figure 1 presents the proposed purchase mechanism. Builders send purchase orders (for one ticket/execution slot at a time) over a public P2P layer. They specify a maximum price and hold a debit account within consensus to guarantee that their purchase orders are backed by sufficient funds. This account is funded using a separate transaction (see the discussion).</p>
<p>Beacon attesters observe all orders up to an observation deadline, enacted for example 2 seconds before the slot boundary. The beacon proposer collects all orders (there will be one purchase order per slot on average), including orders they may have found during the last few seconds of their slot. Orders are added as a group to the beacon block and will later be popped from a virtual first-in first-out (FIFO) queue scheduled across blocks. This queue may be just one slot long, depending on implementation.</p>
<p>Attesters reject the block if the beacon proposer fails to include a purchase order that they observed. The mechanism thus far has similarities to MEV pricing auctions (e.g., <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV burn</a>, <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">EA</a>), but attesters are tasked with simply observing all purchases, instead of setting a bid floor. Another design that might come to mind is inclusion lists (ILs) in the style of <a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">FOCIL</a>, but there is no new active participant in the form of an IL committee.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/0/702bb78973cad1e335953a439305f91bf34e2132.png" title="Figure 1"><img alt="Figure 1" height="424" src="https://ethresear.ch/uploads/default/optimized/3X/7/0/702bb78973cad1e335953a439305f91bf34e2132_2_690x424.png" width="690" /></a></div><p></p>
<p><strong>Figure 1.</strong> Schematic overview of the purchase process. Orders in blue, backed by builders’ debit accounts, are observed by attesters (purple arrows). Beacon proposers subsequently add all incoming orders to the beacon block (dark red arrow). A validity check is performed to ensure that orders are fully backed. Orders are finally processed—using either RANDAO to determine the sequence in cases where several orders came in during the associated slot (yellow), or otherwise using collective minting (red). In ETA, orders are directly queued for proposal.</p>
<p>Once a slot’s orders have been added to the beacon block, a validity check is performed on builders that included at least one new order (cyan in Figure 1). If a builder’s outstanding (not yet processed) orders across the queue are not fully backed by its debit account, all the builder’s pending orders are discarded. A penalty may also be applied. Orders are  priced directly upon being added or, e.g., at the time of sequencing, as described in Section 4. The determined purchase price is charged from the debit account and burned. The remaining ETH of the purchase order is subsequently virtually released such that it can be used to back new purchase orders. Orders are then sequenced and either queued for proposal (yellow arrow) or added to the ticket pool (red arrow), as described in Section 3.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-3-sequencing-process-6" name="h-3-sequencing-process-6"></a>3. Sequencing process</h2>
<p>The purchase orders from the same slot are added unsequenced to the beacon block. The subsequent sequencing of orders from the same slot varies between designs.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-31-et-minting-of-execution-tickets-7" name="h-31-et-minting-of-execution-tickets-7"></a>3.1 ET – Minting of execution tickets</h3>
<p>The natural strategy for ETs is <em>collective minting</em>, wherein all orders from the same slot mint a ticket at the same time, as indicated by the red arrow in Figure 1. The RANDAO used for ETA in the next subsection could also be applied to ETs using the same setup (dashed yellow arrow). However, the only real benefit (which remains marginal) is to facilitate a more even replenishment of the ticket pool.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-32-eta-orders-sequenced-by-randao-8" name="h-32-eta-orders-sequenced-by-randao-8"></a>3.2 ETA – orders sequenced by RANDAO</h3>
<p>Purchase orders that came in during the same slot can be sequenced directly by the RANDAO, completely skipping a ticket pool. Perhaps <em>execution ticket auction</em> (ETA) would be a proper moniker. Indeed, with this design, a buyer will have an <em>Estimated Time of Arrival</em> for their order, which suitably cannot be precisely known beforehand if there is more than one order in the slot. Barnabé’s discussion (<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">1</a>, <a href="https://x.com/barnabemonnot/status/1805872045302898807">2</a>) on the topic of ETs and determinism is relevant here.</p>
<p>Orders can only be sequenced after the RANDAO has been updated. Therefore, there is an initial ineligibility window <span class="math">W</span> during which orders cannot lead to an execution proposal. The RANDAO updates every 32 slots, but the proposed mechanism does not guarantee a new order every slot; in fact, the mode will be zero orders in a slot. Consequently, the safe distance between auction and slot proposal will need to be somewhat longer than 32 slots. Sequenced orders can be understood as sitting in a second FIFO queue while waiting to propose. Note that ETA could set the queue to hold as many proposal rights as the ticket pool, if desirable.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-4-dynamic-pricing-9" name="h-4-dynamic-pricing-9"></a>4. Dynamic pricing</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-41-ticket-saturation-and-delta-10" name="h-41-ticket-saturation-and-delta-10"></a>4.1 Ticket saturation and delta</h3>
<p>The exploration of dynamic pricing will refer to processed orders as “tickets”, although in the ETA design these are just sitting in the ordered queue waiting to propose. The protocol strives to ensure that there are <span class="math">\hat{T}</span> outstanding tickets at any time. The price of a new ticket should be determined by the current number of outstanding tickets <span class="math">T</span> as well as the current supply of purchases and purchase orders <span class="math">T_p</span>, measured over some window of length <span class="math">W_T</span>, which in some versions can be only one slot long.</p>
<p>Define the ticket saturation as <span class="math">T_s=T-\hat{T}</span>. If <span class="math">T_s&lt;0</span>, there are too few tickets, and the protocol would in general like to sell more than one ticket per slot. If <span class="math">T_s&gt;0</span>, there are too many, and it would in general like to sell fewer than one. The delta <span class="math">T_{\delta}=T_p-W_T</span> gives purchase orders relative to an expectation of one ticket per slot, which is the rate at which tickets are consumed by execution proposers. If <span class="math">T_{\delta}&lt;0</span>, the protocol is selling fewer than one ticket per slot and would in general like to sell more. If <span class="math">T_{\delta}&gt;0</span>, it sells more than one and would in general like to sell fewer.</p>
<p>If both <span class="math">T_s</span> and <span class="math">T_{\delta}</span> are negative, the protocol should decrease the ticket price to sell more tickets. If both <span class="math">T_s</span> and <span class="math">T_{\delta}</span> are positive, it should increase the price to sell fewer. The less trivial question is how to approach a situation when one of the variables is negative and the other is positive, how to window sales, and how quickly to adjust the price.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-42-dynamic-pricing-mechanism-11" name="h-42-dynamic-pricing-mechanism-11"></a>4.2 Dynamic pricing mechanism</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-421-overview-12" name="h-421-overview-12"></a>4.2.1 Overview</h4>
<p>The price of tickets adjusts on a relative basis, just like in EIP-1559, gradually shifting by some proportion of the current price each slot. To improve MEV resistance and adapt to the problem at hand, three differences to EIP-1559 however seem useful: (1) the price should depend on orders included in the current slot, not only the preceding; (2) the block should never be “full”, lest the ticket price becomes very high; (3) the mechanism should be “two-dimensional” in the sense that it accounts for both ticket saturation and delta.</p>
<p>This subsection begins by exploring the simplest realization of such a pricing mechanism, which will then gradually be expanded. In the simplest design, <span class="math">W_T=1</span>, and orders can be priced directly when added to the beacon block. If there is one new order (<span class="math">T_{\delta}=0</span>) and the number of outstanding tickets is as desired (<span class="math">T_s=0</span>), the price stays the same. If there are many new orders (a sudden spike in the expected MEV), the pricing mechanism will hike the price substantially. For example, if 100 orders were to come in, the purchase price for them could rise by orders of magnitude; the exact specification would need to be determined based on other auction paramters such as the size of the ticket pool. Builders will of course track incoming orders in real time and update their estimate of the final purchase price. Therefore, even during a sudden rise in expected MEV, there will only be new orders up to the point where the deduced price matches expected MEV.</p>
<p>As another option, <span class="math">W_T</span> can be longer, setting the price <span class="math">W</span> slots after orders have been added to the beacon block. In Figure 1, <span class="math">W=3</span>. An asymmetric window spanning 4 slots up to and including the processing slot is then an option. The most important benefit is MEV resistance during spikes, as will be further discussed in Section 4.3. Other potential benefits include better pricing granularity, a more complete picture when pricing orders, and the marginal simplification in ETA from pricing and sequencing orders at the same. Of course, it can be argued that the picture already is “complete” in the sense that builders can indicate expected MEV already at the current slot, albeit they may not be fully equipped to evaluate incoming orders in real-time. It can also be argued that <span class="math">W&gt;0</span> and <span class="math">W_T&gt;1</span> needlessly increase uncertainty and analytical complexity for builders as well as developers. As an example, builders may place an order several slots before a spike, but still need to pay closer to the real expected value of the MEV they are about to receive (priced closer to proposal time).</p>
<h4><a class="anchor" href="https://ethresear.ch#h-422-equations-13" name="h-422-equations-13"></a>4.2.2 Equations</h4>
<p>A rudimentary example will now be provided. Should this general mechanism be pursued, the exact price controller would have to be determined by reasoning about how quickly the price should adapt to changes in the willingness to buy tickets, sensitivity to ticket saturation, interplay between saturation and delta, sensitivity to MEV induction (see the next subsection), and by running simulations of the purchase process.</p>
<p>Ticket saturation and delta from the previous subsection is first weighed by window length and desired number of outstanding tickets</p>
<div class="math">
w_s=\frac{T_s}{c_s\hat{T}}, \quad w_{\delta}=\frac{T_{\delta}}{c_{\delta}W_T},
</div>
<p>using the constants <span class="math">c_s=2^3</span> and <span class="math">c_{\delta}=2^6</span>. The percentage change <span class="math">w</span> to the ticket price applied each slot (minting <span class="math">n</span> orders) is</p>
<div class="math">
w=(1+w_s)(1+w_{\delta})^k.
</div>
<p>This post uses <span class="math">k=2</span>, ensuring a non-linear price response as <span class="math">T_{\delta}</span> grows. This can be particularly relevant at shorter windows <span class="math">W_T</span>. Setting <span class="math">k=3</span> is also viable. The constant <span class="math">c_{\delta}</span> can then alternatively be increased to offer better pricing granularity at a lower ticket delta, while still offering some guarantees regarding the maximum number of orders that may come in during one slot. The price <span class="math">p</span> updates from its level at the previous slot <span class="math">p_0</span> to its level at the present slot <span class="math">p_1</span> as</p>
<div class="math">
p_1=w \times p_0.
</div>
<h4><a class="anchor" href="https://ethresear.ch#h-423-visualizations-14" name="h-423-visualizations-14"></a>4.2.3 Visualizations</h4>
<p>Figure 2 illustrates what a pricing schedule according to <span class="math">w</span> would look like for the outlined equations, with <span class="math">\hat{T}=4096</span> and <span class="math">W_T=32</span>. The yellow band stipulates no price change (<span class="math">w=1</span>), and passes through the intersection of the black lines, which correspond to a neutral ticket delta (x-axis) and saturation (y-axis). There have been suggestions of much <a href="https://www.youtube.com/watch?v=IrJz4GZW-VM">higher</a> <span class="math">\hat{T}</span>. This issue relates to a wide range of <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">considerations</a> that are not the focus of this post.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/8/383433ceb5b2bfb3db8a88907125d3d913dc871b.png" title="Figure 2"><img alt="Figure 2" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/3/8/383433ceb5b2bfb3db8a88907125d3d913dc871b_2_668x500.png" width="668" /></a></div><p></p>
<p><strong>Figure 2.</strong> Rudimentary example for <span class="math">W_T=32</span> of a percentage change in ticket price  that varies with delta in ticket sales and the overall saturation of tickets in the pool. Black lines indicate a neutral delta (one ticket sold per slot) and saturation (<span class="math">T=\hat{T}</span>).</p>
<p>Figure 3 instead shows a pricing schedule when <span class="math">W_T=1</span> using the same equation and settings as previously. If no orders come in during the measured slot, <span class="math">T_{\delta}=-1</span>. Note that the colormap is log-scaled to capture the large increase in <span class="math">w</span> that is instituted if 64 orders were to come in during a single slot. When <span class="math">T_W=32</span> (Figure 2), a large jump in orders would affect the price for 32 consecutive slots (assuming an asymmetric window), before the purchase takes place, and so <span class="math">w</span> will naturally be lower on a per-slot basis.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4f34c0d1471b29367616a9d71dc0a1fe156cfd73.png" title="Figure 3"><img alt="Figure 3" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4f34c0d1471b29367616a9d71dc0a1fe156cfd73_2_659x500.png" width="659" /></a></div><p></p>
<p><strong>Figure 3.</strong> Rudimentary example for <span class="math">W_T=1</span> of a percentage change in ticket price that varies with delta in ticket sales and the overall saturation of tickets in the pool. Black lines indicate a neutral delta (one ticket sold in the slot) and saturation (<span class="math">T=\hat{T}</span>).</p>
<p>The relative change at <span class="math">W_T=1</span> for different <span class="math">T_{\delta}</span> is shown in Figure 4, at a neutral ticket saturation (<span class="math">T_s=0</span>). The price change instituted with this setting for between 0 to 4 orders is {0.969, 1, 1.031 1.063 1.096}. The same granularity can be preserved at lower quantities of orders while further raising the price at higher quantities, by increasing <span class="math">k</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/1/b1cd5d40cffb62dcaa44cc90cb317c9a4f0ebb76.png" title="Figure 4"><img alt="Figure 4" height="325" src="https://ethresear.ch/uploads/default/optimized/3X/b/1/b1cd5d40cffb62dcaa44cc90cb317c9a4f0ebb76_2_690x325.png" width="690" /></a></div><p></p>
<p><strong>Figure 4.</strong> Rudimentary example for <span class="math">W_T=1</span>, focusing on the relative price change <span class="math">w</span> across <span class="math">T_{\delta}</span> at a neutral saturation. If 60 orders come in during a single slot, the price rises sharply.</p>
<p>Figure 5 instead plots the response at <span class="math">T_{\delta}=-1</span> across <span class="math">T_s</span>. In other words, it shows how the price would change if no purchase orders are registered.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/8/885e3dfacabd2f85c9ee4480a30e67576cb30f5b.png" title="Figure 5"><img alt="Figure 5" height="312" src="https://ethresear.ch/uploads/default/optimized/3X/8/8/885e3dfacabd2f85c9ee4480a30e67576cb30f5b_2_690x312.png" width="690" /></a></div><p></p>
<p><strong>Figure 5.</strong> Rudimentary example for <span class="math">W_T=1</span>, focusing on the relative price change <span class="math">w</span> across <span class="math">T_s</span> when no purchase order comes in.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-43-slot-surge-pricing-15" name="h-43-slot-surge-pricing-15"></a>4.3 Slot surge pricing</h3>
<p>In the outlined pricing mechanism, there is a remaining opportunity for the beacon proposer to derive some MEV at shorter windows <span class="math">T_W</span>. This happens during a sudden spike in interest for purchasing tickets between the point where attesters have observed purchase orders and the slot boundary.</p>
<p>Let <span class="math">n_a</span> be the equilibrium quantity of orders that would have come in during a slot if a spike happened before the attester observation deadline (purple arrows in Figure 1). Builders keep track of incoming orders and calculate the current ticket price, which when compared to the updated expected MEV <span class="math">V_e</span> produces <span class="math">n_a</span> orders. If a spike comes in after the attester deadline, the proposer has exclusivity and could (be paid to) include only a subset of the orders <span class="math">n_p</span>. The surplus MEV for the proposer emerges from providing a lower expected purchase price for each order it lets through. This is a monopoly pricing regime, wherein the proposer sells spots at a price approaching <span class="math">V_e-p_1</span>. It determines <span class="math">n_p</span> to maximize its revenue <span class="math">R(n_p)</span>, in accordance with the revenue function:</p>
<div class="math">
\text{Maximize} \quad R(n) = n (V_e(n) - p_1(n)).
</div>
<p>Here, <span class="math">p_1(n)</span> is based on the price equation provided in the previous subsection. Also note that if many purchase orders come in, <span class="math">V_e</span> might gradually fall (if there is a temporary spike); hence <span class="math">V_e(n)</span>. If the potential price increase between beacon slots is set to be more moderate, while prices still can surge from a high quantity of purchased tickets within a single slot, the proposer’s potential revenue would be reduced. The proposer can then sell fewer spots at a lower price. One way to do this is to set the price in the current slot as previously</p>
<div class="math">
p_1=w \times p_0,
</div>
<p>but to not incorporate the full price change when setting the value <span class="math">p^*_0</span> that will be used as <span class="math">p_0</span> when pricing the next slot</p>
<div class="math">
p^*_0=\left(1+\frac{1-w}{c_w}\right) \times p_0.
</div>
<p>The constant <span class="math">c_w</span> is set above 1, e.g., <span class="math">c_w=2</span>. During a spike in expected value up to a new baseline <span class="math">V_e</span>, the price would then theoretically stay rather fixed (at a new higher level) for subsequent slots, with the number of orders in each slot gradually decreasing, until it proceeds at the regular pace of one purchase order per slot. Yet note that if <span class="math">V_e</span> rises from a temporary opportunity, there will be a bit more MEV for the proposer to extract still, because a lot of the value can depend on getting in early. This also depends on if the mechanism is ET or ETA and the size of the ticket pool. The discussion offers some further thoughts on the proposer’s ability to extract MEV.</p>
<p>As a concluding remark, it should always be remembered that a big ticket pool acts to temper fluctuations in the expected value of tickets. The buyer does not necessarily buy the right to sell tickets within the next couple of epochs, but rather within the next couple of hours, days, weeks or months, depending on the setting for <span class="math">\hat{T}</span>—and it turns out that when measured over longer periods, the level of the MEV has been <a href="https://youtu.be/IrJz4GZW-VM?feature=shared&amp;t=1241">very stable</a> in Ethereum.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-44-the-role-of-a-maximum-price-16" name="h-44-the-role-of-a-maximum-price-16"></a>4.4 The role of a maximum price</h3>
<p>Each buyer assigns a max price to the order. This is the value that needs to be backed by the debit account. If the max price is insufficient at the time of pricing, such that the actual price is higher, the builder does not receive a ticket/slot. Yet builders could make unbacked orders to starve off competitors, which would bring down the purchase price. It seems desirable to not force builders to analyze the balances of every competitor to determine which bids are real and which are “fake”. One simple way to avoid such a situation is to penalize builders for placing orders that turn out to be unbacked at the time of purchase. This can potentially be combined with setting a validity rule requiring some minimum max price, either relative to the prevailing price at bid time, or/and as a fixed overall minimum.</p>
<p>Penalizing builders however exacerbates another potential issue. During an unforeseen spike in expected MEV, there are circumstances where a builder could “liquidate” its competitors’ bids if the current purchase price is close to their stipulated maximum. A builder could enter new bids forcing other builders out, to penalize them and gain cheaper tickets. For this reason, the mechanism could reduce gameability and the risks as well as improve capital efficiency for builders by stipulating an absolute maximum purchase price. A builder that bids the absolute maximum is guaranteed to not get liquidated and will always receive a ticket. This does not mean that the protocol will burn less MEV, merely that in times of extremely high expected MEV, there will temporarily be a higher quantity of bids, wherein each order has a lower chance of actually getting one of the desirable profitable slots.</p>
<p>What should the absolute maximum be set to if this path is pursued? In <a href="https://flashbots-data.s3.us-east-2.amazonaws.com/index.html">data</a> provided by <a href="https://www.flashbots.net/">Flashbots</a> spanning 2.7 million blocks between the last quarter of 2022 and the third quarter of 2023, the maximum average <a href="https://hackmd.io/@flashbots/quantifying-REV">REV</a> across 64 slots is 19.5 ETH. The peak average is skewed by a few spurious blocks with REV of several 100 ETH that may have been hard to predict beforehand. This average does therefore not represent a realistic expected MEV for builders bidding many slots in advance. Expand the window by a factor of 4 to 256 and the maximum average falls almost by a factor of 4, to 5.25. Setting the absolute maximum to 5 ETH would thus presumably not influence the auction even in times of extreme market conditions, since that price would hardly ever be reached.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-5-discussion-17" name="h-5-discussion-17"></a>5. Discussion</h2>
<p>A MEV resistant dynamic pricing auction for selling execution proposal rights has been presented, relevant to the research of both ETs and EAs. It seeks to remove agency from the beacon proposer, thus inducing less MEV. This is achieved by having every order result in a sale, and every order coming in during the same slot having the same expected sales price. The execution ticket auction (ETA) sequences orders directly for proposal by leveraging the RANDAO. Orders that came in during the same slot can otherwise be minted collectively into tickets, with sequencing pursued at a later stage in accordance with the ET proposal.</p>
<p>If pursuing this auction mechanism, the dynamic pricing step would require substantial analysis. One sensitive part is the balance between moderating changes in the supply of orders while still offering sufficient pricing granularity. A high <span class="math">k</span> can be useful here. Another potential avenue is to hold the auction less frequently. The expected timing of orders within the slot would also be interesting to study—orders can be placed early to starve off others, or late to gain better information. One could even theorize that some builders will wait until after the attester deadline, and then pay the proposer a small fee for exclusive post-deadline inclusion (the benefit being to avoid race conditions).</p>
<p>Transactions to fund or withdraw from a builder’s debit account would need to be synchronized with the validity check to avoid race conditions. It may be convenient to expand the role of the debit account if it is desirable to subject builders to slashing or penalties at the execution proposal stage. In other words, the debit account might also function as a stake.</p>
<p>Just as with MEV pricing auctions, attesters accepting or rejecting a block based on some observation deadline is potentially sensitive. However, this particular design should hopefully be less so, since there will only be one order on average per block to observe, and less value (even potentially negative) in bidding later in the block. A potential benefit of an auction administered instead at the execution layer is the “endogenous” component, facilitating a higher burn; the value of a ticket increases if the current ticket holder can extract value from future ticket holders through MEV. However, this direction raises gameability concerns if a single actor can come to monopolize the auction (ILs may here be useful). A MEV resistant mechanism, as here proposed, originating at the consensus layer, therefore seems like a viable direction.</p>
<p>It might seem tempting to replicate some facets of the proposed design for transaction processing: making the protocol more MEV resistant by having attesters observe transactions, the protocol sequence them by RANDAO, and the price adjust in a slot-attentive fashion. However, the requirements for transactions are different than for the purchase orders of execution rights analyzed in this post (e.g., time, quantity). Translating the ideas of this post directly to transaction processing might therefore unfortunately be difficult. Yet the proposed mechanism could perhaps lend some inspiration going forward.</p>
<p>It should be noted that multi-block MEV is a separate topic of concern. The proposed mechanism is resistant to inducing MEV at the purchase stage but does not preclude multi-block MEV. This is a general issue and an underexplored topic at this point in time. Censorship resistance is likewise an important problem not addressed by the auction mechanism. Various strategies, such as ILs (<a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">1</a>, <a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">2</a>, <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">3</a>), have been proposed. Whether the presented auction mechanism can be one part of an overall architecture that also tackles other issues remains to be explored.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/mev-resistant-dynamic-pricing-auction-of-execution-proposal-rights/20024">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 09 Jul 2024 10:52:26 +0000</pubDate>
</item>
<item>
<title>Deep Diving Attestations - A quantitative analysis</title>
<link>https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020</link>
<guid>https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#deep-diving-attestations-1" name="deep-diving-attestations-1"></a>Deep Diving Attestations</h1>
<p><em>I want to provide some quantitative stats on…</em></p>
<ul>
<li><em>Head</em>-, <em>target</em>-, and <em>source</em> votes,</li>
<li>The individual node operators’ attestation performance, including the best and worst validators,</li>
<li>Attestation <em>timing</em> and <em>inclusion delay</em>, and</li>
<li>The impact of <em>MEV-Boost, CL clients, Proposer Timing Games</em> and <em>Big Blocks with Blobs</em> on attestation accuracy.</li>
</ul>
<p><img alt="doge" height="458" src="https://ethresear.ch/uploads/default/original/3X/2/a/2a11d5d44000665f0ed449873280783c5e163cd6.png" width="459" /></p>
<p><em>Many thanks to <a href="https://x.com/casparschwa">Caspar</a>, <a href="https://x.com/dapplion">DappLion</a>, <a href="https://x.com/barnabemonnot">Barnabé</a> and <a href="https://x.com/potuz_eth">Potuz</a> for their feedback and review!</em></p>
<h2><a class="anchor" href="https://ethresear.ch#data-2" name="data-2"></a>Data</h2>
<p>I use data ranging from slot 9,169,184 to slot 9,392,415, amounting to 6,975 epochs, 31 days of data.<br />
The goal is to provide some initial results from analyzing attestations, as a warm-up for analyzing correlated attestation penalties (<a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716</a>).<br />
Some of the data is collected by myself using custom parsing scripts. Other data was provided by <a href="https://ethpandaops.io/">EthPandaOps</a>. This includes timing data collected from running nodes of <strong>every client</strong> in the regions <strong>Sydney</strong>, <strong>Helsinki</strong>, and <strong>San Francisco</strong>, with all nodes being <strong>subscribed to all subnets</strong>. For classifying CL clients, the <a href="https://github.com/sigp/blockprint">blockprint</a> tool was used.</p>
<blockquote>
<p>Importantly, my solo staker categorization is done very conservatively to avoid confusing professional entities with solo stakers. In total, my dataset contains 8,488 validators classified as solo stakers.</p>
</blockquote>
<p>The code for creating the charts is published in <a href="https://github.com/nerolation/eth-deep-diving-attestations">this repo.</a></p>
<h2><a class="anchor" href="https://ethresear.ch#attestations-3" name="attestations-3"></a>Attestations</h2>
<h3><a class="anchor" href="https://ethresear.ch#the-basics-4" name="the-basics-4"></a>The Basics</h3>
<p><a href="https://eth2book.info/capella/part2/consensus/">Attestations</a> are at the core of Ethereum. Through attesting to past checkpoints, Ethereum’s validators agree on a state to become irreversible (<a href="https://eth2book.info/capella/part2/consensus/casper_ffg/">Casper FFG</a>). Furthermore, validators use attestations to agree upon the tip of the chain, deciding which transactions get confirmed and which don’t (<a href="https://eth2book.info/capella/part2/consensus/lmd_ghost/">LMD GHOST</a>).<br />
Every validator, backed by its stake, participates in every epoch and is randomly assigned a slot, during which it is expected to broadcast its view of the chain through attesting.</p>
<p><strong>An attestation contains three things:</strong></p>
<ul>
<li>A <em>source</em> vote: The block (and all predecessors) to be finalized</li>
<li>A <em>target</em> vote: The block (and all predecessors) to be justified (=pre-finalized)</li>
<li>A <em>head</em> vote: The block seen as the head of the chain.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/8/98c353dd9366c270a1d3ef3b75c9efaec79c4fcd.png" title="epochslotvalidator"><img alt="epochslotvalidator" height="182" src="https://ethresear.ch/uploads/default/optimized/3X/9/8/98c353dd9366c270a1d3ef3b75c9efaec79c4fcd_2_690x182.png" width="690" /></a></div><p></p>
<p>Since the <a href="https://ethereum.org/en/history/">Deneb hardfork</a> that included <a href="https://eips.ethereum.org/EIPS/eip-7045">EIP-7045</a>, attestations for a slot in epoch N can be included up until the end of epoch N+1. However, <a href="https://eth2book.info/capella/part2/incentives/rewards/">inclusion doesn’t guarantee a reward</a>:<br />
To be rewarded, a validator must ensure its source vote is included within 5 slots. The target vote has to be included within 32 slots to be rewarded. Head votes must be included in the following slot to be eligible for a reward.</p>
<p>As of today, Ethereum counts <a href="https://beaconcha.in/charts/validators">~1.03</a> million validators. This means we have 1.03 million votes every epoch, ~32,000 every slot. In one day, with 225 epochs, there are approximately 225 million attestations. This data grows quite fast.</p>
<p>If the <strong>source vote</strong> is <strong>invalid</strong>, then the <strong>target</strong> and <strong>head vote</strong> <strong>MUST</strong> be <strong>invalid</strong> too.</p>
<p>A slot can be broken down into 3 phases:<br />
<img alt="slottime" height="92" src="https://ethresear.ch/uploads/default/original/3X/e/2/e2bf8c2e61a6f0079f45f24b5648a1d68f960153.png" width="632" /></p>
<ol>
<li>Validators attest when they have seen a block for the current slot or at second 4 in the slot - the attestation deadline. A block broadcasted at second 0 in the slot has 4 seconds to be seen by all relevant validators and collect votes. Late blocks risk not receiving enough attestations and being reorged by a subsequent block.</li>
<li>Between second 4 and 8 in the slot, attestations are <a href="https://eth2book.info/capella/part2/building_blocks/aggregator/">aggregated</a> and broadcasted by selected validators.</li>
<li>Eventually, the subsequent block proposer includes them into its block.</li>
</ol>
<blockquote>
<p>For more in-depth explanations check out this post by Georgios and Mike on “<a href="https://www.paradigm.xyz/2023/04/mev-boost-ethereum-consensus">Time, slots, and the ordering of events in Ethereum Proof-of-Stake</a>”.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#definitions-5" name="definitions-5"></a>Definitions</h3>
<p><strong>Missed vs. Failed:</strong></p>
<ul>
<li>A validator can either <strong>miss</strong> its attestation (<em>missed</em>) or attest to a <strong>wrong</strong> checkpoint (<em>failed</em>).</li>
<li><strong>Missed attestations</strong> can happen if the node running the validator is out of sync or offline.</li>
<li><strong>Voting for a wrong checkpoint</strong>, e.g. a wrong head, can have various reasons like receiving a block too late, being out of sync or even having a bug, etc.</li>
<li><strong>Regardless of the reason, a <em>failed</em> vote tells us one important fact about a validator—it is online.</strong></li>
</ul>
<p>In the following, we’ll also need the term <em><strong>“high-performing validator”</strong></em> which is a validator that hasn’t failed to cast a correct and timely head vote over the complete time frame analyzed.</p>
<h3><a class="anchor" href="https://ethresear.ch#attestation-inclusion-delay-6" name="attestation-inclusion-delay-6"></a>Attestation Inclusion Delay</h3>
<p>In the best case, attestations are included in the block of the <strong>next slot</strong>, causing a <strong>delay of 0</strong>. Sometimes, especially when the next proposer is offline or gets reorged, attestations are not included in the next slot. Then, the validator misses out on the rewards from the correct head vote, even though the attestation can still be included in a later block.</p>
<p>The following chart shows the distribution of the inclusion delay over seconds 1-63 and the <strong>clients the attesters were using</strong>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/d/fd890aacb6b6636f2240881d9dbbaa7b721face8.png" title="correct_head_delay_clients"><img alt="correct_head_delay_clients" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/f/d/fd890aacb6b6636f2240881d9dbbaa7b721face8_2_690x316.png" width="690" /></a></div><p></p>
<ul>
<li>95.85% of attestations are included in the next slot.</li>
<li>~1.2% of attestations are included in the slot after the next.</li>
<li>When a new epoch begins, old attestations are again picked up and finally included.
<ul>
<li>This is weird (<em>but there’ll be an explanation little down below</em>).</li>
<li>Attestations of validators of all clients are affected.</li>
</ul>
</li>
</ul>
<p><strong>This raises the question, “<em>what are clients doing?</em>”</strong></p>
<p>Examples include slots <strong><a href="https://beaconcha.in/slot/9267438#attestations">9267438</a></strong> with a delay of 35 (5250 validators), <strong><a href="https://beaconcha.in/slot/9267425#attestations">9267425</a></strong> with a delay of 52 (1813 validators), or slot <strong><a href="https://beaconcha.in/slot/9267427#attestations">9267427</a></strong> with a delay of 36 slots (1305 validators).</p>
<p>What if those late attestations were already included earlier and were later just included again (h/t <a href="https://github.com/dapplion">dapplion</a>)? To analyze that, we reproduce the above chart but separate by <em><strong>first inclusion</strong></em> and <em><strong>every following inclusion</strong></em>:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/8/a8cfb4ec1e6b9486dbafddb9587eeb55be1b3d1c.png" title="correct_head_delay_reinclusion"><img alt="correct_head_delay_reinclusion" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/a/8/a8cfb4ec1e6b9486dbafddb9587eeb55be1b3d1c_2_690x316.png" width="690" /></a></div><p></p>
<p>First, it is interesting that almost <strong>half of the attestations included with a delay of 1 slots</strong> (note: best is 0) <strong>have already been included in an earlier slot</strong>. This is possible because proposers are free to pick attestations that have already been included in the past 63 slots and include them again. Additionally, a block can contain the same attestations multiple times, aggregated differently.</p>
<p>We can see that the majority of the attestations included in the second hump with a delay of around 35 slots are <strong>reincluded</strong> attestations.</p>
<p>This raises the question, “<em>why does this occur with a delay of more than 32 slots?</em>”</p>
<p>In <strong>percentage</strong> terms, we can see the <em>first inclusion</em> share reducing over an increasing delay:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/e/5e9f624dcd52ea92cbfedbd5d0da5ebf1f2113e3.png" title="correct_head_delay_reinclusion_per"><img alt="correct_head_delay_reinclusion_per" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/5/e/5e9f624dcd52ea92cbfedbd5d0da5ebf1f2113e3_2_690x316.png" width="690" /></a></div><p></p>
<p>To dig deeper into this reinclusion finding, let’s check the <strong>CL clients that built the blocks</strong> that included attestations with &gt;32 slots delay:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/2/62e38ffb13e5375a76e8d567990bbf2dfcd0c9e6.png" title="correct_head_delay_clients_proposers"><img alt="correct_head_delay_clients_proposers" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/6/2/62e38ffb13e5375a76e8d567990bbf2dfcd0c9e6_2_690x316.png" width="690" /></a></div><p></p>
<p>We can see quite clearly that it’s mainly Prysm proposers who include attestations that have already been included earlier, which is very likely a bug.</p>
<blockquote>
<p>The fact that the plot also shows other clients affected might stem from inaccuracies in classifying clients probabilisticly.</p>
</blockquote>
<p><em>The Prysm team was notified.</em></p>
<p><strong>Edit</strong>: <em>The Prysm team was faster in fixing the bug than I was in finishing this post.</em></p>
<p><strong>Fix</strong>: <a class="inline-onebox" href="https://github.com/prysmaticlabs/prysm/pull/14156#event-13323121631">Increase attestation seen cache exp time to two epochs by terencechain · Pull Request #14156 · prysmaticlabs/prysm · GitHub</a></p>
<h2><a class="anchor" href="https://ethresear.ch#missedfailed-attestations-7" name="missedfailed-attestations-7"></a>Missed/Failed Attestations</h2>
<h3><a class="anchor" href="https://ethresear.ch#missedfailed-head-votes-8" name="missedfailed-head-votes-8"></a>Missed/Failed Head Votes</h3>
<p><strong>Head votes</strong> are the <strong>most difficult</strong> part of an attestation. They need to be cast correctly and timely. Per <a href="https://github.com/ethereum/consensus-specs/blob/1642610bd5994d344fb1b6a9f44ec0e14a527580/specs/phase0/validator.md#attesting">honest validator spec</a>, <strong>validators have 4 seconds</strong> to receive and validate a block for the current slot. If no block is received until second 4, validators attest to the block in the previous slot. <strong>Timeliness in the context of head votes means 1 slot.</strong> Although older head votes can be included, there is no reward for the respective validator.</p>
<blockquote>
<p>The legend is ordered in descending order by the sum of missed votes.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/3/2317707179ceb2e3d59cebbda6ca85119edb590e.png" title="missed_head_votes_over_date"><img alt="missed_head_votes_over_date" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/2/3/2317707179ceb2e3d59cebbda6ca85119edb590e_2_690x380.png" width="690" /></a></div><p></p>
</blockquote>
<p><strong>On average, we observe around ~500 missed or wrong head votes out of ~32k validators per slot and ~16k, out of ~1m, per epoch. This represents around 1.56%.</strong></p>
<blockquote>
<p>The entity labeled as <em>unidentified</em> may consist of multiple independent parties, including solo stakers and entities that haven’t been identified yet, and it has a total market share of 20% of all validators.</p>
</blockquote>
<p>Assuming every node operator performs equally, the market share of each entity should reflect its share of missed head votes. However, this is not the case and we see certain node operators being superior compared to others.</p>
<p><strong>The following chart visualizes the delta in the expected number of missed head votes based on market share and the actual number of missed attestations.</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/7/971dec860541e8e89421505e5ebabcbe71d6154a.png" title="delta_missed_head_votes"><img alt="delta_missed_head_votes" height="335" src="https://ethresear.ch/uploads/default/optimized/3X/9/7/971dec860541e8e89421505e5ebabcbe71d6154a_2_690x335.png" width="690" /></a></div><p></p>
<p>While entities such as <em>Kiln</em>, <em>Ether_fi</em>, <em>Lido</em>, <em>Renzo</em>, <em>Figment</em>, and <em>Stakefish</em> perform better than the average, we observe that Rocketpool validators, Kraken validators, and solo stakers miss up to 3% more head votes than their market share.</p>
<p><strong>Focusing on the slot indices in epochs, we distinguish between missing a head vote due to being offline and voting for the wrong head.</strong></p>
<p>The following chart shows the average number of missed/wrong head votes over the slots of an epoch:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/9/f975b9422a722e62e609aa65aaa40ecc1f722ac7.png" title="failed_missed_head_votes"><img alt="failed_missed_head_votes" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/f/9/f975b9422a722e62e609aa65aaa40ecc1f722ac7_2_690x316.png" width="690" /></a></div><p></p>
<p>From the above chart, we can infer:</p>
<ul>
<li>There is a fairly <strong>constant number of <em>missed</em> head votes</strong>.
<ul>
<li><strong>This is expected</strong> as <em>lost-key validators</em> contribute a constant portion to that category.</li>
</ul>
</li>
<li>The beginning of an epoch, particularly the first slot, has significantly more wrong head votes than the rest.
<ul>
<li><strong>This is expected</strong> because the proposer in the first slot has to carry out the <strong>epoch transition</strong>. It must then broadcast that block to reach all attesters. T</li>
</ul>
</li>
<li>The average amount of missed/wrong head votes is <strong>3 times larger</strong> in the first slot of an epoch than in the epochs 2-32.</li>
</ul>
<p>Focusing on missed head votes and CL clients, we cannot see anything suspicious in the following chart:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/7/f7cbecfb8118dcd5ca0e37e04df641e8c1c994e4.png" title="failed_missed_head_votes_over_clclient"><img alt="failed_missed_head_votes_over_clclient" height="287" src="https://ethresear.ch/uploads/default/optimized/3X/f/7/f7cbecfb8118dcd5ca0e37e04df641e8c1c994e4_2_690x287.png" width="690" /></a></div><p></p>
<p>In general, it looks like all CL clients are affected by early-in-epoch misses the same:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/5/75c8e90cf46709ceb37998916b3ea77c7b9dfe88.png" title="failed_missed_head_votes_over_clclient_over_slot"><img alt="failed_missed_head_votes_over_clclient_over_slot" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/5/75c8e90cf46709ceb37998916b3ea77c7b9dfe88_2_690x316.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#missedfailed-target-votes-9" name="missedfailed-target-votes-9"></a>Missed/Failed Target Votes</h3>
<p>Target votes are already easier to get right. The only exception is the first slot of an epoch that follows the <strong>epoch boundary</strong>: In such cases, the head vote equals the target vote and validators having their target vote wrong tend to vote for the parent block (=the block in the last slot of the previous epoch) instead.</p>
<p>On average, we observe around 150 missed target votes per slot and 4,800 per epoch. This represents around <strong>0.48%</strong> of all validators.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/7/570b69e8ccefa7585e259961fa4afa09206a1663.png" title="missed_target_votes_over_date"><img alt="missed_target_votes_over_date" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/5/7/570b69e8ccefa7585e259961fa4afa09206a1663_2_690x380.png" width="690" /></a></div><p></p>
<p>Visualizing the same over the different CL clients, we see all clients affected to extents close to their market share.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/8/b8284e30b6f3f61ed8a95d5989a6417c275f82bc.png" title="failed_missed_target_votes_over_clclient"><img alt="failed_missed_target_votes_over_clclient" height="287" src="https://ethresear.ch/uploads/default/optimized/3X/b/8/b8284e30b6f3f61ed8a95d5989a6417c275f82bc_2_690x287.png" width="690" /></a></div><p></p>
<p>Looking at the entities that perform better than others, we again see operators such as Lido, Renzo, Mantle, Coinbase, etc. outperforming the average.</p>
<blockquote>
<p>Notably, Lido isn’t a single NO but consists of multiple operators that I combined for simplicity.</p>
</blockquote>
<p>On the other hand, Rocketpool validators and solo stakers perform worse and miss up to 3% more target votes than expected.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/7/17818eccecb8186179f09dbfb5b0fc3de023f5dc.png" title="delta_missed_target_votes"><img alt="delta_missed_target_votes" height="335" src="https://ethresear.ch/uploads/default/optimized/3X/1/7/17818eccecb8186179f09dbfb5b0fc3de023f5dc_2_690x335.png" width="690" /></a></div><p></p>
<p>As seen in <a href="https://ethresear.ch/t/the-second-slot-itch-statistical-analysis-of-reorgs/16333">previous analysis</a> on reorgs, epoch boundaries can cause troubles for certain validators when it comes to proposing a block.<br />
<strong>Blocks are more frequently reorged if they are proposed in the first or second slot of an epoch.</strong> Thus, we would expect those blocks to be responsible for the largest split-views among validators, causing some to attest to the current block, and others to the parent block.</p>
<p>Even though expected, we can see that the slot index in an epoch has a major impact on failed target votes:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/0/20b331e0885aaa2efed7972a75ecbe489ab8dd26.png" title="failed_missed_target_votes"><img alt="failed_missed_target_votes" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/0/20b331e0885aaa2efed7972a75ecbe489ab8dd26_2_690x316.png" width="690" /></a></div><p></p>
<p><strong>Target votes are the hardest to get right at the beginning of an epoch.</strong> This is visible in the above diagram showing the <strong>first slot of an epoch with 18x more wrong target votes</strong> than other slots. The thing is, timely and correct target votes bring twice as many rewards than head or source votes.</p>
<p>Although looking problematic, I’d argue this isn’t a big issue. A target vote at the beginning of an epoch is essentially just a head vote, and the relative share of failures in the first slot at 6.4% is still relatively low. Furthermore, it is a known fact that epoch boundaries come with many different cascading effects including missed slots, which also contributes to the above finding.</p>
<blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/c/2c3c18e5acdc7080ad46101a7f05e775a50edb35.png" title="failed_missed_target_votes_over_clclient_over_slot"><img alt="failed_missed_target_votes_over_clclient_over_slot" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/c/2c3c18e5acdc7080ad46101a7f05e775a50edb35_2_690x316.png" width="690" /></a></div><br />
This phenomenon seems to be agnostic to CL clients.<p></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#missedfailed-source-votes-10" name="missedfailed-source-votes-10"></a>Missed/Failed Source Votes</h3>
<p>Source votes are easy to get correct and even validators that are slightly out of sync have a good chance to vote for the right source checkpoint. This is because the to-be-voted-for checkpoint is at least 6.4 minutes (<em>=1 epoch</em>) in the past. Wrong source votes indicate that the validator is either out of sync or on a completely different chain. Thus, target and head votes must be incorrect if the source vote is wrong.</p>
<blockquote>
<p>For source votes one cannot differentiate between <em>missed</em> and <em>failed</em> because wrong source votes never make it onchain and are ignored by proposers/validators.</p>
</blockquote>
<p>On average, we observe around 100 missed source votes per slot, 3,200 per epoch.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/1/61f31f5346adcf9f2b85495f01d371c64e2bff69.png" title="missed_source_votes_over_date"><img alt="missed_source_votes_over_date" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/6/1/61f31f5346adcf9f2b85495f01d371c64e2bff69_2_690x380.png" width="690" /></a></div><p></p>
<p>Similar to head and target votes, we observe an increased number of missed source votes at the beginning of an epoch. This MIGHT be related to the increased reorg probability at the beginning of an epoch but more analysis would be needed to confirm that.<br />
In general, validators usually have ample time (at least 32 slots) to cast their source vote. However, if their head vote is incorrect, it might result in the entire attestation being ignored by an aggregator and, consequently, not being recorded onchain.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/f/1f1e51c85696870bc5d10d561a9814172f0ef750.png" title="missed_source_votes_over_slot"><img alt="missed_source_votes_over_slot" height="380" src="https://ethresear.ch/uploads/default/optimized/3X/1/f/1f1e51c85696870bc5d10d561a9814172f0ef750_2_690x380.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#best-and-worst-validators-11" name="best-and-worst-validators-11"></a>Best and Worst Validators</h2>
<p>Validators cast a vote in every epoch and quickly checking <a href="https://beaconcha.in/">beaconcha.in</a>, more than 99.9% of validators are active in every epoch.</p>
<p>By summing up correct head votes, we can determine the best and worst-performing validators.</p>
<p><strong>The following chart visualizes the average missed/failed head votes per slot over the validator IDs:</strong></p>
<blockquote>
<p>Withdrawn validators are excluded.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/4/94c96b54be8347449d0d060223ba0a9333dd3013.png" title="head_votes_over_validator_ids"><img alt="head_votes_over_validator_ids" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/9/4/94c96b54be8347449d0d060223ba0a9333dd3013_2_690x316.png" width="690" /></a></div><p></p>
</blockquote>
<p>We can see that the missed slot rate is slightly <strong>increasing with increasing validator IDs,</strong> with outliers for the validators with IDs 0-30k, 300k-330k, and 780k-790k.<br />
The best validators are the group with IDs from 50k-60k.</p>
<p><strong>Over four weeks, most validators miss around 20-30 head votes:</strong></p>
<p>The following chart has a <strong>logarithmic y-axis</strong> to make sure we can also see the last bar on the very right that consists of validators that have never attested in the 4 weeks analyzed.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/7/2757547120b4ca4f9068e3fe491289fa8dec1f06.png" title="failed_missed_head_per_validator_dist_per"><img alt="failed_missed_head_per_validator_dist_per" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/7/2757547120b4ca4f9068e3fe491289fa8dec1f06_2_690x316.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#the-peak-of-performance-best-validators-12" name="the-peak-of-performance-best-validators-12"></a>The peak of performance (best validators)</h3>
<p>For the following, I use data ranging from epoch 292,655 to epoch 293,105, not the entire time frame analyzed, due to the sheer amount of data involved.</p>
<p><em><strong>High-performers</strong></em> are defined as validators who haven’t missed voting for the correct head during a time frame of 3 days, starting from the last slot analyzed and going backward.</p>
<p>The following table shows the largest node operators (sorted in descending order by market share) and the percentage of high-performing validators within 3 days compared to the total number of validators for each entity:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/7/5713faed8326eeee5afcdddcf300a1bbdd15e691.jpeg" title="performer_table"><img alt="performer_table" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/7/5713faed8326eeee5afcdddcf300a1bbdd15e691_2_422x500.jpeg" width="422" /></a></div><p></p>
<p>^ The entities in <em><strong>green</strong></em> have <em><strong>more</strong></em> high-performing validators than the average.</p>
<p><strong>The shares visualized using a bar chart look like the following:</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/0/50ed0ae6c74385c61c57a0e9c89ac9beef1e5d64.png" title="topperformer_percentage"><img alt="topperformer_percentage" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/5/0/50ed0ae6c74385c61c57a0e9c89ac9beef1e5d64_2_690x316.png" width="690" /></a></div><p></p>
<p>We can see that the average high-performer rate is around 0-5% for the shown entities.<br />
<strong>The outliers are <em>Everstake</em>, <em>Frax Finance</em> and <em>Rockx</em>.</strong></p>
<p><em>So, what are those 3 parties doing differently than others?</em></p>
<p><strong>There are two strategies an entity might apply:</strong></p>
<ol>
<li><em>Attest early</em> to ensure their vote has enough time to travel through the network and reach the next proposer for inclusion.</li>
<li><em>Attest late</em> to ensure they vote for the correct head of the chain. The longer a validator waits, the easier it is to determine the head of the chain as other validators have already voted -&gt; <em>the risk is that the vote might not reach the next proposer in time</em>.</li>
</ol>
<p>The latter strategy may be referred to as <em><strong><a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612#attester-timing-games-9">attester timing games</a></strong></em>.</p>
<p><em>But what is better?</em></p>
<p><img alt="Screenshot from 2024-06-27 20-22-27" height="311" src="https://ethresear.ch/uploads/default/original/3X/a/1/a19d7ddccff2f47d6d73e80b5e2b5f1b96572091.png" width="587" /></p>
<p>I asked my Twitter friends, and the majority voted for ‘seen later,’ indicating validators are playing timing games for increased attestation accuracy.</p>
<p>In truth, both are right.</p>
<p>The following chart shows the distributions of attestation-seen timestamps of high-performing validators vs. the rest (non-high-performing validators):</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/a/8acfc992ada1a3b0a22ce9f1cfb036a7f191ab8e.png" title="high_performer_vs_rest_timing"><img alt="high_performer_vs_rest_timing" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/8/a/8acfc992ada1a3b0a22ce9f1cfb036a7f191ab8e_2_690x304.png" width="690" /></a></div><p></p>
<p>We can see that the largest share of head votes from <strong>high-performers</strong> is seen between <strong>second 2 and 3</strong> in the slot. We observe another spike right <strong>after second 5</strong> in the slot. For all other validators (cf. <em>rest</em>), the majority of head votes arrive between <strong>second 4 and 5</strong>.</p>
<p><strong>This points towards:</strong></p>
<ul>
<li>Most attesters are exceptionally good because they are <strong>faster</strong> than others.</li>
<li>Some attesters are exceptionally good because they might <strong>wait longer</strong> for more accuracy.</li>
</ul>
<p><strong>&gt; Early attestations by high-performing validators are seen some milliseconds earlier than the rest.<br />
&gt; Late attestations by high-performing validators are seen about 0.5 seconds later than the rest.</strong></p>
<p>It is worth noting that every high-performing validator can be part of both groups, e.g., attesting late to ‘weak’ blocks (cf. epoch boundaries) and early for ‘strong’ blocks.<br />
Validators with great network connectivity can afford to wait slightly longer. Furthermore, at any second in the slot, validators with great connectivity have more information available than other validators.</p>
<blockquote>
<p>A simple example is Coinbase: Technically, every Coinbase validator can be made aware of the votes of other Coinbase validators before voting. With a 10% market share, this provides significant additional security when voting on the correct head.</p>
</blockquote>
<p>By examining the head votes received/seen timings among the largest entities, we can clearly observe the differences. The best performers—Everstake, Frax Finance, and Rockx—typically attest between 4 and 6 seconds into the slot. While these entities outperform others, the following chart does not necessarily indicate a specific strategy being applied.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/2/c22c5adbedc46936379f5e7d1a775f4ad183cb0c.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/2/c22c5adbedc46936379f5e7d1a775f4ad183cb0c_2_300x500.jpeg" width="300" /></a></div><p></p>
<blockquote>
<p>And for a deeper dive into this topic check out <a href="https://ethereum.github.io/beaconrunner/notebooks/thunderdome/thunderdome.html">this simulation</a> by Barnabé that goes into the depth of strategic attesting behavior.</p>
</blockquote>
<p><strong>Finally, we get the following timings for the attestations over different CL clients:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/0/e01321bc4823cb594799d2c67012c599e352cfcd.png" title="head_timing_cl_clients"><img alt="head_timing_cl_clients" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/e/0/e01321bc4823cb594799d2c67012c599e352cfcd_2_690x345.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#we-like-them-for-what-they-are-worst-validators-13" name="we-like-them-for-what-they-are-worst-validators-13"></a>We like them for what they are… (worst validators)</h3>
<p>Other validators are <em>less performant</em> than others. This becomes obvious by looking at the number of missed attestations over time.</p>
<p>First, let’s consider the validators who are offline. There are various reasons for validators to go offline, and occasionally, random validators might experience brief outages. However, there is a small subset of validators that are very likely to remain permanently offline.</p>
<p><img alt="lost_keys" height="193" src="https://ethresear.ch/uploads/default/original/3X/5/7/57134b955a3de1691a15cf2678146f66c1e04126.png" width="456" /></p>
<p>We observed 139 validators, representing 0.014% of all validators, who were permanently offline in the 4 weeks analyzed.<br />
Now, one can argue that being offline for over 4 weeks doesn’t mean the validator is permanently offline. While this is fair, validators who have never cast any vote provide a good upper-bound estimate for the number of permanently offline validators who might have lost their keys.</p>
<p>Within those offline validators, we identify 12 solo stakers, 37 rocketpool validators, and 90 belonging to the category unidentified (=<em>20% market share, including many many actual solo stakers</em>).</p>
<p><strong>Most offline validators have low validator IDs:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/d/2d0d6b73c9b05e0a3a4bc6ee7b5d020b4c98f24b.png" title="head_votes_over_offline_validator_ids"><img alt="head_votes_over_offline_validator_ids" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/2/d/2d0d6b73c9b05e0a3a4bc6ee7b5d020b4c98f24b_2_690x316.png" width="690" /></a></div><p></p>
<p>We can see spikes around 730k and 870k, but the <strong>largest portion comes from OG validators</strong> with low IDs, those activated before the Merge. This is both expected and unexpected:</p>
<ul>
<li>OG stakers are generally crypto-native individuals who can securely manage private keys.</li>
<li>OG stakers are generally solo stakers who are less sophisticated.</li>
</ul>
<p>Based on the above, it seems the latter is more likely to hold true.</p>
<p><img alt="ogvalidator" height="411" src="https://ethresear.ch/uploads/default/original/3X/e/7/e70bfc6416b8a68b815f9835f7fe8e5076a340d5.png" width="457" /></p>
<br />
<p>Moving the focus to the bad validators that miss more than the mean but not all slots in the analyzed time frame, the bar chart looks like the following:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e535223a575fe5764af70e6d31676c70b7c09e3c.png" title="head_votes_over_bad_validator_ids"><img alt="head_votes_over_bad_validator_ids" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e535223a575fe5764af70e6d31676c70b7c09e3c_2_690x316.png" width="690" /></a></div><p></p>
<p><strong>If low-id validators aren’t offline they perform quite well.</strong> Looking at the above graph, the largest share of “bad” validators can be found at the IDs 900k-1m.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestations-big-blocks-and-blobs-14" name="attestations-big-blocks-and-blobs-14"></a>Attestations, Big Blocks, and Blobs</h2>
<p><strong>Big blocks and blocks with many blocks are expected to receive fewer attestations.</strong> This is because certain validators might struggle to download and validate the block fast enough and therefore vote for another block.</p>
<p>With <a href="https://www.eip4844.com/">EIP-4844</a> going live, the <a href="https://ethresear.ch/t/on-block-sizes-gas-limits-and-scalability/18444">block size</a> consists of 3 parts:</p>
<ul>
<li>EL Payload (~85 KB)</li>
<li>Beacon Block (excl. EL payload) / CL Part (~5 KB)</li>
<li>Blobs (~384 KB)</li>
</ul>
<p>Previous analysis showed that the average beacon block size excl. blobs is around 90 KiB. One blob has a size of 128 KiB. As a result, on average, we get blocks (incl. blobs) of size <code>nr_blobs * 128 + 90</code>, with the blob being the main contributor to the size of a block.</p>
<p><strong>More blobs mean more data that needs to be transmitted across the globe. Thus, we can expect more failed head votes for blocks with 6 blobs than those with one blob.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/6/76d5ade603b46d1fe148a918bda24f4fe3866fd6.png" title="failed_missed_head_size_boxplot"><img alt="failed_missed_head_size_boxplot" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/6/76d5ade603b46d1fe148a918bda24f4fe3866fd6_2_690x316.png" width="690" /></a></div><p></p>
<p>This expectation holds when looking at the above boxplot diagram:<br />
 → <strong>The median missed head votes doubles going from 0 to 6 blobs.</strong></p>
<p><em><strong>Let’s get more granular…</strong></em></p>
<p>The following visualizes the block size incl. blobs in MiB over the failed head votes per slot.</p>
<blockquote>
<p>This chart shows only wrong/failed head votes and excludes offline validators.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4ffabf4ebdf70341da81e69e95094040f0f6591e.png" title="failed_missed_head_size_scatter"><img alt="failed_missed_head_size_scatter" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4ffabf4ebdf70341da81e69e95094040f0f6591e_2_690x316.png" width="690" /></a></div><p></p>
</blockquote>
<p><strong>For the sizes above 0.8 MiB, which are most likely blocks with 6 blobs, we can see more weak blocks than for 0 blob blocks. “Weak” because up to 32k attesters of that slot, up to 99%, voted for a different block.</strong><br />
The only way that block still made it into the canonical chain is the next validator building on top of it instead of reorging that block out.</p>
<p>In the analyzed month, we observe 401 blocks with &gt;31k attesters voting for different blocks that still made it into the canonical chain. 233 of them carried 6 blobs. Assuming most validators attest at the latest at second 4 of a slot, those blocks must have been propagated very late such that validators already attested to a different block before seeing it.<br />
This can be confirmed by plotting the “first seen” time of those weak blocks over the seconds in a slot, comparing it to all other blocks:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/3/b3e8a77964031d2b79681810e8f527c7c95a1699.png" title="hist_late_performer"><img alt="hist_late_performer" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/b/3/b3e8a77964031d2b79681810e8f527c7c95a1699_2_690x304.png" width="690" /></a></div><p></p>
<p>The chart shows that most blocks are seen between second 1 and 2 in the slot. For those weak blocks, it’s between second 4 and 5, right after the attestation deadline.</p>
<p>We can confirm this by looking at the attestation timing over the seconds in a slot. We can see that 80% of the attestations are seen 5 seconds into the slot. A block propagated at second 4 in the slot will likely miss out on at least ~40% of all possible attestations, no matter how fast it propagates through the network.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/2/42fe46361f7b2a22bd61c0195f719a57df04d64d.png" title="attestations_cdf"><img alt="attestations_cdf" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/4/2/42fe46361f7b2a22bd61c0195f719a57df04d64d_2_690x304.png" width="690" /></a></div><p></p>
<p><em><strong>Are blobs the problem?</strong></em></p>
<p>The following chart shows the first seen time of 1-blob blocks vs 6-blob blocks:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/d/9d9090203cef36a8e47a8b59e7a8e3b54be815ae.png" title="hist_late_performer_blobs"><img alt="hist_late_performer_blobs" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/9/d/9d9090203cef36a8e47a8b59e7a8e3b54be815ae_2_690x304.png" width="690" /></a></div><p></p>
<p>We can see that despite 6-blobs blocks being seen later in the slot, the delta is rather small, not to say negligible. At the time of the block arriving, the blobs should have already been seen.</p>
<p>In the past, the fact that a user was (not) using <strong><a href="https://github.com/flashbots/mev-boost">MEV-Boost</a></strong> impacted different performance metrics. Thus, let’s plot MEV-Boost users vs. local builders for completeness:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/9/c9c92b7f095017be8e86eac8b4a486a6c1dfdaec.png" title="hist_late_performer_mevboost"><img alt="hist_late_performer_mevboost" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/c/9/c9c92b7f095017be8e86eac8b4a486a6c1dfdaec_2_690x304.png" width="690" /></a></div><p></p>
<p>Finally, comparing three of the largest relays, we get the following image:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/6/56eedd8200ca5e5c778261aee74f9405630c1677.png" title="hist_mevboost_relays"><img alt="hist_mevboost_relays" height="304" src="https://ethresear.ch/uploads/default/optimized/3X/5/6/56eedd8200ca5e5c778261aee74f9405630c1677_2_690x304.png" width="690" /></a></div><p></p>
<p>While most relays such as Ultra Sound, BloXroute, Agnostic Gnosis, or Flashbots show a very similar curve, we can see the Titan relay having two peaks instead of just one.<br />
This means that some blocks going through the Titan relay are first seen in the p2p network between 2.5-3 seconds into the slot, which is very late.</p>
<p>Notable, those late blocks of Titan still became canonical, pointing towards proposer timing games.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestations-and-proposer-timing-games-15" name="attestations-and-proposer-timing-games-15"></a>Attestations and Proposer Timing Games</h2>
<p>Next, let’s look at the impact of Proposer Timing Games on attestations.<br />
We refer to Proposer Timing Games (see <a href="https://eprint.iacr.org/2023/760">[1]</a>, <a href="https://arxiv.org/abs/2305.09032">[2]</a>) if block proposers delay their block proposal to give the builders more time for MEV extraction.<br />
Instead of asking the relay for a block in second 0 in the block, a proposer can delay this, e.g. until second 2 in the slot, and maximize profits. This comes with the risk of not getting enough attestations and being reorged out.</p>
<p><em>Find some real-time visuals on timing games at <a href="https://timing.pics/">timing.pics</a>.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/5/c563eb0043362562f84cb3fb2f823a14c92dce14.png" title="timing_games2"><img alt="timing_games2" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/c/5/c563eb0043362562f84cb3fb2f823a14c92dce14_2_373x499.png" width="373" /></a></div><p></p>
<p><strong>Proposer timing games are expected to negatively impact validators’ attestation performance</strong>, although this hasn’t been thoroughly analyzed yet. The concern is that <strong>proposer timing games could have cascading effects</strong>: attesters might slightly <strong>delay their attestations</strong> to ensure they vote for the correct head of the chain. Knowing proposers are playing timing games, it might be rational to delay the attestation too. <strong>Such strategies can be harmful to the network’s overall health.</strong></p>
<blockquote>
<p>For more info on the impact of proposer timing games on attestations, check out <a href="https://ethresear.ch/t/timing-games-implications-and-possible-mitigations/17612">Caspar’s post</a> on it.</p>
</blockquote>
<p>The following graph shows the average number of missed head votes over the seconds in a slot. The <a href="https://github.com/flashbots/relay-specs">relays’ Data API</a> (<em>bidsReceived</em> endpoint) was used for the in-slot timestamps.</p>
<blockquote>
<p>Multiple prior analyses showed that using the bidsReceived timestamps provides a <em>good enough</em> approximation of actual propagation timings. Notably, bidReceived <strong>must come earlier</strong> than the block’s propagation timing.</p>
</blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/6/763882ecc1e817832856f802783d3aa9643ce8ca.png" title="failed_missed_head_votes_over_timing"><img alt="failed_missed_head_votes_over_timing" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/7/6/763882ecc1e817832856f802783d3aa9643ce8ca_2_690x316.png" width="690" /></a></div><p></p>
<p>The above chart shows that the number of missed head votes increases rapidly with being 1 - 1.2 seconds into the slot. The longer a proposer waits the fewer attestations its block is expected to receive.</p>
<p><strong>We can see that the number of missed head votes per slot increases to an average of &gt;4k (12.5% of the committee) for late blocks published more than 1.7 seconds into the slot.</strong><br />
This sounds bad although the numbers are still relatively low compared to the 32k validators that attest in each slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/4/540d12e9110a2a48ced72b152688d78d5ab1cc8a.png" title="failed_missed_head_votes_over_timing_per"><img alt="failed_missed_head_votes_over_timing_per" height="316" src="https://ethresear.ch/uploads/default/optimized/3X/5/4/540d12e9110a2a48ced72b152688d78d5ab1cc8a_2_690x316.png" width="690" /></a></div><p></p>
<p>Proposing a block with a <em>bid received</em> timestamp of over 2 seconds causes an average of 5k attestations to be missed. This represents about 15% of the committee.</p>
<h2><a class="anchor" href="https://ethresear.ch#next-steps-16" name="next-steps-16"></a>Next Steps</h2>
<p>In this final section I want to quickly present the idea behing anti-correlation penalties and <a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716</a> in specific.</p>
<p>Operating multiple validators comes with <strong>economies of scale</strong>. Theoretically, one can run thousands of validators from a single node, and validators running on the same node have the same view of the chain and cast the same votes.</p>
<p><img alt="same_node_validators" height="257" src="https://ethresear.ch/uploads/default/original/3X/0/2/02262692e73fd82f5ee6f0ff9a62fc4619db6746.png" width="455" /></p>
<p>Having <strong>multiple validators</strong> on <strong>one node</strong> isn’t the only reason for <strong>correlated failures</strong>: Using the same cloud/ISP provider, the same hardware, running nodes from the same geo-location or having the node be maintained by the same group of individuals; everything that leverages economies of scale increases the correlation among validators. Beautiful.</p>
<p>We should therefore use that knowledge to design economic incentives in a way that makes it harder/less profitable to leverage economies of scale.<br />
Without requiring the protocol to know about the node operators behind validators, correlations present a great way to distinguish small solo stakers from professional operators.<br />
One concrete proposal for improved diversification within the validator set is <a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716 - Anti-Correlation Attestation Penalties</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#eip-7716-anti-correlation-attestation-penalties-17" name="eip-7716-anti-correlation-attestation-penalties-17"></a>EIP-7716 - Anti-Correlation Attestation Penalties</h3>
<p><img alt="7716_correlation" height="317" src="https://ethresear.ch/uploads/default/original/3X/0/5/05134246699e0567331369387e90bc395b260135.png" width="459" /></p>
<p><a href="https://eips.ethereum.org/EIPS/eip-7716">EIP-7716</a> was first described by Vitalik in an <a href="https://ethresear.ch/t/a-concrete-proposal-for-correlated-attester-penalties/19341">ethresearch post</a>. After some initial analysis and a more concrete proposal available the EIP is now at the point where everyone is invited to look into the inner workings of correlated penalties and leave feedback.</p>
<p>In short, the EIP proposes the following:<br />
Multiply the missed source and missed target votes by a penalty factor that ranges from 0 to 4 but remains at 1 on average.</p>
<ul>
<li>If the balance of non-attesting validators increases, the penalty factor does so too.</li>
<li>If the balance of non-attesting validators remains the same, the penalty factor approaches 1.</li>
<li>If the balance of non-attesting validators decreases, the penalty factor can go below 1 for some time and approaches 1 afterward.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#how-does-7716-work-18" name="how-does-7716-work-18"></a>How does 7716 work?</h4>
<div class="md-table">
<table>
<thead>
<tr>
<th>Abbreviation</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">p</span></td>
<td>Penalty factor</td>
</tr>
<tr>
<td><span class="math">p_{exc}</span></td>
<td>Net excess penalties</td>
</tr>
<tr>
<td><span class="math">balance_{NA}</span></td>
<td>Non attesting balance</td>
</tr>
<tr>
<td><span class="math">p_{adj}</span></td>
<td>Penalty adjustment factor</td>
</tr>
<tr>
<td><span class="math">balance_{TOTAL}</span></td>
<td>Total active balance</td>
</tr>
<tr>
<td><span class="math">p_{max}</span></td>
<td>Maximum penalty factor</td>
</tr>
</tbody>
</table>
</div><p>The penalty factor scales the slot penalties to a maximum of <span class="math">p_{max}</span>, or down. It’s determined the following:</p>
<p><span class="math">p = \min\left(\frac{balance_{NA} \times p_{adj}}{p_{exc} \times balance_{TOTAL} + 1}, p_{max} \right)</span></p>
<p>The <span class="math">nep</span> is updated at the end of each slot using:</p>
<p><span class="math">p_{exc} = \max(1, p_{exc} + p) - 1</span></p>
<p><strong>The formula calculates the penalty factor as a ratio of the “penalty weight” of non-attesting validators to the total scaled balance of all validators. A higher non-attesting balance or penalty adjustment factor increases the penalty factor. Conversely, a higher net excess penalty or total active balance reduces the penalty factor.</strong></p>
<p>When  <span class="math">balance_{NA}</span> continuously increases for several rounds, also the penalty factor, as well as the net excess penalty increases. This continues until  <span class="math">balance_{N}</span> stops decreasing. Then, the net excess penalty starts decreasing together with the penalty factor.</p>
<p>With the net excess penalties, <span class="math">p_{exc}</span>, keeping track of the excess penalties of past epochs, the formula can self-regulate what is a “large” number of misses, and what is not.</p>
<p>This mechanism ensures that the sum of penalties doesn’t change with this EIP - only the distribution does.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/deep-diving-attestations-a-quantitative-analysis/20020">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 09 Jul 2024 08:02:31 +0000</pubDate>
</item>
<item>
<title>Mantis: Driving Ethereum’s Cross-Domain Future</title>
<link>https://ethresear.ch/t/mantis-driving-ethereum-s-cross-domain-future/20009</link>
<guid>https://ethresear.ch/t/mantis-driving-ethereum-s-cross-domain-future/20009</guid>
<content:encoded><![CDATA[
<div> 关键词：Mantis、Inter-Blockchain Communication (IBC)、Ethereum、Trust-minimized Bridging、Multi-chain Agnostic Trust-minimized Intent Settlement

总结:
Mantis是一个新兴的协议，旨在优化跨链操作并解决DeFi空间中的挑战。它通过与IBC（Inter-Blockchain Communication）协议和Picasso Network的整合，实现了信任最小化的跨链连接，首次将这种技术扩展到以太坊之外的IBC兼容链，如Cosmos Hub、Polkadot和Solana等。Mantis的架构包括竞赛式的解决方案、拍卖机制和与Ethereum的集成，提供了链间资产交换、意图执行和结算的一站式服务。通过Mantis，Ethereum得以加强其在去中心化金融中的核心地位，并促进新用户和流动性流入。此外，Mantis简化了跨链交易体验，为去中心化应用程序开发者提供工具。未来，Mantis计划进一步开发拍卖系统和可信承诺机制，以提升整体系统的福利。 <div>
<p>Author: <a href="https://x.com/0xbrainjar" rel="noopener nofollow ugc">0xbrainjar</a></p>
<p>Reviewers: <a href="https://x.com/ComposableSyd" rel="noopener nofollow ugc">Sydney Sweck</a> &amp; <a href="https://x.com/0xBrMazoRoig" rel="noopener nofollow ugc">Bruno Mazorra</a></p>
<h1><a class="anchor" href="https://ethresear.ch#summary-1" name="summary-1"></a>Summary</h1>
<p>Recently, Composable <a href="https://twitter.com/Picasso_Network/status/1775512007963500772" rel="noopener nofollow ugc">launched its IBC Ethereum mainnet connection</a>. The <a href="https://www.ibcprotocol.dev/" rel="noopener nofollow ugc">IBC Protocol</a> is emerging as the gold standard for cross-chain communication, as we have previously explored in our comparison analysis <a href="https://medium.com/@Picasso_Network/ibc-as-the-end-game-of-bridging-a-comparison-analysis-on-trust-dcc01e0d9377" rel="noopener nofollow ugc">here</a>. IBC’s trust levels parallel that of ZK bridging, which is limited to the Ethereum ecosystem and its layer 2s. Originally, the IBC Protocol was also limited to one ecosystem: the Interchain, which includes Cosmos SDK chains and the Cosmos Hub. However, IBC has now been expanded outside of the Interchain/Cosmos ecosystem for the first time by Composable’s Picasso Network.</p>
<p>IBC Ethereum a significant milestone, marking the first time that trust-minimized bridging is available between Ethereum and other IBC-enabled chains including the Cosmos hub, Cosmos SDK chains, Polkadot and Kusama parachains, Solana, and more ecosystems soon. Moreover, this was a huge technological feat, given that this connection required architecting a light client on Ethereum. While various projects were exploring the concept of Ethereum light clients at the time, there were no light clients fully available on Ethereum when we began development.</p>
<p>Now, Composable is in the process of launching a product that aims to bring more utility to cross-domain Ethereum operations: Multi-chain Agnostic Trust-minimized Intent Settlement, or Mantis. This framework serves as a vertically integrated intent pipeline, complete with expression, execution, and settlement. Ultimately, Mantis strives to establish a decentralized market for cross-domain intent expression through a permissionless solver network and intent-settlement framework. Through Ethereum IBC and now Mantis, Ethereum will be optimally positioned to continue in its role as the leading hub of DeFi; new cross-chain use cases to and from Ethereum will be generated, enabling the flow of new liquidity and users to Ethereum, with all of the complexities abstracted away to improve the user experience.</p>
<p>The present article thus summarizes Mantis from our recently-published Mantis Whitepaper and Litepaper. Moreover, this post details how Mantis can benefit Ethereum and other IBC-enabled ecosystems.</p>
<h1><a class="anchor" href="https://ethresear.ch#about-mantis-2" name="about-mantis-2"></a>About Mantis</h1>
<h2><a class="anchor" href="https://ethresear.ch#the-industry-need-3" name="the-industry-need-3"></a>The Industry Need</h2>
<p>Mantis is a relevant protocol within the present DeFi space for a number of reasons, as it aims to fulfill a number of challenges currently facing the space:</p>
<ul>
<li><strong>Optimizing UX and Execution:</strong> There has always been a need in the space to optimize both user experience (UX) and execution. If this is accomplished, capital efficiency and value accrual can be maximized for all participants.</li>
<li><strong>Combatting Centralization Trends:</strong> In the multi-chain bridging space, there has been an increased reliance upon centralized structures. Unfortunately, there has been a lack of decentralized solutions that rival the speed and cost of centralized structures.</li>
<li><strong>Facilitating Trust-Minimized Interoperability:</strong> Many bridging structures in place today require putting trust in third-party intermediaries, making them vulnerable to attack. However, new technologies are being introduced with the launch of trust-minimized bridging structures like the <a href="https://www.ibcprotocol.dev/" rel="noopener nofollow ugc">IBC Protocol</a>, which powers the <a href="http://picasso.xyz" rel="noopener nofollow ugc">Picasso Network</a>. These developments enable generalized message passing and synchronization of protocols and applications across multiple blockchain ecosystems.</li>
<li><strong>Delivering Intent-Centricity:</strong> Intents are another new area of development in the DeFi space that are positioned to further assist in resolving user experience and execution issues. However, many intents solutions are not cross-chain interoperable, and are not vertically integrated with execution and settlement solutions, rendering them unable to accrue value from pay for orderflow.</li>
</ul>
<p>With Mantis, Composable addresses these present unmet needs in the DeFi space. Overall, our thesis is that cross-domain interoperability widens the intent solution space. We hypothesize that this increased choice in solutions results in value in the form of better user outcomes.</p>
<h2><a class="anchor" href="https://ethresear.ch#architecture-4" name="architecture-4"></a>Architecture</h2>
<p>Mantis accomplishes its functionalities via the Mantis protocol and rollup, a cross-domain auction mechanism, as well as their synergies with the Inter-Blockchain Communication (IBC) Protocol and the Picasso Network. Moreover, a commitment mechanism between chains allows conditions in the other parts of the architecture to be carried out cross-domain.</p>
<h3><a class="anchor" href="https://ethresear.ch#the-mantis-protocol-rollup-5" name="the-mantis-protocol-rollup-5"></a>The Mantis Protocol &amp; Rollup</h3>
<p>The Mantis protocol facilitates optimal execution of cross-domain intents via a competition of solvers. Users sign intents, which are contained on a private rollup mempool. Solvers are staked agents that can a) observe the transactions on the mempool and b) post solutions in the auctioneer contract. The auctioneer contract scores the solutions in terms of users utility maximization. The winner of the auction is responsible for settling the outcome of the intent to the solution settlement contracts in the final chain expressed by the intent.</p>
<p>The Mantis protocol lives on the Mantis Solana Virtual Machine (SVM) rollup. This rollup serves as a coordination and settlement layer for cross-domain intents, in addition providing a framework for cross-domain block proposals and credible commitments. The rollup further allows for assets to be staked and restaked to provide crypto-economic security along the proof-of-stake model. This includes staking both the native token of Solana (SOL) as well as liquid staked token versions of SOL. These assets are staked into the bridge contract of the rollup, which then sends them to the proper place for staking or restaking.</p>
<p>The Mantis rollup also provides developers with a simplified mechanism for designing cross-domain decentralized applications (cdApps), which are defined by their inclusion of scoring, solvers, solution settlement, and cross-domain integrity proofs. An SDK is provided to further enhance the development and integration process.</p>
<h3><a class="anchor" href="https://ethresear.ch#cross-domain-auctions-6" name="cross-domain-auctions-6"></a>Cross-Domain Auctions</h3>
<p>Mantis plans to introduce cross-domain combinatorial auctions, with the goal of accomplishing the following:</p>
<ul>
<li>Optimized cross-domain MEV extraction*</li>
<li>Cross-domain intent solution atomic settlement</li>
<li>Efficient blockspace allocation</li>
<li>Increased distribution of revenue to validators selling items separately</li>
</ul>
<p>*We would like to take a moment here to reflect on MEV and our goals surrounding this concept. MEV is an evolving term with a number of interpretations. Initially MEV stood for miner extractable value, representing the maximum profit an agent (miner or validator) in proof-of-work blockchain systems could incur from its monopolistic rights over transaction inclusion. With the advent of proof-of-stake systems, MEV has become more often described as maximal extractible value, as miners are largely obsolete. Maximal extractible value still refers to the value that agents derive from strategically reordering and including transactions, but now these agents are frequently searchers.</p>
<p>A number of negative ramifications have been reported from these MEV extraction mechanisms. Thus, Flashbots introduced MEV-geth to Ethereum, which implemented a centralized combinatorial auction where searchers can express complex preferences in bundles. Then, this auction system was decentralized by MEV-Boost, allowing anyone to propose their block by bidding at auction. With the introduction of proposer-builder separation, validators on Ethereum now derive value from their monopolistic power over their slots.</p>
<p>As one can see, value from rearranging and including/excluding transactions can now be carried out by a number of parties in a number of manners. In addition to the extraction by validators, miners, and searchers, builders can also derive profits and users themselves can derive financial benefits from these mechanisms by using protocols such as Flashbots Protect, MEV blocker and Cow Protocol . Therefore, it becomes difficult to define exactly what value accrual mechanisms can be considered MEV.</p>
<p>Another complicating factor in the definition of MEV is that some of the aforementioned value accrual mechanisms have an inverse relationship. Most importantly, there is tension between the profits made by validators and other sellers from MEV and the overall welfare of the system (i.e. total value accrued to all users of the system, including end users, solvers, searchers, stakers, etc.). When overall profits to sellers are maximized, overall welfare goes down.</p>
<p>Thus, the goal of Mantis is not necessarily to maximize MEV extraction. Rather, the goal is to maximize overall welfare.One way in which we hope to achieve this is via our mechanisms designed to allocate blockspace efficiently to the users valuing it the most, such as our cross-domain auctions.</p>
<p>Initially, these auctions will be just-in-time to allow builders to express atomically. For two domains, this will involve two simultaneous English auctions with a unique combinatorial block take-it-or-leave it offer. Buyers can place send blocks with bids for the independent blocks and combinatorial blocks. The problems with this approach are the risk of double-signing and the high level of trust placed in the relay.</p>
<p>Therefore, Mantis aims to later introduce a future combinatorial blockspace market, where the rights to future blockspace on multiple domains can be bought and sold. The new crypto-economic primitive of restaking (such as that being facilitated by the Picasso Network) enables block proposers to issue credible commitments about future block construction. These are promises to build blocks in accordance with specific conditions laid out by execution ticket holders if certain payment thresholds are met. Tickets exist outside of a domain’s consensus protocol and will be exchanged via a combinatorial batch auction where buyers express combinatorial valuations over the tickets and sellers express reserve prices. Then, tickets can be traded or sold in a secondary market. This aims to decrease the monopoly of block sellers while increasing market efficiency.</p>
<h3><a class="anchor" href="https://ethresear.ch#the-ibc-protocol-7" name="the-ibc-protocol-7"></a>The IBC Protocol</h3>
<p>The <a href="https://www.ibcprotocol.dev/" rel="noopener nofollow ugc">IBC Protocol</a> facilitates communication between different blockchain ecosystems. <a href="https://medium.com/picasso-network/why-ibc-everywhere-is-the-key-to-cross-chain-defi-041bed829acd" rel="noopener nofollow ugc">Compared to other cross-chain communication protocols</a>, the benefits of IBC are that it is <a href="https://medium.com/@Picasso_Network/ibc-as-the-end-game-of-bridging-a-comparison-analysis-on-trust-dcc01e0d9377" rel="noopener nofollow ugc">trustless</a>, secure, censorship-resistant, permissionless, fast, cost-effective, and natively interoperable. For these reasons, Mantis has opted to use IBC as its mechanism for cross-chain communication.</p>
<p>Composable has expanded the reach of the IBC so that it not only connects the <a href="https://hub.cosmos.network/" rel="noopener nofollow ugc">Cosmos Hub</a> and <a href="https://v1.cosmos.network/sdk" rel="noopener nofollow ugc">Cosmos SDK</a> chains that it originally linked, but also interoperates with <a href="https://polkadot.network/" rel="noopener nofollow ugc">Polkadot</a> and <a href="https://kusama.network/" rel="noopener nofollow ugc">Kusama</a> parachains, <a href="https://ethereum.org/en/" rel="noopener nofollow ugc">Ethereum</a>, and <a href="https://solana.com/" rel="noopener nofollow ugc">Solana</a>. Creating these novel connections required a significant amount of technical development, given that many blockchains lack different components needed for IBC-compatibility.</p>
<p>In the case of Ethereum, the following components needed to be architected in order to enable IBC-compatibility:</p>
<ul>
<li><strong>ZK Circuit:</strong> This program is able to output a proof given a set of inputs. This proof can then be easily verified to ensure that each computational step that was run inside the circuit was done so correctly. In Picasso’s solution, the ZK circuit connects SNARK ED-25519 signatures to a prover. ED-25519 is a digital signature algorithm (DSA) that offers small key and signature sizes and fast computation being impervious to many common attacks to other DSAs.</li>
<li><strong>Tendermint Light Client on Ethereum:</strong> We constructed a <a href="https://docs.tendermint.com/v0.34/tendermint-core/light-client.html" rel="noopener nofollow ugc">Tendermint light client</a> on Ethereum, which lives as an Ethereum smart contract and is able to communicate over IBC with the light client on Picasso.</li>
<li><strong>Ethereum Light Client on the Picasso Chain:</strong> We also created a CosmWasm contract in the Wasm client of the Picasso Cosmos SDK chain to complete the Ethereum IBC connection.</li>
<li><strong>IBC Stack on Ethereum:</strong> We created a modified IBC stack for Ethereum that consists of Solidity smart contracts on Ethereum. Through this IBC stack, all BC components can operate on Ethereum, facilitating Ethereum’s interoperability with IBC.</li>
<li><strong>Hyperspace Relayer:</strong> The Composable Foundation’s <a href="https://informal.systems/blog/comparing-hyperspace-hermes" rel="noopener nofollow ugc">Hyperspace relayer</a> connects the two light clients involved in Ethereum IBC by transferring IBC packets between them. Hyperspace is the first event-driven, chain-agnostic IBC relayer that is based on ibc-rs (the Rust implementation of IBC). Hyperspace can thus relay packets between any IBC-enabled chains.</li>
<li><strong>Prover:</strong> This entity interacts with the relayer and proves to the verifier that something is true without revealing other information. On Picasso, what is being proved is various transactions sent between Ethereum and IBC. In particular, this prover is a rapid SNARK prover living on the Picasso Cosmos SDK chain.</li>
<li><strong>Verifier:</strong> Verifiers receive a proof from provers and validate this claim. This prover-verifier relationship results in the production of zero-knowledge proofs, as Ethereum explains <a href="https://ethereum.org/en/zero-knowledge-proofs/" rel="noopener nofollow ugc">here</a>.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#the-picasso-network-its-restaking-pool-8" name="the-picasso-network-its-restaking-pool-8"></a>The Picasso Network &amp; Its Restaking Pool</h3>
<p>The <a href="https://picasso.xyz/" rel="noopener nofollow ugc">Picasso Network</a> aims to deliver ecosystem-agnosticism to DeFi. It executes on this vision via the Picasso Layer 1, a Cosmos SDK blockchain that acts as an IBC hub between Cosmos and non-Cosmos IBC-enabled chains.</p>
<p>Picasso is the first censorship-resistant, natively-secured cross-ecosystem interoperability solution. The Picasso Network further emphasizes trust-minimization by drawing on the trustless IBC protocol. While a multisig is initially being used for upgradability of IBC contracts on Picasso, the end goal is to transition to decentralized governance.</p>
<p>Picasso is a critical component of Mantis as it allows the Mantis framework to be cross-chain capable over IBC. Specifically, Mantis transactions are grouped into IBC bundles for shipment based on domain. These bundles are then sent from the Mantis rollup over Picasso IBC and out to relevant blockchains for settlement.</p>
<p>Moreover, a restaking pool on Picasso coordinates the agents that have a combination of stake in different chains. Commitments formed between these actors draw upon this restaking pool.</p>
<h2><a class="anchor" href="https://ethresear.ch#development-roadmap-9" name="development-roadmap-9"></a>Development Roadmap</h2>
<p>The development for Mantis will be carried out in the following steps:</p>
<ol>
<li>
<p><strong>Enabling cross-domain swaps:</strong> integrating with IBC bridges and automated market makers across different chains to facilitate seamless asset swaps</p>
</li>
<li>
<p><strong>Setting up the foundational architecture:</strong> establishing a robust framework that includes the initial design of the Mantis architecture and the development of standards for scoring mechanisms and IBC for intent-based mechanisms</p>
</li>
<li>
<p><strong>Implementing cross-domain intent-based mechanisms:</strong> developing application programming interfaces (APIs) and software development kits (SDKs) that enable users to create and manage cross-domain intents, along with implementing an open-source solver that solves these intents</p>
</li>
<li>
<p><strong>Enriching the restaking layer:</strong> building out the restaking layer of Mantis to have additional functionality (simultaneously to step 3)</p>
</li>
<li>
<p><strong>Creating cross-domain MEV auctions:</strong> developing an auction system that efficiently allocates blockspace (simultaneously to step 3)</p>
</li>
<li>
<p><strong>Deploying block proposal commitments:</strong> enhancing the infrastructure for block proposals and establishing a credible commitment mechanism across domains, including robust fraud-proof mechanisms to maintain trust and security.</p>
</li>
<li>
<p><strong>Completing public launch and scaling:</strong> focusing on officially releasing all functionalities and documentation for Mantis</p>
</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#benefits-to-ethereum-10" name="benefits-to-ethereum-10"></a>Benefits to Ethereum</h1>
<p>Mantis supports Ethereum’s continued role as a leader in DeFi as the space becomes increasingly cross-chain. Composable has already connected Ethereum to the IBC, and therefore, to our trust-minimized bridge. This connection will drive new usership and liquidity to Ethereum from Solana, Cosmos, Polkadot, and Kusama. It will also enable the development of new use cases for ETH outside of Ethereum and on these other networks. Through such new use cases in new locations, DeFi users who do not currently hold ETH will likely be incentivized to do so, and existing users may be incentivized to hold more ETH. Thus, the Ethereum network is positioned to expand its reach even further into the cross-domain DeFi landscape, helping the ecosystem to maintain its reputation as a leader in the space.</p>
<p>Another benefit Mantis aims to deliver is chain abstraction. Mantis provides a mechanism for Ethereum and other domains to easily be participants in cross-chain DeFi without the blockchain, its layer 2s, or any protocols in the ecosystem needing to make significant modifications. Now that Ethereum is integrated with IBC, its innumerable DeFi protocols and applications can be leveraged from within Mantis. A user simply puts their intent for a transaction into the Mantis user interface, and the rest is handled for them. For example, A user may be looking to swap ETH for USDC. Once they input this intent, Solvers on Mantis compete to come up with the best execution route. For the sake of this example, perhaps the best price for this swap is through an ETH-USDC pool on Uniswap. The solver who has proposed the best settlement route wins the rights to settle the solution, routing the funds through Uniswap for the swap, and then back to the user. Once the transaction is settled as specified, the solver is rewarded. In this manner, all parties benefit: new traffic is routed through Uniswap in this example (or more generally, any other protocol or protocols providing best execution), the user has a streamlined experience with optimized settlement, and the solver is rewarded for their role.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-11" name="conclusion-11"></a>Conclusion</h1>
<p>Mantis provides the architecture needed for IBC-enabled chains like Ethereum to easily participate in the cross-domain future. This will help Ethereum continue its role at the forefront of DeFi as the industry continues to embrace multi-domain operations.</p>
<h1><a class="anchor" href="https://ethresear.ch#references-more-about-composable-12" name="references-more-about-composable-12"></a>References &amp; More About Composable</h1>
<p>Composable is dedicated to improving DeFi’s accessibility, quality, transparency, efficiency, and security. Our ultimate vision is for the Composable ecosystem to become an execution hub for chain-agnostic transactions. We are actualizing our mission by working to unite the DeFi space, building an ecosystem and a range of infrastructure to support trustless cross-chain operations.</p>
<ul>
<li><a href="https://assets.website-files.com/65b28e756a8eda2e91e76ca4/6656289f21123d6215091555_MANTIS%20Whitepaper.pdf" rel="noopener nofollow ugc">Mantis Whitepaper</a></li>
<li><a href="https://assets.website-files.com/65b28e756a8eda2e91e76ca4/6655e8e69277b97e9c11c793_MANTIS%20Litepaper.pdf" rel="noopener nofollow ugc">Mantis Litepaper</a></li>
<li><a href="https://www.mantis.app/" rel="noopener nofollow ugc">Mantis app</a></li>
<li><a href="https://www.composable.finance/" rel="noopener nofollow ugc">Composable website</a></li>
<li><a href="https://twitter.com/ComposableFin" rel="noopener nofollow ugc">Composable X/twitter</a></li>
<li><a href="http://discord.gg/composable" rel="noopener nofollow ugc">Composable Discord</a></li>
<li><a href="https://t.me/composable_chat" rel="noopener nofollow ugc">Composable Telegram</a></li>
<li><a href="https://github.com/ComposableFi/" rel="noopener nofollow ugc">Composable GitHub</a></li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/mantis-driving-ethereum-s-cross-domain-future/20009">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 08 Jul 2024 13:16:05 +0000</pubDate>
</item>
<item>
<title>Maximum Viable Security: A New Framing for Ethereum Issuance</title>
<link>https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992</link>
<guid>https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#maximum-viable-security-a-new-framing-for-ethereum-issuance-1" name="maximum-viable-security-a-new-framing-for-ethereum-issuance-1"></a><strong>Maximum Viable Security: A New Framing for Ethereum Issuance</strong></h1>
<p><em>by <a href="http://x.com/artofkot" rel="noopener nofollow ugc">@artofkot</a>, <a href="http://x.com/damcnuta" rel="noopener nofollow ugc">@damcnuta</a>, <a href="http://x.com/sonyasunkim" rel="noopener nofollow ugc">@sonyasunkim</a>, <a href="http://x.com/adcv_" rel="noopener nofollow ugc">@adcv_</a></em></p>
<p><em>Appreciate feedback from <a href="http://x.com/ppclunghe" rel="noopener nofollow ugc">@ppclunghe</a>, <a href="https://x.com/ks_kulk" rel="noopener nofollow ugc">@ks_kulk</a>, <a href="http://x.com/lazyleger" rel="noopener nofollow ugc">@lazyleger</a>, <a href="https://cryptecon.org/team-detail-ce/items/juan-beccuti.html" rel="noopener nofollow ugc">Juan Beccuti</a>, <a href="https://x.com/entigdd" rel="noopener nofollow ugc">enti</a>, <a href="https://x.com/stakesaurus" rel="noopener nofollow ugc">Stakesaurus</a>, <a href="http://x.com/hasufl" rel="noopener nofollow ugc">@hasufl</a>, <a href="http://x.com/lex_node" rel="noopener nofollow ugc">@lex_node</a>, <a href="https://x.com/_vshapovalov" rel="noopener nofollow ugc">@_vshapolapov</a>, <a href="http://x.com/brettpalatiello" rel="noopener nofollow ugc">@brettpalatiello</a></em></p>
<hr />
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#tldr-embrace-security-2">TLDR: Embrace security</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-1-the-foundations-of-the-maximum-viable-security-mvs-framework-3">1. The foundations of the Maximum Viable Security (“MVS”) framework</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-11-ethereum-has-a-clear-goal-build-a-secure-and-sovereign-distributed-system-for-everyone-4">1.1. Ethereum has a clear goal: build a secure and sovereign distributed system for everyone</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-12-a-diverse-staking-economy-is-key-5">1.2. A diverse staking economy is key</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-121-stakers-6">1.2.1. Stakers</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-122-validating-entities-7">1.2.2. Validating entities</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-123-entities-decentralization-8">1.2.3. Entities’ decentralization</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-13-there-is-no-future-proof-safe-level-of-security-9">1.3. There is no future-proof safe level of Security</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-14-reframing-the-discourse-expansion-over-efficiency-10">1.4. Reframing the discourse: expansion over efficiency</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-2-analysis-of-ethereum-issuance-reduction-proposal-within-the-mvs-framework-11">2. Analysis of Ethereum Issuance reduction proposal within the MVS framework</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-21-the-assumption-that-ethereum-overpays-for-security-is-wrong-less-issuance-may-lead-to-centralization-of-the-validator-set-12">2.1. The assumption that Ethereum overpays for security is wrong: less issuance may lead to centralization of the validator set</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-211-etf-inflows-would-exacerbate-centralization-in-the-context-of-a-33-stake-cap-13">2.1.1 ETF inflows would exacerbate centralization in the context of a 33% stake cap</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-212-staked-eth-concentration-with-cexs-doesnt-necessarily-have-to-happen-with-a-higher-stake-cap-14">2.1.2 Staked ETH concentration with CEXs doesn’t necessarily have to happen with a higher stake cap</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-213-mvi-effect-on-the-ratio-of-solo-stakers-15">2.1.3 MVI effect on the ratio of solo stakers</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-22-lst-dominance-and-cost-modeling-are-inadequate-arguments-for-issuance-reduction-19">2.2. LST dominance and cost-modeling are inadequate arguments for issuance reduction</a>
<ul>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-221-issuance-as-a-cost-is-a-reductive-framing-20">2.2.1. Issuance as a cost is a reductive framing</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-222-stakers-getting-higher-real-vs-nominal-yield-is-not-significant-21">2.2.2. Stakers getting higher real vs nominal yield is not significant</a></li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-223-reducing-lst-dominance-shouldnt-be-a-primary-objective-of-ethereums-monetary-policy-22">2.2.3. Reducing LST dominance shouldn’t be a primary objective of Ethereum’s monetary policy</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992#h-3-putting-it-all-together-23">3. Putting it all together</a></li>
</ul>
<hr />
<h2><a class="anchor" href="https://ethresear.ch#tldr-embrace-security-2" name="tldr-embrace-security-2"></a>TLDR: Embrace security</h2>
<p>Given Ethereum’s goal of building a secure and sovereign distributed system, we believe viewing Ethereum’s monetary policy through the lens of Minimum Viable Issuance (MVI) is not appropriate. Instead, we propose Maximum Viable Security (MVS) as a new framework for the community to consider in the Ethereum issuance debate. That is,</p>
<p>From: <strong>Minimum Viable Issuance (MVI)</strong> – minimize issuance, without compromising security.<br />
→<br />
To: <strong>Maximum Viable Security (MVS)</strong> – maximize security, without compromising scarcity.</p>
<p>After covering the motivation and foundations behind MVS, we evaluate Ethereum issuance reduction proposals through the MVS lens. We show that issuance reduction can compromise security and neutrality in a direct way, through staked ETH concentration with Centralized Exchanges – and this effect, on balance, far outweighs the advantages of cutting the issuance.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-1-the-foundations-of-the-maximum-viable-security-mvs-framework-3" name="h-1-the-foundations-of-the-maximum-viable-security-mvs-framework-3"></a>1. The foundations of the Maximum Viable Security (“MVS”) framework</h2>
<h3><a class="anchor" href="https://ethresear.ch#h-11-ethereum-has-a-clear-goal-build-a-secure-and-sovereign-distributed-system-for-everyone-4" name="h-11-ethereum-has-a-clear-goal-build-a-secure-and-sovereign-distributed-system-for-everyone-4"></a>1.1. Ethereum has a clear goal: build a secure and sovereign distributed system for everyone</h3>
<blockquote>
<p><code>There are many goals of this project; one key goal is to facilitate transactions between consenting individuals who would otherwise have no means to trust one another.</code><br />
<em>Source: Ethereum Yellow Paper (<a href="https://ethereum.github.io/yellowpaper/paper.pdf" rel="noopener nofollow ugc">link</a>)</em></p>
</blockquote>
<p>The growth of Ethereum’s market capitalization from 0 to $400bn today underscores the market’s confidence in its current and future potential. This value hinges on Ethereum’s ability to validate state changes transparently, securely, and sovereignly.</p>
<p>Security is a crucial part of the value proposition. Without sybil resistance and slashing defense (programmable or social) against 34% double-signing attacks, a settlement layer would not be trusted by participants. A secure validation layer is the most scalable (<a href="https://unenumerated.blogspot.com/2017/02/money-blockchains-and-social-scalability.html" rel="noopener nofollow ugc">link</a>) foundation for providing transaction settlement with incorruptible finality.</p>
<p>Sovereignty is equally important – Ethereum should be able to defend against more subtle 51% attacks such as short-range reorgs and censoring (<a href="https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/attack-and-defense/#attackers-with-50-stake" rel="noopener nofollow ugc">link</a>), and should be able to resist coercion by state actors. If Ethereum loses sovereignty (aka autonomy), it loses its value as a neutral settlement mechanism:</p>
<blockquote>
<p><code>"Decentralization" is the broad distribution of a system's intrinsic/accepted forms of power, protecting users against arbitrary exercises of power from the recognized legitimate 'authorities' within the system's logic (e.g., validators). "Autonomy" is the system's resistance against extrinsic/unaccepted forms of power, protecting users against all exercises of power from authorities outside the system's logic (e.g., government authorities).</code><br />
<em>Source: lex_node (<a href="https://twitter.com/lex_node/status/1799489646042165662" rel="noopener nofollow ugc">link</a>)</em></p>
</blockquote>
<p>While 34% attacks are costly and 51% attacks are to some extent bounded by reputation and social slashing, a gradual coercion by state actors on independent validators is more feasible, and can even be unintentional. For instance, the European Securities and Markets Authority (ESMA) recently suggested (<a href="https://www.esma.europa.eu/press-news/consultations/consultation-technical-standards-specifying-certain-requirements-mica-3rd#responses" rel="noopener nofollow ugc">link</a>) viewing MEV as a form of market manipulation subject to notification requirements from validators. Such regulations could make it impracticable for node operators to continue to function in Europe. In a worst-case outcome, these regulations could propagate to the rest of the world and impose artificial restrictions on how the consensus algorithm works.</p>
<p>High autonomy is therefore maintained through robust decentralization among validators, which includes:</p>
<ul>
<li><strong>Client software diversity</strong>: running different types of validator software to avoid concentration risk from bugs.</li>
<li><strong>Node operator diversity</strong>: different, independent entities running validator software to prevent individual node operators reaching higher levels of control.</li>
<li><strong>Geographic and jurisdictional diversity</strong>: different levels of base-level infrastructure — such as connectivity to the internet, power supply, law authorities and jurisdictions — that are capable of influencing node operators.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-12-a-diverse-staking-economy-is-key-5" name="h-12-a-diverse-staking-economy-is-key-5"></a>1.2. A diverse staking economy is key</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-121-stakers-6" name="h-121-stakers-6"></a>1.2.1. Stakers</h4>
<p>Stakers fall into three main categories:</p>
<ol>
<li>Retail and Institutions: These participants delegate their staking to Centralized Exchanges (CEXs)</li>
<li>On-chain Actors: They delegate their staking to Decentralized Staking Middleware (DSM), such as Liquid Staking Tokens (LSTs) or decentralized pools, as well as Liquid Restaking Token protocols (LRTs) and Centralized Staking Providers (CSPs).</li>
<li>Solo Stakers: These users choose not to delegate and run validators independently</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#h-122-validating-entities-7" name="h-122-validating-entities-7"></a>1.2.2. Validating entities</h4>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e4e64e83cbc59b58fdfe0316e37c8b548dfb52d8.jpeg" title="tg_image_4158519118"><img alt="tg_image_4158519118" height="469" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e4e64e83cbc59b58fdfe0316e37c8b548dfb52d8_2_690x469.jpeg" width="690" /></a></div><br />
<em>Note: CSP numbers do not include capital delegated from DSM/LRTs. The above numbers are approximate and for illustration purposes; they are our best estimates from Dune (<a href="https://dune.com/hildobby/eth2-staking" rel="noopener nofollow ugc">1</a>, <a href="https://dune.com/lido/eth-deposits-stats" rel="noopener nofollow ugc">2</a>), as of June 30th 2024.</em><p></p>
<p>A hypothetical scenario where most ETF Ether is staked with custodial services, like Coinbase, suggests that this is where most of future inflows will likely originate. Recent Bitcoin ETFs have seen ~$15b of inflows. Proportionally applied to Ethereum, this could mean about 4m ETH. Notably, 8 out of 11 Bitcoin ETFs use Coinbase as their custodian, a pattern that may repeat with ETH.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-123-entities-decentralization-8" name="h-123-entities-decentralization-8"></a>1.2.3. Entities’ decentralization</h4>
<p>Contributions to decentralization and thus censorship resistance and neutrality can be approximated as follows: Solo Stakers &gt; Decentralized Staking Middleware &gt; Liquid Restaking Protocols &gt; Centralized Staking Providers &gt; CEXs.</p>
<ul>
<li><strong>Solo Stakers</strong>: Contribute the most to decentralization because each adds an additional validator</li>
<li><strong>DSM</strong>: Efficiently distribute delegated stake among many parties, bonded via reputation (Lido) or collateral (Rocket Pool, Lido’s Community Staking Module). Their impact on Ethereum’s decentralization is measurable and significant, with data on operational diversity publicly available and regularly updated (<a href="https://app.hex.tech/8dedcd99-17f4-49d8-944e-4857a355b90a/app/3f7d6967-3ef6-4e69-8f7b-d02d903f045b/latest" rel="noopener nofollow ugc">link</a>). The Herfindahl-Hirschmann Index (HHI) can also provide a useful proxy on the effect on validation concentration (<a href="https://dune.com/steakhouse/hhi" rel="noopener nofollow ugc">link</a>)</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/4/b4d2e88d63be2c26d7397166220ad2752e954a34.png" title="dune_hhi"><img alt="dune_hhi" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/b/4/b4d2e88d63be2c26d7397166220ad2752e954a34_2_690x411.png" width="690" /></a></div><p></p>
<ul>
<li><strong>Restaking Infrastructure</strong>: While not cost-optimized for native staking, these protocols distribute stake among fewer node operators without aggregating it under one entity</li>
<li><strong>Centralized Staking Providers</strong>: Risk aggregating large amounts of stake, but competition among them can bolster decentralization if many can sustain independent businesses</li>
<li><strong>CEXs</strong>: Benefit the most from the power law distribution of AUM, often driving staked ETH concentration. Coinbase, for instance, is the largest node operator with nearly 15% market share.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#h-13-there-is-no-future-proof-safe-level-of-security-9" name="h-13-there-is-no-future-proof-safe-level-of-security-9"></a>1.3. There is no future-proof safe level of Security</h3>
<p>Anders Lowsson suggests (<a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/">link</a>) that Ethereum should reduce its issuance, arguing that “excessive incentives for staking, beyond what is necessary for security, can unfortunately over time turn into perverse subsidies, with many downsides.” However, this raises the question of what constitutes “adequate incentives for staking” and what level of security is truly necessary.</p>
<blockquote>
<p><code>What exactly is "neutrality"? I see that term being used in handwavy fashion, especially when scaling comes up, and it's hard to know what we mean by "preserving credible neutrality" at the moment. Would be nice to get some info there. :)</code><br />
<em>Source: eawosikaa (<a href="https://x.com/eawosikaa/status/1808005717976047799" rel="noopener nofollow ugc">link</a>)</em></p>
</blockquote>
<p>Today’s global capital markets are valued in the hundreds of trillions of dollars, while Ethereum represents only a tiny fraction of that. For Ethereum to become a neutral settlement layer for the world, its cost of corruption would need to be in the hundreds of billions, if not trillions, of dollars, to capture the value that could be extracted in a possible attack. For context, large value payment systems (excluding retail payments) cleared quadrillions of dollars in value in 2022 (<a href="https://data.bis.org/topics/CPMI_FMI/tables-and-dashboards/BIS,CPMI_T9,1.0?view=value&amp;dimensions=REP_CTY%3AUS" rel="noopener nofollow ugc">link</a>). In comparison, over the past 12mos, stablecoin transfer value on Ethereum just about cleared $8tn, or 0.5% (<a href="https://www.theblock.co/data/stablecoins/usd-pegged/adjusted-on-chain-volume-of-stablecoins-monthly" rel="noopener nofollow ugc">link</a>). This is consistent with the proportion of market capitalization of Ethereum relative to global capital markets (well under 1% as well).</p>
<p>The slightest risk of insufficient security would stagnate Ethereum’s growth – decentralization and the resulting neutrality is Ethereum’s <span class="hashtag-raw">#1</span> competitive advantage. No risk should be taken to erode that, and instead, we should seek to strengthen it even further. To answer Emmanuel’s question, in our framing, we would use “neutrality” interchangeably with “sovereignty” and “autonomy”: ability to defend against censorship and coercion attacks (<a href="https://nakamoto.com/credible-neutrality/" rel="noopener nofollow ugc">link</a>). Such that the cost of “coercion” is always higher than the benefit from manipulating the state.</p>
<p>Anders’ argument assumes that a 34% double-singing attack is so costly and 51% censorship attack is so unlikely today, that the network can afford to focus on strengthening other layers. If Ethereum were already a major part of the world’s capital markets, this argument might hold more weight, as incremental risks would be smaller. However, reducing today the network’s most crucial features—security and sovereignty—would compromise the network’s ability to grow.</p>
<p>Currently, Ethereum’s social layer serves as the final defense (<a href="https://ercwl.medium.com/the-case-for-social-slashing-59277ff4d9c7" rel="noopener nofollow ugc">link</a>) against norm violations that threaten its credible neutrality. However, this social layer is structurally fragile. It requires constant vigilance from the community so that enforcement can occur on a daily basis. Yet, as Ethereum grows, massive new inflows might bypass today’s social layer altogether. If a large bank, say, staked $1tn worth of Ether with a CEX, what chance does a community of open source developers have to enforce social norms? The key question, as Emmanuel points out, is: What is the threshold for security that Ethereum needs today and in the future? The MVI proposal, in our view, fails to address this critical question, focusing instead on the other effects of reducing the security budget.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-14-reframing-the-discourse-expansion-over-efficiency-10" name="h-14-reframing-the-discourse-expansion-over-efficiency-10"></a>1.4. Reframing the discourse: expansion over efficiency</h3>
<p>Ethereum should balance incentives for all stakeholders to ensure the highest level of security. This balance involves weighing long-term sustainability and expansion vs short-term efficiency to create enduring security value.</p>
<p>MVS suggests that instead of asking “how much could we reduce issuance for staking efficiency”, we should be asking “how much network incentivisation do we need to perpetuate decentralization to maintain and expand security”.</p>
<p>Strategically, MVI and MVS represent two different paths for Ethereum’s growth. MVI focuses on minimizing costs, benefiting ETH holders in the short term. MVS, on the other hand, emphasizes building a long-lasting moat around the network, optimizing long-term value creation for all stakeholders, including ETH holders.</p>
<p>Ethereum’s unique appeal lies in its secure, credibly neutral blockspace. Unlike commodity blockspace, which competes on price, secure blockspace competes on features. Similar to the advanced chip industry, where success de<br />
ffpends on computational ability rather than price, Ethereum should compete on the magnitude of security it offers. This security creates an enduring competitive advantage, accelerating value creation across the ecosystem.</p>
<p>There is a subtlety in that the market cap of Ethereum is a variable that contributes to security, and so minimizing issuance can be seen as bolstering security. Superficially, there is a reflexive effect, where Ethereum’s security both causes and is driven by its market cap. However, we believe that Ethereum’s security making ETH valuable is the primary causation, and therefore security needs to be prioritized. Below we illustrate diagrammatically the alternative value creation paths for Ethereum contributors deciding between MVS and MVI.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/f/1f2963c356b0018f378fbf4fe73ef79e641aa362.jpeg" title="tg_image_2418175601"><img alt="tg_image_2418175601" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/f/1f2963c356b0018f378fbf4fe73ef79e641aa362_2_530x500.jpeg" width="530" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#h-2-analysis-of-ethereum-issuance-reduction-proposal-within-the-mvs-framework-11" name="h-2-analysis-of-ethereum-issuance-reduction-proposal-within-the-mvs-framework-11"></a>2. Analysis of Ethereum Issuance reduction proposal within the MVS framework</h2>
<p>We posit that, under the MVS framework, Ethereum issuance reduction proposals risk creating downstream effects that would compromise Ethereum’s security value. Overall, we believe that ETH’s moneyness stands to increase with greater security and autonomy, to a degree that far outweighs the downsides of issuance or externalities such as capital gains taxes.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-21-the-assumption-that-ethereum-overpays-for-security-is-wrong-less-issuance-may-lead-to-centralization-of-the-validator-set-12" name="h-21-the-assumption-that-ethereum-overpays-for-security-is-wrong-less-issuance-may-lead-to-centralization-of-the-validator-set-12"></a>2.1. The assumption that Ethereum overpays for security is wrong: less issuance may lead to centralization of the validator set</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-211-etf-inflows-would-exacerbate-centralization-in-the-context-of-a-33-stake-cap-13" name="h-211-etf-inflows-would-exacerbate-centralization-in-the-context-of-a-33-stake-cap-13"></a>2.1.1 ETF inflows would exacerbate centralization in the context of a 33% stake cap</h4>
<p>Lowering the target stake ratio (<a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">link</a>) could lead to a concentration of staked ETH with Centralized Exchanges (CEXs), driving capital away from decentralized alternatives.</p>
<p>Consider a scenario where a 33% cap (equivalent to 40.6 million staked ETH) is implemented, and the curve enacts a sharp drop of yield to zero as stake ratio increases from 30% (36.6 million ETH) to 33% (40.6 million ETH). Suppose Ether ETFs are launched in the US, attracting significant capital inflows. If these ETFs use Coinbase as their custodian (as 8 out of 11 BTC ETF issuers do), this could lead to $15 billion in inflows, adding approximately 4.5 million ETH to Coinbase’s custody. The simulated impact on the validation market might look like this; the 40.1m max staked ETH being slightly lower then 40.6 represents the fact that when yield becomes extremely low there is no marginal staker at all on the market.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th><strong>Illustrative impact on validation market with a 33% MVI limit</strong></th>
<th style="text-align: center;"><strong>Current composition</strong></th>
<th style="text-align: center;"><strong>Effect in 4 years</strong></th>
<th style="text-align: center;"><strong>Future composition</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>ETH staked</td>
<td style="text-align: center;">33.1m</td>
<td style="text-align: center;">+7m</td>
<td style="text-align: center;">40.1m</td>
</tr>
<tr>
<td>ETH held with Coinbase</td>
<td style="text-align: center;">17.5m</td>
<td style="text-align: center;">+4.5m (ETFs)</td>
<td style="text-align: center;">22m</td>
</tr>
<tr>
<td>ETH held &amp; staked with Coinbase</td>
<td style="text-align: center;">4.3m</td>
<td style="text-align: center;">+10m</td>
<td style="text-align: center;">14.3m</td>
</tr>
<tr>
<td>ETH staked on-chain via LSTs/LRTs</td>
<td style="text-align: center;">13.7m</td>
<td style="text-align: center;">-2m</td>
<td style="text-align: center;">11.7</td>
</tr>
<tr>
<td>ETH staked by other entities</td>
<td style="text-align: center;">15.1</td>
<td style="text-align: center;">-1m</td>
<td style="text-align: center;">14.1</td>
</tr>
</tbody>
</table>
</div><ol>
<li>Market forces and fiduciary duties ensure that CEXs like Coinbase squeeze the maximum amount of profit from staking-as-a-service (for their customers and ETF issuers), and long-term the majority of their holdings are staked.</li>
</ol>
<p>We model the above impact by assigning a 10m staked ETH inflow to Coinbase. When Coinbase’s stake reaches 7.8 million, total staked ETH will be about 36.6 million, causing rewards to drop sharply. Consequently:</p>
<ol start="2">
<li>Lido stETH and other LST/LRT users, being sophisticated on-chain actors, will seek higher rewards elsewhere. The switching cost of moving capital on-chain is extremely low, so there is no incentive for capital to stay – the capital will leave for higher yields in DeFi.</li>
<li>CSPs will exit these protocols since the 5% fee from middleware won’t cover their costs.</li>
</ol>
<p>We model the above two impacts by assigning a 2 million ETH outflow to LSTs/LRTs and a 1 million ETH outflow to other entities.</p>
<ol start="4">
<li>Meanwhile, CEXs like Coinbase can continue offering staking products because their marginal costs are extremely low, and can even be offset by other business segments. Their customers may remain loyal or lack alternatives due to regulations or unsophisticated nature of the user base. This can happen despite Coinbase having higher fees (25%) compared to better-performing alternatives (5-15%).</li>
</ol>
<p>In this scenario, Coinbase could control 14.3 million ETH, surpassing the 33% network control threshold independently, while Lido and other DSMs lose market share.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-212-staked-eth-concentration-with-cexs-doesnt-necessarily-have-to-happen-with-a-higher-stake-cap-14" name="h-212-staked-eth-concentration-with-cexs-doesnt-necessarily-have-to-happen-with-a-higher-stake-cap-14"></a>2.1.2 Staked ETH concentration with CEXs doesn’t necessarily have to happen with a higher stake cap</h4>
<p>Without the cap, both CEXs and on-chain market segments could coexist without putting pressure on each other due to sufficient demand for staking. LSTs, LRTs and CSPs wouldn’t face the dramatic yield decrease that would occur when Coinbase’s stake reaches 7.8 million ETH. Some might argue that Coinbase would undercut other staking providers by lowering its 25% fee. However, this is uncertain. Coinbase’s customer base seems inelastic, meaning the most profitable strategy might be to maintain or even increase their fees. In addition, even if Coinbase goes after the on-chain market and lowers their fees, the market may not be fully efficient – some people might prefer to stick with LSTs due to their decentralization preference.</p>
<p>In a highly segmented market, margins don’t need to uniformly compress, leaving space for both CEXs/CSPs and LSTs/restaking segments to thrive. LSTs and CEXs serve distinct market segments. For CEXs, the most profitable approach is to charge high fees from retail and institutional clients (e.g., Coinbase’s 25%) without directly competing with LSTs. Targeting stake ratios could stifle the market for on-chain actors but not significantly affect the market for retail and institutional clients.</p>
<p>Thus, in the absence of a stake cap, the coexistence of various staking actors could lead to a more balanced distribution of staked ETH across different market segments.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-213-mvi-effect-on-the-ratio-of-solo-stakers-15" name="h-213-mvi-effect-on-the-ratio-of-solo-stakers-15"></a>2.1.3 MVI effect on the ratio of solo stakers</h4>
<h5><a class="anchor" href="https://ethresear.ch#the-importance-of-this-effect-is-overrated-16" name="the-importance-of-this-effect-is-overrated-16"></a>The importance of this effect is overrated</h5>
<p>Approximately 30 million ETH is delegated, while only 3 million is solo staked. It is evident that delegation dominates as a modality of staking. The key issue is ETH concentration with CEXs, rather than the interaction between solo stakers and LSTs.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: center;"><strong>Grouping</strong></th>
<th style="text-align: center;"><strong>Approximate stake</strong></th>
<th style="text-align: center;"><strong>Type</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">CEXs</td>
<td style="text-align: center;">10m</td>
<td style="text-align: center;">Delegated</td>
</tr>
<tr>
<td style="text-align: center;">LSTs, LRTs, CSPs</td>
<td style="text-align: center;">20m</td>
<td style="text-align: center;">Delegated</td>
</tr>
<tr>
<td style="text-align: center;">Solo stakers</td>
<td style="text-align: center;">3m</td>
<td style="text-align: center;">Solo staked</td>
</tr>
</tbody>
</table>
</div><h5><a class="anchor" href="https://ethresear.ch#lsts-and-csps-can-also-contribute-to-overall-network-quality-17" name="lsts-and-csps-can-also-contribute-to-overall-network-quality-17"></a>LSTs and CSPs can also contribute to overall network quality</h5>
<p>While solo stakers are often seen as the backbone of Ethereum’s network security, the contributions of LSTs and centralized staking providers are undervalued.</p>
<p>There is a lot of nuance to the emergent risks of malicious actors emerging from LSTs such as Lido. There certainly are risks (cf. Mike Neuder’s extensive post on the subject, <a href="https://notes.ethereum.org/@mikeneuder/magnitude-and-direction" rel="noopener nofollow ugc">link</a>). However, there are also many benefits to deterministic stake allocation to professional or larger node operators. It’s possible for solo stakers to have different motivations than an LST whose main objective is to decentralize Ethereum validation (<a href="https://research.lido.fi/t/lido-dao-vibe-alignment-purpose-mission-vision/" rel="noopener nofollow ugc">link</a>). Some of the most noteworthy examples of malicious proposers, for example, have come from solo validators, such as those involved in the April 3rd, 2023 MEV Boost exploit (<a href="https://collective.flashbots.net/t/post-mortem-april-3rd-2023-mev-boost-relay-incident-and-related-timing-issue/" rel="noopener nofollow ugc">link</a>).</p>
<p>Centralized staking providers and LSTs are quantifiably more performant validators than solo stakers. There is significant existing data (<a href="http://rated.network/" rel="noopener nofollow ugc">link</a>) today to quantify proposer effectiveness and attester effectiveness, which drive fewer missed slots and attestations, faster block propagation and chain finalization. Overall the network is much more stable and responsive with professional validators than it would otherwise be, but also more decentralized.</p>
<h5><a class="anchor" href="https://ethresear.ch#issuance-reductions-would-likely-decrease-the-share-of-solo-stakers-18" name="issuance-reductions-would-likely-decrease-the-share-of-solo-stakers-18"></a>Issuance reductions would likely decrease the share of solo stakers</h5>
<p>Some argue that solo stakers are less elastic with respect to yield, because they are as a cohort more heterogeneous than other validating entities, and hence have a steeper supply curve.</p>
<p>However, our simplified analysis of Ethereum validator economics shows this argument is flawed. Solo stakers in fact have much higher fixed costs, making them much less adaptable to a low issuance rates compared to larger node operators. Specifically,</p>
<p>For solo stakers:</p>
<ul>
<li>Staking APR is lower and closer to the Median staking APR (i.e. 2.4% per Rated, <a href="https://explorer.rated.network/network?network=mainnet&amp;timeWindow=1d&amp;rewardsMetric=average&amp;geoDistType=all&amp;hostDistType=all&amp;soloProDist=stake" rel="noopener nofollow ugc">link</a>) than scale node operators due to the unpredictability of proposer rewards, tips and MEV</li>
<li>The costs of running a single validator include hardware (32 GB RAM, 4 TB SSD) and electricity. Home internet plans are sufficient for solo stakers, so broadband cost is assumed to be 0 (no incremental cost).</li>
<li>In this set up, 100% of solo staker’s total costs are fixed costs. Assuming hardware depreciation of 5 years, profit margins are &gt;90% to solo stakers</li>
<li>We exclude the need to reserve 32 ETH in capital as collateral, which brings the capital outlay (though not outright investment) significantly higher</li>
</ul>
<p>Then consider, on the opposite end of the spectrum, a large centralized node operator with 100,000 validators:</p>
<ul>
<li>Staking APR is higher and closer to the Average staking APR (i.e. 3.3% per Rated, <a href="https://explorer.rated.network/network?network=mainnet&amp;timeWindow=1d&amp;rewardsMetric=average&amp;geoDistType=all&amp;hostDistType=all&amp;soloProDist=stake" rel="noopener nofollow ugc">link</a>) as stake pooling smoothes the unpredictable components of both CL (proposer rewards) and EL (tips + MEV) rewards</li>
<li>Costs include hardware but also significant operational costs including technical and marketing staff</li>
<li>Hardware and internet are fixed costs, electricity is a variable cost and staff costs can be seen as a semi-variable cost
<ul>
<li>Employment footprint can be eventually adjusted should the top line be negatively impacted</li>
</ul>
</li>
<li>Counting half of the maintenance &amp; growth spend as fixed and the other half as variable, we arrive at fixed costs representing 64% of the large node operators’ total costs (i.e. much less than solo stakers). Profit margins are also lower than those of solo stakers</li>
</ul>
<div class="md-table">
<table>
<thead>
<tr>
<th>Assumptions</th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td>ETH ($)</td>
<td style="text-align: right;">3,500</td>
</tr>
<tr>
<td>Average staking APR</td>
<td style="text-align: right;">3.3%</td>
</tr>
<tr>
<td>Median staking APR</td>
<td style="text-align: right;">2.4%</td>
</tr>
<tr>
<td>MVI reduction assumed</td>
<td style="text-align: right;">2.0%</td>
</tr>
</tbody>
</table>
</div><div class="md-table">
<table>
<thead>
<tr>
<th><strong>Illustrative Annual P/L</strong></th>
<th style="text-align: center;"><strong>Current</strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align: center;"><strong>Solo Staker</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Large Node Operator</strong></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
</tr>
<tr>
<td># of validators</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">112,000</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">11,200,000,000</td>
</tr>
<tr>
<td>Staking APR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2.4%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">3.3%</td>
</tr>
<tr>
<td>Staking income</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2,677</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">367,360,000</td>
</tr>
<tr>
<td>Commission</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10%</td>
<td style="text-align: center;">36,736,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Hardware cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>800</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>7,750,000</strong></td>
</tr>
<tr>
<td>Computer/servers</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">800</td>
<td style="text-align: center;">350</td>
<td style="text-align: center;">7,000,000</td>
</tr>
<tr>
<td>Backup servers</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">750,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Operational cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>74</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>19,794,780</strong></td>
</tr>
<tr>
<td>Electricity</td>
<td style="text-align: center;">70Wh, $0.12/kWh</td>
<td style="text-align: center;">74</td>
<td style="text-align: center;">750Wh/server, $0.12/kWh</td>
<td style="text-align: center;">354,780</td>
</tr>
<tr>
<td>Internet connection</td>
<td style="text-align: center;">No incremental cost</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">540GB/month/val @ $0.03/GB</td>
<td style="text-align: center;">19,440,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Maintenance &amp; growth</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>11,400,000</strong></td>
</tr>
<tr>
<td>Technical staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">8,400,000</td>
</tr>
<tr>
<td>Marketing/admin staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">3,000,000</td>
</tr>
<tr>
<td>Cybersecurity/miscellaneous</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Total cost (assume 5Y hardware depreciation)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>234</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>32,744,780</strong></td>
</tr>
<tr>
<td>o/w fixed cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">64%</td>
</tr>
<tr>
<td>o/w variable cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">36%</td>
</tr>
<tr>
<td><strong>Payback period on capex (months)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3.9</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>23.3</strong></td>
</tr>
<tr>
<td><strong>Annual income/loss</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>2,443</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3,991,220</strong></td>
</tr>
<tr>
<td><strong>Profit margin (excl. ETH at stake)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>91.3%</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>10.9%</strong></td>
</tr>
</tbody>
</table>
</div><p>In the event that MVI reduces staking APR for all stakers (e.g. -200bps), the below scenario analysis helps visualize how different stakers may be impacted differently. High level:</p>
<ul>
<li>Solo stakers have very limited, if no, way of adjusting their underlying costs. 100% of the reduced staking rewards will fall through to the bottom line, resulting in a dramatic reduction in profit margin. As a result, the payback period on capex (i.e. hardware) multiplies from 3.9 months to 47.2 months in our example, without considering the need to raise 32 ETH to activate a validator to begin with. This raises the question of whether incremental demand from new solo stakers could be sustained in the post-MVI world</li>
<li>Meanwhile, large node operators have more levers to pull to protect their profits and capex payback periods
<ul>
<li>As in Scenario 1, node operators can raise their commission</li>
<li>As in Scenario 2, node operators can raise their commission and reduce variable costs, notably staff costs</li>
<li>With very minor changes to their structure they can come back to prior levels of profit</li>
</ul>
</li>
</ul>
<div class="md-table">
<table>
<thead>
<tr>
<th><strong>Illustrative Annual P/L</strong></th>
<th style="text-align: center;"><strong>If staking APR reduces by 200bps</strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align: center;"><strong>Solo Staker</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Large Node Operator - Scenario 1</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Large Node Operator - Scenario 2</strong></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
<td style="text-align: center;"><strong>Quantity</strong></td>
<td style="text-align: center;"><strong>$</strong></td>
</tr>
<tr>
<td># of validators</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">112,000</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">11,200,000,000</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">11,200,000,000</td>
</tr>
<tr>
<td>Staking APR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>0.4%</em></strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>1.3%</em></strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>1.3%</em></strong></td>
</tr>
<tr>
<td>Staking income</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">437</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">143,360,000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">143,360,000</td>
</tr>
<tr>
<td>Commission</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong><em>25%</em></strong></td>
<td style="text-align: center;">35,840,000</td>
<td style="text-align: center;"><strong><em>25%</em></strong></td>
<td style="text-align: center;">35,840,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Hardware cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>800</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>7,750,000</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>7,750,000</strong></td>
</tr>
<tr>
<td>Computer/servers</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">800</td>
<td style="text-align: center;">350</td>
<td style="text-align: center;">7,000,000</td>
<td style="text-align: center;">350</td>
<td style="text-align: center;">7,000,000</td>
</tr>
<tr>
<td>Backup servers</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">750,000</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">750,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Operational cost</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>74</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>19,794,780</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>19,794,780</strong></td>
</tr>
<tr>
<td>Electricity</td>
<td style="text-align: center;">70Wh, $0.12/kWh</td>
<td style="text-align: center;">74</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">354,780</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">354,780</td>
</tr>
<tr>
<td>Internet connection</td>
<td style="text-align: center;">No incremental cost</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">19,440,000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">19,440,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Maintenance &amp; growth</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>11,400,000</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>10,504,000</strong></td>
</tr>
<tr>
<td>Technical staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">8,400,000</td>
<td style="text-align: center;"><strong><em>64</em></strong></td>
<td style="text-align: center;">7,739,789</td>
</tr>
<tr>
<td>Marketing/admin staff</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">3,000,000</td>
<td style="text-align: center;"><strong><em>28</em></strong></td>
<td style="text-align: center;">2,764,211</td>
</tr>
<tr>
<td>Cybersecurity/miscellaneous</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000,000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000,000</td>
</tr>
<tr>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><strong>Total cost (assume 5Y hardware depreciation)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>234</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>32,744,780</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>31,848,780</strong></td>
</tr>
<tr>
<td>o/w fixed cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">100%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">64%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">66%</td>
</tr>
<tr>
<td>o/w variable cost</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">36%</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">34%</td>
</tr>
<tr>
<td><strong>Payback period on capex (months)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>47.2</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>30.0</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>23.3</strong></td>
</tr>
<tr>
<td><strong>Annual income/loss</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>203</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3,095,220</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>3,991,220</strong></td>
</tr>
<tr>
<td><strong>Profit margin (excl. ETH at stake)</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>46.5%</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>8.6%</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>11.1%</strong></td>
</tr>
</tbody>
</table>
</div><p><em>Illustrative figures can be found <a href="https://docs.google.com/spreadsheets/d/1tr7VJqzJLiywf34_debHa20wfjU5d8db1eYrJWU0i3Q/edit?gid=0#gid=0" rel="noopener nofollow ugc">here</a></em></p>
<p>Due to the presence of a higher proportion of fixed costs, solo stakers (and smaller node operators alike) will show higher sensitivity to changes in staking rewards compared to larger node operators. The corollary is that as MVI reduces staking reward APR, the marginal players may be priced out, leading to a greater centralization of stake. This would exacerbate the already decreasing trend of solo stakers alongside Ethereum’s issuance compression over time.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c75ca71bdb5bbc1207a30f9439fd1dc937b2aa59.png" title="dune_marketshare"><img alt="dune_marketshare" height="411" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c75ca71bdb5bbc1207a30f9439fd1dc937b2aa59_2_690x411.png" width="690" /></a></div><br />
<em>Source: Dune (<a href="https://dune.com/queries/3852057/6478867" rel="noopener nofollow ugc">link</a>)</em><p></p>
<h3><a class="anchor" href="https://ethresear.ch#h-22-lst-dominance-and-cost-modeling-are-inadequate-arguments-for-issuance-reduction-19" name="h-22-lst-dominance-and-cost-modeling-are-inadequate-arguments-for-issuance-reduction-19"></a>2.2. LST dominance and cost-modeling are inadequate arguments for issuance reduction</h3>
<h4><a class="anchor" href="https://ethresear.ch#h-221-issuance-as-a-cost-is-a-reductive-framing-20" name="h-221-issuance-as-a-cost-is-a-reductive-framing-20"></a>2.2.1. Issuance as a cost is a reductive framing</h4>
<p>“Issuance as a cost” concerns the dilution effect on native ETH holders and the potential welfare loss due to externalities like taxes.</p>
<p>The first component focuses on the direct impact of issuance. It redistributes network ownership from unstaked ETH holders to staked ETH holders. High issuance rates force ETH holders to stake to avoid dilution. This increases Ethereum’s security and neutrality but comes with inconvenience and some risk for native ETH holders – which, under MVS, doesn’t qualify as strongly undesirable. Moreover, the cumulative effect could even be seen as beneficial, to the extent that more stake landing with a distributed set of validators justifies investors’ inconvenience.</p>
<p>The second component addresses additional costs for stakers due to taxes. ETH holders who earn staking rewards may face tax obligations, creating additional sell pressure. However, this concern is specific to certain jurisdictions and points in time. Furthermore, the impact of this sell pressure on Ethereum’s overall functionality is questionable. Assuming 3.5% staking rewards, a $400bn ETH market cap, and 30% average taxes paid by all stakers, we get $4.2bn in annual sell pressure. Given Ethereum’s daily trading volume is in billions, absorbing 1% sell pressure over a year seems immaterial. Furthermore, LSTs such as wstETH provide an efficient way to postpone the tax payments, since the tax event is triggered only when wstETH is sold.</p>
<p>Even though ETH market cap is significant in determining attack costs, the relatively minor effect of sell pressure does not provide enough security benefits to justify reducing issuance. The trade-offs include potential staked ETH concentration, loss of sovereignty, and a more substantial decrease in market cap as a result.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-222-stakers-getting-higher-real-vs-nominal-yield-is-not-significant-21" name="h-222-stakers-getting-higher-real-vs-nominal-yield-is-not-significant-21"></a>2.2.2. Stakers getting higher real vs nominal yield is not significant</h4>
<p>This argument, while mathematically beautiful (<a href="https://notes.ethereum.org/@mikeneuder/subsol#3-Scaled-Root-Curve-alternative-issuance" rel="noopener nofollow ugc">link</a>), is not significant in magnitude. It does not affect security and neutrality in any way; in fact, it is not at all clear if there is any benefit to Ethereum in fewer stakers getting higher real yield compared to more stakers getting less real yield. In addition, this analysis assumes concave supply curves with respect to nominal yield, while it is possible that at a higher staking ratio we should adjust our analysis to concave supply curves with respect to real yield.</p>
<h4><a class="anchor" href="https://ethresear.ch#h-223-reducing-lst-dominance-shouldnt-be-a-primary-objective-of-ethereums-monetary-policy-22" name="h-223-reducing-lst-dominance-shouldnt-be-a-primary-objective-of-ethereums-monetary-policy-22"></a>2.2.3. Reducing LST dominance shouldn’t be a primary objective of Ethereum’s monetary policy</h4>
<p>This argument is directly related to security and neutrality, and thus can be analyzed under a security-maximizing framework.</p>
<p>In his article (<a href="https://notes.ethereum.org/@mikeneuder/magnitude-and-direction" rel="noopener nofollow ugc">link</a>) Mike Neuder analyzed various directions and magnitudes of possible Lido attacks on Ethereum in the future. While there are several potential attacks, all of them have a corresponding mitigation plan. Dual governance is at the heart of many of those mitigations. DG is a mechanism that allows stETH holders to slow down Lido’s governance and exit from the protocol before any decision is made. This mechanism is in active and final stages of development (<a href="https://research.lido.fi/t/dual-governance-design-and-implementation-proposal" rel="noopener nofollow ugc">link</a>).</p>
<p>Another argument for issuance reduction is that stETH risks substituting ETH as the de-facto money and collateral. While there is certainly a possibility that LSTs wind up replacing a lot of ETH functionality in DeFi, it does not diminish the moneyness of ETH – all LSTs are underscored by ETH, and thus derive their value from ETH. In order to execute any of these transactions, users will still need ETH to pay for gas, at the very least. Furthermore, ETH will continue to be bridged to various L2s either way, so at a baseline ETH velocity will already decline with broader adoption of L2s, without compromising its moneyness.</p>
<p>Finally, there are unintended consequences to targeting individual applications in an opinionated manner in order to manipulate the viability of ETH as collateral or as commodity money. The long-term roadmap of Ethereum should not be hostage to short-term tactical considerations, least of all on the application layer. The growth of LSTs has allowed the growth of user activity on Ethereum and has also increased the velocity and usage of Ether itself.</p>
<h2><a class="anchor" href="https://ethresear.ch#h-3-putting-it-all-together-23" name="h-3-putting-it-all-together-23"></a>3. Putting it all together</h2>
<p>MVI, as a framework, ultimately suggests to squeeze as much as possible out of staking, so that stakers’ cost and revenue are more or less at the same low rate. The major problem of this approach is that market forces structurally do not reward decentralization, and ultimately drive stake concentration to CEXs, which are entities with the lowest cost validators and the most inelastic customer base. Thus the downside of MVI is undermining the security and neutrality of Ethereum. In our view, the benefits of MVI, such as decreasing the selling pressure from taxes, do not justify taking this risk on balance.</p>
<p>MVS, on the other hand, suggests evaluating monetary policies primarily through the lens of how it affects security and neutrality, the core value propositions of Ethereum. One of the arguments for issuance reduction, namely to tackle LST dominance, indeed falls into MVS focus. However, the security and neutrality concerns of LST dominance are of second order in nature (“if dual governance doesn’t work”, “LST becomes an additional risk layer for all users”, etc). Meanwhile, stake accumulating in CEXs rather than in LSTs, LRTs or even CSPs creates a very real risk of staked ETH concentration with one single entity. As such, we do not see the case where LST dominance risk outweighs the risk of stake concentration with CEXs.</p>
<p>While we presented the MVS framework, and accordingly evaluated the issuance reduction proposal, the natural question stands: what would be the right issuance policy under the MVS approach? This is an incredibly complex and deep question that we would like to explore in future. Some of the directions that we have in mind include:</p>
<ul>
<li>How do we quantifiably measure security? Is there a way for a protocol to see its security? Credit to the contributions from the StakeSure (<a href="https://arxiv.org/abs/2401.05797" rel="noopener nofollow ugc">link</a>) paper in this direction.</li>
<li>Guided by MVS, rather than focusing on value creation through cost reductions, we should instead consider the value creation by improving security and neutrality. There is a heuristic argument that increasing issuance can improve security through making the network more complex via a more diverse validator set. Is there a way to make this precise? How do we make sure that the extra issued ETH strictly improves security and neutrality?</li>
</ul>
<p>Is there a case for a marginal improvement analysis: the more diverse the validator set is, the more complex the network becomes, and improvements to security could have increasing marginal contributions. (Similar to how complexity contributes to entropy and layered security, <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" rel="noopener nofollow ugc">link</a>)</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/f/1f6daf84bc2dfabd3b7747f049d71b9597079ddb.jpeg" title="image"><img alt="image" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/1/f/1f6daf84bc2dfabd3b7747f049d71b9597079ddb_2_690x389.jpeg" width="690" /></a></div><p></p>
<hr />
<p><em>Disclosure: authors are variously affiliated with cyber.fund, Lido DAO, Steakhouse Financial, Progrmd Capital</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/maximum-viable-security-a-new-framing-for-ethereum-issuance/19992">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 06 Jul 2024 21:56:34 +0000</pubDate>
</item>
<item>
<title>Releasing Constantine v0.1.0, a modular cryptography stack for Ethereum</title>
<link>https://ethresear.ch/t/releasing-constantine-v0-1-0-a-modular-cryptography-stack-for-ethereum/19990</link>
<guid>https://ethresear.ch/t/releasing-constantine-v0-1-0-a-modular-cryptography-stack-for-ethereum/19990</guid>
<content:encoded><![CDATA[
<p>I am very proud to release the very first version of <a href="https://github.com/mratsim/constantine" rel="noopener nofollow ugc">Constantine</a>, a high-performance modular cryptography stack for blockchains and proof systems.<br />
It is currently as of July 2024 the fastest implementation of Ethereum-specific cryptographic primitives:</p>
<ul>
<li>BLS signatures</li>
<li>BN254 precompiles (EIP-196 and EIP-197, repriced in EIP-1108)</li>
<li>BLS12-381 precompiles (EIP-2537)</li>
<li>KZG Polynomial commitments (EIP-4844)</li>
</ul>
<p>Constantine has bindings in C, Go, Nim and Rust.</p>
<h2><a class="anchor" href="https://ethresear.ch#history-1" name="history-1"></a>History</h2>
<p>Constantine is written in <a href="https://nim-lang.org/" rel="noopener nofollow ugc">Nim</a>, the language was chosen by Status for Nimbus for its expressiveness, its type system strength, the ease to wrap C and C++ and syntactic closeness to Python so that ethereum/research and PyEVM could be ported with ease.</p>
<p>In February 2018, after woes with C++ in Nimbus, the first library I built was a fixed precision big integer library for uint256.<br />
Then we (at Status) realized that we would also need elliptic curves for secp256k1 and BN254 (also known as BN256 or alt_bn128).</p>
<p>How hard could it be to implement elliptic curves, with cryptographic hardening, once you know how to write big integers?</p>
<p>Turned out it was too hard, after a week or so another approach was taken for time-to-market and correctness reasons:</p>
<ul>
<li>Use libsecp256k1 from Bitcoin</li>
<li>Port 1-1 bncurves from Zcash for BN254</li>
<li>Use Apache Milagro for BLS12-381</li>
</ul>
<p>It was then restarted as a personal side-project in February 2020 after learning a lot from implementing hashing-to-curve and Ethereum BLS signatures and identifying significant performance gap. <em>Note that this predates BLST which was initially released in June 2020.</em></p>
<p>Since then Constantine has seen regular contributions (sometimes with couple months gap) up to where it is today.</p>
<h2><a class="anchor" href="https://ethresear.ch#performance-2" name="performance-2"></a>Performance</h2>
<h3><a class="anchor" href="https://ethresear.ch#ethereum-bls-signatures-consensus-layer-3" name="ethereum-bls-signatures-consensus-layer-3"></a>Ethereum BLS signatures (Consensus Layer)</h3>
<p>Benchmarks are done on an AMD Ryzen 7840U, a low-power ultra-mobile 8-core CPU from 2023.</p>
<h4><a class="anchor" href="https://ethresear.ch#blst-through-nim-blscurve-4" name="blst-through-nim-blscurve-4"></a>BLST (through nim-blscurve)</h4>
<p>Nim-blscurve is the backend of Nimbus-eth2. As Nim compiles to machine code through C (or C++), calling C has zero-overhead from Nim.</p>
<p>Repro.<br />
Install the latest Nim version, Nim v2.0.8.</p>
<pre><code class="lang-auto">git clone https://github.com/status-im/nim-blscurve
cd nim-blscurve
git submodule update --init
nimble bench
</code></pre>
<p>2 benchmarks will be done with 2 different memory management solutions (different implementations of refcounting)<br />
BLST is as-of v0.3.12 (May 2024) with runtime CPU features detection</p>
<pre><code class="lang-auto">Backend: BLST, mode: 64-bit
====================================================================================================================================

Scalar multiplication G1 (255-bit, constant-time)                             10332.180 ops/s        96785 ns/op       318784 cycles
Scalar multiplication G2 (255-bit, constant-time)                              4622.247 ops/s       216345 ns/op       712585 cycles
EC add G1 (constant-time)                                                   1795332.136 ops/s          557 ns/op         1836 cycles
EC add G2 (constant-time)                                                    713775.874 ops/s         1401 ns/op         4617 cycles
------------------------------------------------------------------------------------------------------------------------------------
Pairing (Miller loop + Final Exponentiation)                                   1484.823 ops/s       673481 ns/op      2218271 cycles
------------------------------------------------------------------------------------------------------------------------------------
Hash to G2 (Draft #9) + affine conversion                                      6795.232 ops/s       147162 ns/op       484712 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS signature                                                                  3490.864 ops/s       286462 ns/op       943532 cycles
BLS verification                                                               1212.302 ops/s       824877 ns/op      2716928 cycles
BLS agg verif of 1 msg by 128 pubkeys                                          1139.886 ops/s       877281 ns/op      2889519 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 6 msgs by 6 pubkeys                                                203.231 ops/s      4920498 ns/op     16206824 cycles
Serial batch verify 6 msgs by 6 pubkeys (with blinding)                         359.968 ops/s      2778025 ns/op      9150078 cycles
Parallel batch verify of 6 msgs by 6 pubkeys (with blinding)                    615.452 ops/s      1624822 ns/op      5351722 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 60 msgs by 60 pubkeys                                               20.310 ops/s     49236672 ns/op    162172626 cycles
Serial batch verify 60 msgs by 60 pubkeys (with blinding)                        42.709 ops/s     23414406 ns/op     77120772 cycles
Parallel batch verify of 60 msgs by 60 pubkeys (with blinding)                  250.298 ops/s      3995236 ns/op     13159139 cycles
------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 180 msgs by 180 pubkeys                                              6.746 ops/s    148237745 ns/op    488256390 cycles
Serial batch verify 180 msgs by 180 pubkeys (with blinding)                      14.419 ops/s     69354258 ns/op    228434104 cycles
Parallel batch verify of 180 msgs by 180 pubkeys (with blinding)                 99.467 ops/s     10053540 ns/op     33113513 cycles
------------------------------------------------------------------------------------------------------------------------------------

Using nthreads = 16. The number of threads can be changed with TP_NUM_THREADS environment variable.
</code></pre>
<h4><a class="anchor" href="https://ethresear.ch#constantine-5" name="constantine-5"></a>Constantine</h4>
<p>GCC generates poor code everwhere assembly is not used, hence we force Clang as a compiler.</p>
<pre><code class="lang-auto">git clone https://github.com/mratsim/constantine
cd constantine
CC=clang nimble bench_eth_bls_signatures
</code></pre>
<pre><code class="lang-auto">--------------------------------------------------------------------------------------------------------------------------------------------------
Pubkey deserialization (full checks)                                                     BLS12_381 G1          22295.550 ops/s         44852 ns/op        147729 CPU cycles (approx)
Pubkey deserialization (skip checks)                                                     BLS12_381 G1          92515.496 ops/s         10809 ns/op         35602 CPU cycles (approx)
Signature deserialization (full checks)                                                  BLS12_381 G2          16808.418 ops/s         59494 ns/op        195958 CPU cycles (approx)
Signature deserialization (skip checks)                                                  BLS12_381 G2          46453.291 ops/s         21527 ns/op         70906 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS signature                                                                            BLS12_381 G2           4005.078 ops/s        249683 ns/op        822392 CPU cycles (approx)
BLS verification                                                                         BLS12_381              1498.960 ops/s        667129 ns/op       2197347 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS agg verif of 1 msg by 128 pubkeys                                                    BLS12_381              1423.694 ops/s        702398 ns/op       2313504 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 6 msgs by 6 pubkeys                                                         BLS12_381               249.683 ops/s       4005085 ns/op      13191614 CPU cycles (approx)
BLS serial batch verify of 6 msgs by 6 pubkeys (with blinding)                           BLS12_381               420.912 ops/s       2375795 ns/op       7825187 CPU cycles (approx)
BLS parallel batch verify (16 threads) of 6 msgs by 6 pubkeys (with blinding)            BLS12_381               683.399 ops/s       1463273 ns/op       4819062 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 60 msgs by 60 pubkeys                                                       BLS12_381                24.863 ops/s      40220998 ns/op     132477024 CPU cycles (approx)
BLS serial batch verify of 60 msgs by 60 pubkeys (with blinding)                         BLS12_381                48.878 ops/s      20459201 ns/op      67387049 CPU cycles (approx)
BLS parallel batch verify (16 threads) of 60 msgs by 60 pubkeys (with blinding)          BLS12_381               280.961 ops/s       3559207 ns/op      11722847 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
BLS verif of 180 msgs by 180 pubkeys                                                     BLS12_381                 8.334 ops/s     119995222 ns/op     395232558 CPU cycles (approx)
BLS serial batch verify of 180 msgs by 180 pubkeys (with blinding)                       BLS12_381                16.488 ops/s      60650899 ns/op     199767961 CPU cycles (approx)
BLS parallel batch verify (16 threads) of 180 msgs by 180 pubkeys (with blinding)        BLS12_381               112.215 ops/s       8911481 ns/op      29351939 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------------------------
</code></pre>
<h4><a class="anchor" href="https://ethresear.ch#analysis-6" name="analysis-6"></a>Analysis</h4>
<ul>
<li>15% performance improvement on signatures</li>
<li>24% performance improvement on verification</li>
</ul>
<p>Furthermore, it is in theory possible to achieve a 2x performance improvement for signing if there is a need for it.</p>
<h3><a class="anchor" href="https://ethresear.ch#kzg-polynomial-commitment-for-eip-4844-consensus-layer-7" name="kzg-polynomial-commitment-for-eip-4844-consensus-layer-7"></a>KZG Polynomial commitment for EIP-4844 (Consensus Layer)</h3>
<p>I will reuse my benchmarks from Dec, 2023: <a class="inline-onebox" href="https://github.com/mratsim/constantine/pull/304#issuecomment-1844795359" rel="noopener nofollow ugc">Productionize KZG EIP-4844 by mratsim · Pull Request #304 · mratsim/constantine · GitHub</a></p>
<div class="md-table">
<table>
<thead>
<tr>
<th style="text-align: center;">Bench</th>
<th style="text-align: center;">c-kzg-4844 (serial)</th>
<th style="text-align: center;">go-kzg-4844 (serial)</th>
<th style="text-align: center;">go-kzg-4844 (parallel)</th>
<th style="text-align: center;">constantine (serial)</th>
<th style="text-align: center;">constantine (parallel)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">blob_to_kzg_commitment</td>
<td style="text-align: center;">37.773 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.823 ms</td>
<td style="text-align: center;">23.765 ms</td>
<td style="text-align: center;">4.425 ms</td>
</tr>
<tr>
<td style="text-align: center;">compute_kzg_proof</td>
<td style="text-align: center;">39.945 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.146 ms</td>
<td style="text-align: center;">24.255 ms</td>
<td style="text-align: center;">4.710 ms</td>
</tr>
<tr>
<td style="text-align: center;">compute_blob_kzg_proof</td>
<td style="text-align: center;">40.212 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.205 ms</td>
<td style="text-align: center;">24.288 ms</td>
<td style="text-align: center;">4.794 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_kzg_proof</td>
<td style="text-align: center;">0.915 ms</td>
<td style="text-align: center;">0.923 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.782 ms</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof</td>
<td style="text-align: center;">1.531 ms</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1.390 ms</td>
<td style="text-align: center;">1.266 ms</td>
<td style="text-align: center;">1.113 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 1</td>
<td style="text-align: center;">1.528 ms</td>
<td style="text-align: center;">1.392 ms</td>
<td style="text-align: center;">1.405 ms</td>
<td style="text-align: center;">1.286 ms</td>
<td style="text-align: center;">1.130 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 2</td>
<td style="text-align: center;">2.589 ms</td>
<td style="text-align: center;">3.233 ms</td>
<td style="text-align: center;">1.591 ms</td>
<td style="text-align: center;">2.006 ms</td>
<td style="text-align: center;">1.152 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 4</td>
<td style="text-align: center;">4.553 ms</td>
<td style="text-align: center;">4.671 ms</td>
<td style="text-align: center;">1.914 ms</td>
<td style="text-align: center;">3.437 ms</td>
<td style="text-align: center;">1.250 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 8</td>
<td style="text-align: center;">8.446 ms</td>
<td style="text-align: center;">7.410 ms</td>
<td style="text-align: center;">2.738 ms</td>
<td style="text-align: center;">6.115 ms</td>
<td style="text-align: center;">1.891 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 16</td>
<td style="text-align: center;">16.228 ms</td>
<td style="text-align: center;">12.734 ms</td>
<td style="text-align: center;">3.542 ms</td>
<td style="text-align: center;">11.567 ms</td>
<td style="text-align: center;">3.091 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 32</td>
<td style="text-align: center;">32.016 ms</td>
<td style="text-align: center;">23.048 ms</td>
<td style="text-align: center;">7.215 ms</td>
<td style="text-align: center;">21.779 ms</td>
<td style="text-align: center;">6.764 ms</td>
</tr>
<tr>
<td style="text-align: center;">verify_blob_kzg_proof_batch 64</td>
<td style="text-align: center;">63.415 ms</td>
<td style="text-align: center;">43.224 ms</td>
<td style="text-align: center;">14.438 ms</td>
<td style="text-align: center;">43.099 ms</td>
<td style="text-align: center;">11.538 ms</td>
</tr>
</tbody>
</table>
</div><ul>
<li>A 37% performance improvement over c-kzg-4844 for serial commitment</li>
<li>A 39% improvement for proof generation</li>
<li>A 17% improvement for a single blob verification</li>
<li>A 32% improvement for 64 blob verification</li>
</ul>
<p>And Constantine offers paralellization to improve those numbers 4~6x on my 8-core machine.</p>
<h3><a class="anchor" href="https://ethresear.ch#evm-precompiles-execution-layer-8" name="evm-precompiles-execution-layer-8"></a>EVM precompiles (Execution Layer)</h3>
<p>Note:</p>
<ul>
<li>Constantine also offers a fast MODEXP precompile that reaches 80% to 110% of GMP, without assembly.</li>
<li>SHA256 is faster than OpenSSL and BLST for data size less than 4MB and within 3% otherwise.</li>
</ul>
<pre><code class="lang-auto">git clone https://github.com/mratsim/constantine
cd constantine
CC=clang nimble bench_eth_evm_precompiles
</code></pre>
<pre><code class="lang-auto">--------------------------------------------------------------------------------------------------------------------------------
SHA256 -  32 bytes            72 gas    1714.29 MGas/s    23809523.810 ops/s           42 ns/op          140 CPU cycles (approx)
SHA256 -  64 bytes            84 gas    1584.91 MGas/s    18867924.528 ops/s           53 ns/op          176 CPU cycles (approx)
SHA256 -  96 bytes            96 gas    1777.78 MGas/s    18518518.519 ops/s           54 ns/op          179 CPU cycles (approx)
SHA256 - 128 bytes           108 gas    1333.33 MGas/s    12345679.012 ops/s           81 ns/op          267 CPU cycles (approx)
SHA256 - 160 bytes           120 gas    1481.48 MGas/s    12345679.012 ops/s           81 ns/op          268 CPU cycles (approx)
SHA256 - 192 bytes           132 gas    1233.64 MGas/s     9345794.393 ops/s          107 ns/op          353 CPU cycles (approx)
SHA256 - 224 bytes           144 gas    1321.10 MGas/s     9174311.927 ops/s          109 ns/op          359 CPU cycles (approx)
SHA256 - 256 bytes           156 gas    1130.43 MGas/s     7246376.812 ops/s          138 ns/op          454 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BN254_G1ADD                  150 gas      87.41 MGas/s      582750.583 ops/s         1716 ns/op         5652 CPU cycles (approx)
BN254_G1MUL                 6000 gas     229.66 MGas/s       38276.047 ops/s        26126 ns/op        86050 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BN254_PAIRINGCHECK 1       79000 gas     166.99 MGas/s        2113.754 ops/s       473092 ns/op      1558009 CPU cycles (approx)
BN254_PAIRINGCHECK 2      113000 gas     191.99 MGas/s        1699.056 ops/s       588562 ns/op      1938370 CPU cycles (approx)
BN254_PAIRINGCHECK 3      147000 gas     183.15 MGas/s        1245.930 ops/s       802613 ns/op      2642801 CPU cycles (approx)
BN254_PAIRINGCHECK 4      181000 gas     191.76 MGas/s        1059.434 ops/s       943900 ns/op      3108745 CPU cycles (approx)
BN254_PAIRINGCHECK 5      215000 gas     169.72 MGas/s         789.374 ops/s      1266827 ns/op      4171120 CPU cycles (approx)
BN254_PAIRINGCHECK 6      249000 gas     181.10 MGas/s         727.321 ops/s      1374909 ns/op      4528210 CPU cycles (approx)
BN254_PAIRINGCHECK 7      283000 gas     189.03 MGas/s         667.965 ops/s      1497084 ns/op      4930714 CPU cycles (approx)
BN254_PAIRINGCHECK 8      317000 gas     204.18 MGas/s         644.095 ops/s      1552566 ns/op      5113680 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_G1ADD                  500 gas     164.10 MGas/s      328191.664 ops/s         3047 ns/op        10034 CPU cycles (approx)
BLS12_G2ADD                  800 gas     161.75 MGas/s      202183.583 ops/s         4946 ns/op        16289 CPU cycles (approx)
BLS12_G1MUL                12000 gas     141.66 MGas/s       11805.400 ops/s        84707 ns/op       279001 CPU cycles (approx)
BLS12_G2MUL                45000 gas     325.51 MGas/s        7233.639 ops/s       138243 ns/op       455333 CPU cycles (approx)
BLS12_MAP_FP_TO_G1          5500 gas     161.82 MGas/s       29422.149 ops/s        33988 ns/op       111947 CPU cycles (approx)
BLS12_MAP_FP2_TO_G2        75000 gas     659.96 MGas/s        8799.486 ops/s       113643 ns/op       374305 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_PAIRINGCHECK 1      108000 gas     216.83 MGas/s        2007.665 ops/s       498091 ns/op      1640562 CPU cycles (approx)
BLS12_PAIRINGCHECK 2      151000 gas     222.00 MGas/s        1470.214 ops/s       680173 ns/op      2240287 CPU cycles (approx)
BLS12_PAIRINGCHECK 3      194000 gas     219.98 MGas/s        1133.901 ops/s       881911 ns/op      2904762 CPU cycles (approx)
BLS12_PAIRINGCHECK 4      237000 gas     222.97 MGas/s         940.782 ops/s      1062946 ns/op      3500927 CPU cycles (approx)
BLS12_PAIRINGCHECK 5      280000 gas     221.08 MGas/s         789.576 ops/s      1266502 ns/op      4171417 CPU cycles (approx)
BLS12_PAIRINGCHECK 6      323000 gas     223.09 MGas/s         690.679 ops/s      1447851 ns/op      4768780 CPU cycles (approx)
BLS12_PAIRINGCHECK 7      366000 gas     222.28 MGas/s         607.311 ops/s      1646603 ns/op      5423299 CPU cycles (approx)
BLS12_PAIRINGCHECK 8      409000 gas     221.94 MGas/s         542.640 ops/s      1842844 ns/op      6069597 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_G1MSM   2            21312 gas     120.40 MGas/s        5649.430 ops/s       177009 ns/op       583004 CPU cycles (approx)
BLS12_G1MSM   4            30768 gas     101.53 MGas/s        3299.960 ops/s       303034 ns/op       998108 CPU cycles (approx)
BLS12_G1MSM   8            43488 gas      81.23 MGas/s        1867.787 ops/s       535393 ns/op      1763434 CPU cycles (approx)
BLS12_G1MSM  16            64128 gas      66.43 MGas/s        1035.864 ops/s       965378 ns/op      3179510 CPU cycles (approx)
BLS12_G1MSM  32           103296 gas      57.99 MGas/s         561.362 ops/s      1781382 ns/op      5867248 CPU cycles (approx)
BLS12_G1MSM  64           170496 gas      50.89 MGas/s         298.504 ops/s      3350039 ns/op     11034035 CPU cycles (approx)
BLS12_G1MSM 128           267264 gas      42.24 MGas/s         158.035 ops/s      6327700 ns/op     20841720 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
BLS12_G2MSM   2            79920 gas     269.62 MGas/s        3373.637 ops/s       296416 ns/op       976301 CPU cycles (approx)
BLS12_G2MSM   4           115380 gas     225.12 MGas/s        1951.109 ops/s       512529 ns/op      1688121 CPU cycles (approx)
BLS12_G2MSM   8           163080 gas     177.21 MGas/s        1086.654 ops/s       920256 ns/op      3031066 CPU cycles (approx)
BLS12_G2MSM  16           240480 gas     130.56 MGas/s         542.920 ops/s      1841892 ns/op      6066436 CPU cycles (approx)
BLS12_G2MSM  32           387360 gas     126.36 MGas/s         326.195 ops/s      3065648 ns/op     10097244 CPU cycles (approx)
BLS12_G2MSM  64           639360 gas     118.26 MGas/s         184.965 ops/s      5406423 ns/op     17807268 CPU cycles (approx)
BLS12_G2MSM 128          1002240 gas     100.70 MGas/s         100.471 ops/s      9953136 ns/op     32782906 CPU cycles (approx)
--------------------------------------------------------------------------------------------------------------------------------
</code></pre>
<p>Constantine achieves over 200Mgas/s for a wide range of cryptographic precompiles on a laptop CPU with restricted power consumption (7840U, 15W to 30W)</p>
<p>note, I suggest a repricing for EIP-2537 to help SNARKS applications.</p>
<h2><a class="anchor" href="https://ethresear.ch#security-9" name="security-9"></a>Security</h2>
<p>Constantine, as it names indicates, as a strong focus on security and especially constant-time cryptography is used by default in the core of the library.<br />
It HAS NOT been audited yet, but it has undergone extensive fuzzing by Guido Vranken, thanks to the sponsoring of the Ethereum Foundation in Summer 2023. It has also been added to OSS-Fuzz (<a class="inline-onebox" href="https://github.com/google/oss-fuzz/pull/10710" rel="noopener nofollow ugc">[bls-signatures] Remove Chia, add Constantine by guidovranken · Pull Request #10710 · google/oss-fuzz · GitHub</a>), the Google 24/7 open-source fuzzing initiative.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-future-10" name="the-future-10"></a>The Future</h2>
<p>Constantine will follow and support future Ethereum cryptographic needs. In particular I thank the Ethereum Foundation Fellowship Program and Status for sponsoring work on implementing Verkle Tries in Constantine the past year.</p>
<p>Constantine also supports accelerating Zero-Knowledge proof systems, for example it is possible to use it through PSE (Privacy Scaling Explorations, a branch of the EF) Halo2: <a class="inline-onebox" href="https://github.com/mratsim/constantine/pull/308" rel="noopener nofollow ugc">ZAL: ZK Accel Layer by mratsim · Pull Request #308 · mratsim/constantine · GitHub</a>.</p>
<p>Constantine is has the fastest MSM on x86, all libraries benchmarked as of July 2024 (Arkworks, Barretenberg, Bellman, Gnark, Halo2) and by a factor 2x over popular Rust libraries Arkworks and Halo2. And I do plan to build proof systems on top.</p>
<p>Hidden in Constantine is a compiler for GPU code generation and there are plans for accelerating ARM.</p>
<p>Now I don’t know what a snarkified EVM will look like, but I certainly hope to contribute to make it a reality.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/releasing-constantine-v0-1-0-a-modular-cryptography-stack-for-ethereum/19990">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 06 Jul 2024 11:01:41 +0000</pubDate>
</item>
<item>
<title>Reputation-Centric Light Client Framework for Optimistic Rollups</title>
<link>https://ethresear.ch/t/reputation-centric-light-client-framework-for-optimistic-rollups/19988</link>
<guid>https://ethresear.ch/t/reputation-centric-light-client-framework-for-optimistic-rollups/19988</guid>
<content:encoded><![CDATA[
<div> 关键词：声誉系统、乐观rollup、Herodotus数据处理器、存储证明、快速最终性

总结:<br />
本文提出了一种基于声誉的轻客户端框架，旨在优化乐观rollup（ORU）的性能，特别是缩短最终性时间。框架核心是Herodotus数据处理器，通过计算sequencer的历史行为信誉分数，如无挑战记录和输出根的有效性，允许轻客户端信任信誉良好的sequencer的输出根，无需等待完整的争议期。系统还包括惩罚机制和备份机制，以确保安全性和可靠性。该方法有望改善用户体验并推动L2生态发展。 <div>
<p>Authors: <a href="https://x.com/0xmarcello" rel="noopener nofollow ugc">Marcello Bardus</a> (<a href="https://x.com/HerodotusDev" rel="noopener nofollow ugc">Herodotus</a>), <a href="https://x.com/kacperkozi" rel="noopener nofollow ugc">Kacper Koziol</a> (<a href="https://x.com/HerodotusDev" rel="noopener nofollow ugc">Herodotus</a>)</p>
<p>Thanks for early feedback: <a href="https://x.com/bonustrack87" rel="noopener nofollow ugc">bonustrack87</a> (<a href="https://x.com/SnapshotLabs" rel="noopener nofollow ugc">Snapshot Labs</a>), <a href="https://x.com/lsukernik" rel="noopener nofollow ugc">Larry Sukernik</a> (<a href="https://x.com/hi_reverie" rel="noopener nofollow ugc">Reverie</a>), <a href="https://x.com/piapark_eth" rel="noopener nofollow ugc">Pia Park</a> (<a href="https://x.com/HerodotusDev" rel="noopener nofollow ugc">Herodotus</a>), <a href="https://x.com/wojtekwtf" rel="noopener nofollow ugc">Wojtek</a> (<a href="https://www.supercast.xyz/" rel="noopener nofollow ugc">Supercast</a>),</p>
<h1><a class="anchor" href="https://ethresear.ch#summary-1" name="summary-1"></a>Summary:</h1>
<p>This post introduces a conceptual framework for a reputation-centric light client system designed to address critical challenges in Optimistic Rollups (ORUs), with a primary focus on enabling fast finality for accessing ORU data from Ethereum, ORUs and other Ethereum layers. At its core, the system leverages the Herodotus Data Processor to compute sequencer reputation scores based on the sequencer’s historical behavior, including their track record of submitting valid output roots and avoiding successful challenges. This allows light clients to trust output roots only from sequencers with an impeccable track record without waiting for the full dispute period. This approach significantly reduces finality time while maintaining security. The framework includes a punitive measure that resets a sequencer’s reputation upon successful challenges, ensuring system integrity. Additionally, a fallback mechanism reverts to the standard seven-day dispute period in cases of unresolved conflicts or detected irregularities.</p>
<h3><a class="anchor" href="https://ethresear.ch#reputation-centric-light-client-framework-for-optimistic-rollups-2" name="reputation-centric-light-client-framework-for-optimistic-rollups-2"></a>Reputation-Centric Light Client Framework for Optimistic Rollups</h3>
<p>Optimistic Rollups have seen significant adoption, however, they encounter several challenges, particularly in terms of finality time and data verification. This post introduces a conceptual framework for a reputation-centric light client system that aims to address these issues, enabling fast finality for accessing ORU data from Ethereum, and from other Ethereum layers.</p>
<p>OP Stack and other Optimistic Rollups (ORUs) have a security model based on fraud proofs. In this model, anyone can act as a sequencer, also known as a proposer. The sequencer first proposes the rollup state to Layer 1 (L1), after which a seven-day window is opened. During this period, anyone can challenge the correctness of the proposed state.</p>
<p>In ORU implementations such as OP Stack, proposers periodically submit output roots to L1. These output roots are a hash of certain L2 state information, including the state root, block number, and timestamp of the latest L2 block. OP Stack incorporates a specification for a fault proof system with bonding, which creates incentives for proposers to submit correct output roots.</p>
<p>This mechanism imposes a long finality time for ORUs, which is problematic for Storage Proofs, a secure on-chain data access solution that Herodotus has previously developed for Optimism and several other ORU ecosystems. This is especially problematic following recent upgrades that introduced permissionless fraud proofs on Optimism. With these upgrades, no assumptions can be made about where a valid state root can be found.</p>
<h2><a class="anchor" href="https://ethresear.ch#secure-data-access-and-processing-3" name="secure-data-access-and-processing-3"></a>Secure Data Access and Processing</h2>
<p>The framework incorporates two crucial components:</p>
<h3><a class="anchor" href="https://ethresear.ch#storage-proofs-4" name="storage-proofs-4"></a>Storage Proofs</h3>
<p>Storage Proofs are a secure on-chain data access primitive utilized by the Herodotus Data Processor that enables the cryptographic proving of the provenance of on-chain data. They allow for the verification of any data available on Ethereum, including current and historical balances, transactions, user interactions, liquidations, and more. Storage Proofs also enable the trustless and secure reading of data from arbitrary Ethereum Layers.</p>
<p>By utilizing Storage Proofs, the Herodotus Data Processor can ensure the integrity and authenticity of the on-chain data it processes, providing a foundation of trust for its computations.</p>
<h3><a class="anchor" href="https://ethresear.ch#data-processing-component-5" name="data-processing-component-5"></a>Data Processing Component</h3>
<p>This would leverage the Herodotus Data Processor (HDP) to compute sequencer reputation scores efficiently. HDP can be thought of as a zk-coprocessor, capable of performing computations on verified data. Storage Proofs guarantee the integrity of the input data to HDP. Custom computations can be defined using HDP Modules, which can later process the verified historical data and update reputation scores based on the defined criteria, such as the consistency of avoiding challenges and the validity of proposed output roots over time.</p>
<h2><a class="anchor" href="https://ethresear.ch#reputation-based-light-client-6" name="reputation-based-light-client-6"></a>Reputation based light client</h2>
<p>In our design, a sequencer, identified by an Ethereum address, would be assumed to be the most trustworthy based on the following criteria:</p>
<ul>
<li>The sequencer consistently avoids challenges, or any initiated challenges against them are unsuccessful.</li>
<li>The validity of the sequencer’s proposed output roots over time, as proven by the lack of successful fault proofs against their outputs.</li>
</ul>
<p>In OP Stack implementations like Bedrock, and potentially in other ORUs, output roots represent a compact summary of the L2 state at a specific block. These output roots are not Merkle roots of the entire canonical L2 chain, but rather a hash of certain L2 state information. Bonded proposers periodically submit these output roots to L1.</p>
<p>The output root typically includes a hash of the following information:</p>
<ol>
<li>The state root of the L2 block</li>
<li>The L2 block number</li>
<li>The timestamp of the L2 block</li>
<li>The hash of the L2 block itself</li>
</ol>
<p>This structure allows for efficient verification of specific L2 state information without requiring the entire L2 chain data on L1.</p>
<p>Once a highly reputable sequencer posts a claimed output root to L1, a Light Client contract would assume the claim is valid and treat it as final. This approach ensures that only sequencers with an impeccable track record are trusted, significantly reducing the finality time while relying on the cryptographically proven historical reliability of the sequencer rather than waiting for the full dispute period.</p>
<p>The Light Client contract would store the full output roots proposed by reputable sequencers, not just the block hash, enabling trustless proof of claims like withdrawals against the output roots directly.</p>
<p>The reputation of the sequencer can be periodically updated using the Herodotus Data Processor. This involves assessing historical data to ensure the sequencer continues to meet the criteria of reliability and activity. By continuously evaluating the sequencer’s performance and updating their reputation at fixed intervals, the Light Client can maintain a high level of trust and accuracy in the state roots it accepts.</p>
<h2><a class="anchor" href="https://ethresear.ch#system-architecture-7" name="system-architecture-7"></a>System Architecture</h2>
<h2><a class="anchor" href="https://ethresear.ch#h-326x4111935069506181uploadpmywafztk4c8h3awxejv5ig72gppng-8" name="h-326x4111935069506181uploadpmywafztk4c8h3awxejv5ig72gppng-8"></a><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/4/b4b3807ab51eeeb259a9c7c08890b13cd0910b23.png" title="|326x411.1935069506181"><img alt="|326x411.1935069506181" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/4/b4b3807ab51eeeb259a9c7c08890b13cd0910b23_2_396x500.png" width="396" /></a></div></h2>
<p>The proposed system would operate as follows:</p>
<ol>
<li>Proposers submit output root proposals to the appropriate ORU contracts on L1, based on the state of the ORU L2 chain.</li>
<li>The ORU L1 contracts handle both output root proposals and challenges/fault proofs against these proposals.</li>
<li>The Herodotus Data Processor retrieves and processes data from the ORU L1 contracts, including output root proposals and challenges/fault proofs.</li>
<li>The reputation-based light client contract uses the processed data from the Herodotus Data Processor to track sequencer reputation scores and store trusted output roots. A custom reputation calculation formula can be implemented, allowing for flexible and adaptable assessment of sequencer reliability based on various factors and weighting systems as deemed appropriate for the specific ORU implementation.</li>
<li>The light client interface allows other contracts to query the state root of the L2 chain based on the most reputable sequencer’s output roots.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#handling-successful-challenges-9" name="handling-successful-challenges-9"></a>Handling Successful Challenges</h2>
<p>In the event that any challenge against a sequencer is successful, the reputation of the sequencer would immediately reset to zero in the light client. This punitive measure ensures that only sequencers with an impeccable track record maintain trusted status.</p>
<p>With fault proof systems like those in OP Stack’s Bedrock, the Light Client contract would automatically reset a sequencer’s reputation to zero if a fault proof is successfully submitted and verified, showing an invalid output root proposed by that sequencer. This automated process ensures swift and consistent enforcement of the reputation system.</p>
<p>The permissionless output proposal mechanism provides an objective way to track sequencer reputation over time and identify potentially malicious outputs. Simultaneously, the output roots proposed by sequencers enable the verification of Storage Proofs against these proposed L2 state roots when using the Light Client. Ultimately, this approach creates a self-regulating system that not only incentivizes honest behavior but also ensures quick penalization of any attempts at fraud, thereby maintaining the overall reliability and security of the network.</p>
<h3><a class="anchor" href="https://ethresear.ch#fallback-mechanism-10" name="fallback-mechanism-10"></a>Fallback Mechanism</h3>
<p>In cases of unresolved conflicts or when the system detects any irregularities, it would automatically fall back to the conservative seven-day dispute period. This would ensure that the system remains secure and trustworthy, even in the face of unexpected challenges or disagreements among reputable sequencers.</p>
<h2><a class="anchor" href="https://ethresear.ch#potential-impact-and-future-directions-11" name="potential-impact-and-future-directions-11"></a>Potential Impact and Future Directions</h2>
<p>We believe that this reputation-based light client framework has the potential to significantly decrease duration to finality for ORUs. By reducing finality times while maintaining security, it could substantially improve the user experience and enable new use cases in L2 ecosystems.</p>
<p>As we continue to explore and refine this concept, we welcome input from the community. The next steps would involve further theoretical analysis, simulations, and potentially, prototype implementations.</p>
<h1><a class="anchor" href="https://ethresear.ch#references-12" name="references-12"></a>References</h1>
<p>Optimism Bedrock Documentation: <a class="inline-onebox" href="https://community.optimism.io/docs/developers/bedrock" rel="noopener nofollow ugc">Bedrock Explainer | Optimism Docs</a></p>
<p>L2 Output Root Proposals Specification: <a class="inline-onebox" href="https://github.com/ethereum-optimism/optimism/blob/65ec61dde94ffa93342728d324fecf474d228e1f/specs/proposals.md" rel="noopener nofollow ugc">optimism/specs/proposals.md at 65ec61dde94ffa93342728d324fecf474d228e1f · ethereum-optimism/optimism · GitHub</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/reputation-centric-light-client-framework-for-optimistic-rollups/19988">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 22:01:41 +0000</pubDate>
</item>
<item>
<title>Protocol Asset: canonical tokenized asset with the most social consensus preference of protocol</title>
<link>https://ethresear.ch/t/protocol-asset-canonical-tokenized-asset-with-the-most-social-consensus-preference-of-protocol/19983</link>
<guid>https://ethresear.ch/t/protocol-asset-canonical-tokenized-asset-with-the-most-social-consensus-preference-of-protocol/19983</guid>
<content:encoded><![CDATA[
<div> 关键词：Protocol Asset、社交共识、兼容性、Tokenized、价值体现

总结:
Protocol Asset是一种新型概念，它代表了开放协议或社区标准中最受欢迎的社会共识首选的代币化资产。这类资产如ORDI（Ordinal协议的代表）和Pandora（ERC-404的代表），特点是被广泛接受、完全兼容其底层协议，并承载着该协议的价值。它们不仅是理论与实践的结合体，而且其价值和安全性依赖于社会共识，而非仅仅依赖区块链网络。社交层的共识确保了这些资产作为各自标准的权威象征。 <div>
<p>Idea initiated by <a href="https://x.com/0xozeth" rel="noopener nofollow ugc">0xOZ.eth</a>. Thanks <a href="https://twitter.com/mkkb2156" rel="noopener nofollow ugc">Makd</a> for discussion.</p>
<p>We introduced a new concept: Protocol Asset. Protocol Asset represents canonical tokenized asset with the most social consensus preference of open protocol or community standard.</p>
<p>For example, ORDI is the protocol asset of Ordinal protocol, and Pandora is the protocol asset of ERC-404.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-1" name="background-1"></a>Background</h2>
<p>The evolution of blockchain and crypto has led to the emergence of various standards and protocols, each designed to address specific challenges or enable new functionalities. Notable examples include the Ethereum Improvement Proposals (EIPs) and Ethereum Request for Comments (ERCs) standards, and Ordinal theory with its Inscription protocol.</p>
<p>Despite the establishment of these standards, identifying the materialized asset associated with an open standard remains challenging. For instance, even in the case of ERC standards, which often include a reference implementation, pinpointing a specific instance deployed based on this implementation is not straightforward.</p>
<h2><a class="anchor" href="https://ethresear.ch#concept-2" name="concept-2"></a>Concept</h2>
<p>A Protocol Asset represents a canonical tokenized asset that aligns with the most socially accepted preferences of an open protocol or community standard.</p>
<h3><a class="anchor" href="https://ethresear.ch#characteristics-of-protocol-assets-3" name="characteristics-of-protocol-assets-3"></a>Characteristics of Protocol Assets</h3>
<p>To qualify as a Protocol Asset, it must be:</p>
<ul>
<li><strong>Tokenized and Ownable</strong>: The asset should be a materialized token that can be owned.</li>
<li><strong>Fully Compatible</strong>: The asset must be entirely compatible with the underlying protocol and standard.</li>
<li><strong>Socially Favored</strong>: The asset should be canonically preferred from a social consensus perspective.</li>
</ul>
<p>Typically, the Protocol Asset is the first implementation or instance of the protocol or standard.</p>
<h3><a class="anchor" href="https://ethresear.ch#value-encapsulation-4" name="value-encapsulation-4"></a>Value Encapsulation</h3>
<p>Protocol Assets encapsulate the value inherent in the protocols and standards they represent. They serve as the tangible manifestation of the protocol’s principles, ensuring that the theoretical and practical aspects of the protocol are embodied in a specific, widely recognized asset.</p>
<h3><a class="anchor" href="https://ethresear.ch#social-consensus-and-security-5" name="social-consensus-and-security-5"></a>Social Consensus and Security</h3>
<p>It’s crucial to understand that the security and recognition of token standards, such as ERC-20, are fundamentally based on social consensus rather than being directly secured by the Ethereum network. As Dankrad Feist aptly pointed out, “You have been lied to about ERC-20s. They aren’t secured by Ethereum. It’s just social consensus; any ERC-20 community can just fork away.”</p>
<p>This highlights that the value and trust in these tokens derive from the community’s agreement and collective support. This social layer of consensus is what ultimately secures the token, making it the canonical representation of its respective protocol.</p>
<h2><a class="anchor" href="https://ethresear.ch#examples-6" name="examples-6"></a>Examples</h2>
<h3><a class="anchor" href="https://ethresear.ch#ordi-7" name="ordi-7"></a>ORDI</h3>
<p>ORDI is the Protocol Asset of the Ordinal protocol. It represents the canonical tokenized asset for this protocol, favored by social consensus and adhering to the standards set forth by the Ordinal protocol.</p>
<h3><a class="anchor" href="https://ethresear.ch#pandora-8" name="pandora-8"></a>Pandora</h3>
<p>Pandora serves as the Protocol Asset for ERC-404. As with ORDI, Pandora is the materialized token that aligns with the social consensus and standards of the ERC-404 protocol, representing its values and functionalities in a tangible form.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/protocol-asset-canonical-tokenized-asset-with-the-most-social-consensus-preference-of-protocol/19983">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 17:54:05 +0000</pubDate>
</item>
<item>
<title>Gossipsub Message Propagation Latency</title>
<link>https://ethresear.ch/t/gossipsub-message-propagation-latency/19982</link>
<guid>https://ethresear.ch/t/gossipsub-message-propagation-latency/19982</guid>
<content:encoded><![CDATA[
<div> 关键词：Gossipsub、Ethereum、Message propagation latency、Hermes、Lodestar

总结:
研究团队ProbeLab通过工具Hermes对Ethereum P2P网络中的Gossipsub消息传播延迟进行了调查，以确定哪些协议组件消耗了最大的网络带宽。结果显示，98%的消息能在4秒内送达，而Lodestar客户端的接收时间相对较慢，但可能与其特定实现有关。节点位置靠近网络核心的节点通常能更快接收消息，但过度地理集中可能会加剧这种差异。尽管如此，总体上各节点的表现符合4秒内的要求，显示出网络的稳定性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-and-tldr-1" name="summary-and-tldr-1"></a>Summary and TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io </a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the <a href="https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952">Ethereum Node Message Propagation Bandwidth Consumption</a>, in this post we investigate <strong>Gossipsub’s message propagation latency</strong>, i.e., how long it takes to have a message delivered to all nodes in the network. The target of the study is to identify the protocol components that consume the biggest share of network bandwidth. The study has been co-authored by <a class="mention" href="https://ethresear.ch/u/cortze">@cortze</a> and <a class="mention" href="https://ethresear.ch/u/yiannisbot">@yiannisbot</a>.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer.</a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions.</p>
<p><strong>Study Description:</strong> Message propagation and arrival times are sensitive metrics for blockchain networks. We assume that the message is going to arrive to each peer “as fast as possible”, but in some cases, just because the core of the network achieved fast message delivery time, doesn’t mean that  message propagation to the entire network was done in time.</p>
<p>In the particular case of Ethereum, with such strict message delivery deadlines, ensuring the messages arrive within a 4-second window is essential to reduce the probability of forks.</p>
<p>In this study, we will approximate the average message propagation latency throughout the whole network.</p>
<p><strong>TL;DR:</strong> Despite a relatively short dataset of 3 days, we could observe with high confidence that:</p>
<ul>
<li>98% of messages arrive prior to the 4-second mark.</li>
<li>Lodestar seems to be the slowest client in terms of message arrival time, although this could also be related to when the arrivals are traced in the particular implementation.</li>
<li>Nodes located in or near the core of the network (<a href="https://probelab.io/ethereum/discv5/2024-25/#geolocation" rel="noopener nofollow ugc">NA or EU</a>) do have certain advantages when it comes to receiving messages sooner. Although the traced locations do not show any worrying behaviour, it is worth pointing out that extra geographical centralization could exacerbate the differences even further.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#results-2" name="results-2"></a>Results</h1>
<p>The results in this report have been gathered from EF’s Xatu public datasets. We’ve fetched 3 days’ worth of data from the <code>beacon_api_eth_v2_beacon_block</code> table (from the 14th to the 16th of June).</p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-cdf-times-within-the-slot-3" name="arrival-cdf-times-within-the-slot-3"></a>Arrival CDF times within the slot</h2>
<p>The study starts by calculating the arrival time of all the blocks within the slot that they belong to. The calculation is done based on the slot number and the time since genesis, given that each slot lasts 12 seconds:</p>
<pre><code class="lang-go">time_within_slot = arrival_time - (genesis_time + (slot * 12))
</code></pre>
<p>This measurement is crucial, as any block arrival beyond the 4 second mark is likely to generate a fork in some part of the network (as it can start receiving attestations of a non-proposed block).</p>
<p>In this first graph, we observe that 98% of the blocks arrived within the 4-second mark, leaving only the remaining 2% of blocks exceeding it.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/8/d8861bec5a5ad5613b752e126153afffcd236c23.png" title="CDF-propagation-latency"><img alt="CDF-propagation-latency" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/d/8/d8861bec5a5ad5613b752e126153afffcd236c23_2_517x309.png" width="517" /></a></div><p></p>
<p>The data was originated from the sentry nodes that are under the control of the Ethereum Foundation. These nodes include all the main client implementations in each of the locations, as shown in the following table:</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Continent</th>
<th>Country</th>
<th>Client</th>
</tr>
</thead>
<tbody>
<tr>
<td>EU</td>
<td>FI</td>
<td>lighthouse</td>
</tr>
<tr>
<td></td>
<td></td>
<td>lodestar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nimbus</td>
</tr>
<tr>
<td></td>
<td></td>
<td>prysm</td>
</tr>
<tr>
<td></td>
<td></td>
<td>teku</td>
</tr>
<tr>
<td>NA</td>
<td>US</td>
<td>lighthouse</td>
</tr>
<tr>
<td></td>
<td></td>
<td>lodestar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nimbus</td>
</tr>
<tr>
<td></td>
<td></td>
<td>prysm</td>
</tr>
<tr>
<td></td>
<td></td>
<td>teku</td>
</tr>
<tr>
<td>OC</td>
<td>AU</td>
<td>lighthouse</td>
</tr>
<tr>
<td></td>
<td></td>
<td>lodestar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nimbus</td>
</tr>
<tr>
<td></td>
<td></td>
<td>prysm</td>
</tr>
<tr>
<td></td>
<td></td>
<td>teku</td>
</tr>
</tbody>
</table>
</div><p>When comparing the arrival times over the different sentry nodes (figure below), we do see slight differences between them. The exception of <code>Lodestar</code> catches our attention, as it has a less uniform tail in its distribution. However, the rest of the clients follow a similar trend, with 99% of messages arriving within the first 4 seconds.</p>
<p>Since this data has been collected from the standard <a href="https://ethereum.github.io/beacon-APIs/#/Events/eventstream" rel="noopener nofollow ugc">event streamer Beacon API</a>, it is hard to explain the differences within each of the client implementations, as not only the libp2p codebase is written in different languages, but the message arrivals could also be timestamped at different moments of the message validation logic.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/0/60a95219771e0ec9bdc64265b87b0054bc877b83.png" title="gossipsub_arrival_times_within_slot_by_agent_on_mainnet_beacon_block"><img alt="gossipsub_arrival_times_within_slot_by_agent_on_mainnet_beacon_block" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/6/0/60a95219771e0ec9bdc64265b87b0054bc877b83_2_517x309.png" width="517" /></a></div><p></p>
<p>We were expecting to see different arrival times from different geographic locations, as the network geographical distribution seems to be concentrated within European and North American countries (<a href="https://probelab.io/ethereum/discv5/2024-24/#geolocation" rel="noopener nofollow ugc">link to the distribution</a>). The following graphs show that although there are indeed differences between countries or continents, they are minimal, with all the CDF distributions showing 98-99% of the block arrivals completing within the 4-second mark.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bec7e4974200c56b0e35fe8e118e90b97ea4b873.png" title="gossipsub_arrival_times_within_slot_on_by_country_mainnet_beacon_block"><img alt="gossipsub_arrival_times_within_slot_on_by_country_mainnet_beacon_block" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bec7e4974200c56b0e35fe8e118e90b97ea4b873_2_517x309.png" width="517" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/d/bdd5349b57b1f35d0484f1d82e09c9bea1c358fe.png" title="gossipsub_arrival_times_within_slot_on_by_continent_mainnet_beacon_block"><img alt="gossipsub_arrival_times_within_slot_on_by_continent_mainnet_beacon_block" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/d/bdd5349b57b1f35d0484f1d82e09c9bea1c358fe_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-times-4" name="arrival-times-4"></a>Arrival times</h2>
<p>The previous CDFs show that almost all the block arrivals happen within the expected time range. However, the plots do not reveal outliers, as CDFs are not sensitive to sudden network perturbations.</p>
<p>Thus, the following graphs show the <code>maximum</code>, <code>median</code>, <code>mean</code>, and <code>minimum</code> block arrival times on time windows of 4 epochs (1536 seconds).</p>
<p>We do not find large variations in the <code>minimum</code>, <code>mean</code> and the <code>median</code> distributions over the 3 day period. However, we do see that the maximum arrival time does vary quite significantly. We can observe that arrival times vary from 4 seconds to almost 12 seconds, almost exceeding the entire slot duration.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/2/92b9349d287acecc0903a14950d4876f1df18370.png" title="msg-arrival-overall"><img alt="msg-arrival-overall" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/9/2/92b9349d287acecc0903a14950d4876f1df18370_2_517x309.png" width="517" /></a></div><p></p>
<p>Interestingly, there are differences when comparing the mean arrival times of the different client implementations. Lodestar seems to be the latest one receiving the messages in the mesh and presents quite a high variance, while Teku seems to be the one receiving the messages first, followed by Prysm.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/6/c65b77648c36d9692a84fa65efd21ac3043aadd9.png" title="msg-arrival-by-agent"><img alt="msg-arrival-by-agent" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/c/6/c65b77648c36d9692a84fa65efd21ac3043aadd9_2_517x309.png" width="517" /></a></div><p></p>
<p>A similar pattern is also observed for the arrival time distribution by continent. As we could anticipate, European nodes receive slightly sooner messages than the North American and the Oceania ones. Although the difference is not significant, 0.6 seconds still keeps the arrival within the safety margins. However, this still showcases that there are some latency incentives to locate nodes in regions with lower latency, or in other words, around the core of the network (which, however, will, in turn, lead to more geographic centralization).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/f/bf6284e07ea3c5f9c4473be8b629d95b514371ed.png" title="msg-arrival-by-continent"><img alt="msg-arrival-by-continent" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/f/bf6284e07ea3c5f9c4473be8b629d95b514371ed_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#correlation-between-arrival-times-and-size-of-the-messages-5" name="correlation-between-arrival-times-and-size-of-the-messages-5"></a>Correlation between arrival times and size of the messages</h2>
<p>When attempting to correlate our findings to ones described in the previous <a href="http://ethresear.ch">ethresear.ch</a> <a href="https://ethresear.ch/t/big-block-diffusion-and-organic-big-blocks-on-ethereum/17346">blog post</a> that investigated this issue in particular, we haven’t been able to see any major correlation between size and the arrival time of the blocks. Although the block size distribution achieved in three days isn’t fully representative, the following graph shows that most blocks stay within the 50KB to 150KB range with a similar arrival time of 1 to 3 seconds.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/9/0905bc564c76545c3e9fc2c983edcbc280925d47.png" title="msg-arrival-vs-size"><img alt="msg-arrival-vs-size" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/0/9/0905bc564c76545c3e9fc2c983edcbc280925d47_2_375x375.png" width="375" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-6" name="conclusions-and-takeaways-6"></a>Conclusions and Takeaways</h1>
<p>Despite a relatively short dataset of 3.5hrs, we could observe with high confidende that:</p>
<ul>
<li>98% of messages arrive prior to the 4-second mark.</li>
<li>Lodestar seems to be the slowest client in terms of message arrival time, although this could also be related to when the arrivals are traced in the particular implementation.</li>
<li>Nodes located in or near the core of the network (<a href="https://probelab.io/ethereum/discv5/2024-25/#geolocation" rel="noopener nofollow ugc">NA or EU</a>) do have certain advantages when it comes to receiving messages sooner. Although the traced locations do not show any worrying behaviour, it is worth pointing out that extra geographical centralization could exacerbate the differences even further.</li>
</ul>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/gossipsub-message-propagation-latency/19982">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 14:03:33 +0000</pubDate>
</item>
<item>
<title>EVM in Motoko for Trustless Execution Environments</title>
<link>https://ethresear.ch/t/evm-in-motoko-for-trustless-execution-environments/19981</link>
<guid>https://ethresear.ch/t/evm-in-motoko-for-trustless-execution-environments/19981</guid>
<content:encoded><![CDATA[
<div> 关键词：Motoko、Internet Computer (IC)、EVM实现、教育目标、微EVMs

总结:<br />
文章介绍了作者管理的组织正在资助一个在Motoko中构建的EVM，目标是运行在Internet Computer上，未来可能扩展到AO领域。项目已通过GG19和GG20资金支持，主要目的是实现无信任执行和共识代理。目前完成了第一个里程碑——算术函数，寻求经验丰富的开发人员提供反馈和优化建议。这个项目还有助于教育，提供EVM工作原理的学习资源，并作为其他链上智能合约的微EVM基础，支持跨链交互。开发者正在GitHub上开源项目文件和测试代码，以促进改进和集成。 <div>
<p>Hello ethResearch <img alt=":wave:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wave.png?v=12" title=":wave:" width="20" /> it has been a while since I posted. Thanks for your patience as I wade back into the eth universe.</p>
<p>An organization that I’m running called <a href="https://icdevs.org" rel="noopener nofollow ugc">https://icdevs.org</a> is funding an evm built in Motoko that is targeted to run on the Internet Computer(and that we think will slide well into the AO universe as well). We should have started this 3 years ago, but there is no time like the present. To date this work has been funded through <span class="hashtag-raw">#GG19</span> and <span class="hashtag-raw">#GG20</span>. The eventuality of this project is trustless execution and consensus agents and the ability to monitor and relay messages between EVMs(and other chains) in a trustless manner.</p>
<p>The bounty has reached its first milestone and we’re looking for experienced EVM implementors to tell us what we’ve missed and how to make it better. I realize this forum seems to have moved on to bigger and harder scaling challenges, but I’m hoping you all can point me in the right direction to find the right audience. It is a bit too technical for r/ethereum but may be too basic for this forum and not quite an EIP.</p>
<p>Why we are looking to build out an EVM execution layer for the Intenet computer(from our thread at <a class="inline-onebox" href="https://forum.dfinity.org/t/open-icdevs-org-bounty-63-evm-opcodes-motoko-1-9-cketh/27592?u=skilesare" rel="noopener nofollow ugc">Open - ICDevs.org Bounty #63 - EVM OpCodes - Motoko - 1.9 ckETH - Bounties - Internet Computer Developer Forum</a> )</p>
<ol>
<li>The obvious - we can’t build an EVM in motoko without the op-codes. Now building an evm in motoko isn’t particularly a priority at the moment, but long term the Ethereum Foundation has made it a priority to have EVMs in as many languages as possible as a security feature. Would it make sense to have IC canisters as evm nodes for other chains? Probably depends on network config and a few other things, but I could certainly see it being of value long term. Having the op-codes defined separates the execution concerns from any future project that might want to wire up the rest of the EVM machinery. From building from the ground up you get an EVM that takes the IC’s compute pattern and restrictions into account in ways that existing EVMs written in other languages would need significant rewrites to support.</li>
<li>General education - These opcodes are an awesome way to learn about stacks, memories, and crypto primitives. Education is the primary goal of <a href="http://icdevs.org/" rel="noopener nofollow ugc">ICDevs.org </a> and we feel like Motoko versions of these libraries would make a really interesting set of examples for people learning about how EVMs work, why they work, and what concepts mirror over into the IC(and which ones don’t).</li>
<li>Libraries and Integrations - these libraries build on top of a number of other Bounties that we’ve funded that could use some burn-in and integration testing to improve them and make sure they are working properly. <a href="https://github.com/f0i/merkle-patricia-trie.mo" rel="noopener nofollow ugc">GitHub - f0i/merkle-patricia-trie.mo: A Merkle Patricia Trie implementation in Motoko </a> <a href="https://github.com/relaxed04/rlp-motoko" rel="noopener nofollow ugc">GitHub - relaxed04/rlp-motoko: RLP implementation on motoko</a>. In addition, some of the op codes implement core functionality that we’ll need to do cross-chain like ecrecover which would be important for a motoko canister trying to verify a signature from the evm universe.</li>
<li>Micro EVMs - In one universe bitfinity EVMs proliferate and we end up with a garden of highly specialized evms on the IC that interact and interoperate in unique ways. These libraries would allow you to pull in the memory, storage, etc from those EVMs and run transaction simulations to check for opportunities or to automate actions against them using things like the event logs. The always-on nature of IC canisters makes them ideal for writing bots/agents that seek opportunities and execute on them by signing tecdsa messages and relaying them.</li>
</ol>
<p>Our bounty hunter has completed the first milestone, arithmetic functions.</p>
<p>project file:</p><aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="32" src="https://ethresear.ch/uploads/default/original/2X/b/bad3e5f9ad67c1ddf145107ce7032ac1d7b22563.svg" width="32" />

      <a href="https://github.com/icdevsorg/evm.mo" rel="noopener nofollow ugc" target="_blank">GitHub</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image"><img class="thumbnail" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/5/4/546c435f8f13ad709696b772052a5b091237e94b_2_690x345.png" width="690" /></div>

<h3><a href="https://github.com/icdevsorg/evm.mo" rel="noopener nofollow ugc" target="_blank">GitHub - icdevsorg/evm.mo: EVM Based Libraries for Motoko</a></h3>

  <p>EVM Based Libraries for Motoko. Contribute to icdevsorg/evm.mo development by creating an account on GitHub.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

<p>main code file:</p><aside class="onebox githubblob">
  <header class="source">

      <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <h4><a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo" rel="noopener nofollow ugc" target="_blank">icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo</a></h4>


      <pre><code class="lang-mo">import Array "mo:base/Array";
import Nat "mo:base/Nat";
import Nat8 "mo:base/Nat8";
import Nat64 "mo:base/Nat64";
import Int "mo:base/Int";
import Trie "mo:base/Trie";
import Iter "mo:base/Iter";
import Debug "mo:base/Debug";
import Vec "mo:vector"; // see https://github.com/research-ag/vector
import Map "mo:map/Map"; // see https://mops.one/map
import EVMStack "evmStack";
import T "types";

module {
  
  type Result&lt;Ok, Err&gt; = { #ok: Ok; #err: Err};
  type Engine = [(T.ExecutionContext, T.ExecutionVariables) -&gt; Result&lt;T.ExecutionVariables, Text&gt;];
  type Vec&lt;X&gt; = Vec.Vector&lt;X&gt;;
  type Map&lt;K, V&gt; = Map.Map&lt;K, V&gt;;
  type Trie&lt;K, V&gt; = Trie.Trie&lt;K, V&gt;;
</code></pre>



  This file has been truncated. <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/src/evm_mo_backend/main.mo" rel="noopener nofollow ugc" target="_blank">show original</a>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

<p>tests:</p><aside class="onebox githubblob">
  <header class="source">

      <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo" rel="noopener nofollow ugc" target="_blank">github.com</a>
  </header>

  <article class="onebox-body">
    <h4><a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo" rel="noopener nofollow ugc" target="_blank">icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo</a></h4>


      <pre><code class="lang-mo">import { test; skip } "mo:test/async"; // see https://mops.one/test

import { stateTransition } "../src/evm_mo_backend/main";

import Array "mo:base/Array";
import Nat "mo:base/Nat";
import Nat8 "mo:base/Nat8";
import Nat64 "mo:base/Nat64";
import Int "mo:base/Int";
import Trie "mo:base/Trie";
import Debug "mo:base/Debug";
import Vec "mo:vector";
import Map "mo:map/Map";
import EVMStack "../src/evm_mo_backend/evmStack";
import T "../src/evm_mo_backend/types";

let dummyTransaction: T.Transaction = {
    caller = "\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa\00\aa";
    nonce = 2;
    gasPriceTx = 5;
</code></pre>



  This file has been truncated. <a href="https://github.com/icdevsorg/evm.mo/blob/5b3870c2454caf5cb1506010c8ab6796214ff307/test/main.test.mo" rel="noopener nofollow ugc" target="_blank">show original</a>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/evm-in-motoko-for-trustless-execution-environments/19981">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 13:37:42 +0000</pubDate>
</item>
<item>
<title>Preconfirmations under the NO lens</title>
<link>https://ethresear.ch/t/preconfirmations-under-the-no-lens/19975</link>
<guid>https://ethresear.ch/t/preconfirmations-under-the-no-lens/19975</guid>
<content:encoded><![CDATA[
<p>by <a href="https://twitter.com/umb_nat" rel="noopener nofollow ugc">U. Natale</a>.</p>
<p><strong>Acknowledgements</strong><br />
This research has been granted by <a href="https://chorus.one/" rel="noopener nofollow ugc">Chorus One</a>. We are grateful to <a href="https://twitter.com/plc_hld" rel="noopener nofollow ugc">M. Moser</a>, <a href="https://x.com/crainbf" rel="noopener nofollow ugc">B. Crain</a>, and <a href="https://x.com/Yannimoto" rel="noopener nofollow ugc">Y. Socolov</a> for useful discussions and comments. We also thanks <a href="https://x.com/mempirate" rel="noopener nofollow ugc">J. Bostoen</a> and <a href="https://x.com/fra_mosterts" rel="noopener nofollow ugc">F. Mosterts</a> from <a href="https://x.com/chainbound_" rel="noopener nofollow ugc">Chainbound</a> team for reviewing the entire document (review ≠ endorsement).</p>
<h1><a class="anchor" href="https://ethresear.ch#preconfirmations-landscape-1" name="preconfirmations-landscape-1"></a>Preconfirmations landscape</h1>
<p>In the context of PBS, bargaining between proposer and relay start at around 1s. This means that users submitting transactions after 1s have to wait for the next slot to know if the transaction is included or not. Even in the context of timing games and assuming some aggressive player, there is a hard cut-off at &lt; 4s due to attestation deadline.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/b/8b20ed4fa8795f4a096dc0d24d975d1b02f78d72.png" title="Screenshot 2024-06-21 alle 11.35.54"><img alt="Screenshot 2024-06-21 alle 11.35.54" height="255" src="https://ethresear.ch/uploads/default/optimized/3X/8/b/8b20ed4fa8795f4a096dc0d24d975d1b02f78d72_2_690x255.png" width="690" /></a></div><br />
<strong>Fig. 1:</strong> The current setup under PBS.<p></p>
<p>With preconfirmation, users have the possibility to access the dead time space between two blocks via a <a href="https://mirror.xyz/preconf.eth/sgcuSbd1jgaRXj9odSJW-_OlWIg6jcDREw1hUJnXtgI" rel="noopener nofollow ugc">credible heads-up before a confirmation happens</a>. However, at the moment, preconfirmations give no guarantees on execution.</p>
<p>For example, imagine 2 users submit 2 conflicting transactions (e.g. a swap against the same pool), but both get a preconfirmation. What happens in slot N+1 is that both transactions land in some place into the slot, but one of the two fails.</p>
<p>From the provider of preconfirmations perspective, the original agreement was respected, however one of the two users next time will think twice before paying for a preconfirmation. The same scenario can happen even if there is only one preconf, but this transaction lands in some place into the slot after other conflicting transactions.</p>
<p>This poses some questions on who can preconfirm a transaction and who can’t. From the two example above it is evident that unsophisticated players can’t play this game and provide a real improvement for the Ethereum ecosystem. It is clear that the burden would be reduced if the preconfs were intended only for transactions that do not touch contentious state — e.g. transfers of tokens and NFTs, dApps with “batching” architecture, L2 settlements, etc. In this case no sophistication is needed so we will exclude it from the goal of this analysis.</p>
<h1><a class="anchor" href="https://ethresear.ch#proposer-as-preconf-provider-2" name="proposer-as-preconf-provider-2"></a>Proposer as preconf provider</h1>
<p>Preconfirmations should be managed in a manner which is similarly decentralized to the current PBS setup; they should not give rise to a centralization bottleneck that exceeds the current builder dominance.</p>
<p>Fundamentally, the PBS transaction pipeline is an auction. Preconfirmations under a gateway architecture follow a delegation scheme, where node operators (NOs) select a third party to select transactions for future inclusion. Therefore, the gateway design is not a spot market, and a generally less competitive scheme as the cost of switching is considerably higher. Indeed, the gateway architecture expects each validator to sign an on-chain transaction to deposit collateral, meanwhile this operation under PBS is done completely off-chain, meaning that there is no cost to switching builders.</p>
<p>This may directly reflect in multi-block MEV, where gateways will be able to provide increasingly more competitive partnership offers to node operators as they scale their dominance over the network. In difference to PBS builders, these gateways will have certainty over the slots for which they hold a mandate. Therefore, a gateway architecture is likely to manifest as a heavily centralized setup, where multi-block MEV is the central return to scale, and switching costs are high. Overall, as it is not an auction or a spot market, the gateway architecture is more likely to manifest a centralization bottleneck which exceeds PBS builder dominance.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/9/193ec08347bb058b66d9b5ead9de72df69a1636d.png" title="stake penetration vs slots in a row"><img alt="stake penetration vs slots in a row" height="421" src="https://ethresear.ch/uploads/default/optimized/3X/1/9/193ec08347bb058b66d9b5ead9de72df69a1636d_2_690x421.png" width="690" /></a></div><br />
<strong>Fig. 2:</strong> Rate of N slots in a row over total Ethereum slots in a year as a function of stake penetration. Growth is higher than linear, and the case of builders/gateways dominance in block production is just an extension of above.<p></p>
<p>A preferable scheme would be the proposer selecting preconfirmations itself. Even in the case of the largest proposers, their ability to engage in multi-block MEV is capped by their voting power (see Fig. 2), which is in turn is capped by the proposer market (i.e. access to capital). Even under PBS, proposers could theoretically already engage in multi-block MEV, but refrain to do so, for a variety of reasons ranging from access to capital and organisational setup, to legal liability. These same patterns would likely extend to a preconfirmation setup.</p>
<p>In this section we are going to analyze some scenarios that may arise if the proposer of the slot is the one providing preconfirmation for transactions. We further assume that the NO is a sophisticated player, since the more transactions an unsophisticated preconfirmations provider includes in the preconfirmation list, the more difficult it is for block builders to create a block with all transactions being successful. This implies an execution guarantee on preconfirmed transactions.</p>
<p>If the majority of preconfirmed transactions fail, the market becomes less attractive, making preconfirmations a difficult tool to use. Including conflicting transactions can also damage the NOs credibility, negatively impacting the brand.</p>
<h2><a class="anchor" href="https://ethresear.ch#information-edge-from-private-order-flow-3" name="information-edge-from-private-order-flow-3"></a>Information edge from private order flow</h2>
<p>In this section we are going to show the different information edge builders have in the current PBS framework. As we did in <a href="https://arxiv.org/pdf/2312.09654" rel="noopener nofollow ugc">The cost of artificial latency in the PBS context</a>, we can define a standardized parameter that allows for a comparison of bids irrespective of their absolute size. This corresponds to the ratio between a given bid and the maximum bid in the auction for a particular slot. That is</p>
<div class="math">
\begin{equation}
R = \frac{b_s(t_E)}{\textrm{max}_{t_E}b_S(t)}\,,\qquad(1)
\end{equation}
</div>
<p>where <span class="math">b</span> is the bid value, <span class="math">s</span> indicate the corresponding slot, and <span class="math">t_E</span> is the time at which the bid was made eligible. This allows us to compare builders bidding strategy over all slot proposed by Chorus One since 2024-03-13.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e83b3b463951c5f72911dad23a05e70b9868c23c.png" title="Builders edge on private order flow"><img alt="Builders edge on private order flow" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e83b3b463951c5f72911dad23a05e70b9868c23c_2_690x345.png" width="690" /></a></div><br />
<strong>Fig. 3:</strong> Builder bidding strategy standardized over all slots proposed by Chorus One since 2024-03-13.<p></p>
<p>If we select 6 of the top builders by entity (according to <a href="https://mevboost.pics/" rel="noopener nofollow ugc">mevboost.pic</a>), we can clearly see a difference in the overall strategy, see Fig. 3. For example, we can see how some builders start to deliver bids “late” into the slot, others seems to start much earlier. Furthermore, some builders have a clear linear trend in bid increase per unit of time, others seems to start being careful near the end of the auction.</p>
<p>Although this is independent from the information edge coming from private order flow, we can see how different builders propagates different values of <span class="math">R</span>. Precisely, at 1s into the slot (that is the median value for bid selection in current PBS framework) we have</p>
<ul>
<li><strong>Builder:</strong> 0xb211df4…, <strong>Median:</strong> 0.91, <strong>0.25-quantile:</strong> 0.83, <strong>0.95-quantile:</strong> 0.99</li>
<li><strong>Builder:</strong> 0x83d3495…, <strong>Median:</strong> 0.86, <strong>0.25-quantile:</strong> 0.75, <strong>0.95-quantile:</strong> 0.97</li>
<li><strong>Builder:</strong> 0xa32aadb…, <strong>Median:</strong> 0.90, <strong>0.25-quantile:</strong> 0.83, <strong>0.95-quantile:</strong> 0.98</li>
<li><strong>Builder:</strong> 0xa03a000…, <strong>Median:</strong> 0.81, <strong>0.25-quantile:</strong> 0.74, <strong>0.95-quantile:</strong> 0.95</li>
<li><strong>Builder:</strong> 0xa91d3e5…, <strong>Median:</strong> 0.79, <strong>0.25-quantile:</strong> 0.65, <strong>0.95-quantile:</strong> 0.93</li>
<li><strong>Builder:</strong> 0xb783f81…, <strong>Median:</strong> 0.88, <strong>0.25-quantile:</strong> 0.82, <strong>0.95-quantile:</strong> 0.96</li>
</ul>
<p>that indicates how different entities arrive to the most-likely-end of the auction with less/higher bid values.</p>
<p>From the NO perspective, a difference in information edge could lead to a mispricing of MEV txs, thus increasing the risk of producing less valuable blocks. In general, builders in the current MEV-Boost framework have a comprehensive view of all transactions and typically include those that maximize the block value. However, with validators as preconfirmation providers, proposers must select transactions in advance, often without knowledge of transactions occurring on private channels. The primary metric available to validators in this scenario is the base fee. Specifically, if a transaction pays the base fee (BF) plus a priority fee (PF), it is considered valid in principle. But if the priority fee is the lowest compared to transactions in the private order flow from builders, the block value could decrease. This is because builders are now required to include the preconfirmed transaction instead of a potentially more valuable one. Here sophisticated NOs are in advance since they can develop models to probabilistically evaluate transactions and perform an opinionated selection.</p>
<p>It is worth noting, that validators with private transaction flows could be incompatible with preconfirmations, depending on implementation. Private transaction flows can also manifest by virtue of network jitter. Indeed, if a proposer gives a preconfirmation on a transaction from private transaction flow (or on a transaction from an RPC that’s close to the proposer, but far away from the builder), there could be a non-zero likelihood this transaction is not known by the builders, which may find it difficult to build a valid block (i.e. with the preconfirmed tx). The solution is that the proposer <a href="https://chainbound.github.io/bolt-docs/api/builder-api" rel="noopener nofollow ugc">sends the full transaction to builders</a>. Concerns about privacy are clearly excluded since the proposer already committed to certain execution, and the builder can’t really do anything about that.</p>
<h2><a class="anchor" href="https://ethresear.ch#enforced-early-timing-games-4" name="enforced-early-timing-games-4"></a>Enforced early timing-games</h2>
<p>Arbitrageurs often engage in short-term trading due to competitive pressures. When they opt to delay immediate gains in hopes of capturing a greater mispricing, they run the risk of losing the lucrative opportunity to other traders. This issue is particularly critical within Ethereum’s Proposer-Builder Separation (PBS) mechanism, where searchers must strategically balance their bidding approaches.</p>
<p>Consider an arbitrage opportunity that arises relative to an external source, such as a centralized exchange (CEX), at t=4 seconds into slot N. Since the on-chain price is stale and searchers are uncertain whether the opportunity will vanish on the CEX side, they may prefer to execute the first leg of the trade on the CEX immediately and wait the canonical 12 seconds to see their transaction confirmed on-chain. In the PBS context, however, if a searcher immediately bids their maximum willingness to pay for the opportunity, there is a non-zero likelihood that other searchers may outbid them, effectively frontrunning the original strategy. Conversely, if the searcher bids aggressively too late, the closing trade may fail to be included on-chain since the proposer has already committed to a block that excludes this particular transaction. This scenario creates an auction dynamic that hinges on accurately pricing the time within the slot. The same applies for a DEX &lt;&gt; DEX opportunity, since other arbitrageurs may offer a higher share of MEV for the same opportunity and then seeing their bundle being selected.</p>
<p>Therefore, searchers must strategize not only about how much to bid, but also about the optimal timing of their bids. Bidding too early or too late can both result in a loss of the arbitrage opportunity. The delicate balance between these factors is crucial for optimizing their strategies in such competitive and time-sensitive environments. This study models this behavior and evaluates various strategies to understand the optimal bidding dynamics in Ethereum’s PBS framework.</p>
<h3><a class="anchor" href="https://ethresear.ch#model-description-5" name="model-description-5"></a>Model Description</h3>
<p>To investigate how the introduction of preconfirmations might influence the auction dynamics in PBS, we conducted simulations using an Agent-Based Modeling (ABM) framework. The model is designed to simulate the behavior of searchers participating in PBS auctions under varying conditions, incorporating elements of competitive bidding and strategic timing. In our model, we assume that searchers at step N are aware of the bids at step N-1. While this might seem at odds with the usual dynamics in MEV-Boost, where the auction is not publicly visible, we can reconcile this assumption with two scenarios:</p>
<ol>
<li><strong>Historical Data Adjustment</strong>: Searchers adjust their bidding strategies based on the share of MEV extracted as a function of past data. In this scenario, at each step N, searchers are informed about the behavior of searchers at the corresponding step N-1 from the previous slot. Thus, the predictive model is grounded in the historical data of past auctions.</li>
<li><strong>Vertically Integrated Builders</strong>: In this scenario, searchers are considered as vertically integrated builders. Here, we can imagine a block as a composition of transactions that produce a certain value for the MEV, with the bidding phase representing the exact competition between builders.</li>
</ol>
<p>By incorporating these scenarios, our model aims to provide a simplistic but comprehensive understanding of how searchers might operate within the PBS auction mechanism under the influence of preconfirmations.</p>
<h3><a class="anchor" href="https://ethresear.ch#searchers-behaviour-6" name="searchers-behaviour-6"></a>Searchers behaviour</h3>
<p>In the model, each agent represents a searcher with a specific profit margin, aggressivity parameter, and fear-of-missing-out (FOMO) factor. These agents operate in a simulated environment that mimics the Ethereum PBS auction mechanism. Each agent’s decision-making process is influenced by the bids placed in previous auction steps, representing the competitive nature of the environment.</p>
<p>Agents update their bids in each step based on a combination of their internal parameters and the observed bids from the previous step. The bid update process is governed by a logistic growth model, where the increment of the bid follows a logistic function, adjusted by the agent’s aggressivity parameter and FOMO factor. This approach ensures that agents increase their bids more cautiously in the early stages and more rapidly as the auction progresses, reflecting the strategic balance between the risk of being outbid and the urgency of capturing the arbitrage opportunity. This dynamic allows the agents to optimize their bidding strategies over time, aiming to reach the maximum bid value closer to the end of the auction period.</p>
<p>Additionally, agents take into account the probability that the auction may terminate at any given step. This probability is derived from a fictitious empirical distribution of auction durations, modelled using a truncated normal distribution to generate realistic auction durations, cfr. Fig. 4. In case of preconfirmation, we add a half-normal distribution to the previous one, cfr. Fig. 5. The termination probability influences the agents’ urgency in placing bids, as they must balance the risk of the auction ending unexpectedly with the potential benefits of waiting for a more opportune moment to bid. This probabilistic approach ensures that agents are not only competing against each other but also managing the inherent uncertainty of the auction’s duration.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/6/06e7143081bbd056f94a6b8f8e3873b675a2a89f.png" title="Auction Time - no preconf - PDF &amp; CDF"><img alt="Auction Time - no preconf - PDF &amp; CDF" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/0/6/06e7143081bbd056f94a6b8f8e3873b675a2a89f_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 4:</strong> Single instances of a fictitious empirical distribution for the transaction selection time into the auction in the absence of preconfirmations.<p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/3/d3d2b8c36e3810f0175271e67a2b49d9804afd44.png" title="Auction Time - preconf - PDF &amp; CDF"><img alt="Auction Time - preconf - PDF &amp; CDF" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/d/3/d3d2b8c36e3810f0175271e67a2b49d9804afd44_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 5:</strong> Single instances of a fictitious empirical distribution for the transaction selection time into the auction in the presence of preconfirmations.<p></p>
<p>The model incorporates four different types of searchers, each using a different predictive model to estimate the bid for the next step before applying their respective increment:</p>
<ol>
<li><strong>Predictive Model 1</strong>: This model predicts the next bid as simply the maximum bid observed so far. It assumes that the current trend will continue without significant changes.</li>
<li><strong>Predictive Model 2</strong>: This model uses a linear regression based on the bid history to predict the next bid. It fits a linear model to the previous bids and uses the resulting slope and intercept to estimate the next bid. This approach assumes that the bid growth can be approximated by a linear trend.</li>
<li><strong>Predictive Model 3</strong>: This model calculates the average increment of the bids from previous steps and adds this average increment to the current maximum bid. This model assumes that past increments provide a good estimate for future increases.</li>
<li><strong>Predictive Model 4</strong>: This model uses a logarithmic fit based on the bid history to predict the next bid. It fits a logarithmic model to the previous bids and uses the resulting parameters to estimate the next bid. This approach assumes that the bid growth follows a decelerating trend, reflecting a more conservative strategy as the auction progresses.</li>
</ol>
<p>By incorporating these diverse predictive models, the simulation captures a wide range of bidding behaviors and strategies, providing a more comprehensive understanding of how different types of searchers might operate within the Ethereum PBS auction mechanism.</p>
<h3><a class="anchor" href="https://ethresear.ch#results-7" name="results-7"></a>Results</h3>
<p>Analyzing the results in Fig. 6, we observe that in scenarios where preconfirmations on transactions are possible, searchers begin to increase their share of captured MEV earlier. This suggests that to increase MEV share received, a node operator might opt to run the version that allows for preconfirmations but never actually selects any MEV transactions. This creates a situation where searchers bid higher because the auction might end sooner. However, since no preconfirmations are offered (as the validator does not select any), the auction continues, and searchers find themselves starting from a higher base bid.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/b/5be75738445af00fdf93f6b1e455b905c46a23c2.png" title="Auction war - combined"><img alt="Auction war - combined" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/5/b/5be75738445af00fdf93f6b1e455b905c46a23c2_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 6:</strong> Distribution of different bidding strategy extracted from a set of simulation using the ABM described in previous section. Simulations including a preconfirmation phase are in red, simulations without a preconfirmation phase are in blue.<p></p>
<p>This situation can be likened to a modified version of the prisoner’s dilemma. In this strategic game, each searcher (or prisoner) must decide whether to bid aggressively early (cooperate) or wait for a more opportune moment (defect). If all searchers bid aggressively early, they collectively drive up the MEV share and risk overbidding. Conversely, if they all wait, the auction proceeds normally, and they can potentially secure MEV shares at a lower cost. However, if some searchers bid aggressively while others wait, the aggressive bidders might secure a higher share early, pushing the late bidders to increase their bids even further as the auction continues.</p>
<p>This dynamic creates a tension between the searchers: each must decide whether to trust that others will not bid aggressively early or to secure their position by doing so themselves. The presence of preconfirmations adds an additional layer of complexity, as the threat of an early auction end prompts higher early bids, even when no actual preconfirmations are selected.</p>
<p>In summary, the introduction of preconfirmations influences searchers’ bidding behavior, leading to higher initial bids due to the perceived risk of an early auction end. This strategic interplay resembles the prisoner’s dilemma, where individual decisions to bid early or wait impact the collective outcome, highlighting the intricate balance between cooperation and competition in optimizing MEV shares.</p>
<p>In other words, with preconfirmations, searchers competing for the same opportunity can no longer rely on the probability that a certain builder will win a slot. If a competing searcher’s transaction is preconfirmed, even if the transaction is accepted by the winning builder, the builder must prioritize the preconfirmed one.</p>
<h2><a class="anchor" href="https://ethresear.ch#reversal-timing-game-8" name="reversal-timing-game-8"></a>Reversal timing-game</h2>
<p>Currently, the dynamics involve searchers relying on private auctions through builders, who have a certain probability of winning the block. Builders construct a block based on the privately received transactions and subsequently compete with other builders (through a public auction) to determine the winning block.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/8/d86ee43d92e0249f4368147a23f5f2f24a1560bf.png" title="latency_vs_ntxs"><img alt="latency_vs_ntxs" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/d/8/d86ee43d92e0249f4368147a23f5f2f24a1560bf_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 7:</strong> Dependency in current auction dynamic between number of transactions included in the block and bid value, source from <a href="https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847">The cost of artificial latency in the PBS context</a>.<p></p>
<p>Empirical data shows that the number of transactions included in blocks proposed by builders and the value of the block increase linearly, cfr. Fig 7 and [The cost of artificial latency in the PBS context](<a href="https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847**.">https://ethresear.ch/t/the-cost-of-artificial-latency-in-the-pbs-context/17847**.</a>** This implies that once an arbitrage opportunity between CEX and DEX is identified, stat-arbitrageurs submit their transaction, which is not further modified, and the additional value builders obtain comes from a greater inclusion of transactions. In fact, searchers prefer to submit their transaction immediately as the opportunity might vanish on the CEX, and there is a form of preconfirmation due to the historical probability of a builder winning an auction. Therefore, it is highly likely that the rebalancing on the CEX occurs in the early stages of the block.</p>
<p>By modeling the price difference between CEX and DEX as a Markovian jump-diffusion process, we can derive the expression for the probability that searchers can execute a profitable trade (i.e. that the price difference is greater than the fees needed to execute the trade). This probability, <span class="math">P</span>,  is given by (see Appendix for a derivation):</p>
<div class="math">
\begin{equation}
P = \frac{1}{1+\frac{\sqrt{2\lambda}\gamma}{\sigma}}\,,\qquad(2)
\end{equation}
</div>
<p>where <span class="math">\gamma</span> represents the fee of the trade,  <span class="math">\lambda</span> is such that the time mean interval between trades is <span class="math">\bar{t} = \lambda^{-1}</span>, <span class="math">\sigma</span> is the volatility of the price difference.</p>
<p>Equation (2) allows us to define a new dynamic for stat-arbs under the preconfirmation framework. Indeed, when the time interval between trades is small (i.e. high values of <span class="math">\lambda</span>), the probability of having a profitable trade decrease. On the other hand, if volatility becomes predominant, the dynamic may change. Preconfirmations allows arbitrageurs to tune the time interval <span class="math">\lambda^{-1}</span> in order to maximize the probability of being in the trading regime on a volatility based strategy.<br />
Precisely, the time between trades is determined by the time at which the previous slot selected transactions and the time at which new transactions are selected for current block. With current PBS design this corresponds to 12s. Indeed, even if the builder knows he won the slot at t=4s into the slot N-1, he now has to wait 12s (i.e. 4s into the slot N) before knowing if he wins the slot N. With preconfirmations the frequency of transaction selections is a dynamic variable, because you know that your transaction is selected at different time wrt. the usual 4s into the slot. Clearly, by alternating preconfirmations with normal block inclusion, the parameter <span class="math">\lambda</span> is non-constant.</p>
<p>If now the objective is to minimize the ratio <span class="math">\sqrt{2\lambda}/\sigma</span>, if the volatility is low searchers can start to increase the frequency of trades submission (i.e. participate in preconfirmation auction) in order to maintain <span class="math">\sqrt{2\lambda}/\sigma &lt;&lt; 1</span>.</p>
<p>This modeling is consistent with the hypothesis that searchers may be interested in submit their transaction at the beginning of the block. This creates a dynamic potentially opposite to the timing games observed in the MEV-Boost context, where now searchers strive to compete from the early stages in the preconfirmation market.</p>
<h2><a class="anchor" href="https://ethresear.ch#capturing-on-chain-mev-9" name="capturing-on-chain-mev-9"></a>Capturing on-chain MEV</h2>
<p>With node operators as preconf provider, preconfirmations give validators the power back to decide on some transaction that have to be included in the slot. This means that NO can add new transactions on top of the current MEV-Boost pipeline, meaning that the ways of capturing MEV augment. Indeed, if we stay in the assumption that preconf transactions are likely to be executed as valid transactions, each time a validator is selected to propose a slot, it can preconf on his own transactions. This means that some types of on-chain MEV, in principle, can be captured by NO using preconfirmations, without renouncing to CEX &lt;&gt; DEX arbitrage, that might result more complicated for NOs.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/1/41859fc9aeca6897bb9ff6312cc64a64d9c2414a.png" title="Screenshot 2024-06-20 alle 12.13.39"><img alt="Screenshot 2024-06-20 alle 12.13.39" height="327" src="https://ethresear.ch/uploads/default/optimized/3X/4/1/41859fc9aeca6897bb9ff6312cc64a64d9c2414a_2_690x327.png" width="690" /></a></div><br />
<strong>Fig. 8:</strong> Daily extracted MEV in 30 days by profit. Source <a href="https://eigenphi.io/" rel="noopener nofollow ugc">EigenPhi</a>.<p></p>
<p>Given the importance on the order of transaction execution, only arbitrage and liquidation could be captured using preconfirmation. According to <a href="https://eigenphi.io/" rel="noopener nofollow ugc">EigenPhi</a>, arbitrages and liquidations produced revenue of $3M profit in 30 days. From the Top 12 leaderboard on arbitrageurs, we can see that only 66% of captured MEV is shared with builders. Clearly, also builders retain a portion of MEV, but due to lack of data, we exclude this from our calculation, which at the end will provide a lower bound on extra revenue a NO can make.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e5f6e65454a19f24711d87a2fac6c81cbf950962.png" title="Screenshot 2024-06-20 alle 12.13.52"><img alt="Screenshot 2024-06-20 alle 12.13.52" height="162" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e5f6e65454a19f24711d87a2fac6c81cbf950962_2_690x162.png" width="690" /></a></div><br />
<strong>Fig. 9:</strong> Leaderboard of top 12 on-chain arbitrageurs in 30 days. Source <a href="https://eigenphi.io/" rel="noopener nofollow ugc">EigenPhi</a>.<p></p>
<p>If we assume that a NO with 1% of stake penetration captures 1% of this extra MEV, there is an extra $345,600 in a year. Since the median MEV revenue for a NO with such share is ETH 392.31 (cfr. Fig.  10), assuming a price per ETH of $3,500 this (98.74 ETH extra MEV) corresponds to a 25.17% increase from MEV revenue in a year. It is worth mentioning that <a href="https://adagio.chorus.one/" rel="noopener nofollow ugc">current timing games provide ~10% extra MEV</a>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/8/a869e4823ee39f779a3b39c028ff5e4d784e2066.png" title="MEV yearly size - NO size 10000 over 1005387"><img alt="MEV yearly size - NO size 10000 over 1005387" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/a/8/a869e4823ee39f779a3b39c028ff5e4d784e2066_2_690x230.png" width="690" /></a></div><br />
<strong>Fig. 10:</strong> Probability Distribution Function of MEV proceeds in a year for a node operator with 1% of stake penetration.<p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-10" name="conclusions-10"></a>Conclusions</h1>
<p>Implementing a sophisticated system for preconfirmations within Ethereum’s PBS framework is far from trivial. This complexity opens new avenues for sophisticated NOs to enhance their revenues from MEV.</p>
<p>Our study has demonstrated that preconfirmations introduce a significant layer of strategic depth to the PBS auction mechanism. By providing searchers with a credible heads-up before a transaction is confirmed, preconfirmations alter the timing and aggressiveness of bids. This shift is particularly pronounced in scenarios where NOs, acting as preconfirmation providers, selectively include transactions that maximize their revenue while ensuring successful block proposals.</p>
<p>This analysis highlighted the varied strategies employed by different builders in the current PBS framework, revealing significant differences in how they time their bids. This information asymmetry can lead to mispricing of MEV transactions, potentially reducing the overall value of blocks for node operators.</p>
<p>The presence of preconfirmations forces searchers to engage in more sophisticated bidding strategies. They must carefully balance the risk of being outbid by competitors against the potential for an early auction termination, which could prevent their transactions from being included. This dynamic is akin to a modified prisoner’s dilemma, where searchers must decide between bidding aggressively early or waiting for a more opportune moment, knowing that their decisions impact the overall auction outcome. Overall, this may push for a new type of timing games, where now searchers will compete more aggressively in the first part of the preconfirmation interval.</p>
<p>Complex implementation of preconfirmations provide NOs with a powerful tool to capture on-chain MEV directly. By preconfirming their transactions, NOs can ensure the inclusion of high-value arbitrage and liquidation opportunities, significantly boosting their MEV revenue. Our calculations indicate that a NO with a 1% stake penetration could see a 25.17% increase in annual MEV revenue through strategic use of preconfirmations. This increase is substantial compared to the ~10% extra MEV derived from current timing games.</p>
<p>Despite the potential benefits, the implementation of preconfirmations must be carefully managed to avoid centralization risks. A decentralized approach, where proposers themselves manage preconfirmations, is preferable to a gateway architecture that could lead to undue centralization and higher switching costs.</p>
<h1><a class="anchor" href="https://ethresear.ch#appendix-a-11" name="appendix-a-11"></a>Appendix A</h1>
<h2><a class="anchor" href="https://ethresear.ch#deriving-the-trade-probability-12" name="deriving-the-trade-probability-12"></a>Deriving the trade probability</h2>
<p>To see where Eq. (2) comes from, let’s model the price difference between CEX and DEX  as a Markovian jump-diffusion process. This allows us to derive the expression for the probability that stat-arbitrageurs can execute a profitable trade, i.e. that the price difference is higher than the fees needed to execute the trade.</p>
<p>If we assume that DEX and CEX prices follows a Brownian motion, since the difference between two Brownian motion is still a Brownian motion, we can model the price difference as a Brownian motion with volatility <span class="math">\sigma</span></p>
<div class="math">
\begin{equation}
dM(t) = \mu_Mdt+\sigma dW(t)\,,
\end{equation}
</div>
<p>where <span class="math">\mu_M</span> represents the drift of motion. In the presence of discrete time arrival for trades (i.e. jumps) modelled as a Poisson process with rate <span class="math">\lambda</span>,  we get</p>
<div class="math">
\begin{equation}
dM(t) = \mu_Mdt+\sigma dW(t) + j(M_{t-1}) dN(t)\,,
\end{equation}
</div>
<p>where <span class="math">j(M_{t-1}) dN(t)</span> is the contribution from jumps (depending only on immediately previous state <span class="math">j(M_{t-1})</span>, that’s where the Markovian approximation comes in). The density <span class="math">p(x,t)</span> of the process <span class="math">M(t)</span> is governed by Fokker-Planck equation</p>
<div class="math">
\begin{align}
\partial_t p(x,t) &amp;= -\mu_M\partial_x p(x,t) + \frac{\sigma^2}{2}\partial^2_xp(x,t)+\lambda\left[\int_{-\infty}^{+\infty}p(x-y,t)\delta(y-j)dy - p(x,t)\right]\\
&amp;=-\mu_M\partial_x p(x,t) + \frac{\sigma^2}{2}\partial^2_xp(x,t)+\lambda\left[p(x-j,t)-p(x,t)\right]\,,
\end{align}
</div>
<p>where the Dirac <span class="math">\delta</span> determine the dimension of the jump (we are assuming constant jumps) and <span class="math">\lambda</span> is the mean dimension of jumps in the price difference. In the absence of drift, the equation of the process is</p>
<div class="math">
\begin{equation}
\partial_tp(x,t)=\frac{\sigma^2}{2}\partial^2_xp(x,t)+\lambda\left[p(x-j,t)-p(x,t)\right]\,.
\end{equation}
</div>
<p>To find the stationary distribution (i.e. <span class="math">p(x)</span>), we can consider the case with <span class="math">\partial_tp(x,t)=0</span>, such that Fokker-Planck equation becomes</p>
<div class="math">
\begin{equation}
0=\frac{\sigma^2}{2}\partial^2_xp(x)+\lambda\left[p(x-j)-p(x)\right]\,.
\end{equation}
</div>
<p>Now, if we consider the Taylor expansion of <span class="math">p(x)</span> for small <span class="math">j</span> we obtain</p>
<div class="math">
\begin{equation}
p(x-j)\sim p(x)-j\partial_xp(x)+\frac{\lambda j^2}{2}\partial_x^2p(x)+\ldots\,,
\end{equation}
</div>
<p>which gives</p>
<div class="math">
\begin{equation}
0=\frac{1}{2}\left(\sigma^2+\lambda j^2\right)\partial^2_xp(x,t)-\lambda j\partial_xp(x)\,.
\end{equation}
</div>
<p>If we now observe that for</p>
<div class="math">
j\ll\frac{\sigma}{\sqrt{\lambda}}\,,
</div>
<p>we can neglect second order terms in <span class="math">j</span>. For the next part of the paper we’ll use</p>
<div class="math">
j=\frac{\sigma}{\sqrt{2\lambda}}=\sigma\sqrt{\frac{\bar{t}}{2}}\,,
</div>
<p>which means the dimension of the jump between trades is given by the volatility of price difference times the square root of half the time interval between trades. Under these assumptions our Fokker-Planck equation becomes</p>
<div class="math">
\begin{equation}
0=\frac{\sigma^2}{2}\partial^2_xp(x,t)-\frac{\sqrt{\lambda}\sigma}{\sqrt{2}}\partial_xp(x)\,.
\end{equation}
</div>
<p>This is a second order differential equation, with solution of the form</p>
<div class="math">
\begin{equation}
p(x)=Ae^{r_1x}+Be^{r_2x}\,,
\end{equation}
</div>
<p>where <span class="math">r_1</span> and <span class="math">r_2</span> are the solution of</p>
<div class="math">
\begin{equation}
r^2-\frac{\sqrt{2\lambda}}{\sigma}r=0\,.
\end{equation}
</div>
<p>It follows that</p>
<div class="math">
\begin{equation}
p(x)=A+Be^{\frac{\sqrt{2\lambda}}{\sigma}x}\,.
\end{equation}
</div>
<p>Since <span class="math">p(x)</span> is a density, it has to be normalized and not diverging for <span class="math">x\to\pm\infty</span>. This means that the solution has to be</p>
<div class="math">
\begin{equation}
p(x)=p_1(x|x\in[-\gamma,\gamma])+p_2(x|x\in(-\infty,-\gamma)\,\cup\,(\gamma,\infty))\,,
\end{equation}
</div>
<p>where</p>
<div class="math">
\begin{align}
&amp;p_1(x) = A\,,\qquad\qquad\qquad\,\,\,\, x\in[-\gamma,\gamma]\\
&amp;p_2(x) = Be^{-\frac{\sqrt{2\lambda}}{\sigma}(|x|-\gamma)}\,,\qquad x\in(-\infty,\gamma] \cup [\gamma,\infty)\,.
\end{align}
</div>
<p>The nature of <span class="math">p_2(x)</span> is that it is null at infinity. Now, if we impose continuity of <span class="math">p(x)</span> at boundaries, we have</p>
<div class="math">
p_1(\gamma)=p_2(\gamma)\Rightarrow A = B e^0 = B\,.
</div>
<p>It follows that, by imposing the symmetry condition and the fact that <span class="math">p(x)</span> is a density we get</p>
<div class="math">
\begin{align*}
&amp;2\int_0^\infty p(x)dx = 1 \\
&amp;\to \left.2Ax\right|_0^\gamma-\left.2\frac{B\sigma}{\sqrt{2\lambda}}e^{-\frac{\sqrt{2\lambda}}{\sigma}(|x|-\gamma)}\right|_\gamma^\infty=1\\
&amp;\to 2A\gamma\left(1+\frac{1}{\xi}\right)=1\,,
\end{align*}
</div>
<p>where we introduced the parameter <span class="math">\xi=\frac{\sqrt{2\lambda}\gamma}{\sigma}</span>, characterizing the behaviour of the price difference process. By solving for A, it follows that</p>
<div class="math">
\begin{split}
&amp;p_1(x) = \frac{1}{2\gamma}\frac{\xi}{1+\xi}\,,\qquad\qquad\qquad\,\,\,\, x\in[-\gamma,\gamma]\\
&amp;p_2(x) = \frac{1}{1+\xi}\frac{\xi}{2\gamma}e^{-\frac{\xi}{\gamma}(|x|-\gamma)}\,,\qquad x\in(-\infty,\gamma] \cup [\gamma,\infty)\,.
\end{split}
</div>
<p>Now, we are interested in computing the probability of the trade area. This has as density</p>
<div class="math">
\begin{equation}
p_2(x|x\in(-\infty,-\gamma))+p_2(x|x\in(\gamma,\infty))=\frac{1}{1+\xi}\frac{\xi}{\gamma}e^{-\frac{\xi}{\gamma}(|x|-\gamma)}\,,
\end{equation}
</div>
<p>and since</p>
<div class="math">
\frac{\xi}{\gamma}e^{-\frac{\xi}{\gamma}(|x|-\gamma)}\,,
</div>
<p>is the density of an exponential distribution and that is the only part dependent from <span class="math">x</span>, we have that the invariant for the trade region probability is</p>
<div class="math">
P=\frac{1}{1+\xi}=\frac{1}{1+\frac{\sqrt{2\lambda}\gamma}{\sigma}}\,,
</div>
<p>that is the result used in Eq. (2). Note that this result is consistent with what presented in <a href="https://arxiv.org/pdf/2305.14604" rel="noopener nofollow ugc">Milionis et al</a>, even if the derivation is different.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmations-under-the-no-lens/19975">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 09:39:35 +0000</pubDate>
</item>
<item>
<title>Leaderless and Leader-Based Preconfirmations</title>
<link>https://ethresear.ch/t/leaderless-and-leader-based-preconfirmations/19971</link>
<guid>https://ethresear.ch/t/leaderless-and-leader-based-preconfirmations/19971</guid>
<content:encoded><![CDATA[
<div> 关键词：preconfirmation (预确认), leader-based, leaderless, sourcing leaders, mev-boost

总结:
本文讨论了两种类型的预确认系统：领导型和无领导型。领导型预确认由单一权威提供，确保较高保证但可能导致集中；无领导型通过竞争提供价格发现，可能创造更有价值的区块，但存在不确定性。文章提出“ sourcing leaders”作为结合两者的优势，他们从竞争性提供商处获取预确认并为用户提供100%保证。文章还探讨了领导选举机制、拍卖与抽奖等方法，以及如何优化价格结构以防止集中。未来研究方向包括游戏理论分析、定价策略和集成现有MEV提升基础设施。 <div>
<p><em>Joint work with <a class="mention" href="https://ethresear.ch/u/murat">@murat</a>. Thanks to <a class="mention" href="https://ethresear.ch/u/the-ctra1n">@The-CTra1n</a> and <a class="mention" href="https://ethresear.ch/u/bemagri">@bemagri</a> for reviewing and providing valuable feedback.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>A preconfirmation (preconf) for the context of this article refers to a promise about a given set of transactions relative to a future block, e.g., execution of a transaction in the next block or placing transactions at the top of the block. Entities who want to obtain a preconf can bid a certain amount indicating how much they are willing to pay for a preconf.</p>
<p>One dimension in which preconfs can be distinguished is whether there exists a unique preconf provider for every L1 block (a preconf leader), or whether there can be multiple competing preconf providers for every L1 block, without a leader. We here discuss the two approaches, their respective advantages and disadvantages, and how they can be combined. A particularly promising approach for combining the two concepts to obtain the best of both worlds appears to be using “sourcing leaders”, which are operating in a leaderless setting and collect preconfs from competing preconf providers.</p>
<h1><a class="anchor" href="https://ethresear.ch#overview-and-definitions-2" name="overview-and-definitions-2"></a>Overview and Definitions</h1>
<h2><a class="anchor" href="https://ethresear.ch#leader-based-preconfs-3" name="leader-based-preconfs-3"></a>Leader-Based Preconfs</h2>
<p>The simplest form of preconfs are ones issued by an appointed leader. This leader must have the authority to issue preconfs and have some means to enforce them. It is not necessary to have a single leader overall, as long as there is a unique, predetermined, and publicly known leader at each point in time. A straightforward way to choose leaders is using the current L1 proposer, as, e.g., in <a href="https://github.com/Commit-Boost/commit-boost-client" rel="noopener nofollow ugc">commit-boost</a>. More sophisticated leader-election methods are discussed below, and can be employed by <a href="https://docs.primev.xyz/concepts/what-is-mev-commit" rel="noopener nofollow ugc">mev-commit</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#leaderless-preconfs-4" name="leaderless-preconfs-4"></a>Leaderless Preconfs</h2>
<p>An alternative to leader-based preconfs is to have multiple preconf providers simultaneously. The most natural instantiation of this is to have the block builders act as preconf providers, leveraging the strengths of the existing mev-boost landscape. This mechanism is <a href="https://docs.primev.xyz/concepts/what-is-mev-commit" rel="noopener nofollow ugc">used by mev-commit</a>. In this case, a single preconf provider cannot provide an authoritative preconf; in case the block builders are preconf providers, a single builder can only promise to honor the preconf for the blocks this block builder builds.</p>
<p>A preconf from a single block builder thus constitutes a probabilistic preconf in the sense that the preconf is conditioned on the issuing block builder winning the corresponding block. This can already be useful, e.g., for arbitrage searchers. A proper preconf with a 100% guarantee is obtained if all block builders preconfirm. A subtlety of this is that the set of all possible block builders must be known, which is not the case in a permissionless setting. This is solved by mev-commit by letting <a href="https://docs.primev.xyz/get-started/providers/registering-a-provider" rel="noopener nofollow ugc">block builders register</a> as providers and <a href="https://docs.primev.xyz/get-started/validators" rel="noopener nofollow ugc">proposers and relays opt-in</a> to only deliver blocks from registered block builders. Analyzing the game-theoretic interplay between bidders and multiple preconf providers is an interesting open problem.</p>
<h1><a class="anchor" href="https://ethresear.ch#comparison-5" name="comparison-5"></a>Comparison</h1>
<p>Both approaches have their advantages and disadvantages, which we discuss below.</p>
<h2><a class="anchor" href="https://ethresear.ch#advantages-of-leader-based-preconfs-6" name="advantages-of-leader-based-preconfs-6"></a>Advantages of Leader-Based Preconfs</h2>
<p>The most obvious advantage of leader-based preconfs is that a single preconf already constitutes almost a 100% guarantee (almost because the slot may be missed or the chain reorged). This simplifies the protocol interaction and also possibly provides faster feedback. Note that reorg risks are the same for all types of preconfs, so we do not discuss them further here.</p>
<h2><a class="anchor" href="https://ethresear.ch#advantages-of-leaderless-preconfs-7" name="advantages-of-leaderless-preconfs-7"></a>Advantages of Leaderless Preconfs</h2>
<p>Having multiple simultaneous preconf providers creates a competitive environment, allowing for efficient preconf price discovery and thereby optimizing validator yield. A single provider having a preconf monopoly, on the other hand, can dictate the prices arbitrarily.</p>
<p>Further advantages come from letting the block builders be the preconf providers. First, block builders have sufficient sophistication to properly price preconfs. Secondly, builders are building the blocks and thus are the only entities that can issue preconfs without interfering with block production and adding latency: If another party issues a preconf, it must be communicated to the block builders such that they can build compatible blocks, and failure to receive the preconf in time leads to the block builder building a block violating the preconf. This also means that there is some delay between issuing the preconf and the builders learning about it in a leader based approach, which is particularly problematic towards the end of a slot, where builders may learn too late about the preconf. This also creates an advantage for block builders with fast connections to the preconf leaders, potentially leading to further centralization. Furthermore, receiving a preconf from a separate entity interferes with the block building strategy of the builders and thus can potentially lead to substantially less valuable blocks. Finally, leaderless preconfs can be integrated more easily into the existing mev-boost infrastructure.</p>
<h1><a class="anchor" href="https://ethresear.ch#leader-election-8" name="leader-election-8"></a>Leader Election</h1>
<p>As mentioned above, the simplest way to elect a preconf leader is to choose the current L1 proposer. This, however, requires additional sophistication from the proposer and likely leads to economic inefficiencies. It is therefore likely that proposers want to outsource preconfs similarly to how proposers outsource block building in PBS, even though this might raise concerns such as increased complexity due to additional actors, and potentially more centralization. A crucial difference from PBS is that preconf leaders need to be chosen in advance, i.e., before preconf bids are available. Thus, when the right to become a preconf leader is auctioned off, the potential leaders need to place their bids in the leader election without knowing the value they can derive from becoming a leader. This means their bids can only be based on expected values rather than actual amounts as in PBS, similarly to <a href="https://ethresear.ch/t/execution-tickets/17944">execution tickets</a>. A notable exemption to this are scenarios in which preconfs are not time critical such as preconfs for blob inclusion bids. In this case, the auction can be run after all preconf bids have been issued and thus the auction can be based on the actual value instead of the expected one (cf. <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">Ethereum Research - Blob Preconfirmations with Inclusion Lists to Mitigate Blob Contention and Censorship</a>).</p>
<p>One concern with an expected-value-based auction is that this value likely remains relatively stable over time and thus a possible scenario is that a single entity that is very good at pricing wins an overwhelming fraction of the auctions, leading to centralization and a preconf monopoly (cf. <a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814/1" rel="noopener nofollow ugc">The Flashbots Collective - When To Sell Your Blocks</a>). A possible mitigation to this problem is to instead of running an auction, sell lottery tickets and choose the leader randomly as the holder of the winning ticket. This is akin to a similar mechanism recently proposed by <a href="https://hackmd.io/@EspressoSystems/market-design" rel="noopener nofollow ugc">Espresso Systems in a related context</a>. Further research is required to determine an optimal pricing structure for such lotteries.</p>
<h1><a class="anchor" href="https://ethresear.ch#combining-leaderless-and-leader-based-preconfs-9" name="combining-leaderless-and-leader-based-preconfs-9"></a>Combining Leaderless and Leader-Based Preconfs</h1>
<p>To obtain the best of both worlds, one can combine a leaderless with a leader-based approach. We discuss some options how to achieve this below.</p>
<h2><a class="anchor" href="https://ethresear.ch#simultaneous-leaders-and-leaderless-providers-10" name="simultaneous-leaders-and-leaderless-providers-10"></a>Simultaneous Leaders and Leaderless Providers</h2>
<p>One option to combine leaderless and leader-based preconfs is to have a dedicated preconf leader, but let this leader operate simultaneously with multiple non-leader preconf providers. We assume below that the non-leader providers are block builders. In such a scheme, both the leader and the builders can issue preconfs at any point in time. When the leader issues a preconf, it must be communicated to the block builders, who then need to honor them when building their blocks. At this point, block builders cannot commit to the already committed bid anymore (since such commitment would not add any value). On the other hand, if a builder issues a preconf first, the leader can still commit to the same bid, turning the preconf from the builder into a 100% guaranteed preconf.</p>
<p>While this approach might appear conceptually simple, it comes with several challenges. One issue is that it is probably very hard, if not impossible, for the leader to issue execution preconfs that are compatible with execution preconfs of the block builders. This approach might therefore be limited to inclusion preconfs. Another issue is the timing of preconfs: For the mechanism to work, a total order among preconfs needs to be established, since a builder should only be rewarded for a preconf on a bid that also been committed to by the leader if the builder committed first. This total order can be established by a dedicated side-chain, such as the mev-commit chain. Nevertheless, there is room for leaders to play games with the competing builders by delaying their preconfs or trying to frontrun the builders. Yet another difficulty of this approach are the more complex incentives. Who should be paid how much in case multiple preconfs are issued? Developing a fair mechanism that leads to good preconf prices requires further research.</p>
<h2><a class="anchor" href="https://ethresear.ch#sourcing-leaders-11" name="sourcing-leaders-11"></a>Sourcing Leaders</h2>
<p>An alternative is to have leaders that themselves have no authority to enforce preconfs. Instead, the leaders receive bids from end users and subsequently try to obtain preconfs from the preconf providers. We call such leaders “sourcing leaders”. Once the sourcing leader has obtained preconfs from all providers, they issue a preconf to the end user. A sourcing leader is not strictly speaking a leader as defined above, but can provide the same advantage of a leader, namely issuing preconfs that themselves provide a 100% guarantee to the end user.</p>
<p>The role of a sourcing leader can be taken on by sophisticated actors such as solvers. A sourcing leader can in this case also offer preconfs before all providers have issued one and charge a premium to take on the risk that the preconf is violated. It is furthermore possible to have multiple competing sourcing leaders that offer preconfs with different prices at different speeds, where users can choose the best one for their purposes.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/d/1df247e0731521b812fdecf14287017b6e1a772b.png" title="Sourcing Leader"><img alt="Sourcing Leader" height="219" src="https://ethresear.ch/uploads/default/optimized/3X/1/d/1df247e0731521b812fdecf14287017b6e1a772b_2_690x219.png" width="690" /></a></div><br />
<strong>Figure 1:</strong> Illustration of the interaction between an end user, a sourcing leader running a bidder node, and three preconf providers.<p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-and-open-problems-12" name="conclusion-and-open-problems-12"></a>Conclusion and Open Problems</h1>
<p>Both leader-based and leaderless preconfs offer unique advantages and challenges. Leader-based preconfs offer a 100% guarantee (ignoring missed slots and reorgs) with a single preconfirmation, whereas leaderless ones create a competitive environment, enabling efficient price discovery, and potentially leading to more valuable blocks. Different methods for leader election also have their own trade-offs, with options ranging from auctions to lotteries.</p>
<p>Combining leaderless and leader-based preconfs can provide the benefits of both systems. One approach is to have a dedicated preconf leader operating alongside non-leader providers. Another approach is to use sourcing leaders who have no enforcement authority themselves, but attempt to obtain preconfs from providers. Both approaches allow for a high degree of competition, but also pose additional challenges.</p>
<p>There are still several unresolved research problems uncovered in this article. One of them is to analyze the game-theoretic interplay between bidders and multiple preconf providers in a leaderless preconf system. For a leader-based approach, relevant open problems are determining an optimal pricing structure for preconf leader lotteries to mitigate the risk of centralization and a preconf monopoly, and how to integrate with the existing mev-boost infrastructure. For combining leaderless and leader-based preconfs, designing fair mechanisms for the interaction between both types of preconf providers is left for future research. Finally, an important open question is how the approach with a sourcing leader compares to the others in terms of obtaining fair prices.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/leaderless-and-leader-based-preconfirmations/19971">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 20:41:05 +0000</pubDate>
</item>
<item>
<title>Execution Consensus Separation</title>
<link>https://ethresear.ch/t/execution-consensus-separation/19964</link>
<guid>https://ethresear.ch/t/execution-consensus-separation/19964</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、共识层、执行层、应用层、多提案者共识（MCP）

总结:<br />
文章讨论了执行一致性分离在解决以太坊上的交易优先权执行问题（MEV）中的关键作用。首先，需要改善共识层的抗审查能力，引入多提案者共识（MCP），允许多个提案者同时提出交易，增强交易的包容性。其次，执行层需实现延迟执行和确定性调度规则，确保交易按照规则有序进行。最后，应用层应发展为无序机制，例如通过链上拍卖避免价格猜测导致的价值损失。这些升级将使以太坊对开发者和用户更加友好，研究者可共同推进这一安全协议的改进。 <div>
<h2><a class="anchor" href="https://ethresear.ch#execution-consensus-separation-1" name="execution-consensus-separation-1"></a>Execution Consensus Separation</h2>
<p><strong></strong></p><div class="lightbox-wrapper"><strong><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b9eb4b7bcec14c8b9a8aee948a332d9d48013e4.jpeg" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b9eb4b7bcec14c8b9a8aee948a332d9d48013e4_2_500x500.jpeg" width="500" /></a></strong></div><br />
MEV is fundamentally about control. The proposer has control of which transactions make it into blocks and which order they appear in. In other words MEV is all about censorship and reordering. All of the goals on the Ethereum roadmap related to MEV are therefore impossible without fixing these things. The good news is that fixing these things is possible, the bad news is that the solution requires us to work together to study and prove the security of some meaningful upgrades to both consensus and execution.<p></p>
<p>Current work on the <a href="https://x.com/VitalikButerin/status/1741190491578810445" rel="noopener nofollow ugc">“Scourge” section</a> of the <a href="https://ethereum.org/en/roadmap/" rel="noopener nofollow ugc">Ethereum roadmap</a> has been siloed. People work on individual problems and sometimes lose the broader scope of what we are ultimately trying to achieve. <a href="https://ethresear.ch/t/epbs-design-constraints/18728">ePBS</a>, <a href="https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474" rel="noopener nofollow ugc">Inclusion Lists</a>, <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV Burn</a>, <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">Distributed Block Building</a>, and <a href="https://x.com/VitalikButerin/status/1741190491578810445" rel="noopener nofollow ugc">Application-layer MEV minimization</a>, are examples of ideas that require censorship resistance and control over ordering, but we haven’t yet addressed the pre-requisites. Solving these allows us to kill 5 birds with 1 stone. But to do this we need to think from first principles and work on the underlying root causes rather than tinkering with a thin veneer on top of the protocol.</p>
<p>Solving MEV at the protocol level requires buy in from all three levels of the chain:</p>
<ol>
<li><strong>Consensus Layer:</strong> Multiple concurrent proposers.</li>
<li><strong>Execution Layer:</strong> Delayed execution and deterministic scheduling rules.</li>
<li><strong>Application Layer:</strong> Order-agnostic applications.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#consensus-layer-2" name="consensus-layer-2"></a>Consensus layer</h2>
<p>We cannot get anywhere without vastly improved censorship resistance at the consensus layer. This is what allows us to hold auctions and prevent censorship of competing bids. The root cause of Ethereum’s weak censorship resistance is the fact that only a single entity can include transactions during each 12 second slot. <strong>Multiple concurrent proposers (MCP)</strong> fixes this problem. Instead of coming to consensus on an ordered block of transactions from a single block proposer, each of the K proposers propose a set of transactions at the same time. The protocol then aggregates these proposals using a <strong>common subset</strong> primitive (or a similar algorithm, this is an active area of research), yielding an unordered set of transactions which are to be included in the block.</p>
<p>MCP solves the problem of censorship-resistant inclusion, achieving the goals of <a href="https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474" rel="noopener nofollow ugc">Inclusion Lists</a> in a more natural way. The output is an unordered set of transactions, so it does not solve the problem of reordering. That will be the responsibility of the execution layer.</p>
<p>MCP is an area of active study and we encourage people to get involved. See SMG <a href="https://mechanism.org/spec/01" rel="noopener nofollow ugc">SPEC-01</a> for a theoretical description of MCP. Work is currently underway at SMG to formally specify MCP and create a proposed implementation of a gadget for use in the Ethereum protocol. Contact us if you are interested in working on this.</p>
<h2><a class="anchor" href="https://ethresear.ch#execution-layer-3" name="execution-layer-3"></a>Execution layer</h2>
<p>Ethereum’s execution layer must be upgraded to solve the problem of transaction reordering. To do this, we must delay the calculation of the state root to the next block so that the execution layer has time to implement a deterministic ordering rule.</p>
<p>Once it has the transactions, the execution layer has a new important job: figuring out how to order them. To do this, we need to select a <strong>deterministic scheduling rule</strong>. This is an area of active study where we encourage people to get involved. There are many promising candidates: <a href="https://www.paradigm.xyz/2024/06/priority-is-all-you-need" rel="noopener nofollow ugc">priority fee ordering</a>, as-needed execution, and <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">distributed block building</a>. We will elaborate on the last two in an upcoming article.</p>
<p>With delayed execution and a deterministic scheduling rule, Ethereum’s execution layer will determine the order of transactions in a block, allowing it to achieve the same goals as <a href="https://github.com/flashbots/mev-boost/issues/139" rel="noopener nofollow ugc">distributed block building</a> and <a href="https://ethresear.ch/t/epbs-design-constraints/18728">ePBS</a> in a more natural way. In addition, since the ordering is enforced by the logic of the protocol, not by the goodwill of any particular validator, the protocol can burn all the fees at this stage, achieving the goals of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">MEV Burn</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#application-layer-4" name="application-layer-4"></a>Application layer</h2>
<p>Assuming we succeed in the above upgrades, Ethereum’s application layer will be free to upgrade their applications to be natively MEV-resistant while remaining totally onchain. We call the class of things they will do <strong>order-agnostic applications</strong> or order-agnostic mechanisms.</p>
<p>For example take the problem of liquidation MEV. For the sake of argument, suppose we have 1000 ETH that needs to be liquidated for DAI. We don’t know what the appropriate price is for the ETH, so we have two options: we can guess the right price and have a posted price available to the first person who claims it, which is how Compound and Aave work, and leads to tremendous value leaked to liquidation races, reducing UX. Or, we can hold a Dutch auction, which leads to slightly less value leakage, but doesn’t allow us to clear the distressed debt right away. But now, with MCP and deterministic scheduling, these protocols can simply hold an onchain auction for the right to liquidate 1000 ETH and elicit the price that way.</p>
<p>Order agnostic application design has a number of benefits, and there are many more examples of places where MEV leaks that can be solved. Future posts will elaborate on this.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-5" name="conclusion-5"></a>Conclusion</h2>
<p>The successful implementation of these upgrades will result in a much friendlier Ethereum for both developers and users. The first step of this research program is fleshing out and proving the security of a multi proposer design with simultaneous release. Other blockchains have multiple proposers, but are not designed in the same way or for the same purpose. If you are a consensus researcher interested in working on this topic, please reach out, we have funding available for this.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/execution-consensus-separation/19964">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 19:09:20 +0000</pubDate>
</item>
<item>
<title>Fork Choice compliance test suites &amp; test generator</title>
<link>https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954</link>
<guid>https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954</guid>
<content:encoded><![CDATA[
<div> 关键词：Fork Choice、测试生成器、测试套件、性能优化、未来步骤

总结:<br />
Fork Choice合规性测试生成器已完成初步实施，能够为客户端开发团队提供测试模板。已经生成了三个测试套件（Tiny、Small和Standard），涵盖不同规模的测试目的。尽管生成Extended测试套件需要时间，但支持多进程以提高效率。目前的测试速度较慢，未来将优化性能并增加模型灵活性，计划进行覆盖率导向的模糊测试和新的测试向量格式。整体目标是简化测试采用并确保协议的正确实现。 <div>
<p>This is a preliminary announcement, we’ll officially announce during the next All Core Devs call.</p>
<p>We (TxRx team, ConsenSys) have implemented a Fork Choice compliance test generator as well as have generated Fork Choice compliance test suites.</p>
<p>Overall F/C compliance testing methodology is described <a href="https://hackmd.io/@ericsson49/fork-choice-implementation-vs-spec-testing" rel="noopener nofollow ugc">here</a>.</p>
<p>In this report we briefly describe the results of the initial implementation phase (i.e. the F/C test generator and F/C test suites).  A more detailed description of the work is TBD.</p>
<p>This work was supported by a grant from the Ethereum Foundation.</p>
<h1><a class="anchor" href="https://ethresear.ch#implementation-status-1" name="implementation-status-1"></a>Implementation status</h1>
<h2><a class="anchor" href="https://ethresear.ch#test-generator-2" name="test-generator-2"></a>Test generator</h2>
<p>The initial version of the Fork Choice tests generator is implemented and currently available as a draft <a href="https://github.com/ethereum/consensus-specs/pull/3831" rel="noopener nofollow ugc">consensus-specs PR</a>. We have been focusing on minimizing efforts for client implementer teams to adopt the generated tests. The only a small change to the existing <a href="https://github.com/ethereum/consensus-specs/tree/dev/tests/formats/fork_choice" rel="noopener nofollow ugc">FC test format</a> is the addition of a <a href="https://github.com/ericsson49/eth2.0-specs/tree/fc-compliance2/tests/formats/fork_choice#checks-step" rel="noopener nofollow ugc">new check</a>, which is safe to ignore initially.</p>
<h2><a class="anchor" href="https://ethresear.ch#test-suites-3" name="test-suites-3"></a>Test suites</h2>
<p>We have developed test generation parameters for three suites at the moment.</p>
<div class="md-table">
<table>
<thead>
<tr>
<th>Test suite</th>
<th>size</th>
<th>Purpose</th>
<th>Status</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tiny</td>
<td>135 tests</td>
<td>Demonstration, smoke testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1dWbkJY27fhOVX8i4aUuZ7VBkH3P_Vr1i/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Small</td>
<td>1472 tests</td>
<td>Initial adoption, smoke testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1EAIeTL5F3zelXK5pBkSLuawJjuLWQx3r/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Standard</td>
<td>13240 tests</td>
<td>Main testing</td>
<td>Done</td>
<td><a href="https://drive.google.com/file/d/1_56JObwYWHARgm5QYmE4vrkcLEru854G/view?usp=drive_link" rel="noopener nofollow ugc">link</a></td>
</tr>
<tr>
<td>Extended</td>
<td>about 100K tests</td>
<td>Extended testing</td>
<td>TBD</td>
<td></td>
</tr>
</tbody>
</table>
</div><p><strong>Note</strong>: We are able to generate the Extended test suite. However, it will take significant time (about a week), therefore, we have delayed actual test suite generation until it will be demanded.</p>
<p>It should be possible to generate test suites for any fork (Altair, Capella, Deneb) and preset (mainnet or minimal). However, test generation for mainnet is very slow. We have tested minimal/altair and minimal/deneb.</p>
<p>Test generation currently is slow (about 10-15 seconds per test on average). However, a multiprocessing mode is supported (about 2 seconds per test on Apple M1). Generation of the Standard test suite takes about 8 hours (multiprocessing mode) or two days (single process mode).</p>
<p>The reasons of slow performance are known and are to be alleviated in future. Currently, our top priority is to simplify adoption of the new test suites.</p>
<h2><a class="anchor" href="https://ethresear.ch#testing-the-tests-4" name="testing-the-tests-4"></a>Testing the tests</h2>
<p>We have run the generated tests against <a href="https://github.com/Consensys/teku" rel="noopener nofollow ugc">Teku</a>, using Teku test runner and against the official executable Fork Choice spec (minimal/deneb), using a simple Python <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_run.py" rel="noopener nofollow ugc">test runner</a>.</p>
<h1><a class="anchor" href="https://ethresear.ch#test-generation-approach-5" name="test-generation-approach-5"></a>Test generation approach</h1>
<p>The test generation approach is a mix of model-based and fuzz testing.</p>
<p>Principles:</p>
<ul>
<li>the Fork Choice spec is virtually “decomposed” into two parts: topological sorting of events and actual event processing</li>
<li>tests are generated for the event processing part, the topological sorting part is addressed via event shuffling (time shift plus drop/duplication)</li>
<li>models are used to describe the spec aspects that we want to cover. There are two flavors: trees of various shapes (for block trees and super-majority link trees) and predicates to be covered (<code>filter_block_tree</code>)</li>
<li>for each model there can be multiple solutions, each solution can be seen as a template (e.g. SM link tree + block tree) which can be instantiated in multiple ways (varying validator actions)</li>
<li>each test case can be mutated multiple times</li>
</ul>
<p>Tests are generated with four steps:</p>
<ol>
<li>Models (implemented using MiniZinc), describing abstract coverage aspects that we want to cover. Currently there are three models: <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/SM_links.mzn" rel="noopener nofollow ugc">SM link</a> (super-majority link) tree model, <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/Block_tree.mzn" rel="noopener nofollow ugc">Block tree</a> model and <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/model/minizinc/Block_cover3.mzn" rel="noopener nofollow ugc">Block cover</a> model.</li>
<li>For each model a set of solutions is produced. The models are parameterized, which affects the size of solution set generated.
<ul>
<li>SM link and block tree solutions are combined into a single block tree.</li>
</ul>
</li>
<li>Each solution is instantiated using two test instantiators (<a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/block_tree.py" rel="noopener nofollow ugc">block tree</a> and <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/block_cover.py" rel="noopener nofollow ugc">block cover</a>). The instantiation is randomized, i.e. a coin is flipped on each decision point. This results in a complete Fork Choice test case (i.e. <em>anchor state</em> plus a sequence of <em>tick</em> | <em>block</em> | <em>attestation</em> | <em>attester_slashing</em> events).</li>
<li>Each test case is mutated via <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/instantiators/mutation_operators.py" rel="noopener nofollow ugc">mutation</a> (shuffling) operators. Currently, there are thee mutation operator: time shift, drop and duplicate (with consequent shifting).</li>
</ol>
<p>The models are developed manually.<br />
Solutions to the models are produced with a special <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/generate_test_instances.py" rel="noopener nofollow ugc">generator</a>.<br />
Test instantiators and mutations are performed with <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_gen.py" rel="noopener nofollow ugc">test_gen.py</a>.</p>
<p>After tests are generated, one can validate the produced test steps using <a href="https://github.com/ericsson49/eth2.0-specs/blob/4a0745bd7c0ec6d6a216a8baf81bcb80c30ccaa3/tests/generators/fork_choice_generated/test_run.py" rel="noopener nofollow ugc">test_run.py</a> script, which executes the steps using the pyspecs, performing prescribed checks.</p>
<h1><a class="anchor" href="https://ethresear.ch#test-structure-6" name="test-structure-6"></a>Test structure</h1>
<div class="md-table">
<table>
<thead>
<tr>
<th>Test group</th>
<th>size (standard suite)</th>
<th>parameters (solutions + variations + mutations)</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Block tree</td>
<td>4096 tests</td>
<td>1024*2*(1+1)</td>
<td>focus on trees of varying shapes</td>
</tr>
<tr>
<td>Block weight</td>
<td>2048 tests</td>
<td>8*64*(1+3)</td>
<td>focus on producing block trees with varying weights</td>
</tr>
<tr>
<td>Shuffling</td>
<td>2048 tests</td>
<td>8*4*(1+63)</td>
<td>focus on shuffling/mutation operators</td>
</tr>
<tr>
<td>Attester slashing</td>
<td>1024 tests</td>
<td>8*16*(1+7)</td>
<td>focus on attester slashing</td>
</tr>
<tr>
<td>Invalid messages</td>
<td>1024 tests</td>
<td>8*32*(1+3)</td>
<td>focus on invalid messages</td>
</tr>
<tr>
<td>Block cover</td>
<td>3000 tests</td>
<td>60*5*(1+9)</td>
<td>cover various combinations of predicates from the <code>filter_block_tree</code> method</td>
</tr>
</tbody>
</table>
</div><h1><a class="anchor" href="https://ethresear.ch#future-steps-7" name="future-steps-7"></a>Future steps</h1>
<ul>
<li>improve performance. Performance is adequate right now (for the initial adoption phase). But is the main blocker otherwise.</li>
<li>more flexible test generation. More and better models, better instantiators, better mutation operators.</li>
<li>coverage-guided fuzzing</li>
<li>new test vector format (don’t need full test cases for fuzz testing, as need to compare against the FC spec anyway)</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-compliance-test-suites-test-generator/19954">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 20:00:49 +0000</pubDate>
</item>
<item>
<title>Ethereum Node Message Propagation Bandwidth Consumption</title>
<link>https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952</link>
<guid>https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952</guid>
<content:encoded><![CDATA[
<div> 关键词：GossipSub, Bandwidth consumption, Hermes, Optimization, Ethereum P2P network

总结:
GossipSub在以太坊P2P网络中的性能研究发现，SENT_IHAVE和RECV_IHAVE消息消耗了大量带宽，分别占总带宽的23.4%和10%，对出站和入站流量影响显著。研究建议改进机制以减少重复消息，这将节省约42%的总带宽。尽管Hermes节点配置非标准，但研究结果证实了优化空间。与其他节点的比较显示，当前以太坊节点的带宽使用率相对较低，仍有提升余地。总的来说，这项工作旨在通过深入了解GossipSub的性能，为协议优化提供依据。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-tldr-1" name="summary-tldr-1"></a>Summary &amp; TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io </a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the <a class="inline-onebox" href="https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921">Number Duplicate Messages in Ethereum's Gossipsub Network</a>, in this post we investigate bandwidth consumption at the GossipSub level, i.e., bandwidth consumption for message propagation. The target of the study is to identify the protocol components that consume the biggest share of network bandwidth. The study has been co-authored by <a class="mention" href="https://ethresear.ch/u/cortze">@cortze</a> and <a class="mention" href="https://ethresear.ch/u/yiannisbot">@yiannisbot</a>.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer. </a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions. The results reported here are from a 3.5hr trace.</p>
<p><strong>Study Description:</strong> The distributed nature of p2p systems makes them generally less effective in computational, latency, and bandwidth consumption. This is due to the extra interactions between nodes needed to organize a p2p network without a central authority that bridges between peers. Thus, taking care of processes, such as peer or content discovery, content sharing, and message broadcasting often become a challenge, or bottleneck.</p>
<p>Ethereum is not different in that respect. Message propagation takes a large portion of the network bandwidth used by a node in the Ethereum network. This study investigates bandwidth consumption at the GossipSub level. The target is to identify the protocol components that consume the biggest share of network bandwidth.</p>
<p><strong>TL;DR:</strong> Despite the fact that the configuration of our <code>Hermes</code> node, which, in this case, doesn’t represent a standard node in the Ethereum network, the bandwidth consumption numbers of GossipSub validate that there’s plenty of space for optimization.</p>
<p>We observed that a significant portion of bandwidth is spent on <code>SENT_IHAVE</code> messages (23.4% of the total bandwidth and 30% of the total outgoing bandwidth) and <code>RECV_IHAVE</code> messages (10% of the total bandwidth, and 42% of the total inbound bandwidth).</p>
<p>More than anything, these findings validate the improvement recommendations made during our previous study on the “Effectiveness of Gossipsub’s gossip mechanism”: <a class="inline-onebox" href="https://ethresear.ch/t/gossip-iwant-ihave-effectiveness-in-ethereums-gossipsusb-network/19686">Gossip IWANT/IHAVE Effectiveness in Ethereum's Gossipsusb network</a></p>
<p>Taking into account that a node doesn’t only receive duplicated messages but also generates duplicates to others, we strongly recommend pushing the <a href="https://github.com/libp2p/specs/pull/560" rel="noopener nofollow ugc">GossipSub1.2</a> initiative, as it will effectively eliminate the bandwidth wasted on receiving or generating duplicates, which amounts to ~42% of total bandwidth.</p>
<h1><a class="anchor" href="https://ethresear.ch#results-on-bandwidth-consumption-2" name="results-on-bandwidth-consumption-2"></a>Results on Bandwidth Consumption</h1>
<blockquote>
<p><img alt=":eyes:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/eyes.png?v=12" title=":eyes:" width="20" /> NOTES: The bandwidth usage displayed in this study is limited to:</p>
<ul>
<li>The <code>Holesky</code> network</li>
<li>The GossipSub RPC calls</li>
<li>The following GossipSub topics:
<ul>
<li><code>beacon_block</code></li>
<li><code>beacon_aggregate_and_proof</code></li>
<li><code>sync_commmittee_contribution_and_proof</code></li>
<li><code>attester_slashing</code></li>
<li><code>proposer_slashing</code></li>
<li><code>voluntary_exit</code> * (check <code>Hermes</code> issue → <a class="inline-onebox" href="https://github.com/probe-lab/hermes/issues/24" rel="noopener nofollow ugc">Broadcasting of invalid `voluntary_exit` messages to mesh peers · Issue #24 · probe-lab/hermes · GitHub</a>)</li>
<li><code>bls_to_execution_change</code></li>
</ul>
</li>
<li>The bandwidth of <code>SENT_IHAVE</code> and <code>RECV_IHAVE</code> RPC calls has been calculated based on the number of bytes per <code>topic</code>  strings and <code>msg_ids</code> that were inside.</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#netin-vs-netout-3" name="netin-vs-netout-3"></a>NetIn vs NetOut</h2>
<p>The study starts with a general overview of what is the ratio of sent vs received bandwidth consumption. The following graph shows that on the <code>Hermes</code> node, the biggest share of the bandwidth comes from the data that we send out to the connected peers.</p>
<p>The total outbound bandwidth is around 3 to 4 times higher than the inbound. Note that <code>Hermes</code> differs from a standard node in that it keeps more peer connections (around 250 peers). This clearly has a significant impact on bandwidth usage. That said, although the numbers are not representative of the bandwidth usage of a normal node in absolute terms, the percentage split still represents that of a normal node.</p>
<p>Narrowing down, we observe a ratio of 700-800 KB/s for outgoing traffic and 200 KB/s for incoming traffic.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/f/4fb2e194b5b97ea9f84092740d059ad4447d2061.jpeg" title="bandwidth-in-out"><img alt="bandwidth-in-out" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/4/f/4fb2e194b5b97ea9f84092740d059ad4447d2061_2_517x309.jpeg" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#bandwidth-based-on-each-event-type-4" name="bandwidth-based-on-each-event-type-4"></a>Bandwidth based on each event type</h2>
<p>GossipSub sends multiple types of messages with different purposes. From control messages to keep the mesh stable to pure messages or gossip  <code>IHAVE</code> / <code>IWANT</code>  messages to ensure that the host didn’t miss any message. Each of these message types requires sending RPC calls, adding up to the total of sent and received network traffic.</p>
<p>The following graphs isolate the bandwidth attributed to each of the events. The first one shows the raw KB/s over time, and the second one shows the percentage of each event over the aggregated total.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/3/b352576dc2b9350a99470bde3eb0710d0e710d3c.jpeg" title="bandwidth-by-event"><img alt="bandwidth-by-event" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/b/3/b352576dc2b9350a99470bde3eb0710d0e710d3c_2_517x309.jpeg" width="517" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/b/ab8bda76fba67303a9b9991902f5ff1805c63175.jpeg" title="bandwidth-ratio-by-event"><img alt="bandwidth-ratio-by-event" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/a/b/ab8bda76fba67303a9b9991902f5ff1805c63175_2_517x309.jpeg" width="517" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#percentage-table-5" name="percentage-table-5"></a>Percentage Table</h3>
<pre><code>| Event | % of total BW | % of Received BW | % of Sent BW |
| --- | --- | --- | --- |
| RECV_GRAFT | 0.000367 | 0.001565 | ———————— |
| RECV_IHAVE | 9.974349 | 42.537746 | ———————— |
| RECV_IWANT | 2.368042 | 10.099021 | ———————— |
| RECV_MSG  (duplicated) | 7.347250 | 31.333920 | ———————— |
| RECV_MSG | 3.640691 | 15.526507 | ———————— |
| RECV_PRUNE | 0.002973 | 0.012678 | ———————— |
| RECV_SUBS | 0.114559 | 0.488562 | ———————— |
| SENT_GRAFT | 0.002863 | ———————— | 0.003740 |
| SENT_IHAVE | 23.404913 | ———————— | 30.573967 |
| SENT_IWANT | 0.094569 | ———————— | 0.123536 |
| SENT_MSG | 53.049257 | ———————— | 69.298539 |
| SENT_PRUNE | 0.000164 | ———————— | 0.000214 |
| SENT_SUBS | 0.000003 | ———————— | 0.000004 |
</code></pre>
<p>From the above graphs, we can observe that:</p>
<ul>
<li>The <code>SENT_MSG</code> event is the one that consumes the most network traffic, with a total of 53% of the total network traffic and 69% of the total sent traffic.<br />
It has a spiky oscillation between 500 to 700 KB/s, and it is clearly the most bandwidth consuming event.<br />
It is hard to define which is the ratio of duplicates that all those sent messages generate on the remote side. However, we could assume that it would follow a similar pattern to the <code>RECV_MSG</code> one (2 duplicate bytes per 1 original byte).</li>
<li>Surprisingly, the <code>SENT_IHAVE</code> event follows <code>SENT_MSG</code>s in terms of consumed bandwidth with a total of 23.4% of the total bandwidth and 30% of the total outgoing bandwidth. Interestingly, subscribing to topics with a high frequency of messages (even if they are small in size), does have an impact on the bandwidth that we use sending those <code>IHAVE</code> messages.<br />
Each <code>IHAVE</code> is limited to <code>5,000</code> message IDs; however, with a message ID of 40 bytes, it still adds up to a maximum of 200KBs in message IDs on every heartbeat (0.7s in the case of Ethereum).</li>
<li><code>RECV_IHAVES</code> represent 10% of the total bandwidth, and 42% of the total inbound bandwidth, with an inbound network bandwidth requirement of 100KB/s.</li>
<li>The above two points showcase that, far from being negligible on the overall value they provide, the total bandwidth used on <code>IHAVE</code> messages represents almost 400KB/s, consuming 23% of the total outgoing bandwidth and more than 40% of the incoming bandwidth.</li>
<li>The <code>RECV_MSG</code> events remain in the fourth position with a representation of 11% of the total consumed bandwidth, where only 3.6% belong to unique or original messages, and the remaining 7.3% belong to duplicates. In terms of the overall inbound bandwidth, they represent 15% and 31%, respectively, for original and duplicated received messages.</li>
<li>On a much lower ratio, the whole list of <code>RECV_IWANT</code> messages stays within a lower 2.3% of the total bandwidth usage, which represents 10% of the total received bytes.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#comparison-with-live-nodes-6" name="comparison-with-live-nodes-6"></a>Comparison with live nodes</h2>
<p>In order to validate the previous measurements taken from the GossipSub module at <code>Hermes</code>, we’ve compared the bandwidth usage ratios with standard running Ethereum nodes:</p>
<ul>
<li>Local Prysm node at home setup (Holesky) reports an average received network traffic of 386KB/s and a sent network traffic of 580KB/s.<br />
Although the numbers might be slightly different, these measurements take the whole traffic of the Beacon Node docker container, which includes:
<ul>
<li>Peer discovery</li>
<li>Requests/Responses like <code>beacon_blocs</code> or <code>blobs</code> by range or by root</li>
</ul>
</li>
</ul>
<p>The MigaLabs <a href="https://monitoreth.io/node_metrics#network-in-out" rel="noopener nofollow ugc">public dashboard</a> at <a href="https://monitoreth.io/node_metrics" rel="noopener nofollow ugc">monitor.eth</a> shows slightly bigger bandwidth usage than the ones we measured. However, it is unclear whether the measurement includes the Execution Layer. The reported bandwidth reports an average of 290KB/s inbound and 1.2MB/s outbound, although it doesn’t include many data points (5 points per hour) and the variation is noticeable.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/7/c7cf74da4a25ce8b98d757eeaebf56696d2c6aa6.jpeg" title="migalabs"><img alt="migalabs" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/c/7/c7cf74da4a25ce8b98d757eeaebf56696d2c6aa6_2_517x315.jpeg" width="517" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-7" name="conclusions-and-takeaways-7"></a>Conclusions and takeaways</h1>
<p>Despite the fact that the configuration of our <code>Hermes</code> node, which, in this case, doesn’t represent a standard node in the Ethereum network, the bandwidth consumption numbers of GossipSub validate that there’s plenty of space for optimization.</p>
<p>We observed that <strong>a significant portion of bandwidth is spent on <code>SENT_IHAVE</code> (23.4% of the total bandwidth and 30% of the total outgoing bandwidth) and <code>RECV_IHAVE</code> (10% of the total bandwidth, and 42% of the total inbound bandwidth)</strong>.</p>
<p>More than anything, these findings validate the improvement recommendations made during our previous study on the “Effectiveness of Gossipsub’s gossip mechanism”: <a class="inline-onebox" href="https://ethresear.ch/t/gossip-iwant-ihave-effectiveness-in-ethereums-gossipsusb-network/19686">Gossip IWANT/IHAVE Effectiveness in Ethereum's Gossipsusb network</a></p>
<p>Taking into account that a node doesn’t only receive duplicated messages but also generates duplicates to others, we strongly recommend pushing the <a href="https://github.com/libp2p/specs/pull/560" rel="noopener nofollow ugc">GossipSub1.2</a> initiative, as it will effectively eliminate the bandwidth wasted on receiving or generating duplicates, which amounts to ~42% of total bandwidth.</p>
<p>Even currently though, the network bandwidth usage of a host in the Ethereum network (around 300 KB/s inbound and 1.1 MB/s outbound, including the EL) still constitutes a small percentage of the <a href="https://fairinternetreport.com/research/internet-speed-by-country/" rel="noopener nofollow ugc">average household</a> bandwidth availability, which varies between 8MB/s and 26MB/s depending on the region.</p>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/ethereum-node-message-propagation-bandwidth-consumption/19952">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 14:39:15 +0000</pubDate>
</item>
<item>
<title>Fork Choice Attacks and Protections in EPBS</title>
<link>https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951</link>
<guid>https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、fork choice attack、proposer boost、builder boost、ex-anti attack

总结:
本文探讨了ePBS（增强版持久拜占庭容错）中的分叉选择攻击，重点关注新的分叉选择提升参数设计。文章分析了两种主要攻击类型（后抗攻击和外抗攻击），以及在引入builder块后，ePBS中出现的新攻击情景，如攻击者与建设者合谋的情况。作者提到，尽管存在削弱的防御，但攻击者需要更高的恶意比例才能成功，例如40%的proposer boost和20%的attacker committee。文章还讨论了各种攻击的动机、优势和潜在后果，以及相应的防范措施，包括Reveal Boost和Withheld Boost。最后，文章提出了可能的改进方向，如考虑网络同步性和多槽活度的影响。 <div>
<h2><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h2>
<p>This post explores fork choice attacks through the perspective of ePBS, focusing on the new fork choice boost parameters and the rationale behind their design. We’ll begin by examining why these parameters are crucial, followed by a review of the existing designs. For background reading, I recommend reading <a href="https://ethresear.ch/t/payload-boosts-in-epbs/18769">Payload Boosts in ePBS</a> by Potuz. Additionally, for a deeper understanding of how the LMD GHOST fork choice operates today, consider Ben Edgington’s section on fork choice in his book, <a href="https://eth2book.info/capella/part3/forkchoice/" rel="noopener nofollow ugc">Upgrading Ethereum</a>. Let’s dive in!</p>
<h4><a class="anchor" href="https://ethresear.ch#references-2" name="references-2"></a>References</h4>
<p><a href="https://ethresear.ch/t/payload-boosts-in-epbs/18769">Payload boosts in ePBS</a> - Feb/2024 By Potuz<br />
<a href="https://ethresear.ch/t/sandwitch-attacks-on-epbs/19538/1">Sandwitch attacks on ePBS</a> - May/2024 By Potuz</p>
<h2><a class="anchor" href="https://ethresear.ch#fork-choice-attacks-today-3" name="fork-choice-attacks-today-3"></a>Fork choice attacks today</h2>
<p>We analyze these scenarios from both the attacker’s and the victim’s perspectives, focusing on two consecutive proposal slots, each with distinct proposers. Two primary types of attacks can emerge:</p>
<ol>
<li>The proposer of slot <span class="math">n+1</span> attacks the proposer of slot <span class="math">n</span>.</li>
<li>The proposer of slot <span class="math">n</span> attacks the proposer of slot <span class="math">n+1</span>.</li>
</ol>
<p>To clarify, by “attack,” we mean an attempt to reorg the block out of the canonical chain. The motives behind such a reorg typically include:</p>
<ol>
<li>Stealing the content of the block.</li>
<li>Increasing the time available to build the block, making a 24-second block more valuable than a 12-second one.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#post-anti-attack-4" name="post-anti-attack-4"></a>Post-anti attack</h3>
<p>The first type of attack is a post-anti attack, where the proposer of slot <span class="math">n+1</span> attempts to reorg the block from slot <span class="math">n</span>. In this scenario, the proposer of <span class="math">n+1</span> utilizes the <a href="https://eth2book.info/capella/part3/forkchoice/phase0/#proposer-boost" rel="noopener nofollow ugc">proposer boost</a> to gain an advantage and potentially reorg the block from slot <span class="math">n</span>. Currently, the proposer boost is set at 40%. This means that as long as the block at slot <span class="math">n</span> receives votes from more than 40% of the beacon committee, it is safe against a reorg. Typically, we define the percentage of the beacon committee that belongs to the attacker as <span class="math">\delta</span>. An attacker can successfully reorg a block if <span class="math">\delta &gt; 1 - PB</span>, which is 60% under today’s parameters.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/f/3f93dac13fced8dbaa43115f19cd6ae45668406d.png" title="Screenshot 2024-06-26 at 12.57.24 PM"><img alt="Screenshot 2024-06-26 at 12.57.24 PM" height="297" src="https://ethresear.ch/uploads/default/optimized/3X/3/f/3f93dac13fced8dbaa43115f19cd6ae45668406d_2_690x297.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#ex-anti-attack-5" name="ex-anti-attack-5"></a>Ex-anti attack</h3>
<p>The second type of attack is known as the ex-anti attack, where the proposer of slot <span class="math">n</span> attempts to reorg the block from slot <span class="math">n+1</span>. This type of attack is inherently difficult to pull off because the proposer boost grants a 40% advantage to the block at slot <span class="math">n+1</span>. To successfully carry out this attack, the attacker’s beacon committee must withhold their attestations and block then release them synchronously which occurs shortly after the block at slot <span class="math">n+1</span> is published. To reorg the block at slot <span class="math">n+1</span>, the attacker’s beacon committee support must exceed the proposer boost. We can assert that an attacker can reorg a block if <span class="math">\delta &gt; PB</span>, which is 40% under today’s parameter.</p>
<p>It is worth mentioning in ex-anti attack, attackers who propose multiple consecutive slots have an added advantage. For two slots, the effectiveness of the attack can be simplified to the expression <span class="math">\delta / 2 &gt; PB</span>, requiring only 20% of the stake per slot to reorg an honest block.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/ccb28f1581907f015d5780dae95dd78444ba59d8.png" title="Screenshot 2024-06-26 at 12.57.38 PM"><img alt="Screenshot 2024-06-26 at 12.57.38 PM" height="340" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/ccb28f1581907f015d5780dae95dd78444ba59d8_2_690x340.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#fork-choice-attacks-in-epbs-6" name="fork-choice-attacks-in-epbs-6"></a>Fork choice attacks in ePBS</h2>
<p>In the ePBS model, the introduction of a <strong>builder block between two proposer blocks</strong> complicates the landscape of potential attacks beyond what we see today. This addition expands the array of possible attack scenarios:</p>
<h3><a class="anchor" href="https://ethresear.ch#pre-epbs-scenarios-7" name="pre-epbs-scenarios-7"></a>Pre-ePBS Scenarios:</h3>
<ol>
<li><strong>Proposer <span class="math">n+1</span> attacking proposer <span class="math">n</span></strong> - This scenario concerns post-anti reorg safety.</li>
<li><strong>Proposer <span class="math">n</span> attacking proposer <span class="math">n+1</span></strong> - This scenario concerns ex-anti reorg safety.</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#post-epbs-scenarios-8" name="post-epbs-scenarios-8"></a>Post-ePBS Scenarios:</h3>
<ol>
<li><strong>Proposer of <span class="math">n+1</span> and builder of <span class="math">n</span> collude and attack proposer of <span class="math">n</span></strong> - This scenario concerns proposer post-anti reorg safety.</li>
<li><strong>Proposer and builder of <span class="math">n</span> collude and attack proposer of <span class="math">n+1</span></strong> - This scenario concerns proposer ex-anti reorg safety.</li>
<li><strong>Proposer of <span class="math">n+1</span> and <span class="math">n</span> collude and attack builder of <span class="math">n</span></strong> - This scenario introduces builder safety, including reorg safety and withholding safety.</li>
</ol>
<p>Before we go into the specific attack scenarios under the ePBS framework, it’s important to establish the incentives for honest builder behavior. Similar to the proposer boost, builders are also incentivized through boosts for honest actions through <a href="https://ethresear.ch/t/payload-timeliness-committee-ptc-an-epbs-design/16054">payload timeliness committee</a>.</p>
<ul>
<li><strong>Reveal Boost (<span class="math">RB</span>)</strong>: Awarded to builders who timely reveal their payloads.</li>
<li><strong>Withheld Boost (<span class="math">WB</span>)</strong>: Granted if a builder, feeling unsafe about revealing the payload, opts to release a withheld message. This boost gives weight to the parent block of the committed consensus block.</li>
</ul>
<p>These boosts also ensure both builder <strong>reveal</strong> and <strong>withhold</strong> safety. Builder reveal safety means that if the builder acted honestly and revealed a payload in a timely fashion (as attested by the PTC), then the revealed payload should be on-chain. Builder withhold safety means that if a beacon block containing a builder’s header is withheld or revealed late, then that beacon block should not be the canonical head of the blockchain in the view of honest validators.</p>
<p>To ensure clarity and maintain focus throughout our discussion, we will designate the boosts as follows: Reveal Boost (<span class="math">RB</span>), Withheld Boost (<span class="math">WB</span>), and Proposer Boost (<span class="math">PB</span>). The specific values of these boosts will be displayed towards the end of the post. Now, let’s explore the first scenario: the proposer post-anti attack in ePBS.</p>
<h3><a class="anchor" href="https://ethresear.ch#proposer-post-anti-attack-9" name="proposer-post-anti-attack-9"></a>Proposer post-anti attack</h3>
<p>As you may have noted, this scenario is similar to the post-anti attack today, except that the builder of <span class="math">n</span> colludes with the proposer of <span class="math">n+1</span>. We also assume that a portion of the beacon committee is part of the malicious team, represented by <span class="math">\delta</span>. The post-anti attack is successful if <span class="math">WB + PB + \delta &gt; 1 - \delta</span>. This indicates that post-anti attack resistance is weaker in ePBS due to the added power of the withheld boost from the colluding builder.</p>
<p>Let’s examine the benefits for the attacker in a successful attack:</p>
<ul>
<li>The block at <span class="math">n+1</span> gains two slots worth of transactions by reorg out <span class="math">n</span>, resulting in more time and more transactions, thereby increasing its block value.</li>
<li>Since <span class="math">n</span>'s payload was revealed as withheld, and both <span class="math">n</span>'s builder and <span class="math">n+1</span>'s proposer collude, there is no opportunity to steal <span class="math">n</span>'s payload transaction content. They are all on the same team.</li>
<li>From <span class="math">n</span>'s proposer’s perspective, the loss includes the opportunity to propose a beacon block, and from the protocol’s perspective, it results in the loss of one slot worth of consensus liveness.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/c/bceef4d59d54e6590addac9fc886b98f4d419f29.png" title="Screenshot 2024-06-26 at 12.57.48 PM"><img alt="Screenshot 2024-06-26 at 12.57.48 PM" height="225" src="https://ethresear.ch/uploads/default/optimized/3X/b/c/bceef4d59d54e6590addac9fc886b98f4d419f29_2_690x225.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#proposer-ex-anti-attack-10" name="proposer-ex-anti-attack-10"></a>Proposer ex-anti attack</h3>
<p>Let’s move on to the second scenario: the proposer ex-anti attack in ePBS. In this scenario, we will examine the most extreme version where the builder’s Reveal Boost (<span class="math">RB</span>) is leveraged for the ex-anti attack. What does this attack look like?</p>
<p>The proposer of slot <span class="math">n</span> withholds the block and the beacon committee, represented by <span class="math">\delta</span>, withholds the attestations. The attacking builder of slot <span class="math">n</span> releases the payload on time to gain the <span class="math">RB</span>. The ex-anti attack is successful if <span class="math">RB + \delta &gt; PB</span>. However, realistically, the proposer will try to split the beacon committee into portions seen (<span class="math">x</span>) and not seen (<span class="math">1-x</span>). This modifies the equation to <span class="math">RB + x + \delta &gt; PB + 1-x</span>.</p>
<p>Let’s examine the benefits for the attacker in a successful attack:</p>
<ul>
<li>The block at slot <span class="math">n</span> reorgs out slot <span class="math">n+1</span>. Unlike a post-anti attack, the builder of slot <span class="math">n</span> must commit and release the payload on time to gain the <span class="math">RB</span>. Due to this commitment:
<ul>
<li>Even if the attack is successful, it only provides one slot of transactions without leading to more time and more transactions. The proposer of slot <span class="math">n+2</span> benefits here.</li>
<li>It cannot steal slot <span class="math">n+1</span>'s transactions because the payload is pre-committed, leaving nothing to steal from the consensus block.</li>
</ul>
</li>
</ul>
<p>In other words, the ex-anti attack is less valuable than the post-anti attack if we assume the worst-case scenario for both.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/f/0fb72294c98dbb6a1be55419420ebf8144cfaa62.png" title="Screenshot 2024-06-26 at 12.57.58 PM"><img alt="Screenshot 2024-06-26 at 12.57.58 PM" height="263" src="https://ethresear.ch/uploads/default/optimized/3X/0/f/0fb72294c98dbb6a1be55419420ebf8144cfaa62_2_690x263.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#builder-attacks-11" name="builder-attacks-11"></a>Builder attacks</h3>
<p>Finally, let’s move to the last section: proposers of <span class="math">n</span> and <span class="math">n+1</span> collude to attack the builder of <span class="math">n</span>. We will divide this section into two parts. The first part will focus on reorg out the builder’s payload, and the second part will focus on making the payload part of the canonical chain even if the builder chooses to withhold it.</p>
<h4><a class="anchor" href="https://ethresear.ch#payload-reorging-attack-12" name="payload-reorging-attack-12"></a>Payload reorging attack</h4>
<p>Let’s examine the first part. The proposer of slot <span class="math">n</span> releases the block late / attempts to split the beacon committee view, resulting in <span class="math">x</span> beacon committee members voting for the block and <span class="math">1-x</span> not voting for it. The builder reveals the payload on time and gains a <span class="math">RB</span>. The proposer of slot <span class="math">n+1</span> could then reorg the payload by reorg the entire proposer block of slot <span class="math">n</span>, which is more powerful than just reorganizing the payload itself. The attack is successful if <span class="math">PB + 1 - x &gt; RB + x</span>.</p>
<p>What does a successful attack provide to the attacker?</p>
<ul>
<li>Given that proposers of slots <span class="math">n</span> and <span class="math">n+1</span> are colluding, there is no extra slot advantage gained by reorg out the block at slot $n. It is essentially the same as not proposing a block at slot <span class="math">n</span>.</li>
<li>A minor advantage of the collusion between the two proposers is the ability to steal the payload transactions from slot <span class="math">n</span>. This issue is mitigated if transactions are protected by binding them to slot $n. This scenario is known as a next-slot unbundling attack, which differs from same-slot unbundling. Same-slot unbundling is impossible in ePBS.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e50f3d20a2b304825cb05436a2a3e610fbddcf4f.png" title="Screenshot 2024-06-26 at 12.58.35 PM"><img alt="Screenshot 2024-06-26 at 12.58.35 PM" height="210" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e50f3d20a2b304825cb05436a2a3e610fbddcf4f_2_690x210.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#payload-withholding-attack-13" name="payload-withholding-attack-13"></a>Payload withholding attack</h4>
<p>Let’s look at the second part. The proposer of slot <span class="math">n</span> releases the block late or tries to split the beacon committee view, resulting in <span class="math">x</span> beacon committee members voting for the block and <span class="math">1-x</span> not voting for it. The builder withholds the payload on time and gains a Withheld Boost (<span class="math">WB</span>). The proposer of slot <span class="math">n+1</span> could attempt to force the builder to fulfill unconditional payment by making the block at slot <span class="math">n</span> canonical, which from the chain’s perspective, appears as if the builder did not release the payload. The attack is successful if <span class="math">PB + x &gt; WB + 1 - x</span>.</p>
<p>What does a successful attack provide to the attacker?</p>
<ul>
<li>The only plausible scenario for this attack is when the builder is not confident in revealing the payload and hence withholds it. In this case, the proposer of slot <span class="math">n+1</span>, colluding with the proposer of slot <span class="math">n</span>, wants to take the builder’s payment regardless.</li>
<li>Another primary advantage is that the block at slot <span class="math">n+1</span> can contain two slots’ worth of transactions since the builder submits an empty payload by withholding.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/f/5f04c5fc36d5b005e7dcc6c7839e90f40a4a0af7.png" title="Screenshot 2024-06-26 at 12.58.09 PM"><img alt="Screenshot 2024-06-26 at 12.58.09 PM" height="266" src="https://ethresear.ch/uploads/default/optimized/3X/5/f/5f04c5fc36d5b005e7dcc6c7839e90f40a4a0af7_2_690x266.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#boost-numbers-14" name="boost-numbers-14"></a>Boost numbers</h3>
<p>Finally, let’s summarize the equations for each worst-case attack scenario if the attacker wins:</p>
<ol>
<li><strong>Proposers post-anti attack</strong>: <span class="math">WB + PB + \delta &gt; 1 - \delta</span></li>
<li><strong>Proposers ex-anti attack</strong>: <span class="math">RB + x + \delta &gt; PB + 1 - x</span></li>
<li><strong>Builder reorg payload attack</strong>: <span class="math">PB + 1 - x &gt; RB + x</span></li>
<li><strong>Builder withhold payload attack</strong>: <span class="math">PB + x &gt; WB + 1 - x</span></li>
</ol>
<p>Overall, we can derive that the parameters are approximately <span class="math">PB = 20\%</span>, <span class="math">WB = 40\%</span>, <span class="math">RB = 40\%</span>, and <span class="math">\delta = 20\%</span>. This means we can tolerate a malicious beacon committee up to 20%, whereas today, this tolerance is 40%.</p>
<p>The real question to ask is whether the worst-case scenario of a 20% attack even makes sense, as in the ex-anti attack, the builder must release the payload to perform the attack. Nevertheless, it certainly represents a degradation in fork choice. A 20% attack is significantly more dangerous in the post-anti attack than in the ex-anti attack due to the additional time available.</p>
<p>Something we haven’t analyzed here is how multi-slot liveness may play a role in this context. Given (block, slot) voting and under worse network asynchrony conditions, we may experience prolonged empty slots, making recovery difficult. Solutions like a backoff scheme have been proposed, which require further thought and analysis.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-attacks-and-protections-in-epbs/19951">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 14:24:34 +0000</pubDate>
</item>
<item>
<title>P2P ZK Light Client Bridge between Tron and Ethereum L2s</title>
<link>https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931</link>
<guid>https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931</guid>
<content:encoded><![CDATA[
<div> 关键词：Tron USDT、Ethereum L2、Zero-knowledge proofs、Cross-chain bridge、Decentralization

总结:<br />
这篇文章讨论了Tron网络上的USDT在第三世界国家的广泛应用，但其高度中心化的控制导致高额交易费和生态系统孤立。为解决这些问题，作者提出了一种设计，即利用零知识轻验证的跨链桥，将USDT TRC20与以太坊L2网络低成本连接起来。这种设计旨在减少交易费用、促进去中心化并增强两个生态系统的流动性。通过零知识证明确保交易安全，同时简化用户操作，使得从Tron无缝接入Ethereum成为可能，从而降低集中风险并推动全球去中心化金融基础设施的发展。 <div>
<p><em>By <a href="https://x.com/alexhooketh" rel="noopener nofollow ugc">Alex Hook</a>. Thanks to these people for inspiration, feedback and suggestions: <a href="https://x.com/alexanderchopan" rel="noopener nofollow ugc">accountless.eth</a>, <a href="https://x.com/pseudotheos" rel="noopener nofollow ugc">pseudotheos</a>, <a href="https://x.com/domothy" rel="noopener nofollow ugc">Domothy</a>, <a href="https://x.com/DoganEth" rel="noopener nofollow ugc">Dogan Alpaslan</a>, <a href="https://zkp2p.xyz" rel="noopener nofollow ugc">ZKP2P team</a></em></p>
<hr />
<p><strong>Abstract.</strong> USDT on the Tron Network has emerged as a dominant crypto application in the Third World countries. However, the current cartelized control of the Tron Network results in elevated transaction fees, capital concentration, and an ecosystem isolated from other crypto networks. We propose a design for a cost-effective, peer-to-peer bridge from USDT TRC20 to Ethereum L2 networks, utilizing zero-knowledge light verification of the Tron blockchain.</p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>According to <a href="https://tokenterminal.com/terminal/datasets/stablecoins" rel="noopener nofollow ugc">Token Terminal</a>, USDT on Tron has achieved preeminence by several metrics, including outstanding supply, 30d transfer volume, number of transfers, and number of holders. At the time of writing, the second place by volume, DAI on Ethereum, has only ~20% less volume than it, but two orders of magnitude fewer holders and number of transfers. The second place by number of transfers, USDC on Base, has 5x fewer transfers.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/4/6476c0c44ca7866bfea5a4f35205a47fa7c74204.png" title="Screenshot 2024-06-27 at 8.00.11 PM"><img alt="Screenshot 2024-06-27 at 8.00.11 PM" height="459" src="https://ethresear.ch/uploads/default/optimized/3X/6/4/6476c0c44ca7866bfea5a4f35205a47fa7c74204_2_690x459.png" width="690" /></a></div><p></p>
<p>This shows Tron USDT’s monstrous levels of payment usage among individuals. Unsurprising—Tron team has done an extensive advertisement campaign for its payment solution in Africa and Latin America. Shortly after, the network effect spread it to the developing countries in Asia and Post-Soviet area.</p>
<p>If we look at the areas of the largest prevalence of Tron USDT, a noteworthy pattern can be noticed. Tron USDT is largely used in the countries with weak economies and unsustainable local currencies: Türkiye, Lebanon, Zimbabwe, Venezuela, Argentina, and more. In these countries, traditional banking doesn’t provide people with options for reliable store of value and means of payment, as local currencies are unreliable, and foreign currencies are either banned for payment use or subject to strict control.</p>
<h3><a class="anchor" href="https://ethresear.ch#problems-2" name="problems-2"></a>Problems</h3>
<p>It is fair to say that USDT on Tron is one of the largest crypto applications by usage today. Millions of people around the world are interacting with it every day. It’s massively used as a store of value, acts as a medium of exchange in isolated economies such as Northern Cyprus, Cuba, and Vietnam. <a href="https://mirror.xyz/0x8958D0c419BCDFB8A86b8c0089552bE015fbe364/ODhOuYjK80atc9_jGprXotSo3PNobT1PRLFtorXHBrA" rel="noopener nofollow ugc">Local P2P platforms are building their infrastructure around USDT on Tron</a>. However, its dominance presents certain challenges for the broader Web3 community:</p>
<ul>
<li>
<p><em>A primary concern is the high degree of centralization</em> within the Tron Network. <a href="https://github.com/alexhooketh/tron-light-client/blob/cc3e037c5b71ba5e6216c8d19fee4dfe9d254e69/README.md" rel="noopener nofollow ugc">According to our research</a>, over the past 250 days there were only 28 unique block producers. The same entities are constantly winning the DPoS election due to delegations from the largest TRX holders. Most of these Super Representatives (block producers in Tron) <a href="https://tronscan.org/#/sr/representatives" rel="noopener nofollow ugc">lack any public information</a> beyond their status as block producers.</p>
</li>
<li>
<p>Despite this centralization, <em>transaction fees on Tron remain among the highest in crypto</em>—<a href="https://developers.tron.network/docs/resource-model#energy" rel="noopener nofollow ugc">420 sun</a> (1 sun = 1e-6 TRX) per gas. At the <a href="https://coinmarketcap.com/currencies/tron/" rel="noopener nofollow ugc">TRX’s price of ~0.000035 ETH</a>, this roughly corresponds to Ethereum L1’s gas price of 14.7 gwei. The usual fee for USDT transfers in Tron is <strong>$1-1.5 in TRX</strong>, rendering small transfers barely economical. However, the usage is still very high, as Tron’s ecosystem is isolated and there’s no convenient way to interact with other ecosystems from it.</p>
</li>
</ul>
<p>In contrast, the Ethereum ecosystem continues to thrive. Following the Dencun upgrade, transaction fees on rollups have drastically decreased to <a href="https://www.growthepie.xyz/fundamentals/transaction-costs" rel="noopener nofollow ugc">less than a cent</a> per ERC20 transfer. Combined with L2s, Ethereum DeFi <a href="https://defillama.com/chains" rel="noopener nofollow ugc">now comprises &gt;80% of the entire DeFi TVL</a>. <a href="https://l2beat.com/scaling/activity" rel="noopener nofollow ugc">Rollups alone consistently handle upwards of 100 TPS</a>, <a href="https://mirror.xyz/alexhook.eth/y9PTlM6tVr0H8X68r1LV2UwAnT9D6u1MEEiUFvcpyG0" rel="noopener nofollow ugc">with theoretical limits of 400-800 TPS</a> depending on the specific rollup. OP Mainnet has upgraded to Stage 1 trustlessness with all OP Chains and ZKsync catching up this summer. Arbitrum is working towards Stage 2.</p>
<p>People in developed countries are already integrated with Ethereum. By allowing ones from developing countries to seamlessly move into it from Tron, we can unite these disparate ecosystems and mitigate the risks associated with increasing centralization and monopolization of Sun’s machine.</p>
<h1><a class="anchor" href="https://ethresear.ch#rationale-3" name="rationale-3"></a>Rationale</h1>
<p>The protocol for cross-chain transfers from Tron should ideally possess the following characteristics:</p>
<ul>
<li><strong>Trust-minimized:</strong> The system should preclude the provision of incorrect information about the Tron blockchain or the theft of locked funds, except in the event of an attack on Tron’s consensus. In such a case, the security council authorized to stop the system can be established.</li>
<li><strong>Permissionless liquidity supply:</strong> The protocol should allow any entity to provide liquidity at their preferred rate. This fosters fair competition among providers, potentially resulting in more favorable and flexible exchange rates based on order size.</li>
<li><strong>Permissionless operation:</strong> While a centralized relay for light client updates and order fulfillment is acceptable, provided there exists a self-proposing mechanism in case of liveness failure, the relay must not serve as a source of trust. When feasible, on-chain operations should be implemented instead (e.g., a paymaster for gasless order claims).</li>
<li><strong>As simple as possible from the Tron side:</strong> Gas fees on Tron are extremely high, so it may be not affordable for users to execute more than necessary on-chain. Moreover, USDT Tron users are mostly using wallets such as Trust Wallet, Exodus, hardware wallets, and local exchange accounts, that do not support contract calls or token approvals. The only Tron wallet with these features, TronLink, is not common among USDT Tron users.</li>
<li><strong>Reasonably cheap on the destination side:</strong> Zero-knowledge proofs should be employed where possible to minimize costs. While the system can be more extensive than on the Tron side, it should still be optimized to keep user claim costs low.</li>
<li><strong>Single liquidity hub with enshrined bridging:</strong> The protocol should be deployed on a single L2 network to prevent liquidity fragmentation. To mitigate protocol isolation, cross-chain token bridges can be integrated at the UI level, <a href="https://zkp2p.xyz/send" rel="noopener nofollow ugc">similarly to ZKP2P</a>.</li>
<li><strong>USDC-native:</strong> Given USDC’s prevalence in the Ethereum ecosystem, the protocol can be based on USDC, effectively providing USDT-USDC swaps. However, USDC is virtually unknown in areas of extensive USDT Tron usage, so this difference should be addressed on UX level to reduce user distrust.</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#trons-consensus-and-protocol-101-4" name="trons-consensus-and-protocol-101-4"></a>Tron’s consensus and protocol 101</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/1/81e8ead1ee5585f245d51ac55f4f1db43f3785d2.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/1/81e8ead1ee5585f245d51ac55f4f1db43f3785d2_2_540x500.png" width="540" /></a></div><p></p>
<p>Every 6 hours (7200 blocks), network participants delegate their TRX to validator candidates. The 27 candidates accumulating the most votes are elected as Super Representatives (SRs), who are then responsible for block production. Block producer selection follows a deterministic round-robin pattern. A block is considered finalized after receiving 18 confirmations, 2/3 of the SR set.</p>
<p>The block production is an ECDSA signature over the SHA256 hash of the protobuf-encoded block header. That is, one block = one signature. The top 128 representatives, beyond the 27 SRs, are designated as Super Representative Partners, voting on blocks produced by SRs. However, <a href="https://developers.tron.network/docs/concensus#block-generation-mechanism" rel="noopener nofollow ugc">as producers are predictable and the longest-chain rule is applied</a>, there is no necessity in validating votes.</p>
<p>Block header consists of the following elements:</p>
<pre><code class="lang-auto">message BlockHeader {
  message raw {
    int64 timestamp = 1;
    bytes txTrieRoot = 2;
    bytes parentHash = 3;
    int64 number = 7;
    bytes witness_address = 9;
    int32 version = 10;
  }
  raw raw_data = 1;
  bytes witness_signature = 2;
}
</code></pre>
<p>Even though state root is formally specified in the protocol, it’s not added to the header. We assume this is for backward-compatibility purposes, as the current version of Tron Network does not merkleize state.</p>
<p>The signature is made over a SHA256 hash of the serialized <code>raw_data</code> element. That is, by utilizing light verification, we can access only one transaction-specific element—the Merkle root of the transaction tree. However, in Tron, transactions carry their execution status, so we don’t need to access the state to validate the success of one-transaction operations, such as TRC20 transfer().</p>
<pre><code class="lang-auto">message Transaction {
  ...
  message Result {
    enum code {
      SUCESS = 0;
      FAILED = 1;
    }
    enum contractResult {
      DEFAULT = 0;
      SUCCESS = 1;
      REVERT = 2;
      BAD_JUMP_DESTINATION = 3;
      OUT_OF_MEMORY = 4;
      PRECOMPILED_CONTRACT = 5;
      STACK_TOO_SMALL = 6;
      STACK_TOO_LARGE = 7;
      ILLEGAL_OPERATION = 8;
      STACK_OVERFLOW = 9;
      OUT_OF_ENERGY = 10;
      OUT_OF_TIME = 11;
      JVM_STACK_OVER_FLOW = 12;
      UNKNOWN = 13;
      TRANSFER_FAILED = 14;
      INVALID_CODE = 15;
    }
    int64 fee = 1;
    code ret = 2;
    contractResult contractRet = 3;
    ...
}
</code></pre>
<p>Votes for witnesses (representatives) are of a specific transaction type. This means that in order to calculate the votes, the light client has to download all transactions and re-execute ones of this type.</p>
<pre><code class="lang-auto">message Transaction {
  message Contract {
    enum ContractType {
      ...
      VoteWitnessContract = 4;
      ...
}
</code></pre>
<p>However, considering the fact that the SR set is almost static, we believe that it would be computationally cheaper to delegate choosing the canonical set to DAO or enshrine the set into the circuit.</p>
<p>Normal contract calls, such as TRC20 transfer, have the <code>TriggerSmartContract</code> type and are nearly identical to ERC20 transactions. This means that we can prove the USDT transfer on Tron network using only the transaction root, which can be safely accessed on-chain using ZK light client relay.</p>
<h1><a class="anchor" href="https://ethresear.ch#design-proposal-5" name="design-proposal-5"></a>Design proposal</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4b4b8d0d74dfe0a7dd5991bce974eac97c8621fc.jpeg" title="image"><img alt="image" height="402" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4b4b8d0d74dfe0a7dd5991bce974eac97c8621fc_2_690x402.jpeg" width="690" /></a></div><p></p>
<p>The proposed cross-chain swap mechanism involves three primary entities: the <em>User</em>, the <em>Buyer</em> (or liquidity provider), and the <em>Relayer</em>. The process unfolds as follows:</p>
<ol>
<li>
<p><em>The Buyer</em> locks USDC into the swap contract on the L2, specifying their exchange rate and Tron address for transfers.</p>
</li>
<li>
<p><em>The User</em> selects a <em>Buyer</em> offering the most favorable rate with sufficient liquidity. <em>The User</em> then initiates a transaction on the L2 to temporarily lock a portion of the <em>Buyer’s</em> USDC. This step prevents liquidity depletion before order fulfillment. If supported by the L2, this transaction may be funded by a paymaster.</p>
</li>
<li>
<p><em>The User</em> transfers the corresponding amount of Tron USDT to the <em>Buyer’s</em> specified address.</p>
</li>
<li>
<p>Following 18 block confirmations (~54 seconds, ensuring finality), the <em>Relayer</em> retrieves the latest Tron block headers and generates a ZK proof to them. The circuit for light verification must contain the transaction root from the header as the public input so that it’s known to the relay contract. This proof is needed to efficiently prove the new Tron blocks and their transaction roots <em>to the relay contract</em>.</p>
</li>
<li>
<p><em>The Relayer</em> obtains the finalized transaction from the Tron blockchain and generates a zero-knowledge proof of transaction inclusion against the transaction root. This proof is needed to efficiently prove the order fulfillment <em>to the swap contract</em>. Just like light client proofs, transaction proofs can be aggregated to minimize the costs of on-chain proof verification.</p>
</li>
<li>
<p><em>The Relayer</em> submits these proofs to the respective smart contracts on the L2. Upon verification, the swap contract releases the funds to the <em>User</em> and allocates a small portion to the <em>Relayer</em> as compensation. In case of liveness failure, the <em>User</em> can generate and relay proofs themselves, removing the need for relayer fees.</p>
</li>
<li>
<p><em>The Buyer</em> can exchange their acquired Tron USDT for USDC on the L2 through various means, including direct 1:1 exchange with issuers, and reinvest in the swap contract.</p>
</li>
</ol>
<p>This system streamlines the user experience to just two primary actions: committing to the order on the destination chain and transferring Tron USDT to a specified address. The User receives the equivalent USDC on the L2 within approximately one minute. This system can even be used to accept payments in USDT Tron, requiring only a web browser with a connected wallet for order creation.</p>
<p>For Buyers, liquidity provision is fully automated. They create a Tron wallet, and supply USDC with specified Tron address to the smart contract. When their liquidity is out, it is automatically removed. Received USDT can be spent and exchanged back to USDC at any time. This system is expected to provide higher exchange rates than the existing P2P platforms, as the rate is competitive and there’s no need to cover the costs of KYC and other web2-specific processes.</p>
<p>Relayers require only a server running relayer and ZK prover software. As relayers do not serve as the source of trust, this role can be either permissionless or delegated to the development team, provided self-proposing functionality is supported.</p>
<h1><a class="anchor" href="https://ethresear.ch#zk-light-client-poc-6" name="zk-light-client-poc-6"></a>ZK Light Client PoC</h1>
<p>We’ve written a proof-of-concept of ZK light verification of Tron blocks in Noir language. It receives the previous and new block IDs with a transaction root as the public input, and the block header as the private input. It does not implement round-robin checks and election mechanism for efficiency purposes, and the SR set is hardcoded into the circuit. The proof is generated in about 35 seconds on an M1 machine.</p>
<p>For the production version of this system, it may be necessary to rewrite the circuits to STARK-based proof systems and/or implement GPU proving to improve proving speed.</p>
<p>The source code can be found here: <a class="inline-onebox" href="https://github.com/alexhooketh/zktron" rel="noopener nofollow ugc">GitHub - alexhooketh/zktron: ZK light client for Tron Network written in Noir</a></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-7" name="conclusion-7"></a>Conclusion</h1>
<p>The proposed P2P ZK Light Client Bridge between Tron and Ethereum L2s is a significant advancement in addressing the problems of Tron Network in a Web3 way. By leveraging zero-knowledge proofs and efficient light client verification, this system offers a trust-minimized, permissionless, and cost-effective solution for bridging the gap between these two prominent blockchain ecosystems.</p>
<p>This bridge design addresses several key challenges:</p>
<ol>
<li>It mitigates the risks associated with the centralization of the Tron Network by providing users with seamless access to the more decentralized and robust Ethereum ecosystem.</li>
<li>It significantly reduces transaction costs for users, particularly benefiting those in developing economies who rely heavily on USDT for daily transactions and value storage.</li>
<li>It enhances liquidity and interoperability between Tron and Ethereum, expanding Ethereum ecosystem to the areas of extensive Tron usage.</li>
<li>It maintains a high level of security through the use of ZK proofs, ensuring the integrity of cross-chain transactions without compromising on efficiency.</li>
</ol>
<p>By bridging these ecosystems, we can solve the problem of increasing influence of Tron, taking a significant step towards realizing the vision of a truly global, decentralized financial infrastructure that can benefit users across all economic backgrounds.</p>
<p>We welcome feedback and questions from the community. Feel free to leave your comments, suggestions, or inquiries in the comments section below. <strong>Thank you for reading.</strong></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/p2p-zk-light-client-bridge-between-tron-and-ethereum-l2s/19931">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 20:03:10 +0000</pubDate>
</item>
<item>
<title>Orbit SSF: solo-staking-friendly validator set management for SSF</title>
<link>https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928</link>
<guid>https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928</guid>
<content:encoded><![CDATA[
<p><em>Much of the post came together during a week of in-person whiteboarding with <a href="https://rig.ethereum.org" rel="noopener nofollow ugc">RIG</a> and wannabe RIGs like myself, Ansgar and Toni. Thanks in particular to <a href="https://twitter.com/weboftrees" rel="noopener nofollow ugc">Anders</a>, <a href="https://twitter.com/adietrichs" rel="noopener nofollow ugc">Ansgar</a>, <a href="https://twitter.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://twitter.com/soispoke" rel="noopener nofollow ugc">Thomas</a> for continued discussions and feedback, again to Anders for most of the ideas around individual incentives, and again to Barnabé for the diagrams about finality. The core idea that the post explores was originally proposed by Vitalik in <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">this post</a></em>.</p>
<h2><a class="anchor" href="https://ethresear.ch#where-we-are-1" name="where-we-are-1"></a>Where we are</h2>
<p>The <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality" rel="noopener nofollow ugc">Single Slot Finality (SSF) roadmap</a> has <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#What-are-the-key-questions-we-need-to-solve-to-implement-single-slot-finality" rel="noopener nofollow ugc">three main components</a>:</p>
<ul>
<li>Consensus algorithm</li>
<li>Signature aggregation</li>
<li>Validator set economics</li>
</ul>
<p>Since the previously linked post, there has been a lot of progress on the consensus algorithm side, with <a href="https://ethresear.ch/t/a-simple-single-slot-finality-protocol/14920">multiple</a> <a href="https://arxiv.org/abs/2310.11331" rel="noopener nofollow ugc">candidate</a> <a href="https://notes.ethereum.org/@fradamt/chained-3sf" rel="noopener nofollow ugc">protocols</a> and <a href="https://github.com/fradamt/ssf/tree/main/high_level" rel="noopener nofollow ugc">the beginning of a specification effort</a>. There have also been some effort to explore the design space of signature aggregation, both with a <a href="https://ethresear.ch/t/horn-collecting-signatures-for-faster-finality/14219">networking</a> <a href="https://ethresear.ch/t/flooding-protocol-for-collecting-attestations-in-a-single-slot/17553">focus</a> and a <a href="https://ethresear.ch/t/signature-merging-for-large-scale-consensus/17386">cryptographic focus</a>. Still, we are likely not close to being able to reliably aggregate millions of signatures per slot, without increasing the slot time or validator requirements significantly. On the staking economics side, there has been lots of work over the last year, but for the most part focused on understanding <a href="https://mirror.xyz/barnabe.eth/v7W2CsSVYW6I_9bbHFDqvqShQ6gTX3weAtwkaVAzAL4" rel="noopener nofollow ugc">liquid staking</a> and <a href="https://mirror.xyz/barnabe.eth/96MD_A194uXLLjcOWePW3O2N3P-JG-SHtNxU0b40o50" rel="noopener nofollow ugc">restaking</a>, and on <em>stake</em> capping, i.e., constraining the amount of ETH staked (if you’re reading this, you’re probably already at least at a surface level familiar with the issuance conversation, in which case you might want to dig deeper and check out these posts <a href="https://ethresear.ch/t/properties-of-issuance-level-consensus-incentives-and-variability-across-potential-reward-curves/18448/1">[1]</a> <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">[2]</a>). Here, we are instead interested in <em>validator capping</em>, i.e., constraining the amount of validator identities in the system, or at least the ones actively participating at any given time, to satisfy technical constraints. Some ideas in this direction can be found in this <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#what-would-8192-signatures-per-slot-under-ssf-look-like-2">recent post</a>, and in fact <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">approach 3</a> from the post provides the foundation for this post. Moreover, a recent important development is that <a href="https://eips.ethereum.org/EIPS/eip-7251" rel="noopener nofollow ugc">EIP-7251 (MaxEB)</a> has been included in the <a href="https://github.com/ethereum/consensus-specs/blob/a3a6c916b236c9e8904090303f0c38ae49db1002/specs/electra/beacon-chain.md" rel="noopener nofollow ugc">Electra fork</a>. Validator effective balances will be allowed to be as high as 2048 ETH, enabling staking pools to <a href="https://notes.ethereum.org/@fradamt/maxeb-consolidation" rel="noopener nofollow ugc">consolidate their validators</a>, a new capability which we can leverage in our designs.</p>

<h2><a class="anchor" href="https://ethresear.ch#goals-2" name="goals-2"></a>Goals</h2>
<p>With the goal of finding a design which can make its way into the protocol in a reasonable timeline, we are here going to focus on solutions that <em>do not</em> rely on large improvements in the signature aggregation process. We also do not think it is very realistic to propose significant increases of the slot time, which have many externalities. Given these technical constraints, let’s focus on a minimal set of properties that we ideally want to achieve:</p>
<ul>
<li><strong>Validator capping</strong>: at most <span class="math">N</span> <em>active</em> validators at a time. For example, <span class="math">N = 2^{15} \approx 32k</span>, which we know we can handle because it is the size of a committee today. If we wanted to completely remove attestation aggregation, we would likely need to drop this number to a few thousands.</li>
<li><strong>Solo staking viability</strong>: staking with 32 ETH is <em>guaranteed</em> to still be possible, <em>and</em> the solo staking yield should still not compare unfavorably to delegated staking yields.</li>
<li><strong>High eventual economic security</strong>: More than <span class="math">D_f</span> stake provides economic security, at least <em>eventually</em>. For example <span class="math">D_f = 20M</span> ETH. Ideally, we also do not have to wait longer than today for it (two epochs).</li>
<li><strong>Fast finality</strong>: at least <em>some</em> amount of economic security is available shortly after a block is proposed (think: 10 to 30 seconds, not over 10 minutes).</li>
<li><strong>Optimally secure consensus protocol</strong>: the consensus protocol is (provably) resilient to ~1/2 adversaries under network synchrony, and 1/3 under partial synchrony.</li>
</ul>
<p>Without solo staking viability as defined here, we could simply raise the minimum balance, or go with approaches that allow for a low minimum balance but do not <em>guarantee</em> it, for example in the face of large stakers intentionally splitting their stake. Such solutions would likely have to lean on <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-1-go-all-in-on-decentralized-staking-pools-3">decentralized staking pools</a> or <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-2-two-tiered-staking-4">two-tier staking</a> to preserve the accessible nature of staking as it is today, or perhaps even to carve out a more tailored role for smaller stakers, as is suggested by <a href="https://ethresear.ch/t/unbundling-staking-towards-rainbow-staking/18683">rainbow staking</a>. While there is merit to these approaches and we believe they (and more generally the role of solo staking/broad consensus participation) deserve further exploration, we are choosing here to only explore designs that are compatible with this narrow interpretation of solo staking viability.</p>
<h2><a class="anchor" href="https://ethresear.ch#overview-of-approaches-3" name="overview-of-approaches-3"></a>Overview of approaches</h2>
<p>Validator capping, solo staking viability and high economic security immediately raise an issue: high economic security requires millions of ETH to participate in finalizing and a minimum balance of 32 ETH then implies a worst case of hundreds of thousands or millions of validators (~1M at the time of writing), which seems to conflict with validator capping. There are two main classes of approaches that attempt to deal with this problem:</p>
<ul>
<li><strong>Validator set rotation</strong>: the full validator set is allowed to be large, but only a subset is actively participating at any given time.</li>
<li><strong>Economic validator set capping</strong>: the size of the full validator set is constrained through economic incentives. To <em>guarantee</em> a small validator set size we can for example <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-validator-count" rel="noopener nofollow ugc">reduce issuance past the target validator count</a>. However, this leaves all stakers open to a cheap griefing attack, where a small amount of stake can have a disproportionate negative impact on issuance.</li>
</ul>
<p>In this post we are not going to focus on the latter approach <em>in isolation</em>, but we are going to propose a way to combine economic incentives with a form of validator set rotation.</p>
<h2><a class="anchor" href="https://ethresear.ch#validator-set-rotation-4" name="validator-set-rotation-4"></a>Validator set rotation</h2>
<p>The current protocol also has to deal with the issue we have outlined in the previous section, and the chosen “solution” is precisely validator set rotation: only 1/32 of the validator set votes in any given slot. This design <a href="https://notes.ethereum.org/@vbuterin/serenity_design_rationale#Why-32-ETH-validator-sizes" rel="noopener nofollow ugc">trades off finality time</a>, and fails to satisfy our desired property of fast finality.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/83646288afbace1b452239618b34e83319531d0a.png" title=""><img alt="" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/8/3/83646288afbace1b452239618b34e83319531d0a_2_690x388.png" width="690" /></a></div><p></p>
<p>Let’s then explore whether we can use validator set rotation without giving up on fast finality or other properties.</p>
<h3><a class="anchor" href="https://ethresear.ch#fast-rotation-5" name="fast-rotation-5"></a>Fast rotation</h3>
<p>One way to go about validator set rotation is to have committees which rotate fast, as in the current protocol. In order to avoid a high time-to-finality, we can use a different consensus protocol allowing for <a href="https://ethresear.ch/t/a-model-for-cumulative-committee-based-finality/10259">committee-based finality</a>, i.e., such that even a committee can provide economic security proportional to its stake. In fact, the post linked above deals with <em>cumulative</em> committee-based finality, where the consensus protocol even allows for accumulation of economic security over multiple finalizations, such that <span class="math">k</span> committees finalizing in a row results in <span class="math">k</span> times the economic security that a single committee can provide. We get two birds with one stone, getting both fast (partial) finality and full <em>eventual</em> economic security. In particular, we could have full finality <em>in the same time as today</em> (which gives enough time for each committee to do its own finalization by voting twice), but with the big improvement that economic security accrues every slot, rather than all at once after two epochs.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/6/b6816fefcf5021bb672ed76029c844d1f311047d.png" title=""><img alt="" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/b/6/b6816fefcf5021bb672ed76029c844d1f311047d_2_690x388.png" width="690" /></a></div><p></p>
<p>This seems like a clear improvement on today’s protocol, so why are we not just doing it? An answer comes from the consensus protocol design space: it is not clear at this point how to have an optimally secure dynamically available protocol with <em>fast</em> rotating committees. In fact, much of the problems with the LMD-GHOST component of today’s protocol, or at least the <a href="https://ethresear.ch/t/reorg-resilience-and-security-in-post-ssf-lmd-ghost/14164#introduction-2">fundamental ones</a>, come precisely from the interaction of multiple committees. In short, an adversary can accumulate weight across multiple committees, and use it to reorg honest blocks that have a single committee supporting them.</p>
<p>For interested readers, there actually are optimally secure dynamically available consensus protocols that allow for committees (<a href="https://arxiv.org/abs/2209.03255" rel="noopener nofollow ugc">[1]</a> <a href="https://eprint.iacr.org/2022/1448.pdf" rel="noopener nofollow ugc">[2]</a> for example), but all known ones suffer from catastrophic failures under even short-lived asynchrony (<a href="https://arxiv.org/abs/2302.11326" rel="noopener nofollow ugc">[1]</a> <a href="https://arxiv.org/abs/2309.05347" rel="noopener nofollow ugc">[2]</a>). It is not known whether this is a fundamental limitation, but at least so far we do not know any protocol that gets around it.</p>
<h3><a class="anchor" href="https://ethresear.ch#slow-rotation-6" name="slow-rotation-6"></a>Slow rotation</h3>
<p>There is however a simple way to avoid the problem altogether: giving up on <em>fast</em> committee rotation, and instead having a committee which rotates out slowly, for example by replacing a small percentage of it every slot. The upshot is that such a committee effectively acts as a full validator set, in the sense that its actions do not interact with those of other committees, as would be the case with fast rotation. We can in principle take any protocol that works when the whole validator set is able to participate at once, and make it work with this mechanism by slowing down the rotation sufficiently.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/c/4c21c0ca0871b1e7c6440325b3a3174df016793f.png" title=""><img alt="" height="389" src="https://ethresear.ch/uploads/default/optimized/3X/4/c/4c21c0ca0871b1e7c6440325b3a3174df016793f_2_690x389.png" width="690" /></a></div><p></p>
<p>At a first glance, one obvious downside is that a full rotation of the validator set would be much slower than today, and thus so would finality. However, we could do things a bit differently, by decoupling the committee which votes for the available chain (LMD-GHOST votes) from those which vote for finality (Casper FFG votes). Only LMD-GHOST has problems with fast committee rotation, so we could have a slowly rotating committee whose votes count for LMD-GHOST and in parallel also fast rotating committees whose votes accumulate economic security over time, up to full finality in no more than today’s two epochs.</p>
<p>Besides some amount of extra complexity in the consensus protocol, one remaining downside is that we leave a single committee “in charge” of LMD-GHOST for extended periods of time. Moreover, while linearly accumulating finality is a strict improvement over today’s step function finality, we do not achieve something even stronger, namely getting a high level of economic security immediately. This is of course impossible to achieve given the constraints we have laid out, <em>unless we make some assumptions about the stake distribution</em>, for example that it is <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#The-good-news-gains-from-enabling-voluntary-validator-balance-consolidation" rel="noopener nofollow ugc">Zipfian</a>, or anyway such that a large portion of the stake is concentrated in the first few thousand entities.</p>

<h2><a class="anchor" href="https://ethresear.ch#orbit-ssf-stable-core-rotating-periphery-7" name="orbit-ssf-stable-core-rotating-periphery-7"></a>Orbit SSF: Stable core, rotating periphery</h2>
<p>Our starting point is <a href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989#approach-3-rotating-participation-ie-committees-but-accountable-5">approach 3 from this post</a>, where validators are (roughly) sampled by balance, so that validators with a lot of stake are always in the validator set. Contrast this with the previously considered validator set rotation approaches where validators were (implicitly) sampled by indices, as we do today, which results in each committee having small weight regardless of what the stake distribution looks like.</p>
<p>We then consider adding consolidation incentives, to have stronger guarantees about the level of finality that we can reach with a single committee. The rotating parts of the committee can then rotate slowly, and we do not need to take on the extra consensus complexity of decoupling voting for the available chain and for the finality gadget. Moreover, there is never a small committee (in terms of stake) in charge of a critical consensus component: at all times, we can expect the active validator set to hold a meaningful fraction of the whole stake.</p>
<h3><a class="anchor" href="https://ethresear.ch#active-validator-set-management-8" name="active-validator-set-management-8"></a>Active validator set management</h3>
<p>There are two key components here:</p>
<ul>
<li><em>Active validator set selection</em>: We set a stake threshold <span class="math">T</span> (in principle it could also be set dynamically), and then define the probability of validator with stake <span class="math">S</span> to be sampled in the active set to be <span class="math">p(S) = \min(\frac{S}{T}, 1) = 
\begin{cases}
\frac{S}{T} &amp; S \le T \\ 
1 &amp; S \ge T 
\end{cases}</span><br />
A validator with stake <span class="math">S \le T</span> is selected with probability <span class="math">\frac{S}{T}</span> proportional to its stake, whereas validators with stake <span class="math">S \ge T</span> are <em>always</em> in the validator set. The idea here is of course that it is helpful to have a stable core of large validators always in the active set, because they contribute a lot of economic security but still only add the same load as any other validator.</li>
<li><em>Reward adjustment</em>: We adjust attestation rewards so that all validators still get compensated proportionally to their stake, regardless of whether they fall below or above the threshold <span class="math">T</span>. To define the reward function, we take as reference the maximum attestation reward <span class="math">R</span> that the protocol gives to a validator with stake <span class="math">T</span>, for a single attestation (<span class="math">R</span> can of course vary depending on the overall issuance level). Given <span class="math">R</span>, the maximum reward for an attestation by a validator with stake <span class="math">S</span> is <span class="math">r(S) = R\cdot\max(1, \frac{S}{T}) = 
\begin{cases} 
R &amp; S \le T \\
R \cdot \frac{S}{T} &amp;S \ge T
\end{cases}</span><br />
Overall, the <em>expected</em> rewards of a validator with stake <span class="math">S</span> are then <span class="math">p(S)\cdot r(S) = R\cdot\frac{S}{T} = \frac{R}{T} \cdot S</span>. In other words, <span class="math">\frac{R}{T}</span> per unit of stake, regardless of how it is distributed.  To help visualize this, here’s a plot of <span class="math">p(S)</span>, <span class="math">r(S)</span> and <span class="math">p(S)\cdot r(S)</span>, for <span class="math">R = 2</span> (arbitrary value just for the plot) and <span class="math">T = 1024</span>. Validators with less than <span class="math">T</span> stake do have higher variance, because they only participate <span class="math">\frac{S}{T}</span> of the time, but over longer periods of time the variance will still very low, since attestation rewards are constant and very frequent.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/9/69e8f45397940a38df6d146660314fa29c2f790c.png" title=""><img alt="" height="355" src="https://ethresear.ch/uploads/default/optimized/3X/6/9/69e8f45397940a38df6d146660314fa29c2f790c_2_690x355.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#validator-capping-9" name="validator-capping-9"></a>Validator capping</h4>
<p>We can easily compute the expected size of an active validator set <span class="math">V_a</span> that is sampled this way from a full validator set <span class="math">V</span> whose total deposit size is <span class="math">D</span>:<br />
<span class="math">\mathbb{E}[|V_a|] = \sum_{i \in V} p(S_i) = \sum_{i \in V} \min(\frac{S_i}{T}, 1) = \frac{1}{T}\sum_{i \in V} \min(S_i, T) \le \frac{1}{T}\sum_{i \in V} S_i = \frac{D}{T}</span></p>
<p>Basically, any validator with stake <span class="math">S \le T</span> contributes exactly <span class="math">\frac{S}{T}</span> to the expectation. Crucially, these contribution scale linearly in <span class="math">S</span>: the only effect of splitting up to <span class="math">T</span> stake into small validators is to increase the variance of the active validator set size, without affecting the expectation. As for validators with stake <span class="math">S &gt; T</span>, they even decrease the expectation compared to the worst case, which is <span class="math">\frac{D}{T}</span>, equal to the full validator set size if all validators had <span class="math">T</span> stake.</p>
<p>For example, we can set <span class="math">T = 4096</span> ETH, giving us a <em>maximum</em> expected active validator set size of <span class="math">\frac{120M}{4096} \approx 30k</span>. If we were to employ stake capping (we will later discuss how to do so in this context) to ensure (or have high assurances) that <span class="math">D</span> is bounded by (for example) <span class="math">2^{25}M</span> ETH, we could even set <span class="math">T = 1024</span> and still have an expected active validator set size of at most ~32k. There can of course be deviations from this expected size, but with high probability the actual active validator set size would always fall within reasonably narrow bounds, so we can have very strong guarantees about the maximum load that we would need to be able to handle. We look at this in more detail <a href="https://ethresear.ch#Validator-capping-active-validator-set-variance">in the appendix</a>.</p>
<h3><a class="anchor" href="https://ethresear.ch#incentivizing-consolidation-10" name="incentivizing-consolidation-10"></a>Incentivizing consolidation</h3>
<p>Let <span class="math">D_a</span> be the active deposit size, i.e., the total stake of the active validator set, contrasted with the total deposit size <span class="math">D</span>, the stake of the whole validator set. Optimistically, as long as there is sufficient consolidation, <span class="math">D_a</span> will be high, a clear improvement over the <a href="https://ethresear.ch#Slow-rotation">previous slow rotation approach</a>. Still, we would like this to be more than an optimistic property. The question we are left to answer is then how we can ensure, or at least highly incentivize, a high <span class="math">\frac{D_a}{D}</span> ratio. For example, we want to prevent that all validators keep 32 ETH balances (no one consolidates), which would result in <span class="math">\mathbb{E}[D_a] = \frac{32}{T} D</span>, e.g., only <span class="math">\frac{D}{32}</span> with <span class="math">T = 1024</span>. With today’s <span class="math">D = 32M</span> ETH, the expected active deposit size would only be <span class="math">1M</span> ETH. On the other hand, we do not want to reward consolidated validators disproportionately compared to small validators.</p>
<p>We explore two complementary approaches:</p>
<ul>
<li><strong>Collective consolidation incentives</strong>, growing the size of the pie for the whole validator set when the set is more consolidated.</li>
<li><strong>Individual consolidation incentives</strong>, accounting for the extra risk accruing from further individual consolidation.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#collective-consolidation-incentives-11" name="collective-consolidation-incentives-11"></a>Collective consolidation incentives</h4>
<p>The first approach we explore is to reward <em>everyone</em> for consolidation, spreading out the benefits beyond the consolidating validators so as to maintain rewards undifferentiated, while still providing an incentive to consolidate.</p>
<p>A first proposal in this direction is to set the rewards based on <span class="math">D_a</span>, rather than <span class="math">D</span>. For example, we could use the same issuance curve <span class="math">I</span> we use today, but where the deposit size used as input is <span class="math">D_a</span> instead of <span class="math">D</span>: the cumulative issuance would then be <span class="math">I(D_a)</span>, and the resulting yield per unit of stake <span class="math">\frac{I(D_a)}{D}</span>. Notably, <span class="math">I</span> is monotonically increasing, so, whenever <span class="math">D_a &lt; D</span>, the cumulative issuance <span class="math">I(D_a)</span> is less than the maximum issuance <span class="math">I(D)</span> that would be possible at this deposit size, with full consolidation. The yield gap <span class="math">\frac{I(D) - I(D_a)}{D}</span> between the current yield and the yield with full consolidation then acts as a consolidation incentive.</p>
<p>Consolidation incentives aside, another way to think about this proposal is that we simply pay for the economic security we get, at least from a single committee: if today our security budget for <span class="math">X</span> amount of deposits is <span class="math">Y</span>, as expressed by <span class="math">I(X) = Y</span>, we would now be wiling to pay <span class="math">Y</span> in order to get <span class="math">X</span> amount of <em>active</em> deposits. To get an idea of what this looks like in practice, here’s a color plot of the yield for <span class="math">(D, \frac{D_a}{D})</span> (starting from <span class="math">D = 1</span> to help the visualization).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/afced2f656e5db107f33e22007ab6b5fdd5859fc.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/a/f/afced2f656e5db107f33e22007ab6b5fdd5859fc_2_623x500.png" width="623" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#individual-consolidation-incentives-12" name="individual-consolidation-incentives-12"></a>Individual consolidation incentives</h4>
<p><em>Credit to Anders for raising the issue of differentiated risk and for proposing the kind of individual incentives we explore here</em></p>
<p>Though our exploration of collective incentives has found them to be decently strong, there is one factor we have not considered: validators with stake <span class="math">\ll T</span> have a better risk profile than validators with stake <span class="math">\ge T</span>. This is because they are in the active only a fraction of the time, which means two things:</p>
<ul>
<li>In a staking pool, accidental slashing caused by a bad setup can be caught early with only a fraction of the validators being subject to it</li>
<li>Tail risk of mass slashing or leaking, for example due to client bugs, is much lower, as in many cases this would only affect the active set. For a staking pool, this effectively caps the pool’s slashing exposure to a fraction of the stake, in almost all scenarios.</li>
</ul>
<p>We might then be unwilling to solely rely on collective incentives, which cannot properly account for the risk differentiation between consolidated and non consolidated validators, itself an individual anti-consolidation incentive. On the other hand, we are hesitant to use individual consolidation incentives, because differentiated rewards threaten our goal of solo staking viability. Faced with this dilemma, a potential approach to mitigate the consequences on solo staking viability is to try to set individual consolidation incentives that just offset the added risk from consolidation. The goal is for risk-adjusted rewards to be roughly equivalent for consolidated and non consolidated validators, so that the available choices of higher risk, higher reward and lower risk, lower rewards are similarly attractive. In particular, it is then at least in principle possible (though not guaranteed) to have a validator set where both setups coexist, so that we can aspire to both have a high consolidation ratio and solo staking viability.</p>
<p>Concretely, here’s a way we could go about this. Given the base yield <span class="math">y(D_a, D) = \frac{I(D_a, D)}{D}</span>, we can adjust the yield of a validator with <span class="math">S</span> stake to be <span class="math">y(D_a, D)(1 + \frac{\min(S,T)}{T}g(\frac{D_a}{D}))</span>, where <span class="math">g(x)</span> is decreasing and <span class="math">g(1) = 0</span>. In other words, a validator with <span class="math">S</span> stake gets additional <em>consolidation yield</em> <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T}g(\frac{D_a}{D})y(D_a, D)</span>, or equivalently its yield increases by a factor of <span class="math">\frac{\min(S,T)}{T}g(\frac{D_a}{D})</span>, up to <span class="math">g(\frac{D_a}{D})</span> for fully consolidated validators with <span class="math">S = T</span>. This factor decreases as <span class="math">\frac{D_a}{D}</span> grows, because there are diminishing returns to further consolidation (same reason why the staking yield falls as the total deposit size grows). In particular, it falls all the way to <span class="math">0</span> if <span class="math">\frac{D_a}{D}</span> goes to <span class="math">1</span>, restoring the base yield <span class="math">y(D_a, D)</span> for everyone, and generally making the rewards less and less differentiated as more consolidation occurs. The idea is that an equilibrium will be reached where <span class="math">g(\frac{D_a}{D})</span> just about compensates for the additional risk from consolidating, and further consolidation is not incentivized. We can even set <span class="math">g</span> to reach <span class="math">0</span> at some lower level of consolidation that we are happy with, leaving more space for staking with non consolidated validators to be economically viable. For example, if <span class="math">g(0.8) = 0</span>, then a validator with 32 ETH gets the same yield, and less risk, as a validator with 1024 ETH, even if 20% of the stake is made up of 32 ETH validators.</p>
<p>Let’s now look at a specific form of <span class="math">g</span>. The simplest possible choice is a linear function, which is fully determined by <span class="math">g(0)</span>, the initial yield increase factor when there is no consolidation at all. The function is then simply <span class="math">g(x) = g(0)(1 - x)</span>. For example <span class="math">g(x) = \frac{1-x}{4}</span>, where the maximum yield increase is 25%. The extra yield of a validator with stake <span class="math">S</span> is:<br />
<span class="math">y_c(D_a, D, S) = g(0)\frac{\min(S,T)}{T} \cdot y(D_a, D) \cdot (1 - \frac{D_a}{D})</span></p>
<p>Let’s see what this looks like in combination with the collective incentives introduced <a href="https://ethresear.ch#Collective-consolidation-incentives">in the previous section</a>, where issuance is based on <span class="math">D_a</span>, i.e., <span class="math">y(D_a, D) = \frac{I(D_a)}{D}</span>, and <span class="math">I</span> is the current issuance curve <span class="math">I(x) = c\sqrt{x}</span>. The maximum consolidation yield, or the yield advantage of a consolidated validator over a regular one, is:</p>
<p><span class="math">y_c(D_a, D, S=T) = g(0) \cdot y(D_a, D) (1 - \frac{D_a}{D})  = \\
= g(0) \cdot c \cdot \frac{\sqrt{D_a}}{D}(1 - \frac{D_a}{D}) = \\ g(0) \cdot c \cdot \frac{1}{\sqrt{D_a}} \frac{D_a}{D}(1 - \frac{D_a}{D})</span></p>
<p>The next color plot shows <span class="math">y_c(D_a, D, S=T)</span> as a function of <span class="math">\frac{D_a}{D}</span> and <span class="math">D_a</span>, for <span class="math">g(0) = \frac{1}{4}</span> (some portion on the upper left corner is infeasible, because <span class="math">D</span> would be <span class="math">&gt; 120M</span>). Horizontally, the function looks like <span class="math">x(1-x)</span>: the consolidation yield is low at low consolidation levels, when collective incentives are strong, and at high consolidation levels, when we don’t have a strong requirement for more consolidation and we are more worried about the economic viability of running non consolidated validators. Vertically it looks like <span class="math">\frac{1}{\sqrt{y}}</span>, with the consolidation yield slowly falling off as <span class="math">D_a</span> grows and we have less need for consolidation in general, since the economic security of the active set is determined by <span class="math">D_a</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/c/fc72bbb9885865bf40afe632e841d2ab2ff06e70.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/f/c/fc72bbb9885865bf40afe632e841d2ab2ff06e70_2_586x500.png" width="586" /></a></div><p></p>
<p>We can of course very easily modify any such function <span class="math">g</span> so that the incentives fall to <span class="math">0</span> after a certain consolidation level <span class="math">r_0 \in [0,1]</span>, by replacing <span class="math">g</span> with <span class="math">\tilde{g}(x) = \max(g(\frac{x}{r_0}), 0)</span>, which squeezes <span class="math">g</span> in the range <span class="math">[0,r_0]</span> and sets the consolidation yield to <span class="math">0</span> afterwards. For example, this is the consolidation yield with <span class="math">r_0 = 80\%</span>, starting from the previous <span class="math">g(x) = \frac{1-x}{4}</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/b/1bf37fb8df61c4442a5054ccdaf8d55b02c351f9.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/b/1bf37fb8df61c4442a5054ccdaf8d55b02c351f9_2_573x500.png" width="573" /></a></div><p></p>



<h2><a class="anchor" href="https://ethresear.ch#appendix-13" name="appendix-13"></a>Appendix</h2>
<h3><a class="anchor" href="https://ethresear.ch#validator-capping-active-validator-set-variance-14" name="validator-capping-active-validator-set-variance-14"></a>Validator capping: active validator set variance</h3>
<p>Let’s also get an upper bound on the variance of the active validator set size. <span class="math">\mathbb{V}[|V_a|] = \mathbb{V}[\sum_{i\in V} \chi_{\{i \in V_a\}}] = \sum_{i\in V} \mathbb{V}[\chi_{\{i \in V_a\}}]</span>, since each validator is sampled independently. Moreover, <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = 0</span> whenever <span class="math">S_i \ge T</span>, since validator <span class="math">i</span> is then always in <span class="math">V_a</span>.<br />
For <span class="math">S_i &lt; T</span>, the variance is <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = p(S_i)(1 - p(S_i)) = \frac{S_i}{T}(1 - \frac{S_i}{T})</span>, which is maximized when <span class="math">p(S_i) = \frac{1}{2}</span>, or equivalently when <span class="math">S_i = \frac{T}{2}</span>, in which case <span class="math">\mathbb{V}[\chi_{\{i \in V_a\}}] = \frac{1}{4}</span>. Therefore, <span class="math">\mathbb{V}[|V_a|] \le \frac{1}{4}|V|</span>.</p>
<p>Concretely, say we keep a minimum balance of 32 ETH, so that the maximum validator set size <span class="math">|V|</span> is ~4M. The standard deviation of <span class="math">|V_a|</span> is then bounded by <span class="math">\frac{\sqrt{|V|}}{2} \approx 1000</span>. The probability of deviations beyond 10k is then vanishingly low. We can then even explicitly cap the active validator set size, say at 40k validators. Doing so introduces only a tiny correlation to the sampling of different validators, because sampling is completely unaffected other than in the exceedingly rare events of massive deviations.</p>
<h3><a class="anchor" href="https://ethresear.ch#collective-incentives-15" name="collective-incentives-15"></a>Collective incentives</h3>
<h4><a class="anchor" href="https://ethresear.ch#quantifying-the-individual-effect-of-collective-consolidation-incentives-16" name="quantifying-the-individual-effect-of-collective-consolidation-incentives-16"></a>Quantifying the individual effect of collective consolidation incentives</h4>
<p>Let’s look into the consolidation incentives a bit more quantitatively. While it is true that there is always some consolidation incentive whenever consolidation is at all possible, we should also consider how strong these incentives are for various stakers. In particular, the strength of the incentives varies based on how large a staker is, because a consolidation increases yield <em>for everyone</em>, not just for the party which peforms it. In other words, the gains of a consolidation are socialized, to avoid having a sort of consolidation reward, which would effectively disadvantage smaller validators that cannot access it. Consolidation incentives are therefore stronger the larger a validator is. On the one hand, this means that sufficiently large validators have a strong incentive to consolidate, which means we should expect <span class="math">D_a</span> to always represent at least a meaningful portion of the total stake <span class="math">D</span>. On the other hand, it means that small but still meaningfully sized stakers (e.g. 1%) might not be particularly incentivized to consolidate.</p>
<p>To quantify this, let’s look at how much of an issuance increase there is in the event of the full consolidation of a staker having a fraction <span class="math">p</span> of the total stake <span class="math">D</span>, when <span class="math">\frac{D_a}{D} = r</span>. Here we assume that the stake <span class="math">pD</span> in question is initially not consolidated at all, and neglect the small effect it has on <span class="math">D_a</span> (e.g. if <span class="math">T = 1024</span>, a minimum balance validator only increases <span class="math">D_a</span> by 1/32 of its stake). Issuance, and thus yield, increases by a factor of <span class="math">\frac{I(D_a + pD) - I(D_a)}{I(D_a)} = \frac{I((r + p)D)}{I(rD)} - 1</span>. Plugging in the definition of <span class="math">I</span>, we can simplify this to <span class="math">\sqrt{1 + \frac{p}{r}} - 1</span>. As expected, the consolidation incentives grow with <span class="math">p</span>. It is also expected that they fall with <span class="math">r</span>, since the issuance curve <span class="math">I</span> is concave. As it turns out, there’s no dependency on <span class="math">D</span> for this particular form of <span class="math">I</span>.</p>
<p>We now plot <span class="math">100(\sqrt{1 + \frac{p}{r}} - 1)</span>, the <em>percentage</em> of yield increase that every validator experiences when a fraction <span class="math">p</span> of the stake is fully consolidated, starting from <span class="math">D_a = rD</span>. We restrict <span class="math">r</span> to the range <span class="math">[0.1, 1]</span> for ease of visualization, because the consolidation incentives blow up for <span class="math">r</span> near <span class="math">0</span>, as we would wish. Notice that the minimum <span class="math">r</span> is actually <span class="math">1/32</span> for <span class="math">T = 1024</span> and minimum balance 32 ETH.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/ccde75a7bf33c1105849424713dceee8fd5b151d.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/ccde75a7bf33c1105849424713dceee8fd5b151d_2_598x500.png" width="598" /></a></div><p></p>
<p>On the other hand, the <em>absolute</em> yield increase <span class="math">100\cdot\frac{I(D_a + pD) - I(D_a)}{D_a}</span> is not independent of <span class="math">D</span>. We plot it here specifically for <span class="math">D = 30M</span> ETH. For lower values of <span class="math">D</span>, the consolidation incentives only get stronger in absolute terms.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/3/53bb8a566b7597b844788fa776551f98df5b36c3.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/3/53bb8a566b7597b844788fa776551f98df5b36c3_2_567x500.png" width="567" /></a></div><p></p>
<p>Finally, we also plot the yearly ETH returns from consolidation, <span class="math">(I(D_a + pD) - I(D_a))\cdot \frac{p}{r}</span>, again for <span class="math">D = 30M</span> ETH.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68a7e7faee22708549d1b4c2738e1016de2cf661.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68a7e7faee22708549d1b4c2738e1016de2cf661_2_578x500.png" width="578" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#generalizing-collective-incentives-17" name="generalizing-collective-incentives-17"></a>Generalizing collective incentives</h4>
<p>When <span class="math">I</span> is our current issuance curve, <span class="math">I(x) = c\sqrt{x}</span>, we have that <span class="math">I(D_a) = c\sqrt{D_a} = c \sqrt{D} \sqrt{\frac{D_a}{D}} = I(D)\sqrt{\frac{D_a}{D}}</span>. In other words, we can think about the previous proposal as incentivizing a high <span class="math">\frac{D_a}{D}</span> ratio by directly a  applying an issuance penalty based on it. More generally, we can let the issuance be <span class="math">I(D_a, D) = I(D) \cdot \delta(\frac{D_a}{D})</span> for any <span class="math">\delta</span> such that <span class="math">\delta(0) = 0</span> and <span class="math">\delta(1) = 1</span>. With this, the yield increase from consolidating is exactly <span class="math">\frac{I(D)}{D} \cdot (\delta(r + p) - \delta(p))</span>, i.e., a fraction <span class="math">\delta(r + p) - \delta(r)</span> of the maximum yield available at deposit size <span class="math">D</span>. The percentage yield increase is instead <span class="math">\frac{\delta(r + p) - \delta(r)}{\delta(r)}</span>. The simplest case is <span class="math">\delta(r) = r</span>, where <span class="math">I(D_a, D) = I(D) \cdot \frac{D_a}{D}</span>, in which case the yield increase is simply <span class="math">p \frac{I(D)}{D}</span>, constant in <span class="math">r</span>, and the percentage yield increase is <span class="math">\frac{p}{r}</span>.</p>
<p>In this form, we can more clearly separate the design of incentives to stake from that of incentives to consolidate the stake: <span class="math">I(D)</span> provides the <em>maximum</em> possible incentive to stake at a given total deposit level <span class="math">D</span>, while <span class="math">\delta</span> regulates the incentive to consolidate at a given ratio <span class="math">\frac{D_a}{D}</span>. We can for example have <span class="math">I</span> being concave, as it is currently, but <span class="math">\delta</span> linear as in the previous example: the protocol then considers stake deposits to have diminishing returns, while it believes consolidation to be equally valuable regardless of where <span class="math">\frac{D_a}{D}</span> currently sits.</p>
<h4><a class="anchor" href="https://ethresear.ch#discouragement-attacks-18" name="discouragement-attacks-18"></a>Discouragement attacks</h4>
<p>At any point, it is possible to increase <span class="math">D</span> while barely increasing <span class="math">D_a</span>, by activating validators with minimum balance. Thus, the issuance <span class="math">I(D_a)</span> is approximately constant, but distributed to more stake. This is the same <a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171#h-53-discouragement-attacks-32">discouragement attack</a> that would be possible with a constant issuance curve, or with issuance capped at some maximum value, where the yield also decreases like <span class="math">\frac{1}{D}</span>. While worse than today, where it decreases like <span class="math">\frac{1}{\sqrt{D}}</span>, this discouragement attack is nothing like the ultra cheap griefing vector that would arise with if we were to <a href="https://notes.ethereum.org/@vbuterin/single_slot_finality#Economic-capping-of-total-validator-count" rel="noopener nofollow ugc">use issuance to target a validator count</a>. For example, say we started reducing issuance past our ideal target of ~30k validators, and were to go negative at 40k. Then, activating a few thousands minimum balance validators, in the order of 0.01% to 0.1% of the stake, would be enough to make yields go negative. On the other hand, in the context of the discouragement attack we are considering here, reducing yield by a factor of <span class="math">k</span> requires increasing the deposit size by a factor of <span class="math">k</span>. For example, halving issuance when <span class="math">D = </span> 20M requires depositing another 20M.</p>
<h4><a class="anchor" href="https://ethresear.ch#stake-capping-19" name="stake-capping-19"></a>Stake capping</h4>
<p>If we were to set the issuance based on <span class="math">D_a</span>, we would not be able to immediately adopt any issuance curve that reduces issuance past some deposit size, like the ones discussed <a href="https://ethresear.ch/t/reward-curve-with-tempered-issuance-eip-research-post/19171/1">here</a> and <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">here</a>. The reason for that is simple: if issuance goes down past a certain value of <span class="math">D_a</span>, but it turns out that the yield at that point is still attractive, the incentives are such that <span class="math">D</span> would still grow (more stake wants yield at these levels) while <span class="math">D_a</span> would not (growing <span class="math">D_a</span> lowers yield). In fact, instead of consolidation incentives, we end up having incentives for splitting up stake over multiple validators, so as to decrease <span class="math">D_a</span> and keep it at the point of maximum issuance! Meanwhile, stake capping is not achieved, at least not any more than we would already achieve it by capping issuance at the maximum value, rather than having it decrease afterwards.</p>
<p>If we did want to adopt some form of stake capping, we would then need to do things a bit differently. We could let the issuance be <span class="math">I(D_a, D) = I(D_a) - f(D)</span>, where <span class="math">f</span> acts to reduce the issuance past some critical <em>total</em> deposit size. Intuitively, the goal is to try to ensure two things at once: that we have enough <span class="math">D_a</span>, and that we do not have too much <span class="math">D</span>. For example:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/8/c83ba4769d0fc0c8db841d28c0210dfdd3ab53d2.png" title=""><img alt="" height="227" src="https://ethresear.ch/uploads/default/optimized/3X/c/8/c83ba4769d0fc0c8db841d28c0210dfdd3ab53d2_2_690x227.png" width="690" /></a></div><p></p>
<p>To help visualizing the effect of this further, here are the cumulative issuance and yield while holding <span class="math">\frac{D_a}{D} = 0.8</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/4/044c55ed764d7dfddac4c2df5be73783c8017800.png" title=""><img alt="" height="230" src="https://ethresear.ch/uploads/default/optimized/3X/0/4/044c55ed764d7dfddac4c2df5be73783c8017800_2_690x230.png" width="690" /></a></div><p></p>
<p>Finally, here is a color plot of the yield in the <span class="math">(D, \frac{D_a}{D})</span> space. <span class="math">D</span> starts at 2 to help the visualization be effective.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/4/744db3435b9b033af6e55309e19068c435be1ffb.png" title=""><img alt="" height="463" src="https://ethresear.ch/uploads/default/optimized/3X/7/4/744db3435b9b033af6e55309e19068c435be1ffb_2_690x463.png" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#individual-incentives-20" name="individual-incentives-20"></a>Individual incentives</h3>
<h4><a class="anchor" href="https://ethresear.ch#total-issuance-21" name="total-issuance-21"></a>Total issuance</h4>
<p>The total <em>extra</em> issuance is:</p>
<p><span class="math">I_c(D_a, D) = \sum_{i \in V} y_c(D_a, D, S_i) S_i = g(0) y(D_a, D)(1 - \frac{D_a}{D}) \sum_{i \in V} p(S_i)S_i = \\ = g(0)y(D_a, D)\cdot D_a(1 - \frac{D_a}{D}) = g(0)I(D_a)\cdot \frac{D_a}{D}(1 - \frac{D_a}{D}) = \\
= g(0) \sqrt{D} \sqrt{\frac{D_a}{D}}\cdot \frac{D_a}{D}(1 - \frac{D_a}{D}) = g(0)I(D) \sqrt{\frac{D_a}{D}}\cdot \frac{D_a}{D}(1 - \frac{D_a}{D})</span></p>
<p>The total issuance then is:</p>
<p><span class="math">I_T(D_a, D) = I(D_a) + I_c(D_a, D) = I(D_a)(1 + g(0) \frac{D_a}{D}(1 - \frac{D_a}{D})) = \\
= c \sqrt{D} \sqrt{\frac{D_a}{D}}(1 + g(0)\cdot \frac{D_a}{D}(1 - \frac{D_a}{D})) = \\
= I(D) \sqrt{\frac{D_a}{D}} (1 + g(0)\frac{D_a}{D}(1 - \frac{D_a}{D})) = I(D) \cdot h(\frac{D_a}{D})</span>, where <span class="math">h(x) = \sqrt{x}(1 + g(0)x(1-x))</span>. For <span class="math">g(0) = \frac{1}{4}</span>, we have that <span class="math">h(x) \le 1</span> for <span class="math">x \in [0,1]</span>, so <span class="math">I(D)</span> remains an upper bound on the total issuance.</p>
<p><img alt="" height="435" src="https://ethresear.ch/uploads/default/original/3X/5/4/543c7981de3b9feeff11aff29ac6556c3f9ad5cf.png" width="547" /></p>
<h4><a class="anchor" href="https://ethresear.ch#generalizing-individual-consolidation-incentives-22" name="generalizing-individual-consolidation-incentives-22"></a>Generalizing individual consolidation incentives</h4>
<p>More generally, we can choose any consolidation yield curve <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} y_c(D_a, D)</span>, not necessarily depending on <span class="math">y(D_a, D)</span>, or even any curve <span class="math">y_c(D_a, D, S)</span> with a different kind of dependency on <span class="math">S</span>. An interesting example of the first kind is the curve <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} (y(D) - y(D_a, D))</span>, where <span class="math">y_c(D_a, D, S)</span> essentially interpolates between the yield <span class="math">y(D) = y(D_a = D, D)</span> that would be paid out to a fully consolidated validator set at deposit size <span class="math">D</span>, and the base yield <span class="math">y(D_a, D)</span> paid out at the current consolidation level. In other words, a validator with <span class="math">T</span> stake always gets paid the maximum possible yield for deposit size <span class="math">D</span>, <span class="math">y(D)</span>, regardless of the consolidation level achieved by the whole validator set, while validators with minimum stake get paid closer to the base yield <span class="math">y(D_a, D)</span>, and their yield linearly increases to <span class="math">y(D)</span> as they consolidate. In this case, the consolidation incentives are quite a bit stronger at lower consolidation levels.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/5229207a5722061af774a3d38e53aa0d28a08a89.png" title=""><img alt="" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/5229207a5722061af774a3d38e53aa0d28a08a89_2_573x500.png" width="573" /></a></div><p></p>
<p>While the absolute yield increase falls with <span class="math">D_a</span>, the percentage yield increase from consolidating does not. As it turns out, it only depends on <span class="math">\frac{D_a}{D}</span>:<br />
<span class="math">\frac{y_c(D_a, D)}{y(D_a, D)} = \frac{y(D) - y(D_a, D)}{y(D_a, D)} =
\frac{y(D)}{y(D_a, D)} - 1 = \sqrt{\frac{D}{D_a}} - 1 </span></p>
<p>In other words, this also fits the previous form <span class="math">y_c(D_a, D, S) = \frac{\min(S,T)}{T} g(\frac{D_a}{D}) y(D_a, D)</span>, with <span class="math">g(x) = \sqrt{\frac{1}{x}} - 1</span> instead of a linear function.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/a/4ab4a1cd832f6644730fd660799e1167f71af570.png" title=""><img alt="" height="293" src="https://ethresear.ch/uploads/default/optimized/3X/4/a/4ab4a1cd832f6644730fd660799e1167f71af570_2_690x293.png" width="690" /></a></div><p></p>
<p>Since <span class="math">y(D_a, D) + y_c(D_a, D, S) \le y(D)</span>, it still holds that <span class="math">I(D)</span> is a bound on the total issuance. In fact, the total issuance can be worked out to be <span class="math">I_T(D_a, D) = I(D_a) + I_c(D_a, D) = I(D) \sqrt{\frac{D_a}{D}}(1 + \sqrt{\frac{D_a}{D}} (1 - \sqrt{\frac{D_a}{D}})) = I(D) h(\frac{D_a}{D})</span>, with <span class="math">h(x) = \sqrt{x}(1 + \sqrt{x}(1 - \sqrt{x})))</span>, which we compare here to the previous example:</p>
<p><img alt="" height="435" src="https://ethresear.ch/uploads/default/original/3X/8/e/8e42613ed48e495edae62b74cecc8f994f7499a9.png" width="547" /></p>
            <p><small>3 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/orbit-ssf-solo-staking-friendly-validator-set-management-for-ssf/19928">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 07:22:10 +0000</pubDate>
</item>
<item>
<title>Number Duplicate Messages in Ethereum's Gossipsub Network</title>
<link>https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921</link>
<guid>https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921</guid>
<content:encoded><![CDATA[
<div> 关键词：GossipSub、Ethereum、消息重复、Hermes、优化建议

总结:<br />
GossipSub是Ethereum P2P网络中的消息广播协议，其设计允许一定程度的消息重复。研究团队使用工具Hermes追踪GossipSub性能，发现正常情况下每个消息最多接收3次重复（不包括通过IHAVE/IWANT控制消息传播的情况）。研究发现，通过网格的重复消息保持在3次或以下，但通过Gossip机制可能会有额外的重复。团队提出两点优化建议：限制并发IWANT请求的数量（类似Kademlia的alpha参数）和降低心跳频率，以减少IHAVE消息和额外重复。最后，尽管存在一些边缘情况，但大部分重复消息并不构成重大问题。 <div>
<h1><a class="anchor" href="https://ethresear.ch#summary-tldr-1" name="summary-tldr-1"></a>Summary &amp; TL;DR</h1>
<p>The ProbeLab team (<a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>) is carrying out a study on the performance of Gossipsub in Ethereum’s P2P network. Following from our previous post on the “<a href="https://ethresear.ch/t/gossipsub-network-dynamicity-through-grafts-and-prunes/19750">Gossipsub Network Dynamicity through GRAFTs and PRUNEs</a>” in this post we investigate the number of messages and duplicated messages seen by our node, per topic. There is no public data on the overhead that broadcasting messages and control data over the network imply on each participating node.</p>
<p>For the purposes of this study, we have built a tool called <strong>Hermes, which acts as a GossipSub listener and tracer</strong> (<a href="https://github.com/probe-lab/hermes/" rel="noopener nofollow ugc">GitHub - probe-lab/hermes: A Gossipsub listener and tracer.</a>). Hermes subscribes to all relevant pubsub topics and traces all protocol interactions. The results reported here are from a 3.5hr trace.</p>
<p><strong>Study Description:</strong> Gossipsub’s design is inherently allowing for message duplicates. A brief model we develop shows that it’s normal to receive each message up to 3 extra times (as a duplicate). This excludes the gossip mechanism which propagates messages through the IHAVE/IWANT control message sequence.</p>
<p><strong>TL;DR:</strong> We find that indeed duplicates through mesh stay in the order of 3 per message or below, which, however, doesn’t count for duplicates through gossip. For instance, there are edge cases where a message is requested (and responded to) through an IWANT message while the actual message is already in transit. Eventually, this results in an extra duplicate. We make two recommendations:</p>
<ol>
<li><strong>Reduce the number of concurrent <code>IWANT</code> messages we send through a limiting factor</strong> (somewhat similar to kademlia’s <code>alpha</code> parameter).</li>
<li><strong>Lower the current <code>heartbeat</code> frequency (i.e., increasing the <code>heartbeat</code> interval) from 0.7 seconds to 1 second</strong> (as per the original protocol spec and recommendation). This would reduce the excessive <code>IHAVE</code> messages and reduce the chances of generating extra duplicates.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#background-2" name="background-2"></a>Background</h1>
<p><a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.1.md" rel="noopener nofollow ugc">GossipSub</a> is a routing system that can be enabled on libp2p’s <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/README.md" rel="noopener nofollow ugc">PubSub</a> message broadcasting protocol. This protocol organizes the message broadcasting channels on what is commonly known as Topics, where peers subscribed to a given topic keep a particular subset of connected peers for that particular topic. This subset of peer connections per topic is also known as “mesh”.</p>
<p>In the case of GossipSub, the standard broadcasting mechanism of PubSub is extended with a few sets of enhancements that make it:</p>
<ul>
<li>more efficient than what is commonly called flooding, reducing the protocol’s bandwidth usage</li>
<li>more resilient, as the protocol:
<ul>
<li>shares metadata of seen messages over sporadic Gossip messages (for censorship or Sybil attacks)</li>
<li>keeps a local score for each mesh-connected peer to ensure healthy and useful connections, where each peer keeps connections with the highest scoring neighbours</li>
<li>avoids sharing a message with peers that already sent the message to us</li>
</ul>
</li>
</ul>
<p>This all looks good on paper. However, there is still no public data on the overhead that broadcasting messages and control data over the network imply on each participating node. Even more importantly, how much room for improvement exists within the protocol and the implementations to make it more optimal.</p>
<h2><a class="anchor" href="https://ethresear.ch#expected-results-3" name="expected-results-3"></a>Expected Results</h2>
<p>Message propagation through the GossipSub’s mesh considers some occasional duplicates that can arrive as the message might come from different peers within the mesh:</p>
<p>Given:</p>
<ul>
<li><code>n</code> as the number of nodes in the graph</li>
<li><code>k</code> as the mesh degree</li>
<li><code>l</code> as the number of connections (links) between two nodes <span class="math">l = \frac{nk}{2}</span></li>
</ul>
<p>The number of links used to propagate a message to all nodes in the graph can be defined as <code>n-1 ~= n</code>. The links form a spanning tree with the message origin as root (<code>n</code> is big enough compared to the initial sender link, so that it can be considered negligible).</p>
<p>The number of links not used to propagate a specific message corresponds to <span class="math">l-n = \frac{n(k-2)}{2}</span>.</p>
<p>This means that on average each node will have 1 link used to receive a message, 1 to propagate it to a peer that doesn’t have it yet. And the rest <code>k-2</code>, to either send or receive the duplicate message.</p>
<p>Assuming that <span class="math">\frac{k-2}{2}</span> links are used to send the message to peers that already have it, it means that we receive <span class="math">\frac{k-2}{2}</span> duplicate messages.</p>
<p>In the case of Ethereum, <code>k=8</code>, and therefore, it follows that <span class="math">\frac{k-2}{2} = 3</span>. So, <strong>the expected value is to receive 3 duplicate messages for each message</strong>.</p>
<h1><a class="anchor" href="https://ethresear.ch#results-4" name="results-4"></a>Results</h1>
<p>As previously introduced, this report aims to provide insights on:</p>
<ul>
<li>the number of duplicate messages that we receive per each shared message in the network,</li>
<li>the extra bandwidth that we are spending on duplicates,</li>
<li>any existing unexpected behavior or potential optimization that could be applied on GossipSub.</li>
</ul>
<blockquote>
<p>NOTES:<br />
The numbers presented in the following sections belong to the same 3.5 hours run of <code>Hermes</code> as the previous studies, with the following extra configuration:</p>
<ul>
<li>The experiment is ran on the <code>Holesky</code> network</li>
<li>Our node was subscribed to the following topics:
<ul>
<li><code>beacon_block</code></li>
<li><code>beacon_aggregate_and_proof</code></li>
<li><code>sync_commmittee_contribution_and_proof</code></li>
<li><code>attester_slashing</code></li>
<li><code>proposer_slashing</code></li>
<li><code>voluntary_exit</code> * (check <code>Hermes</code> issue → <a class="inline-onebox" href="https://github.com/probe-lab/hermes/issues/24" rel="noopener nofollow ugc">Broadcasting of invalid `voluntary_exit` messages to mesh peers · Issue #24 · probe-lab/hermes · GitHub</a>)</li>
<li><code>bls_to_execution_change</code></li>
</ul>
</li>
</ul>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#overall-number-of-messages-5" name="overall-number-of-messages-5"></a>Overall Number of Messages</h2>
<p>To give a little bit of context, the report starts by taking a look at the number of messages and the respective duplicates received over time. The following graph shows the number of <code>HANDLED</code> events by the libp2p-host in comparison with the <code>DELIVERED</code> and <code>DUPLICATED</code> ones.</p>
<blockquote>
<p>NOTE: In this report we will consider the <code>DELIVER</code> events as unique identifier of the arrival of a message. This is because the internal event tracer at the libp2p host notifies of the arrival of a unique message at multiple levels, which in turn, makes the <code>HANDLED</code> and <code>DELIVER</code> events at the arrival of a new message the exact same notification, just at different levels of the host.</p>
</blockquote>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65a05809dfbc2915a07ceadedbf9cd8d85f16fe8.jpeg" title="overall-number-of-events"><img alt="overall-number-of-events" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/6/5/65a05809dfbc2915a07ceadedbf9cd8d85f16fe8_2_517x309.jpeg" width="517" /></a></div><p></p>
<ul>
<li>The number of unique messages (i.e., <code>HANDLE_MESSAGE</code>) stays steady around the 3,000 and 3,200 unique messages per minute.</li>
<li>By looking closer into the messages per topic (not shown here), we observe that the topic with the highest message frequency is the <code>beacon_aggregate_and_proof</code> one, receiving over 90% of the tracked unique messages.</li>
<li>There are some duplicated spikes at the <code>beacon_block</code> topic that reach up to 60 duplicates  in some occasions.</li>
<li>The number of duplicates seems to vary quite wildly over time, which can be related to the number of connections per mesh (as per the analysis done further up which showed that 3 duplicates per message are expected).</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#number-of-duplicate-messages-6" name="number-of-duplicate-messages-6"></a>Number of Duplicate Messages</h2>
<p>When it comes to the actual number of <code>DUPLICATE</code> messages, the following figures show that number of duplicates can oscillate over time.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/d/edacb4d1d050448d2a5b17ef6c67ed0cb3ca42e0.png" title="duplicates-per-topic"><img alt="duplicates-per-topic" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/e/d/edacb4d1d050448d2a5b17ef6c67ed0cb3ca42e0_2_517x309.png" width="517" /></a></div><p></p>
<p>Clearly, the <code>beacon_block</code> topic seems to be the only one generating the largest number of spikes at times.</p>
<h2><a class="anchor" href="https://ethresear.ch#cdf-of-duplicate-messages-7" name="cdf-of-duplicate-messages-7"></a>CDF of Duplicate Messages</h2>
<p>The following graph shows the Cumulative Distribution Function (CDF) of the duplicates per message per topic. In the graph, we can see that:</p>
<ul>
<li>smaller but more frequent messages like the <code>beacon_ggregate_and_proof</code> and <code>sync_commitee_contributions</code> do have fewer duplicates.
<ul>
<li>between 32% and 45% of the messages do not have any duplicates.</li>
<li>50% of the messages are received with less than 2 duplicate messages, keeping the mean lower than the theoretical target of <code>3</code> duplicates per message.</li>
<li>the upper tail shows that less than 10% of the messages get more than 4 duplicates, with a cap at 8-10 duplicates (i.e., the node’s mesh size, <code>D</code>).</li>
</ul>
</li>
<li>the case of the <code>beacon_blocks</code> is completely different.
<ul>
<li>there are almost no recorded messages without duplicates (1%-2%).</li>
<li>54% of the messages report the expected <code>3</code>  duplicates from the mesh</li>
<li>Taking look at the tail of the CDF (shown in the dropdown plot further down) there are a few messages that were received up to 34 or 40 times.</li>
</ul>
</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/1/0153b674d22c5c90c7fee45cbf880ec5b865d548.png" title="CDF-duplicates"><img alt="CDF-duplicates" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/0/1/0153b674d22c5c90c7fee45cbf880ec5b865d548_2_517x309.png" width="517" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#correlation-between-message-size-and-number-of-duplicates-8" name="correlation-between-message-size-and-number-of-duplicates-8"></a>Correlation between Message Size and Number of Duplicates</h2>
<p>From the CDF above there seems to be a pattern of “the bigger the size of the message, the more duplicates it has”. So we went a step further to investigate if there is indeed a correlation. The following graph shows that the correlation between the size of a message and the number of duplicates is somewhat present but is not a norm or at least doesn’t follow any fixed pattern.</p>
<p>The figure is complemented by two auxiliary quartile plots or “boxplots”, which represent the given distribution of points of their respective axis, helping us understand that:</p>
<ul>
<li><code>sync_commmittee_contribution_and_proof</code> messages are the smallest ones in size, which also correlates with the smallest ratio of duplicate messages.</li>
<li><code>beacon_aggregate_and_proof</code> messages are the second ones in size, having also a bigger tail of duplicates on the Y concentration plot.</li>
<li><code>beacon_block</code> messages, despite being the ones with the widest variation in size, do not follow any particular pattern that could correlate the message size with the number of duplicates.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb40e85a2381cd48f38c553e329c3f0083a27196.png" title="msg-size-number-of-duplicates"><img alt="msg-size-number-of-duplicates" height="374" src="https://ethresear.ch/uploads/default/optimized/3X/f/b/fb40e85a2381cd48f38c553e329c3f0083a27196_2_383x374.png" width="383" /></a></div><p></p>
<p>As such, we conclude that <strong>there is no correlation between message size and number of duplicates</strong>.</p>
<h2><a class="anchor" href="https://ethresear.ch#arrival-time-of-duplicates-9" name="arrival-time-of-duplicates-9"></a>Arrival Time of Duplicates</h2>
<p>Reducing the number of duplicates has already been a topic of discussion in the community. There are already some proposals like <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2 </a> that spotted this large number of duplicated messages previously, proposing the addition of a new control <code>IDONTWANT</code> message that could not only notify other peers that we already got a message, but also cancel the <code>IWANT</code> ongoing messages.</p>
<p>In order to see how effective the <code>IDONTWANT</code> control message would be, we’ve computed the time between the first delivery of each message and their respective first duplicate. This is done to validate that there is enough time to send the <code>IDONTWANT</code> message once a new message is received (prior to the message validation) and before the duplicate starts being sent over.</p>
<p>The following graph gives the time between the delivery time of a message and the time to the first duplicated message in seconds.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e87ebed2ebacfb8abd79473ceb14e2af58bc7b82.png" title="arrival-cdf"><img alt="arrival-cdf" height="309" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e87ebed2ebacfb8abd79473ceb14e2af58bc7b82_2_517x309.png" width="517" /></a></div><p></p>
<p>Results show that 50% of the duplicated beacon blocks arrive within 73 milliseconds, roughly an entire Round Trip Time (RTT) with a well connected peer. In practice, this means that <strong>the <code>IDONTWANT</code> message could prevent at least the other 50% of messages that arrive between 73 milliseconds and 2 seconds of the first arrival</strong>.</p>
<p>We’ve spotted that a big part of the duplicated messages arrive from <code>IWANT</code> messages that we sent milliseconds before the arrival of the same message though the mesh.<br />
The <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2</a> proposal already contemplates <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md#cancelling-iwant" rel="noopener nofollow ugc">this scenario</a>, where the same <code>IDONTWANT</code> message could break or stop any ongoing responses to <code>IWANT</code> messages for that <code>msgID</code>.</p>
<p>In summary, we conclude that <strong>the <code>IDONTWANT</code> control message addition to Gossipsub will be a valuable enhancement that can indeed prevent the vast majority of duplicate messages</strong>.</p>
<h1><a class="anchor" href="https://ethresear.ch#conclusions-and-takeaways-10" name="conclusions-and-takeaways-10"></a>Conclusions and takeaways</h1>
<blockquote>
<p>This set of conclusions have been extracted from running the <code>go-libp2p</code>  implementation and, although it also involves the traces of how other implementations interact with Hermes, it might be a biased conclusion from the point of view of the Go implementation.</p>
</blockquote>
<ol>
<li>
<p>We have identified that there is no limit on the number of peers that we simultaneously send <code>IWANT</code> messages to for the same <code>msgID</code>.<br />
We identify that this has some benefits:</p>
<ul>
<li>Concurrently fetches the message from multiple actors.</li>
<li>Bypasses bandwidth limitations of peer(s) we have sent <code>IWANT</code> messages to, since we have forwarded the <code>IWANT</code> message to multiple peers.</li>
</ul>
<p>However, it also has obvious downsides:</p>
<ul>
<li>
<p>We receive multiple duplicates from the peers that respond to our simultaneous <code>IWANT</code> request, consuming more bandwidth on both ends.</p>
</li>
<li>
<p>The message could be already on the wire through the mesh connections, so when the <code>IWANT</code> message responses arrive, the message was already delivered through the mesh.</p>
</li>
<li>
<p>There is no track of who we contacted for a given message, given that Gossipsub is:</p>
<ul>
<li>forwarding the message only the first time we see it, and</li>
<li>removing the peer that sent us the message from the list of peers we’re broadcasting the message to and forgetting about that peer.</li>
</ul>
<p>This makes the entire broadcasting process unaware of who sent us that message in <code>IHAVE</code>s, or who we are already contacting for a particular message - resulting in multiple duplicates.</p>
</li>
</ul>
<p><a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md#cancelling-iwant" rel="noopener nofollow ugc">Canceling ongoing <code>IWANT</code>messages</a> with <code>IDONTWANT</code> messages, which is a proposal included in <a href="https://github.com/libp2p/specs/blob/f25d0c22e5ef045c8c050bc91c297468de35f720/pubsub/gossipsub/gossipsub-v1.2.md" rel="noopener nofollow ugc">gossipsub1.2</a> is a valuable enhancement that will limit the number of duplicates.</p>
<h3><a class="anchor" href="https://ethresear.ch#recommendation-1-11" name="recommendation-1-11"></a><strong>Recommendation 1</strong></h3>
<p>We propose having a limiting factor (somewhat similar to kademlia’s <code>alpha</code> parameter), which would limit the number of concurrent <code>IWANT</code> messages we send for the same <code>msgID</code>.</p>
<hr />
<hr />
</li>
<li>
<p>The gossiping mechanism of Gossipsub acts as a backup mechanism to the broadcasting/mesh propagation part of the protocol for those messages that didn’t manage to reach all nodes in the network. The more frequent gossiping is, the higher its contribution becomes to message propagation (i.e., more messages are being requested through <code>IWANT</code> requests because they have not reached the entirety of the network).</p>
<p>An edge case that results from very frequent gossiping (i.e., small <code>heartbeat</code> interval) is that messages that are already in transit, but have not been downloaded completely, are being requested through an <code>IWANT</code> message. This inevitably results in a duplicate message once both messages arrive at their destination.</p>
<p>It is hard to quantify how often the message responses to <code>IWANT</code> messages are indeed future duplicates, but it is still worth pointing out that high heartbeat frequency increases the chances of those edge cases.</p>
<h3><a class="anchor" href="https://ethresear.ch#recommendation-2-12" name="recommendation-2-12"></a>Recommendation 2</h3>
<p>A quick and straightforward optimization is to <strong>lower the current <code>heartbeat</code> frequency (i.e., increasing the <code>heartbeat</code> interval) from 0.7 seconds to 1 second</strong> (as per the original protocol spec and recommendation). This would reduce the excessive <code>IHAVE</code> messages and reduce the chances of generating extra duplicates.</p>
<hr />
<hr />
</li>
<li>
<p>We have spotted some edge cases that may occur due to the “lack” of control over the triggered events at GossipSub (<code>IHAVE</code>/ <code>IWANT</code>).</p>
<p>It isn’t easy to judge from the logs whether those cases are just a matter of timing, as GossipSub replies to those events as interruptions (at least in the Go implementation), or if some of those cases are caused by a bug in one of the implementations.</p>
<p>We found that <strong>the number of messages where we received multiple duplicates from the same peer to just 1% of the total number of <code>beacon_blocks</code> received</strong>. We, therefore, conclude that this is not critical or an issue that requires further investigation.</p>
</li>
</ol>
<p>For more details and <strong>weekly network health reports on Ethereum’s discv5 DHT network</strong> head over to <a href="https://probelab.io/" rel="noopener nofollow ugc">probelab.io</a>.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/number-duplicate-messages-in-ethereums-gossipsub-network/19921">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 08:48:46 +0000</pubDate>
</item>
<item>
<title>Estimating Validator Decentralization Using p2p Data</title>
<link>https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920</link>
<guid>https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920</guid>
<content:encoded><![CDATA[
<div> 关键词：地理分布、验证器、Ethereum、共识层网络、节点连接

总结:<br />
文章探讨了Ethereum区块链中验证器的地理分布问题，重点关注了验证器客户端与 beacon 节点的分离。研究者通过分析验证器的职责、随机分配的委员会以及使用的网络协议，确定了验证器在短-lived attestation subnets上的活动作为调查核心。方法论包括监听节点订阅请求、收集和分析元数据，尤其是订阅的子网数量。然而，由于某些客户端的行为策略，实际观察到的短-lived子网订阅较少，限制了验证器数量的准确估计。结果仅提供了部分验证器的地理分布信息，且存在一些局限性，如最大估计值为62个验证器等。 <div>
<blockquote>
<p>Written by <a href="https://x.com/mempirate" rel="noopener nofollow ugc">Jonas</a> &amp; <a href="https://x.com/namn_grg" rel="noopener nofollow ugc">Naman</a> from <a href="https://x.com/chainbound_" rel="noopener nofollow ugc">Chainbound</a>.<br /><br />
This research was funded by the Robust Incentives Group at the Ethereum Foundation. This work is specifically related to ROP-8. Additional information can be found <a href="https://www.notion.so/bad7233658cc41f38b26e7b4f6cf6e8b?pvs=21" rel="noopener nofollow ugc">here</a>. We want to thank <a href="https://x.com/soispoke" rel="noopener nofollow ugc">soispoke</a>, the <a href="https://x.com/EthPandaOps" rel="noopener nofollow ugc">EF DevOps team</a>, <a href="https://migalabs.io/" rel="noopener nofollow ugc">MigaLabs</a> and <a href="https://probelab.io/" rel="noopener nofollow ugc">ProbeLab</a> for their advice and contributions!</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#table-of-contents-1" name="table-of-contents-1"></a>Table of Contents</h2>
<ul>
<li><a href="https://ethresear.ch#introduction">Introduction</a></li>
<li><a href="https://ethresear.ch#anatomy-of-a-validator">Anatomy of a validator</a></li>
<li><a href="https://ethresear.ch#attestation-duties-and-committees">Attestation duties and committees</a></li>
<li><a href="https://ethresear.ch#attestation-subnets">Attestation subnets</a>
<ul>
<li><a href="https://ethresear.ch#subnet-types">Subnet types</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#validator-footprints">Validator footprints</a></li>
<li><a href="https://ethresear.ch#methodology">Methodology</a>
<ul>
<li><a href="https://ethresear.ch#long-lived-subnets">Long-lived subnets &amp; node metadata</a></li>
<li><a href="https://ethresear.ch#short-lived-subnets">Short-lived subnets</a></li>
<li><a href="https://ethresear.ch#estimating-validator-counts">Estimating validator counts</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#architecture">Architecture</a>
<ul>
<li><a href="https://ethresear.ch#crawler">Crawler</a></li>
<li><a href="https://ethresear.ch#consumer">Consumer</a></li>
</ul>
</li>
<li><a href="https://ethresear.ch#results">Result</a></li>
<li><a href="https://ethresear.ch#limitations">Limitations</a></li>
<li><a href="https://ethresear.ch#references">References</a></li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>The geographical distribution of a validator set is <a href="https://collective.flashbots.net/t/decentralized-crypto-needs-you-to-be-a-geographical-decentralization-maxi/1385" rel="noopener nofollow ugc">one of the most critical factors</a> in determining a blockchain’s level of decentralization. Validator decentralization is vital for Ethereum. It enhances network security, resilience, and censorship resistance by distributing control and minimizing the risk of single points of failure or malicious attacks.</p>
<p>It is well known that Ethereum has a <a href="https://beaconcha.in/charts/validators" rel="noopener nofollow ugc">very large</a> validator set, but <strong>is this validator set geographically distributed?</strong> Ethereum has a substantial amount  of beacon nodes running on the consensus layer network, with current estimates at around ~12,000 active nodes (<a href="https://nodewatch.io/" rel="noopener nofollow ugc">source</a>). A beacon node serves as a <em>potential</em> entrypoint into the network for validators, but it is not representative of the actual validator distribution.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f1dda810cb6cc5f9d3db8c3c592d8167d16710e.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f1dda810cb6cc5f9d3db8c3c592d8167d16710e_2_500x500.jpeg" width="500" /></a></div><br />
<small><em>Probably not.</em></small><p></p>
<p>In this article, we present the methodology and results of an investigation aiming to address this question. We start with some context about the logical components making up a validator, then proceed with some potential methods of identifying validators on the beacon P2P network. We then expand on our chosen methodology and finally present the results.</p>
<h2><a class="anchor" href="https://ethresear.ch#anatomy-of-a-validator-3" name="anatomy-of-a-validator-3"></a>Anatomy of a validator</h2>
<p>An Ethereum validator is a virtual entity that consists of a balance, public key and other properties on the beacon chain. They are roughly responsible for 4 things:</p>
<ol>
<li>Proposing new blocks</li>
<li>Voting on other block proposals (attesting)</li>
<li>Aggregating attestations</li>
<li>Slashing other validators in case they commit faults</li>
</ol>
<p>A <em>validator client</em> is the piece of software that executes these responsibilities for each of its registered validator keys (which can be many). But a validator client on its own cannot connect to the P2P beacon network to talk directly to other validators. Instead, it connects to an entity known as a <em>beacon node</em>, which is a standalone client that maintains the beacon chain and communicates with other beacon nodes.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/8/68536fc182f09a1eb2c1e4b89f380dd4aca9c326.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/6/8/68536fc182f09a1eb2c1e4b89f380dd4aca9c326_2_495x500.jpeg" width="495" /></a></div><br />
<small><em>Schematic of validator clients and a beacon node</em></small><p></p>
<p>Beacon nodes can have a number of validators attached to them that ranges from zero to thousands. In fact, <a href="https://medium.com/@grandine/grandine-0-4-1-released-fb98daef6d60" rel="noopener nofollow ugc">it’s been reported</a> that in some Ethereum testnets client developers have been running upwards of 50k validators on a single machine. This separation of concerns makes our investigation somewhat harder: a simple crawl of the P2P network might give us a good overview of the set of online beacon nodes in real time, but this is not representative of the overall validator client distribution at all. Before we address this problem, we’ll take a closer look at validator duties and their footprint on the network.</p>
<h2><a class="anchor" href="https://ethresear.ch#attestation-duties-and-committees-4" name="attestation-duties-and-committees-4"></a>Attestation duties and committees</h2>
<p>As mentioned above, one of the main responsibilities of a validator is voting on blocks by broadcasting <em>attestations</em>. These attestations express the view of a validator about which chain they think is correct. In more detail, they actually cast 2 different votes: one to express their view of the current head block, and one to help finalize past blocks. This is because Ethereum’s  consensus is a combination of <a href="https://arxiv.org/pdf/2003.03052" rel="noopener nofollow ugc">2 subprotocols</a>: LMD GHOST, a fork-choice rule, and a finality gadget called Casper FFG.</p>
<p>These duties are assigned randomly every epoch (with some <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/validator.md#lookahead" rel="noopener nofollow ugc">lookahead</a>) with RANDAO as the source of randomness. Validators get assigned to one slot per epoch at which they have to cast their attestation, which is just a message with the votes that is signed over with the validator BLS private key. These votes are then to be packed and stored in the next beacon block. However, if <a href="https://beaconcha.in/charts/validators" rel="noopener nofollow ugc">all 1 million validators</a> were to attest for every block, the network would be flooded with messages, and the proposer that is supposed to pack these attestations into their block would have trouble verifying all of those signatures in time. This would make Ethereum’s design goal of low resource validation unfeasible.</p>
<p>To address these issues, the beacon network is subdivided into <em>committees</em>, which are subsets of the active validator set that distribute the overall workload. Committees have a minimum size of <span class="math">128</span> validators, and there are <span class="math">64</span> committees that are assigned per slot. But how is this achieved in practice? What network primitives do we require to enable such a logical separation?</p>
<h2><a class="anchor" href="https://ethresear.ch#attestation-subnets-5" name="attestation-subnets-5"></a>Attestation subnets</h2>
<p>The Ethereum consensus P2P network is built with <a href="https://github.com/libp2p/specs/tree/master/pubsub/gossipsub" rel="noopener nofollow ugc">GossipSub</a>, a scalable pubsub protocol running on libp2p. Being a pubsub protocol, GossipSub supports publish/subscribe patterns and the segmentation of networks into logical components called <em>topics</em> (aka P2P overlays)<em>.</em> These are the networking primitives that underpin beacon committees.</p>
<p>One example of a topic is the <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_block" rel="noopener nofollow ugc"><code>beacon_block</code></a> topic, which is a <em>global topic</em> on which new beacon blocks are broadcast. Every validator must subscribe to this topic in order to update their local view of the chain and perform their duties.</p>
<p>The attestation overlays look quite a bit different. For each committee, we derive a subnet ID based on the committee index (0-64). The topic for the respective subnets then becomes <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_attestation_subnet_id" rel="noopener nofollow ugc"><code>beacon_attestation_{subnet_id}</code></a>. Every validator knows their upcoming attestation duties at least 1 epoch ahead of time and can join the correct subnet in advance. When they have to make an attestation, they broadcast it on this subnet.</p>
<p>As mentioned before, these attestations are eventually supposed to make it into a beacon block. But since upcoming proposers might not be subscribed to these subnets, how does that work? This is where <em>attestation aggregators</em> come in. These are a subset of the beacon committees that are responsible for <em>aggregating</em> all of the attestations they see and broadcasting the aggregate attestations on the global <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#beacon_attestation_subnet_id" rel="noopener nofollow ugc"><code>beacon_aggregate_and_proof</code></a> topic. This topic is again a mandatory global topic that all validators will be subscribed to, thus providing a way for local unaggregated attestations to make it into the global view of the network. Per committee, there’s a target number of aggregators of <span class="math">16</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#subnet-types-6" name="subnet-types-6"></a>Subnet types</h3>
<p>These attestation subnets described above are ephemeral and directly tied to the validator duties. We call these <strong>short-lived</strong> attestation subnets. The problem with these ephemeral subnets is that they are not very robust, and could result in lost messages. To deal with this issue, the notion of a “<a href="https://github.com/ethereum/consensus-specs/issues/2749" rel="noopener nofollow ugc">subnet backbone</a>” was introduced.</p>
<p>This backbone consists of <strong>long-lived</strong>, persistent subnet subscriptions that are not tied to validator duties but rather a <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#attestation-subnet-subscription" rel="noopener nofollow ugc">deterministic function</a> of the beacon node’s unique ID and the current epoch. These long-lived subnets are maintained for <span class="math">256</span> epochs, or around 27 hours, and each beacon node has to subscribe to 2 of them. They are also advertised on the discovery layer, making it easier for beacon nodes with certain duties to find peers on the relevant subnets.</p>
<h2><a class="anchor" href="https://ethresear.ch#validator-footprints-7" name="validator-footprints-7"></a>Validator footprints</h2>
<p>Returning to the separation of the beacon node and validator clients, there’s now a clear footprint that validators leave on the beacon node’s network identity: their short-lived subnet subscriptions. This will be the core of our methodology.</p>
<h2><a class="anchor" href="https://ethresear.ch#methodology-8" name="methodology-8"></a>Methodology</h2>
<p>Generally, the beacon network consists of 3 domains:</p>
<ul>
<li>The discovery domain</li>
<li>The Req/Resp domain</li>
<li>The gossip domain</li>
</ul>
<p>Each of these domains provides some information about a beacon node.</p>
<h3><a class="anchor" href="https://ethresear.ch#long-lived-subnets-node-metadata-9" name="long-lived-subnets-node-metadata-9"></a>Long-lived subnets &amp; node metadata</h3>
<p>At the <strong>discovery layer</strong> (<a href="https://github.com/ethereum/devp2p/blob/5713591d0366da78a913a811c7502d9ca91d29a8/discv5/discv5.md" rel="noopener nofollow ugc">discv5</a>), a beacon node’s identity consists of an <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#enr-structure" rel="noopener nofollow ugc">ENR</a> with some additional metadata. This metadata can roughly be represented as the following object:</p>
<pre><code class="lang-js">{ 
	peer_id, 
	ip, 
	tcp_port, 
	udp_port, 
	attnets, // Important
	fork_digest, 
	next_fork_version, 
	next_fork_epoch 
}
</code></pre>
<p>This metadata helps other peers connect to peers that are relevant to them, indeed, one of the extra metadata fields are the (long-lived) attestation subnets that this node is subscribed to!</p>
<p>The <strong>Req/Resp domain</strong> is where the actual handshake happens. This is where nodes exchange <code>Status</code> messages that look like the following in order to establish a connection:</p>
<pre><code class="lang-js">(
  fork_digest: ForkDigest
  finalized_root: Root
  finalized_epoch: Epoch
  head_root: Root
  head_slot: Slot
)
</code></pre>
<p>The underlying protocol used for the Req/Resp domain is (again) libp2p. On the lower levels, additional information like <code>client_version</code> is also exchanged when connections are set up.</p>
<p>It is at this level that peers can also exchange <code>MetaData</code> objects to identify each other’s most up to date long-lived subnet subscriptions. The <a href="https://github.com/ethereum/consensus-specs/blob/29f39487de964683bbe13d11c7c58b3fe13dca10/specs/phase0/p2p-interface.md#metadata" rel="noopener nofollow ugc"><code>MetaData</code></a> object looks like this:</p>
<pre><code class="lang-js">(
  seq_number: uint64
  attnets: Bitvector[ATTESTATION_SUBNET_COUNT]
  ...
)
</code></pre>
<h3><a class="anchor" href="https://ethresear.ch#short-lived-subnets-10" name="short-lived-subnets-10"></a>Short-lived subnets</h3>
<p>So far, we’ve only seen how nodes exchange metadata and their long-lived subnet subscriptions, which tell us nothing about potential validators. For that, we need the short-lived subnets, which we can only collect on the gossip domain. Our initial strategy was doing just that:</p>
<ol>
<li>Listen to incoming topic subscription requests</li>
<li>Save and index them</li>
</ol>
<p>However, on an initial review of the data, we saw way too many beacon nodes that didn’t subscribe to any additional subnets besides their long-lived, mandatory subscriptions.</p>
<p>Our assumption was that in order to publish data on a gossipsub topic, one needed to be subscribed to it. It turns out that this is not the case, and many clients have different behaviour to minimize bandwidth and CPU usage. Rather than subscribing to the subnet directly, the peer finds other peers that are subscribed to the required subnet beforehand and shares the attestation with them. The subscribed peers make sure to verify and forward these attestations. Remember that in theory, only attestation aggregators need to be listening to all incoming attestations in order to do their jobs. This is exactly what was happening, and explains why we had so little short-lived subnet observations.</p>
<p>With this understanding, we could now tune our assumptions:</p>
<ul>
<li>For each subnet, there’s a target of <code>TARGET_AGGREGATORS_PER_COMMITTEE=16</code> aggregators per committee</li>
<li>This means that on average, there will only be <span class="math">16</span> validators per committee that will be subscribed to an additional short-lived subnet for the duration of an epoch</li>
<li>This results in a maximum of <span class="math">16 * 32 * 64 = 32768</span> useful observations per epoch</li>
</ul>
<p>With these assumptions in mind, we can start estimating validator counts.</p>
<h3><a class="anchor" href="https://ethresear.ch#estimating-validator-counts-11" name="estimating-validator-counts-11"></a>Estimating validator counts</h3>
<p>For each observation, we subtract the number of long-lived subnets <span class="math">S_l</span> from all subscribed subnets <span class="math">S_{all}</span> to arrive at the number of short-lived subnets <span class="math">S_s</span>:</p>
<div class="math">
S_s = S_{all} - S_l
</div>
<p>Since we know aggregators are subscribed to one additional subnet per epoch, <span class="math">S_s</span> will result in an estimated validator count for a certain beacon node in this epoch. Note that just one observation will not be enough to get an accurate estimate, because of the following reasons:</p>
<ul>
<li>It could be that a validator is not an aggregator for this epoch, and thus won’t subscribe to any subnets</li>
<li>There could be overlap between the long-lived and short-lived subnets</li>
</ul>
<p>Due to this reason, we continuously try to collect observations for each known beacon node per epoch, and save the maximum estimated validator counts. Note also that the ceiling for validator estimations is at <span class="math">64 - 2</span>, because that’s the maximum amount of short-lived subnets we can record. This is important! It means that for beacon nodes with more than <span class="math">62</span> validators, we can not estimate how many there are, and just record the ceiling. We want to highlight again that this is just an estimation and won’t be a very accurate representation of the total number of validators.</p>
<h2><a class="anchor" href="https://ethresear.ch#architecture-12" name="architecture-12"></a>Architecture</h2>
<p>In this section we’ll dive a bit deeper into the architecture. All the code for this is open source and can be found in this repository: <a class="inline-onebox" href="https://github.com/chainbound/valtrack" rel="noopener nofollow ugc">GitHub - chainbound/valtrack: An Ethereum validator crawler</a>. A lot of the crawler code is based on projects like <a href="https://github.com/probe-lab/hermes" rel="noopener nofollow ugc">Hermes</a> and <a href="https://github.com/migalabs/armiarma/" rel="noopener nofollow ugc">Armiarma</a>. An overview can be seen here:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/8/e856490bf2dd28b100abeb8c0f37e50f389e882b.jpeg" title="image"><img alt="image" height="305" src="https://ethresear.ch/uploads/default/optimized/3X/e/8/e856490bf2dd28b100abeb8c0f37e50f389e882b_2_690x305.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#crawler-13" name="crawler-13"></a>Crawler</h3>
<p>The crawler is the core component of the system. It will crawl the discv5 discovery DHT, find nodes that are on the correct network by looking at the metadata in their ENRs, and then try to connect with them. It will keep a local cache of known peers and try to reconnect every epoch to get updated observations.</p>
<p>We outline 2 types of events (observations): <code>PeerDiscoveryEvent</code> and <code>MetadataReceivedEvent</code>. The second one is most relevant and contains the following fields:</p>
<pre><code class="lang-go">type MetadataReceivedEvent struct {
	ENR               string          `json:"enr"`
	ID                string          `json:"id"`
	Multiaddr         string          `json:"multiaddr"`
	Epoch             int             `json:"epoch"`
	MetaData          *eth.MetaDataV1 `json:"metadata"`
	SubscribedSubnets []int64         `json:"subscribed_subnets"`
	ClientVersion     string          `json:"client_version"`
	CrawlerID         string          `json:"crawler_id"`
	CrawlerLoc        string          `json:"crawler_location"`
	Timestamp         int64           `json:"timestamp"` // Timestamp in UNIX milliseconds
}
</code></pre>
<p>Along with some metadata, this contains all of the fields required to apply the previously described methodology: <code>SubscribedSubnets</code> contains the actually subscribed subnets, obtained by listening on the GossipSub domain, and <code>MetaData</code> contains the peer’s long-lived subnets.</p>
<p>All of these events are then sent to a persistent message queue, where they are stored until they’re read by the consumer.</p>
<h3><a class="anchor" href="https://ethresear.ch#consumer-14" name="consumer-14"></a>Consumer</h3>
<p>The consumer turns the event logs into a stateful view of the network by implementing the methodology described above. It parses the short-lived subnets from the metadata events to get the estimated validator counts, and updates any existing entries in its stateful view. This stateful view is saved in a local sqlite database, which we expose over an API. The table schema roughly looks like this:</p>
<pre><code class="lang-sql">validator_tracker (
	peer_id TEXT PRIMARY KEY,
	enr TEXT,
	multiaddr TEXT,
	ip TEXT,
	port INTEGER,
	last_seen INTEGER,
	last_epoch INTEGER,
	client_version TEXT,
	possible_validator BOOLEAN,
	max_validator_count INTEGER,
	num_observations INTEGER,
	hostname TEXT,
	city TEXT,
	region TEXT,
	country TEXT,
	latitude REAL,
	longitude REAL,
	postal_code TEXT,
	asn TEXT,	
	asn_organization TEXT,
	asn_type TEXT
)
</code></pre>
<p>We then join this data together with an IP location dataset to provide more information about geographical distribution.</p>
<h2><a class="anchor" href="https://ethresear.ch#results-15" name="results-15"></a>Results</h2>
<p><a href="https://www.chainbound.io/" rel="noopener nofollow ugc">Chainbound</a> runs a <a class="inline-onebox" href="https://github.com/chainbound/valtrack" rel="noopener nofollow ugc">GitHub - chainbound/valtrack: An Ethereum validator crawler</a> deployment that pushes all data to Dune every 24 hours.</p>
<blockquote>
<p><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> Dune table link: <a href="https://dune.com/data/dune.rig_ef.validator_metadata" rel="noopener nofollow ugc">https://dune.com/data/dune.rig_ef.validator_metadata</a>.</p>
</blockquote>
<p><em>This data has been stripped of sensitive information such as IP addresses and exact coordinates. However, it retains information like city, coordinates with a precision of a 10km radius, and ASN information.</em></p>
<p>An example dashboard leveraging this information can be seen <a href="https://chainbound.grafana.net/dashboard/snapshot/AmuaGRjfOrARoc7BWY9L43dD5jIgsgnf?orgId=1" rel="noopener nofollow ugc">here</a>.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/5/e5a141037b8bcb98e8247ccb94f3daeeb2d143ce.jpeg" title="image"><img alt="image" height="360" src="https://ethresear.ch/uploads/default/optimized/3X/e/5/e5a141037b8bcb98e8247ccb94f3daeeb2d143ce_2_690x360.jpeg" width="690" /></a></div><p></p>
<p>We also store the individual event logs, like PeerDiscoveryEvent and MetadataReceivedEvent. These are available on demand by sending an email to <a href="mailto:admin@chainbound.io">admin@chainbound.io</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#limitations-16" name="limitations-16"></a>Limitations</h2>
<ul>
<li>The maximum number of validators we can estimate with this methodology per beacon node is 62, due to that being the maximum amount of short-lived subnet subscriptions. This will result in a significantly underreported total number of validators, but should still be able to provide a reasonable estimation of the geographical distribution.</li>
<li>We failed to gather any meaningful data on Teku nodes over the 30-day period, which could signify an error in our P2P implementation and impact the results.</li>
<li>These results will be skewed towards validators attached to beacon nodes that have opened P2P networking ports in their firewall, which will mostly be beacon nodes running on cloud providers. The reason for this is that our crawler can more easily connect to nodes that have exposed ports.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#references-17" name="references-17"></a>References</h2>
<ul>
<li><a class="inline-onebox" href="https://eth2book.info/capella/" rel="noopener nofollow ugc">Upgrading Ethereum</a></li>
<li><a class="inline-onebox" href="https://hackmd.io/@dmarz/ethereum_overlays" rel="noopener nofollow ugc">The Hitchhiker's Guide to P2P Overlays in Ethereum Consensus - HackMD</a></li>
<li><a class="inline-onebox" href="https://github.com/ethereum/consensus-specs/tree/dev" rel="noopener nofollow ugc">GitHub - ethereum/consensus-specs: Ethereum Proof-of-Stake Consensus Specifications</a></li>
</ul>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/estimating-validator-decentralization-using-p2p-data/19920">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 08:33:30 +0000</pubDate>
</item>
<item>
<title>Presenting Klaster - rethinking chain abstraction</title>
<link>https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910</link>
<guid>https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910</guid>
<content:encoded><![CDATA[
<div> 关键词：Klaster、Interchain Transaction (iTx)、Transaction Commitment Layer、Smart Accounts、Cross-chain transaction flow

总结:
Klaster是一个旨在解决区块链碎片化问题的协议，通过引入网络节点（Klaster Nodes）作为用户和链之间的中介。核心概念包括iTx（跨链交易捆绑），它是一系列可能相互依赖的交易，跨越多个链。Klaster利用智能账户和ERC-4337 Entrypoint，通过经济激励建立可靠的节点网络，允许开发者构建链抽象应用，用户只需一次签名即可执行跨链事务。协议提供了一站式服务，简化复杂操作，如资产转移、交换等，提升了用户体验。Klaster正在测试阶段，未来将实现去中心化，增强网络可靠性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>We are witnessing an ever-growing list of new chains popping out, and attracting a high level of activity and transactions. Ethereum is also scaling nicely, and with the EIP-4844 it’s becoming increasingly cheaper to onboard as a user and start interacting with chains.</p>
<p>This introduces fragmentation, which in our opinion is here to stay especially in a world where there will be hundreds of chains, users will demand fragmentation to be solved for. If we build solutions that kind of aggregate different assets in some sort of “centralized” service only to make all chains look like one and make it easy to move across chains, then we haven’t accomplished much.</p>
<p>We propose a solution which abstracts away chains and solves for fragmentation by introducing <strong>Klaster</strong> - a network of nodes placed between the users and chains. This layer wraps multiple blockchain networks and makes it easy for users to execute complex transaction flows spanning across one or more chains - all of that approved by the single off-chain signature.</p>
<p>By introducing the Klaster Nodes as a generic execution network, and defining how cross-chain transactions are being bundled and approved, we hope to set the standard for building chain abstracted applications. This goes beyond just a simple balance abstraction - spend your funds from one chain by interacting on another chain. It provides a “full” chain abstraction by allowing any arbitrary flow to be defined and executed.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-2" name="tldr-2"></a>TL;DR</h1>
<p>Klaster Protocol aims to position itself as a chain abstraction framework which allows dApps or Wallets to build complex cross-chain transaction bundles and let the users sign only once to execute these bundles across one or more blockchain networks.</p>
<p>We introduce two key concepts:</p>
<ul>
<li><strong>iTx bundles</strong>: series of (possibly dependent) transactions spanning across many chains</li>
<li><strong>Transaction Commitment Layer</strong>: network of nodes providing execution guarantees and offering orchestrated iTx execution across many blockchain networks</li>
</ul>
<p>Klaster Protocol leans on Smart Accounts and ERC-4337 EntryPoint and by introducing the economic incentives provides a reliable network of Klaster Nodes which anyone can use to build truly chain abstracted dApps while not sacrificing on the security, or taking the control from the user.</p>
<h1><a class="anchor" href="https://ethresear.ch#klaster-3" name="klaster-3"></a>Klaster</h1>
<p>Klaster provides an infrastructure for building chain abstracted apps. Klaster does this by introducing a network of Nodes, which act as a <strong>Transaction Commitment Layer</strong>. This layer is placed between the dApp and multiple blockchain networks, It talks to the outside world (users, dApps) via <strong>interchain transactions (iTx)</strong>.</p>
<p>Developers can use these primitives to:</p>
<ul>
<li>Build chain abstracted dApps (no switch network button)</li>
<li>Define complex flows involving multiple chains without having to think of the specifics of how the flow will get executed</li>
<li>Automate the execution of the dependent actions spanning across many chains</li>
<li>Onboard the users from different chains and ecosystems into their dApp with a single user signature</li>
</ul>
<p>Users on the other hand:</p>
<ul>
<li>Can interact with chain abstracted dApps using any wallet they prefer</li>
<li>Don’t have to care of where their funds are, the dApp will be able to spend their funds from other chains with a single user signature</li>
<li>Don’t have to “lock” their funds in order for the dApp to consume their funds</li>
<li>Can use any asset on any chain to pay for gas cost of the full iTx execution involving many transactions on different chains</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#core-concepts-4" name="core-concepts-4"></a>Core concepts</h2>
<p>At its core, Klaster leans on its unique approach of <strong>separating transaction signing from<br />
the transaction execution</strong>.</p>
<p>If we think about how the EOA is executing a transaction on an EVM - it’s all bundled in the same operation - sign &amp; execute happening simultaneously with the user having one EOA wallet popup and interacting with the chain/RPC.</p>
<p>A more advanced approach can be seen with the Account Abstraction (ERC-4337), where users can approve their UserOp and then hand it over to the Bundler for execution. This approach is still bounded to one single chain - the one where the user’s smart account is deployed.</p>
<p>Klaster Model breaks the boundaries of a single chain, and allows an account owner to approve a complex series of (possibly dependent) UserOps targeting different blockchain networks - with a single off-chain signature! This signature is then provided to the Klaster Node (what would be a bundler in AA), for orchestrating an execution across all the different chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/5/755b51c20b470de874fc70cf3589d99577681458.jpeg" title="photo_2024-06-26_14-25-17"><img alt="photo_2024-06-26_14-25-17" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/7/5/755b51c20b470de874fc70cf3589d99577681458_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>As seen from the illustration above, if the user wanted to bridge funds and then swap on the destination chain, they would usually execute two transactions, on two different applications (Bridge app &amp; then DEX app), while also having to pay for gas fees on two different chains.</p>
<p>By splitting the signature from the execution, Klaster is able to convert two actions into one <strong>iTx bundle</strong> and then execute them through the Klaster Node. Klaster node will figure out the ordering of transactions, and execute them as user intended, while also covering for execution fees.</p>
<h2><a class="anchor" href="https://ethresear.ch#interchain-transaction-itx-bundle-5" name="interchain-transaction-itx-bundle-5"></a>Interchain Transaction (iTx bundle)</h2>
<p><strong>Interchain Transaction (iTx)</strong> is the fundamental working unit used within the Klaster protocol. It’s a bundle of one or more blockchain transactions spanning across one or more blockchain networks. It fully describes what the user or the dApp is trying to achieve. One iTx, consisting of two transactions, might be: “bridge assets from chain A using some 3rd party bridge to chain B, and then swap bridged assets for something else on chain B”.</p>
<p>From the Klaster Protocol perspective, one iTx bundle is actually a Merkle Tree of all the UserOps as leaves, and is defined by its Merkle Root hash (iTx hash): <strong>one iTx bundle = one unique iTx hash</strong>.</p>
<p>Any on-chain interaction on any blockchain network can be converted to the UserOp and placed as a part of a bigger iTx Merkle Tree - meaning the iTx tree approach can be used to basically define any complex operation spanning across multiple blockchain networks provided that there’s at least some liquidity services connecting the chains.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/a/2a26e4bc6a55b451b319a567816c3f9fd11c8b5a.jpeg" title="photo_2024-06-26_14-27-23"><img alt="photo_2024-06-26_14-27-23" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/2/a/2a26e4bc6a55b451b319a567816c3f9fd11c8b5a_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>Transaction Commitment Layer takes unsigned iTx requests, and <strong>commits</strong> to execute them in the specific time frame - and therefore provides a reliable execution layer capable of executing the parts of the iTx on different blockchain networks. This involves strategically determining the optimal order for executing the individual transactions within the bundle. For instance, if a transaction on Polygon relies on assets being transferred from Ethereum first, the node will ensure that the Ethereum transfer is finalized before proceeding with the Polygon transaction.</p>
<h2><a class="anchor" href="https://ethresear.ch#high-level-protocol-overview-6" name="high-level-protocol-overview-6"></a>High Level Protocol Overview</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/4/44e74558671473aa21b67bb54151e8dea1ce9070.jpeg" title="photo_2024-06-26_14-28-18"><img alt="photo_2024-06-26_14-28-18" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/4/4/44e74558671473aa21b67bb54151e8dea1ce9070_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>The following steps are involved for the user/dApp to interact with the Klaster Protocol:</p>
<ol>
<li>dApp defines a list of operations to be executed across one or many chains and bundle them together into the iTx</li>
<li>dApp asks the Klaster Network for a quote (fee) for executing an iTx</li>
<li>dApp receives back the iTx with included fee amount and cryptographic execution guarantees given by the Klaster Network</li>
<li>User signs the iTx by signing its root iTx hash and then broadcasts the signed iTx back to the Klaster Network</li>
</ol>
<p>Once the Klaster Network receives the signed iTx, it will charge the user upfront by pulling the fee amount as defined in the quote, and it will start processing the transactions from the iTx bundle, executing them on the different blockchain networks in the correct order. The specifics of how the fee is being calculated and charged upfront is outlined in the technical breakdown section.</p>
<h2><a class="anchor" href="https://ethresear.ch#chain-abstraction-vs-balance-abstraction-aave-example-7" name="chain-abstraction-vs-balance-abstraction-aave-example-7"></a>Chain Abstraction vs Balance Abstraction (AAVE example)</h2>
<p>While balance abstraction is a great step forward in solving for liquidity fragmentation, it’s not covering all bases. Let’s say we want to build a chain abstracted version of AAVE, where users can interact with the dApp not only by having the “balance” abstracted away (supply assets from one chain to AAVE deployed on another chain), but also having an <strong>AAVE “position” abstracted</strong> away which is a more dApp specific use-case.</p>
<p>For example, a user might have 100 USDC supplied on AAVE on Optimism, but they want to switch the position to Base, and supply USDC there, because of better rates. Or there’s a bot that wants to do this periodically, in the user’s name and with the user’s approval.</p>
<p>Right now, the user would have to unwind their position, find a bridge to use, move liquidity to Base and then resupply the USDC. This involves signing multiple transactions and switching between multiple frontends and blockchain networks / RPCs, not to mention also having some gas dust on these chains to be able to execute transactions in the first place. We believe this is unsustainable and there has to be a way of “standardizing” these interactions &amp; making life easier on the user facing side.</p>
<p>By using Klaster protocol, this complicated “position” rebalancing operation can be converted to one simple iTx bundle containing three UserOps:</p>
<ul>
<li>[<em>Optimism</em>] UserOp1: unwinds AAVE USDC position on Optimism</li>
<li>[<em>Optimism</em>] UserOp2: bridges 100 USDC to Base using some third party bridge (across bridge, for example)</li>
<li>[<em>Base</em>] UserOp3: supplies 100 USDC on AAVE</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/a/aaccd85ed18ac9bacdc8cfe3806eb872019b0363.jpeg" title="photo_2024-06-26_14-35-03"><img alt="photo_2024-06-26_14-35-03" height="390" src="https://ethresear.ch/uploads/default/optimized/3X/a/a/aaccd85ed18ac9bacdc8cfe3806eb872019b0363_2_690x390.jpeg" width="690" /></a></div><p></p>
<p>The only thing the user would have to do from their side is provide one signature for the iTx and the balance reposition would be handled by the Klaster Protocol automatically. No gas required on the destination chain. No different apps involved. One simple signature. And we bet that if the developers are provided with tools like Klaster, many more other interesting use-cases might emerge other than the one we’re describing here.</p>
<h1><a class="anchor" href="https://ethresear.ch#technical-breakdown-i-want-to-know-more-8" name="technical-breakdown-i-want-to-know-more-8"></a>Technical Breakdown (I want to know more)</h1>
<h2><a class="anchor" href="https://ethresear.ch#smart-accounts-itx-module-9" name="smart-accounts-itx-module-9"></a>Smart Accounts - iTx Module</h2>
<p>Using an iTx bundle in combination with Smart Contract Accounts allows for one very powerful feature to be implemented - and is there to help on the UX side: <strong>single signature iTx approvals</strong>.</p>
<p>Smart Account modular architecture allows for building a standardized ERC-7579 module which “understands” iTx bundles and can be installed on top of existing smart account wallets or used to initialize new wallets as the UserOp model allows for providing the wallet initialization data as a UserOp parameter.</p>
<p>A smart account owner can approve the whole iTx bundle of many chain transactions by only <strong>signing once</strong> - one off-chain signature of the iTx Merkle Root hash can be used to approve for executing all the transactions across many chains.</p>
<p>As mentioned earlier, the tree is defined by its Merkle root hash - iTx hash. The smart contract owner signs the iTx hash with a signer. This typically is an EOA which is a common owner of all the smart accounts across different chains where the assets are being bridged and consumed, and by providing one signature, all of these operations are immediately executable.</p>
<p>If the user doesn’t have a smart contract account on one or more blockchain networks - the accounts can be “lazy deployed” for the user - meaning, the iTx bundle can contain an operation which bridges some amount of funds to the “not yet created” account as the address of the smart account can be precomputed.</p>
<p>By having the iTx validation module as a standardized module - Klaster protocol remains neutral &amp; unopiniated - it can work with different smart account providers.</p>
<h2><a class="anchor" href="https://ethresear.ch#klaster-fees-node-selection-10" name="klaster-fees-node-selection-10"></a>Klaster Fees &amp; Node Selection</h2>
<p>The Klaster Transaction Commitment Layer consists of many Klaster Nodes - all of them being equal. Every Node is defined by its wallet address, and in order for nodes to join the network, they have to stake capital - this is how the nodes provide uptime &amp; execution guarantees.</p>
<p>Klaster Nodes are taking care of the following:</p>
<ol>
<li>Estimating iTx fees &amp; responding to quote requests</li>
<li>Committing to iTx execution (or rejecting the request)</li>
<li>Executing fully signed iTx (if previously committed to execution)</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#estimating-itx-fees-responding-to-quote-requests-11" name="estimating-itx-fees-responding-to-quote-requests-11"></a>Estimating iTx fees &amp; responding to quote requests</h3>
<p>When the user or the dApp asks the protocol for quotes, every node will estimate the total cost of executing the iTx on different chains. The node adds its own fee on top of the total cost, including the <strong>success execution tip</strong> (more on this in the “optimistic execution” chapter) and responds back with the full cost the user will have to pay in order for the node to do the job.</p>
<h3><a class="anchor" href="https://ethresear.ch#committing-to-itx-execution-or-rejecting-the-request-12" name="committing-to-itx-execution-or-rejecting-the-request-12"></a>Committing to iTx execution (or rejecting the request)</h3>
<p>The user or the dApp chooses the best received quote by taking into account the total execution cost offered by each of the nodes, and their reputation. The dApp then connects directly with the selected node, and asks for a commitment - a guarantee from the node that they are going to execute the iTx in full, provided that the user pays for what the node asks for.</p>
<p>The node commits to the iTx execution by</p>
<ol>
<li>Prepending the payment tx* in the list of the transactions in the iTx bundle</li>
<li>Signing the root iTx hash with its own private key - essentially binding itself to the execution of the iTx</li>
</ol>
<p>*<em>A payment transaction generated and prepended by the node transfers some liquid asset from the user’s account to the node wallet address. The asset is selected by the user and the amount is calculated by the node to cover for all the execution costs + the node fee. This means that the user can pay for the execution on any chain and in any asset supported by the node.</em></p>
<h3><a class="anchor" href="https://ethresear.ch#executing-fully-signed-itx-if-previously-committed-to-execution-13" name="executing-fully-signed-itx-if-previously-committed-to-execution-13"></a>Executing fully signed iTx (if previously committed to execution)</h3>
<p>Once the dApp receives the iTx which includes the payment transaction and the node commitment, the user is finally prompted to approve the full iTx bundle by signing the root iTx hash - essentially approving the execution of all the transactions contained in the bundle. The iTx bundle, whose root iTx hash has been signed by both the node (commitment) &amp; user (execution approval) is sent to back the selected node which:</p>
<ol>
<li>Verifies the iTx bundle integrity (calculates &amp; verifies merkle root)</li>
<li>Verifies the commitment signature (make sure the node really did commit to this iTx)</li>
<li>Verifies the user signature</li>
<li>Collects the payment from the user (the first transaction in the iTx bundle)</li>
<li>Once the payment is complete, proceeds to execute the rest of the operations by performing the optimistic execution algorithm</li>
</ol>
<p>If the node fails to execute the iTx bundle, the user can use the node commitment (node iTx signature) to initiate a slashing request and prove on-chain that the node actually promised to execute the iTx but failed to do so in a given timeframe.</p>
<h2><a class="anchor" href="https://ethresear.ch#meta-paymaster-and-multichain-gas-refunds-14" name="meta-paymaster-and-multichain-gas-refunds-14"></a>Meta Paymaster and Multichain Gas Refunds</h2>
<p>For the node to be fully operational, they have to own the native coin balance on their wallet address for every chain they support - in order to be able to pay for gas and execute UserOps as a part of iTx bundle. By accepting the upfront payment from the user in one token and one chain, and then executing the transactions and subsidizing gas on one or more chains, Klaster Node acts in a way as a Meta Paymaster.</p>
<p>The node executes UserOps contained in the iTx by routing them through the official ERC-4337 EntryPoint on different chains, and after receiving post-operation execution callbacks with the actual gas consumption data, the node will execute refunds for every processed UserOp, that is if actual UserOp cost (including the Klaster Node fee) was less than the maximum UserOp that was prepaid by the user. The process is illustrated below:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/c/9ca11c122eee71670ddf3e95a2ecee88cf427bcb.png" title="klaster-meta-paymaster-latest"><img alt="klaster-meta-paymaster-latest" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/c/9ca11c122eee71670ddf3e95a2ecee88cf427bcb_2_569x500.png" width="569" /></a></div><p></p>
<p>By relying on the official ERC-4337 EntryPoint for UserOp routing, the Klaster Protocol is staying compliant with the AA space, since most of the AA wallets today choose to trust and give control to one EntryPoint contract. Any existing AA wallet could technically activate the Klaster iTx module and gain cross-chain capabilities.</p>
<h2><a class="anchor" href="https://ethresear.ch#optimistic-itx-execution-15" name="optimistic-itx-execution-15"></a>Optimistic iTx Execution</h2>
<p>Klaster Node is incentivized to execute UserOps from a given iTx bundle in the right order of events, without the user having to explicitly provide the order of events.</p>
<p>The right order of events is implicitly deduced by the Klaster Node, by repeatedly simulating every UserOp, between the timestamp deadlines set by the user when defining UserOp, and waiting for the simulation to yield 0 <em>REVERT</em> opcodes in the simulated execution breakdown. Once this happens, Klaster Node “knows” all the preconditions have been met (whatever they may be) and will proceed to execute the UserOp as this maxmizes the profits for the Klaster Node.</p>
<p>In our AAVE example from above, Klaster Node will wait for the bridge action to complete without having to be aware of which bridge is being used and what the estimated bridge time to destination might be. It’s not even aware of the context of any UserOp or the potential dependencies between those. The execution flow would look like this:</p>
<ol start="0">
<li>
<p>The Node executes the Payment UserOp (at index 0 in the list of UserOps). That way the Node charges for the full execution of all the other UserOps upfront and can proceed with the next steps</p>
</li>
<li>
<p>The Node “sees” that out of three UserOps (<strong>unwind, bridge, supply</strong>), the only one with 0 REVERTs is the <strong>unwind</strong> operation, and it proceeds to execute the UserOp successfully (on Optimism)</p>
</li>
<li>
<p>Afterward, another operation that yields 0 REVERTs is the bridge operation as the funds are now there to be bridged (unwinded position), so it proceeds to execute <strong>bridge</strong> action (on Optimism)</p>
</li>
<li>
<p>Finally, once the funds arrive at the user’s dest chain smart account (whenever that may be, depending on the 3rd party bridge being used), the <strong>supply</strong> operation is executed which marks the full iTx execution as complete.</p>
</li>
</ol>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/b/bb781b0246065508b7a832ee5060408e61d20a87.jpeg" title="photo_2024-06-26_14-45-59"><img alt="photo_2024-06-26_14-45-59" height="388" src="https://ethresear.ch/uploads/default/optimized/3X/b/b/bb781b0246065508b7a832ee5060408e61d20a87_2_690x388.jpeg" width="690" /></a></div><p></p>
<p>By having this generic approach of not being aware of the context, iTx bundles can express pretty much any complex cross-chain flow. To incentivize the node to wait for the simulation success (0 REVERTs), but then also to execute the UserOp <strong>as soon as 0 REVERT is detected,</strong> Klaster fee will include the <strong>diminishing success tip</strong>. This fee can be collected by the Node only if the UserOp was executed with 0 REVERT status and the tip is fading to 0 as the UserOp execution moment is closing to the upper bound execution timestamp.</p>
<p><em>It is still possible for some of the UserOps to fail, for example, 3rd party bridge not working properly. In that case - the node has fulfilled its obligation, as it’s recorded on-chain that the node “attempted” to execute the UserOp, although the funds haven’t reached the destination chain. In that case, the node is protected from slashing, while the user experienced a partially executed iTx. The funds are still owned by the user, and have remained on their wallet on one of the chains where the UserOp failed.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#integration-16" name="integration-16"></a>Integration</h1>
<p>dApp/Wallet developers will soon have access to the SDK, which in turn will allow for building chain abstracted applications much more efficiently, while staying neutral and not locking the developer to having to use any specific technology.</p>
<p>The developers are free to use any bridges or 3rd party services as a part of the iTx bundle - depending on the level of security/speed they require, and to rely on different AA wallet providers as the smart account wallets used behind the scenes.</p>
<p>On the user side, they have to sign once, and see their cross-chain intent being executed step by step without having to do any other action or even own gas funds on any of the chains they interact with.</p>
<p>This is how we see it developed further and how dApps might integrate the SDK in order to provide cross-chain experience to the end user:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65e8e1fa54439727f6d9a820b1d86e740f228025.jpeg" title="photo_2024-06-18_13-18-43"><img alt="photo_2024-06-18_13-18-43" height="315" src="https://ethresear.ch/uploads/default/optimized/3X/6/5/65e8e1fa54439727f6d9a820b1d86e740f228025_2_690x315.jpeg" width="690" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#demo-use-cases-17" name="demo-use-cases-17"></a>Demo &amp; Use Cases</h1>
<p>At the moment, we’re building a chain abstracted AAVE dApp - to showcase what the protocol can do in terms of UX improvements.</p>
<p>The frontend will only contain two buttons: “supply” &amp; “borrow” without specifying the chains. When executing borrow or supply, user’s funds will be routed to any chain where the AAVE market’s rates are most favorable, regardless of the fact which chain the user’s funds are on.</p>
<p>If the user wants to rebalance the existing position, again, it’s a one-click interaction for the user, but in the background, iTx is being executed by the Klaster Nodes.</p>
<p>Some other interesting use cases:</p>
<ul>
<li>streamlined checkout flows</li>
<li>easier onboarding to the SocialFi L2/L3 apps, as Klaster protocol works with AA by default, and many of these apps choose to have embedded wallets generated for the users behind the scenes</li>
<li>building chain abstracted flavors of dapps that are natively multichain (DEXs, lending markets, NFT marketplaces)</li>
<li>single-chain dApps can use the Klaster Stack to streamline onboarding flows, attracting users from various chains. With Klaster Stack, users can interact with the dApp in just one click, regardless of their original blockchain</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#faq-18" name="faq-18"></a>FAQ</h1>
<p><strong>Q: Is Klaster a Blockchain Network?</strong><br />
A: No.</p>
<p><strong>Q: What’s the current development status?</strong></p>
<p>A: Centralized Klaster Node including the SDK and the docs is in the testing phase and will be launched very soon. The decentralization phase including the slashing and multichain staking which in turn makes the network more reliable will most likely be rolled out later this year.</p>
<p><strong>Q: What are the dangers of using Klaster Protocol?</strong></p>
<p>A: Dangers are mostly related to the impaired UX.</p>
<p>For example, malicous Klaster Node can refuse to process an iTx bundle in full - they only execute the Payment UserOp part of the iTx bundle. The user can still replay their UserOps manually and achieve the same effect but will have to pay for gas execution themselves. Nodes on the other hand get slashed in the decentralized model because the user can submit a proof of Node commiting to execute the iTx but failing to do so in a given timeframe - which is fully verifiable on-chain. As the AA wallets are used behind the scenes, the user is in full control of their funds, and the security is reduced to security of bridges used as an intermediary steps to move assets between chains. Klaster’s iTx-enabled AA wallet module is pending audits and the reports will be shared soon.</p>
<p><strong>Q: Can I run my own node, and what are the advantages of running a node?</strong></p>
<p>A: Klaster Protocol will host its own public node, with the implementation publicly available for everyone to take a look and verify the inner workings of the Node itself. While the initial version of the protocol is not decentralized in a sense of having a p2p networking implemented between public Klaster nodes, anyone can still choose to run their own Klaster Node either for their own purposes (only handling one single dApp) or even providing this node for others to connect to.</p>
<p>New chains can spin up their own Klaster node to easily onboard users from other chains.</p>
<p>Klaster Node if operational earns a % of the total gas processed and is another revenue stream for Node operators. To set up a node, one needs to have a wallet connected to the node, and funded with native coin on every chain which the Node operator decides to support.</p>
<p><strong>Q: How does Klaster compare to other chain abstraction solutions?</strong></p>
<p>A: For a start, we think we have a unique approach here in being highly focused on the UX part. We’re trying to stay as generic and as neutral as possible, and we’ve developed something that can be used today to fix the UX in some ways. Comparing to some other approaches we see being built in this space, Klaster’s main difference is that Klaster doesn’t work with liquidity nor does it require the Node operators to provide liquidity - meaning it’s easier to run the network and gain an initial base of Node operators. It doesn’t try to be “one solution fits all” which hides away blockchains completely, but rather a framework where, given the fact that the cross-chain action details are known upfront - it enables developers to easily define and build the action, and for the user to sign once and see the effects happening on different chains.</p>
<p><strong>Q: Where does Klaster Protocol fit in the CAKE framework?</strong></p>
<p>A: According to the CAKE Layer definitions, we’d say Klaster comes somewhere in the Settlement Layer (Execution part).</p>
<p><strong>Q: Is Klaster Protocol a bridge?</strong></p>
<p>A: Not really. Klaster Protocol can <em>wrap</em> bridges and other services to create a true cross-chain experience by having bridge action only there as a one step of the more comple iTx interaction.</p>
<p><strong>Q: I want to know more about the slashing process. Why do the Nodes have to stake capital, and how does slashing work?</strong></p>
<p>A: Klaster Nodes have to execute iTx bundles if they previously “promised” to the user they will do so. There has to be a way of punishing the Node for not doing their job - or even worse, collecting the fee payment from the user but never executing their desired intent. To make this possible, Klaster Nodes have to stake capital in order to be accepted by the network and allowed to execute iTx bundles on user’s behalf.</p>
<p>Every UserOp contains lower and upper bound timestamps, and the interval between these are when the UserOp is considered valid and can be executed on-chain. When the Node builds a full iTx tree, and signs the root iTx hash with their private key - we say the Node is “commited” to the iTx. The user has received the full quote including the Node commitment, and can use this commitment to initiate a slashing procedure if the nonce of the user’s smart account was not increased by one in the given timeframe, on any chain where their UserOp was <strong>not executed</strong>.</p>
<p><strong>Q: Is Klaster Protocol actually an Intent Solver network?</strong></p>
<p>A: Not really. Intents mean the user describes the end-result state and <em>someone somehow</em> finds the solution to the steps (txs) required to achieve the desired outcome. Klaster takes a completely opposite approach. The design space of the intent solvers is just too big and solving for all cases using intents is simply too complicated. We say - let’s make the system more exact, in a sense that, we assume that the developers of either dApps or wallets will always know upfront what exactly they want to achieve - and then let’s give them tools and means of how to express this interaction (iTx bundle) while making it easy for users to approve and execute these iTx bundles.</p>
<p>Klaster Protocol though is a great tool for Intent Solvers to express &amp; execute their “paths of execution” once they solve for some specific user’s request.</p>
<p><strong>Q: What’s the role of AA Wallets in the Klaster Protocol?</strong></p>
<p>A: AA Wallet is the only viable option for Klaster Protocol to work. Since we need to be able to have the user authorize many actions with only one signature - the only possibility for this to work is to actually use programmable smart contract wallets.</p>
<p><strong>Q: How is the Node protected from users? How are the users protected from the Node?</strong></p>
<p>A: The Node charges for its service fee plus all the other execution gas costs upfront. This way, the node might overcharge for the gas spendings, but the user will still get charged fairly if the actual gas spent was lower than what the node calculated. The Node will not commit to execute the iTx if the iTx looks risky - too short timespans for the UserOp execution, or the UserOp execution window which starts far away in the future (gas price spike risks).</p>
<p>The user is protected from the Node by being the only owner of the AA Wallet which used to execute iTx steps. Even if the Klaster Network dies completely, the user can still access and manage funds. The Klaster Node can only do what the user explicitly signs &amp; approves.</p>
<p><strong>Q: Does the user need to own the funds on the AA Wallet to interact with the Klaster Protocol in the first place?</strong></p>
<p>A: Unfortunately yes. If the user’s coming with an EOA wallet and assets are held by this EOA, the user will have to execute at least one EOA transaction and move funds from this wallet to an iTx enabled AA wallet to be able to use Klaster for chain abstraction / gas abstraction purposes. Luckily, the EIP-7702 which is confirmed will improve this flow substantially.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/presenting-klaster-rethinking-chain-abstraction/19910">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 13:13:35 +0000</pubDate>
</item>
<item>
<title>Pricing Gas Fee Derivatives</title>
<link>https://ethresear.ch/t/pricing-gas-fee-derivatives/19898</link>
<guid>https://ethresear.ch/t/pricing-gas-fee-derivatives/19898</guid>
<content:encoded><![CDATA[
<p><em>Thanks to Nethermind, <a class="mention" href="https://ethresear.ch/u/tkstanczak">@tkstanczak</a>, <a class="mention" href="https://ethresear.ch/u/swapnilraj">@swapnilraj</a> , <a class="mention" href="https://ethresear.ch/u/dapplion">@dapplion</a>, Martin Koppelmann and <a class="mention" href="https://ethresear.ch/u/drewvanderwerff">@DrewVanderWerff</a> for discussion, feedback and review.</em></p>
<p><strong>This is the first instalment in a series of posts where I will outline a methodology for understanding and pricing gas derivatives. The following approach for pricing will be valuable for gas hedging and can also be applied to develop a subscription model for Ethereum.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/0/2075264e1980cd984ec67a32af4bbe1689af4874.jpeg" title="There-Will-Be-Blood1-ezgif.com-webp-to-jpg-converter"><img alt="There-Will-Be-Blood1-ezgif.com-webp-to-jpg-converter" height="460" src="https://ethresear.ch/uploads/default/optimized/3X/2/0/2075264e1980cd984ec67a32af4bbe1689af4874_2_690x460.jpeg" width="690" /></a></div><p></p>
<p><em>There Will Be Blood” (2007) - are we going to be unwitting extras in the ‘digital oil’ sequel?</em></p>
<p><strong>TLDR:</strong> I show how a two-factor model can be used to price base fee options, of both European and American type. A developed gas derivatives market would be highly beneficial for participants looking to hedge against volatile operational expenses on gas or for those aiming to speculate on future gas fee trends.</p>
<p><strong>Why Price Base Fee Derivatives?</strong></p>
<p>Gas expenditure is a substantial portion of operational costs within blockchain ecosystems. Whether it involves L2 sequencers committing transactions to L1, the running of a DeFi protocols keeper, interacting with oracle contracts, rebalancing liquidity on platforms like Uniswap, verifying proofs, or conducting arbitrage, gas fees are an unpredictable expense. This inherent volatility poses challenges for financial planning and budgeting in blockchain operations. Gas hedging, analogous to its counterpart in traditional financial markets, provides a mechanism to manage and mitigate this uncertainty.</p>
<p>By purchasing gas derivatives, stakeholders can secure current gas fee levels for future transactions, effectively insuring against unforeseen spikes in gas prices. Additionally, with a strike price of zero on a call option, one can fully prepay for gas, paving the way for a ‘gas subscription’ model on Ethereum—assuming a delivery mechanism is established. This research could be particularly useful for pre-confirmations, where blockspace is purchased in advance.</p>
<p>The following post breaks down the importance of understanding base fees, examining their volatility, and proposing a detailed model for pricing base fee derivatives. The first section delves into the calculation of base fees, while the second outlines their structure. In the third section, a model incorporating both deterministic and stochastic components is detailed to simulate base fees using a Monte Carlo process. The fourth and final section explains how to use these Monte Carlo generated paths to price base fee options, including both European and American types. Use cases of this research include participants that want to examine the fair value of a base fee option, a task helpful for those interacting with derivative protocols like Oiler’s Pitch lake <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018" rel="noopener nofollow ugc">[1]</a>.</p>
<p>This post is the first in a series on the topic, aimed at sparking interest among both Ethereum researchers and traders. My goal is to engage quants in the conversation around Ethereum infrastructure.</p>
<p><strong>Understanding Base Fees</strong></p>
<p>Before pricing base fees, we should understand its constituent parts. EIP-1559, implemented in the London hard fork of Ethereum in August 2021, introduced a significant overhaul to the transaction fee mechanism on the Ethereum network. The proposal aimed to improve the predictability and efficiency of transaction fees, addressing several issues inherent in the previous auction-based system. Under EIP-1559, each block has a base fee, which is dynamically adjusted according to network congestion. When demand for block space increases, the base fee rises, and when demand decreases, the base fee falls. This mechanism helps to stabilize transaction fees and makes them more predictable for users.</p>
<p>The specific adjustment rule proposed in the EIP-1559 spec computes the base fee <span class="math">BF_{\text{cur}}</span> for the current block from the base fee <span class="math">BF_{\text{pred}}</span> and size <span class="math">s_{\text{pred}}</span> of the predecessor block using the following formula, where <span class="math">s_{\text{target}}</span> denotes the target block size:</p>
<div class="math">
BF_{\text{cur}} := BF_{\text{pred}} \cdot \left( 1 + \frac{1}{8} \cdot \frac{s_{\text{pred}} - s_{\text{target}}}{s_{\text{target}}} \right)

</div>
<p>In short, the next base fee is adjusted by a percentage that equals one-eighth of the difference to the target percentage - meaning base fees are within the bounds of 12.5% higher or lower than the previous block. As is visible below when comparing gas usage, full blocks of 30M are most frequent, with gas usage of just below 13M second most frequent.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/3/f3ef180d0b94b634c3727e72c56bcf12cb7ccbfa.png" title="Histogram"><img alt="Histogram" height="500" src="https://ethresear.ch/uploads/default/original/3X/f/3/f3ef180d0b94b634c3727e72c56bcf12cb7ccbfa.png" width="657" /></a></div><p></p>
<p><strong>Those Are Some Large Percentage Changes… Why Are Base Fees So Volatile?</strong></p>
<p>Several factors contribute to the high volatility of base fees, with the non-storability of base fees and the limited block-space supply being the most significant. Since block-space has a strict limit to 30M gas, which cannot be stored or transferred over time, supply in each time period is fixed, while demand can fluctuate based on usage needs. Base fees for transactions is thus demand inelastic. Consequently, during periods of low demand, the base fee remains relatively stable. However, during peak times, the relative insensitivity of demand to price changes can lead to significant volatility in short-term base fee prices—‘Jumps’. This situation is similar to the electricity market, where demand remains high regardless of price, causing extreme price volatility during peak usage. In the blockchain context, the necessity of paying the base fee to conduct transactions ensures somewhat steady demand, even as prices fluctuate dramatically.</p>
<p>Additionally, since base fees are influenced by the previous base fee, a block with high demand for blockspace—such as one resulting from the deployment of a large simultaneous smart-contract architecture—will primarily impact users in the following block. Users pay for blockspace based on the previous blocks usage, not the current one. Consequently, in the short term, a deployer will not always experience the negative externalities of increasing gas fees for near-future blockchain users. This creates a scenario where users are indifferent to increasing base fees by the cap of 12.5%. Current discussions, as well researched by SMG <a href="https://www.mechanism.org/spec/04" rel="noopener nofollow ugc">[2]</a>, suggest to minimise this externality, and subsequent short-term volatility by modifying the denominator to a higher value. The change would reduce sensitivity to randomness in gas usage and better align the process with underlying trends, improving stability and predictability.</p>
<p><strong>Characteristics of Base Fees</strong></p>
<p>Base fees can be simulated through understanding the structure of gas usage, before feeding the resulting parameters into the <span class="math">BF_{\text{cur}}</span> equation to find the base fees, or observing base fees themself. The model I propose focuses on the latter, as a result of my focus being on hourly averaged base fees for use in 1 day plus dated options, and a focus on gas usage would also mean accounting for variable gas limits. The model I am proposing is very flexible, and allow us to simultaneously include trends, seasonality, mean reversion, volatility and jumps.</p>
<p><strong>Overarching Trend</strong></p>
<p>Unlike electricity, wherein supply can vary, base fees relate directly to the demand side usage of a product, a blockchain. When a new EIP is passed as to change the structure of base fees, or if gas usage dramatically decreases. Unlike electricity, trends in gas usage are far shorter and dissimilar to one another, trends should thus be likened to regimes. For example, one regime may be a simple horizontal linear trend in periods of stable usage,  where another is an exponential trend downwards as a result of blobs being recently introduced.</p>
<p><strong>Seasonality</strong></p>
<p>Base Fee demand is heavily influenced by varying usage of economic and business activities of agents on the underlying blockchain. Different kinds of seasonality appear in the data; intra-daily and weekly. As it is usual in this type of research, I assume that seasonality is generated by deterministic factors and since I use the average hourly prices.</p>
<p><strong>Mean-reversion</strong></p>
<p>In the short term, during periods of high demand, base fees spike, discouraging excessive gas usage, which in turn reduces congestion and drives fees back down. Conversely, during low demand periods, lower fees encourage more transactions, increasing congestion and pushing fees back up. This cyclical nature of congestion creates a mean-reverting behaviour in base fees. Essentially, despite short-term fluctuations, base fees tend to stabilize around an average level, influenced by the balance of demand and network capacity.</p>
<p><strong>Jumps and volatility</strong></p>
<p>By simple eye inspection of base fees over time, there is clear existence of important jumps in the behaviour of base fees, as a result of sequential filling of blocks. One of the characteristics of evolution of these jumps is that the base fees do not stay in the new level, to which it jumps, but revert to the previous level rapidly. Such a behaviour can be captured by introducing a jump-diffusion component to a simulation model.</p>
<h2><a class="anchor" href="https://ethresear.ch#pricing-base-fees-1" name="pricing-base-fees-1"></a><strong>Pricing Base Fees</strong></h2>
<p>How should one price option premiums? Determining the appropriate pricing model for gas fees involves understanding their nature and selecting an appropriate financial framework. Gas fees could be treated as equities, interest rates, or commodities, each with distinct modelling approaches. Popular analytical models like the Black-Scholes closed-form model, often used for equities, offer theoretical insights into price movements and volatility - but in the case of base fees, the underlying assumption of normality in returns would be too naive, and the mean reversion and seasonality present in base fees wouldn’t be accounted for. Alternatively, numerical methods such as finite difference and Monte Carlo simulations would provide far more flexible and robust techniques for capturing the stochastic and path dependent nature of base fees. I therefore opt for the Monte Carlo simulation approach.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-specification-and-estimation-2" name="model-specification-and-estimation-2"></a><strong>Model Specification and Estimation</strong></h2>
<p><strong>Exponential Trend Examination</strong></p>
<p>I first assess the presence of an exponential trend by computing the weekly statistics of the mean and standard deviation. If the spot price series exhibits an exponential trend, then the means and standard deviations, computed over time periods, should be correlated with a statistically significant slope.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/f/ffd93a4891dbf0193c6c5b3a00494d51f2569a4a.jpeg" title="Figure_1"><img alt="Figure_1" height="449" src="https://ethresear.ch/uploads/default/optimized/3X/f/f/ffd93a4891dbf0193c6c5b3a00494d51f2569a4a_2_690x449.jpeg" width="690" /></a></div><p></p>
<p>Demonstrated by a p-value close to zero (4.43e-18), an exponential trend is evident in the data. When base fees are high, base fees are volatile. Consequently, to simplify modelling and work with linear trends, I from hereon out use the logarithm of the base fee.</p>
<h3><a class="anchor" href="https://ethresear.ch#deterministic-model-specification-3" name="deterministic-model-specification-3"></a><strong>Deterministic Model Specification</strong></h3>
<p>We have seen in the previous section that a reasonable model for base fee prices should allow for the existence of deterministic seasonality, the possibility of mean-reversion, seasonality jumps, and volatility (randomness). Therefore, I propose a model that simultaneously incorporates all these factors in a flexible way.</p>
<p>The combined long-term model can be written as the composite of a deterministic component <span class="math">f(t)</span> and a stochastic component <span class="math">X_t</span>:</p>
<div class="math">
\log(BF_t) = f(t) + X_t
</div>
<p><strong>Estimation of Deterministic Component</strong> <span class="math">f(t)</span></p>
<p>The deterministic component  <span class="math">f(t)</span> is given by the sum of piecewise regime-based quadratic polynomial trends and sinusoidal functions corresponding to different harmonics and periods:</p>
<div class="math">
f(t) = \sum_{i=1}^{m} \mathbb{I}{\{t \in R_i\}} \left( \gamma{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2 \right) + \beta_1 \sin\left(\frac{2\pi t}{24}\right) + \beta_2 \cos\left(\frac{2\pi t}{24}\right) \\
 + \beta_3 \sin\left(\frac{4\pi t}{24}\right) + \beta_4 \cos\left(\frac{4\pi t}{24}\right) + \beta_5 \sin\left(\frac{8\pi t}{24}\right) + \beta_6 \cos\left(\frac{8\pi t}{24}\right) \\
 + \beta_7 \sin\left(\frac{2\pi t}{168}\right) + \beta_8 \cos\left(\frac{2\pi t}{168}\right) + \beta_9 \sin\left(\frac{4\pi t}{168}\right) + \beta_{10} \cos\left(\frac{4\pi t}{168}\right) \\
 + \beta_{11} \sin\left(\frac{8\pi t}{168}\right) + \beta_{12} \cos\left(\frac{8\pi t}{168}\right) + \xi_t
</div>
<p>Where:</p>
<ul>
<li><span class="math">\log BF_t</span> is the logarithm of the base fees per gasat time (t).</li>
<li><span class="math">t</span> is the time in hours since the start of the sample.</li>
<li><span class="math">\beta_1</span> and <span class="math">\beta_2</span> are the coefficients for the fundamental daily seasonal components (1 day period).</li>
<li><span class="math">\beta_3</span> and <span class="math">\beta_4</span>  are the coefficients for the first harmonic daily seasonal components (1 day period).</li>
<li><span class="math">\beta_5</span> and <span class="math">\beta_6</span> are the coefficients for the second harmonic daily seasonal components (1 day period).</li>
<li><span class="math">\beta_7</span> and <span class="math">\beta_8</span> are the coefficients for the fundamental weekly seasonal components (7 day period).</li>
<li><span class="math">\beta_9</span> and <span class="math">\beta_{10}</span>  are the coefficients for the first harmonic weekly seasonal components (7 day period).</li>
<li><span class="math">\beta_{11}</span> and <span class="math">\beta_{12}</span> are the coefficients for the second harmonic weekly seasonal components (7 day period).</li>
<li><span class="math">\mathbb{I}_{\{t \in R_i\}}</span> is an indicator function that equals 1 if <span class="math">t</span> is within regime <span class="math">R_i</span> and 0 otherwise.</li>
<li><span class="math">\gamma_{i,0}</span>, <span class="math">\gamma_{i,1}</span>, and <span class="math">\gamma_{i,2}</span> are the coefficients for the piecewise polynomial trend within regime <span class="math">R_i</span>.</li>
<li><span class="math">\xi_t</span> is the error term.</li>
</ul>
<p>For each regime <span class="math">R_i</span>, I fit a quadratic model of the form:</p>
<div class="math">
z_i(t) = \gamma_{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2
</div>
<p>To discover the boundaries of each regime, I utilise binary segmentation for detection of change points within the time series. This technique employs a piecewise model, identifying changes based on the L2 norm (Euclidean distance). Initially, the algorithm treats the entire time series as a single segment, searching for a point that maximises the cost function by minimising the residual sum of squares. When a significant change point is identified, the segment is split, and the algorithm recursively continues this process until no further significant change points are found.</p>
<p>In our dataset of roughly two years, and discovered partially heuristically, I identify 16 change points, 17 regimes, with an initial regime immediately after EIP-1559’s release. This finding indicates that the underlying trend in base fees shifts approximately every half to two months. Such shifts are likely influenced by market events such as changes in market sentiment, or other critical factors, all of which could warrant their own focused research to fully understand their cause. I then discover the parameters <span class="math">\gamma_{i,0}</span>, <span class="math">\gamma_{i,1}</span>, <span class="math">\gamma_{i,2}</span> for each regime <span class="math">R_i</span>, using the least squares method. This involves minimising the sum of the squared differences between the observed values <span class="math">BF_t</span> and the predicted values <span class="math">z_i(t)</span> within each regime <span class="math">R_i</span>:</p>
<div class="math">
\min_{\gamma_{i,0}, \gamma_{i,1}, \gamma_{i,2}} \sum_{t \in R_i} \left( BF_t - (\gamma_{i,0} + \gamma_{i,1} t + \gamma_{i,2} t^2) \right)^2
</div>
<p>To solve this minimisation problem, I set up the following normal equations by taking partial derivatives with respect to each parameter and setting them to zero:</p>
<div class="math">
\frac{\partial}{\partial \hat{\gamma}_{i,0}} \sum{t \in R_i} \left( y_t - (\hat{\gamma_{i,0}} + \hat{\gamma}_{i,1}) + \hat{\gamma}_{i,2} t^2) \right)^2 = 0 \\
\frac{\partial}{\partial \hat{\gamma}_{i,1}} \sum_{t \in R_i} \left( y_t - (\hat{\gamma}_{i,0} + \hat{\gamma}_{i,1} t + \hat{\gamma}_{i,2} t^2) \right)^2 = 0 \\
\frac{\partial}{\partial \hat{\gamma}_{i,2}} \sum_{t \in R_i} \left( y_t - (\hat{\gamma}_{i,0} + \hat{\gamma}_{i,1} t + \hat{\gamma}_{i,2} t^2) \right)^2 = 0
</div>
<p>Solving these equations yields the least squares estimates for <span class="math">\hat{\gamma}_{i,0}</span><em>, <span class="math">\hat{\gamma}_{i,1}</span></em>, <span class="math">\hat{\gamma}_{i,2}</span>  for each regime <span class="math">R_i</span>. The below figure displays the resulting regimes and trend curves. The regression analysis has a low <span class="math">R^2</span> for the majority of regimes, indicating that the trends are well-fitted to the data. Notably, the current regime, characterised by the implementation of EIP-4844, differs markedly from the previous two regimes, as base fees dramatically decrease immediately after the fork, and are recovering upwards, likely due to the recent bull market activity. I eagerly ask for a discussion with respect to the underlying reasons for each trend.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/4935f9d2b9492a72761b825cbab25df5fc18342c.jpeg" title="Trends"><img alt="Trends" height="412" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/4935f9d2b9492a72761b825cbab25df5fc18342c_2_690x412.jpeg" width="690" /></a></div><p></p>
<p>To calibrate the seasonality components, I first analyse the seasonality present within the data. To do so, I performed a spectral analysis using the Fast Fourier Transform (FFT). The FFT decomposes the time-domain signal into its constituent frequencies, allowing us to compute the power spectrum, which represents the signal’s power distribution across different frequencies. I focused on the positive half of the spectrum and converted frequencies to periods in hours. Significant periodic components were identified by locating peaks in the power spectrum. The identified cycles, with the most prominent displaying daily (24 hours) and weekly (168 hours) seasonality, reinforcing the sinusoidal functions specified above. I visualise the results below to highlight the dominant seasonal patterns in the data.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/c/fc3302537e3548a88afc036869c60322fd6efed6.png" title="Period"><img alt="Period" height="413" src="https://ethresear.ch/uploads/default/original/3X/f/c/fc3302537e3548a88afc036869c60322fd6efed6.png" width="690" /></a></div><p></p>
<p>In estimating the <span class="math">\beta</span> parameters, I also use a least squares optimisation method. Given the observed log base fees <span class="math">BF</span> and the seasonality matrix <span class="math">C</span>, the objective is to estimate the seasonality parameters <span class="math">\beta</span> that minimise the sum of squared residuals. This is formulated as:</p>
<div class="math">
\min_{\beta} \| log(BF)_{detrended} - C \beta \|^2

</div>
<p>where:</p>
<ul>
<li><span class="math">log(BF)_{detrended}</span>  is the vector of de-trended log base fees,</li>
<li><span class="math">C</span>  is the matrix containing the seasonality functions (sine, cosine),</li>
<li><span class="math">\beta</span>  is the vector of seasonality parameters to be estimated.</li>
</ul>
<p>The expanded form of the objective function is:</p>
<div class="math">
\min_{\beta} \sum_{I=1}^{n} (log(BF_i)_{detrended} - C_i \beta)^2
</div>
<p>where  <span class="math">log(BF_i)_{detrended}</span> is the <span class="math">i</span> -th observed log base fee and <span class="math">C_i</span>  is the  <span class="math">i</span>-th row of the seasonality matrix. To find the least squares solution, I set the gradient of the objective function with respect to <span class="math">\beta</span> to zero, yielding the normal equations:</p>
<div class="math">
\frac{\partial}{\partial \beta} \left( \sum_{i=1}^{n} (log(BF_i)_{detrended} - C_i \beta)^2 \right) = -2 C^T (log(BF_i)_{detrended} - C \hat{\beta}) = 0
</div>
<p>Simplifying, I obtain:</p>
<div class="math">
C^T C \hat{\beta} = C^T log(BF)_{detrended}
</div>
<p>Solving the normal equations for  \beta  provides the least squares estimates:</p>
<div class="math">
\hat{\beta} = (C^T C)^{-1} C^T log(BF)_{detrended}
</div>
<p>where  <span class="math">(C^T C)^{-1} C^T</span>  is the Moore-Penrose pseudoinverse of <span class="math">C</span>. The de-seasonalized and de-trended log prices are then calculated by subtracting the combined seasonality components from the observed log prices, as is shown in the figure below.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f324d5ecfcda3c65cc3aebdbfbd09ac4e6bf621.png" title="Seasoned"><img alt="Seasoned" height="459" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f324d5ecfcda3c65cc3aebdbfbd09ac4e6bf621_2_690x459.png" width="690" /></a></div><p></p>
<p>Visibly, base fees in the Ethereum network fluctuate due to weekly and daily patterns of usage. During the week, gas usage is typically higher as business activities, market trading, and development deployments peaks. This weekly seasonality contrasts with daily patterns where peak periods of gas usage occur in the morning and evening as global participants, including Europe and North America, overlap in activity.</p>
<p>Despite removing trend and overarching seasonality, I observe that autocorrelative structure is still present in our time series. To address this, I explore the autocorrelation function (ACF) and the partial autocorrelation function (PACF) of the data. The ACF helps identify the correlation between observations at different lags of base fees, providing insights into the persistence of shocks over time. The PACF isolates the direct effect of a lagged observation by controlling for the contributions of intermediate lags, aiding in the identification of the order of the autoregressive (AR) terms in an ARIMA model. By observing the graph below, we observe 34 autocorrelated lags, and 5 partially autocorrelated lags.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/1/519bf7d93d2812acc39ec47dc5879a39ec44dca8.png" title="Autocorrelation"><img alt="Autocorrelation" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/1/519bf7d93d2812acc39ec47dc5879a39ec44dca8_2_532x500.png" width="532" /></a></div><p></p>
<p>To address these lags, I fit an ARIMA(34, 5, 5) model to the de-seasonalized and de-trended data. This model captures the autoregressive and moving average components along with differencing. By fitting this model, we obtain the residuals, which represent the underlying structure of the noise after accounting for these components. Upon examining the residuals, we find that the distribution of the noise is sharply centered around zero with fat tails. The transition between the central peak and the tails appears to follow an exponential pattern. Consequently, we fit a Laplace distribution to the residuals and compare the observed values against the expected values, where the Laplace distribution is defined as:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/520b0b7803ad250ea93fc680b158f762eb2571b0.png" title="StandardisedResidules"><img alt="StandardisedResidules" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/520b0b7803ad250ea93fc680b158f762eb2571b0_2_673x500.png" width="673" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/5/65238658d70c03f7293ed41bb385d7eb95d65c7d.png" title="PDF"><img alt="PDF" height="499" src="https://ethresear.ch/uploads/default/original/3X/6/5/65238658d70c03f7293ed41bb385d7eb95d65c7d.png" width="690" /></a></div><p></p>
<div class="math">
f(x; \mu, b, \kappa) =
\begin{cases}
\frac{\kappa}{b} \exp \left( \frac{x - \mu}{b} \kappa \right), &amp; \text{if } x \leq \mu \\
\frac{1}{b \kappa} \exp \left( -\frac{x - \mu}{b \kappa} \right), &amp; \text{if } x &gt; \mu
\end{cases}
</div>
<ul>
<li><span class="math">\mu</span>  is the location parameter (mean),</li>
<li><span class="math">b &gt; 0</span>  is the scale parameter,</li>
<li><span class="math">\kappa &gt; 0</span>  controls the asymmetry of the distribution. a Kappa equal to 1 produces a symmetrical Laplace distribution.</li>
</ul>
<p>A Laplace distribution is significant because it characterises the distribution as having exponential decay on both sides of the peak. In the context of Ethereum base fees, changes often occur as a percentage of the previous base fee rather than by fixed amounts. This implies that large deviations from the mean are more probable than would be expected under a normal distribution, leading to the characteristic heavy tails of the Laplace distribution. The sharp central peak of the Laplace distribution indicates a high probability of small changes around the long term mean. The fat tails, on the other hand, reflect the occasional large percentage changes, driven by significant network, a series of full block events or structural shifts in demand for block space. One would expect a higher denominator parameter (reducing sensitivity of base fees to gas usage) to create a ‘tighter’ distribution with a lower standard deviation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/8359c539f8d3aae5ec27461b63895a852255410e.png" title="QQ"><img alt="QQ" height="482" src="https://ethresear.ch/uploads/default/original/3X/8/3/8359c539f8d3aae5ec27461b63895a852255410e.png" width="690" /></a></div><p></p>
<p>I plot the theoretical quantiles of the Laplace distribution against the observed residual quantiles in a QQ plot. The plot revealed that a few outlier observations exhibited fatter tails than predicted by the Laplace distribution, indicating that the residuals have more extreme values than our model accounts for. Nevertheless, the majority of the data points followed the expected distribution, suggesting that the Laplace distribution still provides a reasonable fit for the central portion of the residuals.</p>
<p><strong>Stochastic Component Specification</strong></p>
<div class="math">
X_t = \log BF_t - f(t)
</div>
<p><strong>Cox, Ingersoll &amp; Ross Poisson Asymmetrical Laplace calibrated model</strong></p>
<p>Removing the trend and observing the noise, the stochastic component <span class="math">X_t</span>  is modelled as an Ornstein-Uhlenbeck process (mean-reverting) with jumps, incorporating a Laplace distribution for both the noise term and the jump size</p>
<div class="math">
dX_t = (\alpha - \kappa X_t) \, dt + \sigma \, dL_t + J(\mu_J, \sigma_J) \, d\Pi(\lambda),
</div>
<p>where:</p>
<ul>
<li><span class="math">α</span> is the drift parameter,</li>
<li><span class="math">κ</span>  is the rate of mean reversion,</li>
<li><span class="math">σ</span> is the volatility,</li>
<li><span class="math">L_t</span> is a noise term following a Laplace distribution,</li>
<li><span class="math">J(μ_J , σ_J )</span> is the jump size, following a Laplace distribution with mean  <span class="math">μ_J</span> and scale parameter <span class="math">σ_J</span> ,</li>
<li><span class="math">Π(λ)</span> is a Poisson process with jump intensity <span class="math">λ</span>.</li>
</ul>
<p>The transition probabilities for base fee equilibrium prices follow a Poisson-Laplace process. This can be expressed as:</p>
<div class="math">

p(X_t | X_{t-1}) = \lambda \frac{1}{2b} \exp\left(-\frac{|X_t - (a \Delta t + \phi X_{t-1} + \mu_J)|}{\sqrt{v_t (\sigma^2 + \sigma_J^2)}}\right)

</div>
<div class="math">

• (1-\lambda) \cdot \frac{1}{2b} \exp\left(-\frac{|X_t - (a \Delta t + \phi X_{t-1})|}{\sqrt{v_t \sigma^2}}\right)

</div>
<p>where:</p>
<ul>
<li><span class="math">∆t</span> is the time increment,</li>
<li><span class="math">a</span> is the drift term,</li>
<li><span class="math">φ</span> is the autoregressive coefficient,</li>
<li><span class="math">b</span> is the scale parameter of the Laplace distribution.</li>
</ul>
<p>The parameters <span class="math">Q = {α, κ, σ, a, b, μ_J , σ_J , λ}</span> can first be estimated by Maximum Likelihood (ML). This approach ensures that the parameters <span class="math">Q</span> are optimised to best fit the observed data under the specified model. The results of the simulation, displayed below, demonstrate the simulated log base fees for the next month. Notably, considering the most recent regime of exponential increase, I adopt a neutral market approach by assuming a linear (horizontal) trend. For pricing derivative products, consideration of what the future trend will be should be taken into account. After retrieving calibrated parameters, a range of future hourly dates is produced, before trend and seasonality is added back in, and the exponential is taken to revert the log.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/f/af172a8475671fb615b0494f03c0e53f7d01c0fb.png" title="Simulation"><img alt="Simulation" height="500" src="https://ethresear.ch/uploads/default/original/3X/a/f/af172a8475671fb615b0494f03c0e53f7d01c0fb.png" width="592" /></a></div><p></p>
<p><strong>ARIMA Monte Carlo Method</strong></p>
<p>An alternative method, which requires less computation simulates a monte-carlo process by modelling standardised residuals directly from a Laplace distribution, augmenting these standardised residuals back de-normalising them, before generating future paths as the composite of both this noise and ARIMA forecasts. A simulated residual path is shown below, producing the resulting simulation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/0/70411cba63138e2322e32a338e350acc9dbeebe9.png" title="Residules"><img alt="Residules" height="500" src="https://ethresear.ch/uploads/default/original/3X/7/0/70411cba63138e2322e32a338e350acc9dbeebe9.png" width="651" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/7/a71fae0b0032a14bc4099ebbd6b20f28c69bfd5a.png" title="Sim2"><img alt="Sim2" height="479" src="https://ethresear.ch/uploads/default/optimized/3X/a/7/a71fae0b0032a14bc4099ebbd6b20f28c69bfd5a_2_690x479.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/e/ce326060566053721576245372a025708af87d0b.jpeg" title="Screenshot 2024-06-14 at 12.50.40"><img alt="Screenshot 2024-06-14 at 12.50.40" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/e/ce326060566053721576245372a025708af87d0b_2_687x500.jpeg" width="687" /></a></div><p></p>
<p><strong>Pricing with these simulated values</strong></p>
<p>For the purpose of hedging, pricing a European call or put option based on the simulated paths can be expressed as follows. Let <span class="math">BF_T^i</span> represent base fees per gas at maturity <span class="math">T</span> for the <span class="math">i</span>-th simulated path, where <span class="math">i = 1, 2, \ldots, N</span>, and denote the strike price by <span class="math">K</span>. The payoff for the European call option at maturity for the <span class="math">i</span>-th path is given by <span class="math">\max(BF_T^i - K, 0)</span>, and for the European put option, it is given by <span class="math">\max(K - BF_T^i, 0)</span>. To find the option price, I first calculate the average payoff across all <span class="math">N</span> simulated paths: <span class="math">\frac{1}{N} \sum_{i=1}^N \max(BF_T^i - K, 0)</span> for the call option, and <span class="math">\frac{1}{N} \sum_{i=1}^N \max(K - BF_T^i, 0)</span> for the put option. These average payoffs are then discounted to the present value using the risk-free rate <span class="math">r</span>, giving the price of the European call option at time 0 as <span class="math">C_0 = e^{-rT} \times \frac{1}{N} \sum_{i=1}^N \max(BF_T^i - K, 0)</span> and the price of the European put option at time 0 as <span class="math">P_0 = e^{-rT} \times \frac{1}{N} \sum_{i=1}^N \max(K - BF_T^i, 0)</span>.</p>
<p>In pricing a gas plan where the underwriter subsidises the entire unit of gas at any point before <span class="math">T</span> I can model this as an American call option on gas fees with a strike price of zero and implement the Longstaff and Schwartz Regression Approach. This method involves calculating the payoff at the final period <span class="math">T</span> as the gas fee <span class="math">BF_T^i</span> for each path <span class="math">i</span>, assuming no transaction has been exercised before this time. Moving one time step backward, one regress the discounted future payoffs against the current gas fees <span class="math">BF_t^i</span> to estimate continuation values. This regression, known as a basis function, typically includes terms like a constant, <span class="math">BF_t^i</span>, and <span class="math">(BF_t^i)^2</span>. At each time step <span class="math">t</span>, we compare the immediate exercise value <span class="math">BF_t^i</span> with the estimated continuation value <span class="math">\hat{C}_t^i</span> from the regression. If the exercise value is higher, one updates the cash flow to reflect exercising the option; otherwise, we carry forward the discounted cash flow. Finally, the option price at time 0 (now) is obtained by averaging the discounted cash flows across all paths and all time periods.</p>
<p><strong>Utility in Oiler Pitch Lake</strong><br />
Oiler Pitch Lake is a protocol designed to allow liquidity providers (LPs) by pooling their assets to act as sellers in time-weighted moving average (TWAP) base fee cash-settled call options. Utilizing Starknet STARKS and the Fossil coprocessor for verifiability, Pitch Lake determines option payoffs based on the average base fee over a specified time interval, akin to an Asian option.</p>
<p>Given that LPs put up a limited amount of collateral, there is a cap on each option’s payoff. To protect LPs, a reserve price can be set, which is the minimum price at which the option must be sold. Using the aforementioned methodology, this reserve price can be calculated with both accuracy and verifiability, ensuring that LPs are safeguarded. Pitch Lake is currently in development and is expected to launch in the coming months.</p>
<p><strong>Next Steps</strong></p>
<ul>
<li><strong>Call for reproduction</strong>: Please reproduce my analysis and methodology. Working with complex financial mathematics can be prone to assumptions that may be easily violated. View this as an initial attempt to dive into the gas fee pricing topic</li>
<li><strong>What about the blobs market and L2 fee markets? I</strong> am currently working on similar analysis for the blob fee market place, L2 fees, and other blockchains. Expect more results soon.</li>
</ul>
<p><strong>Bibliography</strong><br />
[1] Oiler Pitch Lake. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018" rel="noopener nofollow ugc">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4123018</a><br />
[2] SMG Spec <a class="inline-onebox" href="https://www.mechanism.org/spec/04" rel="noopener nofollow ugc">04</a><br />
[3] [2] Lucia, Julio J., Schwartz, Eduaro. “Electricity Prices and Power Derivatives: Evidence from the Nordic Power Exchange.” Review of Derivatives Research. Vol. 5, Issue 1, pp 5-50, 2002. <a class="inline-onebox" href="https://link.springer.com/article/10.1023/A:1013846631785" rel="noopener nofollow ugc">Electricity Prices and Power Derivatives: Evidence from the Nordic Power Exchange | Review of Derivatives Research</a><br />
[4] Seifert, Jan, Uhrig-Homburg, Marliese. “Modelling Jumps in Electricity Prices: Theory and Empirical Evidence.” <em>Review of Derivatives Research</em>. Vol. 10, pp 59-85, 2007. <a class="inline-onebox" href="https://uk.mathworks.com/help/fininst/simulating-electricity-prices-with-mean-reversion-and-jump-diffusion.html" rel="noopener nofollow ugc">Simulating Electricity Prices with Mean-Reversion and Jump-Diffusion - MATLAB &amp; Simulink - MathWorks United Kingdom</a><br />
[5] Escribano, Alvaro, Pena, Juan Ignacio, Villaplana, Pablo. “Modeling Electricity Prices: International Evidence.” Universidad Carloes III de Madrid, Working Paper 02-27, 2002. Modeling Electricity Prices: International Evidence <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=299360" rel="noopener nofollow ugc">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=299360</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pricing-gas-fee-derivatives/19898">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 20:59:59 +0000</pubDate>
</item>
<item>
<title>Execution Auctions as an Alternative to Execution Tickets</title>
<link>https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894</link>
<guid>https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894</guid>
<content:encoded><![CDATA[
<div> 关键词：执行拍卖（Execution Auctions, EAs）、执行门票（Execution Tickets, ETs）、MEV、中央化、价值分配

总结:<br />
文章比较了两种解决以太坊中矿工效用提升（MEV）问题的机制：执行拍卖和执行门票。这两种方法旨在通过出售执行权来解决协议中的代理人问题，提高效率并减少外部性。文章分析了两种机制的经济差异，包括预期现值（NPV）、风险折扣、成本控制和中央化风险。执行拍卖简单易实现，但可能导致集中化；执行门票利用随机性，虽能防止集中，但可能涉及复杂性。最后，文章认为执行拍卖在实践中可能更优，尽管执行门票在某些方面提供保护。 <div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/2/128696dce49653e3211f52d33f86612013a883c4.jpeg" title="ealien"><img alt="ealien" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/2/128696dce49653e3211f52d33f86612013a883c4_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><br />
<em>By <a href="https://twitter.com/_JonahB_">Jonah Burian</a> &amp; <a href="https://twitter.com/DavideCrapis">Davide Crapis</a></em></p>
<p><em>Special thanks to <a href="https://x.com/weboftrees">Anders Elowsson</a>, <a href="https://twitter.com/barnabemonnot">Barnabé Monnot</a>, <a href="https://twitter.com/drakefjustin">Justin Drake</a> and <a href="https://twitter.com/mikeneuder">Mike Neuder</a> for the feedback and review.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-1" name="introduction-1"></a>Introduction</h1>
<p>There is a principal-agent problem in Ethereum. While the protocol creates MEV, it leaks it to proposers. Moreover, MEV in its current state exposes the protocol to other externalities, such as <a href="https://arxiv.org/abs/2305.09032">timing games</a>. It is widely held in the research community that capturing and properly redistributing MEV is an important step in the evolution of Ethereum, to make the protocol more resilient and efficient (<em>note: there are some people who <a href="https://www.nano210.blog/infinite-blockspace-equilibrium/">disagree</a>)</em>. The only way to solve this principal-agent problem is for the protocol to sell the rights to earn the MEV with a credible and efficient mechanism.</p>
<p>After many years of research, two approaches have recently emerged as potential avenues for solving MEV-burn. These are mechanisms where the right to propose an execution payload is not given for free to the <em>beacon proposer</em>, but it is instead sold separately to an <em>execution proposer</em>.</p>
<ul>
<li><strong>Execution Auctions (EAs):</strong> The right to propose an execution payload is <em>deterministically allocated</em> in advance for each slot, the slot execution proposer can purchase this right by bidding in a slot auction held beforehand, for example <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ#:~:text=introduce%20it%20next.-,Slot%2Dauction%2B32%20ePBS,-We%20suggest%20now">32 slots earlier</a>.</li>
<li><strong>Execution Tickets (ETs):</strong> the execution proposer right is not deterministically allocated, proposers can purchase a lottery ticket in advance and then, before each slot, a winner is drawn at random from the ticket pool and gets the right to propose.
<ul>
<li>The simple version of the protocol gives the winner the right to propose the following block. This was the focus of <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>.</li>
<li>The original execution ticket post <a href="https://ethresear.ch/t/execution-tickets/17944#:~:text=There%20exists%20a,market%20function%20smoothly.">suggested</a> a general version of the protocol where the winner has the right to propose <span class="math">m</span> slots later (e.g., 32). The intuition for why winners are given slots multiple slots in advance as opposed to immediately is that the solution allows for winners to offer preconfs.</li>
</ul>
</li>
</ul>
<p>The mechanisms have the same objective but important differences. The goal of this post is to compare the two solutions.</p>
<h1><a class="anchor" href="https://ethresear.ch#setup-2" name="setup-2"></a>Setup</h1>
<p>We will introduce formulas throughout this post to outline the key economic differences between the protocols. We will also explain the practical nuances, so if you want to skip the math, no worries! For the extra curious, we lay out the proof of the formulas in the appendix.</p>
<h2><a class="anchor" href="https://ethresear.ch#terms-3" name="terms-3"></a>Terms</h2>
<ul>
<li><span class="math">t</span> — discrete time intervals (slot).</li>
<li><span class="math">n</span> — the number of tickets.</li>
<li><span class="math">d</span> is the inter-slot discount rate used to calculate the present value of future prizes.
<ul>
<li>Note: assuming that the vanilla staking rate is the risk-free rate in Ethereum, <span class="math">d \approx 10^{-8}</span></li>
</ul>
</li>
<li><span class="math">\mathcal{R}</span> is a random variable representing the value of controlling an execution payload at time <span class="math">t</span>.
<ul>
<li>We term this the Execution Layer Reward (EL Reward) which equals MEV + fees in slot <span class="math">t</span>.</li>
<li>We assume that <span class="math">\mathcal{R}</span> has a distribution that does not vary with time and that each draw is independent. (This is usually not the case in practice, as EL rewards are time-varying and correlated, but it allows for a less complicated analysis that can be expanded later.)</li>
</ul>
</li>
<li><span class="math">\mu_{\mathcal{R}}</span> is the expected value of <span class="math">\mathcal{R}</span>.</li>
<li><span class="math">V_{ticket}</span> — Net Present Value (NPV) of a single ticket.
<ul>
<li>Note: present value of some value <span class="math">X</span> realized at time <span class="math">t</span> is calculated as <span class="math">\frac{X}{(1+d)^t}</span>.</li>
</ul>
</li>
<li><span class="math">m</span> — number of slots t after winning that the right to propose is given (e.g., <span class="math">m=32</span>).</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#northstar-4" name="northstar-4"></a>Northstar</h2>
<p>The expected net present value of all future EL Rewards is</p>
<div class="math">
NPV_{\mathcal{R}} = \frac{\mu_{\mathcal{R}}}{d}
</div>
<p>This is the total value of all block space from now into the future of Ethereum. Given that the goal of the Execution Auctions and Execution Tickets is to capture the value of block space and redistribute the value to align with the protocol’s goals, all solutions must be analyzed in terms of how well they capture <span class="math">NPV_{\mathcal{R}}</span>.</p>
<p><em>Note: Capturing all the value depends on the selling mechanism. In this analysis, we assume that the selling mechanism is efficient. Detailed analysis of the selling mechanism in a dynamic/repeated strategic interaction context is an open problem currently under research.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#execution-auctions-5" name="execution-auctions-5"></a>Execution Auctions</h1>
<p>Execution Auctions (EAs) are essentially slot auctions carried out in advance:</p>
<ul>
<li><strong>Proposer right allocation:</strong> the <em>execution proposer right</em> for slot <span class="math">k+m</span> is sold <span class="math">m</span> slots in advance, at slot <span class="math">k</span>.</li>
<li><strong>Selling mechanism:</strong> the beacon proposer of slot <span class="math">k</span> receives bids for that right and commits to the highest bid, attesters vote.</li>
</ul>
<p>A <strong>secondary market</strong> will most likely develop where an EA ticket winner can resell their proposer right before their turn to propose. Even if the protocol does not allow them to transfer that right, this can be easily done via an out-of-protocol gadget.</p>
<h1><a class="anchor" href="https://ethresear.ch#execution-tickets-6" name="execution-tickets-6"></a>Execution Tickets</h1>
<p>Execution Tickets (ETs) have a lottery component that adds uncertainty on the specific block a holder will be able to propose in the future, this can be resolved closer to the time of proposing or further ahead of time.</p>
<ul>
<li><strong>Proposer right allocation:</strong> the <em>execution proposer right</em> for <em>a slot</em> in the future is sold in the form of a lottery ticket.</li>
<li><strong>Selling mechanism:</strong> assume there are already <span class="math">n</span> tickets in the lottery pool, at each slot a ticket is selected as lottery winner (e.g., at the end of the slot using RANDAO) and a new ticket is sold to enter the pool starting from the next slot.
<ul>
<li><strong>Pricing:</strong> We assume an English Auction for comparison with EAs.</li>
<li><strong>Uncertainty resolution:</strong> we can have a next-slot execution lottery, where at the end of slot <span class="math">k</span> we select proposer for slot <span class="math">k+1</span> (we term these sETs i.e, simple ETs), or a future-slot execution lottery, where at the end of slot <span class="math">k</span> we select proposer for slot <span class="math">k+m</span> (we term these ETs).</li>
</ul>
</li>
</ul>
<p>Similarly to EAs, a secondary market will likely emerge where a ticket holder or a winning ticket holder can resell their right to participate in the lottery or propose.</p>
<p><em>Note: In the initial post <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a> we did not yet make the distinction between sETs and ETs. That post was about sETs (a special case of ETs).</em></p>
<p><em>Note 2: <a href="https://twitter.com/drakefjustin">Justin </a> perceptively pointed out that we don’t know how to achieve low-latency randomness using RANDAO, and VDFs wouldn’t help either. Low-latency RANDAO would be biasable (as well as fully predictable when you control two slots in a row).</em></p>
<h1><a class="anchor" href="https://ethresear.ch#analysis-7" name="analysis-7"></a>Analysis</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/0/c088b53c1b671ac4704f3ff5c99e4b792264c861.png" title="Chart 1"><img alt="Chart 1" height="174" src="https://ethresear.ch/uploads/default/optimized/3X/c/0/c088b53c1b671ac4704f3ff5c99e4b792264c861_2_690x174.png" width="690" /></a></div><p></p>
<p><em>Note: All approximations assume <span class="math">m</span> (time from when the ticket wins to when the right is conferred) and <span class="math">n</span> (number of ETs) are not large. Given that <span class="math">d</span> is nearly zero, we are able to simplify the equations.</em></p>
<p><em>Note 2: Without using the approximation,</em> EA tickets <em>and ETs have some Dead Weight Loss associated with the fact that winning tickets cannot be immediately used, i.e., there is some loss given the time discount. The intuition for the approximation is that given <span class="math">d</span> is small, this value loss due to the time discount is nominal.</em></p>
<p><em>Note 3: While we assume in the approximation for the variance of sETs and ETs that <span class="math">n</span> is small, we discussed in “<a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>” that a large <span class="math">n</span> leads to less centralization risk and more democratization in terms of who can afford a ticket. That said, a large <span class="math">n</span> creates valuation complexity and adds the additional complexity of having to run a large sale at the beginning of the lottery to bootstrap the ticket pool. (Read the article to learn more.)</em></p>
<p>Here is a simplified version of the chart assuming the approximation.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/a/dad825aa8d8c8324d64726716ed5a0fd84508ffe.png" title="Chart 2"><img alt="Chart 2" height="186" src="https://ethresear.ch/uploads/default/optimized/3X/d/a/dad825aa8d8c8324d64726716ed5a0fd84508ffe_2_517x186.png" width="517" /></a></div><p></p>
<p>Notice that all three approaches using the approximation arrive at the same conclusion: we can effectively capture (assuming an efficient auction) all the value associated with block space. Moreover, in each design, the tickets have a simple explanation: they are worth about the value associated with proposing an execution payload.</p>
<p>The variance of the ticket value is the variance of the rewards per slot, which is about as good as you are going to get given that the rights to propose are sold in advance, namely prior to the block’s construction.</p>
<h1><a class="anchor" href="https://ethresear.ch#sure-thing-vs-future-possibility-comparing-eas-and-setsets-8" name="sure-thing-vs-future-possibility-comparing-eas-and-setsets-8"></a>Sure Thing vs Future Possibility: Comparing EAs and sETs/ETs</h1>
<p>We now turn to comparing EAs and sETs/ETs to elucidate trade-offs when thinking about implementing such mechanisms in practice. It should be noted that most of the tradeoffs stand from the fundamental difference between EAs and sETs/ETs - the former is a deterministic protocol while the latter leverages nondeterminism.</p>
<ul>
<li><strong>Implementation Simplicity:</strong> EAs are simpler to implement, the tickets do not require randomness so there is no need to worry about RANDAO bias. Moreover, it is unclear how to implement the randomness for sETs. The secondary market for proposer rights with EA tickets will be much simpler than with sETs/ETs, no need to worry about ticket MEV. Moreover, there seems to be a <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">clear path to implement EAs via ePBS</a> and bypassability not an issue since we’re selling future slots.</li>
<li><strong>Simpler Assets:</strong> It is easier to reason about a deterministic asset than a random one, which makes EA better than sETs and ETS. That said, buyers in the protocol are most likely sophisticated, and the current paradigm for selecting validators relies on randomness, meaning maintaining non-determinism won’t be a substantial break from the status quo. However, a counterargument is that current proposers might not be buyers of tickets.</li>
<li><strong>Variance could affect valuation and EA tickets are less exposed:</strong> It is reasonable for ticket holders to apply a risk discount to the tickets; that is, they might value the tickets less given risk aversion. While EA tickets are only exposed to the variance in the value of the EL rewards in slot <span class="math">t+m</span>, both sETs and ETs are exposed to the variance in EL rewards and the variance in when a ticket wins. Intuitively, EA would therefore have the lowest risk discount.</li>
<li><strong>Efficiency:</strong> From the protocol’s POV, sETs are more efficient because proposer rights are sold closer to the slot of the MEV in expectation while EAs and ETs have dead weight loss in theory. That said, when factoring in risk aversion, EAs might be more efficient.</li>
<li><strong>Preconfs</strong>: Preconfs require there to be a lookahead, meaning the protocol must know in advance who will control the rights to the execution payload. While EAs and ETs allow for preconfs, sETs do not, as winners are decided at each block.</li>
<li><strong>Cost-of-control:</strong>
<ul>
<li><strong>In EA</strong>
<ul>
<li>EAs put <em>transaction liveness</em> risk on Ethereum—namely, the cost of monopolizing block space is disjoint from the security budget of Ethereum, and the cost of controlling consecutive blocks has a fixed value. Controlling <span class="math">x</span> blocks in a row costs approximately <strong><span class="math">\approx x\mu_{\mathcal{R}}</span></strong>. Luckily, new <a href="https://eips.ethereum.org/EIPS/eip-7547">IL designs</a> could rectify this. Even with ILs, relying heavily on them is suboptimal (they are designed to be a last resort, not commonplace—this can be argued). Importantly as well, the ability to consistently control multiple slots means that well-capitalized parties will perpetually win more block space. This could lead to centralization of the execution payload construction pipeline, exacerbating the current centralization challenges within this pipeline. (See the Multi-block MEV section in “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>”).</li>
<li><a href="https://twitter.com/barnabemonnot">Barnabé</a> aptly noted to us that saying the “the cost of monopolizing block space is disjoint from the security budget of Ethereum” is no different from the existing setup where validators can sell building rights. Currently, validators can sell multiple consecutive blocks in a row. <em>This does not mean that the centralization argument is incorrect but indicates that EAs are not a substantial break from the status quo.</em></li>
</ul>
</li>
<li><strong>In sETs (and ETs):</strong>
<ul>
<li>
<p>While the cost of monopolizing block space is disjoint from the security budget with sETs (and ETs), it is substantially more expensive and less likely that a single party can control multiple consecutive blocks in a row. Non-determinism prevents guaranteed control over block space reducing the likelihood of control. Randomness serves as a defense against centralization.</p>
<ul>
<li>
<p>The first chart provides an intuitive understanding of this principle. It shows a scenario with 100 outstanding sETs/ETs. If someone owns 95% of the initial outstanding tickets (remember, one is subsequently minted per block), the probability of winning 20 slots in a row is approximately 4%, while the probability of winning 35 in a row is almost impossible.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/3/63786be4729c8134b1fa101788af325a31fb7427.png" title="Graph 1"><img alt="Graph 1" height="412" src="https://ethresear.ch/uploads/default/optimized/3X/6/3/63786be4729c8134b1fa101788af325a31fb7427_2_690x412.png" width="690" /></a></div><p></p>
</li>
<li>
<p>Moreover, the costs of controlling <span class="math">P\%</span> of the blocks increases in <span class="math">n</span> (See: <a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894">Economic Analysis of Execution Tickets</a>)<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/5/b5e0ee59790fe044c3adbb4ae4f5ae4408e0694c.png" title="Graph 2"><img alt="Graph 2" height="186" src="https://ethresear.ch/uploads/default/optimized/3X/b/5/b5e0ee59790fe044c3adbb4ae4f5ae4408e0694c_2_690x186.png" width="690" /></a></div><p></p>
</li>
</ul>
</li>
<li>
<p><strong>Where ETs differ:</strong></p>
<ul>
<li>While an attacker in sETs must rely on chance to win consecutive blocks, a clever ETs user can buy a sequence of winning tickets for <span class="math">t+m</span> to <span class="math">t+m+x</span> on the secondary market, making the centralization in ETs similar to the centralization problem with EAs. One can argue that sETs are subject to the same risk as an out-of-protocol auction for control of the sETs winners’ rights can happen. That said, there may be honest actors who don’t sell rights to execution payload construction. If one of these holders wins, they end the sequence of winning blocks for a sET attacker, meaning that a sET attack, even with the out-of-protocol option, is exposed to uncertainty.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><a class="anchor" href="https://ethresear.ch#concluding-remarks-9" name="concluding-remarks-9"></a>Concluding Remarks</h1>
<p>EAs dominate in simplicity, while sETs protect from centralization but at the expense of allowing for preconfs. sETs may also be unimplementable in the Ethereum Protocol today given the RANDAO problem. ILs can curb centralization concerns with EAs, and the secondary market for sETs/ETs can nullify their protective benefits. Moreover, EAs are not a substantial break from the status quo in terms of centralization.</p>
<p><em>While there are still open questions around implementing EAs and their efficiency, EAs seem to be superior to sETs and ETs for the Ethereum protocol.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#related-work-10" name="related-work-10"></a><strong>Related work</strong></h1>
<p><em>This list is copied and pasted from</em> <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a> with the addition of <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>. lol</p>
<ol>
<li><em>mev-boost &amp; relays</em>
<ul>
<li><a href="https://ethresear.ch/t/mev-boost-merge-ready-flashbots-architecture/11177"><em>MEV-Boost: Merge ready Flashbots Architecture</em></a>; Flashbots team</li>
<li><a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278"><em>Relays in a post-ePBS world</em></a>; Mike, Jon, Hasu, Tomasz, Chris, Toni</li>
</ul>
</li>
<li><em>mev-burn / mev-smoothing</em>
<ul>
<li><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>Burning MEV through block proposer auctions</em></a>; Domothy</li>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn – a simple design</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408"><em>Committee-driven MEV smoothing</em></a>; Francesco</li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384"><em>Dr. changestuff or: how I learned to stop worrying and love mev-burn</em></a>; Mike, Toni, Justin</li>
</ul>
</li>
<li><em>enshrined Proposer-Builder Separation (ePBS)</em>
<ul>
<li><a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980"><em>Two-slot proposer/builder separation</em></a>; Vitalik</li>
<li><a href="https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879"><em>Unbundling PBS: towards protocol-enforced proposer commitments (PEPC)</em></a>; Barnabé</li>
<li><a href="https://barnabe.substack.com/p/pbs"><em>Notes on Proposer-Builder Separation</em></a>; Barnabé</li>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ"><em>More pictures about proposers and builders</em></a>; Barnabé</li>
<li><a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710"><em>Why enshrine Proposer-Builder Separation?</em></a>; Mike, Justin</li>
<li><a href="https://ethresear.ch/t/epbs-design-constraints/18728"><em>ePBS design constraints</em></a>; Potuz</li>
<li><a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg"><em>Reconsidering the market structure of PBS</em></a>; Barnabé</li>
</ul>
</li>
<li><em>block-space futures</em>
<ul>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ"><em>Block vs. Slot Auction PBS</em></a>; Julian</li>
<li><a href="https://frontier.tech/ethereums-blockspace-future"><em>Opportunities and Considerations of Ethereum’s Blockspace Future</em></a>; Drew, Ankit</li>
<li><a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814"><em>When to sell your blocks</em></a>; Quintus, Conor</li>
</ul>
</li>
<li><em>execution tickets</em>
<ul>
<li><a href="https://www.youtube.com/watch?v=MtvbGuBbNqI"><em>Attester-proposer separation</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/execution-tickets/17944"><em>Execution tickets</em></a>; Justin, Mike</li>
<li><a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894"><em>Economic Analysis of Execution Tickets</em></a>; Jonah, Davide</li>
<li><a href="https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232"><em>Block-auction ePBS versus Execution Ticket</em></a>; Terence</li>
</ul>
</li>
<li><em><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>; Mike, Pranav, &amp; Dr. Tim Roughgarden</em></li>
</ol>
<p><em>This post has a similar goal to</em> <a href="https://x.com/mikeneuder">Mike</a>, <a href="https://x.com/PGarimidi">Pranav</a>, &amp; <a href="https://x.com/Tim_Roughgarden">Tim</a>’s recent work titled <a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">On block-space distribution mechanisms</a>: <em>comparing new mechanisms for execution rights allocation.</em> However, there are a few key differences in our analysis that we highlight here:</p>
<ol>
<li>They use a modified ET model (i.e., a model where all tickets are burned between slots). This model, while easier to implement, does not lead to an efficient allocation (as those with lower valuations for block space can still be allocated it).</li>
<li>They focus on a Tullock Contest model, while our model resembles a fixed-income model.</li>
<li>Their analysis focuses on the trade-off between the quality of the in-protocol MEV oracle and the fairness of the mechanism, while we focus on other trade-offs such as implementation ease, risk discounts, centralization control, and economic efficiency.</li>
</ol>
<h1><a class="anchor" href="https://ethresear.ch#appendix-11" name="appendix-11"></a>Appendix</h1>
<p><strong>Calculating the discount rate:</strong></p>
<p>The staking rate at the time of this article is <code>~3.4%</code> (<a href="https://www.coindesk.com/indices/ether/cesr">source</a>).</p>
<p><span class="math">1.34=(1+d)^{\text{number of slots in a year}}=(1+d)^{365 * 24 * 60 * 60 / 12}</span> <img alt=":arrow_right:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/arrow_right.png?v=12" title=":arrow_right:" width="20" />  <span class="math">d=1.27e-08 \approx 10^{-8}</span></p>
<p><strong>The expected net present value of all future EL Rewards:</strong></p>
<p>See this <a href="https://arxiv.org/abs/2404.04262">paper</a> for the proof</p>
<p><strong>Calculating:</strong> <span class="math">E[V_{\text{EA ticket}}]</span></p>
<div class="math">
E[V_{\text{EA ticket}}] =  \frac{\mu_{\mathcal{R}}}{(1+d)^m}
</div>
<p>This is because the value is recognized <span class="math">m</span> slots later so you need to discount the MEV received in <span class="math">m</span> blocks by the discount rate <span class="math">d</span>.</p>
<p><strong>Calculating <span class="math">E[V_{\text{all EA tickets}}]</span></strong></p>
<div class="math">
\begin{align*}
    E[V_{\text{all EA tickets}}] &amp;=
    \sum_{t=1}^{\infty} \frac{ E[V_{\text{EA ticket}}]}{(1+d)^t} \\
    &amp;= \sum_{t=1}^{\infty} \frac{\mu_{\mathcal{R}}}{(1+d)^{m+t}} \\
    &amp;= \frac{1}{(1+d)^{m}} \sum_{t=1}^{\infty} \frac{\mu_{\mathcal{R}}}{(1+d)^{t}} \\
    &amp;= \frac{1}{(1+d)^{m}} NPV_{\mathcal{R}} 
\end{align*}
</div>
<p><strong>Calculating</strong> <span class="math">\text{Var}(V_{\text{EA ticket}})</span></p>
<div class="math">
\text{Var}(V_{\text{EA ticket}}) =  \text{Var}\left(\mathcal{\frac{R}{(1+d)^m}}\right) =  \frac{\text{Var}(\mathcal{R})}{(1+d)^{2m}}
</div>
<p><strong>Calculating</strong> <span class="math">NPV_{\mathcal{R}}</span>, <span class="math">E[V_{\text{sET}}]</span>, <span class="math">E[V_{\text{all sETs}}]</span> and  <span class="math">\text{Var}(V_{\text{sET}})</span></p>
<p>The proofs can be found in Jonah’s “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>” paper. Remember, the paper does not make the sET vs. ET distinction.</p>
<p><strong>Calculating</strong> <span class="math">E[V_{\text{ET}}]</span>, <span class="math">E[V_{\text{all ETs}}]</span> and  <span class="math">\text{Var}(V_{\text{ET}})</span>,</p>
<p>These are simple modifications to the sET calculations using the <span class="math">m</span> slot discount.</p>
<p><strong>Calculating Graph 1:</strong></p>
<p>The probability of winning <span class="math">m</span> consecutive slots when holding <span class="math">p</span> percent of the sETs/ETs initially (without rebuying a ticket each block) is determined by the product of the probabilities of winning each individual draw:</p>
<div class="math">
\begin{align*}W &amp;= \left(\frac{pn}{n}\right) \cdot \left(\frac{pn-1}{n}\right) \cdot \left(\frac{pn-2}{n}\right) \cdots \left(\frac{pn-(m-1)}{n}\right) \\&amp;= \frac{(pn)!}{(pn-m)! n^m}\end{align*}
</div>
<p><strong>Calculating Graph 2:</strong></p>
<p>See section 4.4 in the “<a href="https://arxiv.org/abs/2404.04262">Future of MEV</a>” paper.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/execution-auctions-as-an-alternative-to-execution-tickets/19894">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 15:40:47 +0000</pubDate>
</item>
<item>
<title>Avoiding Accidental Liveness Faults for Based Preconfs</title>
<link>https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888</link>
<guid>https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888</guid>
<content:encoded><![CDATA[
<div> 关键词：基于预确认、意外活期性故障、保护、链条化、预验证

总结:<br />
本文讨论了在引入基于预确认（based preconfirmations）的以太坊网络中，如何解决提案者面临的意外活期性故障（liveness faults）导致的潜在损失问题。作者提出了一种利用预验证链条（preconf chaining）的方法，该机制无需修改现有协议设计，旨在防止个体提案者因偶然事件导致的活期性故障被罚。通过链条化的预验证请求，依赖关系和智能的切割条件，可以确保即使一个提案者出现问题，后续的链条也能保证预验证的履行，从而减少误罚。此外，文章还探讨了如何通过激励措施鼓励链条化行为，如共享提示和建立良好的声誉预期。总的来说，链条化预验证为提案者提供了更好的保护，增强了预验证的可靠性，促进了系统的整体稳定性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#avoiding-accidental-liveness-faults-for-based-preconfs-1" name="avoiding-accidental-liveness-faults-for-based-preconfs-1"></a>Avoiding Accidental Liveness Faults for Based Preconfs</h1>
<p><em>thanks to <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin Drake</a>, <a href="https://x.com/jon_charb" rel="noopener nofollow ugc">Jon Charbonneau</a>, <a href="https://x.com/lvdaniels" rel="noopener nofollow ugc">Ladislaus</a>, <a href="https://x.com/aimxhaisse" rel="noopener nofollow ugc">Sébastien Rannou</a>, <a href="https://x.com/lazyleger" rel="noopener nofollow ugc">sacha</a>, <a href="https://x.com/DrewVdW" rel="noopener nofollow ugc">Drew van Der Werff</a>, and Max Wilde from <a href="https://x.com/aestusrelay" rel="noopener nofollow ugc">Aestus</a> for thinking and review</em><br />
.<br />
.<br />
<em><strong>tl;dr:</strong> We solve one of the largest problems with based preconf opt-in from proposers: accidental liveness slashing. The mechanism we introduce requires no changes to existing based preconf protocol designs and has been under our noses the whole time. We use preconf chaining to protect individual proposers from being slashed for liveness failures.</em><br />
.<br />
.</p>
<h2><a class="anchor" href="https://ethresear.ch#background-2" name="background-2"></a>Background</h2>
<p>On Ethereum today, liveness issues with block proposals are largely accepted, and penalties are minimal. When we introduce based preconfirmations, liveness issues can mean different consequences.</p>
<p>When dealing with preconfs: from the user’s perspective, liveness faults (missing a block proposal) and safety faults (proposing a block that does not fulfill preconf commitments) are the same thing. In both scenarios, a user experiences a situation where their preconfirmation is not fulfilled.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/d/9d996b95a0c2f74f54edf8f3d3b89beda26956db.png" title="liveness faults are safety faults"><img alt="liveness faults are safety faults" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/d/9d996b95a0c2f74f54edf8f3d3b89beda26956db_2_406x500.png" width="406" /></a></div><p></p>
<p>Now, from the perspective of the proposer, liveness faults and safety faults are two very different things. Liveness faults may occur from a multitude of external, accidental circumstances (like power outages, wifi downtime, reorgs, spontaneous combustion) that many proposers just aren’t prepared for. On the other hand, safety faults can only occur when some party (the proposer or some delegate) acts maliciously.</p>
<p>Additionally, attributing liveness faults is difficult. Many actors within the block supply chain may be responsible for a liveness fault occurring. The complexity involved with this attribution would be nice to avoid.</p>
<p>To make proposers feel more comfortable with putting up potentially high amounts of collateral, being slashed for accidental liveness faults should be very rare if not impossible.</p>
<h2><a class="anchor" href="https://ethresear.ch#preconf-chaining-3" name="preconf-chaining-3"></a>Preconf Chaining</h2>
<p><img alt="preconf chaining" height="500" src="https://ethresear.ch/uploads/default/original/3X/5/2/524180b5ef3a6673ab62d02d5afdc1a4d0d94fe5.png" width="500" /></p>
<h3><a class="anchor" href="https://ethresear.ch#brief-assumptions-4" name="brief-assumptions-4"></a>Brief Assumptions:</h3>
<ul>
<li>(we are talking about based preconfs here, not L1 preconfs)</li>
<li>slashing conditions are expressive</li>
<li>preconf requests include L2 block number</li>
<li>“active preconfer” refers to the current preconfer (an L1 proposer or delegate in the lookahead), “next active preconfer” refers to the entity who will be the next preconfer.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#slashing-conditions-construction-5" name="slashing-conditions-construction-5"></a>Slashing Conditions Construction:</h3>
<p>We assume a slashing conditions paradigm that is similar to the one presented in <a href="https://ethresear.ch/t/credibly-neutral-preconfirmation-collateral-the-preconfirmation-registry/19634">The Preconf Registry.</a> Specifically, that slashing conditions are “smart” and expressive enough to represent the following constructions.</p>
<p>The slashing conditions are designed so that a preconfer is slashed if:</p>
<ul>
<li>they sign a preconf request about a transaction <code>A</code> and block <code>B</code>, where <code>B</code> is a future L2 block. Also signed is a list of “dependents”, a list of other preconfers (by address or other ID).</li>
<li><code>A</code> is not fulfilled in <code>B</code>, or was not fulfilled in a block prior to <code>B</code></li>
<li>All dependents have signed the same preconf request (commitments/signatures from these are required) and have not been slashed (a challenge/cooldown period is useful here).</li>
</ul>
<p>This dependent design enables a preconfer to conditionally preconfirm a transaction, based on the choices of other preconfer.</p>
<h3><a class="anchor" href="https://ethresear.ch#preconf-flow-6" name="preconf-flow-6"></a>Preconf Flow</h3>
<ul>
<li>Alice (a based L2 user) wants an inclusion preconf for a transaction <code>A</code></li>
<li>Alice <a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812">delivers a preconf request to the active preconfer</a></li>
<li>Some entity who obtains a preconf commitment from the active preconfer (Alice, a gateway, or even the active preconfer itself) forwards Alice’s preconf request to the next active preconfer (with a dependent on the active preconfer added) and also forwards the active preconfer’s commitment.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/4/84a8b7a1158dfc8f844abfc5447b193b3d35f12e.png" title="diagram representing how any actor can send a chained preconf request to the next active preconfer"><img alt="diagram representing how any actor can send a chained preconf request to the next active preconfer" height="387" src="https://ethresear.ch/uploads/default/optimized/3X/8/4/84a8b7a1158dfc8f844abfc5447b193b3d35f12e_2_690x387.png" width="690" /></a></div><p></p>
<p><strong>Any actor with access to a preconf commitment may construct a chained preconf and forward it to the next active preconfer.</strong></p>
<p>Note that incentives for doing this vary:</p>
<ul>
<li><strong>preconf RPC:</strong> aka <a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812">The Preconfirmation Gateway</a> might chain preconfs as a public good for proposers.</li>
<li><strong>gateway:</strong> A gateway might also chain preconfs as a public good for proposers, but may also use this as a feature to attract proposers (maybe called “liveness fault protection”).</li>
<li><strong>proposers:</strong> A proposer (or node operator) might also chain preconfs themselves. Their incentive is obviously to avoid being slashed for liveness faults.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#determining-penalties-7" name="determining-penalties-7"></a>Determining Penalties</h3>
<ul>
<li>In the case where the active preconfer represents a proposer that has a liveness failure and proposes no L2 block, they wouldn’t be slashed because the preconf could still be fulfilled by the next preconfer (and the preconf request block number would match).</li>
<li>If the active preconfer proposes a block and does not fulfill the preconf request, they would be slashed for a safety fault.</li>
<li>If the active preconfer does not propose a block and the next preconfer does but does not fulfill the preconf request, the second preconfer is slashed for a safety fault.</li>
<li>If both preconfers have liveness issues, both are slashed for a safety fault. (This can be avoided by chaining beyond 2.)</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#incentivizing-chaining-8" name="incentivizing-chaining-8"></a>Incentivizing Chaining</h3>
<p>To incentivize a future active preconfer to chain preconfs, an active preconfer might share tips. Also, a reputational expectation to chain preconfs can encourage more chaining.</p>
<p>One possible way to get chaining adoption is to simply require that chaining happens. To make this practical, the future active preconfers must be able to access the preconf commitments of previous preconfers. The DA problem must be solved to make this practical, and this could be done with an external DA layer. Notably, using an external DA layer introduces dependencies on another sequencer: the DA sequencer. TBD how designs of different DA layers can work around this issue and potential censorship that might occur.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-9" name="conclusion-9"></a>Conclusion</h2>
<p>In this post, we focus on the benefits of chaining for proposers. Widespread chaining also increases the guarantees that users get for preconfirmations, making preconfs even more valuable. It’s a win-win!</p>
<p>Whether forced or opt-in, preconf chaining can protect proposers from being slashed for accidental liveness faults. This system can help proposers feel more comfortable opting into higher collateral requirements.</p>
<p><img alt="preconf chaining protects proposers from penalties for liveness faults" height="451" src="https://ethresear.ch/uploads/default/original/3X/c/c/cc0abe035c50a142437976c953764a60e774427a.png" width="553" /></p>
<h4><a class="anchor" href="https://ethresear.ch#references-10" name="references-10"></a>References</h4>
<ul>
<li><a href="https://ethresear.ch/t/the-preconfirmation-gateway-unlocking-preconfirmations-from-user-to-preconfer/18812#chained-preconfirmations-13">The Preconfirmation Gateway</a> by <a href="https://x.com/mteamisloading" rel="noopener nofollow ugc">mteam (me)</a> mentions chained preconfirmations as better liveness guarantees for users.</li>
<li><a href="https://ethresear.ch/t/based-preconfirmations/17353">Based preconfirmations</a> by <a href="https://x.com/drakefjustin" rel="noopener nofollow ugc">Justin Drake</a> introduces a simple design for based preconfs.</li>
<li><a href="https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884">Pre-confirmation Liveness Slashing Penalties from the Proposer’s Perspective</a> by <a href="https://x.com/aimxhaisse" rel="noopener nofollow ugc">Sébastien Rannou</a> touches on the liveness slashing problem and explains how it decreases the economic viability of preconfs for proposers.</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/avoiding-accidental-liveness-faults-for-based-preconfs/19888">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 18:46:11 +0000</pubDate>
</item>
<item>
<title>Pre-confirmation Liveness Slashing Penalties from the Proposer's Perspective</title>
<link>https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884</link>
<guid>https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884</guid>
<content:encoded><![CDATA[
<div> 关键词：liveness penalty, proposer, pre-confirmations, economic viability, missed blocks

总结:
这篇文章探讨了以太坊网络中预确认（pre-confirmations）的预设罚金对提案者（proposer）经济可行性的影响。文章指出，约0.54%的区块在过去7天内被错过，为了收支平衡，提案者需要从预确认接收的额外小费（tip）至少为错过块罚金（0.0054 ETH）的一半。模型显示，随着错过率增加，预确认小费需相应提高。文章提出了几种可能的解决方案，如基于网络错过率自动调整罚金、用户自定义罚金和小费，以及只在经济上可行时才参与预确认。然而，模型缺乏激励机制，不确定是否能鼓励提案者积极参与。 <div>
<p>Current designs around pre-confirmations involve a slashing penalty on liveness, that is if a proposer who commited to pre-confirmations misses its proposal, part of its collateral is burned or redistributed to the user that sent the pre-confirmation as a payback.</p>
<p>This post explores the liveness penalty from the point of view of proposers from an economical perspective.</p>
<h2><a class="anchor" href="https://ethresear.ch#sources-of-liveness-issues-1" name="sources-of-liveness-issues-1"></a>Sources of Liveness Issues</h2>
<p>Liveness issues are complex and can come from different actors or sources, part of them are the result of the proposer’s actions or choices, part of them don’t depend on the proposer. For example:</p>
<ul>
<li>proposing a block in time but being reorg by the next proposer,</li>
<li>failure from the relayer to send the header in time,</li>
<li>failure from the relayer to propagate the signed header in time and reveal the block to the proposer.</li>
</ul>
<p>As a result, the decision on whether to opt-in or not from a proposer perspective has to take into account an <strong>inherent</strong> risk outside of its actions. Using a statistical approach on network history sounds like an easy starting point.</p>
<h2><a class="anchor" href="https://ethresear.ch#economical-minimal-viability-2" name="economical-minimal-viability-2"></a>Economical Minimal Viability</h2>
<p>In the last 7 days on the network, about <code>0.54%</code> of slots were missed, to break-even economically (that is, for an operator to not lose or win anything in the long run), assuming the liveness fault is <code>1 ETH</code>, the minimal extra-tip of a pre-confirmation would be <code>0.0054 ETH</code>.</p>
<p>To put it in perspective, the median execution reward in the last 7 days is <code>~0.048 ETH</code>, so with <code>1 ETH</code> of collateral, the pre-confirmations would need to be about <code>10%</code> of the block’s value with the current network conditions. Using <code>P(miss)</code> as the probability to miss a block, the break-even formula is:</p>
<div class="math">
(1 - (P(miss))) * tip = P(miss) * penalty
</div>
<p>And so the minimal tip:</p>
<div class="math">
tip = {(P(miss) * penalty) \over (1 - P(miss))}
</div>
<p>With <code>1 ETH</code> as a collateral, here is the model for low probabilites of missed block with <code>P(miss) &lt; 0.025</code>:</p>
<p><img alt="download" height="455" src="https://ethresear.ch/uploads/default/original/3X/e/a/ea574d8ff641f0e75064bfc788d672f031b6a3cb.png" width="626" /></p>
<p>Zooming out up with <code>P(miss) &lt; 0.5</code>:</p>
<p><img alt="download" height="455" src="https://ethresear.ch/uploads/default/original/3X/0/6/0638f8a59181327ccce1392f2bd48663d52562aa.png" width="608" /></p>
<h2><a class="anchor" href="https://ethresear.ch#opt-in-if-economically-viable-3" name="opt-in-if-economically-viable-3"></a>Opt-in if Economically Viable</h2>
<p>One idea to make it viable at scale with little effort from proposers would be for the pre-confirmation sidecar on the proposer side to opt-in to pre-confirmations only it if the tip is above what’s economically sound given the current rate of misses on the network. For example, if in the last 24 hours the average missed block proposal is <code>0.5%</code>, only commit to pre-confirmations which tip is above <code>0.005 ETH</code>.</p>
<p>This approach requires the relayer to pass the pre-confirmation tip information to the proposer to decide whether or not to commit to pre-confirmations, or the proposer to send the minimal-tip to the builder so it can provide a block that match it.</p>
<p>The advantage of this approach is if the network is struggling at scale, the risk for a proposer to miss a slot increases, and so it makes sense for proposers to opt-out of pre-confirmations until the situation resolves. Increasing the pre-confirmer bid under such conditions makes sense as more risk is taken.</p>
<p>A disavantage is that the missed block proposal rate is an approximation: it doesn’t account for totally offline validators, or for the extra-cost involved in validating the pre-confirmation on the proposer side which can take time and increase the risks of missing the slot.</p>
<h2><a class="anchor" href="https://ethresear.ch#alternatives-4" name="alternatives-4"></a>Alternatives</h2>
<h4><a class="anchor" href="https://ethresear.ch#adjusted-liveness-penalty-5" name="adjusted-liveness-penalty-5"></a>Adjusted Liveness Penalty</h4>
<p>Instead of using a minimal tip as a way to decide if it’s viable, the liveness penalty could be dynamically adjusted to what is the minimal viable condition. The tip could then be a fixed value.</p>
<h4><a class="anchor" href="https://ethresear.ch#user-defined-liveness-penalty-6" name="user-defined-liveness-penalty-6"></a>User-Defined Liveness Penalty</h4>
<p>The user sending the pre-confirmation could also decide both the liveness penalty and the tip as suggested in <a href="https://ethresear.ch/t/user-defined-penalties-ensuring-honest-preconf-behavior/19545">User-Defined Penalties: Ensuring Honest Preconf Behavior</a>, and adjust it to what the current state of the network is/what validators accept. The assumption here is maybe for some pre-confirmations the goal is to be as soon as possible on the L1, and so, reducing the liveness penalty would increase their probabilities of being pre-confirmed. On the other hand an arbitrage pre-confirmation could prefer to opt-in for a larger liveness penalty as its opportunity would be lost if the block is missed.</p>
<h2><a class="anchor" href="https://ethresear.ch#caveats-7" name="caveats-7"></a>Caveats</h2>
<p>This simple break-even model on the proposer side has no incentive, it is unclear if it will motivate proposers to opt-in.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/pre-confirmation-liveness-slashing-penalties-from-the-proposers-perspective/19884">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 11:44:23 +0000</pubDate>
</item>
<item>
<title>Blob Usage Strategies by Rollups and Non-rollup Applications</title>
<link>https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874</link>
<guid>https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874</guid>
<content:encoded><![CDATA[
<div> 关键词：rollup, non-rollup, blobs, type 3 transactions, cost-effectiveness

总结:
这篇文章深入研究了以太坊升级后type 3交易中携带blob的应用策略，主要关注rollup和non-rollup应用的差异。rollup应用倾向于根据自身需求选择不同的blob使用策略，如blob数量、利用率和提交频率，以平衡可用数据费用和延迟成本。非-rollup应用通常用于上传完整内容，其blob策略与rollup不同，交易频繁且单blob利用率较高。

文章分析了blob成本效益、gas价格波动对不同应用的影响，以及blob与块重组的关系。结果表明，虽然blob作为数据可用性解决方案通常更经济，但在某些情况下，calldata可能更便宜。此外，blob gas价格的短期波动主要受non-rollup应用驱动，而非rollup应用对价格变动的响应并不明显。

总结:<br />rollup和non-rollup应用的blob策略各有特点，rollup通过调整blob数量和利用率来平衡成本；non-rollup则以高频次、低利用率的方式使用blob。文章还探讨了blob成本、gas价格和块重组之间的关系，发现blob滥用的识别对设计反滥用机制至关重要。 <div>
<p><a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc">Full Report</a></p>
<h2><a class="anchor" href="https://ethresear.ch#tdlr-1" name="tdlr-1"></a>TDLR</h2>
<ol>
<li>The main applications using blobs are rollups, accounting for approximately 87%. Non-rollup applications mainly include <a href="https://blobscan.com/tx/0x3ff787f16ad6d65dc8d6e45a3ea95440fca2da2c0e344e76a6e509857673da01" rel="noopener nofollow ugc">Blobscriptions</a> and <a href="https://blobscan.com/tx/0x1956039b71bbc1c5de31ceafb27782eb2e8a07c9299d1d534e470bcf35f9835a" rel="noopener nofollow ugc">customized type 3 transactions</a>.</li>
<li>Rollup applications choose different blob usage strategies according to their own situations. The strategies will consider the number of blobs carried by type 3 transactions, blob utilization, and blob submission frequency to balance the costs of availability data fees and delay costs.</li>
<li>Non-rollup applications can be characterized and distinguished from rollup applications by the number of blobs carried by type 3 transactions, blob utilization, and blob submission frequency. These features help identify scenarios of blob abuse, allowing for the design of corresponding anti-abuse mechanisms.</li>
<li>In most cases, using blobs as a data availability solution is more cost-effective than calldata. However, there are a few scenarios where calldata is cheaper: blob gas price spikes and blob utilization is extremely low.</li>
<li>Short-term fluctuations in blob gas price is mainly influenced by the demand from non-rollup applications. Rollup applications have a relatively inelastic demand for blobs, so they do not significantly impact short-term fluctuations in blob gas prices.</li>
<li>Currently, rollup applications do not seem to consider blob gas price as a reference factor in their blob usage strategies.</li>
<li>The probability of blocks containing type 3 transactions being reorganized is extremely low. Additionally, carrying more blobs does not increase the probability of block reorganization. However, there is a clustering phenomenon in block height for blocks containing type 3 transactions.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>This report provides an in-depth analysis of type 3 transactions used for carrying blobs from the time of the Ethereum Decun upgrade until May 22, 2024. It focuses on blob usage strategies of rollup and non-rollup applications. The dataset, data processing programs, and visualization code for this report are <a href="https://github.com/doublespending/EIP-4844-Data-Analysis" rel="noopener nofollow ugc">open source</a>, detailed in the following “Dataset” section.</p>
<h2><a class="anchor" href="https://ethresear.ch#type-3-transactions-blobs-share-by-applications-3" name="type-3-transactions-blobs-share-by-applications-3"></a>Type 3 Transactions &amp; Blobs Share by Applications</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/1/9101b16c984217aa1e5a51a59e7c0024aa6e8e18.jpeg" title="image"><img alt="image" height="363" src="https://ethresear.ch/uploads/default/optimized/3X/9/1/9101b16c984217aa1e5a51a59e7c0024aa6e8e18_2_690x363.jpeg" width="690" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#rollup-applications-4" name="rollup-applications-4"></a>Rollup Applications</h3>
<p>Observations from Figure 1 on the proportion of type 3 transactions:</p>
<ul>
<li>Base, Scroll, Linea, and Starknet are in the same tier, having the highest transaction proportions.</li>
<li>Arbitrum, Optimism, and Zksync are in the next tier, having the second-highest transaction proportions.</li>
</ul>
<p>This phenomenon seems counterintuitive as Arbitrum and Optimism have higher TPS than Scroll, Linea, and Starknet and should have a higher proportion of type 3 transactions.</p>
<p>Figure 2 shows that counterintuitive phenomenon is caused by different rollup strategies in the number of blobs carried by type 3 transactions.</p>
<p>Observations from Figure 2 on the proportion of blobs:</p>
<ul>
<li>Base stands alone, having the highest proportion of blobs.</li>
<li>Arbitrum and Optimism are in the same tier, having the second-highest proportion of blobs.</li>
<li>Scroll, Linea, Starknet, and Zksync are in the same tier, having a medium proportion of blobs.</li>
</ul>
<p>This phenomenon aligns more with intuition: blob proportions are directly related to the scale of rollup’s availability data, thus showing a positive correlation with rollup TPS.</p>
<p>The difference between the proportion of type 3 transactions (31%) and blobs (14%) for non-rollup applications indicates that non-rollup applications and rollup applications have different needs.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-rollup-applications-5" name="non-rollup-applications-5"></a>Non-Rollup Applications</h3>
<ul>
<li>Rollup applications are B2B businesses aiming to fill fine-grained Layer 2 transaction availability data, so their type 3 transactions are not limited to carrying only 1 blob.</li>
<li>Non-rollup applications are B2C businesses aiming to upload complete text, images, etc., so their type 3 transactions usually carry only 1 blob to meet their needs.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#rollup-blob-usage-strategies-6" name="rollup-blob-usage-strategies-6"></a>Rollup Blob Usage Strategies</h2>
<h3><a class="anchor" href="https://ethresear.ch#rollup-strategy-model-7" name="rollup-strategy-model-7"></a>Rollup Strategy Model</h3>
<p>This section models the rollup blob usage strategies with</p>
<ol>
<li><code>blobNumber</code>, i.e. the number of blobs carried by type 3 transactions</li>
<li><code>blobUtilization</code>, i.e. blob space utilization</li>
<li><code>blobInterval</code>, i.e. the blob submission interval</li>
</ol>
<h4><a class="anchor" href="https://ethresear.ch#fee-cost-8" name="fee-cost-8"></a>Fee Cost</h4>
<p>The fee cost per transaction for rollups is expressed as:</p>
<div class="math">
\begin{equation}
feeCost = \frac{1}{k}(\frac{blobCost}{blobUtilization}+\frac{fixedCost}{blobNumber*blobUtilization})
\end{equation}
</div>
<ul>
<li><code>fixedCost</code>: the fixed cost of a type 3 transaction</li>
<li><code>blobCost</code>: the cost of a single blob</li>
<li>The larger the <code>blobUtilization</code>, the lower the amortized cost of the blob fee <span class="math">\frac{blobCost}{blobUtilization}</span> and the fixed cost <span class="math">\frac{fixedCost}{blobNumber*blobUtilization}</span>, resulting in a lower fee cost <code>feeCost</code>.</li>
<li>The larger the <code>blobNumber</code>, the lower the amortized cost of the fixed cost <span class="math">\frac{fixedCost}{blobNumber*blobUtilization}</span>, resulting in a lower fee cost <code>feeCost</code>.</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#delay-cost-9" name="delay-cost-9"></a>Delay Cost</h4>
<p><strong>The delay cost per transaction for rollups is expressed as:</strong></p>
<div class="math">
\begin{equation}
delayCost = F(\frac{blobNumber*blobUtilization*k}{tps})
\end{equation}
</div>
<ul>
<li>The larger the <code>blobUtilization</code>, the larger the delay cost <code>delayCost</code>.</li>
<li>The larger the <code>blobNumber</code>, the larger the delay cost <code>delayCost</code>.</li>
<li>The larger the <code>tps</code>, the smaller the delay cost <code>delayCost</code>.</li>
</ul>
<blockquote>
<p>The derivation of the formula can be found in the <a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc">full version</a>.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#rollup-strategy-analysis-10" name="rollup-strategy-analysis-10"></a>Rollup Strategy Analysis</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced.png" title="image"><img alt="image" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced_2_690x260.png" width="690" /></a></div><p></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/2/32521830fd7aab2cbd7f19d504720344afb2eff7.jpeg" title="image"><img alt="image" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/3/2/32521830fd7aab2cbd7f19d504720344afb2eff7_2_574x499.jpeg" width="574" /></a></div><p></p>
<h3><a class="anchor" href="https://ethresear.ch#non-rollup-blob-strategies-11" name="non-rollup-blob-strategies-11"></a>Non-Rollup Blob Strategies</h3>
<p>Rollup applications are B2B, while non-rollup applications are B2C. Therefore, non-rollup applications differ from the rollup strategy model. For non-rollup applications:</p>
<ul>
<li>The number of blobs carried by type 3 transactions depends on the size of the content (texts/images) stored in the blobs.</li>
<li>Blob utilization depends on the size of the content (texts/images) stored in the blobs.</li>
<li>Blob submission intervals depend on the immediate needs of C-end users, with no delay costs involved.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced.png" title="image"><img alt="image" height="260" src="https://ethresear.ch/uploads/default/optimized/3X/c/c/cc978c93e42157bd63c06de9c0637fc887dccced_2_690x260.png" width="690" /></a></div><p></p>
<ul>
<li>
<p>According to Figure 5 (<strong>Others</strong> ), 1 blob can meet the needs of most non-rollup applications.</p>
</li>
<li>
<p>According to Figure 6 (<strong>Others</strong> ), the blob utilization is concentrated between 20% and 40%, indicating that non-rollup applications generally cannot fill the blob, with the data size mainly between 25.6 kB and 51.2 kB.</p>
</li>
<li>
<p>According to Figure 7 (<strong>Others</strong> ), about 83% of blobs have a submission interval of less than 1 minute, indicating a relative high frequency of user demand for non-rollup applications.</p>
</li>
</ul>
<p>In summary, the type 3 transactions for non-rollup applications can be characterized as: <strong>high-frequency transactions carrying 1 low-utilization blob</strong> .</p>
<p>The essence of this characterization is that non-rollup applications are driven by immediate needs and are less concerned about the fee cost per data byte compared to rollup applications.</p>
<p>This characterization allows for the identification of non-rollup applications, which in turn helps design mechanisms to limit blob abuse by non-rollup applications.</p>
<h2><a class="anchor" href="https://ethresear.ch#is-using-blobs-always-more-cost-effective-than-calldata-12" name="is-using-blobs-always-more-cost-effective-than-calldata-12"></a>Is Using Blobs Always More Cost-effective than Calldata?</h2>
<p>Introducing <code>feeRatio</code> to measure the relative advantages of the two solutions:</p>
<div class="math">
\begin{equation}
feeRatio = \frac{calldataFeeCost }{blobFeeCost}
\end{equation}
</div>
<ul>
<li>When <code>feeRatio</code> ≥ 1, it indicates that using blobs as a data availability solution is not worse than calldata.</li>
<li>When <code>feeRatio</code> &lt; 1, it indicates that using blobs as a data availability solution is worse than calldata.</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/5/b5e1ca6b02490795bf2e742ecb92586d1b18e685.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/b/5/b5e1ca6b02490795bf2e742ecb92586d1b18e685_2_472x500.jpeg" width="472" /></a></div><p></p>
<p>Figure 8 also shows a few cases where <code>feeRatio</code> &lt; 1 (red), indicating that calldata is more cost-effective than blobs:</p>
<ul>
<li>Mostly in non-Rollup applications (<strong>Others</strong>):
<ul>
<li>Non-rollup applications generally do not care about the cost differences between blobs and calldata; they care about using blobs itself, such as in Blobscriptions.</li>
</ul>
</li>
<li>A few in Metal rollup:
<ul>
<li>Rollup application Metal seems not to have considered switching between blobs and calldata in its strategy, leading to suboptimal choices in some extreme cases.</li>
<li>Extreme cases are mainly due to Metal’s low blob utilization (see Figure 6) coinciding with a spike in blob gas prices.</li>
<li>However, given that extreme scenarios are rare and maintaining two data availability solutions is costly, Metal’s suboptimal strategy in extreme cases seems acceptable.</li>
</ul>
</li>
</ul>
<blockquote>
<p>The analysis of blob and calldata solutions in this section only considers fee costs and not delay costs. Considering delay costs, calldata has an actual advantage.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#blob-gas-price-and-blob-usage-strategies-13" name="blob-gas-price-and-blob-usage-strategies-13"></a>Blob Gas Price and Blob Usage Strategies</h2>
<h3><a class="anchor" href="https://ethresear.ch#analysis-of-blob-gas-price-fluctuations-14" name="analysis-of-blob-gas-price-fluctuations-14"></a>Analysis of Blob Gas Price Fluctuations</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/8/58dd45e0e206936eb5eb2b32fc343a70322254c1.jpeg" title="image"><img alt="image" height="363" src="https://ethresear.ch/uploads/default/optimized/3X/5/8/58dd45e0e206936eb5eb2b32fc343a70322254c1_2_690x363.jpeg" width="690" /></a></div><br />
Figures 9 and 10 show that in scenarios of high blob gas prices (&gt; 10), the proportion of non-rollup applications (<strong>Others</strong>) is significantly higher than in scenarios of low blob gas prices (&lt; 10).<p></p>
<p>Therefore, it can be concluded that the surge in blob gas prices is mainly driven by the demand from non-rollup applications, rather than rollup applications. Otherwise, the proportion of rollup and non-rollup applications should remain stable.</p>
<h3><a class="anchor" href="https://ethresear.ch#how-rollups-respond-to-blob-gas-price-fluctuations-15" name="how-rollups-respond-to-blob-gas-price-fluctuations-15"></a>How Rollups Respond to Blob Gas Price Fluctuations</h3>
<p><em>Hypothesis 1: The higher the blob gas price, to reduce fee costs, applications should carry more blobs in type 3 transactions, i.e., the number of blobs should be positively correlated with blob gas prices.</em><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/f/b/fb34ad1ab0fcf6250662d82b007a763309889ef7.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/f/b/fb34ad1ab0fcf6250662d82b007a763309889ef7_2_505x500.jpeg" width="505" /></a></div><p></p>
<p>Figure 14 shows that the hypothesis does not hold.</p>
<p><em>Hypothesis 2: The higher the blob gas price, to reduce fee costs, applications should increase blob utilization, i.e., blob utilization should be positively correlated with blob gas prices.</em><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/2/521bb465406b224d50b0117150169a5991c5029c.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/5/2/521bb465406b224d50b0117150169a5991c5029c_2_498x500.jpeg" width="498" /></a></div><p></p>
<p>Figure 15 shows that the hypothesis does not hold.</p>
<p><em>Hypothesis 3: The higher the blob gas price, to reduce fee costs, applications should delay blob submissions, i.e., blob submission intervals should be positively correlated with blob gas prices.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/e/9e1dd1bbb0bad1163b9eaf7f8d61f340279bb0fd.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/9/e/9e1dd1bbb0bad1163b9eaf7f8d61f340279bb0fd_2_514x500.jpeg" width="514" /></a></div><p></p>
<p>Figure 16 shows that the hypothesis does not hold.</p>
<blockquote>
<p>In Figures 9 and 10, readers might notice that some rollup applications seem to respond to high blob gas prices. Scroll seems to suspend blob submissions under high blob gas prices. However, this conclusion is incorrect. The reason is that not all rollups immediately used blobs after the EIP-4844 upgrade.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#blobs-and-block-reorg-16" name="blobs-and-block-reorg-16"></a>Blobs and Block Reorg</h2>
<p>From the Decun upgrade to May 22, there were 171 type 3 transactions included in the forked blocks and 348,121 included in the canonical blocks. Therefore, the proportion of type 3 transactions being forked is approximately 0.049%. This section explores the relationship between block reorg and blob.</p>
<h3><a class="anchor" href="https://ethresear.ch#blob-number-distribution-in-the-canonical-and-forked-blocks-with-blobs-17" name="blob-number-distribution-in-the-canonical-and-forked-blocks-with-blobs-17"></a>Blob Number Distribution in the Canonical and Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bef1c025b4ae7c6990e2c7968acf12a6eccba1a2.jpeg" title="image"><img alt="image" height="403" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bef1c025b4ae7c6990e2c7968acf12a6eccba1a2_2_690x403.jpeg" width="690" /></a></div><p></p>
<p><em>Hypothesis: More blobs increase the probability of block reorganizations.</em></p>
<p>If the hypothesis holds, the following inequality should be satisfied:</p>
<div class="math">
\begin{equation}
P(reorg|blob=n)  &gt; P(reorg|blob=n-1)
\end{equation}
</div>
<p>According to <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener nofollow ugc">Bayes’ theorem</a>, inequality above is equivalent to:</p>
<div class="math">
\begin{equation}
\frac{P(blob=n|reorg)}{P(blob=n)}  &gt; \frac{P(blob=n-1|reorg)}{P(blob=n-1)}
\end{equation}
</div>
<p>We check whether the actual data satisfies inequality and obtain the following table:<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/c/ec253f7881bbf00cf3b5a37a8635dfb0181309ee.png" title="image"><img alt="image" height="201" src="https://ethresear.ch/uploads/default/optimized/3X/e/c/ec253f7881bbf00cf3b5a37a8635dfb0181309ee_2_690x201.png" width="690" /></a></div><p></p>
<p>The table above shows that equation (10) does not hold for all <code>n</code>. Therefore, the hypothesis does not hold, indicating that more blobs are not significantly related to block reorganizations.</p>
<h3><a class="anchor" href="https://ethresear.ch#distribution-of-type-3-transactions-and-blobs-by-applications-in-the-canonical-and-forked-blocks-with-blobs-18" name="distribution-of-type-3-transactions-and-blobs-by-applications-in-the-canonical-and-forked-blocks-with-blobs-18"></a>Distribution of Type 3 Transactions and Blobs by Applications in the Canonical and Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/d/ddfc7f0d5d5b2a90aaf6efff87b6d7a3733c2aff.jpeg" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/d/d/ddfc7f0d5d5b2a90aaf6efff87b6d7a3733c2aff_2_425x500.jpeg" width="425" /></a></div><br />
Figures 18 and 19 show that the proportion of type 3 transactions/blobs for Zksync and Scroll in forked blocks is significantly higher than in the canonical blocks.<p></p>
<p>Applications seem to have some connection with block reorganizations, possibly related to differences in blob usage strategies by applications:</p>
<ul>
<li>Zksync and Scroll are less strategic in selecting the timing of submitting type 3 transactions, targeting block heights prone to reorganization.</li>
<li>The unique characteristics of Zksync and Scroll’s type 3 transactions make the blocks containing them more likely to be reorganized.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#clustering-phenomenon-of-forked-blocks-with-blobs-19" name="clustering-phenomenon-of-forked-blocks-with-blobs-19"></a>Clustering Phenomenon of Forked Blocks with Blobs</h3>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/2/8/281e3d3c49f900b77406ef467f2c32a1b08331eb.jpeg" title="image"><img alt="image" height="286" src="https://ethresear.ch/uploads/default/optimized/3X/2/8/281e3d3c49f900b77406ef467f2c32a1b08331eb_2_690x286.jpeg" width="690" /></a></div><br />
If each block has the same probability of being reorganized, the forked blocks should be evenly distributed across the block height range. However, Figure 20 shows a clustering phenomenon in block heights for forked blocks, possibly related to network conditions.<p></p>
<p>In addition, the clustering phenomenon that occurs in block reorganization seems to be somewhat related to the applications that submit blobs. For example, type 3 transactions for non rollup applications are only included in forked blocks between 19500000 and 19600000.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img class="site-icon" height="64" src="https://ethresear.ch/uploads/default/original/3X/3/0/30aea33d55bd45ce96fab5bf70ecd7a3d0178f9d.png" width="64" />

      <a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc" target="_blank">0xpantarhei.substack.com</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image"><img class="thumbnail" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/f/7/f7108d3b335a7303d071fa1c0b9afa898ea3fa24_2_690x345.jpeg" width="690" /></div>

<h3><a href="https://0xpantarhei.substack.com/p/blob-usage-strategies" rel="noopener nofollow ugc" target="_blank">Blob Usage Strategies by Rollups and Non-rollup Applications</a></h3>

  <p>This report provides an in-depth analysis of type 3 transactions used for carrying blobs.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both;"></div>
</aside>

            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/blob-usage-strategies-by-rollups-and-non-rollup-applications/19874">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 03:39:04 +0000</pubDate>
</item>
<item>
<title>Block Building is not just knapsack!</title>
<link>https://ethresear.ch/t/block-building-is-not-just-knapsack/19871</link>
<guid>https://ethresear.ch/t/block-building-is-not-just-knapsack/19871</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、块构建、NP-hard、贪婪算法、交易冲突

总结:
本文探讨了区块链中块构建的复杂性，通过将问题与背包问题和最大独立集问题关联，揭示其NP-hard性质。研究者提出几种贪婪算法，包括经典和改进版本，以及如何考虑交易间的冲突。实验结果显示，通过结合背包约束优化的贪婪算法比现有方法能多赚约15%的费用。文章还讨论了模型对以太坊矿工的实际意义，以及未来研究方向，如更精确的序列化问题和交易效用影响的建模。 <div>
<p>Authors: <a class="mention" href="https://ethresear.ch/u/mikerah">@Mikerah</a> Afonso <a class="mention" href="https://ethresear.ch/u/sarisht">@sarisht</a></p>
<p>Shoutout to Gabearro Ventalitan Nerla Yun Qi and Surya for all the vibes and discussions!</p>
<p>This project was done as a Hackathon Project at IC3 camp last week.</p>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h2>
<p>We present a formal model or block building in blockchains. We show that block building is at least a combination of the Knapsack problem and the Maximum Independent Set problem, thus showing that block building is an NP-hard problem. Next, we provide various greedy algorithms with different tradeoffs. Then, we show simulation results to justify the algorithms and benchmarks. Our results show that tweaking the greedy solution with the results of the known knapsack constraint outperforms the currently used greedy algorithm by ~15% in terms of fee earned. Finally, we discuss how this is relevant for block builders in Ethereum in practice and directions for future research.</p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>Block building in Ethereum has evolved into a multimillion-dollar industry, particularly with the introduction of MEV-Boost. This has significantly increased the revenue earned by the builders. However, the builders’ algorithm for selecting transactions and transaction bundles needs more study. In collaboration with Flashbots, Mikerah (group lead for the project) has recently worked on a project that <a href="https://collective.flashbots.net/t/frp-10-distributed-blockbuilding-networks-via-secure-knapsack-auctions/1955" rel="noopener nofollow ugc">formalizes the model for block building as a knapsack problem</a>. This model considers each transaction’s utility (the fee offered by the transaction) and cost (the gas used by the transaction), with a budget for the maximum price that can be paid (the gas limit for the block). The practical relevance of this research is evident, as it addresses a significant limitation of the current model, where not all transactions are independent of each other.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-problem-3" name="the-problem-3"></a>The Problem</h2>
<p>Let’s delve into the heart of the matter by examining why transactions are not independent, a key challenge in block building.</p>
<h3><a class="anchor" href="https://ethresear.ch#bitcoin-blockchain-4" name="bitcoin-blockchain-4"></a>Bitcoin Blockchain</h3>
<p>The most critical problem described in the Satoshi Nakamoto blockchain paper was catching double-spending. If two transactions try to spend the same UTXO, only one of them should make it on-chain. Thus, we can see that some transactions are dependent on each other. However, that is not all; some transactions that interact with Bitcoin’s OP-Code design can also depend on each other. A classic example of this would be that in an HTLC, either a refund transaction (released by revealing a pre-image of a hash) or payment (released when the timelock on the transaction expires) can go through. If both transactions are simultaneously in the mempool, then the transactions conflict with each other.</p>
<h3><a class="anchor" href="https://ethresear.ch#ethereum-blockchain-5" name="ethereum-blockchain-5"></a>Ethereum Blockchain</h3>
<p>Ethereum inherits the double-spending transaction problem, but owing to its smart contract and gas fee design, it only partially suffers from the other type of conflict since the fee is paid based on the gas used. This causes the model to shift slightly, where the fee paid and the gas used depends on other chain transactions. Further, in the presence of searchers, some transactions are bundled such that multiple bundles contain the same transaction and thus cannot be included in the block simultaneously.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-6" name="model-6"></a>Model</h2>
<p>We first introduce the assumptions we make before describing the mathematical formulations.</p>
<h4><a class="anchor" href="https://ethresear.ch#assumptions-7" name="assumptions-7"></a>Assumptions</h4>
<ul>
<li>Dependent fees and gas are hard to model since we cannot have a boolean representation. Thus, we only consider “Conflicts” and touch upon “Dependency.” Conflicts are situations in which the transactions cannot occur together, and dependency is when one transaction requires another transaction to be executed before it is valid.</li>
<li>We further ignore the optimal ordering of transactions inside a block. Ordering transactions in a particular order can lead to higher profits due to MEV, which we ignore for the same reason as above.</li>
<li>For Ethereum, under the conditions of EIP 1559, the fee considered is the part above the base fee. Any transaction with a negative fee is ignored.</li>
</ul>
<p>Given these assumptions, we now model the binary allocation problem with constraints and dependencies as follows:<br />
Let <span class="math">T</span> be the set of transactions. A transaction in <span class="math">T</span> is denoted by <span class="math">tx_i</span>.<br />
Let <span class="math">f_i</span> denote the fee associated with a transaction <span class="math">tx_i</span>.<br />
Let <span class="math">g_i</span> denote the gas associated with a transaction <span class="math">t_i</span><br />
Let <span class="math">B</span> be the maximum block gas limit.</p>
<p>Then, we have the following optimization problem<br />
Maximise</p>
<div class="math">
\sum_{i\in n} f_ix_i 
</div>
<p>Subject to</p>
<div class="math">
\begin{align*}
 &amp;\sum_{i\in n} x_ig_i \leq B \\
 &amp; x_i+x_j \leq C_{ij}, \forall i\neq j \in n\\
 &amp; x_j - x_i \leq M_{ij}, \forall i\neq j \in n\\
 &amp; x_i \in \{0,1\}
 \end{align*}
</div>
<p>where,</p>
<ul>
<li><span class="math">C_{ij} = 1</span> if <span class="math">t_i</span> and <span class="math">t_j</span> are conflicting transactions, 2 otherwise</li>
<li><span class="math">M_{ij} = 0</span> if <span class="math">t_j</span> depends on <span class="math">t_i</span> and can only be allocated after <span class="math">t_i</span>, 1 otherwise</li>
</ul>
<p>Since, in practice, it is hard for a block builder to infer the 3rd condition (without executing all of the transactions) within a limit snapshot of the transactions within their order flow pools, we can omit the 3rd constraint to simplify the problem. If the builder comes across such a transaction, it would be considered invalid.</p>
<p>As such, we can obtain the following simplified optimization problem<br />
Maximise</p>
<div class="math">
\sum_{i\in n} f_ix_i
</div>
<p>Subject to</p>
<div class="math">
\begin{align*}
 &amp;\sum_{i\in n} x_ig_i \leq BL \\
 &amp; x_i+x_j \leq C_{ij}, \forall i\neq j \in n\\
 &amp; x_i \in \{0,1\}
 \end{align*}
</div>
<p>where,</p>
<ul>
<li><span class="math">C_{ij} = 1</span> if <span class="math">t_i</span> and <span class="math">t_j</span> are conflicting transactions, 2 otherwise</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#reductions-8" name="reductions-8"></a>Reductions</h3>
<p>Now, we present formal arguments as to why block building is an instance of the knapsack problem and the maximum independent set problem.</p>
<h4><a class="anchor" href="https://ethresear.ch#reduction-to-knapsack-9" name="reduction-to-knapsack-9"></a>Reduction to knapsack</h4>
<p>The reduction of the above problem to knapsack is easy to see. We assume no conflicts arise amongst any transactions. In that case, the problem is the same as solving a knapsack problem, with the utility as the fee paid by the transaction, space occupied as the gas used by a transaction, and finally, the block’s gas limit determines the knapsack size. Thus, the block-building problem is at least as hard as the knapsack problem.</p>
<h4><a class="anchor" href="https://ethresear.ch#reduction-to-maximum-independent-set-10" name="reduction-to-maximum-independent-set-10"></a>Reduction to Maximum Independent Set</h4>
<p>If we can solve the above instance of block building problem without any constraint that limits the size of the block in polynomials, then consider the following instance where the block gas limit is set to the sum of gas of all transactions in the mempool. This would imply enough space for all the transactions in the mempool to fit in the block. This problem is now equivalent to finding the maximum weighted independent set because we can consider all transactions as vertices, and an edge exists between two vertices if the corresponding transactions conflict. The above reduction creates the instantiation of the maximum weighted independent set problem, which is again known as NP-hard.</p>
<h2><a class="anchor" href="https://ethresear.ch#algorithms-for-approximate-result-11" name="algorithms-for-approximate-result-11"></a>Algorithms for approximate result</h2>
<p>As we mentioned above, block building is an NP-hard problem with reductions to both the knapsack problem and the maximum weighted independent set problem. Since we know that the maximum weighted independent set problem doesn’t have a C-approximation, this implies that the block-building problem also doesn’t have a C-approximation.</p>
<p>As such, we devise several greedy algorithms in order to solve the block-building problem in practice.</p>

<h3><a class="anchor" href="https://ethresear.ch#greedy-classic-gc-12" name="greedy-classic-gc-12"></a>Greedy Classic (GC)</h3>
<p>We expect today’s builders to use the first algorithm we present. It follows the most widely used knapsack greedy solution, where all objects are sorted according to the ratio of their utility to cost, and then greedily allocate space to each object until you can no longer allocate more space. Due to the added conflict constraint, the builder must check for conflict with any transaction already added to the block. Thus, the algorithm works as follows:</p>
<p>Algorithm input: <span class="math">T = \{t_i\}, F = \{f_i\}, G = \{g_i\}</span><br />
Algorithm output: An ordered block with gas used less than BL<br />
Algorithm description:</p>
<pre><code class="lang-auto">Sort T by corresponding F/G
Let B  := {}
Let BS := 0
For each t in T, f in F, g in G do:
    if t has any conflict with tx in B: continue;
    if g + BS &lt; BL: B.append(t); BS += g
return B
</code></pre>
<p>In practice, the conflict between transactions is only known if simulated sequentially. We propose two constraints on how this conflict can be modeled.</p>
<ul>
<li>Two transactions <span class="math">t_1</span> and <span class="math">t_2</span> conflict if the transactions cannot be executed together. This can happen if some address is trying to double-spend some money it has or if two searcher bundles try to extract MEV from the transaction. We call this conflict a “Real” conflict.</li>
<li>Two transactions <span class="math">t_1</span> and <span class="math">t_2</span> conflict if they interact with the same address. We call this conflict an “All” condition. These transactions do not necessarily invalidate each other. Still, we keep this as a potential conflict condition since this conflict is more straightforward to determine (constant size operation) than the other constraint (gas size operation), and thus can be helpful for builders optimizing based on the time computing is used.</li>
</ul>
<p>Note: In the solution simulation, we assume that <span class="math">p=0.95</span> of transactions in the “All” conflict are not in the “Real” conflict.</p>
<p>Based on the definition of conflicts, we present the two baseline greedy solutions, which we label CG All and CG Real.</p>
<h2><a class="anchor" href="https://ethresear.ch#knapsack-greedy-13" name="knapsack-greedy-13"></a>Knapsack Greedy</h2>
<p>The greedy solution described above is not a good approximation solution. Looking back at the knapsack problem, we get a 1/2 approximation over the optimal solution by comparing the above classic greedy with the utility of the first object that was not allocated.</p>
<p>The algorithm begins by running an instance of the greedy classic. It then finds the highest paying (highest f/g) transaction and adds it to the block. Adding this transaction would require modification of the block since some transactions in block (B) conflicted with this transaction, or the transaction could not be inserted due to insufficient space. Thus, we remove transactions that conflict with this new addition and then make enough space to add this transaction. After inserting the transaction, we repeat the greedy insertion until the block is again full. We repeat the above algorithm until we have seen each transaction at least once over the greedy solution.</p>
<p>The pseudocode for the solution is as follows:</p>
<pre><code class="lang-auto">Sort T by corresponding F/G
Let B  := {}
Let B_f:= {}
Let S  := {}
Let BS := 0
while S != T: 
    let t := t in T, not in S, with maximum f/g:
    remove any transaction from B that conflicts with t.
    remove smallest f/g txs until there is space to insert t.
    B.append(t)
    S.append(t)
    For each t in T, f in F, g in G do:
        if t has any conflict with tx in B: continue;
        if g + BS &lt; BL: B.append(t); BS += g; S.append(t)
    if sum(B.f) &gt; sum(B_f.f): B_f = B

return B_f

# B.f is the fee corresponding to each transaction in B
</code></pre>
<p>In this greedy protocol, we attempt to enforce the inclusion of a transaction every time. It is still distinct from the greedy knapsack 1/2 approximation, but it tries to replicate what was accomplished by the knapsack greedy but for all items not picked by the greedy algorithm.</p>
<p>This solution will outperform its classic greedy counterpart since it computes maximum over all solutions, one of which is the classic greedy solution. Like the classic greedy solution, we analyze this when conflicts are “Real” and “All”.</p>
<h2><a class="anchor" href="https://ethresear.ch#classic-greedy-informed-solutions-14" name="classic-greedy-informed-solutions-14"></a>Classic Greedy Informed Solutions</h2>
<p>Solving the knapsack problem is very easy compared to all known NP-Hard problems, especially the maximum independent set condition we have been imposing. Thus, we allow the builder to solve the knapsack reasonably accurately and quickly via a BLP solver. The knapsack solution gives the builder some idea about how to build the block, and then when there are conflicting transactions in the chosen block, the “later” transactions are discarded. In this solution, we run a knapsack LP solution. On the output of the LP, we sort the output based on i) f/g ratio ii) f, and finally iii) g. The way greedy works here is that the transactions are picked in the order of the metric, and whenever there is a conflict, the LP solver is recalled, but removing constraints on the already added and the conflicting transaction (<span class="math">x_i</span> is set to 1 for all that have already been chosen and <span class="math">x_i</span> is set to 0 for the conflicting transaction). This is repeated until the block is full.</p>
<pre><code class="lang-auto">Let B  := {}
Let B_c:= {nil}
Let BS := 0
Let C  := {}
while B_c != B:
    B_c = LP.solve(sum(x.f), x.g &lt;= BL, C)
    Sort B_c by "heuristic"
    for t in B_c:
        if t has any conflict with tx in B: 
            C.add(x_t = 0)
            break;
        B.append(t)
        C.add(x_t = 1)

return B


# Replace "heurestic" by f/g for standard, 
                       f for high-value 
# Sorting is in descending order 
</code></pre>
<p>We label these transactions as CGI-f/g and CGI-f. We only analyze the “All” conflicts for this since the time to run the algorithm is potentially higher than for the other Greedy Algorithms.</p>
<h2><a class="anchor" href="https://ethresear.ch#simulation-15" name="simulation-15"></a>Simulation</h2>
<p>Due to our limited time to work on the project, we tried to replicate the transaction data synthetically instead of working with real transactions. To properly simulate Ethereum mempool transactions, we choose the following dataset:</p>
<h3><a class="anchor" href="https://ethresear.ch#dataset-16" name="dataset-16"></a>Dataset</h3>
<p>We choose 2000 transactions under this distribution.</p>
<ul>
<li>80%: SMALL: g ~ N(24k, 3k)  f/g ~ N(16,4) - These low gas-consuming transactions have minimal smart contract interactions and thus use less gas. In almost all cases, the gas fees for these transactions are small since they are usually never a priority transaction.</li>
<li>18%  : LARGE1: g ~ N(200k, 20K)  f/g ~ N(16,4) - These represent transactions that have a significant contract execution; however, in this case, these are still not priority transactions, since the user is okay to wait for some time for the contract execution.</li>
<li>2%  : LARGE2: g ~ N(200k, 20K)  f/g ~ N(40,10) - These are the priority transactions. Usually, these have high gas usage since they mostly interact with, for example, DeFi contracts and want to be executed as soon as possible.</li>
</ul>
<p>We simulate the conflicts among these transactions by randomly choosing transactions such that each transaction has a <span class="math">\sigma</span> number of conflicts. While our preliminary results constitute the same <span class="math">\sigma</span> across all types of transactions, in practice, the larger transactions, especially the high-paying ones, would have a more significant number of conflicts since usually MEV extracting bundles would be constructed around them.</p>
<h3><a class="anchor" href="https://ethresear.ch#results-17" name="results-17"></a>Results</h3>
<p>We ran our simulation over 100 blocks with the mempool created as above.</p>
<p>When we consider <span class="math">\sigma=2</span> number of conflicts per transaction, we see the following results:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/5/45d6ba5351f45cbc8f51bd30a3637d3f1554c6f5.png" title="s2feeratio"><img alt="s2feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/4/5/45d6ba5351f45cbc8f51bd30a3637d3f1554c6f5_2_668x499.png" width="668" /></a></div><br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/4/1430b955e746ba6faf056ac169b049c0e3dded9a.png" title="s2wastedgas"><img alt="s2wastedgas" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/1/4/1430b955e746ba6faf056ac169b049c0e3dded9a_2_668x499.png" width="668" /></a></div><p></p>
<p>Increasing the number of conflicts each transaction had increases the problem’s difficulty. Therefore, the various greedy algorithms have a larger separation in performance:</p>
<p>For <span class="math">\sigma = 10</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/e/ae043667cfb292234612d06e14e402d2cc86b268.png" title="s10feeratio"><img alt="s10feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/a/e/ae043667cfb292234612d06e14e402d2cc86b268_2_668x499.png" width="668" /></a></div><p></p>
<p>For <span class="math">\sigma = 20</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/9/79e0d8ad31f56fcb617c858775285e5e6b5b28fb.png" title="s20feeratio"><img alt="s20feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/7/9/79e0d8ad31f56fcb617c858775285e5e6b5b28fb_2_668x499.png" width="668" /></a></div><p></p>
<p>For <span class="math">\sigma = 40</span>,<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/3/e333c84dc6daa57f54481113545d081b8bb2af91.png" title="s40feeratio"><img alt="s40feeratio" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/e/3/e333c84dc6daa57f54481113545d081b8bb2af91_2_668x499.png" width="668" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#future-research-direction-18" name="future-research-direction-18"></a>Future Research Direction</h2>
<p>Based on our results, solving the block-building problem is an NP-Hard problem, and as long as conflicts exist amongst the transactions, it remains a complex problem.</p>
<p>However, this does not mean that all hope is lost. The block-building problem may have more potential than the Maximum Independent Set problem. Combining the space of Knapsack and Maximum Independent Set gives us a smaller search space to find a satisfactory approximate solution for the issue at hand.</p>
<p>Further, for Ethereum bundles from searchers, if <span class="math">tx_i</span> and <span class="math">tx_j</span> conflict, as well as <span class="math">tx_j</span> and <span class="math">tx_k</span> conflict, then there is a high likelihood that <span class="math">tx_i</span> and <span class="math">tx_k</span> also conflict. This eases the constraints on the solution since, amongst an all-2-all graph of transactions, for MIS, you only need to pick the transaction with the highest utility (also satisfying knapsack).</p>
<p>Another thing to note is that our algorithms can inform how block builders construct blocks in practice. Notably, the Classical Greedy Informed algorithm, in which we sort the transactions by highest fee, is closest to the optimal solution.</p>
<p>That being said, the most exciting extension to this research would be modeling the block-building problem as a job sequencing problem instead and somehow estimating how utility (fee+MEV) from one transaction affects the utility of other transactions sequenced after the first transaction.</p>
<p>On that note, we invite potential collaborators to explore new ideas for building blocks that maximize the builders’ utility.</p>
            <p><small>7 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/block-building-is-not-just-knapsack/19871">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 17:35:36 +0000</pubDate>
</item>
<item>
<title>Fork-Choice enforced Inclusion Lists (FOCIL): A simple committee-based inclusion list proposal</title>
<link>https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870</link>
<guid>https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870</guid>
<content:encoded><![CDATA[
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/6/3/639a5b7de796701a13a5759e8f5a1fe393f067f3.jpeg" title="DALL·E 2024-06-05 14.58.08 - A highly realistic illustration of a rock with the Ethereum symbol fossilized into it, set in a cave. The rock should appear weathered and ancient, wi"><img alt="DALL·E 2024-06-05 14.58.08 - A highly realistic illustration of a rock with the Ethereum symbol fossilized into it, set in a cave. The rock should appear weathered and ancient, wi" height="394" src="https://ethresear.ch/uploads/default/optimized/3X/6/3/639a5b7de796701a13a5759e8f5a1fe393f067f3_2_690x394.jpeg" width="690" /></a></div><br />
<em>^focil =&gt; fossil =&gt; protocol ossification</em><p></p>
<p><em>by <a href="https://ethresear.ch/u/soispoke/summary">Thomas</a>, <a href="https://ethresear.ch/u/fradamt/summary">Barnabé</a>, <a href="https://ethresear.ch/u/fradamt/summary">Francesco</a> and <a href="https://ethresear.ch/u/julian/summary">Julian</a></em> - June 19th, 2024</p>
<p><em>This design came together during a small, week long, in-person gathering in Berlin with RIG and friends to discuss censorship resistance, issuance, and Attester-Proposer-Builder-Consensus-Execution-[insert here] Separation.</em></p>
<p><em>Thanks to Luca, Terence, Toni, Ansgar, Alex, Caspar and Anders for discussions, feedback and comments on this proposal.</em></p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a><strong>tldr</strong></h1>
<p>In this post, we introduce Fork-Choice enforced Inclusion Lists (FOCIL), a simple committee-based IL design.</p>
<p>FOCIL is built in three simple steps:</p>
<ol>
<li>Each slot, a set of validators is selected to become <strong>IL committee members.</strong> Each member gossips one <em>local inclusion list</em> according to their subjective view of the mempool.</li>
<li><strong>The block proposer</strong> collects and aggregates available local inclusion lists into a concise <em>aggregate</em>, which is included in its block.</li>
<li><strong>The attesters</strong> evaluate the quality of the <em>aggregate</em> given their own view of the gossiped local lists to ensure the block proposer accurately reports the available local lists.</li>
</ol>
<p>This design ensures a robust and reliable mechanism to uphold Ethereum’s censorship resistance and <a href="https://ethresear.ch/t/uncrowdable-inclusion-lists-the-tension-between-chain-neutrality-preconfirmations-and-proposer-commitments/19372">chain neutrality</a> properties, by guaranteeing timely transaction inclusion.</p>
<h1><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h1>
<p>In an effort to shield the Ethereum validator set from centralizing forces, the right to build blocks has been auctioned off to specialized entities known as builders. Over the past year, this has resulted in a few sophisticated builders dominating the network’s block production. Economies of scale have further entrenched their position, making it increasingly difficult for new entrants to gain significant market share. A direct consequence of oligopolistic block production is a deterioration of the network’s (weak) censorship resistance properties. Today, <a href="https://censorship.pics/" rel="noopener nofollow ugc">two of the top three builders</a> are actively filtering out transactions interacting with sanctioned addresses from their blocks. In contrast, 90% of the <a href="https://www.ethernodes.org/countries" rel="noopener nofollow ugc">more decentralized and heterogeneous validator set</a> is not engaging in censorship.</p>
<p>This has driven <a href="https://github.com/michaelneuder/mev-bibliography?tab=readme-ov-file#censorship-resistance" rel="noopener nofollow ugc">research</a> toward ways that allow validators to impose constraints on builders by force-including transactions in their blocks. These efforts recently culminated in the first practical implementation of forward <span class="math">\text{ILs}</span> (<span class="math">\text{fILs}</span>) being considered for inclusion in the upcoming Pectra fork (see <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">design</a>, <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP</a>, and <a href="https://notes.ethereum.org/@mikeneuder/il-spec-overview" rel="noopener nofollow ugc">specs</a> <a href="https://gist.github.com/michaelneuder/ba32e608c75d48719a7ecba29ec3d64b" rel="noopener nofollow ugc">here</a>). However, some concerns were raised about the specific mechanism proposed in <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a>, leading to its rejection.</p>
<p>Here, we introduce FOCIL, a simple committee-based design improving upon previous IL mechanisms (<a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">Forward ILs</a>, <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a>) or co-created blocks (<a href="https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777">CBP</a>) and addressing issues related to <a href="https://ethresear.ch/t/fun-and-games-with-inclusion-lists/16557">bribing/extortion attacks</a>, IL equivocation, <a href="https://ethereum.org/en/roadmap/account-abstraction/" rel="noopener nofollow ugc">account abstraction</a> (AA) and incentive incompatibilities. Note also Vitalik’s recent proposal “<a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">One-bit-per-attester inclusion lists</a>”, where the committee chosen to build the list is essentially the whole set of attesters.</p>
<h1><a class="anchor" href="https://ethresear.ch#design-3" name="design-3"></a><strong>Design</strong></h1>
<p>In this section, we introduce the core properties of the FOCIL mechanism (see <strong>Figure 1.</strong>).</p>
<h2><a class="anchor" href="https://ethresear.ch#high-level-overview-4" name="high-level-overview-4"></a><strong>High-level overview</strong></h2>
<p>Each slot, a set of validators is randomly selected to become part of an inclusion list (<span class="math">\text{IL}</span>) committee. <span class="math">\text{IL}</span> committee members are responsible for creating local inclusion lists (<span class="math">\text{IL}_\text{local}</span>) of transactions pending in the public mempool. Local <span class="math">\text{ILs}</span> are then broadcast over the global topic, and the block producer must include a canonical aggregate (<span class="math">\text{IL}_\text{agg}</span>) of transactions from the collected local <span class="math">\text{ILs}</span> in its block <span class="math">B</span>. The quality of <span class="math">\text{IL}_\text{agg}</span> is checked by attesters, and conditions the validity of block <span class="math">B</span>.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/e/bedfe43a4319b8ef24f99db6089793aeda7dc3fb.png" title="Screenshot 2024-06-04 at 15.58.51"><img alt="Screenshot 2024-06-04 at 15.58.51" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/b/e/bedfe43a4319b8ef24f99db6089793aeda7dc3fb_2_690x375.png" width="690" /></a></div><p></p>
<blockquote>
<p><strong>Figure 1.</strong> Diagram illustrating the FOCIL mechanism.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#mechanism-5" name="mechanism-5"></a><strong>Mechanism</strong></h2>
<ul>
<li><strong>Validator Selection and Local Inclusion Lists</strong>
<ul>
<li>A set of validators is selected from the beacon committee to become <span class="math">\text{IL}</span> committee members for slot <span class="math">n</span>. This set is denoted as <span class="math">\text{IL}_\text{committee}(n) = \{ 1, \dots, m \}</span>, where <span class="math">m</span> is the number of <span class="math">\text{IL}</span> committee members.</li>
<li>Each <span class="math">\text{IL}</span> committee member <span class="math">i \in \text{IL}_\text{committee}(n)</span> releases a local <span class="math">\text{IL}</span>, resulting in a set of local <span class="math">\text{ILs}</span> for slot <span class="math">n</span>, defined as <span class="math">\text{IL}_\text{local}(n) = \{ \text{IL}_1, \dots, \text{IL}_m \}</span>.</li>
<li>Each local <span class="math">\text{IL}_i</span> contains transactions: <span class="math">\text{IL}_i = \{ \text{tx}^1_i, \dots, \text{tx}^{j_i}_i \}</span>, where each <span class="math">\text{tx}</span> is represented as  <span class="math">\text{tx} = (\text{tx}[\text{From}], \text{tx}[\text{Gas Limit}])</span>, and  <span class="math">j_i</span> indicates the number of transactions in <span class="math">\text{IL}_i</span>. The <code>From</code> field represents the sender’s address, and the <code>Gas Limit</code> field represents the maximum gas consumed by a transaction. This is used to check whether a transaction can be included in a block given the <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">conditional</a> IL property.</li>
</ul>
</li>
<li><strong>Block Producer’s Role</strong>
<ul>
<li>The block producer of slot <span class="math">n</span>, denoted <span class="math">\text{BP}(n)</span>, must include an <span class="math">\text{IL}</span> aggregate denoted <span class="math">\text{IL}_\text{agg}</span> and a payload in their block  <span class="math">B = (B[\text{IL}_\text{agg}], B[\text{payload}])</span>.</li>
<li><span class="math">\text{IL}_\text{agg}</span> consists of transactions: <span class="math">\text{IL}_\text{agg} = \{ \text{tx}^1_\text{agg}, \dots, \text{tx}^{t_\text{agg}}_\text{agg} \}</span> where each transaction <span class="math">\text{tx}_\text{agg}</span> is defined as <span class="math">(\text{tx}_\text{agg}[\text{tx}], \text{tx}_\text{agg}[\text{bitlist}])</span>, and the <span class="math">\text{payload}</span> must include transactions present in the <span class="math">\text{IL}_\text{agg}</span>.</li>
<li>The bitlist <span class="math">\text{tx}_\text{agg}[\text{bitlist}] \in \{0, 1\}^m</span> indicates which local $\text{IL}$s included a given transaction.</li>
<li>The function <span class="math">\text{Agg}</span> takes the set of available local ILs <span class="math">\text{IL}_\text{local}(n)</span> and outputs a “canonical” aggregate. The proposer aggregate <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> is included in block <span class="math">B</span>, and each attester evaluates it quality by comparing it against its own <span class="math">\text{IL}_\text{agg}^\text{attester}</span>, using the function <span class="math">\text{Eval}(\text{IL}_\text{agg}^\text{attester}, \text{IL}_\text{agg}^\text{proposer}, Δ) \in \{ \text{True}, \text{False} \}</span>.</li>
</ul>
</li>
<li><strong>Attesters’ Role</strong>
<ul>
<li>Attesters for slot <span class="math">n</span> receive the block <span class="math">B</span> and apply a function <span class="math">\text{Valid}(B)</span> to determine the block validity.</li>
<li><span class="math">\text{Valid}</span> encodes the block validity according to the result of <span class="math">\text{Eval}</span>, as well as core IL properties such as <a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">conditional vs. unconditional</a>.</li>
<li>Here are some scenarios to illustrate <span class="math">\text{IL}</span>-dependent validity conditions:
<ul>
<li>If local <span class="math">\text{ILs}</span> are made available before deadline <span class="math">d</span>, but the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is considered invalid.</li>
<li>If no local <span class="math">\text{ILs}</span> are made available before deadline <span class="math">d</span>, and the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is considered valid.</li>
<li>If block <span class="math">B</span> is full, local $\text{IL}$s were available before <span class="math">d</span>, and the proposer doesn’t include an <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>, block <span class="math">B</span> is still considered valid.</li>
<li>If <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> doesn’t overlap with most of attesters’ <span class="math">\text{IL}_\text{agg}^\text{attester}</span> according to <span class="math">\text{Eval}</span>, block <span class="math">B</span> is considered invalid.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>The core FOCIL mechanism could be defined as:</strong></p>
<div class="math">
\mathcal{M}_\text{FOCIL}= (\text{Agg}, \text{Eval}, \text{Valid})
</div>
<h2><a class="anchor" href="https://ethresear.ch#timeline-6" name="timeline-6"></a>Timeline</h2>
<p>The specific timing is given here as an example, but more research is required to figure out which numbers make sense.</p>
<ul>
<li><strong>Slot</strong> <span class="math">n-1</span><strong>,</strong> <span class="math">t = 6</span><strong>:</strong> The <span class="math">\text{IL}</span> committee releases their local <span class="math">\text{ILs}</span>, knowing the contents of block <span class="math">n-1</span>.</li>
<li><strong>Slot</strong> <span class="math">n-1</span><strong>,</strong> <span class="math">t=9</span><strong>:</strong> There is a local <span class="math">\text{IL}</span> freeze deadline <span class="math">d</span> after which everyone locks their view of the observed local <span class="math">\text{ILs}</span>. The proposer broadcast the <span class="math">\text{IL}_\text{agg}</span> over the global topic.</li>
<li><strong>Slot</strong> <span class="math">n</span><strong>,</strong> <span class="math">t=0</span><strong>:</strong> The block producer of slot <span class="math">n</span> releases their block <span class="math">B</span> which contains both the payload and aggregated <span class="math">\text{IL}_\text{agg}</span>.</li>
<li><strong>Slot</strong> <span class="math">n</span><strong>,</strong> <span class="math">t=4</span><strong>:</strong> The attesters of slot <span class="math">n</span> vote on block <span class="math">B</span>, deciding whether <span class="math">\text{IL}_\text{agg}</span> is “good enough” by comparing the result of computing the <span class="math">\text{Agg}</span> function over their local view of available local <span class="math">\text{ILs}</span> (applying <span class="math">\text{Eval}</span>) and checking if block <span class="math">B</span> is <span class="math">\text{Valid}</span>.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#aggregation-evaluation-and-validation-functions-7" name="aggregation-evaluation-and-validation-functions-7"></a><strong>Aggregation, Evaluation and Validation Functions</strong></h2>
<p>As mentioned in the mechanism section, FOCIL relies on three core functions. Each of these needs to be specified to ensure the mechanism fulfils its purpose.</p>
<ul>
<li>
<p><strong>The <span class="math">\text{Agg}</span> function</strong> is probably the most straightforward to define: Transactions from all collected local <span class="math">\text{ILs}</span> should be deterministically aggregated and deduplicated to construct <span class="math">\text{IL}_\text{agg}</span>. We let:</p>
<ul>
<li><span class="math">\text{IL}_\text{local} = \{\text{IL}_1, \text{IL}_2, \ldots, \text{IL}_m\}</span> be the set of local inclusion lists collected from committee members <span class="math">m</span>.</li>
<li>Each <span class="math">\text{IL}_i = \{\text{tx}_i^1, \text{tx}_i^2, \ldots, \text{tx}_i^{t_i}\}</span><br />
be the transactions in the local inclusion list of the <span class="math">i</span>-th committee member.</li>
<li>Each transaction <span class="math">\text{tx}</span> be defined by <span class="math">(\text{hash}, \text{sender}, \text{nonce})</span></li>
</ul>
<p><span class="math">\text{Agg}(\text{IL}_\text{local})</span>  can be thus defined as:</p>
<div class="math">
\text{Agg}(\text{IL}_\text{local}) = {\text{tx} | \text{tx} \in \bigcup_{i \in m} \text{tx}_{i} }
</div>
</li>
<li>
<p><strong>The <span class="math">\text{Eval}</span> function</strong> is used by each slot <span class="math">n</span> attester to assess the quality of the <span class="math">\text{IL}_\text{agg}</span> included in block <span class="math">B</span>. Each attester calculates the <span class="math">\text{Agg}</span> function over all local <span class="math">\text{ILs}</span> they have observed in their view and then compares their generated <span class="math">\text{IL}_\text{agg}^\text{attester}</span> to the one included by the proposer <span class="math">\text{IL}_\text{agg}^\text{proposer}</span>. The <strong><span class="math">\text{Eval}</span></strong> function can then be defined so that the proposer’s <span class="math">IL_{\text{agg}}^{\text{proposer}}</span> is valid if it includes a sufficient proportion of transactions observed by the attesters, as defined by the parameter <span class="math">Δ</span>:</p>
<div class="math">
\text{Eval}(IL_{\text{agg}}^{\text{attester}}, IL_{\text{agg}}^{\text{proposer}}, \Delta) = 
\begin{cases} 
\text{True} &amp; \text{if } \frac{|IL_{\text{agg}}^{\text{attester}} \cap IL_{\text{agg}}^{\text{proposer}}|}{|IL_{\text{agg}}^{\text{attester}}|} \geq \Delta \\
\text{False} &amp; \text{otherwise}
\end{cases}
</div>
<p><em>Note that the <span class="math">\text{Eval}</span> function, and especially its parameter <span class="math">Δ</span>, will determine the trade-off between <strong>(1) the quality</strong> of the <span class="math">\text{IL}_\text{agg}^\text{proposer}</span> and the agency we are willing to give to proposers, and <strong>(2)</strong> <strong>liveness</strong>, as we might see an increase in missed slots if the criteria are set too strictly.</em></p>
</li>
<li>
<p><strong>The <span class="math">\text{Valid}</span> function</strong> encodes whether the  <span class="math">\text{IL}_\text{agg}</span> conforms to pre-defined core <span class="math">\text{IL}</span> properties, such as:</p>
<ul>
<li><strong>Conditional vs. Unconditional</strong>: Should the proposer include as many <span class="math">\text{IL}</span> transactions in the block as possible as long as there is space left, or is there dedicated block space reserved for <span class="math">\text{IL}</span> transactions?</li>
<li><strong>Where-in-block</strong>: Where should <span class="math">\text{IL}</span> transactions be included in the block? Should they be placed anywhere, at the top of the block, or at the end of the block?</li>
<li><strong>Expiry</strong>: How long do transactions remain in the <span class="math">\text{IL}</span> once they have been included? What happens if a slot is skipped?</li>
</ul>
</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#more-rules-8" name="more-rules-8"></a><strong>More rules</strong></h2>
<p>In the following section, we introduce other rules that could be added to the core mechanism to specify:</p>
<ul>
<li>How users should pay for having their transactions included (<span class="math">\text{Payment}</span>)</li>
<li>How rewards can be distributed across FOCIL participants (<span class="math">\text{Reward}</span>)</li>
<li>How local <span class="math">\text{ILs}</span> are constructed (<strong><span class="math">\text{Inclusion}</span></strong>)</li>
<li>Interactions between <span class="math">\text{IL}</span> and payload transactions (<span class="math">\text{Priority}</span>).</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#user-bidding-textpayment-and-textreward-rules-9" name="user-bidding-textpayment-and-textreward-rules-9"></a><strong>User Bidding,</strong> <span class="math">\text{Payment}</span> <strong>and</strong> <span class="math">\text{Reward}</span> <strong>rules</strong></h3>
<ul>
<li>Users place bids based on the value they assign to having their transactions included in block <span class="math">B</span>. They need to take into consideration the FOCIL mechanism <span class="math">\mathcal{M}_\text{FOCIL}</span>, but also how the <a href="https://eips.ethereum.org/EIPS/eip-1559" rel="noopener nofollow ugc">EIP-1559</a> mechanism works to set their base fees, denoted <span class="math">\mathcal{M}_\text{1559}</span>. For instance, a user <span class="math">t</span> makes a bid <span class="math">b^t(v^t, \mathcal{M}_\text{FOCIL},\mathcal{M}_\text{1559}) = (\delta^t, f^t)</span>, where <span class="math">\delta^t</span> is the maximum priority fee and <span class="math">f^t</span> is the maximum total fee (i.e., base fee <span class="math">r</span> + priority fee <span class="math">\delta^t</span>).</li>
<li>The vector of bids from all users is denoted as <span class="math">\mathbf{b} = (b^1, b^2, \dots, b^T)</span>, where each <span class="math">b^t</span> represents the bid from user <span class="math">t</span>.</li>
<li>The <span class="math">\text{Payment}</span> rule <span class="math">p(\mathbf{b}) = (p_0(\mathbf{b}), p_1(\mathbf{b}), \dots, p_t(\mathbf{b}), \dots, p_m(\mathbf{b}))</span> ensures that users pay no more than their priority fee <span class="math">\hat{\delta}^t = \min(\delta^t, f^t - r)</span>. Here, <span class="math">p_0(\mathbf{b}</span>) represents the payment to the block producer, and <span class="math">p_t(\mathbf{b}</span>) represents the payment made by user <span class="math">t</span> to all other <span class="math">\text{IL}</span> committee members, where the set of users has size <span class="math">m</span> and the block producer is indexed by 0.</li>
</ul>
<p>The <span class="math">\text{Payment}</span> rule defined above is meant to give a general view of how the value paid by users’ transactions can be redistributed across FOCIL participants (e.g., <span class="math">\text{IL}</span> committee members, block producer) to incentivize behavior that is considered good for the network, in this case preserving its censorship-resistant properties. Incentivizing <span class="math">\text{IL}</span> committee members for including transactions strengthens the robustness of the mechanism by increasing the <a href="https://arxiv.org/abs/2301.13321" rel="noopener nofollow ugc">cost of censorship</a>, or the amount a censoring party would have to pay for <span class="math">\text{IL}</span> committee members to exclude transactions from their local <span class="math">\text{ILs}</span>. Delving into the specifics of how the builder and <span class="math">\text{IL}</span> committee members should be rewarded is beyond the scope of this post as distributing rewards in an incentive-compatible way, especially during congestion, gets quite complex.</p>
<p>However, here are three high-level options to consider:</p>
<ul>
<li><strong>Option 1</strong>: All transaction priority fees go to the builder, and <span class="math">\text{IL}</span> committee members are just not incentivized to include transactions in their local <span class="math">\text{ILs}</span>. This simple option doesn’t require any changes to the existing fee market, but entirely relies on altruism from <span class="math">\text{IL}</span> committee members. We could even consider an opt-in version of FOCIL, where validators can choose to be part of a list that may be elected to become <span class="math">\text{IL}</span> committee members and participate in building <span class="math">\text{ILs}</span> altruistically. However, it wouldn’t increase the cost of censorship nor would it make it very appealing for validators to participate in the mechanism. This could also lead to out-of-band payments from users wanted to have their transactions included in local <span class="math">\text{ILs}</span>.</li>
<li><strong>Option 2</strong>: Priority fees from transactions included in the block are given to the <span class="math">\text{IL}</span> committee members. To distribute rewards among members, we could implement a weighted incentive system by defining a <span class="math">\text{Reward}</span> rule to calculate and distribute rewards for each member, considering the quantity (i.e., count) and uniqueness of transactions included in their local lists (see Appendix 1 of the <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS post</a> for more details). If transactions are not part of the <span class="math">\text{IL}_\text{agg}</span>, priority fees go to the builder. However, this approach could be problematic during congestion periods with the conditional <span class="math">\text{IL}</span> property, as builders might be incentivized to fill the block with transactions that are not in the <span class="math">\text{IL}_\text{agg}</span>, even if <span class="math">\text{IL}</span> transactions have higher priority fees. To address this, we might need to design a mechanism that redirects priority fees to the builder during congestion. However, the practical implementation and potential secondary effects need further investigation.</li>
<li><strong>Option 3</strong>: A third option is to introduce a new, separate inclusion fee that always go to IL committee members while priority fees always go to the builder. This would likely address the concerns of <strong>Option 2</strong> related to congestion but would introduce a whole other variable that users need to set. A useful distinction between Option 2 and Option 3 is whether the complexity is pushed upon the IL committee members or the end users.</li>
</ul>
<p>Another interesting question to explore is the impact of fee distribution across <span class="math">\text{IL}</span> committee members on mechanisms like <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">MEV-burn</a>. <strong>Options 2</strong> and <strong>3</strong> would effectively “reduce the burn” and produce a similar effect as <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV-smoothing</a>, but on a smaller scale limited to the size of the <span class="math">\text{IL}</span> committee (h/t Anders).</p>
<h3><a class="anchor" href="https://ethresear.ch#textinclusion-rule-10" name="textinclusion-rule-10"></a><span class="math">\text{Inclusion}</span> <strong>Rule</strong></h3>
<p>The <span class="math">\text{Inclusion}</span> rule determines the criteria according to which <span class="math">\text{IL}</span> committee members should build their local <span class="math">\text{ILs}</span>. In FOCIL, we define it with the premise that IL committee members will try to maximize their rewards. Assuming <strong>Option 2</strong> for the <span class="math">\text{Payment}</span> rule, the <span class="math">\text{Inclusion}</span> rule could be to include all transactions seen in the public mempool, ordered by priority fees.</p>
<h3><a class="anchor" href="https://ethresear.ch#textpriority-rule-11" name="textpriority-rule-11"></a><span class="math">\text{Priority}</span> <strong>Rule</strong></h3>
<p>We assume the block will be made of two components: a payload and an  <span class="math">\text{IL}_\text{agg}</span> included by the proposer to impose constraints on transactions that need to be included in the builder’s payload. Imposing constraints to the block payload via the  <span class="math">\text{IL}_\text{agg}</span> thus requires a priority rule to determine what happens during congestion. Generally, the priority rule in FOCIL states that transactions in the  <span class="math">\text{IL}_\text{agg}</span> might be excluded if the block can be filled with the builder’s payload transactions. In other words, the block will still be valid even if some transactions in the <span class="math">\text{IL}_\text{agg}</span> are not included, as long as the block is completely full (i.e., the <code>30 M</code> gas limit is reached).</p>
<p><em>Note: Rules are not set in stone and should be interpreted as candidates for FOCIL. Rules also don’t necessarily have to be made explicit. For instance, we can define the <span class="math">\text{Reward}</span> such that the dominant strategy of the <span class="math">\text{IL}</span> committee is to adhere to the <span class="math">\text{Inclusion}</span> rule without any kind of enforcement by the protocol.</em></p>
<h2><a class="anchor" href="https://ethresear.ch#improvements-and-mitigations-12" name="improvements-and-mitigations-12"></a>Improvements and Mitigations</h2>
<p>In this section, we discuss improvements over previous  <span class="math">\text{IL}</span> proposals, focusing on simplification and addressing specific implementation concerns.</p>
<h3><a class="anchor" href="https://ethresear.ch#commitment-attacks-13" name="commitment-attacks-13"></a><strong>Commitment attacks</strong></h3>
<p>One of the main differences between FOCIL and the forward IL (<span class="math">\text{fIL}</span>) design proposed in <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> is that FOCIL relies on a committee of multiple validators, rather than a single proposer, to construct and broadcast the <span class="math">\text{IL}</span>. This approach imposes stricter constraints on creating a “good” aggregate list and significantly reduces the surface for bribery attacks. Instead of targeting a single party to influence the exclusion of transactions from the <span class="math">\text{IL}</span>, attackers would now need to bribe an entire <span class="math">\text{IL}</span> committee (e.g., <code>256</code> members), substantially increasing the cost of such attacks. Previous designs (e.g., <a href="https://ethresear.ch/t/the-more-the-less-censored-introducing-committee-enforced-inclusion-sets-comis-on-ethereum/18835">COMIS</a> and <a href="https://ethresear.ch/t/anonymous-inclusion-lists-anon-ils/19627">anon-IL</a>), also involved multiple parties in building inclusion lists but still relied on an aggregator to collect, aggregate, and deduplicate local <span class="math">\text{ILs}</span>. In FOCIL, the entire set of attesters now participates in enforcing and ensuring the quality of the <span class="math">\text{IL}</span> included in the proposer’s block, thus removing single-party dependency other than the proposer. Additionally, it is worth noting that a censoring proposer would have to forego all consensus and execution layer rewards and cause a missed slot to avoid including transactions in the <span class="math">\text{IL}</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#splitting-attacks-and-il-equivocation-14" name="splitting-attacks-and-il-equivocation-14"></a><strong>Splitting attacks and IL equivocation</strong></h3>
<p>Another concern with <span class="math">\text{fILs}</span> focused on possible “splitting” attacks using <span class="math">\text{ILs}</span>. <a href="https://eprint.iacr.org/2021/1413.pdf" rel="noopener nofollow ugc">Splitting attacks</a> like timed release or “equivocation” occur when malicious participants attempt to divide the honest view of the network to stall consensus. On Ethereum, a validator equivocating by contradicting something it previously advertised to the network is a <a href="https://eth2book.info/capella/part2/incentives/slashing/" rel="noopener nofollow ugc">slashable offense</a>. If there is evidence of the offence being included in a beacon chain block, the malicious validator gets ejected from the validator set. Quick reminder that in the <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">EIP-7547</a> design, the proposer for slot <span class="math">n-1</span> is responsible for making the <span class="math">\text{IL}</span> to constrain proposer <span class="math">n</span>, and can broadcast multiple <span class="math">\text{ILs}</span> (check out the <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">No-free lunch</a> post to see why, and how it relates to solving the free data availability problem). This means a malicious proposer could split the honest view of the network through <span class="math">\text{IL}</span> equivocation without being slashed. However, this is not a concern with FOCIL, since <span class="math">\text{IL}_\text{agg}</span> has to be part of proposer $n$’s block. An <span class="math">\text{IL}</span> equivocation would thus be equivalent to a block equivocation, which is a known, slashable offense from the protocol’s perspective.</p>
<h3><a class="anchor" href="https://ethresear.ch#incentives-incompatibilities-15" name="incentives-incompatibilities-15"></a>Incentives incompatibilities</h3>
<p>Previous <span class="math">\text{fILs}</span> proposals did not consider incentivizing the <span class="math">\text{IL}</span> proposer(s) for including “good” transactions. Relying on altruistic behavior might be fine, but there is always the risk that only very few validators will choose to participate in the mechanism if there is no incentive to gain. There is a strong argument to be made that the adoption of any <span class="math">\text{IL}</span> mechanism might be very low if validators risk being flagged as either non-censoring or censoring entities by revealing their preferences (see the <a href="https://ethresear.ch/t/anonymous-inclusion-lists-anon-ils/19627">Anonymous Inclusion Lists post</a>), and if they are not rewarded for contributing to preserving the network’s censorship resistance properties. In FOCIL, we consider mechanisms to distribute rewards across <span class="math">\text{IL}</span> committee members and mention two options (<strong>Option 2</strong> and Option 3 in the <span class="math">\text{Payment}</span> rule section) for sharing transaction fees based on the quantity (i.e., count) and uniqueness of transactions included in their local lists. We hope to continue working in this direction and to find incentive-compatible ways to increase the costs of censorship.</p>
<h3><a class="anchor" href="https://ethresear.ch#same-slot-censorship-resistance-16" name="same-slot-censorship-resistance-16"></a>Same-slot censorship resistance</h3>
<p>By having FOCIL run in parallel with block building during slot  <span class="math">n-1</span>, we can impose constraints on the block by including transactions submitted during the same slot in local <span class="math">\text{ILs}</span>. This is a strict improvement over <span class="math">\text{fILs}</span> designs, where the forward property imposes a 1-slot delay on <span class="math">\text{IL}</span> transactions. This property is particularly useful for time-sensitive transactions that might be censored for MEV reasons (see <a href="https://cdn.prod.website-files.com/642f3d0236c604d1022330f2/6499f35e0bd0f43471a95adc_MEV_Auctions_ArXiV_6.pdf" rel="noopener nofollow ugc">Censorship resistance in onchain auctions</a> paper). Admittedly, the mechanism is not exactly real-time because we still need to impose the “local <span class="math">\text{IL}</span> freeze” deadline <span class="math">d</span> so block producers have time to consider <span class="math">\text{IL}_\text{agg}</span> transactions before proposing their block.</p>
<h3><a class="anchor" href="https://ethresear.ch#textil-conditionality-17" name="textil-conditionality-17"></a><span class="math">\text{IL}</span> conditionality</h3>
<p>A core property of <span class="math">\text{ILs}</span> is their conditionality, which determines whether ILs should have dedicated block space for their transactions (<a href="https://ethresear.ch/t/unconditional-inclusion-lists/18500">unconditional</a>) or share block space with the payload and only being included if the block isn’t full (conditional). For FOCIL, we’re leaning towards using conditional <span class="math">\text{ILs}</span> for a couple of reasons. Firstly, it might generally be best to give sophisticated entities like builders the maximum amount of freedom in organizing block space as long as they include <span class="math">\text{IL}</span> transactions. Allowing them to order transactions and fill blocks as they prefer, rather than imposing too many restrictions on their action space, reduces the risk of them using side channels to circumvent overly rigid mechanisms. Specifically, the unconditional property just couldn’t really be enforced effectively with FOCIL, since builders wanting to use <span class="math">\text{IL}</span> dedicated block space could simply “buy up <span class="math">\text{IL}</span> committee seats” from the elected validators to include their transactions via local <span class="math">\text{ILs}</span>. Another reason to opt for conditional <span class="math">\text{ILs}</span> is the flexibility in the size of the list. With unconditional ILs, an added block space must strictly set an arbitrary maximum <span class="math">\text{IL}</span> gas limit (e.g., <code>3M</code> gas). In contrast, conditional <span class="math">\text{ILs}</span> allow for a much more flexible <span class="math">\text{IL}</span> size, depending on the remaining space in the block. The known tradeoff with conditional <span class="math">\text{ILs}</span> is block stuffing: censoring builders might fill their blocks up to the gas limit to keep <span class="math">\text{IL}</span> transactions out. More research is needed to determine the sustainability of block stuffing, as <a href="https://timroughgarden.org/papers/eip1559.pdf" rel="noopener nofollow ugc">consecutive full blocks exponentially increase base fees</a> and the overall cost of this strategy.</p>
<h3><a class="anchor" href="https://ethresear.ch#account-abstraction-accounting-18" name="account-abstraction-accounting-18"></a><strong>Account Abstraction accounting</strong></h3>
<p>In previous proposals, <span class="math">\text{IL}</span> summaries were constructed as structures to constrain blocks without committing to specific raw transactions. Each <span class="math">\text{IL}</span> summary —or <span class="math">\text{IL}_\text{agg}</span> for FOCIL— entry represents a transaction by including the following fields: <code>From</code> and <code>Gas Limit</code>. Satisfying an entry in the <span class="math">IL</span> summary requires that at least <em>some</em> transaction from the <code>From</code> address has been executed, <em>unless</em> the remaining gas in the block is less than <code>Gas Limit</code> . The idea is simple: if a transaction was previously valid and had a sufficiently high basefee, the only two things preventing its inclusion are the lack of sufficient gas in the block or its invalidation, which would require a transaction from the same sender to have been previously executed. Here we rely on a property of Ethereum EOAs: the <code>nonce</code> and <code>balance</code> of an EOA determine the validity of any transaction originating from that EOA, and can only be modified by such a transaction.</p>
<p>However, even limited forms of Account Abstraction that have been considered for inclusion in Electra (e.g., <a href="https://github.com/ethereum/EIPs/blob/43fb1e0ca950c42a09efdf9a85d8acfe260efac1/EIPS/eip-3074.md" rel="noopener nofollow ugc">EIP-3074</a> or <a href="https://github.com/ethereum/EIPs/blob/43fb1e0ca950c42a09efdf9a85d8acfe260efac1/EIPS/eip-7702.md" rel="noopener nofollow ugc">EIP-7702</a>) allow a transaction to trigger a change in an EOA’s balance, <em>without originating from that EOA</em>. This <a href="https://hackmd.io/@potuz/BkWngLly0#Transactions-that-become-invalid" rel="noopener nofollow ugc">raised concerns</a> regarding previous <span class="math">\text{fIL}</span> proposals, as proposer <span class="math">n</span> is not aware of what is included in builder $n$’s payload when proposing its <span class="math">\text{IL}</span>. This could lead to a scenario where proposer <span class="math">n</span> includes a transaction <span class="math">txn_A</span> from address <span class="math">A</span> in the <span class="math">\text{IL}</span>, while builder <span class="math">n</span> includes an EIP-7702 transaction <span class="math">txn_B</span>, originating from address <span class="math">B</span> but sweeping out all the <code>ETH</code> from address <span class="math">A</span>, and thus invalidating  <span class="math">txn_A</span>. Consequently, builder <span class="math">n+1</span> would no longer be able to include <span class="math">txn_A</span>, though no other transaction from address <span class="math">A</span> has been previously executed. In other words, the <span class="math">IL</span> summary would be unsatisfiable.</p>
<p>In FOCIL, one simplification is that the constraints from the <span class="math">\text{IL}_\text{agg}</span> apply to the block that is being built concurrently. This means a transaction in the <span class="math">\text{IL}_\text{agg}</span> can’t be invalidated because of a transaction in the previous block, as it can in <span class="math">\text{fIL}</span> designs. In other words, we do not need to worry about what happened in the previous block in order to check for satisfaction of the <span class="math">\text{IL}_\text{agg}</span>. However, a builder could still insert EIP-7702 transactions in its payload that invalidate <span class="math">\text{IL}_\text{agg}</span> transactions. To handle this case, we can do the following when validating a block:</p>
<ul>
<li>Before executing the block’s transactions, we store <code>nonce</code> and <code>balance</code> of all <code>From</code> addresses that appear in the <span class="math">\text{IL}_\text{agg}</span>.</li>
<li>After execution, we check the <code>nonce</code> and <code>balance</code> of all <code>From</code> addresses from the <span class="math">\text{IL}_\text{agg}</span> again, and for each (<code>From</code>, <code>Gas Limit</code>) pair in the <span class="math">\text{IL}_\text{agg}</span> we require that either the <code>nonce</code> or the <code>balance</code> has changed, or the <code>Gas Limit</code> is more than the remaining gas.</li>
</ul>
<p>If the <code>nonce</code> has changed, some transaction from that address has been executed. If the <code>balance</code> has changed but the <code>nonce</code> has not, some AA transaction has touched that address. In either case, that address has transacted in the block, and the entry is satisfied.</p>
<p><em>Note: With "full” AA, transactions could have validity that depends on arbitrary state (e.g., the price changing in a Uniswap pool). In such cases, relying on a reduced form of transactions (i.e., entries with <code>From</code> and <code>Gas limit</code> fields) is insufficient, as the full validation logic of the transaction is needed. Due to the <a href="https://notes.ethereum.org/@vbuterin/pbs_censorship_resistance#What-are-the-design-goals-of-any-anti-censorship-scheme" rel="noopener nofollow ugc">free data-availability</a> problem, putting raw transactions on-chain is not an option. Instead, attesters could check this locally since they need to construct their own <span class="math">\text{IL}_\text{agg}^\text{attester}</span> and could, therefore, evaluate the full validation logic. This allows them to verify if the transaction has been invalidated and if its inclusion should be enforced. However, attesters might have <span class="math">\text{IL}_\text{agg}^\text{attester}\text{s}</span> that contain different transactions from the same <code>From</code> address, leading to a situation where one transaction might be invalidated while another is not. This would result in split views and potential attacks</em></p>
            <p><small>10 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/fork-choice-enforced-inclusion-lists-focil-a-simple-committee-based-inclusion-list-proposal/19870">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 15:42:04 +0000</pubDate>
</item>
<item>
<title>Burn incentives in MEV pricing auctions</title>
<link>https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856</link>
<guid>https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV定价拍卖、公共利益、竞争、贿赂、共识机制

总结:
本文分析了MEV定价拍卖中的五种潜在激励，包括公有利益建设者、营利性公有利益建设者、敲诈勒索、攻击性竞争（包括单个和联合攻击）以及与共识机制的风险。这些因素促使参与者竞相烧掉MEV，以确保自身或竞争对手的收益。文章指出，尽管存在对晚投标和缺乏公平性的担忧，但实际博弈中，特别是通过与验证者服务提供商（SSP）的紧密合作，MEV燃烧的动机变得更加强烈。此外，作者提醒要警惕MEV定价拍卖可能对共识机制产生的负面影响，比如attester-builder的整合可能导致共识形成过程中的竞争失衡。因此，设计MEV机制时需平衡各方利益，防止意外破坏网络稳定。 <div>
<h1><a class="anchor" href="https://ethresear.ch#burn-incentives-in-mev-pricing-auctions-1" name="burn-incentives-in-mev-pricing-auctions-1"></a>Burn incentives in MEV pricing auctions</h1>
<p><em>Thanks to Barnabé Monnot, Thomas Thiery and Caspar Schwarz-Schilling for feedback and comments.</em></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/7/1703882e171fbc76c500a2799ebea0ad8dfe61d7.jpeg" title="The process of burning MEV"><img alt="The process of burning MEV" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/1/7/1703882e171fbc76c500a2799ebea0ad8dfe61d7_2_375x375.jpeg" width="375" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<h3><a class="anchor" href="https://ethresear.ch#overview-3" name="overview-3"></a>Overview</h3>
<p>This post presents a rudimentary review of incentives for burning MEV under the <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590">“simple” MEV burn mechanism</a> presented by Justin, as well as its slot auction counterpart, <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">“execution auctions”</a> presented by Barnabé. The analysis is also applicable to Francesco’s original <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a> design. These auctions—involving builders bidding, attesters enforcing a base fee floor, and proposers selecting a winning bid—will be defined as MEV pricing auctions (in the author’s view, the “execution auction” moniker could also be extended to cover all MEV pricing auctions).</p>
<p>The post highlights how incentives to drive up the price floor (and thus burn more MEV) can emerge in these designs regardless of any direct profit motive among builders for doing so. Importantly, stakers and staking service providers wish to ensure that competitors do not attain more rewards for selling MEV capture rights than them. They may therefore integrate with builders to bid away competing stakers’ profits. Auctions that set a price floor on proposers’ MEV capture rights will thus be influenced by the overarching staking <a href="https://en.wikipedia.org/wiki/Metagame">metagame</a>. It is only at this layer that griefing attacks against proposers to burn their MEV capture rights can be understood. Adverse competition during the consensus formation process might hypothetically lead attesters to bias their MEV base fee floor during split views, rejecting or admitting blocks depending on how it impacts their bottom line (in their roles as both builders and stakers). This is something to be attentive to. Naturally, burning MEV might also be considered a public good, and such incentives are reviewed in the text as well.</p>
<h3><a class="anchor" href="https://ethresear.ch#mev-pricing-auctions-4" name="mev-pricing-auctions-4"></a>MEV pricing auctions</h3>
<p>In <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn–a simple design</em></a>, Justin formulated an add-on to <a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710">enshrined proposer–builder separation</a> (ePBS), modifying the <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">MEV smoothing</a> design.  Builders can specify a base fee and a tip in their block bids. At some specific time before the slot begins (e.g., 2 seconds), attesters observe the highest base fee among the bids (“observation deadline”) and impose it as a subjective base fee floor when attesting to the proposer’s block. Only bids with a base fee above the floor are accepted, and the base fee is burned.</p>
<p>If builders bid before the observation deadline with the same timing as today, then the mechanism will <a href="https://ethresear.ch/t/in-a-post-mev-burn-world-some-simulations-and-stats/17092">burn substantial MEV</a>. Concerns have however been raised over the risk of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">collusion between proposers and builders</a> and lack of <a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/23">proper incentivization</a>. A <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384">recent write-up</a> on the benefits of the design and MEV burn in general generated similar worries of a <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">stable equilibrium of late bidding</a>.</p>
<p>The design can be further modified to involve auctioning off the rights to the entire slot, 32 slots in advance (“<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ">execution auction</a>”). A benefit of this design is the ability to offer long-lived preconfirmations and—hypothetically—the reduced value-in-flight during the auction. The same concerns raised for the block auction design can be applied to the slot auction design, because the beacon proposer might still benefit from colluding with builders to form late-bidding cartels when selecting the execution proposer.</p>
<p>A modified MEV pricing auction, <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">MEV burn with builder kickbacks</a>, attempts to compensate builders for bidding early. That design is not the focus of this post, but incentives and side effects in uncompensated MEV pricing auctions will affect its relevance.</p>
<h2><a class="anchor" href="https://ethresear.ch#five-burn-incentives-in-mev-pricing-auctions-5" name="five-burn-incentives-in-mev-pricing-auctions-5"></a>Five burn incentives in MEV pricing auctions</h2>
<p>The outlined concerns of late bidding are valid, but it turns out that it is not possible to analyze MEV burn without incorporating stakers as participating agents. In such an analysis, competition for attaining the most yield will—under equilibrium—drive participants to burn each other’s MEV. Other incentives for burning MEV also exist. The analysis starts from the most idealistic public good example in (A) and gradually builds toward a metagame of active collusion to discourage other stakers in (E) (see Figure 1).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/a/7a0cc1b660d8b22ac81aff0bbc070505e6f30e7e.jpeg" title="Figure 1"><img alt="Figure 1" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/a/7a0cc1b660d8b22ac81aff0bbc070505e6f30e7e_2_500x500.jpeg" width="500" /></a></div><p></p>
<p><strong>Figure 1.</strong> Five types of builders potentially burning MEV in MEV pricing auctions: (A) Public good builder, (B) For-profit public good builder, (C) Extortion racket, (D) Staker-initiated griefing, (E) Staker-initiated griefing cartel. The incentives behind (D) are important to understand (indicated by an arrow).</p>
<h3><a class="anchor" href="https://ethresear.ch#a-public-good-builder-6" name="a-public-good-builder-6"></a>(A) Public good builder</h3>
<p>The first example is a builder that dedicates resources to burning MEV without a direct profit motive. If Ethereum’s users believe that burning MEV is a public good, and in particular if no other incentive is sufficient, they may come together to fund the development and operation of a public good builder. Initiatives to fund public goods are fairly <a href="https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c">prevalent</a> within the Ethereum ecosystem. The public good builder can for example consistently bid according to guaranteed MEV at the observation deadline in the block auction design. This ensures that the MEV is burned while the builder will not suffer any direct losses from the bid. In the slot auction design, the builder would instead need to bid according to its expected MEV for the entire slot and might bid slightly below to stay safe.</p>
<p>The public good builder will likely not be the best and will often be outbid in terms of tips from other builders in the proposer auction (taking place after the observation deadline), in which the proposer selects a winning bid. But the operation can still be very impactful. After all, priority fees are a significant portion of all value (in this post these fees are also treated as MEV), and some further “low-hanging MEV fruits” are potentially available without dedicating too large resources for extraction. While the builder may use any public goods funding received diligently and not strive for any profit, pursuing an idealistic path can still raise the originators’ public profile and provide significant economic benefits in the future (perhaps not even directly related to building blocks).</p>
<h3><a class="anchor" href="https://ethresear.ch#b-for-profit-public-good-builder-7" name="b-for-profit-public-good-builder-7"></a>(B) For-profit public good builder</h3>
<p>A builder that positions itself as providing a public good may also enjoy direct economic benefits from its operation if some validators sympathize with the mission. There may for example be a market fit for builders that do not censor, nor extract various types of toxic MEV. In the block auction design, the builder could keep the MEV base fee in line with the available (non-censorship/non-toxic) MEV during the attester auction, and then pivot to tipping afterward, retaining some small profit margin. The MEV in some blocks is not particularly geared towards specialized searchers, and stakers may not lose that much in tips for some blocks by selecting the public good builder. Therefore, the public good builder could have higher profit margins in the blocks it does eventually get to build than builders that have not positioned themselves as providing a public good. A builder bidding before the observation deadline might of course also hope that its bids are the only ones to reach the proposer in times of degraded network conditions.</p>
<h3><a class="anchor" href="https://ethresear.ch#c-extortion-racket-8" name="c-extortion-racket-8"></a>(C) Extortion racket</h3>
<p>Given the lower effort required for extracting some of the MEV, it seems like (A) and (B) could have a natural position and high impact within the Ethereum ecosystem. But it may very well be that no successful public good builder can be sustained over the long run. After all, many stakers will not be particularly enthusiastic over a builder that burns their MEV opportunities.</p>
<p>Still, consider the importance of a dedicated MEV-burning builder within the staking ecosystem. If the builder is operational, proposers will lose out on a lot of value relative to if it does not operate. Is there a business opportunity here? Perhaps a builder could commit to burning the maximum possible MEV but abstain from doing so if it receives a bribe from the proposer? It seems natural that proposers would be willing to pay for this, since the proposer stands to capture most value from the available MEV if none is burned. But the prospect of competition makes the business model perilous. If a sole extortive builder is profitable, then a few more may try to enter the market as well. There is not much use in paying off two builders if it turns out that a third burned the MEV anyway through a bid. A mechanism for reconciling this ex-post would become rather complex. The validator may then be better off by simply not negotiating with any extortion racket.</p>
<p>While the extortion racket seems unsustainable, it helps to underscore the power that builders have over proposers. The ultimate incentive for burning MEV then emerges when changing the responsible actor from one unaffected by the staking equilibrium (extorting builder) to one that is not (other stakers). The auction will eventually become part of the <a href="https://en.wikipedia.org/wiki/Metagame">metagame</a> of the overarching staking equilibrium.</p>
<h3><a class="anchor" href="https://ethresear.ch#d-metagame-staker-initiated-griefing-9" name="d-metagame-staker-initiated-griefing-9"></a>(D) Metagame—staker-initiated griefing</h3>
<p>Staking service providers (SSPs) compete for delegated stake and derive income by taking a cut of the staking yield when they pass it back to the delegators. An SSP must ensure that the yield it offers delegating stakers is competitive relative to offers from other SSPs. The MEV pricing auction may therefore lead SSPs to burn competing proposers’ MEV by tightly integrating with builders or running them in-house. If a competitor burns an SSP’s MEV, then the SSP must respond in kind or will lose out on delegators and thus income. When considering the metalevel of SSPs, this equilibrium seems more stable than an equilibrium of late bidding leading to little or no MEV burn. All it takes to break the late-bidding cartel is one defecting SSP builder, forcing others to respond.</p>
<p>An SSP that through a builder griefs other stakers without taking any loss executes something comparable to a <a href="https://github.com/ethereum/research/blob/d1d465f658e0024a2010b0a6ad960a76d9c40cac/papers/discouragement/discouragement.pdf">discouragement attack</a> with an infinite griefing factor. This is a very advantageous attack, primarily because delegators will flow to the best performing SSP. In addition, a reduction in overall yield for other stakers pushes down the quantity of supplied stake, bringing up the equilibrium yield. Thus, even if some delegators do not flow to the SSP that burns its competitor’s MEV, the expected staking yield (that the SSP will share in the profit from) will still go up, if the competitor’s customers simply stop delegating. Of course, the cost of running the builder must be accounted for. But large SSPs can amortize that cost across a vast amount of yield-bearing validators.</p>
<p>Yet, directly profiting from the MEV is almost always better than burning it. When an SSP’s builder is able to extract more MEV in a competitor’s slot than any other builder, it will still be better off only bidding to a level that ensures it wins the auction. The SSP must thus make a probabilistic judgment as to the uniqueness of its MEV opportunity in the particular slot before deciding how to proceed (or more precisely, any edge in MEV value <span class="math">V_e</span> relative to the second best builder). An SSP builder must in essence bid before the observation deadline up to the point where the expected payoff from burning the marginal MEV is equal to the expected payoff from waiting and hoping to extract it. There are some game-theoretic nuances to this that here will be set aside, with some aspects discussed in the next section. The point is to assert that there are stronger incentives for builders to bid before the observation deadline than what has been previously understood, because a builder might be run by an SSP that indirectly profits from burning other stakers’ potential MEV revenue.</p>
<p>What happens in the metagame to smaller SSPs and solo stakers? They may not afford to run a builder of their own to ensure that their competitors’ MEV is burned. It is of course possible for solo stakers to try to come together to form a union around a builder, where each contributor is guaranteed to see their validators excluded from MEV base fee bids by the specific builder (and receive full tips during the proposer auction). There is then a question of if they will be able to organize such a union, but also if it really would be necessary. On the one hand, if there are several “griefing builders” running concurrently among the largest SSPs, parties holding less stake may not need to run their own griefing builder. Everyone will see their MEV burned anyway, since the big SSPs burn each other’s and everyone else’s MEV. On the other hand, a party not having a griefing builder readily available may be suboptimally positioned when considering the prospect of cartelization.</p>
<h3><a class="anchor" href="https://ethresear.ch#e-metagame-staker-initiated-griefing-cartel-10" name="e-metagame-staker-initiated-griefing-cartel-10"></a>(E) Metagame—staker-initiated griefing cartel</h3>
<p>Can builders operating at the metalevel collude to selectively burn or selectively <em>not</em> burn MEV, depending on the identity of the slot’s validator? The cartel would strive to ensure that all participating SSPs (or any union of solo stakers) receive the MEV in their validators’ proposed blocks, while minimizing MEV in all other validators’ blocks.</p>
<p>However, if attesters are honest, builders can only cartelize to selectively burn or not burn MEV that they uniquely are able to extract. As long as competing builders are operational, this substantially limits the power of any cartel. Therefore, the advantage of (E) over (D) is not substantial.</p>
<h4><a class="anchor" href="https://ethresear.ch#proposer-is-part-of-the-cartel-11" name="proposer-is-part-of-the-cartel-11"></a>Proposer is part of the cartel</h4>
<p>When the beacon proposer is part of the cartel, members will abstain from bidding before the observation deadline to ensure that as much value as possible flows to the proposer. This type of cartelization has been highlighted as a concern (<a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590/4">1</a>, <a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384/3">2</a>) in the debate around MEV pricing auctions. The idea is that participants come to an explicit or implicit agreement to not bid before the observation deadline. Yet the incentive to burn MEV is stronger than previously understood, since stakers outside the cartel will wish to grief cartel members by bidding early (D), and so from this perspective, the risk of late-bidding-cartelization is lower than feared.</p>
<p>It might also be difficult to efficiently uphold cartelization, because it is not possible for members to know which, if any, defected in pursuit of (D). One avenue would be to try to share the profits from every slot to give all participants incentives to hold back bids before the observation deadline. Yet overall, the existence of (A), (B), and (D) means that some value will still reasonably be burned by public good builders or any competitors not part of the cartel.</p>
<h4><a class="anchor" href="https://ethresear.ch#proposer-is-not-part-of-the-cartel-12" name="proposer-is-not-part-of-the-cartel-12"></a>Proposer is not part of the cartel</h4>
<p>When the beacon proposer is outside the cartel, the goal is to deprive it of revenue while still capturing as much of the MEV as possible. It will still be more profitable for the cartel to extract any unique MEV opportunity rather than burn it. Define <span class="math">V_s</span> as the value a builder can attain in the slot auction and <span class="math">V_b</span> as its value for the block auction (from a block built at the observation deadline). When a builder can extract the most MEV, it has an edge <span class="math">V_e</span> over the second-best builder (kept constant for simplicity). Just as in (D), the cartel can bid up to <span class="math">V_b-V_e</span> or <span class="math">V_s-V_e</span>, with the difference that <span class="math">V_e</span> expands if the cartel collectively gains a larger edge against the best builder outside of the cartel. This expansion is what the cartel tries to capitalize on, both when the proposer is part of the cartel (expanding <span class="math">V_e</span> to lower the burn) and when not (expanding <span class="math">V_e</span> to increase builder profits). A challenge—just as in (D)—is that the cartel might not be able to properly estimate <span class="math">V_e</span>. After the observation deadline, the cartel attempts to extract as much value as possible, leaving the MEV either burned or in their hands.</p>
<h4><a class="anchor" href="https://ethresear.ch#collusion-at-other-levels-13" name="collusion-at-other-levels-13"></a>Collusion at other levels</h4>
<p>The presentation so far has been somewhat simplistic. It bears mentioning that collusion need not happen at the level of the builders, but can for example happen at the level of searchers or any out-of-protocol relay that the cartel still finds beneficial to maintain before posting to the P2P layer. In all scenarios of successful cartelization, if some stakers (for example solo stakers) are unable to act collectively, they may end up at the short end of the discouragement dynamic.</p>
<h2><a class="anchor" href="https://ethresear.ch#risks-associated-with-attester-builder-integration-14" name="risks-associated-with-attester-builder-integration-14"></a>Risks associated with attester–builder integration</h2>
<p>The analysis so far indicates that (D) may have a significant effect on its own but that it does not necessarily lead to the riskier cartelization in (E). But what might happen when we give SSPs tools for depriving each other of revenue? While SSPs will always compete, competition in MEV pricing auctions is on the verge of seeping into the consensus formation process. At the consensus level, all participants are expected to behave honestly and are rewarded for good behaviour. Through staker–builder integration in (D)-(E), SSPs will come to actively influence each other’s rewards, cooperating or griefing each other. A risk is that SSPs might navigate down perilous paths in this landscape.</p>
<p>It has been noted that MEV pricing auctions suffer from attesters potentially having <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">split views</a> of the MEV base fee floor. Biasing the outcome in a split view one way or the other might benefit one builder over another, result in a block being forked out to deprive the beacon proposer of all rewards, or allow the proposer to reap higher rewards when selling MEV capture rights. One concern is that SSPs might eventually try to profit by tuning their attestations of the MEV base fee floor to produce favorable outcomes. This can also be done as part of a cartel. The honest majority assumption need not be broken to derive profits, due to split views. It is only necessary to put a thumb on the scale, and a competitive consensus formation might make such behavior more likely.</p>
<p>Of course, stakers who do not honestly attest to which bids they have observed at which specific time point subject themselves to risks of social slashing if malicious behavior can be uncovered. This is always a potential final resort under proof of stake. In essence, just as it is prudent to be cautious of MEV or excessive issuance as strata for cartelization, it also seems prudent to be cautious of MEV pricing auctions as a stratum for consensus adversity.</p>
<h2><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-in-terms-of-mev-pricing-15" name="block-vs-slot-auctions-in-terms-of-mev-pricing-15"></a>Block vs. slot auctions in terms of MEV pricing</h2>
<p>Will block auctions or slot auctions burn more MEV? Is one more centralizing than the other? These questions are not easy to answer, because it depends on which burn incentive that comes to dominate, the likelihood of cartelization under different designs, etc. This section will discuss some differences (previous writings on <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ">block vs. slot auctions</a> provide a broader perspective).</p>
<h3><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-concerning-d-16" name="block-vs-slot-auctions-concerning-d-16"></a>Block vs. slot auctions concerning (D)</h3>
<p>Assume that (D) becomes an important incentive for burning MEV. Further, assume a competitive market without cartelization and perfect information about how much MEV each participant can extract. In the block auction design, the builder can bid <span class="math">V_b-V_e</span> for the block at the observation deadline to maximize burn while retaining opportunities to extract value. It then updates its block and bid through tips in the proposer auction up until the slot boundary. There is <span class="math">V_s-V_b</span> worth of value that the proposer hopes to attain through tips, and <span class="math">V_e</span> worth of value left for the builder (under these simplified conditions).</p>
<p>In the slot auction design, the builder can instead bid <span class="math">V_s-V_e</span> already at the observation deadline. It is just buying the rights to build the block, not committing to its content, and that value is an entire slot’s worth of MEV. Naturally, <span class="math">V_s</span> will here just be an estimate, and the risk that builders take on by bidding on an expected value instead of a tangible value might be worth some fraction of the total bid value. But incomplete information around competitors’ eventual final bids will likely serve to pull down the bid value at the observation deadline more. The staker–builder can ideally burn <span class="math">V_s-V_e</span> of a competing beacon proposer’s auctionable MEV, and again retain <span class="math">V_e</span> for itself. The difference in MEV burn between the two designs is then <span class="math">V_s-V_b</span>.</p>
<p>If the staker–builder could estimate <span class="math">V_s</span> also in the block auction design (which nominally is easier since it bids much closer to the deadline), it could bid <span class="math">V_s-V_e-V_g</span> already at the observation deadline. Since the bid is attached to a block containing only <span class="math">V_b</span> of MEV, <span class="math">V_g</span> is reserved as a tip for the proposer auction. If there is no tip, the proposer might elect to pick the block from the observation deadline, depriving the builder of <span class="math">V_s-V_b</span>. However, while the proposer might specifically wish to do so if the same builder bids with low tips also in the proposer auction, a staker can obfuscate its identity by running several builders (the kickback design disincentivizes obfuscation).</p>
<p>In either design, it seems most likely that the burn ends up being lower than these theoretical maxima due to incomplete information in combination with the fact that capturing the MEV is more valuable than burning it. The staker–builder will therefore operate with quite some margin to maximize expected profits.</p>
<h3><a class="anchor" href="https://ethresear.ch#block-vs-slot-auctions-concerning-a-b-17" name="block-vs-slot-auctions-concerning-a-b-17"></a>Block vs. slot auctions concerning (A)-(B)</h3>
<p>The analysis for (D) is to some extent also applicable for (A) and (B). The public good builder could theoretically bid higher in the slot auction than in the block auction. However, the risk associated with overbidding in the slot auction design might be more serious for these builders. In the block auction design, the available value will be much clearer, making it easier for an unsophisticated builder to make low-risk bids.</p>
<h3><a class="anchor" href="https://ethresear.ch#value-of-preconfirmations-18" name="value-of-preconfirmations-18"></a>Value of preconfirmations</h3>
<p>As previously mentioned, the slot auction design facilitates execution layer preconfirmations, which can provide a welfare gain to Ethereum. In addition, their value can be burnt (just as in <a href="https://ethresear.ch/t/execution-tickets/17944#roadmap-compatibility-6">execution tickets</a>), since builders are bidding to attain that value. This increases the burn of the slot auction design.</p>
<h3><a class="anchor" href="https://ethresear.ch#builder-centralization-under-competition-over-expected-mev-19" name="builder-centralization-under-competition-over-expected-mev-19"></a>Builder centralization under competition over expected MEV</h3>
<p>If builders have different strengths and weaknesses, they will intermittently attain the highest <span class="math">V_b</span> in the block auction design. While one builder might be able to extract the highest MEV in expectation, not all blocks will play to its strengths. However, in the slot auction, builders bid on expected MEV, and one specific builder might then always have the highest expected <span class="math">V_s</span>. <a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814">This could potentially be a centralizing force</a>, depending on how secondary markets evolve.</p>
<h2><a class="anchor" href="https://ethresear.ch#conclusion-20" name="conclusion-20"></a>Conclusion</h2>
<p>There are strong incentives for burning MEV even in designs that do not directly compensate for it, for example to provide a public good service or to ensure that other participants in the staking metagame do not attain a higher yield. Uncompensated MEV pricing auctions accommodates these incentives. Of particular relevance is staker-initiated griefing (D). It seems clear that SSPs will seek to influence builders’ bidding strategies, and this can lead to staker–builder integration. Still, this form of integration does not necessarily lead to censorship or higher MEV profits; thus not negating sought benefits of proposer–builder separation. If it is desirable to give an outside party an independent incentive to burn MEV, then <a href="https://ethresear.ch/t/mev-burn-incentivizing-earlier-bidding-in-a-simple-design/17389">builder kickbacks</a> are an option. They can also be applied to the slot auction design.</p>
<p>When implementing a MEV burn mechanism, it is important to ensure that the burn mechanism does not accidentally set fire to Ethereum’s consensus mechanism. Giving SSPs tools for griefing each other could lead to adverse competition during the consensus formation process. A particular concern is then if emerging attester–builder integration leads attesters to bias their MEV base fee floor, rejecting or admitting blocks depending on how it impacts their bottom line (in their roles as both builders and stakers). Which of the different scenarios (A-E) that would predominate is seemingly a more important parameter when evaluating the merits of MEV pricing auctions than the mechanism’s ability to burn substantial MEV (which this post suggests it can).</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/burn-incentives-in-mev-pricing-auctions/19856">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 20:58:14 +0000</pubDate>
</item>
<item>
<title>Preconfirmations: On splitting the block, mev-boost compatibility and relays</title>
<link>https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837</link>
<guid>https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837</guid>
<content:encoded><![CDATA[
<div> 关键词：Preconfirmation, XGA-style, Ethereum, Block Splitting, Relay

总结:
本文讨论了一种名为XGA-style的预确认机制，它为非优先级交易提供有限时间内（2个epoch后）的区块底部预留空间。这种机制将区块分为顶部和底部两部分，顶部用于传统MEV竞拍，底部通过预确认拍卖分配。预确认通过多单位拍卖进行，买家可以锁定区块容量确保交易成功纳入。文章还提到，这有助于缓解竞争性建块者压力，简化预确认定价，以及对Relay角色的重新思考，提出通过保险和奖励机制来保障预确认平台的稳定运行。XGA是首个实现这一设计的L2平台，目前已有主网版本，但正在进行进一步开发以支持更多功能。 <div>
<p>Thanks to <a class="mention" href="https://ethresear.ch/u/fabrizioromanogenove">@FabrizioRomanoGenove</a>, <a class="mention" href="https://ethresear.ch/u/meridian">@meridian</a> and Philipp Zahn for helpful comments and feedback on this post.</p>
<h2><a class="anchor" href="https://ethresear.ch#what-is-a-preconfirmation-1" name="what-is-a-preconfirmation-1"></a><img alt=":question:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/question.png?v=12" title=":question:" width="20" /> What is a Preconfirmation?</h2>
<p>There have been a lot of variations on the definition of preconfirmation going around recently in the Ethereum community. In this post we will keep the definition as simple and broad as possible in order to generate the least amount of confusion and avoid arguing on semantics as much as possible:</p>
<blockquote>
<p>We call a <strong><em>preconfirmation mechanism</em></strong> any mechanism that ensures (non-positional) inclusion of a (bundle of) transaction(s), if execution is successful, in a finite and bounded amount of time from the emission of the preconfirmation.</p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#xga-style-preconfirmations-2" name="xga-style-preconfirmations-2"></a><img alt=":mag:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/mag.png?v=12" title=":mag:" width="20" /> XGA-Style Preconfirmations</h3>
<p>We will analyze a specific kind of preconfirmation mechanism – as hinted to in <a href="https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800/3">this post on ethresearch</a> – that we came up with some time ago and have been building since then:</p>
<blockquote>
<p>An <strong><em>XGA-style preconfirmation mechanism</em></strong> is a preconfirmation mechanism that guarantees (non-positional) inclusion of a sized bundle of transactions <strong>in the bottom portion of a predetermined block to be minted 2 epochs after the preconfirmation was emitted</strong>. Maximum bundle size is determined at the time of emission of the preconfirmation.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#splitting-the-block-3" name="splitting-the-block-3"></a><img alt=":scissors:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/scissors.png?v=12" title=":scissors:" width="20" /> Splitting the Block</h2>
<p>Looking at the previous definition, I assume the first couple of questions that would come to mind is “what do you mean exactly by the bottom portion of a block?” and “how is the block to include the bundle predetermined?”. Our idea is pretty simple: Partition the block in such a way to keep a top-of-the-block (ToB)<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-1" id="footnote-ref-48655-1">[1]</a></sup>, high-priority section, in which traditional builders do their usual thing and is allocated through a traditional mev-boost auction or whatever the relay running it prefers; and a reserved bottom-of-the-block (BoB) section, which will serve as allocation space for preconfirmations. In this design, preconfirmation bundles will be allocated via a separate auction in the form of <strong><em>forward contracts</em></strong>.</p>
<h3><a class="anchor" href="https://ethresear.ch#a-two-auction-format-4" name="a-two-auction-format-4"></a><img alt=":busts_in_silhouette:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/busts_in_silhouette.png?v=12" title=":busts_in_silhouette:" width="20" /> A Two-Auction Format</h3>
<p>As briefly mentioned above, in the XGA-style split-block design, preconfirmations are allocated in a completely separate way from the traditional mev-boost auction, allowing them to coexist without excessively disrupting the ecosystem. Traditional builders will be able to do their own thing with minimal adjustments, while everyone else can still enjoy the benefits of preconfirmations.</p>
<p>In simple terms: An XGA-style BoB auction is a multi-unit auction selling gas tokens for a specific block <span class="math">B</span> in fixed-size units (e.g. <span class="math">100</span> K gas). These tokens can then be used to submit a bundle<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-2" id="footnote-ref-48655-2">[2]</a></sup> that is guaranteed inclusion in <span class="math">B</span> if execution is successful.</p>
<p>As an example, picture this scenario:</p>
<ul>
<li><img alt=":clock2:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/clock2.png?v=12" title=":clock2:" width="20" /> At the start of epoch <span class="math">N-2</span> we know that the validator <span class="math">V</span>, serving XGA-style preconfirmations, will be the proposer for the <span class="math">K</span>-th slot of epoch <span class="math">N</span>.</li>
<li><img alt=":oil_drum:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/oil_drum.png?v=12" title=":oil_drum:" width="20" /> $5$M gas out of the standard <span class="math">30</span> M will be auctioned off into <span class="math">50</span> gas tokens, each representing a capacity of <span class="math">100</span> K gas.</li>
<li><img alt=":shopping_cart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/shopping_cart.png?v=12" title=":shopping_cart:" width="20" /> At some fixed time <span class="math">t</span> before the start of slot <span class="math">K</span>, a multi-unit auction allocating the tokens is run. Aki manages to win 5 tokens for <span class="math">K</span>, for a combined capacity of <span class="math">500</span> K.</li>
<li><img alt=":alarm_clock:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/alarm_clock.png?v=12" title=":alarm_clock:" width="20" /> Within the deadline fixed at some time <span class="math">d</span> before the end of <span class="math">K</span>, Aki uses the <span class="math">5</span> tokens to submit a bundle of size just over <span class="math">400</span> K gas.</li>
<li><img alt=":outbox_tray:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/outbox_tray.png?v=12" title=":outbox_tray:" width="20" /> In the meantime, other BoB auction winners submit their own bundles.</li>
<li><img alt=":dollar:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/dollar.png?v=12" title=":dollar:" width="20" /> At the start of <span class="math">K</span>, a traditional mev-boost auction for <span class="math">25</span> M gas is run as usual by all relays, and is won by Bogdan via relay <span class="math">R</span>.</li>
<li><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> After deadline <span class="math">d</span> is reached and the mev-boost auction is over, the BoB part is assembled and attached at the bottom of the max-<span class="math">25</span> M block submitted by Bogdan via relay <span class="math">R</span>.</li>
<li><img alt=":tada:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/tada.png?v=12" title=":tada:" width="20" /> Since Aki’s bundle contained no reverting transactions, it is included without any problem – together with the non-reverting bundles submitted by the other BoB winners – somewhere after the portion built by Bogdan.</li>
<li><img alt=":satellite:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/satellite.png?v=12" title=":satellite:" width="20" /> The block for <span class="math">K</span> gets broadcasted as usual.</li>
<li><img alt=":x:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/x.png?v=12" title=":x:" width="20" /> Excess tokens for <span class="math">K</span> that didn’t get spent can no longer be used.</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#who-builds-the-blocks-then-5" name="who-builds-the-blocks-then-5"></a><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> Who Builds the Blocks, then?</h3>
<p>Block building, in the case of XGA-style preconfirmations, is handled by multiple parties:</p>
<ul>
<li><img alt=":package:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/package.png?v=12" title=":package:" width="20" /> The ToB part is built by traditional mev-boost builders as usual.</li>
<li><img alt=":gift:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/gift.png?v=12" title=":gift:" width="20" /> The BoB part is assembled by the party running the BoB auction.</li>
<li><img alt=":brick:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/brick.png?v=12" title=":brick:" width="20" /> Merging the two parts and sending the block over is handled by the relay.</li>
</ul>
<p>In this setup, the relay takes on more work and responsibilities than it currently does. We will explore a potentially beneficial approach to this change later.</p>
<h3><a class="anchor" href="https://ethresear.ch#what-are-the-economic-advantages-of-preconfirmations-6" name="what-are-the-economic-advantages-of-preconfirmations-6"></a><img alt=":money_with_wings:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/money_with_wings.png?v=12" title=":money_with_wings:" width="20" /> What Are the Economic Advantages of Preconfirmations?</h3>
<p>Well… In general, for the whole range of designs that are being discussed right now this is not clear yet! <strong>Conjecturally</strong>, some of the proposed preconfirmation mechanisms will allow more value to trickle down to validators, but since the preconfirmation design landscape is so broad and confused right now it’s hard to take into account all the possible market effects that could come out of such designs. For example, most of the preconf mechanisms currently being discussed are pretty unfriendly towards what has been one of the main APY-cows for validators since the dawn of mev-boost: competitive builder/searchers.</p>
<h4><a class="anchor" href="https://ethresear.ch#why-are-we-betting-on-xga-style-preconfs-7" name="why-are-we-betting-on-xga-style-preconfs-7"></a><img alt=":game_die:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/game_die.png?v=12" title=":game_die:" width="20" /> Why Are We Betting on XGA-Style Preconfs?</h4>
<p>It seems clear to us that reserving a spot for non-priority-sensitive transactions can offer several benefits:</p>
<ul>
<li>Users and platforms (e.g. rollups) that are not involved in competitive building/searching just doesn’t care about running HFT operations on L1 can greatly benefit from separating their concerns from those of competitive builder/searchers.</li>
<li>On the other end, it eases some of the pressure on the competitive builder/searcher side by removing some of the burden of having to include <em>“filler transactions”</em> to keep their blocks competitive. E.g. freeing them from needing to include blob-bearing transactions that could negatively impact latency.</li>
<li>It makes actually pricing inclusion preconfirmations simpler, since it is still regulated by the usual gas pricing model, and at the same time the preconf inclusion market is kept separate from the traditional priority market for position-sensitive transactions.</li>
<li>Moreover, we believe in gradual change, allowing time for everyone to adapt to and observe the effects of new, potentially disruptive features in a controlled manner. A split-block design compatible with traditional mev-boost block building offers a less intrusive path to adoption.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#rethinking-relays-8" name="rethinking-relays-8"></a><img alt=":bulb:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/bulb.png?v=12" title=":bulb:" width="20" /> Rethinking Relays</h2>
<p>At the moment running a relay naively is mostly a non remunerative gig. Under XGA-style preconfirmations, the relay does significantly more work and takes on more risk than before, e.g. if a block is missed and/or already sold preconfirmation tokens end up not getting included due to the relay malfunctioning, whoever bought them incurs an active loss of assets. While this sounds scary, it is also a good opportunity to rethink the role of relays in the Ethereum ecosystem.</p>
<h3><a class="anchor" href="https://ethresear.ch#insurance-and-reward-mechanisms-for-relays-9" name="insurance-and-reward-mechanisms-for-relays-9"></a><img alt=":shield:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/shield.png?v=12" title=":shield:" width="20" /> Insurance and Reward Mechanisms for Relays</h3>
<p>What we are proposing is that a relay can subscribe to an XGA-style preconf platform by staking a collateral that could be used to offer the damaged parties a refund in case of the relay malfunctioning, while sharing a percentage of the platform revenue each time it submits a successful block that includes XGA-enabled preconfirmations<sup class="footnote-ref"><a href="https://ethresear.ch#footnote-48655-3" id="footnote-ref-48655-3">[3]</a></sup>.</p>
<h2><a class="anchor" href="https://ethresear.ch#introducing-xga-10" name="introducing-xga-10"></a><img alt=":mega:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/mega.png?v=12" title=":mega:" width="20" /> Introducing XGA</h2>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/4/448bd42d21b7642cd38d003f7cec9cb82adfc3b6.png" title="image"><img alt="image" height="99" src="https://ethresear.ch/uploads/default/optimized/3X/4/4/448bd42d21b7642cd38d003f7cec9cb82adfc3b6_2_690x99.png" width="690" /></a></div><br />
XGA – eXtensible Gas Auctions – is the first L2 platform for XGA-style preconfirmations (lol), designed and built by the combined efforts of <a href="https://www.manifoldfinance.com/" rel="noopener nofollow ugc">Manifold Finance</a> and <a href="https://20squares.xyz/" rel="noopener nofollow ugc">20Squares</a>. We’re very willing to make this an open and collaborative effort, so if you have any feedback and/or are interested in building this together with us, please reach out!<p></p>
<p>Right now we have released on mainnet our v1.0 (yes, this is not a beta, <strong>we’re ready to go</strong> and currently onboarding validators), with the caveat that in v1.0, the ToB mev-boost auction can only be run on a single relay. We’re currently working on shipping v2.0, which will allow a <strong>relay-agnostic</strong> auction to be run in the ToB part. You can find more about it at <a href="https://docs.xga.com/" rel="noopener nofollow ugc">docs.xga.com</a>.</p>
<hr class="footnotes-sep" />

<ol class="footnotes-list">
<li class="footnote-item" id="footnote-48655-1"><p>We have specific terms for ToB and BoB auctions, namely α and β-auctions respectively. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-1">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-48655-2"><p>Note that this doesn’t exclude the possibility of overwriting an already submitted bundle, if re-submitted before the deadline. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-2">↩︎</a></p>
</li>
<li class="footnote-item" id="footnote-48655-3"><p>We are already iterating on designs for captive insurance mechanisms for XGA-style platforms. We will upload a new post detailing some of the possible designs soon. <a class="footnote-backref" href="https://ethresear.ch#footnote-ref-48655-3">↩︎</a></p>
</li>
</ol>
            <p><small>4 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/preconfirmations-on-splitting-the-block-mev-boost-compatibility-and-relays/19837">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 09:40:41 +0000</pubDate>
</item>
<item>
<title>IPv6 vs Ethereum?</title>
<link>https://ethresear.ch/t/ipv6-vs-ethereum/19829</link>
<guid>https://ethresear.ch/t/ipv6-vs-ethereum/19829</guid>
<content:encoded><![CDATA[
<div> 关键词：IPv6、CGA、BCA、Subnet ID、Interface ID

总结: 这篇文章探讨了IPv6地址结构与以太坊区块链网络之间的类比。作者提出将IPv6 Subnet ID和Interface ID的概念应用于以太坊，形成类似VPC（虚拟私有云）的结构，每个链对应不同的Subnet。使用加密技术如Cryptographically Generated Addresses (CGA) 和 Bitcoin Address-based Addresses (BCA)，可以增强节点身份验证和隐私保护。这种设想旨在通过利用IPv6的发现协议和现有机制，简化Solano节点设置，解决网络碎片问题，并增强跨链通信的安全性。 <div>
<p>I started writing this after a few days of unsuccessful attempts to run solo node behind CGNAT, as just a brainbreeze on whether it could be somehow done differently to ease up solo node setup.<br />
So far It does not seem to be an answer, however I want to share some thoughts on analogies seen with ipv6 networking to see if anyone has ideas on how this can be useful . .</p>
<h2><a class="anchor" href="https://ethresear.ch#ipv6-101-1" name="ipv6-101-1"></a>ipv6 101</h2>
<p>An IPv6 address consists of 128 bits, represented as eight groups of four hexadecimal digits separated by colons. Each group is called a hextet. For example:</p>
<p><code>2001:0db8:85a3:0000:0000:8a2e:0370:7334</code></p>
<p>where</p>
<ul>
<li>Global Routing Prefix: 2001:0db8 (Assigned by the Regional Internet Registry)</li>
<li>Subnet ID: 85a3:0000 (Identifies a specific subnet within the network)</li>
<li>Interface ID: 0000:8a2e:0370:7334 (identify the individual interface or device on the subnet)</li>
</ul>
<p>This hierarchical structure allows for efficient routing of IPv6 packets. Routers can quickly determine the destination network based on the global routing prefix, then further refine the path based on the subnet ID.</p>
<p><em>Multiple gateways</em> from ipv6 subnet may exist to public ipv6 space. Addresses within ipv6 sub network may access global ipv6 address space. Routing protocols such as <a href="https://datatracker.ietf.org/doc/html/rfc5340" rel="noopener nofollow ugc">OSPFv3</a> or <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol" rel="noopener nofollow ugc">BGP</a> may be used.</p>
<h2><a class="anchor" href="https://ethresear.ch#subnet-gateway-analogy-2" name="subnet-gateway-analogy-2"></a>Subnet Gateway analogy</h2>
<p>Just as an IPv6 router directs traffic to devices within its subnet, an RPC node facilitates communication with nodes and smart contracts within its respective blockchain network.</p>
<p>When we consider the concept of Chain IDs. In blockchain, Chain IDs are unique identifiers for different networks (e.g., Ethereum Mainnet has Chain ID 1, while various testnets have different IDs). Similarly, in IPv6, a subnet is identified by its unique prefix, which is a portion of the IPv6 address.</p>
<h2><a class="anchor" href="https://ethresear.ch#address-analogy-3" name="address-analogy-3"></a>Address analogy</h2>
<p>Since Interface Ids in IPv6 are only 64 bits long, they are too small to fit in 160 bits address of Eth.</p>
<p>However, what could be useful is using InterfaceIds to identify the nodes in the P2P network, forming VPC for Ethereum.</p>
<p>In IPv6, organizations or individuals can assign themselves a unique subnet prefix, effectively creating their own independent addressing space.</p>
<h3><a class="anchor" href="https://ethresear.ch#cryptography-for-ipv6-address-generation-4" name="cryptography-for-ipv6-address-generation-4"></a>Cryptography for IPv6 address generation</h3>
<p><a href="https://en.wikipedia.org/wiki/Secure_Neighbor_Discovery" rel="noopener nofollow ugc">Secure Neighbor Discovery (SEND)</a> is a security extension to the Neighbor Discovery Protocol (NDP) in IPv6, designed to address the vulnerabilities in the original NDP.</p>
<p>There are several papers and RFCs (Requests for Comments) relevant to cryptography for IPv6 address generation, particularly focusing on enhancing privacy and security:</p>
<p><strong><a href="https://datatracker.ietf.org/doc/html/rfc3972" rel="noopener nofollow ugc">RFC 3972</a> - Cryptographically Generated Addresses (CGA)</strong>: This RFC introduces the concept of CGA, where the interface identifier of an IPv6 address is generated using a cryptographic hash function from a public key and other parameters. This approach aims to bind a public key to an address securely, deterring address theft and enhancing authentication.</p>
<p><strong><a href="https://datatracker.ietf.org/doc/html/rfc7721" rel="noopener nofollow ugc">RFC 7721</a> - Security and Privacy Considerations for IPv6 Address Generation Mechanisms</strong>: This RFC discusses the security and privacy implications of different IPv6 address generation mechanisms, including SLAAC, privacy extensions, and CGAs. It provides recommendations for mitigating potential risks and improving privacy protection.</p>
<p><strong><a href="https://www.researchgate.net/publication/350518202_IPv6_Cryptographically_Generated_Address_Analysis_Optimization_and_Protection" rel="noopener nofollow ugc">IPv6 Cryptographically Generated Address: Analysis, Optimization and Protection</a></strong>:  This paper delves into the details of CGAs, analyzing their security and performance characteristics. It proposes optimizations to improve the efficiency of CGA generation and suggests additional security measures to strengthen the protection they offer.</p>
<p><strong><a href="https://arxiv.org/pdf/2311.15842" rel="noopener nofollow ugc">IPv6 Bitcoin-Certified Addresses, Mathieu Ducroux</a></strong>: proposes mechanism for enhancing the security and privacy of IPv6 addresses by leveraging the Bitcoin blockchain.<br />
In essence, BCAs are IPv6 addresses where the interface identifier is derived from a Bitcoin address.</p>
<h2><a class="anchor" href="https://ethresear.ch#how-could-this-be-beneficial-5" name="how-could-this-be-beneficial-5"></a>How could this be beneficial?</h2>
<p>If we can think of ethereum ecosystem as one big VPN where chains are subnet addressable that potentially solves fragmentation issues, allowing to use already established discovery protocols to route traffic between different nodes, use features like <a href="https://en.wikipedia.org/wiki/Multicast_address" rel="noopener nofollow ugc">multicast</a> etc.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/ipv6-vs-ethereum/19829">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 21:28:45 +0000</pubDate>
</item>
<item>
<title>Slot Inclusion Rates and Blob Market Combinatorics</title>
<link>https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817</link>
<guid>https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817</guid>
<content:encoded><![CDATA[
<div> 关键词：slot inclusion rate, blob market, integer packing problem, reorg risk, builder censorship

总结:<br />本文探讨了blob市场的slot inclusion rate（区块包含率）问题，指出其存在高波动性和某些Rollup（如Optimism和Base）的高值。文章分析了当前blob提交策略导致的竞争和整数打包问题（integer packing problem），这可能导致更高的slot inclusion rate而非建设者审查。研究发现，虽然市场容量未充分利用，但大blob交易的策略（如Base一次提交多个）导致平均slot inclusion rate较高。文章还提出了优化建议，如调整最大blob数量、动态投标策略和预确认机制，以提高效率并减少竞争中的潜在延迟审查。总的来说，文章强调了blob市场设计对slot inclusion rate影响的重要性，并呼吁进一步研究来改善市场动态。 <div>
<h2><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TLDR</h2>
<ul>
<li><strong>Slot inclusion rate</strong>, the number of slots required for a blob to be included in the beacon chain, has a high variance and is higher for some rollups than others.</li>
<li>The current combinatorics of the blob market has an <strong>integer packing problem</strong>. This is a type of combinatorial optimization that generally involves packing objects of different sizes into a finite number of containers or bins.</li>
<li>Data suggests that the integer packing problem is contributing more to higher slot inclusion rates than builder censorship.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h2>
<p>This post offers a fresh perspective on the current design and constraints of the blob market, presenting additional data (<a href="https://blobs.primev.xyz/dashboard" rel="noopener nofollow ugc">from a blob tracking dashboard created at Primev</a>) on slot inclusion concerning reorg risks, and a combinatorial analysis of the blob market design, revealing an integer packing problem.</p>
<p>The key metric in this post is the <strong>slot inclusion rate</strong>. The slot inclusion rate indicates the number of slots required for a blob to be included in the beacon chain,<br />
with a higher rate signifying a longer inclusion time.</p>
<p>Recent research on the blob market <a href="https://ethresear.ch/t/big-blocks-blobs-and-reorgs/19674">[1]</a>, <a href="https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783">[2]</a>, <a href="https://mirror.xyz/preconf.eth/cxUO8pPBfqnqAlzFUzoEUa6sgnr68DRmsNhBWPb2u-c" rel="noopener nofollow ugc">[3]</a> has focused on how larger blobs increase reorg risk due to higher latency. This could incentivize builder censorship to reduce latency by excluding blobs from blocks.</p>
<p>Despite the blob market being under capacity and the base fee remaining at 1 wei, research <a href="https://mirror.xyz/preconf.eth/6lZYL62DR9U14KC7wCC4RHReVdHcBeMy5PKeHVbPq5k" rel="noopener nofollow ugc">[4]</a> shows that rollups like Optimism and Base often have high slot inclusion rates, taking more than five slots to be included. Given the underutilized market, this seems counterintuitive, suggesting possible latency censorship. However, the current blob submission strategies and blob market combinatorics suggest that higher slot inclusion rates may indicate increased competition between blob producers rather than builder censorship.</p>
<h2><a class="anchor" href="https://ethresear.ch#blob-submission-strategies-3" name="blob-submission-strategies-3"></a>Blob Submission Strategies</h2>
<p>The below table <a href="https://analytics.mev-commit.xyz/dashboard" rel="noopener nofollow ugc">from the dashboard</a> shows a 7 day snapshot of the largest blob market participants.</p>
<p>There are now 3 major strategies across the number of blobs:</p>
<ul>
<li>submit the max 5-6 blobs at a time (blast, base, linea, optimism)</li>
<li>submit 3-4 blobs at a time (arbitrum, zksync)</li>
<li>submit 1-2 blobs at a time (taiko, metal, paradex, scroll)<br />
<div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7e768a0ed198c966965d14171b97d1c2600eea7d.png" title="image"><img alt="image" height="244" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7e768a0ed198c966965d14171b97d1c2600eea7d_2_690x244.png" width="690" /></a></div></li>
</ul>
<p>Aggregating blobs into fewer transactions reduces transaction expenses (base fee, blob fee, priority fee) but increases slot inclusion times. In contrast, smaller blob transactions improve slot inclusion times at the cost of higher transaction expenses.</p>
<h2><a class="anchor" href="https://ethresear.ch#slot-inclusion-rates-4" name="slot-inclusion-rates-4"></a>Slot Inclusion Rates</h2>
<p>The next chart displays a time series overlay of base block demand (total transaction fees and base fee in gwei) with the slot inclusion rate for each blob transaction. It shows high slot inclusion rates, up to 30 slots, even during periods of low blockspace demand.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/3/832319c888134f3fe0b465411923147c0c85c5fa.png" title="image"><img alt="image" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/8/3/832319c888134f3fe0b465411923147c0c85c5fa_2_690x258.png" width="690" /></a></div><p></p>
<p>The table mentioned earlier above contains the average slot inclusion rate for each rollup. Base, which submits the largest blobs in each transaction has the highest, averaging 13 slots. Taiko has the lowest average at 1.7 slots and submits only single blobs for each transaction right now.</p>
<p><strong>Base slot inclusion rate:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/a/5/a5f9d2f0d94388d88993444ae9da999347121e7e.png" title="image"><img alt="image" height="300" src="https://ethresear.ch/uploads/default/optimized/3X/a/5/a5f9d2f0d94388d88993444ae9da999347121e7e_2_690x300.png" width="690" /></a></div><p></p>
<p>taiko slot inclusion rate<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/e/ce84eb73e15b668adaa7dc811f23e8c3606000ee.png" title="image"><img alt="image" height="300" src="https://ethresear.ch/uploads/default/optimized/3X/c/e/ce84eb73e15b668adaa7dc811f23e8c3606000ee_2_690x300.png" width="690" /></a></div><p></p>
<h2><a class="anchor" href="https://ethresear.ch#builder-slot-inclusion-rates-5" name="builder-slot-inclusion-rates-5"></a>Builder Slot Inclusion Rates</h2>
<p>This table examines slot inclusion rates from the builder’s perspective, including the number of blocks, blob transactions, average blob count, and priority fees collected.</p>
<p>A higher slot inclusion rate means a blob has waited longer to be included in a block. An efficiency metric would be to have the lowest possible slot inclusion rate, indicating that builders are including blobs sooner rather than later.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/9/f/9fe6938327d570742a8b7f278788cacfa4df81ca.png" title="image"><img alt="image" height="211" src="https://ethresear.ch/uploads/default/original/3X/9/f/9fe6938327d570742a8b7f278788cacfa4df81ca.png" width="690" /></a></div><p></p>
<p>Builders like Titan and Beaverbuild have more efficient blob slot inclusion rates than vanilla builders. They also have the lowest average blobs per block. This could be due to their efficiency in accepting strategies like Taiko blobs over other block builders.</p>
<h2><a class="anchor" href="https://ethresear.ch#combinatorics-6" name="combinatorics-6"></a>Combinatorics</h2>
<p><a href="https://colab.research.google.com/drive/1EeRpWjb0meIi53IyyyZu7QWmg8HqVAMr#scrollTo=PDAJADyB24Jv" rel="noopener nofollow ugc">This notebook</a> uses dynamic programming to count the number of combinations of blobs for the current blob market. Given the current 6 blob per block capacity and 6 blobs per block, there are 11 possible combinations.</p>
<p><strong>Occurrences of each number:</strong><br />
1: 19<br />
2: 8<br />
3: 4<br />
4: 2<br />
5: 1<br />
6: 1</p>
<p>A trivial observation is that there is only one combination in which a block can fit 5 or 6 blobs. Since 4 out of 10 rollups submit these 5 and 6 blob transactions, there will only be one winner. Additionally, a single 1-blob transaction can “censor” a 6-blob transaction for an entire slot by being accepted first.</p>
<p>The combinatorics of the current blob market size suggest that the small size itself is causing higher slot inclusion problems, rather than blob censorship latency. This indicates that censorship is not from builders but from competition among blob users.</p>
<p>This raises an important question: what is the optimal maximum number of blobs allowed in a block relative to the maximum number that can fit in a block? Would the combinatorics be more favorable if the maximum blob size were 3 instead of 6? Would it be better to allow 9 blobs per block instead of 8? There is an economic incentive to group blobs as large as possible to save on costs, which disproportionately favors larger rollups over smaller ones until blob sharing becomes feasible.</p>
<h2><a class="anchor" href="https://ethresear.ch#bidding-strategies-7" name="bidding-strategies-7"></a>Bidding Strategies</h2>
<p>Currently, blobs use static bidding strategies, generally resubmitting their blobs if their bids sit in the mempool for too long. This shows a certain level of insensitivity to slot inclusion for each rollup. If a blob is delayed for 100 slots, there seem to be no consequences or incentives to increase slot inclusion rates at this time.</p>
<p>The two charts below show sample bidding strategies used by Base and Taiko, just two examples of the rollup strategies available on the dashboard. Base averages a priority fee of 4.5 gwei, while Taiko averages 2.9 gwei. There is no correlation between priority bids and base fee fluctuations.</p>
<p><strong>base:</strong><br />
<img alt="image" height="336" src="https://ethresear.ch/uploads/default/original/3X/8/7/8785ccb0b147a318d6426a694bf7697d3f1a5383.png" width="501" /></p>
<p><strong>taiko:</strong><br />
<img alt="image" height="336" src="https://ethresear.ch/uploads/default/original/3X/9/1/91bab571ac6836399edf78b7c7ce757ad62cf2ed.png" width="501" /></p>
<p>Resubmitting blobs through the mempool is expensive and generally not recommended as a good practice. This creates the problem of how blob producers can become more competitive in their bidding strategies if they need to make their slot inclusion rates more efficient.</p>
<p>One solution is to use preconfirmations. For example, using a protocol such as mev-commit to attach preconf bids to blob transactions would allow rollups to dynamically adjust their bids without having to resubmit blobs into the mempool. A stronger solution would be <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">to receive preconfirmations from proposers</a> to guarantee that builders wouldn’t be able to censor blobs.</p>
<h3><a class="anchor" href="https://ethresear.ch#conclusion-8" name="conclusion-8"></a>Conclusion</h3>
<p>Analysis of slot inclusion rates and blob market combinatorics reveals a complex interplay between efficient slot inclusion, competition, and potential censorship. While current data suggests that high slot inclusion rates are primarily driven by competition among blob users, there remain several unanswered questions:</p>
<ul>
<li>What is the optimal maximum number of blobs per block to balance efficiency and fairness?</li>
<li>How can blob producers develop more competitive bidding strategies?</li>
<li>Could the implementation of dynamic bidding strategies or preconfirmations significantly reduce slot inclusion times?</li>
<li>What long-term effects might increased competition and potential latency censorship have on the blob market?</li>
</ul>
<p>The combinatorics of the blob market are a fundamental factor affecting slot inclusion efficiency and cost. By understanding and optimizing these combinatorial constraints, it is possible to enhance market dynamics, reduce costs, and improve transaction efficiency for all participants. Further research and experimentation are needed to address these questions and optimize the blob market for all participants.</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/slot-inclusion-rates-and-blob-market-combinatorics/19817">Read full topic</a></p>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 16:47:05 +0000</pubDate>
</item>
<item>
<title>A simple, small, mev-boost compatible preconfirmation idea</title>
<link>https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800</link>
<guid>https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-boost、preconfs、proposer、relayer、merging policies

总结:<br />
本文提出了一种扩展MEV-boost以支持预配置交易（preconfs）的机制。该想法保持了现有MEV-boost流程的稳定性，仅改变提案阶段，让提案者在开始投票前提供预配置交易列表。提案者发送包含交易要求的签名JSON对象给中继器，如必须包含或排除的交易。中继器根据合并策略处理这些信息，同时保持传统MEV-boost拍卖的兼容性。尽管存在一些挑战，如中继器的额外计算负担和预配置信息的一致性问题，但作者认为这个设计有助于减少生态系统分裂，且具有渐进式替代MEV-boost的潜力。 <div>
<p><strong>Disclaimer</strong>: This post will not contain any nice images, because I am artistically inept.</p>
<p>The reasons why I’m writing this are the following:</p>
<ol>
<li>Preconfs are a very hot topic right now and many people are working on them;</li>
<li>As usual, some of the proposed solutions advocate for punching changes all the way into the main Ethereum protocol. I’m personally not a fan of this, since life is already full of <em>oh my God, what have I done?™</em> moments and <em>more drama™</em> is the least thing everyone probably needs.</li>
<li>MEV-boost is probably the <em>only</em> thing this community has really almost universally agreed upon since MEV has been a thing. So I’d very much try to preserve backwards-compatibility with MEV-boost and generalize on this than coming up with more innovative ways to balkanize our ecosystem even further.</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#a-primer-on-mev-boost-1" name="a-primer-on-mev-boost-1"></a>A primer on MEV-boost</h2>
<p>This section exists just so that everyone is on the same page. Feel free to skip it or to insult me if you think I summarised things stupidly.</p>
<p>In layman terms, MEV-boost works like this:</p>
<ol>
<li>Proposer polls the relayer(s) for their best blocks;</li>
<li>Relayer(s) send their best block headers to proposer;</li>
<li>Proposer picks the best block by comparing the block headers received and the block built in-house.</li>
<li>For an in-house block, proposer just signs and broadcasts. For a mev-boost block, proposer signs the header. Relay will broadcast the complete block revealing the payload.</li>
</ol>
<p>This mechanism is nice because the only party that builders have to trust is relayer: Proposer cannot unbundle blocks and scam builders.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-actual-idea-2" name="the-actual-idea-2"></a>The actual idea</h2>
<p>The idea I have in mind works towards extending mev-boost by allowing for preconfs (and most likely for a lot of other stuff if one wants to). Notably, it does not change points 2,3,4 in the previous section, but only point 1.</p>
<p>Suppose proposer has a stash of preconfed txs on the side. The only thing the idea assumes is the following:</p>
<blockquote>
<p>By the time Proposer starts polling, it needs to have a finalized lists of preconfed txs to include.</p>
</blockquote>
<p>The reason for this will become clear shortly. Having this list at hand, proposer sends a signed JSON object to the relayer when it polls, containing the preconfed txs. This object could look, for instance, like this:</p>
<pre><code class="lang-JSON">{
    proposer: address,
    slotNumber: int,
    gasUsed: int,
    blobsUsed: int.
    mergingPolicy: int,
    mustBeginWith: txBundle,
    mustContain: txBundle,
    mustOmit: txBundle,
    mustEndWith: txBundle,
    otherStuff: JSON,
    signature : signature
}
</code></pre>
<p><strong>This design is just an idea. It is by no means fixed yet and most likely can be improved upon both in conceptual and performance terms, so take it with a grain of salt.</strong><br />
The fields <code>proposer</code> and <code>slotNumber</code> are obvious. The fields <code>mergingPolicy</code>, <code>mustBeginWith</code>, <code>mustContain</code>, <code>mustOmit</code>, <code>mustEndWith</code> can all be empty: They contain bundles of transactions that must (or must not) be included in the block. These fields are, effectively, the ones that proposer can use to signal relayer that 'hey, I need the block to respect these requirements, because of previous agreement I made with other parties."</p>
<p>How the proposer comes to define this json object is not our concern, and is outside of the scope of this idea. Just for the sake of clarity though, let’s consider some examples: For instance, <a href="https://docs.xga.com" rel="noopener nofollow ugc">XGA</a>, one of the projects <code>20[ ]</code> is contributing to, provides preconfs as tokenized bottom-of-block space. As such, XGA-style preconfs will produce objects where only <code>mustEndWith</code> is not empty.</p>
<p>The fields <code>gasUsed</code> and <code>blobsUsed</code> tell the relay how much gas and blobs the ‘preconf space’ already claimed. <code>otherStuff</code> exists to be able to extend this standard in the future without <em>more drama™</em>.</p>
<h3><a class="anchor" href="https://ethresear.ch#merging-policies-3" name="merging-policies-3"></a>Merging policies</h3>
<p>The <code>mergingPolicy</code> fields instructs the relay about how to deal with all this information. This is fundamental because, in the end, the relay will still run a traditional mev-boost auction for the remaining blockspace. As soon as a block is built by more than one party there’s a risk that different parties may step up on each other’s toes. As such, <code>mergingPolicy</code> serves as a well-defined conflict resolution policy. If you need a mental reference, think about git conflicts and automated ways to solve them if you so like.</p>
<p>How to define merging policies is up for debate. The community could agree on a common repository where merging policies are defined, voted and agreed upon, and where merging algos are explicitly provided. So, for instance, one merging policy could be:</p>
<blockquote>
<p>If the payload coming from the builder contains a transaction that also appears in the preconf bundle, deal with it in the following way:</p>
</blockquote>
<p>As said above, XGA sells BOB as preconfs, and leaves TOB open for traditional mev-boost auctions. As such, it has already defined and implemented a merging policy for its bottom of the block case, which will hopefully be open sourced soon.</p>
<h3><a class="anchor" href="https://ethresear.ch#what-does-the-relay-do-4" name="what-does-the-relay-do-4"></a>What does the relay do?</h3>
<p>This is probably already kinda clear at this point, but to make it explicit: The relay receives this signed JSON object when the proposer polls. What should it do with it? First of all, it should make some of these fields public to the builders, such as <code>mergingPolicy</code>, <code>gasUsed</code>, <code>blobsUsed</code> and <code>mustOmit</code>. This way builders will know what they can build.</p>
<p>When a block from a builder is received, the relayer will <strong>unbundle</strong> the block and apply the merging policy to merge it with the preconfed txs. The <strong>relay</strong> will sign the block header, and send it to the proposer.</p>
<p>From the POV of a builder, everything is kinda the same. They create their block using the info provided by the relay (in the simplest case this just means using slightly less gas than limit), and submit it as their bid.</p>
<p>From this point on, everything works as in traditional MEV-boost.</p>
<h2><a class="anchor" href="https://ethresear.ch#analysis-5" name="analysis-5"></a>Analysis</h2>
<p>Ok, so let’s run a rapid analysis of this thing.</p>
<h3><a class="anchor" href="https://ethresear.ch#pros-6" name="pros-6"></a>Pros</h3>
<ol>
<li>
<p>Changes to MEV-boost proper are really minimal. We just need to define an API that MEV-boost must listen to to build the polling payload, and redefine the polling logic.</p>
</li>
<li>
<p>Very little work from Proposer’s side. More work may be needed depending on the preconf system a given proposer wants to use, but then again this is out of the scope of this idea.</p>
</li>
<li>
<p>Very little work from builder’s side unless people go overly crazy with merging policies. I do not think this is necessarily a problem tho as an overly deranged merging policy would result in builders not submitting anything, and most likely in relayers not taking bets in the first place. So I’d bet that this could pretty much evolve as a ‘let the markets decide’ thing.</p>
</li>
<li>
<p>This idea is straightforwardly backwads-compatible with traditional MEV-boost: If the polling payload is empty, we collapse to a traditional MEV-boost auction with no other requisites.</p>
</li>
<li>
<p>This idea allows for gradual phasing out of MEV-boost if the community so decides. For instance, proposers may agree to produce bundles where <code>usedGas</code> is a very low parameter in the beginning (it won’t exceed 5M for XGA, for instance), meaning that the majority of blockspace would come from traditional building, with only a tiny part being preconfs or more generally ‘other stuff’. This parameter may then be increasingly crancked up or varied with time if the community so decides, effectively phasing out traditional block building in favor of ‘something else’. In this respect yes, I know I’m being vague here but when it comes to how this thing could be adopted I can only speculate.</p>
</li>
<li>
<p>This system can be extended in many ways, and it is flexible. Merging policies could be defined democratically, and the polling info could be extended effectively implementing something akin to PEPSI, for instance. Another possible extension/evolution can be using <code>otherStuff</code> to define Jito-style auctions. I mean, there’s really a plethora of ways to go from here.</p>
</li>
<li>
<p>The polling payload is signed by the proposer, and the block header is signed by the relayer. This keeps both parties in check as we accumulate evidence for slashing both. For instance:</p>
<ul>
<li>Imagine I get some preconf guarantee from proposer and that I have evidence of this. Again how this happens is outside of the scope of this post, as this mechanism is agnostic wrt how preconfs are negotiated.</li>
<li>Now suppose furthermore than my preconfed tx does <strong>not</strong> land in the block.</li>
<li>I can use the chain of signed objects to challenge both relayer and proposer. If my tx wasn’t in the polling info signed by proposer, that’s proposer’s fault. On the other hand, if it was, but it wasn’t in the block, then it’s relayer’s fault. I think this is enough to build a slashing mechanism of sorts, which could for instance leverage some already available restaking solution.</li>
</ul>
<p><strong>Note:</strong> If there’s enough interest in this idea, we as 20[  ] can throw some open games at it and simulate the various scenarios. Let me know!</p>
</li>
<li>
<p><strong>Ethereum protocol doesn’t see any of this.</strong> So if it fucks up, we just call it a day and retire in good order without having caused the apocalypse: Relays will only accept empty payloads, proposers will only send empty payloads, and we’ll essentially revert to mev-boost without anyone having to downgrade their infra. I think this is the main selling point of this idea: The amount of ways to make stuff explode in mev-related infraland are countless, so this whole idea was built with a ‘it has to be failsafe’ idea in mind.</p>
</li>
</ol>
<h3><a class="anchor" href="https://ethresear.ch#cons-7" name="cons-7"></a>Cons</h3>
<ol>
<li>
<p>Relayer must unbundle builder blocks to do the merging. I do not think this creates a huge trust issue as relayer can already do this as of now: In general, a relayer that scams builders is a relayer that won’t be used again, and will go out of business quickly.</p>
</li>
<li>
<p>Relayer must do computational work. This is probably the major pain point. This idea entails slightly more latency, as an incoming bid cannot be relayed instantly because <code>mergingPolicy</code> has to be applied. The computational penalty is furthermore heavily dependent on how deranged the merging policy is. As a silver lining, this computational work is <em>provable</em> as both the merging info and the resulting block are signed. The result is that we have <strong>provable evidence to remunerate a relay for its work if we want to</strong>, possibly solving a major pain point for relayers in traditional mev-boost.</p>
</li>
<li>
<p>Relayer is slashable if it screws up. Again, how this should be implemented is outside of the scope of this idea as this mechanism only accounts for the needed trail of evidence to implement slashing, but does not deal with the slashing per sé. Anyway, it is still worth reasoning on the possible consequences of this: If slashing policies are implemented, Relayers will most likely need to provide some collateral or implement some form of captive insurance. Again, this may signify more complexity on one hand but also opportunity on the other, as relayers may for instance decide to tokenize said collateral and develop mechanisms to make money out of these newly created financial instruments. As relayers are private enterprises I’ll leave these considerations to the interested parties.</p>
</li>
<li>
<p><strong>Polling info must stay fixed</strong>. This is related to point 3 above and point 6 of the <a href="https://ethresear.ch#pros">Pros</a> subsection: If the polling info changes all the time, this means huge computational stress for the relayer, and it furthermore allows for malicious behavior from the proposer: For instance, a proposer could send two different polling payloads, and include a given preconfed tx only in one of them. How to resolve these inconsistencies is an open question. In my opinion, the wisest and simplest thing to do would be requiring the polling info to be fixed, meaning that if proposer signs conflicting payloads for the same slot this should be considered akin to equivocation, and thus a slashable offence.</p>
<p>By the way, the consequence of this is that the idea proposed here necessarily excludes some preconf use cases. This is related to my comment <a href="https://ethresear.ch/t/strawmanning-based-preconfirmations/19695/2">here</a> and I think it is unavoidable if we want to keep MEV-boost around. As the majority  of revenue from MEV comes precisely from the bids of very refined, high-time frame searchers, and as I am quite sure that validators don’t want to give this money up at least for now, ‘leaving these players be’ by ruling out such preconf use-cases is in my opinion the most practical option, and exactly the rationale motivating this idea.</p>
</li>
</ol>
<h2><a class="anchor" href="https://ethresear.ch#closing-remarks-8" name="closing-remarks-8"></a>Closing remarks</h2>
<p>That’s it. If the idea is interesting enough let me know, I’ll be happy to start a discussion around it.  The <code>20[ ]</code> team will also be around at EthCC if you want to discuss this in person.</p>
            <p><small>8 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/a-simple-small-mev-boost-compatible-preconfirmation-idea/19800">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 13:33:55 +0000</pubDate>
</item>
<item>
<title>One-bit-per-attester inclusion lists</title>
<link>https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797</link>
<guid>https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797</guid>
<content:encoded><![CDATA[
<div> 关键词：Inclusion lists, transaction selection, RANDAO_REVEAL, Reed-Solomon decoding, fork choice rule.

总结:
本文提出了一种新的机制，用于在区块链中实现更去中心化的交易入选列表（Inclusion lists）。机制的核心是利用RANDAO_REVEAL生成随机种子，将验证者分为小组，每个小组负责查找优先级高、费用支付的交易，并通过Erasure编码提供与种子相关联的交易部分。如果多数验证者诚实，Reed-Solomon解码可以确定交易；否则，可能需要使用更复杂的方法恢复交易。验证者的选择和交易的入选受制于区块生产者的决定，但通过调整时间权重和fork choice规则，可以增加对长期未被选中的交易的包容性。这种机制旨在减少集中化风险，提高去中心化程度。 <div>
<p>Inclusion lists are a technology for distributing the authority for choosing which transactions to include into the next block. Currently, the best idea for them is to have an actor that is from a set that is likely to be highly decentralized (eg. consensus block proposers) generate the list. This authority is decoupled from the right to <em>order</em> (or <em>prepend</em>) transactions, which is an inherently economies-of-scale-demanding and so likely to be highly concentrated in practice.</p>
<p>But what if we could avoid putting the responsibility onto a <em>single</em> actor, and instead put it on a <em>large set of actors</em>? In fact, we can even do it in such a way that it’s semi-deniable: from each attester’s contribution, there is no clear evidence of which transaction they included, because one individual piece of provided data could come from multiple possible transactions.</p>
<p>This post proposes a possible way to do this.</p>
<h3><a class="anchor" href="https://ethresear.ch#mechanism-1" name="mechanism-1"></a>Mechanism</h3>
<p>When the block for slot N is published, let <code>seed</code> be the RANDAO_REVEAL of the block. Suppose for convenience that each transaction is under <code>T</code> bytes (eg. <code>T = 500</code>); we can say in this initial proposal that larger transactions are not supported. We put all attesters for that slot into groups of size <code>2 * T</code>, with <code>k = attesters_per_slot / (2 * T)</code> groups.</p>
<p>Each attester is chosen to be the j’th attester of the i’th group. They identify the highest-priority-fee-paying valid transaction which was published before the slot N block, and where <code>hash(seed + tx)</code> is between <code>2**256 / k * i</code> and <code>2**256 / k * (i+1)</code>. They erasure-code that transaction to <code>2T</code> bits, and publish the j’th bit of the erasure encoding as part of their attestation.</p>
<p>When those attestations are included in the next block, an algorithm such as <a href="https://en.wikipedia.org/wiki/Berlekamp%E2%80%93Welch_algorithm">Berlekamp-Welch</a> is used to try to extract the transaction from the provided attester bits.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/d/e/deedccb04e5bb133ccacdbe2c2c17d1e5abdc3ce.png" title="attester_inclusion_list.drawio"><img alt="attester_inclusion_list.drawio" height="271" src="https://ethresear.ch/uploads/default/optimized/3X/d/e/deedccb04e5bb133ccacdbe2c2c17d1e5abdc3ce_2_690x271.png" width="690" /></a></div><p></p>
<p>The Reed-Solomon decoding will fail in two cases:</p>
<ol>
<li>If too many attesters are dishonest</li>
<li>If attesters have different views about whether a particular transaction was published before or after the block, and so they are split between providing bits for two or more different transactions.</li>
</ol>
<p>Note that in case (2), if the transactions are sufficiently small, advanced <a href="https://www.cs.cmu.edu/~venkatg/teaching/codingtheory/notes/notes10.pdf">list decoding algorithms</a> may nevertheless be able to recover several or all of the transactions!</p>
<p>The next block proposer will be able to see which transactions the attestations imply, and so they will be able to block transactions from the list by selectively failing to include attestations. This is an unavoidable limitation of the scheme, though it can be mitigated by having a fork choice rule discount blocks that fail to include enough attestations.</p>
<p>Additionally, the mechanism can be modified so that if a transaction has not been included for 2+ slots, <em>all</em> attesters (or a large fraction thereof) attempt to include it, and so any block that fails to include the transaction would lose the fork choice. One simple way to do this is to score transactions not by <code>priority_fee</code>, but by <code>priority_fee * time_seen</code>, and at the same time have a rule that a transaction that has been seen for <code>k</code> slots is a candidate not just for attester group <code>i</code>, but also for attester group <code>i...i+k-1</code> (wrapping around if needed).</p>
            <p><small>8 posts - 7 participants</small></p>
            <p><a href="https://ethresear.ch/t/one-bit-per-attester-inclusion-lists/19797">Read full topic</a></p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 09:33:36 +0000</pubDate>
</item>
<item>
<title>Torrents and EIP-4444</title>
<link>https://ethresear.ch/t/torrents-and-eip-4444/19788</link>
<guid>https://ethresear.ch/t/torrents-and-eip-4444/19788</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP-4444、Torrents、Ethereum、Pre-merge data、Merkle roots

总结:
EIP-4444目标是减少以太坊节点所需存储的历史数据。文章介绍了使用BitTorrent技术来分发历史数据的方法，通过在geth v1.14.3版本上创建era文件并验证根文件（roots.txt）来实现。这个过程产生了427GB的torrent文件，用于同步pre-merge数据。虽然torrent有依赖多个活跃节点和增加节点网络需求的缺点，但它提供了一种可能的解决方案。客户端可以选择不预下载数据，用户可以通过命令行或特定标志获取。要重现或验证torrent，需同步geth节点、执行era文件导出和创建torrent，以及使用era工具验证数据完整性。 <div>
<h1><a class="anchor" href="https://ethresear.ch#torrents-and-eip-4444-1" name="torrents-and-eip-4444-1"></a>Torrents and EIP-4444</h1>
<h3><a class="anchor" href="https://ethresear.ch#introduction-2" name="introduction-2"></a>Introduction</h3>
<p>EIP-4444 aims to limit the historical data that Ethereum nodes need to store. This EIP has two main problems that require solutions: Format for history archival and Methods to reliably retrieve history. The client teams have agreed on a common <a href="https://ethresear.ch/t/era-archival-files-for-block-and-consensus-data/13526">era files</a> format, solving one half of the problem. The second half of the problem, i.e Method to reliably retrieve history will likely not rely on a single solution. Some client teams may rely on the <a href="https://ethereum.org/en/developers/docs/networking-layer/portal-network/" rel="noopener nofollow ugc">Portal network</a>, some rely on torrents, others might rely on some form of snapshot storage.</p>
<h3><a class="anchor" href="https://ethresear.ch#torrents-for-eip-4444-3" name="torrents-for-eip-4444-3"></a>Torrents for EIP-4444</h3>
<p>Torrents offer us a unique way to distribute this history, torrents as a technology have existed since 2001 and have withstood the test of time. Some client teams, such as <a href="https://github.com/ledgerwatch/erigon" rel="noopener nofollow ugc">Erigon</a> already include a method to sync via torrents that has run in production systems.</p>
<p>In order to make some progress on the Torrent approach of history retrieval, the files would first be required. So an era file export was made on a <a href="https://github.com/ethereum/go-ethereum/" rel="noopener nofollow ugc">geth</a> running version <code>v1.14.3</code> . To explore the initial idea, the torrent approach chose pre-merge data as a target. The merge occurred at block height <a href="https://etherscan.io/block/15537393" rel="noopener nofollow ugc">15537393</a>, meaning all pre-merge data could be archived by choosing a range of 0 to block 15537393. The era files were then created using the command <code> geth --datadir=/data export-history /data/erafiles 0 15537393</code>.</p>
<p>Once the era files were created, they were verified using the command <code>era verify roots.txt</code>, with the source of the <code>roots.txt</code> file being <a href="https://gist.githubusercontent.com/lightclient/528b95ffe434ac7dcbca57bff6dd5bd1/raw/fd660cfedb65cd8f133b510c442287dc8a71660f/roots.txt" rel="noopener nofollow ugc">this</a>. The entire process has been outlined in <a href="https://github.com/ethereum/go-ethereum/pull/26621#issuecomment-1434023464" rel="noopener nofollow ugc">this PR comment</a>. The verification output was found to be this log message: <code>Verifying Era1 files             verified=1896,  elapsed=5h21m49.184s</code></p>
<p>The output era files were then uploaded onto a server and a torrent was created using the software <code>mktorrent</code>. An updated list of trackers was found using the github repo <a href="https://github.com/ngosang/trackerslist" rel="noopener nofollow ugc">trackerslist</a>. The trackers chosen were a mix of http/https/udp in order to allow for maximal compatibility. The chunk size of the torrent was chosen to be 64MB, which was the max allowed and recommended value for a torrent of this size.</p>
<p>The result of this process is now a torrent of size 427GB. This torrent can be imported with <a href="https://ethresear.ch">this magnet link</a>  and a torrent client would be able to pull the entire pre-merge history as era files.</p>
<h4><a class="anchor" href="https://ethresear.ch#tradeoffs-4" name="tradeoffs-4"></a>Tradeoffs</h4>
<p>There are of course some tradeoffs with torrents, as with many of the other EIP-4444 approaches:</p>
<ul>
<li>Torrents rely on a robust set of peers to share the data, there is however no way to incentivise or ensure that this data is served by peers</li>
<li>A torrent client would need to be included in the client releases and some client languages might not have a torrent library</li>
<li>Torrents would de-facto expect the nodes to also seed the content they leech, this would increase node network requirements if they choose to store history</li>
<li>The JSON-RPC response needs to take into account that it may not have the data to return a response in case the user decides to not download pre-merge data</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#conclusion-5" name="conclusion-5"></a>Conclusion</h3>
<p>A client could potentially include this torrent into their releases and avoid syncing pre-merge data by default, which could then be fetched via torrent if a user requests it (perhaps with a flag similar to <code>--preMergeData=True</code>). The client could also hardcode the hash of the expected data, ensuring that the data retrieved matches what they expect.</p>
<h3><a class="anchor" href="https://ethresear.ch#instructions-for-re-creating-torrent-6" name="instructions-for-re-creating-torrent-6"></a>Instructions for re-creating torrent:</h3>
<ul>
<li>Sync a geth node using the latest release</li>
<li>Stop the geth node and run <code>geth --datadir=/data export-history /data/erafiles 0 15537393</code> to export the data in a folder called <code>data/erafiles</code>(Warning, this will use ~427GB of additional space)</li>
<li>Use the <code>mktorrent</code> tool or the <code>rutorrent</code> GUI to create a torrent. Choose the <code>/data/erafiles/</code> folder as the source for the data. Next, obtain the latest open trackers from <a href="https://github.com/ngosang/trackerslist?tab=readme-ov-file" rel="noopener nofollow ugc">this github repository</a>. Choose a healthy mix of udp/http/https trackers and choose the chunk size of the torrent to be 64MB.</li>
<li>The tool should output a <code>.torrent</code> file, the GUI will also allow you to copy a magnet link if that is required</li>
</ul>
<h3><a class="anchor" href="https://ethresear.ch#instructions-for-download-and-verification-of-torrent-data-7" name="instructions-for-download-and-verification-of-torrent-data-7"></a>Instructions for download and verification of torrent data:</h3>
<ul>
<li>Download the torrent data with this magnet link and in a torrent client of your choice: <a href="https://ethresear.ch">link</a></li>
<li>Clone the latest release of <a href="https://github.com/ethereum/go-ethereum/" rel="noopener nofollow ugc">geth</a> and install the dependencies</li>
<li>Run <code>make all</code> in the geth repository to build the <code>era</code> binary</li>
<li>Fetch the <code>roots.txt</code> file with the command: <code>wget https://gist.githubusercontent.com/lightclient/528b95ffe434ac7dcbca57bff6dd5bd1/raw/fd660cfedb65cd8f133b510c442287dc8a71660f/roots.txt</code></li>
<li>Run <code>era verify roots.txt</code> in the folder to verify the integrity of the data</li>
</ul>
            <p><small>15 posts - 5 participants</small></p>
            <p><a href="https://ethresear.ch/t/torrents-and-eip-4444/19788">Read full topic</a></p>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 09:35:32 +0000</pubDate>
</item>
<item>
<title>Blobs, Reorgs, and the Role of MEV-Boost</title>
<link>https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783</link>
<guid>https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783</guid>
<content:encoded><![CDATA[
<div> 关键词：blobs、MEV-Boost、reorgs、latency、block propagation

总结:
这篇文章探讨了区块中的大对象（blobs）对以太坊网络延迟和重组（reorgs）的影响，特别是与MEV-Boost（矿工提取价值优化）相关的生态系统。非MEV-Boost用户平均包含更多blobs，导致他们区块被重组的概率较高。MEV-Boost用户由于其低延迟连接和专业性，区块被重组的可能性显著较低。研究还指出不同构建者和中继器可能采用策略来处理blobs，比如Rsync-Builder和Flashbots的平均blob数量较少。未来的研究将关注节点能力的提升和减少非MEV-Boost用户的重组率。随着blob市场的发展，其交易提示可能会追平常规交易。 <div>
<h1><a class="anchor" href="https://ethresear.ch#blobs-reorgs-and-the-role-of-mev-boost-1" name="blobs-reorgs-and-the-role-of-mev-boost-1"></a>Blobs, Reorgs, and the Role of MEV-Boost</h1>
<p><strong>The TL;DR is:</strong></p>
<ul>
<li><strong>Builders</strong> might have an incentive to not include blobs because of the higher latency they cause.</li>
<li><strong>Non-MEV-Boost users</strong> include, on average, more blobs in blocks than MEV-Boost builders.</li>
<li><strong>MEV-Boost users</strong> show a significantly lower probability of being reorged than <em>Non-MEV-Boost</em> users (see section <em>MEV-Boost and Reorgs</em> for details).</li>
<li><strong>Rsync-Builder</strong> and <strong>Flashbots</strong> have a lower average number of blobs per block than other builders.</li>
</ul>
<hr />
<p>In a <a href="https://ethresear.ch/t/big-blocks-blobs-and-reorgs/19674">recent analysis on big blocks, blobs and reorgs</a>, we could see the impact of blobs on the reorg probability.</p>
<p><strong>In the following, I want to expand on this by taking the MEV-Boost ecosystem into account.</strong></p>
<p><strong>The fundamental question is…</strong><br />
-&gt; <strong>“<em>Does MEV-Boost impact reorgs, and if so, by how much?</em>”</strong></p>
<p>Blobs are “<em>big</em>” and big objects cause higher latency. Thus, one might expect builders to not include blobs into their blocks in scenarios in which:</p>
<ul>
<li>The builder is submitting its block late in the slot to minimize latency (see timing games).</li>
<li>The builder wants to capture a high MEV opportunity and doesn’t want to risk unavailable blobs invalidating its block.</li>
<li>The proposer is less well connected (because the gossiping starts later in the slot).</li>
</ul>
<p><strong>Builders</strong> might demand to be <strong>compensated</strong> through priority fees for including transactions which might cause blocks to be propagated with higher latency. Until 4844, such transactions have been those with a lot of calldata. As of 4844, blobs are the main drivers of latency.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/d/8db1993891d52c3c8be9d7c6adde8633810ad15b.png" title="tx_type_prio_fee_all (2)"><img alt="tx_type_prio_fee_all (2)" height="345" src="https://ethresear.ch/uploads/default/optimized/3X/8/d/8db1993891d52c3c8be9d7c6adde8633810ad15b_2_690x345.png" width="690" /></a></div><p></p>
<p><strong>As visible in the above chart, blob transactions don’t tip as much as regular Type-2 transactions.</strong><br />
Based on that, blobs don’t give builders a significant edge over other builders competing for the same slot.<br />
Another explanation could be private deals between builders and rollups to secure timely inclusion of blob transactions for a fee paid through side channels.</p>
<h2><a class="anchor" href="https://ethresear.ch#mev-boost-and-reorgs-2" name="mev-boost-and-reorgs-2"></a>MEV-Boost and Reorgs</h2>
<p>The MEV-Boost ecosystem consists of sophisticated parties, <strong>builders</strong> and <strong>relays</strong>, that are well connected and specialized in having low-latency connections to peers.<br />
Thus, it is expected that proposers using MEV-Boost should be reorged less often than ‘Vanilla Builders’ (i.e., users not using MEV-Boost).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/5/859fee3890096d24a955abd65642fee08ebd141c.png" title="reorgs_mevb_over_blobs (3)"><img alt="reorgs_mevb_over_blobs (3)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/8/5/859fee3890096d24a955abd65642fee08ebd141c_2_690x258.png" width="690" /></a></div><p></p>
<p>This expectation holds true when looking at the above chart.<br />
<strong>We can see that the reorg probability increases with the number of blobs. However, the reorg probability for MEV-Boost users is much lower than the one for Non-MEV-Boost users (Vanilla Builders).</strong></p>
<p><strong>In this context it’s important to not confuse correlation and causation:<br />
-&gt; <em>Non-MEV-Boost users are on average less sophisticated entities which also contributes to the effect we observe in the above chart.</em></strong></p>
<p>In this context it is interesting to compare the <strong>average number of blobs per block</strong> of MEV-Boost users vs. Non-MEV-Boost users.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/c/3cbac65d110bbf6d535ba55d7dfb62f69206a271.png" title="blobs_over_time (3)"><img alt="blobs_over_time (3)" height="373" src="https://ethresear.ch/uploads/default/optimized/3X/3/c/3cbac65d110bbf6d535ba55d7dfb62f69206a271_2_690x373.png" width="690" /></a></div><p></p>
<p><strong>As visible in the above chart, proposers not using MEV-Boost included on average more blobs into their blocks than MEV-Boost users.</strong><br />
This might point towards MEV-Boost ecosystem participants (relays and builders) applying strategies that go beyond the “<em>include it if there’s space</em>” strategy.</p>
<p><strong>First, let’s look at the builders more closely.</strong></p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/b/4bf0a4fe8bc95e88d122c479fe88cf4f32883fbf.png" title="blobs_over_time_builder (4)"><img alt="blobs_over_time_builder (4)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/4/b/4bf0a4fe8bc95e88d122c479fe88cf4f32883fbf_2_690x258.png" width="690" /></a></div><p></p>
<p>Vanilla Builders (Non-MEV-Boost proposers) are the ones that have the highest blob inclusion rate, followed by Beaverbuild and Titan Builder.</p>
<p>Rsync-Builder seems to include way less blobs in their blocks.<br />
The same applies to the Flashbots builder that seems to have changed its behavior in early May, with the average number of blobs per block approaching zero.</p>
<p><strong>“Is it fair to say 'Builder XY censors blobs!?”</strong><br />
&gt; <strong>No</strong></p>
<blockquote>
<p><em>Different builders follow different strategies. For example a builder such as Rsync-Builder that is generally competitive in slots where low latency and speed matters might end up with winning those blocks where there are no blobs around (c.f. <em>selection bias</em>)</em></p>
</blockquote>
<br />
<p><strong>Next, let’s shift the focus to the relays:</strong><br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/3/7/374ff432477462e6a307a3d83c7da899f3a5b541.png" title="blobs_over_time_relays (4)"><img alt="blobs_over_time_relays (4)" height="258" src="https://ethresear.ch/uploads/default/optimized/3X/3/7/374ff432477462e6a307a3d83c7da899f3a5b541_2_690x258.png" width="690" /></a></div><p></p>
<p>As visible above, Vanilla Builders have on average the highest blob inclusion rate.<br />
The Ultrasound and Agnostic Gnosis relays are second and third, followed by the relays of BloXroute.<br />
The Flashbots relay seems to include the lowest number of blobs.</p>
<p><strong>Importantly, relays are dependent on builders and ultimately it’s the builders that impact the above graph.</strong></p>
<h2><a class="anchor" href="https://ethresear.ch#next-steps-3" name="next-steps-3"></a>Next Steps</h2>
<p>In the context of <a href="https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541">PeerDAS</a>, the network will have to rely on nodes that are <em>stronger</em> than others and able to handle way more than 6 blobs per block. Therefore, it’d be super valuable to see more research on that topic happening.</p>
<ul>
<li><strong>Call for reproduction</strong>: It’d be great if someone could verify my results by reproducing this analysis.</li>
<li><strong>Investigate the reasons</strong> why certain builders have a significantly lower blob inclusion rate than others.</li>
<li><strong>Reduce reorg rate for Non-MEV-Boost users</strong>: Relays could offer Non-MEV-Boost users their block propagation services to ensure that fewer of their blocks get reorged.</li>
</ul>
<p>The blob market is still under development and a stable blob price is yet to be discovered. With increasing demand for blob space, tips from blob transaction will likely catch up to regular transactions.</p>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/blobs-reorgs-and-the-role-of-mev-boost/19783">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 15:46:12 +0000</pubDate>
</item>
<item>
<title>Block Proposing &amp; Validating Timelines for 1.) MEV-Boost, 2.) ePBS, and 3.) ePBS with MEV-Boost</title>
<link>https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782</link>
<guid>https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Boost、ePBS、block release time、validation time、propagation time

总结:<br />
MEV-Boost与ePBS比较的关键点在于验证时间和块释放时间。MEV-Boost中，由于额外的步骤（如提案者获取头和执行块），导致整体释放时间较长（RT^{mevboost}）。相比之下，ePBS通过共识层和执行层的并行处理，减少了验证时间，特别是对于执行块（VT^{EL} 和 SPT）。验证共识块时，ePBS的条件更为宽松（RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL}），而MEV-Boost可能导致因SPT和VT^{EL}的额外延迟而产生重新排序（reorgs）。因此，使用MEV-Boost进行ePBS会比纯ePBS更慢。 <div>
<p>This writeup summarizes the timeline differences between ePBS and MEV-Boost using inequalities. We analyze three models: 1) MEV-Boost, 2) ePBS, and 3) MEV-Boost with relayers on ePBS. We show that MEV-Boost with relayers on ePBS is slower than ePBS alone, which could lead to reorgs.</p>
<h2><a class="anchor" href="https://ethresear.ch#definitions-1" name="definitions-1"></a>Definitions</h2>
<p><span class="math">VT^{CL}</span>: Consensus layer validation time. The time taken by a node to verify the consensus portion of a block.<br />
<span class="math">VT^{EL}</span>: Execution layer validation time. The time taken by a node to verify the execution portion of a block.<br />
<span class="math">RT^{mevboost}</span>: Mev-boost block release time. The time when a block is released from a node or relayer, assuming the MEV-boost setting.<br />
<span class="math">RT^{epbs,cl}</span>: ePBS consensus block release time. The time when a consensus block is released from a node or relayer, assuming the ePBS setting.<br />
<span class="math">RT^{epbs,el}</span>: ePBS execution block release time. The time when an execution block is released from a node or relayer, assuming the ePBS setting.<br />
<span class="math">PT^{mevboost}</span>: Mev-boost block propagation time. The time taken for a block to propagate across the network, assuming the mev-boost setting.<br />
<span class="math">PT^{epbs,cl}</span>: ePBS consensus block propagation time. The time taken for a consensus block to propagate across the network, assuming ePBS setting.<br />
<span class="math">PT^{epbs,el}</span>: ePBS execution block propagation time. The time taken for an execution block to propagate across the network, assuming ePBS setting.<br />
<span class="math">Attestation\_RT^{beacon}</span>: Beacon attestation release time. The time when a beacon attestation is released from a node.<br />
<span class="math">Attestation\_RT^{ptc}</span>: PTC attestation release time. The time when a payload attestation is released from a node, assuming the ePBS setting.<br />
<span class="math">BBT</span>: Proposer build block time. The time taken for a proposer to build consensus portion of a block.<br />
<span class="math">GHT</span>: Proposer get header time. The time taken for a proposer to obtain a header from a relayer (MEV-boost) or builder (ePBS).<br />
<span class="math">GPT</span>: Proposer get payload time. The time a proposer takes to obtain a payload from a relayer (MEV-boost).<br />
<span class="math">SPT</span>: Builder submit payload time. The time taken for a relayer to receive a payload from the builder (MEV-boost).<br />
<span class="math">SBBT</span>: Proposer submit blind block time. The time a proposer takes to submit blind block to the relayer (MEV-boost).</p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-a-mev-boost-block-2" name="proposing-a-mev-boost-block-2"></a>Proposing a mev-boost block</h2>
<p>In Mev-Boost, proposing a block involves two parts. First, the builder sends the block to the relayer. Second, the proposer requests the header and returns the signed block to the relayer. We break down the time it takes in the following subsections, starting with the non-optimistic relayer and then the optimistic relayer. We also assume that everything starts at the 0-second mark of the slot, including the builder sending the execution block to the relayer.</p>
<h3><a class="anchor" href="https://ethresear.ch#non-optimistic-relayer-3" name="non-optimistic-relayer-3"></a>Non optimistic relayer</h3>
<p><span class="math">BRT</span> defines builder to relayer time. This is how much time takes for a builder to submit a block (ie bid) to the relayer and the relayer verifies the block is valid.<br />
<span class="math">BRT = SPT + VT^{EL}</span></p>
<p><span class="math">PRT</span> defines proposer to relayer time. This is how much time takes for a proposer to build block, request header, request payload, and submit blind block.<br />
<span class="math">PRT = BBT + GHT + GPT + SBBT</span></p>
<p><span class="math">RT^{mevboost} = BRT + PRT</span></p>
<p>This assumes everything happens after the slot start because bids become more valuable. Another model is to assume <span class="math">BRT</span> happens before the slot. Then <span class="math">RT^{mevboost} = PRT</span>.</p>
<h3><a class="anchor" href="https://ethresear.ch#optimistic-relayer-4" name="optimistic-relayer-4"></a>Optimistic relayer</h3>
<h4><a class="anchor" href="https://ethresear.ch#relayer-receives-builder-block-time-5" name="relayer-receives-builder-block-time-5"></a>Relayer receives builder block time</h4>
<p><span class="math">BRT = SPT</span></p>
<p><span class="math">PRT</span> is the same as before</p>
<p><span class="math">RT^{mevboost} = BRT + PRT</span></p>
<blockquote>
<p>Using optimistic relayer is faster than non-optimistic relayer by: <span class="math">VT^{EL}</span></p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#validating-a-mev-boost-block-6" name="validating-a-mev-boost-block-6"></a>Validating a mev-boost block</h2>
<p>In MEV-Boost, the block must be processed before <span class="math">Attestation\_RT^{beacon}</span> to be considered canonical. The following equation shows the conditions that need to be met for the block to be considered canonical from the perspective of all nodes.</p>
<p>For a beacon block to be canonical, it should satisfy:<br />
<span class="math">RT^{mevboost} + PT^{mevboost} + VT^{CL} + VT^{EL} &lt; Attestation\_RT^{beacon}</span></p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-an-epbs-block-7" name="proposing-an-epbs-block-7"></a>Proposing an ePBS block</h2>
<p>In ePBS, proposing the consensus block and the execution block are pipelined, where the consensus block commits to the execution block’s header. Block release time becomes two parts 1.) CL block release time and 2.) EL block release time.</p>
<h3><a class="anchor" href="https://ethresear.ch#proposing-the-consensus-block-8" name="proposing-the-consensus-block-8"></a>Proposing the consensus block</h3>
<p>We assume the proposer uses the builder’s RPC to get the header. The proposer could also self-build or use P2P to obtain the header, which is arguably faster. Therefore, there is no need for proposer get header time anymore.</p>
<p><span class="math">RT^{epbs,cl} = GHT + BBT</span></p>
<blockquote>
<p>Using ePBS is faster than mev-boost by: <span class="math">SPT+VT^{EL}+GPT + SBBT</span></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#proposing-the-execution-block-9" name="proposing-the-execution-block-9"></a>Proposing the execution block</h3>
<p><span class="math">RT^{epbs,el}</span> is when fork choice accumulates sufficient weight (~40%) or 6 seconds into the slot. The builder could propose a “withhold” block to try to reorg consensus layer block so builder does not have to pay the proposer.</p>
<h2><a class="anchor" href="https://ethresear.ch#validating-an-epbs-block-10" name="validating-an-epbs-block-10"></a>Validating an ePBS block</h2>
<p>In ePBS, validating the consensus block and the execution block are pipelined in different stages. The beacon attestation cutoff time has been moved from 4 seconds into the slot to 3 seconds into the slot. However, we can assume that the CL block propagation time is shorter than the block propagation time. EL block validation can be delayed until the subsequent slot, as shown in the equations.</p>
<h3><a class="anchor" href="https://ethresear.ch#validating-the-consensus-block-11" name="validating-the-consensus-block-11"></a>Validating the consensus block</h3>
<p><span class="math">PT^{epbs,cl} &lt; PT^{mevboost}</span><br />
<span class="math">Attestation\_RT^{beacon,epbs} &lt; Attestation\_RT^{beacon,mevboost}</span></p>
<p>For a consensus block to be canonical, it should satisfy:<br />
<span class="math">RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL} &lt; Attestation\_RT^{beacon}</span></p>
<blockquote>
<p>Using ePBS is faster than mev-boost by: <span class="math">PT^{mevboost}-PT^{epbs,cl}+VT^{EL}</span></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#validating-the-execution-block-12" name="validating-the-execution-block-12"></a>Validating the execution block</h3>
<h4><a class="anchor" href="https://ethresear.ch#as-a-ptc-voting-for-execution-blocks-presence-13" name="as-a-ptc-voting-for-execution-blocks-presence-13"></a>As a PTC voting for execution block’s presence</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} &lt; Attestation\_RT^{ptc}</span></p>
<h4><a class="anchor" href="https://ethresear.ch#as-a-proposer-proposing-the-next-slots-consensus-block-14" name="as-a-proposer-proposing-the-next-slots-consensus-block-14"></a>As a proposer proposing the next slot’s consensus block</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} + VT^{EL} &lt; Next\_Slot\_Start\_Time</span></p>
<h4><a class="anchor" href="https://ethresear.ch#everyone-else-15" name="everyone-else-15"></a>Everyone else</h4>
<p><span class="math">RT^{epbs,el} + PT^{epbs,el} + VT^{EL} &lt; Next\_Slot\_Attestation\_RT^{beacon}</span></p>
<h2><a class="anchor" href="https://ethresear.ch#proposing-an-epbs-block-using-mev-boost-16" name="proposing-an-epbs-block-using-mev-boost-16"></a>Proposing an ePBS block using mev-boost</h2>
<p><span class="math">BRT = SPT + VT^{EL}</span><br />
<span class="math">PRT = BBT + GHT</span><br />
<span class="math">RT^{epbs,cl} = BRT + PRT</span></p>
<blockquote>
<p>Using MEV-Boost for ePBS is slower than ePBS by: <span class="math">SPT + VT^{EL}</span><br />
The additional latency occurs because the trusted party must receive and verify the execution block before releasing it to the proposer.</p>
</blockquote>
<h2><a class="anchor" href="https://ethresear.ch#validating-the-consensus-block-17" name="validating-the-consensus-block-17"></a>Validating the consensus block</h2>
<p><span class="math">RT^{epbs,cl} + PT^{epbs,cl} + VT^{CL} &lt; Attestation\_RT^{beacon}</span></p>
<blockquote>
<p>Given <span class="math">Attestation\_RT^{beacon}</span> is shorter than ePBS, an extra <span class="math">SPT + VT^{EL}</span> could lead to additional reorgs.</p>
</blockquote>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/block-proposing-validating-timelines-for-1-mev-boost-2-epbs-and-3-epbs-with-mev-boost/19782">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 13:52:44 +0000</pubDate>
</item>
<item>
<title>SGX as 2FA for FHE/MPC</title>
<link>https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780</link>
<guid>https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780</guid>
<content:encoded><![CDATA[
<div> 关键词：SGX、MPC、FHE、Trusted Execution Environment (TEE)、Collusion Risk

总结:
本文探讨了如何利用SGX（安全多方计算）作为FHE（全同态加密）项目的双重身份验证（2FA），特别是在MPC（多方计算）加密管理中增强安全性。文章指出，FHE项目的关键瓶颈在于MPC节点的密钥管理，而将MPC运行在SGX中可以防止节点间的串通风险。SGX作为2FA的优势包括提高安全性、减少信任依赖、保持低延迟和易于扩展。然而，SGX也有其问题，如声誉不佳、可能的误报安全以及缺乏链上远程证明。尽管如此，随着相关项目的发展，如Phala的进展，SGX在隐私保护技术中的应用前景值得关注。 <div>
<p><em>About me: I am <a href="https://x.com/tolak_eth" rel="noopener nofollow ugc">Wenfeng Wang</a>, a builder and researcher at Phala Network, put this topic here and hope to have a comprehensive discussion with the community.</em></p>
<p><strong>TLDR</strong>: Involving SGX introduces a safeguard against the collusion risk inherent in current MPC and FHE systems.</p>
<p>Continuing from Justin Drake’s well-articulated <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">post</a> about SGX as a 2FA for zk-rollups, I aim to expand on the potential of SGX as 2FA in FHE projects, specifically in their MPC encryption management. Despite their distinct applications, both leverage some fundamental features of SGX.</p>
<h2><a class="anchor" href="https://ethresear.ch#mpc-is-the-bottleneck-of-fhe-1" name="mpc-is-the-bottleneck-of-fhe-1"></a>MPC is the bottleneck of FHE</h2>
<p>Lately, the interest in FHE (Fully Homomorphic Encryption) technologies has rejuvenated, especially in the context of Ethereum Virtual Machines (EVMs). What was once merely a concept is now a tangible tool developers can use to write privacy-preserving smart contracts. Interested readers can refer to Vitalik’s early 2020 <a href="https://vitalik.eth.limo/general/2020/07/20/homomorphic.html" rel="noopener nofollow ugc">post</a> about FHE. Now, let’s look at the general architecture of most current FHE projects.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f17a45e5c32060cd1578a8f2112437f58880327.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f17a45e5c32060cd1578a8f2112437f58880327_2_663x500.png" width="663" /></a></div><p></p>
<p>I will not dive too deep into FHE itself here, but you can find a notable challenge most FHE designs encounter today lies in the MPC node’s key management. Due to the practice of writing an FHE application, the key is globally used by all users to encrypt the data they send to the FHE server, which will execute under an encryption state. Thus, the whole security of the system relies on the security of the MPC network, and as we all know the truths of the MPC network are:</p>
<ul>
<li>The more nodes you have, the more latency you get</li>
<li>The fewer nodes you have, the more trust assumptions you need</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#tee-as-a-2fa-to-mpc-2" name="tee-as-a-2fa-to-mpc-2"></a>TEE as a 2FA to MPC</h2>
<p>We don’t want to give full trust to MPC nodes because of the possibility of collusion if it is run by humans. Instead, we can add SGX as 2FA to hedge the risk by moving the key management to <a href="https://en.wikipedia.org/wiki/Trusted_execution_environment" rel="noopener nofollow ugc">TEE</a> (Trusted Execution Environments, a technology to run the program in an isolated zone inside CPU, prove program immutable and limited-accessible).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/1/d/1dc05649e162e2e9de3318a6da112754d5a6cd7e.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/1/d/1dc05649e162e2e9de3318a6da112754d5a6cd7e_2_608x500.png" width="608" /></a></div><p></p>
<p>As illustrated above, MPC nodes of the FHE system are now running inside TEE, instead of producing TEE proof when acting as 2FA for zk-rollups, here SGX is used to protect the key generation progress in the MPC network, and the whole lifecycle of the key is kept inside TEE and never gonna reveal to the outside world, more importantly, the key can not be touched by human even a single piece. TEE itself can guarantee the program it runs is verifiable, it’s impossible for someone can manipulate the state. Also, the data passing between TEE and the client is secured by TLS communication.<br />
With TEE as a 2FA, it can help reduce the risk in an economic way that:</p>
<ul>
<li>If SGX is not compromised, there is no chance that collusion can happen;</li>
<li>If SGX gets compromised, only when collusion happens between nodes that the system is broken.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#advantagesdisadvantages-of-sgx-as-2fa-for-fhe-3" name="advantagesdisadvantages-of-sgx-as-2fa-for-fhe-3"></a>Advantages/Disadvantages of SGX as 2FA for FHE</h2>
<ul>
<li>
<p>Advantages</p>
<ul>
<li>Security: Remove the possibility of collusion, trust is built on top of machinehood + cryptography instead of humanity.</li>
<li>Safety: By running MPC inside SGX, even a small MPC network can be reasonably secure. Even if TEE is broken, e.g. have bugs in SGX or Intel being malicious, we still fall back to ordinary MPC.</li>
<li>Latency: Using SGX, we can get higher security without introducing more workers. This gives more confident to users to run latency sensitive operations on MPC.</li>
<li>Liveness: SGX didn’t provide extra liveness naturally, but projects like Phala have built a decentralized <a href="https://docs.phala.network/tech-specs/blockchain" rel="noopener nofollow ugc">TEE network</a> that can help make it easy to build an unstoppable network.</li>
<li>Scalability: Scaling the MPC network is hard, but there are a bunch of existing TEE networks that are ready to deploy MPC nodes. So it lowers the cost to build a larger MPC network.</li>
<li>Throughout: There also is no throughput lost, but considering the optimization of latency, throughput can be improved theoretically.</li>
<li>More advantages that can be brought by SGX were well addressed by <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">Justin’s post</a>.</li>
</ul>
</li>
<li>
<p>Disadvantage</p>
<ul>
<li>It’s worth mentioning that SGX also has its own problems, a quote from Justin’s post:</li>
</ul>
<blockquote>
<ul>
<li>SGX has a bad reputation, especially within the blockchain space. Association with the technology may be memetically suboptimal.</li>
<li>false sense of security: Easily-broken SGX 2FA (e.g. if the privkey is easily extractable) may provide a false sense of security.</li>
<li>novelty: No Ethereum application that verifies SGX remote attestations on-chain could be found.</li>
</ul>
</blockquote>
<ul>
<li>As for the last one that SGX remote attestation on-chain doesn’t exist, the latest state is we have a couple of projects working on it, including Puffer, Automata, and also Phala’s <a href="https://github.com/tolak/zk-dcap-verifier" rel="noopener nofollow ugc">zk-dcap-verifier</a>. But considering it hasn’t been deployed on the mainnet, I kept it on the list.</li>
</ul>
</li>
</ul>
<p><em>Special thanks Justin Drake for his research of <a href="https://ethresear.ch/t/2fa-zk-rollups-using-sgx/14462">2FA zk-rollups using SGX</a> and Andrew Miller for this research of TEE in Multi-Proof system, check his <a href="https://docs.google.com/presentation/d/1K96G50S8ICdllQDbEW1su1Ik_eOc5bK9Ih3uvoG-P9Y/edit?usp=sharing" rel="noopener nofollow ugc">presentation</a>.</em></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/sgx-as-2fa-for-fhe-mpc/19780">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 03:25:10 +0000</pubDate>
</item>
<item>
<title>Solutions to the Preconf Fair Exchange Problem</title>
<link>https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779</link>
<guid>https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779</guid>
<content:encoded><![CDATA[
<div> 关键词：公平交换、领导预确认、声誉系统、最后权利、执行承诺

总结:
本文探讨了在领导预确认（preconfirmation）框架中解决公平交换问题的方法。首先，通过建立声誉系统，激励预确认者诚实回应，但依赖于经济条件的稳定性。其次，提出“最后权利”方案，根据预确认者的顺序决定PER的处理权，最后一个处理PER的预确认者有权获得交易提示。这解决了公平问题，且成本随技术进步而降低。最后，还讨论了“第一权利”方案，即反向请求承诺，适用于对执行承诺不那么敏感的场景。文章也提出了结合使用这些方法的可能性，以适应不同规模的交易需求。

< br>总结: <div>
<h3><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>tldr</h3>
<p>Solutions for dealing with the fair exchange problem in leader-based preconfirmation setups.</p>
<p>Reputation can incentivize preconfers to act honestly.</p>
<p>Alternatively, use order to dictate who gets the PER tip. One can invalidate a PER by sending it to a preconfer with higher priority.</p>
<h1><a class="anchor" href="https://ethresear.ch#fair-exchange-2" name="fair-exchange-2"></a>Fair Exchange?</h1>
<p>The fair exchange problem can be summarized as two untrusted players blindly giving up something in hopes that the other party will do the same. The goal is to try to find a method to ensure that both will cooperate. In the context of preconfirmations, the requesting party (gateway) has no guarantee that their preconfirmation enforcement request (PER) will receive a signed commitment. The preconfer has every right to not return a commitment, hold onto the PER until the last second, and include it if profitable (pocketing the tip for free).</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-1-reputation-3" name="solution-1-reputation-3"></a>Solution 1: Reputation</h1>
<p>One solution to this is by tracking reputation. More specifically, leveraging the promise of future PERs to incentivize preconfers to respond promptly via either commitments or non-commitments (slash-able promises to NOT include). The gateway can throttle or simply ignore preconfers if they misbehave.</p>
<p>Reputation is a tried method and exists today in mev-boost relays (see <a href="https://ethresear.ch/t/the-preconfirmation-sauna/19762">Switchboard’s Sauna Appendix</a>). While this might work, it still requires certain economic conditions for security. If for whatever reason it becomes really profitable to behave dishonestly, the guarantees fall apart.</p>
<h1><a class="anchor" href="https://ethresear.ch#can-we-do-better-4" name="can-we-do-better-4"></a>Can we do better?</h1>
<p>In an ideal scenario, without any limitations of technology, one would simply invalidate the PER if the preconfer takes too long to respond. With blockchains, this is complicated, and time-based approaches require some sort of additional consensus, breaking the based paradigm. However, we can indirectly access “time” by using order. Blocks are ordered, so preconfers can be as well. If we take advantage of this, we arrive at a new solution that avoids the Fair Exchange problem altogether.</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-2-last-right-5" name="solution-2-last-right-5"></a>Solution 2: Last Right</h1>
<p>Determine an order for preconfers. This can be done per block (or even intra-block). Send the PER optimistically to the first preconfer. If they commit, then great. If they return a non-commitment, or do not respond, then send the PER to the next preconfer.</p>
<p>But wait, they can still include my PER and pocket my tip! Yes, they can but they won’t be able to keep the tip. This is due to the central idea of this solution: <strong>the last preconfer to include the PER has the right to the tips</strong>. If two preconfers attempt to include the PER, the second preconfer has the right to the preconf tip. For example, the last preconfer submits a proof and transfers the PER tip to their balance. Other mechanisms are also possible and should be explored.</p>
<p>One consideration here is the cost. If claiming the tip is more expensive than the tip itself, then the model falls apart. The good news is this cost is directly tied to the technology and should decrease exponentially (e.g. zk proof). Preconfirmation tips on the other hand are tied to the value of the transaction itself, which is not as dependent on the tech. So perhaps this mechanism will become more and more economically favorable.</p>
<p>One great side effect of this method is that it preserves the possibility of execution promises. If the first preconfer acts honestly, then it can guarantee the execution state for the PER. Execution guarantees fall apart if there’s any dishonesty (same as Solution 1).</p>
<h1><a class="anchor" href="https://ethresear.ch#solution-3-first-right-6" name="solution-3-first-right-6"></a>Solution 3: First Right</h1>
<p>If we are willing to forgo execution promises, then the gateway can instead request commitments from preconfers in reverse order. Forward the PER to a preconfer down the list, and then move up until one commits. <strong>The first preconfer to include the PER gets the tip.</strong> In the case where L1 proposers are preconfers, this is enforced by the L1 replay protection. This is a much simpler version of Solution 2.</p>
<p>One downside is the “real” latency before the transaction is actually included since the default preconfer is not the current one. But one could argue that for important transactions where L1 settlement is important (e.g. buying a house), preconfirmations in general are probably not a priority.</p>
<p>Note that execution promises are technically still possible if all the state transitions up to the point of inclusion has already been determined. (e.g. All block space has already been filled by PERs or similar.)</p>
<h1><a class="anchor" href="https://ethresear.ch#final-thoughts-7" name="final-thoughts-7"></a>Final Thoughts</h1>
<p>We can even perhaps use these Solutions in tandem. For smaller preconf tips, we can rely on Solution 1, let the first preconfer pocket it and “slash” their reputation. For larger preconf tips, we can fallback to Solution 2 and let the next preconfer steal it back. Or just use them at the same time.</p>
<p>Thanks to <span class="mention">@mteam</span> for getting me up to speed and providing feedback. We at Spire Labs are actively researching preconfirmations and related topics, and building towards a better, unified Ethereum.</p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://ethresear.ch/t/solutions-to-the-preconf-fair-exchange-problem/19779">Read full topic</a></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 02:55:02 +0000</pubDate>
</item>
<item>
<title>Inactivity Leak unveiled</title>
<link>https://ethresear.ch/t/inactivity-leak-unveiled/19774</link>
<guid>https://ethresear.ch/t/inactivity-leak-unveiled/19774</guid>
<content:encoded><![CDATA[
<div> 关键词：inactivity leak, finalization, Ethereum PoS, Byzantine validators, safety

总结:
本文探讨了以太坊PoS区块链中的"不活动泄漏"问题，这是一种在灾难性网络故障期间恢复最终性的理论分析。不活动泄漏机制导致链的连续增长，优先保证区块的最终性（活性），但可能牺牲安全。当网络中存在拜占庭验证者时，这一问题更加突出，它们可能导致冲突的最终区块，威胁协议的安全。文章详细描述了不活动分数和惩罚机制，以及在不同行为（活跃和不活跃）下的验证者权益变化。研究发现，拜占庭验证者的恶意行为会加速安全丧失，特别是在初始比例较高时。作者强调了对协议设计中潜在问题的认识对于BFT分析和未来改进的重要性。 <div>
<p>We summarize here the <a href="https://arxiv.org/abs/2404.16363" rel="noopener nofollow ugc">article</a> that presents the first theoretical analysis of the inactivity leak, designed to restore finalization during catastrophic network failures. This work is accepted at DSN2024.</p>
<h1><a class="anchor" href="https://ethresear.ch#tldr-1" name="tldr-1"></a>TL;DR</h1>
<ul>
<li>The inactivity leak is intrinsically problematic for the safety of the protocol. It favors the constant finalization of blocks (<em>liveness</em>) at the expense of having conflicting finalized blocks (<em>safety</em>).</li>
<li>The presence of Byzantine validators -validators that deviate from the protocol- can accelerate the loss of safety.</li>
</ul>
<hr />
<p>The Ethereum PoS blockchain strives for the continuous growth of the finalized chain. In consequence, the protocol incentivizes validators to finalize blocks actively. The inactivity leak is the mechanism used to regain finality. Specifically, the inactivity leak is initiated if a chain has not undergone finalization for four consecutive epochs. The inactivity leak happened for the first time on the mainnet in May 2023.</p>
<p>A good introduction to the inactivity leak is available thanks to the excellent work of Ben Eddington <a href="https://eth2book.info/capella/part2/incentives/inactivity/" rel="noopener nofollow ugc">here</a> (which motivated this work). We formalize the inactivity leak starting by the inactivity score.</p>
<h2><a class="anchor" href="https://ethresear.ch#inactivity-score-2" name="inactivity-score-2"></a>Inactivity Score</h2>
<p>During an inactivity leak, at epoch <span class="math">t</span>, the inactivity score, <span class="math">I_i(t)</span>, of validator <span class="math">i</span> is:</p>
<div class="math">
\begin{cases}
        I_i(t) = I_i(t-1)+4, \text{if $i$ is inactive at epoch $t$} \\
        I_i(t) = \max(I_i(t-1)-1, 0), \text{ otherwise.}
    \end{cases}
</div>
<p>Thus, a validator’s inactivity score increases by <span class="math">4</span> if it is inactive and decreases by <span class="math">1</span> if it is active. The inactivity score is always positive and will be used to penalize validators during the inactivity leak.</p>
<h2><a class="anchor" href="https://ethresear.ch#inactivity-penalties-3" name="inactivity-penalties-3"></a>Inactivity Penalties</h2>
<p>Let <span class="math">s_i(t)</span> represent the stake of validator <span class="math">i</span> at epoch <span class="math">t</span>, and let <span class="math">I_i(t)</span> denote its inactivity score. The penalty at each epoch <span class="math">t</span> is <span class="math">I_i(t-1)\cdot s_i(t-1)/2^{26}</span>. Therefore, the evolution of the stake is expressed by:</p>
<div class="math">
s_i(t)=s_i(t-1)-\frac{I_i(t-1)\cdot s_i(t-1)}{2^{26}}. 
</div>
<h2><a class="anchor" href="https://ethresear.ch#stake-during-the-inactivity-leak-4" name="stake-during-the-inactivity-leak-4"></a>Stake during the Inactivity Leak</h2>
<p>In this work, we model the stake function <span class="math">s</span> as a continuous and differentiable function, yielding the following differential equation:</p>
<div class="math">
s'(t)=-I(t)\cdot s(t)/2^{26}.
</div>
<p>With this equation, we can determine a validator’s stake according to the time by fixing the evolution of its inactivity score. And that is exactly what we do. We define two types of behavior: Active and Inactive.</p>
<ul>
<li>Active validators: they are always active.</li>
<li>Inactive validators: they are always inactive.</li>
</ul>
<p>Validators with these behaviors experience different evolutions in their inactivity scores: (a) Active validators have a constant inactivity score <span class="math">I(t)=0</span>; (b) Inactive validators’ inactivity score increases by 4 every epoch, <span class="math">I(t)=4t</span>. The stake of each type of validator during an inactivity leak:</p>
<ul>
<li>Active validator’s stake: <span class="math"> s(t) = s_0 = 32. </span></li>
<li>Inactive validator’s stake: <span class="math"> s(t) = s_0e^{-t^2/2^{25}}. </span></li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/4/9/496a7e5de461559b800a4d612eacb356a5f3cc84.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/4/9/496a7e5de461559b800a4d612eacb356a5f3cc84_2_685x500.png" width="685" /></a></div><p></p>
<p>The graph shows the evolution of the stake of validators depending on their activity during the inactivity leak. The expulsion limit is set by the protocol to eject validators that have accumulated too many penalties.</p>

What is an active validator? <a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774/1">(click for more details)</a>
<hr />
<p>This was the formalization of the protocol. Now we make the analysis of the protocol’s property of safety. To do so, we use the following model.</p>
<h2><a class="anchor" href="https://ethresear.ch#model-5" name="model-5"></a>Model</h2>
<ul>
<li><strong>Network</strong>: We assume a partially synchronous system, which transitions from an asynchronous state to a synchronous state after an apriori unknown Global Stabilization Time (GST).</li>
<li><strong>Fault</strong>: Validators are either <em>honest</em> or <em>Byzantine</em> (deviating from the protocol). A Byzantine validator can deviate arbitrarily from the protocol.</li>
<li><strong>Stake</strong>: Each validator starts with 32 ETH.</li>
</ul>
<p>There is no bound on message transfer delay during the asynchronous state.</p>
<h1><a class="anchor" href="https://ethresear.ch#bound-for-safety-6" name="bound-for-safety-6"></a>Bound for safety</h1>
<h2><a class="anchor" href="https://ethresear.ch#with-only-honest-validators-7" name="with-only-honest-validators-7"></a>With only honest validators</h2>
<p>By construction, the inactivity leak will breach safety if a partition occurs for long enough. The question is, how quickly?</p>
<blockquote>
<p><em>Any network partition lasting longer than 4686 epochs (about 3 weeks) will result in a loss of Safety because of conflicting finalization. This is an upper bound for Safety on the duration of the inactivity leak with only honest validators.</em></p>
</blockquote>
<h3><a class="anchor" href="https://ethresear.ch#detailed-analysis-8" name="detailed-analysis-8"></a>Detailed Analysis</h3>
<p>Let us analyze the scenario in which the validators (which are all honest) are partitioned in two. (We are in the asynchronous state according to our model).<br />
The partition will necessarily create a fork, each partition building on the only chain they see. The chains will finalize once the proportion of active validators returns to 2/3rd.</p>
<p>In this case, by understanding the distribution of the validators across the partitions, we can compute the time it takes for the proportion of active validators’ stake to return to 2/3 of the stake on each branch, thus finalizing and breaking safety.</p>
<p>For the analysis, we make the following notations. At the beginning of the inactivity leak:</p>
<ul>
<li><span class="math">n</span> is the total number of validators</li>
<li><span class="math">n_B</span> is the total number of Byzantine validators</li>
<li><span class="math">n_H</span> is the total number of honest validators</li>
<li><span class="math">n_{H_1}</span> is the number of honest validators on branch 1</li>
<li><span class="math">n_{H_2}</span> is the number of honest validators on branch 2</li>
</ul>
<p>There are no Byzantine validators for the first part of our analysis, which implies that <span class="math">n=n_H</span>. Honest validators are only partitioned in two, thus <span class="math">n_H=n_{H_1}+n_{H_2}</span>.</p>
<p><strong>Our goal is to determine when the proportion of honest validators on branch 1 will be superior to 2/3rd of the total stake.</strong>  Which is to say that we look at when the ratio:</p>
<div class="math">
\frac{\text{stake of validator in branch 1}}{\text{stake of validator in branch 1 + stake of validator in branch 2}},
</div>
<p>is superior to 2/3. With our notation, the ratio can be rewritten as:</p>
<div class="math">
\frac{n_{\text H_1}s_{\text H_1}(t)}{n_{\text H_1}s_{\text H_1}(t)+n_{\text H_2}s_{\text H_2}(t)} ,
</div>
<p><span class="math">s_{\text H_1}</span> and <span class="math">s_{\text H_2}</span> are the stakes of honest active and inactive validators, respectively. Since the <span class="math">n_{\text H_1}</span> validators on branch 1 are always active on branch 1, and the <span class="math">n_{\text H_2}</span> validators are always inactive on branch 1 (they are active on branch 2); we know that <span class="math">s_{\text H_1}(t)=s_0</span> and <span class="math">s_{\text H_2}(t)=s_0e^{-t^2/2^{25}}</span>.<br />
Using the notation <span class="math">p_0=n_{\text H_1}/n_H</span>, the ratio of active validators over time is:</p>
<div class="math">
\frac{p_0}{p_0+(1-p_0)e^{-t^2/2^{25}}}. 
</div>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/e/7ec6a1a64318159dada408e4cc0365a1663b28d1.png" title="image"><img alt="image" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/7/e/7ec6a1a64318159dada408e4cc0365a1663b28d1_2_668x500.png" width="668" /></a></div><p></p>
<p>This graph shows the ratio of active validators on branch 1 over time. If finalization hasn’t occurred by epoch <span class="math">t=4685</span>, inactive validators are ejected, causing a jump to 100% active validators.</p>
<h2><a class="anchor" href="https://ethresear.ch#byzantine-validators-9" name="byzantine-validators-9"></a>Byzantine validators</h2>
<p>We now add Byzantine validators.</p>

These Byzantine validators can send messages to each partition without restriction. <a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774/1">(click for more details)</a>
<p>The situation we analyze is now as such:</p>
<ul>
<li>Less than one-third of the stake is held by Byzantine validators (<span class="math">\beta_0=n_{\rm B}/n&lt;1/3</span>).</li>
<li>Honest validators are divided into branches <span class="math">1</span> and <span class="math">2</span>; a proportion <span class="math">p_0=n_{\rm H_1}/n_{\rm H}</span> on branch <span class="math">1</span> and <span class="math">1-p_0=n_{\rm H_2}/n_{\rm H}</span> on branch <span class="math">2</span>.</li>
<li>Byzantine validators can communicate with both branches.</li>
</ul>
<p>Byzantine validators can be active on both branches simultaneously, breaching safety faster. The ratio of active validators on branch 1 is:</p>
<div class="math">
\frac{p_0(1-\beta_0)+\beta_0}{p_0(1-\beta_0)+\beta_0+(1-p_0)(1-\beta_0)e^{-t^2/2^{25}}}.
</div>
<p>This table shows the time it takes to break safety depending on the initial proportion of Byzantine validators (<span class="math">\beta_0</span>):<br />
<img alt="image" height="195" src="https://ethresear.ch/uploads/default/original/3X/3/0/30cda7537ed8ab1493f4beadd138924b6b6408f3.png" width="157" /></p>
<p><em>Byzantine validators can expedite the loss of Safety. If their initial proportion is 0.33, they can make conflicting finalization occur approximately ten times faster than scenarios involving only honest participants.</em></p>
<hr />
<p>The original paper provides more details on the assumptions, scenarios, protocol, and other aspects such as:</p>
<ul>
<li>Ways for Byzantine validators to breach safety without committing slashable behavior.</li>
<li>Methods for Byzantine validators to exceed the 1/3 threshold on both branches of the fork.</li>
<li>An analysis of the probabilistic bouncing attack while considering the inactivity leak. Spoiler alert: this aggravates the attack slightly, but the conditions for the attack to start and persist in time make it highly improbable to be a real threat.</li>
</ul>
<p>For an additional quick peek at the paper’s findings, here is a graphic that presents how quickly Byzantine validators can break safety depending on their initial proportion and whether their behavior is slashable or not.  As you can see, they can have a strong impact even without slashable behavior.<br />
</p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/a/8a447d3888021e7cf6ba7c2b99fd1907ad3a5738.png" title="image"><img alt="image" height="375" src="https://ethresear.ch/uploads/default/optimized/3X/8/a/8a447d3888021e7cf6ba7c2b99fd1907ad3a5738_2_500x375.png" width="500" /></a></div><p></p>
<h1><a class="anchor" href="https://ethresear.ch#conclusion-10" name="conclusion-10"></a>Conclusion</h1>
<p>Our findings highlight the importance of penalty mechanisms in Byzantine Fault Tolerance (BFT) analysis. By identifying potential issues in protocol design, we aim to provide insights for future improvements and tools for further investigation.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://ethresear.ch/t/inactivity-leak-unveiled/19774">Read full topic</a></p>
]]></content:encoded>
<pubDate>Mon, 10 Jun 2024 13:46:18 +0000</pubDate>
</item>
<item>
<title>The contention between preconfs and ePBS</title>
<link>https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770</link>
<guid>https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770</guid>
<content:encoded><![CDATA[
<div> 关键词：ePBS、preconfirmations、inclusion lists、centralized entity、staked builders

总结:<br />
文章讨论了ePBS（加密预言机拜占庭服务）与不同预确认机制的兼容性。主要观点如下：<br />
1. 使用预确认列表可能会导致交易广播两次，增加网络负担，这与ePBS优化的共识块验证时间不兼容。
2. 预确认系统的中心化性质，通常依赖于集中式实体，如中继，与ePBS的去中心化目标相悖。
3. ePBS下，强制执行预确认可能导致全交易列表广播，挑战了ePBS的优化，即仅验证共识块。
4. 建议利用已有的staked builders作为预确认者，他们在预确认系统中的角色可以像提案者一样受到规则约束。
5. ePBS对restaking（复投）也构成挑战，因为预确认和潜在违规行为可能发生在同一个交易中，需要额外处理。

因此，为保持与ePBS的兼容性，预确认系统的设计需要避免直接在共识块中包含完整交易列表，而是考虑利用staked builders的角色来间接实现预确认。 <div>
<p>This quick note is motivated by a question of <a class="mention" href="https://ethresear.ch/u/hasu.research">@Hasu.research</a> regarding the compatibility of ePBS with the different mechanisms for preconfirmations that are being proposed by independent groups <a href="https://ethresear.ch/t/the-preconfirmation-sauna/19762">1</a> <a href="https://ethresear.ch/t/blob-preconfirmations-with-inclusion-lists-to-mitigate-blob-contention-and-censorship/19150">2</a> <a href="https://chainbound.github.io/bolt-docs/" rel="noopener nofollow ugc">3</a> <a href="https://docs.google.com/presentation/d/1a-0rP2knM11g59UmnKn7I7NH8BlFM5wNhczH35sbkSo/edit#slide=id.g2731bc99d1b_0_0" rel="noopener nofollow ugc">4</a> <a href="https://docs.primev.xyz/get-started/introduction" rel="noopener nofollow ugc">5</a>. The only purpose of this note is to leave a quick written record of the fundamental contention between the enshrinements of preconfirmations and the <a href="https://github.com/potuz/consensus-specs/pull/2" rel="noopener nofollow ugc">current proposal for ePBX</a>.</p>
<h2><a class="anchor" href="https://ethresear.ch#overloading-inclusion-lists-1" name="overloading-inclusion-lists-1"></a>Overloading inclusion lists.</h2>
<p>Even in the very first post on <a href="https://ethresear.ch/t/based-preconfirmations/17353">based preconfirmations</a>, the idea of using <a href="https://eips.ethereum.org/EIPS/eip-7547" rel="noopener nofollow ugc">forced inclusion lists</a> was put forward as a way for proposers to signal their intent of honoring preconfirmations, forcing builders to include these transactions. An extrapolation of this idea led, in one of the original designs for ILs, to propose that inclusion lists may essentially include a complete list of transactions the proposer has in its current mempool. One of the problems with these ideas is that the full list of transactions would need to be broadcast over the P2P network twice: once when the inclusion list is broadcast, and the second time within the payload itself. In all known designs for inclusion lists, validators attest for the existence of the full executable transaction list. This implies in particular that</p>
<ol>
<li>The list must be available at the beacon block validation time.</li>
<li>The list must be executed at the beacon block validation time.</li>
</ol>
<p>This section is not meant to be read as <em>inclusion lists aren’t compatible with ePBS</em> but rather any preconfirmation system (and next block forced inclusion lists by definition are such a system) that relies on the execution and distribution of the transactions at the consensus block validation time, necessarily clashes with the main optimization from ePBS.</p>
<h2><a class="anchor" href="https://ethresear.ch#epbs-validation-optimization-2" name="epbs-validation-optimization-2"></a>ePBS validation optimization</h2>
<p>The above two points are in direct opposition with the main optimization that ePBS brings to block processing, that is that the only hot path to validation is that of the consensus block that has to be fully verified before the attestation deadline. All other validations, like transaction execution, data availability, etc. are deferred to the remainder of the slot and into the next slot.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f3daa474ae131dfbee7c96cfd9f2a7e4035c06a.jpeg" title="ePBS slot"><img alt="ePBS slot" height="364" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f3daa474ae131dfbee7c96cfd9f2a7e4035c06a_2_690x364.jpeg" width="690" /></a></div><p></p>
<p>While ePBS is compatible with inclusion lists, their addition inherently stresses this optimization. Broadcasting a small list of 16 transactions that can be immediately executed in microseconds is not the same as broadcasting a full block, and presumably, even blob transactions as some based rollups would require.</p>
<h2><a class="anchor" href="https://ethresear.ch#the-centralized-nature-of-preconfs-3" name="the-centralized-nature-of-preconfs-3"></a>The centralized nature of preconfs</h2>
<p>There is no current design (that I am aware of) of preconfirmations, that does not rely on a centralized entity. This is natural to expect in the absence of an encrypted public mempool, users can’t send their transactions in the open to the next proposer (although they could <em>encrypt the transactions to the public BLS address of the next proposer</em>), and we can’t enshrine an RPC provider, all systems thus make use on existing centralized entities (for example relays) to act as a preconfer. Decentralization comes in that it is ultimately the proposer who enforces these preconfirmations, by forcing the builder to fullfil them.</p>
<p>Thus, in all proposed systems for preconfirmations, either of L1 transactions or for based rollups, there exist a centralized entity that at the very least is responsible for gathering the transactions and giving out the preconfirmations. Systems differ on how is that these preconfirmations are enforced, they range from new L1 slashing proposals, to restaking proposals (moving the slashing to a separate layer), etc. The point is that preconfirmations can be enforced by the protocol itself, or by a somewhat decentralized party like the subset of validators participating in the preconfirmation scheme. In summary, there is a plethora of options for enforcing the (or penalizing the lack of) inclusion of preconfirmations, in decreasing level of trustlessness:</p>
<ul>
<li>The L1 protocol itself enforces inclusion. For example, forced ILs, with proposer level slashings on missed slots, preconf equivocations, etc.</li>
<li>Some separate committee enforces them. For example a subset of the L1 validators also participate in a sidechain by restaking, and the enforcement/punishment is carried in that sidechain.</li>
<li>A centralized entity enforces them. For example the relay itself only sends bids from builders that have satisfied the required preconfs.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#a-viable-way-compatible-with-epbs-staked-builders-as-preconfirmers-4" name="a-viable-way-compatible-with-epbs-staked-builders-as-preconfirmers-4"></a>A viable way compatible with ePBS: staked builders as preconfirmers.</h2>
<p>Any approach with a full payload being broadcast with the consensus block for preconfirmation enforcement clashes directly with the main scaling optimization of ePBS with regard to block validation. As thus, it seems difficult to expect a working design in which the proposers are in charge of sending and enforcing preconfirmations. The second and third approaches above are fully compatible with ePBS.</p>
<p>One of the features that preconfirmation systems can leverage when ePBS is in place, is that builders themselves are staked validators, thus they can be subject to the same rules that these systems currently require from proposers. For example, those systems that rely on slashings on a restaking scheme could simply add conditions on participating builders. That is, the proposer set participating in the scheme only take bids from builders that are participants of the scheme. The builders and proposers are required to be restaked. There are new penalty conditions for</p>
<ul>
<li>A proposer that does not include a block.</li>
<li>A proposer that includes a block with a commitment to a non-participating builder.</li>
<li>A builder that does not include the payload</li>
<li>A builder that includes a payload does not satisfies the preconf list.</li>
</ul>
<h2><a class="anchor" href="https://ethresear.ch#a-separate-note-on-restaking-5" name="a-separate-note-on-restaking-5"></a>A separate note on restaking</h2>
<p>ePBS also presents a challenge on any restaking scheme: builders can transfer funds in the same payload that they commit a slashable offense. L1 protocol can deal with this by immediately deducting the bid from the builder’s balance at the time of CL block processing, but delaying the credit to the proposer. In case the builder commits a slashable offense, the buffer allows the L1 protocol to implement penalization procedures that can impact those delayed funds accordingly. If the builder is restaked however, the restaking chain does not have access to these funds.</p>
            <p><small>7 posts - 4 participants</small></p>
            <p><a href="https://ethresear.ch/t/the-contention-between-preconfs-and-epbs/19770">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 07:59:33 +0000</pubDate>
</item>
<item>
<title>On block-space distribution mechanisms</title>
<link>https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764</link>
<guid>https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764</guid>
<content:encoded><![CDATA[
<h1><a class="anchor" href="https://ethresear.ch#on-block-space-distribution-mechanisms-1" name="on-block-space-distribution-mechanisms-1"></a>On block-space distribution mechanisms</h1>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/c/3/c3fa4239ef0f468256ba44d0e860fb3d7edaedcf.jpeg" title="upload_3067440b5b4f752379ddba32df7ecf8b"><img alt="upload_3067440b5b4f752379ddba32df7ecf8b" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/c/3/c3fa4239ef0f468256ba44d0e860fb3d7edaedcf_2_499x500.jpeg" width="499" /></a></div><br />
<sub><strong>^p.s. yes, we anthropomorphize the protocol as a ghost because <a href="https://arxiv.org/pdf/1710.09437.pdf" rel="noopener nofollow ugc">Casper</a>.</strong></sub><br />
<sub><strong>^^p.p.s. not sure why the auctioneer ghost looks like he is conducting an orchestra, but here we are ¯\_(ツ)_/¯.</strong></sub><br />
<sub><strong>^^^ p.p.p.s. by the way, if you haven’t seen <a href="https://en.wikipedia.org/wiki/Maestro_(2023_film)" rel="noopener nofollow ugc">Maestro</a>, it’s great.</strong></sub><p></p>
<p><span class="math">\cdot</span><br />
<em>by <a href="https://x.com/mikeneuder" rel="noopener nofollow ugc">Mike</a>, <a href="https://x.com/PGarimidi" rel="noopener nofollow ugc">Pranav</a>, &amp; <a href="https://x.com/Tim_Roughgarden" rel="noopener nofollow ugc">Dr. Tim Roughgarden</a> – June 8, 2024.</em><br />
<span class="math">\cdot</span><br />
<strong>Acknowledgements</strong><br />
<em>Special thanks to <a href="https://x.com/barnabemonnot" rel="noopener nofollow ugc">Barnabé</a>, <a href="https://x.com/_julianma" rel="noopener nofollow ugc">Julian</a>, <a href="https://x.com/_JonahB_" rel="noopener nofollow ugc">Jonah</a>, <a href="https://x.com/DavideCrapis" rel="noopener nofollow ugc">Davide</a>, <a href="https://x.com/soispoke" rel="noopener nofollow ugc">Thomas</a>, <a href="https://x.com/terencechain" rel="noopener nofollow ugc">Terence</a>, <a href="https://x.com/potuz_eth" rel="noopener nofollow ugc">Potuz</a>, &amp; <a href="https://www.nano210.blog/" rel="noopener nofollow ugc">Nate</a> for comments and discussions.</em><br />
<span class="math">\cdot</span><br />
<strong>tl;dr;</strong> <em>Block space, the capacity for transaction inclusion, is the principal resource exported by blockchains. As the crypto ecosystem scales up and professionalizes, the value produced by efficient usage of block space (<a href="https://arxiv.org/abs/1904.05234" rel="noopener nofollow ugc">MEV</a>) has come to play a significant role in the economics of permissionless consensus mechanisms. An immense amount of ink has been spilled by the research community considering what, if anything, protocols should enshrine in response to MEV (see <a href="https://ethresear.ch#related-work-2">Related Work</a>). Indeed, the past few years resemble a <a href="https://en.wikipedia.org/wiki/Blind_men_and_an_elephant" rel="noopener nofollow ugc">Blind Men and the Elephant</a> narrative arc, where many different perspectives, solutions, and theories have been propounded, but each angle can feel disjoint and difficult to compare. The first half of this article aims to present a broad-strokes painting of the “MEV-ephant” by distilling the design space into a core set of questions and exploring how existing proposals answer them. The second half hones in specifically on allocation mechanisms enabled by execution tickets, demonstrating an important new insight – there is a trade-off between the quality of the in-protocol MEV oracle and the fairness of the mechanism.</em></p>
<p><strong>Organization:</strong> <a href="https://ethresear.ch#h-1-motivation-3">Section 1</a> motivates the need for an in-protocol mechanism to handle block-space distribution as part of the “endgame” for Proof-of-Stake. <a href="https://ethresear.ch#h-2-enumeration-6">Section 2</a> enumerates five axes along which block-space distribution mechanisms may be measured, using a familiar set of questions: <em>who, what, when, where, how</em> (abbr. the <code>W^4H questions</code>). <a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> interrogates how the block builder is selected, focusing on the execution tickets model. <a href="https://ethresear.ch#h-4-extrapolation-18">Section 4</a> extrapolates by concluding and raising open questions that follow from the framework established.</p>
<p><strong>Structural note:</strong> This article is rather long for this format and has some technical elements. We encourage the reader to focus on the portion of the article they are most interested in:</p>
<ul>
<li>Sections <a href="https://ethresear.ch#h-1-motivation-3">1</a>, <a href="https://ethresear.ch#h-2-enumeration-6">2</a>, &amp; <a href="https://ethresear.ch#h-4-extrapolation-18">4</a> provide a broader perspective on the existing proposals and our proposed methodology for analyzing them.</li>
<li><a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> (which is <span class="math">\approx 44\%</span> of the content, but <a href="https://youtu.be/VDvr08sCPOc?t=111" rel="noopener nofollow ugc"><span class="math">100\%</span></a> of the math) provides a detailed analysis of allocation mechanisms enabled by the execution tickets design. This section can be read in sequence, in isolation, or skipped altogether – up to you!</li>
</ul>
<p><span class="math">\cdot</span><br />
<strong>Contents</strong></p>
<ol>
<li><a href="https://ethresear.ch#h-1-motivation-3"><strong>Motivation</strong></a><br />
<a href="https://ethresear.ch#h-1-what-4"><em>1) What</em></a><br />
<a href="https://ethresear.ch#Block-space-distribution-today"><em>Block-space distribution today through <code>mev-boost</code></em></a></li>
<li><a href="https://ethresear.ch#h-2-enumeration-6"><strong>Enumeration</strong></a><br />
<a href="https://ethresear.ch#the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7"><em>The elements of block-space distribution</em></a><br />
<a href="https://ethresear.ch#execution-tickets-and-other-animals-8"><em>Execution tickets and other animals</em></a><br />
<a href="https://ethresear.ch#applying-w4h-a-comparative-analysis-9"><em>Applying W^4H: a comparative analysis</em></a><br />
<a href="https://ethresear.ch#motivational-interlude-10"><em>Motivational interlude</em></a></li>
<li><a href="https://ethresear.ch#h-3-interrogation-11"><strong>Interrogation</strong></a><br />
<a href="https://ethresear.ch#preliminaries-12"><em>Preliminaries</em></a><br />
<a href="https://ethresear.ch#model-13"><em>Model</em></a><br />
<a href="https://ethresear.ch#familiar-allocation-mechanisms-14"><em>Familiar allocation mechanisms</em></a><br />
<a href="https://ethresear.ch#comparing-the-outcomes-15"><em>Comparing the outcomes</em></a><br />
<a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16"><em>Aside #1: Calculating equilibrium bids</em></a><br />
<a href="https://ethresear.ch#aside-2-tullock-contests-17"><em>Aside #2: Tullock Contests</em></a></li>
<li><a href="https://ethresear.ch#h-4-extrapolation-18"><strong>Extrapolation</strong></a></li>
</ol>
<p><span class="math">\cdot</span></p>
<h4><a class="anchor" href="https://ethresear.ch#related-work-2" name="related-work-2"></a><strong>Related work</strong></h4>
<ol>
<li><em>mev-boost &amp; relays</em>
<ul>
<li><a href="https://ethresear.ch/t/mev-boost-merge-ready-flashbots-architecture/11177"><em>MEV-Boost: Merge ready Flashbots Architecture</em></a>; Flashbots team</li>
<li><a href="https://ethresear.ch/t/relays-in-a-post-epbs-world/16278"><em>Relays in a post-ePBS world</em></a>; Mike, Jon, Hasu, Tomasz, Chris, Toni</li>
</ul>
</li>
<li><em>mev-burn / mev-smoothing</em>
<ul>
<li><a href="https://ethresear.ch/t/burning-mev-through-block-proposer-auctions/14029"><em>Burning MEV through block proposer auctions</em></a>; Domothy</li>
<li><a href="https://ethresear.ch/t/mev-burn-a-simple-design/15590"><em>MEV burn – a simple design</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408"><em>Committee-driven MEV smoothing</em></a>; Francesco</li>
<li><a href="https://ethresear.ch/t/dr-changestuff-or-how-i-learned-to-stop-worrying-and-love-mev-burn/17384"><em>Dr. changestuff or: how I learned to stop worrying and love mev-burn</em></a>; Mike, Toni, Justin</li>
</ul>
</li>
<li><em>enshrined Proposer-Builder Separation (ePBS)</em>
<ul>
<li><a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980"><em>Two-slot proposer/builder separation</em></a>; Vitalik</li>
<li><a href="https://ethresear.ch/t/unbundling-pbs-towards-protocol-enforced-proposer-commitments-pepc/13879"><em>Unbundling PBS: towards protocol-enforced proposer commitments (PEPC)</em></a>; Barnabé</li>
<li><a href="https://barnabe.substack.com/p/pbs" rel="noopener nofollow ugc"><em>Notes on Proposer-Builder Separation</em></a>; Barnabé</li>
<li><a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>; Barnabé</li>
<li><a href="https://ethresear.ch/t/why-enshrine-proposer-builder-separation-a-viable-path-to-epbs/15710"><em>Why enshrine Proposer-Builder Separation?</em></a>; Mike, Justin</li>
<li><a href="https://ethresear.ch/t/epbs-design-constraints/18728"><em>ePBS design constraints</em></a>; Potuz</li>
<li><a href="https://mirror.xyz/barnabe.eth/LJUb_TpANS0VWi3TOwGx_fgomBvqPaQ39anVj3mnCOg" rel="noopener nofollow ugc"><em>Reconsidering the market structure of PBS</em></a>; Barnabé</li>
</ul>
</li>
<li><em>block-space futures</em>
<ul>
<li><a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc"><em>Block vs. Slot Auction PBS</em></a>; Julian</li>
<li><a href="https://frontier.tech/ethereums-blockspace-future" rel="noopener nofollow ugc"><em>Opportunities and Considerations of Ethereum’s Blockspace Future</em></a>; Drew, Ankit</li>
<li><a href="https://collective.flashbots.net/t/when-to-sell-your-blocks/2814" rel="noopener nofollow ugc"><em>When to sell your blocks</em></a>; Quintus, Conor</li>
</ul>
</li>
<li><em>execution tickets</em>
<ul>
<li><a href="https://www.youtube.com/watch?v=MtvbGuBbNqI" rel="noopener nofollow ugc"><em>Attester-proposer separation</em></a>; Justin</li>
<li><a href="https://ethresear.ch/t/execution-tickets/17944"><em>Execution tickets</em></a>; Justin, Mike</li>
<li><a href="https://ethresear.ch/t/economic-analysis-of-execution-tickets/18894"><em>Economic Analysis of Execution Tickets</em></a>; Jonah, Davide</li>
<li><a href="https://ethresear.ch/t/block-auction-epbs-versus-execution-ticket/19232"><em>Block-auction ePBS versus Execution Ticket</em></a>; Terence</li>
</ul>
</li>
</ol>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#h-1-motivation-3" name="h-1-motivation-3"></a>(1) – Motivation</h3>
<p>Before descending into this murky rabbit hole, let’s start by simply motivating the necessity of a block-space distribution mechanism. Validators in Proof-of-Stake protocols are tasked with producing and voting on blocks. The figure below, from Barnabé’s excellent “<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>,” describes these as “proposing” and “attesting” rights, respectively.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/7/d/7d85ca7f1812a5822490fa079365301c99733620.png" title="upload_72dad4dc4f8c77f0d57f8f126b3c2e46"><img alt="upload_72dad4dc4f8c77f0d57f8f126b3c2e46" height="219" src="https://ethresear.ch/uploads/default/optimized/3X/7/d/7d85ca7f1812a5822490fa079365301c99733620_2_690x219.png" width="690" /></a></div><p></p>
<h4><a class="anchor" href="https://ethresear.ch#h-1-what-4" name="h-1-what-4"></a>1) What</h4>
<p>(<span class="math">\uparrow</span> <a href="https://twitter.com/SBF_FTX/status/1591989554881658880?lang=en" rel="noopener nofollow ugc">important cultural ref</a>.)</p>
<p>A block-space distribution mechanism is the process by which the protocol determines the owner of the “proposing” or “block construction” rights. Proof-of-Stake protocols typically use some version of the following rules:</p>
<ul>
<li><strong>block-space (proposing) rights</strong> – A random validator is elected as the leader and permitted to create the next block.</li>
<li><strong>voting (attesting) rights</strong> – All validators vote during some time window for the block they see as the canonical head.</li>
</ul>
<p>Validators perform these tasks because they receive rewards for doing so. We categorize the rewards according to their origin in either the consensus layer (the issuance from the protocol – e.g., newly minted <code>ETH</code>) or the execution layer (transaction fees and MEV):</p>
<ol>
<li><strong>Consensus layer</strong><br />
a. <em>Attestation rewards</em> – see <a href="https://github.com/ethereum/annotated-spec/blob/160764ac180eca2cea3581f731ee96ac7098f9f7/phase0/beacon-chain.md#components-of-attestation-deltas" rel="noopener nofollow ugc">attestation deltas</a>.<br />
b. <em>Block rewards</em> – see <a href="https://github.com/ethereum/annotated-spec/blob/160764ac180eca2cea3581f731ee96ac7098f9f7/phase0/beacon-chain.md#rewards-and-penalties-1" rel="noopener nofollow ugc"><code>get_proposer_reward</code></a>.</li>
<li><strong>Execution layer</strong><br />
a. <em>Transaction fees</em> – see <a href="https://etherscan.io/gastracker" rel="noopener nofollow ugc">gas tracker</a>.<br />
b. <em>MEV (transaction ordering)</em> – see <a href="https://mevboost.pics/" rel="noopener nofollow ugc">mevboost.pics</a>.</li>
</ol>
<p>Rewards <code>1a</code>, <code>1b</code>, &amp; <code>2a</code> are well understood and “<a href="https://barnabe.substack.com/p/seeing-like-a-protocol" rel="noopener nofollow ugc">in the view</a>” of the protocol. MEV rewards present a more serious challenge because fully capturing the value realized by transaction ordering is difficult. Unlike the other rewards, even the amount of MEV in a block is unknowable for all intents and purposes (as a permissionless and pseudonymous system, it’s impossible to trace who controls each account and any corresponding offchain activity that may be profitable in tandem). MEV also changes dramatically over time (e.g., as a function of price volatility), resulting in execution layer rewards having a much higher variance than the consensus layer rewards. Further, the Ethereum protocol, as implemented, has no insight into the MEV being produced and extracted by its transactions. To improve protocol visibility into MEV, many mechanisms try to approximate the MEV in a given block; we refer to these as <em>MEV oracles</em>. Block-space distribution mechanisms generally have the potential to produce such an oracle, making the protocol “MEV-aware.”</p>
<p>This suggests the question, <em>why does the protocol care about being MEV-aware?</em> One answer: <strong>MEV awareness may increase the protocol’s ability to preserve the homogeneity of validator rewards, even if validators have varying degrees of sophistication.</strong> For example, if the protocol could accurately burn all MEV, then the validator incentives would be fully in the protocol’s view (just like <code>1a</code>, <code>1b</code>, &amp; <code>2a</code> above). Alternatively, a mechanism that shares all MEV among validators regardless of their sophistication (e.g., <a href="https://ethresear.ch/t/committee-driven-mev-smoothing/10408">mev-smoothing</a>) would seem to promote a larger, more diverse and decentralized validator set, while keeping the MEV rewards as an extra incentivization to stake. Without MEV awareness, the validators best equipped to extract or smooth MEV (e.g., due to relationships with block builders, proprietary algorithms/software, access to exclusive order flow, &amp; economies of scale) may earn disproportionately high rewards and exert significant centralization pressures on the protocol.</p>
<p>Ethereum protocol design strives to keep a decentralized validator set at all costs. It probably goes without saying, but for completeness: <strong>the protocol’s credible neutrality, censorship resistance, and permissionlessness are directly downstream of a decentralized validator set.</strong></p>
<h4><a class="anchor" href="https://ethresear.ch#block-space-distribution-today-5" name="block-space-distribution-today-5"></a>Block-space distribution today</h4>
<p>In Ethereum today, <a href="https://mevboost.pics/" rel="noopener nofollow ugc"><code>mev-boost</code></a> accounts for <span class="math">\approx 90\%</span> of all blocks. Using <code>mev-boost</code>, proposers (the validator randomly selected as the leader) sell their block-building rights to the highest paying bidder through an auction. The figure below demonstrates this flow (we exclude the <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">relays</a> because they functionally serve as an extension of the builders).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/b/7/b70bdfef2fd8dc26a478c2b870495ea39ebd07bc.png" title="upload_5f698b1a28978bd8f9779e596c471d9a"><img alt="upload_5f698b1a28978bd8f9779e596c471d9a" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/b/7/b70bdfef2fd8dc26a478c2b870495ea39ebd07bc_2_252x499.png" width="252" /></a></div><br />
.<br />
Proposers are incentivized to outsource their block building because builders (the canonical name for MEV-extracting agents specializing in sequencing transactions) pay them more than they would have earned had they built the block themselves. Circling back to our goal of “<strong>preserving the homogeneity of validator rewards in the presence of MEV</strong>,” we see that <code>mev-boost</code> allows access to the builder market for <em>all validators</em>, effectively preserving near-equivalent MEV rewards among solo stakers and professional staking service providers – great! But…<p></p>
<p>Of course, there is a but… <code>mev-boost</code> has issues that continue to rankle some of the Ethereum community. Without being exhaustive, a few of the negative side-effects of taking the <code>mev-boost</code> medicine are:</p>
<ul>
<li><strong>Relays</strong> – These <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">trusted-third parties</a> broker the sale of blocks between proposers and builders. The immense reliance on relays increases the fragility of the protocol as a whole, as demonstrated through <a href="https://collective.flashbots.net/t/disclosure-mitigation-of-block-equivocation-strategy-with-early-getpayload-calls-for-proposers/1705" rel="noopener nofollow ugc">repeated</a>, <a href="https://research.lido.fi/t/bloxroute-feb-6th-post-mortem/6586" rel="noopener nofollow ugc">incidents</a>, <a href="https://gist.github.com/benhenryhunter/5c397db3985a59d14a52816305a6c1b8" rel="noopener nofollow ugc">involving</a>, <a href="https://gist.github.com/benhenryhunter/7b7d9c9e3218aad52f75e3647b83a6cc" rel="noopener nofollow ugc">relays</a>. Further, since relays have no inherent revenue stream, more exotic (and closed-source) methods of capturing margins (e.g., <a href="https://bloxroute.com/pulse/introducing-the-validator-gateway-boost-your-ethereum-validator-rewards/" rel="noopener nofollow ugc">timing games as a service</a> and <a href="https://twitter.com/sui414/status/1778708084510302445" rel="noopener nofollow ugc">bid adjustments</a>) are being implemented.</li>
<li><strong>Out-of-protocol software is brittle</strong> – Beyond the relays, participation in the <code>mev-boost</code> market requires validators to run additional software. The standard suite for solo staking now involves running four binaries: (i) the consensus beacon node, (ii) the consensus validator client, (iii) the execution client, and (iv) mev-boost. Beyond the significant overhead for solo stakers, reliance on this software also provides another potential point of failure during hard forks. See the <a href="https://collective.flashbots.net/t/impact-of-the-prysm-invalid-signature-bug-on-the-mev-boost-ecosystem-at-the-shapella-fork/1623" rel="noopener nofollow ugc">Shapella incident</a> and the <a href="https://writings.flashbots.net/preparing-for-dencun" rel="noopener nofollow ugc">Dencun upgrade</a> for an example of the complexity induced by having more out-of-protocol software.</li>
<li><strong>Builder centralization and censorship</strong> – While this is likely <a href="https://vitalik.eth.limo/general/2021/12/06/endgame.html" rel="noopener nofollow ugc">inevitable</a>, builder centralization was accelerated by the mass adoption of <code>mev-boost</code>. <a href="https://www.relayscan.io/" rel="noopener nofollow ugc">Three builders</a> account for <span class="math">\approx 95\%</span> of <code>mev-boost</code> blocks (<span class="math">85\%</span> of all Ethereum blocks). <code>mev-boost</code> implements an open-outcry, first-price, winner-takes-all auction, leading to high levels of builder concentration and <a href="https://ethresear.ch/t/game-theoretic-model-for-mev-boost-auctions-mma/16206">strategic</a>, <a href="https://ethresear.ch/t/bid-cancellations-considered-harmful/15500">bidding</a>. Without <a href="https://ethresear.ch/t/no-free-lunch-a-new-inclusion-list-design/16389">inclusion lists</a> or another censorship-resistance gadget, builders have extreme influence over transaction inclusion and exclusion – see <a href="https://censorship.pics/" rel="noopener nofollow ugc">censorship.pics</a>.</li>
<li><strong>Timing games</strong> – While <a href="https://arxiv.org/abs/2305.09032" rel="noopener nofollow ugc">timing games</a> are known to be a fundamental issue in Proof-of-Stake protocols, <code>mev-boost</code> pushes staking service providers to compete on thin margins. Additionally, relays (who conduct <code>mev-boost</code> auctions on the proposer’s behalf) serve as sophisticated middlemen facilitating timing games. Thus, we have seen <a href="https://p2p.org/economy/unlock-p2p-orgs-mev-enhancement-feature/" rel="noopener nofollow ugc">marketing</a> endorsing playing timing games to boost the yield from staking with a specific provider.</li>
</ul>
<p><em>“OK, OK … blah blah … we have heard this story before … <a href="https://youtu.be/q8wJqMbr6eY?si=LVryerWbrw3_ge-I" rel="noopener nofollow ugc">tell me something I don’t know</a>.” (<span class="math">\leftarrow</span> h/t Barnabé for the aptly-named, 14k-views on youtube, musical reference.)</em></p>
<h3><a class="anchor" href="https://ethresear.ch#h-2-enumeration-6" name="h-2-enumeration-6"></a>(2) – Enumeration</h3>
<p>Obligatory ‘stage-setting’ out of the way, let’s look a little more carefully at the ~essence~ of a block-space distribution mechanism.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/5/5/55cc9892e24d897856dff5e70b48fe8682903b6e.jpeg" title="upload_cdbf47258422c2a96ea2903ce113a113"><img alt="upload_cdbf47258422c2a96ea2903ce113a113" height="367" src="https://ethresear.ch/uploads/default/optimized/3X/5/5/55cc9892e24d897856dff5e70b48fe8682903b6e_2_552x367.jpeg" width="552" /></a></div><br />
<sub><strong>^ “<a href="https://youtu.be/mvy4YH9--Vw?t=108" rel="noopener nofollow ugc"><em>Is that what I think it is?</em></a>”</strong></sub><p></p>
<h4><a class="anchor" href="https://ethresear.ch#the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7" name="the-elementshttpsenwikipediaorgwikieuclid27s_elements-of-block-space-distribution-7"></a>The <a href="https://en.wikipedia.org/wiki/Euclid%27s_Elements" rel="noopener nofollow ugc">elements</a> of block-space distribution</h4>
<p>Consider the game of acquiring block space; MEV incentivizes agents to participate, while the combination of in-protocol and out-of-protocol software defines the rules. When designing this game, what elements should be considered? To answer this question, we use a familiar rhetorical pattern of “who, what, when, where, &amp; how” (hopefully <a href="https://ethresear.ch#h-1-motivation-3">Section 1</a> sufficiently answered “why”), which we refer to as the <code>W^4H questions</code>. (<span class="math">\leftarrow</span> h/t Barnabé pt. 2 for the connection to “<a href="https://www.goodreads.com/book/show/22749723-who-gets-what-and-why" rel="noopener nofollow ugc"><em>Who Gets What – and Why</em></a>”).</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em></li>
<li><em><strong>What</strong> is the good that players are competing for?</em></li>
<li><em><strong>When</strong> does the game take place?</em></li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em></li>
<li><em><strong>How</strong> is the block builder chosen?</em></li>
</ul>
<p>These questions might seem overly simplistic, but when considered in isolation, each can be viewed as an axis in the design space to measure mechanisms. To demonstrate this, we highlight a few different species from the block-space distribution mechanism <a href="https://en.wikipedia.org/wiki/Genus" rel="noopener nofollow ugc">genus</a> that have been explored in the past. While they may feel disjointed and unrelated, their relationship is clarified by understanding how they answer the <code>W^4H questions</code>.</p>
<h4><a class="anchor" href="https://ethresear.ch#execution-tickets-and-other-animals-8" name="execution-tickets-and-other-animals-8"></a>Execution tickets and other animals</h4>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/0/5/05be4a7b2ce343036ba89733f9371dc1cbaa2b5b.jpeg" title="upload_23e73e8aae1d7223973af83053d41ebc"><img alt="upload_23e73e8aae1d7223973af83053d41ebc" height="500" src="https://ethresear.ch/uploads/default/optimized/3X/0/5/05be4a7b2ce343036ba89733f9371dc1cbaa2b5b_2_328x500.jpeg" width="328" /></a></div><br />
<sub><strong>^ fantastic book.</strong></sub><p></p>
<p>We present a compendium of many different proposed mechanisms. Note that this is only a subset of the rather substantial literature around these designs – cf. <a href="https://notes.ethereum.org/@mikeneuder/infinite-buffet" rel="noopener nofollow ugc">infinite buffet</a>. For each of the following, we summarize only the key ideas (see <a href="https://ethresear.ch#related-work-2">related work</a> for more).</p>
<ul>
<li>Execution tickets
<ul>
<li><strong>Key ideas</strong> – Block building and proposing rights are sold directly through “tickets” issued by the protocol. Ticket holders are randomly sampled to become block builders with a fixed lookahead. The ticket holder has the authority to produce a block at the assigned slot.</li>
</ul>
</li>
<li>Block-auction PBS
<ul>
<li><strong>Key ideas</strong> – The protocol bestows block production rights through a random leader-election process. The selected validator can sell their block outright to the builder market or build it locally. The builder must ~commit to a specific block~ when bidding in the auction. <code>mev-boost</code> is an out-of-protocol instantiation of block-auction PBS; enshrined PBS (ePBS), as <a href="https://ethresear.ch/t/two-slot-proposer-builder-separation/10980">originally presented</a>, is the in-protocol equivalent.</li>
</ul>
</li>
<li>MEV-burn/mev-smoothing
<ul>
<li><strong>Key ideas</strong> – A committee is tasked with enforcing a minimum value over the bid the proposer selects in an auction. By requiring the proposer to choose a “large enough” bid, an MEV oracle is created. The MEV is either <em>smoothed</em> between committee members or <em>burned</em> (smoothed over all <code>ETH</code> holders).</li>
</ul>
</li>
<li>Slot-auction PBS
<ul>
<li><strong>Key ideas</strong> – Similar to block-auction PBS but instead sells the <a href="https://mirror.xyz/0x03c29504CEcCa30B93FF5774183a1358D41fbeB1/CPYI91s98cp9zKFkanKs_qotYzw09kWvouaAa9GXBrQ" rel="noopener nofollow ugc">slot</a> to the builder market ~without~ requiring a commitment to a specific block – sometimes referred to as block space futures. By not requiring the builders to commit to a particular block, future slots may be auctioned off ahead of time rather than waiting until the slot itself.</li>
</ul>
</li>
<li>Partial-block auction
<ul>
<li><strong>Key ideas</strong> – Allows a more flexible unit for selling block-space. Instead of selling the full block or slot, allow proposers to sell <em>some</em> of their block, e.g., the top-of-block (which is the most valuable for arbitrageurs), while retaining the rest-of-block construction. Live in other Proof-of-Stake networks, e.g., Jito’s <a href="https://jito-labs.gitbook.io/mev/searcher-resources/block-engine" rel="noopener nofollow ugc">block engine</a> and Skip <a href="https://docs.skip.money/blocksdk/lanes/existing-lanes/mev" rel="noopener nofollow ugc">MEV lane</a>.</li>
</ul>
</li>
<li>APS-burn a.k.a. Execution Auction (nomenclature in flux &amp; the EA acronym has a bit of … <a href="https://en.wikipedia.org/wiki/Effective_altruism" rel="noopener nofollow ugc">baggage</a>)
<ul>
<li><strong>Key ideas</strong> – A brand new proposal from <a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc">Barnabé</a> which compels a proposer to auction off the block building and proposing rights ahead of time. The slot is sold ex-ante (a fixed amount of time in advance) without requiring a commitment to a specific block; a committee (à la mev-burn/smoothing) enforces the winning bid is sufficiently large.</li>
</ul>
</li>
</ul>
<p>We know, we know – it’s a lot to keep track of; it’s nearly a full-time job just to stay abreast of all these acronyms. But by comparing these proposals along the axes laid out by the <code>W^4H questions</code>, we can see how they all fit together as different parts of the same design space.</p>
<h4><a class="anchor" href="https://ethresear.ch#applying-w4h-a-comparative-analysis-9" name="applying-w4h-a-comparative-analysis-9"></a>Applying W^4H: a comparative analysis</h4>
<p>For each of the five <code>W^4H questions</code>, we describe different trade-offs made by the aforementioned proposals. For brevity, we don’t analyze each question for each proposal; we instead focus on highlighting key differences arising from each line of questioning.</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em>
<ul>
<li>With execution tickets, the protocol dictates the winner of the game by randomly choosing from the set of ticket holders.</li>
<li>With block-auction PBS, the proposer (protocol-elected leader) unilaterally chooses the winner of the game.</li>
<li>With mev-burn, the proposer still chooses the winner, but the winning bid is constrained by the committee, reducing the proposer’s agency.</li>
</ul>
</li>
<li><em><strong>What</strong> is the good that players are competing for?</em>
<ul>
<li>With block-auction PBS, the entire block is sold, but bids must commit to the block contents.</li>
<li>With slot-auction PBS, the entire block is sold, but without any specific block commitment.</li>
<li>With partial-block PBS, a portion of the block is sold.</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>With block-auction PBS, the auction takes place during the slot.</li>
<li>With slot-auction PBS, the auction may take place many slots (e.g., 32) ahead of time because there is no block-content commitment.</li>
<li>With execution tickets, the tickets are assigned to slots at a fixed lookahead after being sold ex-ante by the protocol (more on the ticket-selling model we use below).</li>
</ul>
</li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em>
<ul>
<li>With mev-burn/smoothing, a committee enforces that a sufficiently large bid is selected as the winner; this bid size is the oracle.</li>
<li>With execution tickets, the total money spent on tickets serves as the oracle.</li>
</ul>
</li>
<li><em><strong>How</strong> is the block builder chosen?</em>
<ul>
<li>In block-auction PBS, any outsourced block production has a winner-take-all allocation, with the highest bidder granted the block-building rights.</li>
<li>Within execution tickets, many different allocation mechanisms can be implemented. In the original proposal, for example, where a random ticket is selected, the mechanism is ‘proportional-to-ticket-count’; in this case, the highest paying bidder (whoever holds the most tickets) merely has the highest probability of being selected, meaning they are not guaranteed the block building rights.</li>
<li>If that (^) seems opaque, don’t worry. The entire following section is a deep dive into these different allocations.</li>
</ul>
</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#motivational-interlude-10" name="motivational-interlude-10"></a>Motivational interlude</h4>
<p>Before continuing, let’s review our original motivation for block-space distribution mechanisms:</p>
<blockquote>
<p><strong>Block-space distribution mechanisms aim to preserve the homogeneity of validator rewards in the presence of MEV.</strong></p>
</blockquote>
<p>This is a great grounding, but if that is our only goal, why not just continue using <code>mev-boost</code>? Well, remember that <code>mev-boost</code> has some negative side effects that we probably want the endgame protocol to be resilient against. We highlight four other potential design goals of a block-space distribution mechanism:</p>
<ol>
<li><em>Encouraging a wider set of builders to be competitive.</em></li>
<li><em>Allow validators and builders to interact trustlessly.</em></li>
<li><em>Incorporating MEV-awareness into the base layer protocol.</em></li>
<li><em>Removing MEV from validator rewards altogether.</em></li>
</ol>
<p>Note that while (1, 2, &amp; 3) appear relatively uncontroversial (*knock on wood*), (4) is more opinionated (and requires (3) as a pre-condition). The protocol may hope to eliminate MEV rewards from validator rewards as a means to ensure that the consensus layer rewards (what the protocol controls) more accurately reflect the full incentives of the system. This also ties into questions around staking macro-economics and the idea of <a href="https://ethresear.ch/t/endgame-staking-economics-a-case-for-targeting/18751">protocol</a>, <a href="https://notes.ethereum.org/@mikeneuder/iiii" rel="noopener nofollow ugc">issuance</a> – a much more politically-charged discussion. On the other hand, MEV rewards are a byproduct of network usage; MEV could instead be seen as a <a href="https://www.nano210.blog/infinite-blockspace-equilibrium/" rel="noopener nofollow ugc">value capture</a> mechanism for the native token. We aren’t trying to address these questions here but rather explore how different answers to them would shape the design of the mechanism.</p>
<p>What can we do at the protocol-design level to align with these desiderata? As laid out above, there are many trade-offs to consider, but in the following section, we examine “<em>How is the block builder chosen?</em>” to improve on some of these dimensions.</p>
<h3><a class="anchor" href="https://ethresear.ch#h-3-interrogation-11" name="h-3-interrogation-11"></a>(3) – Interrogation</h3>
<p><strong>Editorial note:</strong> As mentioned earlier, this section is longer and more technical than the others – feel free to skip to <a href="https://ethresear.ch#h-4-extrapolation-18">Section 4</a> if you are time (or interest) constrained!</p>
<p><strong>Section goal:</strong> <em>To demonstrate the quantitative trade-off between MEV-oracle quality and the “fairness” of the two most familiar approaches to allocating block proposer rights, which we call <code>Proportional-all-pay</code> and <code>Winner-take-all</code>.</em></p>
<p>We aim to accomplish this with the following subsections:</p>
<ul>
<li><a href="https://ethresear.ch#preliminaries-12"><em>Preliminaries</em></a> – Motivate the fixed-price, unlimited-quantity execution ticket sale mechanism we use.</li>
<li><a href="https://ethresear.ch#model-13"><em>Model</em></a> - Introduce the notation needed to analyze the model.</li>
<li><a href="https://ethresear.ch#familiar-allocation-mechanisms-14"><em>Familiar allocation mechanisms</em></a> - Describe the <code>Proportional-all-pay</code> and <code>Winner-take-all</code> mechanisms using the established framework.</li>
<li><a href="https://ethresear.ch#comparing-the-outcomes-15"><em>Comparing the outcomes</em></a> - Calculate the resulting equilibria in a two-player example.</li>
<li><a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16"><em>Aside #1: Calculating equilibrium bids</em></a> - Derive the equilibria in the general case.</li>
<li><a href="https://ethresear.ch#aside-2-tullock-contests-17"><em>Aside #2: Tullock Contests</em></a> - Contextualize the model as a Tullock Contest and draw connections to the existing literature.</li>
</ul>
<p>Let’s <a href="https://youtu.be/GLsCR2RMBak?t=119" rel="noopener nofollow ugc">dig</a> in.</p>
<h4><a class="anchor" href="https://ethresear.ch#preliminaries-12" name="preliminaries-12"></a>Preliminaries</h4>
<p>Before diving into the space of allocation mechanisms made possible with execution tickets, we must first set up the model. Consider a protocol that sells execution tickets with the following rules:</p>
<ol>
<li>the price is fixed at <code>1 WEI</code>, and</li>
<li>unlimited tickets can be bought and sold from the protocol.</li>
</ol>
<p><strong>Note:</strong> <em>this version of execution tickets is effectively equivalent to creating two disjoint staking mechanisms – one each for attesting and proposing. Small changes in the design, e.g., not allowing tickets to be resold to the protocol, may have massive implications for how the market plays out, but that isn’t the focus of this article. Instead, we narrowly explore the question of block-space allocation, given an existing ticket holder set.</em></p>
<p>Notably, the set of block producers is disjoint (from the protocol’s perspective) from the set of attesters – individuals must select which part of the protocol they participate in by deciding whether to stake or buy tickets. The secondary ticket market may evolve as a venue for selling the building rights just in time to the builder market (as is done in <code>mev-boost</code> today).</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/e/4/e4f36ef0b6e6e5d80c4a923d9465bf74212af039.png" title="upload_45a1fa23182dd6a28c2c07dc2479f150"><img alt="upload_45a1fa23182dd6a28c2c07dc2479f150" height="499" src="https://ethresear.ch/uploads/default/optimized/3X/e/4/e4f36ef0b6e6e5d80c4a923d9465bf74212af039_2_486x499.png" width="486" /></a></div><br />
<span class="math">\cdot</span><br />
Separately, builders may choose to interact directly with the protocol by buying execution tickets themselves, but their capital may be better utilized as active liquidity, capturing arbitrage across trading venues. Thus, they may prefer buying block space on the secondary market during the just-in-time auction instead.<p></p>
<p>Why restrict ourselves to this posted-price-unlimited-supply mechanism? Two reasons:</p>
<ol>
<li><em>It’s not clear that a sophisticated market could even be implemented in the consensus layer.</em> The clients are optimized to allow any validator with consumer-grade hardware to participate in the network. This desideratum may be incompatible with fast auctions, bonding curves, or other possible ticket-selling mechanisms. Questions around how many tickets are sold, the MEV around onchain ticket-sale inclusion (meta-MEV?!), and the timing (and timing games) of ticket sales seem closer to execution layer concerns than something that could reasonably be implemented by Ethereum consensus while keeping hardware requirements limited.</li>
</ol>
<blockquote>
<p>“<em>One may imagine the inclusion of ET market-related transactions to possibly induce MEV, whether these transactions are included in the beacon block or the execution payload.</em>” – <strong>Barnabé in</strong> “<a href="https://mirror.xyz/barnabe.eth/QJ6W0mmyOwjec-2zuH6lZb0iEI2aYFB9gE-LHWIMzjQ" rel="noopener nofollow ugc"><em>More pictures about proposers and builders</em></a>.”</p>
</blockquote>
<ol start="2">
<li><em>Even if (a big if) the protocol ~could~ implement a more rigid ticket-selling market, the design space for such a mechanism is immense.</em> Many potential pricing mechanisms have been discussed, e.g., bonding curves, 1559-style dynamic pricing, auctions, etc.; making general claims about these remains outside the scope of this post.</li>
</ol>
<p>Therefore, we focus on the “unlimited, 1 <code>WEI</code> posted-price” version of execution tickets, where the protocol internalizes minimal complexity. With this framing, we can ask the question that is probably <a href="https://youtu.be/5KNEZJ6KkLI?t=53" rel="noopener nofollow ugc">burning</a> you up inside, “<em>given a set of execution ticket holders, how should the winner be selected?</em>” … sounds easy enough, right? Turns out there is a good deal we can say, even with such a seemingly simple question; let’s explore a few different options.</p>
<h4><a class="anchor" href="https://ethresear.ch#model-13" name="model-13"></a>Model</h4>
<p>Consider the repeated game of buying execution tickets to earn MEV rewards for your investment.</p>
<ul>
<li>During each period, each player effectively submits a bid, which is the number of tickets they buy. Denote the vector of bids by <span class="math">\mathbf{b}</span>, where <span class="math">b_i</span> is the bid of the <span class="math">i^{th}</span> player.</li>
<li>Each player has a valuation for winning the block production rights. Denote the vector of valuations by <span class="math">\mathbf{v}</span>, where <span class="math">v_i</span> is the value of the <span class="math">i^{th}</span> player.</li>
<li>At each time step, an allocation mechanism determines each player’s allocation based on the vector of bids. Assuming bidders are risk-neutral (i.e., don’t care between winning 2 <code>ETH</code> with probability <span class="math">0.5</span> vs. 1 <code>ETH</code> with probability <span class="math">1</span>), we can equivalently say that they are each allocated “some portion” of the block, which can be alternatively be interpreted as “the probability that they win a given block.” In an <span class="math">n</span> player game, let <span class="math">x: \mathbf{b} \rightarrow [0,1]^n</span> denote the map implementing an allocation mechanism, where <span class="math">x_i(\mathbf{b})</span> is the allocation of the <span class="math">i^{th}</span> player, under the constraint that <span class="math">\sum_i x_i(\mathbf{b}) =1</span> (i.e., the mechanism fully allocates).</li>
<li>Each player’s payment is collected at each round. Let <span class="math">p: \mathbf{b} \rightarrow \mathbb{R}_{\geq 0}^n</span> denote the payment rule determined by the set of bids, where <span class="math">p_i(\mathbf{b})</span> is the payment of the <span class="math">i^{th}</span> player.</li>
<li>The utility function of each player in the game is, <span class="math">U_i(\mathbf{b}) = v_i x_i(\mathbf{b}) - p_i(\mathbf{b})</span>. The intuition is that “a player’s utility is their value for winning multiplied by the amount they won, less their payment.”</li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#familiar-allocation-mechanisms-14" name="familiar-allocation-mechanisms-14"></a>Familiar allocation mechanisms</h4>
<p>Consider two (quite different) possible mechanisms.</p>
<p><code>Proportional-all-pay</code> (a slight modification to the <a href="https://ethresear.ch/t/execution-tickets/17944">original</a> execution tickets proposal)</p>
<ul>
<li>During each round, all players submit a bid. Denote the vector of bids by <span class="math">\mathbf{b}</span>.</li>
<li>The probability that a bid wins the game is the value of the bid divided by the sum of all the values of the bids,</li>
</ul>
<div class="math">
x_i(\mathbf{b}) = \frac{b_i}{\sum_j b_j}.
</div>
<ul>
<li>Each player pays their bid, no matter the outcome of the game (hence “all-pay”), <span class="math">p_i(\mathbf{b}) = b_i.</span><a href="https://ethresear.ch#fn1dst"><span class="math">^{[1]}</span></a><a href="https://ethresear.ch" name="fn1"></a></li>
</ul>
<p><code>Winner-take-all</code> (the current implementation of PBS)</p>
<ul>
<li>During each round, all players submit a bid. Denote the vector of bids by <span class="math">\mathbf{b}</span>.</li>
<li>The highest bidder wins the game, so <span class="math">x_i(\mathbf{b}) = 1</span> if <span class="math">\max(\mathbf{b}) = b_i</span> and <span class="math">x_i(\mathbf{b}) = 0</span> otherwise (where ties are broken in favor of the lower index bidder, say).</li>
<li>Only the winning player pays the value of their bid, so <span class="math">p_i(\mathbf{b}) = b_i</span> if <span class="math">\max(\mathbf{b}) = b_i</span> and <span class="math">p_i(\mathbf{b}) = 0</span> otherwise (same tie-breaking as above).<a href="https://ethresear.ch#fn2dst"><span class="math">^{[2]}</span></a><a href="https://ethresear.ch" name="fn2"></a></li>
</ul>
<h4><a class="anchor" href="https://ethresear.ch#comparing-the-outcomes-15" name="comparing-the-outcomes-15"></a>Comparing the outcomes</h4>
<p>To demonstrate the different outcomes from these two mechanisms, consider the two-player game where <code>Player 1</code> has a valuation of <span class="math">v_1 = 4</span> and <code>Player 2</code> has a valuation of <span class="math">v_2 = 2.</span> (We consider a complete information setting in which the individual values are common knowledge. To see how the equilibria bid is calculated and for extended discussion, see <a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16">Aside 1</a>.)</p>
<ul>
<li><strong><code>Proportional-all-pay</code> outcome:</strong>
<ul>
<li>Equilibrium Bids: <span class="math">\qquad\,\,\,\;\;\; b_1 = 8/9</span>, <span class="math">\,b_2 = 4/9</span></li>
<li>Equilibrium Allocations: <span class="math">\;\;\; x_1 = 2/3</span>, <span class="math">x_2 = 1/3</span></li>
<li>Equilibrium Payments: <span class="math">\;\;\;\; p_1 = 8/9</span>, <span class="math">\,p_2 = 4/9</span></li>
</ul>
</li>
</ul>
<p>This all should feel intuitively correct; with <span class="math">v_1 = 2 \cdot v_2</span> (<code>Player 1</code> has <code>2x</code> the value for the block), <code>Player 1</code> bids, receives and pays twice as much as <code>Player 2</code>.</p>
<ul>
<li><strong><code>Winner-take-all</code> outcome:</strong>
<ul>
<li>Equilibrium Bids: <span class="math">\qquad\,\,\,\;\;\; b_1 = 2+\epsilon</span>, <span class="math">b_2 = 2</span></li>
<li>Equilibrium Allocations: <span class="math">\;\;\; x_1 = 1</span>, <span class="math">\quad\;\; x_2 = 0</span></li>
<li>Equilibrium Payments: <span class="math">\;\;\;\,\, p_1 = 2+\epsilon</span>, <span class="math">p_2 = 0</span></li>
</ul>
</li>
</ul>
<p>This is pretty different. <code>Player 1</code> bids and pays just over <code>Player 2</code>’s value (we use <span class="math">\epsilon</span> to denote a small amount), receiving the entire allocation. <code>Player 2</code> receives nothing and pays nothing.<a href="https://ethresear.ch#fn3dst"><span class="math">^{[3]}</span></a><a href="https://ethresear.ch" name="fn3"></a></p>
<p>Now consider the “revenue” (or the sum of the bids collected by the mechanism) generated from each case:</p>
<ul>
<li><strong><code>Proportional-all-pay</code> revenue:</strong> <span class="math">b_1 + b_2 = 4/3</span></li>
<li><strong><code>Winner-take-all</code> revenue:</strong> <span class="math">\qquad\quad\,\,\,\;\;\;\; b_1 = 2+\epsilon</span></li>
</ul>
<p><code>Winner-take-all</code> has better revenue, corresponding to a more accurate MEV oracle (and thus more MEV burned or smoothed by the protocol) than <code>Proportional-all-pay</code>. Intuitively, by allocating block-production rights to players with lower values (as <code>Proportional-all-pay</code> does), we forgo revenue we would have received had we simply allocated the entire rights to the player with the highest value. We point the interested reader to <a href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16">Aside 1</a> for a more complete treatment.</p>
<p>Another factor to consider is the “fairness” or “distribution” of the allocation mechanism. For example, suppose we agree on the metric: <span class="math">\text{fairness} = \sqrt{x_1 \cdot x_2}</span> (we use the geometric mean because if <span class="math">x_1 + x_2</span> has a fixed sum, the geometric mean is maximized at <span class="math">x_1 = x_2</span> and zero if either <span class="math">x_1,x_2</span> is zero). Now, let’s look at the fairness outcomes of the two candidate mechanisms:</p>
<ul>
<li><strong><code>Proportional-all-pay</code> fairness:</strong> <span class="math">\sqrt{1/3 \cdot 2/3} \approx 0.471</span></li>
<li><strong><code>Winner-take-all</code> fairness:</strong> <span class="math">\qquad\qquad\;\,\;\sqrt{1 \cdot 0} = 0</span></li>
</ul>
<p>Here, the “performance” of the two mechanisms flips – the <code>Winner-take-all</code> is <em>less fair</em> because <code>Player 2</code> has no chance of winning the game with a lower value. In the <code>Proportional-all-pay</code>, <code>Player 2</code> can hope to win some blocks despite bidding a lower value. As another example, consider the case where <span class="math">v_1=v_2+\epsilon</span>. The <code>Winner-take-all</code> mechanism allocates all the rights to <code>Player 1</code>, while the <code>Proportional-all-pay</code> splits the rights approximately in half.</p>
<blockquote>
<p>Brief note: why might the protocol care about fairness? In a decentralized protocol, a single actor having too much power undermines the credible neutrality of the system. As such, the protocol may be willing to “pay” (in the form of reduced revenue) to ensure that a resource is more evenly distributed among players. Alternatively, we could consider this a measure of “entropy” or even simply randomness being injected into the outcome of the game to try to reduce the influence the most dominant player can have.</p>
</blockquote>
<p>This leads to the punchline from this small example: <strong>a fundamental trade-off exists between MEV-oracle quality and fairness.</strong> The <code>Proportional-all-pay</code> mechanism (and hence the original execution tickets proposal) is fairer because both players win the game with some probability, incentivizing them each (but more importantly, the higher value player) to <a href="https://en.wikipedia.org/wiki/Bid_shading" rel="noopener nofollow ugc">shade</a> their bid accordingly, lowering the revenue, and thus the MEV-oracle accuracy, of the mechanism. The first price mechanism elicits higher bids since bidders only pay if they win the entire block production rights, increasing the revenue, but this <code>Winner-take-all</code> dynamic makes the allocation less fair.</p>
<p><em>Open question: is <code>Proportional-all-pay</code> an “optimal” Sybil-proof mechanism?</em> In the permissionless setting, we only consider Sybil-proof mechanisms, where a player doesn’t benefit from splitting their bid into multiple identities. We posit that the <code>Proportional-all-pay</code> mechanism sits in the <a href="https://en.wikipedia.org/wiki/Habitable_zone" rel="noopener nofollow ugc">Goldilock’s Zone</a> of a Sybil-proof mechanism that gets both good revenue/MEV-oracle accuracy and fairness. We leave as an interesting open problem to determine the extent to which the <code>Proportional-all-pay</code> mechanism’s “optimality” (e.g., we were unable to find another Sybil-proof mechanism that dominates it in both revenue and fairness).</p>
<h4><a class="anchor" href="https://ethresear.ch#aside-1-calculating-equilibrium-bids-16" name="aside-1-calculating-equilibrium-bids-16"></a>Aside <span class="hashtag-raw">#1</span> – Calculating equilibrium bids</h4>
<p><a href="https://ethresear.ch#h-4-extrapolation-18">Convenience link</a> to skip to the conclusion for the less-keen reader <img alt=":wink:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wink.png?v=12" title=":wink:" width="20" /></p>
<p>In the numerical example above, we provide the equilibrium bids for the <code>Winner-take-all</code> and <code>Proportional-all-pay</code> mechanisms without proof. How can these be determined generally (e.g., continuing to assume that bidders’ values are common knowledge)?<a href="https://ethresear.ch#fn4dst"><span class="math">^{[4]}</span></a><a href="https://ethresear.ch" name="fn4"></a></p>
<p>The <code>Winner-take-all</code> is the familiar <a href="https://www.econport.org/econport/request?page=man_auctions_firstpricesealed" rel="noopener nofollow ugc">First Price Auction</a> setting. In such auctions, the complete information Pure-Nash equilibrium has the two highest-value bidders, each bidding the second-highest bidder’s value, with every other agent bidding below this. In effect, we expect that the highest-value bidder always wins while paying the second highest bidder’s value (we represent this simply as <span class="math">b_1=b_2+\epsilon</span>, though you could equivalently tie-break in favor of the higher-value player).</p>
<p>In the <code>Proportional-all-pay</code> setting, each player has the utility,</p>
<div class="math">
\begin{align}
U_i (\mathbf{b}) &amp;= v_i \cdot x_i(\mathbf{b}) - b_i \\
&amp;= v_i \cdot \frac{b_i}{\sum_j b_j} - b_i.
\end{align}
</div>
<p>To determine the existence of a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" rel="noopener nofollow ugc">Pure Nash Equilibrium</a>, we consider each player’s first- and second-order conditions. Let <span class="math">\mathbf{b}^*</span> denote the candidate equilibrium set of bids.</p>
<ol>
<li><strong>First-order condition</strong>: <span class="math">\partial U_i / \partial b_i (\mathbf{b^*}) = 0</span> (or <span class="math">\partial U_i / \partial b_i (\mathbf{b^*}) \leq 0, \;\forall i \text{ s.t. } b^*_i=0</span>.)
<ul>
<li>Intuitively, this condition checks a non-zero-bidding player is (to first order) locally indifferent to small changes in its bid.</li>
</ul>
</li>
<li><strong>Second-order condition</strong>: <span class="math">\partial^2 U_i / \partial b_i^2 &lt; 0</span>
<ul>
<li>Intuitively, this condition ensures that the utility function is concave, implying that locally best responses are globally best for all players.</li>
</ul>
</li>
</ol>
<p>In our simple two-player example in the <code>Proportional-all-pay</code> setting, we have the following.</p>
<div class="math">
\begin{align}
\frac{\partial U_1}{\partial b_1}(\mathbf{b}) = \frac{v_1 b_2}{(b_1 + b_2)^2} - 1 = 0 \; , \quad \frac{\partial U_2}{\partial b_2}(\mathbf{b}) = \frac{v_2 b_1}{(b_1 + b_2)^2} - 1 = 0
\end{align}
</div>
<p>This system can be solved to find the equilibrium bids, <span class="math">\mathbf{b}^*</span>,</p>
<div class="math">
\begin{align}
b^*_1 = \frac{v_1^2 v_2}{(v_1 + v_2)^2}\; , \quad b^*_2 = \frac{v_2^2 v_1}{(v_1 + v_2)^2}.
\end{align}
</div>
<p>For our toy example, we have <span class="math">v_1=4, \; v_2=2 \implies b_1^* = 32/36, \; b_2^* = 16/36</span>. We can verify our first-order conditions</p>
<div class="math">
\begin{align}
\frac{4 \cdot 16/36}{16/9} - 1 = 0 \; , \quad \frac{2 \cdot 32/36}{16/9} - 1 = 0 \quad \checkmark
\end{align}
</div>
<p>The second-order conditions can also be verified – this is left as an exercise for the reader <img alt=":wink:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/wink.png?v=12" title=":wink:" width="20" /></p>
<h4><a class="anchor" href="https://ethresear.ch#aside-2-tullock-contests-17" name="aside-2-tullock-contests-17"></a>Aside <span class="hashtag-raw">#2</span> – Tullock Contests</h4>
<p><a href="https://youtu.be/lL2ZwXj1tXM?t=60" rel="noopener nofollow ugc">Last chance</a> to <a href="https://ethresear.ch#h-4-extrapolation-18">skip to the conclusion</a>. (If you continue, by definition, you are the “interested reader” – <a href="https://www.youtube.com/watch?v=SC4xMk98Pdc&amp;t=35s" rel="noopener nofollow ugc">congrats</a>.)</p>
<p>The model described above is established in the algorithmic game theory literature as a <a href="https://www.chapman.edu/ESI/wp/GeneralizedTullockContest-Sheremeta.pdf" rel="noopener nofollow ugc">Tullock Contest</a> – named for Gordon Tullock, who explored the idea in his seminal work, “<a href="https://link.springer.com/chapter/10.1007/978-3-540-79182-9_6" rel="noopener nofollow ugc"><em>Efficient Rent Seeking</em></a>.” He motivates this study by considering situations where investment is made before the outcome is known and where the investments might not transfer easily between participants, e.g., political spending.</p>
<blockquote>
<p>“<em>Suppose, for example, that we organize a lobby in Washington for the purpose of raising the price of milk and are unsuccessful. We cannot simply transfer our collection of contacts, influences, past bribes, and so forth to the steel manufacturers’ lobby. In general, our investments are too specialized, and, in many cases, they are matters of very particular and detailed goodwill to a specific organization. It is true that we could sell the steel lobby our lobbyists with their connections and perhaps our mailing list. But presumably, all these things have been bought by us at their proper cost. Our investment has not paid, but there is nothing left to transfer.</em>” – <strong>Gordon Tullock (1980)</strong></p>
</blockquote>
<p>This allocation mechanism has been applied in the previous crypto literature as well. Back in 2018 (ancient history in crypto-terms), Arnosti and Weinberg wrote “<a href="https://arxiv.org/abs/1811.08572" rel="noopener nofollow ugc"><em>Bitcoin: A natural oligopoly</em></a>,” which demonstrates that even small operating cost advantages among miners in a Proof-of-Work system lead to surprisingly concentrated equilibria. Similarly, Bahrani, Garimidi, and Roughgarden (these names sound familiar :D) explored the centralization effects of heterogeneity in block building skill in “<a href="https://arxiv.org/abs/2401.12120" rel="noopener nofollow ugc"><em>Centralization in Block Building and Proposer-Builder Separation</em></a>.” There appears to be a deep relationship between permissionless crypto-economic systems, where anti-Sybil mechanisms typically require financial investment for participation, and Tullock Contests – more on this <code>Soon™</code> (maybe).</p>
<h3><a class="anchor" href="https://ethresear.ch#h-4-extrapolation-18" name="h-4-extrapolation-18"></a>(4) – Extrapolation</h3>
<p>Phew, thanks for hanging in there; let’s take stock of what we learned. <strong><a href="https://ethresear.ch#h-3-interrogation-11">Section 3</a> demonstrates the fundamental trade-off between MEV-oracle accuracy and fairness of an instantiation of an execution ticket mechanism.</strong> A protocol may be willing to *pay* (in the form of reduced revenue) for more distribution and entropy with the goal of improving and maintaining the protocol’s credible neutrality. Further, using the model to derive equilibrium bids helps inform how we may expect agents to respond to various allocation and payment rules. <a href="https://youtu.be/Hm3JodBR-vs?t=21" rel="noopener nofollow ugc">Neat</a> – our framework led to some interesting and hopefully helpful insights! Maybe we can extend it to other problems in the space as well?</p>
<p>Further questions that this specific model may help answer (returning to three of our <code>W^4 questions</code>):</p>
<ul>
<li><em><strong>What</strong> is the good that players are competing for?</em>
<ul>
<li>Can we extend the model dimensionality, allowing different players to have different values for portions of the block (e.g., an arbitrageur may disproportionately value the top of a block but have zero value for the remainder)?</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>How does the MEV-oracle accuracy change if the game takes place far ahead of time versus during the slot itself (e.g., pricing future expected MEV versus present realizable MEV)?</li>
</ul>
</li>
<li><em><strong>How</strong> is the block builder chosen?</em>
<ul>
<li>Are there other Sybil-proof mechanisms that dominate <code>Proportional-all-pay</code> in both revenue and fairness?</li>
<li>Can we more formally characterize the fundamental trade-offs between revenue and fairness?</li>
<li>Given the Sybil-proofness constraint, what alternative allocation and payment rules should be explored (e.g., Tullock contests where the allocation rule is parameterized by <span class="math">\alpha&gt;1</span> where <span class="math">x_i = b_i^\alpha / \sum_j b_j^\alpha</span>), and can we identify the optimal choice?</li>
</ul>
</li>
</ul>
<p>Zooming back out, other versions of the <code>W^4H questions</code> may require different models to reason about.</p>
<ul>
<li><em><strong>Who</strong> controls the outcome of the game?</em>
<ul>
<li>In the committee-enforced version of these mechanisms, how could collusive behavior emerge?</li>
<li>If the just-in-time block auction continues to take place out-of-protocol, should we explicitly describe the secondary market?</li>
</ul>
</li>
<li><em><strong>When</strong> does the game take place?</em>
<ul>
<li>How critical is network latency when considering lookahead block-space sales versus same-slot? Is it worth modeling the <a href="https://dl.acm.org/doi/pdf/10.1145/42282.42283" rel="noopener nofollow ugc">partially-synchronous</a> setting?</li>
<li>How do block builder valuations change if multi-slot MEV is feasible?</li>
</ul>
</li>
<li><em><strong>Where</strong> does the MEV oracle come from?</em>
<ul>
<li>If it comes from the committee, are there incentives for committee members to behave dishonestly?</li>
<li>Do such incentives depend on whether protocol-captured MEV is burned or smoothed?</li>
</ul>
</li>
</ul>
<p>As per usual, open questions abound, but we hope (a) <code>W^4H questions</code> help expand the understanding of block-space distribution mechanisms and (b) the deep dive into allocation mechanisms helps inform the potential design space of execution tickets.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://ethresear.ch/uploads/default/original/3X/8/f/8f4ceb270ae099c612cbb2afb4958a9bea1b42d1.jpeg" title="upload_a24cdf5b513fb4e410700573687adcd6"><img alt="upload_a24cdf5b513fb4e410700573687adcd6" height="493" src="https://ethresear.ch/uploads/default/optimized/3X/8/f/8f4ceb270ae099c612cbb2afb4958a9bea1b42d1_2_690x493.jpeg" width="690" /></a></div><br />
<sub><strong>^ <a href="https://youtu.be/WSLMN6g_Od4?t=92" rel="noopener nofollow ugc">The world once we figure out MEV.</a></strong></sub><p></p>
<p>Excited to be here with y’all.</p>
<p><em>— made with <img alt=":heart:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/heart.png?v=12" title=":heart:" width="20" /> by mike, pranav, &amp; dr. tim roughgarden.</em></p>
<hr />
<h3><a class="anchor" href="https://ethresear.ch#footnotes-19" name="footnotes-19"></a>footnotes</h3>
<p><span class="math">^{[1]}</span><a href="https://ethresear.ch" name="fn1dst"></a>: The “all-pay” feature is made possible by burning the price paid for each ticket. <a href="https://ethresear.ch#fn1"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[2]}</span><a href="https://ethresear.ch" name="fn2dst"></a>: The “winner-pay” version could be done by refunding all non-winning ticket holders their payment at the end of each round. <a href="https://ethresear.ch#fn2"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[3]}</span><a href="https://ethresear.ch" name="fn3dst"></a>: As mentioned earlier, simply refunding the non-winning tickets instantiates the “winner-pays” property. <a href="https://ethresear.ch#fn3"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
<p><span class="math">^{[4]}</span><a href="https://ethresear.ch" name="fn4dst"></a>: This is primarily for tractability in calculating equilibria analytically. Although a strong assumption, it’s not unreasonable in the context of lookahead auctions where bidders might have established prior distributions on their competitor’s valuations. We also view the insights from studying the complete-information equilibria as valuable heuristics for how we may expect these mechanisms to behave in practice. <a href="https://ethresear.ch#fn4"><img alt=":leftwards_arrow_with_hook:" class="emoji" height="20" src="https://ethresear.ch/images/emoji/facebook_messenger/leftwards_arrow_with_hook.png?v=12" title=":leftwards_arrow_with_hook:" width="20" />︎</a></p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://ethresear.ch/t/on-block-space-distribution-mechanisms/19764">Read full topic</a></p>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 12:42:54 +0000</pubDate>
</item>
</channel>
</rss>