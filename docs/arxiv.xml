<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>

<item>
<title>FORAY: Towards Effective Attack Synthesis against Deep Logical Vulnerabilities in DeFi Protocols</title>
<link>https://arxiv.org/abs/2407.06348</link>
<guid>https://arxiv.org/abs/2407.06348</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain, Decentralized Finance (DeFi), smart contract, vulnerability detection, attack synthesis framework.

总结:<br>
区块链技术随着去中心化金融(DeFi)应用的兴起而迅速发展，但其价值巨大使其成为攻击目标。当前的智能合约漏洞检测工具在处理复杂的DeFi协议时面临挑战，因为它们涉及多个智能合约间的深层逻辑错误。为此，研究人员提出了Foray，一个针对DeFi深逻辑漏洞的有效攻击合成框架。Foray首先将低级智能合约提升到金融操作的高级别，通过设计领域特定语言(DSL)构建Token Flow Graph(TFG)。它采用策略性路径寻找生成攻击草图，而非随机枚举，提高效率。对于每个候选草图，Foray进行领域特定的符号编译，简化约束并适用于大规模问题。最后，通过现有求解器完成并转换为实际攻击。Foray有效地应对了DeFi中的复杂安全威胁。 <div>
arXiv:2407.06348v1 Announce Type: new 
Abstract: Blockchain adoption has surged with the rise of Decentralized Finance (DeFi) applications. However, the significant value of digital assets managed by DeFi protocols makes them prime targets for attacks. Current smart contract vulnerability detection tools struggle with DeFi protocols due to deep logical bugs arising from complex financial interactions between multiple smart contracts. These tools primarily analyze individual contracts and resort to brute-force methods for DeFi protocols crossing numerous smart contracts, leading to inefficiency. We introduce Foray, a highly effective attack synthesis framework against deep logical bugs in DeFi protocols. Foray proposes a novel attack sketch generation and completion framework. Specifically, instead of treating DeFis as regular programs, we design a domain-specific language (DSL) to lift the low-level smart contracts into their high-level financial operations. Based on our DSL, we first compile a given DeFi protocol into a token flow graph, our graphical representation of DeFi protocols. Then, we design an efficient sketch generation method to synthesize attack sketches for a certain attack goal (e.g., price manipulation, arbitrage, etc.). This algorithm strategically identifies candidate sketches by finding reachable paths in TFG, which is much more efficient than random enumeration. For each candidate sketch written in our DSL, Foray designs a domain-specific symbolic compilation to compile it into SMT constraints. Our compilation simplifies the constraints by removing redundant smart contract semantics. It maintains the usability of symbolic compilation, yet scales to problems orders of magnitude larger. Finally, the candidates are completed via existing solvers and are transformed into concrete attacks via direct syntax transformation.
]]></content:encoded>


</item>
<item>
<title>Toychain: A Simple Blockchain for Research in Swarm Robotics</title>
<link>https://arxiv.org/abs/2407.06630</link>
<guid>https://arxiv.org/abs/2407.06630</guid>
<content:encoded><![CDATA[
<div> 关键词：Toychain, Python, blockchain, robotics, smart contracts.

总结:
Toychain是一个由Python实现的轻量级区块链技术，专为机器人研究设计，易于部署和实用。它支持与ARGoS、Gazebo和ROS2等机器人软件工具集成，也可部署在具备Wi-Fi通信的实体机器人上。Toychain的核心功能是执行用Python编写的智能合约，通过广播交易更新分布式网络的状态，共识协议可以根据研究需求进行定制，目前支持Proof-of-Work和Proof-of-Authority。这个技术简化了在机器人领域应用区块链的过程。 <div>
arXiv:2407.06630v1 Announce Type: new 
Abstract: This technical report describes the implementation of Toychain: a simple, lightweight blockchain implemented in Python, designed for ease of deployment and practicality in robotics research. It can be integrated with various software and simulation tools used in robotics (we have integrated it with ARGoS, Gazebo, and ROS2), and also be deployed on real robots capable of Wi-Fi communications. The Toychain package supports the deployment of smart contracts written in Python (computer programs that can be executed by and synchronized across a distributed network). The nodes in the blockchain can execute smart contract functions by broadcasting transactions, which update the state of the blockchain upon agreement by all other nodes. The conditions for this agreement are established by a consensus protocol. The Toychain package allows for custom implementations of the consensus protocol, which can be useful for research or meeting specific application requirements. Currently, Proof-of-Work and Proof-of-Authority are implemented.
]]></content:encoded>


</item>
<item>
<title>The Cost of Executing Business Processes on Next-Generation Blockchains: The Case of Algorand</title>
<link>https://arxiv.org/abs/2407.06725</link>
<guid>https://arxiv.org/abs/2407.06725</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, process execution, Algorand, transaction fees, scalability

总结: 这篇文章探讨了区块链技术在业务流程执行中的应用，特别是关注了Algorand这种新型区块链系统。Algorand的特点在于低交易费用和快速最终性，但其成本结构与传统区块链（如以太坊）有显著差异。作者开发了一个BPMN Choreographies编译器，将流程转换为Algorand的智能合约语言TEAL，对比了在Algorand上执行流程的成本与传统云服务及先前研究。研究发现Algorand可以带来巨大的成本优势，但也提出了未来需要进一步探索和比较的多个挑战。 <div>
arXiv:2407.06725v1 Announce Type: new 
Abstract: Process (or workflow) execution on blockchain suffers from limited scalability; specifically, costs in the form of transactions fees are a major limitation for employing traditional public blockchain platforms in practice. Research, so far, has mainly focused on exploring first (Bitcoin) and second-generation (e.g., Ethereum) blockchains for business process enactment. However, since then, novel blockchain systems have been introduced - aimed at tackling many of the problems of previous-generation blockchains. We study such a system, Algorand, from a process execution perspective. Algorand promises low transaction fees and fast finality. However, Algorand's cost structure differs greatly from previous generation blockchains, rendering earlier cost models for blockchain-based process execution non-applicable. We discuss and contrast Algorand's novel cost structure with Ethereum's well-known cost model. To study the impact for process execution, we present a compiler for BPMN Choreographies, with an intermediary layer, which can support multi-platform output, and provide a translation to TEAL contracts, the smart contract language of Algorand. We compare the cost of executing processes on Algorand to previous work as well as traditional cloud computing. In short: they allow vast cost benefits. However, we note a multitude of future research challenges that remain in investigating and comparing such results.
]]></content:encoded>


</item>
<item>
<title>Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems</title>
<link>https://arxiv.org/abs/2407.06862</link>
<guid>https://arxiv.org/abs/2407.06862</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized Architectures, Inter-Planetary File System (IPFS), Smart Contract, Weight Aggregation

总结:
本文探讨了一种基于去中心化架构的联邦学习（FL）系统，利用IPFS存储加密模型参数并通过智能合约管理协作过程，确保数据安全和可靠性。研究比较了两种聚合方法：经典平均和联邦proximal聚合。实验结果证实了该提案的可行性。通过智能合约的透明性和自动执行，这种设计提高了FL的信任度和效率。<br>总结: <div>
arXiv:2407.06862v1 Announce Type: new 
Abstract: In this paper, we present a study of a Federated Learning (FL) system, based on the use of decentralized architectures to ensure trust and increase reliability. The system is based on the idea that the FL collaborators upload the (ciphered) model parameters on the Inter-Planetary File System (IPFS) and interact with a dedicated smart contract to track their behavior. Thank to this smart contract, the phases of parameter updates are managed efficiently, thereby strengthening data security. We have carried out an experimental study that exploits two different methods of weight aggregation, i.e., a classic averaging scheme and a federated proximal aggregation. The results confirm the feasibility of the proposal.
]]></content:encoded>


</item>
<item>
<title>DL-Chain: Scalable and Stable Blockchain Sharding with High Concurrency via Dual-Layer Consensus</title>
<link>https://arxiv.org/abs/2407.06882</link>
<guid>https://arxiv.org/abs/2407.06882</guid>
<content:encoded><![CDATA[
<div> 关键词：Sharding, Blockchain, Concurrency, Security, DL-Chain

总结:<br>
这篇文章主要探讨了区块链分片技术（Sharding）在提高交易并发性的同时面临的挑战，特别是如何在减小分片规模以增强并发性与确保系统安全之间找到平衡。作者提出了一种新型的区块链系统DL-Chain，它采用双层架构和共识机制，通过较小的提案分片（PSs）处理交易，较大的最终确认委员会（FCs）进行事务最终化。DL-Chain的关键创新在于通过PSs和FCs的合作保持系统的活跃性，避免了频繁的恢复过程，从而实现高并发性和稳定性能。此外，该系统优化FC设计，支持多个并存，允许每个PS中有较少的恶意节点，从而能配置更小的分片以提升并发性。实验结果表明，DL-Chain在吞吐量上比现有方案提高了10倍，并能在高达2,550个节点的情况下提供稳定的并发能力。 <div>
arXiv:2407.06882v1 Announce Type: new 
Abstract: Sharding enhances blockchain scalability by partitioning nodes into multiple groups for concurrent transaction processing. Configuring a large number of \emph{small shards} helps improve the transaction concurrency of a sharding system. However, it increases the fraction of malicious nodes within each shard, easily leading to shard corruption and jeopardizing system security. Some existing works have attempted to improve concurrency by reducing the shard size while maintaining security. However, they often require frequent and time-consuming recovery of corrupted shards, leading to severe system stagnation. Also, they usually require network-wide consensus to guarantee security, which limits scalability.
  To address these issues, we propose DL-Chain, a blockchain sharding system that can securely provide \emph{high concurrency with stable and scalable performance.} Our core idea is a \underline{D}ual-\underline{L}ayer architecture and consensus, which consists of numerous smaller proposer shards (PSs) for transaction processing and multiple larger finalizer committees (FCs) for transaction finalization. To avoid system stagnation and thus guarantee stable performance, we ensure PSs' liveness even if they are corrupted through the cooperation of PSs and FCs, thus eliminating the recovery process of corrupted PSs. To better trade-off security and scalability, we fine-tune the FCs to enable multiple FCs to coexist securely. As a result, DL-Chain allows a larger fraction of malicious nodes in each PS ($<1/2$) and thus can securely configure smaller shards for boosted stable and scalable concurrency. Evaluation results show that DL-Chain achieves up to 10 times improvement in throughput compared to existing solutions and provides stable concurrency with up to 2,550 nodes.
]]></content:encoded>


</item>
<item>
<title>SP-Chain: Boosting Intra-Shard and Cross-Shard Security and Performance in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2407.06953</link>
<guid>https://arxiv.org/abs/2407.06953</guid>
<content:encoded><![CDATA[
<div> 关键词：sharding, blockchain, SP-Chain, security, performance

总结:<br>
SP-Chain是一种新的区块链分片系统，旨在解决现有区块链在扩展性和安全性方面的挑战。它在保证高性能的同时，增强了对内部（intra-shard）和跨分片（cross-shard）交易的保护。论文的关键创新包括：<br>
1. 采用两阶段并发投票机制，提高系统吞吐量和降低交易确认延迟。
2. 设计高效无偏的领导者轮换方案，确保在恶意行为下仍保持性能。
3. 提出基于证明的跨分片交易处理机制，以低开销保障交易安全。
4. 实现于Harmony平台，通过大规模部署评估，结果显示在4000节点网络中，即使面对恶意行为，也能处理超过10000笔每秒的交易，确认时间为7.6秒。 <div>
arXiv:2407.06953v1 Announce Type: new 
Abstract: A promising way to overcome the scalability limitations of the current blockchain is to use sharding, which is to split the transaction processing among multiple, smaller groups of nodes. A well-performed blockchain sharding system requires both high performance and high security in both intra- and cross-shard perspectives. However, existing protocols either have issues on protecting security or trade off great performance for security. In this paper, we propose SP-Chain, a blockchain sharding system with enhanced Security and Performance for both intra- and cross-shard perspectives. For intra-shard aspect, we design a two-phase concurrent voting scheme to provide high system throughput and low transaction confirmation latency. Moreover, we propose an efficient unbiased leader rotation scheme to ensure high performance under malicious behavior. For cross-shard aspect, a proof-assisted efficient cross-shard transaction processing mechanism is proposed to guard the cross-shard transactions with low overhead. We implement SP-Chain based on Harmony, and evaluate its performance via large-scale deployment. Extensive evaluations suggest that SP-Chain can process more than 10,000 tx/sec under malicious behaviors with a confirmation latency of 7.6s in a network of 4,000 nodes.
]]></content:encoded>


</item>
<item>
<title>Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies</title>
<link>https://arxiv.org/abs/2407.07019</link>
<guid>https://arxiv.org/abs/2407.07019</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs), Health Insurance, Smart Contracts, Blockchain, Policy Automation.

总结:
本文探讨了使用大型语言模型（LLMs）生成自动化的健康保险流程代码，从文本政策中。研究重点是区块链智能合约，因其提供不可变性、可验证性、可扩展性和无需预先建立信任的环境。方法论涉及生成不同技术细节层次的内容：文本摘要、决策逻辑和带有单元测试的智能合约代码。评估表明LLMs在生成文本摘要方面表现良好，但任务（2）和（3）的结构化输出需要人工审阅，因为它们可能不完整、不准确或语法错误。尽管如此，实验展示了LLMs在将文本处理描述转化为智能合约方面的潜力，尤其是对于简单的场景。复杂场景仍面临挑战，需要进一步改进。总的来说，文章展示了LLMs在医疗保险自动化中的初步应用前景，但仍需结合人类专家的监督。 <div>
arXiv:2407.07019v1 Announce Type: new 
Abstract: We explore using Large Language Models (LLMs) to generate application code that automates health insurance processes from text-based policies. We target blockchain-based smart contracts as they offer immutability, verifiability, scalability, and a trustless setting: any number of parties can use the smart contracts, and they need not have previously established trust relationships with each other. Our methodology generates outputs at increasing levels of technical detail: (1) textual summaries, (2) declarative decision logic, and (3) smart contract code with unit tests. We ascertain LLMs are good at the task (1), and the structured output is useful to validate tasks (2) and (3). Declarative languages (task 2) are often used to formalize healthcare policies, but their execution on blockchain is non-trivial. Hence, task (3) attempts to directly automate the process using smart contracts. To assess the LLM output, we propose completeness, soundness, clarity, syntax, and functioning code as metrics. Our evaluation employs three health insurance policies (scenarios) with increasing difficulty from Medicare's official booklet. Our evaluation uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our findings confirm that LLMs perform quite well in generating textual summaries. Although outputs from tasks (2)-(3) are useful starting points, they require human oversight: in multiple cases, even "runnable" code will not yield sound results; the popularity of the target language affects the output quality; and more complex scenarios still seem a bridge too far. Nevertheless, our experiments demonstrate the promise of LLMs for translating textual process descriptions into smart contracts.
]]></content:encoded>


</item>
<item>
<title>A Differentially Private Blockchain-Based Approach for Vertical Federated Learning</title>
<link>https://arxiv.org/abs/2407.07054</link>
<guid>https://arxiv.org/abs/2407.07054</guid>
<content:encoded><![CDATA[
<div> 关键词：Differentially Private Blockchain-Based Vertical Federated Learning (DP-BBVFL), privacy, embeddings, blockchain, medical data.

总结:<br>本文介绍了Differentially Private Blockchain-Based Vertical Federated Learning (DP-BBVFL)算法，一种结合了区块链技术和差分隐私的新型联邦学习方法。该算法通过智能合约透明地聚合客户端的特征表示（嵌入），同时保护存储在区块链上的原始数据隐私。DP-BBVFL首次展示了差分隐私与区块链在垂直联邦学习中的应用潜力。实验结果显示，尽管增加了训练时间，但该方法在医疗数据上实现了高精度，预示着分布式、可信任的机器学习应用的新纪元。<br>总结: <div>
arXiv:2407.07054v1 Announce Type: new 
Abstract: We present the Differentially Private Blockchain-Based Vertical Federal Learning (DP-BBVFL) algorithm that provides verifiability and privacy guarantees for decentralized applications. DP-BBVFL uses a smart contract to aggregate the feature representations, i.e., the embeddings, from clients transparently. We apply local differential privacy to provide privacy for embeddings stored on a blockchain, hence protecting the original data. We provide the first prototype application of differential privacy with blockchain for vertical federated learning. Our experiments with medical data show that DP-BBVFL achieves high accuracy with a tradeoff in training time due to on-chain aggregation. This innovative fusion of differential privacy and blockchain technology in DP-BBVFL could herald a new era of collaborative and trustworthy machine learning applications across several decentralized application domains.
]]></content:encoded>


</item>
<item>
<title>Hyperion - A fast, versatile symbolic Gaussian Belief Propagation framework for Continuous-Time SLAM</title>
<link>https://arxiv.org/abs/2407.07074</link>
<guid>https://arxiv.org/abs/2407.07074</guid>
<content:encoded><![CDATA[
<div> 关键词：Continuous-Time SLAM, Centralized NLLS, SymForce, B- and Z-Spline, Gaussian Belief Propagation.

总结:<br>
本文介绍了一种新型的连续时间同时定位与建图(CTSLAM)方法，针对当前CTSLAM算法的计算需求高和集中式优化的问题。研究者提出了一种速度更快的SymForce（[Martiros等，RSS 2022]）B-和Z-Spline实现，比Sommer等人的方法[CVPR 2020]快2.43倍到110.31倍。此外，他们还开发了一个新的连续时间高斯信念传播框架Hyperion，旨在实现跨设备的分布式概率推断，适用于多传感器融合，如事件相机、滚筒式摄像头和惯性测量单元(IMU)。实验验证了新方法在运动跟踪和定位任务中的有效性，并通过实证研究进行了深入评估。 <div>
arXiv:2407.07074v1 Announce Type: new 
Abstract: Continuous-Time Simultaneous Localization And Mapping (CTSLAM) has become a promising approach for fusing asynchronous and multi-modal sensor suites. Unlike discrete-time SLAM, which estimates poses discretely, CTSLAM uses continuous-time motion parametrizations, facilitating the integration of a variety of sensors such as rolling-shutter cameras, event cameras and Inertial Measurement Units (IMUs). However, CTSLAM approaches remain computationally demanding and are conventionally posed as centralized Non-Linear Least Squares (NLLS) optimizations. Targeting these limitations, we not only present the fastest SymForce-based [Martiros et al., RSS 2022] B- and Z-Spline implementations achieving speedups between 2.43x and 110.31x over Sommer et al. [CVPR 2020] but also implement a novel continuous-time Gaussian Belief Propagation (GBP) framework, coined Hyperion, which targets decentralized probabilistic inference across agents. We demonstrate the efficacy of our method in motion tracking and localization settings, complemented by empirical ablation studies.
]]></content:encoded>


</item>
<item>
<title>Semantic Communication in Multi-team Dynamic Games: A Mean Field Perspective</title>
<link>https://arxiv.org/abs/2407.06528</link>
<guid>https://arxiv.org/abs/2407.06528</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent systems, networked control, mean-field games, noncooperative game, decentralized Nash equilibrium

总结:<br>本文研究了大规模多团队动态游戏中的协调通信与控制问题。每个团队由传感器和控制器组成，通过共享网络共同控制一个动态状态，同时考虑动作成本和传感/通信成本。由于无线通道的共享性质，团队的整体成本受其他团队策略影响，形成非合作博弈。通过扩展的mean-field游戏方法，文章计算了近似的分散式纳什均衡策略，考虑了平均流量和传感器信息价值。为解决传感器动作空间有限导致的非合同性问题，文章优化了代表团队的控制器和传感器策略。此外，文章证明了mean-field均衡解的ε-纳什性质，表明其对有限团队系统的性能。最后，大量的数值模拟验证了理论结果并揭示了更多洞察。 <div>
arXiv:2407.06528v1 Announce Type: cross 
Abstract: Coordinating communication and control is a key component in the stability and performance of networked multi-agent systems. While single user networked control systems have gained a lot of attention within this domain, in this work, we address the more challenging problem of large population multi-team dynamic games. In particular, each team constitutes two decision makers (namely, the sensor and the controller) who coordinate over a shared network to control a dynamically evolving state of interest under costs on both actuation and sensing/communication. Due to the shared nature of the wireless channel, the overall cost of each team depends on other teams' policies, thereby leading to a noncooperative game setup. Due to the presence of a large number of teams, we compute approximate decentralized Nash equilibrium policies for each team using the paradigm of (extended) mean-field games, which is governed by (1) the mean traffic flowing over the channel, and (2) the value of information at the sensor, which highlights the semantic nature of the ensuing communication. In the process, we compute optimal controller policies and approximately optimal sensor policies for each representative team of the mean-field system to alleviate the problem of general non-contractivity of the mean-field fixed point operator associated with the finite cardinality of the sensor action space. Consequently, we also prove the $\epsilon$--Nash property of the mean-field equilibrium solution which essentially characterizes how well the solution derived using mean-field analysis performs on the finite-team system. Finally, we provide extensive numerical simulations, which corroborate the theoretical findings and lead to additional insights on the properties of the results presented.
]]></content:encoded>


</item>
<item>
<title>Straggler-Resilient Decentralized Learning via Adaptive Asynchronous Updates</title>
<link>https://arxiv.org/abs/2306.06559</link>
<guid>https://arxiv.org/abs/2306.06559</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Optimization, Machine Learning, Synchronization, Asynchronous Updates, Staleness.

总结:
本文关注大规模机器学习模型的分布式训练，提出了一种全新的全分布式算法DSGD-AAU。DSGD-AAU旨在解决传统同步更新方法中的“尾随”问题，通过自适应地调整每个工作节点与邻居通信的数量，实现异步更新，从而减少参数过时（staleness）的影响。研究者证明了DSGD-AAU具有线性加速的收敛速度，并通过大量实验验证了其有效性，为处理大规模数据训练提供了高效且健壮的解决方案。 <div>
arXiv:2306.06559v2 Announce Type: replace 
Abstract: With the increasing demand for large-scale training of machine learning models, fully decentralized optimization methods have recently been advocated as alternatives to the popular parameter server framework. In this paradigm, each worker maintains a local estimate of the optimal parameter vector, and iteratively updates it by waiting and averaging all estimates obtained from its neighbors, and then corrects it on the basis of its local dataset. However, the synchronization phase is sensitive to stragglers. An efficient way to mitigate this effect is to consider asynchronous updates, where each worker computes stochastic gradients and communicates with other workers at its own pace. Unfortunately, fully asynchronous updates suffer from staleness of stragglers' parameters. To address these limitations, we propose a fully decentralized algorithm DSGD-AAU with adaptive asynchronous updates via adaptively determining the number of neighbor workers for each worker to communicate with. We show that DSGD-AAU achieves a linear speedup for convergence and demonstrate its effectiveness via extensive experiments.
]]></content:encoded>


</item>

<item>
<title>Experimental Study of Decentralized Robot Network Coordination</title>
<link>https://arxiv.org/abs/2407.04832</link>
<guid>https://arxiv.org/abs/2407.04832</guid>
<content:encoded><![CDATA[
<div> 关键词：synchronization, desynchronization, robotics, decentralized algorithm, Roomba robots

总结:<br />该研究关注于机器人网络中的同步与解同步问题，这是机器人合作领域鲜少探讨的主题。作者改进了先前开发的算法，并通过实验证明其在多机器人系统（如Roomba机器人）中的应用。实验中，调整算法参数影响了同步和解同步的时间以及网络状态稳定性。测试了三种不同的方法，结果各异。这些改进的算法为未来机器人协作任务的成功执行提供了可能。未来的研究将有望在各种任务中应用这些算法，促进分布式机器人系统的协同工作。 <div>
arXiv:2407.04832v1 Announce Type: new 
Abstract: Synchronization and desynchronization in networks is a highly studied topic in many electrical systems, but there is a distinct lack of research on this topic with respect to robotics. Creating an effective decentralized synchronization algorithm for a robotic network would allow multiple robots to work together to achieve a task and would be able to adapt to the addition or loss of robots in real-time. The purpose of this study is to improve algorithms implemented developed by the authors for this purpose and experimentally evaluate these methods. The most effective algorithm for synchronization and desynchronization found in a former study were modified to improve testing and vary its methods of calculation. A multi-robot platform composed of multiple Roomba robots was used in the experimental study. Observation of data showed how adjusting parameters of the algorithms affected both the time to reach a desired state of synchronization or desynchronization and how the network maintained this state. Testing three different methods on each algorithm showed differing results. Future work in cooperative robotics will likely see success using these algorithms to accomplish a variety of tasks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-agent Off-policy Actor-Critic Reinforcement Learning for Partially Observable Environments</title>
<link>https://arxiv.org/abs/2407.04974</link>
<guid>https://arxiv.org/abs/2407.04974</guid>
<content:encoded><![CDATA[
<div> 关键词：social learning, multi-agent, off-policy actor-critic, partially observable environment, decentralized

总结:<br />该研究提出了一种基于社会学习的多智能体强化学习算法，用于在部分可观测环境中估计全局状态。算法适用于模型免费的多智能体系统，无需了解转换模型，且采用去中心化操作，允许智能体与其邻居交换信息。文章分析了通过社会学习估计与完全观察全局状态结果的差异有界性，并展示了其在实验中的有效性，优于现有方法。这种方法为处理复杂环境中的协作学习提供了新的解决方案。 <div>
arXiv:2407.04974v1 Announce Type: new 
Abstract: This study proposes the use of a social learning method to estimate a global state within a multi-agent off-policy actor-critic algorithm for reinforcement learning (RL) operating in a partially observable environment. We assume that the network of agents operates in a fully-decentralized manner, possessing the capability to exchange variables with their immediate neighbors. The proposed design methodology is supported by an analysis demonstrating that the difference between final outcomes, obtained when the global state is fully observed versus estimated through the social learning method, is $\varepsilon$-bounded when an appropriate number of iterations of social learning updates are implemented. Unlike many existing dec-POMDP-based RL approaches, the proposed algorithm is suitable for model-free multi-agent reinforcement learning as it does not require knowledge of a transition model. Furthermore, experimental results illustrate the efficacy of the algorithm and demonstrate its superiority over the current state-of-the-art methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A game theory analysis of decentralized epidemic management with opinion dynamics</title>
<link>https://arxiv.org/abs/2407.05020</link>
<guid>https://arxiv.org/abs/2407.05020</guid>
<content:encoded><![CDATA[
<div> 关键词：game model, decentralized control, epidemic, Generalized Nash equilibrium (GNE), Price of Anarchy (PoA)

总结:<br />
本文提出了一种静态博弈模型，用于评估全球流行病中去中心化控制或管理导致的效率损失。每个玩家代表一个地区，决策包括实施公共卫生措施和影响区域意见。文章主要贡献在于对这种具有实际意义的游戏进行了详尽的分析，通过构造辅助游戏证明了GNE的存在性和唯一性，计算了GNE和最优集中化解决方案（总成本）。研究结果允许作者量化去中心化带来的PoA，考虑或不考虑意见动态。总的来说，这项工作为理解和比较不同控制策略对疫情管理的影响提供了数学工具。 <div>
arXiv:2407.05020v1 Announce Type: new 
Abstract: In this paper, we introduce a static game that allows one to numerically assess the loss of efficiency induced by decentralized control or management of a global epidemic. Each player represents a region which is assumed to choose its control to implement a tradeoff between socio-economic aspects and health aspects; the control comprises both epidemic control physical measures and influence actions on the region opinion. The Generalized Nash equilibrium $(\mathrm{GNE})$ analysis of the proposed game model is conducted. The direct analysis of this game of practical interest is non-trivial but it turns out that one can construct an auxiliary game which allows one: to prove existence and uniqueness; to compute the GNE and the optimal centralized solution (sum-cost) of the game. These results allow us to assess numerically the loss (measured in terms of Price of Anarchy ($\mathrm{PoA}$)) induced by decentralization with or without taking into account the opinion dynamics.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Impact of Network Topology on Byzantine Resilience in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2407.05141</link>
<guid>https://arxiv.org/abs/2407.05141</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized FL, Byzantine nodes, Aggregation function, Network topology.

总结:<br />Federated Learning (FL)是一种分布式机器学习方法，尤其在去中心化形式（Decentralized FL）中，用户无需中心服务器即可协作训练。然而，这类系统面临的一个关键挑战是处理可能存在的“拜占庭节点”，即试图干扰学习过程的异常节点。以往的研究主要集中在客户端-服务器或全连接网络上的拜占庭鲁棒性，但尚未评估其在复杂网络结构中的表现。本文研究了当前最先进的拜占庭鲁棒聚合策略在大型非完全连接网络中的效果，发现这些策略在复杂大型网络中并不稳健。因此，作者呼吁开发针对网络拓扑的聚合方案，这对于大规模现实部署至关重要。这一发现强调了在去中心化FL中考虑网络结构的必要性，以确保系统的健壮性和可靠性。 <div>
arXiv:2407.05141v1 Announce Type: new 
Abstract: Federated learning (FL) enables a collaborative environment for training machine learning models without sharing training data between users. This is typically achieved by aggregating model gradients on a central server. Decentralized federated learning is a rising paradigm that enables users to collaboratively train machine learning models in a peer-to-peer manner, without the need for a central aggregation server. However, before applying decentralized FL in real-world use training environments, nodes that deviate from the FL process (Byzantine nodes) must be considered when selecting an aggregation function. Recent research has focused on Byzantine-robust aggregation for client-server or fully connected networks, but has not yet evaluated such aggregation schemes for complex topologies possible with decentralized FL. Thus, the need for empirical evidence of Byzantine robustness in differing network topologies is evident. This work investigates the effects of state-of-the-art Byzantine-robust aggregation methods in complex, large-scale network structures. We find that state-of-the-art Byzantine robust aggregation strategies are not resilient within large non-fully connected networks. As such, our findings point the field towards the development of topology-aware aggregation schemes, especially necessary within the context of large scale real-world deployment.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BFLN: A Blockchain-based Federated Learning Model for Non-IID Data</title>
<link>https://arxiv.org/abs/2407.05276</link>
<guid>https://arxiv.org/abs/2407.05276</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, imbalanced data distribution, blockchain technology, aggregation method, incentive algorithm

总结:<br />
这篇文章主要关注了联邦学习中数据分布不均衡的问题，提出了一种结合区块链和联邦学习的新型模型——BFLN（Blockchain-based Federated Learning Model for Non-IID Data）。BFLN通过引入新的聚合方法和激励算法，提升了非独立同分布数据下的联邦学习性能。实验结果显示，相比于现有最先进的模型，BFLN在训练准确性上有所提高，并为个性化联邦学习提供了可持续的激励机制。总的来说，BFLN旨在解决数据不平衡问题，提高联邦学习的效率和公平性。 <div>
arXiv:2407.05276v1 Announce Type: new 
Abstract: As the application of federated learning becomes increasingly widespread, the issue of imbalanced training data distribution has emerged as a significant challenge. Federated learning utilizes local data stored on different training clients for model training, rather than centralizing data on a server, thereby greatly enhancing the privacy and security of training data. However, the distribution of training data across different clients may be imbalanced, with different categories of data potentially residing on different clients. This presents a challenge to traditional federated learning, which assumes data distribution is independent and identically distributed (IID). This paper proposes a Blockchain-based Federated Learning Model for Non-IID Data (BFLN), which combines federated learning with blockchain technology. By introducing a new aggregation method and incentive algorithm, BFLN enhances the model performance of federated learning on non-IID data. Experiments on public datasets demonstrate that, compared to other state-of-the-art models, BFLN improves training accuracy and provides a sustainable incentive mechanism for personalized federated learning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulnerability-Hunter: An Adaptive Feature Perception Attention Network for Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2407.05318</link>
<guid>https://arxiv.org/abs/2407.05318</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart Contract Vulnerability Detection, Graph Neural Networks, Feature Perception Module, Relationship Perception Attention Module, Performance Evaluation.

总结:<br />
该研究论文关注区块链系统的质量保证，特别是智能合约漏洞检测(ScVD)。现有的深度学习方法依赖图神经网络来理解代码语义，但其局限在于预定义规则的图采样和子图池化策略，这在处理智能合约代码的异构拓扑时可能不够灵活。为此，论文提出了一种新型的漏洞检测模型AFPNet，它包含特征感知模块和关系感知注意力模块。特征感知模块动态地扫描整个代码并自动提取关键代码片段，而关系感知注意力模块则利用注意力机制学习这些片段之间的依赖，以提高漏洞检测的准确性。实验结果显示，相比于现有最先进的方法，AFPNet在F1分数上提高了6.38%到14.02%，证明了其在动态提取有价值信息和优化SCVD方面的有效性。 <div>
arXiv:2407.05318v1 Announce Type: new 
Abstract: Smart Contract Vulnerability Detection (SCVD) is crucial to guarantee the quality of blockchain-based systems. Graph neural networks have been shown to be effective in learning semantic representations of smart contract code and are commonly adopted by existing deep learning-based SCVD. However, the current methods still have limitations in their utilization of graph sampling or subgraph pooling based on predefined rules for extracting crucial components from structure graphs of smart contract code. These predefined rule-based strategies, typically designed using static rules or heuristics, demonstrate limited adaptability to dynamically adjust extraction strategies according to the structure and content of the graph in heterogeneous topologies of smart contract code. Consequently, these strategies may not possess universal applicability to all smart contracts, potentially leading to false positives or omissions. To address these problems, we propose AFPNet, a novel vulnerability detection model equipped with a feature perception module that has dynamic weights for comprehensive scanning of the entire smart contract code and automatic extraction of crucial code snippets (the $P$ snippets with the largest weights). Subsequently, the relationship perception attention module employs an attention mechanism to learn dependencies among these code snippets and detect smart contract vulnerabilities. The efforts made by AFPNet consistently enable the capture of crucial code snippets and enhance the performance of SCVD optimization. We conduct an evaluation of AFPNet in the several large-scale datasets with vulnerability labels. The experimental results show that our AFPNet significantly outperforms the state-of-the-art approach by 6.38\%-14.02\% in term of F1-score. The results demonstrate the effectiveness of AFPNet in dynamically extracting valuable information and vulnerability detection.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Challenges and Best Practices in Corporate AI Governance:Lessons from the Biopharmaceutical Industry</title>
<link>https://arxiv.org/abs/2407.05339</link>
<guid>https://arxiv.org/abs/2407.05339</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、伦理原则、实践挑战、AstraZeneca、AI治理。

总结:<br />Astrazeneca是一家生物制药公司，正在探讨如何将伦理原则转化为有效的AI治理实践。文章指出，企业在实施AI治理时面临诸多挑战，如确定AI治理的范围、协调跨部门标准和衡量治理效果。Astrazeneca的经验包括依靠现有政策、实用术语、风险管理、员工教育和持续改进。这些实践对于其他组织设计和实施AI治理框架具有参考价值，鼓励企业注重风险管理，强化内部沟通与培训。 <div>
arXiv:2407.05339v1 Announce Type: new 
Abstract: While the use of artificial intelligence (AI) systems promises to bring significant economic and social benefits, it is also coupled with ethical, legal, and technical challenges. Business leaders thus face the question of how to best reap the benefits of automation whilst managing the associated risks. As a first step, many companies have committed themselves to various sets of ethics principles aimed at guiding the design and use of AI systems. So far so good. But how can well-intentioned ethical principles be translated into effective practice? And what challenges await companies that attempt to operationalize AI governance? In this article, we address these questions by drawing on our first-hand experience of shaping and driving the roll-out of AI governance within AstraZeneca, a biopharmaceutical company. The examples we discuss highlight challenges that any organization attempting to operationalize AI governance will have to face. These include questions concerning how to define the material scope of AI governance, how to harmonize standards across decentralized organizations, and how to measure the impact of specific AI governance initiatives. By showcasing how AstraZeneca managed these operational questions, we hope to provide project managers, CIOs, AI practitioners, and data privacy officers responsible for designing and implementing AI governance frameworks within other organizations with generalizable best practices. In essence, companies seeking to operationalize AI governance are encouraged to build on existing policies and governance structures, use pragmatic and action-oriented terminology, focus on risk management in development and procurement, and empower employees through continuous education and change management.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Blockchain Embedded Peer-to-Peer Access Control Framework for IoT Systems</title>
<link>https://arxiv.org/abs/2407.05506</link>
<guid>https://arxiv.org/abs/2407.05506</guid>
<content:encoded><![CDATA[
<div> 关键词：IoT系统、Blockchain、Access control、Decentralized、Pruned Blockchain-based Access Control (PBAC)

总结:<br />
这篇文章探讨了物联网(IoT)系统的访问控制问题，尤其是在涉及设备共享和数据访问的场景中。由于IoT设备分散在互联网边缘，传统的集中式访问控制面临挑战。为解决这一问题，作者提出了一种名为Pruned Blockchain-based Access Control (PBAC)的新协议。PBAC通过减少不必要的消息轮次，优化了验证和策略管理的效率。该协议包括两个关键部分：快捷方式（shortcut）和基于角色和设备层次结构的访问控制(R&amp;D-BAC)，以适应不同环境。此外，文中还详细讨论了实现PBAC所需的系统架构设计。实验结果显示，PBAC的快捷机制将访问时间减少了约43%，而R&amp;D-BAC比传统区块链基RBAC提高了两倍以上，显示了其显著的性能优势。 <div>
arXiv:2407.05506v1 Announce Type: new 
Abstract: We consider access control for IoT systems that involves shared accesses to the IoT devices as well as their data. Since IoT devices are dispersed all over the edge of the Internet, traditional centralized access control has problems. Blockchain based decentralized access control is thus the new solution trend. However, existing blockchain based access control methods do not focus on performance issues and may incur a high communication overhead.
  In this paper, we develop a Pruned Blockchain based Access Control (PBAC) protocol to cutdown the unnecessary message rounds and achieve high efficiency in access validations and policy management. The protocol includes a shortcut and a Role and Device Hierarchy-Based Access Control (R&amp;D-BAC) approaches for different environment settings. To realize the PBAC protocol, it is necessary to carefully engineer the system architecture, which is also discussed in the paper. Experiments demonstrate the efficacy of the PBAC protocol, specifically, the shortcut mechanism reduces access time by approximately 43%, and R&amp;D-BAC outperforms traditional blockchain based RBAC by more than two folds.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DFedSat: Communication-Efficient and Robust Decentralized Federated Learning for LEO Satellite Constellations</title>
<link>https://arxiv.org/abs/2407.05850</link>
<guid>https://arxiv.org/abs/2407.05850</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)卫星、人工智能、联邦学习、分布式学习、动态ISLs。

总结: 这篇论文关注低地球轨道（LEO）卫星在6G网络和空间-地面-空中集成系统中的应用。传统的集中式方法因卫星与地面站间连接不稳定而效率低下，因此提出了一种名为DFedSat的全分布式联邦学习框架。DFedSat通过在同轨道和异轨道卫星间设计自适应聚合机制，加速了模型训练，并引入补偿机制增强跨轨道链路的鲁棒性。论文还分析了非凸情况下DFedSat的亚线性收敛率。实验结果显示，DFedSat在收敛速度、通信效率和抗链路故障方面优于其他分布式学习基准。 <div>
arXiv:2407.05850v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellites play a crucial role in the development of 6G mobile networks and space-air-ground integrated systems. Recent advancements in space technology have empowered LEO satellites with the capability to run AI applications. However, centralized approaches, where ground stations (GSs) act as servers and satellites as clients, often encounter slow convergence and inefficiencies due to intermittent connectivity between satellites and GSs. In contrast, decentralized federated learning (DFL) offers a promising alternative by facilitating direct communication between satellites (clients) via inter-satellite links (ISLs). However, inter-plane ISLs connecting satellites from different orbital planes are dynamic due to Doppler shifts and pointing limitations. This could impact model propagation and lead to slower convergence. To mitigate these issues, we propose DFedSat, a fully decentralized federated learning framework tailored for LEO satellites. DFedSat accelerates the training process by employing two adaptive mechanisms for intra-plane and inter-plane model aggregation, respectively. Furthermore, a self-compensation mechanism is integrated to enhance the robustness of inter-plane ISLs against transmission failure. Additionally, we derive the sublinear convergence rate for the non-convex case of DFedSat. Extensive experimental results demonstrate DFedSat's superiority over other DFL baselines regarding convergence rate, communication efficiency, and resilience to unreliable links.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Redactable Blockchain Solutions for IoT: A Review of Mechanisms and Applications</title>
<link>https://arxiv.org/abs/2407.05948</link>
<guid>https://arxiv.org/abs/2407.05948</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Internet of Things (IoT), redaction, data security, data protection

总结:<br />
本文探讨了区块链技术与物联网（IoT）结合的最新趋势，特别是在处理数据隐私和保护问题上。关键词“可红删区块链”成为焦点，因为其在确保数据安全的同时，满足了法律对敏感信息删除的需求。研究深入分析了现有红删机制在IoT领域的应用，揭示了挑战和机遇，以及如何通过实施红删区块链来解决数据管理中的隐私顾虑。文章展示了实际的IoT案例，展示了这种技术在实践中的潜力和价值。 <div>
arXiv:2407.05948v1 Announce Type: new 
Abstract: The integration of blockchain technology with the Internet of Things (IoT) presents a promising solution to enhance data security, integrity, and trust within IoT ecosystems. However, the immutable nature of blockchain technology conflicts with data redaction requirements mandated by data protection laws. This paper provides a comprehensive review of the current state of redactable blockchains and redaction mechanisms, particularly focusing on their application within IoT contexts. Through an extensive review of existing literature, this paper identifies key challenges and opportunities in implementing redactable blockchains for IoT data management. Various redaction mechanisms are explored, and the paper examines IoT implementations and use cases where redactable blockchains are employed to address data protection concerns.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards Understanding the Bugs in Solidity Compiler</title>
<link>https://arxiv.org/abs/2407.05981</link>
<guid>https://arxiv.org/abs/2407.05981</guid>
<content:encoded><![CDATA[
<div> 关键词：Solidity编译器、bug、特性、测试用例、fuzzers。

总结:<br />
本文针对Solidity编译器的533个已知漏洞进行了深入研究，重点关注了这些bug的症状、根源和触发测试案例。研究发现七个关键见解，揭示了编译器在处理智能合约特定语言和优化过程中存在的挑战。同时，对三种Solidity编译器fuzzer的评估显示，它们在检测漏洞方面的效率较低，主要受限于未能充分考虑引发bug的有趣特性、相关编译标志以及测试或acles。这强调了改进现有工具以提高智能合约安全性的必要性。 <div>
arXiv:2407.05981v1 Announce Type: new 
Abstract: Solidity compiler plays a key role in enabling the development of smart contract applications on Ethereum by governing the syntax of a domain-specific language called Solidity and performing compilation and optimization of Solidity code. The correctness of Solidity compiler is critical in fostering transparency, efficiency, and trust in industries reliant on smart contracts. However, like other software systems, Solidity compiler is prone to bugs, which may produce incorrect bytecodes on blockchain platforms, resulting in severe security concerns. As a domain-specific compiler for smart contracts, Solidity compiler differs from other compilers in many perspectives, posing unique challenges to detect its bugs. To understand the bugs in Solidity compiler and benefit future research, in this paper, we present the first systematic study on 533 Solidity compiler bugs. We carefully examined their characteristics (including symptoms, root causes, and distribution), and their triggering test cases. Our study leads to seven bug-revealing takeaways for Solidity compiler. Moreover, to study the limitations of Solidity compiler fuzzers and bring our findings into practical scenarios, we evaluate three Solidity compiler fuzzers on our constructed benchmark. The results show that these fuzzers are inefficient in detecting Solidity compiler bugs. The inefficiency arises from their failure to consider the interesting bug-inducing features, bug-related compilation flags, and test oracles
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cellular Automata as a Network Topology</title>
<link>https://arxiv.org/abs/2407.05048</link>
<guid>https://arxiv.org/abs/2407.05048</guid>
<content:encoded><![CDATA[
<div> 关键词：cellular automata, network topologies, decentralized networks, load balancing, fault tolerance.

总结:<br />
本文探讨了将细胞自动机应用于网络拓扑建模的潜力，特别是在去中心化网络中。细胞自动机作为一种离散空间和时间的物理系统模型，可以模拟有限量值的物理量。研究旨在利用这种模型改善分布式系统的负载均衡、故障容错能力，以及信息传播的效率和规模扩展。通过细胞自动机，网络结构可能变得更加灵活和高效，为处理复杂通信问题提供新的途径。 <div>
arXiv:2407.05048v1 Announce Type: cross 
Abstract: Cellular automata represent physical systems where both space and time are discrete, and the associated physical quantities assume a limited set of values. While previous research has applied cellular automata in modeling chemical, biological, and physical systems, its potential for modeling topological systems, specifically network topologies, remains underexplored. This paper investigates the use of cellular automata to model decentralized network topologies, which could enhance load balancing, fault tolerance, scalability, and the propagation and dissemination of information in distributed systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Simple Opinion Dynamics for No-Regret Learning</title>
<link>https://arxiv.org/abs/2306.08670</link>
<guid>https://arxiv.org/abs/2306.08670</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent bandit, distributed GOSSIP model, memoryless protocols, consensus, adversarial rewards

总结: 这篇文章主要探讨了分布式GOSSIP模型下的多代理强化学习问题。研究者提出了基于已有意见动态算法的记忆less和时间无关的协议，实现了最优的双重世界行为：在 stationary reward设置中，这些简单协议具有常数累积后悔$R(T)/T = \widetilde{O}(1/T)$，同时能在$\widetilde{O}(\sqrt{n})$轮内达成对最高期望动作的一致。文章揭示了这些协议与零和乘法权重更新过程之间的新联系，从而建立了一般性框架来分析协议的全局性能。此外，这些协议在对抗性奖励环境下也表现出惊人的鲁棒性，即使在时间轮数与$n$的关系不紧密的情况下，也能实现$R(T)/T = \widetilde{O}(1/\sqrt{T})$的子线性后悔。 <div>
arXiv:2306.08670v4 Announce Type: replace 
Abstract: We study a cooperative multi-agent bandit setting in the distributed GOSSIP model: in every round, each of $n$ agents chooses an action from a common set, observes the action's corresponding reward, and subsequently exchanges information with a single randomly chosen neighbor, which may inform its choice in the next round. We introduce and analyze families of memoryless and time-independent protocols for this setting, inspired by opinion dynamics that are well-studied for other algorithmic tasks in the GOSSIP model. For stationary reward settings, we prove for the first time that these simple protocols exhibit best-of-both-worlds behavior, simultaneously obtaining constant cumulative regret scaling like $R(T)/T = \widetilde O(1/T)$, and also reaching consensus on the highest-mean action within $\widetilde O(\sqrt{n})$ rounds. We obtain these results by showing a new connection between the global evolution of these decentralized protocols and a class of zero-sum multiplicative weights update} processes. Using this connection, we establish a general framework for analyzing the population-level regret and other properties of our protocols. Finally, we show our protocols are also surprisingly robust to adversarial rewards, and in this regime we obtain sublinear regret scaling like $R(T)/T = \widetilde O(1/\sqrt{T})$ as long as the number of rounds does not grow too fast as a function of $n$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Kernel Ridge Regression Based on Data-Dependent Random Feature</title>
<link>https://arxiv.org/abs/2405.07791</link>
<guid>https://arxiv.org/abs/2405.07791</guid>
<content:encoded><![CDATA[
<div> 关键词：random feature（随机特征）、decentralized kernel ridge regression（分布式核岭回归）、node consistency（节点一致性）、decision functions（决策函数）、convergence（收敛性）。

总结:<br />该论文提出了一种新的分布式核岭回归算法，采用随机特征处理节点间数据差异。与现有方法相比，它不强制要求不同节点使用相同的随机特征，而是追求决策函数的一致性。这种适应性强的方法允许根据各节点数据自动生成不同的随机特征，从而提高了回归精度，平均提升了25.5%。算法具有良好的收敛性，并在六项真实世界的数据集上得到了验证。 <div>
arXiv:2405.07791v2 Announce Type: replace 
Abstract: Random feature (RF) has been widely used for node consistency in decentralized kernel ridge regression (KRR). Currently, the consistency is guaranteed by imposing constraints on coefficients of features, necessitating that the random features on different nodes are identical. However, in many applications, data on different nodes varies significantly on the number or distribution, which calls for adaptive and data-dependent methods that generate different RFs. To tackle the essential difficulty, we propose a new decentralized KRR algorithm that pursues consensus on decision functions, which allows great flexibility and well adapts data on nodes. The convergence is rigorously given and the effectiveness is numerically verified: by capturing the characteristics of the data on each node, while maintaining the same communication costs as other methods, we achieved an average regression accuracy improvement of 25.5\% across six real-world data sets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Correlations versus noise in the NFT market</title>
<link>https://arxiv.org/abs/2404.15495</link>
<guid>https://arxiv.org/abs/2404.15495</guid>
<content:encoded><![CDATA[
<div> 关键词：non-fungible token (NFT), market dynamics, correlation matrix, Marchenko-Pastur distribution, correlation strength.

总结:<br />
非同质化代币(NFT)市场利用区块链技术崭露头角，本文基于以太坊平台上大量token集合的资本化变化和交易量，研究其市场动态。通过多变量方法分析了集合之间的依赖性，发现NFT市场的相关性较弱，其相关矩阵的特征值谱接近马尔钦科-帕斯图分布，但仍存在一定程度的关联。对比皮尔逊系数和去趋势交叉相关系数构建的关联矩阵显示，NFT市场的全球关联主要源自高频波动。资本化变异性的最小生成树(MST)表现出幂律特性，而交易数量的MST则相对分散，显示出市场的复杂性和动态特性。 <div>
arXiv:2404.15495v2 Announce Type: replace-cross 
Abstract: The non-fungible token (NFT) market emerges as a recent trading innovation leveraging blockchain technology, mirroring the dynamics of the cryptocurrency market. The current study is based on the capitalization changes and transaction volumes across a large number of token collections on the Ethereum platform. In order to deepen the understanding of the market dynamics, the collection-collection dependencies are examined by using the multivariate formalism of detrended correlation coefficient and correlation matrix. It appears that correlation strength is lower here than that observed in previously studied markets. Consequently, the eigenvalue spectra of the correlation matrix more closely follow the Marchenko-Pastur distribution, still, some departures indicating the existence of correlations remain. The comparison of results obtained from the correlation matrix built from the Pearson coefficients and, independently, from the detrended cross-correlation coefficients suggests that the global correlations in the NFT market arise from higher frequency fluctuations. Corresponding minimal spanning trees (MSTs) for capitalization variability exhibit a scale-free character while, for the number of transactions, they are somewhat more decentralized.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ESBMC-Python: A Bounded Model Checker for Python Programs</title>
<link>https://arxiv.org/abs/2407.03472</link>
<guid>https://arxiv.org/abs/2407.03472</guid>
<content:encoded><![CDATA[
<div> 关键词：Python程序、类型注解、抽象语法树、Bounded Model Checking (BMC)、ESBMC-Python。

总结:<br />
本文介绍了一种新的Python程序验证工具，利用类型注解和前端处理，结合了Bounded Model Checking (BMC)技术。该工具首先将输入程序转换为带有类型信息的抽象语法树，随后将表达式和语句转化为中间表示，最后通过与SMT求解器交互，实现对代码的验证。实验结果表明，ESBMC-Python在专门设计的测试套件中表现出有效性，能正确评估成功和失败的测试，并发现Ethereum共识规范中的实际问题。 <div>
arXiv:2407.03472v1 Announce Type: new 
Abstract: This paper introduces a tool for verifying Python programs, which, using type annotation and front-end processing, can harness the capabilities of a bounded model-checking (BMC) pipeline. It transforms an input program into an abstract syntax tree to infer and add type information. Then, it translates Python expressions and statements into an intermediate representation. Finally, it converts this description into formulae evaluated with satisfiability modulo theories (SMT) solvers. The proposed approach was realized with the efficient SMT-based bounded model checker (ESBMC), which resulted in a tool called ESBMC-Python, the first BMC-based Python-code verifier. Experimental results, with a test suite specifically developed for this purpose, showed its effectiveness, where successful and failed tests were correctly evaluated. Moreover, it found a real problem in the Ethereum Consensus Specification.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Scalable Zero-Knowledge Proofs for Verifying Cryptographic Hashing in Blockchain Applications</title>
<link>https://arxiv.org/abs/2407.03511</link>
<guid>https://arxiv.org/abs/2407.03511</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明（ZKP）、SHA-256、Plonky2框架、PLONK协议、FRI承诺方案。

总结:<br />
本文提出了一种使用零知识证明（ZKP）验证SHA-256算法计算完整性的方法，基于Plonky2框架和FRI承诺方案。研究专注于提高效率和可扩展性，对随机数据和NEAR区块链的真实数据块进行了实验，证明了其在不同数据规模和类型下的性能稳定。生成的电路和证明保持在可管理的大小，适用于大型交易的现实世界数据块。该方法有助于构建安全可信的区块链系统，同时保证计算的保密性。未来还需研究其在其他加密算法和复杂场景的应用及性能。 <div>
arXiv:2407.03511v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKPs) have emerged as a promising solution to address the scalability challenges in modern blockchain systems. This study proposes a methodology for generating and verifying ZKPs to ensure the computational integrity of cryptographic hashing, specifically focusing on the SHA-256 algorithm. By leveraging the Plonky2 framework, which implements the PLONK protocol with FRI commitment scheme, we demonstrate the efficiency and scalability of our approach for both random data and real data blocks from the NEAR blockchain. The experimental results show consistent performance across different data sizes and types, with the time required for proof generation and verification remaining within acceptable limits. The generated circuits and proofs maintain manageable sizes, even for real-world data blocks with a large number of transactions. The proposed methodology contributes to the development of secure and trustworthy blockchain systems, where the integrity of computations can be verified without revealing the underlying data. Further research is needed to assess the applicability of the approach to other cryptographic primitives and to evaluate its performance in more complex real-world scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PEDDiM: Formal Definitions and Provably Secure Designs for Pre-Execution DoS Defense in Mempools</title>
<link>https://arxiv.org/abs/2407.03543</link>
<guid>https://arxiv.org/abs/2407.03543</guid>
<content:encoded><![CDATA[
<div> 关键词：mempool, secure blockchain, asymmetric eviction DoS attacks, secure transaction admission algorithm, \textsc{saferAd-PR}

总结:<br />
这篇论文关注区块链系统中的关键组件——mempool，它在处理待执行交易时面临asymmetric eviction DoS攻击的风险。作者提出了一种新型的防御策略，即\textsc{saferAd-PR}安全交易接纳算法。该算法设定了执行 eviction DoS 攻击的最低成本，确保了mempool的安全性。通过实际交易回放测试，\textsc{saferAd-PR}表现出低延迟和对各种攻击的强大防护能力，证明了其在保障区块链mempool安全方面的有效性与稳定性。 <div>
arXiv:2407.03543v1 Announce Type: new 
Abstract: The mempool plays a crucial role in blockchain systems as a buffer zone for pending transactions before they are executed and included in a block. However, existing works primarily focus on mitigating defenses against already identified real-world attacks. This paper introduces secure blockchain-mempool designs capable of defending against any form of asymmetric eviction DoS attacks. We establish formal security definitions for mempools under the eviction-based attack vector. Our proposed secure transaction admission algorithm, named \textsc{saferAd-PR}, ensures eviction-security by providing a provable lower bound on the cost of executing eviction DoS attacks. Through evaluation with real transaction trace replays, \textsc{saferAd-PR} demonstrates negligible latency and significantly high lower bounds against any eviction attack, highlighting its effectiveness and robustness in securing blockchain mempools.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SRAS: Self-governed Remote Attestation Scheme for Multi-party Collaboration</title>
<link>https://arxiv.org/abs/2407.03745</link>
<guid>https://arxiv.org/abs/2407.03745</guid>
<content:encoded><![CDATA[
<div> 关键词：Trusted Execution Environments (TEEs), Intel Software Guard Extensions (SGX), Remote Attestation, Multi-party Cloud Computing, Decentralized Verification.

总结:<br />本文提出了一种名为SRAS的开放自我治理远程验证方案，针对多党云计算中如何选择可信赖的第三方验证TEE（如Intel SGX）并保护数据隐私的问题。SRAS设计了一个Relying Party Enclave，形成虚拟可验证网络，能在本地代表其他参与者进行验证，无需泄露敏感信息。该方案实现了去中心化的统一可信验证平台，为云用户和开发者提供了开源原型，促进了相关技术的采纳。 <div>
arXiv:2407.03745v1 Announce Type: new 
Abstract: Trusted Execution Environments (TEEs), such as Intel Software Guard Extensions (SGX), ensure the confidentiality and integrity of user applications when using cloud computing resources. However, in the multi-party cloud computing scenario, how to select a Relying Party to verify the TEE of each party and avoid leaking sensitive data to each other remains an open question. In this paper, we propose SRAS, an open self-governed remote attestation scheme with attestation and verification functions for verifying the trustworthiness of TEEs and computing assets, achieving decentralized unified trusted attestation and verification platform for multi-party cloud users. In SRAS, we design a Relying Party enclave, which can form a virtual verifiable network, capable of local verification on behalf of other participants relying parties without leaking sensitive data to others. We provide an open-source prototype implementation of SRAS to facilitate the adoption of this technology by cloud users or developers.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>GriDB: Scaling Blockchain Database via Sharding and Off-Chain Cross-Shard Mechanism</title>
<link>https://arxiv.org/abs/2407.03750</link>
<guid>https://arxiv.org/abs/2407.03750</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain数据库、Scalability、Sharding、Cross-shard机制、Off-chain mechanism

总结:<br />
区块链数据库因其潜力而备受关注，但传统的非可扩展区块链限制了其性能。为解决这一问题，本文提出了一种名为GriDB的新型可扩展区块链数据库，通过设计一种新颖的离链跨 shard 机制，以提高跨 shard 数据服务的效率。GriDB借鉴了支付领域中离链处理的概念，选择不同 shard 的少量节点处理大规模数据交换，并通过生成简洁证明来抵抗拜占庭环境，共识机制只负责低成本的验证。文章还创新性地引入了几个新的认证数据结构（ADS），以满足数据库服务的额外要求，如完整性、正确性、新鲜性和可用性。此外，文中还探讨了负载均衡在区块链数据库中的重要性，并设计了一种离线且实时的方法，兼顾效率和可用性。总的来说，GriDB通过优化跨 shard 交互，为区块链数据库的可扩展性提供了新的解决方案。 <div>
arXiv:2407.03750v1 Announce Type: new 
Abstract: Blockchain databases have attracted widespread attention but suffer from poor scalability due to underlying non-scalable blockchains. While blockchain sharding is necessary for a scalable blockchain database, it poses a new challenge named on-chain cross-shard database services. Each cross-shard database service (e.g., cross-shard queries or inter-shard load balancing) involves massive cross-shard data exchanges, while the existing cross-shard mechanisms need to process each cross-shard data exchange via the consensus of all nodes in the related shards (i.e., on-chain) to resist a Byzantine environment of blockchain, which eliminates sharding benefits. To tackle the challenge, this paper presents GriDB, the first scalable blockchain database, by designing a novel off-chain cross-shard mechanism for efficient cross-shard database services. Borrowing the idea of off-chain payments, GriDB delegates massive cross-shard data exchange to a few nodes, each of which is randomly picked from a different shard. Considering the Byzantine environment, the untrusted delegates cooperate to generate succinct proof for cross-shard data exchanges, while the consensus is only responsible for the low-cost proof verification. However, different from payments, the database services' verification has more requirements (e.g., completeness, correctness, freshness, and availability); thus, we introduce several new authenticated data structures (ADS). Particularly, we utilize consensus to extend the threat model and reduce the complexity of traditional accumulator-based ADS for verifiable cross-shard queries with a rich set of relational operators. Moreover, we study the necessity of inter-shard load balancing for a scalable blockchain database and design an off-chain and live approach for both efficiency and availability during balancing.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Real-time Cyberattack Detection with Collaborative Learning for Blockchain Networks</title>
<link>https://arxiv.org/abs/2407.04011</link>
<guid>https://arxiv.org/abs/2407.04011</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链网络、攻击检测、协作学习、隐私保护、准确性。

总结:<br />
这篇文章关注区块链网络的安全问题，研究了常见的攻击手段如交易洪水和暴力破解。作者构建了一个包含正常和攻击流量数据的实验室区块链网络，用于生成实际攻击数据，训练和测试攻击检测模型。他们提出了一种实时的协作学习模型，允许网络中的节点在不泄露私有数据的情况下共享学习知识，从而提高整个系统的性能。实验结果显示，该模型能以高达97%的准确率检测区块链网络中的攻击，强调了隐私保护和高效检测的重要性。 <div>
arXiv:2407.04011v1 Announce Type: new 
Abstract: With the ever-increasing popularity of blockchain applications, securing blockchain networks plays a critical role in these cyber systems. In this paper, we first study cyberattacks (e.g., flooding of transactions, brute pass) in blockchain networks and then propose an efficient collaborative cyberattack detection model to protect blockchain networks. Specifically, we deploy a blockchain network in our laboratory to build a new dataset including both normal and attack traffic data. The main aim of this dataset is to generate actual attack data from different nodes in the blockchain network that can be used to train and test blockchain attack detection models. We then propose a real-time collaborative learning model that enables nodes in the network to share learning knowledge without disclosing their private data, thereby significantly enhancing system performance for the whole network. The extensive simulation and real-time experimental results show that our proposed detection model can detect attacks in the blockchain network with an accuracy of up to 97%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Pathfinder: Exploring Path Diversity for Assessing Internet Censorship Inconsistency</title>
<link>https://arxiv.org/abs/2407.04213</link>
<guid>https://arxiv.org/abs/2407.04213</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet censorship, ISP level, Routing paths, Incomplete/Flawed implementation, Decentralized censorship, Hosting platforms, Peering relationships, Inconsistent censorship.

总结:<br />
本文研究了互联网审查的多样性，关注国内ISP级别的部署差异。通过端到端测量框架，作者发现不同路由路径导致的审查不一致普遍存在，揭示了集中式审查的不完整和缺陷，以及分布式审查的广泛存在。此外，研究还指出，不同的托管平台由于与国内ISP的互联关系不同，会导致审查活动的不一致性。案例分析深入探讨了导致审查不一致的配置和原因。 <div>
arXiv:2407.04213v1 Announce Type: new 
Abstract: Internet censorship is typically enforced by authorities to achieve information control for a certain group of Internet users. So far existing censorship studies have primarily focused on country-level characterization because (1) in many cases, censorship is enabled by governments with nationwide policies and (2) it is usually hard to control how the probing packets are routed to trigger censorship in different networks inside a country. However, the deployment and implementation of censorship could be highly diverse at the ISP level. In this paper, we investigate Internet censorship from a different perspective by scrutinizing the diverse censorship deployment inside a country. Specifically, by leveraging an end-to-end measurement framework, we deploy multiple geo-distributed back-end control servers to explore various paths from one single vantage point. The generated traffic with the same domain but different control servers' IPs could be forced to traverse different transit networks, thereby being examined by different censorship devices if present. Through our large-scale experiments and in-depth investigation, we reveal that the diversity of Internet censorship caused by different routing paths inside a country is prevalent, implying that (1) the implementations of centralized censorship are commonly incomplete or flawed and (2) decentralized censorship is also common. Moreover, we identify that different hosting platforms also result in inconsistent censorship activities due to different peering relationships with the ISPs in a country. Finally, we present extensive case studies in detail to illustrate the configurations that lead to censorship inconsistency and explore the causes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Effective Targeted Testing of Smart Contracts</title>
<link>https://arxiv.org/abs/2407.04250</link>
<guid>https://arxiv.org/abs/2407.04250</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, symbolic execution, test data generation, targeted execution, CFG+

总结:
智能合约是一种部署在区块链网络上的自动执行代码，最初由以太坊在2014年提出。它们应用广泛，但固有的不可变性导致一旦出现错误无法修复，造成经济损失。文章关注测试数据生成与测试充分性的差距，提出了Griffin框架，采用目标导向的符号执行技术生成测试数据。它适用于多种场景，如验证静态分析警告和满足安全条件的反例。作者还改进了Solidity智能合约的控制流图（CFG+），并讨论了自定义启发式在合理时间内探索程序空间的方法。实验结果显示，Griffin能有效识别所需测试数据。 <div>
arXiv:2407.04250v1 Announce Type: new 
Abstract: Smart contracts are autonomous and immutable pieces of code that are deployed on blockchain networks and run by miners. They were first introduced by Ethereum in 2014 and have since been used for various applications such as security tokens, voting, gambling, non-fungible tokens, self-sovereign identities, stock taking, decentralized finances, decentralized exchanges, and atomic swaps. Since smart contracts are immutable, their bugs cannot be fixed, which may lead to significant monetary losses. While many researchers have focused on testing smart contracts, our recent work has highlighted a gap between test adequacy and test data generation, despite numerous efforts in both fields. Our framework, Griffin, tackles this deficiency by employing a targeted symbolic execution technique for generating test data. This tool can be used in diverse applications, such as killing the survived mutants in mutation testing, validating static analysis alarms, creating counter-examples for safety conditions, and reaching manually selected lines of code. This paper discusses how smart contracts differ from legacy software in targeted symbolic execution and how these differences can affect the tool structure, leading us to propose an enhanced version of the control-flow graph for Solidity smart contracts called CFG+. We also discuss how Griffin can utilize custom heuristics to explore the program space and find the test data that reaches a target line while considering a safety condition in a reasonable execution time. We conducted experiments involving an extensive set of smart contracts, target lines, and safety conditions based on real-world faults and test suites from related tools. The results of our evaluation demonstrate that Griffin can effectively identify the required test data within a reasonable timeframe.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Temporal fingerprints: Identity matching across fully encrypted domain</title>
<link>https://arxiv.org/abs/2407.04350</link>
<guid>https://arxiv.org/abs/2407.04350</guid>
<content:encoded><![CDATA[
<div> 关键词：temporal data, inter-event times, identity matching, Ethereum Blockchain, privacy preservation

总结:<br />
这篇文章探讨了技术进步如何促使人们在不同领域使用多个人格身份。研究发现，个体的时间行为，即事件之间的间隔分布，构成了独特的“时间指纹”，可用于跨域身份关联，即使在加密的数字交易平台（如以太坊区块链）上也能实现高精度匹配。这挑战了用户的隐私保护，因为仅仅知道一个人何时活跃就可能揭示其真实身份，即使缺乏交谈内容和联系人信息。因此，了解和保护这种时间数据的隐私成为当今数字时代的关键议题。 <div>
arXiv:2407.04350v1 Announce Type: new 
Abstract: Technological advancements have significantly transformed communication patterns, introducing a diverse array of online platforms, thereby prompting individuals to use multiple profiles for different domains and objectives. Enhancing the understanding of cross domain identity matching capabilities is essential, not only for practical applications such as commercial strategies and cybersecurity measures, but also for theoretical insights into the privacy implications of data disclosure. In this study, we demonstrate that individual temporal data, in the form of inter-event times distribution, constitutes an individual temporal fingerprint, allowing for matching profiles across different domains back to their associated real-world entity. We evaluate our methodology on encrypted digital trading platforms within the Ethereum Blockchain and present impressing results in matching identities across these privacy-preserving domains, while outperforming previously suggested models. Our findings indicate that simply knowing when an individual is active, even if information about who they talk to and what they discuss is lacking, poses risks to users' privacy, highlighting the inherent challenges in preserving privacy in today's digital landscape.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-based PKI within a Corporate Organization: Advantages and Challenges</title>
<link>https://arxiv.org/abs/2407.04536</link>
<guid>https://arxiv.org/abs/2407.04536</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Public Key Infrastructure (PKI), decentralized, security, transparency

总结: <br />
本研究探讨了区块链技术在组织内部作为公共密钥基础设施（PKI）的潜在应用，与传统PKI系统进行了比较。文章关注点在于评估区块链技术的可行性，特别是在增强安全性和透明度方面的优势，如去中心化信任、防篡改证书管理和行为监控。同时，它还考虑了现行法律框架，如网络安全法(CRA)和NIS-2指令对这种新型PKI的影响。结论显示，区块链PKI在多个方面具有优势，尽管存在一些挑战，但仍显示出广阔的发展前景。 <div>
arXiv:2407.04536v1 Announce Type: new 
Abstract: This research investigates the potential use of a blockchain-based Public Key Infrastructure (PKI) within an organization and compares it to conventional PKI systems. The goal is to assess the advantages and disadvantages of both approaches in order to determine the feasibility of employing blockchain technology for a decentralized PKI. The study will also evaluate the impact of current legal frameworks, such as the Cyber Resilience Act (CRA) and NIS-2 Directive. The study will examine various implementations of blockchain PKIs based on factors such as security, performance, and platform. The results indicate that blockchain-based PKIs can overcome the limitations of conventional PKIs by decentralizing the trust anchor, providing greater security. Blockchain technology allows for the immutable and transparent management of certificates, making tampering significantly more challenging. Additionally, blockchain-based PKIs offer enhanced mechanisms for identifying and addressing certificate misconduct.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Joint Fronthaul Load Balancing and Computation Resource Allocation in Cell-Free User-Centric Massive MIMO Networks</title>
<link>https://arxiv.org/abs/2310.14911</link>
<guid>https://arxiv.org/abs/2310.14911</guid>
<content:encoded><![CDATA[
<div> 关键词：cell-free massive MIMO, open radio access network, user-centric clusters, fronthaul topology, computation resource allocation

总结:<br />
本文研究了一种可扩展的细胞自由大规模多输入多输出网络架构，该架构采用开放无线接入网络，包括用户设备(UEs)、无线单元(RUs)和分布式处理单元(DUs)。与现有文献主要关注无限制前传通信和计算能力下的用户速率不同，本文着重考虑了前传拓扑、有限容量和DU的计算约束。新提出的优化框架旨在解决前传负载平衡和计算资源分配问题。研究发现，RU的模数转换量化位数存在最优值，这影响系统性能。通过数值结果，文章揭示了这一优化问题的关键影响因素。 <div>
arXiv:2310.14911v2 Announce Type: replace 
Abstract: We consider scalable cell-free massive multiple-input multiple-output networks under an open radio access network paradigm comprising user equipments (UEs), radio units (RUs), and decentralized processing units (DUs). UEs are served by dynamically allocated user-centric clusters of RUs. The corresponding cluster processors (implementing the physical layer for each user) are hosted by the DUs as software-defined virtual network functions. Unlike the current literature, mainly focused on the characterization of the user rates under unrestricted fronthaul communication and computation, in this work we explicitly take into account the fronthaul topology, the limited fronthaul communication capacity, and computation constraints at the DUs. In particular, we systematically address the new problem of joint fronthaul load balancing and allocation of the computation resource. As a consequence of our new optimization framework, we present representative numerical results highlighting the existence of an optimal number of quantization bits in the analog-to-digital conversion at the RUs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-empowered Federated Learning: Benefits, Challenges, and Solutions</title>
<link>https://arxiv.org/abs/2403.00873</link>
<guid>https://arxiv.org/abs/2403.00873</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Blockchain, Privacy, Security, Scalability.

总结:<br />Federated Learning (FL)是一种分布式机器学习方法，强调用户数据隐私保护。然而，它面临单点故障、激励不足和安全性问题。为解决这些问题，研究者将区块链技术与FL结合（Blockchain-empowered FL, BC-FL），以增强系统安全、公平性和扩展性。本文详尽回顾了BC-FL的最新研究，探讨了区块链如何融入FL，其带来的资源需求、优势与挑战，以及现有的解决方案。同时，对未来研究方向提出了见解。总的来说，BC-FL旨在优化FL系统的性能和隐私保护，但需要平衡网络、计算和存储资源的使用。 <div>
arXiv:2403.00873v2 Announce Type: replace 
Abstract: Federated learning (FL) is a distributed machine learning approach that protects user data privacy by training models locally on clients and aggregating them on a parameter server. While effective at preserving privacy, FL systems face limitations such as single points of failure, lack of incentives, and inadequate security. To address these challenges, blockchain technology is integrated into FL systems to provide stronger security, fairness, and scalability. However, blockchain-empowered FL (BC-FL) systems introduce additional demands on network, computing, and storage resources. This survey provides a comprehensive review of recent research on BC-FL systems, analyzing the benefits and challenges associated with blockchain integration. We explore why blockchain is applicable to FL, how it can be implemented, and the challenges and existing solutions for its integration. Additionally, we offer insights on future research directions for the BC-FL system.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection</title>
<link>https://arxiv.org/abs/2406.02318</link>
<guid>https://arxiv.org/abs/2406.02318</guid>
<content:encoded><![CDATA[
<div> 关键词：时间序列数据、联邦学习、异常检测、预训练语言模型、参数效率。

总结:<br />
本文提出了一种名为PeFAD的参数高效的联邦异常检测框架，旨在解决去中心化时间序列数据与集中式异常检测算法之间的差距。PeFAD利用预训练语言模型（PLM）作为客户端本地模型的基础，利用其跨模态知识转移能力。通过设计参数高效的联邦训练模块，降低通信成本和本地模型适应性，仅需微调少量参数并上传至服务器。文章还提出一种异常驱动的掩码选择策略来缓解训练中忽视异常的影响，并通过知识蒸馏处理合成的隐私保护数据集，解决客户端间的数据异质性问题。在四个真实数据集的实验中，PeFAD比现有最先进的方法性能提升高达28.74%。 <div>
arXiv:2406.02318v2 Announce Type: replace 
Abstract: With the proliferation of mobile sensing techniques, huge amounts of time series data are generated and accumulated in various domains, fueling plenty of real-world applications. In this setting, time series anomaly detection is practically important. It endeavors to identify deviant samples from the normal sample distribution in time series. Existing approaches generally assume that all the time series is available at a central location. However, we are witnessing the decentralized collection of time series due to the deployment of various edge devices. To bridge the gap between the decentralized time series data and the centralized anomaly detection algorithms, we propose a Parameter-efficient Federated Anomaly Detection framework named PeFAD with the increasing privacy concerns. PeFAD for the first time employs the pre-trained language model (PLM) as the body of the client's local model, which can benefit from its cross-modality knowledge transfer capability. To reduce the communication overhead and local model adaptation cost, we propose a parameter-efficient federated training module such that clients only need to fine-tune small-scale parameters and transmit them to the server for update. PeFAD utilizes a novel anomaly-driven mask selection strategy to mitigate the impact of neglected anomalies during training. A knowledge distillation operation on a synthetic privacy-preserving dataset that is shared by all the clients is also proposed to address the data heterogeneity issue across clients. We conduct extensive evaluations on four real datasets, where PeFAD outperforms existing state-of-the-art baselines by up to 28.74%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health</title>
<link>https://arxiv.org/abs/2406.07114</link>
<guid>https://arxiv.org/abs/2406.07114</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse, Healthcare, Technology, Machine Learning, Privacy

总结:<br />
本文探讨了Metaverse在医疗领域的潜力和应用。首先，介绍了Metaverse的基本概念和技术，特别是机器学习在其中的作用，指出其能提升医疗数据分析的深度。文章分析了Metaverse对医疗保健的积极影响，如改善患者护理、教育和研究。其次，讨论了区块链等新兴技术在未来医疗服务中的前景，以及如何处理隐私问题。总的来说，这篇研究为理解Metaverse在医疗行业的革命性作用提供了见解，强调了其可能带来的变革和挑战。 <div>
arXiv:2406.07114v2 Announce Type: replace 
Abstract: The concept of Metaverse has attracted a lot of attention in various fields and one of its important applications is health and treatment. The Metaverse has enormous potential to transform healthcare by changing patient care, medical education, and the way teaching/learning and research are done. The purpose of this research is to provide an introduction to the basic concepts and fundamental technologies of the Metaverse. This paper examines the pros and cons of the Metaverse in healthcare context and analyzes its potential from the technology and AI perspective. In particular, the role of machine learning methods is discussed; We will explain how machine learning algorithms can be applied to the Metaverse generated data to gain better insights in healthcare applications. Additionally, we examine the future visions of the Metaverse in health delivery, by examining emerging technologies such as blockchain and also addressing privacy concerns. The findings of this study contribute to a deeper understanding of the applications of Metaverse in healthcare and its potential to revolutionize the delivery of medical services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data</title>
<link>https://arxiv.org/abs/2406.10563</link>
<guid>https://arxiv.org/abs/2406.10563</guid>
<content:encoded><![CDATA[
<div> 关键词：healthcare, decentralized facilities, machine learning, data privacy, model confidentiality

总结:<br />文章探讨了在医疗保健领域，尤其是去中心化设施下，机器学习面临的两大挑战：数据隐私保护和模型异质性协作训练。为解决这些问题，作者提出了"Abstention-Aware Federated Voting (AAFV)"框架。AAFV结合了 abstention-aware voting 机制和差分隐私技术，允许本地模型在保持机密性的同时协作训练。通过阈值投票方法，筛选高置信度预测，提升学习效率并保护模型知识产权。实验结果验证了AAFV在糖尿病和院内患者死亡率预测任务中的有效性与隐私保护性能。 <div>
arXiv:2406.10563v2 Announce Type: replace 
Abstract: In the realm of healthcare where decentralized facilities are prevalent, machine learning faces two major challenges concerning the protection of data and models. The data-level challenge concerns the data privacy leakage when centralizing data with sensitive personal information. While the model-level challenge arises from the heterogeneity of local models, which need to be collaboratively trained while ensuring their confidentiality to address intellectual property concerns. To tackle these challenges, we propose a new framework termed Abstention-Aware Federated Voting (AAFV) that can collaboratively and confidentially train heterogeneous local models while simultaneously protecting the data privacy. This is achieved by integrating a novel abstention-aware voting mechanism and a differential privacy mechanism onto local models' predictions. In particular, the proposed abstention-aware voting mechanism exploits a threshold-based abstention method to select high-confidence votes from heterogeneous local models, which not only enhances the learning utility but also protects model confidentiality. Furthermore, we implement AAFV on two practical prediction tasks of diabetes and in-hospital patient mortality. The experiments demonstrate the effectiveness and confidentiality of AAFV in testing accuracy and privacy protection.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Learning Decentralized Linear Quadratic Regulators with $\sqrt{T}$ Regret</title>
<link>https://arxiv.org/abs/2210.08886</link>
<guid>https://arxiv.org/abs/2210.08886</guid>
<content:encoded><![CDATA[
<div> 关键词：online learning, decentralized LQR, system model, unknown, regret

总结:<br />
本文提出了一种在线学习算法，针对未知系统模型和单轨迹数据的动态调整，设计适应性的去中心化线性二次控制器。该算法利用了干扰反馈表示状态反馈控制器，结合在线凸优化和延迟反馈。研究结果表明，当系统稳定或已知稳定控制器时，算法在部分嵌套信息模式下的期望 regret 与时间步长 $T$ 成 $\sqrt{T}$ 规模增长。对于更普遍的信息模式，最优控制器未知，算法的 regret 相对于线性次优控制器。实验验证了理论分析。这种自适应控制策略在不断变化的环境中展示了其有效性。 <div>
arXiv:2210.08886v4 Announce Type: replace-cross 
Abstract: We propose an online learning algorithm that adaptively designs a decentralized linear quadratic regulator when the system model is unknown a priori and new data samples from a single system trajectory become progressively available. The algorithm uses a disturbance-feedback representation of state-feedback controllers coupled with online convex optimization with memory and delayed feedback. Under the assumption that the system is stable or given a known stabilizing controller, we show that our controller enjoys an expected regret that scales as $\sqrt{T}$ with the time horizon $T$ for the case of partially nested information pattern. For more general information patterns, the optimal controller is unknown even if the system model is known. In this case, the regret of our controller is shown with respect to a linear sub-optimal controller. We validate our theoretical findings using numerical experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Accelerating Distributed Optimization: A Primal-Dual Perspective on Local Steps</title>
<link>https://arxiv.org/abs/2407.02689</link>
<guid>https://arxiv.org/abs/2407.02689</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式机器学习、通信复杂性、Primal-Dual方法、Accelerated GA-MSGD、Catalyst框架。

总结:<br />
本文探讨了分布式机器学习中高效训练的问题，特别是处理不同数据分布的多代理场景。作者提出了一种基本的Primal-Dual方法，即Accelerated Gradient Ascent Multiple Stochastic Gradient Descent (GA-MSGD)，它在处理拉格朗日函数时自然地融入了局部更新，无需跨代理通信。对于强凸目标，GA-MSGD即使在仅线性依赖于对偶变量的情况下也能实现通信轮次的线性收敛。这得益于对偶变量被限制在耦合矩阵的张成空间，使得对偶问题变得强烈凸。通过与Catalyst框架结合，该方法在各种设置下实现了近乎最优的通信复杂度，无需大批量处理。在随机分散问题中，它的性能接近确定性情况，优于现有算法。 <div>
arXiv:2407.02689v1 Announce Type: new 
Abstract: In distributed machine learning, efficient training across multiple agents with different data distributions poses significant challenges. Even with a centralized coordinator, current algorithms that achieve optimal communication complexity typically require either large minibatches or compromise on gradient complexity. In this work, we tackle both centralized and decentralized settings across strongly convex, convex, and nonconvex objectives. We first demonstrate that a basic primal-dual method, (Accelerated) Gradient Ascent Multiple Stochastic Gradient Descent (GA-MSGD), applied to the Lagrangian of distributed optimization inherently incorporates local updates, because the inner loops of running Stochastic Gradient Descent on the primal variable require no inter-agent communication. Notably, for strongly convex objectives, we show (Accelerated) GA-MSGD achieves linear convergence in communication rounds despite the Lagrangian being only linear in the dual variables. This is due to a unique structural property where the dual variable is confined to the span of the coupling matrix, rendering the dual problem strongly concave. When integrated with the Catalyst framework, our approach achieves nearly optimal communication complexity across various settings without the need for minibatches. Moreover, in stochastic decentralized problems, it attains communication complexities comparable to those in deterministic settings, improving over existing algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Balancing Patient Privacy and Health Data Security: The Role of Compliance in Protected Health Information (PHI) Sharing</title>
<link>https://arxiv.org/abs/2407.02766</link>
<guid>https://arxiv.org/abs/2407.02766</guid>
<content:encoded><![CDATA[
<div> 关键词：Protected Health Information (PHI)，Blockchain technology，Smart contracts，Patient consent management，HIPAA。

总结:<br />
本文探讨了区块链技术在保护医疗健康信息（PHI）方面的潜力。PHI的共享对于提升医疗服务质量和协调性至关重要，但必须遵循严格的隐私和安全政策，如HIPAA。作者提出了一种结合智能合约的区块链系统，旨在自动化部分知情同意流程，确保PHI的访问和分享符合患者意愿及法律要求，从而提高合规性和数据安全性。这一创新有助于实现高效、安全的医疗信息管理。 <div>
arXiv:2407.02766v1 Announce Type: new 
Abstract: Protected Health Information (PHI) sharing significantly enhances patient care quality and coordination, contributing to more accurate diagnoses, efficient treatment plans, and a comprehensive understanding of patient history. Compliance with strict privacy and security policies, such as those required by laws like HIPAA, is critical to protect PHI. Blockchain technology, which offers a decentralized and tamper-evident ledger system, hold promise in policy compliance. This system ensures the authenticity and integrity of PHI while facilitating patient consent management. In this work, we propose a blockchain technology that integrates smart contracts to partially automate consent-related processes and ensuring that PHI access and sharing follow patient preferences and legal requirements.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Hybrid Reactive Routing Protocol for Decentralized UAV Networks</title>
<link>https://arxiv.org/abs/2407.02929</link>
<guid>https://arxiv.org/abs/2407.02929</guid>
<content:encoded><![CDATA[
<div> 关键词：UAV网络、低SWaP、FW-UAVs、多跳通信、动态路由、管道机制。

总结:<br />
本文主要探讨了低SWaP和FW-UAVs构成的无线网络中，由于高机动性、快速变化的拓扑和频繁的路由中断所面临的挑战。为解决这些问题，作者提出了一种混合型的、基于需求的路由协议。该协议通过动态监控选定路线（称为“管道”）并提前切换到备用路线，以维持高服务质量的多跳通信。实验结果表明，与现有方案相比，这种管道机制能够提高吞吐量，减少路由发现次数、控制开销和流量中断，即使在高负载、密集节点和快速移动条件下也能保持优势。尽管对网络拓扑信息依赖有限，且算法复杂度较低，但作者的提议在不同网络和流量设置下仍表现出优于主动优化的链路状态路由的性能。同时，文中还对比了反应式和主动式路由策略的相对优劣。 <div>
arXiv:2407.02929v1 Announce Type: new 
Abstract: Wireless networks consisting of low SWaP, FW-UAVs are used in many applications, such as monitoring, search and surveillance of inaccessible areas. A decentralized and autonomous approach ensures robustness to failures; the UAVs explore and sense within the area and forward their information, in a multihop manner, to nearby aerial gateway nodes. However, the unpredictable nature of the events, relatively high speed of UAVs, and dynamic UAV trajectories cause the network topology to change significantly over time, resulting in frequent route breaks. A holistic routing approach is needed to support multiple traffic flows in these networks to provide mobility- and congestion-aware, high-quality routes when needed, with low control and computational overheads, using the information collected in a distributed manner. Existing routing schemes do not address all the mentioned issues.
  We present a hybrid reactive routing protocol for decentralized UAV networks. Our scheme searches routes on-demand, monitors a region around the selected route (the pipe), and proactively switches to an alternative route before the current route's quality degrades below a threshold. We empirically evaluate the impact of pipe width and node density on our ability to find alternate high-quality routes within the pipe and the overhead required to maintain the pipe. Compared to existing reactive routing schemes, our approach achieves higher throughput and reduces the number of route discoveries, overhead, and resulting flow interruptions at different traffic loads, node densities and speeds. Despite having limited network topology information, and low overhead and route computation complexity, our proposed scheme achieves superior throughput to proactive optimized link state routing scheme at different network and traffic settings. We also evaluate the relative performance of reactive and proactive routing schemes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Zero-X: A Blockchain-Enabled Open-Set Federated Learning Framework for Zero-Day Attack Detection in IoV</title>
<link>https://arxiv.org/abs/2407.02969</link>
<guid>https://arxiv.org/abs/2407.02969</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Vehicles (IoV), 5G/6G networks, zero-day attacks, Open-Set Recognition (OSR), federated learning (FL)

总结:<br />该论文关注互联网车辆（IoV）的安全问题，随着5G和即将来临的6G网络发展，网络安全威胁加剧，尤其是零日攻击。为此，作者提出Zero-X框架，结合深度神经网络与开放集识别（OSR），实现对未知漏洞的高效检测。创新之处在于利用区块链技术支持隐私保护的联邦学习，让汽车自主系统（CAVs）和安全运营中心（SOCs）在保护数据隐私的同时协作学习。实验结果表明，Zero-X框架在两个网络流量数据集上表现优秀，优于现有解决方案，具有高检测率和低误报率。 <div>
arXiv:2407.02969v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV) is a crucial technology for Intelligent Transportation Systems (ITS) that integrates vehicles with the Internet and other entities. The emergence of 5G and the forthcoming 6G networks presents an enormous potential to transform the IoV by enabling ultra-reliable, low-latency, and high-bandwidth communications. Nevertheless, as connectivity expands, cybersecurity threats have become a significant concern. The issue has been further exacerbated by the rising number of zero-day (0-day) attacks, which can exploit unknown vulnerabilities and bypass existing Intrusion Detection Systems (IDSs). In this paper, we propose Zero-X, an innovative security framework that effectively detects both 0-day and N-day attacks. The framework achieves this by combining deep neural networks with Open-Set Recognition (OSR). Our approach introduces a novel scheme that uses blockchain technology to facilitate trusted and decentralized federated learning (FL) of the ZeroX framework. This scheme also prioritizes privacy preservation, enabling both CAVs and Security Operation Centers (SOCs) to contribute their unique knowledge while protecting the privacy of their sensitive data. To the best of our knowledge, this is the first work to leverage OSR in combination with privacy-preserving FL to identify both 0-day and N-day attacks in the realm of IoV. The in-depth experiments on two recent network traffic datasets show that the proposed framework achieved a high detection rate while minimizing the false positive rate. Comparison with related work showed that the Zero-X framework outperforms existing solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Ultra-Lightweight Collaborative Mapping for Robot Swarms</title>
<link>https://arxiv.org/abs/2407.03136</link>
<guid>https://arxiv.org/abs/2407.03136</guid>
<content:encoded><![CDATA[
<div> 关键词：collaborative SLAM, lightweight, swarm robotics, onboard sensing, low-cost hardware

总结: 这篇文章介绍了一种创新的分布式、轻量级协作SLAM方法，旨在解决小规模和低成本机器人在自主定位与建图（SLAM）方面的挑战。该方法适用于各种机器人，包括微型昆虫尺寸设备，支持大规模群体协作，能有效协调数百个节点。实验表明，即使在仅重46克的厘米级无人机上实现，其性能接近高端解决方案，同时成本、内存和计算需求降低两个数量级。创新点包括：无基础设施的协作建图、优化的无线通信以支持大量节点以及分布式协调策略，降低延迟并提高精度。 <div>
arXiv:2407.03136v1 Announce Type: new 
Abstract: A key requirement in robotics is the ability to simultaneously self-localize and map a previously unknown environment, relying primarily on onboard sensing and computation. Achieving fully onboard accurate simultaneous localization and mapping (SLAM) is feasible for high-end robotic platforms, whereas small and inexpensive robots face challenges due to constrained hardware, therefore frequently resorting to external infrastructure for sensing and computation. The challenge is further exacerbated in swarms of robots, where coordination, scalability, and latency are crucial concerns. This work introduces a decentralized and lightweight collaborative SLAM approach that enables mapping on virtually any robot, even those equipped with low-cost hardware, including miniaturized insect-size devices. Moreover, the proposed solution supports large swarm formations with the capability to coordinate hundreds of agents. To substantiate our claims, we have successfully implemented collaborative SLAM on centimeter-size drones weighing only 46 grams. Remarkably, we achieve results comparable to high-end state-of-the-art solutions while reducing the cost, memory, and computation requirements by two orders of magnitude. Our approach is innovative in three main aspects. First, it enables onboard infrastructure-less collaborative mapping with a lightweight and cost-effective solution in terms of sensing and computation. Second, we optimize the data traffic within the swarm to support hundreds of cooperative agents using standard wireless protocols such as ultra-wideband (UWB), Bluetooth, or WiFi. Last, we implement a distributed swarm coordination policy to decrease mapping latency and enhance accuracy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2407.03144</link>
<guid>https://arxiv.org/abs/2407.03144</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Backdoor Attack, Imperceptible, Target-on-Demand, Venomancer.

总结:<br />
Federated Learning（FL）是一种分布式机器学习方法，旨在保护数据隐私。然而，它也面临后门攻击威胁。文章介绍了一种新的攻击手段Venomancer，它具有隐形和目标自定义的特点。隐形通过视觉损失函数实现，使毒数据与原始数据难以区分；目标自定义则通过条件对抗性训练允许攻击者选择任意目标类别。实验表明，Venomancer对抗现有防御机制如Norm Clipping、Weak DP、Krum和Multi-Krum表现出稳健性。代码可在https://anonymous.4open.science/r/Venomancer-3426获取。 <div>
arXiv:2407.03144v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning approach that maintains data privacy by training on decentralized data sources. Similar to centralized machine learning, FL is also susceptible to backdoor attacks. Most backdoor attacks in FL assume a predefined target class and require control over a large number of clients or knowledge of benign clients' information. Furthermore, they are not imperceptible and are easily detected by human inspection due to clear artifacts left on the poison data. To overcome these challenges, we propose Venomancer, an effective backdoor attack that is imperceptible and allows target-on-demand. Specifically, imperceptibility is achieved by using a visual loss function to make the poison data visually indistinguishable from the original data. Target-on-demand property allows the attacker to choose arbitrary target classes via conditional adversarial training. Additionally, experiments showed that the method is robust against state-of-the-art defenses such as Norm Clipping, Weak DP, Krum, and Multi-Krum. The source code is available at https://anonymous.4open.science/r/Venomancer-3426.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cooperative Multi-Agent Deep Reinforcement Learning Methods for UAV-aided Mobile Edge Computing Networks</title>
<link>https://arxiv.org/abs/2407.03280</link>
<guid>https://arxiv.org/abs/2407.03280</guid>
<content:encoded><![CDATA[
<div> 关键词：无人飞行器、移动边缘计算、深度强化学习、协同多代理、任务卸载。

总结:<br />
本文提出了一种基于深度强化学习的协作多代理方法，应用于无人机辅助的移动边缘计算网络。该方法旨在优化无人机轨迹、资源分配和任务卸载策略，以提高地面物联网设备的服务性能。通过设计专用的演员神经网络生成消息动作和解决方案动作，实现无人机与设备的协调决策，即使面对任意数量的设备也能进行有效操作。文章还提出了一种可扩展的训练算法，适用于不同网络配置。实验结果显示，该协作多代理深度强化学习方法相较于传统方法表现出显著优势。 <div>
arXiv:2407.03280v1 Announce Type: new 
Abstract: This paper presents a cooperative multi-agent deep reinforcement learning (MADRL) approach for unmmaned aerial vehicle (UAV)-aided mobile edge computing (MEC) networks. An UAV with computing capability can provide task offlaoding services to ground internet-of-things devices (IDs). With partial observation of the entire network state, the UAV and the IDs individually determine their MEC strategies, i.e., UAV trajectory, resource allocation, and task offloading policy. This requires joint optimization of decision-making process and coordination strategies among the UAV and the IDs. To address this difficulty, the proposed cooperative MADRL approach computes two types of action variables, namely message action and solution action, each of which is generated by dedicated actor neural networks (NNs). As a result, each agent can automatically encapsulate its coordination messages to enhance the MEC performance in the decentralized manner. The proposed actor structure is designed based on graph attention networks such that operations are possible regardless of the number of IDs. A scalable training algorithm is also proposed to train a group of NNs for arbitrary network configurations. Numerical results demonstrate the superiority of the proposed cooperative MADRL approach over conventional methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits</title>
<link>https://arxiv.org/abs/2001.05452</link>
<guid>https://arxiv.org/abs/2001.05452</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent, Multi-Armed Bandit, Decentralized, Gossip Communication, Regret

总结: 本文探讨了一个多智能体马尔可夫链赌博（MAB）问题，其中N个智能体通过任意连接图进行协作，目标是减少个体累计后悔。研究者提出两种新算法，允许智能体仅交换臂ID而非样本，通过通信更新选择的臂集。文章表明，即使少量交流也能使每个智能体的后悔减少约N倍。通信对算法影响的二级效应也被分析，以理解后悔与通信之间的权衡。实验证明了这些结果的普遍性，且算法的性能界限是无沟通限制下的最优。总的来说，协作显著降低了所有智能体的后悔。 <div>
arXiv:2001.05452v4 Announce Type: replace 
Abstract: We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup consisting of $N$ agents, solving the same MAB instance to minimize individual cumulative regret. In our model, agents collaborate by exchanging messages through pairwise gossip style communications on an arbitrary connected graph. We develop two novel algorithms, where each agent only plays from a subset of all the arms. Agents use the communication medium to recommend only arm-IDs (not samples), and thus update the set of arms from which they play. We establish that, if agents communicate $\Omega(\log(T))$ times through any connected pairwise gossip mechanism, then every agent's regret is a factor of order $N$ smaller compared to the case of no collaborations. Furthermore, we show that the communication constraints only have a second order effect on the regret of our algorithm. We then analyze this second order term of the regret to derive bounds on the regret-communication tradeoffs. Finally, we empirically evaluate our algorithm and conclude that the insights are fundamental and not artifacts of our bounds. We also show a lower bound which gives that the regret scaling obtained by our algorithm cannot be improved even in the absence of any communication constraints. Our results thus demonstrate that even a minimal level of collaboration among agents greatly reduces regret for all agents.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2305.18784</link>
<guid>https://arxiv.org/abs/2305.18784</guid>
<content:encoded><![CDATA[
<div> 关键词：collaborative multi-agent bandits, decentralized algorithms, cumulative regret, group regret, lower bounds

总结:<br />本文关注协作多智能体_bandits的研究，探讨了由N个学习M个随机臂老虎机的代理组成的团队，目标是减少整体累积遗憾。研究者开发了去中心化的算法，适用于两种情景，并分析了算法性能，提供了每个代理和团队的累积遗憾上界。此外，文章还给出了团队遗憾的下界，证明了提议算法的近最优性。 <div>
arXiv:2305.18784v2 Announce Type: replace 
Abstract: The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Gradual Verification for Smart Contracts</title>
<link>https://arxiv.org/abs/2311.13351</link>
<guid>https://arxiv.org/abs/2311.13351</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchains, smart contracts, re-entrancy attacks, verification, Algorand.

总结:<br />
本文主要关注区块链中的智能合约安全问题，特别是针对外部合同交互时的漏洞，如著名的重入攻击(re-entrancy attacks)。作者提出了一种创新的方法——渐进式验证(gradual verification)，它结合了静态和动态验证技术，旨在提升智能合约的安全性、保证正确性和灵活性，同时优化资源使用。通过实现pyTEAL语言的Algorand智能合约验证原型，研究者展示了这种方法的有效性，有助于推动智能合约的稳健高效执行，从而保障区块链系统的安全性。 <div>
arXiv:2311.13351v2 Announce Type: replace 
Abstract: Blockchains facilitate secure resource transactions through smart contracts, yet these digital agreements are prone to vulnerabilities, particularly when interacting with external contracts, leading to substantial monetary losses. Traditional verification techniques fall short in providing comprehensive security assurances, especially against re-entrancy attacks, due to the unavailable implementations of external contracts. This paper introduces an incremental approach: gradual verification. We combine static and dynamic verification techniques to enhance security, guarantee soundness and flexibility, and optimize resource usage in smart contract interactions. By implementing a prototype for gradually verifying Algorand smart contracts via the pyTEAL language, we demonstrate the effectiveness of our approach, contributing to the safe and efficient execution of smart contracts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-Agent Probabilistic Ensembles with Trajectory Sampling for Connected Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2312.13910</link>
<guid>https://arxiv.org/abs/2312.13910</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Vehicles, Reinforcement Learning, Model-Based RL, Model-Free RL, Multi-Agent Probabilistic Ensembles with Trajectory Sampling

总结:
本文探讨了自动驾驶车辆（AVs）中的决策问题，特别关注了在连接的自动驾驶汽车（CAVs）中采用强化学习（RL）。文章指出，尽管模型自由的RL（MFRL）在数据驱动决策上表现出色，但在实际应用中可能面临数据需求大和学习不稳定的问题。相比之下，模型基于的RL（MBRL）虽然样本效率高，但长期性能可能不如最先进的MFRL算法。

研究者提出了一种多代理算法MA-PETS，它结合了概率ensemble神经网络（Probabilistic Ensemble，PE）和轨迹采样（Trajectory Sampling，TS）技术，以处理多个CAV之间的有限通信环境。MA-PETS通过利用邻居共享的数据，更好地捕捉环境不确定性，同时发展出基于模型预测控制的决策策略。文章还数学证明，通过在多代理学习中有效信息交流，可以降低多代理群体的后悔值。

实验结果表明，MA-PETS在样本效率上与MFRL相当，显示出其在复杂交通场景中的优势。总的来说，该研究提出了一种有效的多代理决策框架，兼顾了样本效率和不确定性处理，为连接的自动驾驶汽车的协同决策提供了新的解决方案。 <div>
arXiv:2312.13910v2 Announce Type: replace 
Abstract: Autonomous Vehicles (AVs) have attracted significant attention in recent years and Reinforcement Learning (RL) has shown remarkable performance in improving the autonomy of vehicles. In that regard, the widely adopted Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs (CAVs), contingent on the readiness of a significant amount of data samples for training. Nevertheless, it might be infeasible in practice and possibly lead to learning instability. In contrast, Model-Based RL (MBRL) manifests itself in sample-efficient learning, but the asymptotic performance of MBRL might lag behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs are limited to the decision-making of a single AV only, thus underscoring the performance due to the absence of communications. In this study, we try to address the decision-making problem of multiple CAVs with limited communications and propose a decentralized Multi-Agent Probabilistic Ensembles with Trajectory Sampling algorithm MA-PETS. In particular, in order to better capture the uncertainty of the unknown environment, MA-PETS leverages Probabilistic Ensemble (PE) neural networks to learn from communicated samples among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory Sampling (TS)-based model-predictive control for decision-making. On this basis, we derive the multi-agent group regret bound affected by the number of agents within the communication range and mathematically validate that incorporating effective information exchange among agents into the multi-agent learning scheme contributes to reducing the group regret bound in the worst case. Finally, we empirically demonstrate the superiority of MA-PETS in terms of the sample efficiency comparable to MFBL.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2406.17249</link>
<guid>https://arxiv.org/abs/2406.17249</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized, Metric-Semantic SLAM, Hierarchical Representation, Object-Based, Heterogeneous Robot Team

总结:<br />
本文提出了一种实时的分布式度量-语义同时定位和建图（SLAM）方法，适用于各种环境探索。该系统利用稀疏和轻量级的对象表示，支持异构机器人团队在室内、城市和森林环境中进行自主导航，无需GPS。通过层次化的度量-语义地图，包括高阶的对象模型和低阶的voxel地图，实现了跨不同传感器类型的机器人之间的位置识别。通信模块允许在通信链接可用时共享观察数据，构建合并地图。实验结果展示了出色的定位精度（约20厘米位置误差，0.2度方向误差），对象映射的F1分数超过0.9，以及每公里路径通信包大小仅2-3MB，即使有1000个地标。这项工作为多机器人协作的自主探索提供了有效解决方案。 <div>
arXiv:2406.17249v2 Announce Type: replace 
Abstract: This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) approach that leverages a sparse and lightweight object-based representation to enable a heterogeneous robot team to autonomously explore 3D environments featuring indoor, urban, and forested areas without relying on GPS. We use a hierarchical metric-semantic representation of the environment, including high-level sparse semantic maps of object models and low-level voxel maps. We leverage the informativeness and viewpoint invariance of the high-level semantic map to obtain an effective semantics-driven place-recognition algorithm for inter-robot loop closure detection across aerial and ground robots with different sensing modalities. A communication module is designed to track each robot's own observations and those of other robots whenever communication links are available. Such observations are then used to construct a merged map. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate and deploy our proposed framework on three types of aerial and ground robots. Extensive experimental results show an average inter-robot localization error of approximately 20 cm in position and 0.2 degrees in orientation, an object mapping F1 score consistently over 0.9, and a communication packet size of merely 2-3 megabytes per kilometer trajectory with as many as 1,000 landmarks. The project website can be found at https://xurobotics.github.io/slideslam/.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Commodification of Compute</title>
<link>https://arxiv.org/abs/2406.19261</link>
<guid>https://arxiv.org/abs/2406.19261</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、区块链技术、智能合约、全球计算交换（GCX）、资源优化。

总结:<br />
本文介绍了一种名为全球计算交换（GCX）的新型平台，它利用区块链技术和智能合约来解决计算资源分配中的效率问题和价格波动。GCX通过构建市场、应用、清算、风险管理、离链和区块链等多层结构，创建了一个安全、透明的市场，使用户能够买卖计算能力，实现资源的公平访问和优化使用。这个平台不仅提升了计算资源的利用率，还稳定了价格，促进了创新，并有望推动计算资源的民主化。总的来说，GCX是一个具有革新性的解决方案，预示着计算资源商品化的未来趋势。 <div>
arXiv:2406.19261v2 Announce Type: replace 
Abstract: The rapid advancements in artificial intelligence, big data analytics, and cloud computing have precipitated an unprecedented demand for computational resources. However, the current landscape of computational resource allocation is characterized by significant inefficiencies, including underutilization and price volatility. This paper addresses these challenges by introducing a novel global platform for the commodification of compute hours, termed the Global Compute Exchange (GCX) (Patent Pending). The GCX leverages blockchain technology and smart contracts to create a secure, transparent, and efficient marketplace for buying and selling computational power. The GCX is built in a layered fashion, comprising Market, App, Clearing, Risk Management, Exchange (Offchain), and Blockchain (Onchain) layers, each ensuring a robust and efficient operation. This platform aims to revolutionize the computational resource market by fostering a decentralized, efficient, and transparent ecosystem that ensures equitable access to computing power, stimulates innovation, and supports diverse user needs on a global scale. By transforming compute hours into a tradable commodity, the GCX seeks to optimize resource utilization, stabilize pricing, and democratize access to computational resources. This paper explores the technological infrastructure, market potential, and societal impact of the GCX, positioning it as a pioneering solution poised to drive the next wave of innovation in commodities and compute.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-topic belief formation through bifurcations over signed social networks</title>
<link>https://arxiv.org/abs/2308.02755</link>
<guid>https://arxiv.org/abs/2308.02755</guid>
<content:encoded><![CDATA[
<div> 关键词：信念形成、多维、社会网络、认知不协调、动态模型

总结:<br />
本文提出并分析了一个连续时间多维度的信念形成模型，考虑了社会网络结构、个体自我评估、内在偏见以及认知不协调等社会心理学理论因素。模型通过描述意见形成过程中的转折点（即分岔）探讨了个体观点的形成。研究发现，社交网络效应的平衡决定了信念形成过程的性质，以及多稳态信念均衡和由此产生的信念振荡。该模型揭示了社会系统动态的新见解，并为设计工程网络中基于结构关系的去中心化决策提供了理论框架。 <div>
arXiv:2308.02755v2 Announce Type: replace-cross 
Abstract: We propose and analyze a nonlinear dynamic model of continuous-time multi-dimensional belief formation over signed social networks. Our model accounts for the effects of a structured belief system, self-appraisal, internal biases, and various sources of cognitive dissonance posited by recent theories in social psychology. We prove that agents become opinionated as a consequence of a bifurcation. We analyze how the balance of social network effects in the model controls the nature of the bifurcation and, therefore, the belief-forming limit-set solutions. Our analysis provides constructive conditions on how multi-stable network belief equilibria and belief oscillations emerging at a belief-forming bifurcation depend on the communication network graph and belief system network graph. Our model and analysis provide new theoretical insights on the dynamics of social systems and a new principled framework for designing decentralized decision-making on engineered networks in the presence of structured relationships among alternatives.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reusable Formal Verification of DAG-based Consensus Protocols</title>
<link>https://arxiv.org/abs/2407.02167</link>
<guid>https://arxiv.org/abs/2407.02167</guid>
<content:encoded><![CDATA[
<div> 关键词：DAG-based consensus, protocols, blockchain, safety proof, TLA+

总结:<br />
本文探讨了DAG（有向无环图）为基础的共识协议在区块链领域的应用，这些协议旨在降低能源消耗和增强安全性。作者提供了两个此类协议的安全性证明形式规范，强调了协议的不同实现变种，如传播、DAG构建和排序。使用TLA+语言对抽象模型进行了描述，包括492-732行的规格说明和2025-2294项义务的验证，整个过程在6-8分钟内完成。这一工作对于区块链技术的正确性和可靠性提供了重要保障。 <div>
arXiv:2407.02167v1 Announce Type: new 
Abstract: DAG-based consensus protocols are being adoption by blockchain companies to decrease energy footprints and improve security. A DAG-based consensus protocol collaboratively constructs a partial order of blocks of transactions and produces linearly ordered blocks. The ubiquity and strategic importance of blockchains call for formal proof of the correctness of key components, namely, consensus protocols. This paper presents a safety-proven formal specification of two DAG-based protocols. Our specification highlights several dissemination, DAG construction, and ordering variations that can be combined to express the two protocols. The formalization requires a refinement approach for modeling the consensus. In an abstract model, we first show the safety of DAG-based consensus on leader blocks and then further refine the specification to encompass all blocks for all processes. The TLA+ specification for a given protocol consists of 492-732 lines, and the proof system TLAPS verifies 2025-2294 obligations in 6-8 minutes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>RollupTheCrowd: Leveraging ZkRollups for a Scalable and Privacy-Preserving Reputation-based Crowdsourcing Platform</title>
<link>https://arxiv.org/abs/2407.02226</link>
<guid>https://arxiv.org/abs/2407.02226</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, reputation, crowdsourcing, zkRollups, scalability

总结:<br />
这篇文章介绍了一种名为RollupTheCrowd的新型区块链框架，专注于解决现有区块链声誉系统在效率、隐私和可扩展性之间的平衡问题。通过结合zkRollups（零知识证明的rollup），该框架能够在保护用户隐私的同时，有效评估众包工作者的信誉，减轻了区块链上的交易压力，降低了约20倍的gas消耗。文章还提到，作者开发了一个概念验证原型，并通过实验展示了RollupTheCrowd的可行性和实际应用潜力。 <div>
arXiv:2407.02226v1 Announce Type: new 
Abstract: Current blockchain-based reputation solutions for crowdsourcing fail to tackle the challenge of ensuring both efficiency and privacy without compromising the scalability of the blockchain. Developing an effective, transparent, and privacy-preserving reputation model necessitates on-chain implementation using smart contracts. However, managing task evaluation and reputation updates alongside crowdsourcing transactions on-chain substantially strains system scalability and performance. This paper introduces RollupTheCrowd, a novel blockchain-powered crowdsourcing framework that leverages zkRollups to enhance system scalability while protecting user privacy. Our framework includes an effective and privacy-preserving reputation model that gauges workers' trustworthiness by assessing their crowdsourcing interactions. To alleviate the load on our blockchain, we employ an off-chain storage scheme, optimizing RollupTheCrowd's performance. Utilizing smart contracts and zero-knowledge proofs, our Rollup layer achieves a significant 20x reduction in gas consumption. To prove the feasibility of the proposed framework, we developed a proof-of-concept implementation using cutting-edge tools. The experimental results presented in this paper demonstrate the effectiveness and scalability of RollupTheCrowd, validating its potential for real-world application scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Intelligence Network (DIN)</title>
<link>https://arxiv.org/abs/2407.02461</link>
<guid>https://arxiv.org/abs/2407.02461</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Intelligence Network (DIN), 数据主权, 分散式学习, 公共区块链, 奖励机制

总结:<br />
Decentralized Intelligence Network (DIN)是一个创新框架，旨在解决数据碎片化和AI利用中的问题。它通过五个关键点实现：首先，个人数据存储支持数据主权；其次，基于公共区块链的联邦学习协议允许在保持数据私有性的同时进行模型参数共享；接着，通过无第三方的信任奖励机制激励参与，确保公平分配；此外，该系统防止任何一方控制数据访问或收益决定；最后，DIN创建了一个去中心化的生态系统，促进集体AI发展，保护用户数据权益并实现多方共赢。 <div>
arXiv:2407.02461v1 Announce Type: new 
Abstract: Decentralized Intelligence Network (DIN) addresses the significant challenges of data sovereignty and AI utilization caused by the fragmentation and siloing of data across providers and institutions. This comprehensive framework overcomes access barriers to scalable data sources previously hindered by silos by leveraging: 1) personal data stores as a prerequisite for data sovereignty; 2) a scalable federated learning protocol implemented on a public blockchain for decentralized AI training, where data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training, allowing participants to maintain control over their data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Efficient and Sybil Attack Resistant Voting Mechanism</title>
<link>https://arxiv.org/abs/2407.01844</link>
<guid>https://arxiv.org/abs/2407.01844</guid>
<content:encoded><![CDATA[
<div> 关键词：投票机制、Sybil攻击、Bayesian机制设计、风险中性、效率

总结: 这篇文章探讨了在无需身份验证的去中心化决策场景中，如何设计一种既能抵抗多重账户（Sybil攻击）又能实现最大集体利益的投票机制。研究者提出了一种基于Bayesian机制设计的解决方案，其核心在于：玩家通过财富存款表达偏好，投票结果影响个人收益分配；机制设计使得恶意投票者对整体效用的影响大于自身收益，从而保证系统在风险中性玩家和私有信息的假设下既防SA又高效。这一成果为构建更稳健的去中心化决策机制提供了新思路。 <div>
arXiv:2407.01844v1 Announce Type: cross 
Abstract: Voting mechanisms are widely accepted and used methods for decentralized decision-making. Ensuring the acceptance of the voting mechanism's outcome is a crucial characteristic of robust voting systems. Consider this scenario: A group of individuals wants to choose an option from a set of alternatives without requiring an identification or proof-of-personhood system. Moreover, they want to implement utilitarianism as their selection criteria. In such a case, players could submit votes multiple times using dummy accounts, commonly known as a Sybil attack (SA), which presents a challenge for decentralized organizations. Is there a voting mechanism that always prevents players from benefiting by casting votes multiple times (SA-proof) while also selecting the alternative that maximizes the added valuations of all players (efficient)? One-person-one-vote is neither SA-proof nor efficient. Coin voting is SA-proof but not efficient. Quadratic voting is efficient but not SA-proof. This study uses Bayesian mechanism design to propose a solution. The mechanism's structure is as follows: Players make wealth deposits to indicate the strength of their preference for each alternative. Each player then receives an amount based on their deposit and the voting outcome. The proposed mechanism relies on two main concepts: 1) Transfers are influenced by the outcome in a way that each player's optimal action depends only on individual preferences and the number of alternatives; 2) A player who votes through multiple accounts slightly reduces the expected utility of all players more than the individual benefit gained. This study demonstrates that if players are risk-neutral and each player has private information about their preferences and beliefs, then the mechanism is SA-proof and efficient. This research provides new insights into the design of more robust decentralized decision-making mechanisms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Knowledge Connectivity Requirements for Solving BFT Consensus with Unknown Participants and Fault Threshold (Extended Version)</title>
<link>https://arxiv.org/abs/2405.06055</link>
<guid>https://arxiv.org/abs/2405.06055</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Fault Tolerant Consensus, Knowledge Connectivity Graph, Fault Threshold, BFT-CUP, BFT-CUPFT.

总结:<br />
本文主要关注拜占庭容错共识（BFT）在参与者知识受限的场景，即每个参与者仅知道部分参与者。首先，文章讨论了BFT-CUP问题，即在提供故障阈值给所有参与者的情况下达成共识。然而，研究者发现这不适用于BFT-CUPFT，即故障阈值未知的情况。为此，文章提出了一种新的知识连接图类型，确定了解决BFT-CUPFT所需的必要和充分条件。最后，作者设计了一个协议来处理这种故障未知的BFT共识场景，扩展了先前理论并解决了实际应用中的挑战。 <div>
arXiv:2405.06055v2 Announce Type: replace 
Abstract: Consensus stands as a fundamental building block for constructing reliable and fault-tolerant distributed services. The increasing demand for high-performance and scalable blockchain protocols has brought attention to solving consensus in scenarios where each participant joins the system knowing only a subset of participants. In such scenarios, the participants' initial knowledge about the existence of other participants can collectively be represented by a directed graph known as knowledge connectivity graph. The Byzantine Fault Tolerant Consensus with Unknown Participants (BFT-CUP) problem aims to solve consensus in those scenarios by identifying the necessary and sufficient conditions that the knowledge connectivity graphs must satisfy when a fault threshold is provided to all participants. This work extends BFT-CUP by eliminating the requirement to provide the fault threshold to the participants. We indeed address the problem of solving BFT consensus in settings where each participant initially knows a subset of participants, and although a fault threshold exists, no participant is provided with this information -- referred to as BFT Consensus with Unknown Participants and Fault Threshold (BFT-CUPFT). With this aim, we first demonstrate that the conditions for knowledge connectivity graphs identified by BFT-CUP are insufficient to solve BFT-CUPFT. Accordingly, we introduce a new type of knowledge connectivity graphs by determining the necessary and sufficient conditions they must satisfy to solve BFT-CUPFT. Furthermore, we design a protocol for solving BFT-CUPFT.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations</title>
<link>https://arxiv.org/abs/2407.00632</link>
<guid>https://arxiv.org/abs/2407.00632</guid>
<content:encoded><![CDATA[
<div> 关键词：视觉导航、多机器人协作、大型语言模型、通信触发、动态领导组织结构。

总结:<br />本文探讨了在复杂视觉导航任务中，如何利用大型语言模型（LLMs）实现多机器人有效协作。研究提出了一种框架，通过设计通信触发的动态领导组织结构，促进团队成员间的快速共识和减少交流次数，从而提高导航效率和探索效率。这种创新的通信机制使得框架在处理多目标导航时表现出冲突解决能力和对团队规模扩大的稳健性，为家庭服务机器人的协作导航提供了新思路。 <div>
arXiv:2407.00632v1 Announce Type: new 
Abstract: Visual navigation tasks are critical for household service robots. As these tasks become increasingly complex, effective communication and collaboration among multiple robots become imperative to ensure successful completion. In recent years, large language models (LLMs) have exhibited remarkable comprehension and planning abilities in the context of embodied agents. However, their application in household scenarios, specifically in the use of multiple agents collaborating to complete complex navigation tasks through communication, remains unexplored. Therefore, this paper proposes a framework for decentralized multi-agent navigation, leveraging LLM-enabled communication and collaboration. By designing the communication-triggered dynamic leadership organization structure, we achieve faster team consensus with fewer communication instances, leading to better navigation effectiveness and collaborative exploration efficiency. With the proposed novel communication scheme, our framework promises to be conflict-free and robust in multi-object navigation tasks, even when there is a surge in team size.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Opportunities for Shape-based Optimization of Link Traversal Queries</title>
<link>https://arxiv.org/abs/2407.00998</link>
<guid>https://arxiv.org/abs/2407.00998</guid>
<content:encoded><![CDATA[
<div> 关键词：web数据、Link Traversal Query Processing (LTQP)、RDF数据形状、source selection algorithm、decentralized query processing

总结:<br />
这篇文章主要探讨了在Web数据的去中心化环境中，如何利用RDF数据形状优化Link Traversal Query Processing (LTQP)的问题。作者提出了一种基于RDF数据形状映射的源选择算法，旨在解决LTQP中缺乏先验信息和大量HTTP请求的问题。初步实验表明，通过少量维护和服务器工作，该方法能显著减少查询执行时间（高达80%）和链接遍历数量（达97%）。这为非启发式查询规划研究提供了新的方向，展示了RDF数据形状的强大描述能力。未来的研究可能集中在更深入地挖掘这种潜力上。 <div>
arXiv:2407.00998v1 Announce Type: new 
Abstract: Data on the web is naturally unindexed and decentralized. Centralizing web data, especially personal data, raises ethical and legal concerns. Yet, compared to centralized query approaches, decentralization-friendly alternatives such as Link Traversal Query Processing (LTQP) are significantly less performant and understood. The two main difficulties of LTQP are the lack of apriori information about data sources and the high number of HTTP requests. Exploring decentralized-friendly ways to document unindexed networks of data sources could lead to solutions to alleviate those difficulties. RDF data shapes are widely used to validate linked data documents, therefore, it is worthwhile to investigate their potential for LTQP optimization. In our work, we built an early version of a source selection algorithm for LTQP using RDF data shape mappings with linked data documents and measured its performance in a realistic setup. In this article, we present our algorithm and early results, thus, opening opportunities for further research for shape-based optimization of link traversal queries. Our initial experiments show that with little maintenance and work from the server, our method can reduce up to 80% the execution time and 97% the number of links traversed during realistic queries. Given our early results and the descriptive power of RDF data shapes it would be worthwhile to investigate non-heuristic-based query planning using RDF shapes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Energy-Aware Decentralized Learning with Intermittent Model Training</title>
<link>https://arxiv.org/abs/2407.01283</link>
<guid>https://arxiv.org/abs/2407.01283</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized learning, Energy consumption, SkipTrain, Synchronization rounds, Model accuracy.

总结:<br />
本文介绍了一种名为SkipTrain的新型去中心化学习（Decentralized learning）算法，其目标是减少能源消耗并提高模型准确性。SkipTrain通过有策略地跳过一些训练轮次，用同步轮替之，从而在不牺牲模型性能的前提下，节省了大量能量。与常规的D-PSGD算法相比，SkipTrain在256节点实验中显示出高达50%的节能效果和高达12%的模型精度提升。这种方法不仅降低了计算成本，还促进了模型间的更好融合。 <div>
arXiv:2407.01283v1 Announce Type: new 
Abstract: Decentralized learning (DL) offers a powerful framework where nodes collaboratively train models without sharing raw data and without the coordination of a central server. In the iterative rounds of DL, models are trained locally, shared with neighbors in the topology, and aggregated with other models received from neighbors. Sharing and merging models contribute to convergence towards a consensus model that generalizes better across the collective data captured at training time. In addition, the energy consumption while sharing and merging model parameters is negligible compared to the energy spent during the training phase. Leveraging this fact, we present SkipTrain, a novel DL algorithm, which minimizes energy consumption in decentralized learning by strategically skipping some training rounds and substituting them with synchronization rounds. These training-silent periods, besides saving energy, also allow models to better mix and finally produce models with superior accuracy than typical DL algorithms that train at every round. Our empirical evaluations with 256 nodes demonstrate that SkipTrain reduces energy consumption by 50% and increases model accuracy by up to 12% compared to D-PSGD, the conventional DL algorithm.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>C-MP: A decentralized adaptive-coordinated traffic signal control using the Max Pressure framework</title>
<link>https://arxiv.org/abs/2407.01421</link>
<guid>https://arxiv.org/abs/2407.01421</guid>
<content:encoded><![CDATA[
<div> 关键词：Coordinated Max Pressure (C-MP), adaptive traffic signals, decentralized decision-making, arterial network, stable region.

总结:<br />
本文提出了一种新颖的协调最大压力(Coordinated Max Pressure, C-MP)交通信号框架，旨在解决分布式决策下协调交通流的问题。C-MP利用车辆空间平均速度检测并优先处理沿走廊的自由行驶车队，通过调整上游车队的权重和下游车队的权重，确保交通流畅。文章证明了C-MP保持最大稳定性，并通过模拟分析展示了其在动脉网络中相较于基准MP控制策略具有更大的稳定区域。C-MP在无需预设交错时间和约束的情况下有效协调双向动脉交通，减少旅行时间和燃料消耗，实现交通流量的均衡。 <div>
arXiv:2407.01421v1 Announce Type: new 
Abstract: Coordinated traffic signals seek to provide uninterrupted flow through a series of closely spaced intersections, typically using pre-defined fixed signal timings and offsets. Adaptive traffic signals dynamically change signal timings based on observed traffic conditions in a way that might disrupt coordinated movements, particularly when these decisions are made independently at each intersection. To alleviate this issue, this paper introduces a novel Max Pressure-based traffic signal framework that can provide coordination even under decentralized decision-making. The proposed Coordinated Max Pressure (C-MP) algorithm uses the space mean speeds of vehicles to explicitly detect freely flowing platoons of vehicles and prioritizes their movement along a corridor. Specifically, upstream platoons are detected and their weight in the MP framework increased to provide priority, while downstream platoons are detected and their weight reduced to ensure smooth traffic flow across corridors. The study analytically proves that C-MP maintains the desirable maximum stability property, while micro-simulation analyses conducted on an arterial network demonstrate its ability to achieve a larger stable region compared to benchmark MP control policies. Simulation results also reveal that the proposed control algorithm can effectively coordinate traffic signals in both directions along an arterial without explicitly assigned offsets or constraints. The results also reveal C-MP's superiority to benchmark coordination strategies in reducing travel time, and fuel consumption both at the corridor level and the network level by balancing the negative impact imparted to vehicles in the minor direction.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Graph Neural Networks and Reinforcement Learning for Proactive Application Image Placement</title>
<link>https://arxiv.org/abs/2407.00007</link>
<guid>https://arxiv.org/abs/2407.00007</guid>
<content:encoded><![CDATA[
<div> 关键词：Edge computing, Cloud-Edge continuum, Service placement, Application placement, Reinforcement Learning.

总结:<br />
云计算向云边计算的转变为数据密集型和交互式应用带来了机遇与挑战。边缘计算作为下一代应用严格需求的关键支持，通过将计算任务移至用户附近，实现了低延迟和高带宽。然而，边缘计算的分布式、动态和异构特性使得服务部署成为一个难题。本文提出了一种结合图神经网络和强化学习（Actor-Critic）的前瞻性图像部署方法，旨在减少图像传输时间并优化应用部署。尽管在某些情况下可能导致执行时间稍长，但实验结果显示，该方法在整体应用部署上表现更优。 <div>
arXiv:2407.00007v1 Announce Type: new 
Abstract: The shift from Cloud Computing to a Cloud-Edge continuum presents new opportunities and challenges for data-intensive and interactive applications. Edge computing has garnered a lot of attention from both industry and academia in recent years, emerging as a key enabler for meeting the increasingly strict demands of Next Generation applications. In Edge computing the computations are placed closer to the end-users, to facilitate low-latency and high-bandwidth applications and services. However, the distributed, dynamic, and heterogeneous nature of Edge computing, presents a significant challenge for service placement. A critical aspect of Edge computing involves managing the placement of applications within the network system to minimize each application's runtime, considering the resources available on system devices and the capabilities of the system's network. The placement of application images must be proactively planned to minimize image tranfer time, and meet the strict demands of the applications. In this regard, this paper proposes an approach for proactive image placement that combines Graph Neural Networks and actor-critic Reinforcement Learning, which is evaluated empirically and compared against various solutions. The findings indicate that although the proposed approach may result in longer execution times in certain scenarios, it consistently achieves superior outcomes in terms of application placement.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A New Approach for Evaluating the Performance of Distributed Latency-Sensitive Services</title>
<link>https://arxiv.org/abs/2407.00015</link>
<guid>https://arxiv.org/abs/2407.00015</guid>
<content:encoded><![CDATA[
<div> 关键词：latency metrics, Service Level Agreement (SLA), distributed computing, immersive services, latency performance.

总结:<br />本文提出了一篇关于新型延迟度量标准（latency metrics）的研究论文，针对传统指标在评估现代服务和分布式计算环境中性能的局限性。研究者强调了现有指标无法充分捕捉两个关键性能方面：超过服务级别协议（SLA）阈值的频率以及恢复到可接受水平的时间。为解决这一问题，作者开发了五个创新的延迟度量，它们能够提供更深入的服务性能洞察。这些新指标尤其适用于对低延迟有严格要求的沉浸式服务。论文通过大规模实验验证了新指标的有效性和实用性，以促进服务性能优化。 <div>
arXiv:2407.00015v1 Announce Type: new 
Abstract: Conventional latency metrics are formulated based on a broad definition of traditional monolithic services, and hence lack the capacity to address the complexities inherent in modern services and distributed computing paradigms. Consequently, their effectiveness in identifying areas for improvement is restricted, falling short of providing a comprehensive evaluation of service performance within the context of contemporary services and computing paradigms. More specifically, these metrics do not offer insights into two critical aspects of service performance: the frequency of latency surpassing specified Service Level Agreement (SLA) thresholds and the time required for latency to return to an acceptable level once the threshold is exceeded. This limitation is quite significant in the frame of contemporary latency-sensitive services, and especially immersive services that require deterministic low latency that behaves in a consistent manner. Towards addressing this limitation, the authors of this work propose 5 novel latency metrics that when leveraged alongside the conventional latency metrics manage to provide advanced insights that can be potentially used to improve service performance. The validity and usefulness of the proposed metrics in the frame of providing advanced insights into service performance is evaluated using a large-scale experiment.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Preble: Efficient Distributed Prompt Scheduling for LLM Serving</title>
<link>https://arxiv.org/abs/2407.00023</link>
<guid>https://arxiv.org/abs/2407.00023</guid>
<content:encoded><![CDATA[
<div> 关键词：Preble、大型语言模型（LLMs）、分布式 serving 平台、prompt 分享、计算重用。

总结:
Preble 是一项创新，它提出了一种针对大型语言模型（LLMs）服务的分布式平台，专注于优化提示共享。文章研究了五个流行的工作负载，发现当前系统忽视了重复提示的注意力计算可以复用的潜力。为此，Preble 设计了一个分布式调度系统，兼顾计算重用和负载均衡。实验证明，与现有技术相比，Preble 在两到八GPU上分别提高了平均延迟1.5倍至14.5倍和p99值的2倍至10倍，显著提升了性能。 <div>
arXiv:2407.00023v1 Announce Type: new 
Abstract: Prompts to large language models (LLMs) have evolved beyond simple user questions. For LLMs to solve complex problems, today's practices include domain-specific instructions, illustration of tool usages, and long context, such as textbook chapters in prompts. As such, many parts of prompts are repetitive across requests, and their attention computation results can be reused. However, today's LLM serving systems treat every request in isolation, missing the opportunity of computation reuse.
  This paper proposes Preble, the first distributed LLM serving platform that targets and optimizes for prompt sharing. We perform a study on five popular LLM workloads. Based on our study results, we designed a distributed scheduling system that co-optimizes computation reuse and load balancing. Our evaluation of Preble on two to 8 GPUs with real workloads and request arrival patterns on two open-source LLM models shows that Preble outperforms the state-of-the-art average latency by 1.5X to 14.5X and p99 by 2X to 10X.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Inference Performance Optimization for LLMs on CPUs</title>
<link>https://arxiv.org/abs/2407.00029</link>
<guid>https://arxiv.org/abs/2407.00029</guid>
<content:encoded><![CDATA[
<div> 关键词：large language models (LLMs), distributed computing, resource-limited hardware, memory capacity, inference optimization.

总结:
本文介绍了一种针对大型语言模型（LLMs）的分布式推理优化解决方案，旨在缓解资源受限硬件设备上的内存限制和提高计算性能。该方法特别适用于部署在5代Intel Xeon Scalable处理器上。实验结果显示，使用72亿参数的LLM，通过优化后的方案，每输出一个令牌的时间降低到140毫秒，远低于人类阅读的平均速度（约200毫秒/令牌），显著提高了效率。这一成果表明分布式计算在有效利用CPU资源、扩展LLM应用中具有重要价值。 <div>
arXiv:2407.00029v1 Announce Type: new 
Abstract: Large language models (LLMs) hold tremendous potential for addressing numerous real-world challenges, yet they typically demand significant computational resources and memory. Deploying LLMs onto a resource-limited hardware device with restricted memory capacity presents considerable challenges. Distributed computing emerges as a prevalent strategy to mitigate single-node memory constraints and expedite LLM inference performance. To reduce the hardware limitation burden, we proposed an efficient distributed inference optimization solution for LLMs on CPUs. We conduct experiments with the proposed solution on 5th Gen Intel Xeon Scalable Processors, and the result shows the time per output token for the LLM with 72B parameter is 140 ms/token, much faster than the average human reading speed about 200ms per token.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On Orchestrating Parallel Broadcasts for Distributed Ledgers</title>
<link>https://arxiv.org/abs/2407.00030</link>
<guid>https://arxiv.org/abs/2407.00030</guid>
<content:encoded><![CDATA[
<div> 关键词：ticketing, atomic broadcasts, distributed system, managed ticketing, unmanaged ticketing

总结:<br />本文主要探讨了“票证”(ticketing)的概念在分布式系统中对原子广播的组织。文章研究了不同类型的票证制度，允许并行执行但防止慢节点影响整体进度。一种混合方案被提出，结合了管理和未管理的票证模式，旨在平衡适应性和鲁棒性。性能评估显示，无论是静态还是动态场景，资源异构的系统中，管理票证制度对吞吐量有优势，因为它能更好地适应。最后，实验表明，使用混合票证制度可以同时享受管理票证的适应性与未管理票证的活度保证。 <div>
arXiv:2407.00030v1 Announce Type: new 
Abstract: This paper introduces and develops the concept of ``ticketing'', through which atomic broadcasts are orchestrated by nodes in a distributed system. The paper studies different ticketing regimes that allow parallelism, yet prevent slow nodes from hampering overall progress. It introduces a hybrid scheme which combines managed and unmanaged ticketing regimes, striking a balance between adaptivity and resilience. The performance evaluation demonstrates how managed and unmanaged ticketing regimes benefit throughput in systems with heterogeneous resources both in static and dynamic scenarios, with the managed ticketing regime performing better among the two as it adapts better. Finally, it demonstrates how using the hybrid ticketing regime performance can enjoy both the adaptivity of the managed regime and the liveness guarantees of the unmanaged regime.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Systems in Fintech</title>
<link>https://arxiv.org/abs/2407.00034</link>
<guid>https://arxiv.org/abs/2407.00034</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统、金融技术（Fintech）、区块链、去中心化金融（DeFi）、分布式 ledger technology (DLT)

总结:<br />
分布式系统在Fintech中的作用日益凸显，推动了行业革新。本文分析了分布式系统的架构，如区块链、DeFi和DLT，它们在提升金融操作的安全性、可扩展性和效率方面展现出巨大潜力。文章深入探讨了这些技术如何影响金融服务、支付、资产管理等，并展望了未来分布式系统在Fintech领域的广阔前景。随着技术不断发展，分布式系统有望重塑金融行业的版图。 <div>
arXiv:2407.00034v1 Announce Type: new 
Abstract: The emergence of distributed systems has revolutionized the financial technology (Fintech) landscape, offering unprecedented opportunities for enhancing security, scalability, and efficiency in financial operations. This paper explores the role of distributed systems in Fintech, analyzing their architecture, benefits, challenges, and applications. It examines key distributed technologies such as blockchain, decentralized finance (DeFi), and distributed ledger technology (DLT), and their impact on various aspects of the financial industry, and future directions for distributed systems in Fintech.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Streamline Intelligent Crowd Monitoring with IoT Cloud Computing Middleware</title>
<link>https://arxiv.org/abs/2407.00045</link>
<guid>https://arxiv.org/abs/2407.00045</guid>
<content:encoded><![CDATA[
<div> 关键词：middleware, Raspberry Pi, wireless sensor networks (WSNs), MapReduce, fault tolerance

总结:<br />
本文介绍了一种新颖的中间件系统，它利用低成本、低功耗的设备如Raspberry Pi分析无线传感器网络（WSN）的数据。该系统针对室内环境，如历史建筑和博物馆，用于监控访客、识别兴趣点并作为疏散辅助工具。通过MapReduce算法收集和分布数据，结合故障容忍的领导选举算法，其性能与资源密集型方法相当，但使用简单硬件。在希腊一处历史建筑（哈茨迪亚基斯故居）进行了成功测试。与现有实现相比，这种设计的优势在于其经济、分布式且具有故障恢复能力。尤其在COVID-19大流行期间，这种中间件对于室内位置的监控具有重要意义，能有效追踪访客数量和整体建筑占用率。 <div>
arXiv:2407.00045v1 Announce Type: new 
Abstract: This article introduces a novel middleware that utilizes cost-effective, low-power computing devices like Raspberry Pi to analyze data from wireless sensor networks (WSNs). It is designed for indoor settings like historical buildings and museums, tracking visitors and identifying points of interest. It serves as an evacuation aid by monitoring occupancy and gauging the popularity of specific areas, subjects, or art exhibitions. The middleware employs a basic form of the MapReduce algorithm to gather WSN data and distribute it across available computer nodes. Data collected by RFID sensors on visitor badges is stored on mini-computers placed in exhibition rooms and then transmitted to a remote database after a preset time frame. Utilizing MapReduce for data analysis and a leader election algorithm for fault tolerance, this middleware showcases its viability through metrics, demonstrating applications like swift prototyping and accurate validation of findings. Despite using simpler hardware, its performance matches resource-intensive methods involving audiovisual and AI techniques. This design's innovation lies in its fault-tolerant, distributed setup using budget-friendly, low-power devices rather than resource-heavy hardware or methods. Successfully tested at a historical building in Greece (M. Hatzidakis' residence), it is tailored for indoor spaces. This paper compares its algorithmic application layer with other implementations, highlighting its technical strengths and advantages. Particularly relevant in the wake of the COVID-19 pandemic and general monitoring middleware for indoor locations, this middleware holds promise in tracking visitor counts and overall building occupancy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Tracing Distributed Algorithms Using Replay Clocks</title>
<link>https://arxiv.org/abs/2407.00069</link>
<guid>https://arxiv.org/abs/2407.00069</guid>
<content:encoded><![CDATA[
<div> 关键词：replay clocks (RepCl), distributed computations, concurrent events, constraint violations, visualization.

总结:<br />
本文介绍了一种新的时钟基础设施——replay clocks (RepCl)，它旨在支持离线分析分布式计算。RepCl结合了向量时钟(VC)和混合逻辑时钟(HLC)的优势，提供高效重放功能，允许用户检查并发事件下的约束条件和潜在执行路径。文章强调了RepCl的低开销实现（最多4个整数表示64个进程）以及与同步时间的关系。通过模拟和NS-3网络模拟器，作者评估了RepCl的预期开销，并确定了其可行性的区域。此外，文中提出了一种基于RepCl的分布式计算追踪器，可实时分析系统的特性，同时考虑并发路径。这个可视化工具提供了逐进程和全局视图，便于深入理解计算过程。 <div>
arXiv:2407.00069v1 Announce Type: new 
Abstract: In this thesis, we introduce replay clocks (RepCl), a novel clock infrastructure that allows us to do offline analyses of distributed computations. The replay clock structure provides a methodology to replay a computation as it happened, with the ability to represent concurrent events effectively. It builds on the structures introduced by vector clocks (VC) and the Hybrid Logical Clock (HLC), combining their infrastructures to provide efficient replay. With such a clock, a user can replay a computation whilst considering multiple paths of executions, and check for constraint violations and properties that potential pathways could take in the presence of concurrent events. Specifically, if event e must occur before f then the replay clock must ensure that e is replayed before f. On the other hand, if e and f could occur in any order, replay should not force an order between them. We demonstrate that RepCl can be implemented with less than four integers for 64 processes for various system parameters if clocks are synchronized within 1ms. Furthermore, the overhead of RepCl (for computing timestamps and message size) is proportional to the size of the clock. Using simulations in a custom distributed system and NS-3, a state-of-the-art network simulator, we identify the expected overhead of RepCl. We also identify how a user can then identify feasibility region for RepCl, where unabridged replay is possible. Using the RepCl, we provide a tracer for distributed computations, that allows any computation using the RepCl to be replayed efficiently. The visualization allows users to analyze specific properties and constraints in an online fashion, with the ability to consider concurrent paths independently. The visualization provides per-process views and an overarching view of the whole computation based on the time recorded by the RepCl for each event.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Task Offloading and Load-Balancing for Mobile Edge Computing in Dense Networks</title>
<link>https://arxiv.org/abs/2407.00080</link>
<guid>https://arxiv.org/abs/2407.00080</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized task offloading, load-balancing, dense network, edge servers, mean field multi-agent MAB game.

总结:
该研究关注于密集网络中众多设备和边缘服务器之间的任务卸载与负载均衡问题。由于网络信息未知和任务大小随机，优化这一问题颇具挑战。论文提出了一种结合了多智能体多臂赌博（MAB）游戏的平均场方法，通过调整服务器奖励实现目标用户分布，即使在分布式决策制定下也能达到平衡。数值结果证明了这种方法的有效性，并展示了其能导向目标负载分布。 <div>
arXiv:2407.00080v1 Announce Type: new 
Abstract: We study the problem of decentralized task offloading and load-balancing in a dense network with numerous devices and a set of edge servers. Solving this problem optimally is complicated due to the unknown network information and random task sizes. The shared network resources also influence the users' decisions and resource distribution. Our solution combines the mean field multi-agent multi-armed bandit (MAB) game with a load-balancing technique that adjusts the servers' rewards to achieve a target population profile despite the distributed user decision-making. Numerical results demonstrate the efficacy of our approach and the convergence to the target load distribution.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges</title>
<link>https://arxiv.org/abs/2407.00147</link>
<guid>https://arxiv.org/abs/2407.00147</guid>
<content:encoded><![CDATA[
<div> 关键词：数据挖掘、医院化、急诊部门、预测准确性、诊断错误。

总结: 这篇文章探讨了如何利用数据挖掘技术分析大型医院化数据，以预测患者在急诊部门出院后可能的早期住院。通过组合运用逻辑回归、朴素贝叶斯和关联规则分类器，研究者实现了对3天、7天和14天内住院的高精度预测。这种方法不仅准确，而且生成的可解释模型便于医生理解，规则可以直接转化为实践中的决策工具，帮助他们在患者出院前识别潜在的早期住院风险，从而改善诊断质量和患者安全。 <div>
arXiv:2407.00147v1 Announce Type: new 
Abstract: Hospitalizations that follow closely on the heels of one or more emergency department visits are often symptoms of missed opportunities to form a proper diagnosis. These diagnostic errors imply a failure to recognize the need for hospitalization and deliver appropriate care, and thus also bear important connotations for patient safety. In this paper, we show how data mining techniques can be applied to a large existing hospitalization data set to learn useful models that predict these upcoming hospitalizations with high accuracy. Specifically, we use an ensemble of logistics regression, na\"ive Bayes and association rule classifiers to successfully predict hospitalization within 3, 7 and 14 days of an emergency department discharge. Aside from high accuracy, one of the advantages of the techniques proposed here is that the resulting classifier is easily inspected and interpreted by humans so that the learned rules can be readily operationalized. These rules can then be easily distributed and applied directly by physicians in emergency department settings to predict the risk of early admission prior to discharging their emergency department patients.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dual-view Aware Smart Contract Vulnerability Detection for Ethereum</title>
<link>https://arxiv.org/abs/2407.00336</link>
<guid>https://arxiv.org/abs/2407.00336</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、smart contracts、vulnerability detection、Dual-view Aware、DVDet。

总结:<br />
本文介绍了一种名为DVDet的双视图智能合约漏洞检测框架。该框架针对以太坊智能合约的源代码和字节码，通过转化为加权图和控制流序列，从两个视角捕捉潜在风险特征并整合分析，以提高合同漏洞检测的效率和准确性。实验结果显示，DVDet在检测智能合约漏洞方面表现出色，超越了其他方法，为区块链技术的安全性提供了有力支持。 <div>
arXiv:2407.00336v1 Announce Type: new 
Abstract: The wide application of Ethereum technology has brought technological innovation to traditional industries. As one of Ethereum's core applications, smart contracts utilize diverse contract codes to meet various functional needs and have gained widespread use. However, the non-tamperability of smart contracts, coupled with vulnerabilities caused by natural flaws or human errors, has brought unprecedented challenges to blockchain security. Therefore, in order to ensure the healthy development of blockchain technology and the stability of the blockchain community, it is particularly important to study the vulnerability detection techniques for smart contracts. In this paper, we propose a Dual-view Aware Smart Contract Vulnerability Detection Framework named DVDet. The framework initially converts the source code and bytecode of smart contracts into weighted graphs and control flow sequences, capturing potential risk features from these two perspectives and integrating them for analysis, ultimately achieving effective contract vulnerability detection. Comprehensive experiments on the Ethereum dataset show that our method outperforms others in detecting vulnerabilities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>C-MASS: Combinatorial Mobility-Aware Sensor Scheduling for Collaborative Perception with Second-Order Topology Approximation</title>
<link>https://arxiv.org/abs/2407.00412</link>
<guid>https://arxiv.org/abs/2407.00412</guid>
<content:encoded><![CDATA[
<div> 关键词：Collaborative Perception, Sensor Scheduling, Combinatorial Mobility-Aware, Budgeted Maximum Coverage, Wireless Bandwidth.

总结:<br />该论文关注于协作感知(Collaborative Perception, CP)中如何有效利用有限的无线带宽。传统的传感器调度面临车辆移动带来的感知拓扑不确定性挑战。为此，作者提出了一种名为C-MASS的框架，通过组合单辆车和车对的数据来近似完整感知拓扑，减少通信开销。C-MASS采用一种混合贪婪算法解决带预算的最大覆盖问题，兼顾探索与利用，以应对移动性问题。实验结果表明，C-MASS在边缘辅助和分布式配置下接近最优，相较于基于距离和区域的贪心策略，性能提升明显。 <div>
arXiv:2407.00412v1 Announce Type: new 
Abstract: Collaborative Perception (CP) has been a promising solution to address occlusions in the traffic environment by sharing sensor data among collaborative vehicles (CoV) via vehicle-to-everything (V2X) network. With limited wireless bandwidth, CP necessitates task-oriented and receiver-aware sensor scheduling to prioritize important and complementary sensor data. However, due to vehicular mobility, it is challenging and costly to obtain the up-to-date perception topology, i.e., whether a combination of CoVs can jointly detect an object. In this paper, we propose a combinatorial mobility-aware sensor scheduling (C-MASS) framework for CP with minimal communication overhead. Specifically, detections are replayed with sensor data from individual CoVs and pairs of CoVs to maintain an empirical perception topology up to the second order, which approximately represents the complete perception topology. A hybrid greedy algorithm is then proposed to solve a variant of the budgeted maximum coverage problem with a worst-case performance guarantee. The C-MASS scheduling algorithm adapts the greedy algorithm by incorporating the topological uncertainty and the unexplored time of CoVs to balance exploration and exploitation, addressing the mobility challenge. Extensive numerical experiments demonstrate the near-optimality of the proposed C-MASS framework in both edge-assisted and distributed CP configurations. The weighted recall improvements over object-level CP are 5.8% and 4.2%, respectively. Compared to distance-based and area-based greedy heuristics, the gaps to the offline optimal solutions are reduced by up to 75% and 71%, respectively.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Data-Driven Control of Linear Parabolic Systems using Koopman Eigenstructure Assignment</title>
<link>https://arxiv.org/abs/2407.00432</link>
<guid>https://arxiv.org/abs/2407.00432</guid>
<content:encoded><![CDATA[
<div> 关键词：Koopman operator, data-driven, stabilization, parabolic PDEs, eigenstructure assignment.

总结:<br />
本文探讨了如何利用Koopman算子实现线性边界控制下抛物型PDE系统的数据驱动稳定化。研究的核心内容是解决Koopman特征向量赋值问题，即设计一个反馈控制器，使其能设定期望的有限组闭合环Koopman特征值和特征函数。这个控制器依赖于扩展的Krylov-DMD方法来处理抛物型系统，仅需有限数量的采样输出和输入数据。文章证明了在小的Krylov-DMD误差下，闭环系统是指数稳定的。最后，通过一个不稳定的扩散-反应系统的例子，验证了这种适用于分布式参数系统的新型数据驱动控制器设计技术。 <div>
arXiv:2407.00432v1 Announce Type: new 
Abstract: This paper considers the data-driven stabilization of linear boundary controlled parabolic PDEs by making use of the Koopman operator. For this, a Koopman eigenstructure assignment problem is solved, which amounts to determine a feedback of the Koopman open-loop eigenfunctionals assigning a desired finite set of closed-loop Koopman eigenvalues and eigenfunctionals to the closed-loop system. It is shown that the designed controller only needs a finite number of open-loop Koopman eigenvalues and modes of the state. They are determined by extending the classical Krylov-DMD to parabolic systems. For this, only a finite number of pointlike outputs and their temporal samples as well as temporal samples of the inputs are required resulting in a data-driven solution of the eigenstructure assignment problem. Exponential stability of the closed-loop system in the presence of small Krylov-DMD errors is verified. An unstable diffusion-reaction system demonstrates the new data-driven controller design technique for distributed-parameter systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Graph Neural Networks Gone Hogwild</title>
<link>https://arxiv.org/abs/2407.00494</link>
<guid>https://arxiv.org/abs/2407.00494</guid>
<content:encoded><![CDATA[
<div> 关键词：message passing GNNs, asynchronous inference, implicitly-defined GNNs, energy GNN, multi-agent systems.

总结:<br />
本文探讨了图神经网络（GNN）在异步推理时的性能问题，发现普通GNN架构在节点更新不同时会导致错误预测。为解决这一问题，作者提出了"隐式定义"的GNN类别，其中一种名为能量GNN的新架构特别受关注。这种架构基于异步优化的理论，如Bertsekas（1982）和Niu等人（2011）的工作，具有对部分异步" hogwild"推理的稳健性。实验表明，能量GNN在多智能体系统相关的合成任务上优于同类GNN，并在现实世界数据集上表现出竞争力。 <div>
arXiv:2407.00494v1 Announce Type: new 
Abstract: Message passing graph neural networks (GNNs) would appear to be powerful tools to learn distributed algorithms via gradient descent, but generate catastrophically incorrect predictions when nodes update asynchronously during inference. This failure under asynchrony effectively excludes these architectures from many potential applications, such as learning local communication policies between resource-constrained agents in, e.g., robotic swarms or sensor networks. In this work we explore why this failure occurs in common GNN architectures, and identify "implicitly-defined" GNNs as a class of architectures which is provably robust to partially asynchronous "hogwild" inference, adapting convergence guarantees from work in asynchronous and distributed optimization, e.g., Bertsekas (1982); Niu et al. (2011). We then propose a novel implicitly-defined GNN architecture, which we call an energy GNN. We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems, and achieves competitive performance on real-world datasets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain based Decentralized Petition System</title>
<link>https://arxiv.org/abs/2407.00534</link>
<guid>https://arxiv.org/abs/2407.00534</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized online petition system, blockchain technology, transparency, voting platform, integrity

总结:
本文探讨了一种基于区块链技术的去中心化在线请愿系统，旨在克服现有系统在透明度、安全性和信任度上的不足。该系统通过区块链记录每个签名和行动，确保过程不可篡改，支持民主决策的民主化。文章还提出了一个基于区块链的去中心化投票应用，设计考虑了系统架构、透明计票机制以及消除中心权威的需求。研究着重于技术实现的细节，如算法和协议，目标是提升民主流程的公正性、安全性和防篡改能力。未来的研究将深入技术层面，以进一步优化这一创新平台。 <div>
arXiv:2407.00534v1 Announce Type: new 
Abstract: A decentralized online petition system enables individuals or groups to create, sign, and share petitions without a central authority. Using blockchain technology, these systems ensure the integrity and transparency of the petition process by recording every signature or action on the blockchain, making alterations or deletions impossible. This provides a permanent, tamper-proof record of the petition's progress. Such systems allow users to bypass traditional intermediaries like government or social media platforms, fostering more democratic and transparent decision-making.
  This paper reviews research on petition systems, highlighting the shortcomings of existing systems such as lack of accountability, vulnerability to hacking, and security issues. The proposed blockchain-based implementation aims to overcome these challenges. Decentralized voting systems have garnered interest recently due to their potential to provide secure and transparent voting platforms without intermediaries, addressing issues like voter fraud, manipulation, and trust in the electoral process.
  We propose a decentralized voting system web application using blockchain technology to ensure the integrity and security of the voting process. This system aims to provide a transparent, decentralized decision-making process that counts every vote while eliminating the need for centralized authorities. The paper presents an overview of the system architecture, design considerations, and implementation details, along with the potential benefits and limitations.
  Finally, we discuss future research directions, examining the technical aspects of the application, including underlying algorithms and protocols. Our research aims to enhance the integrity and accessibility of democratic processes, improve security, and ensure fairness, transparency, and tamper-proofness.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Challenging the Need for Packet Spraying in Large-Scale Distributed Training</title>
<link>https://arxiv.org/abs/2407.00550</link>
<guid>https://arxiv.org/abs/2407.00550</guid>
<content:encoded><![CDATA[
<div> 关键词：large-scale distributed training, network communication, packet spraying, singlepath transport, multipath transport.

总结:<br />该论文质疑了业界普遍接受的观点，即在大规模分布式训练中，多路径传输和包喷射对于提升性能至关重要。研究者发现，单路径传输（从网卡角度看）实际上可以接近理想的多路径传输效果。他们通过分析集体通信模式驱动的工作负载的四个关键特性得出这一结论：同时启动的流量、近似的等量流量、集体完成时间更重要以及流量可以在到达时分割。作者证明，应用层少量的流量分割使得单路径传输在最大拥塞方面与理想多路径传输和包喷射相当。初步评估支持这些发现，提出研发针对大规模分布式训练的下一代传输协议的新方向。 <div>
arXiv:2407.00550v1 Announce Type: new 
Abstract: Large-scale distributed training in production datacenters constitutes a challenging workload bottlenecked by network communication. In response, both major industry players (e.g., Ultra Ethernet Consortium) and parts of academia have surprisingly, and almost unanimously, agreed that packet spraying is necessary to improve the performance of large-scale distributed training workloads.
  In this paper, we challenge this prevailing belief and pose the question: How close can a singlepath transport approach an optimal multipath transport? We demonstrate that singlepath transport (from a NIC's perspective) is sufficient and can perform nearly as well as an ideal multipath transport with packet spraying, particularly in the context of distributed training in leaf-spine topologies. Our assertion is based on four key observations about workloads driven by collective communication patterns: (i) flows within a collective start almost simultaneously, (ii) flow sizes are nearly equal, (iii) the completion time of a collective is more crucial than individual flow completion times, and (iv) flows can be split upon arrival. We analytically prove that singlepath transport, using minimal flow splitting (at the application layer), is equivalent to an ideal multipath transport with packet spraying in terms of maximum congestion. Our preliminary evaluations support our claims. This paper suggests an alternative agenda for developing next-generation transport protocols tailored for large-scale distributed training.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Joint Task Allocation and Scheduling for Multi-Hop Distributed Computing</title>
<link>https://arxiv.org/abs/2407.00565</link>
<guid>https://arxiv.org/abs/2407.00565</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Things, Edge Computing, Distributed Computing, Master-Worker Paradigm, Multi-hop Routing

总结:<br />该论文探讨了物联网和边缘计算时代分布式计算的新框架，突破传统的一跳范围限制。研究提出将网络图转换为沉降树结构，通过联合优化任务分配和调度，实现跨多层节点的资源共享。论文提供了两种精确算法和三种启发式策略来解决这一问题。实验结果显示，新方法在有限资源、动态连通性和延迟敏感应用中表现出色，优于传统策略。总的来说，这项工作扩展了分布式计算的适用性，提升了计算效率。 <div>
arXiv:2407.00565v1 Announce Type: new 
Abstract: The rise of the Internet of Things and edge computing has shifted computing resources closer to end-users, benefiting numerous delay-sensitive, computation-intensive applications. To speed up computation, distributed computing is a promising technique that allows parallel execution of tasks across multiple compute nodes. However, current research predominantly revolves around the master-worker paradigm, limiting resource sharing within one-hop neighborhoods. This limitation can render distributed computing ineffective in scenarios with limited nearby resources or constrained/dynamic connectivity. In this paper, we address this limitation by introducing a new distributed computing framework that extends resource sharing beyond one-hop neighborhoods through exploring layered network structures and multi-hop routing. Our framework involves transforming the network graph into a sink tree and formulating a joint optimization problem based on the layered tree structure for task allocation and scheduling. To solve this problem, we propose two exact methods that find optimal solutions and three heuristic strategies to improve efficiency and scalability. The performances of these methods are analyzed and evaluated through theoretical analyses and comprehensive simulation studies. The results demonstrate their promising performances over the traditional distributed computing and computation offloading strategies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DDRM: Distributed Drone Reputation Management for Trust and Reliability in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2407.00591</link>
<guid>https://arxiv.org/abs/2407.00591</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Drone Reputation Management (DDRM), Internet of Drone Things (IoDT), Ethereum blockchain, Service Review Authorization Token (SRAT), Drone Reputation Enhancement Token (DRET)

总结:<br />
分布式无人机信誉管理系统（DDRM）是一项针对互联网无人机事物（IoDT）生态的创新框架。它利用以太坊区块链构建一个可验证的透明评论机制，旨在提升无人机服务的信任度。DDRM采用双币系统，包括服务审查授权令牌（SRAT）用于权限管理，以及无人机声誉增强令牌（DRET）以奖励表现可靠的无人机。研究证明，DDRM能够抵御欺诈行为，有效提高无人机服务的效率和可靠性，为无人机服务民主化提供保障。 <div>
arXiv:2407.00591v1 Announce Type: new 
Abstract: This study introduces the Distributed Drone Reputation Management (DDRM) framework, designed to fortify trust and authenticity within the Internet of Drone Things (IoDT) ecosystem. As drones increasingly play a pivotal role across diverse sectors, integrating crowdsourced drone services within the IoDT has emerged as a vital avenue for democratizing access to these services. A critical challenge, however, lies in ensuring the authenticity and reliability of drone service reviews. Leveraging the Ethereum blockchain, DDRM addresses this challenge by instituting a verifiable and transparent review mechanism. The framework innovates with a dual-token system, comprising the Service Review Authorization Token (SRAT) for facilitating review authorization and the Drone Reputation Enhancement Token (DRET) for rewarding and recognizing drones demonstrating consistent reliability. Comprehensive analysis within this paper showcases DDRM's resilience against various reputation frauds and underscores its operational effectiveness, particularly in enhancing the efficiency and reliability of drone services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BAZAM: A Blockchain-Assisted Zero-Trust Authentication in Multi-UAV Wireless Networks</title>
<link>https://arxiv.org/abs/2407.00630</link>
<guid>https://arxiv.org/abs/2407.00630</guid>
<content:encoded><![CDATA[
<div> 关键词：Unmanned Aerial Vehicles (UAVs), Zero-trust framework, Blockchain, Authentication scheme, Physical Unclonable Functions (PUFs).

总结:<br />本文主要探讨了无人驾驶航空器(UAVs)网络中的身份验证问题。针对传统身份认证的不足，如系统中心化、无法适应多样的UAV身份和访问需求，以及缺乏持续的身份合规检查，作者提出了一种基于区块链的零信任身份验证方案BAZAM。该方案利用物理不可克隆功能(PUFs)生成密钥，并借助加密技术验证UAV的注册和访问请求，同时通过区块链实现UAV身份信息的永久存储。文章详细分析了BAZAM的安全性和效率，并通过实验验证其有效性。 <div>
arXiv:2407.00630v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) are vulnerable to interception and attacks when operated remotely without a unified and efficient identity authentication. Meanwhile, the openness of wireless communication environments potentially leads to data leakage and system paralysis. However, conventional authentication schemes in the UAV network are system-centric, failing to adapt to the diversity of UAVs identities and access, resulting in changes in network environments and connection statuses. Additionally, UAVs are not subjected to periodic identity compliance checks once authenticated, leading to difficulties in controlling access anomalies. Therefore, in this work, we consider a zero-trust framework for UAV network authentication, aiming to achieve UAVs identity authentication through the principle of ``never trust and always verify''. We introduce a blockchain-assisted zero-trust authentication scheme, namely BAZAM, designed for multi-UAV wireless networks. In this scheme, UAVs follow a key generation approach using physical unclonable functions (PUFs), and cryptographic technique helps verify registration and access requests of UAVs. The blockchain is applied to store UAVs authentication information in immutable storage. Through thorough security analysis and extensive evaluation, we demonstrate the effectiveness and efficiency of the proposed BAZAM.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Field Knowledge as a Dual to Distributed Knowledge: A Characterization by Weighted Modal Logic</title>
<link>https://arxiv.org/abs/2407.00687</link>
<guid>https://arxiv.org/abs/2407.00687</guid>
<content:encoded><![CDATA[
<div> 关键词：group knowledge, distributed knowledge, field knowledge, epistemic logic, weighted models

总结:<br />本文探讨了群体知识概念，如相互知识、共同知识和分布式知识在认识逻辑中的应用。作者提出将认知能力纳入分布式知识的定义，并引入了场知识的概念，作为分布式知识的对立面。研究基于带有不同群体知识构造的识别模型（weighted models），发展了八种逻辑系统，并分析了它们的表达力。文章通过形式化的方法，提供了关于这些逻辑系统的完备的公理体系。 <div>
arXiv:2407.00687v1 Announce Type: new 
Abstract: The study of group knowledge concepts such as mutual, common, and distributed knowledge is well established within the discipline of epistemic logic. In this work, we incorporate epistemic abilities of agents to refine the formal definition of distributed knowledge and introduce a formal characterization of field knowledge. We propose that field knowledge serves as a dual to distributed knowledge. Our approach utilizes epistemic logics with various group knowledge constructs, interpreted through weighted models. We delve into the eight logics that stem from these considerations, explore their relative expressivity and develop sound and complete axiomatic systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A posteriori error estimator for elliptic interface problems in the fictitious formulation</title>
<link>https://arxiv.org/abs/2407.00786</link>
<guid>https://arxiv.org/abs/2407.00786</guid>
<content:encoded><![CDATA[
<div> 关键词：a posteriori error estimator, elliptic interface problem, fictitious domain formulation, discontinuous Lagrange multiplier, adaptive algorithm.

总结:<br />
本文研究了一种针对椭圆界面问题的后验误差估计器，该问题采用虚域方法和分布拉格朗日乘子处理，且考虑了不连续拉格朗日乘子有限元素空间。理论部分探讨了常数系数和光滑系数跳跃情况下的误差估计，证明了其可靠性和效率。数值实验通过不同几何嵌入和大系数跳跃实例验证了理论结果，展示了适应性算法的有效性。计算结果显示，误差估计器在处理几何奇异性或系数跳跃时表现出最优收敛特性。 <div>
arXiv:2407.00786v1 Announce Type: new 
Abstract: A posteriori error estimator is derived for an elliptic interface problem in the fictitious domain formulation with distributed Lagrange multiplier considering a discontinuous Lagrange multiplier finite element space. A posteriori error estimation plays a pivotal role in assessing the accuracy and reliability of computational solutions across various domains of science and engineering. This study delves into the theoretical underpinnings and computational considerations of a residual-based estimator.
  Theoretically, the estimator is studied for cases with constant coefficients which jump across an interface as well as generalized scenarios with smooth coefficients that jump across an interface. Theoretical findings demonstrate the reliability and efficiency of the proposed estimators under all considered cases.
  Numerical experiments are conducted to validate the theoretical results, incorporating various immersed geometries and instances of high coefficients jumps at the interface. Leveraging an adaptive algorithm, the estimator identifies regions with singularities and applies refinement accordingly. Results substantiate the theoretical findings, highlighting the reliability and efficiency of the estimators. Furthermore, numerical solutions exhibit optimal convergence properties, demonstrating resilience against geometric singularities or coefficients jumps.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-Aware Spectrum Pricing and Power Control Optimization for LEO Satellite Internet-of-Things</title>
<link>https://arxiv.org/abs/2407.00814</link>
<guid>https://arxiv.org/abs/2407.00814</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)、satellite systems、IoT、federated learning (FL)、blockchain

总结:<br />该论文关注低地球轨道(LEO)卫星系统在物联网(IoT)中的应用，探讨了如何通过结合区块链技术和联邦学习(FL)来解决复杂谱资源管理问题。首先，提出了一种基于深度强化学习的本地算法，以优化卫星的定价和功率控制策略，以最大化收入。其次，构建了一个去中心化的FL系统，利用区块链技术实现数据隐私保护。通过声誉机制，确保模型聚合和区块生成的信任度。最后，实验结果显示，该方法既能有效提高LEO卫星系统的收益，又能保护用户隐私。总的来说，研究者提出了一个创新的框架，旨在提升LEO卫星IoT的运营效率和隐私保护。 <div>
arXiv:2407.00814v1 Announce Type: new 
Abstract: Low earth orbit (LEO) satellite systems play an important role in next generation communication networks due to their ability to provide extensive global coverage with guaranteed communications in remote areas and isolated areas where base stations cannot be cost-efficiently deployed. With the pervasive adoption of LEO satellite systems, especially in the LEO Internet-of-Things (IoT) scenarios, their spectrum resource management requirements have become more complex as a result of massive service requests and high bandwidth demand from terrestrial terminals. For instance, when leasing the spectrum to terrestrial users and controlling the uplink transmit power, satellites collect user data for machine learning purposes, which usually are sensitive information such as location, budget and quality of service (QoS) requirement. To facilitate model training in LEO IoT while preserving the privacy of data, blockchain-driven federated learning (FL) is widely used by leveraging on a fully decentralized architecture. In this paper, we propose a hybrid spectrum pricing and power control framework for LEO IoT by combining blockchain technology and FL. We first design a local deep reinforcement learning algorithm for LEO satellite systems to learn a revenue-maximizing pricing and power control scheme. Then the agents collaborate to form a FL system. We also propose a reputation-based blockchain which is used in the global model aggregation phase of FL. Based on the reputation mechanism, a node is selected for each global training round to perform model aggregation and block generation, which can further enhance the decentralization of the network and guarantee the trust. Simulation tests are conducted to evaluate the performances of the proposed scheme. Our results show the efficiency of finding the maximum revenue scheme for LEO satellite systems while preserving the privacy of each agent.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-First Crowdsourcing: Blockchain and Local Differential Privacy in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2407.00873</link>
<guid>https://arxiv.org/abs/2407.00873</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、无人机、数据集成、本地差分隐私、区块链。

总结:<br />
本文介绍了一种新的隐私保护框架，旨在将消费级无人机融入丛林火灾管理。该系统通过本地差分隐私技术确保数据提供者的隐私安全，利用区块链技术保证公平的数据交换和责任追踪。文章以原型实现验证了其在大规模数据收集场景中的可行性和扩展性。这一解决方案符合澳大利亚《1988年隐私法》等法规，为通过众包无人机服务提升丛林火灾检测与管理提供了实用途径。 <div>
arXiv:2407.00873v1 Announce Type: new 
Abstract: We introduce a privacy-preserving framework for integrating consumer-grade drones into bushfire management. This system creates a marketplace where bushfire management authorities obtain essential data from drone operators. Key features include local differential privacy to protect data providers and a blockchain-based solution ensuring fair data exchanges and accountability. The framework is validated through a proof-of-concept implementation, demonstrating its scalability and potential for various large-scale data collection scenarios. This approach addresses privacy concerns and compliance with regulations like Australia's Privacy Act 1988, offering a practical solution for enhancing bushfire detection and management through crowdsourced drone services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized PKI Framework for Data Integrity in Spatial Crowdsourcing Drone Services</title>
<link>https://arxiv.org/abs/2407.00876</link>
<guid>https://arxiv.org/abs/2407.00876</guid>
<content:encoded><![CDATA[
<div> 关键词：Spatial Crowdsourcing, D2XChain, Blockchain-based PKI, Internet of Drone Things (IoDT), X.509 standard.

总结:<br />
本文主要关注的是无人机服务领域的网络安全，特别是针对空间众包无人机任务（如配送、监控和数据收集）中的通信安全。文章提出了D2XChain，一种基于区块链的公钥基础设施（PKI）框架，旨在解决传统PKI中集中式信任模型的单点故障问题。D2XChain通过去中心化CA（证书权威机构）实现了分布式操作，支持X.509标准，涵盖证书注册、验证、核查和撤销等关键操作。它增强了无人机通信的安全性和可靠性，尤其在私有以太坊测试环境中成功部署，为无人机服务，特别是关键任务下的可信运营提供了创新且实用的解决方案。 <div>
arXiv:2407.00876v1 Announce Type: new 
Abstract: In the domain of spatial crowdsourcing drone services, which includes tasks like delivery, surveillance, and data collection, secure communication is paramount. The Public Key Infrastructure (PKI) ensures this by providing a system for digital certificates that authenticate the identities of entities involved, securing data and command transmissions between drones and their operators. However, the centralized trust model of traditional PKI, dependent on Certificate Authorities (CAs), presents a vulnerability due to its single point of failure, risking security breaches. To counteract this, the paper presents D2XChain, a blockchain-based PKI framework designed for the Internet of Drone Things (IoDT). By decentralizing the CA infrastructure, D2XChain eliminates this single point of failure, thereby enhancing the security and reliability of drone communications. Fully compatible with the X.509 standard, it integrates seamlessly with existing PKI systems, supporting all key operations such as certificate registration, validation, verification, and revocation in a distributed manner. This innovative approach not only strengthens the defense of drone services against various security threats but also showcases its practical application through deployment on a private Ethereum testbed, representing a significant advancement in addressing the unique security challenges of drone-based services and ensuring their trustworthy operation in critical tasks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Ares II: Tracing the Flaws of a (Storage) God</title>
<link>https://arxiv.org/abs/2407.00881</link>
<guid>https://arxiv.org/abs/2407.00881</guid>
<content:encoded><![CDATA[
<div> 关键词：Ares, distributed shared memory, performance bottlenecks, optimizations, Ares II.

总结:<br />Ares是一个模块化的框架，旨在实现动态、可配置的分布式共享内存对象。最新版本通过版本化和数据条带技术支持大对象。研究者发现性能瓶颈并提出优化措施，包括piggyback机制、垃圾回收和批量重新配置，创建了优化版Ares II。该工作通过分布式追踪实验验证了Ares II的性能提升和存储效率改善，同时保持了正确性。 <div>
arXiv:2407.00881v1 Announce Type: new 
Abstract: Ares is a modular framework, designed to implement dynamic, reconfigurable, fault-tolerant, read/write and strongly consistent distributed shared memory objects. Recent enhancements of the framework have realized the efficient implementation of large objects, by introducing versioning and data striping techniques. In this work, we identify performance bottlenecks of the Ares's variants by utilizing distributed tracing, a popular technique for monitoring and profiling distributed systems. We then propose optimizations across all versions of Ares, aiming in overcoming the identified flaws, while preserving correctness. We refer to the optimized version of Ares as Ares II, which now features a piggyback mechanism, a garbage collection mechanism, and a batching reconfiguration technique for improving the performance and storage efficiency of the original Ares. We rigorously prove the correctness of Ares II, and we demonstrate the performance improvements by an experimental comparison (via distributed tracing) of the Ares II variants with their original counterparts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SplitLoRA: A Split Parameter-Efficient Fine-Tuning Framework for Large Language Models</title>
<link>https://arxiv.org/abs/2407.00952</link>
<guid>https://arxiv.org/abs/2407.00952</guid>
<content:encoded><![CDATA[
<div> 关键词：large language models, federated learning, split learning, SplitLoRA, benchmark

总结:<br />该研究关注的是大型语言模型（LLMs）的联邦学习（FL）和分割学习（SL）应用。面对LLMs对大量数据和计算资源的需求，文章提出SplitLoRA，一个首开源的SL LLM fine-tuning框架。它结合了FL的并行训练优势和SL的模型分割，以降低计算和通信压力，提高效率。SplitLoRA作为SL LLM调优的基准，旨在推动相关研究。实验结果表明，SplitLoRA在达到相同准确度时所需时间远少于现有方法，显示出其出色的训练性能。项目页面链接为https://fduinc.github.io/splitlora/。 <div>
arXiv:2407.00952v1 Announce Type: new 
Abstract: The scalability of large language models (LLMs) in handling high-complexity models and large-scale datasets has led to tremendous successes in pivotal domains. While there is an urgent need to acquire more training data for LLMs, a concerning reality is the depletion of high-quality public datasets within a few years. In view of this, the federated learning (FL) LLM fine-tuning paradigm recently has been proposed to facilitate collaborative LLM fine-tuning on distributed private data, where multiple data owners collaboratively fine-tune a shared LLM without sharing raw data. However, the staggering model size of LLMs imposes heavy computing and communication burdens on clients, posing significant barriers to the democratization of the FL LLM fine-tuning paradigm. To address this issue, split learning (SL) has emerged as a promising solution by offloading the primary training workload to a server via model partitioning while exchanging activation/activation's gradients with smaller data sizes rather than the entire LLM. Unfortunately, research on the SL LLM fine-tuning paradigm is still in its nascent stage. To fill this gap, in this paper, we propose the first SL LLM fine-tuning framework, named SplitLoRA. SplitLoRA is built on the split federated learning (SFL) framework, amalgamating the advantages of parallel training from FL and model splitting from SL and thus greatly enhancing the training efficiency. It is worth noting that SplitLoRA is the inaugural open-source benchmark for SL LLM fine-tuning, providing a foundation for research efforts dedicated to advancing SL LLM fine-tuning. Extensive simulations validate that SplitLoRA achieves target accuracy in significantly less time than state-of-the-art LLM fine-tuning frameworks, demonstrating the superior training performance of SplitLoRA. The project page is available at https://fduinc.github.io/splitlora/.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Parallel Computing Architectures for Robotic Applications: A Comprehensive Review</title>
<link>https://arxiv.org/abs/2407.01011</link>
<guid>https://arxiv.org/abs/2407.01011</guid>
<content:encoded><![CDATA[
<div> 关键词：parallel computing, robotics, real-time processing, sensor integration, control algorithms

总结:
本文探讨了在现代机器人系统中，日益增长的复杂性和功能需求对计算性能提出了更高的要求。传统的串行计算已难以满足，因此并行计算，如多核CPU、GPU、FPGA和分布式系统，因其能同时处理多个任务而成为解决之道。这些架构在实时图像处理、传感器融合和路径规划等方面显著提升机器人系统的性能。文章通过实例分析展示了并行计算在机器人技术中的潜力，同时也指出了挑战，如硬件与软件协同、能耗问题等，并提出未来研究方向。并行计算为推动机器人技术进步提供了强大的工具。 <div>
arXiv:2407.01011v1 Announce Type: new 
Abstract: With the growing complexity and capability of contemporary robotic systems, the necessity of sophisticated computing solutions to efficiently handle tasks such as real-time processing, sensor integration, decision-making, and control algorithms is also increasing. Conventional serial computing frequently fails to meet these requirements, underscoring the necessity for high-performance computing alternatives. Parallel computing, the utilization of several processing elements simultaneously to solve computational problems, offers a possible answer. Various parallel computing designs, such as multi-core CPUs, GPUs, FPGAs, and distributed systems, provide substantial enhancements in processing capacity and efficiency. By utilizing these architectures, robotic systems can attain improved performance in functionalities such as real-time image processing, sensor fusion, and path planning. The transformative potential of parallel computing architectures in advancing robotic technology has been underscored, real-life case studies of these architectures in the robotics field have been discussed, and comparisons are presented. Challenges pertaining to these architectures have been explored, and possible solutions have been mentioned for further research and enhancement of the robotic applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DistML.js: Installation-free Distributed Deep Learning Framework for Web Browsers</title>
<link>https://arxiv.org/abs/2407.01023</link>
<guid>https://arxiv.org/abs/2407.01023</guid>
<content:encoded><![CDATA[
<div> 关键词：DistML.js, web浏览器, 机器学习模型, 深度学习 API, WebGL

总结:<br />DistML.js是一个专为Web浏览器设计的机器学习库，支持本地训练和分布式学习。其API与PyTorch类似，便于原型开发，利用WebGL进行后台矩阵计算以实现高效运算。该库强调数据并行性，源代码开源。<br />DistML.js是用于浏览器的机器学习解决方案，易于使用，支持本地和服务器协作，通过WebGL加速计算，适合快速原型和实践深度学习项目。 <div>
arXiv:2407.01023v1 Announce Type: new 
Abstract: We present "DistML.js", a library designed for training and inference of machine learning models within web browsers. Not only does DistML.js facilitate model training on local devices, but it also supports distributed learning through communication with servers. Its design and define-by-run API for deep learning model construction resemble PyTorch, thereby reducing the learning curve for prototyping. Matrix computations involved in model training and inference are executed on the backend utilizing WebGL, enabling high-speed calculations. We provide a comprehensive explanation of DistML.js's design, API, and implementation, alongside practical applications including data parallelism in learning. The source code is publicly available at https://github.com/mil-tokyo/distmljs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Randomized linear solvers for computational architectures with straggling workers</title>
<link>https://arxiv.org/abs/2407.01098</link>
<guid>https://arxiv.org/abs/2407.01098</guid>
<content:encoded><![CDATA[
<div> 关键词：sparse system, iterative solution, partial matrix-vector product, random variable, convergence.

总结:<br />该论文探讨了在仅部分计算稀疏线性方程组系数矩阵的乘积时，迭代求解的问题。模型假设计算的元素数量及其行索引集是随机变量，且给定数量时行索引均匀分布。研究者提出了一种随机Richardson迭代法和Chebyshev半迭代法，并证明了它们在期望下的收敛条件。实验结果验证了理论和方法的有效性，尤其是在混合云架构的控制器-工作者分布式模型中，处理延迟（straggling workers）的情况。 <div>
arXiv:2407.01098v1 Announce Type: new 
Abstract: In this paper, we consider the iterative solution of sparse systems of linear algebraic equations under the condition that sparse matrix-vector products with the coefficient matrix are computed only partially. At the same time, non-computed entries are set to zeros. We assume that both the number of computed entries and their associated row index set are random variables, with the row index set sampled uniformly given the number of computed entries. This model of computations is prevalent to that realized in hybrid cloud computing architectures following the controller-worker distributed model under the influence of straggling workers. We propose a randomized Richardson iterative scheme and a randomized Chebyshev semi-iterative method within this model and prove the sufficient conditions for their convergence in expectation. Numerical experiments verify the presented theoretical results as well as the effectiveness of the proposed schemes on a few sparse matrix problems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FedRC: A Rapid-Converged Hierarchical Federated Learning Framework in Street Scene Semantic Understanding</title>
<link>https://arxiv.org/abs/2407.01103</link>
<guid>https://arxiv.org/abs/2407.01103</guid>
<content:encoded><![CDATA[
<div> 关键词：Street Scene Semantic Understanding, Hierarchical Federated Learning, Convergence Rate, Data Heterogeneity, Gaussian Distributions.

总结:<br />
本文提出了一种新的联邦学习框架FedRC，针对城市间数据异质性问题，旨在加速街景语义理解（TriSU）任务的模型收敛。FedRC通过将单张RGB图像和RGB数据集建模为高斯分布，区分每个样本并考虑数据量和统计特性，而非仅凭数据量决策，从而提高了HFL在复杂任务中的性能。实验结果显示，FedRC比现有基准快38.7%、37.5%、35.5%和40.6%的mIoU、mPrecision、mRecall和mF1，且在CARLA模拟环境中表现出色，展示了顶级性能。 <div>
arXiv:2407.01103v1 Announce Type: new 
Abstract: Street Scene Semantic Understanding (denoted as TriSU) is a crucial but complex task for world-wide distributed autonomous driving (AD) vehicles (e.g., Tesla). Its inference model faces poor generalization issue due to inter-city domain-shift. Hierarchical Federated Learning (HFL) offers a potential solution for improving TriSU model generalization, but suffers from slow convergence rate because of vehicles' surrounding heterogeneity across cities. Going beyond existing HFL works that have deficient capabilities in complex tasks, we propose a rapid-converged heterogeneous HFL framework (FedRC) to address the inter-city data heterogeneity and accelerate HFL model convergence rate. In our proposed FedRC framework, both single RGB image and RGB dataset are modelled as Gaussian distributions in HFL aggregation weight design. This approach not only differentiates each RGB sample instead of typically equalizing them, but also considers both data volume and statistical properties rather than simply taking data quantity into consideration. Extensive experiments on the TriSU task using across-city datasets demonstrate that FedRC converges faster than the state-of-the-art benchmark by 38.7%, 37.5%, 35.5%, and 40.6% in terms of mIoU, mPrecision, mRecall, and mF1, respectively. Furthermore, qualitative evaluations in the CARLA simulation environment confirm that the proposed FedRC framework delivers top-tier performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SCIF: A Language for Compositional Smart Contract Security</title>
<link>https://arxiv.org/abs/2407.01204</link>
<guid>https://arxiv.org/abs/2407.01204</guid>
<content:encoded><![CDATA[
<div> 关键词：SCIF、智能合约、安全、信息流、Solidity。

总结:<br />
SCIF是一种用于构建安全智能合约的语言，特别强调在与不可信代码协作时的安全性。它基于安全信息流原理，扩展机制以防御重入攻击、混淆副官攻击和错误处理问题，即使面对不遵守规则的恶意合约也能保护系统。SCIF支持动态信任管理，允许复杂生态中部分信任的主体交互。该语言已实现为Solidity编译器，提供静态检查规则和运行时支持。通过实施多个具有深度安全考虑的应用，SCIF展示了其在构建复杂智能合约中的有效性和对潜在安全漏洞的精确诊断能力。 <div>
arXiv:2407.01204v1 Announce Type: new 
Abstract: Securing smart contracts remains a fundamental challenge. At its core, it is about building software that is secure in composition with untrusted code, a challenge that extends far beyond blockchains. We introduce SCIF, a language for building smart contracts that are compositionally secure. SCIF is based on the fundamentally compositional principle of secure information flow, but extends this core mechanism to include protection against reentrancy attacks, confused deputy attacks, and improper error handling, even in the presence of malicious contracts that do not follow SCIF's rules. SCIF supports a rich ecosystem of interacting principals with partial trust through its mechanisms for dynamic trust management. SCIF has been implemented as a compiler to Solidity. We describe the SCIF language, including its static checking rules and runtime. Finally, we implement several applications with intricate security reasoning, showing how SCIF supports building complex smart contracts securely and gives programmer accurate diagnostics about potential security bugs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On the Parameters of Codes for Data Access</title>
<link>https://arxiv.org/abs/2407.01229</link>
<guid>https://arxiv.org/abs/2407.01229</guid>
<content:encoded><![CDATA[
<div> 关键词：coded distributed storage systems, alphabet size, servers, service rate region, code constructions.

总结:<br />该论文关注编码分布式存储系统中的关键问题，研究了两个方面：<br />1) 在固定字母大小下，确定最小服务器数量以保证服务速率区域包含特定点；<br />2) 对于给定服务器数，找出最小字母大小以满足相同条件。论文提供了严格的上界和下界，以及基于编码理论、优化和项目几何的代码构造方法。<br />通过这些方法，作者深入探讨了系统性能与设计参数之间的关系。 <div>
arXiv:2407.01229v1 Announce Type: new 
Abstract: This paper studies two crucial problems in the context of coded distributed storage systems directly related to their performance: 1) for a fixed alphabet size, determine the minimum number of servers the system must have for its service rate region to contain a prescribed set of points; 2) for a given number of servers, determine the minimum alphabet size for which the service rate region of the system contains a prescribed set of points. The paper establishes rigorous upper and lower bounds, as well as code constructions based on techniques from coding theory, optimization, and projective geometry.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Operational Semantics for Yul</title>
<link>https://arxiv.org/abs/2407.01365</link>
<guid>https://arxiv.org/abs/2407.01365</guid>
<content:encoded><![CDATA[
<div> 关键词：Yul、Solidity、EVM bytecode、operational semantics、small-step semantics

总结:<br />
本文介绍了一种针对Yul（Solidity编译器产生的EVM字节码的中间语言）的大步和小步操作语义，采用与编程语言文献相符的数学表示法，便于语言证明并作为精确易理解的语言规范。作者对原有非正式规范进行了澄清，并证明了两种语义之间的等价性。此外，他们实现了一个小型步态解释器，支持优化并经过测试。这项工作有望推动在Yul上开发验证和符号执行技术，增强以太坊安全体系，并为未来的类型系统提供坚实的理论基础。 <div>
arXiv:2407.01365v1 Announce Type: new 
Abstract: We present a big-step and small-step operational semantics for Yul -- the intermediate language used by the Solidity compiler to produce EVM bytecode -- in a mathematical notation that is congruous with the literature of programming languages, lends itself to language proofs, and can serve as a precise, widely accessible specification for the language. Our two semantics stay faithful to the original, informal specification of the language but also clarify under-specified cases such as void function calls. Our presentation allows us to prove the equivalence between the two semantics. We also implement the small-step semantics in an interpreter for Yul which avails of optimisations that are provably correct. We have tested the interpreter using tests from the Solidity compiler and our own. We envisage that this work will enable the development of verification and symbolic execution technology directly in Yul, contributing to the Ethereum security ecosystem, as well as aid the development of a provably sound future type system.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Beyond Throughput and Compression Ratios: Towards High End-to-end Utility of Gradient Compression</title>
<link>https://arxiv.org/abs/2407.01378</link>
<guid>https://arxiv.org/abs/2407.01378</guid>
<content:encoded><![CDATA[
<div> 关键词：gradient compression, distributed machine learning, training systems, acceleration, accuracy.

总结:
本文主要关注大规模分布式机器学习训练系统中的瓶颈——梯度聚合。作者发现先前的梯度压缩方案存在计算开销大、与all-reduce不兼容以及评估指标不合适等问题。为解决这些问题，作者提出改进设计和评估技术，包括降低计算负担、适应all-reduce通信方式以及采用更合适的端到端评价标准（如16位基线）。初步结果显示，这些技巧提升了系统的性能，有助于更准确地评估梯度压缩方法的实际效益。 <div>
arXiv:2407.01378v1 Announce Type: new 
Abstract: Gradient aggregation has long been identified as a major bottleneck in today's large-scale distributed machine learning training systems. One promising solution to mitigate such bottlenecks is gradient compression, directly reducing communicated gradient data volume. However, in practice, many gradient compression schemes do not achieve acceleration of the training process while also preserving accuracy.
  In this work, we identify several common issues in previous gradient compression systems and evaluation methods. These issues include excessive computational overheads; incompatibility with all-reduce; and inappropriate evaluation metrics, such as not using an end-to-end metric or using a 32-bit baseline instead of a 16-bit baseline. We propose several general design and evaluation techniques to address these issues and provide guidelines for future work. Our preliminary evaluation shows that our techniques enhance the system's performance and provide a clearer understanding of the end-to-end utility of gradient compression methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Maximizing Blockchain Performance: Mitigating Conflicting Transactions through Parallelism and Dependency Management</title>
<link>https://arxiv.org/abs/2407.01426</link>
<guid>https://arxiv.org/abs/2407.01426</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchains, cryptocurrency, conflicting transactions, Hyperledger Fabric, transaction parallelism

总结: 本文主要关注区块链技术在加密货币领域的扩展应用，特别是解决"冲突交易"（conflicting transactions）问题。提出了一种新的区块链方案，结合了事务并行性和智能依赖管理器，旨在减少交易冲突，从而降低网络延迟、提高系统资源利用率和交易成功率。实验结果显示，该方案不仅有效解决了冲突交易问题，而且在与现有的Hyperledger Fabric网络比较中表现出色，实现了更高的交易吞吐量和更低的延迟。这一集成为改善现实世界中区块链网络的性能和稳定性提供了前景。<br /><br />总结: 关键词：区块链、冲突交易、Hyperledger Fabric、事务并行性、智能依赖管理。文章提出的新方案通过优化并行处理和依赖管理，显著提升了区块链网络的性能，特别是在交易成功率、吞吐量和延迟方面超越了现有系统，为实际应用中的区块链网络改进提供了解决方案。 <div>
arXiv:2407.01426v1 Announce Type: new 
Abstract: While blockchains initially gained popularity in the realm of cryptocurrencies, their widespread adoption is expanding beyond conventional applications, driven by the imperative need for enhanced data security. Despite providing a secure network, blockchains come with certain tradeoffs, including high latency, lower throughput, and an increased number of transaction failures. A pivotal issue contributing to these challenges is the improper management of "conflicting transactions", commonly referred to as "contention". When a number of pending transactions within a blockchain collide with each other, this results in a state of contention. This situation worsens network latency, leads to the wastage of system resources, and ultimately contributes to reduced throughput and higher transaction failures. In response to this issue, in this work, we present a novel blockchain scheme that integrates transaction parallelism and an intelligent dependency manager aiming to reduce the occurrence of conflicting transactions within blockchain networks. In terms of effectiveness and efficiency, experimental results show that our scheme not only mitigates the challenges posed by conflicting transactions, but also outperforms both existing parallel and non-parallel Hyperledger Fabric blockchain networks achieving higher transaction success rate, throughput, and latency. The integration of our scheme with Hyperledger Fabric appears to be a promising solution for improving the overall performance and stability of blockchain networks in real-world applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reinforcement Learning-driven Data-intensive Workflow Scheduling for Volunteer Edge-Cloud</title>
<link>https://arxiv.org/abs/2407.01428</link>
<guid>https://arxiv.org/abs/2407.01428</guid>
<content:encoded><![CDATA[
<div> 关键词：Volunteer Edge-Cloud (VEC), Reinforcement Learning (RL), Data-intensive scientific workflows, Workflow scheduling, Resource allocation.

总结:<br />本文提出了一种基于强化学习（RL）的策略，旨在解决志愿边缘云（VEC）中数据密集型科学工作流任务调度的挑战。该方法考虑了工作流需求、VEC资源对工作流的偏好以及多样的VEC资源策略，通过将长期性能优化问题建模为马尔可夫决策过程，采用事件驱动的异步优势Actor-Critic RL算法求解。实验结果表明，相比于传统方法，该RL驱动的调度方案在满足工作流需求、优化VEC资源使用和满意度方面表现出色。 <div>
arXiv:2407.01428v1 Announce Type: new 
Abstract: In recent times, Volunteer Edge-Cloud (VEC) has gained traction as a cost-effective, community computing paradigm to support data-intensive scientific workflows. However, due to the highly distributed and heterogeneous nature of VEC resources, centralized workflow task scheduling remains a challenge. In this paper, we propose a Reinforcement Learning (RL)-driven data-intensive scientific workflow scheduling approach that takes into consideration: i) workflow requirements, ii) VEC resources' preference on workflows, and iii) diverse VEC resource policies, to ensure robust resource allocation. We formulate the long-term average performance optimization problem as a Markov Decision Process, which is solved using an event-based Asynchronous Advantage Actor-Critic RL approach. Our extensive simulations and testbed implementations demonstrate our approach's benefits over popular baseline strategies in terms of workflow requirement satisfaction, VEC preference satisfaction, and available VEC resource utilization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources</title>
<link>https://arxiv.org/abs/2407.01445</link>
<guid>https://arxiv.org/abs/2407.01445</guid>
<content:encoded><![CDATA[
<div> 关键词：Contrastive Language-Image Pretraining (CLIP), Large-scale data, Resource limitation, FastCLIP, Optimization techniques.

总结:<br />该研究关注在资源受限情况下（如少于数百GPU）训练最先进的CLIP模型。FastCLIP是一个专为分布式设置设计和优化的框架，采用高效梯度降低策略减少通信开销。研究还探讨了内学习率调度、温度参数和模型参数更新规则对效率的影响。实验表明，FastCLIP在不同规模（32 GPU和3种数据集大小）上显著优于OpenCLIP基准，特别在资源有限的情况下。研究成果已开源。<br /> <div>
arXiv:2407.01445v1 Announce Type: new 
Abstract: Existing studies of training state-of-the-art Contrastive Language-Image Pretraining (CLIP) models on large-scale data involve hundreds of or even thousands of GPUs due to the requirement of a large batch size. However, such a large amount of resources is not accessible to most people. While advanced compositional optimization techniques for optimizing global contrastive losses have been demonstrated effective for removing the requirement of large batch size, their performance on large-scale data remains underexplored and not optimized. To bridge the gap, this paper explores several aspects of CLIP training with limited resources (e.g., up to tens of GPUs). First, we introduce FastCLIP, a general CLIP training framework built on advanced compositional optimization techniques while designed and optimized for the distributed setting. Our framework is equipped with an efficient gradient reduction strategy to reduce communication overhead. Second, to further boost training efficiency, we investigate three components of the framework from an optimization perspective: the schedule of the inner learning rate, the update rules of the temperature parameter and the model parameters, respectively. Experiments on different strategies for each component shed light on how to conduct CLIP training more efficiently. Finally, we benchmark the performance of FastCLIP and the state-of-the-art training baseline (OpenCLIP) on different compute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7 million, 9.1 million to 315 million image-text pairs to demonstrate the significant improvement of FastCLIP in the resource-limited setting. We release the code of FastCLIP at https://github.com/Optimization-AI/fast_clip .
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>How Clustering Affects the Convergence of Decentralized Optimization over Networks: A Monte-Carlo-based Approach</title>
<link>https://arxiv.org/abs/2407.01460</link>
<guid>https://arxiv.org/abs/2407.01460</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized algorithms, Convergence rate, Network topology, Clustering coefficient, Scale-free networks.

总结:
本文主要探讨了分布式优化算法在随机尺度自由网络（Scale-free, SF）和簇尺度自由网络（Clustered Scale-free, CSF）中的收敛速度，通过调整网络的聚类系数。研究发现，当其他网络属性如幂律度分布、链接数量和平均度保持不变时，低聚类系数的网络往往具有更快的收敛率。这一发现对于改进现有分布式机器学习系统的学习速率具有重要意义，因为可以通过调整网络结构来提升性能。作者还通过实际网络案例分析，进一步验证了这一结论。 <div>
arXiv:2407.01460v1 Announce Type: new 
Abstract: Decentralized algorithms have gained substantial interest owing to advancements in cloud computing, Internet of Things (IoT), intelligent transportation networks, and parallel processing over sensor networks. The convergence of such algorithms is directly related to specific properties of the underlying network topology. Specifically, the clustering coefficient is known to affect, for example, the controllability/observability and the epidemic growth over networks. In this work, we study the effects of the clustering coefficient on the convergence rate of networked optimization approaches. In this regard, we model the structure of large-scale distributed systems by random scale-free (SF) and clustered scale-free (CSF) networks and compare the convergence rate by tuning the network clustering coefficient. This is done by keeping other relevant network properties (such as power-law degree distribution, number of links, and average degree) unchanged. Monte-Carlo-based simulations are used to compare the convergence rate over many trials of SF graph topologies. Furthermore, to study the convergence rate over real case studies, we compare the clustering coefficient of some real-world networks with the eigenspectrum of the underlying network (as a measure of convergence rate). The results interestingly show higher convergence rate over low-clustered networks. This is significant as one can improve the learning rate of many existing decentralized machine-learning scenarios by tuning the network clustering.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Immutable in Principle, Upgradeable by Design: Exploratory Study of Smart Contract Upgradeability</title>
<link>https://arxiv.org/abs/2407.01493</link>
<guid>https://arxiv.org/abs/2407.01493</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, upgradeable, Ethereum blockchain, upgrade mechanisms, user engagement.

总结:<br />
升级可编程合约（upgradeable smart contracts）是Ethereum区块链上的一种创新，旨在解决固有不可变性与后期维护需求之间的矛盾。本文研究通过创建一个详细记录智能合约版本和演化路径的数据库，关注五个关键点：升级机制的使用频率、升级行为的发生率、升级后的修改性质、对用户参与的影响以及合同活动的变化。结果发现，只有约3%的智能合约具备升级功能，其中只有0.34%实际进行了升级，表明开发者对于改动持谨慎态度，可能源于升级过程的复杂性和维护稳定性偏好。升级主要集中在功能增强和漏洞修复，尤其是当源代码公开时。然而，升级与用户活跃度的关系复杂，暗示着影响智能合约使用的因素远不止其进化历程。 <div>
arXiv:2407.01493v1 Announce Type: new 
Abstract: Smart contracts, known for their immutable nature to ensure trust via automated enforcement, have evolved to require upgradeability due to unforeseen vulnerabilities and the need for feature enhancements post-deployment. This contradiction between immutability and the need for modifications has led to the development of upgradeable smart contracts. These contracts are immutable in principle yet upgradable by design, allowing updates without altering the underlying data or state, thus preserving the contract's intent while allowing improvements. This study aims to understand the application and implications of upgradeable smart contracts on the Ethereum blockchain. By introducing a dataset that catalogs the versions and evolutionary trajectories of smart contracts, the research explores key dimensions: the prevalence and adoption patterns of upgrade mechanisms, the likelihood and occurrences of contract upgrades, the nature of modifications post-upgrade, and their impact on user engagement and contract activity. Through empirical analysis, this study identifies upgradeable contracts and examines their upgrade history to uncover trends, preferences, and challenges associated with modifications. The evidence from analyzing over 44 million contracts shows that only 3% have upgradeable characteristics, with only 0.34% undergoing upgrades. This finding underscores a cautious approach by developers towards modifications, possibly due to the complexity of upgrade processes or a preference for maintaining stability. Furthermore, the study shows that upgrades are mainly aimed at feature enhancement and vulnerability mitigation, particularly when the contracts' source codes are accessible. However, the relationship between upgrades and user activity is complex, suggesting that additional factors significantly affect the use of smart contracts beyond their evolution.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Inverted 3-Sum Box: General Formulation and Quantum Information Theoretic Optimality</title>
<link>https://arxiv.org/abs/2407.01498</link>
<guid>https://arxiv.org/abs/2407.01498</guid>
<content:encoded><![CDATA[
<div> 关键词：$N$-sum box, quantum multiple access channel (QMAC), communication cost, quantum coding schemes, information theory.

总结:<br />
该论文探讨了在量子多路访问信道（QMAC）上计算$\mathbb{F}_d$线性函数的最优通信成本问题。研究焦点在于给定任意转移矩阵$V_k$时，确定所有可能的量子编码方案中，传输所需最小的量子比特数$\Delta_1, \Delta_2, \Delta_3$。对于三个发送者（$K=3$）的情况，作者给出了完整的结果，表明基于$N$-sum box协议的编码在所有情况下都达到信息论最优。文章还提供了特定参数下（如矩阵秩$r_1, r_2, r_3$）的最小总下载成本公式。对于$K\geq 4$的发送者情况，问题仍未解决。 <div>
arXiv:2407.01498v1 Announce Type: new 
Abstract: The $N$-sum box protocol specifies a class of $\mathbb{F}_d$ linear functions $f(W_1,\cdots,W_K)=V_1W_1+V_2W_2+\cdots+V_KW_K\in\mathbb{F}_d^{m\times 1}$ that can be computed at information theoretically optimal communication cost (minimum number of qudits $\Delta_1,\cdots,\Delta_K$ sent by the transmitters Alice$_1$, Alice$_2$,$\cdots$, Alice$_K$, respectively, to the receiver, Bob, per computation instance) over a noise-free quantum multiple access channel (QMAC), when the input data streams $W_k\in\mathbb{F}_d^{m_k\times 1}, k\in[K]$, originate at the distributed transmitters, who share quantum entanglement in advance but are not otherwise allowed to communicate with each other. In prior work this set of optimally computable functions is identified in terms of a strong self-orthogonality (SSO) condition on the transfer function of the $N$-sum box. In this work we consider an `inverted' scenario, where instead of a feasible $N$-sum box transfer function, we are given an arbitrary $\mathbb{F}_d$ linear function, i.e., arbitrary matrices $V_k\in\mathbb{F}_d^{m\times m_k}$ are specified, and the goal is to characterize the set of all feasible communication cost tuples $(\Delta_1,\cdots,\Delta_K)$, not just based on $N$-sum box protocols, but across all possible quantum coding schemes. As our main result, we fully solve this problem for $K=3$ transmitters ($K\geq 4$ settings remain open). Coding schemes based on the $N$-sum box protocol (along with elementary ideas such as treating qudits as classical dits, time-sharing and batch-processing) are shown to be information theoretically optimal in all cases. As an example, in the symmetric case where rk$(V_1)$=rk$(V_2)$=rk$(V_3) \triangleq r_1$, rk$([V_1, V_2])$=rk$([V_2, V_3])$=rk$([V_3, V_1])\triangleq r_2$, and rk$([V_1, V_2, V_3])\triangleq r_3$ (rk = rank), the minimum total-download cost is $\max \{1.5r_1 + 0.75(r_3 - r_2), r_3\}$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Linear and Nonlinear MMSE Estimation in One-Bit Quantized Systems under a Gaussian Mixture Prior</title>
<link>https://arxiv.org/abs/2407.01305</link>
<guid>https://arxiv.org/abs/2407.01305</guid>
<content:encoded><![CDATA[
<div> 关键词：mean square error (MSE), conditional mean estimator (CME), one-bit quantization, Gaussian mixture model (GMM), additive white Gaussian noise (AWGN).

总结:<br />该论文研究了一比特量化系统中，对于由高斯混合模型（GMM）分布的信号和加性白高斯噪声（AWGN）干扰的信号，MSE-最优条件均值估计器（CME）的新理论。首先，论文提供了Busgang估计器的闭式解析表达式，这是量化系统中的线性最小均方误差（MMSE）估计算法。接着，文中揭示了CME在特殊情况下的线性性质，与高分辨率情况相反。论文还比较了Gaussian案例，发现信号与量化噪声存在相关性。此外，研究扩展到多观测场景，探讨了MSE-最优发送序列，并进行了大样本分析，给出了MSE及其极限的解析表达。这些结果对信号处理应用的分析和设计具有广泛影响。 <div>
arXiv:2407.01305v1 Announce Type: cross 
Abstract: We present new fundamental results for the mean square error (MSE)-optimal conditional mean estimator (CME) in one-bit quantized systems for a Gaussian mixture model (GMM) distributed signal of interest, possibly corrupted by additive white Gaussian noise (AWGN). We first derive novel closed-form analytic expressions for the Bussgang estimator, the well-known linear minimum mean square error (MMSE) estimator in quantized systems. Afterward, closed-form analytic expressions for the CME in special cases are presented, revealing that the optimal estimator is linear in the one-bit quantized observation, opposite to higher resolution cases. Through a comparison to the recently studied Gaussian case, we establish a novel MSE inequality and show that that the signal of interest is correlated with the auxiliary quantization noise. We extend our analysis to multiple observation scenarios, examining the MSE-optimal transmit sequence and conducting an asymptotic analysis, yielding analytic expressions for the MSE and its limit. These contributions have broad impact for the analysis and design of various signal processing applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Neural Distributed Source Coding</title>
<link>https://arxiv.org/abs/2106.02797</link>
<guid>https://arxiv.org/abs/2106.02797</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed source coding, Slepian-Wolf, Vector-Quantized Variational Autoencoder (VQ-VAE), Lossy compression, High dimensions.

总结:<br />本文介绍了一种新颖的分布式源编码（DSC）框架，它能够处理复杂的数据集和各种相关性结构，突破了传统方法的限制。该方法利用条件Vector-Quantized Variational Autoencoder (VQ-VAE)，即条件VQ-VAE，作为学习型编码器和解码器，实现了无须依赖特定源模型的高效编码。实验结果显示，这种神经网络驱动的DSC方法在处理高维数据时表现出色，能够在保持高质量（PSNR）的同时，适应各类复杂的关联。代码已在GitHub上开源，为实际应用中的分布式压缩提供了新的可能。 <div>
arXiv:2106.02797v4 Announce Type: replace 
Abstract: Distributed source coding (DSC) is the task of encoding an input in the absence of correlated side information that is only available to the decoder. Remarkably, Slepian and Wolf showed in 1973 that an encoder without access to the side information can asymptotically achieve the same compression rate as when the side information is available to it. While there is vast prior work on this topic, practical DSC has been limited to synthetic datasets and specific correlation structures. Here we present a framework for lossy DSC that is agnostic to the correlation structure and can scale to high dimensions. Rather than relying on hand-crafted source modeling, our method utilizes a conditional Vector-Quantized Variational Autoencoder (VQ-VAE) to learn the distributed encoder and decoder. We evaluate our method on multiple datasets and show that our method can handle complex correlations and achieves state-of-the-art PSNR. Our code is made available at https://github.com/acnagle/neural-dsc.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Directional Antenna Based Scheduling Protocol for IoT Networks</title>
<link>https://arxiv.org/abs/2305.02511</link>
<guid>https://arxiv.org/abs/2305.02511</guid>
<content:encoded><![CDATA[
<div> 关键词：IoT网络，MAC层，Scheduling协议，Directional Scheduling，6TiSCH-IoT。

总结:<br />
本文主要关注物联网(IoT)网络中的一 hop 调度和频道访问。现有的基于全方位天线的应用数据传输在性能上不如采用方向性天线的调度协议。为此，研究者提出了一种分布式一跳调度算法，称为Directional Scheduling协议，特别适用于受限的确定性6TiSCH-IoT网络。该算法通过定向传输实现了更高的空间重用，允许更多的物联网节点并发数据传输，减少了头阻塞现象。结果表明，这种策略能够显著提升6TiSCH-IoT网络的吞吐量和效率。 <div>
arXiv:2305.02511v2 Announce Type: replace 
Abstract: Scheduling and Channel Access at the MAC layer of the IoT network plays a pivotal role in enhancing the performance of IoT networks. State-of-the-art Omni-directional antenna based application data transmission has relatively less achievable throughput in comparison with directional antenna based scheduling protocols. To enhance the performance of the IoT networks, this paper propose a distributed one-hop scheduling algorithm called Directional Scheduling protocol for constrained deterministic 6TiSCH-IoT network. With this, in-creased number of IoT nodes can have concurrent application data transmission with efficient spatial reuse. This in-turn results in higher number of cell allocation to the one-hop IoT nodes during data transmission. The proposed algorithm makes use of through directional transmissions avoids head of line blocking.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration</title>
<link>https://arxiv.org/abs/2305.19476</link>
<guid>https://arxiv.org/abs/2305.19476</guid>
<content:encoded><![CDATA[
<div> 关键词：state entropy, reinforcement learning, value-conditional state entropy, exploration, high-value states.

总结:<br />本文介绍了一种新的强化学习探索策略，针对传统方法在有任务奖励的监督环境中遇到的问题。该策略关注价值条件下的状态熵（value-conditional state entropy），即分别估计每个状态的价值估计后计算的熵，以平均值为目标进行最大化。这种方法避免了低价值和高价值状态分布之间的不平衡，防止了低价值区域的探索偏向于高价值区域。实验结果表明，相比于单纯的 state entropy 基线，该策略在 MiniGrid、DeepMind Control Suite 和 Meta-World 等多个任务中显著加速了学习过程。源代码可在此处获取：[链接]。 <div>
arXiv:2305.19476v2 Announce Type: replace 
Abstract: A promising technique for exploration is to maximize the entropy of visited state distribution, i.e., state entropy, by encouraging uniform coverage of visited state space. While it has been effective for an unsupervised setup, it tends to struggle in a supervised setup with a task reward, where an agent prefers to visit high-value states to exploit the task reward. Such a preference can cause an imbalance between the distributions of high-value states and low-value states, which biases exploration towards low-value state regions as a result of the state entropy increasing when the distribution becomes more uniform. This issue is exacerbated when high-value states are narrowly distributed within the state space, making it difficult for the agent to complete the tasks. In this paper, we present a novel exploration technique that maximizes the value-conditional state entropy, which separately estimates the state entropies that are conditioned on the value estimates of each state, then maximizes their average. By only considering the visited states with similar value estimates for computing the intrinsic bonus, our method prevents the distribution of low-value states from affecting exploration around high-value states, and vice versa. We demonstrate that the proposed alternative to the state entropy baseline significantly accelerates various reinforcement learning algorithms across a variety of tasks within MiniGrid, DeepMind Control Suite, and Meta-World benchmarks. Source code is available at https://sites.google.com/view/rl-vcse.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Pilot Assignment for Distributed Massive-MIMO Networks</title>
<link>https://arxiv.org/abs/2309.15709</link>
<guid>https://arxiv.org/abs/2309.15709</guid>
<content:encoded><![CDATA[
<div> 关键词：pilot contamination, distributed massive MIMO, pilot assignment scheme, signaling overhead, fault-tolerance.

总结:<br />
本文主要关注大规模多输入多输出（massive MIMO）网络中的飞行员污染问题。提出了一种创新的分布式飞行员分配方案，旨在有效缓解该问题，同时减少信号开销并提高系统的容错性。通过大量数值模拟，研究结果显示，新方案在降低飞行员污染和提升网络吞吐量方面优于现有的中心化和分布式策略。总的来说，这项工作提供了一个有效的解决方案，优化了多用户环境下的通信性能。 <div>
arXiv:2309.15709v3 Announce Type: replace 
Abstract: Pilot contamination is a critical issue in distributed massive MIMO networks, where the reuse of pilot sequences due to limited availability of orthogonal pilots for channel estimation leads to performance degradation. In this work, we propose a novel distributed pilot assignment scheme to effectively mitigate the impact of pilot contamination. Our proposed scheme not only reduces signaling overhead, but it also enhances fault-tolerance. Extensive numerical simulations are conducted to evaluate the performance of the proposed scheme. Our results establish that the proposed scheme outperforms existing centralized and distributed schemes in terms of mitigating pilot contamination and significantly enhancing network throughput.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CO-ASnet :A Smart Contract Architecture Design based on Blockchain Technology with Active Sensor Networks</title>
<link>https://arxiv.org/abs/2310.05070</link>
<guid>https://arxiv.org/abs/2310.05070</guid>
<content:encoded><![CDATA[
<div> 关键词：opinion leaders, blockchain, ICOs, influence, regulatory scheme

总结:<br />
这篇文章关注意见领袖在区块链金融中的影响力，特别是通过ICO进行资产影响的案例分析。研究发现，意见领袖能够利用社交媒体和社交网络中的金钱与流量影响代币资产价格，实现超额回报并降低资产实现成本。基于此现象，文章提出采用ChainLink Oracle与Active Sensor Networks（CO-ASnet）设计的去中心化监管方案，为token发行提供风险评估和预警措施。这一研究对区块链金融产品发展和治理具有参考价值，提示监管者和企业应探索其边界。 <div>
arXiv:2310.05070v2 Announce Type: replace 
Abstract: The influence of opinion leaders impacts different aspects of social finance. How to analyse the utility of opinion leaders' influence in realizing assets on the blockchain and adopt a compliant regulatory scheme is worth exploring and pondering. Taking Musk's call on social media to buy Dogecoin as an example, this paper uses an event study to empirically investigate the phenomenon in which opinion leaders use ICOs (initial coin offerings) to exert influence. The results show that opinion leaders can use ICOs to influence the price of token assets with money and data traffic in their social network. They can obtain excess returns and reduce the cost of realization so that the closed loop of influence realization will be accelerated. Based on this phenomenon and the results of its impact, we use the ChainLink Oracle with Active Sensor Networks(CO-ASnet) to design a safe and applicable decentralized regulatory scheme that can constructively provide risk assessment strategies and early warning measures for token issuance. The influence realization of opinion leaders in blockchain issuance is bound to receive widespread attention, and this paper will provide an exemplary reference for regulators and enterprises to explore the boundaries of blockchain financial product development and governance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance</title>
<link>https://arxiv.org/abs/2310.11373</link>
<guid>https://arxiv.org/abs/2310.11373</guid>
<content:encoded><![CDATA[
<div> 关键词：Reticulum, sharding, blockchain, scalability, adversarial attacks.

总结:<br />Reticulum是一种创新的区块链分片协议，旨在提高交易吞吐量并抵御各种网络攻击。它采用两阶段架构，包括控制和处理分片。处理分片至少包含一个可信节点，而控制分片由多数可信节点组成。首先，交易在处理分片中进行投票，共识通过后确认。若未达成一致，控制分片介入，决定并解决争议。实验表明，Reticulum在高吞吐量和抗攻击性方面超越现有协议，为区块链网络提供强大且安全的扩展能力。 <div>
arXiv:2310.11373v4 Announce Type: replace 
Abstract: Sharding is essential for improving blockchain scalability. Existing protocols overlook diverse adversarial attacks, limiting transaction throughput. This paper presents Reticulum, a groundbreaking sharding protocol addressing this issue, boosting blockchain scalability.
  Reticulum employs a two-phase approach, adapting transaction throughput based on runtime adversarial attacks. It comprises "control" and "process" shards in two layers. Process shards contain at least one trustworthy node, while control shards have a majority of trusted nodes. In the first phase, transactions are written to blocks and voted on by nodes in process shards. Unanimously accepted blocks are confirmed. In the second phase, blocks without unanimous acceptance are voted on by control shards. Blocks are accepted if the majority votes in favor, eliminating first-phase opponents and silent voters. Reticulum uses unanimous voting in the first phase, involving fewer nodes, enabling more parallel process shards. Control shards finalize decisions and resolve disputes.
  Experiments confirm Reticulum's innovative design, providing high transaction throughput and robustness against various network attacks, outperforming existing sharding protocols for blockchain networks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>History Trees and Their Applications</title>
<link>https://arxiv.org/abs/2404.02673</link>
<guid>https://arxiv.org/abs/2404.02673</guid>
<content:encoded><![CDATA[
<div> 关键词：history trees, distributed communication networks, anonymous agents, dynamic networks, open problems

总结:<br />这篇论文介绍了历史树在分布式通信网络研究中的重要性。历史树作为一种结构，有助于理解匿名节点在接收到不同邻居信息后如何变得可区分。它在分析既匿名又动态变化的网络中，为设计最优确定算法提供了框架。文章还回顾了历史树的最新应用进展，并拓展了理论边界，提出了几个待解决的问题。通过比较传统结构和历史树，作者为读者提供了一个易于理解的历史树入门指南。 <div>
arXiv:2404.02673v3 Announce Type: replace 
Abstract: In the theoretical study of distributed communication networks, "history trees" are a discrete structure that naturally models the concept that anonymous agents become distinguishable upon receiving different sets of messages from neighboring agents. By conveniently organizing temporal information in a systematic manner, history trees have been instrumental in the development of optimal deterministic algorithms for networks that are both anonymous and dynamically evolving.
  This note provides an accessible introduction to history trees, drawing comparisons with more traditional structures found in existing literature and reviewing the latest advancements in the applications of history trees, especially within dynamic networks. Furthermore, it expands the theoretical framework of history trees in new directions, also highlighting several open problems for further investigation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches</title>
<link>https://arxiv.org/abs/2404.02817</link>
<guid>https://arxiv.org/abs/2404.02817</guid>
<content:encoded><![CDATA[
<div> 关键词：Task and Motion Planning (TAMP), Optimization-based TAMP, Hybrid optimization, Locomotion, Manipulation.

总结:
本文是一篇关于优化型任务和运动规划（Optimization-based Task and Motion Planning，简称TAMP）的全面综述。TAMP旨在整合高阶任务规划与低阶运动规划，使机器人具备处理复杂、动态任务的能力，尤其适合解决涉及物理交互的高难度行走和操纵问题。文章重点讨论了TAMP的三个方面：(1) 规模表示，如动作描述语言和时序逻辑；(2) 解决策略，包括人工智能规划和轨迹优化；(3) 逻辑任务规划与模型基运动优化之间的动态互动。作者强调了高效的算法结构，如分级和分布式方法，并探讨了传统方法与基于学习的技术（如大型语言模型）的融合。最后，文章展望了TAMP的未来研究方向，包括算法改进和应用挑战。 <div>
arXiv:2404.02817v4 Announce Type: replace 
Abstract: Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO. A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches. Additionally, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations such as large language models. Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Static Application Security Testing (SAST) Tools for Smart Contracts: How Far Are We?</title>
<link>https://arxiv.org/abs/2404.18186</link>
<guid>https://arxiv.org/abs/2404.18186</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, static application security testing (SAST), vulnerability types, benchmark, evaluation.

总结:<br />
本文关注智能合约的安全性，随着攻击事件增多，静态应用安全测试(SAST)工具发展迅速。研究者提出了一种最新的、精细划分的45种漏洞类型分类，构建了一个涵盖40种类型的广泛基准，包括不同代码特性和应用场景。对8款SAST工具进行评估，结果显示这些工具漏检了约50%的基准漏洞，误报率高，精确度不足10%。结合工具可以降低漏检率，但会增加更多误报。许多非访问控制和重入性漏洞未被检测到。该研究为工具开发、改进、评估和选择提供了指导。 <div>
arXiv:2404.18186v3 Announce Type: replace 
Abstract: In recent years, the importance of smart contract security has been heightened by the increasing number of attacks against them. To address this issue, a multitude of static application security testing (SAST) tools have been proposed for detecting vulnerabilities in smart contracts. However, objectively comparing these tools to determine their effectiveness remains challenging. Existing studies often fall short due to the taxonomies and benchmarks only covering a coarse and potentially outdated set of vulnerability types, which leads to evaluations that are not entirely comprehensive and may display bias.
  In this paper, we fill this gap by proposing an up-to-date and fine-grained taxonomy that includes 45 unique vulnerability types for smart contracts. Taking it as a baseline, we develop an extensive benchmark that covers 40 distinct types and includes a diverse range of code characteristics, vulnerability patterns, and application scenarios. Based on them, we evaluated 8 SAST tools using this benchmark, which comprises 788 smart contract files and 10,394 vulnerabilities. Our results reveal that the existing SAST tools fail to detect around 50% of vulnerabilities in our benchmark and suffer from high false positives, with precision not surpassing 10%. We also discover that by combining the results of multiple tools, the false negative rate can be reduced effectively, at the expense of flagging 36.77 percentage points more functions. Nevertheless, many vulnerabilities, especially those beyond Access Control and Reentrancy vulnerabilities, remain undetected. We finally highlight the valuable insights from our study, hoping to provide guidance on tool development, enhancement, evaluation, and selection for developers, researchers, and practitioners.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AB-Training: A Communication-Efficient Approach for Distributed Low-Rank Learning</title>
<link>https://arxiv.org/abs/2405.01067</link>
<guid>https://arxiv.org/abs/2405.01067</guid>
<content:encoded><![CDATA[
<div> 关键词：AB-training, communication bottlenecks, distributed neural network training, low-rank representations, independent training groups

总结: AB-training是一种新型的分布式神经网络训练方法，旨在解决通信瓶颈问题。它利用低秩表示和独立训练组显著减少通信开销，平均降低网络流量约70.31%。这种方法不仅加速大规模系统中的收敛，还在小规模下显示正则化效果，提高泛化能力同时保持或缩短训练时间。实验中，AB-training在VGG16和ResNet-50模型上表现出色，分别实现了44.14:1的压缩比和1.55%的性能提升。然而，文章指出大型批量效应在低秩设置中仍然存在，提示对大规模分布式训练优化更新机制的研究仍有待深入。 <div>
arXiv:2405.01067v2 Announce Type: replace 
Abstract: Communication bottlenecks severely hinder the scalability of distributed neural network training, particularly in high-performance computing (HPC) environments. We introduce AB-training, a novel data-parallel method that leverages low-rank representations and independent training groups to significantly reduce communication overhead. Our experiments demonstrate an average reduction in network traffic of approximately 70.31\% across various scaling scenarios, increasing the training potential of communication-constrained systems and accelerating convergence at scale. AB-training also exhibits a pronounced regularization effect at smaller scales, leading to improved generalization while maintaining or even reducing training time. We achieve a remarkable 44.14 : 1 compression ratio on VGG16 trained on CIFAR-10 with minimal accuracy loss, and outperform traditional data parallel training by 1.55\% on ResNet-50 trained on ImageNet-2012. While AB-training is promising, our findings also reveal that large batch effects persist even in low-rank regimes, underscoring the need for further research into optimized update mechanisms for massively distributed training.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Facilitating Feature and Topology Lightweighting: An Ethereum Transaction Graph Compression Method for Malicious Account Detection</title>
<link>https://arxiv.org/abs/2405.08278</link>
<guid>https://arxiv.org/abs/2405.08278</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、malicious accounts、transaction graph、feature engineering、TGC4Eth。

总结:<br />Ethereum作为全球主要的加密货币平台，其交易图谱庞大，恶意账户活动频繁。本文提出TGC4Eth方法，旨在通过特征选择和图结构压缩提升恶意账户检测的效率与鲁棒性。首先，TGC4Eth筛选交易特征，降低对重要性较低特征的依赖，对抗特征逃逸攻击；其次，通过聚焦和粗化过程压缩图谱结构，提高数据处理和模型推理效率。实验结果表明，TGC4Eth显著提高了现有检测模型的计算效率，保持了交易图的连通性，并且在面对特征逃逸攻击时表现出高稳定性。 <div>
arXiv:2405.08278v2 Announce Type: replace 
Abstract: Ethereum has become one of the primary global platforms for cryptocurrency, playing an important role in promoting the diversification of the financial ecosystem. However, the relative lag in regulation has led to a proliferation of malicious activities in Ethereum, posing a serious threat to fund security. Existing regulatory methods usually detect malicious accounts through feature engineering or large-scale transaction graph mining. However, due to the immense scale of transaction data and malicious attacks, these methods suffer from inefficiency and low robustness during data processing and anomaly detection. In this regard, we propose an Ethereum Transaction Graph Compression method named TGC4Eth, which assists malicious account detection by lightweighting both features and topology of the transaction graph. At the feature level, we select transaction features based on their low importance to improve the robustness of the subsequent detection models against feature evasion attacks; at the topology level, we employ focusing and coarsening processes to compress the structure of the transaction graph, thereby improving both data processing and inference efficiency of detection models. Extensive experiments demonstrate that TGC4Eth significantly improves the computational efficiency of existing detection models while preserving the connectivity of the transaction graph. Furthermore, TGC4Eth enables existing detection models to maintain stable performance and exhibit high robustness against feature evasion attacks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Adaptive Control of Disturbed Interconnected Systems with High-Order Tuners</title>
<link>https://arxiv.org/abs/2405.15178</link>
<guid>https://arxiv.org/abs/2405.15178</guid>
<content:encoded><![CDATA[
<div> 关键词：network synchronization, distributed adaptive control, interconnected agents, consensus, communication limitations

总结:<br />
本文探讨了在通信受限的情况下，如何实现异质性子系统（包括领导者和跟随者）之间的网络同步，以达成共识。研究关注的是未知线性子系统的分布式自适应控制，存在输入-输出扰动。关键创新在于增强多 agent 系统内的通信，通过根据与领导者距离调整测量值，实现跟随。文章分析了不同类型的平衡网络（星形、循环、路径和随机）中第一至高阶调节器的效果，考虑了时间变系数。数值模拟展示了网络稀疏性对性能的影响，并指出增加节点数量并不总是减小误差。最后，经验证明，提出的改进高阶调节器优于其他方法，提供了深入的理论洞察和结论。 <div>
arXiv:2405.15178v2 Announce Type: replace 
Abstract: This paper addresses the challenge of network synchronization under limited communication, involving heterogeneous agents with different dynamics and various network topologies, to achieve consensus. We investigate the distributed adaptive control for interconnected unknown linear subsystems with a leader and followers, in the presence of input-output disturbance. We enhance the communication within multi-agent systems to achieve consensus under the leadership's guidance. While the measured variable is similar among the followers, the incoming measurements are weighted and constructed based on their proximity to the leader. We also explore the convergence rates across various balanced topologies (Star-like, Cyclic-like, Path, Random), featuring different numbers of agents, using three distributed algorithms, ranging from first- to high-order tuners to effectively address time-varying regressors. The mathematical foundation is rigorously presented from the network designs of the unknown agents following a leader, to the distributed methods. Moreover, we conduct several numerical simulations across various networks, agents and tuners to evaluate the effects of sparsity in the interaction between subsystems using the $L_2-$norm and $L_\infty-$norm. Some networks exhibit a trend where an increasing number of agents results in smaller errors, although this is not universally the case. Additionally, patterns observed at initial times may not reliably predict overall performance across different networks. Finally, we demonstrate that the proposed modified high-order tuner outperforms its counterparts, and we provide related insights along with our conclusions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization</title>
<link>https://arxiv.org/abs/2406.07948</link>
<guid>https://arxiv.org/abs/2406.07948</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure Multi-party Computation, Decision Trees, Communication Optimization, Radix Sort Protocols, Training Framework

总结:<br />
本文介绍了一种名为 Ents 的高效三 party 训练框架，专注于优化决策树的多 party 训练过程中的通信效率。首先， Ents 提出基于安全排序协议的解决方案，有效处理连续属性数据集的分割，减少通信开销。其次，通过设计高效的份额转换协议，减少在大型环上进行大部分计算导致的通信负担。实验结果表明， Ents 相比现有框架在通信大小和轮数上分别提高了 5.5 倍到 9.3 倍和 3.9 倍到 5.3 倍，训练时间也缩短了 3.5 倍到 6.7 倍。在实际应用中， Ents 能在仅需三个小时的情况下，通过 WAN 环境对具有 245,000 多个样本的真实世界皮肤分割数据集进行安全训练，显示其实践可行性。 <div>
arXiv:2406.07948v3 Announce Type: replace 
Abstract: Multi-party training frameworks for decision trees based on secure multi-party computation enable multiple parties to train high-performance models on distributed private data with privacy preservation. The training process essentially involves frequent dataset splitting according to the splitting criterion (e.g. Gini impurity). However, existing multi-party training frameworks for decision trees demonstrate communication inefficiency due to the following issues: (1) They suffer from huge communication overhead in securely splitting a dataset with continuous attributes. (2) They suffer from huge communication overhead due to performing almost all the computations on a large ring to accommodate the secure computations for the splitting criterion.
  In this paper, we are motivated to present an efficient three-party training framework, namely Ents, for decision trees by communication optimization. For the first issue, we present a series of training protocols based on the secure radix sort protocols to efficiently and securely split a dataset with continuous attributes. For the second issue, we propose an efficient share conversion protocol to convert shares between a small ring and a large ring to reduce the communication overhead incurred by performing almost all the computations on a large ring. Experimental results from eight widely used datasets show that Ents outperforms state-of-the-art frameworks by $5.5\times \sim 9.3\times$ in communication sizes and $3.9\times \sim 5.3\times$ in communication rounds. In terms of training time, Ents yields an improvement of $3.5\times \sim 6.7\times$. To demonstrate its practicality, Ents requires less than three hours to securely train a decision tree on a widely used real-world dataset (Skin Segmentation) with more than 245,000 samples in the WAN setting.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>TemPrompt: Multi-Task Prompt Learning for Temporal Relation Extraction in RAG-based Crowdsourcing Systems</title>
<link>https://arxiv.org/abs/2406.14825</link>
<guid>https://arxiv.org/abs/2406.14825</guid>
<content:encoded><![CDATA[
<div> 关键词：Temporal Relation Extraction, Temporal Prompt Learning, Pre-trained Language Models, Contrastive Learning, Crowdsourcing Scenarios.

总结: 本文介绍了一种名为TemPrompt的多任务提示学习框架，用于解决时间关系抽取（TRE）任务中的数据限制和分布不均问题。该方法利用预训练语言模型（PLMs）的全球知识，通过任务导向的自动提示生成，结合prompt tuning和对比学习来提升性能。文章还提出利用时间事件推理辅助模型关注事件和时间线索。实验结果显示，TemPrompt在标准和少量样本条件下，相较于其他方法在大多数指标上表现更优，并通过案例研究验证了其在众包场景中的有效性。 <div>
arXiv:2406.14825v3 Announce Type: replace 
Abstract: Temporal relation extraction (TRE) aims to grasp the evolution of events or actions, and thus shape the workflow of associated tasks, so it holds promise in helping understand task requests initiated by requesters in crowdsourcing systems. However, existing methods still struggle with limited and unevenly distributed annotated data. Therefore, inspired by the abundant global knowledge stored within pre-trained language models (PLMs), we propose a multi-task prompt learning framework for TRE (TemPrompt), incorporating prompt tuning and contrastive learning to tackle these issues. To elicit more effective prompts for PLMs, we introduce a task-oriented prompt construction approach that thoroughly takes the myriad factors of TRE into consideration for automatic prompt generation. In addition, we present temporal event reasoning as a supplement to bolster the model's focus on events and temporal cues. The experimental results demonstrate that TemPrompt outperforms all compared baselines across the majority of metrics under both standard and few-shot settings. A case study is provided to validate its effectiveness in crowdsourcing scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ammBoost: State Growth Control for AMMs</title>
<link>https://arxiv.org/abs/2406.17094</link>
<guid>https://arxiv.org/abs/2406.17094</guid>
<content:encoded><![CDATA[
<div> 关键词：Automated Market Makers (AMMs), Decentralized Finance (DeFi), Scalability issues, Sidechain architecture, ammBoost.

总结:<br />
本文探讨了去中心化金融(DeFi)应用中的自动市场 maker (AMM)面临的可扩展性问题，特别是高昂的链上存储开销。为解决这一问题，作者提出了一种新的侧链架构方案——ammBoost。ammBoost通过减少链上交易、提升吞吐量并支持区块链修剪，有效降低了交易成本和链增长。实验表明，ammBoost能将gas成本降低94.53%，链增长减少至少80%，并能处理比Uniswap实际流量高500倍的交易量。这一创新为AMM的高效运行提供了有力支持。 <div>
arXiv:2406.17094v2 Announce Type: replace 
Abstract: Automated market makers (AMMs) are a form of decentralized cryptocurrency exchanges and considered a prime example of Decentralized Finance (DeFi) applications. Their popularity and high trading activity have resulted in millions of on-chain transactions leading to serious scalability issues. In this paper, we address the on-chain storage overhead problem of AMMs by utilizing a new sidechain architecture as a layer 2 solution, building a system called ammBoost. Our system reduces the amount of on-chain transactions, boosts throughput, and supports blockchain pruning. We devise several techniques to enable layer 2 processing for AMMs while preserving correctness and security of the underlying AMM. We also build a proof-of-concept of ammBoost for a Uniswap-inspired use case to empirically evaluate its performance. Our experiments show that ammBoost decreases the gas cost by 94.53% and the chain growth by at least 80%, and that it can support up to 500x of the daily traffic volume observed for Uniswap in practice.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Protecting the 'Stop Using My Data' Right through Blockchain-assisted Evidence Generation</title>
<link>https://arxiv.org/abs/2406.17694</link>
<guid>https://arxiv.org/abs/2406.17694</guid>
<content:encoded><![CDATA[
<div> 关键词：个人数据、停止使用、证据生成、区块链、权利侵犯。

总结:<br />本文探讨了互联网平台如何在保护用户隐私的同时提供个性化服务。文章关注的核心问题是“停止使用我的数据”这一数据权利，它属于“被遗忘权”的重要方面。作者提出了一种创新的证据生成框架，利用区块链技术设计并实现了一个系统，以防止在数据收购后对这项权利的侵犯。该系统采用两阶段证据生成协议，其有效性由新提出的引理保证。通过在两个真实世界推荐系统数据集上的实验验证，证明了该方法的成功率超过99%。这个研究为数据保护提供了一种新的解决方案，确保用户的‘停止使用我的数据’请求得到尊重。 <div>
arXiv:2406.17694v2 Announce Type: replace 
Abstract: In order to provide personalized services to users, Internet-based platforms collect and utilize user-generated behavioral data. Although the 'stop using my data' right should be a fundamental data right, which allows individuals to request their personal data to be no longer utilized by online platforms, the existing preventive data protection measures (e.g., cryptographic data elimination, differential privacy) are unfortunately not applicable. This work aims to develop the first Evidence Generation Framework for deterring post-acquisition data right violations. We formulated the 'stop using my data' problem, which captures a vantage facet of the multi-faceted notion of 'right to be forgotten'. We designed and implemented the first blockchain-assisted system to generate evidence for deterring the violations of the 'stop using my data' right. Our system employs a novel two-stage evidence generation protocol whose efficacy is ensured by a newly proposed Lemma. To validate our framework, we conducted a case study on recommendation systems with systematic evaluation experiments using two real-world datasets: the measured success rate exceeds 99%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Federated Graph Semantic and Structural Learning</title>
<link>https://arxiv.org/abs/2406.18937</link>
<guid>https://arxiv.org/abs/2406.18937</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Graph Learning, Graph Neural Networks, Node-Level Semantics, Graph-Level Structure, Distillation

总结:<br />
该论文关注联邦图学习中的挑战，主要集中在非独立同分布问题上，目标是协作训练全球图神经网络。首先，论文发现节点级语义对本地模型性能至关重要，通过对比不同类别的节点进行正则化，提升区分度。其次，论文提出结构信息对于邻居节点具有相似性，但直接对齐可能因类别不一致而阻碍区分。为解决这个问题，作者将邻接关系转化为相似度分布，并利用全局模型向本地模型传授关系知识，保持局部模型的结构信息和识别能力。实验结果在三个图数据集上验证了该方法的有效性，优于现有方法。 <div>
arXiv:2406.18937v2 Announce Type: replace 
Abstract: Federated graph learning collaboratively learns a global graph neural network with distributed graphs, where the non-independent and identically distributed property is one of the major challenges. Most relative arts focus on traditional distributed tasks like images and voices, incapable of graph structures. This paper firstly reveals that local client distortion is brought by both node-level semantics and graph-level structure. First, for node-level semantics, we find that contrasting nodes from distinct classes is beneficial to provide a well-performing discrimination. We pull the local node towards the global node of the same class and push it away from the global node of different classes. Second, we postulate that a well-structural graph neural network possesses similarity for neighbors due to the inherent adjacency relationships. However, aligning each node with adjacent nodes hinders discrimination due to the potential class inconsistency. We transform the adjacency relationships into the similarity distribution and leverage the global model to distill the relation knowledge into the local model, which preserves the structural information and discriminability of the local model. Empirical results on three graph datasets manifest the superiority of the proposed method over its counterparts.
]]></content:encoded>
<pubDate></pubDate>
</item>
</channel>
</rss>