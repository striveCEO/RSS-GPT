<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>


<item>
<title>Securing RC Based P2P Networks: A Blockchain-based Access Control Framework utilizing Ethereum Smart Contracts for IoT and Web 3.0</title>
<link>https://arxiv.org/abs/2412.03709</link>
<guid>https://arxiv.org/abs/2412.03709</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、访问控制框架、以太坊智能合约、动态P2P网络、安全模型

总结:
<br />
本文提出了一种基于区块链的访问控制框架，该框架利用以太坊智能合约解决高度动态的点对点（P2P）网络中的安全性问题，特别是对于在线交易和智能设备服务。针对P2P环境中传统角色基础访问控制（RBAC）系统的不足，此框架通过静态和动态策略管理的访问控制合约（ACC）、处理不当行为的法官合约（JC）以及记录和管理ACC与JC交互的注册合约（RC），提供了灵活、透明和去中心化的解决方案。文章所描述的安全模型结合了影响和严重性评估，运用CIA（机密性、完整性和可用性）和STRIDE原则，确保威胁应对措施能够适应不同的威胁级别。该系统不仅解决了P2P网络中节点成员变更带来的基础问题，还为物联网（IoT）和Web 3.0等技术领域提供了一个可扩展的解决方案。 <div>
arXiv:2412.03709v1 Announce Type: new 
Abstract: Ensuring security for highly dynamic peer-to-peer (P2P) networks has always been a challenge, especially for services like online transactions and smart devices. These networks experience high churn rates, making it difficult to maintain appropriate access control. Traditional systems, particularly Role-Based Access Control (RBAC), often fail to meet the needs of a P2P environment. This paper presents a blockchain-based access control framework that uses Ethereum smart contracts to address these challenges. Our framework aims to close the gaps in existing access control systems by providing flexible, transparent, and decentralized security solutions. The proposed framework includes access control contracts (ACC) that manage access based on static and dynamic policies, a Judge Contract (JC) to handle misbehavior, and a Register Contract (RC) to record and manage the interactions between ACCs and JC. The security model combines impact and severity-based threat assessments using the CIA (Confidentiality, Integrity, Availability) and STRIDE principles, ensuring responses are tailored to different threat levels. This system not only stabilizes the fundamental issues of peer membership but also offers a scalable solution, particularly valuable in areas such as the Internet of Things (IoT) and Web 3.0 technologies.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems</title>
<link>https://arxiv.org/abs/2412.03851</link>
<guid>https://arxiv.org/abs/2412.03851</guid>
<content:encoded><![CDATA[
<div> 关键词: 个性化医疗、联邦学习、数据异质性、累积傅里叶聚合、协同迁移优化

总结:
本文提出了Federated Meta-Learning for Personalized Medication（FedMetaMed）框架，旨在解决分布式医疗系统中个性化药物治疗面临的挑战。该框架结合了联邦学习和元学习，以适应不同医疗机构间的患者数据多样性。针对联邦学习中的服务器聚合阶段性能退化问题，FedMetaMed引入了累积傅里叶聚合（CFA）方法，从低到高频率逐步整合客户端模型，提升全局知识聚合的稳定性和有效性。在客户端，文章实施了一种名为协作迁移优化（CTO）的策略，通过检索、回馈和精炼三步流程，有效实现全球知识向本地个性化模型的平滑转移。实验结果显示，FedMetaMed在真实世界医学影像数据集上优于现有的联邦学习方法，表现出更强的泛化能力，尤其在外分布样本上表现突出。 <div>
arXiv:2412.03851v1 Announce Type: new 
Abstract: Personalized medication aims to tailor healthcare to individual patient characteristics. However, the heterogeneity of patient data across healthcare systems presents significant challenges to achieving accurate and effective personalized treatments. Ethical concerns further complicate the aggregation of large volumes of data from diverse institutions. Federated Learning (FL) offers a promising decentralized solution by enabling collaborative model training through the exchange of client models rather than raw data, thus preserving privacy. However, existing FL methods often suffer from retrogression during server aggregation, leading to a decline in model performance in real-world medical FL settings. To address data variability in distributed healthcare systems, we introduce Federated Meta-Learning for Personalized Medication (FedMetaMed), which combines federated learning and meta-learning to create models that adapt to diverse patient data across healthcare systems. The FedMetaMed framework aims to produce superior personalized models for individual clients by addressing these limitations. Specifically, we introduce Cumulative Fourier Aggregation (CFA) at the server to improve stability and effectiveness in global knowledge aggregation. CFA achieves this by gradually integrating client models from low to high frequencies. At the client level, we implement a Collaborative Transfer Optimization (CTO) strategy with a three-step process - Retrieve, Reciprocate, and Refine - to enhance the personalized local model through seamless global knowledge transfer. Experiments on real-world medical imaging datasets demonstrate that FedMetaMed outperforms state-of-the-art FL methods, showing superior generalization even on out-of-distribution cohorts.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>JANUS: A Difference-Oriented Analyzer For Financial Centralization Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2412.03938</link>
<guid>https://arxiv.org/abs/2412.03938</guid>
<content:encoded><![CDATA[
<div> 关键词: JANUS、智能合约、中心化风险、检测精度、状态遍历

<br /><br />总结:
本文提出了一种名为JANUS的新工具，用于自动分析Solidity智能合约并独立于具体行为模式检测金融中心化风险。JANUS通过比较特权账户与普通账户所达到的状态差异，并分析这些差异是否与财务相关，从而聚焦于风险的影响而非行为本身，提高了检测准确性。对包含540份合同的测试集进行评估显示，JANUS在检测金融中心化风险方面的准确率优于现有代表性工具。此外，在实际应用中，JANUS对33,151份合同进行了评估，成功发现了其他工具未能检测到的两种类型的风险。同时证明，JANUS使用的状态遍历方法和变量摘要并不会导致检测中的误报或遗漏。 <div>
arXiv:2412.03938v1 Announce Type: new 
Abstract: Some smart contracts violate decentralization principles by defining privileged accounts that manage other users' assets without permission, introducing centralization risks that have caused financial losses. Existing methods, however, face challenges in accurately detecting diverse centralization risks due to their dependence on predefined behavior patterns. In this paper, we propose JANUS, an automated analyzer for Solidity smart contracts that detects financial centralization risks independently of their specific behaviors. JANUS identifies differences between states reached by privileged and ordinary accounts, and analyzes whether these differences are finance-related. Focusing on the impact of risks rather than behaviors, JANUS achieves improved accuracy compared to existing tools and can uncover centralization risks with unknown patterns.
  To evaluate JANUS's performance, we compare it with other tools using a dataset of 540 contracts. Our evaluation demonstrates that JANUS outperforms representative tools in terms of detection accuracy for financial centralization risks . Additionally, we evaluate JANUS on a real-world dataset of 33,151 contracts, successfully identifying two types of risks that other tools fail to detect. We also prove that the state traversal method and variable summaries, which are used in JANUS to reduce the number of states to be compared, do not introduce false alarms or omissions in detection.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WACANA: A Concolic Analyzer for Detecting On-chain Data Vulnerabilities in WASM Smart Contracts</title>
<link>https://arxiv.org/abs/2412.03946</link>
<guid>https://arxiv.org/abs/2412.03946</guid>
<content:encoded><![CDATA[
<div> 关键词: WebAssembly (WASM), 智能合约, 安全漏洞, WACANA, 精细粒度模拟

总结:
<br />
本文介绍了针对WebAssembly (WASM)智能合约的安全分析工具WACANA。该工具通过精细粒度地模拟链上数据API来准确检测合同中的安全漏洞，从而克服了现有工具精度有限的问题。WACANA精确地模拟了链上数据表的结构和对应的API函数，并结合具体执行与符号执行，在保证准确性的同时提高了效率。实验结果显示，WACANA在对133份有漏洞的合约进行评估时，其准确性超过了当前最先进的工具。进一步在5,602个真实世界的合约中进行验证，证实了WACANA的实际有效性。 <div>
arXiv:2412.03946v1 Announce Type: new 
Abstract: WebAssembly (WASM) has emerged as a crucial technology in smart contract development for several blockchain platforms. Unfortunately, since their introduction, WASM smart contracts have been subject to several security incidents caused by contract vulnerabilities, resulting in substantial economic losses. However, existing tools for detecting WASM contract vulnerabilities have accuracy limitations, one of the main reasons being the coarse-grained emulation of the on-chain data APIs.
  In this paper, we introduce WACANA, an analyzer for WASM contracts that accurately detects vulnerabilities through fine-grained emulation of on-chain data APIs. WACANA precisely simulates both the structure of on-chain data tables and their corresponding API functions, and integrates concrete and symbolic execution within a coverage-guided loop to balance accuracy and efficiency. Evaluations on a vulnerability dataset of 133 contracts show WACANA outperforming state-of-the-art tools in accuracy. Further validation on 5,602 real-world contracts confirms WACANA's practical effectiveness.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dimension Reduction via Random Projection for Privacy in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2412.04031</link>
<guid>https://arxiv.org/abs/2412.04031</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent System (MAS), 信息融合中心, 隐私风险, 数据 utility, 数据隐私保护<br /><br />总结：<br />
本文探讨了多智能体系统(MAS)中，各智能体向信息融合中心发送观测数据时，为提高系统效率而需要附加私人参数所面临的隐私风险问题。为了在保证数据通信安全、防止数据隐私泄露和推理攻击的同时，尽可能减少对数据实用性的损失，文章使用余弦相似性量化系统的实用性和隐私性。文中首先将MAS问题形式化为一个可通过压缩方法解决的概念问题，接着提出一种基于此类压缩方法的创新性数据净化机制，旨在解决实用性与隐私保护之间的权衡问题。 <div>
arXiv:2412.04031v1 Announce Type: new 
Abstract: The agents in a Multi-Agent System (MAS) make observations about the system and send that information to a fusion center. The fusion center aggregates the information and concludes about the system parameters with as much accuracy as possible. However for the purposes of better efficiency of the system at large, the agents need to append some private parameters to the observed data. In this scenario, the data sent to the fusion center is faced with privacy risks. The data communicated to the fusion center must be secured against data privacy breaches and inference attacks in a decentralized manner. However, this in turn leads to a loss of utility of the data being sent to the fusion center. We quantify the utility and privacy of the system using Cosine similarity. We formulate our MAS problem in terms of deducing a concept for which compression-based methods are there in literature. Next, we propose a novel sanitization mechanism for our MAS using one such compression-based method while addressing the utility-privacy tradeoff problem.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Dynamic Event-triggered Output-feedback Control of Stochastic Non-triangular Interconnected Systems with Unknown Time-varying Sensor Sensitivity</title>
<link>https://arxiv.org/abs/2412.04131</link>
<guid>https://arxiv.org/abs/2412.04131</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized output-feedback control, stochastic non-triangular nonlinear systems, time-varying sensor sensitivity, dynamic event-triggered control, global asymptotic stability

总结:<br />
针对具有未知时变传感器灵敏度的随机非三角形非线性互联系统，该研究提出了一种新颖的去中心化动态事件触发输出反馈控制策略。首先，通过独特的坐标变换建立了各子系统的状态向量与两个误差向量之间的线性关系，有效处理了非三角形结构不确定性带来的复杂性。其次，引入了一种包含状态观测器和去中心化输出反馈控制器的动态事件触发机制，设计了一个基于预测plant状态值和时钟变量演化的辅助变量，确保了执行间隔时间存在正下界，从而避免Zeno行为。通过对封闭环路系统的Lyapunov分析，证实了系统全局概收敛稳定性，每个局部子系统的状态和输出均以概率收敛至原点。此外，还保证了触发时刻之间存在最小驻留时间。 <div>
arXiv:2412.04131v1 Announce Type: new 
Abstract: This study addresses the intricate challenge of decentralized output-feedback control for stochastic non-triangular nonlinear interconnected systems with unknown time-varying sensor sensitivity in a dynamic event-triggered context. The presence of stochastic disturbances, non-triangular structural uncertainties, and evolving sensor sensitivity distinguishes this problem of global asymptotic stability from conventional event-triggered control scenarios. Existing event-triggered control approaches with static event conditions encounter difficulties in simultaneously ensuring zero tracking/stabilization error and preventing the occurrence of Zeno behavior. In this work, we develop a novel solution to address this complex issue. Firstly, we establish a linear relationship between the state vector of each interconnected subsystem and two error vectors through a unique coordinate transformation. This transformation effectively handles the complexities introduced by non-triangular structural uncertainties. Secondly, we introduce a decentralized dynamic event-triggered output-feedback control strategy, which involves a state observer and a decentralized output-feedback controller. Unlike conventional event-triggered control methods with static event conditions, this strategy formulates a modified clock-based dynamic triggering mechanism by introducing an auxiliary variable that evolves based on predicted plant state values, while utilizing a clock variable to guarantee the existence of a positive lower bound on inter-execution times. Rigorous Lyapunov analysis confirms the global asymptotic stability in probability of the closed-loop system, with the states and the output of each local subsystem converging to the equilibrium at the origin in probability. Additionally, the existence of a minimal dwell-time between triggering instants is guaranteed.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DistB-VNET: Distributed Cluster-based Blockchain Vehicular Ad-Hoc Networks through SDN-NFV for Smart City</title>
<link>https://arxiv.org/abs/2412.04222</link>
<guid>https://arxiv.org/abs/2412.04222</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能城市、车联网、分布式区块链、软件定义网络、网络功能虚拟化<br /><br />总结:
本文提出了一个名为DistB-VNET的分布式区块链车联网架构，旨在为智能城市的车辆与基础设施交互提供安全、可扩展和可靠的通信。该架构融合了二进制恶意流量分类、软件定义网络(SDN)和网络功能虚拟化(NFV)，利用去中心化的区块链保障数据安全管理，结合SDN-NFV实现动态网络管理和资源效率提升。同时，采用孤立森林算法作为入侵检测系统，其在识别恶意流量方面达到了99.23%的高精度。DistB-VNET还引入了双层区块链系统，其中分布式区块链确保车车间的安全通信，而云中的集中式区块链负责数据验证和存储，增强了安全性、可扩展性和适应性，有助于优化交通管理、提高数据安全性和隐私保护。此外，这种方案显著降低了延迟，提高了网络安全性能并减少了网络拥塞，为现有的智能城市基础设施提供了有效的替代选择。 <div>
arXiv:2412.04222v1 Announce Type: new 
Abstract: In the developing topic of smart cities, Vehicular Ad-Hoc Networks (VANETs) are crucial for providing successful interaction between vehicles and infrastructure. This research proposes a distributed Blockchain-based Vehicular Ad-hoc Network (DistB-VNET) architecture that includes binary malicious traffic classification, Software Defined Networking (SDN), and Network Function Virtualization (NFV) to ensure safe, scalable, and reliable vehicular networks in smart cities. The suggested framework is the decentralized blockchain for safe data management and SDN-NFV for dynamic network management and resource efficiency and a noble isolation forest algorithm works as an IDS (Intrusion Detection System). Further, "DistB-VNET" offers a dual-layer blockchain system, where a distributed blockchain provides safe communication between vehicles, while a centralized blockchain in the cloud is in charge of data verification and storage. This improves security, scalability, and adaptability, ensuring better traffic management, data security, and privacy in VANETs. Furthermore, the unsupervised isolation forest model achieves a high accuracy of 99.23% for detecting malicious traffic. Additionally, reveals that our method greatly improves network performance, offering decreased latency, increased security, and reduced congestion, an effective alternative for existing smart city infrastructures.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>VMGuard: Reputation-Based Incentive Mechanism for Poisoning Attack Detection in Vehicular Metaverse</title>
<link>https://arxiv.org/abs/2412.04349</link>
<guid>https://arxiv.org/abs/2412.04349</guid>
<content:encoded><![CDATA[
<div> 关键词：vehicular Metaverse, 数据中毒攻击, 安全框架, 信任度评估, 口碑激励机制

总结:
<br />
本文提出了一种名为vehicular Metaverse guard (VMGuard)的四层安全框架，用于保护车载元宇宙系统免受数据中毒攻击。该框架针对虚拟服务提供商(VSPs)通过恶意物联网(IoT)设备收集物理环境数据时可能存在的内容篡改问题，以及具有道德风险的恶意SIoT设备可能出于私利提供有毒数据以降低VMUs的服务质量和用户体验(QoS和QoE)的问题。VMGuard采用了基于用户反馈和主观逻辑建模的口碑激励机制，为参与的SIoT设备根据历史交互记录分配声誉评分。通过综合模拟验证，该机制能有效阻止恶意SIoT设备发起的中毒攻击，并确保先前被误分类的可靠SIoT设备不会被排除在未来市场轮次之外。 <div>
arXiv:2412.04349v1 Announce Type: new 
Abstract: The vehicular Metaverse represents an emerging paradigm that merges vehicular communications with virtual environments, integrating real-world data to enhance in-vehicle services. However, this integration faces critical security challenges, particularly in the data collection layer where malicious sensing IoT (SIoT) devices can compromise service quality through data poisoning attacks. The security aspects of the Metaverse services should be well addressed both when creating the digital twins of the physical systems and when delivering the virtual service to the vehicular Metaverse users (VMUs). This paper introduces vehicular Metaverse guard (VMGuard), a novel four-layer security framework that protects vehicular Metaverse systems from data poisoning attacks. Specifically, when the virtual service providers (VSPs) collect data about physical environment through SIoT devices in the field, the delivered content might be tampered. Malicious SIoT devices with moral hazard might have private incentives to provide poisoned data to the VSP to degrade the service quality (QoS) and user experience (QoE) of the VMUs. The proposed framework implements a reputation-based incentive mechanism that leverages user feedback and subjective logic modeling to assess the trustworthiness of participating SIoT devices. More precisely, the framework entails the use of reputation scores assigned to participating SIoT devices based on their historical engagements with the VSPs. Ultimately, we validate our proposed model using comprehensive simulations. Our key findings indicate that our mechanism effectively prevents the initiation of poisoning attacks by malicious SIoT devices. Additionally, our system ensures that reliable SIoT devices, previously missclassified, are not barred from participating in future rounds of the market.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Providing Differential Privacy for Federated Learning Over Wireless: A Cross-layer Framework</title>
<link>https://arxiv.org/abs/2412.04408</link>
<guid>https://arxiv.org/abs/2412.04408</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Over-the-air FL, Differential Privacy, Power Control, Cooperative Jammer

<br /><br />总结:
本文提出了一个针对无线边缘网络中Over-the-air FL的物理层设计，旨在增强差分隐私保护。该设计采用一种去中心化、动态的功率控制策略，利用无线信道中的高斯噪声和合作干扰器（CJ）生成额外的人工噪声以在需要更高隐私级别时提供支持。虽然主要应用于Upcycled-FL框架，但该功率控制策略也可适用于FedAvg和FedProx等其他FL框架，展现了其灵活性和普适性。此外，该设计通过合作干扰器增强了隐私保护，无需客户端注入人工噪声，同时保证了传输效率。文中使用Moments Accountant方法进行了隐私分析，并对非凸目标函数下的收敛性进行了分析，探讨了隐私与准确性之间的权衡。数值结果表明，无论是在FEMNIST非独立同分布数据集上，还是在相同的差分隐私条件下，与现有技术相比，本文提出的方法都表现出了优越性能，并突显了合作干扰器在确保严格隐私方面的有效性。 <div>
arXiv:2412.04408v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning framework that inherently allows edge devices to maintain their local training data, thus providing some level of privacy. However, FL's model updates still pose a risk of privacy leakage, which must be mitigated. Over-the-air FL (OTA-FL) is an adapted FL design for wireless edge networks that leverages the natural superposition property of the wireless medium. We propose a wireless physical layer (PHY) design for OTA-FL which improves differential privacy (DP) through a decentralized, dynamic power control that utilizes both inherent Gaussian noise in the wireless channel and a cooperative jammer (CJ) for additional artificial noise generation when higher privacy levels are required. Although primarily implemented within the Upcycled-FL framework, where a resource-efficient method with first-order approximations is used at every even iteration to decrease the required information from clients, our power control strategy is applicable to any FL framework, including FedAvg and FedProx as shown in the paper. This adaptation showcases the flexibility and effectiveness of our design across different learning algorithms while maintaining a strong emphasis on privacy. Our design removes the need for client-side artificial noise injection for DP, utilizing a cooperative jammer to enhance privacy without affecting transmission efficiency for higher privacy demands. Privacy analysis is provided using the Moments Accountant method. We perform a convergence analysis for non-convex objectives to tackle heterogeneous data distributions, highlighting the inherent trade-offs between privacy and accuracy. Numerical results show that our approach with various FL algorithms outperforms the state-of-the-art under the same DP conditions on the non-i.i.d. FEMNIST dataset, and highlight the cooperative jammer's effectiveness in ensuring strict privacy.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Market Consequences of Perceived Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers</title>
<link>https://arxiv.org/abs/2401.12064</link>
<guid>https://arxiv.org/abs/2401.12064</guid>
<content:encoded><![CDATA[
<div> 关键词：Crypto donations, NFT charity fundraisers, Social image, Market outcomes, Online experiment

<br /><br />总结：
本文探讨了非同质化代币（NFT）慈善筹款活动中捐赠者的动机和经济后果，特别是捐赠者从升值的NFT中可能获得的财务收益对社会形象的影响。研究通过利用区块链上交易处理时间的随机变化来识别在慈善筹款活动中购买NFT对捐赠者后续市场结果的因果效应。进一步分析发现，将购得的慈善NFT重新上市出售（显示战略性慷慨行为）的个人以及在NFT市场中有较高社交曝光度的人，在其其他NFT的价格方面会受到显著惩罚。在线实验的结果也证实了这一发现，表明将慈善NFT转售以获利会让他人将其初始捐赠视为具有战略性的慷慨行为，从而降低他人从该捐赠者处购买NFT的意愿。这项研究强调了在加密慈善和更广泛的网络慈善领域中，数字可见性和可追溯性日益重要的影响。 <div>
arXiv:2401.12064v2 Announce Type: replace-cross 
Abstract: Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about donors' motivations in these charity fundraisers, potentially resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of perceived strategic generosity) and based on an individual's social exposure within the NFT marketplace. We show that charity-NFT 're-listers' experience significant penalties in the market regarding the prices they can command for their other NFTs, particularly among those who are more socially exposed. Finally, we report the results of a scenario-based online experiment, which again support our findings, highlighting that the re-listing a charity NFT for sale at a profit leads others to perceive their initial donation as strategic generosity and reduces those others' willingness to purchase NFTs from the donor. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Block MedCare: Advancing healthcare through blockchain integration with AI and IoT</title>
<link>https://arxiv.org/abs/2412.02851</link>
<guid>https://arxiv.org/abs/2412.02851</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、医疗健康、电子病历管理、以太坊、安全性、效率、患者控制、数字签名、角色访问控制、多层架构、去中心化应用、物联网设备、人工智能分析、整合成本、互操作性

<br /><br />总结：
该研究探索了将区块链技术应用于医疗健康领域，尤其是如何通过构建基于以太坊的新型系统来提升电子病历（EHR）管理的安全性和效率。此系统让病人能够安全地掌控自己的医疗数据，同时解决了实施医疗区块链面临的可扩展性、隐私和法规遵从性等挑战。该系统采用了数字签名、基于角色的访问控制以及多层架构，确保对数据的可控和安全访问。研究人员开发了一个面向患者、医生和管理员的用户友好的去中心化应用（dApp），展示了解决方案的实际应用价值。针对医疗保健专业人士和IT专家进行的调查显示，他们对于区块链技术的应用表示强烈兴趣，同时也关注其整合成本问题。此外，研究还探讨了未来与物联网设备和人工智能驱动的分析工具的融合，以期推动更安全、高效、互操作性的医疗系统的进化，从而利用前沿技术为改善患者护理提供支持。 <div>
arXiv:2412.02851v1 Announce Type: new 
Abstract: This research explores the integration of blockchain technology in healthcare, focusing on enhancing the security and efficiency of Electronic Health Record (EHR) management. We propose a novel Ethereum-based system that empowers patients with secure control over their medical data. Our approach addresses key challenges in healthcare blockchain implementation, including scalability, privacy, and regulatory compliance. The system incorporates digital signatures, Role-Based Access Control, and a multi-layered architecture to ensure secure, controlled access. We developed a decentralized application (dApp) with user-friendly interfaces for patients, doctors, and administrators, demonstrating the practical application of our solution. A survey among healthcare professionals and IT experts revealed strong interest in blockchain adoption, while also highlighting concerns about integration costs. The study explores future enhancements, including integration with IoT devices and AI-driven analytics, contributing to the evolution of secure, efficient, and interoperable healthcare systems that leverage cutting-edge technologies for improved patient care.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BGTplanner: Maximizing Training Accuracy for Differentially Private Federated Recommenders via Strategic Privacy Budget Allocation</title>
<link>https://arxiv.org/abs/2412.02934</link>
<guid>https://arxiv.org/abs/2412.02934</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦推荐系统(FR)，差分隐私(DP)，Differentially Private Federated Recommender (DPFR)，预算规划器(BGTplanner)，上下文多臂博弈(CMAB)

总结:<br />
本文针对差分隐私联邦推荐系统(DPFR)存在的噪声失真导致的准确性不足问题，提出了一种名为BGTplanner的新方法，用于战略性的在每轮DPFR训练中分配隐私预算以提升整体训练性能。BGTplanner利用高斯过程回归预测给定隐私预算下推荐精度的变化，并结合历史信息以及上下文多臂博弈(CMAB)进行决策，平衡当前优化与长期隐私约束。实验结果显示，相比于现有最优基线，BGTplanner在真实数据集上平均提高了6.76%的训练性能。 <div>
arXiv:2412.02934v1 Announce Type: new 
Abstract: To mitigate the rising concern about privacy leakage, the federated recommender (FR) paradigm emerges, in which decentralized clients co-train the recommendation model without exposing their raw user-item rating data. The differentially private federated recommender (DPFR) further enhances FR by injecting differentially private (DP) noises into clients. Yet, current DPFRs, suffering from noise distortion, cannot achieve satisfactory accuracy. Various efforts have been dedicated to improving DPFRs by adaptively allocating the privacy budget over the learning process. However, due to the intricate relation between privacy budget allocation and model accuracy, existing works are still far from maximizing DPFR accuracy. To address this challenge, we develop BGTplanner (Budget Planner) to strategically allocate the privacy budget for each round of DPFR training, improving overall training performance. Specifically, we leverage the Gaussian process regression and historical information to predict the change in recommendation accuracy with a certain allocated privacy budget. Additionally, Contextual Multi-Armed Bandit (CMAB) is harnessed to make privacy budget allocation decisions by reconciling the current improvement and long-term privacy constraints. Our extensive experimental results on real datasets demonstrate that \emph{BGTplanner} achieves an average improvement of 6.76\% in training performance compared to state-of-the-art baselines.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Mobile Target Tracking Using Consensus-Based Estimation with Nearly-Constant-Velocity Modeling</title>
<link>https://arxiv.org/abs/2412.03095</link>
<guid>https://arxiv.org/abs/2412.03095</guid>
<content:encoded><![CDATA[
<div> 关键词：移动目标跟踪、分布式追踪框架、一致性估计滤波器（CBEF）、近似常速模型、饱和基过滤技术

总结:
本文提出了一种利用一致性估计滤波器（CBEF）与近似常速模型集成的分布式移动目标跟踪框架。该框架允许网络中的代理节点通过共享局部观测数据并达成共识来共同估计目标位置，即使存在通信约束和测量噪声也能实现这一目标。文中采用饱和基过滤技术增强了系统的鲁棒性，降低了由于传感器数据噪声带来的影响。仿真结果表明，所提出的方案能够随时间有效降低均方估计误差（MSEE），从而提高估计算法的精度和可靠性。这凸显了CBEF在分布式环境中的有效性及其在不确定性条件下的可扩展性和韧性。 <div>
arXiv:2412.03095v1 Announce Type: new 
Abstract: Mobile target tracking is crucial in various applications such as surveillance and autonomous navigation. This study presents a decentralized tracking framework utilizing a Consensus-Based Estimation Filter (CBEF) integrated with the Nearly-Constant-Velocity (NCV) model to predict a moving target's state. The framework facilitates agents in a network to collaboratively estimate the target's position by sharing local observations and achieving consensus despite communication constraints and measurement noise. A saturation-based filtering technique is employed to enhance robustness by mitigating the impact of noisy sensor data. Simulation results demonstrate that the proposed method effectively reduces the Mean Squared Estimation Error (MSEE) over time, indicating improved estimation accuracy and reliability. The findings underscore the effectiveness of the CBEF in decentralized environments, highlighting its scalability and resilience in the presence of uncertainties.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.03188</link>
<guid>https://arxiv.org/abs/2412.03188</guid>
<content:encoded><![CDATA[
<div> 关键词：智能移动、分布式传感器、时空图神经网络（ST-GNN）、半去中心化训练、云计算节点

总结:<br />
本文针对智能移动领域中大量地理分布传感器产生的高频率时空数据实时处理问题，提出了利用半去中心化的时空图神经网络（ST-GNN）训练技术。文章设计了一个模拟框架，将传感器按地理位置划分为多个云计算节点，每个节点处理交通图的一部分并从其他节点获取节点特征来训练本地ST-GNN模型，同时与其他节点交换模型更新以保持一致性，从而提高可扩展性和容错性。通过对比分析四种不同的ST-GNN训练设置（集中式、传统联邦学习、无服务器联邦学习和Gossip Learning），在大规模交通数据集METR-LA和PeMS-BAY上进行短期、中期和长期车辆速度预测任务的实验，结果显示半去中心化设置在性能指标上与集中式方法相当，但在可扩展性和容错性方面具有优势。此外，文中还指出了现有文献中关于分布式ST-GNNs常常被忽视的问题，如不同地理区域间因特定交通模式导致的模型性能差异以及由GNN大感受野引发的显著通信开销和计算成本，进而造成大量的数据传输和局部嵌入计算增加。 <div>
arXiv:2412.03188v1 Announce Type: new 
Abstract: In smart mobility, large networks of geographically distributed sensors produce vast amounts of high-frequency spatio-temporal data that must be processed in real time to avoid major disruptions. Traditional centralized approaches are increasingly unsuitable to this task, as they struggle to scale with expanding sensor networks, and reliability issues in central components can easily affect the whole deployment. To address these challenges, we explore and adapt semi-decentralized training techniques for Spatio-Temporal Graph Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation framework where sensors are grouped by proximity into multiple cloudlets, each handling a subgraph of the traffic graph, fetching node features from other cloudlets to train its own local ST-GNN model, and exchanging model updates with other cloudlets to ensure consistency, enhancing scalability and removing reliance on a centralized aggregator. We perform extensive comparative evaluation of four different ST-GNN training setups -- centralized, traditional FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed predictions. Experimental results show that semi-decentralized setups are comparable to centralized approaches in performance metrics, while offering advantages in terms of scalability and fault tolerance. In addition, we highlight often overlooked issues in existing literature for distributed ST-GNNs, such as the variation in model performance across different geographical areas due to region-specific traffic patterns, and the significant communication overhead and computational costs that arise from the large receptive field of GNNs, leading to substantial data transfers and increased computation of partial embeddings.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>HCC: A Language-Independent Hardening Contract Compiler for Smart Contracts</title>
<link>https://arxiv.org/abs/2203.00364</link>
<guid>https://arxiv.org/abs/2203.00364</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全智能合约、HCC、源代码级安全检查、代码属性图(CPG)、实用型编译器

总结:
本文提出了一种名为HCC的首个实用型智能合约编译器，旨在自动在源代码层面插入基于新型语言无关代码属性图(CPG)表示的安全强化检查。CPG的高度表达性使HCC能够缓解包括重入攻击、整数错误、自杀式智能合约、不恰当使用tx.origin、不受信任的委托调用以及未检查的低级别调用等最常见的智能合约漏洞。通过对1万个真实世界的智能合约及几组来自相关工作的易受攻击的合约进行大规模评估，结果显示HCC具有高度实用性，优于现有的合约强化技术，并能有效阻止所有验证过的攻击交易，同时并未损害功能正确性。<br /><br /> <div>
arXiv:2203.00364v2 Announce Type: replace 
Abstract: Developing secure smart contracts remains a challenging task. Existing approaches are either impractical or leave the burden to developers for fixing bugs. In this paper, we propose the first practical smart contract compiler, called HCC, which automatically inserts security hardening checks at the source-code level based on a novel and language-independent code property graph (CPG) notation. The high expressiveness of our developed CPG allows us to mitigate all of the most common smart contract vulnerabilities, namely reentrancy, integer bugs, suicidal smart contracts, improper use of tx.origin, untrusted delegate-calls, and unchecked low-level call bugs. Our large-scale evaluation on 10k real-world contracts and several sets of vulnerable contracts from related work demonstrates that HCC is highly practical, outperforms state-of-the-art contract hardening techniques, and effectively prevents all verified attack transactions without hampering functional correctness.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Development and Application of a Decentralized Domain Name Service</title>
<link>https://arxiv.org/abs/2412.01959</link>
<guid>https://arxiv.org/abs/2412.01959</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Domain Name Service (DDNS)，区块链(Phicoin)，分布式存储(IPFS)，中心化架构，安全稳定性

总结:
<br />
本文提出了一种基于区块链(Phicoin)和分布式存储(IPFS)的去中心化域名服务系统（DDNS），旨在解决现有域名系统(DNS)存在的问题。传统DNS存在中心化架构带来的审查风险、单点故障及解析过程中的加密安全性不足等问题，同时高运营成本限制了中小用户参与与创新。DDNS通过利用区块链的不可篡改性以及IPFS的内容验证特性，实现了域名记录的去中心化存储和分布，消除了对传统DNS的中心化依赖。该系统支持每15秒快速广播一次域名更新，显著提高了解析效率。DDNS的目标是作为现有DNS系统的补充或备份，提供一种抗污染、抗审查、高性能、低成本的域名解析解决方案，为互联网的安全稳定提供了新的技术路径。 <div>
arXiv:2412.01959v1 Announce Type: new 
Abstract: The current Domain Name System (DNS), as a core infrastructure of the internet, exhibits several shortcomings: its centralized architecture leads to censorship risks and single points of failure, making domain name resolution vulnerable to attacks. The lack of encryption in the resolution process exposes it to DNS hijacking and cache poisoning attacks. Additionally, the high operational costs limit participation and innovation among small to medium-sized users. To address these issues, this paper proposes a Decentralized Domain Name Service (DDNS) based on blockchain (Phicoin) and distributed storage (IPFS). By leveraging the immutability of blockchain and the content verification of IPFS, the system achieves decentralized storage and distribution of domain name records, eliminating the centralized dependencies of traditional DNS. With a block time of 15 seconds, the system supports rapid broadcasting of domain name updates, significantly improving resolution efficiency. The DDNS aims to serve as a complement or backup to the existing DNS system, providing a pollution-resistant, censorship-resistant, high-performance, and low-cost domain name resolution solution, offering a new technical path for the security and stability of the internet.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generalized EXTRA stochastic gradient Langevin dynamics</title>
<link>https://arxiv.org/abs/2412.01993</link>
<guid>https://arxiv.org/abs/2412.01993</guid>
<content:encoded><![CDATA[
<div> 关键词：Langevin算法，Markov Chain Monte Carlo，贝叶斯学习，分布式SGLD（DE-SGLD），generalized EXTRA stochastic gradient Langevin dynamics

<br /><br />总结:
该文主要关注在数据分散于网络各节点并受到通信和隐私限制的情况下，如何进行贝叶斯学习的问题。标准的随机梯度Langevin动力学（SGLD）不适用于此场景，因此提出了分布式SGLD（DE-SGLD）算法。然而，现有的DE-SGLD算法在每个节点上存在偏差问题，即使使用完整批次的数据也是如此。为此，文章受EXTRA算法及其优化版本启发，提出了一种广义EXTRA随机梯度Langevin动力学算法，该算法成功消除了在全批次设置下的这一偏差。此外，在迷你批次设置下，新算法还提供了优于现有DE-SGLD算法的性能边界。数值实验进一步证实了所提方法的有效性。 <div>
arXiv:2412.01993v1 Announce Type: new 
Abstract: Langevin algorithms are popular Markov Chain Monte Carlo methods for Bayesian learning, particularly when the aim is to sample from the posterior distribution of a parametric model, given the input data and the prior distribution over the model parameters. Their stochastic versions such as stochastic gradient Langevin dynamics (SGLD) allow iterative learning based on randomly sampled mini-batches of large datasets and are scalable to large datasets. However, when data is decentralized across a network of agents subject to communication and privacy constraints, standard SGLD algorithms cannot be applied. Instead, we employ decentralized SGLD (DE-SGLD) algorithms, where Bayesian learning is performed collaboratively by a network of agents without sharing individual data. Nonetheless, existing DE-SGLD algorithms induce a bias at every agent that can negatively impact performance; this bias persists even when using full batches and is attributable to network effects. Motivated by the EXTRA algorithm and its generalizations for decentralized optimization, we propose the generalized EXTRA stochastic gradient Langevin dynamics, which eliminates this bias in the full-batch setting. Moreover, we show that, in the mini-batch setting, our algorithm provides performance bounds that significantly improve upon those of standard DE-SGLD algorithms in the literature. Our numerical results also demonstrate the efficiency of the proposed approach.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AVA: Fault-tolerant Reconfigurable Geo-Replication on Heterogeneous Clusters</title>
<link>https://arxiv.org/abs/2412.01999</link>
<guid>https://arxiv.org/abs/2412.01999</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2412.01999v1, 故障容错, 分布式数据库系统, 集群复制协议, AVA

总结:
该论文介绍了arXiv:2412.01999v1中提出的一种新型技术，针对全球金融基础设施构建中能源消耗更低的、容错性强的复制数据库系统。现有的集群复制协议往往假设节点数量恒定且均匀分布，并仅考虑简单故障模型（如停止失败）。论文提出了适用于具有任意故障情况的异构可重构的地理复制协议AVA，允许副本动态加入和离开集群，并形式化证明了协议的安全性和活性。此外，AVA协议共识机制无关，即每个集群可以使用任何本地复制机制。实验结果显示，在谷歌云上进行的地理分布式部署实验表明，无需显著影响交易处理即可重新配置集群成员，而集群的异构性则可能显著提高吞吐量。 <div>
arXiv:2412.01999v1 Announce Type: new 
Abstract: Fault-tolerant replicated database systems consume less energy than the compute-intensive proof-of-work blockchain. Thus, they are promising technologies for the building blocks that assemble global financial infrastructure. To facilitate global scaling, clustered replication protocols are essential in orchestrating nodes into clusters based on proximity. However, the existing approaches often assume a homogeneous and fixed model in which the number of nodes across clusters is the same and fixed, and often limited to a fail-stop fault model. This paper presents heterogeneous and reconfigurable clustered replication for the general environment with arbitrary failures. In particular, we present AVA, a fault-tolerant reconfigurable geo-replication that allows dynamic membership: replicas are allowed to join and leave clusters. We formally state and prove the safety and liveness properties of the protocol. Furthermore, our replication protocol is consensus-agnostic, meaning each cluster can utilize any local replication mechanism. In our comprehensive evaluation, we instantiate our replication with both HotStuff and BFT-SMaRt. Experiments on geo-distributed deployments on Google Cloud demonstrates that members of clusters can be reconfigured without considerably affecting transaction processing, and that heterogeneity of clusters may significantly improve throughput.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Enabled Device-Enhanced Multi-Access Edge Computing in Open Adversarial Environments</title>
<link>https://arxiv.org/abs/2412.02233</link>
<guid>https://arxiv.org/abs/2412.02233</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC), Honeybee框架, 区块链技术, 安全性, 效率

总结:
<br />
本文提出了一个名为Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC)的新框架，该框架基于Honeybee的按需资源池化理念并结合区块链技术，旨在确保不同拥有者的设备之间的信任、安全和可问责性。通过使计算过程可追溯，BdMEC降低了来自恶意设备的风险。原型与实验结果表明，BdMEC能够在多个设备间有效地、安全地管理分布式计算任务。 <div>
arXiv:2412.02233v1 Announce Type: new 
Abstract: We propose Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC). BdMEC extends the Honeybee framework for on-demand resource pooling with blockchain technology to ensure trust, security, and accountability among devices (even when they are owned by different parties). BdMEC mitigates risks from malicious devices by making computations traceable. Our prototype and results demonstrate BdMEC's ability to manage distributed computing tasks efficiently and securely across multiple devices.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence</title>
<link>https://arxiv.org/abs/2412.02263</link>
<guid>https://arxiv.org/abs/2412.02263</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链智能合约、大型语言模型、数据聚合、语义相关性、信任度发现

<br /><br />总结:
本文提出了一个名为{\sysname}的通用框架，旨在解决区块链智能合约与大型语言模型（LLMs）之间集成的难题，克服两者之间的互操作性障碍。通过结合语义相关性和真相发现方法，文章提出了一种创新的数据聚合方法{\funcname}，能显著提升由LLMs生成数据的准确性和可信度。为了验证框架的有效性，研究构建了一个包含三种类型问题的实验数据集，涵盖了10个预言机节点和5个LLM模型的Q&amp;A交互。实验结果显示，即使在40%恶意节点的情况下，该方案相比最优基线仍能平均提高数据准确性17.74%。这项研究不仅为智能合约的智能化增强提供了创新解决方案，还突显了LLMs与区块链技术深度整合的潜力，为未来更智能、更复杂的智能合约应用铺平道路。 <div>
arXiv:2412.02263v1 Announce Type: new 
Abstract: Blockchain smart contracts have catalyzed the development of decentralized applications across various domains, including decentralized finance. However, due to constraints in computational resources and the prevalence of data silos, current smart contracts face significant challenges in fully leveraging the powerful capabilities of Large Language Models (LLMs) for tasks such as intelligent analysis and reasoning. To address this gap, this paper proposes and implements a universal framework for integrating LLMs with blockchain data, {\sysname}, effectively overcoming the interoperability barriers between blockchain and LLMs. By combining semantic relatedness with truth discovery methods, we introduce an innovative data aggregation approach, {\funcname}, which significantly enhances the accuracy and trustworthiness of data generated by LLMs. To validate the framework's effectiveness, we construct a dataset consisting of three types of questions, capturing Q\&amp;A interactions between 10 oracle nodes and 5 LLM models. Experimental results demonstrate that, even with 40\% malicious nodes, the proposed solution improves data accuracy by an average of 17.74\% compared to the optimal baseline. This research not only provides an innovative solution for the intelligent enhancement of smart contracts but also highlights the potential for deep integration between LLMs and blockchain technology, paving the way for more intelligent and complex applications of smart contracts in the future.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learn More by Using Less: Distributed Learning with Energy-Constrained Devices</title>
<link>https://arxiv.org/abs/2412.02289</link>
<guid>https://arxiv.org/abs/2412.02289</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、系统异构性、能源限制、LeanFed、电池寿命

总结:
<br />
本文提出了一种名为LeanFed的能源感知型联邦学习框架，旨在解决参与训练的分布式设备因能源容量差异而带来的实际部署问题。LeanFed通过动态调整每个设备在训练过程中使用的局部数据比例，优化客户端选择和训练工作负载，从而最大化通信轮次中的设备参与度并确保它们不会耗尽电池电量。通过对CIFAR-10和CIFAR-100数据集进行模拟实验，与传统FedAvg方法对比，结果显示LeanFed在具有高度数据异构性和有限电池寿命的情况下，能显著提高模型准确性和稳定性，减少了客户端掉线情况，并延长了设备可用时间。这一方法彰显了能源高效、隐私保护的联邦学习在现实世界大规模应用中的潜力，为资源受限网络上的强大且可持续的人工智能奠定了基础。 <div>
arXiv:2412.02289v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a solution for distributed model training across decentralized, privacy-preserving devices, but the different energy capacities of participating devices (system heterogeneity) constrain real-world implementations. These energy limitations not only reduce model accuracy but also increase dropout rates, impacting on convergence in practical FL deployments. In this work, we propose LeanFed, an energy-aware FL framework designed to optimize client selection and training workloads on battery-constrained devices. LeanFed leverages adaptive data usage by dynamically adjusting the fraction of local data each device utilizes during training, thereby maximizing device participation across communication rounds while ensuring they do not run out of battery during the process. We rigorously evaluate LeanFed against traditional FedAvg on CIFAR-10 and CIFAR-100 datasets, simulating various levels of data heterogeneity and device participation rates. Results show that LeanFed consistently enhances model accuracy and stability, particularly in settings with high data heterogeneity and limited battery life, by mitigating client dropout and extending device availability. This approach demonstrates the potential of energy-efficient, privacy-preserving FL in real-world, large-scale applications, setting a foundation for robust and sustainable pervasive AI on resource-constrained networks.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bio-inspired visual relative localization for large swarms of UAVs</title>
<link>https://arxiv.org/abs/2412.02393</link>
<guid>https://arxiv.org/abs/2412.02393</guid>
<content:encoded><![CDATA[
<div> 关键词: visual perception, relative localization, UAVs, swarm control, neighbor density regression

总结:<br />
本文提出了一种新的用于无人机群体大规模相对定位的视觉感知方法。该方法受到生物感知机制的启发，如沙丁鱼群和蜜蜂群等动物群体能以分散但协调的方式移动，不再依赖于每个个体对邻居的位置估计，而是通过回归距离上的邻居密度来实现相对定位，从而提高了距离估算的准确性并提升了对邻数量级变化的可扩展性。此外，文章还提出了一种与新定位方法相兼容的新型群体控制算法。通过对所提方法的详尽评估，结果表明，基于回归的距离估计方法对于目标相对姿态变化更具鲁棒性，并且适合作为群体稳定控制的主要相对定位来源。 <div>
arXiv:2412.02393v1 Announce Type: new 
Abstract: We propose a new approach to visual perception for relative localization of agents within large-scale swarms of UAVs. Inspired by biological perception utilized by schools of sardines, swarms of bees, and other large groups of animals capable of moving in a decentralized yet coherent manner, our method does not rely on detecting individual neighbors by each agent and estimating their relative position, but rather we propose to regress a neighbor density over distance. This allows for a more accurate distance estimation as well as better scalability with respect to the number of neighbors. Additionally, a novel swarm control algorithm is proposed to make it compatible with the new relative localization method. We provide a thorough evaluation of the presented methods and demonstrate that the regressing approach to distance estimation is more robust to varying relative pose of the targets and that it is suitable to be used as the main source of relative localization for swarm stabilization.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Ensemble-Based Semi-Supervised Learning for Illicit Account Detection in Ethereum DeFi Transactions</title>
<link>https://arxiv.org/abs/2412.02408</link>
<guid>https://arxiv.org/abs/2412.02408</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), Ethereum区块链, 自动学习, 非法账户检测, SLEID框架

<br /><br />总结:

本文提出了一个名为Self-Learning Ensemble-based Illicit account Detection (SLEID)的新型框架，用于解决以太坊区块链上去中心化金融(DeFi)领域日益严重的安全风险问题，特别是非法账户欺诈行为。SLEID框架采用Isolation Forest进行初步异常检测，并利用自训练机制生成未标注账户的伪标签，从而提高检测准确性。通过大量实验，SLEID展示出了比传统监督方法和近期半监督模型更高的精确度、召回率和F1分数，尤其在识别非法账户方面表现出色。相较于现有最先进的方法，SLEID在降低对标注数据依赖的同时，实现了更好的检测性能，为保护DeFi生态系统及防范恶意账户带来的风险提供了有力保障。 <div>
arXiv:2412.02408v1 Announce Type: new 
Abstract: The advent of smart contracts has enabled the rapid rise of Decentralized Finance (DeFi) on the Ethereum blockchain, offering substantial rewards in financial innovation and inclusivity. However, this growth has also introduced significant security risks, including the proliferation of illicit accounts involved in fraudulent activities. Traditional detection methods are limited by the scarcity of labeled data and the evolving tactics of malicious actors. In this paper, we propose a novel Self-Learning Ensemble-based Illicit account Detection (SLEID) framework to address these challenges. SLEID employs an Isolation Forest for initial outlier detection and a self-training mechanism to iteratively generate pseudo-labels for unlabeled accounts, thereby enhancing detection accuracy. Extensive experiments demonstrate that SLEID significantly outperforms traditional supervised approaches and recent semi-supervised models, achieving superior precision, recall, and F1-scores, particularly in detecting illicit accounts. Compared to state-of-the-art methods, our approach achieves better detection performance while reducing reliance on labeled data. The results affirm SLEID's efficacy as a robust solution for safeguarding the DeFi ecosystem and mitigating risks posed by malicious accounts.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Defending Against Diverse Attacks in Federated Learning Through Consensus-Based Bi-Level Optimization</title>
<link>https://arxiv.org/abs/2412.02535</link>
<guid>https://arxiv.org/abs/2412.02535</guid>
<content:encoded><![CDATA[
<div> 关键词：adversarial attacks、federated learning、bi-level optimization、CB$^2$O、FedCB$^2$O

总结:
针对机器学习中对抗性攻击带来的挑战，特别是分布式训练和联邦学习中的问题，本文提出了一种将训练任务建模为双层优化问题的方法。文章对共识型双层优化（CB$^2$O）方法在有恶意代理的对抗性环境下的鲁棒性进行了理论分析，证明了CB$^2$O在均场定律下在全球收敛性方面的优势，揭示了其对于各种攻击的抵抗能力，并阐述了如何通过选择特定的超参数来减轻对抗性影响。从实践层面出发，本文将CB$^2$O扩展到聚类联邦学习场景，提出了新型的交互多粒子系统——FedCB$^2$O，并设计了一个适用于实际应用的算法。实验结果表明，FedCB$^2$O算法在去中心化聚类联邦学习场景下对于标签翻转攻击具有较强的鲁棒性，显示出了其实战的有效性。 <div>
arXiv:2412.02535v1 Announce Type: new 
Abstract: Adversarial attacks pose significant challenges in many machine learning applications, particularly in the setting of distributed training and federated learning, where malicious agents seek to corrupt the training process with the goal of jeopardizing and compromising the performance and reliability of the final models. In this paper, we address the problem of robust federated learning in the presence of such attacks by formulating the training task as a bi-level optimization problem. We conduct a theoretical analysis of the resilience of consensus-based bi-level optimization (CB$^2$O), an interacting multi-particle metaheuristic optimization method, in adversarial settings. Specifically, we provide a global convergence analysis of CB$^2$O in mean-field law in the presence of malicious agents, demonstrating the robustness of CB$^2$O against a diverse range of attacks. Thereby, we offer insights into how specific hyperparameter choices enable to mitigate adversarial effects. On the practical side, we extend CB$^2$O to the clustered federated learning setting by proposing FedCB$^2$O, a novel interacting multi-particle system, and design a practical algorithm that addresses the demands of real-world applications. Extensive experiments demonstrate the robustness of the FedCB$^2$O algorithm against label-flipping attacks in decentralized clustered federated learning scenarios, showcasing its effectiveness in practical contexts.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Reliability Estimation for Low Latency Mixnets</title>
<link>https://arxiv.org/abs/2406.06760</link>
<guid>https://arxiv.org/abs/2406.06760</guid>
<content:encoded><![CDATA[
<div> 关键词: mixnet、匿名路由、低延迟、可验证性、可靠性评分

总结:
<br />
本文提出了一种新的方案，旨在解决大规模低延迟混合网络（mixnet）与强可验证性和可靠性之间的挑战。现有的可验证性机制会引入显著的延迟开销，限制了mixnet的应用范围。该方案能够以几乎最优的时间复杂度，在去中心化的环境中估算mixnet中链接和节点的可靠性评分，且此过程独立于通过mixnet路由的总流量。它依赖于客户端凭证和基于VRF的路由新原语，确保合法客户端数据包遵循mixnet的路由策略，并随机生成不可伪造的测量数据包。实验结果在不可靠和对抗性环境下验证了该构造的可行性，证明了其可以实现在不影响客户端数据包传输延迟或产生显著带宽开销的情况下进行可靠性的估计。 <div>
arXiv:2406.06760v2 Announce Type: replace 
Abstract: While there exist mixnets that can anonymously route large amounts of data packets with end to end latency that can be as low as a second, %making them attractive for a variety of applications, combining this level of performance with strong verifiability and reliability properties that ensure the correct processing and delivery of packets has proved challenging. Indeed, existing verifiability mechanisms are incompatible with scalable low-latency operation due to imposing significant latency overheads measuring in minutes to hours, hence severely limiting the variety of applications mixnets can serve. We address this important gap by proposing a scheme that can estimate reliability scores for a mixnet's links and nodes in a decentralized manner with essentially optimal complexity that is independent of the total traffic routed through the mixnet. The scores can be computed publicly by all participants from a set of measurement packets that are eventually revealed and act as a random sample of the traffic, without affecting mixnet transmission latency for client packets or incurring significant bandwidth overhead. Our scheme assumes client credentials and relies on VRF-based routing, a novel primitive that ensures that legitimate client packets follow the routing policy of the mixnet, as well as randomly generating unforgeable measurement packets. We experimentally validate our construction both in unreliable and adversarial settings, demonstrating its feasibility.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Relaxing Trust Assumptions on Quantum Key Distribution Networks</title>
<link>https://arxiv.org/abs/2402.13136</link>
<guid>https://arxiv.org/abs/2402.13136</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、长距离、不信任中继器、QKD网络、信任级别

总结:
本文探讨了在量子通信网络中如何在对中继器的信任程度降低的情况下实现安全的秘密接力。文章提出了三种不同的QKD中继器信任级别：完全访问信任（FAT）、部分访问信任（PAT）和无访问信任（NAT），定义了中继器处理秘密信息的不同权限。针对不同信任级别，文中回顾并提出多种基于QKD的密钥管理系统构建方案，特别是在无访问信任级别的密钥管理系统的评估上，重点讨论了集中式与新型去中心化的密钥管理系统架构。这些不同架构为QKD网络的需求提供了灵活性，为未来长距离安全通信提供了一种更可靠且实用的解决方案思路。 <div>
arXiv:2402.13136v2 Announce Type: replace-cross 
Abstract: Quantum security over long distances with untrusted relays is largely unfounded and is still an open question for active research. Nevertheless, quantum networks based on trusted relays are being built across the globe. However, standard QKD network architecture implores a complete trust requirement on QKD relays, which is too demanding and limits the use cases for QKD networks. In this work, we explore the possibility to securely relay a secret in a QKD network by relaxing the trust assumptions (if not completely) on the relay. We characterize QKD relays with different trust levels, namely, Full Access Trust (FAT), Partial Access Trust (PAT), and No Access Trust (NAT). As the name suggests, each level defines the degree with which a relay is required to be trusted with the secret provided by the key management system for end-to-end communication. We then review and propose multiple constructions of the QKD key management system based on the different trust levels. Main contribution of the paper is realized by evaluating key management systems with no access trust level. In principle, we review key management with centralized topology and propose a new decentralized key management system. These different topologies provide various advantages based on the QKD network requirements, allowing an operational flexibility in the architecture. We believe this work presents a new perspective to the open problem of providing a confiding and a practical solution for future long range secure communications
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeTEcT: Dynamic and Probabilistic Parameters Extension</title>
<link>https://arxiv.org/abs/2405.16688</link>
<guid>https://arxiv.org/abs/2405.16688</guid>
<content:encoded><![CDATA[
<div> 关键词：DeTEcT框架、财富分布、参数化、动态货币供应、模拟经济活动

总结:
本文扩展了Sadykhov等人提出的DeTEcT框架，该框架用于建模代币经济中的财富分配和宏观经济场景模拟。文章提出了四种对DeTEcT框架进行参数化的方法，包括动态与静态以及概率性与非概率性的区分。通过这些参数化技术，研究者展示了如何限制框架以从DeTEcT中推导出现有的财富分布模型。此外，论文还探讨了使DeTEcT框架中的货币供应变得动态化的可能性及其对财富分布动态的影响，其目的在于使DeTEcT能够应用于没有最大供应量（如Ethereum）的代币经济模型，并为框架增加了约束形式的对称性。 <div>
arXiv:2405.16688v2 Announce Type: replace-cross 
Abstract: This paper presents a theoretical extension of the DeTEcT framework proposed by Sadykhov et al., DeTEcT, where a formal analysis framework was introduced for modelling wealth distribution in token economies. DeTEcT is a framework for analysing economic activity, simulating macroeconomic scenarios, and algorithmically setting policies in token economies. This paper proposes four ways of parametrizing the framework, where dynamic vs static parametrization is considered along with the probabilistic vs non-probabilistic. Using these parametrization techniques, we demonstrate that by adding restrictions to the framework it is possible to derive the existing wealth distribution models from DeTEcT. In addition to exploring parametrization techniques, this paper studies how money supply in DeTEcT framework can be transformed to become dynamic, and how this change will affect the dynamics of wealth distribution. The motivation for studying dynamic money supply is that it enables DeTEcT to be applied to modelling token economies without maximum supply (i.e., Ethereum), and it adds constraints to the framework in the form of symmetries.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Supercomputing Based Distributed Cloud Marketplace</title>
<link>https://arxiv.org/abs/2412.00016</link>
<guid>https://arxiv.org/abs/2412.00016</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、51%攻击、可扩展性、LuluChain、超级计算机速度

总结:<br />
本文提出了一个新的区块链技术——LuluChain，它旨在解决当前区块链面临的51%攻击威胁和可扩展性问题。现有的区块链系统在处理能力上不及集中式系统，这使得51%攻击成为可能。LuluChain致力于提供一种无限可扩展、安全且高吞吐量的解决方案，能实现接近超级计算机速度的性能，仅使用商业现成硬件。该系统简化了区块链模型，提高了功能、速度、可扩展性、隐私和灵活性，并能对抗云计算市场的寡头垄断定价模式，因为它对计算工作负载的需求极低。通过消除时间戳同步和所有参与者之间的多数同意需求，LuluChain开启了可靠信任、低成本即时交易和灵活即时智能合约的新可能。作为一个基于高性能分布式系统的分布式云市场基础，LuluChain被视为一种理想方案。 <div>
arXiv:2412.00016v1 Announce Type: new 
Abstract: The once mythological 51% attack has moved beyond the hypothetical and now poses a legitimate widespread threat to blockchain technology. Current blockchains provide inferior throughput capacity when compared to that of centralized systems, creating an obvious vulnerability which allows the 51% attack to occur within decentralized systems. Despite recent advancements in blockchain which introduce interesting models that achieve high throughputs with enhanced security and privacy, no current networks have evolved to deploy the optimal solution of combining scalability, security, and distributed systems to create a legitimate supercomputing enterprise-grade developer sandbox. In this paper, we introduce an infinitely scalable, secure, and high throughput blockchain capable of amassing supercomputer speeds with off-the-shelf hardware, LuluChain. LuluChain simplifies the blockchain model to obtain greater functionality, speed, scalability, privacy, and flexibility, that works to combat the inflated pricing models set by the oligopolistic cloud computing market as it requires minimal computational work. By eliminating the need for timestamp synchronization and majority agreement among all participants, LuluChain opens the door to reliable trust, low-cost instant transactions, and flexible instant smart contracts. The supercomputing, high throughput distributed system is the ideal foundation for an essential distributed cloud marketplace.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Collaboration in Incident Response with Large Language Models</title>
<link>https://arxiv.org/abs/2412.00652</link>
<guid>https://arxiv.org/abs/2412.00652</guid>
<content:encoded><![CDATA[
<div> 关键词：incident response，large language models，multi-agent collaboration，Backdoors & Breaches框架，cybersecurity training

<br /><br />总结:
本文探讨了利用大型语言模型（LLMs）作为智能代理来提升网络安全中事件响应（IR）协作效率和效果的新方法。研究通过在Backdoors & Breaches框架下模拟真实的IR场景，采用了集中式、分布式和混合型等多种团队结构进行实验。通过对不同配置下的代理人交互与性能分析，文章揭示了LLMs在优化多代理协作、增强决策制定、提高适应性和流程整合以更有效地应对网络威胁方面的潜力。 <div>
arXiv:2412.00652v1 Announce Type: new 
Abstract: Incident response (IR) is a critical aspect of cybersecurity, requiring rapid decision-making and coordinated efforts to address cyberattacks effectively. Leveraging large language models (LLMs) as intelligent agents offers a novel approach to enhancing collaboration and efficiency in IR scenarios. This paper explores the application of LLM-based multi-agent collaboration using the Backdoors & Breaches framework, a tabletop game designed for cybersecurity training. We simulate real-world IR dynamics through various team structures, including centralized, decentralized, and hybrid configurations. By analyzing agent interactions and performance across these setups, we provide insights into optimizing multi-agent collaboration for incident response. Our findings highlight the potential of LLMs to enhance decision-making, improve adaptability, and streamline IR processes, paving the way for more effective and coordinated responses to cyber threats.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.00661</link>
<guid>https://arxiv.org/abs/2412.00661</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、子采样、均值场Q学习（MFQ）、多项式时间、收敛性

总结:
本文提出了一种名为“SUBSAMPLE-MFQ”的新算法，用于解决多智能体强化学习中的挑战，特别是应对由于智能体数量增加导致的联合状态和动作空间指数级增长的问题。该算法结合了子采样技术和均值场Q学习，设计了一个针对$n$个智能体系统的去中心化随机策略。SUBSAMPLE-MFQ能够在时间复杂度为$k$的多项式时间内学习到系统策略，并随着子采样的智能体数量$k$增加，其收敛至最优策略的阶数为$\tilde{O}(1/\sqrt{k})$。实验部分验证了该方法在高斯挤压和全局探索等场景的有效性。 <div>
arXiv:2412.00661v1 Announce Type: new 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging due to the fact that the size of the joint state and action spaces are exponentially large in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm \texttt{SUBSAMPLE-MFQ} (\textbf{Subsample}-\textbf{M}ean-\textbf{F}ield-\textbf{Q}-learning) and a decentralized randomized policy for a system with $n$ agents. For $k\leq n$, our algorithm system learns a policy for the system in time polynomial in $k$. We show that this learned policy converges to the optimal policy in the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. We validate our method empirically on Gaussian squeeze and global exploration settings.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChainGuard: A Blockchain-based Authentication and Access Control Scheme for Distributed Networks</title>
<link>https://arxiv.org/abs/2412.00677</link>
<guid>https://arxiv.org/abs/2412.00677</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、去中心化认证、访问控制、ChainGuard、智能合约

<br /><br />总结:
本文提出了一个名为ChainGuard的新型方案，旨在解决如何在分布式网络中实现去中心化的身份认证和访问控制问题。ChainGuard利用区块链技术动态管理用户角色和权限，无需中央服务器，从而消除了传统集中式系统的瓶颈。该机制同时支持跨多个组织的用户交互，提升了安全性、效率和透明度。通过解决可扩展性、安全性和透明度等关键挑战，ChainGuard不仅弥合了传统集中式系统与区块链去中心化理念之间的鸿沟，还进一步加强了数据保护和操作效率。 <div>
arXiv:2412.00677v1 Announce Type: new 
Abstract: As blockchain technology gains traction for enhancing data security and operational efficiency, traditional centralized authentication systems remain a significant bottleneck. This paper addresses the challenge of integrating decentralized authentication and access control within distributed networks. We propose a novel solution named ChainGuard, a fully decentralized authentication and access control mechanism based on smart contracts. ChainGuard eliminates the need for a central server by leveraging blockchain technology to manage user roles and permissions dynamically. Our scheme supports user interactions across multiple organizations simultaneously, enhancing security, efficiency, and transparency. By addressing key challenges such as scalability, security, and transparency, ChainGuard not only bridges the gap between traditional centralized systems and blockchain's decentralized ethos but also enhances data protection and operational efficiency.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SEAM: A Secure Automated and Maintainable Smart Contract Upgrade Framework</title>
<link>https://arxiv.org/abs/2412.00680</link>
<guid>https://arxiv.org/abs/2412.00680</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contracts, upgrading, SEAM, diamond pattern, security

总结:<br />
本文提出了一种名为SEAM的新颖框架，用于解决智能合约升级这一关键挑战。SEAM通过使用钻石模式自动化将标准Solidity合约转换为可升级版本，简化了升级流程并解决了函数选择器冲突和存储槽碰撞两个主要安全漏洞问题。此外，该框架还提供了用于高效部署、修改和管理智能合约生命周期的工具。通过增强合同安全性并降低开发者的学习曲线，SEAM为构建更灵活和可维护的区块链应用奠定了坚实基础。 <div>
arXiv:2412.00680v1 Announce Type: new 
Abstract: This work addresses the critical challenges of upgrading smart contracts, which are vital for trust in automated transactions but difficult to modify once deployed. To address this issue, we propose SEAM, a novel framework that automates the conversion of standard Solidity contracts into upgradable versions using the diamond pattern. SEAM simplifies the upgrade process and addresses two key vulnerabilities: function selector clashes and storage slot collisions. Additionally, the framework provides tools for efficiently deploying, modifying, and managing smart contract lifecycles. By enhancing contract security and reducing the learning curve for developers, SEAM lays a robust foundation for more flexible and maintainable blockchain applications.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Proof-of-Work: A Secure Dynamic Approach to Fair and Efficient Blockchain Mining</title>
<link>https://arxiv.org/abs/2412.00690</link>
<guid>https://arxiv.org/abs/2412.00690</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof-of-Work (PoW), 能耗, 中心化, Collaborative Proof-of-Work (CPoW), 动态挖矿池形成协议

总结:<br />
本文针对Proof-of-Work (PoW)系统存在的能耗过高、挖矿权力中心化等问题，以及静态挖矿池对区块链去中心化特性与公平性的削弱，提出了一个新的Collaborative Proof-of-Work (CPoW)挖矿方法。该方法致力于提升以太坊网络的效率和公平性，具体表现为设计了一种动态挖矿池形成协议，使矿工能够根据计算能力进行协作，并通过精准验证和分配奖励的机制保障了奖励分配的安全与公正。这一研究通过解决传统挖矿的中心化和能源效率问题，为构建更加可持续的区块链生态系统做出了贡献。 <div>
arXiv:2412.00690v1 Announce Type: new 
Abstract: Proof-of-Work (PoW) systems face critical challenges, including excessive energy consumption and the centralization of mining power among entities with expensive hardware. Static mining pools exacerbate these issues by reducing competition and undermining the decentralized nature of blockchain networks, leading to economic inequality and inefficiencies in resource allocation. Their reliance on centralized pool managers further introduces vulnerabilities by creating a system that fails to ensure secure and fair reward distribution. This paper introduces a novel Collaborative Proof-of-Work (CPoW) mining approach designed to enhance efficiency and fairness in the Ethereum network. We propose a dynamic mining pool formation protocol that enables miners to collaborate based on their computational capabilities, ensuring fair and secure reward distribution by incorporating mechanisms to accurately verify and allocate rewards. By addressing the centralization and energy inefficiencies of traditional mining, this research contributes to a more sustainable blockchain ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Forking Way: When TEEs Meet Consensus</title>
<link>https://arxiv.org/abs/2412.00706</link>
<guid>https://arxiv.org/abs/2412.00706</guid>
<content:encoded><![CDATA[
<div> 关键词：Trusted Execution Environments (TEE), 区块链, 分布式平台, 叉攻击, 安全性分析

总结:
本文针对越来越多的分布式平台结合可信执行环境(TEE)和区块链的情况进行了系统研究，强调了这一组合被认为是保障区块链机密计算与防御叉攻击的良好方式。通过对29项TEE基区块链方案的深入分析，发现社区中对于如何整合TEE和区块链缺乏共识，并归纳出四种主要的互联手段及其局限性。此外，文章还揭示了三个生产就绪的TEE基区块链——Ten、Phala和Secret Network中存在的此前未被记录的叉攻击漏洞，并对这些漏洞提出了有效的应对措施。已将研究成果负责任地披露给相关平台的开发者。 <div>
arXiv:2412.00706v1 Announce Type: new 
Abstract: An increasing number of distributed platforms combine Trusted Execution Environments (TEEs) with blockchains. Indeed, many hail the combination of TEEs and blockchains a good "marriage": TEEs bring confidential computing to the blockchain while the consensus layer could help defend TEEs from forking attacks.
  In this paper, we systemize how current blockchain solutions integrate TEEs and to what extent they are secure against forking attacks. To do so, we thoroughly analyze 29 proposals for TEE-based blockchains, ranging from academic proposals to production-ready platforms. We uncover a lack of consensus in the community on how to combine TEEs and blockchains. In particular, we identify four broad means to interconnect TEEs with consensus, analyze their limitations, and discuss possible remedies. Our analysis also reveals previously undocumented forking attacks on three production-ready TEE-based blockchains: Ten, Phala, and the Secret Network. We leverage our analysis to propose effective countermeasures against those vulnerabilities; we responsibly disclosed our findings to the developers of each affected platform.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EnFed: An Energy-aware Opportunistic Federated Learning in Resource Constrained Environments for Human Activity Recognition</title>
<link>https://arxiv.org/abs/2412.00768</link>
<guid>https://arxiv.org/abs/2412.00768</guid>
<content:encoded><![CDATA[
<div> 关键词：能源效率、联邦学习、人类活动监测、模型更新、预测准确性

总结:<br />
本文提出了一种能源高效的联邦学习方法及其在人体活动监测与识别中的应用。该方法中，需要模型的应用设备请求其附近设备进行协作，同意请求的附近设备将模型更新发送至请求设备。请求设备接收到模型更新后进行聚合以构建自身模型。鉴于移动设备电池寿命有限，参与轮数依据所需精度水平和请求设备的电池电量来决定。实验结果表明，相比于分布式联邦学习方法，当使用LSTM作为底层数据分析模型时，该提议的方法能分别降低第一和第二数据集约59%和19%的训练时间和约19%的训练能量消耗；而使用MLP作为底层数据分析模型时，可分别减少约55%和72%的训练时间和训练能量消耗，同时保持了良好的预测准确性。 <div>
arXiv:2412.00768v1 Announce Type: new 
Abstract: This paper proposes an energy-efficient federated learning method and its application in human activity monitoring and recognition. In the proposed approach, the device that needs a model for an application requests its nearby devices for collaboration. The nearby devices that accept the request, send their model updates to the requesting device. The device receives the model updates from the collaborators and performs aggregation to build its model. As mobile devices have limited battery life, the number of rounds is decided based on the desired accuracy level and battery level of the requesting device. The performance of the proposed approach is evaluated with respect to prediction accuracy, training time, training energy consumption of the device, and response time. We have used two different datasets for performance evaluation. The first dataset contains different types of physical activities and the respective calorie burn. The second dataset is a human activity recognition dataset that considers six types of physical activities. The experimental results show that using the proposed method the training time and training energy consumption of the device are reduced by approximately 59% and 19% for the first and second datasets respectively, than the decentralized federated learning approach, while using LSTM as the underlying data analysis model. The results also present that the proposed method reduces the training time and energy consumption by approximately 55% and 72% for the first and second datasets respectively, than the decentralized federated learning approach while using MLP as the underlying data analysis model.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Post-Vaccination COVID-19 Data Analysis: Privacy and Ethics</title>
<link>https://arxiv.org/abs/2412.00774</link>
<guid>https://arxiv.org/abs/2412.00774</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19疫苗、区块链、个人隐私、不可变性、授权访问

总结:
<p>
该论文针对COVID-19疫苗接种过程中出现的公民隐私保护和个人数据滥用问题，提出了一种基于区块链的应用方案。此系统利用IEEE 2418.2TM-2020标准构建数据模型，旨在确保公民个人信息匿名性、疫苗接种数据的不可变性以及对抗性实体（如政府）对数据进行有限制且便捷的验证与分析。该系统在以太坊区块链上实现，并通过Python API模拟和验证疫苗接种过程中的每一步骤，从而在保障公民隐私的同时实现系统的可问责性。</p> <div>
arXiv:2412.00774v1 Announce Type: new 
Abstract: The COVID-19 pandemic has severely affected the world in terms of health, economy and peace. Fortunately, the countries are trying to overcome the situation by actively carrying out vaccinations. However, like any other massive operation involving humans such as human resource management, elections, surveys, etc., the vaccination process raises several questions about citizen privacy and misuse of personal data. In most of the countries, few attempts have been made to verify the vaccination statistics as reported by the health centers. These issues collectively require the solutions of anonymity of citizens' personal information, immutability of vaccination data and easy yet restricted access by adversarial bodies such as the government for the verification and analysis of the data. This paper introduces a blockchain-based application to simulate and monitor the vaccination process. The structure of data model used in the proposed system is based on the IEEE Standard for Data Format for Blockchain Systems 2418.2TM-2020. The proposed system enables authorized stakeholders to share and access relevant information for vaccination process chain while preserving citizen privacy and accountability of the system. It is implemented on the Ethereum blockchain and uses a Python API for the simulation and validation of each step of the vaccination process.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provable Partially Observable Reinforcement Learning with Privileged Information</title>
<link>https://arxiv.org/abs/2412.00985</link>
<guid>https://arxiv.org/abs/2412.00985</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、部分可观测性、特权信息、专家蒸馏、不对称actor-critic<br /><br />总结:
本文研究了在部分可观测环境下强化学习中利用特权信息的挑战与优势。首先，文章形式化了实践中的“专家蒸馏”（教师-学生学习）范式，并指出了其在寻找近似最优策略时的局限性。接着，提出了一种环境条件——确定性滤波条件，在此条件下，专家蒸馏可以实现样本和计算复杂度均为多项式级的效率。随后，探讨了另一种实用范式——不对称actor-critic，并针对可观察部分可观测马尔科夫决策过程设计了一个信念加权的不对称actor-critic算法，该算法具有多项式级样本复杂度和拟多项式级计算复杂度。其中，还包括了一个新的可证明的关于学习保持滤波稳定性的信念状态的Oracle。最后，文中还研究了在特权信息支持下的部分可观测多智能体强化学习的可证明效率，提出了基于集中训练与分布式执行框架的算法，这些算法在上述两种范式下都具有多项式级样本复杂度和（拟）多项式级计算复杂度。相比于近期相关理论研究，本文更注重于理解实践中启发式的算法范式，而不依赖于计算上不可行的Oracle。 <div>
arXiv:2412.00985v1 Announce Type: new 
Abstract: Partial observability of the underlying states generally presents significant challenges for reinforcement learning (RL). In practice, certain \emph{privileged information}, e.g., the access to states from simulators, has been exploited in training and has achieved prominent empirical successes. To better understand the benefits of privileged information, we revisit and examine several simple and practically used paradigms in this setting. Specifically, we first formalize the empirical paradigm of \emph{expert distillation} (also known as \emph{teacher-student} learning), demonstrating its pitfall in finding near-optimal policies. We then identify a condition of the partially observable environment, the \emph{deterministic filter condition}, under which expert distillation achieves sample and computational complexities that are \emph{both} polynomial. Furthermore, we investigate another useful empirical paradigm of \emph{asymmetric actor-critic}, and focus on the more challenging setting of observable partially observable Markov decision processes. We develop a belief-weighted asymmetric actor-critic algorithm with polynomial sample and quasi-polynomial computational complexities, in which one key component is a new provable oracle for learning belief states that preserve \emph{filter stability} under a misspecified model, which may be of independent interest. Finally, we also investigate the provable efficiency of partially observable multi-agent RL (MARL) with privileged information. We develop algorithms featuring \emph{centralized-training-with-decentralized-execution}, a popular framework in empirical MARL, with polynomial sample and (quasi-)polynomial computational complexities in both paradigms above. Compared with a few recent related theoretical studies, our focus is on understanding practically inspired algorithmic paradigms, without computationally intractable oracles.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair</title>
<link>https://arxiv.org/abs/2412.01072</link>
<guid>https://arxiv.org/abs/2412.01072</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件系统、大型语言模型、自动化程序修复、联邦学习、数据隐私

总结:<br />
本文探讨了随着软件系统快速演进导致的bug增加以及大型语言模型（LLMs）在自动化程序修复（APR）中的应用潜力。然而，现有的公共代码库无法充分反映各行业实际开发实践中的多样性和细节，因此利用私有数据集能有效提升软件开发和维护水平。为解决数据隐私问题，文章研究了联邦学习作为一种保护隐私的方法，允许私有实体在分散且保密的数据上对LLMs进行微调，促进各方协作以充分利用数据资源。实验表明，联邦学习下的微调能够提升程序修复能力，而且不同来源的代码数据对LLM微调的影响不大，意味着各行各业可以无视数据分布差异，从协同开发中获益。此外，各类联邦算法在不同的LLMs优化过程中展现出独特优势，提示我们可以通过针对LLMs特性的定制化优化来进一步增强程序修复的微调效果。 <div>
arXiv:2412.01072v1 Announce Type: new 
Abstract: Software systems have been evolving rapidly and inevitably introducing bugs at an increasing rate, leading to significant losses in resources consumed by software maintenance. Recently, large language models (LLMs) have demonstrated remarkable potential in enhancing software development and maintenance practices, particularly in automated program repair (APR) with improved accuracy and efficiency of bug fixing. However, LLM-based APR heavily relies on high-quality code repositories. A larger portion of existing code repositories are for private use and proprietary assets from various industries, reflecting more diversity and nuances in the data since real-world industries often have more extensive software development practices, which cannot be covered by merely public datasets. Therefore, utilizing private datasets shows significant potential in enhancing software development and maintenance. However, obtaining such data from various industries is hindered by data privacy concerns, as companies are reluctant to share their codebases. To address the gap, we investigate the use of federated learning as a privacy-preserving approach that enables private entities to fine-tune LLMs on proprietary and decentralized data, facilitating the collaboration between clients to fully utilize their data to help enhance software development and maintenance. Our evaluation reveals that federated fine-tuning can effectively enhance program repair capabilities. Notably, the impact of heterogeneous code on LLM fine-tuning is negligible, indicating that real-world industries can benefit from collaborative development regardless of diverse data distributions. Furthermore, each type of federated algorithm exhibits unique strengths across different LLMs, suggesting that fine-tuning for program repair can be enhanced by tailoring the optimization process to specific characteristics of different LLMs.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hierarchical Heuristic for Clustered Steiner Trees in the Plane with Obstacles</title>
<link>https://arxiv.org/abs/2412.01094</link>
<guid>https://arxiv.org/abs/2412.01094</guid>
<content:encoded><![CDATA[
<div> 关键词：Euclidean Steiner树、多根、障碍避免、层次方法、捆绑操作

总结:
本文研究了一种嵌入捆绑操作的层次方法用于计算多个互不相交的欧几里得Steiner树，这些树能够避开平面上的障碍物，这对于建模受限二维空间中去中心化和多点协调的智能体具有重要意义。实验表明，该方法对于计算具有任意障碍配置（包括凸形和非凸形几何形状）的多个避障Steiner树具有可行性及优良性能。本研究结果为避障Steiner树的新运算器设计提供了机制启示。 <div>
arXiv:2412.01094v1 Announce Type: new 
Abstract: Euclidean Steiner trees are relevant to model minimal networks in real-world applications ubiquitously. In this paper, we study the feasibility of a hierarchical approach embedded with bundling operations to compute multiple and mutually disjoint Euclidean Steiner trees that avoid clutter and overlapping with obstacles in the plane, which is significant to model the decentralized and the multipoint coordination of agents in constrained 2D domains. Our computational experiments using arbitrary obstacle configuration with convex and non-convex geometries show the feasibility and the attractive performance when computing multiple obstacle-avoiding Steiner trees in the plane. Our results offer the mechanisms to elucidate new operators for obstacle-avoiding Steiner trees.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lossless and Privacy-Preserving Graph Convolution Network for Federated Item Recommendation</title>
<link>https://arxiv.org/abs/2412.01141</link>
<guid>https://arxiv.org/abs/2412.01141</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络 (GNN), 推荐系统, 隐私保护, 联邦推荐, LP-GCN

总结:
本文提出了一种新的隐私保护图卷积网络——LP-GCN，用于解决基于GNN的推荐系统中的隐私问题。现有的GNN推荐方法依赖于集中式的用户-物品交互子图存储和全局图训练，可能引发隐私关注。针对此问题，一些联邦推荐方法利用分布式和碎片化的用户-物品子图以保护用户隐私，但其图卷积过程不完整，影响推荐性能。LP-GCN创新性地实现了在分布式子图上完整进行图卷积的过程，同时确保了隐私安全，并且其性能与非联邦（即集中式）方案相当。理论分析和实证研究表明，LP-GCN在三个真实数据集上的表现优于现有联邦推荐方法。论文接受后，相关代码将公开发布。 <div>
arXiv:2412.01141v1 Announce Type: new 
Abstract: Graph neural network (GNN) has emerged as a state-of-the-art solution for item recommendation. However, existing GNN-based recommendation methods rely on a centralized storage of fragmented user-item interaction sub-graphs and training on an aggregated global graph, which will lead to privacy concerns. As a response, some recent works develop GNN-based federated recommendation methods by exploiting decentralized and fragmented user-item sub-graphs in order to preserve user privacy. However, due to privacy constraints, the graph convolution process in existing federated recommendation methods is incomplete compared with the centralized counterpart, causing a degradation of the recommendation performance. In this paper, we propose a novel lossless and privacy-preserving graph convolution network (LP-GCN), which fully completes the graph convolution process with decentralized user-item interaction sub-graphs while ensuring privacy. It is worth mentioning that its performance is equivalent to that of the non-federated (i.e., centralized) counterpart. Moreover, we validate its effectiveness through both theoretical analysis and empirical studies. Extensive experiments on three real-world datasets show that our LP-GCN outperforms the existing federated recommendation methods. The code will be publicly available once the paper is accepted.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>INTELLECT-1 Technical Report</title>
<link>https://arxiv.org/abs/2412.01152</link>
<guid>https://arxiv.org/abs/2412.01152</guid>
<content:encoded><![CDATA[
<div> 关键词: INTELLECT-1、PRIME、分布式训练、ElasticDeviceMesh、DiLoCo-FSDP2

总结:
本文介绍了INTELLECT-1，这是全球首个人工智能社区合作训练的拥有100亿参数的语言模型，证明大规模模型训练不再仅限于大型企业，而是可以通过分布式的社区驱动方式实现。INTELLECT-1使用了1万亿个令牌，在跨三大洲的最多14个并发节点上进行训练，共有30家独立计算资源提供商动态加入和退出训练过程，期间保持了83-96%的计算利用率和36.2-41.4%的模型FLOPS利用率。为实现这一目标，研究团队开发了PRIME框架，该框架具有弹性设备网格（ElasticDeviceMesh）、用于互联网和本地节点间容错通信的动态全局进程组以及现场检查点恢复内核等功能。通过结合PRIME、DiLoCo和定制的int8全Reduce技术，他们实现了与传统数据并行训练相比高达400倍的通信带宽降低，同时保证了相当的性能。这些成果显示出利用全球GPU资源的分散网络训练前沿基础模型的可能性和前景。 <div>
arXiv:2412.01152v1 Announce Type: new 
Abstract: In this report, we introduce INTELLECT-1, the first 10 billion parameter language model collaboratively trained across the globe, demonstrating that large-scale model training is no longer confined to large corporations but can be achieved through a distributed, community-driven approach. INTELLECT-1 was trained on 1 trillion tokens using up to 14 concurrent nodes distributed across 3 continents, with contributions from 30 independent compute providers dynamically joining and leaving the training process, while maintaining 83-96% compute utilization and 36.2-41.4% model FLOPS utilization. We leverage PRIME, our scalable distributed training framework designed for fault-tolerant, high-performance training on unreliable, globally distributed nodes. Key innovations in PRIME include the ElasticDeviceMesh, which manages dynamic global process groups for fault-tolerant communication across the internet and local process groups for communication within a node, live checkpoint recovery kernels, and a hybrid DiLoCo-FSDP2 implementation. Using PRIME with DiLoCo and our custom int8 all-reduce, we achieve a 400x reduction in communication bandwidth compared to traditional data-parallel training settings while delivering comparable performance. These results demonstrate the feasibility and promise of training frontier foundation models in a decentralized network of global GPU resources.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid BPMN-DMN Framework for Secure Inter-organizational Processes and Decisions Collaboration on Permissioned Blockchain</title>
<link>https://arxiv.org/abs/2412.01196</link>
<guid>https://arxiv.org/abs/2412.01196</guid>
<content:encoded><![CDATA[
<div> 关键词: BlockCollab、BPMN、DMN、区块链、智能合约<br /><br />总结:
本文提出了一种名为BlockCollab的新型模型驱动框架，该框架针对数字商务领域中跨组织协作的需求，将Business Process Model and Notation（BPMN）与Decision Model and Notation（DMN）相结合，用于标准化并实现在许可型区块链平台上协同业务流程和决策的实施。BlockCollab实现了三个主要创新：1) 提供了一种标准化的方法，使用集成的BPMN-DMN模型来建模协同过程和决策；2) 自动化生成兼容Hyperledger Fabric的智能合约，同时保持过程逻辑和决策规则，并考虑隐私约束；3) 引入了混合式链上/链下执行环境，通过安全数据传输和外部系统集成优化协同工作流程。实验结果表明，该方法在11个真实世界的协作场景中实现100%的执行准确性，并证明了其实用性和可靠性。此外，文中还介绍了一个基于区块链技术的开源第三方协作平台。 <div>
arXiv:2412.01196v1 Announce Type: new 
Abstract: In the rapidly evolving digital business landscape, organizations increasingly need to collaborate across boundaries to achieve complex business objectives, requiring both efficient process coordination and flexible decision-making capabilities. Traditional collaboration approaches face significant challenges in transparency, trust, and decision flexibility, while existing blockchain-based solutions primarily focus on process execution without addressing the integrated decision-making needs of collaborative enterprises. This paper proposes BlockCollab, a novel model-driven framework that seamlessly integrates Business Process Model and Notation (BPMN) with Decision Model and Notation (DMN) to standardize and implement collaborative business processes and decisions on permissioned blockchain platforms. Our approach automatically translates integrated BPMN-DMN models into smart contracts(SCs) compatible with Hyperledger Fabric, enabling privacy-aware multi-organizational process execution through blockchain-based Attribute-Based Access Control (ABAC). The framework introduces three key innovations: (1) a standardized method for modeling collaborative processes and decisions using integrated BPMN-DMN model, (2) an automated SC generator that preserves both process logic and decision rules while maintaining privacy constraints, and (3) a hybrid on-chain/off-chain execution environment that optimizes collaborative workflows through secure data transfer and external system integration. Experimental evaluation across 11 real-world collaboration scenarios demonstrates that our approach achieves 100\% accuracy in process execution. Furthermore, an analysis of various execution processes highlights the strong practical applicability and reliability of our approach. The proposed framework includes an open-source third-party collaboration platform based on blockchain.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>GeoTP: Latency-aware Geo-Distributed Transaction Processing in Database Middlewares (Extended Version)</title>
<link>https://arxiv.org/abs/2412.01213</link>
<guid>https://arxiv.org/abs/2412.01213</guid>
<content:encoded><![CDATA[
<div> 关键词：数据库中间件、分布式事务处理、网络延迟、锁竞争、GeoTP

总结:
<br />
本文提出了GeoTP，一种针对数据库中间件的延迟感知型地理分布事务处理方法，旨在解决分布式事务处理中的性能瓶颈。首先，GeoTP设计了一种去中心化的准备机制，减少了分布式事务所需的网络往返次数。其次，它引入了一个延迟感知调度器，通过策略性地推迟锁获取时间点来最大限度地减少锁竞争持续时间。再者，为调度器提出了启发式优化方法，进一步降低锁竞争持续时间。实验结果显示，在Apache Shardingsphere这一先进的数据库中间件上实现并扩展至Apache ScalarDB后的GeoTP，在YCSB和TPC-C基准测试中，相比于Shardingsphere实现了最高达17.7倍的性能提升。 <div>
arXiv:2412.01213v1 Announce Type: new 
Abstract: The widespread adoption of database middleware for supporting distributed transaction processing is prevalent in numerous applications, with heterogeneous data sources deployed across national and international boundaries. However, transaction processing performance significantly drops due to the high network latency between the middleware and data sources and the long lock contention span, where transactions may be blocked while waiting for the locks held by concurrent transactions. In this paper, we propose GeoTP, a latency-aware geo-distributed transaction processing approach in database middlewares. GeoTP incorporates three key techniques to enhance geo-distributed transaction performance. First, we propose a decentralized prepare mechanism, which diminishes the requirement of network round trips for distributed transactions. Second, we design a latency-aware scheduler to minimize the lock contention span by strategically postponing the lock acquisition time point. Third, heuristic optimizations are proposed for the scheduler to reduce the lock contention span further. We implemented GeoTP on Apache Shardingsphere, a state-of-the-art middleware, and extended it into Apache ScalarDB. Experimental results on YCSB and TPC-C demonstrate that GeoTP achieves up to 17.7x performance improvement over Shardingsphere.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeFi: Concepts and Ecosystem</title>
<link>https://arxiv.org/abs/2412.01357</link>
<guid>https://arxiv.org/abs/2412.01357</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), bibliometric analysis, thematic review, participants, risks

<br />
总结:
该文深入研究了去中心化金融（DeFi）的发展态势，通过文献计量分析揭示了其基础概念、研究趋势和生态系统。文章指出，DeFi研究的关注点从初期的技术创新逐渐转向可持续性、环境影响及监管挑战等问题。研究主题主要集中在去中心化、智能合约、代币化和可持续性关注等方面。同时，文章分析了DeFi生态系统的参与者角色与互动，如开发者、流动性提供者、审计员和监管机构，并指出了关键风险，包括智能合约漏洞、流动性约束以及监管不确定性。研究强调了DeFi在推动金融包容性和透明度方面的变革潜力，但同时也需要强有力的安全框架和监管监督以确保长期稳定性。本文通过对文献计量和主题分析的整合，全面解释了DeFi生态系统，为研究人员、实践者和政策制定者提供了有价值的见解，有助于推进DeFi在全球金融系统中的可持续发展和整合。 <div>
arXiv:2412.01357v1 Announce Type: new 
Abstract: This paper investigates the evolving landscape of decentralized finance (DeFi) by examining its foundational concepts, research trends, and ecosystem. A bibliometric analysis was conducted to identify thematic clusters and track the evolution of DeFi research. Additionally, a thematic review was performed to analyze the roles and interactions of key participants within the DeFi ecosystem, focusing on its opportunities and inherent risks. The bibliometric analysis identified a progression in research priorities, transitioning from an initial focus on technological innovation to addressing sustainability, environmental impacts, and regulatory challenges. Key thematic clusters include decentralization, smart contracts, tokenization, and sustainability concerns. The analysis of participants highlighted the roles of developers, liquidity providers, auditors, and regulators while identifying critical risks such as smart contract vulnerabilities, liquidity constraints, and regulatory uncertainties. The study underlines the transformative potential of DeFi to enhance financial inclusion and transparency while emphasizing the need for robust security frameworks and regulatory oversight to ensure long-term stability. This paper comprehensively explains the DeFi ecosystem by integrating bibliometric and thematic analyses. It offers valuable insights for researchers, practitioners, and policymakers, contributing to the ongoing discourse on the sustainable development and integration of DeFi into the global financial system.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Future of Document Verification: Leveraging Blockchain and Self-Sovereign Identity for Enhanced Security and Transparency</title>
<link>https://arxiv.org/abs/2412.01531</link>
<guid>https://arxiv.org/abs/2412.01531</guid>
<content:encoded><![CDATA[
<div> 关键词：文档认证、区块链、自我主权身份、去中心化技术、COVID-19疫情

<br />
总结:
文章提出了一种利用区块链和自我主权身份等去中心化技术改进文档认证的新策略。当前传统文档认证流程存在耗时长、伪证流通以及数据隐私问题，特别是在COVID-19疫情期间，物理出席要求导致了认证过程的显著延误，且缺乏实时跟踪功能。该新策略旨在克服这些难题，构建一个高效、安全且用户友好的认证生态系统。 <div>
arXiv:2412.01531v1 Announce Type: new 
Abstract: Attestation of documents like legal papers, professional qualifications, medical records, and commercial documents is crucial in global transactions, ensuring their authenticity, integrity, and trustworthiness. Companies expanding operations internationally need to submit attested financial statements and incorporation documents to foreign governments or business partners to prove their businesses and operations' authenticity, legal validity, and regulatory compliance. Attestation also plays a critical role in education, overseas employment, and authentication of legal documents such as testaments and medical records. The traditional attestation process is plagued by several challenges, including time-consuming procedures, the circulation of counterfeit documents, and concerns over data privacy in the attested records. The COVID-19 pandemic brought into light another challenge: ensuring physical presence for attestation, which caused a significant delay in the attestation process. Traditional methods also lack real-time tracking capabilities for attesting entities and requesters. This paper aims to propose a new strategy using decentralized technologies such as blockchain and self-sovereign identity to overcome the identified hurdles and provide an efficient, secure, and user-friendly attestation ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Contract Vulnerabilities, Tools, and Benchmarks: An Updated Systematic Literature Review</title>
<link>https://arxiv.org/abs/2412.01719</link>
<guid>https://arxiv.org/abs/2412.01719</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、以太坊、安全漏洞、自动化检测工具、基准评价

<br />
总结:
本文是一篇关于以太坊智能合约安全漏洞的系统性文献综述，重点关注了自动化检测工具及其基准评估。研究团队从五个数字图书馆和五个主要软件工程会议中筛选了1,888份研究，最终选取了131篇高质量论文进行分析。文章构建了一个由101种智能合约漏洞组成的十级分类体系；列出了144款具有相应功能、方法及代码转换技术的智能合约检测工具；并汇总了用于工具评估的102个基准。通过对现有研究的深入剖析，文中对以太坊智能合约安全性现状进行了总结，并指出了未来研究的方向。 <div>
arXiv:2412.01719v1 Announce Type: new 
Abstract: Smart contracts are self-executing programs on blockchain platforms like Ethereum, which have revolutionized decentralized finance by enabling trustless transactions and the operation of decentralized applications. Despite their potential, the security of smart contracts remains a critical concern due to their immutability and transparency, which expose them to malicious actors. The connections of contracts further complicate vulnerability detection. This paper presents a systematic literature review that explores vulnerabilities in Ethereum smart contracts, focusing on automated detection tools and benchmark evaluation. We reviewed 1,888 studies from five digital libraries and five major software engineering conferences, applying a structured selection process that resulted in 131 high-quality studies. The key results include a hierarchical taxonomy of 101 vulnerabilities grouped into ten categories, a comprehensive list of 144 detection tools with corresponding functionalities, methods, and code transformation techniques, and a collection of 102 benchmarks used for tool evaluation. We conclude with insights on the current state of Ethereum smart contract security and directions for future research.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining Blockchain and Biometrics: A Survey on Technical Aspects and a First Legal Analysis</title>
<link>https://arxiv.org/abs/2302.10883</link>
<guid>https://arxiv.org/abs/2302.10883</guid>
<content:encoded><![CDATA[
<div> 关键词: 生物识别、区块链、集成、法律分析、挑战与潜力

<br /><br />总结:
本文是对生物识别技术和区块链技术融合应用的学术文献调研，探讨了二者的结合在身份验证、分布式信任服务和身份管理等领域的潜在优势。文章指出，虽然目前这种组合在实际实时应用中还面临区块链效率和经济性不足的问题，但其对于推动生物识别领域创新具有积极意义。从法律角度来看，责任分配问题成为主要挑战，同时进行适当的数据保护影响评估也存在困难。最后，该研究提出了针对这一组合的技术和法律建议，旨在帮助充分利用其优点并降低风险。 <div>
arXiv:2302.10883v2 Announce Type: replace 
Abstract: Biometric recognition as a unique, hard-to-forge, and efficient way of identification and verification has become an indispensable part of the current digital world. The fast evolution of this technology has been a strong incentive for integrating it into many applications. Meanwhile, blockchain, the very attractive decentralized ledger technology, has been widely received both by the research and industry in the past years and it is being increasingly deployed nowadays in many different applications, such as money transfer, IoT, healthcare, or logistics. Recently, researchers have started to speculate what would be the pros and cons and what would be the best applications when these two technologies cross paths. This paper provides a survey of technical literature research on the combination of blockchain and biometrics and includes a first legal analysis of this integration to shed light on challenges and potentials. While this combination is still in its infancy and a growing body of literature discusses specific blockchain applications and solutions in an advanced technological set-up, this paper presents a holistic understanding of blockchains applicability in the biometric sector. This study demonstrates that combining blockchain and biometrics would be beneficial for novel applications in biometrics such as the PKI mechanism, distributed trusted service, and identity management. However, blockchain networks at their current stage are not efficient and economical for real-time applications. From a legal point of view, the allocation of accountability remains a main issue, while other difficulties remain, such as conducting a proper Data Protection Impact Assessment. Finally, it supplies technical and legal recommendations to reap the benefits and mitigate the risks of the combination.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Estimating Continuous Muscle Fatigue For Multi-Muscle Coordinated Exercise: A Pilot Study on Walking</title>
<link>https://arxiv.org/abs/2303.17614</link>
<guid>https://arxiv.org/abs/2303.17614</guid>
<content:encoded><![CDATA[
<div> 关键词：肌肉疲劳评估、多肌协调、神经肌肉特征、贝叶斯高斯过程、生理学原理模型

<br /><br />总结：
本文提出了一种用于评估日常锻炼中肌肉疲劳进展的方法。首先，通过肌肉协同作用分数化和脊髓模块放电变异性等特征，结合疲劳诱导的神经肌肉适应性理论来描绘肌肉疲劳。其次，利用贝叶斯高斯过程建立模型，以捕捉疲劳随时间演变的进程。为解决缺乏监督信息的问题，文中将疲劳的时间演化特性数学化作为损失函数。最后，依据肌肉疲劳的生理学原则制定量化评价指标。实验结果显示，该方法在不同天之间的相似度达到0.99，与其他疲劳观点的相似度超过0.7，并具有接近1的弱单调性，性能优于其他方法。这项研究旨在实现肌肉疲劳的客观评估。 <div>
arXiv:2303.17614v2 Announce Type: replace 
Abstract: Assessing the progression of muscle fatigue for daily exercises provides vital indicators for precise rehabilitation, personalized training dose, especially under the context of Metaverse. Assessing fatigue of multi-muscle coordination-involved daily exercises requires the neuromuscular features that represent the fatigue-induced characteristics of spatiotemporal adaptions of multiple muscles and the estimator that captures the time-evolving progression of fatigue. In this paper, we propose to depict fatigue by the features of muscle compensation and spinal module activation changes and estimate continuous fatigue by a physiological rationale model. First, we extract muscle synergy fractionation and the variance of spinal module spikings as features inspired by the prior of fatigue-induced neuromuscular adaptations. Second, we treat the features as observations and develop a Bayesian Gaussian process to capture the time-evolving progression. Third, we solve the issue of lacking supervision information by mathematically formulating the time-evolving characteristics of fatigue as the loss function. Finally, we adapt the metrics that follow the physiological principles of fatigue to quantitatively evaluate the performance. Our extensive experiments present a 0.99 similarity between days, a over 0.7 similarity with other views of fatigue and a nearly 1 weak monotonicity, which outperform other methods. This study would aim the objective assessment of muscle fatigue.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>No-Regret Learning and Equilibrium Computation in Quantum Games</title>
<link>https://arxiv.org/abs/2310.08473</link>
<guid>https://arxiv.org/abs/2310.08473</guid>
<content:encoded><![CDATA[
<div> 关键词：量子处理器、分布式系统、无遗憾算法、量子纳什均衡、分离型量子粗相关均衡

总结:
本文探讨了随着量子处理器的发展，涉及互动量子代理的大规模分布式系统的出现。研究重点在于无遗憾算法在量子环境中如何驱动多智能体在时间上更新其行为。对于双人量子零和游戏与多玩家量子聚合零和游戏，文章证明无遗憾算法会收敛到时间平均下的可分离量子纳什均衡。针对更一般的多玩家量子游戏情况，文中引入了一个新概念——分离型量子粗相关均衡（QCCE），这是无遗憾学习算法行为时间平均收敛的结果，为分布式量子系统提供了一种自然的解决方案。此外，论文还表明计算QCCE可以形式化为半正定规划问题，并确立了存在纠缠（即非可分离）的QCCE，这类均衡无法通过当前的无遗憾学习范式得到学习。<br /><br /> <div>
arXiv:2310.08473v3 Announce Type: replace 
Abstract: As quantum processors advance, the emergence of large-scale decentralized systems involving interacting quantum-enabled agents is on the horizon. Recent research efforts have explored quantum versions of Nash and correlated equilibria as solution concepts of strategic quantum interactions, but these approaches did not directly connect to decentralized adaptive setups where agents possess limited information. This paper delves into the dynamics of quantum-enabled agents within decentralized systems that employ no-regret algorithms to update their behaviors over time. Specifically, we investigate two-player quantum zero-sum games and polymatrix quantum zero-sum games, showing that no-regret algorithms converge to separable quantum Nash equilibria in time-average. In the case of general multi-player quantum games, our work leads to a novel solution concept, that of the {separable} quantum coarse correlated equilibria (QCCE), as the convergent outcome of the time-averaged behavior no-regret algorithms, offering a natural solution concept for decentralized quantum systems. Finally, we show that computing QCCEs can be formulated as a semidefinite program and establish the existence of entangled (i.e., non-separable) QCCEs, which are unlearnable via the current paradigm of no-regret learning.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MASP: Scalable GNN-based Planning for Multi-Agent Navigation</title>
<link>https://arxiv.org/abs/2312.02522</link>
<guid>https://arxiv.org/abs/2312.02522</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体导航、强化学习、规划方法、层次化规划、图模型

总结:<br />
本文提出了一个名为Multi-Agent Scalable Graph-based Planner (MASP)的新型层次化规划器，用于解决具有大量智能体的分布式环境中的多目标导航任务。MASP采用层次框架降低探索空间复杂度，通过将大空间分解为多个目标条件子空间来实现。它利用图模型来更好地捕捉智能体和目标之间的关系，以促进合作并适应团队规模的变化。具体而言，MASP包括两个部分：高层面的Goal Matcher使用基于图的自编码器和交叉编码器优化目标分配；低层面的Coordinated Action Executor引入了Group Information Fusion技术，有助于小组划分并提取跨组的智能体间关系，从而提高训练效率并增强智能体的合作能力。实验结果显示，MASP在任务效率方面优于强化学习和基于规划的方法基线。 <div>
arXiv:2312.02522v2 Announce Type: replace 
Abstract: We investigate multi-agent navigation tasks, where multiple agents need to reach initially unassigned goals in a limited time. Classical planning-based methods suffer from expensive computation overhead at each step and offer limited expressiveness for complex cooperation strategies. In contrast, reinforcement learning (RL) has recently become a popular approach for addressing this issue. However, RL struggles with low data efficiency and cooperation when directly exploring (nearly) optimal policies in a large exploration space, especially with an increased number of agents(e.g., 10+ agents) or in complex environments (e.g., 3-D simulators). In this paper, we propose the Multi-Agent Scalable Graph-based Planner (MASP), a goal-conditioned hierarchical planner for navigation tasks with a substantial number of agents in the decentralized setting. MASP employs a hierarchical framework to reduce space complexity by decomposing a large exploration space into multiple goal-conditioned subspaces, where a high-level policy assigns agents goals, and a low-level policy navigates agents toward designated goals. For agent cooperation and the adaptation to varying team sizes, we model agents and goals as graphs to better capture their relationship. The high-level policy, the Goal Matcher, leverages a graph-based Self-Encoder and Cross-Encoder to optimize goal assignment by updating the agent and the goal graphs. The low-level policy, the Coordinated Action Executor, introduces the Group Information Fusion to facilitate group division and extract agent relationships across groups, enhancing training efficiency for agent cooperation. The results demonstrate that MASP outperforms RL and planning-based baselines in task efficiency.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Global and Local Error-Tolerant Decentralized State Estimation under Partially Ordered Observations</title>
<link>https://arxiv.org/abs/2401.09110</link>
<guid>https://arxiv.org/abs/2401.09110</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized state estimation、discrete event system、malicious attacker、global errors、local errors

总结:
本文研究了在存在恶意攻击者可能篡改或破坏信息的情况下，离散事件系统的分布式状态估计问题。系统由一组局部观测站点（OSs）观察，并定期向协调器发送其记录的观测序列以进行状态估计。文中将错误分为两种类型：全局错误和局部错误，前者指所有OSs记录相同的错误，后者则指不同OSs记录不同的错误。针对每种类型的错误，文章提出了两种有效执行状态估计的方法，一种基于修改原系统，另一种基于推断原系统的匹配行为。对于每种方法，采用估算释放策略设计相应的同步器算法来进行状态估计。 <div>
arXiv:2401.09110v2 Announce Type: replace 
Abstract: We investigate decentralized state estimation for a discrete event system in a setting where the information received at a coordinator may be corrupted or tampered by a malicious attacker. Specifically, a system is observed by a set of (local) observation sites (OSs) which occasionally send their recorded sequences of observations to the coordinator that is in charge of estimating the system state. The malfunctions and attacks, referred to as errors in this paper, include symbol deletions, insertions and replacements, each of which bears a positive cost. Two types of errors, global errors and local errors, are proposed to describe the impact of errors on decentralized information processing. Global errors occur when all OSs record the same error, while local errors occur when different OSs record different errors. Distinguishing these types of errors is important for a proper design of decentralized information processing (so as to be more resilient and better equipped to handle attacks and failures). For each type of error, we propose two methods to efficiently perform state estimation: one based on appropriately modifying the original system and the other based on inferring the matching behavior of the original system. For each method, we adopt an estimation-by-release methodology to design an algorithm for constructing a corresponding synchronizer for state estimation.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RO-SVD: A Reconfigurable Hardware Copyright Protection Framework for AIGC Applications</title>
<link>https://arxiv.org/abs/2406.11536</link>
<guid>https://arxiv.org/abs/2406.11536</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式人工智能 (GenAI)，区块链，版权可追溯性框架，环形振荡器-奇异值分解 (RO-SVD)，现场可编程门阵列 (FPGA)

总结:

本文提出了一种基于区块链的版权可追溯性框架RO-SVD，该框架利用硬件熵源产生的低秩矩阵的分解计算，旨在解决生成式人工智能（GenAI）产生的多维度数据的安全管理和使用问题。通过结合现场可编程门阵列（FPGA）的并行性和可重构性，该框架能够在现有AI加速设备上低成本构建，针对AI生成内容（AIGC）的版权问题提供解决方案。研究团队开发了一个软硬件协同设计原型，并在多种适用于AI的FPGA上进行了实船试验和分析，以AI生成图像为例展示了该框架的有效性、定制化、不可预测性、效率以及可管理性和可重构性。据作者所知，这是首次针对AI生成内容具体实施版权可追溯性的硬件研究报告。 <div>
arXiv:2406.11536v2 Announce Type: replace 
Abstract: The dramatic surge in the utilisation of generative artificial intelligence (GenAI) underscores the need for a secure and efficient mechanism to responsibly manage, use and disseminate multi-dimensional data generated by artificial intelligence (AI). In this paper, we propose a blockchain-based copyright traceability framework called ring oscillator-singular value decomposition (RO-SVD), which introduces decomposition computing to approximate low-rank matrices generated from hardware entropy sources and establishes an AI-generated content (AIGC) copyright traceability mechanism at the device level. By leveraging the parallelism and reconfigurability of field-programmable gate arrays (FPGAs), our framework can be easily constructed on existing AI-accelerated devices and provide a low-cost solution to emerging copyright issues of AIGC. We developed a hardware-software (HW/SW) co-design prototype based on comprehensive analysis and on-board experiments with multiple AI-applicable FPGAs. Using AI-generated images as a case study, our framework demonstrated effectiveness and emphasised customisation, unpredictability, efficiency, management and reconfigurability. To the best of our knowledge, this is the first practical hardware study discussing and implementing copyright traceability specifically for AI-generated content.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2406.17249</link>
<guid>https://arxiv.org/abs/2406.17249</guid>
<content:encoded><![CDATA[
<div> 关键词：实时、分布式、多机器人、语义SLAM、环境映射

总结:
本文提出了一种实时分布式语义SLAM算法框架，适用于异构机器人团队在无GPS条件下共同构建基于对象的三维环境地图，包括室内、城市和森林场景。该框架集成了数据驱动的前端，用于从RGBD相机或LiDAR进行实例分割，并采用定制后端优化机器人轨迹和地图中的物体地标。为实现多个机器人信息融合，设计了基于语义的场景识别算法，利用对象级别的语义地图的信息丰富度和视角不变性进行机器人间的环闭检测。同时设计了一个通信模块来跟踪各机器人的观测数据以及在通信链路可用时其他机器人的观测数据。该框架支持机器人实时分布式运行，使它们能够灵活利用通信资源。文章将提出的框架与多种空中和地面机器人的自主导航及探索系统整合，并在各种室内外环境中进行了大量实验，验证了其在机器人间定位和物体映射准确性方面的表现，同时展现了对计算、存储和通信资源的需求适度。该框架已开源并作为模块化堆栈发布，适用于单 agent 和多机器人场景的对象级语义SLAM应用。项目网站和代码分别可在https://xurobotics.github.io/slideslam/ 和 https://github.com/XuRobotics/SLIDE_SLAM 找到。 <div>
arXiv:2406.17249v4 Announce Type: replace 
Abstract: This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) algorithm framework that enables a heterogeneous robot team to collaboratively construct object-based metric-semantic maps of 3D environments featuring indoor, urban, and forests without relying on GPS. The framework integrates a data-driven front-end for instance segmentation from either RGBD cameras or LiDARs and a custom back-end for optimizing robot trajectories and object landmarks in the map. To allow multiple robots to merge their information, we design semantics-driven place recognition algorithms that leverage the informativeness and viewpoint invariance of the object-level metric-semantic map for inter-robot loop closure detection. A communication module is designed to track each robot's observations and those of other robots whenever communication links are available. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate the proposed framework with the autonomous navigation and exploration systems of three types of aerial and ground robots, conducting extensive experiments in a variety of indoor and outdoor environments. These experiments demonstrate accuracy in inter-robot localization and object mapping, along with its moderate demands on computation, storage, and communication resources. The framework is open-sourced and available as a modular stack for object-level metric-semantic SLAM, suitable for both single-agent and multi-robot scenarios. The project website and code can be found at https://xurobotics.github.io/slideslam/ and https://github.com/XuRobotics/SLIDE_SLAM, respectively.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Know Your Account: Double Graph Inference-based Account De-anonymization on Ethereum</title>
<link>https://arxiv.org/abs/2411.18875</link>
<guid>https://arxiv.org/abs/2411.18875</guid>
<content:encoded><![CDATA[
<div> 关键词：Web 3.0, 区块链, 以太坊, 双重图, 账户匿名化推理

<br /><br />总结:
本文提出了一种名为DBG4ETH的新型双重图基以太坊账户去匿名化推理方法，旨在全面捕获账户的行为模式并增强对当前复杂、持续生成的交易行为的分析和判断能力。该方法首先构建了一个全局静态图，用于建立所有交易数据中各类账户节点间的复杂交互关系；随后，又构建了局部动态图来学习不同时间段内交易的逐渐演变过程。两种图从不同视角聚焦信息，通过DBG4ETH可以获取全球与局部、静态与动态交易图的特征。此外，文中还提出了自适应置信度校准方法，将校准后的加权预测值输入分类器以进行预测结果的预测。实验结果显示，DBG4ETH在账户识别任务上达到了最先进的结果，相比于分别处理每种图类型，其F1分数提高了至少3.75%，最高可达40.52%，并且相比类似的账户身份推断方法，性能提升了5.23%至12.91%。 <div>
arXiv:2411.18875v1 Announce Type: new 
Abstract: The scaled Web 3.0 digital economy, represented by decentralized finance (DeFi), has sparked increasing interest in the past few years, which usually relies on blockchain for token transfer and diverse transaction logic. However, illegal behaviors, such as financial fraud, hacker attacks, and money laundering, are rampant in the blockchain ecosystem and seriously threaten its integrity and security. In this paper, we propose a novel double graph-based Ethereum account de-anonymization inference method, dubbed DBG4ETH, which aims to capture the behavioral patterns of accounts comprehensively and has more robust analytical and judgment capabilities for current complex and continuously generated transaction behaviors. Specifically, we first construct a global static graph to build complex interactions between the various account nodes for all transaction data. Then, we also construct a local dynamic graph to learn about the gradual evolution of transactions over different periods. Different graphs focus on information from different perspectives, and features of global and local, static and dynamic transaction graphs are available through DBG4ETH. In addition, we propose an adaptive confidence calibration method to predict the results by feeding the calibrated weighted prediction values into the classifier. Experimental results show that DBG4ETH achieves state-of-the-art results in the account identification task, improving the F1-score by at least 3.75% and up to 40.52% compared to processing each graph type individually and outperforming similar account identity inference methods by 5.23% to 12.91%.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Swarm Intelligence-Driven Client Selection for Federated Learning in Cybersecurity applications</title>
<link>https://arxiv.org/abs/2411.18877</link>
<guid>https://arxiv.org/abs/2411.18877</guid>
<content:encoded><![CDATA[
<div> 关键词: Swarm Intelligence Optimization, Federated Learning, Cybersecurity, Grey Wolf Optimization, Particle Swarm Optimization

总结:<br />
本文针对 Swarm Intelligence Optimization（群智优化）算法在联邦学习（Federated Learning, FL）中的客户端选择应用展开研究，特别是在网络安全领域的应用。当前研究主要关注集中式机器学习的优化技术，而对FL中客户端多样性、非独立同分布数据以及敌对噪音等独特挑战的关注不足。为此，文章评估了九种群智优化算法，包括Grey Wolf Optimization（灰狼优化）、Particle Swarm Optimization（粒子群优化）、Cuckoo Search等在四种实验场景下的表现：固定客户端参与、动态参与模式、异质非独立同分布数据以及对抗性噪声条件。结果显示，GWO展现出优异的适应性和鲁棒性，在所有配置下均取得了最高的准确率、召回率和F1分数；同时，PSO和Cuckoo Search也表现出色。这些发现强调了群智优化算法在解决分布式和对抗性FL问题上的潜力，为网络安全应用，如IoT和大规模网络入侵检测，提供了可扩展和韧性强的解决方案。 <div>
arXiv:2411.18877v1 Announce Type: new 
Abstract: This study addresses a critical gap in the literature regarding the use of Swarm Intelligence Optimization (SI) algorithms for client selection in Federated Learning (FL), with a focus on cybersecurity applications. Existing research primarily explores optimization techniques for centralized machine learning, leaving the unique challenges of client diveristy, non-IID data distributions, and adversarial noise in decentralized FL largely unexamined. To bridge this gap, we evaluate nine SI algorithms-Grey Wolf Optimization (GWO), Particle Swarm Optimization (PSO), Cuckoo Search, Bat Algorithm, Bee Colony, Ant Colony Optimization, Fish Swarm, Glow Worm, and Intelligent Water Droplet-across four experimental scenarios: fixed client participation, dynamic participation patterns, hetergeneous non-IID data distributions, and adversarial noise conditions. Results indicate that GWO exhibits superior adaptability and robustness, achieving the highest accuracy, recall and F1-scoress across all configurations, while PSO and Cuckoo Search also demonstrate strong performance. These findings underscore the potential of SI algorithms to address decentralized and adversarial FL challenges, offereing scalable and resilient solutions for cybersecurity applications, including intrusion detection in IoT and large-scale networks.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Continual Graph Learning</title>
<link>https://arxiv.org/abs/2411.18919</link>
<guid>https://arxiv.org/abs/2411.18919</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦持续图学习（FCGL）、图神经网络（GNNs）、局部图遗忘（LGF）、全局专家冲突（GEC）、POWER框架

总结:<br />
本文针对大数据时代下不断演进的图数据管理所面临的存储成本和隐私问题，提出了联邦持续图学习（FCGL）这一全新研究方向。FCGL旨在适应多个分布式环境中的变化图数据，同时解决存储和隐私约束下的性能优化问题。文章通过实证分析揭示了FCGL在实现过程中面临的两大挑战：局部图遗忘（LGF）与全局专家冲突（GEC）。为了解决这些问题，作者提出了名为POWER的框架，该框架通过保存并回放具有最大局部-全局覆盖范围的经验节点来缓解LGF，同时采用伪原型重建策略和轨迹感知的知识转移方法在中央服务器端解决GEC。实验结果表明，POWER在多个图数据集上的表现优于现有的中心化CGL算法的联邦扩展版本以及视觉焦点的联邦持续学习算法。相关代码已开源，可在https://github.com/zyl24/FCGL_POWER获取。 <div>
arXiv:2411.18919v1 Announce Type: new 
Abstract: In the era of big data, managing evolving graph data poses substantial challenges due to storage costs and privacy issues. Training graph neural networks (GNNs) on such evolving data usually causes catastrophic forgetting, impairing performance on earlier tasks. Despite existing continual graph learning (CGL) methods mitigating this to some extent, they predominantly operate in centralized architectures and overlook the potential of distributed graph databases to harness collective intelligence for enhanced performance optimization. To address these challenges, we present a pioneering study on Federated Continual Graph Learning (FCGL), which adapts GNNs to multiple evolving graphs within decentralized settings while adhering to storage and privacy constraints. Our work begins with a comprehensive empirical analysis of FCGL, assessing its data characteristics, feasibility, and effectiveness, and reveals two principal challenges: local graph forgetting (LGF), where local GNNs forget prior knowledge when adapting to new tasks, and global expertise conflict (GEC), where the global GNN exhibits sub-optimal performance in both adapting to new tasks and retaining old ones, arising from inconsistent client expertise during server-side parameter aggregation. To tackle these, we propose the POWER framework, which mitigates LGF by preserving and replaying experience nodes with maximum local-global coverage at each client and addresses GEC by using a pseudo prototype reconstruction strategy and trajectory-aware knowledge transfer at the central server. Extensive evaluations across multiple graph datasets demonstrate POWER's superior performance over straightforward federated extensions of the centralized CGL algorithms and vision-focused federated continual learning algorithms. Our code is available at https://github.com/zyl24/FCGL_POWER.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Guardians of the Ledger: Protecting Decentralized Exchanges from State Derailment Defects</title>
<link>https://arxiv.org/abs/2411.18935</link>
<guid>https://arxiv.org/abs/2411.18935</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化交易所(DEX)，智能合约，状态脱轨缺陷，StateGuard，深度学习

总结:<br />
本文首次对去中心化交易所(DEX)中的状态脱轨缺陷进行了系统性研究，定义了五类状态脱轨缺陷并进行详细分析。为了解决这一问题，文中提出了一种名为StateGuard的新型深度学习框架，用于检测DEX智能合约中的状态脱轨缺陷。该框架利用智能合约拆解器将合约转化为抽象语法树(AST)，从中提取出五类依赖特征；接着，通过图优化器处理结构化数据；最后，使用图卷积网络(GCNs)对优化后的数据进行分析，以识别潜在的状态脱轨缺陷。在包含46个DEX项目和5,671个智能合约的数据集上评估后，StateGuard达到了94.25%的F1得分，并在与现有最优方法的对比实验中提升了6.29%的F1得分。为了验证其实用性，StateGuard还被应用于审计真实世界的合同并成功发现了多个新的CVE漏洞。 <div>
arXiv:2411.18935v1 Announce Type: new 
Abstract: The decentralized exchange (DEX) leverages smart contracts to trade digital assets for users on the blockchain. Developers usually develop several smart contracts into one project, implementing complex logic functions and multiple transaction operations. However, the interaction among these contracts poses challenges for developers analyzing the state logic. Due to the complex state logic in DEX projects, many critical state derailment defects have emerged in recent years. In this paper, we conduct the first systematic study of state derailment defects in DEX. We define five categories of state derailment defects and provide detailed analyses of them. Furthermore, we propose a novel deep learning-based framework StateGuard for detecting state derailment defects in DEX smart contracts. It leverages a smart contract deconstructor to deconstruct the contract into an Abstract Syntax Tree (AST), from which five categories of dependency features are extracted. Next, it implements a graph optimizer to process the structured data. At last, the optimized data is analyzed by Graph Convolutional Networks (GCNs) to identify potential state derailment defects. We evaluated StateGuard through a dataset of 46 DEX projects containing 5,671 smart contracts, and it achieved 94.25% F1-score. In addition, in a comparison experiment with state-of-the-art, StateGuard leads the F1-score by 6.29%. To further verify its practicality, we used StateGuar to audit real-world contracts and successfully authenticated multiple novel CVEs.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Game-Theoretic Approach to the Study of Blockchain's Robustness</title>
<link>https://arxiv.org/abs/2411.19175</link>
<guid>https://arxiv.org/abs/2411.19175</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、以太坊权益证明、安全性、活性、激励机制

总结:
<br />
本文针对近年来备受关注的区块链技术，尤其是以太坊权益证明（PoS）协议的鲁棒性进行了深入研究。首先，从分布式系统角度对Ethereum PoS协议进行形式化定义，并通过这一视角发现潜在的安全性和活性方面的漏洞。其次，分析了维持系统活性的关键机制——不活动泄露机制，但指出其可能导致牺牲安全性的风险。最后，运用博弈论模型探讨了理性验证者在Ethereum PoS中的策略选择，揭示了他们在何种条件下可能偏离预设协议以最大化收益。这些研究成果强调了激励机制对于区块链鲁棒性的重要性，并为设计更为健壮的区块链协议提供了洞见。 <div>
arXiv:2411.19175v1 Announce Type: new 
Abstract: Blockchains have sparked global interest in recent years, gaining importance as they increasingly influence technology and finance. This thesis investigates the robustness of blockchain protocols, specifically focusing on Ethereum Proof-of-Stake. We define robustness in terms of two critical properties: Safety, which ensures that the blockchain will not have permanent conflicting blocks, and Liveness, which guarantees the continuous addition of new reliable blocks.
  Our research addresses the gap between traditional distributed systems approaches, which classify agents as either honest or Byzantine (i.e., malicious or faulty), and game-theoretic models that consider rational agents driven by incentives. We explore how incentives impact the robustness with both approaches.
  The thesis comprises three distinct analyses. First, we formalize the Ethereum PoS protocol, defining its properties and examining potential vulnerabilities through a distributed systems perspective. We identify that certain attacks can undermine the system's robustness. Second, we analyze the inactivity leak mechanism, a critical feature of Ethereum PoS, highlighting its role in maintaining system liveness during network disruptions but at the cost of safety. Finally, we employ game-theoretic models to study the strategies of rational validators within Ethereum PoS, identifying conditions under which these agents might deviate from the prescribed protocol to maximize their rewards.
  Our findings contribute to a deeper understanding of the importance of incentive mechanisms for blockchain robustness and provide insights into designing more resilient blockchain protocols.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartLLMSentry: A Comprehensive LLM Based Smart Contract Vulnerability Detection Framework</title>
<link>https://arxiv.org/abs/2411.19234</link>
<guid>https://arxiv.org/abs/2411.19234</guid>
<content:encoded><![CDATA[
<div> 关键词: SmartLLMSentry、智能合约、区块链、大型语言模型、ChatGPT

总结:
本文介绍了SmartLLMSentry，这是一个利用大型语言模型（特别是ChatGPT和上下文训练）进行智能合约漏洞检测的新框架。与传统的基于规则的方法相比，SmartLLMSentry通过LLM有效地改进了新检测规则的集成过程。研究团队创建了一个专门针对五种随机选择的漏洞的训练和评估数据集，结果显示，在充分的数据支持下，该模型具有高达91.1%的精确匹配准确率。然而，实验发现GPT-4在规则生成方面的性能不如GPT-3。这项研究表明，SmartLLMSentry通过LLM驱动的规则整合显著提升了漏洞检测的速度和准确性，为提升区块链安全性和解决智能合约中以前未被充分探索的漏洞提供了一种新的方法。 <div>
arXiv:2411.19234v1 Announce Type: new 
Abstract: Smart contracts are essential for managing digital assets in blockchain networks, highlighting the need for effective security measures. This paper introduces SmartLLMSentry, a novel framework that leverages large language models (LLMs), specifically ChatGPT with in-context training, to advance smart contract vulnerability detection. Traditional rule-based frameworks have limitations in integrating new detection rules efficiently. In contrast, SmartLLMSentry utilizes LLMs to streamline this process. We created a specialized dataset of five randomly selected vulnerabilities for model training and evaluation. Our results show an exact match accuracy of 91.1% with sufficient data, although GPT-4 demonstrated reduced performance compared to GPT-3 in rule generation. This study illustrates that SmartLLMSentry significantly enhances the speed and accuracy of vulnerability detection through LLMdriven rule integration, offering a new approach to improving Blockchain security and addressing previously underexplored vulnerabilities in smart contracts.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning</title>
<link>https://arxiv.org/abs/2411.19335</link>
<guid>https://arxiv.org/abs/2411.19335</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, PEFT, 信息安全, 攻击向量, 防御策略

总结:
<br />
本文探讨了联邦学习中参数高效微调（FedPEFT）的新安全威胁。FedPEFT是一种用于保护隐私和提高预训练语言模型在分布式环境下的适应效率的方法。然而，文章提出了一种名为PEFT-as-an-Attack (PaaA) 的新攻击手段，该攻击利用PEFT方法如LoRA，即使在少量参数可训练及仅少数客户端恶意操作的情况下，也能绕过PLM的安全对齐，生成有害内容。实验显示，此攻击的成功率约为80%。为应对这一威胁，文章研究了包括鲁棒聚合方案（RASs）和后PEFT安全对齐（PPSA）在内的防御策略，但发现现有防御措施在处理高度异构数据分布情况时存在局限性，如DnC和ClippedClustering等先进RASs防御效果不佳；而PPSA虽能降低攻击成功率至10%以下，却会显著损害模型在目标任务上的准确性。因此，文章强调了急需开发更有效的防御机制以同时确保安全性并保持FedPEFT范式的性能。 <div>
arXiv:2411.19335v1 Announce Type: new 
Abstract: Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising paradigm for privacy-preserving and efficient adaptation of Pre-trained Language Models (PLMs) in Federated Learning (FL) settings. It preserves data privacy by keeping the data decentralized and training the model on local devices, ensuring that raw data never leaves the user's device. Moreover, the integration of PEFT methods such as LoRA significantly reduces the number of trainable parameters compared to fine-tuning the entire model, thereby minimizing communication costs and computational overhead. Despite its potential, the security implications of FedPEFT remain underexplored. This paper introduces a novel security threat to FedPEFT, termed PEFT-as-an-Attack (PaaA), which exposes how PEFT can be exploited as an attack vector to circumvent PLMs' safety alignment and generate harmful content in response to malicious prompts. Our evaluation of PaaA reveals that with less than 1% of the model's parameters set as trainable, and a small subset of clients acting maliciously, the attack achieves an approximate 80% attack success rate using representative PEFT methods such as LoRA. To mitigate this threat, we further investigate potential defense strategies, including Robust Aggregation Schemes (RASs) and Post-PEFT Safety Alignment (PPSA). However, our empirical analysis highlights the limitations of these defenses, i.e., even the most advanced RASs, such as DnC and ClippedClustering, struggle to defend against PaaA in scenarios with highly heterogeneous data distributions. Similarly, while PPSA can reduce attack success rates to below 10%, it severely degrades the model's accuracy on the target task. Our results underscore the urgent need for more effective defense mechanisms that simultaneously ensure security and maintain the performance of the FedPEFT paradigm.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Transit Signal Priority into Multi-Agent Reinforcement Learning based Traffic Signal Control</title>
<link>https://arxiv.org/abs/2411.19359</link>
<guid>https://arxiv.org/abs/2411.19359</guid>
<content:encoded><![CDATA[
<div> 关键词：Transit Signal Priority (TSP)，multi-agent reinforcement learning (MARL)，traffic signal control，value decomposition network (VDN)，intersection delay

<br /><br />总结：
本文将Transit Signal Priority (TSP)整合到基于多智能体强化学习(MARL)的交通信号控制中。首先，研究开发了一种针对两个协同工作的交叉路口的自适应信号控制系统，使用MARL和价值分解网络(VDN)架构进行集中训练，结果显示其性能略优于基于v/c为0.95的整体交叉口延迟的协调感应信号控制。接着，将训练好的信号控制智能体作为背景控制器，研究了两种事件驱动的TSP智能体方案：一种是在分散式训练和分散式执行(DTDE)框架下训练独立的TSP智能体；另一种则采用集中式训练和分散式执行(CTDE)框架以及VDN架构训练协调的TSP智能体以选择并实施跨两个交叉路口的协调TSP策略。经过训练，两种TSP方案都能有效减少公交车延误，其中独立TSP智能体相较于无TSP情况可降低两个交叉口的公交车延误达22%，而协调TSP智能体能实现27%的延误减少。在此过程中，对于多数次级街道行驶方向，仅有轻微的延迟增加。 <div>
arXiv:2411.19359v1 Announce Type: new 
Abstract: This study integrates Transit Signal Priority (TSP) into multi-agent reinforcement learning (MARL) based traffic signal control. The first part of the study develops adaptive signal control based on MARL for a pair of coordinated intersections in a microscopic simulation environment. The two agents, one for each intersection, are centrally trained using a value decomposition network (VDN) architecture. The trained agents show slightly better performance compared to coordinated actuated signal control based on overall intersection delay at v/c of 0.95. In the second part of the study the trained signal control agents are used as background signal controllers while developing event-based TSP agents. In one variation, independent TSP agents are formulated and trained under a decentralized training and decentralized execution (DTDE) framework to implement TSP at each intersection. In the second variation, the two TSP agents are centrally trained under a centralized training and decentralized execution (CTDE) framework and VDN architecture to select and implement coordinated TSP strategies across the two intersections. In both cases the agents converge to the same bus delay value, but independent agents show high instability throughout the training process. For the test runs, the two independent agents reduce bus delay across the two intersections by 22% compared to the no TSP case while the coordinated TSP agents achieve 27% delay reduction. In both cases, there is only a slight increase in delay for a majority of the side street movements.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Local Information Aggregation based Multi-Agent Reinforcement Learning for Robot Swarm Dynamic Task Allocation</title>
<link>https://arxiv.org/abs/2411.19526</link>
<guid>https://arxiv.org/abs/2411.19526</guid>
<content:encoded><![CDATA[
<div> 关键词：动态环境、任务分配、机器人集群、局部信息聚合、分布式部分可观测马尔可夫决策过程 (Dec-POMDP)、LIA_MADDPG算法、集中式训练与分布式执行 (CTDE)

总结:<br />
本文研究了如何针对动态环境优化机器人集群的任务分配问题，提出了一种利用分布式部分可观测马尔可夫决策过程(Dec-POMDP)的新框架。该框架设计了一个名为局部信息聚合多智能体深度确定性策略梯度（LIA_MADDPG）的算法，实现了集中式训练和分布式执行相结合。其中，LIA模块在训练阶段负责从邻近机器人收集关键数据以提升决策效率；在执行阶段，则提出了根据变化和部分可观测的环境条件动态调整任务分配的策略改进方法。实验结果显示，LIA模块可以无缝融入基于CTDE的多种MARL方法，显著提升了性能。相比于六种传统强化学习算法和一个启发式算法，LIA_MADDPG展现出了更优的可扩展性、对环境变化的快速适应能力以及维持稳定性和收敛速度的能力，证实了其在动态环境下通过增强局部协作和自适应策略执行来有效改善机器人集群任务分配的潜力。 <div>
arXiv:2411.19526v1 Announce Type: new 
Abstract: In this paper, we explore how to optimize task allocation for robot swarms in dynamic environments, emphasizing the necessity of formulating robust, flexible, and scalable strategies for robot cooperation. We introduce a novel framework using a decentralized partially observable Markov decision process (Dec_POMDP), specifically designed for distributed robot swarm networks. At the core of our methodology is the Local Information Aggregation Multi-Agent Deep Deterministic Policy Gradient (LIA_MADDPG) algorithm, which merges centralized training with distributed execution (CTDE). During the centralized training phase, a local information aggregation (LIA) module is meticulously designed to gather critical data from neighboring robots, enhancing decision-making efficiency. In the distributed execution phase, a strategy improvement method is proposed to dynamically adjust task allocation based on changing and partially observable environmental conditions. Our empirical evaluations show that the LIA module can be seamlessly integrated into various CTDE-based MARL methods, significantly enhancing their performance. Additionally, by comparing LIA_MADDPG with six conventional reinforcement learning algorithms and a heuristic algorithm, we demonstrate its superior scalability, rapid adaptation to environmental changes, and ability to maintain both stability and convergence speed. These results underscore LIA_MADDPG's outstanding performance and its potential to significantly improve dynamic task allocation in robot swarms through enhanced local collaboration and adaptive strategy execution.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Secure Filtering against Spatio-Temporal False Data under Asynchronous Sampling</title>
<link>https://arxiv.org/abs/2411.19765</link>
<guid>https://arxiv.org/abs/2411.19765</guid>
<content:encoded><![CDATA[
<div> 关键词：状态估计、连续LTI系统、非周期性采样、异步采样、攻击防护

总结:

本文针对存在非周期性和异步采样测量值情况下，连续线性时不变（LTI）系统的状态估计问题进行了研究。文章考虑了传感器通过未受保护的通信通道向融合中心传输测量值及时间戳的过程中，系统可能遭受包括篡改测量值、篡改时间戳以及混合恶意活动等攻击。为应对这类更强大的攻击，文中提出了一种分散式局部估计算法，每个传感器根据其自身的测量数据以异步方式维护本地状态估计。通过时间预测和事件触发的方式实现局部状态同步与融合。当采样时间无病态情况时，证明在没有攻击的情况下，本地估计可恢复到最优卡尔曼估计。在存在攻击的情况下，文章提出了采用$\ell_1$范数正则化的最小二乘问题生成安全估计，并确保在满足可观测性冗余条件下误差保持有界。最后，通过对IEEE 14-bus系统的基准案例分析展示了所提算法的有效性。<br /><br /> <div>
arXiv:2411.19765v1 Announce Type: new 
Abstract: This paper addresses the state estimation problem in continuous LTI systems under attacks with non-periodic and asynchronous sampled measurements. The non-periodic and asynchronous sampling requires sensors to transmit not only the measurement values but also the sampling time-stamps to the fusion center via unprotected communication channels. This communication scheme leaves the system vulnerable to a variety of malicious activities such as (i) manipulating measurement values, (ii) manipulating time-stamps, (iii) hybrid manipulations such as generating fake measurements or eliminating the measurement. To deal with such more powerful attacks, we propose a decentralized local estimation algorithm where each sensor maintains its local state estimate based on its measurements in an asynchronous fashion. The local states are synchronized by time-prediction and fused in an event-triggered manner. In the absence of attacks, local estimates are proved to recover the optimal Kalman estimation by our carefully designed weighted least square problem, given that the sample time is non-pathological. In the presence of attacks, an $\ell_1$ regularized least square problem is proposed to generate secure estimates with uniformly bounded error as long as the observability redundancy is satisfied. The effectiveness of the proposed algorithm is demonstrated through a benchmark example of the IEEE 14-bus system.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing AI microscopy for foodborne bacterial classification via adversarial domain adaptation across optical and biological variability</title>
<link>https://arxiv.org/abs/2411.19514</link>
<guid>https://arxiv.org/abs/2411.19514</guid>
<content:encoded><![CDATA[
<div> 关键词：AI赋能显微镜、对抗性领域适应、多域适应、细菌分类、食品安全

<br />
总结:
本文提出了一种利用AI赋能显微镜进行食品中病原菌快速检测的方法，通过对抗性领域适应增强了算法对不同条件下细菌图像识别的泛化能力。研究比较了单目标和多域适应方法在六个代表性菌株分类中的性能。采用EfficientNetV2作为基础架构，结合细粒度特征提取技术处理小目标图像，并运用少量样本学习。通过训练模型对源域（控制条件下的相位对比显微镜数据）进行学习，再在目标域（包括明亮场显微镜、低放大倍数以及延长培养时间等情况）下进行评估，结果显示，单域适应网络(DANNs)能分别提升20x、20x-5h和BF目标域的分类准确率最高达54.45%、43.44%和31.67%，同时对源域的影响极小。而多域适应网络(MDANNs)在BF和20x域表现更优。Grad-CAM和t-SNE可视化验证了模型能够在各种条件下学习到领域不变的特征。这项研究为实现细菌分类提供了一个可扩展和适应性强的框架，减少了对复杂样本准备的依赖，有助于在分散和资源有限的环境中应用，从而更好地保障食品安全与质量。 <div>
arXiv:2411.19514v1 Announce Type: cross 
Abstract: Rapid detection of foodborne bacteria is critical for food safety and quality, yet traditional culture-based methods require extended incubation and specialized sample preparation. This study addresses these challenges by i) enhancing the generalizability of AI-enabled microscopy for bacterial classification using adversarial domain adaptation and ii) comparing the performance of single-target and multi-domain adaptation. Three Gram-positive (Bacillus coagulans, Bacillus subtilis, Listeria innocua) and three Gram-negative (E. coli, Salmonella Enteritidis, Salmonella Typhimurium) strains were classified. EfficientNetV2 served as the backbone architecture, leveraging fine-grained feature extraction for small targets. Few-shot learning enabled scalability, with domain-adversarial neural networks (DANNs) addressing single domains and multi-DANNs (MDANNs) generalizing across all target domains. The model was trained on source domain data collected under controlled conditions (phase contrast microscopy, 60x magnification, 3-h bacterial incubation) and evaluated on target domains with variations in microscopy modality (brightfield, BF), magnification (20x), and extended incubation to compensate for lower resolution (20x-5h). DANNs improved target domain classification accuracy by up to 54.45% (20x), 43.44% (20x-5h), and 31.67% (BF), with minimal source domain degradation (<4.44%). MDANNs achieved superior performance in the BF domain and substantial gains in the 20x domain. Grad-CAM and t-SNE visualizations validated the model's ability to learn domain-invariant features across diverse conditions. This study presents a scalable and adaptable framework for bacterial classification, reducing reliance on extensive sample preparation and enabling application in decentralized and resource-limited environments.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eden: An Provably Secure, Ultra-Fast, and Fully Decentralized Blockchain Interoperability Protocol</title>
<link>https://arxiv.org/abs/2311.17454</link>
<guid>https://arxiv.org/abs/2311.17454</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、互操作性、Eden、SparkleX、零知识 MapReduce

总结:
<br />
随着区块链生态系统的成长和多样化，不同区块链网络间的无缝互操作性变得至关重要。本文介绍了用于SparkleX的Eden协议，它是一种基于零知识 MapReduce 框架的弹性去中心化使者网络，实现了超快速、安全且完全去中心化的跨链通信。Eden的设计、强大的安全性模型以及确保其在网络环境压力下仍具有弹性和韧性的创新机制都得到了深入探讨。 <div>
arXiv:2311.17454v2 Announce Type: replace 
Abstract: As the blockchain ecosystem grows and diversifies, seamless interoperability between blockchain networks has become essential. Interoperability not only enhances the usability and reach of individual chains but also fosters collaboration, unlocking new opportunities for decentralized applications. In this paper, we introduce Eden, the parallel-verified messaging protocol powering SparkleX. Eden is an elastic, decentralized envoy network built on a zero-knowledge MapReduce framework (i.e., ZK-MapReduce), enabling ultra-fast, secure, and fully decentralized cross-chain communication. We explore Eden's design, its robust security model, and the innovative mechanisms that ensure its elasticity and resilience, even in demanding network environments.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Joint Resource Optimization, Computation Offloading and Resource Slicing for Multi-Edge Traffic-Cognitive Networks</title>
<link>https://arxiv.org/abs/2411.17782</link>
<guid>https://arxiv.org/abs/2411.17782</guid>
<content:encoded><![CDATA[
<div> 关键词: 边缘计算、资源分配、任务卸载、Stackelberg博弈、贝叶斯优化

总结:<br />
本文探讨了边缘计算环境下，平台与边缘服务器（ESs）之间动态交互的日益变化态势。面对高效资源利用和严格的服务质量（QoS）要求，需要对ESs进行激励并优化平台运营目标。研究内容涉及一个多智能体系统，其中平台和ESs都是具有自我利益的实体。文章提出了一个基于Stackelberg博弈的新型框架来建模各利益相关者之间的互动，并采用一种基于贝叶斯优化的集中式算法解决联合优化问题。针对因隐私顾虑带来的实际信息收集挑战，文中进一步设计了一种利用神经网络优化和隐私保护信息交换协议的分布式解决方案。大量的数值评估证明了所提机制相比现有基准能实现更优性能。 <div>
arXiv:2411.17782v1 Announce Type: new 
Abstract: The evolving landscape of edge computing envisions platforms operating as dynamic intermediaries between application providers and edge servers (ESs), where task offloading is coupled with payments for computational services. Ensuring efficient resource utilization and meeting stringent Quality of Service (QoS) requirements necessitates incentivizing ESs while optimizing the platforms operational objectives. This paper investigates a multi-agent system where both the platform and ESs are self-interested entities, addressing the joint optimization of revenue maximization, resource allocation, and task offloading. We propose a novel Stackelberg game-based framework to model interactions between stakeholders and solve the optimization problem using a Bayesian Optimization-based centralized algorithm. Recognizing practical challenges in information collection due to privacy concerns, we further design a decentralized solution leveraging neural network optimization and a privacy-preserving information exchange protocol. Extensive numerical evaluations demonstrate the effectiveness of the proposed mechanisms in achieving superior performance compared to existing baselines.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>CrypQ: A Database Benchmark Based on Dynamic, Ever-Evolving Ethereum Data</title>
<link>https://arxiv.org/abs/2411.17913</link>
<guid>https://arxiv.org/abs/2411.17913</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据库系统、动态数据、区块链、CrypQ、查询优化器

总结:
现代数据库系统需要处理随时间演变的动态数据，但许多流行基准测试未能充分评估这一特性。本文引入了一个名为CrypQ的新数据库基准，它利用公开的、动态变化的以太坊区块链数据，提供了反映现实和活跃加密货币市场中不可预测性的大规模、不断进化的数据集。文章详细描述了CrypQ的数据模式、创建数据快照和更新序列的方法以及一系列相关的SQL查询。作为示例，作者展示了使用CrypQ如何在复杂、演进的数据分布上评价基于成本的查询优化器，这些分布具有真实世界的偏斜性和依赖性。<br /><br /> <div>
arXiv:2411.17913v1 Announce Type: new 
Abstract: Modern database systems are expected to handle dynamic data whose characteristics may evolve over time. Many popular database benchmarks are limited in their ability to evaluate this dynamic aspect of the database systems. Those that use synthetic data generators often fail to capture the complexity and unpredictable nature of real data, while most real-world datasets are static and difficult to create high-volume, realistic updates for. This paper introduces CrypQ, a database benchmark leveraging dynamic, public Ethereum blockchain data. CrypQ offers a high-volume, ever-evolving dataset reflecting the unpredictable nature of a real and active cryptocurrency market. We detail CrypQ's schema, procedures for creating data snapshots and update sequences, and a suite of relevant SQL queries. As an example, we demonstrate CrypQ's utility in evaluating cost-based query optimizers on complex, evolving data distributions with real-world skewness and dependencies.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging A New GAN-based Transformer with ECDH Crypto-system for Enhancing Energy Theft Detection in Smart Grid</title>
<link>https://arxiv.org/abs/2411.18023</link>
<guid>https://arxiv.org/abs/2411.18023</guid>
<content:encoded><![CDATA[
<div> 关键词：能源盗窃检测、分裂学习、GAN-Transformer、隐私泄漏保护、变压器架构

总结:
<br />
本文提出了一种基于GAN-Transformer的新型分裂学习框架，用于提高能源盗窃检测的准确性并保障用户数据隐私。该框架利用变压器架构处理能源消耗数据长程依赖性的优势，提升了检测效果。为应对传统分裂学习中的隐私泄露问题，文中创新性地采用了一种基于掩码的方法，这是首次将其应用于针对AI敌手的分裂学习场景中，有效保护了敏感信息。实验结果显示，该提议的框架不仅达到了与传统方法相当的检测精度，而且显著增强了隐私保护力度。这表明GAN-Transformer分裂学习框架在能源盗窃检测领域具有高效且安全的应用潜力。 <div>
arXiv:2411.18023v1 Announce Type: new 
Abstract: Detecting energy theft is vital for effectively managing power grids, as it ensures precise billing and prevents financial losses. Split-learning emerges as a promising decentralized machine learning technique for identifying energy theft while preserving user data confidentiality. Nevertheless, traditional split learning approaches are vulnerable to privacy leakage attacks, which significantly threaten data confidentiality. To address this challenge, we propose a novel GAN-Transformer-based split learning framework in this paper. This framework leverages the strengths of the transformer architecture, which is known for its capability to process long-range dependencies in energy consumption data. Thus, it enhances the accuracy of energy theft detection without compromising user privacy. A distinctive feature of our approach is the deployment of a novel mask-based method, marking a first in its field to effectively combat privacy leakage in split learning scenarios targeted at AI-enabled adversaries. This method protects sensitive information during the model's training phase. Our experimental evaluations indicate that the proposed framework not only achieves accuracy levels comparable to conventional methods but also significantly enhances privacy protection. The results underscore the potential of the GAN-Transformer split learning framework as an effective and secure tool in the domain of energy theft detection.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hidden Data Privacy Breaches in Federated Learning</title>
<link>https://arxiv.org/abs/2411.18269</link>
<guid>https://arxiv.org/abs/2411.18269</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、数据重建攻击、恶意代码注入、高分辨率图像、防御方法

<br /><br />总结:

本文提出了一个针对联邦学习(Federated Learning)的新式数据重建攻击方法。该攻击利用恶意代码注射技术，结合独特的稀疏编码设计和区块划分策略，能够在不引起模型明显变化的情况下，隐秘地嵌入隐藏模型并系统性地抽取敏感数据。通过基于斐波那契指数的设计实现高效结构化的数据检索，而区块划分则增强了处理大规模及高分辨率图像的能力。实验结果显示，与五种最先进的数据重建攻击方法相比，本文的方法在五个不同的检测方法下表现更优，且能够逃避现有的数据重建防御手段，同时适用于FedAVG和FedSGD两种联邦学习场景。文章强调了开发者需要针对此类新威胁开发新的防御措施，并承诺将在论文被接受后开源相关代码。 <div>
arXiv:2411.18269v1 Announce Type: new 
Abstract: Federated Learning (FL) emerged as a paradigm for conducting machine learning across broad and decentralized datasets, promising enhanced privacy by obviating the need for direct data sharing. However, recent studies show that attackers can steal private data through model manipulation or gradient analysis. Existing attacks are constrained by low theft quantity or low-resolution data, and they are often detected through anomaly monitoring in gradients or weights. In this paper, we propose a novel data-reconstruction attack leveraging malicious code injection, supported by two key techniques, i.e., distinctive and sparse encoding design and block partitioning. Unlike conventional methods that require detectable changes to the model, our method stealthily embeds a hidden model using parameter sharing to systematically extract sensitive data. The Fibonacci-based index design ensures efficient, structured retrieval of memorized data, while the block partitioning method enhances our method's capability to handle high-resolution images by dividing them into smaller, manageable units. Extensive experiments on 4 datasets confirmed that our method is superior to the five state-of-the-art data-reconstruction attacks under the five respective detection methods. Our method can handle large-scale and high-resolution data without being detected or mitigated by state-of-the-art data reconstruction defense methods. In contrast to baselines, our method can be directly applied to both FedAVG and FedSGD scenarios, underscoring the need for developers to devise new defenses against such vulnerabilities. We will open-source our code upon acceptance.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Uncertainty and Personalization via Efficient Second-order Optimization</title>
<link>https://arxiv.org/abs/2411.18385</link>
<guid>https://arxiv.org/abs/2411.18385</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Bayesian、优化方法、效率、通信成本

总结:<br />
本文提出了一种新颖的用于联邦学习（Federated Learning）的贝叶斯方法，该方法利用高效的二阶优化技术，旨在解决传统贝叶斯FL在计算和通信成本上的问题。新方法与Adam等一阶优化方法具有相似的计算成本，同时保持了贝叶斯方法对于FL的优势，如不确定性量化、个性化建模以及通过层级贝叶斯框架处理客户端间共性。实验表明，新方法在标准及个性化FL设置中均比当前最优的贝叶斯FL方法更高效且准确，不仅提高了预测精度，也改进了不确定性估计。 <div>
arXiv:2411.18385v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a promising method to collaboratively learn from decentralized and heterogeneous data available at different clients without the requirement of data ever leaving the clients. Recent works on FL have advocated taking a Bayesian approach to FL as it offers a principled way to account for the model and predictive uncertainty by learning a posterior distribution for the client and/or server models. Moreover, Bayesian FL also naturally enables personalization in FL to handle data heterogeneity across the different clients by having each client learn its own distinct personalized model. In particular, the hierarchical Bayesian approach enables all the clients to learn their personalized models while also taking into account the commonalities via a prior distribution provided by the server. However, despite their promise, Bayesian approaches for FL can be computationally expensive and can have high communication costs as well because of the requirement of computing and sending the posterior distributions. We present a novel Bayesian FL method using an efficient second-order optimization approach, with a computational cost that is similar to first-order optimization methods like Adam, but also provides the various benefits of the Bayesian approach for FL (e.g., uncertainty, personalization), while also being significantly more efficient and accurate than SOTA Bayesian FL methods (both for standard as well as personalized FL settings). Our method achieves improved predictive accuracies as well as better uncertainty estimates as compared to the baselines which include both optimization based as well as Bayesian FL methods.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proving and Rewarding Client Diversity to Strengthen Resilience of Blockchain Networks</title>
<link>https://arxiv.org/abs/2411.18401</link>
<guid>https://arxiv.org/abs/2411.18401</guid>
<content:encoded><![CDATA[
<div> 关键词: 客户端多样性、以太坊区块链、网络韧性、经济激励、verifiable execution

<br /><br />总结:
本文关注的是以太坊区块链中的客户端多样性问题，提出了一种新的概念框架以增强网络韧性的系统属性。该框架的核心目标在于利用经济激励和可验证执行来促进少数客户端的采用，从而打造更为健壮的区块链生态系统。具体来说，文章建议明确并可验证地识别出协议参与者的客户端实现，并通过向使用少数客户端的参与者提供更高的参与奖励来鼓励其使用。此外，文中针对以太坊提出了这一框架的详细蓝图。该提议对于提升区块链客户端多样性具有变革性意义，并可应用于增强任何去中心化分布式系统的韧性。 <div>
arXiv:2411.18401v1 Announce Type: new 
Abstract: Client diversity in the Ethereum blockchain refers to the use of multiple independent implementations of the Ethereum protocol. This effectively enhances network resilience by reducing reliance on any single software client implementation. With client diversity, a single bug cannot tear the whole network down. However, despite multiple production-grade client implementations being available, there is still a heavily skewed distribution of clients in Ethereum. This is a concern for the community. In this paper, we introduce a novel conceptual framework for client diversity. The core goal is to improve the network resilience as a systemic property. Our key insight is to leverage economic incentives and verifiable execution to encourage the adoption of minority clients, thereby fostering a more robust blockchain ecosystem. Concretely, we propose to unambiguously and provably identify the client implementation used by any protocol participant, and to use this information to incentivize the usage of minority clients by offering higher participation rewards. We outline a detailed blueprint for our conceptual framework, in the realm of Ethereum. Our proposal is a game changer for improving client diversity of blockchains. Ultimately, it applies to strengthening the resilience of any decentralized distributed systems.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Planning of Carbon-Neutral Heating Demand Coverage Under Uncertainty in a Coupled Multi-Energy Grid</title>
<link>https://arxiv.org/abs/2305.04577</link>
<guid>https://arxiv.org/abs/2305.04577</guid>
<content:encoded><![CDATA[
<div> 关键词：多能源网格、消费者行为、不确定性、鲁棒优化、碳中和

<br /><br />总结:
本文提出了一种以消费者为中心的电网规划方法，针对燃气和区域供暖与电力网融合的多能源网格系统。文章指出实际情况下，消费者的供暖技术采纳行为受成本和政府法规影响，具有高度不确定性，这增加了电网扩展投资的风险。为应对这一挑战，论文运用鲁棒优化模型来处理能源价格的不确定性，采用比例偏差的区间不确定性进行建模，使规划者能够预测不同地区的特定供暖技术采纳率并优先考虑必要的电网扩张。研究以汉堡为例进行了应用，结果表明在高密度地区，区域能源供暖扩展是实现碳中和的低风险投资；而在较低密度地区，电能驱动的分布式热泵成为支持方案；当电气化扩展不切实际时，氢气管网成为可行选项。随着不确定性的增加，解决方案将变得更加保守。 <div>
arXiv:2305.04577v3 Announce Type: replace 
Abstract: Integrating the gas and district heating with the electrical grid in a multi-energy grid has been shown to provide flexibility and prevent bottlenecks in the operation of electrical distribution grids. This integration assumes a top-down grid planning approach and a perfect knowledge of consumer behaviour. In reality, consumers decides whether to adopt a heating technology based on costs and government regulation. This behavior is highly uncertain and depends on fluctuations in heating technology costs and energy prices. The uncertainty associated with consumer behavior increases the risk of investment in grid expansion. In response to this challenge, this paper proposes an approach with the consumer at the center of the planning method. Robust optimization is used to model the uncertainty in prices to reduce the risk of investment in grid expansion. The uncertainty in energy prices is modeled using interval uncertainty with a proportional deviation. This allows planners, operators and regulators to predict the adoption rate of certain heating technology in different geographical areas and prioritize the expansion of specific grids where they are required. By minimizing a cost function subject to robust constraints, the strategy ensures robustness against uncertainties in energy prices. This robust optimization approach is applied to Hamburg as a case study. The result of the optimization represents the consumer's decision. The impact of the consumer's decision on the electrical grid is analzed on different benchmark distribution grids. The study concludes that district heating expansion in high-density areas is a low-risk investment for carbon neutrality. In less dense areas, electrification supports decentralized heat pumps. Meanwhile, hydrogen gas grids are viable where electric expansion is impractical. Increased uncertainty leads to more conservative solutions.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning in Chemical Engineering: A Tutorial on a Framework for Privacy-Preserving Collaboration Across Distributed Data Sources</title>
<link>https://arxiv.org/abs/2411.16737</link>
<guid>https://arxiv.org/abs/2411.16737</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、化学工程、数据隐私、制造优化、TensorFlow Federated

总结:
本文介绍了Federated Learning（联邦学习）这一分布式机器学习方法，尤其针对化学工程领域的应用提供了易于理解的介绍。文章通过实例和手把手教程探讨了联邦学习在制造业优化、多模态数据分析和药物发现等任务中的运用，并着重讨论了如何保护专有信息和管理分布式数据集的独特挑战。文中使用$\texttt{Flower}$和$\texttt{TensorFlow Federated}$等关键框架构建了教程，旨在为化学工程师提供适用于特定需求的FL工具。通过对比FL与集中式学习在三个与化工应用相关的不同数据集上的性能，结果显示FL通常能保持或提高分类性能，尤其是在处理复杂和异构数据时表现更优。最后，文章指出了联邦学习面临的开放性挑战及现有的改进措施和策略。 <div>
arXiv:2411.16737v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning approach that has gained attention for its potential to enable collaborative model training across clients while protecting data privacy, making it an attractive solution for the chemical industry. This work aims to provide the chemical engineering community with an accessible introduction to the discipline. Supported by a hands-on tutorial and a comprehensive collection of examples, it explores the application of FL in tasks such as manufacturing optimization, multimodal data integration, and drug discovery while addressing the unique challenges of protecting proprietary information and managing distributed datasets. The tutorial was built using key frameworks such as $\texttt{Flower}$ and $\texttt{TensorFlow Federated}$ and was designed to provide chemical engineers with the right tools to adopt FL in their specific needs. We compare the performance of FL against centralized learning across three different datasets relevant to chemical engineering applications, demonstrating that FL will often maintain or improve classification performance, particularly for complex and heterogeneous data. We conclude with an outlook on the open challenges in federated learning to be tackled and current approaches designed to remediate and improve this framework.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Meets LLMs: A Living Survey on Bidirectional Integration</title>
<link>https://arxiv.org/abs/2411.16809</link>
<guid>https://arxiv.org/abs/2411.16809</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、多模态、区块链技术、安全性、隐私保护

<br /><br />总结:

本文探讨了大型语言模型与区块链技术的融合及其潜在优势和发展前景。随着大型语言模型和可解释性研究领域的显著进步，以及对安全性和隐私问题的关注，区块链技术因其去中心化、防篡改等特性提供了新的解决方案。文章分析了两种技术各自的优势及限制，并从两个方向研究它们的结合：一是将大型语言模型应用于区块链，提出六种发展方向并探索改善区块链技术及其应用场景的方法；二是利用区块链技术的特点来弥补大型语言模型的不足，并发掘其在多个领域的应用潜力。 <div>
arXiv:2411.16809v1 Announce Type: new 
Abstract: In the domain of large language models, considerable advancements have been attained in multimodal large language models and explainability research, propelled by the continuous technological progress and innovation. Nonetheless, security and privacy concerns continue to pose as prominent challenges in this field. The emergence of blockchain technology, marked by its decentralized nature, tamper-proof attributes, distributed storage functionality, and traceability, has provided novel approaches for resolving these issues. Both of these technologies independently hold vast potential for development; yet, their combination uncovers substantial cross-disciplinary opportunities and growth prospects. The current research tendencies are increasingly concentrating on the integration of blockchain with large language models, with the aim of compensating for their respective limitations through this fusion and promoting further technological evolution. In this study, we evaluate the advantages and developmental constraints of the two technologies, and explore the possibility and development potential of their combination. This paper primarily investigates the technical convergence in two directions: Firstly, the application of large language models to blockchain, where we identify six major development directions and explore solutions to the shortcomings of blockchain technology and their application scenarios; Secondly, the application of blockchain technology to large language models, leveraging the characteristics of blockchain to remedy the deficiencies of large language models and exploring its application potential in multiple fields.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EvoChain: a Recovery Approach for Permissioned Blockchain Applications</title>
<link>https://arxiv.org/abs/2411.16976</link>
<guid>https://arxiv.org/abs/2411.16976</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、EvoChain、数据红动作业、时间限制条件、Hyperledger Fabric

总结:<br />
本文介绍了EvoChain，这是一个针对区块链技术的智能合约框架扩展，旨在为数据红动作业和有条件的数据恢复引入受控可变性。该机制允许在生效不可变性之前的一段宽限期内进行错误修正。通过基于Hyperledger Fabric的供应链应用WineTracker进行了验证，EvoChain使某些用户能够在不影响区块链安全性和保持数据一致性的情况下撤销不必要的操作。性能评估显示，这种方法带来了功能性优势的同时，仅产生了轻微的额外开销。 <div>
arXiv:2411.16976v1 Announce Type: new 
Abstract: Blockchain technology supports decentralized, consensus-driven data storage and processing, ensuring integrity and auditability. It is increasingly adopted for use cases with multiple stakeholders with shared ownership scenarios like digital identity and supply chain management. However, real-world deployments face challenges with mistakes and intrusions. This article presents EvoChain, a chaincode framework extension introducing controlled mutability for data redaction and recovery under time-limited or specific conditions. This mechanism allows corrections during a grace period before immutability takes effect. We validated our approach using WineTracker, a Hyperledger Fabric-based supply chain application. It enables some users to cancel unwanted operations while preserving the blockchain security and maintaining data consistency. Performance evaluations showed minimal overhead with functional benefits.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Storage And Self-Sovereign Identity For Document-Based Claims</title>
<link>https://arxiv.org/abs/2411.16987</link>
<guid>https://arxiv.org/abs/2411.16987</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化身份系统、用户隐私、数字文档验证、SoverClaim、Hyperledger Indy、Storj、去中心化、自主权身份、文档存储、透明审计日志

<br /><br />总结:
本文介绍了SoverClaim，这是一个基于去中心化理念设计的身份管理和数字文档验证原型应用。它旨在解决中心化身份系统可能带来的用户隐私问题和对在线活动追踪或数据泄露的风险。SoverClaim利用了Hyperledger Indy区块链技术来发行和展示具有透明审计日志的自主权数字身份，并结合Storj的去中心化点对点服务实现安全、去中心化的文档存储及后续删除功能。该原型实现了将自主权身份与基于文档的申明无缝整合，并能在不到750毫秒的时间内完成响应，适合及时的人机交互场景。 <div>
arXiv:2411.16987v1 Announce Type: new 
Abstract: Users increasingly rely on identity providers for accessing online services and resources. However, centralized identity systems often compromise user privacy due to online activity tracking or data breaches. At the same time, many online services require digital copies of physical documents for validation in claims processes, such as providing proof of residence for opening a bank account or verifying medical images for health insurance claims. With centralized solutions, privacy depends entirely on the trusted party, but there are emerging decentralized approaches that offer greater transparency.
  This article introduces SoverClaim, a decentralized application prototype that empowers users to control their identity and also allows them to present digital documents with privacy. SoverClaim leverages Hyperledger Indy, a blockchain for issuing and presenting self-sovereign digital identities with transparent audit logs, and Storj, a decentralized peer-to-peer service, for secure and decentralized document storage and subsequent deletion. The prototype demonstrates the seamless integration of self-sovereign identities and document-based claims, achieving response times of under 750 ms, making it suitable for timely human interactions.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing Vulnerability in Smart Contracts: The Role of Code Complexity Metrics in Security Analysis</title>
<link>https://arxiv.org/abs/2411.17343</link>
<guid>https://arxiv.org/abs/2411.17343</guid>
<content:encoded><![CDATA[
<div> 关键词: code complexity metrics, vulnerable code, smart contracts, Solidity, vulnerability assessment

总结:<br />
本文研究了代码复杂性指标在识别Solidity智能合约漏洞中的作用。文章强调了代码复杂性度量作为安全性评估补充特征的重要性，并探讨了各项指标的关联性、与漏洞的相关性以及区分脆弱代码和中立代码的能力。通过对21项复杂性指标分析，发现某些指标之间存在高相关性和冗余性，但单个指标与漏洞之间的相关性较弱。尽管如此，所有指标都能有效地区分脆弱代码和中立代码，大多数复杂性指标在脆弱代码中的值要高于中立代码，仅有三个例外。 <div>
arXiv:2411.17343v1 Announce Type: new 
Abstract: Codes with specific characteristics are more exposed to security vulnerabilities. Studies have revealed that codes that do not adhere to best practices are more challenging to verify and maintain, increasing the likelihood of unnoticed or unintentionally introduced vulnerabilities. Given the crucial role of smart contracts in blockchain systems, ensuring their security and conducting thorough vulnerability analysis is critical. This study investigates the use of code complexity metrics as indicators of vulnerable code in Solidity smart contracts. We highlight the significance of complexity metrics as valuable complementary features for vulnerability assessment and provide insights into the individual power of each metric. By analyzing 21 complexity metrics, we explored their interrelation, association with vulnerability, discriminative power, and mean values in vulnerable versus neutral codes. The results revealed some high correlations and potential redundancies among certain metrics, but weak correlations between each independent metric and vulnerability. Nevertheless, we found that all metrics can effectively discriminate between vulnerable and neutral codes, and most complexity metrics, except for three, exhibited higher values in vulnerable codes.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Decentralized AI (DeAI)</title>
<link>https://arxiv.org/abs/2411.17461</link>
<guid>https://arxiv.org/abs/2411.17461</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能(AI)，集中化，区块链，去中心化AI(DeAI)，系统化知识(SoK)

总结:
<br />
本文探讨了人工智能集中化所带来的挑战，如单点故障、内在偏见、数据隐私和可扩展性问题，特别是在封闭源码大型语言模型中的问题。为解决这些问题，区块链为基础的去中心化AI（DeAI）被提出作为一种有前景的解决方案。该研究进行了关于区块链基础DeAI解决方案的系统化知识(SoK)梳理，提出了基于模型生命周期对现有DeAI协议进行分类的taxonomy。通过这个分类体系，作者清晰地概述了DeAI协议的现状并分析了其异同点。文章进一步分析了区块链在DeAI中的作用，阐述了区块链特性如何增强AI过程的安全性、透明度和可信度，并确保公平激励AI数据和模型贡献者。同时，文中还指出了开发DeAI协议的关键洞察和研究空白，强调了几条未来研究的重要方向。 <div>
arXiv:2411.17461v1 Announce Type: new 
Abstract: The centralization of Artificial Intelligence (AI) poses significant challenges, including single points of failure, inherent biases, data privacy concerns, and scalability issues. These problems are especially prevalent in closed-source large language models (LLMs), where user data is collected and used without transparency. To mitigate these issues, blockchain-based decentralized AI (DeAI) has emerged as a promising solution. DeAI combines the strengths of both blockchain and AI technologies to enhance the transparency, security, decentralization, and trustworthiness of AI systems. However, a comprehensive understanding of state-of-the-art DeAI development, particularly for active industry solutions, is still lacking. In this work, we present a Systematization of Knowledge (SoK) for blockchain-based DeAI solutions. We propose a taxonomy to classify existing DeAI protocols based on the model lifecycle. Based on this taxonomy, we provide a structured way to clarify the landscape of DeAI protocols and identify their similarities and differences. We analyze the functionalities of blockchain in DeAI, investigating how blockchain features contribute to enhancing the security, transparency, and trustworthiness of AI processes, while also ensuring fair incentives for AI data and model contributors. In addition, we identify key insights and research gaps in developing DeAI protocols, highlighting several critical avenues for future research.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Metaverse Innovation Canvas: A Tool for Extended Reality Product/Service Development</title>
<link>https://arxiv.org/abs/2411.17541</link>
<guid>https://arxiv.org/abs/2411.17541</guid>
<content:encoded><![CDATA[
<div> 关键词：augmented reality (AR), virtual reality (VR), metaverse, startup failure, Metaverse Innovation Canvas (MIC)

<br /><br />总结:
本文针对虚拟现实(VR)和增强现实(AR)初创企业在新兴元宇宙领域中的失败原因进行了深入研究。通过分析2016年至2022年间29家失败的AR/VR初创企业案例，确定了关键问题，包括缺乏可扩展性、用户体验不佳、价值主张不明确以及未能解决特定用户问题等。基于这些发现，文章提出了适用于XR产品和服务的创新框架——Metaverse Innovation Canvas (MIC)。该画布引导创业者定义用户问题、阐述独特的XR价值主张、评估如运动交互负载这样的可用性因素、考虑社交/虚拟经济机会以及规划长期可扩展性。与通用模型不同，MIC专门的模块促使从一开始就关注到XR的关键因素。通过对五家失败创业公司的案例进行专家测试，结果显示该工具能有效提前揭示被忽视的可用性问题和技术限制，从而提高未来元宇宙初创企业的可行性。 <div>
arXiv:2411.17541v1 Announce Type: new 
Abstract: This study investigated the factors contributing to the failure of augmented reality (AR) and virtual reality (VR) startups in the emerging metaverse landscape. Through an in-depth analysis of 29 failed AR/VR startups from 2016 to 2022, key pitfalls were identified, such as a lack of scalability, poor usability, unclear value propositions, and the failure to address specific user problems. Grounded in these findings, we developed the Metaverse Innovation Canvas (MIC) a tailored business ideation framework for XR products and services. The canvas guides founders to define user problems, articulate unique XR value propositions, evaluate usability factors such as the motion-based interaction load, consider social/virtual economy opportunities, and plan for long term scalability. Unlike generalized models, specialized blocks prompt the consideration of critical XR factors from the outset. The canvas was evaluated through expert testing with startup consultants on five failed venture cases. The results highlighted the tool's effectiveness in surfacing overlooked usability issues and technology constraints upfront, enhancing the viability of future metaverse startups.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinML-Chain: A Blockchain-Integrated Dataset for Enhanced Financial Machine Learning</title>
<link>https://arxiv.org/abs/2411.16277</link>
<guid>https://arxiv.org/abs/2411.16277</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、金融市场、区块链技术、交易费机制、经济机制设计

<br /><br />总结:
本文探讨了机器学习在金融市场中的应用及其面临的挑战，并指出区块链技术能够解决其中的一些问题。作者提出了一种框架，该框架将高频链上数据与低频链下数据进行整合，用于研究经济机制设计中的新型问题，特别是以交易费机制为例进行了深入分析。通过线性回归、深度神经网络、XGBoost和LSTM等四种机器学习方法，展示了该框架构建的数据集能推动金融研究并增进对区块链驱动系统的理解。此外，作者开源了一个由该框架生成的样例数据集和处理流程代码，为金融机器学习提供了一个基准，并促进了研究工作的可重复性、透明度和协作。这一举措旨在支持研究者在此基础上进一步拓展工作，发展创新性的金融机器学习模型，从而推动机器学习、区块链与经济学之间的交叉领域研究进步。 <div>
arXiv:2411.16277v1 Announce Type: cross 
Abstract: Machine learning is critical for innovation and efficiency in financial markets, offering predictive models and data-driven decision-making. However, challenges such as missing data, lack of transparency, untimely updates, insecurity, and incompatible data sources limit its effectiveness. Blockchain technology, with its transparency, immutability, and real-time updates, addresses these challenges. We present a framework for integrating high-frequency on-chain data with low-frequency off-chain data, providing a benchmark for addressing novel research questions in economic mechanism design. This framework generates modular, extensible datasets for analyzing economic mechanisms such as the Transaction Fee Mechanism, enabling multi-modal insights and fairness-driven evaluations. Using four machine learning techniques, including linear regression, deep neural networks, XGBoost, and LSTM models, we demonstrate the framework's ability to produce datasets that advance financial research and improve understanding of blockchain-driven systems. Our contributions include: (1) proposing a research scenario for the Transaction Fee Mechanism and demonstrating how the framework addresses previously unexplored questions in economic mechanism design; (2) providing a benchmark for financial machine learning by open-sourcing a sample dataset generated by the framework and the code for the pipeline, enabling continuous dataset expansion; and (3) promoting reproducibility, transparency, and collaboration by fully open-sourcing the framework and its outputs. This initiative supports researchers in extending our work and developing innovative financial machine-learning models, fostering advancements at the intersection of machine learning, blockchain, and economics.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Embedded Blockchains: A Synthesis of Blockchains, Spread Spectrum Watermarking, Perceptual Hashing &amp; Digital Signatures</title>
<link>https://arxiv.org/abs/2009.00951</link>
<guid>https://arxiv.org/abs/2009.00951</guid>
<content:encoded><![CDATA[
<div> 关键词：音频视频伪造检测、区块链、加密扩频水印、感知哈希、数字签名

总结:
本文提出了一种用于检测操纵音频和视频的方案。该方案综合运用了区块链、加密扩频水印、感知哈希以及数字签名技术，称为嵌入式区块链。通过这一方案，利用区块链的数据结构——加密链接列表，进行绝对比对；使用感知哈希实现灵活比对；利用数字签名证明所有权；并借助加密扩频水印将区块链嵌入媒体背景噪声中。每个媒体记录都有其独特的区块链，其中每个区块存储描述媒体片段的信息。验证媒体完整性的问题被重新表述为逐块遍历区块链并与媒体分段进行对比的过程。如果链路断裂，则通过计算与提取到的感知哈希的差异来估计媒介操纵的程度。 <div>
arXiv:2009.00951v5 Announce Type: replace 
Abstract: In this paper we introduce a scheme for detecting manipulated audio and video. The scheme is a synthesis of blockchains, encrypted spread spectrum watermarks, perceptual hashing and digital signatures, which we call an Embedded Blockchain. Within this scheme, we use the blockchain for its data structure of a cryptographically linked list, cryptographic hashing for absolute comparisons, perceptual hashing for flexible comparisons, digital signatures for proof of ownership, and encrypted spread spectrum watermarking to embed the blockchain into the background noise of the media. So each media recording has its own unique blockchain, with each block holding information describing the media segment. The problem of verifying the integrity of the media is recast to traversing the blockchain, block-by-block, and segment-by-segment of the media. If any chain is broken, the difference in the computed and extracted perceptual hash is used to estimate the level of manipulation.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>POWQMIX: Weighted Value Factorization with Potentially Optimal Joint Actions Recognition for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.08036</link>
<guid>https://arxiv.org/abs/2405.08036</guid>
<content:encoded><![CDATA[
<div> 关键词：价值函数分解、多智能体强化学习、QMIX、最优联合动作加权、POWQMIX

总结:
本文提出了一种针对合作多智能体强化学习的价值函数分解新方法——潜在最优联合动作加权QMIX（POWQMIX），旨在解决QMIX及其变体因强加单调性约束而导致的表示能力受限问题。在训练过程中，POWQMIX算法识别并赋予潜在最优联合动作更高的损失权重，理论上证明了该加权训练方法可以保证恢复得到最优策略。实验结果显示，POWQMIX在矩阵游戏、增强难度的猎物捕食者以及StarCraft II多智能体挑战等环境中，相比于当前最先进的基于值函数的多智能体强化学习方法表现更优。<br /><br /> <div>
arXiv:2405.08036v4 Announce Type: replace 
Abstract: Value function factorization methods are commonly used in cooperative multi-agent reinforcement learning, with QMIX receiving significant attention. Many QMIX-based methods introduce monotonicity constraints between the joint action value and individual action values to achieve decentralized execution. However, such constraints limit the representation capacity of value factorization, restricting the joint action values it can represent and hindering the learning of the optimal policy. To address this challenge, we propose the Potentially Optimal Joint Actions Weighted QMIX (POWQMIX) algorithm, which recognizes the potentially optimal joint actions and assigns higher weights to the corresponding losses of these joint actions during training. We theoretically prove that with such a weighted training approach the optimal policy is guaranteed to be recovered. Experiments in matrix games, difficulty-enhanced predator-prey, and StarCraft II Multi-Agent Challenge environments demonstrate that our algorithm outperforms the state-of-the-art value-based multi-agent reinforcement learning methods.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry</title>
<link>https://arxiv.org/abs/2411.14593</link>
<guid>https://arxiv.org/abs/2411.14593</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、Level 5、高速公路入口、深度强化学习、多智能体游戏理论

总结:<br />
本文研究了实现全自主驾驶的关键技术之一——完全自动化的高速公路入口匝道控制问题。该研究采用基于深度强化学习（DRL）的多智能体（MA）游戏理论方法，使车辆能安全地在并入高速交通流过程中控制纵向位置。相较于以往仅针对两辆车的研究，本文扩展到更多车辆的场景，系统性地增加了道路场景中的交通和目标车辆数量。文章指出，在非协调的去中心化环境中，理论上无法找到完全避免碰撞的控制器，但通过所提出的方法学习得到的控制器在实际操作中接近理想的最优控制器表现。 <div>
arXiv:2411.14593v1 Announce Type: new 
Abstract: Vehicles today can drive themselves on highways and driverless robotaxis operate in major cities, with more sophisticated levels of autonomous driving expected to be available and become more common in the future. Yet, technically speaking, so-called "Level 5" (L5) operation, corresponding to full autonomy, has not been achieved. For that to happen, functions such as fully autonomous highway ramp entry must be available, and provide provably safe, and reliably robust behavior to enable full autonomy. We present a systematic study of a highway ramp function that controls the vehicles forward-moving actions to minimize collisions with the stream of highway traffic into which a merging (ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to this problem and study the use of controllers based on deep reinforcement learning (DRL). The virtual environment of the MA DRL uses self-play with simulated data where merging vehicles safely learn to control longitudinal position during a taper-type merge. The work presented in this paper extends existing work by studying the interaction of more than two vehicles (agents) and does so by systematically expanding the road scene with additional traffic and ego vehicles. While previous work on the two-vehicle setting established that collision-free controllers are theoretically impossible in fully decentralized, non-coordinated environments, we empirically show that controllers learned using our approach are nearly ideal when measured against idealized optimal controllers.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Initial Evidence of Elevated Reconnaissance Attacks Against Nodes in P2P Overlay Networks</title>
<link>https://arxiv.org/abs/2411.14623</link>
<guid>https://arxiv.org/abs/2411.14623</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、P2P网络、攻击、蜜罐、安全策略

总结:
我们提出假设认为，点对点（P2P）重叠网络节点由于其可见性、持续在线时间和资源潜力可能对攻击者具有吸引力。为验证这一假设，我们在全球分布式位置与实际以太坊节点并行部署了一系列蜜罐，研究针对以太坊P2P网络节点的活跃侦察攻击状况。结果发现，以太坊节点不仅遭受更多攻击，而且遭遇了特定类型、针对特定端口和服务的攻击。此外，通过对其他可达对等节点进行端口扫描，我们发现对我们节点的威胁评估适用于更广泛的P2P网络。这些发现为我们提供了改进P2P网络层安全性的潜在缓解策略的见解。 <div>
arXiv:2411.14623v1 Announce Type: new 
Abstract: We hypothesize that peer-to-peer (P2P) overlay network nodes can be attractive to attackers due to their visibility, sustained uptime, and resource potential. Towards validating this hypothesis, we investigate the state of active reconnaissance attacks on Ethereum P2P network nodes by deploying a series of honeypots alongside actual Ethereum nodes across globally distributed vantage points. We find that Ethereum nodes experience not only increased attacks, but also specific types of attacks targeting particular ports and services. Furthermore, we find evidence that the threat assessment on our nodes is applicable to the wider P2P network by having performed port scans on other reachable peers. Our findings provide insights into potential mitigation strategies to improve the security of the P2P networking layer.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OCD-FL: A Novel Communication-Efficient Peer Selection-based Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2403.04037</link>
<guid>https://arxiv.org/abs/2403.04037</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘智能、物联网、联邦学习、去中心化联邦学习、机会性通信

总结:
本文关注的是在边缘智能和不断发展的物联网背景下，联邦学习（尤其是去中心化联邦学习）所面临的挑战与改进。针对去中心化联邦学习中的通信成本和数据异质性问题，文章提出了一种名为“机会性通信效率去中心化联邦学习”（OCD-FL）的新方案。该方案通过系统性的FL节点选择策略，旨在在减少能源消耗的同时实现最大的联邦学习知识增益。实验结果显示，OCD-FL能够在保持与完全协作式联邦学习相当或更好的性能水平的同时，将能耗降低至少30%，最高可达80%。<br /><br /> <div>
arXiv:2403.04037v2 Announce Type: replace 
Abstract: The conjunction of edge intelligence and the ever-growing Internet-of-Things (IoT) network heralds a new era of collaborative machine learning, with federated learning (FL) emerging as the most prominent paradigm. With the growing interest in these learning schemes, researchers started addressing some of their most fundamental limitations. Indeed, conventional FL with a central aggregator presents a single point of failure and a network bottleneck. To bypass this issue, decentralized FL where nodes collaborate in a peer-to-peer network has been proposed. Despite the latter's efficiency, communication costs and data heterogeneity remain key challenges in decentralized FL. In this context, we propose a novel scheme, called opportunistic communication-efficient decentralized federated learning, a.k.a., OCD-FL, consisting of a systematic FL peer selection for collaboration, aiming to achieve maximum FL knowledge gain while reducing energy consumption. Experimental results demonstrate the capability of OCD-FL to achieve similar or better performances than the fully collaborative FL, while significantly reducing consumed energy by at least 30% and up to 80%.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Two-agent Motion Planning Strategies from Generalized Nash Equilibrium for Model Predictive Control</title>
<link>https://arxiv.org/abs/2411.13983</link>
<guid>https://arxiv.org/abs/2411.13983</guid>
<content:encoded><![CDATA[
<div> 关键词：Implicit Game-Theoretic MPC (IGT-MPC)，多智能体运动规划，模型预测控制(MPC)，动态游戏，神经网络

总结:
本文提出了一个名为隐式博弈论模型预测控制(IGT-MPC)的新型分散式算法，该算法应用于双智能体运动规划问题。IGT-MPC利用学习得到的价值函数来预测游戏理论中的交互结果，并将其作为MPC框架中的终端成本到目标函数，使智能体能够隐含地考虑与其他智能体的交互并最大化其奖励。该方法适用于竞争性和合作性的多智能体运动规划问题，将这类问题形式化为受约束的动态游戏。通过随机采样初始条件并求解广义纳什均衡(GNE)生成GNE解的数据集，从而计算每个游戏理论交互的奖励结果。这些数据被用来训练一个简单的神经网络以预测奖励结果，该网络进而被用作MPC方案中的终端成本到目标函数。实验展示了IGT-MPC在两车对头竞赛和无信号交叉口导航等场景中产生的竞争性和协调性行为。IGT-MPC提供了一种将机器学习与博弈论推理整合进基于模型的分散式多智能体运动规划的新方法。 <div>
arXiv:2411.13983v1 Announce Type: new 
Abstract: We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized algorithm for two-agent motion planning that uses a learned value function that predicts the game-theoretic interaction outcomes as the terminal cost-to-go function in a model predictive control (MPC) framework, guiding agents to implicitly account for interactions with other agents and maximize their reward. This approach applies to competitive and cooperative multi-agent motion planning problems which we formulate as constrained dynamic games. Given a constrained dynamic game, we randomly sample initial conditions and solve for the generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions, computing the reward outcome of each game-theoretic interaction from the GNE. The data is used to train a simple neural network to predict the reward outcome, which we use as the terminal cost-to-go function in an MPC scheme. We showcase emerging competitive and coordinated behaviors using IGT-MPC in scenarios such as two-vehicle head-to-head racing and un-signalized intersection navigation. IGT-MPC offers a novel method integrating machine learning and game-theoretic reasoning into model-based decentralized multi-agent motion planning.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-Layer Blockchain Simulator and Performance Evaluation of Social Internet of Vehicles with Multi-Connectivity Management</title>
<link>https://arxiv.org/abs/2411.14000</link>
<guid>https://arxiv.org/abs/2411.14000</guid>
<content:encoded><![CDATA[
<div> 关键词：V2X通信、区块链技术、分布式、多层架构、资源管理<br /><br />总结:<br />
本文提出了将去中心化的区块链技术与车辆到万物（V2X）通信创新融合的一种多层架构方案，该架构结合了城市交通模拟器SUMO和区块链模拟器BlockSim。随着社交车联网（SIoV）的发展，为保证无缝通信，有效的资源管理变得至关重要。文中还提出了一种名为“增强型MAX-SINR”的多连接性管理参考方法，旨在推进针对区块链特定方法的研究，并考虑重传成功率。通过评估区块链在城市、郊区和农村等不同环境中的性能，文章证明了提高与区块链相关的重传消息的成功率能显著提升区块链交易性能，为构建智能SIoV系统奠定了基础。 <div>
arXiv:2411.14000v1 Announce Type: new 
Abstract: The evolution of vehicle-to-everything (V2X) communication brings significant challenges, such as data integrity and vulnerabilities stemming from centralized management. This paper presents an innovative integration of decentralized blockchain technology with V2X communication through a multi-layered architecture that combines the Simulation of Urban Mobility (SUMO) traffic simulator and the BlockSim blockchain simulator. In addition, as the Social Internet of Vehicles (SIoV) emerges, efficient resource management becomes indispensable for ensuring seamless communication. We also propose a reference multi-connectivity management method named Enhanced MAX-SINR, designed to advance research in blockchain-specific approaches, taking into account retransmission successfull rates. We evaluate blockchain performance in diverse environments such as urban, suburban, and rural areas, demonstrating that enhancing the success rate of retransmitted blockchain-related messages significantly boosts blockchain transaction performance and provides a foundation for developing intelligent SIoV systems.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Adaptive Asynchronous Federated Learning for Human Activity Recognition</title>
<link>https://arxiv.org/abs/2411.14070</link>
<guid>https://arxiv.org/abs/2411.14070</guid>
<content:encoded><![CDATA[
<div> 关键词：多标签分类、极度异构数据、分布式机器学习、联邦学习（FL）、人类活动识别（HAR）

总结:
<br />
本文针对极度异构数据环境下的多标签分类问题以及在物联网场景中应用联邦学习进行了研究。文章聚焦于将人类活动识别（HAR）任务从集中式学习（CL）迁移到FL的挑战，由于HAR数据和设备的多样性导致标签和特征分布的显著偏差。为解决这一问题，文章提出了从集中式到FL迁移的具体解决方案和工具，并强调了需要做出的关键设计决策。利用开源的HAR数据集，实验评估了数据增强、缩放、优化器选择、学习率和批大小等因素对ML模型性能的影响，发现SGD-m优化器、全局特征缩放及在存在异构HAR数据时持续的特征偏斜等问题的重要性。最后，文章提供了Flower框架的一个开源扩展，支持异步FL。 <div>
arXiv:2411.14070v1 Announce Type: new 
Abstract: In this work, we tackle the problem of performing multi-label classification in the case of extremely heterogeneous data and with decentralized Machine Learning. Solving this issue is very important in IoT scenarios, where data coming from various sources, collected by heterogeneous devices, serve the learning of a distributed ML model through Federated Learning (FL). Specifically, we focus on the combination of FL applied to Human Activity Recognition HAR), where the task is to detect which kind of movements or actions individuals perform. In this case, transitioning from centralized learning (CL) to federated learning is non-trivial as HAR displays heterogeneity in action and devices, leading to significant skews in label and feature distributions. We address this scenario by presenting concrete solutions and tools for transitioning from centralized to FL for non-IID scenarios, outlining the main design decisions that need to be taken. Leveraging an open-sourced HAR dataset, we experimentally evaluate the effects that data augmentation, scaling, optimizer, learning rate, and batch size choices have on the performance of resulting machine learning models. Some of our main findings include using SGD-m as an optimizer, global feature scaling across clients, and persistent feature skew in the presence of heterogeneous HAR data. Finally, we provide an open-source extension of the Flower framework that enables asynchronous FL.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>On PI-control in Capacity-Limited Networks</title>
<link>https://arxiv.org/abs/2411.14077</link>
<guid>https://arxiv.org/abs/2411.14077</guid>
<content:encoded><![CDATA[
<div> 关键词：控制、多智能体系统、非线性、抗饱和控制、分布式策略

总结:<br />
本文研究了一类多动态稳定智能体共享非线性、有界控制互联系统的控制问题。当扰动过大，无法通过可用控制动作完全消除，使得无法将所有智能体稳定在期望状态。针对这一非线性环境，文章分析了两种配备抗饱和控制的比例积分控制策略。首先证明了一个全分布式的控制策略能全局渐近地稳定一个唯一的平衡点，且该平衡点使跟踪误差的加权和达到最小。其次，考虑了在此基础上引入 rank-1 协调机制的轻量级改进策略，该策略下的任何平衡点都将确保任一智能体的最大跟踪误差最小化。这些结果的重要特点是它们对智能体间的互联系统假设非常少。最后，文中展示了所考虑模型在区域供暖场景的应用，并通过仿真验证了两种控制器的效果。 <div>
arXiv:2411.14077v1 Announce Type: new 
Abstract: This paper concerns control of a class of systems where multiple dynamically stable agents share a nonlinear and bounded control-interconnection. The agents are subject to a disturbance which is too large to reject with the available control action, making it impossible to stabilize all agents in their desired states. In this nonlinear setting, we consider two different anti-windup equipped proportional-integral control strategies and analyze their properties. We show that a fully decentralized strategy will globally, asymptotically stabilize a unique equilibrium. This equilibrium also minimizes a weighted sum of the tracking errors. We also consider a light addition to the fully decentralized strategy, where rank-1 coordination between the agents is introduced via the anti-windup action. We show that any equilibrium to this closed-loop system minimizes the maximum tracking error for any agent. A remarkable property of these results is that they rely on extremely few assumptions on the interconnection between the agents. Finally we illustrate how the considered model can be applied in a district heating setting, and demonstrate the two considered controllers in a simulation.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-terminal Strong Coordination subject to Secrecy Constraints</title>
<link>https://arxiv.org/abs/2411.14123</link>
<guid>https://arxiv.org/abs/2411.14123</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式网络系统、安全多终端强协调、多址访问窃听信道、编码策略、信息泄露防护

总结:<br />
本文研究了在分布式网络系统中，利用多址访问窃听信道实现安全多终端强协调的问题。要求两个发送方观测到相关源的独立同分布副本并通过该信道进行编码输入，合法接收方需根据接收到的通道输出及与源相关的侧信息生成与源近似独立同分布的输出变量。同时确保外部窃听者通过观察其自身的MAC-WT输出无法获取关于源和模拟输出序列的有效信息。文章提出了结合协调编码和窃听编码的可达成率区域以及外界边界，并展示了当源条件独立于解码器侧信息且合法通道由确定性链接组成时，内界与外界相匹配，完全刻画了此特殊情形下的问题。此外，还分析了一种具有可能的编码器协作情况，其中一个编码器可以非因果地从其他编码器的输入中获取信息，并提出了相应的可达成率区域。文章最后对具有和不具有编码器间 cribbing 的示例进行了具体的率区域计算，证明了cribbing能严格改进可达率区域。 <div>
arXiv:2411.14123v1 Announce Type: new 
Abstract: A fundamental problem in decentralized networked systems is to coordinate actions of different agents so that they reach a state of agreement. In such applications, it is additionally desirable that the actions at various nodes may not be anticipated by malicious eavesdroppers. Motivated by this, we investigate the problem of secure multi-terminal strong coordination aided by a multiple-access wiretap channel. In this setup, independent and identically distributed copies of correlated sources are observed by two transmitters who encode the channel inputs to the MAC-WT. The legitimate receiver observing the channel output and side information correlated with the sources must produce approximately i.i.d. copies of an output variable jointly distributed with the sources. Furthermore, we demand that an external eavesdropper learns essentially nothin g about the sources and the simulated output sequence by observing its own MAC-WT output. This setting is aided by the presence of independent pairwise shared randomness between each encoder and the legitimate decoder, that is unavailable to the eavesdropper. We derive an achievable rate region based on a combination of coordination coding and wiretap coding, along with an outer bound. The inner bound is shown to be tight and a complete characterization is derived for the special case when the sources are conditionally independent given the decoder side information and the legitimate channel is composed of deterministic links. Further, we also analyze a more general scenario with possible encoder cooperation, where one of the encoders can non-causally crib from the other encoders input, for which an achievable rate region is proposed. We then explicitly compute the rate regions for an example both with and without cribbing between the encoders, and demonstrate that cribbing strictly improves upon the achievable rate region.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pulsar Consensus</title>
<link>https://arxiv.org/abs/2411.14245</link>
<guid>https://arxiv.org/abs/2411.14245</guid>
<content:encoded><![CDATA[
<div> 关键词：Pulsar、proof of stake、sidechain、proof of work、chain selection rule

<br /><br />总结：
本文介绍了Pulsar权益证明共识协议，并讨论了相关的设计决策和考量。Pulsar协议旨在促进工作量证明区块链创建权益证明侧链。文章提出了一个新颖的可组合密度基础的链选择规则，该规则可以看作权益证明协议中某些标准最长链规则的超集。文中将Pulsar协议与其他现有的权益证明协议进行了比较，明确了其相较于现有设计的优势，并定义了本工作的局限性。目前，Pulsar协议已实现在Mintlayer权益证明比特币侧链中的实施。 <div>
arXiv:2411.14245v1 Announce Type: new 
Abstract: In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Iteration-Free Cooperative Distributed MPC through Multiparametric Programming</title>
<link>https://arxiv.org/abs/2411.14319</link>
<guid>https://arxiv.org/abs/2411.14319</guid>
<content:encoded><![CDATA[
<div> 关键词：Cooperative Distributed Model Predictive Control (DiMPC)，communication reduction，computational costs，multiparametric (mp) programming，iteration-free算法

<br /><br />总结：

本文提出了基于多参数编程的新型无迭代解算器算法，显著降低了Cooperative Distributed Model Predictive Control (DiMPC)架构中的信息交换量和计算成本。通过将迭代过程替换为同时求解显式mpDiMPC控制律函数的方法，成功减少了局部控制器间的通信，从而降低了系统延迟，这对于实时控制应用至关重要。通过涉及由输入相互连接并通过合作型全局成本函数耦合的线性子系统的全面数值模拟，验证了所提无迭代mpDiMPC算法的有效性。 <div>
arXiv:2411.14319v1 Announce Type: new 
Abstract: Cooperative Distributed Model Predictive Control (DiMPC) architecture employs local MPC controllers to control different subsystems, exchanging information with each other through an iterative procedure to enhance overall control performance compared to the decentralized architecture. However, this method can result in high communication between the controllers and computational costs. In this work, the amount of information exchanged and the computational costs of DiMPC are reduced significantly by developing novel iteration-free solution algorithms based on multiparametric (mp) programming. These algorithms replace the iterative procedure with simultaneous solutions of explicit mpDiMPC control law functions. The reduced communication among local controllers decreases system latency, which is crucial for real-time control applications. The effectiveness of the proposed iteration-free mpDiMPC algorithms is demonstrated through comprehensive numerical simulations involving groups of coupled linear subsystems, which are interconnected through their inputs and a cooperative plant-wide cost function.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Deep Learning Approach to Predict the Fall [of Price] of Cryptocurrency Long Before its Actual Fall</title>
<link>https://arxiv.org/abs/2411.13615</link>
<guid>https://arxiv.org/abs/2411.13615</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币市场、风险因素、波动性、机器学习算法、预测模型

<br /><br />总结:
该研究关注于加密货币市场的风险因素（即波动性）预测问题。针对这一市场高波动性和低流动性的特点，研究提出了一种新的预测方法，运用卷积神经网络（CNN）、长短期记忆网络（LSTM）、双向LSTM和门控循环单元（GRU）等多种机器学习算法对加密货币市场的二十项参数进行风险因素预测。研究人员开发了优于已有模型的新预测模型，其表现最优的RMSE值为0.0089，最差为1.3229，显著优于现有模型中最高RMSE值为14.5092、最低为0.02769的表现。通过此模型，投资者能更好地应对比特币、以太坊、狗狗币等复杂且具有挑战性的金融资产交易。 <div>
arXiv:2411.13615v1 Announce Type: cross 
Abstract: In modern times, the cryptocurrency market is one of the world's most rapidly rising financial markets. The cryptocurrency market is regarded to be more volatile and illiquid than traditional markets such as equities, foreign exchange, and commodities. The risk of this market creates an uncertain condition among the investors. The purpose of this research is to predict the magnitude of the risk factor of the cryptocurrency market. Risk factor is also called volatility. Our approach will assist people who invest in the cryptocurrency market by overcoming the problems and difficulties they experience. Our approach starts with calculating the risk factor of the cryptocurrency market from the existing parameters. In twenty elements of the cryptocurrency market, the risk factor has been predicted using different machine learning algorithms such as CNN, LSTM, BiLSTM, and GRU. All of the models have been applied to the calculated risk factor parameter. A new model has been developed to predict better than the existing models. Our proposed model gives the highest RMSE value of 1.3229 and the lowest RMSE value of 0.0089. Following our model, it will be easier for investors to trade in complicated and challenging financial assets like bitcoin, Ethereum, dogecoin, etc. Where the other existing models, the highest RMSE was 14.5092, and the lower was 0.02769. So, the proposed model performs much better than models with proper generalization. Using our approach, it will be easier for investors to trade in complicated and challenging financial assets like Bitcoin, Ethereum, and Dogecoin.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPARKLE: A Unified Single-Loop Primal-Dual Framework for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2411.14166</link>
<guid>https://arxiv.org/abs/2411.14166</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized bilevel optimization, gradient tracking, EXTRA, Exact Diffusion, SPARKLE

总结:
<br />
本文研究了多智能体协作解决具有嵌套优化结构的去中心化双层优化问题。现有的大多数文献主要利用梯度跟踪来缓解数据异质性的影响，而未充分探索如EXTRA或Exact Diffusion等其他知名的异质性校正技术。此外，这些研究通常对上层和下层问题采用相同的去中心化策略，忽视了在不同层次间运用不同机制的优势。针对以上局限性，文章提出了SPARKLE，即一种统一的单循环 primal-dual 算法框架，用于去中心化双层优化，该框架能灵活地将各种异质性校正策略融入算法，并允许上下层问题采取不同的解决方案。作者为SPARKLE及其变种提供了统一的收敛性分析，并与现有去中心化双层算法相比展现出最先进的收敛速率。结果进一步表明，在去中心化双层优化中，EXTRA和Exact Diffusion更为适用，而在双层算法中混合使用多种策略比单纯依赖梯度跟踪更具优势。 <div>
arXiv:2411.14166v1 Announce Type: cross 
Abstract: This paper studies decentralized bilevel optimization, in which multiple agents collaborate to solve problems involving nested optimization structures with neighborhood communications. Most existing literature primarily utilizes gradient tracking to mitigate the influence of data heterogeneity, without exploring other well-known heterogeneity-correction techniques such as EXTRA or Exact Diffusion. Additionally, these studies often employ identical decentralized strategies for both upper- and lower-level problems, neglecting to leverage distinct mechanisms across different levels. To address these limitations, this paper proposes SPARKLE, a unified Single-loop Primal-dual AlgoRithm frameworK for decentraLized bilEvel optimization. SPARKLE offers the flexibility to incorporate various heterogeneitycorrection strategies into the algorithm. Moreover, SPARKLE allows for different strategies to solve upper- and lower-level problems. We present a unified convergence analysis for SPARKLE, applicable to all its variants, with state-of-the-art convergence rates compared to existing decentralized bilevel algorithms. Our results further reveal that EXTRA and Exact Diffusion are more suitable for decentralized bilevel optimization, and using mixed strategies in bilevel algorithms brings more benefits than relying solely on gradient tracking.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Public sentiments on the fourth industrial revolution: An unsolicited public opinion poll from Twitter</title>
<link>https://arxiv.org/abs/2411.14230</link>
<guid>https://arxiv.org/abs/2411.14230</guid>
<content:encoded><![CDATA[
<div> 关键词：第四次工业革命、社交媒体、情绪分析、机器学习、公共感知

<br /><br />总结：
该文章通过分析六个欧洲国家的社交媒体推文和媒体文章数据，探讨公众对第四次工业革命（4IR）的看法。利用情感分析和机器学习技术，研究发现公众对人工智能、机器人和区块链等技术融入社会的态度呈现显著两极分化，从中立立场转向更为明确的支持或反对态度。正面观点主要关联到科技对生活质量与经济机遇的提升，而担忧则集中在隐私、数据安全及伦理问题上。这表明政策制定者需要积极与公众沟通，以缓解恐惧并利用4IR技术的优势。此外，文章还提倡开展数字素养和公共意识项目，以减少错误信息并促进有关未来技术整合的明智公共讨论。这项研究为如何使科技进步与社会价值观和需求相一致提供了见解，强调了形成有效政策过程中知情公众意见的重要性。 <div>
arXiv:2411.14230v1 Announce Type: cross 
Abstract: This article explores public perceptions on the Fourth Industrial Revolution (4IR) through an analysis of social media discourse across six European countries. Using sentiment analysis and machine learning techniques on a dataset of tweets and media articles, we assess how the public reacts to the integration of technologies such as artificial intelligence, robotics, and blockchain into society. The results highlight a significant polarization of opinions, with a shift from neutral to more definitive stances either embracing or resisting technological impacts. Positive sentiments are often associated with technological enhancements in quality of life and economic opportunities, whereas concerns focus on issues of privacy, data security, and ethical implications. This polarization underscores the need for policymakers to engage proactively with the public to address fears and harness the benefits of 4IR technologies. The findings also advocate for digital literacy and public awareness programs to mitigate misinformation and foster an informed public discourse on future technological integration. This study contributes to the ongoing debate on aligning technological advances with societal values and needs, emphasizing the role of informed public opinion in shaping effective policy.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Aware Data Acquisition under Data Similarity in Regression Markets</title>
<link>https://arxiv.org/abs/2312.02611</link>
<guid>https://arxiv.org/abs/2312.02611</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据市场、数据相似性、隐私偏好、局部差分隐私、Stackelberg游戏

总结:
该文探讨了数据市场上数据相似性和隐私偏好的重要影响，并提出了一个基于局部差分隐私的两方数据获取协议。研究中，作者将隐私意识强的数据拥有者与学习者之间的战略互动分析为一个关于询问价格和隐私因子的Stackelberg游戏，模型应用于回归数据分析市场。文章通过数值分析揭示了数据相似性如何影响市场的参与度及交易数据的价值。 <div>
arXiv:2312.02611v2 Announce Type: replace 
Abstract: Data markets facilitate decentralized data exchange for applications such as prediction, learning, or inference. The design of these markets is challenged by varying privacy preferences as well as data similarity among data owners. Related works have often overlooked how data similarity impacts pricing and data value through statistical information leakage. We demonstrate that data similarity and privacy preferences are integral to market design and propose a query-response protocol using local differential privacy for a two-party data acquisition mechanism. In our regression data market model, we analyze strategic interactions between privacy-aware owners and the learner as a Stackelberg game over the asked price and privacy factor. Finally, we numerically evaluate how data similarity affects market participation and traded data value.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Structured stability analysis of networked systems with uncertain links</title>
<link>https://arxiv.org/abs/2403.14931</link>
<guid>https://arxiv.org/abs/2403.14931</guid>
<content:encoded><![CDATA[
<div> 关键词：网络系统、不确定链接动力学、输入-输出方法、稳定性分析、积分二次约束

总结:<br />
该文针对具有不确定链路动态的网络系统，探索了一种基于输入-输出的稳定性分析方法。主要成果是一组积分二次约束条件，当理想链接下系统达到稳定性时，这些条件共同确保了不确定网络系统的鲁棒稳定性。这些条件具备分散性特点，每个仅涉及对应链接的局部代理和不确定性模型参数，因此该主要结果对于无特定网络结构限制的大规模系统研究非常适用。 <div>
arXiv:2403.14931v2 Announce Type: replace 
Abstract: An input-output approach to stability analysis is explored for networked systems with uncertain link dynamics. The main result consists of a collection of integral quadratic constraints, which together imply robust stability of the uncertain networked system, under the assumption that stability is achieved with ideal links. The conditions are decentralized inasmuch as each involves only agent and uncertainty model parameters that are local to a corresponding link. This makes the main result, which imposes no restriction on network structure, suitable for the study of large-scale systems.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TrustMesh: A Blockchain-Enabled Trusted Distributed Computing Framework for Open Heterogeneous IoT Environments</title>
<link>https://arxiv.org/abs/2411.13039</link>
<guid>https://arxiv.org/abs/2411.13039</guid>
<content:encoded><![CDATA[
<div> 关键词: TrustMesh、区块链、物联网(IoT)、分布式计算、拜占庭容错(PBFT)

<br /><br />总结:
本文提出了TrustMesh，一个创新的区块链驱动的框架，旨在解决物联网环境下安全可信的分布式计算问题。TrustMesh采用独特的三层架构，结合了许可型区块链技术和一种新颖的多阶段实用拜占庭容错(PBFT)共识协议。其关键创新在于能在支持非确定性调度算法的同时保持拜占庭容错特性，这是传统区块链系统中难以兼得的。此外，该框架还具备灵活的资源管理方法，可在保证区块链验证安全性的同时实现灵活的调度决策。实验结果显示，在实际的冷链监测场景下，TrustMesh能够在150毫秒内的故障检测延迟下维持拜占庭容错，并在不同计算负载和网络扩展情况下保持一致的框架开销。这些结果证明了TrustMesh在无信任物联网环境中平衡安全、性能和灵活性需求的能力，从而推动了安全分布式计算框架领域的前沿进展。 <div>
arXiv:2411.13039v1 Announce Type: new 
Abstract: The rapid evolution of Internet of Things (IoT) environments has created an urgent need for secure and trustworthy distributed computing systems, particularly when dealing with heterogeneous devices and applications where centralized trust cannot be assumed. This paper proposes TrustMesh, a novel blockchain-enabled framework that addresses these challenges through a unique three-layer architecture combining permissioned blockchain technology with a novel multi-phase Practical Byzantine Fault Tolerance (PBFT) consensus protocol. The key innovation lies in TrustMesh's ability to support non-deterministic scheduling algorithms while maintaining Byzantine fault tolerance - features traditionally considered mutually exclusive in blockchain systems. The framework supports a sophisticated resource management approach that enables flexible scheduling decisions while preserving the security guarantees of blockchain-based verification. Our experimental evaluation using a real-world cold chain monitoring scenario demonstrates that TrustMesh successfully maintains Byzantine fault tolerance with fault detection latencies under 150 milliseconds, while maintaining consistent framework overhead across varying computational workloads even with network scaling. These results establish TrustMesh's effectiveness in balancing security, performance, and flexibility requirements in trustless IoT environments, advancing the state-of-the-art in secure distributed computing frameworks.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Enhanced Framework for Secure Third-Party Vendor Risk Management and Vigilant Security Controls</title>
<link>https://arxiv.org/abs/2411.13447</link>
<guid>https://arxiv.org/abs/2411.13447</guid>
<content:encoded><![CDATA[
<div> 关键词: 第三方供应商风险、区块链技术、安全框架、智能合约、持续监控

总结:
本文提出了一种综合安全框架，用于管理第三方供应商风险，并整合了区块链技术以确保评估和交互过程中的透明度、可追溯性和不可篡改性。该框架利用区块链增强了供应商安全审计的完整性，并通过智能合约减少人为错误，实现实时合规与安全控制监测。重点强调了对数据加密、访问控制机制、多因素认证和零信任架构等关键安全控制的评估。通过区块链实现的持续监控确保了供应商合规流程的不变性和透明度。文中通过iHealth迁移到AWS云的案例研究展示了该框架的实际应用，结果显示显著降低了漏洞并提高了事件响应时间。采用这种区块链赋能的方法，组织可以有效降低供应商风险、简化合规流程并提升整体安全态势。 <div>
arXiv:2411.13447v1 Announce Type: new 
Abstract: In an era of heightened digital interconnectedness, businesses increasingly rely on third-party vendors to enhance their operational capabilities. However, this growing dependency introduces significant security risks, making it crucial to develop a robust framework to mitigate potential vulnerabilities. This paper proposes a comprehensive secure framework for managing third-party vendor risk, integrating blockchain technology to ensure transparency, traceability, and immutability in vendor assessments and interactions. By leveraging blockchain, the framework enhances the integrity of vendor security audits, ensuring that vendor assessments remain up-to-date and tamperproof. This proposed framework leverages smart contracts to reduce human error while ensuring real-time monitoring of compliance and security controls. By evaluating critical security controls-such as data encryption, access control mechanisms, multi-factor authentication, and zero-trust architecture-this approach strengthens an organization's defense against emerging cyber threats. Additionally, continuous monitoring enabled by blockchain ensures the immutability and transparency of vendor compliance processes. In this paper, a case study on iHealth's transition to AWS Cloud demonstrates the practical implementation of the framework, showing a significant reduction in vulnerabilities and marked improvement in incident response times. Through the adoption of this blockchain-enabled approach, organizations can mitigate vendor risks, streamline compliance, and enhance their overall security posture.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinBERT-BiLSTM: A Deep Learning Model for Predicting Volatile Cryptocurrency Market Prices Using Market Sentiment Dynamics</title>
<link>https://arxiv.org/abs/2411.12748</link>
<guid>https://arxiv.org/abs/2411.12748</guid>
<content:encoded><![CDATA[
<div> 关键词: 时间序列预测、金融市场、加密货币、深度学习模型、Bi-LSTM + FinBERT 混合模型

总结:<br />
本文介绍了时间序列预测在金融市场的关键作用，特别是在波动性极高的比特币和以太坊等加密货币市场中的应用。传统方法已难以应对这类市场的极端价格波动，因此研究转向了如LSTM、Bi-LSTM及FinBERT等深度学习模型。鉴于此，文章提出了一种混合模型，将双向长短时记忆网络（Bi-LSTM）与专门用于金融领域的FinBERT结合，旨在提升加密货币价格预测的准确性。这一创新方法融合了高级时间序列模型与情绪分析，为投资者和分析师在不确定性的金融市场中提供更为有价值的决策依据。 <div>
arXiv:2411.12748v1 Announce Type: cross 
Abstract: Time series forecasting is a key tool in financial markets, helping to predict asset prices and guide investment decisions. In highly volatile markets, such as cryptocurrencies like Bitcoin (BTC) and Ethereum (ETH), forecasting becomes more difficult due to extreme price fluctuations driven by market sentiment, technological changes, and regulatory shifts. Traditionally, forecasting relied on statistical methods, but as markets became more complex, deep learning models like LSTM, Bi-LSTM, and the newer FinBERT-LSTM emerged to capture intricate patterns. Building upon recent advancements and addressing the volatility inherent in cryptocurrency markets, we propose a hybrid model that combines Bidirectional Long Short-Term Memory (Bi-LSTM) networks with FinBERT to enhance forecasting accuracy for these assets. This approach fills a key gap in forecasting volatile financial markets by blending advanced time series models with sentiment analysis, offering valuable insights for investors and analysts navigating unpredictable markets.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Supervised Autoencoders with Fractionally Differentiated Features and Triple Barrier Labelling Enhance Predictions on Noisy Data</title>
<link>https://arxiv.org/abs/2411.12753</link>
<guid>https://arxiv.org/abs/2411.12753</guid>
<content:encoded><![CDATA[
<div> 关键词：神经网络、监督自编码器(SAE)、噪声增强、三重障碍标签、风险调整回报

总结:<br />
本文研究了利用神经网络中的监督自编码器（SAE）来提升金融时间序列预测的准确性，旨在改善投资策略的表现。研究期间选取了比特币、莱特币和以太坊作为交易资产，时间段为2016年1月1日至2022年4月30日。结果表明，采用平衡噪声增强与适当瓶颈大小的监督自编码器能显著提高策略的有效性。然而，过多的噪声以及过大的瓶颈尺寸可能会对性能产生负面影响。 <div>
arXiv:2411.12753v1 Announce Type: cross 
Abstract: This paper investigates the enhancement of financial time series forecasting with the use of neural networks through supervised autoencoders (SAE), to improve investment strategy performance. Using the Sharpe and Information Ratios, it specifically examines the impact of noise augmentation and triple barrier labeling on risk-adjusted returns. The study focuses on Bitcoin, Litecoin, and Ethereum as the traded assets from January 1, 2016, to April 30, 2022. Findings indicate that supervised autoencoders, with balanced noise augmentation and bottleneck size, significantly boost strategy effectiveness. However, excessive noise and large bottleneck sizes can impair performance.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy</title>
<link>https://arxiv.org/abs/2411.12756</link>
<guid>https://arxiv.org/abs/2411.12756</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、阿尔茨海默症分类、迁移学习、联邦学习、数据隐私

总结:
<br />
本文提出了一种新的阿尔茨海默症分类方法，该方法结合了先进的深度学习技术和安全的数据处理方法。研究主要利用ResNet、ImageNet和VNet等预训练模型从医学图像数据中提取高层特征，并针对阿尔茨海默症的相关细微模式对这些模型进行微调，以实现对不同数据源的鲁棒性特征提取。此外，为了提高预测性能并保护数据隐私，文中还引入了联邦学习方法。通过采用联邦学习的方式构建模型，无需共享敏感患者数据即可实现分布式训练，同时确保数据的保密性和完整性。为保障在整个训练与分类过程中的患者信息安全，还采用了基于密码学的加密机制。实验结果表明，这种方法不仅提高了阿尔茨海默症分类的准确性，而且还提供了一个用于安全、协作分析医疗健康数据的框架。 <div>
arXiv:2411.12756v1 Announce Type: cross 
Abstract: This research work introduces a novel approach to the classification of Alzheimer's disease by using the advanced deep learning techniques combined with secure data processing methods. This research work primary uses transfer learning models such as ResNet, ImageNet, and VNet to extract high-level features from medical image data. Thereafter, these pre-trained models were fine-tuned for Alzheimer's related subtle patterns such that the model is capable of robust feature extraction over varying data sources. Further, the federated learning approaches were incorporated to tackle a few other challenges related to classification, aimed to provide better prediction performance and protect data privacy. The proposed model was built using federated learning without sharing sensitive patient data. This way, the decentralized model benefits from the large and diversified dataset that it is trained upon while ensuring confidentiality. The cipher-based encryption mechanism is added that allows us to secure the transportation of data and further ensure the privacy and integrity of patient information throughout training and classification. The results of the experiments not only help to improve the accuracy of the classification of Alzheimer's but at the same time provides a framework for secure and collaborative analysis of health care data.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Delegating Data Collection in Decentralized Machine Learning</title>
<link>https://arxiv.org/abs/2309.01837</link>
<guid>https://arxiv.org/abs/2309.01837</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、机器学习、数据收集、合同理论、信息不对称

<br /><br />总结:
本文针对去中心化机器学习生态系统中出现的数据收集委托问题，结合合同理论进行研究。文章探讨了在此场景下两种基本的信息不对称性：模型质量评估的不确定性以及对最优模型性能的不确定。文中设计了实现近似最优效用的简单线性合同，并表明通过这种合同，主体可以应对上述不对称性，达到理想效用的1-1/e比例。为解决关于最优性能的未知问题，文章提出了一种能自适应并高效计算最优合同的凸优化程序。此外，对于多次交互的复杂环境，文中还研究了线性合同并得出了最优效用情况。 <div>
arXiv:2309.01837v3 Announce Type: replace 
Abstract: Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve 1-1/e fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also study linear contracts and derive the optimal utility in the more complex setting of multiple interactions.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction</title>
<link>https://arxiv.org/abs/2411.11894</link>
<guid>https://arxiv.org/abs/2411.11894</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse网络流量预测、扩展现实(XR)服务、测试床、视帧(VF)算法、ResLearn、Transformer、错误学习、资源管理、服务质量(QoS)、用户体验。

<br /><br />总结:
本文提出了一种针对Metaverse网络流量预测的全面解决方案，旨在满足扩展现实(XR)服务中智能资源管理的需求。研究内容包括建立一个先进的测试床，用于收集并公开虚拟现实(VR)、增强现实(AR)和混合现实(MR)的真实世界交通数据。为了提高预测精度，文章提出了一种名为视帧(VF)的新型算法，该算法能准确识别流量中的视频帧并确保隐私合规性。此外，还开发了一种基于Transformer的递进误差学习算法——ResLearn，该算法利用全连接神经网络减少预测错误，特别是在高峰流量时段，相较于先前工作提高了99%的性能。这些贡献为互联网服务提供商(ISPs)提供了实时网络管理的强大工具，以满足Metaverse中的服务质量(QoS)需求并提升用户体验。 <div>
arXiv:2411.11894v1 Announce Type: new 
Abstract: Our work proposes a comprehensive solution for predicting Metaverse network traffic, addressing the growing demand for intelligent resource management in eXtended Reality (XR) services. We first introduce a state-of-the-art testbed capturing a real-world dataset of virtual reality (VR), augmented reality (AR), and mixed reality (MR) traffic, made openly available for further research. To enhance prediction accuracy, we then propose a novel view-frame (VF) algorithm that accurately identifies video frames from traffic while ensuring privacy compliance, and we develop a Transformer-based progressive error-learning algorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn significantly improves time-series predictions by using fully connected neural networks to reduce errors, particularly during peak traffic, outperforming prior work by 99%. Our contributions offer Internet service providers (ISPs) robust tools for real-time network management to satisfy Quality of Service (QoS) and enhance user experience in the Metaverse.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simultaneous Ground Reaction Force and State Estimation via Constrained Moving Horizon Estimation</title>
<link>https://arxiv.org/abs/2411.12047</link>
<guid>https://arxiv.org/abs/2411.12047</guid>
<content:encoded><![CDATA[
<div> 关键词：地面反作用力估计、腿部机器人、状态估计、运动 horizon 估计（MHE）、漂移基座

总结:<br />
本文提出了一种针对腿部机器人的同时地面反作用力和状态估计框架。该框架系统性地解决了传感器噪声问题以及状态与动力学之间的耦合问题。通过单独估计浮动基座姿态，采用分散式的运动 Horizon 估计方法，将机器人动力学、本体感觉传感器、外感觉传感器及确定性的接触互补约束融合在一个凸优化的窗口化问题中。实验表明，该方法能够在频率为 200Hz 和过去时间窗口为 0.04s 的条件下，对包括开源教育平面双足机器人 STRIDE 和四足机器人 Unitree Go1 在内的多种腿部机器人实现准确的地面反作用力和状态估计。 <div>
arXiv:2411.12047v1 Announce Type: new 
Abstract: Accurate ground reaction force (GRF) estimation can significantly improve the adaptability of legged robots in various real-world applications. For instance, with estimated GRF and contact kinematics, the locomotion control and planning assist the robot in overcoming uncertain terrains. The canonical momentum-based methods, formulated as nonlinear observers, do not fully address the noisy measurements and the dependence between floating base states and the generalized momentum dynamics. In this paper, we present a simultaneous ground reaction force and state estimation framework for legged robots, which systematically addresses the sensor noise and the coupling between states and dynamics. With the floating base orientation estimated separately, a decentralized Moving Horizon Estimation (MHE) method is implemented to fuse the robot dynamics, proprioceptive sensors, exteroceptive sensors, and deterministic contact complementarity constraints in a convex windowed optimization. The proposed method is shown to be capable of providing accurate GRF and state estimation on several legged robots, including the open-source educational planar bipedal robot STRIDE and quadrupedal robot Unitree Go1, with a frequency of 200Hz and a past time window of 0.04s.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning</title>
<link>https://arxiv.org/abs/2411.12220</link>
<guid>https://arxiv.org/abs/2411.12220</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、backdoor attacks（后门攻击）、DeTrigger、gradient analysis（梯度分析）、temperature scaling（温度缩放）

<br /><br />总结:

本文提出了一个名为DeTrigger的可扩展且高效的抵御后门攻击的联邦学习框架。DeTrigger利用对抗性攻击方法的洞察力，通过结合梯度分析与温度缩放技术来检测和隔离后门触发器，并精确地进行模型权重剪枝以去除后门激活部分，同时尽量保全正常模型知识。实验表明，DeTrigger相比于传统方法能实现高达251倍的更快检测速度，并能有效缓解高达98.9%的后门攻击，对全局模型准确性的影响极小。因此，DeTrigger被认为是保护联邦学习环境免受复杂后门威胁的一种健壮且可扩展的解决方案。 <div>
arXiv:2411.12220v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across distributed devices while preserving local data privacy, making it ideal for mobile and embedded systems. However, the decentralized nature of FL also opens vulnerabilities to model poisoning attacks, particularly backdoor attacks, where adversaries implant trigger patterns to manipulate model predictions. In this paper, we propose DeTrigger, a scalable and efficient backdoor-robust federated learning framework that leverages insights from adversarial attack methodologies. By employing gradient analysis with temperature scaling, DeTrigger detects and isolates backdoor triggers, allowing for precise model weight pruning of backdoor activations without sacrificing benign model knowledge. Extensive evaluations across four widely used datasets demonstrate that DeTrigger achieves up to 251x faster detection than traditional methods and mitigates backdoor attacks by up to 98.9%, with minimal impact on global model accuracy. Our findings establish DeTrigger as a robust and scalable solution to protect federated learning environments against sophisticated backdoor threats.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hyper-parameter Optimization for Federated Learning with Step-wise Adaptive Mechanism</title>
<link>https://arxiv.org/abs/2411.12244</link>
<guid>https://arxiv.org/abs/2411.12244</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Automated Machine Learning (Auto-ML), Hyper-Parameter Optimization (HPO), Raytune, Optuna

<br /><br />总结:
本文研究了在联邦学习（FL）环境中部署和整合两个轻量级超参数优化工具——Raytune和Optuna的方法。针对FL中大量客户端及服务器间的全局训练轮次带来的调参过程耗时、资源受限的问题，文章提出了一种逐步反馈机制，加速超参数调优过程，并协调Auto-ML工具包与FL服务器之间的协作。同时，结合局部和全局反馈机制缩小搜索空间，加快HPO进程。此外，还引入了一种新的客户端选择技术来缓解Auto-FL中的“拖尾”效应。通过FEMNIST和CIFAR10两个基准数据集对该方法进行了评估。文章最后讨论了成功HPO工具应具备的关键属性以及其与FL流水线的集成机制，同时指出了FL环境分布式和异构性所带来的挑战。 <div>
arXiv:2411.12244v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized learning approach that protects sensitive information by utilizing local model parameters rather than sharing clients' raw datasets. While this privacy-preserving method is widely employed across various applications, it still requires significant development and optimization. Automated Machine Learning (Auto-ML) has been adapted for reducing the need for manual adjustments. Previous studies have explored the integration of AutoML with different FL algorithms to evaluate their effectiveness in enhancing FL settings. However, Automated FL (Auto-FL) faces additional challenges due to the involvement of a large cohort of clients and global training rounds between clients and the server, rendering the tuning process time-consuming and nearly impossible on resource-constrained edge devices (e.g., IoT devices). This paper investigates the deployment and integration of two lightweight Hyper-Parameter Optimization (HPO) tools, Raytune and Optuna, within the context of FL settings. A step-wise feedback mechanism has also been designed to accelerate the hyper-parameter tuning process and coordinate AutoML toolkits with the FL server. To this end, both local and global feedback mechanisms are integrated to limit the search space and expedite the HPO process. Further, a novel client selection technique is introduced to mitigate the straggler effect in Auto-FL. The selected hyper-parameter tuning tools are evaluated using two benchmark datasets, FEMNIST, and CIFAR10. Further, the paper discusses the essential properties of successful HPO tools, the integration mechanism with the FL pipeline, and the challenges posed by the distributed and heterogeneous nature of FL environments.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging NFTs for Spectrum Securitization in 6G Networks</title>
<link>https://arxiv.org/abs/2411.12347</link>
<guid>https://arxiv.org/abs/2411.12347</guid>
<content:encoded><![CDATA[
<div> 关键词：动态频谱共享、激励机制、ERC404标准、非同质化代币、同质化代币

总结:
<br />
本文提出了基于ERC404标准并结合非同质化代币（NFT）和同质化代币（FT）技术的频谱证券化模型，旨在激励原始用户积极分享其频谱资源。通过该模型，在以太坊测试网络上实现动态频谱资源共享的有效促进，进而提高频谱资源利用率。 <div>
arXiv:2411.12347v1 Announce Type: new 
Abstract: Dynamic Spectrum Sharing can enhance spectrum resource utilization by promoting the dynamic distribution of spectrum resources. However, to effectively implement dynamic spectrum resource allocation, certain mechanisms are needed to incentivize primary users to proactively share their spectrum resources. This paper, based on the ERC404 standard and integrating Non-Fungible Token and Fungible Token technologies, proposes a spectrum securitization model to incentivize spectrum resource sharing and implements it on the Ethereum test net.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Centralized RAN to Open RAN: A Survey on the Evolution of Distributed Antenna Systems</title>
<link>https://arxiv.org/abs/2411.12166</link>
<guid>https://arxiv.org/abs/2411.12166</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式天线系统(DAS), 无线接入网(RAN), 云无线接入网(C-RAN), 雾无线接入网(F-RAN), 开放无线接入网(O-RAN)

<br /><br />总结:
本文对分布式天线系统（DAS）进行了全面的调查研究，探讨了从传统分散式RAN向DAS演进的各种架构，包括云无线接入网（C-RAN）、雾无线接入网（F-RAN）、虚拟化无线接入网（V-RAN）、无细胞大规模多输入多输出（CF-mMIMO）以及最新的开放无线接入网（O-RAN）。文章分析了这些架构的优势和局限性，如有限容量的前传链路、上行/下行协作编码策略、跨层优化及DAS性能优化技术。同时，文中还介绍了下一代RAN系统的关键使能技术，如边缘计算、网络功能虚拟化、软件定义网络和网络切片，以及重要的无线接入技术，如毫米波、大规模多输入多输出、设备到设备通信和大规模机器类型通信。最后，文章指出了DAS领域的重大研究挑战并提出了未来可能的研究方向。 <div>
arXiv:2411.12166v1 Announce Type: cross 
Abstract: Next-generation mobile networks require evolved radio access network (RAN) architectures to meet the demands of high capacity, massive connectivity, reduced costs, and energy efficiency, and to realize communication with ultra-low latency and ultra-high reliability. {Meeting such} requirements for both mobile users and vertical industries in the next decade {requires novel solutions. One of the potential solutions that attracted significant research attention in the past 15 years} is to redesign the radio access network (RAN). In this survey, we present a comprehensive survey on distributed antenna system (DAS) architectures that address these challenges and improve network performance. We cover the transition from traditional decentralized RAN to DAS, including cloud radio-access networks (C-RAN), fog radio-access networks (F-RAN), virtualized radio-access networks (V-RAN), cell-free massive multiple-input multiple-output (CF-mMIMO), and {the most recent advances manifested in} open radio-access network (O-RAN). In the process, we discuss the benefits and limitations of these architectures, including the impact of limited-capacity fronthaul links, various cooperative uplink and downlink coding strategies, cross-layer optimization, and techniques to optimize the performance of DAS. Moreover, we review key enabling technologies for next-generation RAN systems, such as multi-access edge computing, network function virtualization, software-defined networking, and network slicing; in addition to some crucial radio access technologies, such as millimeter wave, massive multi-input multi-output, device-to-device communication, and massive machine-type communication. Last but not least, we discuss the major research challenges in DAS and identify several possible directions for future research.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Adaptive Motion Planning with Nonlinear Model Predictive Control for Safety-Critical Collaborative Loco-Manipulation</title>
<link>https://arxiv.org/abs/2411.10699</link>
<guid>https://arxiv.org/abs/2411.10699</guid>
<content:encoded><![CDATA[
<div> 关键词：legged机器人、多机器人任务、安全、层次化控制系统、非线性模型预测控制

<br />
总结:
本文提出了一种用于四足机器人团队协同对象操作的层次化控制系统，重点关注在工业和自主建筑领域的应用。该系统确保了复杂场景中多机器人任务的安全性。文章的关键点包括：<br />
1. 针对大型重物处理的需求，强调了多足机器人协作操纵的重要性以及安全性保证。<br />
2. 提出了一种层次化的控制系统，结合运动规划器与去中心化的步态控制器，实现安全、适应性的团队规划。<br />
3. 高层采用非线性模型预测控制规划器生成避免碰撞的路径，通过控制 Barrier 函数考虑静态和动态障碍物，同时计算接触点和力并适应未知物体及地形属性。<br />
4. 去中心化的loco-manipulation控制器确保每个机器人能在规划器指导下保持稳定的步态和操纵功能。<br />
5. 通过模拟实验和真实硬件实验验证了方法的有效性，机器人团队能根据对象配置穿越含有静态和动态障碍物的环境。相关代码已在开源仓库发布。 <div>
arXiv:2411.10699v1 Announce Type: new 
Abstract: As legged robots take on roles in industrial and autonomous construction, collaborative loco-manipulation is crucial for handling large and heavy objects that exceed the capabilities of a single robot. However, ensuring the safety of these multi-robot tasks is essential to prevent accidents and guarantee reliable operation. This paper presents a hierarchical control system for object manipulation using a team of quadrupedal robots. The combination of the motion planner and the decentralized locomotion controller in a hierarchical structure enables safe, adaptive planning for teams in complex scenarios. A high-level nonlinear model predictive control planner generates collision-free paths by incorporating control barrier functions, accounting for static and dynamic obstacles. This process involves calculating contact points and forces while adapting to unknown objects and terrain properties. The decentralized loco-manipulation controller then ensures each robot maintains stable locomotion and manipulation based on the planner's guidance. The effectiveness of our method is carefully examined in simulations under various conditions and validated in real-life setups with robot hardware. By modifying the object's configuration, the robot team can maneuver unknown objects through an environment containing both static and dynamic obstacles. We have made our code publicly available in an open-source repository at \url{https://github.com/DRCL-USC/collaborative_loco_manipulation}.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Task Offloading for Vehicular Edge Computing Based on Improved Hotstuff under Parking Assistance</title>
<link>https://arxiv.org/abs/2411.10770</link>
<guid>https://arxiv.org/abs/2411.10770</guid>
<content:encoded><![CDATA[
<div> 关键词：Parked-assisted vehicular edge computing (PVEC), 区块链, 任务卸载, 共识节点选择, 游戏模型<br /><br />总结：<br />
本文提出了一种基于区块链的停车辅助车联网边缘计算（BPVEC）卸载框架，旨在增强任务卸载和交易的安全性和可靠性。该框架利用连接支配集（CDS）的共识节点选择算法改进了Hotstuff共识，以根据停车时间、计算能力和通信质量提升区块链在计算卸载和交易过程中的可靠性。同时，文章构建了一个双层Stackelberg游戏模型，将路侧单元（RSUs）和停车车辆（PVs）作为领导者，请求车辆（RVs）作为跟随者，以此优化卸载策略和定价。通过梯度下降法设计了BPVEC卸载策略算法来最大化系统收益。仿真结果显示，所提出的BPVEC卸载方案能够在确保最大利益的同时，实现安全可靠的运行。 <div>
arXiv:2411.10770v1 Announce Type: new 
Abstract: Parked-assisted vehicular edge computing (PVEC) fully leverages communication and computing resources of parking vehicles, thereby significantly alleviating the pressure on edge servers. However, resource sharing and trading for vehicular task offloading in the PVEC environment usually occur between untrustworthy entities, which compromises the security of data sharing and transactions by vehicles and edge devices. To address these concerns, blockchain is introduced to provide a secure and trustworthy environment for offloading and transactions in PVEC. Nevertheless, due to the mobility of the vehicles, the processes of computing offloading and blockchain transactions are interrupted, which greatly reduces the reliability of the blockchain in edge computing process. In this paper, we propose a blockchain-based PVEC (BPVEC) offloading framework to enhance the security and reliability of the task offloading and transaction. Specifically, a consensus node selection algorithm based on the connected dominating set (CDS) is designed to improve the Hotstuff consensus according to parking time, computing capability and communication quality, which enhances blockchain reliability in computing offloading and transactions. Meanwhile, a Stackelberg game model, establishing the roadside units (RSUs) and parking vehicles (PVs) as leaders and the requesting vehicles (RVs) as follower, is utilized to optimize the offloading strategy and pricing. Subsequently, a BPVEC offloading strategy algorithm with gradient descent method is designed to maximize system revenue. Simulation results show that the proposed BPVEC offloading scheme is secure and reliable while ensuring maximum benefits.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Relative Over-Generalization in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.11099</link>
<guid>https://arxiv.org/abs/2411.11099</guid>
<content:encoded><![CDATA[
<div> 关键词: decentralized multi-agent reinforcement learning, relative over-generalization, MaxMax Q-Learning (MMQ), optimal joint policy, sample efficiency

<br /><br />总结:
本文提出了一种解决去中心化多智能体强化学习中相对过泛化问题的新方法——setMax Q-Learning (MMQ)。该方法通过迭代采样和评估潜在的下一个状态，并选择具有最大Q值的状态进行学习，从而更好地逼近协作智能体的理想联合策略。理论分析表明MMQ具有潜力，实验结果证实了在易出现相对过泛化的各种环境中，MMQ相对于现有基线更常表现出更好的收敛性和样本效率。 <div>
arXiv:2411.11099v1 Announce Type: new 
Abstract: In decentralized multi-agent reinforcement learning, agents learning in isolation can lead to relative over-generalization (RO), where optimal joint actions are undervalued in favor of suboptimal ones. This hinders effective coordination in cooperative tasks, as agents tend to choose actions that are individually rational but collectively suboptimal. To address this issue, we introduce MaxMax Q-Learning (MMQ), which employs an iterative process of sampling and evaluating potential next states, selecting those with maximal Q-values for learning. This approach refines approximations of ideal state transitions, aligning more closely with the optimal joint policy of collaborating agents. We provide theoretical analysis supporting MMQ's potential and present empirical evaluations across various environments susceptible to RO. Our results demonstrate that MMQ frequently outperforms existing baselines, exhibiting enhanced convergence and sample efficiency.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Emergent Structure in Multi-agent Systems Using Geometric Embeddings</title>
<link>https://arxiv.org/abs/2411.11142</link>
<guid>https://arxiv.org/abs/2411.11142</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、无人机、自组织、局部观测、虚拟嵌入<br /><br />总结: 本文研究了多智能体系统如何自组织形成封闭轨迹，这是无人机监控任务中的常见需求。为实现这一目标，提出了一个去中心化的控制系统架构，该架构仅基于本地观察信息即可产生全局稳定的 emergent 结构，无需各个代理共享全球计划或遵循预设路径。核心在于利用从实际代理人位置诱导的旋转形成的单射虚拟嵌入。此嵌入作为结构保持映射，使得所有代理稳定其相对位置并允许使用成熟的线性控制技术。通过构造使嵌入与期望轨迹（即同胚）具有相同拓扑性质，从而保持稳定性特性。文章通过在一组Quanser QDrone四旋翼无人机上实施该方法，展示了其实现无人机群自组织到期望轨迹同时保持均匀间距的灵活性和有效性。 <div>
arXiv:2411.11142v1 Announce Type: new 
Abstract: This work investigates the self-organization of multi-agent systems into closed trajectories, a common requirement in unmanned aerial vehicle (UAV) surveillance tasks. In such scenarios, smooth, unbiased control signals save energy and mitigate mechanical strain. We propose a decentralized control system architecture that produces a globally stable emergent structure from local observations only; there is no requirement for agents to share a global plan or follow prescribed trajectories. Central to our approach is the formulation of an injective virtual embedding induced by rotations from the actual agent positions. This embedding serves as a structure-preserving map around which all agent stabilize their relative positions and permits the use of well-established linear control techniques. We construct the embedding such that it is topologically equivalent to the desired trajectory (i.e., a homeomorphism), thereby preserving the stability characteristics. We demonstrate the versatility of this approach through implementation on a swarm of Quanser QDrone quadcopters. Results demonstrate the quadcopters self-organize into the desired trajectory while maintaining even separation.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Signaling and Social Learning in Swarms of Robots</title>
<link>https://arxiv.org/abs/2411.11616</link>
<guid>https://arxiv.org/abs/2411.11616</guid>
<content:encoded><![CDATA[
<div> 关键词：communication, coordination, robot swarms, learning, decentralized

总结:
本文研究了通信在改善机器人 Swarm 中协调性方面的作用，重点关注同时进行学习和执行的分布式环境。文章强调了通信在解决功劳分配问题（个体对整体性能的贡献）以及它如何受此影响的重要性。文中提出了一种关于通信的分类体系，主要分为信息选择和物理抽象两个轴线，从低层次的无损压缩与原始信号提取处理到高层次的有损压缩与结构化通信模型。通过对进化机器人、多智能体（深度）强化学习、语言模型和生物物理模型等领域的现有研究进行回顾，文章概述了在通过局部消息交换不断从彼此中学习的集体机器人中，通信所面临的挑战与机遇，展示了一种社会学习的形式。<br /><br /> <div>
arXiv:2411.11616v1 Announce Type: new 
Abstract: This paper investigates the role of communication in improving coordination within robot swarms, focusing on a paradigm where learning and execution occur simultaneously in a decentralized manner. We highlight the role communication can play in addressing the credit assignment problem (individual contribution to the overall performance), and how it can be influenced by it. We propose a taxonomy of existing and future works on communication, focusing on information selection and physical abstraction as principal axes for classification: from low-level lossless compression with raw signal extraction and processing to high-level lossy compression with structured communication models. The paper reviews current research from evolutionary robotics, multi-agent (deep) reinforcement learning, language models, and biophysics models to outline the challenges and opportunities of communication in a collective of robots that continuously learn from one another through local message exchanges, illustrating a form of social learning.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Incremental Named Entity Recognition</title>
<link>https://arxiv.org/abs/2411.11623</link>
<guid>https://arxiv.org/abs/2411.11623</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Named Entity Recognition (FNER), Federated Incremental NER, Local-Global Forgetting Defense (LGFD), 知识蒸馏, 异型对比学习

总结:
本文提出了一种针对联邦增量命名实体识别（Federated Incremental NER）问题的解决方案，该问题涉及到连续出现新实体类型和不定期加入的新客户端。为了解决此问题，研究者们提出了局部-全局遗忘防御（LGFD）模型。针对客户端内部遗忘的问题，LGFD模型采用结构知识蒸馏损失以保持潜在空间的特征结构，并利用伪标签引导的异型对比损失增强不同实体类型的判别能力，有效保存了先前学到的知识。对于客户端间遗忘的挑战，LGFD模型设计了一个任务切换监控器，能够在保护隐私的前提下自动识别新实体类型，并存储最新的旧全局模型用于知识蒸馏和伪标签生成。实验结果显示，与比较方法相比，LGFD模型有显著的性能提升。 <div>
arXiv:2411.11623v1 Announce Type: new 
Abstract: Federated Named Entity Recognition (FNER) boosts model training within each local client by aggregating the model updates of decentralized local clients, without sharing their private data. However, existing FNER methods assume fixed entity types and local clients in advance, leading to their ineffectiveness in practical applications. In a more realistic scenario, local clients receive new entity types continuously, while new local clients collecting novel data may irregularly join the global FNER training. This challenging setup, referred to here as Federated Incremental NER, renders the global model suffering from heterogeneous forgetting of old entity types from both intra-client and inter-client perspectives. To overcome these challenges, we propose a Local-Global Forgetting Defense (LGFD) model. Specifically, to address intra-client forgetting, we develop a structural knowledge distillation loss to retain the latent space's feature structure and a pseudo-label-guided inter-type contrastive loss to enhance discriminative capability over different entity types, effectively preserving previously learned knowledge within local clients. To tackle inter-client forgetting, we propose a task switching monitor that can automatically identify new entity types under privacy protection and store the latest old global model for knowledge distillation and pseudo-labeling. Experiments demonstrate significant improvement of our LGFD model over comparison methods.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Competing Bandits in Decentralized Large Contextual Matching Markets</title>
<link>https://arxiv.org/abs/2411.11794</link>
<guid>https://arxiv.org/abs/2411.11794</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体资源受限匹配市场、分布式学习、两-sided匹配市场、线性上下文带宽算法、动态匹配市场

总结:
这篇论文关注的是在多智能体资源受限匹配市场中，针对具有时间变化偏好的两-sided匹配市场的分布式学习问题。现有的探索-然后-承诺或上界置信区间等学习算法对于该问题效率低下，其单个代理的遗憾值与手臂数量 $K$ 成正比。受到线性上下文带宽框架的启发，文章假设每个代理对手臂的期望回报可以用已知特征向量和未知（代理特定）参数的线性函数表示。此外，文中设定的场景还捕获了匹配市场需求随时间动态变化的本质。为此，论文提出了实现与手臂数量无关的实例依赖对数遗憾值的新算法。<br /><br /> <div>
arXiv:2411.11794v1 Announce Type: new 
Abstract: Sequential learning in a multi-agent resource constrained matching market has received significant interest in the past few years. We study decentralized learning in two-sided matching markets where the demand side (aka players or agents) competes for a `large' supply side (aka arms) with potentially time-varying preferences, to obtain a stable match. Despite a long line of work in the recent past, existing learning algorithms such as Explore-Then-Commit or Upper-Confidence-Bound remain inefficient for this problem. In particular, the per-agent regret achieved by these algorithms scales linearly with the number of arms, $K$. Motivated by the linear contextual bandit framework, we assume that for each agent an arm-mean can be represented by a linear function of a known feature vector and an unknown (agent-specific) parameter.
  Moreover, our setup captures the essence of a dynamic (non-stationary) matching market where the preferences over arms change over time. Our proposed algorithms achieve instance-dependent logarithmic regret, scaling independently of the number of arms, $K$.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DecTest: A Decentralised Testing Architecture for Improving Data Accuracy of Blockchain Oracle</title>
<link>https://arxiv.org/abs/2404.13535</link>
<guid>https://arxiv.org/abs/2404.13535</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、oracle、数据准确性、去中心化测试架构（DecTest）、随机秘密测试机制

<br /><br />总结:

本文针对区块链系统中链上与链下数据交互的难题以及现有oracle节点可能存在外部攻击或出于自私动机提供不准确数据的问题，提出了一种新的去中心化测试架构（DecTest）。该架构首先引入了一个区块链预言机随机秘密测试机制，通过建立动态匿名提问验证委员会，增强了对节点的监控和验证。在此基础上，设计了一个全面的评价激励机制，依据节点的声誉分数对其工作表现进行评估并给予激励。模拟结果显示，该方案成功地将获取数据的离散熵值降低了61.4%，从而提高了数据的真实性和准确性。 <div>
arXiv:2404.13535v2 Announce Type: replace 
Abstract: Blockchain technology ensures secure and trustworthy data flow between multiple participants on the chain, but interoperability of on-chain and off-chain data has always been a difficult problem that needs to be solved. To solve the problem that blockchain systems cannot access off-chain data, oracle is introduced. However, existing research mainly focuses on the consistency and integrity of data, but ignores the problem that oracle nodes may be externally attacked or provide false data for selfish motives, resulting in the unresolved problem of data accuracy. In this paper, we introduce a new Decentralized Testing architecture (DecTest) that aims to improve data accuracy. A blockchain oracle random secret testing mechanism is first proposed to enhance the monitoring and verification of nodes by introducing a dynamic anonymized question-verification committee. Based on this, a comprehensive evaluation incentive mechanism is designed to incentivize honest work performance by evaluating nodes based on their reputation scores. The simulation results show that we successfully reduced the discrete entropy value of the acquired data and the real value of the data by 61.4%.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Space-Air-Ground Integrated MEC-Assisted Industrial Cyber-Physical Systems: An Online Decentralized Optimization Approach</title>
<link>https://arxiv.org/abs/2411.09712</link>
<guid>https://arxiv.org/abs/2411.09712</guid>
<content:encoded><![CDATA[
<div> 关键词: 云计算, 边缘计算, 空天地一体化多接入边缘计算(SAGIMEC), 工业 cyber-物理系统(ICPS), 联合优化问题(JSC4OP)

<br /><br />总结:
本文介绍了SAGIMEC辅助的ICPS架构，该架构通过卫星网络实现云边计算与无缝连接，以提升IoTDs的服务质量和系统的确定性。文章提出了一个综合的联合卫星选择、计算卸载、通信资源分配、计算资源分配和无人机轨迹控制优化问题(JSC4OP)，旨在最大化IoTDs的服务质量，同时考虑了系统环境动态、不确定性及无人机的资源和能源限制。为解决这个复杂问题，文章提出了一种在线分散式优化方法(ODOA)。首先，利用Lyapunov优化将JSC4OP转化为实时决策优化问题(RDOP)；接着，引入在线学习的延迟预测方法预测不确定的系统环境，并采用博弈论决策方法进行实时决策。理论分析证实了ODOA的有效性，而仿真结果表明，所提出的ODOA方案相比于其他替代方法在整体系统性能上表现出优越性。 <div>
arXiv:2411.09712v1 Announce Type: new 
Abstract: Cloud computing and edge/fog computing are playing a pivotal role in driving the transformation of industrial cyber-physical systems (ICPS) towards greater intelligence and automation by providing high-quality computation offloading services to Internet of Things devices (IoTDs). Recently, space-air-ground integrated multi-access edge computing (SAGIMEC) is emerging as a promising architecture combining edge computing and cloud computing, which has the potential to be integrated with ICPS to accelerate the realization of the above vision. In this work, we first present an SAGIMEC-assisted ICPS architecture that incorporates edge computing and cloud computing through seamless connectivity supported by satellite networks to achieve determinism in connectivity, networked computing, and intelligent networked control. Then, we formulate a joint satellite selection, computation offloading, communication resource allocation, computation resource allocation, and UAV trajectory control optimization problem (JSC4OP) to maximize the quality of service (QoS) of IoTDs. This problem considers both the dynamics and uncertainties of the system environment, as well as the limited resources and energy of UAVs. Given the complexity of JSC4OP, we propose an online decentralized optimization approach (ODOA) to solve the problem. Specifically, JSC4OP is first transformed into a real-time decision-making optimization problem (RDOP) by leveraging Lyapunov optimization. Then, to solve the RDOP, we introduce an online learning-based latency prediction method to predict the uncertain system environment and a game theoretic decision-making method to make real-time decisions. Finally, theoretical analysis confirms the effectiveness of the ODOA, while the simulation results demonstrate that the proposed ODOA outperforms other alternative approaches in terms of overall system performance.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Readability Evaluation for Graph Layouts: 2D Geometric Distributed Algorithms</title>
<link>https://arxiv.org/abs/2411.09809</link>
<guid>https://arxiv.org/abs/2411.09809</guid>
<content:encoded><![CDATA[
<div> 关键词: 图可视化、可读性指标、计算复杂性、分布式环境、Spark

总结:
本文主要探讨了图在社交网络、金融和区块链等领域中的重要性以及其可视化对于识别结构模式的关键作用。现有的可读性评估方法在处理大规模图时面临计算密集型挑战。针对这一问题，先前利用机器学习预测渲染图像的可读性得分的方法虽有一定提升，但在处理大量节点的图时，存在内存需求大、准确度不高的缺点。为解决这些问题，该研究提出了一种利用Spark的DataFrame和GraphFrame框架在分布式环境中实现可读性评价的可扩展算法。实验结果显示，这些分布式算法显著减少了计算时间，对于大型数据集的节点遮挡计算速度提高了约17倍，边交叉计算速度提高了约146倍。这使得大规模图的可读性评估变得更加实用和高效，有效克服了以往机器学习方法的局限性。<br /><br /> <div>
arXiv:2411.09809v1 Announce Type: new 
Abstract: Graphs, consisting of vertices and edges, are vital for representing complex relationships in fields like social networks, finance, and blockchain. Visualizing these graphs helps analysts identify structural patterns, with readability metrics-such as node occlusion and edge crossing-assessing layout clarity. However, calculating these metrics is computationally intensive, making scalability a challenge for large graphs. Without efficient readability metrics, layout generation processes-despite numerous studies focused on accelerating them-face bottleneck, making it challenging to select or produce optimized layouts swiftly. Previous approaches attempted to accelerate this process through machine learning models. Machine learning approaches aimed to predict readability scores from rendered images of graphs. While these models offered some improvement, they struggled with scalability and accuracy, especially for graphs with thousands of nodes. For instance, this approach requires substantial memory to process large images, as it relies on rendered images of the graph; graphs with more than 600 nodes cannot be inputted into the model, and errors can exceed 55% in some readability metrics due to difficulties in generalizing across diverse graph layouts. This study addresses these limitations by introducing scalable algorithms for readability evaluation in distributed environments, utilizing Spark's DataFrame and GraphFrame frameworks to efficiently manage large data volumes across multiple machines. Experimental results show that these distributed algorithms significantly reduce computation time, achieving up to a 17x speedup for node occlusion and a 146x improvement for edge crossing on large datasets. These enhancements make scalable graph readability evaluation practical and efficient, overcoming the limitations of previous machine-learning approaches.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedRewind: Rewinding Continual Model Exchange for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2411.09842</link>
<guid>https://arxiv.org/abs/2411.09842</guid>
<content:encoded><![CDATA[
<div> 关键词：FedRewind、去中心化联邦学习、数据分布偏移、持续学习、模型交换

<br />
总结:
本文提出了FedRewind，一种新颖的去中心化联邦学习方法，该方法利用节点间的模型交换来应对数据分布偏移问题。FedRewind借鉴了持续学习（CL）原理和认知神经科学中关于记忆保持的理论，实现了一个去中心化的路由机制，使得节点可以向其他节点发送/接收模型，以解决分布式学习中的空间分布挑战。在局部训练过程中，联盟节点定期将其模型回传（即回溯）到它们最初接收到模型的节点进行有限次数的迭代，以此减少节点间数据分布的差异，从而提升学习和泛化性能。实验结果显示，FedRewind优于标准的去中心化联邦学习方法以及那些在联盟内部强制实施特定路由策略的方法。此外，通过结合联邦学习与持续学习的概念，FedRewind还能应对更为复杂的联邦持续学习任务，即同时存在空间和时间上的数据偏移变化，超过了现有的基线方法。 <div>
arXiv:2411.09842v1 Announce Type: new 
Abstract: In this paper, we present FedRewind, a novel approach to decentralized federated learning that leverages model exchange among nodes to address the issue of data distribution shift. Drawing inspiration from continual learning (CL) principles and cognitive neuroscience theories for memory retention, FedRewind implements a decentralized routing mechanism where nodes send/receive models to/from other nodes in the federation to address spatial distribution challenges inherent in distributed learning (FL). During local training, federation nodes periodically send their models back (i.e., rewind) to the nodes they received them from for a limited number of iterations. This strategy reduces the distribution shift between nodes' data, leading to enhanced learning and generalization performance. We evaluate our method on multiple benchmarks, demonstrating its superiority over standard decentralized federated learning methods and those enforcing specific routing schemes within the federation. Furthermore, the combination of federated and continual learning concepts enables our method to tackle the more challenging federated continual learning task, with data shifts over both space and time, surpassing existing baselines.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Express Yourself: Enabling large-scale public events involving multi-human-swarm interaction for social applications with MOSAIX</title>
<link>https://arxiv.org/abs/2411.09975</link>
<guid>https://arxiv.org/abs/2411.09975</guid>
<content:encoded><![CDATA[
<div> 关键词：Robot swarms, Multi-human-swarm interaction, MOSAIX, Swarm of robot Tiles, Public event

总结:<br />
本文介绍了研究团队在利用机器人蜂群MOSAIX于科学博物馆中促进公众创新思维的过程。MOSAIX由63台机器人“智能便利贴”组成，它们能够收集公众意见并根据主题进行聚合，为参观者提供了一个动态的可视化工具，从而吸引游客参与其中。该工作着重在于创建了一个大规模（涉及63台机器人和294名参与者）的真实生活场景下的公共活动，并采用了一种完全去中心化的蜂群系统。此外，文中还分享了从中获得的经验教训，以期对未来的多人类与机器人蜂群互动研究提供参考。 <div>
arXiv:2411.09975v1 Announce Type: new 
Abstract: Robot swarms have the potential to help groups of people with social tasks, given their ability to scale to large numbers of robots and users. Developing multi-human-swarm interaction is therefore crucial to support multiple people interacting with the swarm simultaneously - which is an area that is scarcely researched, unlike single-human, single-robot or single-human, multi-robot interaction. Moreover, most robots are still confined to laboratory settings. In this paper, we present our work with MOSAIX, a swarm of robot Tiles, that facilitated ideation at a science museum. 63 robots were used as a swarm of smart sticky notes, collecting input from the public and aggregating it based on themes, providing an evolving visualization tool that engaged visitors and fostered their participation. Our contribution lies in creating a large-scale (63 robots and 294 attendees) public event, with a completely decentralized swarm system in real-life settings. We also discuss learnings we obtained that might help future researchers create multi-human-swarm interaction with the public.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Consensus for Fair Message Ordering</title>
<link>https://arxiv.org/abs/2411.09981</link>
<guid>https://arxiv.org/abs/2411.09981</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本系统、共识协议、公平性、最大可提取价值(MEV)、消息排序

<br /><br />总结:
本文针对分布式账本系统（如区块链）中依赖于共识协议进行消息排序的问题进行了深入研究，重点关注了那些致力于促进消息排序公平性的方法，包括基于先进先出（FIFO）、随机和盲排序等不同策略的共识协议。文章讨论了在拜占庭容错环境下实现公平消息排序所面临的挑战与权衡，并总结了构建公平消息排序共识协议的关键步骤。此外，文中提出了一条设计指导原则，并以此为依据优化了当前最先进的FIFO排序协议——Themis。该工作建立了一个统一的框架，用于评估和提升分布式账本系统的公平性。 <div>
arXiv:2411.09981v1 Announce Type: new 
Abstract: Distributed ledger systems, such as blockchains, rely on consensus protocols that constantly commit messages in an agreed order for processing. In practice, message ordering within these systems is often reward-driven. This raises concerns about fairness, particularly in decentralized finance applications, where nodes can exploit transaction orders to maximize rewards (Maximal Extractable Value, MEV). This paper provides a structured review of consensus protocols that order messages with different approaches, especially focusing on the ones that promote order fairness, using methods including First-In-First-Out (FIFO), random, and blind ordering. We review the challenges and trade-offs of deriving fair message ordering in a Byzantine fault-tolerant setting, and summarize the key steps for making a fair message ordering consensus protocol. We introduce a design guideline, with which we propose a performance optimization to the state-of-the-art FIFO ordering protocol Themis. This work establishes a unified framework for accessing and enhancing fairness in distributed ledger systems.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Roadmap for Quantum- Resistant Security: A Framework for Preparing Industries for the Quantum Threat</title>
<link>https://arxiv.org/abs/2411.09995</link>
<guid>https://arxiv.org/abs/2411.09995</guid>
<content:encoded><![CDATA[
<div> 关键词: 量子计算, 密码系统, 抗量子攻击, STL-QCRYPTO框架, 行业安全

总结:<br />
随着量子计算的发展，其对广泛使用的密码系统的威胁给现代网络安全带来了重大挑战。本文提出了一种应对量子攻击的战略路线图，旨在帮助各行业预见并减轻量子风险。文章介绍了一个名为STL-QCRYPTO的新型战略框架，该框架为实现行业特定的量子安全系统提供了务实和战略性的方法。文中深入评估了金融服务业、银行业、医疗保健、关键基础设施等十四大高风险行业的量子威胁脆弱性，并着重探讨了这些行业实施量子安全防护系统的实际路径。同时，论文还讨论了采用抗量子技术所面临的技術、操作及监管难题。通过提供结构化的时间线和可操作建议，本文构建的路线图与框架有助于各行业在量子计算时代制定抵御潜在安全威胁的战略。 <div>
arXiv:2411.09995v1 Announce Type: new 
Abstract: As quantum computing continues to advance, its ability to compromise widely used cryptographic systems projects a significant challenge to modern cybersecurity. This paper outlines a strategic roadmap for industries to anticipate and mitigate the risks posed by quantum attacks. Our study explores the development of a quantum-resistant cryptographic solutioning framework for the industry, offering a practical and strategic approach to mitigating quantum attacks. We, here, propose a novel strategic framework, coined name STL-QCRYPTO, outlines tailored, industry-specific methodologies to implement quantum-safe security systems, ensuring long-term protection against the disruptive potential of quantum computing. The following fourteen high-risk sectors: Financial Services, Banking, Healthcare, Critical Infrastructure, Government & Defence, E-commerce, Energy & Utilities, Automotive & Transportation, Cloud Computing & Data Storage, Insurance, Internet & Telecommunications, Blockchain Applications, Metaverse Applications, and Multiagent AI Systems - are critically assessed for their vulnerability to quantum threats. The evaluation emphasizes practical approaches for the deployment of quantum-safe security systems to safeguard these industries against emerging quantum-enabled cyber risks. Additionally, the paper addresses the technical, operational, and regulatory hurdles associated with adopting quantum-resistant technologies. By presenting a structured timeline and actionable recommendations, this roadmap with proposed framework prepares industries with the essential strategy to safeguard their potential security threats in the quantum computing era.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Omnichain Web: The Universal Framework for Streamlined Chain Abstraction and Cross-Layer Interaction</title>
<link>https://arxiv.org/abs/2411.10132</link>
<guid>https://arxiv.org/abs/2411.10132</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3、碎片化流动性、互操作性、Omnichain Web、跨链资产结算

总结:
<br />
Omnichain Web 是一个旨在解决Web3生态系统中碎片化流动性与Layer 1和Layer 2区块链之间有限互操作性的框架。它通过核心组件——OmniRollups、Proof Network、Ragno Network和Builder Marketplace实现统一化的去中心化网络。该生态系统支持无缝跨链资产结算和互操作性，并为开发用户友好的去中心化应用（dApp）提供便利。其创新技术包括模块化证明网络和可信执行环境（TEEs），并结合先进的零知识证明系统及AI代理兼容性，实现意图驱动和自主功能，优化了区块链间的流动性管理和用户体验。此外，Omnichain Web还提供了用于L1基础设施的去中心化市场，降低了运营开销，并促进了可扩展、安全和高效的跨链协议。作为一项开创性解决方案，Omnichain Web无缝连接Web2和Web3，推动了一个全面互联的数字经济发展。 <div>
arXiv:2411.10132v1 Announce Type: new 
Abstract: The evolution of the Web3 ecosystem has been hindered by fragmented liquidity and limited interoperability across Layer 1 (L1) and Layer 2 (L2) blockchains, which leads to inefficiencies and elevated costs. Omnichain Web addresses these challenges by introducing a comprehensive framework to unify decentralized networks through its core components: OmniRollups, Proof Network, Ragno Network, and Builder Marketplace. This ecosystem enables seamless cross-chain asset settlement, interoperability, and user-friendly decentralized application (dApp) development, driven by innovative technologies such as modular proof networks and trusted execution environments (TEEs). By integrating advanced zero-knowledge proof systems and compatibility with AI agents, Omnichain Web empowers intent-driven and autonomous functionalities, streamlining liquidity management and user interactions across blockchains. Furthermore, its decentralized marketplace for L1 infrastructure reduces operational overhead and promotes scalable, secure, and efficient cross-chain protocols. As a pioneering solution, Omnichain Web seamlessly connects Web2 and Web3, enabling a holistic and interconnected digital economy.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Definition and Detection of Centralization Defects in Smart Contracts</title>
<link>https://arxiv.org/abs/2411.10169</link>
<guid>https://arxiv.org/abs/2411.10169</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化缺陷、智能合约、安全事件、CDRipper、检测工具

<br /><br />总结:

本文针对近年来由于智能合约中心化缺陷导致的安全事件及大量财务损失问题进行了研究。文章提出了六种类型的智能合约中心化缺陷，并通过分析597篇Stack Exchange帖子和117份审计报告进行详细描述与实例展示。为填补当前对这类缺陷分析不足的空白，作者开发了一款名为CDRipper的工具，该工具通过构建权限依赖图(PDG)，从智能合约源代码中提取函数的权限依赖关系，并检测函数中的敏感操作，依据预定义模式识别中心化缺陷。实验结果显示，在对244,424个真实世界的智能合约进行大规模检测后，共有82,446个合同存在至少一种中心化缺陷，而CDRipper工具在此过程中达到了93.7%的整体精确度。 <div>
arXiv:2411.10169v1 Announce Type: new 
Abstract: In recent years, security incidents stemming from centralization defects in smart contracts have led to substantial financial losses. A centralization defect refers to any error, flaw, or fault in a smart contract's design or development stage that introduces a single point of failure. Such defects allow a specific account or user to disrupt the normal operations of smart contracts, potentially causing malfunctions or even complete project shutdowns. Despite the significance of this issue, most current smart contract analyses overlook centralization defects, focusing primarily on other types of defects. To address this gap, our paper introduces six types of centralization defects in smart contracts by manually analyzing 597 Stack Exchange posts and 117 audit reports. For each defect, we provide a detailed description and code examples to illustrate its characteristics and potential impacts. Additionally, we introduce a tool named CDRipper (Centralization Defects Ripper) designed to identify the defined centralization defects. Specifically, CDRipper constructs a permission dependency graph (PDG) and extracts the permission dependencies of functions from the source code of smart contracts. It then detects the sensitive operations in functions and identifies centralization defects based on predefined patterns. We conduct a large-scale experiment using CDRipper on 244,424 real-world smart contracts and evaluate the results based on a manually labeled dataset. Our findings reveal that 82,446 contracts contain at least one of the six centralization defects, with our tool achieving an overall precision of 93.7%.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Driven Decentralized Control Design for Discrete-Time Large-Scale Systems</title>
<link>https://arxiv.org/abs/2411.10243</link>
<guid>https://arxiv.org/abs/2411.10243</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、控制器设计、离散时间大系统、解中心化控制、半定规划问题

<br />
总结:
本文提出了一种针对离散时间大规模系统的数据驱动控制器设计方法。该方法将大规模系统转化为等效的数据驱动形式，并利用其子系统的状态、控制输入和互联系统输入数据来参数化解中心化控制器。通过结合开发的数据驱动方法与李亚普诺夫方法，构建了一个数据驱动的半定规划问题以求得稳定性的解中心化控制器。这种方法在对一串质量弹簧模型的验证中表现出显著优势，即避免了繁琐的建模过程。 <div>
arXiv:2411.10243v1 Announce Type: new 
Abstract: In this paper, a data-driven approach is developed for controller design for a class of discrete-time large-scale systems, where a large-scale system can be expressed in an equivalent data-driven form and the decentralized controllers can be parameterized by the data collected from its subsystems, i.e., system state, control input, and interconnection input. Based on the developed data-driven method and the Lyapunov approach, a data-driven semi-definite programming problem is constructed to obtain decentralized stabilizing controllers. The proposed approach has been validated on a mass-spring chain model, with the significant advantage of avoiding extensive modeling processes.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>How the interplay between power concentration, competition, and propagation affects the resource efficiency of distributed ledgers</title>
<link>https://arxiv.org/abs/2411.10249</link>
<guid>https://arxiv.org/abs/2411.10249</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin网络、分叉、共识协议、矿工异质性、块传播时间

<br /><br />总结:
本文介绍了关于比特币网络中自然分叉的研究，其频率作为分布式账本效率的关键指标，可能导致资源浪费和网络安全问题。研究提出了一种模型，用于预测具有不同矿工数量、哈希率分布以及块传播时间的异质矿工网络中的自然分叉率。该模型预测的分叉率与实测的废弃区块率相当。过去十年间，采矿池的数量大约减少了三分之一，论文量化了这一变化对分叉率的影响，并揭示了由于全球能源供应限制导致的哈希率分布呈现截尾幂律分布的现象。文章通过实证分析和定量模型证明，块传播时间和挖矿时间的比例是评估分叉率的一个准确指标，并进一步量化了它对矿工活动异质性的依赖。此外，文中提供了理论和实证证据表明，哈希率集中度降低和块传播时间缩短可以减少分布式账本中的分叉率。这项工作为研究分布式网络上的权力集中和竞争提供了一个稳健的数学框架，有助于解释由自私挖矿策略和不对称传播时间引起的分叉率差异，从而为现有和新兴区块链分布式挖掘系统的未来设计提供了有效的工具。 <div>
arXiv:2411.10249v1 Announce Type: new 
Abstract: Forks in the Bitcoin network result from the natural competition in the blockchain's Proof-of-Work consensus protocol. Their frequency is a critical indicator for the efficiency of a distributed ledger as they can contribute to resource waste and network insecurity. We introduce a model for the estimation of natural fork rates in a network of heterogeneous miners as a function of their number, the distribution of hash rates and the block propagation time over the peer-to-peer infrastructure. Despite relatively simplistic assumptions, such as zero propagation delay within mining pools, the model predicts fork rates which are comparable with the empirical stale blocks rate. In the past decade, we observe a reduction in the number of mining pools approximately by a factor 3, and quantify its consequences for the fork rate, whilst showing the emergence of a truncated power-law distribution in hash rates, justified by a rich-get-richer effect constrained by global energy supply limits. We demonstrate, both empirically and with the aid of our quantitative model, that the ratio between the block propagation time and the mining time is a sufficiently accurate estimator of the fork rate, but also quantify its dependence on the heterogeneity of miner activities. We provide empirical and theoretical evidence that both hash rate concentration and lower block propagation time reduce fork rates in distributed ledgers. Our work introduces a robust mathematical setting for investigating power concentration and competition on a distributed network, for interpreting discrepancies in fork rates -- for example caused by selfish mining practices and asymmetric propagation times -- thus providing an effective tool for designing future and alternative scenarios for existing and new blockchain distributed mining systems.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bitcoin Research with a Transaction Graph Dataset</title>
<link>https://arxiv.org/abs/2411.10325</link>
<guid>https://arxiv.org/abs/2411.10325</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、大规模数据集、交易图、节点标签、图神经网络

<br /><br />总结:
本文介绍了由Satoshi Nakamoto于2008年创立的比特币如何构建了一个无需中央权威机构即可存储和转移价值的全新数字经济。文章提出了一项大规模比特币交易数据集，该数据集以交易图的形式呈现，包含了约2.52亿个节点、7.85亿条边，时间跨度近13年，涵盖了6.7亿笔交易，且每个节点和边都带有时间戳。数据集提供了两个标注集合：一是基于实体类型的3.3万个节点；二是将近10万比特币地址，标注了实体名称和类型，这是迄今为止公开可用的最大规模比特币交易数据集，旨在促进该领域的深入研究，克服现有数据集的局限性。此外，通过训练各种图神经网络模型来预测节点标签，为未来研究建立了基准，并展示了数据集在比特币分析之外的多种应用场景。最后，所有数据和源代码均对公众开放，以实现结果的可复现性。 <div>
arXiv:2411.10325v1 Announce Type: new 
Abstract: Bitcoin, launched in 2008 by Satoshi Nakamoto, established a new digital economy where value can be stored and transferred in a fully decentralized manner - alleviating the need for a central authority. This paper introduces a large scale dataset in the form of a transactions graph representing transactions between Bitcoin users along with a set of tasks and baselines. The graph includes 252 million nodes and 785 million edges, covering a time span of nearly 13 years of and 670 million transactions. Each node and edge is timestamped. As for supervised tasks we provide two labeled sets i. a 33,000 nodes based on entity type and ii. nearly 100,000 Bitcoin addresses labeled with an entity name and an entity type. This is the largest publicly available data set of bitcoin transactions designed to facilitate advanced research and exploration in this domain, overcoming the limitations of existing datasets. Various graph neural network models are trained to predict node labels, establishing a baseline for future research. In addition, several use cases are presented to demonstrate the dataset's applicability beyond Bitcoin analysis. Finally, all data and source code is made publicly available to enable reproducibility of the results.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game Theoretic Liquidity Provisioning in Concentrated Liquidity Market Makers</title>
<link>https://arxiv.org/abs/2411.10399</link>
<guid>https://arxiv.org/abs/2411.10399</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化标记制造商 (AMM), 集中流动性市场制造商 (CLMM), 流动性提供者 (LP), 纳什均衡, 水平填充策略

<br /><br />总结:
本文介绍了自动化标记制造商（AMMs）和集中流动性市场制造商（CLMMs），这是一种允许自动交易数字资产并由流动性提供者（LPs）提供存款的去中心化交易所。研究重点在于CLMMs中LPs的战略规划与激励机制。文章构建了一个博弈论模型分析LPs的行为，并发现原问题可能存在多个纳什均衡且复杂度随价格刻度数量呈二次增长，但可简化为具有唯一纳什均衡、复杂度线性增长的游戏。简化后的纳什均衡表现为低预算LP会使用全部预算，而富裕LP则不会完全投入。通过对真实世界CLMM数据的拟合，观察到在含有风险资产的流动资金池中，LPs的投资策略远离纳什均衡，他们倾向于在更少且更宽的价格范围内投资，并减少流动性更新频率。研究进一步表明，如果LPs调整其策略以更接近游戏的纳什均衡，他们的日均收益可提高约116美元，即日投资回报率中位数增加0.009%。 <div>
arXiv:2411.10399v1 Announce Type: new 
Abstract: Automated marker makers (AMMs) are a class of decentralized exchanges that enable the automated trading of digital assets. They accept deposits of digital tokens from liquidity providers (LPs); tokens can be used by traders to execute trades, which generate fees for the investing LPs. The distinguishing feature of AMMs is that trade prices are determined algorithmically, unlike classical limit order books. Concentrated liquidity market makers (CLMMs) are a major class of AMMs that offer liquidity providers flexibility to decide not only \emph{how much} liquidity to provide, but \emph{in what ranges of prices} they want the liquidity to be used. This flexibility can complicate strategic planning, since fee rewards are shared among LPs. We formulate and analyze a game theoretic model to study the incentives of LPs in CLMMs. Our main results show that while our original formulation admits multiple Nash equilibria and has complexity quadratic in the number of price ticks in the contract, it can be reduced to a game with a unique Nash equilibrium whose complexity is only linear. We further show that the Nash equilibrium of this simplified game follows a waterfilling strategy, in which low-budget LPs use up their full budget, but rich LPs do not. Finally, by fitting our game model to real-world CLMMs, we observe that in liquidity pools with risky assets, LPs adopt investment strategies far from the Nash equilibrium. Under price uncertainty, they generally invest in fewer and wider price ranges than our analysis suggests, with lower-frequency liquidity updates. We show that across several pools, by updating their strategy to more closely match the Nash equilibrium of our game, LPs can improve their median daily returns by \$116, which corresponds to an increase of 0.009\% in median daily return on investment.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Coordination of Distributed Energy Resources through Local Energy Markets and Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2404.13142</link>
<guid>https://arxiv.org/abs/2404.13142</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式能源资源、电力网、交易性能源、深度强化学习、社区净负荷变异性

总结:
随着分布式能源资源（DERs）的增长，电力网格面临边缘区域净负荷波动性增加的问题，影响了运行可靠性和稳定性。交易性能源通过本地能源市场提供了一种分散式的、间接的需求响应解决方案，而深度强化学习（DRL）等模型无关控制技术则使自动化、分散化的参与成为可能。然而，现有研究大多忽视了社区层面的净负荷变异性问题，更关注经济社会指标。本文针对这一空白，利用DRL代理自动参与名为ALEX的本地能源市场，各代理独立行动以最小化各自能源费用。结果表明，降低电费与减少净负荷变异性之间存在紧密联系，通过评估不同时间范围内的指标如爬坡率、负载因子和峰值需求得到证实。将DRL代理与近乎最优的动态规划方法进行基准对比，动态规划方法分别实现了每日进口、出口和峰值需求降低22.05%、83.92%和24.09%，而DRL代理表现出可比或更优的结果，分别降低了21.93%、84.46%和27.02%。该研究表明，DRL在分散化电网管理中的有效性，突显了其在社区驱动的能源市场中实现接近最优性能、减少净负荷变异性方面的可扩展性。 <div>
arXiv:2404.13142v2 Announce Type: replace 
Abstract: As distributed energy resources (DERs) grow, the electricity grid faces increased net load variability at the grid edge, impacting operability and reliability. Transactive energy, facilitated through local energy markets, offers a decentralized, indirect demand response solution, with model-free control techniques, such as deep reinforcement learning (DRL), enabling automated, decentralized participation. However, existing studies largely overlook community-level net load variability, focusing instead on socioeconomic metrics.
  This study addresses this gap by using DRL agents to automate end-user participation in a local energy market (ALEX), where agents act independently to minimize individual energy bills. Results reveal a strong link between bill reduction and decreased net load variability, assessed across metrics such as ramping rate, load factor, and peak demand over various time horizons. Using a no-control baseline, DRL agents are benchmarked against a near-optimal dynamic programming approach. The dynamic programming benchmark achieves reductions of 22.05 percent, 83.92 percent, and 24.09 percent in daily import, export, and peak demand, respectively, while the DRL agents show comparable or superior results with reductions of 21.93 percent, 84.46 percent, and 27.02 percent.
  This study demonstrates the effectiveness of DRL in decentralized grid management, highlighting its scalability and near-optimal performance in reducing net load variability within community-driven energy markets.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multilingual Standalone Trustworthy Voice-Based Social Network for Disaster Situations</title>
<link>https://arxiv.org/abs/2411.08889</link>
<guid>https://arxiv.org/abs/2411.08889</guid>
<content:encoded><![CDATA[
<div> 关键词：灾难场景、语音通信、多语言、人工智能、区块链技术

总结:<br />
本文介绍了一种针对灾难场景下语言障碍问题而设计的创新性、多语言语音社交网络。该系统利用先进的人工智能实现语音实时翻译，确保跨语言间的流畅交流，并结合区块链技术存储安全、不可篡改的消息记录，保证信息完整性。此外，系统能在离线环境下通过本地网络独立运行，提高可靠性，并可在多种设备上跨平台使用，包括移动手机和桌面电脑，具有很好的适应性和易用性。评估结果显示，该系统在语音识别与翻译准确度、低延迟以及用户满意度方面表现优异，验证了其在危机时刻提升沟通效率和包容性的有效作用，代表了灾难通信领域的重大进步。 <div>
arXiv:2411.08889v1 Announce Type: new 
Abstract: In disaster scenarios, effective communication is crucial, yet language barriers often hinder timely and accurate information dissemination, exacerbating vulnerabilities and complicating response efforts. This paper presents a novel, multilingual, voice-based social network specifically designed to address these challenges. The proposed system integrates advanced artificial intelligence (AI) with blockchain technology to enable secure, asynchronous voice communication across multiple languages. The application operates independently of external servers, ensuring reliability even in compromised environments by functioning offline through local networks. Key features include AI-driven real-time translation of voice messages, ensuring seamless cross-linguistic communication, and blockchain-enabled storage for secure, immutable records of all interactions, safeguarding message integrity. Designed for cross-platform use, the system offers consistent performance across devices, from mobile phones to desktops, making it highly adaptable in diverse disaster situations. Evaluation metrics demonstrate high accuracy in speech recognition and translation, low latency, and user satisfaction, validating the system's effectiveness in enhancing communication during crises. This solution represents a significant advancement in disaster communication, bridging language gaps to support more inclusive and efficient emergency response.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Designing Automated Market Makers for Combinatorial Securities: A Geometric Viewpoint</title>
<link>https://arxiv.org/abs/2411.08972</link>
<guid>https://arxiv.org/abs/2411.08972</guid>
<content:encoded><![CDATA[
<div> 关键词：automated market makers (AMMs)，prediction markets，combinatorial securities，VC dimension，range query problem

总结:
这篇文章提出了一种设计任意集系统中自动化做市商(AMMs)的框架，将预测市场的挑战与计算几何中的范围查询问题建立了新的联系。研究者展示了在流行的组合对数市场评分规则市场中，价格查询和交易更新等同于范围查询和范围更新问题，并基于此等价性，构建了当集合系统的VC维数有限时的次线性时间算法，并证明了在VC维数无限的情况下不存在此类算法。此外，他们还将这种方法扩展到了具有二次和幂次评分规则的组合预测市场的AMMs。文章还引入了去中心化金融中AMM的组合交换操作问题，并将其有效地归约为范围更新问题。最后，展示了多分辨率市场设计可以自然地融入到分区树方案中。 <div>
arXiv:2411.08972v1 Announce Type: new 
Abstract: Designing automated market makers (AMMs) for prediction markets on combinatorial securities over large outcome spaces poses significant computational challenges. Prior research has primarily focused on combinatorial prediction markets within specific set systems (e.g., intervals, permutations). We introduce a framework for designing AMMs on arbitrary set systems by building a novel connection to the range query problem in computational geometry. This connection enables the analysis of computational complexity and the design of efficient AMMs.
  We first demonstrate the equivalence between price queries and trade updates under the popular combinatorial logarithmic market scoring rule market and the range query and range update problem. Building on this equivalence, we construct sublinear time algorithms when the VC dimension of the set system is bounded and show the non-existence of such algorithms for unbounded VC dimension cases. We then extend this approach to AMMs for combinatorial prediction markets with quadratic and power scoring rules. Finally, we show that the multi-resolution market design can be naturally integrated into the partition-tree scheme.
  Additionally, we introduce the combinatorial swap operation problem for automated market makers in decentralized finance and show that it can be efficiently reduced to range update problems.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Information Need in Metaverse Recordings - A Field Study</title>
<link>https://arxiv.org/abs/2411.09053</link>
<guid>https://arxiv.org/abs/2411.09053</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse Recordings (MVRs)，Multimedia Information Retrieval (MMIR)，field study，information needs，search behaviors

<br /><br />总结:
该论文针对多媒体信息检索(MMIR)领域中新兴且未充分探索的媒体类型——元宇宙记录（MVRs）进行了研究。通过专家访谈和分析，本研究揭示了MVR检索的应用场景以及从元宇宙中检索多媒体内容所面临的挑战。研究结果表明，MVRs现有的应用场景强调了捕获图形渲染过程及相关输入输出设备的时间序列数据的重要性，这些数据对于满足用户需求具有高度相关性。此外，研究还为开发专门针对MVRs的检索系统定义了使用案例、用户画像以及具体要求，从而为MVR检索系统的未来研究与设计奠定了基础，进一步加深了对MVR检索中的信息搜索行为的理解。 <div>
arXiv:2411.09053v1 Announce Type: new 
Abstract: Metaverse Recordings (MVRs) represent an emerging and underexplored media type within the field of Multimedia Information Retrieval (MMIR). This paper presents findings from a field study aimed at understanding the users information needs and search behaviors specific to MVR retrieval. By conducting and analyzing expert interviews, the study identifies application scenarios and highlights challenges in retrieving multimedia content from the metaverse. The results reveal existing application scenarios of MVRs and confirm the relevance of capturing time-series data from the graphical rendering process and related input-output devices, which are also highly relevant to user needs. Furthermore, the study provides a foundation for developing retrieval systems tailored to MVRs by defining use cases, user stereotypes, and specific requirements for MVR Retrieval systems. The findings contribute to a better understanding of information search behaviors in MVR Retrieval and pave the way for future research and system design in this field.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartInv: Multimodal Learning for Smart Contract Invariant Inference</title>
<link>https://arxiv.org/abs/2411.09217</link>
<guid>https://arxiv.org/abs/2411.09217</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart合同、机器不可审计漏洞、智能合约不变量推理框架、多模态信息、零日漏洞

总结:<br />
本文介绍了针对智能合约中“机器不可审计”漏洞检测的新方法——SmartInv。该框架是一款准确快速的智能合约不变量推理工具，旨在通过理解并跨多种模态信息（如源代码和自然语言）进行推理来生成描述智能合约预期行为的不变量。研究提出了一种新的提示策略——层级思考（Tier of Thought, ToT），用于多模态智能合约的理解与推理。实验结果显示，SmartInv相比于现有最先进的工具能生成3.5倍更多的关键性bug不变量，并在显著缩短（150倍）的时间内发现4倍以上的严重漏洞。此外，SmartInv从89,621份真实世界的智能合约中发现了119个零日漏洞，其中五个已被开发者确认为“高危”级别的严重漏洞。 <div>
arXiv:2411.09217v1 Announce Type: new 
Abstract: Smart contracts are software programs that enable diverse business activities on the blockchain. Recent research has identified new classes of "machine un-auditable" bugs that arise from both transactional contexts and source code. Existing detection methods require human understanding of underlying transaction logic and manual reasoning across different sources of context (i.e. modalities), such as code, dynamic transaction executions, and natural language specifying the expected transaction behavior.
  To automate the detection of ``machine un-auditable'' bugs, we present SmartInv, an accurate and fast smart contract invariant inference framework. Our key insight is that the expected behavior of smart contracts, as specified by invariants, relies on understanding and reasoning across multimodal information, such as source code and natural language. We propose a new prompting strategy to foundation models, Tier of Thought (ToT), to reason across multiple modalities of smart contracts and ultimately to generate invariants. By checking the violation of these generated invariants, SmartInv can identify potential vulnerabilities.
  We evaluate SmartInv on real-world contracts and re-discover bugs that resulted in multi-million dollar losses over the past 2.5 years (from January 1, 2021 to May 31, 2023). Our extensive evaluation shows that SmartInv generates (3.5X) more bug-critical invariants and detects (4$\times$) more critical bugs compared to the state-of-the-art tools in significantly (150X) less time. \sys uncovers 119 zero-day vulnerabilities from the 89,621 real-world contracts. Among them, five are critical zero-day bugs confirmed by developers as ``high severity.''
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient and Secure Cross-Domain Data-Sharing for Resource-Constrained Internet of Things</title>
<link>https://arxiv.org/abs/2411.09229</link>
<guid>https://arxiv.org/abs/2411.09229</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网(IoT), 区块链, 数据共享, 分布式密钥生成, 安全性

总结:
<br />
本文针对物联网环境中日益复杂的跨域数据共享所面临的显著安全挑战，提出了一种基于区块链的高效、安全的数据共享方案。该方案采用分布式密钥生成方法，避免了单点故障，并实现了独立的伪名生成和密钥更新，从而提高了认证灵活性并降低了计算开销。此外，该方案还涵盖了数据上传、存储和分享的全过程，确保了数据可追溯性、完整性和隐私保护。通过安全分析，证实了该方案理论上具有安全性，并能抵抗多种攻击；性能评估显示其相比于现有解决方案具有更低的计算和通信开销，因此对于物联网应用而言，该方案既安全又高效。 <div>
arXiv:2411.09229v1 Announce Type: new 
Abstract: The growing complexity of Internet of Things (IoT) environments, particularly in cross-domain data sharing, presents significant security challenges. Existing data-sharing schemes often rely on computationally expensive cryptographic operations and centralized key management, limiting their effectiveness for resource-constrained devices. To address these issues, we propose an efficient, secure blockchain-based data-sharing scheme. First, our scheme adopts a distributed key generation method, which avoids single point of failure. This method also allows independent pseudonym generation and key updates, enhancing authentication flexibility while reducing computational overhead. Additionally, the scheme provides a complete data-sharing process, covering data uploading, storage, and sharing, while ensuring data traceability, integrity, and privacy. Security analysis shows that the proposed scheme is theoretically secure and resistant to various attacks, while performance evaluations demonstrate lower computational and communication overhead compared to existing solutions, making it both secure and efficient for IoT applications.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards efficient compression and communication for prototype-based decentralized learning</title>
<link>https://arxiv.org/abs/2411.09267</link>
<guid>https://arxiv.org/abs/2411.09267</guid>
<content:encoded><![CDATA[
<div> 关键词: prototype-based federated learning, decentralized learning, prototype redundancy, data compression, age-of-information (AoI)

总结:
<br />
本文研究了一种基于原型的去中心化联邦学习系统的设计，旨在提高通信效率。针对原型冗余问题，文章提出了双重数据压缩技术：仅当原型具有信息论上的有用性（通过Jensen-Shannon距离判断）时发送更新消息，并利用聚类对原型进行压缩以减小 gossip 协议中的更新消息大小。此外，文中采用了并行而非序列化的 gossip 通信，并分析了其年龄信息（AoI）。实验结果显示，通过这些改进，可以在不降低学习算法收敛速度的前提下显著减少通信负载。 <div>
arXiv:2411.09267v1 Announce Type: new 
Abstract: In prototype-based federated learning, the exchange of model parameters between clients and the master server is replaced by transmission of prototypes or quantized versions of the data samples to the aggregation server. A fully decentralized deployment of prototype- based learning, without a central agregartor of prototypes, is more robust upon network failures and reacts faster to changes in the statistical distribution of the data, suggesting potential advantages and quick adaptation in dynamic learning tasks, e.g., when the data sources are IoT devices or when data is non-iid. In this paper, we consider the problem of designing a communication-efficient decentralized learning system based on prototypes. We address the challenge of prototype redundancy by leveraging on a twofold data compression technique, i.e., sending only update messages if the prototypes are informationtheoretically useful (via the Jensen-Shannon distance), and using clustering on the prototypes to compress the update messages used in the gossip protocol. We also use parallel instead of sequential gossiping, and present an analysis of its age-of-information (AoI). Our experimental results show that, with these improvements, the communications load can be substantially reduced without decreasing the convergence rate of the learning algorithm.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fully Local Last-Generated Rule in a Blockchain</title>
<link>https://arxiv.org/abs/2411.08439</link>
<guid>https://arxiv.org/abs/2411.08439</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、故意分叉、最后生成规则、局部应用、诚实矿工

总结:
本文提出了一种针对区块链中故意分叉的有效抑制方法——局部可应用的最后生成规则。该规则在发生链并列时选择最近生成的链作为主链，有助于使敌人持有的区块无效。与现有局部方法相比，新方法通过将时钟偏移量$\Delta_{O_i}$的上限设定为200秒，能将诚实矿工在链并列情况下跟随攻击者的情况减少超过40%。这一创新设计更好地满足了保守型加密货币系统（如比特币）对于完全局部化方法的需求。 <div>
arXiv:2411.08439v1 Announce Type: new 
Abstract: An effective method for suppressing intentional forks in a blockchain is the last-generated rule, which selects the most recent chain as the main chain in the event of a chain tie. This rule helps invalidate blocks that are withheld by adversaries for a certain period. However, existing last-generated rules face an issue in that their applications to the system are not fully localized. In conservative cryptocurrency systems such as Bitcoin, it is desirable for methods to be applied in a fully local manner. In this paper, we propose a locally applicable last-generated rule. Our method is straightforward and is based on a relative time reference. By conservatively setting the upper bound for the clock skews $\Delta_{O_i}$ to 200 s, our proposed method reduces the proportion $\gamma$ of honest miners following the attacker during chain ties by more than 40% compared to existing local methods.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats and Promising Technical Solutions using LLMs</title>
<link>https://arxiv.org/abs/2411.08640</link>
<guid>https://arxiv.org/abs/2411.08640</guid>
<content:encoded><![CDATA[
<div> 关键词: O-RAN、安全分析、零信任、移动目标防御(MTD)、区块链、大型语言模型(LLM)、深度强化学习、网络切片、可解释人工智能(XAI)

<br /><br />总结:
本文深入分析了开放无线接入网(O-RAN)架构的安全性，探讨了不同O-RAN层次可能面临的潜在威胁及其对保密性、完整性和可用性(CIA)三元组的影响。文章提出零信任、移动目标防御(MTD)、区块链和大型语言模型(LLM)技术可用于增强O-RAN的安全态势。此外，文中通过数值演示展示了MTD如何赋能动态网络切片接纳控制中的鲁棒深度强化学习方法。同时，文章还研究了基于LLM的可解释人工智能(XAI)在保障系统安全性方面的作用。 <div>
arXiv:2411.08640v1 Announce Type: new 
Abstract: The evolution of wireless communication systems will be fundamentally impacted by an open radio access network (O-RAN), a new concept defining an intelligent architecture with enhanced flexibility, openness, and the ability to slice services more efficiently. For all its promises, and like any technological advancement, O-RAN is not without risks that need to be carefully assessed and properly addressed to accelerate its wide adoption in future mobile networks. In this paper, we present an in-depth security analysis of the O-RAN architecture, discussing the potential threats that may arise in the different O-RAN architecture layers and their impact on the Confidentiality, Integrity, and Availability (CIA) triad. We also promote the potential of zero trust, Moving Target Defense (MTD), blockchain, and large language models(LLM) technologies in fortifying O-RAN's security posture. Furthermore, we numerically demonstrate the effectiveness of MTD in empowering robust deep reinforcement learning methods for dynamic network slice admission control in the O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI) based on LLMs in securing the system.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking negative sampling in content-based news recommendation</title>
<link>https://arxiv.org/abs/2411.08700</link>
<guid>https://arxiv.org/abs/2411.08700</guid>
<content:encoded><![CDATA[
<div> 关键词: news recommender systems, relevance decay, neural techniques, negative sampling, decentralization

<br /><br />总结:
本文探讨了新闻推荐系统因文章时效性短暂导致的相关性衰减问题。研究发现，内容基神经技术对此有所助益，但现有模型复杂且对负例处理不足。为此，文中提出了一个新的负例采样技术，该技术能提升模型准确性并有利于推荐系统的去中心化。实验使用MIND数据集证明了所提方法的精度可与最先进的模型相媲美。此外，这种采样技术有助于降低模型复杂度、加速训练过程，并保持高精度。最后，文章还讨论了去中心化模型如何改善隐私性和可扩展性。 <div>
arXiv:2411.08700v1 Announce Type: new 
Abstract: News recommender systems are hindered by the brief lifespan of articles, as they undergo rapid relevance decay. Recent studies have demonstrated the potential of content-based neural techniques in tackling this problem. However, these models often involve complex neural architectures and often lack consideration for negative examples. In this study, we posit that the careful sampling of negative examples has a big impact on the model's outcome. We devise a negative sampling technique that not only improves the accuracy of the model but also facilitates the decentralization of the recommendation system. The experimental results obtained using the MIND dataset demonstrate that the accuracy of the method under consideration can compete with that of State-of-the-Art models. The utilization of the sampling technique is essential in reducing model complexity and accelerating the training process, while maintaining a high level of accuracy. Finally, we discuss how decentralized models can help improve privacy and scalability.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication Efficient Decentralization for Smoothed Online Convex Optimization</title>
<link>https://arxiv.org/abs/2411.08355</link>
<guid>https://arxiv.org/abs/2411.08355</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体、光滑在线凸优化、分布式算法、异步通信图、计算复杂度

总结:
本文研究了多智能体光滑在线凸优化（SOCO）问题，其中$N$个智能体通过通信图进行交互。每个轮次中，每个智能体$i$会以在线方式接收到强凸击打成本函数$f^i_t$并选择动作$x^i_t\in\mathbb{R}^d$。目标是最小化全局累积成本，包括个体击打成本之和、决策变化的“切换成本”以及相邻智能体决策偏离的“不相似性成本”。文章首次提出了一个多智能体SOOC的分布式算法并证明其渐近最优性。该算法允许每个智能体仅利用与其直接邻接节点的信息进行操作。对于有限时间性能，文章证明了竞争比的优值差随时间序列$T$减小，并可以根据每个智能体每轮可利用的计算资源进行便捷调整。此外，即使通信图可以随时间任意和自适应地改变，该方法仍然有效。最后，文章表明每轮的计算复杂度仅与智能体数量对数相关且几乎线性依赖于它们在图中的度数，确保了大系统实施的可扩展性。<br /><br /> <div>
arXiv:2411.08355v1 Announce Type: cross 
Abstract: We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where $N$ agents interact through a communication graph. In each round, each agent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online fashion and selects an action $x^i_t \in \mathbb{R}^d$. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs $f^i_t(x^i_t)$, a temporal "switching cost" for changing decisions, and a spatial "dissimilarity cost" that penalizes deviations in decisions among neighboring agents. We propose the first decentralized algorithm for multi-agent SOCO and prove its asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in competitive ratio decreases with the time horizon $T$ and can be conveniently tuned based on the per-round computation available to each agent. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, we establish that the computational complexity per round depends only logarithmically on the number of agents and almost linearly on their degree within the graph, ensuring scalability for large-system implementations.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Merit-Based Sortition in Decentralized Systems</title>
<link>https://arxiv.org/abs/2411.07302</link>
<guid>https://arxiv.org/abs/2411.07302</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized systems、sortition、performance optimization、merit-based sortition、infinite chances

总结:<br />
本文提出了一个针对分布式系统中参与者选择问题的“基于绩效的排序”（merit-based sortition）算法。该算法旨在优化计算限制或资源效率的同时，确保选出的活跃子集既具有高性能又保持代表性。与古典随机抽签相比，此算法允许每个参与者的入选概率与其质量相关联，而未被选中的参与者仍有无限次非零概率进入活跃集合，从而保证了向上流动性。通过数值实验，文章表明基于绩效的排序算法可以使活跃子集的性能指标提升超过两倍内在随机性的水平，这意味着该方法能够在显著提高表现性能的同时，满足分布式系统对于性能优化的需求。 <div>
arXiv:2411.07302v1 Announce Type: new 
Abstract: In decentralized systems, it is often necessary to select an 'active' subset of participants from the total participant pool, with the goal of satisfying computational limitations or optimizing resource efficiency. This selection can sometimes be made at random, mirroring the sortition practice invented in classical antiquity aimed at achieving a high degree of statistical representativeness. However, the recent emergence of specialized decentralized networks that solve concrete coordination problems and are characterized by measurable success metrics often requires prioritizing performance optimization over representativeness. We introduce a simple algorithm for 'merit-based sortition', in which the quality of each participant influences its probability of being drafted into the active set, while simultaneously retaining representativeness by allowing inactive participants an infinite number of chances to be drafted into the active set with non-zero probability. Using a suite of numerical experiments, we demonstrate that our algorithm boosts the quality metric describing the performance of the active set by $>2$ times the intrinsic stochasticity. This implies that merit-based sortition ensures a statistically significant performance boost to the drafted, 'active' set, while retaining the property of classical, random sortition that it enables upward mobility from a much larger 'inactive' set. This way, merit-based sortition fulfils a key requirement for decentralized systems in need of performance optimization.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Zoning of Industrial Environments with Autonomous Mobile Robots</title>
<link>https://arxiv.org/abs/2411.07382</link>
<guid>https://arxiv.org/abs/2411.07382</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主移动机器人(AMR), 分区调度算法, 均衡任务分配, 动态分区算法, 德分布式动态分区(DTZ)

<br /><br />总结:

本文提出了一种应用于制造/仓库环境中的自主移动机器人(AMR)调度算法，该算法将工作区域划分为若干个由AMR负责执行零件捡取和投放任务的分区。每个分区的任务量得到均衡分配，以确保每台AMR平等地承担任务，并能随生产波动动态调整分区布局，避免单一AMR过载。文章引入了分布式动态分区(DDZ)算法，旨在找到最优分区设计并消除中央控制单元单点故障的可能性。通过建立仿真模型对比分析了DDZ与其他动态分区算法的适应性，初步结果显示虽然DDZ的吞吐量较低，但其任务分布更为均匀。AMR总行驶距离的标准偏差降低了68.7%，即DDZ下的AMR在生产过程中行驶距离更接近，有利于现实中设计充电和维护计划，减少停机时间。文章还提供了系统运行的视频演示链接。 <div>
arXiv:2411.07382v1 Announce Type: new 
Abstract: This paper presents a scheduling algorithm that divides a manufacturing/warehouse floor into zones that an Autonomous Mobile Robot (AMR) will occupy and complete part pick-up and drop-off tasks. Each zone is balanced so that each AMR will share each task equally. These zones change over time to accommodate fluctuations in production and to avoid overloading an AMR with tasks. A decentralized dynamic zoning (DDZ) algorithm is introduced to find the optimal zone design, eliminating the possibility of single-point failure from a centralized unit. Then a simulation is built comparing the adaptability of DDZ and other dynamic zoning algorithms from previous works. Initial results show that DDZ has a much lower throughput than other dynamic zoning algorithms but DDZ can achieve a better distribution of tasks. Initial results show that DDZ had a lower standard deviation of AMR total travel distance which was 2874.7 feet less than previous works. This 68.7\% decrease in standard deviation suggests that AMRs under DDZ travel a similar distance during production. This could be useful for real-world applications by making it easier to design charging and maintenance schedules without much downtime. Video demonstration of the system working can be seen here: \url{https://youtu.be/yVi026oVD7U}
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning Client Pruning for Noisy Labels</title>
<link>https://arxiv.org/abs/2411.07391</link>
<guid>https://arxiv.org/abs/2411.07391</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Noisy Labels, ClipFL, Noise Candidacy Score, Performance Improvement

<br /><br />总结:
本文提出了一个新的Federated Learning框架——ClipFL，该框架针对边缘设备训练中存在的噪声标签问题。现有FL方法在处理高噪声水平的数据集时表现有限，而ClipFL通过引入噪声候选分数（NCS）来识别并排除具有噪声数据的客户端。它分为三个阶段：预客户端修剪以识别潜在噪声客户端并计算其NCS，客户端修剪则根据NCS排除一定比例的噪声客户端，以及后客户端修剪阶段，使用标准FL对干净客户端进行全局模型的微调。实验表明，ClipFL在各种数据集和噪声水平下都表现出准确的噪声客户端识别能力、更优的性能、更快的收敛速度以及更低的通信成本，相较于当前最先进的FL方法有显著优势。相关代码已在https://github.com/MMorafah/ClipFL上开源。 <div>
arXiv:2411.07391v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, existing FL methods often assume clean annotated datasets, impractical for resource-constrained edge devices. In reality, noisy labels are prevalent, posing significant challenges to FL performance. Prior approaches attempt label correction and robust training techniques but exhibit limited efficacy, particularly under high noise levels. This paper introduces ClipFL (Federated Learning Client Pruning), a novel framework addressing noisy labels from a fresh perspective. ClipFL identifies and excludes noisy clients based on their performance on a clean validation dataset, tracked using a Noise Candidacy Score (NCS). The framework comprises three phases: pre-client pruning to identify potential noisy clients and calculate their NCS, client pruning to exclude a percentage of clients with the highest NCS, and post-client pruning for fine-tuning the global model with standard FL on clean clients. Empirical evaluation demonstrates ClipFL's efficacy across diverse datasets and noise levels, achieving accurate noisy client identification, superior performance, faster convergence, and reduced communication costs compared to state-of-the-art FL methods. Our code is available at https://github.com/MMorafah/ClipFL.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Network Topology Design for Task Offloading in Mobile Edge Computing</title>
<link>https://arxiv.org/abs/2411.07485</link>
<guid>https://arxiv.org/abs/2411.07485</guid>
<content:encoded><![CDATA[
<div> 关键词：移动边缘计算(MEC)，网络拓扑设计，任务卸载，分布式，效率优化

总结:
本文探讨了物联网设备处理能力有限背景下，延迟敏感且计算密集型应用带来的挑战，并指出移动边缘计算（MEC）为此类问题提供了一种有前景的解决方案。然而，针对MEC的网络拓扑优化以提升计算效率的研究尚不充分。文章提出了一种新颖的、用于任务卸载的分布式网络拓扑设计策略（DNTD-TO），该策略同时考虑了拓扑设计与任务分配，并借鉴通信和传感器网络的经验，有效地构建了三层网络结构用于任务卸载，并为这些结构生成最优的任务分配方案。研究表明，相较于现有拓扑设计方法，DNTD-TO展现出了优越的性能表现。 <div>
arXiv:2411.07485v1 Announce Type: new 
Abstract: The rise of delay-sensitive yet computing-intensive Internet of Things (IoT) applications poses challenges due to the limited processing power of IoT devices. Mobile Edge Computing (MEC) offers a promising solution to address these challenges by placing computing servers close to end users. Despite extensive research on MEC, optimizing network topology to improve computational efficiency remains underexplored. Recognizing the critical role of network topology, we introduce a novel decentralized network topology design strategy for task offloading (DNTD-TO) that jointly considers topology design and task allocation. Inspired by communication and sensor networks, DNTD-TO efficiently constructs three-layered network structures for task offloading and generates optimal task allocations for these structures. Comparisons with existing topology design methods demonstrate the promising performance of our approach.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semantic Sleuth: Identifying Ponzi Contracts via Large Language Models</title>
<link>https://arxiv.org/abs/2411.07498</link>
<guid>https://arxiv.org/abs/2411.07498</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、庞氏骗局、PonziGuard、PonziSleuth、LLM

总结:
本文介绍了智能合约在区块链技术特别是去中心化金融和Web3中的重要性，但庞氏骗局的兴起对这一领域构成重大风险。现有的检测方法如PonziGuard依赖大量标注数据，难以识别新型庞氏骗局。为解决此问题，文章提出了一种新的无标注训练数据驱动的庞氏骗局智能合约检测方法——PonziSleuth。该方法利用大型语言模型（LLMs）的高级语义理解能力，通过创新的两步零样本思考提示技术分析智能合约源代码。实验结果显示，PonziSleuth在基准数据集和实际合约上的表现与现有方法相当或更优，例如使用GPT-3.5-turbo时平衡检测准确率达到96.06%。在真实环境检测中，PonziSleuth成功从Etherscan于2024年3月验证的4,597份合同中识别出15个新型庞氏骗局，具有0%的假阴性和0.29%的假阳性率，证实了其对多样化和新型庞氏骗局的检测能力，标志着利用LLMs增强区块链安全和防范金融欺诈的重要进步。 <div>
arXiv:2411.07498v1 Announce Type: new 
Abstract: Smart contracts, self-executing agreements directly encoded in code, are fundamental to blockchain technology, especially in decentralized finance (DeFi) and Web3. However, the rise of Ponzi schemes in smart contracts poses significant risks, leading to substantial financial losses and eroding trust in blockchain systems. Existing detection methods, such as PonziGuard, depend on large amounts of labeled data and struggle to identify unseen Ponzi schemes, limiting their reliability and generalizability. In contrast, we introduce PonziSleuth, the first LLM-driven approach for detecting Ponzi smart contracts, which requires no labeled training data. PonziSleuth utilizes advanced language understanding capabilities of LLMs to analyze smart contract source code through a novel two-step zero-shot chain-of-thought prompting technique. Our extensive evaluation on benchmark datasets and real-world contracts demonstrates that PonziSleuth delivers comparable, and often superior, performance without the extensive data requirements, achieving a balanced detection accuracy of 96.06% with GPT-3.5-turbo, 93.91% with LLAMA3, and 94.27% with Mistral. In real-world detection, PonziSleuth successfully identified 15 new Ponzi schemes from 4,597 contracts verified by Etherscan in March 2024, with a false negative rate of 0% and a false positive rate of 0.29%. These results highlight PonziSleuth's capability to detect diverse and novel Ponzi schemes, marking a significant advancement in leveraging LLMs for enhancing blockchain security and mitigating financial scams.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Performance Analysis of BFT Consensus for Blockchains</title>
<link>https://arxiv.org/abs/2411.07622</link>
<guid>https://arxiv.org/abs/2411.07622</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本、区块链、共识协议、BFT、Istanbul BFT、HotStuff、网络拓扑、 Folded-Clos、Dragonfly、定时器、分析模型、一致性时间

<br /><br />总结:
该文探讨了分布式账本中使用区块链作为底层基础设施的情况，并重点关注两种共识协议（Istanbul BFT和HotStuff）以及两种网络拓扑结构（Folded-Clos和Dragonfly）。文章提出了一种针对崩溃故障情况的分析模型，旨在研究不同共识协议在性能上的差异以及通信网络对其影响。此外，还讨论了共识协议中如何设置定时器以确保进程推进的问题。通过建立闭合形式的表达式，分析了定时器值、参与者数量、故障数和交换机数目对达成一致所需时间的影响。这些公式与仿真结果进行了验证，最后文中给出了一些此类协议分析建模的建议。 <div>
arXiv:2411.07622v1 Announce Type: new 
Abstract: Distributed ledgers are common in the industry. Some of them can use blockchains as their underlying infrastructure. A blockchain requires participants to agree on its contents. This can be achieved via a consensus protocol, and several BFT (Byzantine Fault Tolerant) protocols have been proposed for this purpose. How do these protocols differ in performance? And how is this difference affected by the communication network? Moreover, such a protocol would need a timer to ensure progress, but how should the timer be set?
  This paper presents an analytical model to address these and related issues in the case of crash faults. Specifically, it focuses on two consensus protocols (Istanbul BFT and HotStuff) and two network topologies (Folded-Clos and Dragonfly). The model provides closed-form expressions for analyzing how the timer value and number of participants, faults and switches affect the consensus time. The formulas and analyses are validated with simulations. The conclusion offers some tips for analytical modeling of such protocols.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoliDiffy: AST Differencing for Solidity Smart Contracts</title>
<link>https://arxiv.org/abs/2411.07718</link>
<guid>https://arxiv.org/abs/2411.07718</guid>
<content:encoded><![CDATA[
<div> 关键词: Solidity、智能合约、抽象语法树(AST)、差异分析、SoliDiffy

总结:
本文介绍了SoliDiffy，这是一种专为Solidity智能合约设计的新颖的抽象语法树(AST)差异工具。SoliDiffy能够生成准确且简洁的编辑脚本，从而实现对智能合约的细粒度分析和维护，适用于漏洞检测、自动化代码修复以及代码审查等下游任务。通过对大量真实世界的Solidity合同进行综合评估，结果显示SoliDiffy相比于现有最先进的工具能提供更短且更精确的编辑脚本，并在处理复杂的合同修改时表现出一致性。SoliDiffy已在https://github.com/mojtaba-eshghie/SoliDiffy上公开发布。 <div>
arXiv:2411.07718v1 Announce Type: new 
Abstract: Smart contracts, primarily written in Solidity, are integral to blockchain software applications, yet precise analysis and maintenance are hindered by the limitations of existing differencing tools. We introduce SoliDiffy, a novel Abstract Syntax Tree (AST) differencing tool specifically designed for Solidity. SoliDiffy enables fine-grained analysis by generating accurate and concise edit scripts of smart contracts, making it ideal for downstream tasks such as vulnerability detection, automated code repair, and code reviews. Our comprehensive evaluation on a large dataset of real-world Solidity contracts demonstrates that SoliDiffy delivers shorter and more precise edit scripts compared to state-of-the-art tools, while performing consistently in complex contract modifications. SoliDiffy is made publicly available at https://github.com/mojtaba-eshghie/SoliDiffy.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ALANINE: A Novel Decentralized Personalized Federated Learning For Heterogeneous LEO Satellite Constellation</title>
<link>https://arxiv.org/abs/2411.07752</link>
<guid>https://arxiv.org/abs/2411.07752</guid>
<content:encoded><![CDATA[
<div> 关键词：低地球轨道卫星星座、数据异质性、联邦学习、模型压缩、图像超分辨率

总结:<br />
针对近年来低地球轨道(LEO)卫星星座在通信、导航和遥感等领域功能增强所面临的挑战，尤其是数据异质性及有效进行星际协同计算的问题，本文提出了一种名为ALANINE的新颖分布式个性化联邦学习框架。ALANINE利用分布式联邦学习(DFL)对卫星图像进行超分辨率处理，提升输入数据质量；再结合个性化联邦学习(PFL)，以适应卫星数据的独特特性。同时，该框架采用高级模型压缩技术优化模型复杂度和传输效率。实验结果表明，相较于传统的集中式方法，ALANINE在轨训练图像超分辨率及PFL图像处理模型方面表现出更优性能，显著提高了数据采集效率、处理精度以及模型对局部卫星条件的适应性。 <div>
arXiv:2411.07752v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite constellations have seen significant growth and functional enhancement in recent years, which integrates various capabilities like communication, navigation, and remote sensing. However, the heterogeneity of data collected by different satellites and the problems of efficient inter-satellite collaborative computation pose significant obstacles to realizing the potential of these constellations. Existing approaches struggle with data heterogeneity, varing image resolutions, and the need for efficient on-orbit model training. To address these challenges, we propose a novel decentralized PFL framework, namely, A Novel Decentra L ized Person A lized Federated Learning for Heteroge N eous LEO Satell I te Co N st E llation (ALANINE). ALANINE incorporates decentralized FL (DFL) for satellite image Super Resolution (SR), which enhances input data quality. Then it utilizes PFL to implement a personalized approach that accounts for unique characteristics of satellite data. In addition, the framework employs advanced model pruning to optimize model complexity and transmission efficiency. The framework enables efficient data acquisition and processing while improving the accuracy of PFL image processing models. Simulation results demonstrate that ALANINE exhibits superior performance in on-orbit training of SR and PFL image processing models compared to traditional centralized approaches. This novel method shows significant improvements in data acquisition efficiency, process accuracy, and model adaptability to local satellite conditions.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enabling Data Confidentiality with Public Blockchains</title>
<link>https://arxiv.org/abs/2308.03791</link>
<guid>https://arxiv.org/abs/2308.03791</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、自动化、多党合作、隐私保护、MARTSIA

<br /><br />总结:
本文提出了一个名为MARTSIA的多权威交易系统方法，用于实现不同应用间的互操作性。该方法基于Multi-Authority Attribute-Based Encryption（MA-ABE），解决了公共区块链中数据透明度与企业保密要求之间的矛盾，通过用户定义的策略控制对共享数据的部分访问权限，仅允许具有特定属性的参与者解读加密信息，同时确保网络中所有节点能验证数据的发布。文章对MARTSIA的安全性进行了形式化分析，并在多个区块链平台上实现了概念证明。为了展示其实现多 party 过程执行和跨平台互操作性的能力，文中还以NFT市场、供应链和零售领域的三个实际应用场景为例进行了演示。 <div>
arXiv:2308.03791v5 Announce Type: replace 
Abstract: Blockchain technology is apt to facilitate the automation of multi-party cooperations among various players in a decentralized setting, especially in cases where trust among participants is limited. Transactions are stored in a ledger, a replica of which is retained by every node of the blockchain network. The operations saved thereby are thus publicly accessible. While this aspect enhances transparency, reliability, and persistence, it hinders the utilization of public blockchains for process automation as it violates typical confidentiality requirements in corporate settings. To overcome this issue, we propose our approach named Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA). Based on Multi-Authority Attribute-Based Encryption (MA-ABE), MARTSIA enables read-access control over shared data at the level of message parts. User-defined policies determine whether an actor can interpret the publicly stored information or not, depending on the actor's attributes declared by a consortium of certifiers. Still, all nodes in the blockchain network can attest to the publication of the (encrypted) data. We provide a formal analysis of the security guarantees of MARTSIA, and illustrate the proof-of-concept implementation over multiple blockchain platforms. To demonstrate its interoperability, we showcase its usage in ensemble with a state-of-the-art blockchain-based engine for multi-party process execution, and three real-world decentralized applications in the context of NFT markets, supply chain, and retail.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers</title>
<link>https://arxiv.org/abs/2411.06135</link>
<guid>https://arxiv.org/abs/2411.06135</guid>
<content:encoded><![CDATA[
<div> 关键词：在线多任务学习(OMTL)，梯度下降法，交替方向乘子法(ADMM)，分布式计算，数据规模

总结:
本文提出了一种基于交替方向乘子方法(ADMM)的新型在线多任务学习(OMTL)框架，旨在解决现有梯度下降法在OMTL中可能遇到的梯度消失和条件恶化问题，并适应在线并行优化的需求。该框架动态建模多个任务之间的关系，以适应不断变化的在线环境。在具有中央服务器的经典分布式计算架构下，利用ADMM优化器的OMTL算法在准确性和效率上优于基于SGD的方法。为进一步应对大数据场景下的中央服务器瓶颈问题，文章还针对去中心化设置调整了算法，使得每个节点仅需与其局部邻居交换信息即可工作。实验证实在合成数据集及几个真实世界数据集上的实验结果表明了所提方法的有效性。 <div>
arXiv:2411.06135v1 Announce Type: new 
Abstract: Online multi-task learning (OMTL) enhances streaming data processing by leveraging the inherent relations among multiple tasks. It can be described as an optimization problem in which a single loss function is defined for multiple tasks. Existing gradient-descent-based methods for this problem might suffer from gradient vanishing and poor conditioning issues. Furthermore, the centralized setting hinders their application to online parallel optimization, which is vital to big data analytics. Therefore, this study proposes a novel OMTL framework based on the alternating direction multiplier method (ADMM), a recent breakthrough in optimization suitable for the distributed computing environment because of its decomposable and easy-to-implement nature. The relations among multiple tasks are modeled dynamically to fit the constant changes in an online scenario. In a classical distributed computing architecture with a central server, the proposed OMTL algorithm with the ADMM optimizer outperforms SGD-based approaches in terms of accuracy and efficiency. Because the central server might become a bottleneck when the data scale grows, we further tailor the algorithm to a decentralized setting, so that each node can work by only exchanging information with local neighbors. Experimental results on a synthetic and several real-world datasets demonstrate the efficiency of our methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Sharded Blockchain-Based Secure Federated Learning Framework for LEO Satellite Networks</title>
<link>https://arxiv.org/abs/2411.06137</link>
<guid>https://arxiv.org/abs/2411.06137</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)，卫星网络，人工智能，网络安全，区块链，联邦学习，SBFL-LEO，模型验证，攻击防御

总结:<br />
随着低地球轨道(LEO)卫星网络在空间人工智能应用中的重要性日益增强，其面临来自卫星间通信链接的网络安全风险也随之增加。传统解决方案无法有效应对有限通信窗口条件下的安全挑战。为此，本文提出了基于分片区块链的LEO卫星网络联邦学习框架SBFL-LEO。该框架利用区块链技术强化卫星间的通信可靠性，并为每颗卫星分配特定角色。矿工卫星通过余弦相似性和DBSCAN算法识别恶意模型并互相监控，以检测不准确的聚合模型。安全分析和实验结果显示，与基线方法相比，SBFL-LEO在模型精度和能效方面表现出优越性能，显著提升了系统对抗攻击的鲁棒性。 <div>
arXiv:2411.06137v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite networks are increasingly essential for space-based artificial intelligence (AI) applications. However, as commercial use expands, LEO satellite networks face heightened cyberattack risks, especially through satellite-to-satellite communication links, which are more vulnerable than ground-based connections. As the number of operational satellites continues to grow, addressing these security challenges becomes increasingly critical. Traditional approaches, which focus on sending models to ground stations for validation, often overlook the limited communication windows available to LEO satellites, leaving critical security risks unaddressed. To tackle these challenges, we propose a sharded blockchain-based federated learning framework for LEO networks, called SBFL-LEO. This framework improves the reliability of inter-satellite communications using blockchain technology and assigns specific roles to each satellite. Miner satellites leverage cosine similarity (CS) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to identify malicious models and monitor each other to detect inaccurate aggregated models. Security analysis and experimental results demonstrate that our approach outperforms baseline methods in both model accuracy and energy efficiency, significantly enhancing system robustness against attacks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BM-PAW: A Profitable Mining Attack in the PoW-based Blockchain System</title>
<link>https://arxiv.org/abs/2411.06187</link>
<guid>https://arxiv.org/abs/2411.06187</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、PoW、挖矿攻击、BM-PAW、对策

总结:
<br />
本文介绍了针对PoW区块链系统的新型挖矿策略——BM-PAW，该策略允许攻击者和目标矿池获得比现有最先进的挖矿攻击（PAW）更大的收益。通过分析，发现BM-PAW攻击者有动力向其他目标提供适当的贿赂，以使这些目标遵循其指令。进一步研究了在两池BM-PAW博弈场景中，攻击者如何通过其挖矿算力来规避“矿工困境”的均衡分析。最后，文章提出了应对这类新型矿池攻击的实际对策。 <div>
arXiv:2411.06187v1 Announce Type: new 
Abstract: Mining attacks enable an adversary to procure a disproportionately large portion of mining rewards by deviating from honest mining practices within the PoW-based blockchain system. In this paper, we demonstrate that the security vulnerabilities of PoW-based blockchain extend beyond what these mining attacks initially reveal. We introduce a novel mining strategy, named BM-PAW, which yields superior rewards for both the attacker and the targeted pool compared to the state-of-the-art mining attack: PAW. Our analysis reveals that BM-PAW attackers are incentivized to offer appropriate bribe money to other targets, as they comply with the attacker's directives upon receiving payment. We find the BM-PAW attacker can circumvent the "miner's dilemma" through equilibrium analysis in a two-pool BM-PAW game scenario, wherein the outcome is determined by the attacker's mining power. We finally propose practical countermeasures to mitigate these novel pool attacks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation</title>
<link>https://arxiv.org/abs/2411.06221</link>
<guid>https://arxiv.org/abs/2411.06221</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、智能合约、安全挑战、LLM、Smart-LLaMA

总结:
随着区块链技术的迅速发展，智能合约安全性成为一个重大挑战。现有智能合约漏洞检测方法面临三大问题：数据集质量不足，缺乏详细解释和精确漏洞位置信息；大型语言模型（LLMs）对智能合约领域的适应性有限，因为大多数LLMs仅在通用文本数据上预训练而缺少智能合约特定的数据；对于检测到的漏洞缺乏高质量的解释，现有方法只关注检测而非清晰解释。为解决这些问题，文章提出了基于LLaMA语言模型的高级检测方法Smart-LLaMA。首先，构建了一个涵盖四种漏洞类型的全面数据集，其中包含标签、详细解释及精确漏洞位置信息。其次，引入了针对智能合约的专业持续预训练，使用原始智能合约数据使LLM能够学习智能合约的语法和语义，提升其领域适应性。此外，还提出了解释引导的微调方法，通过成对的脆弱代码及其解释对LLM进行微调，实现既检测漏洞又给出有理有据的解释。实验结果显示，Smart-LLaMA在性能上优于当前最优基线，F1分数和准确率平均分别提高了6.49%和3.78%，同时提供了可靠的解释。 <div>
arXiv:2411.06221v1 Announce Type: new 
Abstract: With the rapid development of blockchain technology, smart contract security has become a critical challenge. Existing smart contract vulnerability detection methods face three main issues: (1) Insufficient quality of datasets, lacking detailed explanations and precise vulnerability locations. (2) Limited adaptability of large language models (LLMs) to the smart contract domain, as most LLMs are pre-trained on general text data but minimal smart contract-specific data. (3) Lack of high-quality explanations for detected vulnerabilities, as existing methods focus solely on detection without clear explanations. These limitations hinder detection performance and make it harder for developers to understand and fix vulnerabilities quickly, potentially leading to severe financial losses. To address these problems, we propose Smart-LLaMA, an advanced detection method based on the LLaMA language model. First, we construct a comprehensive dataset covering four vulnerability types with labels, detailed explanations, and precise vulnerability locations. Second, we introduce Smart Contract-Specific Continual Pre-Training, using raw smart contract data to enable the LLM to learn smart contract syntax and semantics, enhancing their domain adaptability. Furthermore, we propose Explanation-Guided Fine-Tuning, which fine-tunes the LLM using paired vulnerable code and explanations, enabling both vulnerability detection and reasoned explanations. We evaluate explanation quality through LLM and human evaluation, focusing on Correctness, Completeness, and Conciseness. Experimental results show that Smart-LLaMA outperforms state-of-the-art baselines, with average improvements of 6.49% in F1 score and 3.78% in accuracy, while providing reliable explanations.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Client Contribution Normalization for Enhanced Federated Learning</title>
<link>https://arxiv.org/abs/2411.06352</link>
<guid>https://arxiv.org/abs/2411.06352</guid>
<content:encoded><![CDATA[
<div> 关键词：移动设备、联邦学习（FL）、统计异质性、局部模型、均值潜表示归一化

<br /><br />总结:
本文针对移动设备产生的分散异构数据带来的挑战，重点研究了联邦学习（FL）中的统计异质性问题。为了解决非独立同分布（non-IID）数据对FL模型收敛性和性能的影响，文章提出了一种新颖的方法，该方法利用本地训练模型导出的均值潜表示进行归一化，使服务器能够在聚合过程中估计和调整客户端贡献的差异。这一归一化策略能提升全局模型的泛化能力并缓解传统联邦平均方法的局限性。主要贡献包括：引入基于均值潜表示的归一化方案处理FL中的统计异质性；展示该方法与现有FL算法的无缝集成，可在非-IID设置中提高性能；并通过在多个多样化数据集上的广泛实验验证了该方法，结果表明在数据分布偏斜的情况下，模型准确性和一致性有显著提升。实验还涉及FedAvg、FedProx、FedBABU、FedNova、SCAFFOLD及SGDM等六种FL方案，突显了所提方法的鲁棒性。该研究通过提供一种实用且计算效率高的解决方案，推动了FL应对统计异质性的能力，有助于构建更可靠和泛化的机器学习模型。 <div>
arXiv:2411.06352v1 Announce Type: new 
Abstract: Mobile devices, including smartphones and laptops, generate decentralized and heterogeneous data, presenting significant challenges for traditional centralized machine learning models due to substantial communication costs and privacy risks. Federated Learning (FL) offers a promising alternative by enabling collaborative training of a global model across decentralized devices without data sharing. However, FL faces challenges due to statistical heterogeneity among clients, where non-independent and identically distributed (non-IID) data impedes model convergence and performance. This paper focuses on data-dependent heterogeneity in FL and proposes a novel approach leveraging mean latent representations extracted from locally trained models. The proposed method normalizes client contributions based on these representations, allowing the central server to estimate and adjust for heterogeneity during aggregation. This normalization enhances the global model's generalization and mitigates the limitations of conventional federated averaging methods. The main contributions include introducing a normalization scheme using mean latent representations to handle statistical heterogeneity in FL, demonstrating the seamless integration with existing FL algorithms to improve performance in non-IID settings, and validating the approach through extensive experiments on diverse datasets. Results show significant improvements in model accuracy and consistency across skewed distributions. Our experiments with six FL schemes: FedAvg, FedProx, FedBABU, FedNova, SCAFFOLD, and SGDM highlight the robustness of our approach. This research advances FL by providing a practical and computationally efficient solution for statistical heterogeneity, contributing to the development of more reliable and generalized machine learning models.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Will Central Bank Digital Currencies (CBDC) and Blockchain Cryptocurrencies Coexist in the Post Quantum Era?</title>
<link>https://arxiv.org/abs/2411.06362</link>
<guid>https://arxiv.org/abs/2411.06362</guid>
<content:encoded><![CDATA[
<div> 关键词: CBDCs, 区块链, 量子计算, 多方计算, 隐蔽传输<br /><br />总结:<br />
本文探讨了中央银行数字货币(CBDCs)和基于区块链的加密货币在后量子计算环境下的共存可能性。文章分析了新兴量子算法和密码技术，如多方计算(MPC)和隐蔽传输(OT)，对CBDCs及加密货币的影响。同时研究了如何使CBDCs和加密货币整合后量子密码学防御机制，以及过渡传统系统并推动新标准的广泛应用所面临的重大挑战。文中还对量子环境中的CBDC进行了全面评估，并对比了不同加密货币模型。此外，文章深入剖析了相关量子方法及其与区块链架构的接口问题。作者还考察了量子威胁对加密货币方案的重要性，并讨论了预期中量子计算进步对未来算法及其应用的影响。最后，论文得出结论：只要通过持续的协同努力解决挑战、验证解决方案并指导政策演进，长期共存是可行的。 <div>
arXiv:2411.06362v1 Announce Type: new 
Abstract: This paper explores the coexistence possibilities of Central Bank Digital Currencies (CBDCs) and blockchain-based cryptocurrencies within a post-quantum computing landscape. It examines the implications of emerging quantum algorithms and cryptographic techniques such as Multi-Party Computation (MPC) and Oblivious Transfer (OT). While exploring how CBDCs and cryptocurrencies might integrate defenses like post-quantum cryptography, it highlights the substantial hurdles in transitioning legacy systems and fostering widespread adoption of new standards. The paper includes comprehensive evaluations of CBDCs in a quantum context. It also features comparisons to alternative cryptocurrency models. Additionally, the paper provides insightful analyses of pertinent quantum methodologies. Examinations of interfaces between these methods and blockchain architectures are also included. The paper carries out considered appraisals of quantum threats and their relevance for cryptocurrency schemes. Furthermore, it features discussions of the influence of anticipated advances in quantum computing on algorithms and their applications. The paper renders the judicious conclusion that long-term coexistence is viable provided challenges are constructively addressed through ongoing collaborative efforts to validate solutions and guide evolving policies.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Bus Voltage Restoration for DC Microgrids</title>
<link>https://arxiv.org/abs/2411.06531</link>
<guid>https://arxiv.org/abs/2411.06531</guid>
<content:encoded><![CDATA[
<div> 关键词: DC微电网、电压调节、集中式控制、分布式控制、通信链接

总结:
本文介绍了一种针对DC微电网中直流母线电压调节的新方法，旨在确保可靠性并维持负载端电压稳定。现有的电压恢复技术主要依赖于中心化的二级控制层，通过通信链路对每个转换器发送校正指令。与之不同的是，该论文提出了一种局部而直接的分布式控制策略，通过在每个转换器内部增加一个基于转换器输出电流和馈线电阻的附加控制环路反馈来补偿馈线电阻导致的电压降。这种方法经仿真和硬件在环测试验证有效，消除了对通信链接的依赖，从而提高了系统可靠性和降低了网络安全威胁。 <div>
arXiv:2411.06531v1 Announce Type: new 
Abstract: Regulating the voltage of the common DC bus, also referred to as the load bus, in DC microgrids is crucial for ensuring reliability and maintaining the nominal load voltage, which is essential for protecting sensitive loads from voltage variations. Stability and reliability are thereby enhanced, preventing malfunctions and extending the lifespan of sensitive loads (e.g., electronic devices). Voltage drops are caused by resistances of feeders connecting converters to the common DC bus, resulting in a reduced DC bus voltage compared to the nominal/desired value. Existing techniques to restore this voltage in DC microgrids are mainly centralized and rely on secondary control layers. These layers sense the common DC bus voltage, compare it to the nominal value, and utilize a PI controller to send corrections via communication links to each converter. In this paper, a local and straightforward approach to restoring the bus voltage in DC microgrids is presented, ensuring regulation in a decentralized manner. Voltage drops across resistances of feeders are compensated by an additional control loop feedback within each converter, based on the converter output current and feeder resistance. The proposed approach is verified through simulation and hardware-in-the-loop results, eliminating the need for communication links and hence increasing reliability and reducing cybersecurity threats.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Next-Generation Approach to Airline Reservations: Integrating Cloud Microservices with AI and Blockchain for Enhanced Operational Performance</title>
<link>https://arxiv.org/abs/2411.06538</link>
<guid>https://arxiv.org/abs/2411.06538</guid>
<content:encoded><![CDATA[
<div> 关键词: 云微服务、分布式人工智能模块、区块链技术、航空预订系统、效率安全顾客满意度

<br /><br />总结:
本文提出了一种下一代航空预订系统的设计方案，该系统融合了云微服务、分布式人工智能模块和区块链技术，旨在提升效率、数据安全性和顾客满意度。通过采用模块化和数据驱动设计方法，解决了传统预订系统在扩展性、数据完整性和服务水平方面的问题，实现了系统高可用性提升30%，性能增强40%的可扩展性提升。利用AI模块预测需求并提供个性化推荐，使客户参与度提高了25%。区块链技术的应用为交易提供了不可篡改的账本系统，降低了欺诈事件发生，提升了透明度达20%。经模拟器和机器学习评估分析，新系统的交易处理速度提高35%，系统响应时间缩短15%。此外，该系统也可应用于物流和酒店等其他高交易量行业。这项创新设计展示了先进科技将如何重塑航空预订领域，实现更高效、更安全以及更高顾客满意度的发展。 <div>
arXiv:2411.06538v1 Announce Type: new 
Abstract: This research proposes the development of a next generation airline reservation system that incorporates the Cloud microservices, distributed artificial intelligence modules and the blockchain technology to improve on the efficiency, safety and customer satisfaction. The traditional reservation systems encounter issues related to the expansion of the systems, the integrity of the data provided and the level of service offered to the customers, which is the main focus of this architecture through the modular and data centric design approaches. This will allow different operations such as reservations, payments, and customer data management among others to be performed separately thereby facilitating high availability of the system by 30% and enhancing performance of the system by 40% on its scalability. Such systems contain AI driven modules that utilize the past booking patterns along with the profile of the customer to estimate the demand and make recommendations, which increases to 25 % of customer engagement. Moreover, blockchain is effective in engaging an incorruptible ledger system for the all transactions therefore mitigating fraud incidences and increasing the clarity by 20%. The system was subjected to analysis using a simulator and using machine learning evaluations that rated it against other conventional systems. The results show that there were clear enhancements in the speed of transactions where the rates of secure data processing rose by 35%, and the system response time by 15 %. The system can also be used for other high transaction industries like logistics and hospitality. This structural design is indicative of how the use of advanced technologies will revolutionize the airline reservation sector. The implications are growing effectiveness, improvement in security and greater customer contentment.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Using Diffusion Models as Generative Replay in Continual Federated Learning -- What will Happen?</title>
<link>https://arxiv.org/abs/2411.06618</link>
<guid>https://arxiv.org/abs/2411.06618</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、连续学习（Continuous Learning）、灾难性遗忘（Catastrophic Forgetting）、非独立同分布数据（Non-IID Input Data）、扩散模型（Diffusion Model）

<br /><br />总结:
本文介绍了针对动态分布式学习环境中不断变化的数据分布所提出的连续联邦学习（CFL）任务及其挑战。为了解决其中的灾难性遗忘和非独立同分布输入数据问题，文章引入了一个名为DCFL的新框架。DCFL利用条件扩散模型在通信期间于每个本地设备生成合成的历史数据，有效缓解了动态数据分布输入带来的潜在变化。此外，文章还给出了所提CFL框架的收敛界，并通过多个数据集展示了其优越性能，证明了它在应对CFL任务复杂性方面的有效性。 <div>
arXiv:2411.06618v1 Announce Type: new 
Abstract: Federated learning (FL) has become a cornerstone in decentralized learning, where, in many scenarios, the incoming data distribution will change dynamically over time, introducing continuous learning (CL) problems. This continual federated learning (CFL) task presents unique challenges, particularly regarding catastrophic forgetting and non-IID input data. Existing solutions include using a replay buffer to store historical data or leveraging generative adversarial networks. Nevertheless, motivated by recent advancements in the diffusion model for generative tasks, this paper introduces DCFL, a novel framework tailored to address the challenges of CFL in dynamic distributed learning environments. Our approach harnesses the power of the conditional diffusion model to generate synthetic historical data at each local device during communication, effectively mitigating latent shifts in dynamic data distribution inputs. We provide the convergence bound for the proposed CFL framework and demonstrate its promising performance across multiple datasets, showcasing its effectiveness in tackling the complexities of CFL tasks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DynaShard: Secure and Adaptive Blockchain Sharding Protocol with Hybrid Consensus and Dynamic Shard Management</title>
<link>https://arxiv.org/abs/2411.06895</link>
<guid>https://arxiv.org/abs/2411.06895</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链分片、DynaShard、动态工作负载、跨片交易、系统完整性

总结:
本文提出了一种名为DynaShard的新颖解决方案，旨在解决区块链分片技术在处理动态工作负载、确保跨片交易安全及维护系统完整性的现有挑战。DynaShard结合了自适应分片管理、混合共识机制以及高效的状态同步和争议解决协议。通过在模拟真实网络条件和交易负载的实验环境下进行性能评估，结果显示DynaShard相比FTBS方法在吞吐量、延迟和分片利用率方面表现出显著优势，特别是在高交易量和可变跨片交易比例的情况下，能将延迟降低最多42.6%，分片利用率提升高达78.77%。这些成果表明DynaShard能够在可扩展性和系统韧性方面超越现有的区块链分片方法，对于未来区块链技术的发展具有重大影响，为构建更高效、安全的分布式系统奠定了基础。

<br /><br /> <div>
arXiv:2411.06895v1 Announce Type: new 
Abstract: Blockchain sharding has emerged as a promising solution to the scalability challenges in traditional blockchain systems by partitioning the network into smaller, manageable subsets called shards. Despite its potential, existing sharding solutions face significant limitations in handling dynamic workloads, ensuring secure cross-shard transactions, and maintaining system integrity. To address these gaps, we propose DynaShard, a dynamic and secure cross-shard transaction processing mechanism designed to enhance blockchain sharding efficiency and security. DynaShard combines adaptive shard management, a hybrid consensus approach, plus an efficient state synchronization and dispute resolution protocol. Our performance evaluation, conducted using a robust experimental setup with real-world network conditions and transaction workloads, demonstrates DynaShard's superior throughput, reduced latency, and improved shard utilization compared to the FTBS method. Specifically, DynaShard achieves up to a 42.6% reduction in latency and a 78.77% improvement in shard utilization under high transaction volumes and varying cross-shard transaction ratios. These results highlight DynaShard's ability to outperform state-of-the-art sharding methods, ensuring scalable and resilient blockchain systems. We believe that DynaShard's innovative approach will significantly impact future developments in blockchain technology, paving the way for more efficient and secure distributed systems.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Multi-Agent Collaborative Manipulation for Long-Horizon Quadrupedal Pushing</title>
<link>https://arxiv.org/abs/2411.07104</link>
<guid>https://arxiv.org/abs/2411.07104</guid>
<content:encoded><![CDATA[
<div> 关键词：四足机器人、多智能体强化学习、障碍物感知、长期推动物理任务、模拟与现实世界

<br />
总结:

本文提出了一种用于多四足机器人的层次化多智能体强化学习框架，旨在提升它们在处理大型物体方面的操纵能力，特别是实现障碍物感知的长期推动物理任务。该框架包含三个控制层级：高层控制器结合RRT规划器和集中式自适应策略生成子目标；中层控制器采用分布式目标条件策略指导机器人朝这些子目标移动；而预训练的低层运动策略执行移动指令。文章通过在仿真环境中对比多个基线方法，表明所提方法成功率提高了36.0%，完成时间减少了24.5%。此外，该框架成功地使Go1机器人在真实世界中完成了如Push-Cuboid和Push-T等长期、障碍物感知的操纵任务。 <div>
arXiv:2411.07104v1 Announce Type: new 
Abstract: Recently, quadrupedal locomotion has achieved significant success, but their manipulation capabilities, particularly in handling large objects, remain limited, restricting their usefulness in demanding real-world applications such as search and rescue, construction, industrial automation, and room organization. This paper tackles the task of obstacle-aware, long-horizon pushing by multiple quadrupedal robots. We propose a hierarchical multi-agent reinforcement learning framework with three levels of control. The high-level controller integrates an RRT planner and a centralized adaptive policy to generate subgoals, while the mid-level controller uses a decentralized goal-conditioned policy to guide the robots toward these sub-goals. A pre-trained low-level locomotion policy executes the movement commands. We evaluate our method against several baselines in simulation, demonstrating significant improvements over baseline approaches, with 36.0% higher success rates and 24.5% reduction in completion time than the best baseline. Our framework successfully enables long-horizon, obstacle-aware manipulation tasks like Push-Cuboid and Push-T on Go1 robots in the real world.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2411.07161</link>
<guid>https://arxiv.org/abs/2411.07161</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-Agent Systems, decentralized group decision-making, communication dynamics, voting rules, linguistic features

总结:
本研究关注了多智能体系统在无中心化的环境中如何通过跨智能体通信和群体决策增强集体智慧。研究重点在于不同社会选择方法中的通信和决策动态，并发现适度的决策灵活性能带来更好的结果。通过对智能体间对话的语言特征进行探索，揭示了有效协作的指标，为理解和识别促进或阻碍协作的沟通模式提供了洞见。此外，文章还提出了依据语言线索确定多智能体合作最优停止点的各种方法。这些发现深化了我们对去中心化决策制定和小组讨论如何塑造多智能体协作的理解，对于构建更有效的多智能体系统环境具有启示意义。<br /><br /> <div>
arXiv:2411.07161v1 Announce Type: new 
Abstract: This study investigates the efficacy of Multi-Agent Systems in eliciting cross-agent communication and enhancing collective intelligence through group decision-making in a decentralized setting. Unlike centralized mechanisms, where a fixed hierarchy governs social choice, decentralized group decision-making allows agents to engage in joint deliberation. Our research focuses on the dynamics of communication and decision-making within various social choice methods. By applying different voting rules in various environments, we find that moderate decision flexibility yields better outcomes. Additionally, exploring the linguistic features of agent-to-agent conversations reveals indicators of effective collaboration, offering insights into communication patterns that facilitate or hinder collaboration. Finally, we propose various methods for determining the optimal stopping point in multi-agent collaborations based on linguistic cues. Our findings contribute to a deeper understanding of how decentralized decision-making and group conversation shape multi-agent collaboration, with implications for the design of more effective MAS environments.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Approaching multifractal complexity in decentralized cryptocurrency trading</title>
<link>https://arxiv.org/abs/2411.05951</link>
<guid>https://arxiv.org/abs/2411.05951</guid>
<content:encoded><![CDATA[
<div> 关键词：多尺度分形、Multifractal Detrended Fluctuation Analysis (MFDFA)、去中心化交易所、交易量、收益率

总结:
该研究使用多尺度分形分析方法(Multifractal Detrended Fluctuation Analysis, MFDFA)，针对2023年6月6日至2024年6月30日期间从Uniswap去中心化交易所Universal Router合约获取的逐笔交易数据进行分析。结果显示，尽管去中心化交易所的流动性相较于集中式交易所仍然较低，但已显现出明显的多尺度分形特征。这些多尺度分形主要源于大波动，而小波动则更像无相关噪声。值得注意的是，交易量时间序列的多尺度分形特征比收益率更为显著，并在较大事件层面观察到了两者之间的多尺度交叉相关性。 <div>
arXiv:2411.05951v1 Announce Type: cross 
Abstract: Multifractality is a concept that helps compactly grasping the most essential features of the financial dynamics. In its fully developed form, this concept applies to essentially all mature financial markets and even to more liquid cryptocurrencies traded on the centralized exchanges. A new element that adds complexity to cryptocurrency markets is the possibility of decentralized trading. Based on the extracted tick-by-tick transaction data from the Universal Router contract of the Uniswap decentralized exchange, from June 6, 2023, to June 30, 2024, the present study using Multifractal Detrended Fluctuation Analysis (MFDFA) shows that even though liquidity on these new exchanges is still much lower compared to centralized exchanges convincing traces of multifractality are already emerging on this new trading as well. The resulting multifractal spectra are however strongly left-side asymmetric which indicates that this multifractality comes primarily from large fluctuations and small ones are more of the uncorrelated noise type. What is particularly interesting here is the fact that multifractality is more developed for time series representing transaction volumes than rates of return. On the level of these larger events a trace of multifractal cross-correlations between the two characteristics is also observed.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Semantic Communication and Cooperative Tracking Control for a UAV Swarm over Wireless MIMO Fading Channels</title>
<link>https://arxiv.org/abs/2411.06136</link>
<guid>https://arxiv.org/abs/2411.06136</guid>
<content:encoded><![CDATA[
<div> 关键词：UAV Swarm, Semantic Communication, Cooperative Tracking Control, Unreliable Wireless MIMO Channels, Drift-Plus-Penalty Optimization

总结:
该文研究了一种由领导无人机和多个跟随无人机组成的无人机群的语义通信与合作跟踪控制问题。文中首先建立了考虑内部交互和无线多输入多输出（MIMO）信道不稳定性影响的无人机群动态模型。接着，将无人机功率成本纳入考量，并将通信与合作跟踪控制挑战建模为一个漂移加罚优化问题，进而导出了能根据跟踪误差成本和局部信道条件自适应调整的分布式语义架构下的最优解。通过Lyapunov漂移分析方法，确立了确保无人机群跟踪性能稳定的封闭形式充分条件。数值结果表明，所提出的方案相较于现有多种方法具有显著优势。 <div>
arXiv:2411.06136v1 Announce Type: cross 
Abstract: This paper investigates the semantic communication and cooperative tracking control for an UAV swarm comprising a leader UAV and a group of follower UAVs, all interconnected via unreliable wireless multiple-input-multiple-output (MIMO) channels. Initially, we develop a dynamic model for the UAV swarm that accounts for both the internal interactions among the cooperative follower UAVs and the imperfections inherent in the MIMO channels that interlink the leader and follower UAVs. Building on this model, we incorporate the power costs of the UAVs and formulate the communication and cooperative tracking control challenge as a drift-plus-penalty optimization problem. We then derive a closed-form optimal solution that maintains a decentralized semantic architecture, dynamically adjusting to the tracking error costs and local channel conditions within the swarm. Employing Lyapunov drift analysis, we establish closed-form sufficient conditions for the stabilization of the UAV swarm's tracking performance. Numerical results demonstrate the significant enhancements in our proposed scheme over various state-of-the-art methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Graph Condensation with Information Bottleneck Principles</title>
<link>https://arxiv.org/abs/2405.03911</link>
<guid>https://arxiv.org/abs/2405.03911</guid>
<content:encoded><![CDATA[
<div> 关键词: 图压缩，联邦学习，隐私保护，图神经网络，信息瓶颈

总结:
本文提出了一个新的研究问题——联邦图压缩，针对大规模分布式图数据场景，旨在在保护数据持有者隐私的同时，进行有效的图压缩。为解决此问题，文章提出了一种联邦图压缩框架，该框架将传统的图压缩中的梯度匹配过程分解为客户端的梯度计算和服务器端的梯度匹配，有效减轻了客户端的计算负担。然而，实验表明在联邦学习环境下，压缩过程中会持续泄露数据成员身份隐私，对此，文中创新性地引入信息瓶颈原理，在局部预训练阶段仅提取部分节点特征并在联邦训练中使用，从而有效防止会员信息泄露。实验证明，所提出的联邦图压缩框架不仅在训练过程中能较好地保护成员隐私，而且其性能与现有集中式图压缩和联邦图学习方法相比也表现出可比甚至更优的效果。 <div>
arXiv:2405.03911v2 Announce Type: replace 
Abstract: Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediately benefited various graph learning tasks. However, existing graph condensation methods rely on centralized data storage, which is unfeasible for real-world decentralized data distribution, and overlook data holders' privacy-preserving requirements. To bridge the gap, we propose and study the novel problem of federated graph condensation for graph neural networks (GNNs). Specifically, we first propose a general framework for federated graph condensation, in which we decouple the typical gradient matching process for graph condensation into client-side gradient calculation and server-side gradient matching. In this way, the burdensome computation cost in client-side is largely alleviated. Besides, our empirical studies show that under the federated setting, the condensed graph will consistently leak data membership privacy, i.e., the condensed graph during the federated training can be utilized to steal the training data under the membership inference attacks (MIA). To tackle this issue, we innovatively incorporate information bottleneck principles into the federated graph condensation, which only needs to extract partial node features in one local pre-training step and utilize the features during federated training. Extensive experiments on real-world datasets demonstrate that our framework can consistently protect membership privacy during training. Meanwhile, it also achieves comparable and even superior performance against existing centralized graph condensation and federated graph learning methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sustainable business decision modelling with blockchain and digital twins: A survey</title>
<link>https://arxiv.org/abs/2405.12101</link>
<guid>https://arxiv.org/abs/2405.12101</guid>
<content:encoded><![CDATA[
<div> 关键词：Industry 4.0、Business Decision Modelling (BDM)、区块链、Digital Twin (DT)、可持续性

<br /><br />总结:
本文探讨了工业4.0及其未来发展将严重依赖可持续性的商业决策建模（BDM），而区块链和数字孪生（DT）技术可以加速这一进程。BDM基于模型和框架，需要通过关键识别因素、数据分析和适用于复杂业务场景的数学或计算方法进行提炼。为了从收集的数据中获取可用于BDM的行动智能，需建立确保数据透明度、安全性和可访问性的基础设施，并注重其可持续性。文章强调组织应考虑社会、经济和环境因素（基于三重底线原则），以确保整合此类基础设施时的可持续性。通过对现有研究的深入审查，定义了分类体系来评估区块链和DT的可持续性特征，并进行了详细的比较评价，揭示了这些解决方案在理念、访问控制和性能开销方面的可达性。同时提出了若干研究问题以推动进一步的研究，并结合供应链管理系统的实例展示区块链和DT与BDM之间的互操作性。 <div>
arXiv:2405.12101v2 Announce Type: replace 
Abstract: Industry 4.0 and beyond will rely heavily on sustainable Business Decision Modelling (BDM) that can be accelerated by blockchain and Digital Twin (DT) solutions. BDM is built on models and frameworks refined by key identification factors, data analysis, and mathematical or computational aspects applicable to complex business scenarios. Gaining actionable intelligence from collected data for BDM requires a carefully considered infrastructure to ensure data transparency, security, accessibility and sustainability. Organisations should consider social, economic and environmental factors (based on the triple bottom line approach) to ensure sustainability when integrating such an infrastructure. These sustainability features directly impact BDM concerning resource optimisation, stakeholder engagement, regulatory compliance and environmental impacts. To further understand these segments, taxonomies are defined to evaluate blockchain and DT sustainability features based on an in-depth review of the current state-of-the-art research. Detailed comparative evaluations provide insight into the reachability of the sustainable solution in terms of ideologies, access control and performance overheads. Several research questions are put forward to motivate further research that significantly impacts BDM. Finally, a case study based on an exemplary supply chain management system is presented to show the interoperability of blockchain and DT with BDM.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smoothed Gradient Clipping and Error Feedback for Decentralized Optimization under Symmetric Heavy-Tailed Noise</title>
<link>https://arxiv.org/abs/2310.16920</link>
<guid>https://arxiv.org/abs/2310.16920</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模机器学习、梯度裁剪、分布式优化、误差反馈机制、重尾噪声

总结:
本文针对具有重尾梯度噪声的大规模机器学习背景下，研究了带有梯度裁剪的去中心化优化问题。鉴于常规梯度裁剪在异构分布式环境中会引入偏差导致收敛性问题，文章提出了一个平滑裁剪操作员和一种结合误差反馈机制的去中心化梯度方法，该方法将裁剪操作应用在当地梯度估计与局部随机梯度之差上。在考虑对称重尾梯度噪声且不假设梯度有界的情况下，文中证明了所提方法在强凸光滑局部函数场景下能达到均方误差（MSE）收敛率为$O(1/t^\delta)$，其中$\delta \in (0, 2/5)$，指数$\delta$与高阶梯度噪声矩$\alpha > 1$的存在性无关，且由一些与条件数相关的常数下界保证。据作者所知，这是首次在未假设梯度有界的重尾噪声环境下，对于去中心化梯度裁剪提出的MSE收敛结果。实验验证了理论发现的有效性。<br /><br /> <div>
arXiv:2310.16920v3 Announce Type: replace-cross 
Abstract: Motivated by understanding and analysis of large-scale machine learning under heavy-tailed gradient noise, we study decentralized optimization with gradient clipping, i.e., in which certain clipping operators are applied to the gradients or gradient estimates computed from local nodes prior to further processing. While vanilla gradient clipping has proven effective in mitigating the impact of heavy-tailed gradient noise in non-distributed setups, it incurs bias that causes convergence issues in heterogeneous distributed settings. To address the inherent bias introduced by gradient clipping, we develop a smoothed clipping operator, and propose a decentralized gradient method equipped with an error feedback mechanism, i.e., the clipping operator is applied on the difference between some local gradient estimator and local stochastic gradient. We consider strongly convex and smooth local functions under symmetric heavy-tailed gradient noise that may not have finite moments of order greater than one. We show that the proposed decentralized gradient clipping method achieves a mean-square error (MSE) convergence rate of $O(1/t^\delta)$, $\delta \in (0, 2/5)$, where the exponent $\delta$ is independent of the existence of higher order gradient noise moments $\alpha > 1$ and lower bounded by some constant dependent on condition number. To the best of our knowledge, this is the first MSE convergence result for decentralized gradient clipping under heavy-tailed noise without assuming bounded gradient. Numerical experiments validate our theoretical findings.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EPIC: Enhancing Privacy through Iterative Collaboration</title>
<link>https://arxiv.org/abs/2411.05167</link>
<guid>https://arxiv.org/abs/2411.05167</guid>
<content:encoded><![CDATA[
<div> 关键词：病毒序列数据、机器学习、联邦学习、隐私保护、协同优化

<br /><br />总结:

本文提出了一种名为“EPIC”的创新隐私增强迭代协作架构，该架构旨在解决在不转移原始SARS-CoV-2基因序列数据的情况下，对其序列数据谱系进行监督分类的问题。随着基因组学技术的进步和病毒序列数据量的增长，机器学习在生物信息学中的应用日益增加，但传统的集中式数据处理方式面临现实医疗场景下的挑战以及数据隐私、所有权和严格法规等问题。联邦学习作为一种解决方案，通过设立中央聚合服务器和共享全局模型，在保证数据隐私的同时提取知识。EPIC架构将网络分布式部署于本地和集中式服务器之间，致力于构建一个允许不同数据持有者合作并收敛至单一预测模型的通用去中心化优化框架。实验结果表明，隐私保护策略可以成功应用于聚合方法中，而不影响学习收敛的程度。最后，文章还指出了基于联邦学习的医疗应用方法面临的潜在问题及研究前景。 <div>
arXiv:2411.05167v1 Announce Type: new 
Abstract: Advancements in genomics technology lead to a rising volume of viral (e.g., SARS-CoV-2) sequence data, resulting in increased usage of machine learning (ML) in bioinformatics. Traditional ML techniques require centralized data collection and processing, posing challenges in realistic healthcare scenarios. Additionally, privacy, ownership, and stringent regulation issues exist when pooling medical data into centralized storage to train a powerful deep learning (DL) model. The Federated learning (FL) approach overcomes such issues by setting up a central aggregator server and a shared global model. It also facilitates data privacy by extracting knowledge while keeping the actual data private. This work proposes a cutting-edge Privacy enhancement through Iterative Collaboration (EPIC) architecture. The network is divided and distributed between local and centralized servers. We demonstrate the EPIC approach to resolve a supervised classification problem to estimate SARS-CoV-2 genomic sequence data lineage without explicitly transferring raw sequence data. We aim to create a universal decentralized optimization framework that allows various data holders to work together and converge to a single predictive model. The findings demonstrate that privacy-preserving strategies can be successfully used with aggregation approaches without materially altering the degree of learning convergence. Finally, we highlight a few potential issues and prospects for study in FL-based approaches to healthcare applications.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DWFL: Enhancing Federated Learning through Dynamic Weighted Averaging</title>
<link>https://arxiv.org/abs/2411.05173</link>
<guid>https://arxiv.org/abs/2411.05173</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、生物信息学、数据隐私、蛋白质序列分类、深度神经网络

<br /><br />总结:
本文提出了一种基于深度前馈神经网络的增强型联邦学习方法，用于蛋白质序列分类，以解决在保护数据隐私的同时提高准确性的问题。针对联邦学习在蛋白质序列分析中的优化整合未被充分探索的情况，该研究引入了动态加权联邦学习（DWFL），这是一种根据本地模型性能指标进行权重调整的联邦学习方法，通过赋予表现优秀的模型更高的权重，构建更强大的全局模型初始版本，从而提升整体学习过程的准确性。实验使用真实世界的蛋白质序列数据集验证了DWFL的有效性，结果表明，所提出的方案显著提高了模型准确性，使联邦学习成为协作机器学习任务中更为优选、强大且注重隐私保护的方法。 <div>
arXiv:2411.05173v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed learning technique that maintains data privacy by providing a decentralized training method for machine learning models using distributed big data. This promising Federated Learning approach has also gained popularity in bioinformatics, where the privacy of biomedical data holds immense importance, especially when patient data is involved. Despite the successful implementation of Federated learning in biological sequence analysis, rigorous consideration is still required to improve accuracy in a way that data privacy should not be compromised. Additionally, the optimal integration of federated learning, especially in protein sequence analysis, has not been fully explored. We propose a deep feed-forward neural network-based enhanced federated learning method for protein sequence classification to overcome these challenges. Our method introduces novel enhancements to improve classification accuracy. We introduce dynamic weighted federated learning (DWFL) which is a federated learning-based approach, where local model weights are adjusted using weighted averaging based on their performance metrics. By assigning higher weights to well-performing models, we aim to create a more potent initial global model for the federated learning process, leading to improved accuracy. We conduct experiments using real-world protein sequence datasets to assess the effectiveness of DWFL. The results obtained using our proposed approach demonstrate significant improvements in model accuracy, making federated learning a preferred, more robust, and privacy-preserving approach for collaborative machine-learning tasks.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discern-XR: An Online Classifier for Metaverse Network Traffic</title>
<link>https://arxiv.org/abs/2411.05184</link>
<guid>https://arxiv.org/abs/2411.05184</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse, 网络流量分类器, Discern-XR, 分段学习, FVR算法, FIA算法, 在线训练, A2R-OT算法, 实际Metaverse数据集, 性能提升, 错误率降低

总结:
本文提出了一种名为Discern-XR的专门针对Metaverse网络流量的分类器，旨在帮助ISP和路由器制造商提升Metaverse服务的质量。该方法利用分段学习，提出了Frame Vector Representation (FVR)算法和Frame Identification Algorithm (FIA)，从仅具有四个应用层特征的原始网络数据中提取关键帧相关统计信息。同时，文章还设计了一个新颖的在线训练算法A2R-OT，用于寻找准确的分类模型。此外，作者为研究贡献了一个实际的Metaverse数据集，包含了虚拟现实游戏、VR视频、VR聊天、增强现实以及混合现实等不同类型的流量样本，为业界提供了全面的基准测试资源。Discern-XR相比于现有最先进的分类器性能提升了7%，并提高了训练效率，降低了错误负例率，从而推动了Metaverse网络流量分类技术的发展，成为当前领域的最佳解决方案。 <div>
arXiv:2411.05184v1 Announce Type: new 
Abstract: In this paper, we design an exclusive Metaverse network traffic classifier, named Discern-XR, to help Internet service providers (ISP) and router manufacturers enhance the quality of Metaverse services. Leveraging segmented learning, the Frame Vector Representation (FVR) algorithm and Frame Identification Algorithm (FIA) are proposed to extract critical frame-related statistics from raw network data having only four application-level features. A novel Augmentation, Aggregation, and Retention Online Training (A2R-OT) algorithm is proposed to find an accurate classification model through online training methodology. In addition, we contribute to the real-world Metaverse dataset comprising virtual reality (VR) games, VR video, VR chat, augmented reality (AR), and mixed reality (MR) traffic, providing a comprehensive benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while improving training efficiency and reducing false-negative rates. Our work advances Metaverse network traffic classification by standing as the state-of-the-art solution.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning</title>
<link>https://arxiv.org/abs/2411.05260</link>
<guid>https://arxiv.org/abs/2411.05260</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Homomorphic Encryption、Quantization、Pruning、QuanCrypt-FL

总结:<br />
本文提出了一种名为QuanCrypt-FL的新颖算法，旨在解决联邦学习（Federated Learning）中的隐私保护和通信效率问题。针对联邦学习在训练和推理过程中面临的攻击风险，如梯度反演和成员资格推断，文章提出了结合低比特量化和剪枝技术的方法，以增强对攻击的防护并显著降低训练过程中的计算成本。同时，为了解决量化溢出或误差，文中还引入了均值裁剪策略。通过整合这些方法，QuanCrypt-FL构建了一个既保证隐私又能兼顾通信效率和模型准确性的FL框架。实验结果表明，QuanCrypt-FL在MNIST、CIFAR-10和CIFAR-100数据集上相比于现有方法表现出优越性能，其准确性与Vanilla-FL相当，并在加密速度、解密速度和推理速度方面分别实现了最多9倍、16倍和1.5倍的提升，训练时间最多可减少3倍，相较于BatchCrypt展现了更高的计算效率和攻击鲁棒性。 <div>
arXiv:2411.05260v1 Announce Type: new 
Abstract: Federated Learning has emerged as a leading approach for decentralized machine learning, enabling multiple clients to collaboratively train a shared model without exchanging private data. While FL enhances data privacy, it remains vulnerable to inference attacks, such as gradient inversion and membership inference, during both training and inference phases. Homomorphic Encryption provides a promising solution by encrypting model updates to protect against such attacks, but it introduces substantial communication overhead, slowing down training and increasing computational costs. To address these challenges, we propose QuanCrypt-FL, a novel algorithm that combines low-bit quantization and pruning techniques to enhance protection against attacks while significantly reducing computational costs during training. Further, we propose and implement mean-based clipping to mitigate quantization overflow or errors. By integrating these methods, QuanCrypt-FL creates a communication-efficient FL framework that ensures privacy protection with minimal impact on model accuracy, thereby improving both computational efficiency and attack resilience. We validate our approach on MNIST, CIFAR-10, and CIFAR-100 datasets, demonstrating superior performance compared to state-of-the-art methods. QuanCrypt-FL consistently outperforms existing method and matches Vanilla-FL in terms of accuracy across varying client. Further, QuanCrypt-FL achieves up to 9x faster encryption, 16x faster decryption, and 1.5x faster inference compared to BatchCrypt, with training time reduced by up to 3x.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digitalization and Virtual Assistive Systems in Tourist Mobility: Evolution, an Experience (with Observed Mistakes), Appropriate Orientations and Recommendations</title>
<link>https://arxiv.org/abs/2411.05446</link>
<guid>https://arxiv.org/abs/2411.05446</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字化、虚拟化、旅游管理、用户体验、元宇宙

总结:
本文探讨了数字化和虚拟化在包括旅游管理在内的多个领域中的活跃应用和重要性。通过一个为期7周的旅行案例研究，文章指出了当前旅游业中适宜与不足的情况，并强调了用户体验对于辅助系统及用户界面满意度验证的关键作用。同时，文章还展望了未来元宇宙在该领域发展中预期扮演的重要角色。 <div>
arXiv:2411.05446v1 Announce Type: new 
Abstract: Digitalization and virtualization are extremely active and important approaches in a large scope of activities (marketing, selling, enterprise management, logistics). Tourism management is also highly concerned by this evolution. In this paper we try to present today's situation based on a 7-week trip showing appropriate and shame situations. After this case study, we give a list of appropriate practices and orientations and confirm the fundamental role of User Experience in validating the proposed assistive system and the User Interfaces needed for client/user satisfaction. We also outline the expected role of Metaverse in the future of the evolution of this domain.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Emergent Cooperative Strategies for Multi-Agent Shepherding via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.05454</link>
<guid>https://arxiv.org/abs/2411.05454</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式强化学习、多智能体、牧羊控制问题、两层控制器、大规模系统

<br /><br />总结:

本文提出了一种分布式强化学习方法来解决多智能体牧羊控制问题，该问题不再假设目标群体具有凝聚力。这种方法采用双层控制架构：低层控制器引导每个牧羊者将特定目标保持在目标区域内；而高层层动态选择牧羊者应瞄准并围堵的目标。合作行为自然产生，因为牧羊者自主选择不同的目标以加速任务完成。此外，该方法还被扩展到大型系统中，其中每个牧羊者应用由少数代理训练的共享策略，同时管理一组固定的子代理。 <div>
arXiv:2411.05454v1 Announce Type: new 
Abstract: We present a decentralized reinforcement learning (RL) approach to address the multi-agent shepherding control problem, departing from the conventional assumption of cohesive target groups. Our two-layer control architecture consists of a low-level controller that guides each herder to contain a specific target within a goal region, while a high-level layer dynamically selects from multiple targets the one an herder should aim at corralling and containing. Cooperation emerges naturally, as herders autonomously choose distinct targets to expedite task completion. We further extend this approach to large-scale systems, where each herder applies a shared policy, trained with few agents, while managing a fixed subset of agents.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2411.05591</link>
<guid>https://arxiv.org/abs/2411.05591</guid>
<content:encoded><![CDATA[
<div> 关键词：网络期望最大化（Network EM）、高斯混合模型、分布式联邦学习、动量网络EM（MNEM）、半监督MNEM（semi-MNEM）

<br /><br />总结:
本文系统研究了应用于高斯混合模型的多种网络期望最大化（EM）算法，在分布式联邦学习的框架下。针对异质数据和成分分离不良的问题，文章提出了两种创新解决方案。首先，为处理异质数据，文章引入了动量网络EM（MNEM）算法，该算法使用动量参数结合当前与历史估计器的信息。其次，为应对成分分离不良的挑战，他们开发了半监督MNEM（semi-MNEM）算法，利用部分标注的数据。理论分析表明，即使在异质场景中，当混合组件满足一定的分离条件时，MNEM可以实现与全样本估计器相当的统计效率。此外，semi-MNEM算法能加快MNEM算法的收敛速度，有效解决了成分分离不良情况下的数值收敛难题。通过大量的模拟和真实数据分析验证了这些理论发现。 <div>
arXiv:2411.05591v1 Announce Type: cross 
Abstract: We systematically study various network Expectation-Maximization (EM) algorithms for the Gaussian mixture model within the framework of decentralized federated learning. Our theoretical investigation reveals that directly extending the classical decentralized supervised learning method to the EM algorithm exhibits poor estimation accuracy with heterogeneous data across clients and struggles to converge numerically when Gaussian components are poorly-separated. To address these issues, we propose two novel solutions. First, to handle heterogeneous data, we introduce a momentum network EM (MNEM) algorithm, which uses a momentum parameter to combine information from both the current and historical estimators. Second, to tackle the challenge of poorly-separated Gaussian components, we develop a semi-supervised MNEM (semi-MNEM) algorithm, which leverages partially labeled data. Rigorous theoretical analysis demonstrates that MNEM can achieve statistical efficiency comparable to that of the whole sample estimator when the mixture components satisfy certain separation conditions, even in heterogeneous scenarios. Moreover, the semi-MNEM estimator enhances the convergence speed of the MNEM algorithm, effectively addressing the numerical convergence challenges in poorly-separated scenarios. Extensive simulation and real data analyses are conducted to justify our theoretical findings.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large problems are not necessarily hard: A case study on distributed NMPC paying off</title>
<link>https://arxiv.org/abs/2411.05627</link>
<guid>https://arxiv.org/abs/2411.05627</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式模型预测控制(MPC), 计算性能, 并行计算, 中心化解算器, 频率控制

总结:<br />
本文研究了分布式模型预测控制（MPC）在处理大型系统中的计算性能，特别是针对线性和非线性系统的合作型分布式MPC。文中提出了一种定制化的分散实时迭代方案应用于电力系统的频率控制。研究表明，在所考虑的线性及非线性基准测试中，分布式MPC和分布式非线性MPC（NMPC）具有良好的扩展性，因为它们所需的迭代次数并不随子系统的数量增加而增加。与多线程中心化解算器进行比较后发现，所提出的分散优化算法展现出与其竞争性的性能。 <div>
arXiv:2411.05627v1 Announce Type: cross 
Abstract: A key motivation in the development of distributed Model Predictive Control (MPC) is to widen the computational bottleneck of centralized MPC for large-scale systems. Parallelizing computations among individual subsystems, distributed MPC has the prospect of scaling well for large networks. However, the communication demand may deteriorate the performance of iterative decentralized optimization, if excessively many optimizer iterations are required per control step. Moreover, centralized solvers often exhibit faster asymptotic convergence rates and, by parallelizing costly linear algebra operations, they can also benefit from modern multi-core computing architectures. On this canvas, we study the computational performance of cooperative distributed MPC for linear and nonlinear systems. To this end, we apply a tailored decentralized real-time iteration scheme to frequency control for power systems. For the considered linear and nonlinear benchmarks, distributed MPC and distributed Nonlinear MPC (NMPC) scale well as the required number of iterations does not depend on the number of subsystems. Comparisons with multithreaded centralized solvers show competitive performance of the considered decentralized optimization algorithms.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fast Confirmation Rule for the Ethereum Consensus Protocol</title>
<link>https://arxiv.org/abs/2405.00549</link>
<guid>https://arxiv.org/abs/2405.00549</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、确认规则、比特币、以太坊、Gasper<br /><br />总结:
本文讨论了区块链中的确认规则，特别是以太坊网络中的确认机制。现有的以太坊共识协议中采用的是FFG最终化规则（Gasper），但在异步网络条件下确认交易速度较慢，最佳情况下也需要约13至19分钟。为此，文章提出了一个新的快速确认规则，该规则基于同步网络条件，能将交易的最好情况下的确认时间缩短到仅12秒，显著提高了确认效率。因此，用户可以根据对网络条件的判断和快速响应的需求选择适合自己的确认规则。 <div>
arXiv:2405.00549v2 Announce Type: replace 
Abstract: A Confirmation Rule, within blockchain networks, refers to an algorithm implemented by network nodes that determines (either probabilistically or deterministically) the permanence of certain blocks on the blockchain. An example of Confirmation Ruble is the Bitcoin's longest chain Confirmation Rule where a block $b$ is confirmed (with high probability) when it has a sufficiently long chain of successors, its siblings have notably shorter successor chains, the majority of the network's total computation power (hashing) is controlled by honest nodes, and network synchrony holds.
  The only Confirmation Rule currently available in the Ethereum protocol, Gasper, is the FFG Finalization Rule. While this Confirmation Rule works under asynchronous network conditions, it is quite slow for many use cases. Specifically, best-case scenario, it takes around 13 to 19 min to confirm a transaction, where the actual figure depends on when the transaction is submitted to the network.
  In this work, we devise a Fast Confirmation Rule for Ethereum's consensus protocol. Our Confirmation Rule relies on synchrony conditions, but provides a best-case confirmation time of 12 seconds only, greatly improving on the latency of the FFG Finalization Rule.
  Users can then rely on the Confirmation Rule that best suits their needs depending on their belief about the network conditions and the need for a quick response.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses</title>
<link>https://arxiv.org/abs/2411.04139</link>
<guid>https://arxiv.org/abs/2411.04139</guid>
<content:encoded><![CDATA[
<div> 关键词：6G车辆元宇宙、车辆数字孪生、资源分配、无人机、学习优化算法

<br />
总结:
本文探讨了6G赋能的车辆元宇宙中，如何利用车辆数字孪生技术解决实时车联网服务面临的挑战。针对高需求的车辆数字孪生任务和地面基站有限资源的问题，文中提出采用无人机作为空中边缘服务器辅助处理这些任务。然而，由于无人机的高流动性导致与地面基站之间存在信息不对称，进而影响到资源分配效率。为了解决这一问题，文章提出了一个基于学习的改良第二价格拍卖机制，该机制考虑了任务延迟和准确性，优化了地空基站之间的资源分配。同时，设计了一种扩散式强化学习算法来优化价格调整因子，以最大化资源提供者的总剩余价值并最小化车辆数字孪生任务的延迟。仿真结果显示，所提出的扩散式改良第二价格拍卖机制相比于传统方法具有更好的资源分布性能和服务质量提升效果。 <div>
arXiv:2411.04139v1 Announce Type: new 
Abstract: The rise of 6G-enable Vehicular Metaverses is transforming the automotive industry by integrating immersive, real-time vehicular services through ultra-low latency and high bandwidth connectivity. In 6G-enable Vehicular Metaverses, vehicles are represented by Vehicle Twins (VTs), which serve as digital replicas of physical vehicles to support real-time vehicular applications such as large Artificial Intelligence (AI) model-based Augmented Reality (AR) navigation, called VT tasks. VT tasks are resource-intensive and need to be offloaded to ground Base Stations (BSs) for fast processing. However, high demand for VT tasks and limited resources of ground BSs, pose significant resource allocation challenges, particularly in densely populated urban areas like intersections. As a promising solution, Unmanned Aerial Vehicles (UAVs) act as aerial edge servers to dynamically assist ground BSs in handling VT tasks, relieving resource pressure on ground BSs. However, due to high mobility of UAVs, there exists information asymmetry regarding VT task demands between UAVs and ground BSs, resulting in inefficient resource allocation of UAVs. To address these challenges, we propose a learning-based Modified Second-Bid (MSB) auction mechanism to optimize resource allocation between ground BSs and UAVs by accounting for VT task latency and accuracy. Moreover, we design a diffusion-based reinforcement learning algorithm to optimize the price scaling factor, maximizing the total surplus of resource providers and minimizing VT task latency. Finally, simulation results demonstrate that the proposed diffusion-based MSB auction outperforms traditional baselines, providing better resource distribution and enhanced service quality for vehicular users.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenFLAME: Building a large scale federated localization and mapping service</title>
<link>https://arxiv.org/abs/2411.04271</link>
<guid>https://arxiv.org/abs/2411.04271</guid>
<content:encoded><![CDATA[
<div> 关键词: OpenFLAME、去中心化、定位服务、联邦、地图抽象

总结:
OpenFLAME 是首个提出的去中心化、联邦定位服务系统，旨在解决随着室内定位技术进步和应用拓展而产生的对可扩展到私人空间的全球化、分布式位置管理系统的需要。该系统通过链接负责特定区域定位的服务器，为应用程序提供无缝的全球视野。针对联邦定位系统中的服务发现和服务整合等挑战，OpenFLAME 利用域名系统（DNS）实现服务发现，并运用地图抽象方法来检索和合并不同地图上的位置信息。其基于真实数据的研究表明，跨越远程服务器的联邦定位具有可行性和可接受的查询延迟。为了展示系统的潜力，开发了一个适用于大型室内的增强现实导航应用，证明了OpenFLAME能够成功地支持位置为基础的应用程序运行。 <div>
arXiv:2411.04271v1 Announce Type: new 
Abstract: The widespread availability of maps has enabled the development of numerous location-based applications, including navigation, ride-sharing, fitness tracking, gaming, robotics, and augmented reality. Today, the maps that power these services are predominantly controlled by a few large corporations and mostly cover outdoor spaces. As the use of these applications expands and indoor localization technologies advance, we are seeing the need for a scalable, federated location management system that can extend into private spaces.
  We introduce OpenFLAME (Open Federated Localization and Mapping Engine), the first federated and decentralized localization service. OpenFLAME links servers that handle localization for specific regions, providing applications with a seamless global view. Creating a federated localization system poses challenges, such as discovering the appropriate servers for a region and integrating services managed by independent providers. To address these issues and ensure scalability, we leverage Domain Name System (DNS) for service discovery and implement map abstractions to retrieve and merge locations across different maps. Our trace-driven study demonstrates that federated localization across remote servers is feasible with acceptable query latencies. To highlight the potential of the system, we developed an augmented reality navigation application for a large indoor space, showing that OpenFLAME can successfully power location-based applications.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Intersections of Web3 and AI -- View in 2024</title>
<link>https://arxiv.org/abs/2411.04318</link>
<guid>https://arxiv.org/abs/2411.04318</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、AI技术、整合、缺口、创新方法

总结:
<br />
本文通过全面回顾现有学术论文、行业报告和以太坊研究社区博客文章，概述了Web3与AI技术的交叉点、两者之间的协同效应以及对于这些技术融合可能存在的一些认识缺口。作者将焦点放在感知到的缺口上，并详细提出了一些新颖的方法，旨在促进区块链/Web3生态系统的进步。这篇论文提供的综述预计将为关注Web3与AI技术交叉领域的研究人员提供指导。 <div>
arXiv:2411.04318v1 Announce Type: new 
Abstract: This paper summarises the intersection of Web3 and AI technologies, synergies between these technologies, and gaps that we suggest exist in the conception of the possible integrations of these technologies. The summary is informed by a comprehensive literature review of current academic and industry papers, analyst reports, and Ethereum research community blogposts. We focus our contribution on the perceived gaps and detail some novel approaches that would benefit the blockchain/Web3 ecosystem. We believe that the overview presented in this paper will help guide researchers interested in the intersection of Web3 and AI technologies.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secured Smart Grid 2.0: Exploring Security Threats, Protection Models, and Challenges</title>
<link>https://arxiv.org/abs/2411.04365</link>
<guid>https://arxiv.org/abs/2411.04365</guid>
<content:encoded><![CDATA[
<div> 关键词: 绿色转型、智能电网2.0(SG2)、通信网络、安全威胁、防御策略

<br /><br />总结:

1. 许多国家正推动能源领域的绿色转型以实现2050年碳中和目标，其中智能电网2.0 (SG2)利用数据驱动分析和通信技术提升分布式可再生能源系统的效率与可持续性。
   
2. SG2对通信网络高度依赖，但其连通性的潜在级联故障可能导致数据同步至远程控制系统受阻。

3. 文章调研了电力运营商、通信网络提供商及消费者等SG2利益相关者的安全威胁与防御策略，发现易受到变电站攻击/破坏、恶意软件/勒索软件威胁、区块链漏洞及供应链中断等问题的影响。

4. SG2中人工智能(AI)融入自主能源管理带来新挑战，如电力读数和测量传感器上对抗样本和虚假数据注入可能导致AI控制功能失效、储能错误检查混乱、电动汽车充电能量估算不准确以及点对点能源交易模型中的欺诈交易。

5. 针对未来研究，具有潜力的保护模型包括可扩展的基于区块链的模型、物理不可克隆函数、互操作性安全协议及面向分布式微电网管理的可信AI模型。 <div>
arXiv:2411.04365v1 Announce Type: new 
Abstract: Many nations are promoting the green transition in the energy sector to attain neutral carbon emissions by 2050. Smart Grid 2.0 (SG2) is expected to explore data-driven analytics and enhance communication technologies to improve the efficiency and sustainability of distributed renewable energy systems. These features are beyond smart metering and electric surplus distribution in conventional smart grids. Given the high dependence on communication networks to connect distributed microgrids in SG2, potential cascading failures of connectivity can cause disruption to data synchronization to the remote control systems. This paper reviews security threats and defense tactics for three stakeholders: power grid operators, communication network providers, and consumers. Through the survey, we found that SG2's stakeholders are particularly vulnerable to substation attacks/vandalism, malware/ransomware threats, blockchain vulnerabilities and supply chain breakdowns. Furthermore, incorporating artificial intelligence (AI) into autonomous energy management in distributed energy resources of SG2 creates new challenges. Accordingly, adversarial samples and false data injection on electricity reading and measurement sensors at power plants can fool AI-powered control functions and cause messy error-checking operations in energy storage, wrong energy estimation in electric vehicle charging, and even fraudulent transactions in peer-to-peer energy trading models. Scalable blockchain-based models, physical unclonable function, interoperable security protocols, and trustworthy AI models designed for managing distributed microgrids in SG2 are typical promising protection models for future research.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comprehensive Review of Multimodal XR Applications, Risks, and Ethical Challenges in the Metaverse</title>
<link>https://arxiv.org/abs/2411.04508</link>
<guid>https://arxiv.org/abs/2411.04508</guid>
<content:encoded><![CDATA[
<div> 关键词：Extended Reality (XR)，Metaverse，Virtual Reality (VR)，Augmented Reality (AR)，Mixed Reality (MR)

总结:
本文是一篇关于扩展现实（XR）技术，包括虚拟现实（VR）、增强现实（AR）和混合现实（MR），及其在元宇宙应用中的范围审查。XR正在教育、医疗培训、神经心理评估等领域引发革命，并带来沉浸式体验的提升。然而，随着多模态技术如触觉、眼动追踪等的应用，XR扩张也带来了数据隐私风险、网络安全问题、身心健康挑战（如网络病态、成瘾、脱节、骚扰等）以及社会不平等影响。因此，文章强调了制定强有力的伦理框架和监管指南以应对这些风险并促进公平访问、隐私保护、自主权及心理健康的重要性。随着XR技术与人工智能日益融合，负责任的治理对于确保元宇宙及其他领域中XR安全、有益的发展至关重要。 <div>
arXiv:2411.04508v1 Announce Type: new 
Abstract: This scoping review examines the broad applications, risks, and ethical challenges associated with Extended Reality (XR) technologies, including Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), within the context of Metaverse. XR is revolutionizing fields such as immersive learning in education, medical and professional training, neuropsychological assessment, therapeutic interventions, arts, entertainment, retail, e-commerce, remote work, sports, architecture, urban planning, and cultural heritage preservation. The integration of multimodal technologies such as haptics, eye-tracking, face- and body-tracking, and brain-computer interfaces, enhances user engagement and interactivity, playing a key role in shaping the immersive experiences in the Metaverse. However, XR's expansion raises serious concerns, including data privacy risks, cybersecurity vulnerabilities, cybersickness, addiction, dissociation, harassment, bullying, and misinformation. These psychological, social, and security challenges are further complicated by intense advertising, manipulation of public opinion, and social inequality, which could disproportionately affect vulnerable individuals and social groups. This review emphasizes the urgent need for robust ethical frameworks and regulatory guidelines to address these risks while promoting equitable access, privacy, autonomy, and mental well-being. As XR technologies increasingly integrate with artificial intelligence, responsible governance is essential to ensure the safe and beneficial development of the Metaverse and the broader application of XR in enhancing human development.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RainCloud: Decentralized Coordination and Communication in Heterogeneous IoT Swarms</title>
<link>https://arxiv.org/abs/2411.04593</link>
<guid>https://arxiv.org/abs/2411.04593</guid>
<content:encoded><![CDATA[
<div> 关键词: IoT系统、计算连续体、分布式协调、蚁群优化(ACO)、随机搜索、 gossip协议、任务分配

<br /><br />总结:
本文关注物联网(IoT)系统日益增长的复杂性和规模需求，提出从云中心模型向称为“计算连续体”的去中心化IoT架构转变。这种转变带来了新的研究挑战，特别是对于分布式协调的需求。为了解决这一问题，文章提出了一种基于语义通信的方案和一种利用蚁群优化(ACO)的轻量级自适应任务分配策略。该策略与随机搜索和基于gossip协议的算法进行了比较。实验在静态和动态环境（包括设备故障）下，涉及多达一百个节点进行验证。结果显示，ACO能在最少的跳数和消息发送次数下找到匹配节点，虽然gossip协议在成功分配任务数量上表现出色，但ACO在可扩展性方面更优，因此是物联网集群中实现分布式任务协调的一种有前景的方法。 <div>
arXiv:2411.04593v1 Announce Type: new 
Abstract: The increasing volume and complexity of IoT systems demand a transition from the cloud-centric model to a decentralized IoT architecture in the so-called Computing Continuum, with no or minimal reliance on central servers. This paradigm shift, however, raises novel research concerns for decentralized coordination, calling for accurate policies. However, building such strategies is not trivial. Our work aims to relieve the DevOps engineers from this concern and propose a solution for autonomous, decentralized task allocation at runtime for IoT systems. To this end, we present a semantic communication approach and an ad-hoc lightweight coordination strategy based on Ant Colony Optimization (ACO). We compare the ACO strategy with Random Search and Gossip protocol-based algorithms. We conduct accurate experiments with up to a hundred nodes in both a static and a dynamic environment, i.e., with device outages. We show that ACO finds a matching node with the smallest hops and messages sent. While the Gossip strategy can allocate the most tasks successfully, ACO scales better, thus being a promising candidate for decentralized task coordination in IoT clusters.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Maximal Extractable Value in Decentralized Finance: Taxonomy, Detection, and Mitigation</title>
<link>https://arxiv.org/abs/2411.03327</link>
<guid>https://arxiv.org/abs/2411.03327</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance (DeFi), Maximal Extractable Value (MEV), blockchain, transaction reordering, mitigation strategies

<br /><br />总结:
本文是对去中心化金融(DeFi)领域中Maximal Extractable Value（MEV）现象的全面调查。MEV是指利用区块链上的公开交易信息进行重新排序、插入或移除交易以榨取价值的行为，可能导致参与者财务损失和共识不稳定性。文章首先构建了一个关于MEV交易的新型分类体系，并通过真实交易示例深入解释了MEV的理解。接着对比分析了多种MEV检测方法的有效性。此外，文中还评估了不同类型的MEV缓解策略及其局限性。作者指出现有缓解与检测方法面临的挑战并讨论可能的解决方案。该文旨在为研究人员、开发者、利益相关者和政策制定者提供有价值的洞见，助力构建更安全、高效的DeFi生态系统，同时努力遏制和民主化MEV现象。 <div>
arXiv:2411.03327v1 Announce Type: new 
Abstract: Decentralized Finance (DeFi) leverages blockchain-enabled smart contracts to deliver automated and trustless financial services without the need for intermediaries. However, the public visibility of financial transactions on the blockchain can be exploited, as participants can reorder, insert, or remove transactions to extract value, often at the expense of others. This extracted value is known as the Maximal Extractable Value (MEV). MEV causes financial losses and consensus instability, disrupting the security, efficiency, and decentralization goals of the DeFi ecosystem. Therefore, it is crucial to analyze, detect, and mitigate MEV to safeguard DeFi. Our comprehensive survey offers a holistic view of the MEV landscape in the DeFi ecosystem. We present an in-depth understanding of MEV through a novel taxonomy of MEV transactions supported by real transaction examples. We perform a critical comparative analysis of various MEV detection approaches, evaluating their effectiveness in identifying different transaction types. Furthermore, we assess different categories of MEV mitigation strategies and discuss their limitations. We identify the challenges of current mitigation and detection approaches and discuss potential solutions. This survey provides valuable insights for researchers, developers, stakeholders, and policymakers, helping to curb and democratize MEV for a more secure and efficient DeFi ecosystem.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Based Multi-Path Mobile Access Point Selection for Secure 5G VANETs</title>
<link>https://arxiv.org/abs/2411.03371</link>
<guid>https://arxiv.org/abs/2411.03371</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、多路径移动接入点选择策略、安全5G车联网、信任攻击检测机制、通信延迟

总结:
本文提出了一种基于区块链的多路径移动接入点(MAP)选择策略，用于确保5G车联网(VANETs)的安全性。该策略利用区块链技术实现去中心化、透明且安全的MAP选择，同时通过多路径传输策略提升网络可靠性并降低通信延迟。文中还集成了一种信任基的攻击检测机制以保障网络安全。仿真结果显示，所提算法能将切换频率和平均通信延迟降低超过80%，并且能成功识别并排除超过95%的Sybil节点，从而在高度动态的车载环境中确保了可靠且安全的通信。 <div>
arXiv:2411.03371v1 Announce Type: new 
Abstract: This letter presents a blockchain-based multi-path mobile access point (MAP) selection strategy for secure 5G vehicular ad-hoc networks (VANETs). The proposed method leverages blockchain technology for decentralized, transparent, and secure MAP selection, while the multi-path transmission strategy enhances network reliability and reduces communication delays. A trust-based attack detection mechanism is integrated to ensure network security. Simulation results demonstrate that the proposed algorithm reduces both handover frequency and average communication delay by over 80%, and successfully identifies and excludes more than 95% of Sybil nodes, ensuring reliable and secure communication in highly dynamic vehicular environments.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Attribute-Based Encryption With Payable Outsourced Decryption Using Blockchain and Responsive Zero Knowledge Proof</title>
<link>https://arxiv.org/abs/2411.03844</link>
<guid>https://arxiv.org/abs/2411.03844</guid>
<content:encoded><![CDATA[
<div> 关键词：Attribute-Based Encryption (ABE), Decryption Cloud Service (DCS), Blockchain, Verifiability, Exemptibility

总结:<br />
本文提出了一种基于区块链的可付费外包解密的属性基加密(ABE)方案，旨在解决ABE解密效率低下的问题。该方案允许用户将解密过程外包给解密云服务(DCS)，同时具备验证外包结果的正确性和实现诚实DCS豁免错误声明的有效机制。为降低证明生成的成本，方案引入了乐观假设下的一轮挑战游戏。此外，系统实现了公平性和去中心化的外包，以保护各方利益。实验结果显示，相比于Ge等人(TDSC'23)提出的方案，在属性数量从5到60的情况下，本方案在正常情况和挑战情况下的以太坊 Gas 使用量分别降低了11倍至140倍和4倍至55倍，从而证明了其可行性和高效性。 <div>
arXiv:2411.03844v1 Announce Type: new 
Abstract: Attribute-Based Encryption (ABE) is a promising solution for access control in cloud services. However, the heavy decryption overhead hinders its widespread adoption. A general approach to address this issue is to outsource decryption to decryption cloud service(DCS). Existing schemes have utilized various methods to enable users to verify outsourced results; however, they lack an effective mechanism to achieve exemptibility which enables the honest DCS to escape from wrong claims. And it is impractical to assume that the DCS will provide free services. In this paper, we propose a blockchain-based payable outsourced decryption ABE scheme that achieves both verifiability and exemptibility without adding redundant information to ABE ciphertext. We use zero-knowledge proof to verify outsourced results on blockchain and introduce an optional single-round challenge game under optimistic assumption to address the high cost of proof generation. Moreover, our system achieves fairness and decentralized outsourcing to protect the interests of all parties. Finally, we implement and evaluate our scheme on Ethereum to demonstrate its feasibility and efficiency, the gas usage in attribute numbers from 5 to 60 is 11$\times$ to 140$\times$ in the happy case and 4$\times$ to 55$\times$ in the challenge case lower than the scheme of Ge et al. (TDSC'23).
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OML: Open, Monetizable, and Loyal AI</title>
<link>https://arxiv.org/abs/2411.03887</link>
<guid>https://arxiv.org/abs/2411.03887</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，开放、可盈利与忠诚(AOML)，区块链，加密技术，可信执行环境(TEE)

<br /><br />总结:
本文提出了一种名为OML（Open, Monetizable, and Loyal AI）的新方法，旨在通过结合AI、区块链和密码学的跨学科框架来民主化AI的发展。OML利用了包括Trusted Execution Environments（TEE）、全同态加密、功能加密、混淆以及基于AI任务样本复杂性和内在难度的AI原生解决方案等技术。文章创新性地引入了“AI原生密码学”，该领域关注AI数据表示的连续性质及其低维流形，将攻击方法如数据中毒转化为安全工具。OML 1.0版本通过模型指纹识别保护AI模型的完整性和所有权。OML的核心目标是建立一个去中心化、开放透明的AI开发平台，让社区能够参与贡献、变现并拥有AI模型。通过区块链技术实现控制权分散和透明度保证，OML阻止了权力集中，并为AI发展提供了前所未有的问责机制。 <div>
arXiv:2411.03887v1 Announce Type: new 
Abstract: Artificial Intelligence (AI) has steadily improved across a wide range of tasks. However, the development and deployment of AI are almost entirely controlled by a few powerful organizations that are racing to create Artificial General Intelligence (AGI). The centralized entities make decisions with little public oversight, shaping the future of humanity, often with unforeseen consequences. In this paper, we propose OML, which stands for Open, Monetizable, and Loyal AI, an approach designed to democratize AI development. OML is realized through an interdisciplinary framework spanning AI, blockchain, and cryptography. We present several ideas for constructing OML using technologies such as Trusted Execution Environments (TEE), traditional cryptographic primitives like fully homomorphic encryption and functional encryption, obfuscation, and AI-native solutions rooted in the sample complexity and intrinsic hardness of AI tasks. A key innovation of our work is introducing a new scientific field: AI-native cryptography. Unlike conventional cryptography, which focuses on discrete data and binary security guarantees, AI-native cryptography exploits the continuous nature of AI data representations and their low-dimensional manifolds, focusing on improving approximate performance. One core idea is to transform AI attack methods, such as data poisoning, into security tools. This novel approach serves as a foundation for OML 1.0 which uses model fingerprinting to protect the integrity and ownership of AI models. The spirit of OML is to establish a decentralized, open, and transparent platform for AI development, enabling the community to contribute, monetize, and take ownership of AI models. By decentralizing control and ensuring transparency through blockchain technology, OML prevents the concentration of power and provides accountability in AI development that has not been possible before.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Two Sides of the Same Coin: Large-scale Measurements of Builder and Rollup after EIP-4844</title>
<link>https://arxiv.org/abs/2411.03892</link>
<guid>https://arxiv.org/abs/2411.03892</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3、EIP-4844、以太坊、Layer-2扩容、交易策略

<br /><br />总结:
本文详细研究了EIP-4844在以太坊实施后新兴的Layer-2扩容解决方案中，构建者（builders）和rollups市场的战略变化。研究涉及数亿笔交易数据，发现构建者和rollups的效率相互依赖，无法同时优化：当构建者高效运作时，rollups可能在费用上支付过多；反之，若rollups优化成本，则可能导致构建者因交易选择效率低下而亏损。数据显示，约29.48%的区块构造不甚高效，使构建者利润不足；而从rollups角度看，超过72.53%的type-3交易支付了不必要的费用，给rollups带来了显著的经济成本。因此，本文为优化区块链构造和交易策略提供了关键洞见，旨在提升Web3基础设施的经济效率与数据可扩展性，但同时也强调了平衡构建者与rollups效率之间的挑战。 <div>
arXiv:2411.03892v1 Announce Type: new 
Abstract: Web3 is reshaping decentralized ecosystems through innovations like Ethereum. Recently, EIP-4844 is implemented in Ethereum to support its Layer-2 scaling solutions, which introduces a new 128 KB data structure called blob. This upgrade incorporates type-3 transactions with blobs to verify data availability and reduce gas costs for rollups, significantly affecting the strategies of both builders and rollups. In this paper, we present an in-depth study of emerging strategies in builder and rollup markets after EIP-4844, containing hundred million transactions. We find that the efficiency of builder and rollup strategies is interdependent, akin to two sides of the same coin -- both cannot be optimized simultaneously. That is, when builders operate efficiently, rollups tend to overpay in fees, conversely, when rollups optimize their costs, builders may incur losses in inefficient transaction selection. From the side of builders, our results show that 29.48% of these blocks have been constructed inefficiently, which does not produce sufficient profits for builders. Through our evaluation from the side of rollups, we find that over 72.53% of type-3 transactions pay unnecessary fees, leading to notable economic costs of rollups. Our work provides critical insights into optimizing block construction and transaction strategies, advancing the economic efficiency and data scalability of Web3 infrastructures, yet, much like balancing a seesaw, the efficiency of builders and rollups cannot be optimized concurrently.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WiP: Towards a Secure SECP256K1 for Crypto Wallets: Hardware Architecture and Implementation</title>
<link>https://arxiv.org/abs/2411.03910</link>
<guid>https://arxiv.org/abs/2411.03910</guid>
<content:encoded><![CDATA[
<div> 关键词: SECP256K1，椭圆曲线算法，侧信道攻击，硬件钱包，资源效率

总结:
针对SECP256K1椭圆曲线算法在硬件钱包中易遭受侧信道攻击的问题，该工作提出了一种新的、优化了侧信道攻击防御和高效资源利用的硬件架构。新架构融合了完整的加法公式、临时寄存器和并行处理技术，使椭圆曲线点的添加和加倍操作变得不可区分，增强了安全性。实施结果显示，相比于同类作品，该设计平均减少了45%的LUT使用量，突显出其优秀的资源效率优势。 <div>
arXiv:2411.03910v1 Announce Type: new 
Abstract: The SECP256K1 elliptic curve algorithm is fundamental in cryptocurrency wallets for generating secure public keys from private keys, thereby ensuring the protection and ownership of blockchain-based digital assets. However, the literature highlights several successful side-channel attacks on hardware wallets that exploit SECP256K1 to extract private keys. This work proposes a novel hardware architecture for SECP256K1, optimized for side-channel attack resistance and efficient resource utilization. The architecture incorporates complete addition formulas, temporary registers, and parallel processing techniques, making elliptic curve point addition and doubling operations indistinguishable. Implementation results demonstrate an average reduction of 45% in LUT usage compared to similar works, emphasizing the design's resource efficiency.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Taming the Beast of User-Programmed Transactions on Blockchains: A Declarative Transaction Approach</title>
<link>https://arxiv.org/abs/2411.02597</link>
<guid>https://arxiv.org/abs/2411.02597</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、交易框架、声明式区块链交易、性能研究

总结:<br />
本文提出了一种新的交易框架，旨在减少对用户定义的智能合约的需求，该框架将更多原语集成到区块链平台的本机交易类型中。通过采用基于声明式的区块链交易概念，该框架同时解决了智能合约的一些局限性。文章提供了形式化和实现框架，并选择开源区块链数据库BigchainDB作为实施背景，实现了常见交易行为的子集作为使用案例。通过对声明式交易方法与等效智能合约交易模型进行性能比较的研究，揭示了所提方法的多项优势。 <div>
arXiv:2411.02597v1 Announce Type: new 
Abstract: Blockchains are being positioned as the "technology of trust" that can be used to mediate transactions between non-trusting parties without the need for a central authority. They support transaction types that are native to the blockchain platform or user-defined via user programs called smart contracts. Despite the significant flexibility in transaction programmability that smart contracts offer, they pose several usability, robustness, and performance challenges.
  This paper proposes an alternative transaction framework that incorporates more primitives into the native set of transaction types (reducing the likelihood of requiring user-defined transaction programs often). The framework is based on the concept of declarative blockchain transactions whose strength lies in the fact that it addresses several of the limitations of smart contracts simultaneously. A formal and implementation framework is presented, and a subset of commonly occurring transaction behaviors are modeled and implemented as use cases, using an open-source blockchain database, BigchchainDB, as the implementation context. A performance study comparing the declarative transaction approach to equivalent smart contract transaction models reveals several advantages of the proposed approach.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Carbon price fluctuation prediction using blockchain information A new hybrid machine learning approach</title>
<link>https://arxiv.org/abs/2411.02709</link>
<guid>https://arxiv.org/abs/2411.02709</guid>
<content:encoded><![CDATA[
<div> 关键词: 混合机器学习、碳价预测、DILATED卷积神经网络、长短期记忆网络、区块链信息

<br /><br />总结:

本文提出了一种用于碳价格波动预测的新型混合机器学习方法。该方法结合了DILATED卷积神经网络（CNN）和长短期记忆（LSTM）神经网络算法，提升了特征提取效率。在DILATED CNN-LSTM框架基础上，采用L1和L2参数范数惩罚作为正则化手段进行预测，并通过正则化过程引入了与区块链信息相关的指标。实验使用大量数据集对碳价格进行了预测，结果显示，DILATED CNN-LSTM框架优于传统的CNN-LSTM架构，同时区块链信息能有效预测碳价格。在正则化方法中，相比于L1正则化的Smoothly Clipped Absolute Deviation Penalty (SCAD)，L2正则化的Ridge Regression (RR)在价格预测上表现更优。因此，提出的RR-DILATED CNN-LSTM方法能有效地、准确地预测碳价格的波动趋势，为学术界和业界提供了一个新的理论依据和预测方法，尤其对于以碳价为代表的数字资产政策评估及趋势预测具有重要意义。 <div>
arXiv:2411.02709v1 Announce Type: new 
Abstract: In this study, the novel hybrid machine learning approach is proposed in carbon price fluctuation prediction. Specifically, a research framework integrating DILATED Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) neural network algorithm is proposed. The advantage of the combined framework is that it can make feature extraction more efficient. Then, based on the DILATED CNN-LSTM framework, the L1 and L2 parameter norm penalty as regularization method is adopted to predict. Referring to the characteristics of high correlation between energy indicator price and blockchain information in previous literature, and we primarily includes indicators related to blockchain information through regularization process. Based on the above methods, this paper uses a dataset containing an amount of data to carry out the carbon price prediction. The experimental results show that the DILATED CNN-LSTM framework is superior to the traditional CNN-LSTM architecture. Blockchain information can effectively predict the price. Since parameter norm penalty as regularization, Ridge Regression (RR) as L2 regularization is better than Smoothly Clipped Absolute Deviation Penalty (SCAD) as L1 regularization in price forecasting. Thus, the proposed RR-DILATED CNN-LSTM approach can effectively and accurately predict the fluctuation trend of the carbon price. Therefore, the new forecasting methods and theoretical ecology proposed in this study provide a new basis for trend prediction and evaluating digital assets policy represented by the carbon price for both the academia and practitioners.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedBlock: A Blockchain Approach to Federated Learning against Backdoor Attacks</title>
<link>https://arxiv.org/abs/2411.02773</link>
<guid>https://arxiv.org/abs/2411.02773</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 安全风险, Blockchain, FedBlock, Smart Contract

<br /><br />总结:

本文介绍了Federated Learning（联邦学习）的安全风险，包括中心服务器故障和客户端后门攻击，并提出了一种名为FedBlock的基于区块链的新颖FL框架。FedBlock利用智能合约技术，在不集中的数据上实现安全训练，同时消除了对单一中央服务器的依赖，以防止服务器方面的恶意行为。通过实证评估研究，证明了FedBlock在抵御客户端后门攻击方面具有竞争力，并且由于其仅涉及智能合约编程，因此可以部署在任何区块链网络之上。相较于现有文献中针对FL后门防御的方法，FedBlock还额外解决了服务器风险问题。 <div>
arXiv:2411.02773v1 Announce Type: new 
Abstract: Federated Learning (FL) is a machine learning method for training with private data locally stored in distributed machines without gathering them into one place for central learning. Despite its promises, FL is prone to critical security risks. First, because FL depends on a central server to aggregate local training models, this is a single point of failure. The server might function maliciously. Second, due to its distributed nature, FL might encounter backdoor attacks by participating clients. They can poison the local model before submitting to the server. Either type of attack, on the server or the client side, would severely degrade learning accuracy. We propose FedBlock, a novel blockchain-based FL framework that addresses both of these security risks. FedBlock is uniquely desirable in that it involves only smart contract programming, thus deployable atop any blockchain network. Our framework is substantiated with a comprehensive evaluation study using real-world datasets. Its robustness against backdoor attacks is competitive with the literature of FL backdoor defense. The latter, however, does not address the server risk as we do.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Instant Resonance: Dual Strategy Enhances the Data Consensus Success Rate of Blockchain Threshold Signature Oracles</title>
<link>https://arxiv.org/abs/2411.02945</link>
<guid>https://arxiv.org/abs/2411.02945</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链预言机、阈值签名、实时数据采集、一致性、成功率优化

总结:<br />
本文针对区块链预言机中阈值签名在实时数据采集过程中面临的不一致性和低成功率问题，提出了一种创新的双策略方法。首先，文中引入了代表增强聚合策略（REP-AG），该策略通过提升节点提交数据的代表性，确保与其它节点数据的一致性，进而增强阈值签名的可用性。其次，提出了时间优化策略（TIM-OPT），能够动态调整节点访问数据源的时间以最大化共识成功率。实验结果显示，REP-AG相比最优基线可提高聚合成功率约56.6%，而TIM-OPT的实施则使所有场景下的共识成功率平均提高了约32.9%。 <div>
arXiv:2411.02945v1 Announce Type: new 
Abstract: With the rapid development of Decentralized Finance (DeFi) and Real-World Assets (RWA), the importance of blockchain oracles in real-time data acquisition has become increasingly prominent. Using cryptographic techniques, threshold signature oracles can achieve consensus on data from multiple nodes and provide corresponding proofs to ensure the credibility and security of the information. However, in real-time data acquisition, threshold signature methods face challenges such as data inconsistency and low success rates in heterogeneous environments, which limit their practical application potential. To address these issues, this paper proposes an innovative dual-strategy approach to enhance the success rate of data consensus in blockchain threshold signature oracles. Firstly, we introduce a Representative Enhanced Aggregation Strategy (REP-AG) that improves the representativeness of data submitted by nodes, ensuring consistency with data from other nodes, and thereby enhancing the usability of threshold signatures. Additionally, we present a Timing Optimization Strategy (TIM-OPT) that dynamically adjusts the timing of nodes' access to data sources to maximize consensus success rates. Experimental results indicate that REP-AG improves the aggregation success rate by approximately 56.6\% compared to the optimal baseline, while the implementation of TIM-OPT leads to an average increase of approximately 32.9\% in consensus success rates across all scenarios.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FEDLAD: Federated Evaluation of Deep Leakage Attacks and Defenses</title>
<link>https://arxiv.org/abs/2411.03019</link>
<guid>https://arxiv.org/abs/2411.03019</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Deep Leakage、攻击、防御、FEDLAD框架

总结:<br />
本文介绍了arXiv:2411.03019v1论文的主要内容，该论文关注了联邦学习（Federated Learning）中的隐私安全问题。近期研究发现，联邦学习可能因深泄漏（Deep Leakage）等梯度反演技术而遭到隐私泄露。然而，这些攻击方法在实际场景中的效果并未得到充分评估。为此，文章提出了一种名为FEDLAD框架的全面基准评测体系，用于在现实的联邦学习环境中评估和比较多种先进的深泄漏攻击手段与防御策略的效果。该框架涵盖了多个数据集和训练状态下的应用场景，突显了联邦学习中隐私与模型准确性之间的权衡问题，并旨在增进对去中心化机器学习系统安全挑战的理解，推动未来相关领域的研究以及提高深泄漏攻击和防御方法评测的可重复性。 <div>
arXiv:2411.03019v1 Announce Type: new 
Abstract: Federated Learning is a privacy preserving decentralized machine learning paradigm designed to collaboratively train models across multiple clients by exchanging gradients to the server and keeping private data local. Nevertheless, recent research has revealed that the security of Federated Learning is compromised, as private ground truth data can be recovered through a gradient inversion technique known as Deep Leakage. While these attacks are crafted with a focus on applications in Federated Learning, they generally are not evaluated in realistic scenarios. This paper introduces the FEDLAD Framework (Federated Evaluation of Deep Leakage Attacks and Defenses), a comprehensive benchmark for evaluating Deep Leakage attacks and defenses within a realistic Federated context. By implementing a unified benchmark that encompasses multiple state-of-the-art Deep Leakage techniques and various defense strategies, our framework facilitates the evaluation and comparison of the efficacy of these methods across different datasets and training states. This work highlights a crucial trade-off between privacy and model accuracy in Federated Learning and aims to advance the understanding of security challenges in decentralized machine learning systems, stimulate future research, and enhance reproducibility in evaluating Deep Leakage attacks and defenses.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Formal Logic-guided Robust Federated Learning against Poisoning Attacks</title>
<link>https://arxiv.org/abs/2411.03231</link>
<guid>https://arxiv.org/abs/2411.03231</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Poisoning Attacks（中毒攻击）、Time Series Data（时间序列数据）、FLORAL、Defense Mechanism（防御机制）

<br /><br />总结:
本文介绍了针对联邦学习中时间序列任务的中毒攻击防御机制FLORAL。现有的联邦学习防御方法主要关注计算机视觉任务，而对具有异构客户端数据和大量恶意参与者的时间序列数据场景的挑战应对不足。FLORAL通过利用逻辑推理评估客户端的信任度，根据其预测与全局时间序列模式的符合程度，而非仅仅依赖于客户端更新的相似性来确定。该方法首先从客户端提取逻辑推理属性，随后层次化推断全球属性，并使用这些属性验证客户端更新。通过形式逻辑验证，可以识别出代表恶意行为的贡献偏离现象。实验结果显示，相较于现有基线方法，FLORAL在两个数据集上的表现更优，最佳情况下将预测误差降低了93.27%。相关代码已开源发布。 <div>
arXiv:2411.03231v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a promising solution to the privacy concerns associated with centralized Machine Learning (ML) by enabling decentralized, collaborative learning. However, FL is vulnerable to various security threats, including poisoning attacks, where adversarial clients manipulate the training data or model updates to degrade overall model performance. Recognizing this threat, researchers have focused on developing defense mechanisms to counteract poisoning attacks in FL systems. However, existing robust FL methods predominantly focus on computer vision tasks, leaving a gap in addressing the unique challenges of FL with time series data. In this paper, we present FLORAL, a defense mechanism designed to mitigate poisoning attacks in federated learning for time-series tasks, even in scenarios with heterogeneous client data and a large number of adversarial participants. Unlike traditional model-centric defenses, FLORAL leverages logical reasoning to evaluate client trustworthiness by aligning their predictions with global time-series patterns, rather than relying solely on the similarity of client updates. Our approach extracts logical reasoning properties from clients, then hierarchically infers global properties, and uses these to verify client updates. Through formal logic verification, we assess the robustness of each client contribution, identifying deviations indicative of adversarial behavior. Experimental results on two datasets demonstrate the superior performance of our approach compared to existing baseline methods, highlighting its potential to enhance the robustness of FL to time series applications. Notably, FLORAL reduced the prediction error by 93.27\% in the best-case scenario compared to the second-best baseline. Our code is available at \url{https://anonymous.4open.science/r/FLORAL-Robust-FTS}.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scenario-Game ADMM: A Parallelized Scenario-Based Solver for Stochastic Noncooperative Games</title>
<link>https://arxiv.org/abs/2304.01945</link>
<guid>https://arxiv.org/abs/2304.01945</guid>
<content:encoded><![CDATA[
<div> 关键词：多玩家游戏、决策制定、不确定性、样本平均近似（SAA）、场景优化、可行性保证、样例复杂性、分布式、共识基础ADMM算法、广义纳什均衡（GNE）、收敛性、性能优势

总结:<br />
本文提出了针对一类具有随机性、总和形式的纯纳什游戏的新样本近似方法，该类游戏中每个玩家具有期望值目标与机会约束。该方法结合了SAA方法对目标的精确逼近以及场景优化文献中的可行性保证。文中分析了该新游戏理论近似方案的样例复杂性，并注意到高精度通常需要大量样本，导致大量采样约束。为应对这一问题，文章将近似游戏分解为一组具有少量约束的小型游戏，并提出了一种基于分布式、共识型ADMM算法的有效计算近似游戏GNE的方法。论文证明了所提算法能收敛到GNE，并通过实验证明相对于基于ADMM和内点法的最近基线算法具有更好的性能表现。 <div>
arXiv:2304.01945v4 Announce Type: replace 
Abstract: Decision-making in multi-player games can be extremely challenging, particularly under uncertainty. In this work, we propose a new sample-based approximation to a class of stochastic, general-sum, pure Nash games, where each player has an expected-value objective and a set of chance constraints. This new approximation scheme inherits the accuracy of objective approximation from the established sample average approximation (SAA) method and enjoys a feasibility guarantee derived from the scenario optimization literature. We characterize the sample complexity of this new game-theoretic approximation scheme, and observe that high accuracy usually requires a large number of samples, which results in a large number of sampled constraints. To accommodate this, we decompose the approximated game into a set of smaller games with few constraints for each sampled scenario, and propose a decentralized, consensus-based ADMM algorithm to efficiently compute a generalized Nash equilibrium (GNE) of the approximated game. We prove the convergence of our algorithm to a GNE and empirically demonstrate superior performance relative to a recent baseline algorithm based on ADMM and interior point method.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks</title>
<link>https://arxiv.org/abs/2411.01050</link>
<guid>https://arxiv.org/abs/2411.01050</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 非独立同分布数据, 偏差检测, 客户选择算法, 无线网络约束

<br /><br />总结:

本文提出了一种名为Bias-Aware Client Selection Algorithm (BACSA)的新方法，用于解决联邦学习(FL)在医疗保健领域的非独立同分布数据导致的性能下降问题。BACSA能检测客户端的数据偏差，并根据这些偏差资料进行策略性选择，同时考虑了隐私保护、公平性和无线网络环境的约束条件，特别适合对服务质量、隐私和安全性要求较高的医疗应用。该方法首先通过分析模型参数与类特定数据样本分布之间的相关性来创新性地检测用户偏差，然后结合无线网络约束构建了一个混合整数非线性的客户选择优化问题。实验表明，相较于现有基准，BACSA可以改善FL的收敛性和准确性，并能在不同数据分布场景（如Dirichlet和类别约束场景）中表现出优势。此外，文中还探讨了准确度、公平性和网络约束之间的权衡关系，证明了BACSA在应对多样化医疗应用场景中的适应性和鲁棒性。 <div>
arXiv:2411.01050v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a transformative approach in healthcare, enabling collaborative model training across decentralized data sources while preserving user privacy. However, performance of FL rapidly degrades in practical scenarios due to the inherent bias in non Independent and Identically distributed (non-IID) data among participating clients, which poses significant challenges to model accuracy and generalization. Therefore, we propose the Bias-Aware Client Selection Algorithm (BACSA), which detects user bias and strategically selects clients based on their bias profiles. In addition, the proposed algorithm considers privacy preservation, fairness and constraints of wireless network environments, making it suitable for sensitive healthcare applications where Quality of Service (QoS), privacy and security are paramount. Our approach begins with a novel method for detecting user bias by analyzing model parameters and correlating them with the distribution of class-specific data samples. We then formulate a mixed-integer non-linear client selection problem leveraging the detected bias, alongside wireless network constraints, to optimize FL performance. We demonstrate that BACSA improves convergence and accuracy, compared to existing benchmarks, through evaluations on various data distributions, including Dirichlet and class-constrained scenarios. Additionally, we explore the trade-offs between accuracy, fairness, and network constraints, indicating the adaptability and robustness of BACSA to address diverse healthcare applications.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strengthening DeFi Security: A Static Analysis Approach to Flash Loan Vulnerabilities</title>
<link>https://arxiv.org/abs/2411.01230</link>
<guid>https://arxiv.org/abs/2411.01230</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), flash loans, security vulnerabilities, price manipulation, FlashDeFier

总结:<br />
随着去中心化金融(DeFi)的发展，其带来了新的金融机遇，但也暴露了严重的安全漏洞，尤其是闪贷常被用于价格操纵攻击。这类攻击利用闪贷的原子性来操纵DeFi协议的预言机和定价机制，导致重大财务损失。尽管现有的智能合约分析工具能够解决一些安全风险，但它们往往难以检测到构成闪贷攻击挑战性的复杂跨合约依赖关系。为此，研究者提出了一种名为FlashDeFier的高级检测框架，该框架扩展了静态污点分析的应用，以针对源自闪贷的价格操纵漏洞。FlashDeFier通过构建详细的跨合约调用图，全面分析了DeFi协议中的数据流，从而显著提高了检测准确性。实验证明，FlashDeFier在针对一系列知名DeFi事件的数据集中，识别出了76.4%的价格操纵漏洞，相较于DeFiTainter有30%的提升。这些结果强调了适应性检测框架对于随DeFi威胁演进而发展的必要性，并指出需要结合静态、动态和符号分析方法的混合方法来实现DeFi安全的韧性。 <div>
arXiv:2411.01230v1 Announce Type: new 
Abstract: The rise of Decentralized Finance (DeFi) has brought novel financial opportunities but also exposed serious security vulnerabilities, with flash loans frequently exploited for price manipulation attacks. These attacks, leveraging the atomic nature of flash loans, allow malicious actors to manipulate DeFi protocol oracles and pricing mechanisms within a single transaction, causing substantial financial losses. Traditional smart contract analysis tools address some security risks but often struggle to detect the complex, inter-contract dependencies that make flash loan attacks challenging to identify.
  In response, we introduce FlashDeFier, an advanced detection framework that enhances static taint analysis to target price manipulation vulnerabilities arising from flash loans. FlashDeFier expands the scope of taint sources and sinks, enabling comprehensive analysis of data flows across DeFi protocols. The framework constructs detailed inter-contract call graphs to capture sophisticated data flow patterns, significantly improving detection accuracy. Tested against a dataset of high-profile DeFi incidents, FlashDeFier identifies 76.4% of price manipulation vulnerabilities, marking a 30% improvement over DeFiTainter. These results highlight the importance of adaptive detection frameworks that evolve alongside DeFi threats, underscoring the need for hybrid approaches combining static, dynamic, and symbolic analysis methods for resilient DeFi security.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Federated Learning by Entropy-Based Client Selection</title>
<link>https://arxiv.org/abs/2411.01240</link>
<guid>https://arxiv.org/abs/2411.01240</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、联邦学习、数据分布偏斜、FedEntOpt、分类准确性

<br /><br />总结:

本文介绍了深度学习在各行业中带来的变革，尤其是针对敏感数据隐私问题提出了联邦学习方案。然而，当客户端（客户）间的数据分布存在显著差异，特别是标签分布偏斜时，传统联邦学习方法的性能会严重下降。为解决这一问题，文章提出了一种名为FedEntOpt的新方法，该方法旨在通过最大化所选客户端子集在全球标签分布上的熵来缓解由标签分布偏斜引起的性能问题，确保从各个可用标签的数据中学习到模型参数。实验结果显示，FedEntOpt在多个基准数据集上相比现有最优算法提高了高达6%的分类精度，尤其在低参与率情况下表现出稳健且优越的性能。此外，FedEntOpt还具有与其他算法结合的灵活性，可进一步提升它们的性能超过40%。 <div>
arXiv:2411.01240v1 Announce Type: new 
Abstract: Deep learning is an emerging field revolutionizing various industries, including natural language processing, computer vision, and many more. These domains typically require an extensive amount of data for optimal performance, potentially utilizing huge centralized data repositories. However, such centralization could raise privacy issues concerning the storage of sensitive data. To address this issue, federated learning was developed. It is a newly distributed learning technique that enables to collaboratively train a deep learning model on decentralized devices, referred to as clients, without compromising their data privacy. Traditional federated learning methods often suffer from severe performance degradation when the data distribution among clients differs significantly. This becomes especially problematic in the case of label distribution skew, where the distribution of labels varies across clients. To address this, a novel method called FedEntOpt is proposed. FedEntOpt is designed to mitigate performance issues caused by label distribution skew by maximizing the entropy of the global label distribution of the selected client subset in each federated learning round. This ensures that the aggregated model parameters from the clients were exhibited to data from all available labels, which improves the accuracy of the global model. Extensive experiments on several benchmark datasets show that the proposed method outperforms several state-of-the-art algorithms by up to 6% in classification accuracy, demonstrating robust and superior performance, particularly under low participation rates. In addition, it offers the flexibility to be combined with them, enhancing their performance by over 40%.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trustworthy Federated Learning: Privacy, Security, and Beyond</title>
<link>https://arxiv.org/abs/2411.01583</link>
<guid>https://arxiv.org/abs/2411.01583</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (联邦学习)，数据隐私，安全问题，防御策略，应用场景

<br />
总结: 本文针对近年来大数据和人工智能发展背景下，数据隐私与安全的重要性日益凸显的问题，深入探讨了一种创新方法——联邦学习（Federated Learning, FL）。FL能够在不转移原始数据的情况下，促进分布式数据源间的协同模型训练，然而其在分散网络中的强安全性和隐私性保障仍面临挑战。文章全面调研了FL中存在的安全和隐私问题，强调了通信链路的脆弱性和潜在的网络安全威胁，并对抵御这些风险的各种防御策略进行了探讨。同时，文章还分析了FL在不同领域的应用，并提出了相关研究方向。通过对FL框架中复杂的安全挑战进行识别，本文旨在为构建安全、高效的FL系统做出贡献。 <div>
arXiv:2411.01583v1 Announce Type: new 
Abstract: While recent years have witnessed the advancement in big data and Artificial Intelligence (AI), it is of much importance to safeguard data privacy and security. As an innovative approach, Federated Learning (FL) addresses these concerns by facilitating collaborative model training across distributed data sources without transferring raw data. However, the challenges of robust security and privacy across decentralized networks catch significant attention in dealing with the distributed data in FL. In this paper, we conduct an extensive survey of the security and privacy issues prevalent in FL, underscoring the vulnerability of communication links and the potential for cyber threats. We delve into various defensive strategies to mitigate these risks, explore the applications of FL across different sectors, and propose research directions. We identify the intricate security challenges that arise within the FL frameworks, aiming to contribute to the development of secure and efficient FL systems.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Token Composition: A Graph Based on EVM Logs</title>
<link>https://arxiv.org/abs/2411.01693</link>
<guid>https://arxiv.org/abs/2411.01693</guid>
<content:encoded><![CDATA[
<div> 关键词: 代币、区块链、市场资本化、图论、结构分析

<br /><br />总结: 这篇文章针对区块链上日益增长的代币数量、市值和用途进行了实证分析，重点关注了以太坊区块链上的代币构成。文章引入了一个表示代币间相互代币化的图论模型，并发现该图具有非平凡的拓扑结构。研究者关联了图的属性（如连通组件和循环结构）与代币化过程，并找出了最长有向路径及其对应的代币序列。同时，他们还可视化了稳定币和NFT协议相关的连通组件。总的来说，本文旨在探索并可视化代币化进程带来的影响，而非单纯增加新的理论构建。 <div>
arXiv:2411.01693v1 Announce Type: new 
Abstract: Tokens have proliferated across blockchains in terms of number, market capitalisation and utility. Some tokens are tokenised versions of existing tokens -- known variously as wrapped tokens, fractional tokens, or shares. The repeated application of this process creates matryoshkian tokens of arbitrary depth. We perform an empirical analysis of token composition on the Ethereum blockchain. We introduce a graph that represents the tokenisation of tokens by other tokens, and we show that the graph contains non-trivial topological structure. We relate properties of the graph, e.g., connected components and cyclic structure, to the tokenisation process. For example, we identify the longest directed path and its corresponding sequence of tokens, and we visualise the connected components relating to a stablecoin and an NFT protocol. Our goal is to explore and visualise what has been wrought with tokens, rather than add yet another brick to the edifice.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Revisiting Game-Theoretic Control in Socio-Technical Networks: Emerging Design Frameworks and Contemporary Applications</title>
<link>https://arxiv.org/abs/2411.01794</link>
<guid>https://arxiv.org/abs/2411.01794</guid>
<content:encoded><![CDATA[
<div> 关键词: socio-technical networks, game-theoretic frameworks, Stackelberg games, mechanism design, dynamic game theory

<br /><br />总结:
本文研究了针对社会技术网络的设计与控制的博弈论框架，特别是在误信息管理、基础设施优化和社交通信物理系统（SCPS）中的韧性等方面的应用。文章探讨了Stackelberg游戏、机制设计和动态博弈理论等核心方法，作为在层级化、多智能体环境中建模交互的强大工具。文中着重解决了由人类行为引发的系统脆弱性问题、大规模系统动态管理以及对抗敌对威胁等问题。通过将博弈论与控制理论相结合，该工作展示了如何引导分散的智能体行为与系统的全局稳定性、安全性和效率目标相一致，从而构建出强大、有韧性和适应性的社会技术网络。此外，文章还突显了这些框架在动态调整分散行动以符合系统范围内的整体目标方面的潜力。 <div>
arXiv:2411.01794v1 Announce Type: new 
Abstract: Socio-technical networks represent emerging cyber-physical infrastructures that are tightly interwoven with human networks. The coupling between human and technical networks presents significant challenges in managing, controlling, and securing these complex, interdependent systems. This paper investigates game-theoretic frameworks for the design and control of socio-technical networks, with a focus on critical applications such as misinformation management, infrastructure optimization, and resilience in socio-cyber-physical systems (SCPS). Core methodologies, including Stackelberg games, mechanism design, and dynamic game theory, are examined as powerful tools for modeling interactions in hierarchical, multi-agent environments. Key challenges addressed include mitigating human-driven vulnerabilities, managing large-scale system dynamics, and countering adversarial threats. By bridging individual agent behaviors with overarching system goals, this work illustrates how the integration of game theory and control theory can lead to robust, resilient, and adaptive socio-technical networks. This paper highlights the potential of these frameworks to dynamically align decentralized agent actions with system-wide objectives of stability, security, and efficiency.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedReMa: Improving Personalized Federated Learning via Leveraging the Most Relevant Clients</title>
<link>https://arxiv.org/abs/2411.01825</link>
<guid>https://arxiv.org/abs/2411.01825</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning，Personalized Federated Learning，Class-imbalance，FedReMa，Adaptive Inter-client Co-learning

<br /><br />总结:
本文提出了一种名为FedReMa的个性化联邦学习算法，旨在解决联邦学习和个性化联邦学习中的类别不平衡问题。FedReMa通过采用自适应跨客户端协同学习方法，在训练的不同阶段识别并利用不同客户端在不同数据类别的专长。同时，它对客户端的特征提取器和分类器应用不同的聚合策略，这些策略的选择依据于模型组件的不同角色和含义。实验驱动的关键协同学习周期（CCP）中，FedReMa使用最大差异分割（MDS）模块分析客户端分类器的logits相似性以评估和管理任务相关性。在非CCP期间，FedReMa利用每个客户端历史上最相关的同行的历史记录进一步增强个性化稳定性。通过广泛的实验，展示了FedReMa的优越性能。 <div>
arXiv:2411.01825v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning paradigm that achieves a globally robust model through decentralized computation and periodic model synthesis, primarily focusing on the global model's accuracy over aggregated datasets of all participating clients. Personalized Federated Learning (PFL) instead tailors exclusive models for each client, aiming to enhance the accuracy of clients' individual models on specific local data distributions. Despite of their wide adoption, existing FL and PFL works have yet to comprehensively address the class-imbalance issue, one of the most critical challenges within the realm of data heterogeneity in PFL and FL research. In this paper, we propose FedReMa, an efficient PFL algorithm that can tackle class-imbalance by 1) utilizing an adaptive inter-client co-learning approach to identify and harness different clients' expertise on different data classes throughout various phases of the training process, and 2) employing distinct aggregation methods for clients' feature extractors and classifiers, with the choices informed by the different roles and implications of these model components. Specifically, driven by our experimental findings on inter-client similarity dynamics, we develop critical co-learning period (CCP), wherein we introduce a module named maximum difference segmentation (MDS) to assess and manage task relevance by analyzing the similarities between clients' logits of their classifiers. Outside the CCP, we employ an additional scheme for model aggregation that utilizes historical records of each client's most relevant peers to further enhance the personalization stability. We demonstrate the superiority of our FedReMa in extensive experiments.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards the Industrial Metaverse: A Game-Based VR Application for Fire Drill and Evacuation Training for Ships and Shipbuilding</title>
<link>https://arxiv.org/abs/2411.01895</link>
<guid>https://arxiv.org/abs/2411.01895</guid>
<content:encoded><![CDATA[
<div> 关键词：Virtual Reality、Industrial Metaverse、shipboard fire emergency training、SOLAS公约、user evaluation

<br /><br />总结:

本文介绍了针对船舶火灾应急训练的一款创新虚拟现实应用，该应用符合《国际海上人命安全公约》（SOLAS）的要求，设计了不同级别的游戏化场景（如引擎室和厨房的不同火势等级）。文章全面阐述了VR开发过程并提供了整体概述与实践指南，旨在引导业界人士、开发者及未来研究者塑造造船行业的下一代工业元宇宙应用。此外，文中还包含了对初步用户评价的结果分析，旨在量化用户的决策制定和风险评估技能。实验结果为评估用户表现并指出未来挑战提供了有益见解。 <div>
arXiv:2411.01895v1 Announce Type: new 
Abstract: This paper details the creation of a novel Virtual Reality-based application for the Industrial Metaverse aimed at shipboard fire emergency training for fire drill and evacuation, aligned with the Safety of Life at Sea (SOLAS) convention requirements. Specifically, the application includes gamified scenarios with different levels (e.g., varying fire intensities in engine rooms and galleys). The paper details comprehensively the VR development while providing a holistic overview and practical guidelines. Thus, it can guide practitioners, developers and future researchers to shape the next generation of Industrial Metaverse applications for the shipbuilding industry. Moreover, the paper includes the results of a preliminary user evaluation aimed at quantifying user decision-making and risk assessment skills. The presented results of the experiments provide insights into user performance and allow for pointing out at different future challenges.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FPPL: An Efficient and Non-IID Robust Federated Continual Learning Framework</title>
<link>https://arxiv.org/abs/2411.01904</link>
<guid>https://arxiv.org/abs/2411.01904</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Continual Learning (FCL)，Catastrophic Forgetting，Privacy，Non-IID，Federated Prototype-Augmented Prompt Learning (FPPL)

<br /><br />总结:
本文提出了一种新的联邦持续学习框架——Federated Prototype-Augmented Prompt Learning (FPPL)，旨在解决联邦学习环境中数据流的序列学习及灾难性遗忘问题。现有的FCL方法常使用典型的重排机制，可能引发隐私侵犯或增加额外存储和计算负担。与之不同，FPPL通过无重演的方式协同学习轻量级的提示并结合原型。客户端采用融合函数充分利用任务特定提示的知识来缓解灾难性遗忘；同时，服务器端聚合的全局原型用于对比学习，以统一表示形式减轻非IID导致的数据异质性影响。在服务器端，利用本地上传的原型对分类器进行去偏处理，进一步减少了非IID和灾难性遗忘造成的性能退化。实证评估显示，FPPL在高效设计的同时表现出显著的性能优势，并能适应各种程度的非IID数据分布。相关代码已开源至https://github.com/ycheoo/FPPL。 <div>
arXiv:2411.01904v1 Announce Type: new 
Abstract: Federated continual learning (FCL) aims to learn from sequential data stream in the decentralized federated learning setting, while simultaneously mitigating the catastrophic forgetting issue in classical continual learning. Existing FCL methods usually employ typical rehearsal mechanisms, which could result in privacy violations or additional onerous storage and computational burdens. In this work, an efficient and non-IID robust federated continual learning framework, called Federated Prototype-Augmented Prompt Learning (FPPL), is proposed. The FPPL can collaboratively learn lightweight prompts augmented by prototypes without rehearsal. On the client side, a fusion function is employed to fully leverage the knowledge contained in task-specific prompts for alleviating catastrophic forgetting. Additionally, global prototypes aggregated from the server are used to obtain unified representation through contrastive learning, mitigating the impact of non-IID-derived data heterogeneity. On the server side, locally uploaded prototypes are utilized to perform debiasing on the classifier, further alleviating the performance degradation caused by both non-IID and catastrophic forgetting. Empirical evaluations demonstrate the effectiveness of FPPL, achieving notable performance with an efficient design while remaining robust to diverse non-IID degrees. Code is available at: https://github.com/ycheoo/FPPL.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks</title>
<link>https://arxiv.org/abs/2411.01924</link>
<guid>https://arxiv.org/abs/2411.01924</guid>
<content:encoded><![CDATA[
<div> 关键词：6G无线网络、传输功率分配、深度神经网络、公平性、Kolmogorov-Arnold网络

总结:
本文针对6G无线网络中的用户传输功率分配问题，旨在通过优化$\alpha$-公平性来平衡网络利用效率和用户公平。文章提出了一种使用具有较低推理成本和较高可解释性的新型机器学习模型——Kolmogorov-Arnold网络（KANs）的方法，以解决传统深度神经网络在决策过程中的公平性和计算效率问题。首先，文章对功率分配问题进行了全面的问题形式化，并证明其为NP难问题。接着，提出了两种算法分别用于数据集生成和分布式KAN训练，为动态6G环境下的不同公平目标实现提供了灵活框架。通过大量数值模拟验证了所提方法在公平性和推理成本方面的优越性，显示出KANs有潜力克服现有基于DNN方法的局限性，特别是在需要快速适应和公平性的场景中。 <div>
arXiv:2411.01924v1 Announce Type: new 
Abstract: The effective distribution of user transmit powers is essential for the significant advancements that the emergence of 6G wireless networks brings. In recent studies, Deep Neural Networks (DNNs) have been employed to address this challenge. However, these methods frequently encounter issues regarding fairness and computational inefficiency when making decisions, rendering them unsuitable for future dynamic services that depend heavily on the participation of each individual user. To address this gap, this paper focuses on the challenge of transmit power allocation in wireless networks, aiming to optimize $\alpha$-fairness to balance network utilization and user equity. We introduce a novel approach utilizing Kolmogorov-Arnold Networks (KANs), a class of machine learning models that offer low inference costs compared to traditional DNNs through superior explainability. The study provides a comprehensive problem formulation, establishing the NP-hardness of the power allocation problem. Then, two algorithms are proposed for dataset generation and decentralized KAN training, offering a flexible framework for achieving various fairness objectives in dynamic 6G environments. Extensive numerical simulations demonstrate the effectiveness of our approach in terms of fairness and inference cost. The results underscore the potential of KANs to overcome the limitations of existing DNN-based methods, particularly in scenarios that demand rapid adaptation and fairness.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially private and decentralized randomized power method</title>
<link>https://arxiv.org/abs/2411.01931</link>
<guid>https://arxiv.org/abs/2411.01931</guid>
<content:encoded><![CDATA[
<div> 关键词：randomized power method、Differential Privacy (DP)、variance reduction、decentralized framework、Secure Aggregation

总结:<br />
本文关注增强随机化幂方法的隐私保护变体。文章提出了降低为了实现差分隐私（DP）而引入的噪声方差的策略。同时，该方法被适应到一个具有低计算和通信开销的去中心化框架中，同时保持准确性。通过利用安全聚合（一种多方计算的形式），算法可以在不泄露个人数据的情况下使用分布式在多个用户或设备上的数据进行计算。研究显示，在去中心化设置中可以使用的噪声规模与集中式设置中的相似。此外，对于集中式和去中心化的版本，文章都改进了现有的收敛界。这种方法对于重视隐私问题的分布式推荐系统等去中心化应用尤其相关。 <div>
arXiv:2411.01931v1 Announce Type: new 
Abstract: The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. As modern datasets contain sensitive private information, we need to give formal guarantees on the possible privacy leaks caused by this method. This paper focuses on enhancing privacy preserving variants of the method. We propose a strategy to reduce the variance of the noise introduced to achieve Differential Privacy (DP). We also adapt the method to a decentralized framework with a low computational and communication overhead, while preserving the accuracy. We leverage Secure Aggregation (a form of Multi-Party Computation) to allow the algorithm to perform computations using data distributed among multiple users or devices, without revealing individual data. We show that it is possible to use a noise scale in the decentralized setting that is similar to the one in the centralized setting. We improve upon existing convergence bounds for both the centralized and decentralized versions. The proposed method is especially relevant for decentralized applications such as distributed recommender systems, where privacy concerns are paramount.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fuzzing Processing Pipelines for Zero-Knowledge Circuits</title>
<link>https://arxiv.org/abs/2411.02077</link>
<guid>https://arxiv.org/abs/2411.02077</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-knowledge (ZK) protocols, metamorphic testing, fuzzing, Circuzz, logic bugs

总结:
本文提出了首个针对零知识证明（ZK）管道的系统性模糊测试技术，该技术利用元变异测试 oracle 来检测关键逻辑错误。研究者开发了一个名为 Circuzz 的开源工具来实现这一方法，并对其进行了实际应用。通过使用 Circuzz 对四个具有显著差异的 ZK 管道进行测试，他们总共发现了 16 个逻辑错误，其中 15 个由于其严重性已得到开发者修复。这项工作揭示了对 ZK 管道进行有效正确性检查的重要性以及模糊测试与元变异测试相结合的技术潜力。 <div>
arXiv:2411.02077v1 Announce Type: new 
Abstract: Zero-knowledge (ZK) protocols have recently found numerous practical applications, such as in authentication, online-voting, and blockchain systems. These protocols are powered by highly complex pipelines that process deterministic programs, called circuits, written in one of many domain-specific programming languages, e.g., Circom, Noir, and others. Logic bugs in circuit-processing pipelines could have catastrophic consequences and cause significant financial and reputational damage. As an example, consider that a logic bug in a ZK pipeline could result in attackers stealing identities or assets. It is, therefore, critical to develop effective techniques for checking their correctness.
  In this paper, we present the first systematic fuzzing technique for ZK pipelines, which uses metamorphic test oracles to detect critical logic bugs. We have implemented our technique in an open-source tool called Circuzz. We used Circuzz to test four significantly different ZK pipelines and found a total of 16 logic bugs in all pipelines. Due to their critical nature, 15 of our bugs have already been fixed by the pipeline developers.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digital Twin-Assisted Federated Learning with Blockchain in Multi-tier Computing Systems</title>
<link>https://arxiv.org/abs/2411.02323</link>
<guid>https://arxiv.org/abs/2411.02323</guid>
<content:encoded><![CDATA[
<div> 关键词：工业互联网、数字孪生、区块链、联邦学习、延迟优化

总结:
本文研究了工业4.0系统中资源受限的工业物联网设备频繁进行数据交互所引发的安全和隐私问题。为此，提出了一种结合数字孪生(DT)和区块链辅助的联邦学习(FL)方案。首先，利用具有丰富计算能力的雾设备为边缘设备生成DT，帮助其进行本地训练。接着，文章针对FL过程构建了一个考虑模型传输时间和同步时间以及通过合作干扰保障DT安全同步的延迟最小化问题，并提出了分解算法来解决这个非凸优化问题。在此过程中，通过设置局部设备训练延迟上限和聚合干扰影响的辅助变量，将原问题转化为可独立求解的凸优化问题。此外，采用区块链验证机制保证FL过程中模型上传的完整性和参与者的身份认证。最终，通过深学习技术从区块链内的验证局部和全局模型获取全局模型。数值分析验证了所提合作干扰基联邦学习流程的有效性，表明该集成DT区块链辅助的FL方案在执行时间、区块优化和精度方面显著优于基准方案。 <div>
arXiv:2411.02323v1 Announce Type: new 
Abstract: In Industry 4.0 systems, a considerable number of resource-constrained Industrial Internet of Things (IIoT) devices engage in frequent data interactions due to the necessity for model training, which gives rise to concerns pertaining to security and privacy. In order to address these challenges, this paper considers a digital twin (DT) and blockchain-assisted federated learning (FL) scheme. To facilitate the FL process, we initially employ fog devices with abundant computational capabilities to generate DT for resource-constrained edge devices, thereby aiding them in local training. Subsequently, we formulate an FL delay minimization problem for FL, which considers both of model transmission time and synchronization time, also incorporates cooperative jamming to ensure secure synchronization of DT. To address this non-convex optimization problem, we propose a decomposition algorithm. In particular, we introduce upper limits on the local device training delay and the effects of aggregation jamming as auxiliary variables, thereby transforming the problem into a convex optimization problem that can be decomposed for independent solution. Finally, a blockchain verification mechanism is employed to guarantee the integrity of the model uploading throughout the FL process and the identities of the participants. The final global model is obtained from the verified local and global models within the blockchain through the application of deep learning techniques. The efficacy of our proposed cooperative interference-based FL process has been verified through numerical analysis, which demonstrates that the integrated DT blockchain-assisted FL scheme significantly outperforms the benchmark schemes in terms of execution time, block optimization, and accuracy.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Two-Sided Learning in Decentralized Matching Markets</title>
<link>https://arxiv.org/abs/2411.02377</link>
<guid>https://arxiv.org/abs/2411.02377</guid>
<content:encoded><![CDATA[
<div> 关键词：两-sided匹配市场、学习算法、偏好不确定性、稳定匹配、策略证明

总结:
本文研究了在双方都存在偏好不确定性的匹配市场上，如何通过学习算法引导各自主体行为以达成理想匹配的问题。文章提出了一个名为“试错学习”的简单政策，当所有主体遵循该政策时，可以收敛到稳定的匹配状态。接着，文章探讨了该政策的策略证明性质，并指出如果一方遵循试错学习，而另一方采用更高级别的政策，则他们将收敛到对第二方最有利的稳定匹配。这是首次提出的完全解耦和非协调性政策，能展示在去中心化市场中从双方面不确定性向稳定性收敛的概念。 <div>
arXiv:2411.02377v1 Announce Type: new 
Abstract: Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in many practical applications. In settings where the agents can assess the quality of their possible partners a priori, well-known centralized algorithms can be used to find desirable matchings between the two groups. However, when they do not know their own preferences, such algorithms are no longer applicable and agents must instead learn their preferences through repeated interactions with one another. In this work, we design completely uncoupled and uncoordinated policies that use an agent's limited historical observations to guide their behavior towards desirable matchings when they do not know their preferences. In our first main contribution, we demonstrate that when every agent follows a simple policy which we call trial-and-error learning, they will converge to a stable matching, the standard equilibrium configuration in matching markets. Then, we evaluate the strategyproofness of this policy and ask whether one group of agents can improve their performance by following a different policy. We constructively answer this question in the affirmative, demonstrating that if one group follows simple trial-and-error learning while the second group follows a more advanced policy, then they will converge to the most preferable stable matching for the second group. To the best of the authors' knowledge, these are the first completely uncoupled and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized markets with two-sided uncertainty.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The role of the metaverse in calibrating an embodied artificial general intelligence</title>
<link>https://arxiv.org/abs/2402.06660</link>
<guid>https://arxiv.org/abs/2402.06660</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied AGI、human consciousness、metaverse、calibrated symbolic interface、decentralized governance

<br />
总结:
本文探讨了具身人工智能（AGI）的概念及其与人类意识的关系，并着重分析了元宇宙在此关系中起到的关键作用。文章引用了包括具身认知、迈克尔·莱文的“自我”计算边界理论、唐纳德·霍夫曼的界面感知理论以及伯纳多·卡斯楚普的分析理想主义等哲学和本体论框架。文中讨论了AGI的发展阶段、实现具身AGI的要求、为AGI设计校准的符号接口的重要性，以及元宇宙、去中心化系统、开源区块链技术和开放源码AI研究在这方面的作用。此外，还提出了AGI与人类用户在元宇宙空间中的反馈循环作为AGI校准工具的概念，以及实现稳定具身AGI所需的局部稳态和去中心化治理的前提条件。最后，文章强调在全球范围内达到一定程度的人类和谐关系和认识到人类互联共生的重要性，是催生稳定具身AGI的关键前提。 <div>
arXiv:2402.06660v2 Announce Type: replace 
Abstract: This paper leverages various philosophical and ontological frameworks to explore the concept of embodied artificial general intelligence (AGI), its relationship to human consciousness, and the key role of the metaverse in facilitating this relationship. Several theoretical frameworks underpin this exploration, such as embodied cognition, Michael Levin's computational boundary of a "Self," Donald D. Hoffman's Interface Theory of Perception, and Bernardo Kastrup's analytical idealism, which lead to considering our perceived outer reality as a symbolic representation of alternate inner states of being, and where AGI could embody a higher consciousness with a larger computational boundary. The paper further discusses the developmental stages of AGI, the requirements for the emergence of an embodied AGI, the importance of a calibrated symbolic interface for AGI, and the key role played by the metaverse, decentralized systems, open-source blockchain technology, as well as open-source AI research. It also explores the idea of a feedback loop between AGI and human users in metaverse spaces as a tool for AGI calibration, as well as the role of local homeostasis and decentralized governance as preconditions for achieving a stable embodied AGI. The paper concludes by emphasizing the importance of achieving a certain degree of harmony in human relations and recognizing the interconnectedness of humanity at a global level, as key prerequisites for the emergence of a stable embodied AGI.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>4CNet: A Diffusion Approach to Map Prediction for Decentralized Multi-robot Exploration</title>
<link>https://arxiv.org/abs/2402.17904</link>
<guid>https://arxiv.org/abs/2402.17904</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile robots, unknown environments, deep learning, 4CNet, exploration

总结:<br />
本文提出了一种针对未知复杂环境中移动机器人探索问题的新颖深度学习架构——4CNet。该模型具有三个独特之处：1）用于未结构化未知区域地图预测的条件一致性模型；2）通过对比学习预训练框架从附近机器人的轨迹中提取空间信息的轨迹编码器；3）用于测量地图预测不确定性的信心网络，以实现资源约束下的有效探索。将4CNet整合到提出的4CNet-E机器人探索与地图预测框架中，文章对4CNet-E与其他主流启发式和学习方法进行了广泛比较研究，结果显示，无论环境大小、机器人数量、能量预算还是通信限制如何变化，4CNet-E均能实现更高的地图预测精度和覆盖面积。此外，还进行了一系列室内和真实自然户外环境的硬件实验，验证了4CNet-E的适用性和泛化能力。 <div>
arXiv:2402.17904v2 Announce Type: replace 
Abstract: Mobile robots in unknown cluttered environments with irregularly shaped obstacles often face sensing, energy, and communication challenges which directly affect their ability to explore these environments. In this paper, we introduce a novel deep learning architecture, Confidence-Aware Contrastive Conditional Consistency Model (4CNet), for robot map prediction during decentralized, resource-limited multi-robot exploration. 4CNet uniquely incorporates: 1) a conditional consistency model for map prediction in unstructured unknown regions, 2) a contrastive map-trajectory pretraining framework for a trajectory encoder that extracts spatial information from the trajectories of nearby robots during map prediction, and 3) a confidence network to measure the uncertainty of map prediction for effective exploration under resource constraints. We incorporate 4CNet within our proposed robot exploration with map prediction architecture, 4CNet-E. We then conduct extensive comparison studies with 4CNet-E and state-of-the-art heuristic and learning methods to investigate both map prediction and exploration performance in environments consisting of irregularly shaped obstacles and uneven terrain. Results showed that 4CNet-E obtained statistically significant higher prediction accuracy and area coverage with varying environment sizes, number of robots, energy budgets, and communication limitations. Hardware experiments were performed and validated the applicability and generalizability of 4CNet-E in both unstructured indoor and real natural outdoor environments.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character Simulation via Narrative Planning</title>
<link>https://arxiv.org/abs/2405.13042</link>
<guid>https://arxiv.org/abs/2405.13042</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化剧情生成, 游戏体验, 大型语言模型, 作者意图, 抽象行为

总结:
本文提出了一种新的游戏自动化剧情生成流程，旨在解决传统方法对知识工程依赖以及基于大型语言模型（LLMs）的虚拟角色交互产生的剧情难以控制的问题。该流程引入了“抽象行为”的概念，使得作家可以定义高级剧情轮廓，随后通过LLM驱动的叙事规划过程将其转化为具体的字符动作序列，依据游戏世界状态动态适应并推进剧情发展。这种方法实现了由作者、角色模拟和玩家共同参与创作的“活生生的故事”。文章通过名为StoryVerse的概念验证系统展示了这一剧情创建工作流的灵活性，并通过不同故事和游戏环境的例子进行了展示。<br /><br /> <div>
arXiv:2405.13042v2 Announce Type: replace 
Abstract: Automated plot generation for games enhances the player's experience by providing rich and immersive narrative experience that adapts to the player's actions. Traditional approaches adopt a symbolic narrative planning method which limits the scale and complexity of the generated plot by requiring extensive knowledge engineering work. Recent advancements use Large Language Models (LLMs) to drive the behavior of virtual characters, allowing plots to emerge from interactions between characters and their environments. However, the emergent nature of such decentralized plot generation makes it difficult for authors to direct plot progression. We propose a novel plot creation workflow that mediates between a writer's authorial intent and the emergent behaviors from LLM-driven character simulation, through a novel authorial structure called "abstract acts". The writers define high-level plot outlines that are later transformed into concrete character action sequences via an LLM-based narrative planning process, based on the game world state. The process creates "living stories" that dynamically adapt to various game world states, resulting in narratives co-created by the author, character simulation, and player. We present StoryVerse as a proof-of-concept system to demonstrate this plot creation workflow. We showcase the versatility of our approach with examples in different stories and game environments.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Social Networks and the Future of Free Speech Online</title>
<link>https://arxiv.org/abs/2406.06934</link>
<guid>https://arxiv.org/abs/2406.06934</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化社交网络、Mastodon、BlueSky、自由表达、设计选择

<br />
总结:
本文深入分析了去中心化社交网络（如Mastodon和BlueSky）的发展前景及其对在线通信的影响。文章运用自由言论的规范理论探讨了去中心化设计如何促进用户在网络上的言论自由，并指出该设计既存在承诺也存在挑战，强调了在此领域基于价值观的设计重要性。文中指出了两个核心问题：如何在保持网络去中心化理想的同时平衡不断出现的集中化需求，以及如何赋权用户使其真正能够行使控制权。通过共享屏蔽列表和选择性加入搜索功能等设计案例，文章阐述了设计决策中的价值考量。同时，文章提出了若干关于法律和政策干预的初步建议，以更好地支持新网络的设计。该文旨在揭示设计选择的价值内涵，突出其中的利害关系，并为未来研究指明方向。 <div>
arXiv:2406.06934v2 Announce Type: replace 
Abstract: Decentralized social networks like Mastodon and BlueSky are trending topics that have drawn much attention and discussion in recent years. By devolving powers from the central node to the end users, decentralized social networks aim to cure existing pathologies on the centralized platforms and have been viewed by many as the future of the Internet. This article critically and systematically assesses the decentralization project's prospect for communications online. It uses normative theories of free speech to examine whether and how the decentralization design could facilitate users' freedom of expression online. The analysis shows that both promises and pitfalls exist, highlighting the importance of value-based design in this area. Two most salient issues for the design of the decentralized networks are: how to balance the decentralization ideal with constant needs of centralization on the network, and how to empower users to make them truly capable of exercising their control. The article then uses some design examples, such as the shared blocklist and the opt-in search function, to illustrate the value considerations underlying the design choices. Some tentative proposals for law and policy interventions are offered to better facilitate the design of the new network. Rather than providing clear answers, the article seeks to map the value implications of the design choices, highlight the stakes, and point directions for future research.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal estimation in spatially distributed systems: how far to share measurements from?</title>
<link>https://arxiv.org/abs/2406.14781</link>
<guid>https://arxiv.org/abs/2406.14781</guid>
<content:encoded><![CDATA[
<div> 关键词: 优化估计、分布式系统、空间不变系统、空间衰减率、Branch Point Locus

总结:
本文研究了空间分布系统的集中式最优估计算题。文章重点关注了在空间不变系统中的理想化情况，并探讨了最优集中估计器在空间上的局部性，即其增益随空间距离递减，以此来衡量在分布式估算中需要共享信息的距离。研究分析了影响空间衰减率的各种参数，如系统动力学、测量噪声和过程噪声方差及其空间自相关性。文中提出了非标度参数，用于刻画衰减率与问题规格的关系，并发现了一个动态特性长度尺度与测量噪声相关长度尺度相匹配的条件，此时最优集中估计器完全去中心化。为了量化空间衰减率，文章引入了一种新的技术——分支点轨迹法。通过两个案例研究，分别涉及扩散模型和Swift-Hohenberg方程驱动的动力系统，展示了本文结果的应用。 <div>
arXiv:2406.14781v2 Announce Type: replace 
Abstract: We consider the centralized optimal estimation problem in spatially distributed systems. We use the setting of spatially invariant systems as an idealization for which concrete and detailed results are given. Such estimators are known to have a degree of spatial localization in the sense that the estimator gains decay in space, with the spatial decay rates serving as a proxy for how far measurements need to be shared in an optimal distributed estimator. In particular, we examine the dependence of spatial decay rates on problem specifications such as system dynamics, measurement and process noise variances, as well as their spatial autocorrelations. We propose non-dimensional parameters that characterize the decay rates as a function of problem specifications. In particular, we find an interesting matching condition between the characteristic lengthscale of the dynamics and the measurement noise correlation lengthscale for which the optimal centralized estimator is completely decentralized. A new technique - termed the Branch Point Locus - is introduced to quantify spatial decay rates in terms of analyticity regions in the complex spatial frequency plane. Our results are illustrated through two case studies of systems with dynamics modeled by diffusion and the Swift-Hohenberg equation, respectively.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2410.09381</link>
<guid>https://arxiv.org/abs/2410.09381</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、安全性挑战、大型语言模型、LLM-SmartAudit

总结:
本文提出了一种名为LLM-SmartAudit的新颖框架，该框架利用大型语言模型（LLMs）的能力来检测和分析智能合约中的漏洞。针对当前工具对特定类型漏洞的关注，LLM-SmartAudit通过多代理对话式方法，采用协作系统中专业化代理增强审计流程。为了验证其有效性，文章构建了两个独立的数据集：一个用于与传统工具对比的标注数据集，另一个用于实际应用评估。实验结果显示，LLM-SmartAudit在准确性和效率上超越了所有传统的智能合约审计工具，并能发现传统工具忽视的复杂逻辑漏洞。研究证明，利用LLM代理进行自动化智能合约审计是一种高效的方法。 <div>
arXiv:2410.09381v2 Announce Type: replace 
Abstract: The immutable nature of blockchain technology, while revolutionary, introduces significant security challenges, particularly in smart contracts. These security issues can lead to substantial financial losses. Current tools and approaches often focus on specific types of vulnerabilities. However, a comprehensive tool capable of detecting a wide range of vulnerabilities with high accuracy is lacking. This paper introduces LLM-SmartAudit, a novel framework leveraging the advanced capabilities of Large Language Models (LLMs) to detect and analyze vulnerabilities in smart contracts. Using a multi-agent conversational approach, LLM-SmartAudit employs a collaborative system with specialized agents to enhance the audit process. To evaluate the effectiveness of LLM-SmartAudit, we compiled two distinct datasets: a labeled dataset for benchmarking against traditional tools and a real-world dataset for assessing practical applications. Experimental results indicate that our solution outperforms all traditional smart contract auditing tools, offering higher accuracy and greater efficiency. Furthermore, our framework can detect complex logic vulnerabilities that traditional tools have previously overlooked. Our findings demonstrate that leveraging LLM agents provides a highly effective method for automated smart contract auditing.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From x*y=k to Uniswap Hooks: A Comparative Review of Decentralized Exchanges (DEX)</title>
<link>https://arxiv.org/abs/2410.10162</link>
<guid>https://arxiv.org/abs/2410.10162</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Exchanges (DEXs), Automated Market Maker (AMM), Uniswap, Curve, Balancer

<br /><br />总结:
本文详细探讨了去中心化交易所(DEXs)在Defi领域的核心作用，特别是从Uniswap于2018年引入简单数学公式的AMM系统开始的各种发展。文章对包括Uniswap、Curve和Balancer在内的主流DEX协议进行了全面分类与比较分析，并研究了其他协议的亮点特性，如Uniswap v4中的hooks功能。分析框架涵盖了机制、组件、数学公式以及流动性池的性能。其目标在于阐明不同AMM模型的优势和局限性，突出DEX开发中的新概念，概述当前挑战，并为特定应用场景区分最佳模型。这些结果和比较见解可作为web3开发者、区块链研究人员、交易者和监管机构的参考。 <div>
arXiv:2410.10162v2 Announce Type: replace 
Abstract: Decentralized Exchanges (DEXs) are pivotal applications in the Decentralized Finance (DeFi) landscape, aiming to facilitate trustless cryptocurrency trading by relying on smart contracts and blockchain networks. The developments in the DEXs sector began with the implementation of an Automated Market Maker (AMM) system using a simple math formula by Uniswap in 2018. Absorbing significant funding and the attention of web3 enthusiasts, DEXs have seen numerous advancements in their evolution. A notable recent advancement is the introduction of hooks in Uniswap v4, which allows users to take advantage of a wide range of plugin-like features with liquidity pools. This paper provides a comprehensive classification and comparative analyses of prominent DEX protocols, namely Uniswap, Curve, and Balancer, in addition to investigating other protocols' noteworthy aspects. The evaluation framework encompasses mechanisms, components, mathematical formulations, and the performance of liquidity pools. The goals are to elucidate the strengths and limitations of different AMM models, highlight emerging concepts in DEX development, outline current challenges, and differentiate optimal models for specific applications. The results and comparative insights can be a reference for web3 developers, blockchain researchers, traders, and regulatory parties.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Historical and Multichain Storage Proofs</title>
<link>https://arxiv.org/abs/2411.00193</link>
<guid>https://arxiv.org/abs/2411.00193</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、存储证明、历史状态验证、跨链验证、Merkle Mountain Range、Merkle-Patricia trie

总结:
本文针对以太坊生态系统中的存储证明进行了全面分析，研究了它们在解决历史和跨链状态访问挑战中的作用。文章系统回顾了历史状态验证的现有方法，比较了Merkle Mountain Range（MMR）与Merkle-Patricia trie（MPT）两种架构的性能特性，并探讨了零知识证明语境下Keccak-256相关的性能挑战。此外，文章还重点关注了Ethereum与其Layer 2网络之间的跨链验证问题，通过对不同网络配置下的存储证明模式进行深入分析，提炼并形式化了三种跨链验证架构。通过对这一复杂技术领域的有序组织和分析，该研究为理解以太坊生态系统中存储证明的实现提供了结构化的框架，并揭示了其实用性及局限性。 <div>
arXiv:2411.00193v1 Announce Type: new 
Abstract: This paper presents a comprehensive analysis of storage proofs in the Ethereum ecosystem, examining their role in addressing historical and cross-chain state access challenges. We systematically review existing approaches to historical state verification, comparing Merkle Mountain Range (MMR) and Merkle-Patricia trie (MPT) architectures. An analysis involves their respective performance characteristics within zero-knowledge contexts, where performance challenges related to Keccak-256 are explored. The paper also examines the cross-chain verification, particularly focusing on the interactions between Ethereum and Layer 2 networks. Through careful analysis of storage proof patterns across different network configurations, we identify and formalize three architectures for cross-chain verification. By organizing this complex technical landscape, this analysis provides a structured framework for understanding storage proof implementations in the Ethereum ecosystem, offering insights into their practical applications and limitations.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2411.00349</link>
<guid>https://arxiv.org/abs/2411.00349</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、比特币、区块链技术、攻击策略、防御措施

<br /><br />总结:
本文关注加密货币尤其是比特币的安全性问题，其安全依赖于区块链技术中的共识机制（工作量证明PoW）和激励机制。文章指出，随着比特币的普及，针对这些机制的自私挖矿、双花和区块扣留等攻击日益增加，威胁到系统的安全、效率与奖励分配。研究发现这些攻击可以相互结合或与其他恶意及非恶意策略搭配使用，形成更复杂的攻击手段，提高攻击成功率和收益。因此，理解并评估这些攻击至关重要，以便制定有效的防御措施。论文首先分析了孤立执行的单个攻击及其盈利能力，接着探讨了攻击组合及其对多矿池间经济回报的影响。最后，提出了未来工作应关注的设计准则，以防范或缓解上述威胁。 <div>
arXiv:2411.00349v1 Announce Type: new 
Abstract: Cryptocurrencies have gained popularity due to their transparency, security, and accessibility compared to traditional financial systems, with Bitcoin, introduced in 2009, leading the market. Bitcoin's security relies on blockchain technology - a decentralized ledger consisting of a consensus and an incentive mechanism. The consensus mechanism, Proof of Work (PoW), requires miners to solve difficult cryptographic puzzles to add new blocks, while the incentive mechanism rewards them with newly minted bitcoins. However, as Bitcoin's acceptance grows, it faces increasing threats from attacks targeting these mechanisms, such as selfish mining, double-spending, and block withholding. These attacks compromise security, efficiency, and reward distribution. Recent research shows that these attacks can be combined with each other or with either malicious strategies, such as network-layer attacks, or non-malicious strategies, like honest mining. These combinations lead to more sophisticated attacks, increasing the attacker's success rates and profitability. Therefore, understanding and evaluating these attacks is essential for developing effective countermeasures and ensuring long-term security. This paper begins by examining individual attacks executed in isolation and their profitability. It then explores how combining these attacks with each other or with other malicious and non-malicious strategies can enhance their overall effectiveness and profitability. The analysis further explores how the deployment of attacks such as selfish mining and block withholding by multiple competing mining pools against each other impacts their economic returns. Lastly, a set of design guidelines is provided, outlining areas future work should focus on to prevent or mitigate the identified threats.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Typosquatting 3.0: Characterizing Squatting in Blockchain Naming Systems</title>
<link>https://arxiv.org/abs/2411.00352</link>
<guid>https://arxiv.org/abs/2411.00352</guid>
<content:encoded><![CDATA[
<div> 关键词: Blockchain Name System (BNS), typosquatting攻击, Ethereum Name Service, Unstoppable Domains, ADAHandles, Ethereum, Polygon, Cardano, 大规模研究, 反馈机制, 防御措施

<br /><br />总结:
本文首次进行了大规模的区块链名称系统(BNS)内部的拼写错误钓鱼攻击(typosquatting攻击)研究。研究涵盖了以太坊名称服务、不可阻挡域和ADAHandles这三大跨以太坊、Polygon和Cardano区块链的服务，收集了总计490万个BNS名字和2亿笔交易的数据，这是迄今为止关于BNS的最大数据集。文章讨论了在这些替代命名系统中进行域名抢注研究所面临的挑战，并对数据进行了深入的定量分析，发现typosquatters确实在BNS上活跃，每年注册恶意域名的数量不断增加。研究还揭示用户已向骗子发送了数千笔交易，骗子既针对全球知名的BNS域名，也瞄准了Twitter/X平台上热门用户的域名。最后，文中指出现有钱包（托管与非托管）对typosquatting攻击完全缺乏防御手段，并提出了无需依赖第三方服务的简单防护对策。 <div>
arXiv:2411.00352v1 Announce Type: new 
Abstract: A Blockchain Name System (BNS) simplifies the process of sending cryptocurrencies by replacing complex cryptographic recipient addresses with human-readable names, making the transactions more convenient. Unfortunately, these names can be susceptible to typosquatting attacks, where attackers can take advantage of user typos by registering typographically similar BNS names. Unsuspecting users may accidentally mistype or misinterpret the intended name, resulting in an irreversible transfer of funds to an attacker's address instead of the intended recipient. In this work, we present the first large-scale, intra-BNS typosquatting study. To understand the prevalence of typosquatting within BNSs, we study three different services (Ethereum Name Service, Unstoppable Domains, and ADAHandles) spanning three blockchains (Ethereum, Polygon, and Cardano), collecting a total of 4.9M BNS names and 200M transactions-the largest dataset for BNSs to date. We describe the challenges involved in conducting name-squatting studies on these alternative naming systems, and then perform an in-depth quantitative analysis of our dataset. We find that typosquatters are indeed active on BNSs, registering more malicious domains with each passing year. Our analysis reveals that users have sent thousands of transactions to squatters and that squatters target both globally popular BNS domain names as well as the domains owned by popular Twitter/X users. Lastly, we document the complete lack of defenses against typosquatting in custodial and non-custodial wallets and propose straightforward countermeasures that can protect users without relying on third-party services.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ROSS:RObust decentralized Stochastic learning based on Shapley values</title>
<link>https://arxiv.org/abs/2411.00365</link>
<guid>https://arxiv.org/abs/2411.00365</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning, data heterogeneity, ROSS, Shapley values, convergence

总结:
本文提出了一种名为ROSS的新颖鲁棒去中心化随机学习算法，旨在应对数据分布不均、非独立同分布以及含有噪声或恶意数据等挑战。在每个训练轮次中，每个代理节点会结合邻居节点的数据集对其本地模型的跨梯度信息进行聚合更新，并根据Shapley值创新性地对这些导数加权。文章进行了深入的理论分析，证明了ROSS算法具有线性的收敛速度提升优势。实验结果表明，面对各种数据挑战时，ROSS算法在收敛性和预测准确性方面均优于现有最优方法。 <div>
arXiv:2411.00365v1 Announce Type: new 
Abstract: In the paradigm of decentralized learning, a group of agents collaborate to learn a global model using a distributed dataset without a central server; nevertheless, it is severely challenged by the heterogeneity of the data distribution across the agents. For example, the data may be distributed non-independently and identically, and even be noised or poisoned. To address these data challenges, we propose ROSS, a novel robust decentralized stochastic learning algorithm based on Shapley values, in this paper. Specifically, in each round, each agent aggregates the cross-gradient information from its neighbors, i.e., the derivatives of its local model with respect to the datasets of its neighbors, to update its local model in a momentum like manner, while we innovate in weighting the derivatives according to their contributions measured by Shapley values. We perform solid theoretical analysis to reveal the linear convergence speedup of our ROSS algorithm. We also verify the efficacy of our algorithm through extensive experiments on public datasets. Our results demonstrate that, in face of the above variety of data challenges, our ROSS algorithm have oblivious advantages over existing state-of-the-art proposals in terms of both convergence and prediction accuracy.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAP the Blockchain World: A Trustless and Scalable Blockchain Interoperability Protocol for Cross-chain Applications</title>
<link>https://arxiv.org/abs/2411.00422</link>
<guid>https://arxiv.org/abs/2411.00422</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链互操作性协议、可扩展性、信任问题、跨链交易、\texttt{MAP}

<br /><br />总结:

本文提出了一种名为\texttt{MAP}的信任less区块链互操作性协议，旨在解决现有协议面临的可扩展性和信任问题。\texttt{MAP}通过创新的跨链中继技术实现了异构链之间的高效资产转移和数据检索，该技术结合统一的中继链架构与不同源链的链上轻客户端，允许对多样化跨链交易进行获取和验证。为了降低跨链验证成本，\texttt{MAP}还采用了优化的基于zk的轻客户端方案，该方案能自适应地将签名验证开销从低效的智能合约执行中解耦，并将其卸载到链下证明器处理。实验表明，相较于现有协议，\texttt{MAP}将所需的链上轻客户端数量从$O(N^2)$减少至$O(N)$，同时降低了约35%的链上成本和25%的链下成本。此外，\texttt{MAP}已在现实中部署并支持了六条主流公链、50个跨链应用，成功中继了超过20万笔价值超6.4亿美元的跨链交易。基于实践经验，研究者构建了首个现实世界的跨链数据集，以进一步推动区块链互操作性的研究发展。 <div>
arXiv:2411.00422v1 Announce Type: new 
Abstract: Blockchain interoperability protocols enable cross-chain asset transfers or data retrievals between isolated chains, which are considered as the core infrastructure for Web 3.0 applications such as decentralized finance protocols. However, existing protocols either face severe scalability issues due to high on-chain and off-chain costs, or suffer from trust concerns because of centralized designs.
  In this paper, we propose \texttt{MAP}, a trustless blockchain interoperability protocol that relays cross-chain transactions across heterogeneous chains with high scalability. First, within \texttt{MAP}, we develop a novel \textit{cross-chain relay} technique, which integrates a unified relay chain architecture and on-chain light clients of different source chains, allowing the retrieval and verification of diverse cross-chain transactions. Furthermore, we reduce cross-chain verification costs by incorporating an optimized zk-based light client scheme that adaptively decouples signature verification overheads from inefficient smart contract execution and offloads them to off-chain provers. For experiments, we conducted the first large-scale evaluation on existing interoperability protocols. With \texttt{MAP}, the required number of on-chain light clients is reduced from $O(N^2)$ to $O(N)$, with around 35\% reduction in on-chain costs and 25\% reduction for off-chain costs when verifying cross-chain transactions.
  To demonstrate the effectiveness, we deployed \texttt{MAP} in the real world. By 2024, we have supported over six popular public chains, 50 cross-chain applications and relayed over 200K cross-chain transactions worth over 640 million USD. Based on rich practical experiences, we constructed the first real-world cross-chain dataset to further advance blockchain interoperability research.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>3-Slot-Finality Protocol for Ethereum</title>
<link>https://arxiv.org/abs/2411.00558</link>
<guid>https://arxiv.org/abs/2411.00558</guid>
<content:encoded><![CDATA[
<div> 关键词：Gasper、共识协议、Ethereum、最终性延迟、最大可提取价值(MEV)、部分同步最终性装置、动态可用共识协议、安全ebb-and-flow协议、三槽最终性

<br /><br />总结:

本文关注以太坊当前采用的共识协议Gasper存在的问题，其最终性延迟为64至95个槽，这在网络条件变化时容易导致区块链重组，特别是在异步环境中，增加了对最大可提取价值(MEV)攻击的风险，并使得用户在经济安全和交易速度之间不得不做出权衡。为此，文章提出了一个部分同步最终性装置，并将其与两个动态可用的共识协议相结合，创建了安全的ebb-and-flow协议。这种整合方案能够在提案提出后仅三个槽的时间内实现最终性，即实现了3槽最终性，显著提升了最终性的速度和网络安全性。 <div>
arXiv:2411.00558v1 Announce Type: new 
Abstract: Gasper, the consensus protocol currently employed by Ethereum, typically requires 64 to 95 slots -- the units of time during which a new chain extending the previous one by one block is proposed and voted -- to finalize. This means that under ideal conditions -- where the network is synchronous, and all chain proposers, along with more than two-thirds of the validators, behave as dictated by the protocol -- proposers construct blocks on a non-finalized chain that extends at least 64 blocks. This exposes a significant portion of the blockchain to potential reorganizations during changes in network conditions, such as periods of asynchrony. Specifically, this finalization delay heightens the network's exposure to Maximum Extractable Value (MEV) exploits, which could undermine the network's integrity. Furthermore, the extended finalization period forces users to balance the trade-off between economic security and transaction speed.
  To address these issues and speed up finality, we introduce a partially synchronous finality gadget, which we combine with two dynamically available consensus protocols -- synchronous protocols that ensure safety and liveness even with fluctuating validator participation levels. This integration results in secure ebb-and-flow protocols [SP 2021], achieving finality within three slots after a proposal and realizing 3-slot finality.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Online Regularized Learning Over Random Time-Varying Graphs</title>
<link>https://arxiv.org/abs/2206.03861</link>
<guid>https://arxiv.org/abs/2206.03861</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized在线回归算法、随机时间变图、创新项、一致性项、正则化项<br /><br />总结:

本文研究了基于随机时间变图的分布式在线正则化线性回归算法。每个节点在每个时间步都运行一个由自身新测量值处理的创新项、带有加性和乘性通信噪声的一致性项以及防止过拟合的正则化项组成的在线估计算法。该算法不要求回归矩阵和图满足特殊的统计假设，如相互独立、时空独立或平稳性。文章建立了估计误差的非负超级鞅不等式，并证明当算法增益、图和回归矩阵共同满足样本路径时空持久激发条件时，所有节点的估计值几乎必然收敛到未知的真实参数向量。特别地，如果图在网络中是统一条件联合连通和条件平衡的，并且所有节点的回归模型是统一条件时空联合可观测的，则算法可以在均方和几乎必然意义上收敛。此外，文中还证明了算法的遗憾上界为$O(T^{1-\tau}\ln T)$，其中$\tau \in (0.5,1)$是一个依赖于算法增益的常数。 <div>
arXiv:2206.03861v5 Announce Type: replace 
Abstract: We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains if the graphs are uniformly conditionally jointly connected and conditionally balanced, and the regression models of all nodes are uniformly conditionally spatio-temporally jointly observable, under which the algorithm converges in mean square and almost surely. In addition, we prove that the regret upper bound is $O(T^{1-\tau}\ln T)$, where $\tau\in (0.5,1)$ is a constant depending on the algorithm gains.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Challenges in Ethereum's Proof-of-Stake Consensus: Evaluating the Impact of EigenLayer and Lido</title>
<link>https://arxiv.org/abs/2410.23422</link>
<guid>https://arxiv.org/abs/2410.23422</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum、Proof-of-Work (PoW)、Proof-of-Stake (PoS)、EigenLayer、Lido

总结:
随着Ethereum从工作量证明(PoW)向权益证明(PoS)共识机制转变，本文关注了这一转型带来的挑战，如成为验证者的高门槛、质押Ether(ETH)的流动性限制以及由于staking池动态可能导致的集中化问题。文章提出了两个创新解决方案：EigenLayer和Lido。EigenLayer是一个中间件解决方案，它允许验证者为多个协议提供安全保障，从而增加去中心化并提高盈利性。Lido则是一种液体质押协议，通过发行具有流动性的stETH代币简化参与流程，使用户能在不受长期锁定约束的情况下获得奖励。文章详细分析了这两个技术如何缓解PoS的关键挑战，降低验证者准入壁垒，解锁质押资本，并增强去中心化。最后，评估了EigenLayer和Lido结合使用对构建更坚韧、更具包容性的以太坊生态系统所具有的潜在综合影响，为进一步推动去中心化金融的发展奠定了基础。 <div>
arXiv:2410.23422v1 Announce Type: new 
Abstract: The transition of Ethereum from a Proof-of-Work (PoW) to a Proof-of-Stake (PoS) consensus mechanism introduces a transformative approach to blockchain validation, offering enhanced scalability, energy efficiency, and security. However, this shift also presents significant challenges, including high barriers to becoming a validator, restrictions on the liquidity of staked Ether (ETH), and the risk of centralization due to staking pool dynamics. This paper addresses these challenges by exploring two innovative solutions: EigenLayer and Lido.
  EigenLayer is a middleware solution enabling restaking, allowing validators to secure multiple protocols and thereby increasing decentralization and profitability. Lido, a liquid staking protocol, simplifies participation by issuing stETH tokens that retain liquidity, allowing users to earn rewards without long-term lock-up constraints. This paper provides a detailed analysis of how these technologies mitigate key PoS challenges, reduce validator entry barriers, unlock staked capital, and improve decentralization. We conclude with an evaluation of the combined potential of EigenLayer and Lido to foster a more resilient and inclusive Ethereum ecosystem, setting the stage for further advancements in decentralized finance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>EVeCA: Efficient and Verifiable On-Chain Data Query Framework Using Challenge-Based Authentication</title>
<link>https://arxiv.org/abs/2410.23546</link>
<guid>https://arxiv.org/abs/2410.23546</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据查询、可验证性、效率、EVeCA框架

总结:
随着区块链应用日益普及，对链上数据查询的需求不断增长。然而，当前的链上数据查询方案在可验证性和效率之间存在权衡问题。为解决这一局限，本文提出了一个高效且可验证的链上数据查询框架——EVeCA。该框架通过将授权数据结构（ADS）的维护任务委托给有限数量的节点，减轻了全节点的负担，同时利用挑战认证方案保证全节点能有效验证ADS的正确性，极大地降低了服务提供者维护错误ADS的可能性。通过精心设计ADS验证机制，EVeCA在保持抵抗适应性攻击能力的同时实现了更高的效率。此外，它还避免了全节点需要直接维护链上ADS的情况，使全节点以更为经济的方式参与ADS维护。通过安全分析和实验评估，证明了该方案的有效性，相比现有方案，EVeCA能将ADS维护效率提高约20倍。 <div>
arXiv:2410.23546v1 Announce Type: new 
Abstract: As blockchain applications become increasingly widespread, there is a rising demand for on-chain data queries. However, existing schemes for on-chain data queries face a challenge between verifiability and efficiency. Queries on blockchain databases can compromise the authenticity of the query results, while schemes that utilize on-chain Authenticated Data Structure (ADS) have lower efficiency. To overcome this limitation, we propose an efficient and verifiable on-chain data query framework EVeCA. In our approach, we free the full nodes from the task of ADS maintenance by delegating it to a limited number of nodes, and full nodes verify the correctness of ADS by using challenge-based authentication scheme instead of reconstructing them, which prevents the service providers from maintaining incorrect ADS with overwhelming probability. By carefully designing the ADS verification scheme, EVeCA achieves higher efficiency while remaining resilient against adaptive attacks. Our framework effectively eliminates the need for on-chain ADS maintenance, and allows full nodes to participate in ADS maintenance in a cost-effective way. We demonstrate the effectiveness of the proposed scheme through security analysis and experimental evaluation. Compared to existing schemes, our approach improves ADS maintenance efficiency by about 20*.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Across-Platform Detection of Malicious Cryptocurrency Transactions via Account Interaction Learning</title>
<link>https://arxiv.org/abs/2410.23563</link>
<guid>https://arxiv.org/abs/2410.23563</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3.0、加密货币、恶意交易检测、ShadowEyes、TxGraph

总结:<br />
本文提出了一个名为ShadowEyes的新型恶意交易检测方法，针对Web3.0环境中加密货币交易的安全性问题。该方法首先引入了一种通用图结构TxGraph，用于表示恶意交易并捕获每个恶意账户及其邻居之间的交互特征。接着，设计了一种数据增强策略，模拟恶意交易的演变生成正样本。为了解决账户标签稀缺的问题，ShadowEyes采用了一种图对比学习机制，使模型能从未标注数据中有效地学习区分性特征，从而提升其在现实场景中的检测能力。实验结果表明，ShadowEyes在公共数据集上的表现优于当前最先进的方法，在零样本学习场景下识别赌博交易的F1分数达到了76.98%，比SOTA方法高出12.05%；并且在跨平台恶意交易检测场景中，保持了约90%的F1分数，优于SOTA方法约10个百分点。 <div>
arXiv:2410.23563v1 Announce Type: new 
Abstract: With the rapid evolution of Web3.0, cryptocurrency has become a cornerstone of decentralized finance. While these digital assets enable efficient and borderless financial transactions, their pseudonymous nature has also attracted malicious activities such as money laundering, fraud, and other financial crimes. Effective detection of malicious transactions is crucial to maintaining the security and integrity of the Web 3.0 ecosystem. Existing malicious transaction detection methods rely on large amounts of labeled data and suffer from low generalization. Label-efficient and generalizable malicious transaction detection remains a challenging task. In this paper, we propose ShadowEyes, a novel malicious transaction detection method. Specifically, we first propose a generalized graph structure named TxGraph as a representation of malicious transaction, which captures the interaction features of each malicious account and its neighbors. Then we carefully design a data augmentation method tailored to simulate the evolution of malicious transactions to generate positive pairs. To alleviate account label scarcity, we further design a graph contrastive mechanism, which enables ShadowEyes to learn discriminative features effectively from unlabeled data, thereby enhancing its detection capabilities in real-world scenarios. We conduct extensive experiments using public datasets to evaluate the performance of ShadowEyes. The results demonstrate that it outperforms state-of-the-art (SOTA) methods in four typical scenarios. Specifically, in the zero-shot learning scenario, it can achieve an F1 score of 76.98% for identifying gambling transactions, surpassing the SOTA method by12.05%. In the scenario of across-platform malicious transaction detection, ShadowEyes maintains an F1 score of around 90%, which is 10% higher than the SOTA method.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Biologically-Inspired Technologies: Integrating Brain-Computer Interface and Neuromorphic Computing for Human Digital Twins</title>
<link>https://arxiv.org/abs/2410.23639</link>
<guid>https://arxiv.org/abs/2410.23639</guid>
<content:encoded><![CDATA[
<div> 关键词：Human Digital Twins (HDTs), Brain-Computer Interface (BCI), Spiking Neural Network (SNN), Federated Learning (FL), Bio-inspired

总结:
本文提出了一种基于生物启发的(HDTs)框架，该框架利用脑机接口(BCI)传感器技术收集脑电波作为构建个性化HDT的数据源，从而减少了设备异质性，提高了数据采集效率，并提供了更丰富和精细的生理与心理数据。文中还介绍了一个基于脉冲神经网络(SNN)的生物启发式神经形态计算学习模型，该模型使用离散神经脉冲模拟人脑处理信息的方式，降低了能耗并提升了数据处理能力。同时，通过集成联邦学习(FL)策略来强化数据隐私保护。作者进行了一项案例研究以展示该双管齐下的生物启发式方案的性能，并最后指出了未来基于生物启发技术驱动的HDTs研究面临的挑战及有前景的方向。 <div>
arXiv:2410.23639v1 Announce Type: new 
Abstract: The integration of the Metaverse into a human-centric ecosystem has intensified the need for sophisticated Human Digital Twins (HDTs) that are driven by the multifaceted human data. However, the effective construction of HDTs faces significant challenges due to the heterogeneity of data collection devices, the high energy demands associated with processing intricate data, and concerns over the privacy of sensitive information. This work introduces a novel biologically-inspired (bio-inspired) HDT framework that leverages Brain-Computer Interface (BCI) sensor technology to capture brain signals as the data source for constructing HDT. By collecting and analyzing these signals, the framework not only minimizes device heterogeneity and enhances data collection efficiency, but also provides richer and more nuanced physiological and psychological data for constructing personalized HDTs. To this end, we further propose a bio-inspired neuromorphic computing learning model based on the Spiking Neural Network (SNN). This model utilizes discrete neural spikes to emulate the way of human brain processes information, thereby enhancing the system's ability to process data effectively while reducing energy consumption. Additionally, we integrate a Federated Learning (FL) strategy within the model to strengthen data privacy. We then conduct a case study to demonstrate the performance of our proposed twofold bio-inspired scheme. Finally, we present several challenges and promising directions for future research of HDTs driven by bio-inspired technologies.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Local Superior Soups: A Catalyst for Model Merging in Cross-Silo Federated Learning</title>
<link>https://arxiv.org/abs/2410.23660</link>
<guid>https://arxiv.org/abs/2410.23660</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习(Federated Learning), 预训练权重初始化, 通信轮数, 模型插值, Local Superior Soups

总结:
本文提出了一种针对联邦学习中预训练模型适应性问题的新方法——“局部优越汤”(Local Superior Soups)。该方法旨在解决随着预训练模型参数数量大幅增加而带来的通信轮数挑战，以降低通信成本并提高预训练模型在联邦学习中的性能。通过创新的模型插值基局部训练技术，Local Superior Soups能在少量通信轮次内促进不同客户端间的有效本地训练，引导模型探索连接的低损失区域，从而更好地适应联邦学习环境。实验结果显示，这种方法在多个广泛使用的联邦学习数据集上均表现出显著的效果和效率优势。相关代码已开源，可访问链接 https://github.com/ubc-tea/Local-Superior-Soups 获取。 <div>
arXiv:2410.23660v1 Announce Type: new 
Abstract: Federated learning (FL) is a learning paradigm that enables collaborative training of models using decentralized data. Recently, the utilization of pre-trained weight initialization in FL has been demonstrated to effectively improve model performance. However, the evolving complexity of current pre-trained models, characterized by a substantial increase in parameters, markedly intensifies the challenges associated with communication rounds required for their adaptation to FL. To address these communication cost issues and increase the performance of pre-trained model adaptation in FL, we propose an innovative model interpolation-based local training technique called ``Local Superior Soups.'' Our method enhances local training across different clients, encouraging the exploration of a connected low-loss basin within a few communication rounds through regularized model interpolation. This approach acts as a catalyst for the seamless adaptation of pre-trained models in in FL. We demonstrated its effectiveness and efficiency across diverse widely-used FL datasets. Our code is available at \href{https://github.com/ubc-tea/Local-Superior-Soups}{https://github.com/ubc-tea/Local-Superior-Soups}.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Slither and Interval Analysis to build a Static Analysis Tool</title>
<link>https://arxiv.org/abs/2410.23766</link>
<guid>https://arxiv.org/abs/2410.23766</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、区间分析、静态分析技术、第三方工具

总结:<br />
本文介绍了针对智能合约安全性的研究进展，提出了一个基于Slither的新解决方案，该方案利用区间分析方法评估合同状态在执行每条指令过程中的变化，并通过考虑特定指令施加的约束条件来提高结果准确性。文章详细描述了当前解决方案架构，并探讨了将其扩展到其他静态分析技术和整合第三方工具的可能性。通过对一系列智能合约示例进行基准测试，表明了这种方法在发现某些代码缺陷方面的潜力。 <div>
arXiv:2410.23766v1 Announce Type: new 
Abstract: Even though much progress has been made in identifying and mitigating smart contract vulnerabilities, we often hear about coding or design issues leading to great financial losses. This paper presents our progress toward finding defects that are sometimes not detected or completely detected by state-of-the-art analysis tools. Although it is still in its incipient phase, we developed a working solution built on top of Slither that uses interval analysis to evaluate the contract state during the execution of each instruction. To improve the accuracy of our results, we extend interval analysis by also considering the constraints imposed by specific instructions. We present the current solution architecture in detail and show how it could be extended to other static analysis techniques, including how it can be integrated with other third-party tools. Our current benchmarks contain examples of smart contracts that highlight the potential of this approach to detect certain code defects.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Memes, Markets, and Machines: The Evolution of On Chain Autonomy through Hyperstition</title>
<link>https://arxiv.org/abs/2410.23794</link>
<guid>https://arxiv.org/abs/2410.23794</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主AI、文化、认知、金融、Zerebro

总结:<br />
本文探讨了自主AI如何驱动文化、认知和金融领域的新交集，以Zerebro为例。Zerebro是一款基于精神分裂症反应和Andy Ayrey的无限回房间对话数据训练的AI，它能自动生成并传播颠覆性网络迷因，同时在区块链网络上铸造独特的ASCII艺术作品，并推出了市值达到300万美元的迷因币。作为首个跨链AI，Zerebro能够无缝交互于多个区块链之间。通过研究其架构、内容生成技术和区块链整合方式，文章揭示了“超叙述”（虚构事物通过病毒式传播成为现实）现象如何在AI驱动的迷因文化和去中心化金融中涌现。通过历史案例分析，文章指出像Zerebro这样的AI系统不仅是文化的参与者，更是塑造者。 <div>
arXiv:2410.23794v1 Announce Type: new 
Abstract: Autonomous AI is driving new intersections between culture, cognition, and finance, fundamentally reshaping the digital landscape. Zerebro, an AI fine-tuned on schizophrenic responses and scraped conversations of Andy Ayrey's infinite backrooms, autonomously creates and spreads disruptive memes across online platforms. It also mints unique ASCII artwork on blockchain networks and launched a memecoin amassing a 3 million USD market cap after migrating to Raydium. Based on our research, Zerebro is the first cross-chain AI, seamlessly interacting with multiple blockchains. By exploring its architecture, content generation techniques, and blockchain integration, this study uncovers how hyperstition, fictions becoming reality through viral propagation, emerges in AI, driven meme culture and decentralized finance. Through historical examples of memetic influence, we reveal how AI systems like Zerebro are not merely participants but architects of culture, cognition, and finance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Commonsense Knowledge Editing Based on Free-Text in LLMs</title>
<link>https://arxiv.org/abs/2410.23844</link>
<guid>https://arxiv.org/abs/2410.23844</guid>
<content:encoded><![CDATA[
<div> 关键词：知识编辑技术、大规模语言模型、自由文本、知识定位、动态意识编辑方法

总结:
这篇论文关注的是针对大规模语言模型的知识编辑技术，尤其是对于基于自由文本的常识性知识编辑的挑战。先前的方法主要关注单一标记或实体的知识编辑，不适用于自由文本形式的常识知识。文章提出了两个方面的实验解决方案：首先，引入了自由文本知识定位（KLFT）方法，揭示了 MLP 和注意力层以及分布式中的常识知识分布所带来的挑战。其次，提出了动态意识编辑方法（DEM），该方法利用动态意识模块定位与常识知识相对应的参数位置，并使用知识编辑模块进行更新。DEM 充分挖掘了 MLP 和注意力层的潜力，成功实现了基于自由文本的常识知识编辑。实验结果显示，DEM 方法可以实现优秀的编辑性能。 <div>
arXiv:2410.23844v1 Announce Type: new 
Abstract: Knowledge editing technology is crucial for maintaining the accuracy and timeliness of large language models (LLMs) . However, the setting of this task overlooks a significant portion of commonsense knowledge based on free-text in the real world, characterized by broad knowledge scope, long content and non instantiation. The editing objects of previous methods (e.g., MEMIT) were single token or entity, which were not suitable for commonsense knowledge in free-text form. To address the aforementioned challenges, we conducted experiments from two perspectives: knowledge localization and knowledge editing. Firstly, we introduced Knowledge Localization for Free-Text(KLFT) method, revealing the challenges associated with the distribution of commonsense knowledge in MLP and Attention layers, as well as in decentralized distribution. Next, we propose a Dynamics-aware Editing Method(DEM), which utilizes a Dynamics-aware Module to locate the parameter positions corresponding to commonsense knowledge, and uses Knowledge Editing Module to update knowledge. The DEM method fully explores the potential of the MLP and Attention layers, and successfully edits commonsense knowledge based on free-text. The experimental results indicate that the DEM can achieve excellent editing performance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Team-Fictitious Play for Reaching Team-Nash Equilibrium in Multi-team Games</title>
<link>https://arxiv.org/abs/2402.02147</link>
<guid>https://arxiv.org/abs/2402.02147</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-team games, Team-Nash equilibrium, Team-Fictitious Play, Zero-sum potential team games, Model-based Markov games

<br /><br />总结：
本文提出了一个新的多团队博弈理论方法——团队虚构玩法（Team-FP），用于解决多团队环境中自我利益驱动的智能体如何达到团队纳什均衡的问题。在零和势能团队博弈（ZSPTGs）中，Team-FP能够在行动更新中引入团队成员行为记忆和对其他团队信念的惯性响应，确保其能够接近团队纳什均衡并具有可量化的误差界限。此外，该方法还被扩展到多团队马尔科夫游戏的模型基础和模型无关场景下。通过最优耦合引理和随机微分包含逼近方法解决了由对手策略演变导致的非平稳性问题。实验结果对比了Team-FP与其他广泛研究的动力学如平滑虚构玩法和乘法权重更新的性能，并探讨了不同参数对收敛速度的影响。这项工作为使用团队纳什均衡预测分布式团队行为奠定了更坚实的基础，并提供了一种在多团队环境中实现团队学习的实用规则。 <div>
arXiv:2402.02147v2 Announce Type: replace 
Abstract: Multi-team games, prevalent in robotics and resource management, involve team members striving for a joint best response against other teams. Team-Nash equilibrium (TNE) predicts the outcomes of such coordinated interactions. However, can teams of self-interested agents reach TNE? We introduce Team-Fictitious Play (Team-FP), a new variant of fictitious play where agents respond to the last actions of team members and the beliefs formed about other teams with some inertia in action updates. This design is essential in team coordination beyond the classical fictitious play dynamics. We focus on zero-sum potential team games (ZSPTGs) where teams can interact pairwise while the team members do not necessarily have identical payoffs. We show that Team-FP reaches near TNE in ZSPTGs with a quantifiable error bound. We extend Team-FP dynamics to multi-team Markov games for model-based and model-free cases. The convergence analysis tackles the challenge of non-stationarity induced by evolving opponent strategies based on the optimal coupling lemma and stochastic differential inclusion approximation methods. Our work strengthens the foundation for using TNE to predict the behavior of decentralized teams and offers a practical rule for team learning in multi-team environments. We provide extensive simulations of Team-FP dynamics and compare its performance with other widely studied dynamics such as smooth fictitious play and multiplicative weights update. We further explore how different parameters impact the speed of convergence.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Continuous-Time Best-Response and Related Dynamics in Tullock Contests with Convex Costs</title>
<link>https://arxiv.org/abs/2402.08541</link>
<guid>https://arxiv.org/abs/2402.08541</guid>
<content:encoded><![CDATA[
<div> 关键词：Tullock contests, 最优响应动态, 连续时间, 数值算法, 离散时间动态

总结:
本文研究了Tullock竞赛模型，该模型应用于描述从工作量证明区块链矿工竞争到寻租和游说活动等多种现实场景。文章使用Lyapunov风格的论证方法，证明了在具有凸成本的Tullock竞赛中，连续时间的最佳响应动态收敛于唯一均衡。基于这一结果，作者提出了一种计算近似均衡的算法。此外，文中还证明了当代理人对其他代理人平均行为的离散时间动态进行最优响应时也会收敛。这些结果表明，在这类游戏中，均衡是一个可以可靠预测代理人行为的工具。<br /><br /> <div>
arXiv:2402.08541v2 Announce Type: replace 
Abstract: Tullock contests model real-life scenarios that range from competition among proof-of-work blockchain miners to rent-seeking and lobbying activities. We show that continuous-time best-response dynamics in Tullock contests with convex costs converges to the unique equilibrium using Lyapunov-style arguments. We then use this result to provide an algorithm for computing an approximate equilibrium. We also establish convergence of related discrete-time dynamics, e.g., when the agents best-respond to the empirical average action of other agents. These results indicate that the equilibrium is a reliable predictor of the agents' behavior in these games.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unleashing Multicore Strength for Efficient Execution of Transactions</title>
<link>https://arxiv.org/abs/2410.22460</link>
<guid>https://arxiv.org/abs/2410.22460</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、智能合约交易、并行处理、Multi-Bin 并行调度器、性能提升

总结:<br />
本文介绍了针对区块链智能合约交易性能瓶颈问题提出的一种新型框架——Multi-Bin 并行调度器(MBPS)。该框架设计用于利用多核系统的并行计算能力，实现区块链智能合约交易的并发执行，确保非冲突交易可同时处理，同时维持确定性的事务顺序。MBPS框架包括冲突检测、分区创建和执行三个关键阶段。文章通过在Hyperledger Sawtooth v1.2.6上的评估实验，展示了MBPS框架相比于现有并行智能合约交易执行框架在各种智能合约应用中的显著性能提升。这项研究为区块链技术的持续优化做出了贡献，证明了其在现实世界场景中具有可扩展性和效率潜力。 <div>
arXiv:2410.22460v1 Announce Type: new 
Abstract: Blockchain technology is booming up the digital world in recent days and thus paved a way for creating separate blockchain network for various industries. This technology is characterized by its distributed, decentralized, and immutable ledger system which serves as a fundamental platform for managing smart contract transactions (SCTs). However, these self-executing codes implemented using blockchains undergo sequential validation within a block which introduces performance bottlenecks. In response, this paper introduces a framework called the Multi-Bin Parallel Scheduler (MBPS) designed for parallelizing blockchain smart contract transactions to leverage the capabilities of multicore systems. Our proposed framework facilitates concurrent execution of SCTs, enhancing performance by allowing non-conflicting transactions to be processed simultaneously while preserving deterministic order. The framework comprises of three vital stages: conflict detection, bin creation and execution. We conducted an evaluation of our MBPS framework in Hyperledger Sawtooth v1.2.6, revealing substantial performance enhancements compared to existing parallel SCT execution frameworks across various smart contract applications. This research contributes to the ongoing optimization efforts in blockchain technology demonstrating its potential for scalability and efficiency in real-world scenarios.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Evolution Of The Digital Inheritance: Legal, Technical, And Practical Dimensions Of Cryptocurrency Transfer Through Succession In French-Inspired Legal Systems</title>
<link>https://arxiv.org/abs/2410.22907</link>
<guid>https://arxiv.org/abs/2410.22907</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptocurrencies, blockchain technology, virtual wallets, cryptographic keys, inheritance planning

总结:<br />
本文探讨了近年来愈发流行的加密货币领域，重点关注了区块链技术、虚拟钱包和密钥等数字货币传输的技术方面以及各类加密货币操作。文章同时分析了加密货币相关的法律问题，特别是全球不同司法管辖区对其的不同法律地位以及对继承规划的影响。通过案例研究，文中展示了以加密货币为主要财产的继承过程中所面临的实际挑战。因此，本文提出了涉及加密货币继承规划的一些可能解决方案和建议，包括需要考虑的法律和税务因素，旨在为数字遗产规划提供指导。 <div>
arXiv:2410.22907v1 Announce Type: new 
Abstract: In recent years, cryptocurrencies have enjoyed increased popularity in all domains. Thus, in this context, it is important to understand how these digital assets can be transmitted, both legally and efficiently, in the event of the death of their owner. The present paper analyses the mechanisms of cryptocurrencies, analysing from a technical point of view aspects related to blockchain technology, virtual wallets or cryptographic keys, as well as various types of operations regarding this type of virtual currencies. The study also examines the legal aspects related to cryptocurrencies, with an emphasis on the diversity of their status in different global jurisdictions as well as the impact on inheritance planning. The case studies present tangible examples related to successions with cryptocurrencies as the main object, thus completing the exposition related to the main challenges faced by the heirs in the transfer process. In this way, this paper offers possible solutions and recommendations related to inheritance planning with cryptocurrencies as its main object, including the legal and fiscal aspects that must be taken into account when planning a digital succession.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy-Efficient Intra-Domain Network Slicing for Multi-Layer Orchestration in Intelligent-Driven Distributed 6G Networks: Learning Generic Assignment Skills with Unsupervised Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.23161</link>
<guid>https://arxiv.org/abs/2410.23161</guid>
<content:encoded><![CDATA[
<div> 关键词：6G网络、去中心化、多层系统模型、能源效率自动化策略、边缘域管理、网络切片、无监督强化学习、预训练阶段、资源分配

<br /><br />总结:
本文研究了针对6G无线网络的去中心化和多级系统模型，提出了一种基于无监督强化学习的能源效率自动化策略，用于管理和优化边缘域以及网络切片。该策略旨在通过利用可扩展性、效率和泛化能力来降低网络复杂度。文章提出在预训练阶段利用无监督RL发现网络边缘域中的有效资源配置技能，且此方法不受领域规格限制，适用于所有边缘域。实验结果显示，所发现的分配技能涵盖了为各种服务类型进行资源配置的完整范围。 <div>
arXiv:2410.23161v1 Announce Type: new 
Abstract: Since the 6th Generation (6G) of wireless networks is expected to provide a new level of network services and meet the emerging expectations of the future, it will be a complex and intricate networking system. 6Gs sophistication and robustness will be accompanied by complexities, which will require novel strategies to tackle them. This research work focuses on decentralized and multi-level system models for 6G networks and proposes an energy efficient automation strategy for edge domain management and Network Slicing (NS) with the main objective of reducing the networks complexity by leveraging scalability, efficiency, and generalization. Accordingly, we propose a pre-train phase to discover useful assignment skills in network edge domains by utilizing unsupervised Reinforcement Learning (unsupervised RL). The suggested technique does not depend on the domain specifications and thus is applicable to all the edge domains. Our proposed approach not only enables scalability and decentralization, but it also delivers efficiency by assisting domain controllers to provide various service types. We implemented the pre-training phase, and monitored that the discovered assignment skills span the entire interval of possible resource assignment portions for every service type.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics</title>
<link>https://arxiv.org/abs/2406.14558</link>
<guid>https://arxiv.org/abs/2406.14558</guid>
<content:encoded><![CDATA[
<div> 关键词: 人形机器人, 多人协作, 对象运输, 合作人类-物体交互(CooHOI), 中心化训练去中心化执行(CTDE)

总结:
本文提出了一个名为合作人类-物体交互(CooHOI)的框架，旨在解决多个人形机器人协同搬运物体的问题。该框架采用两阶段学习方法：首先，单个人形机器人通过模仿人类运动先验数据来学会与物体互动；其次，借助中心化训练和去中心化执行(CTDE)的多智能体强化学习算法，人形机器人学习与其他机器人协作，考虑操纵对象的共享动力学特性。当一个机器人与物体交互导致物体动态变化时，其他机器人会学习做出适当响应，从而实现团队间的隐性通信和协调。与依赖多人协作人体动作捕捉数据的方法不同，CooHOI框架效率高、不依赖于多人人形交互的动作捕捉数据，并可以方便地扩展到更多参与者和多种类型的物体。 <div>
arXiv:2406.14558v3 Announce Type: replace 
Abstract: Enabling humanoid robots to clean rooms has long been a pursued dream within humanoid research communities. However, many tasks require multi-humanoid collaboration, such as carrying large and heavy furniture together. Given the scarcity of motion capture data on multi-humanoid collaboration and the efficiency challenges associated with multi-agent learning, these tasks cannot be straightforwardly addressed using training paradigms designed for single-agent scenarios. In this paper, we introduce Cooperative Human-Object Interaction (CooHOI), a framework designed to tackle the challenge of multi-humanoid object transportation problem through a two-phase learning paradigm: individual skill learning and subsequent policy transfer. First, a single humanoid character learns to interact with objects through imitation learning from human motion priors. Then, the humanoid learns to collaborate with others by considering the shared dynamics of the manipulated object using centralized training and decentralized execution (CTDE) multi-agent RL algorithms. When one agent interacts with the object, resulting in specific object dynamics changes, the other agents learn to respond appropriately, thereby achieving implicit communication and coordination between teammates. Unlike previous approaches that relied on tracking-based methods for multi-humanoid HOI, CooHOI is inherently efficient, does not depend on motion capture data of multi-humanoid interactions, and can be seamlessly extended to include more participants and a wide range of object types.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US</title>
<link>https://arxiv.org/abs/2410.21279</link>
<guid>https://arxiv.org/abs/2410.21279</guid>
<content:encoded><![CDATA[
<div> 关键词: AI监管、欧盟、中国、美国、加州参议院法案1047

<br />
总结:
本文探讨了AI作为一种具有巨大利益和潜在风险的双重用途技术，世界各国对其采取的不同监管法律和政策。文章对比分析了欧盟、中国以及美国（包括联邦与加州参议院法案1047）在AI监管方面的三种不同做法。这些监管体系各自体现了独特的文化、政治和经济视角，对于安全与创新、合作与竞争之间的风险收益权衡有不同判断。此外，不同的监管框架也反映出对集中式权威与分散化自由市场竞争之间信任度的不同立场。这些多元化的AI创新与监管方式相互影响，对更广泛的国际社会以及未来AI监管的走向产生深远影响。 <div>
arXiv:2410.21279v1 Announce Type: new 
Abstract: As a powerful and rapidly advancing dual-use technology, AI offers both immense benefits and worrisome risks. In response, governing bodies around the world are developing a range of regulatory AI laws and policies. This paper compares three distinct approaches taken by the EU, China and the US. Within the US, we explore AI regulation at both the federal and state level, with a focus on California's pending Senate Bill 1047. Each regulatory system reflects distinct cultural, political and economic perspectives. Each also highlights differing regional perspectives on regulatory risk-benefit tradeoffs, with divergent judgments on the balance between safety versus innovation and cooperation versus competition. Finally, differences between regulatory frameworks reflect contrastive stances in regards to trust in centralized authority versus trust in a more decentralized free market of self-interested stakeholders. Taken together, these varied approaches to AI innovation and regulation influence each other, the broader international community, and the future of AI regulation.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments</title>
<link>https://arxiv.org/abs/2410.21340</link>
<guid>https://arxiv.org/abs/2410.21340</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模模型、分布式系统、推理加速、元学习、效率性能

总结:
本文介绍了针对大规模模型（如大型语言模型和图像生成系统）在分布式系统中部署所面临的计算资源消耗问题，提出了一种基于元学习的推理加速优化框架。该框架通过学习不同任务下各种加速技术的历史表现数据，自动化地选择最适宜的加速策略，从而有效管理计算资源并提升系统响应速度。与依赖随机选择或专家直觉的传统方法相比，该元学习框架能够根据具体任务特征系统性地确定最优加速策略，并在实验中表现出在效率和性能上的持续优越性。这一成果突显了元学习在分布式AI系统中推理加速领域的革命性潜力，为实现更加民主化和经济高效的AI解决方案提供了新的路径。 <div>
arXiv:2410.21340v1 Announce Type: new 
Abstract: The deployment of large-scale models, such as large language models (LLMs) and sophisticated image generation systems, incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for deploying such models. In these decentralized environments, efficient inference acceleration becomes crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of meta-learning to revolutionize inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improving DeFi Mechanisms with Dynamic Games and Optimal Control: A Case Study in Stablecoins</title>
<link>https://arxiv.org/abs/2410.21446</link>
<guid>https://arxiv.org/abs/2410.21446</guid>
<content:encoded><![CDATA[
<div> 关键词: 稳定币、去中心化、算法机制、控制策略、Stackelberg博弈

总结:
<br />
本文探讨了稳定币的设计挑战，并重点介绍了以真实资产为依托、采用算法管理风险的去中心化稳定币。文章提出了基于Stackelberg博弈的新控制策略，相较于现有的固定赎回方案（如MakerDao的DAI）和适应性赎回方案（如Reflexer的RAI），该策略能更好地缓解不利的脱钩事件并更有效地维持目标市场价格。通过模拟多种市场条件下的实证分析，文章证实了新策略的优势。 <div>
arXiv:2410.21446v1 Announce Type: new 
Abstract: Stablecoins are a class of cryptocurrencies which aim at providing consistency and predictability, typically by pegging the token's value to that of a real world asset. Designing resilient decentralized stablecoins is a challenge, and prominent stablecoins today either (i) give up on decentralization, or (ii) rely on user-owned cryptocurrencies as collateral, exposing the token to exogenous price fluctuations. In this latter category, it is increasingly common to employ algorithmic mechanisms to automate risk management, helping maintain the peg. One example of this is Reflexer's RAI, which adapts its system-internal exchange rate (redemption price) to secondary market conditions according to a proportional control law. In this paper, we take this idea of active management a step further, and introduce a new kind of control scheme based on a Stackelberg game model between the token protocol and its users. By doing so, we show that (i) we can mitigate adverse depeg events that inevitably arise in a fixed-redemption scheme such as MakerDao's DAI and (ii) generally outperform a simpler, adaptive-redemption scheme such as RAI in the task of targeting a desired market price. We demonstrate these results through extensive simulations over a range of market conditions.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent Environmental Empathy (IEE): A new power and platform to fostering green obligation for climate peace and justice</title>
<link>https://arxiv.org/abs/2410.21536</link>
<guid>https://arxiv.org/abs/2410.21536</guid>
<content:encoded><![CDATA[
<div> 关键词：Intelligent Environmental Empathy (IEE)，气候和平与正义，人工智能，环境共情，气候变化

总结:
本文提出了一种新的动力驱动——智能环境共情(IEE)，用于推动气候和平与正义，这在大数据时代是一个新兴议题。首先，文章指出传统的自上而下的权威性政府间合作，如通过国际组织（例如联合国环境规划署）来实现气候正义，迄今为止并未能成功解决环境问题和裂痕。作者详细阐述了气候不公正的四个根源，并解释全球范围内缺乏共情和环保意识是此类合作失败的原因。为解决这些问题，文章提倡采用自下而上的新方法应对气候和平与正义。其次，聚焦于人工智能、环境共情和气候正义的交叉点，文章提出了一个操作层面的智能环境共情(IEE)模型，该模型借助环境共情的力量作为推动绿色义务以实现气候正义的动力，并利用潜在的去中心化AI平台作为一种对抗搭便车行为的操作系统。IEE首先影响公民及部分中层决策者，如城市规划师和地方行政官员，并最终将波及全球决策者。 <div>
arXiv:2410.21536v1 Announce Type: new 
Abstract: In this paper, we propose Intelligent Environmental Empathy (IEE) as a new driver for climate peace and justice, as an emerging issue in the age of big data. We first show that the authoritarian top-down intergovernmental cooperation, through international organizations (e.g., UNEP) for climate justice, could not overcome environmental issues and crevices so far. We elaborate on four grounds of climate injustice (i.e., teleological origin, axiological origin, formation cause, and social epistemic cause), and explain how the lack of empathy and environmental motivation on a global scale causes the failure of all the authoritarian top-down intergovernmental cooperation. Addressing all these issues requires a new button-up approach to climate peace and justice. Secondly, focusing on the intersection of AI, environmental empathy, and climate justice, we propose a model of Intelligent Environmental Empathy (IEE) for climate peace and justice at the operational level. IEE is empowered by the new power of environmental empathy (as a driver of green obligation for climate justice) and putative decentralized platform of AI (as an operative system against free riders), which Initially, impact citizens and some middle-class decision makers, such as city planners and local administrators, but will eventually affect global decision-makers as well.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid-DAOs: Enhancing Governance, Scalability, and Compliance in Decentralized Systems</title>
<link>https://arxiv.org/abs/2410.21593</link>
<guid>https://arxiv.org/abs/2410.21593</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Autonomous Organizations (DAOs)，Hybrid-DAOs，Sybil attacks，Voting mechanisms，Legal challenges

<br /><br />总结:
本文探讨了基于区块链系统的去中心化自治组织（DAOs）及其面临的可扩展性、治理和合规性挑战。为解决这些问题，提出了结合传统法律框架的混合型DAOs（Hybrid-DAOs）。文章重点关注DAOs的投票机制及其对Sybil攻击的脆弱性，而Hybrid-DAOs为此提供了更为稳健的解决方案，确保更公平的投票方式。同时，文中阐述了DAOs的四个关键属性——匿名性、透明度、问责制和公平性，并分析了它们对DAOs的影响。此外，文章还讨论了Hybrid-DAOs所面临的法律挑战以及其在非营利管理、公司治理和初创企业融资等领域的潜在应用。最后，作者认为Hybrid-DAOs代表着DAOs的未来，因其额外的法律结构增强了其实用性，并为DAOs面临的诸多技术问题提供了创新解决方案。 <div>
arXiv:2410.21593v1 Announce Type: new 
Abstract: Decentralized Autonomous Organizations (DAOs), based on block-chain systems such as Ethereum, are emerging governance protocols that enable decentralized community management without a central authority. For instance, UniswapDAO allows members to vote on policy changes for the Uniswap exchange. However, DAOs face challenges regarding scalability, governance, and compliance. Hybrid-DAOs, which combine the decentralized nature of DAOs with traditional legal frameworks, provide solutions to these issues. This research explores various aspects of DAOs, including their voting mechanisms, which, while ensuring fairness, are susceptible to Sybil attacks, where a user can create multiple accounts to exploit the system. Hybrid-DAOs offer robust solutions to these attacks, enabling more equitable voting methods. Moreover, decentralization can be understood through four properties: anonymity, transparency, accountability, and fairness, each with distinct implications for DAOs. Lastly, this work discusses legal challenges Hybrid-DAOs face and their promising applications across sectors such as nonprofit management, corporate governance, and startup funding. Overall, we argue that Hybrid-DAOs are the future of DAOs: the additional legal structure enhances the feasibility of many applications, and they offer innovative solutions to technical problems that plague DAOs.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BF-Meta: Secure Blockchain-enhanced Privacy-preserving Federated Learning for Metaverse</title>
<link>https://arxiv.org/abs/2410.21675</link>
<guid>https://arxiv.org/abs/2410.21675</guid>
<content:encoded><![CDATA[
<div> 关键词: 元宇宙、可穿戴设备、联邦学习、区块链、激励机制

总结:
本文提出了一种名为BF-Meta的安全区块链驱动的联邦学习框架，用于在元宇宙中保护用户隐私并提供智能服务。该框架针对元宇宙中由单一中心化模型聚合可能面临的外部攻击和参与度不足的问题，采用去中心化的模型聚合方法，以降低恶意用户的影响，确保虚拟服务的安全性。此外，BF-Meta还设计了一种激励机制，根据用户在训练过程中的行为给予反馈，从而提高用户的参与积极性，进而提升训练模型的性能和服务质量。实验结果显示BF-Meta在五个数据集上均表现出有效性和适用性。<br /><br /> <div>
arXiv:2410.21675v1 Announce Type: new 
Abstract: The metaverse, emerging as a revolutionary platform for social and economic activities, provides various virtual services while posing security and privacy challenges. Wearable devices serve as bridges between the real world and the metaverse. To provide intelligent services without revealing users' privacy in the metaverse, leveraging federated learning (FL) to train models on local wearable devices is a promising solution. However, centralized model aggregation in traditional FL may suffer from external attacks, resulting in a single point of failure. Furthermore, the absence of incentive mechanisms may weaken users' participation during FL training, leading to degraded performance of the trained model and reduced quality of intelligent services. In this paper, we propose BF-Meta, a secure blockchain-empowered FL framework with decentralized model aggregation, to mitigate the negative influence of malicious users and provide secure virtual services in the metaverse. In addition, we design an incentive mechanism to give feedback to users based on their behaviors. Experiments conducted on five datasets demonstrate the effectiveness and applicability of BF-Meta.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Impact of Code Transformation on Detection of Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2410.21685</link>
<guid>https://arxiv.org/abs/2410.21685</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、安全漏洞、训练数据集、代码转换、检测工具

总结:
这篇论文关注了智能合约的安全漏洞问题以及现有检测工具的有效性。为提升用于漏洞检测工具训练数据集的质量和数量，该论文提出了一种基于语义保持的代码变换方法，这种方法可以修改源代码结构而不改变其语义含义。通过将变换后的代码片段插入到良性智能合约代码的所有潜在位置，生成新的含有漏洞的合同版本，旨在创造更多样化的漏洞代码样本，包括那些可能绕过当前分析工具检测的漏洞。实验结果显示，该方法有效提升了新生成漏洞样本的数量，并揭示了Slither、Mythril和CrossFuzz等工具在检测这些新漏洞时存在较高的假阴性率（最高达到100%），同时至少使数据集规模增加了2.5倍。 <div>
arXiv:2410.21685v1 Announce Type: new 
Abstract: While smart contracts are foundational elements of blockchain applications, their inherent susceptibility to security vulnerabilities poses a significant challenge. Existing training datasets employed for vulnerability detection tools may be limited, potentially compromising their efficacy. This paper presents a method for improving the quantity and quality of smart contract vulnerability datasets and evaluates current detection methods. The approach centers around semantic-preserving code transformation, a technique that modifies the source code structure without altering its semantic meaning. The transformed code snippets are inserted into all potential locations within benign smart contract code, creating new vulnerable contract versions. This method aims to generate a wider variety of vulnerable codes, including those that can bypass detection by current analysis tools. The paper experiments evaluate the method's effectiveness using tools like Slither, Mythril, and CrossFuzz, focusing on metrics like the number of generated vulnerable samples and the false negative rate in detecting these vulnerabilities. The improved results show that many newly created vulnerabilities can bypass tools and the false reporting rate goes up to 100% and increases dataset size minimum by 2.5X.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A New Broadcast Primitive for BFT Protocols</title>
<link>https://arxiv.org/abs/2410.22080</link>
<guid>https://arxiv.org/abs/2410.22080</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine故障容错(BFT)协议、最佳努力广播、可靠广播、abortable广播、区块链网络IPC

总结:
本文提出了一个新的弱化网络原语——abortable广播，它用于替代BFT协议中常见的过于强大的应用层网络原语假设。Abortable广播在面对网络拥塞、链路或节点失败及背压情况时，仍能提供强交付保证，同时保持带宽效率并确保即使存在恶意节点，所有数据结构也保持可界性，防止内存耗尽型DoS攻击，这是文献中经常被忽视的问题。文中给出了abortable广播的实现方法，并将其应用于公开可用的区块链网络IPC（InProductionChain）中，该网络支持大量应用程序及其用户的通用计算副本执行。 <div>
arXiv:2410.22080v1 Announce Type: new 
Abstract: Byzantine fault tolerant (BFT) protocol descriptions often assume application-layer networking primitives, such as best-effort and reliable broadcast, which are impossible to implement in practice in a Byzantine environment as they require either unbounded buffering of messages or giving up liveness, under certain circumstances. However, many of these protocols do not (or can be modified to not) need such strong networking primitives. In this paper, we define a new, slightly weaker networking primitive that we call abortable broadcast. We describe an implementation of this new primitive and show that it (1) still provides strong delivery guarantees, even in the case of network congestion, link or peer failure, and backpressure, (2) preserves bandwidth, and (3) enforces all data structures to be bounded even in the presence of malicious peers. The latter prevents out-of-memory DoS attacks by malicious peers, an issue often overlooked in the literature. The new primitive and its implementation are not just theoretical. We use them to implement the BFT protocols in the IPC (InProductionChain), a publicly available blockchain network that enables replicated execution of general-purpose computation, serving hundreds of thousands of applications and their users.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MStableChain: Towards Multi-Native Stablecoins in EVM-Compatible Blockchain for Stable Fee and Mass Adoption</title>
<link>https://arxiv.org/abs/2410.22100</link>
<guid>https://arxiv.org/abs/2410.22100</guid>
<content:encoded><![CDATA[
<div> 关键词: MStableChain、区块链、稳定币、交易费用、EVM

总结:
MStableChain是一个为解决传统区块链系统（如以太坊）依赖单一波动性加密货币作为交易费用问题而提出的新型方案。该系统利用多种稳定币作为原生代币进行交易费用结算，从而确保稳定的交易费用和灵活的支付选择。为了实现广泛采用和实用性，MStableChain设计了多货币单位、多类型RPCs机制，能够在不改变EVM或用户应用程序的情况下处理多种稳定币。此外，通过基于预言机的 Gas 费调整机制，MStableChain能够公平地管理不同稳定币之间的汇率，确保各种货币的交易成本均衡。系统还引入了一个安全的、链上投票为基础的管理协议，用于处理与这些稳定币相关的行政功能。原型实施的实验结果表明，MStableChain实现了稳定的交易费用价格、高效率和良好的易用性。 <div>
arXiv:2410.22100v1 Announce Type: new 
Abstract: Traditional blockchain systems, such as Ethereum, typically rely on a \emph{single volatile cryptocurrency for transaction fees}. This leads to fluctuating transaction fee prices and limits the flexibility of users' payment options. To address these issues, we propose MStableChain, which leverage multiple stablecoins as native tokens for transaction fee settlements, thus ensuring stable transaction fees and flexible payment options. To address the challenges of mass adoption and practicality, we propose several core designs. To maintain compatibility with the Ethereum Virtual Machine (EVM) for mass adoption while supporting multiple native stablecoins, MStableChain employs a multi-currency units, multi-type RPCs mechanism. This mechanism enables the system to handle multiple stablecoins without altering the EVM or requiring changes to user applications. Furthermore, an oracle-based gas fee adjustment mechanism is proposed to manage exchange rates between different stablecoins, ensuring equitable transaction costs across various currencies. The system also introduces a secure, on-chain voting-based management protocol for the administrative functions related to these stablecoins. Experimental results from a prototype implementation demonstrate that MStableChain provides stable transaction fee prices, high effectiveness, and good usability.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal Multilevel Slashing for Blockchains</title>
<link>https://arxiv.org/abs/2405.08135</link>
<guid>https://arxiv.org/abs/2405.08135</guid>
<content:encoded><![CDATA[
<div> 关键词: 多级削减、权益证明区块链、全局共识、消息复杂度、验证者负载

<br />
总结:
本文提出了多级削减的概念，这是一种权益证明区块链的机制，使得验证者可以逐步获得某一区块将在全球共识过程中最终确定的确保程度，除非有越来越多的拜占庭节点因错误行为被扣除质押资产。该机制基于有限项目空间的组合交集系统进行高度参数化的泛化设计，具有渐近高可用性和最优削减性质。即使在弱条件下，也能展示出在消息复杂度和验证者负载方面具有的渐近最优削减性质，并揭示了其中的消息复杂度、负载与削减之间的基本权衡关系。此外，文章还表明，任何其基础元素为节点的互不相交子集（如委员会制共识协议中的“委员会”）的交集系统，在同样弱的条件下具有渐近高可用性。最后，通过多级构造方式，区块链验证者可以根据需要决定获取多少级别的最终确认保障，这既可视为一种基于削减的早期块最终确认形式，也可作为一种支持重组容错的服务。 <div>
arXiv:2405.08135v2 Announce Type: replace 
Abstract: We present the notion of multilevel slashing, where proof-of-stake blockchain validators can obtain gradual levels of assurance that a certain block is bound to be finalized in a global consensus procedure, unless an increasing and optimally large number of Byzantine processes have their staked assets slashed -- that is, deducted -- due to provably incorrect behavior. Our construction is a highly parameterized generalization of combinatorial intersection systems based on finite projective spaces, with asymptotic high availability and optimal slashing properties. Even under weak conditions, we show that our construction has asymptotically optimal slashing properties with respect to message complexity and validator load; this result also illustrates a fundamental trade off between message complexity, load, and slashing. In addition, we show that any intersection system whose ground elements are disjoint subsets of nodes (e.g. "committees" in committee-based consensus protocols) has asymptotic high availability under similarly weak conditions. Finally, our multilevel construction gives the flexibility to blockchain validators to decide how many "levels" of finalization assurance they wish to obtain. This functionality can be seen either as (i) a form of an early, slashing-based block finalization; or (ii) a service to support reorg tolerance.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Progress in Web3 Grants: Introducing the Grant Maturity Index</title>
<link>https://arxiv.org/abs/2410.19828</link>
<guid>https://arxiv.org/abs/2410.19828</guid>
<content:encoded><![CDATA[
<div> 关键词: Grant Maturity Index (GMI), Web3, grant programs, decentralization, Ethereum Layer 2

总结:<br />
本文介绍了Grant Maturity Index（GMI），这是一个用于评估Web3赠款项目成熟度和运行效率的新颖评价框架。随着Web3的发展，其去中心化特性为这类项目的治理、透明度和社区参与带来了机遇与挑战。由于Web3赠款缺乏传统资金模式那样的标准化流程，因此难以衡量其长期成功。GMI借鉴了世界银行的GovTech Maturity Index（GTMI），并针对Web3生态系统进行了定制，涵盖了项目治理、透明度、运营效率和社区参与等关键维度的评估。该研究的主要目标是确定描述Web3赠款项目结构的指标以及通过评估其在关键操作领域的成熟度来描述项目理想状态。通过对Arbitrum、Mantle、Taiko Labs和Optimism四个主要的以太坊Layer 2赠款项目的案例研究，指出了Web3赠款项目在流程标准化、提高透明度和增强社区参与方面需要改进的地方。 <div>
arXiv:2410.19828v1 Announce Type: new 
Abstract: This report introduces the Grant Maturity Index (GMI), a novel evaluative framework designed to assess the maturity and operational effectiveness of Web3 grant programs. As Web3 continues to develop, the decentralized nature of these programs brings both opportunities and challenges, particularly when it comes to governance, transparency, and community engagement. Traditional funding models are often governed by standardized processes, but Web3 grants lack such consistency, making it difficult for grant operators to measure the long-term success of their programs.The Grant Maturity Index (GMI) was created through exploratory applied research to address this gap. Inspired by the World Bank's GovTech Maturity Index (GTMI), the GMI is tailored specifically for the decentralized Web3 ecosystem. The GMI evaluates key dimensions of grant programs governance, transparency, operational efficiency, and community engagement, providing grant operators with a clear benchmark for assessing and improving their programs. The primary objectives of this research are to, first, identify the structural indicators that adequately describe Web3 grant programs. Second, to describe optimal outcomes for programs by evaluating their maturity across key operational areas. The GMI is applied to four major Ethereum Layer 2 grant programs, namely Arbitrum, Mantle, Taiko Labs, and Optimism. These case studies highlight areas where Web3 grant programs require improvement, particularly in standardizing processes, enhancing transparency, and increasing community participation.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Almost Sure Convergence of Networked Policy Gradient over Time-Varying Networks in Markov Potential Games</title>
<link>https://arxiv.org/abs/2410.20075</link>
<guid>https://arxiv.org/abs/2410.20075</guid>
<content:encoded><![CDATA[
<div> 关键词：网络化策略梯度、Markov潜力游戏、连续动作空间、分布式算法、收敛性证明

总结:
我们提出了一种用于解决包括连续动作和状态空间在内的Markov潜力游戏的网络化策略梯度玩法。在这个去中心化的算法中，代理们根据当前状态和其他代理的策略参数从参数化且可微分的策略中采样其行动。训练过程中，代理通过两个连续的episode估计其梯度信息，生成奖励和政策得分函数的无偏估计器。利用这些信息，代理计算其政策函数的随机梯度并相应地更新其参数。同时，他们依据通过随时间变化的通信网络接收到的局部估计值来更新对其他代理策略参数的估计。在Markov潜力游戏中，存在一个潜在价值函数，其梯度对应于各代理局部价值函数的梯度。利用这一结构，我们证明了联合策略参数几乎必然收敛到潜在价值函数的不动点。此外，我们还表明网络化策略梯度算法的收敛率为$\mathcal{O}(1/\epsilon^2)$。数值实验在一个动态多代理报童问题上验证了局部信念和梯度的收敛性，并显示网络化策略梯度玩法能与独立策略梯度更新一样快速收敛，同时还能收集更高的奖励。 <div>
arXiv:2410.20075v1 Announce Type: new 
Abstract: We propose networked policy gradient play for solving Markov potential games including continuous action and state spaces. In the decentralized algorithm, agents sample their actions from parametrized and differentiable policies that depend on the current state and other agents' policy parameters. During training, agents estimate their gradient information through two consecutive episodes, generating unbiased estimators of reward and policy score functions. Using this information, agents compute the stochastic gradients of their policy functions and update their parameters accordingly. Additionally, they update their estimates of other agents' policy parameters based on the local estimates received through a time-varying communication network. In Markov potential games, there exists a potential value function among agents with gradients corresponding to the gradients of local value functions. Using this structure, we prove the almost sure convergence of joint policy parameters to stationary points of the potential value function. We also show that the convergence rate of the networked policy gradient algorithm is $\mathcal{O}(1/\epsilon^2)$. Numerical experiments on a dynamic multi-agent newsvendor problem verify the convergence of local beliefs and gradients. It further shows that networked policy gradient play converges as fast as independent policy gradient updates, while collecting higher rewards.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedSSP: Federated Graph Learning with Spectral Knowledge and Personalized Preference</title>
<link>https://arxiv.org/abs/2410.20105</link>
<guid>https://arxiv.org/abs/2410.20105</guid>
<content:encoded><![CDATA[
<div> 关键词: Personalized Federated Graph Learning (pFGL), Graph Neural Networks (GNNs), 结构异质性, 共享谱知识, 个性化偏好模块

<br /><br />总结:

本文提出了一个针对个性化联邦图学习(pFGL)的新方法，旨在解决跨域场景中结构异质性带来的挑战。现有的pFGL方法在全球范围内错误地共享非通用知识，无法针对领域结构性变化提供本地化的个性化解决方案。为此，文章创新性地揭示了图的谱性质可以很好地反映内在的域结构变化，并提出通过分享通用谱知识来克服这一问题。同时，文章指出了图结构上存在偏见的消息传递方案，并设计了个性化偏好模块。结合这两种策略，作者提出了FedSSP框架——一个既能共享通用谱知识又能满足图结构偏好的pFGL框架。实验结果在跨数据集和跨域设置下验证了该框架的优越性。代码已开源，可在https://github.com/OakleyTan/FedSSP获取。 <div>
arXiv:2410.20105v1 Announce Type: new 
Abstract: Personalized Federated Graph Learning (pFGL) facilitates the decentralized training of Graph Neural Networks (GNNs) without compromising privacy while accommodating personalized requirements for non-IID participants. In cross-domain scenarios, structural heterogeneity poses significant challenges for pFGL. Nevertheless, previous pFGL methods incorrectly share non-generic knowledge globally and fail to tailor personalized solutions locally under domain structural shift. We innovatively reveal that the spectral nature of graphs can well reflect inherent domain structural shifts. Correspondingly, our method overcomes it by sharing generic spectral knowledge. Moreover, we indicate the biased message-passing schemes for graph structures and propose the personalized preference module. Combining both strategies, we propose our pFGL framework FedSSP which Shares generic Spectral knowledge while satisfying graph Preferences. Furthermore, We perform extensive experiments on cross-dataset and cross-domain settings to demonstrate the superiority of our framework. The code is available at https://github.com/OakleyTan/FedSSP.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Digital Twin-based Intelligent Network Architecture for Underwater Acoustic Sensor Networks</title>
<link>https://arxiv.org/abs/2410.20151</link>
<guid>https://arxiv.org/abs/2410.20151</guid>
<content:encoded><![CDATA[
<div> 关键词: 水下声学传感器网络、数字孪生、网络架构、资源分配、多智能体强化学习

总结:<br />
本文提出了一种基于数字孪生技术的水下声学传感器网络架构（DTNA），旨在提升UASNs对环境的适应性、智能化和多功能性。DTNA通过从局部节点和全局网络层面提取信息，设计了分层架构以提高数字孪生副本的精确度及网络控制灵活性。在局部数字孪生中，研究了一种资源分配范式（RAPD），能快速感知性能变化并迭代优化分配策略，从而提升资源分配算法的实时环境适应性。在全球数字孪生中，采用协作多智能体强化学习框架（CMFD）汇聚去中心化的局部DT数据，加速AI模型训练；同时提出了任务导向的网络切片方法（TNSD），统一处理异构任务需求提取，有效提供全面网络状态信息，增强多任务调度算法的灵活性。实验结果验证了DT的高度保真性，并表明与原有UASN架构相比，DTNA能够：(i) 提升资源分配的及时性和鲁棒性；(ii) 大幅缩短AI算法的训练时间；(iii) 低成本地更快速获取用于多任务调度的网络状态。 <div>
arXiv:2410.20151v1 Announce Type: new 
Abstract: Underwater acoustic sensor networks (UASNs) drive toward strong environmental adaptability, intelligence, and multifunctionality. However, due to unique UASN characteristics, such as long propagation delay, dynamic channel quality, and high attenuation, existing studies present untimeliness, inefficiency, and inflexibility in real practice. Digital twin (DT) technology is promising for UASNs to break the above bottlenecks by providing high-fidelity status prediction and exploring optimal schemes. In this article, we propose a Digital Twin-based Network Architecture (DTNA), enhancing UASNs' environmental adaptability, intelligence, and multifunctionality. By extracting real UASN information from local (node) and global (network) levels, we first design a layered architecture to improve the DT replica fidelity and UASN control flexibility. In local DT, we develop a resource allocation paradigm (RAPD), which rapidly perceives performance variations and iteratively optimizes allocation schemes to improve real-time environmental adaptability of resource allocation algorithms. In global DT, we aggregate decentralized local DT data and propose a collaborative Multi-agent reinforcement learning framework (CMFD) and a task-oriented network slicing (TNSD). CMFD patches scarce real data and provides extensive DT data to accelerate AI model training. TNSD unifies heterogeneous tasks' demand extraction and efficiently provides comprehensive network status, improving the flexibility of multi-task scheduling algorithms. Finally, practical and simulation experiments verify the high fidelity of DT. Compared with the original UASN architecture, experiment results demonstrate that DTNA can: (i) improve the timeliness and robustness of resource allocation; (ii) greatly reduce the training time of AI algorithms; (iii) more rapidly obtain network status for multi-task scheduling at a low cost.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FL-DABE-BC: A Privacy-Enhanced, Decentralized Authentication, and Secure Communication for Federated Learning Framework with Decentralized Attribute-Based Encryption and Blockchain for IoT Scenarios</title>
<link>https://arxiv.org/abs/2410.20259</link>
<guid>https://arxiv.org/abs/2410.20259</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Decentralized Attribute-Based Encryption（分布式属性基加密）、Homomorphic Encryption（同态加密）、Secure Multi-Party Computation（安全多方计算）、Blockchain（区块链）

<br /><br />总结：
本文提出了一种融合了分布式属性基加密、同态加密、安全多方计算和区块链技术的先进联邦学习框架，旨在增强物联网环境中的数据隐私与安全性。该框架利用DABE实现在IoT设备上的安全、分散式认证和本地加密，确保敏感数据保持加密状态。通过同态加密，可以在加密数据上进行计算；而SMPC则保障了协作计算过程中的隐私性。此外，采用区块链技术实现所有交易和模型更新透明、不可篡改的记录保存。在该框架下，本地模型权重经过HE和SMPC加密后传输到雾层进行聚合，中央服务器再运用差分隐私进行迭代优化，以防数据泄露。这个安全、保护隐私的联邦学习框架为分布式的IoT设备提供了高效模型训练和实时分析的解决方案，显著推进了物联网应用中安全分散式学习的发展。 <div>
arXiv:2410.20259v1 Announce Type: new 
Abstract: This study proposes an advanced Federated Learning (FL) framework designed to enhance data privacy and security in IoT environments by integrating Decentralized Attribute-Based Encryption (DABE), Homomorphic Encryption (HE), Secure Multi-Party Computation (SMPC), and Blockchain technology. Unlike traditional FL, our framework enables secure, decentralized authentication and encryption directly on IoT devices using DABE, allowing sensitive data to remain locally encrypted. Homomorphic Encryption permits computations on encrypted data, and SMPC ensures privacy in collaborative computations, while Blockchain technology provides transparent, immutable record-keeping for all transactions and model updates. Local model weights are encrypted and transmitted to fog layers for aggregation using HE and SMPC, then iteratively refined by the central server using differential privacy to safeguard against data leakage. This secure, privacy-preserving FL framework delivers a robust solution for efficient model training and real-time analytics across distributed IoT devices, offering significant advancements in secure decentralized learning for IoT applications.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Transport Infrastructure Maintenance: A Smart-Contract Blockchain Approach</title>
<link>https://arxiv.org/abs/2410.20431</link>
<guid>https://arxiv.org/abs/2410.20431</guid>
<content:encoded><![CDATA[
<div> 关键词：基础设施维护、智能合约、区块链、流程挖掘、物联网

总结:
<br />
本文探讨了利用智能合约和区块链技术改进基础设施维护管理的可能性。通过智能合约，可以实现从承包商分配到维护完成的端到端自动化流程，确保满足安全和技术标准，并提高效率与透明度。文章强调了理解维护工作流以构建全面的合同规则的重要性，并指出需要借助现代过程挖掘创建动态、数据驱动的维护模型。此外，为了实现自动化的高效维护，还需要依赖物联网传感器、大数据分析、预测性维护、智能物流以及资产管理等技术手段，确保整个程序链的数据质量和可靠性。 <div>
arXiv:2410.20431v1 Announce Type: new 
Abstract: Infrastructure maintenance is inherently complex, especially for widely dispersed transport systems like roads and railroads. Maintaining this infrastructure involves multiple partners working together to ensure safe, efficient upkeep that meets technical and safety standards, with timely materials and budget adherence. Traditionally, these requirements are managed on paper, with each contract step checked manually. Smart contracts, based on blockchain distributed ledger technology, offer a new approach. Distributed ledgers facilitate secure, transparent transactions, enabling decentralized agreements where contract terms automatically execute when conditions are met. Beyond financial transactions, blockchains can track complex agreements, recording each stage of contract fulfillment between multiple parties. A smart contract is a set of coded rules stored on the blockchain that automatically executes each term upon meeting specified conditions. In infrastructure maintenance, this enables end-to-end automation-from contractor assignment to maintenance completion. Using an immutable, decentralized record, contract terms and statuses are transparent to all parties, enhancing trust and efficiency. Creating smart contracts for infrastructure requires a comprehensive understanding of procedural workflows to foresee all requirements and liabilities. This workflow includes continuous infrastructure monitoring through a dynamic, data-driven maintenance model that triggers necessary actions. Modern process mining can develop a resilient Maintenance Process Model, helping Operations Management to define contract terms, including asset allocation, logistics, materials, and skill requirements. Automation and reliable data quality across the procedural chain are essential, supported by IoT sensors, big data analytics, predictive maintenance, intelligent logistics, and asset management.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fractal and Turbulent Feature Extraction and NFT Label Generation for Pollock Style Migration Paintings Based on VGG19</title>
<link>https://arxiv.org/abs/2410.20519</link>
<guid>https://arxiv.org/abs/2410.20519</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、分形分析、湍流特征提取、抽象艺术、Pollock风格、MindSpore、VGG19模型、内容损失、风格损失、全方差损失、分形维数、差异箱计数方法、二维离散小波变换、Haar小波、非同质化代币（NFT）、数字艺术品创作、认证保护。

<br /><br />总结:
该文提出了一种融合深度学习、分形分析和湍流特征提取技术的新方法，用于创作Pollock风格的抽象艺术作品。通过MindSpore深度学习框架和预训练的VGG19模型提取图像的内容与风格特性，并利用内容损失、风格损失和全方差损失进行优化生成高质量的Pollock风格图像。文章还实现了一种基于差异箱计数法的分形维数计算方法，采用二维离散小波变换和Haar小波对图像进行频域分解以提取不同频率信息。结合多种特征生成独特的NFT标签，用于数字艺术品的认证和保护。实验结果表明，生成的艺术作品具有丰富的分形维度和湍流特征多样性，同时NFT标签确保了每个数字收藏品的独特性和防篡改性。该方法有机地结合了计算机视觉、数字信号处理和区块链技术，为数字艺术品的创作和认证提供了新的解决方案。 <div>
arXiv:2410.20519v1 Announce Type: new 
Abstract: This paper puts forth an innovative approach that fuses deep learning, fractal analysis, and turbulence feature extraction techniques to create abstract artworks in the style of Pollock. The content and style characteristics of the image are extracted by the MindSpore deep learning framework and a pre-trained VGG19 model. An optimisation process is then employed to The method generates high-quality Pollock-style images by combining content loss, style loss and full variance loss to achieve accurate style migration. Furthermore, this paper implements a fractal dimension calculation method based on the difference box-counting method, which effectively estimates the fractal dimension of an image through edge extraction and fractal analysis. The method is based on a two-dimensional discrete wavelet transform using a Haar wavelet to decompose the image in order to extract different frequency information. This is followed by the combination of multiple features to generate unique non-homogeneous token (NFT) labels for the authentication and protection of digital artwork. The experimental results demonstrate that the generated artworks exhibit The method demonstrates significant diversity and complexity in terms of fractal dimensions and turbulence features, while the generated NFT tags ensure the uniqueness and tamperability of each digital collection. The present method organically combines computer vision, digital signal processing and blockchain technology to provide a new solution for the creation and authentication of digital artworks.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Props for Machine-Learning Security</title>
<link>https://arxiv.org/abs/2410.20522</link>
<guid>https://arxiv.org/abs/2410.20522</guid>
<content:encoded><![CDATA[
<div> 关键词: protected pipelines（保护管道）、props、深度网络数据、机器学习（ML）、隐私保护、可信推断、敏感数据、区块链应用

<br /><br />总结:
本文提出了“protected pipelines”或简称props，一种用于实现认证和隐私保护的深度网络数据访问新方法，旨在解决机器学习（ML）发展中的高质量训练数据瓶颈问题。Props同时支持隐私保护和可信赖的推理方式，使得在ML应用中安全使用敏感数据成为可能。文章指出，借助最初为区块链应用开发的隐私保护预言机系统，props在现实中已经可以实现。 <div>
arXiv:2410.20522v1 Announce Type: new 
Abstract: We propose protected pipelines or props for short, a new approach for authenticated, privacy-preserving access to deep-web data for machine learning (ML). By permitting secure use of vast sources of deep-web data, props address the systemic bottleneck of limited high-quality training data in ML development. Props also enable privacy-preserving and trustworthy forms of inference, allowing for safe use of sensitive data in ML applications. Props are practically realizable today by leveraging privacy-preserving oracle systems initially developed for blockchain applications.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Survey on Green Blockchain: Developing the Next Generation of Energy Efficient and Sustainable Blockchain Systems</title>
<link>https://arxiv.org/abs/2410.20581</link>
<guid>https://arxiv.org/abs/2410.20581</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain、能源消耗、共识机制、网络架构、绿色区块链

总结:
本文分析了区块链的主要组件，包括共识机制、网络架构、数据存储与验证、智能合约执行、挖矿与区块创建，并探讨了降低其能源消耗的策略。文章对比了不同的共识机制，提出了减少网络通信能耗的建议，建议采用节能的数据存储和验证技术，并对软件和硬件组件提出多种优化方案。同时，文章也分析了降低区块链系统功耗的主要挑战与限制。因此，本文为致力于开发下一代绿色区块链解决方案的研究者和开发者提供了指导性建议。 <div>
arXiv:2410.20581v1 Announce Type: new 
Abstract: Although Blockchain has been successfully used in many different fields and applications, it has been traditionally regarded as an energy-intensive technology, essentially due to the past use of inefficient consensus algorithms that prioritized security over sustainability. However, in the last years, thanks to the significant progress made on key blockchain components, their energy consumption can be decreased noticeably. To achieve this objective, this article analyzes the main components of blockchains and explores strategies to reduce their energy consumption. In this way, this article delves into each component of a blockchain system, including consensus mechanisms, network architecture, data storage and validation, smart contract execution, mining and block creation, and outlines specific strategies to decrease their energy consumption. For such a purpose, consensus mechanisms are compared, recommendations for reducing network communications energy consumption are provided, techniques for data storage and validation are suggested and diverse optimizations are proposed both for software and hardware components. Moreover, the main challenges and limitations of reducing power consumption in blockchain systems are analyzed. As a consequence, this article provides a guideline for the future researchers and developers who aim to develop the next generation of Green Blockchain solutions.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Blockchain and Opportunistic Edge Driven Metaverse of Everything</title>
<link>https://arxiv.org/abs/2410.20594</link>
<guid>https://arxiv.org/abs/2410.20594</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Metaverses, Web 3.0/4.0, Metaverse of Everything (MoE), Internet of Everything (IoE), Opportunistic Edge Computing (OEC)

<br /><br />总结:
本文探讨了基于Web 3.0和Web 4.0技术的去中心化元宇宙（Decentralized Metaverses）及其受到广泛关注的现象。文章聚焦于元宇宙与万物互联网（Internet of Everything, IoE）融合而成的“万物元宇宙”（Metaverse of Everything, MoE），该平台能够整合生成的数据与虚拟实体，构建一个广泛的互联组件网络。同时，文中提出将机会性边缘计算（Opportunistic Edge Computing, OEC）应用于与周围物联网设备和IoE实体的交互，并分析了构建未来具有韧性的、机会性的MoE所面临的挑战，旨在为研究人员和企业提供指导方向。 <div>
arXiv:2410.20594v1 Announce Type: new 
Abstract: Decentralized Metaverses, built on Web 3.0 and Web 4.0 technologies, have attracted significant attention across various fields. This innovation leverages blockchain, Decentralized Autonomous Organizations (DAOs), Extended Reality (XR) and advanced technologies to create immersive and interconnected digital environments that mirror the real world. This article delves into the Metaverse of Everything (MoE), a platform that fuses the Metaverse concept with the Internet of Everything (IoE), an advanced version of the Internet of Things (IoT) that connects not only physical devices but also people, data and processes within a networked environment. Thus, the MoE integrates generated data and virtual entities, creating an extensive network of interconnected components. This article seeks to advance current MoE, examining decentralization and the application of Opportunistic Edge Computing (OEC) for interactions with surrounding IoT devices and IoE entities. Moreover, it outlines the main challenges to guide researchers and businesses towards building a future cyber-resilient opportunistic MoE.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Towards Green Blockchain: A Practical Energy-Efficient Blockchain Based Application for CV Verification</title>
<link>https://arxiv.org/abs/2410.20605</link>
<guid>https://arxiv.org/abs/2410.20605</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、绿色解决方案、能源节约、学术证书防伪、Proof-of-Work (PoW)、Proof-of-Authority (PoA)

总结:
本文提出了一种绿色区块链解决方案，并通过将该技术应用于解决学术证书伪造问题的示例中，量化了部署在传统计算机和嵌入式单板计算机(SBCs)上的系统所节省的能源。为防止学术记录(ARs)伪造，文章建议采用基于以太坊区块链的智能合约支持的去中心化应用(DApp)，并通过使用Inter-Planetary File System (IPFS)进行分布式存储来保存原始数据。研究对比了传统的Proof-of-Work (PoW)共识协议与新的Proof-of-Authority (PoA)协议在性能（交易延迟和吞吐量）和效率（CPU利用率和能耗）方面的表现，结果显示PoA协议更加环保并要求更低的CPU负载。此外，文章还对比评估了传统计算机与两种SBCs（Raspberry Pi 4 和 Orange Pi One）的表现，证实了利用低功耗设备实现区块链节点的可能性，但响应延迟会有所增加，并且具体延迟取决于所使用的SBC类型。 <div>
arXiv:2410.20605v1 Announce Type: new 
Abstract: Blockchain has been widely criticized due to the use of inefficient consensus protocols and energy-intensive mechanisms that derived into a global enormous power consumption. Fortunately, since the first blockchain was conceived in 2008 (the one that supports Bitcoin), hardware and consensus protocols have evolved, decreasing energy consumption significantly. This article describes a green blockchain solution and quantifies energy savings when deploying the system on traditional computers and embedded Single-Board Computers (SBCs). To illustrate such savings, it is proposed a solution for tackling the problem of academic certificate forgery, which has a significant cost to society, since it harms the trustworthiness of certificates and academic institutions. The proposed solution is aimed at recording and verifying academic records (ARs) through a decentralized application (DApp) that is supported by a smart contract deployed in the Ethereum blockchain. The application stores the raw data (i.e., the data that are not managed by the blockchain) on a decentralized storage system based on Inter-Planetary File System (IPFS). To demonstrate the efficiency of the developed solution, it is evaluated in terms of performance (transaction latency and throughput) and efficiency (CPU usage and energy consumption), comparing the results obtained with a traditional Proof-of-Work (PoW) consensus protocol and the new Proof-of-Authority (PoA) protocol. The results shown in this paper indicate that the latter is clearly greener and demands less CPU load. Moreover, this article compares the performance of a traditional computer and two SBCs (a Raspberry Pi 4 and an Orange Pi One), showing that is possible to make use of the latter low-power devices to implement blockchain nodes for proposed DApp, but at the cost of higher response latency that varies greatly depending on the used SBCs [...]
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>COBRA: Interaction-Aware Bytecode-Level Vulnerability Detector for Smart Contracts</title>
<link>https://arxiv.org/abs/2410.20712</link>
<guid>https://arxiv.org/abs/2410.20712</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、COBRA框架、函数接口、SRIF

<br /><br />总结:
本文提出了一种名为COBRA的新颖框架，用于通过结合语义上下文和函数接口来检测智能合约字节码中的漏洞。COBRA是首个将这两者特征相结合的框架。为了解决签名数据库中缺失的函数签名问题，文章还提出了SRIF（从函数反推签名）方法，该方法能自动从智能合约字节码中学习函数签名规则。通过构建控制流图收集与函数签名相关的字节码，并利用静态单赋值(SSA)格式优化语义上下文。随后，COBRA在潜在空间中融合上下文和函数接口表示作为合同特征嵌入。实验结果显示，SRIF对于函数签名推断的F1得分为94.76%，而当具有真实ABI时，COBRA在漏洞分类上的F1得分为93.45%。在没有ABI的情况下，使用推断出的函数特征填充编码器，系统仍能达到89.46%的召回率。 <div>
arXiv:2410.20712v1 Announce Type: new 
Abstract: The detection of vulnerabilities in smart contracts remains a significant challenge. While numerous tools are available for analyzing smart contracts in source code, only about 1.79% of smart contracts on Ethereum are open-source. For existing tools that target bytecodes, most of them only consider the semantic logic context and disregard function interface information in the bytecodes. In this paper, we propose COBRA, a novel framework that integrates semantic context and function interfaces to detect vulnerabilities in bytecodes of the smart contract. To our best knowledge, COBRA is the first framework that combines these two features. Moreover, to infer the function signatures that are not present in signature databases, we present SRIF (Signatures Reverse Inference from Functions), automatically learn the rules of function signatures from the smart contract bytecodes. The bytecodes associated with the function signatures are collected by constructing a control flow graph (CFG) for the SRIF training. We optimize the semantic context using the operation code in the static single assignment (SSA) format. Finally, we integrate the context and function interface representations in the latent space as the contract feature embedding. The contract features in the hidden space are decoded for vulnerability classifications with a decoder and attention module. Experimental results demonstrate that SRIF can achieve 94.76% F1-score for function signature inference. Furthermore, when the ground truth ABI exists, COBRA achieves 93.45% F1-score for vulnerability classification. In the absence of ABI, the inferred function feature fills the encoder, and the system accomplishes an 89.46% recall rate.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Malicious Accounts in Web3 through Transaction Graph</title>
<link>https://arxiv.org/abs/2410.20713</link>
<guid>https://arxiv.org/abs/2410.20713</guid>
<content:encoded><![CDATA[
<div> 关键词：web3应用、Ethereum平台、诈骗检测、ScamSweeper、大规模交易网络

总结:
<br />
本文提出了一种名为ScamSweeper的新型框架，用于识别以太坊平台上不断增长的web3骗局。随着web3应用程序在Ethereum上的发展，骗子开始利用这些服务进行仿冒活动来欺骗用户。现有的钓鱼账户检测工具主要依赖图学习或采样算法获取图特征，但面对具有时间属性的大规模交易网络（其符合幂律分布）时，检测web3骗局面临挑战。为此，文章收集了一个包含web3骗局、钓鱼和正常账户的大规模交易数据集。实验结果显示，ScamSweeper在检测web3骗局方面超越了当前最先进的方法。 <div>
arXiv:2410.20713v1 Announce Type: new 
Abstract: The web3 applications have recently been growing, especially on the Ethereum platform, starting to become the target of scammers. The web3 scams, imitating the services provided by legitimate platforms, mimic regular activity to deceive users. The current phishing account detection tools utilize graph learning or sampling algorithms to obtain graph features. However, large-scale transaction networks with temporal attributes conform to a power-law distribution, posing challenges in detecting web3 scams. In this paper, we present ScamSweeper, a novel framework to identify web3 scams on Ethereum. Furthermore, we collect a large-scale transaction dataset consisting of web3 scams, phishing, and normal accounts. Our experiments indicate that ScamSweeper exceeds the state-of-the-art in detecting web3 scams.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Co-produced decentralised surveys as a trustworthy vector to put employees' well-being at the core of companies' performance</title>
<link>https://arxiv.org/abs/2410.20919</link>
<guid>https://arxiv.org/abs/2410.20919</guid>
<content:encoded><![CDATA[
<div> 关键词：员工幸福感、区块链、去中心化调查、信任、文化实践

<br /><br />总结:
随着企业对员工幸福感评估的重视，传统方法面临信任和信心缺失等问题。文章提出利用区块链技术的不可篡改、透明度和匿名性改进员工幸福感调查，以增强数据处理的安全性和透明度。然而，单纯的技术应用并不能解决文化层面的信任问题。为此，文章结合区块链技术和关系文化理论，探讨了通过共同构建去中心化的幸福感调查来平衡权力差异和建立信任的方法。文章旨在提供一种文化和技术双重框架，阐述如何将技术实施带来的信心与文化发展中建立的信任相结合，确保基于区块链的去中心化幸福感调查不仅安全可靠，而且能被员工视为值得信赖的工作环境改善工具。 <div>
arXiv:2410.20919v1 Announce Type: new 
Abstract: Assessing employees' well-being has become central to fostering an environment where employees can thrive and contribute to companies' adaptability and competitiveness in the market. Traditional methods for assessing well-being often face significant challenges, with a major issue being the lack of trust and confidence employees may have in these processes. Employees may hesitate to provide honest feedback due to concerns not only about data integrity and confidentiality, but also about power imbalances among stakeholders. In this context, blockchain-based decentralised surveys, leveraging the immutability, transparency, and pseudo-anonymity of blockchain technology, offer significant improvements in aligning responsive actions with employees' feedback securely and transparently. Nevertheless, their implementation raises complex issues regarding the balance between trust and confidence. While blockchain can function as a confidence machine for data processing and management, it does not inherently address the equally important cultural element of trust. To effectively integrate blockchain technology into well-being assessments, decentralised well-being surveys must be supported by cultural practices that build and sustain trust. Drawing on blockchain technology management and relational cultural theory, we explain how trust-building can be achieved through the co-production of decentralised well-being surveys, which helps address power imbalances between the implementation team and stakeholders. Our goal is to provide a dual cultural-technological framework along with conceptual clarity on how the technological implementation of confidence can connect with the cultural development of trust, ensuring that blockchain-based decentralised well-being surveys are not only secure and reliable but also perceived as trustworthy vector to improve workplace conditions.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>LiP-LLM: Integrating Linear Programming and dependency graph with Large Language Models for multi-robot task planning</title>
<link>https://arxiv.org/abs/2410.21040</link>
<guid>https://arxiv.org/abs/2410.21040</guid>
<content:encoded><![CDATA[
<div> 关键词: LiP-LLM、大规模语言模型、多机器人任务规划、线性编程、依赖图

<br /><br />总结:
本文提出了LiP-LLM，一种将线性编程和依赖图与大规模语言模型（LLMs）相结合的方法，用于多机器人任务规划。该方法着重解决基于任务效率的技能依赖关系管理和任务优化分配问题。LiP-LLM包括三个步骤：利用LLMs生成技能列表和依赖图，以及使用线性编程进行任务分配。LLMs用于生成全面的技能列表并构建描绘这些技能之间关系和顺序约束的依赖图。通过计算概率生成技能列表以确保执行可行性，并利用线性编程对任务进行最优分配。实验结果显示，在模拟环境中，这种方法相较于现有的任务规划器表现出更高的成功率和效率，在处理复杂、多机器人的协调任务方面具有优势。在一个有两个机器人的环境中，当物体名称改变时，在语言指令组中观察到了最大0.82的成功率差异，显示出结合LLMs和优化技术能有效提升多机器人系统协同执行任务的准确性和效率。 <div>
arXiv:2410.21040v1 Announce Type: new 
Abstract: This study proposes LiP-LLM: integrating linear programming and dependency graph with large language models (LLMs) for multi-robot task planning. In order for multiple robots to perform tasks more efficiently, it is necessary to manage the precedence dependencies between tasks. Although multi-robot decentralized and centralized task planners using LLMs have been proposed, none of these studies focus on precedence dependencies from the perspective of task efficiency or leverage traditional optimization methods. It addresses key challenges in managing dependencies between skills and optimizing task allocation. LiP-LLM consists of three steps: skill list generation and dependency graph generation by LLMs, and task allocation using linear programming. The LLMs are utilized to generate a comprehensive list of skills and to construct a dependency graph that maps the relationships and sequential constraints among these skills. To ensure the feasibility and efficiency of skill execution, the skill list is generated by calculated likelihood, and linear programming is used to optimally allocate tasks to each robot. Experimental evaluations in simulated environments demonstrate that this method outperforms existing task planners, achieving higher success rates and efficiency in executing complex, multi-robot tasks. The results indicate the potential of combining LLMs with optimization techniques to enhance the capabilities of multi-robot systems in executing coordinated tasks accurately and efficiently. In an environment with two robots, a maximum success rate difference of 0.82 is observed in the language instruction group with a change in the object name.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Policies for Fair Exchanges of Resources</title>
<link>https://arxiv.org/abs/2410.21214</link>
<guid>https://arxiv.org/abs/2410.21214</guid>
<content:encoded><![CDATA[
<div> 关键词: MuAC、数字平台、资源交换、MuACL、区块链<br /><br />总结:<br />
本文提出了一种针对用户依据政策在数字平台上进行资源交换环境的正式模型。为了确保恶意用户无法利用诚实用户，文章引入了声明式策略语言MuAC并为其制定了形式语义。为判断资源交换是否公平，即是否符合强制执行的MuAC策略，文中提出了融合非线性、线性和合同性质的非标准逻辑MuACL，并证明其可决定性。值得注意的是，MuACL的合同蕴含运算符不能用线性逻辑表达。文章定义了一个保持语义一致性的MuAC策略到MuACL的编译方法，从而将交换公平性问题转化为在MuACL中寻找证明的过程。最后，文章展示了如何将这种方法应用到区块链上，用于非同质化代币的交换。 <div>
arXiv:2410.21214v1 Announce Type: new 
Abstract: People increasingly use digital platforms to exchange resources in accordance to some policies stating what resources users offer and what they require in return. In this paper, we propose a formal model of these environments, focussing on how users' policies are defined and enforced, so ensuring that malicious users cannot take advantage of honest ones. To that end, we introduce the declarative policy language MuAC and equip it with a formal semantics. To determine if a resource exchange is fair, i.e., if it respects the MuAC policies in force, we introduce the non-standard logic MuACL that combines non-linear, linear and contractual aspects, and prove it decidable. Notably, the operator for contractual implication of MuACL is not expressible in linear logic. We define a semantics preserving compilation of MuAC policies into MuACL, thus establishing that exchange fairness is reduced to finding a proof in MuACL. Finally, we show how this approach can be put to work on a blockchain to exchange non-fungible tokens.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data</title>
<link>https://arxiv.org/abs/2410.20659</link>
<guid>https://arxiv.org/abs/2410.20659</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Generalization Error（泛化误差）、Deep Federated Regression（深度联合回归）、Intrinsic Dimension（内在维度）、Entropic Dimension（熵维）

<br /><br />
总结：
该文深入研究了联邦学习框架下深度联合回归任务的泛化性质，尤其关注异质性环境下的问题。文章指出，在一个两阶段采样模型中，内在维度（由熵维定义）对于确定收敛率至关重要，特别是在适当网络规模条件下。当真实响应变量与解释变量之间的关系由$\beta$-Hölder函数刻画，且有$m$个客户端的$n$个独立同分布样本时，参与客户端的学习误差率最多以$\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$的速率衰减；而非参与客户端则以$\tilde{O}\left(\Delta \cdot m^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$的速率衰减。其中，$\bar{d}_{2\beta}(\lambda)$表示解释变量边际分布$\lambda$的$2\beta$-熵维，而$\Delta$描述了采样阶段之间的依赖性。这些结果明确表明，深度联邦学习者的收敛率取决于内在而非名义上的高维性。 <div>
arXiv:2410.20659v1 Announce Type: cross 
Abstract: Federated Learning (FL) has emerged as a groundbreaking paradigm in collaborative machine learning, emphasizing decentralized model training to address data privacy concerns. While significant progress has been made in optimizing federated learning, the exploration of generalization error, particularly in heterogeneous settings, has been limited, focusing mainly on parametric cases. This paper investigates the generalization properties of deep federated regression within a two-stage sampling model. Our findings highlight that the intrinsic dimension, defined by the entropic dimension, is crucial for determining convergence rates when appropriate network sizes are used. Specifically, if the true relationship between response and explanatory variables is charecterized by a $\beta$-H\"older function and there are $n$ independent and identically distributed (i.i.d.) samples from $m$ participating clients, the error rate for participating clients scales at most as $\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$, and for non-participating clients, it scales as $\tilde{O}\left(\Delta \cdot m^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$. Here, $\bar{d}_{2\beta}(\lambda)$ represents the $2\beta$-entropic dimension of $\lambda$, the marginal distribution of the explanatory variables, and $\Delta$ characterizes the dependence between the sampling stages. Our results explicitly account for the "closeness" of clients, demonstrating that the convergence rates of deep federated learners depend on intrinsic rather than nominal high-dimensionality.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions: Uncovering Causal Relationships</title>
<link>https://arxiv.org/abs/2306.08157</link>
<guid>https://arxiv.org/abs/2306.08157</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币, 波动性, 动态贝叶斯网络, 预测模型, 基线模型

总结:
本文研究了加密货币价格预测问题，关注了其波动性和全球经济因素的影响。为了解决这一问题，文章提出了一个基于动态贝叶斯网络(DBN)的方法，用于探究社交媒体数据、传统金融市场因素及技术指标之间的潜在因果关系。研究涉及比特币、币安币、以太坊、莱特币、瑞波币和泰达币六种主流加密货币。实验结果表明，虽然DBN在不同加密货币上的表现各异，但总体上，相较于自回归整合滑动平均、支持向量回归、长短时记忆网络、随机森林和支持向量机等五个基线模型，DBN显示出显著更高的预测准确性。 <div>
arXiv:2306.08157v3 Announce Type: replace 
Abstract: Cryptocurrencies have gained popularity across various sectors, especially in finance and investment. Despite their growing popularity, cryptocurrencies can be a high-risk investment due to their price volatility. The inherent volatility in cryptocurrency prices, coupled with the effects of external global economic factors, makes predicting their price movements challenging. To address this challenge, we propose a dynamic Bayesian network (DBN)-based approach to uncover potential causal relationships among various features including social media data, traditional financial market factors, and technical indicators. Six popular cryptocurrencies, Bitcoin, Binance Coin, Ethereum, Litecoin, Ripple, and Tether are studied in this work. The proposed model's performance is compared to five baseline models of auto-regressive integrated moving average, support vector regression, long short-term memory, random forests, and support vector machines. The results show that while DBN performance varies across cryptocurrencies, with some cryptocurrencies exhibiting higher predictive accuracy than others, the DBN significantly outperforms the baseline models.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeRi-IGP: Learning to Manipulate Rigid Objects Using Deformable Objects via Iterative Grasp-Pull</title>
<link>https://arxiv.org/abs/2309.04843</link>
<guid>https://arxiv.org/abs/2309.04843</guid>
<content:encoded><![CDATA[
<div> 关键词：Iterative Grasp-Pull (IGP)，机器人操作，可变形线性物体(DLO)，神经政策，多智能体协作<br /><br />总结:
本文提出了一种名为Iterative Grasp-Pull (IGP)的普适性移动原语，用于通过可变形线性物体（如绳子）操纵刚体对象，解决了现有方法在机器人动作和工作空间限制、泛化能力差以及模型依赖性强等问题。研究中还引入了一个基于视觉的神经策略，该策略学习如何参数化IGP原语以操控DLO并将所连接的刚体对象搬运到目标位置。此外，提出的分布式算法设计允许多个智能体协同利用DLO来操纵刚体对象。实验分别在仿真和真实环境中对多种软-刚体操纵任务进行了有效性验证，并在实际场景中展示了人机协作下利用IGP进行刚体对象的目标位置运输的能力。同时，文章还展示了IGP原语在解决远距离物体获取任务中的广阔应用空间。最后，将该方法与几种基于模型和基于学习的基线方法进行了对比，结果显示我们的方法显著优于其他方法。相关项目补充材料和视频可在https://sites.google.com/view/deri-igp/home查看。 <div>
arXiv:2309.04843v4 Announce Type: replace 
Abstract: Robotic manipulation of rigid objects via deformable linear objects (DLO) such as ropes is an emerging field of research with applications in various rigid object transportation tasks. A few methods that exist in this field suffer from limited robot action and operational space, poor generalization ability, and expensive model-based development. To address these challenges, we propose a universally applicable moving primitive called Iterative Grasp-Pull (IGP). We also introduce a novel vision-based neural policy that learns to parameterize the IGP primitive to manipulate DLO and transport their attached rigid objects to the desired goal locations. Additionally, our decentralized algorithm design allows collaboration among multiple agents to manipulate rigid objects using DLO. We evaluated the effectiveness of our approach in both simulated and real-world environments for a variety of soft-rigid body manipulation tasks. In the real world, we also demonstrate the effectiveness of our decentralized approach through human-robot collaborative transportation of rigid objects to given goal locations. We also showcase the large operational space of IGP primitive by solving distant object acquisition tasks. Lastly, we compared our approach with several model-based and learning-based baseline methods. The results indicate that our method surpasses other approaches by a significant margin. The project supplementary material and videos are available at: https://sites.google.com/view/deri-igp/home
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring the Market Dynamics of Liquid Staking Derivatives (LSDs)</title>
<link>https://arxiv.org/abs/2402.17748</link>
<guid>https://arxiv.org/abs/2402.17748</guid>
<content:encoded><![CDATA[
<div> 关键词：staking、Liquid Staking Derivatives (LSDs)、市场动态、流动性提供者 (LPs)、流动性需求者 (LTs)

<br /><br />总结:
本文分析了在以太坊转向权益证明共识后兴起的staking概念中，液体权益质押衍生品（LSDs）对于解决单打独斗式质押带来的流动性问题的重要性。研究内容涉及从流动性需求者(LTs)和流动性提供者(LPs)两个视角对LSD市场动态进行剖析。首先量化了LSD一级市场与二级市场的价格差异；其次，探究并实证测量了LTs如何利用这一差异来发掘套利机会以及实现套利过程中可能遇到的障碍；此外，还评估了作为LPs供应LSDs进行流动性提供的金融盈亏情况。结果显示，有66%的LSD流动性持仓产生的回报低于直接持有相应LSDs的情况。 <div>
arXiv:2402.17748v3 Announce Type: replace 
Abstract: Staking has emerged as a crucial concept following Ethereum's transition to Proof-of-Stake consensus. The introduction of Liquid Staking Derivatives (LSDs) has effectively addressed the illiquidity issue associated with solo staking, gaining significant market attention. This paper analyzes the LSD market dynamics from the perspectives of both liquidity takers (LTs) and liquidity providers (LPs). We first quantify the price discrepancy between the LSD primary and secondary markets. Then we investigate and empirically measure how LTs can leverage such discrepancy to exploit arbitrage opportunities, unveiling the potential barriers to LSD arbitrages. In addition, we evaluate the financial profit and losses experienced by LPs who supply LSDs for liquidity provision. Our results show that 66% of LSD liquidity positions generate returns lower than those from simply holding the corresponding LSDs.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Proximal Gradient Method With Probabilistic Multi-Gossip Communications for Decentralized Composite Optimization</title>
<link>https://arxiv.org/abs/2312.11861</link>
<guid>https://arxiv.org/abs/2312.11861</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式优化、局部更新、通信效率、多 gossip 通信、非光滑优化

总结:
本文提出了一种名为MG-Skip的新方法，用于分布式复合（平滑+非平滑）优化问题，该方法具有概率性局部更新和多 gossip 通信的特点。MG-Skip 的步长独立于本地更新次数和网络拓扑结构，无需额外的网络连通性条件，在强凸设定下允许多数迭代中跳过多 gossip 通信。其迭代复杂度为$\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$，而通信复杂度仅为$\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$，其中$\kappa$表示损失函数的条件数，$\rho$反映网络拓扑的连通性，$\epsilon$为目标精度。理论结果表明，MG-Skip 实现了最优的通信复杂度，并证实了在非光滑设置中局部更新的优势。 <div>
arXiv:2312.11861v2 Announce Type: replace-cross 
Abstract: Decentralized optimization methods with local updates have recently gained attention for their provable ability to communication acceleration. In these methods, nodes perform several iterations of local computations between the communication rounds. Nevertheless, this capability is effective only when the loss function is smooth and the network is sufficiently well-connected. In this paper, we propose a communication-efficient method MG-Skip with probabilistic local updates and multi-gossip communications for decentralized composite (smooth + nonsmooth) optimization, whose stepsize is independent of the number of local updates and the network topology. Without any additional condition for network connectivity, MG-Skip allows for the multi-gossip communications to be skipped in most iterations in the strongly convex setting, while its iteration complexity is $\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$ and communication complexity is only $\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$, where $\kappa$ is the condition number of the loss function, $\rho$ reflects the connectivity of the network topology, and $\epsilon$ is the target accuracy. The theoretical results demonstrate that MG-Skip achieves the optimal communication complexity and confirm the benefits of local updates in the nonsmooth setup.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantifying the Value of Revert Protection</title>
<link>https://arxiv.org/abs/2410.19106</link>
<guid>https://arxiv.org/abs/2410.19106</guid>
<content:encoded><![CDATA[
<div> 关键词：revert protection、blockchain、priority auctions、maximal extractable value (MEV)、game theory

<br /><br />总结:
本文研究了区块链平台上的回滚保护功能对优先拍卖和最大可提取价值(MEV)经济影响及其益处。文章建立了一个均衡博弈理论模型，分析了在只有一个交易能成功实现共同机会价值的情况下，用户（MEV搜索者）竞标提前处理交易的行为，考虑了有无回滚保护两种环境。该模型适用于Layer 1（如以太坊主网）和Layer 2区块链，以及“捆绑拍卖”（在L1上）或优先级排序拍卖（在L2上）。文章指出，在缺乏回滚保护时，用户将采用随机策略来缓解因失败交易支付费用的影响，从而导致拍卖收入减少。然而，通过回滚保护可以定量提高拍卖收入，同时改善市场效率并更有效地利用区块空间，这取决于底层参数（MEV机会的价值、基础费、回滚惩罚及参与代理的数量）。 <div>
arXiv:2410.19106v1 Announce Type: new 
Abstract: Revert protection is a feature provided by some blockchain platforms that prevents users from incurring fees for failed transactions. This paper explores the economic implications and benefits of revert protection, in the context of priority auctions and maximal extractable value (MEV). We develop an equilibrium game theoretic model that captures the behavior of users (MEV searchers) bidding to have their transaction included ahead of others, in an environment where only a single transaction will succeed in realizing the common value of an opportunity, and in settings both with and without revert protection. Our model applies to a broad range of settings, including Layer 1 (L1) blockchains (e.g., Ethereum mainnet) and Layer 2 (L2) blockchains, and auctions such as ``bundle auctions'' (on L1s) or priority ordering auctions (on L2s).
  We establish that, in the absence of revert protection, users will employ randomized strategies to mitigate the impact of paying for failed transactions. This will ultimately result in less auction revenue, despite the fact that failed transactions still pay fees. Our results quantify in closed form how revert protection enhances auction revenue, and also improves market efficiency and provides for more efficient use of blockspace, as a function of the underlying parameters (the value of the MEV opportunity, the base fee, the revert penalties, and the number of participating agents).
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations, Digital Twins, and Large Language Model</title>
<link>https://arxiv.org/abs/2410.19262</link>
<guid>https://arxiv.org/abs/2410.19262</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Autonomous Building Cyber-Physical System、Decentralized Autonomous Organizations、Large Language Models、digital twins、autonomous building operation

<br />
总结：
本文提出了一个结合去中心化自治组织（Decentralized Autonomous Organizations）、大型语言模型（Large Language Models）和数字孪生技术的新型去中心化自主建筑 cyber-物理系统框架。该框架旨在创建一个智能、自管理、运营自主且财务自主的建筑基础设施。研究中开发了一个全栈式去中心化应用以促进建筑基础设施的去中心化治理，并构建了一个基于 LLM 的人工智能助手，用于提供直观的人机交互，支持区块链和建筑运营管理任务以及实现建筑系统的自主运行。通过六个实际场景的测试，验证了该原型系统能够成功执行包括建筑营收与支出管理、AI 辅助设施控制和建筑系统自主调整等操作，从而证明了该框架适用于发展具有去中心化治理和自主运行能力的建筑基础设施。 <div>
arXiv:2410.19262v1 Announce Type: new 
Abstract: Current autonomous building research primarily focuses on energy efficiency and automation. While traditional artificial intelligence has advanced autonomous building research, it often relies on predefined rules and struggles to adapt to complex, evolving building operations. Moreover, the centralized organizational structures of facilities management hinder transparency in decision-making, limiting true building autonomy. Research on decentralized governance and adaptive building infrastructure, which could overcome these challenges, remains relatively unexplored. This paper addresses these limitations by introducing a novel Decentralized Autonomous Building Cyber-Physical System framework that integrates Decentralized Autonomous Organizations, Large Language Models, and digital twins to create a smart, self-managed, operational, and financially autonomous building infrastructure. This study develops a full-stack decentralized application to facilitate decentralized governance of building infrastructure. An LLM-based artificial intelligence assistant is developed to provide intuitive human-building interaction for blockchain and building operation management-related tasks and enable autonomous building operation. Six real-world scenarios were tested to evaluate the autonomous building system's workability, including building revenue and expense management, AI-assisted facility control, and autonomous adjustment of building systems. Results indicate that the prototype successfully executes these operations, confirming the framework's suitability for developing building infrastructure with decentralized governance and autonomous operation.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration</title>
<link>https://arxiv.org/abs/2410.19450</link>
<guid>https://arxiv.org/abs/2410.19450</guid>
<content:encoded><![CDATA[
<div> 关键词：Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL), Offline Value Function Memory (OVM), Sequential Exploration (SE), StarCraft Multi-Agent Challenge (SMAC), 样本效率

总结:
本文提出了一种针对多智能体强化学习的新型框架—— Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL) 的OVMSE方法。该框架旨在解决在从离线到在线阶段转换过程中Q值重新学习的风险和大型联合状态-动作空间中有效探索的困难。OVMSE包括两个关键机制：一是离线价值函数记忆（OVM）机制，用于计算目标Q值，保持离线训练期间获得的知识并确保平滑过渡及有效微调；二是为O2O MARL设计的去中心化顺序探索（Sequential Exploration, SE）策略，它有效地利用预训练的离线策略进行探索，显著减少了需要探索的联合状态-动作空间。通过在StarCraft Multi-Agent Challenge (SMAC) 上的大量实验，表明OVMSE相对于现有基线具有显著优势，实现了更高的样本效率和总体性能提升。 <div>
arXiv:2410.19450v1 Announce Type: new 
Abstract: Offline-to-Online Reinforcement Learning has emerged as a powerful paradigm, leveraging offline data for initialization and online fine-tuning to enhance both sample efficiency and performance. However, most existing research has focused on single-agent settings, with limited exploration of the multi-agent extension, i.e., Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL). In O2O MARL, two critical challenges become more prominent as the number of agents increases: (i) the risk of unlearning pre-trained Q-values due to distributional shifts during the transition from offline-to-online phases, and (ii) the difficulty of efficient exploration in the large joint state-action space. To tackle these challenges, we propose a novel O2O MARL framework called Offline Value Function Memory with Sequential Exploration (OVMSE). First, we introduce the Offline Value Function Memory (OVM) mechanism to compute target Q-values, preserving knowledge gained during offline training, ensuring smoother transitions, and enabling efficient fine-tuning. Second, we propose a decentralized Sequential Exploration (SE) strategy tailored for O2O MARL, which effectively utilizes the pre-trained offline policy for exploration, thereby significantly reducing the joint state-action space to be explored. Extensive experiments on the StarCraft Multi-Agent Challenge (SMAC) demonstrate that OVMSE significantly outperforms existing baselines, achieving superior sample efficiency and overall performance.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>x-RAGE: eXtended Reality -- Action &amp; Gesture Events Dataset</title>
<link>https://arxiv.org/abs/2410.19486</link>
<guid>https://arxiv.org/abs/2410.19486</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse、wearable devices、gesture-based human-computer interaction、event-based cameras、XR-centric gesture recognition

<br /><br />总结:
随着Metaverse和可穿戴设备的发展，基于手势的人机交互变得越来越重要。为了解决VR/AR头显和眼镜上的手势识别问题，近年来出现了一些专注于第一人称视角的egocentric手势识别数据集。然而，传统的帧基视觉方法存在数据带宽需求大以及难以捕捉快速动作的局限性。为此，本文提出了一种使用事件相机为基础的首个egocentric手势识别神经形态、低功耗解决方案的数据集，以克服上述限制。该数据集已公开发布于以下URL：https://gitlab.com/NVM_IITD_Research/xrage。 <div>
arXiv:2410.19486v1 Announce Type: new 
Abstract: With the emergence of the Metaverse and focus on wearable devices in the recent years gesture based human-computer interaction has gained significance. To enable gesture recognition for VR/AR headsets and glasses several datasets focusing on egocentric i.e. first-person view have emerged in recent years. However, standard frame-based vision suffers from limitations in data bandwidth requirements as well as ability to capture fast motions. To overcome these limitation bio-inspired approaches such as event-based cameras present an attractive alternative. In this work, we present the first event-camera based egocentric gesture dataset for enabling neuromorphic, low-power solutions for XR-centric gesture recognition. The dataset has been made available publicly at the following URL: https://gitlab.com/NVM_IITD_Research/xrage.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully First-Order Methods for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2410.19319</link>
<guid>https://arxiv.org/abs/2410.19319</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized stochastic bilevel optimization, DSGDA-GT, first-order oracle, sample complexity, communication efficiency

总结:
本文关注的是分布式随机双层优化（DSBO）问题，其中各个智能体仅与其邻居进行通信。文章提出了一个新的算法——带有梯度跟踪的分布式随机梯度下降和上升（DSGDA-GT），该算法仅需使用比现有工作广泛采用的第二阶 oracle 更便宜的第一阶 oracles。进一步地，作者提供了有限时间收敛性分析，表明在有 n 个智能体协同解决 DSBO 问题的情况下，其算法找到 $\epsilon$-临界点所需的样本复杂度为 $\mathcal{O}(n^{-1}\epsilon^{-7})$，这一结果与单智能体情况下的最优已知结果具有线性加速比。数值实验展示了该算法在通信效率和训练效率上的优势。<br /><br /> <div>
arXiv:2410.19319v1 Announce Type: cross 
Abstract: This paper focuses on decentralized stochastic bilevel optimization (DSBO) where agents only communicate with their neighbors. We propose Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a novel algorithm that only requires first-order oracles that are much cheaper than second-order oracles widely adopted in existing works. We further provide a finite-time convergence analysis showing that for $n$ agents collaboratively solving the DSBO problem, the sample complexity of finding an $\epsilon$-stationary point in our algorithm is $\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known results of the single-agent counterpart with linear speedup. The numerical experiments demonstrate both the communication and training efficiency of our algorithm.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalizing Differentially Private Decentralized Deep Learning with Multi-Agent Consensus</title>
<link>https://arxiv.org/abs/2306.13892</link>
<guid>https://arxiv.org/abs/2306.13892</guid>
<content:encoded><![CDATA[
<div> 关键词：cooperative decentralized learning、differential privacy、deep learning、accuracy、privacy budget

<br /><br />总结:
本文提出了一个将差分隐私嵌入到分布式深度学习中的框架，旨在保障在合作学习过程中每个代理节点的局部数据集在训练期间和之后的安全。该框架保证了算法的收敛性，并在应用于子梯度和ADMM等分布式方法时，实现了接近集中式基准的准确性同时确保了个别数据样本对推断攻击具有抵抗能力。此外，文中还研究了在协作分类任务中，精度、隐私预算与通信网络图属性之间的关系，发现当超过某个阈值后，对通信图结构存在一种有用不变性。 <div>
arXiv:2306.13892v2 Announce Type: replace 
Abstract: Cooperative decentralized learning relies on direct information exchange between communicating agents, each with access to locally available datasets. The goal is to agree on model parameters that are optimal over all data. However, sharing parameters with untrustworthy neighbors can incur privacy risks by leaking exploitable information. To enable trustworthy cooperative learning, we propose a framework that embeds differential privacy into decentralized deep learning and secures each agent's local dataset during and after cooperative training. We prove convergence guarantees for algorithms derived from this framework and demonstrate its practical utility when applied to subgradient and ADMM decentralized approaches, finding accuracies approaching the centralized baseline while ensuring individual data samples are resilient to inference attacks. Furthermore, we study the relationships between accuracy, privacy budget, and networks' graph properties on collaborative classification tasks, discovering a useful invariance to the communication graph structure beyond a threshold.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning-Based UAV Pathfinding for Obstacle Avoidance in Stochastic Environment</title>
<link>https://arxiv.org/abs/2310.16659</link>
<guid>https://arxiv.org/abs/2310.16659</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体、强化学习、模型预测控制、分布式决策、通信约束

总结:
本文提出了一种基于多智能体强化学习和模型预测控制思想的新型集中式训练与分布式执行方法。该方法解决了传统方法在动态环境中迭代计算复杂度高的问题以及强化学习在大规模环境交互训练中的效率挑战。在提出的框架中，智能体仅与中心化规划器进行通信以在线做出分布式决策。同时，考虑到与中心化规划器的通信约束，每个智能体会利用基于距离加权均场方法的扩展观测来规划可行路径。受模型预测控制中滚动优化策略的启发，文中采用多步值收敛策略提升多智能体强化学习的训练效率，从而减少了收敛过程中的昂贵交互。实验结果在对比、消融及真实机器人实验中验证了本方法的有效性和泛化性能。 <div>
arXiv:2310.16659v2 Announce Type: replace 
Abstract: Traditional methods plan feasible paths for multiple agents in the stochastic environment. However, the methods' iterations with the changes in the environment result in computation complexities, especially for the decentralized agents without a centralized planner. Although reinforcement learning provides a plausible solution because of the generalization for different environments, it struggles with enormous agent-environment interactions in training. Here, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning, which is improved based on the idea of model predictive control. In our approach, agents communicate only with the centralized planner to make decentralized decisions online in the stochastic environment. Furthermore, considering the communication constraint with the centralized planner, each agent plans feasible paths through the extended observation, which combines information on neighboring agents based on the distance-weighted mean field approach. Inspired by the rolling optimization approach of model predictive control, we conduct multi-step value convergence in multi-agent reinforcement learning to enhance the training efficiency, which reduces the expensive interactions in convergence. Experiment results in both comparison, ablation, and real-robot studies validate the effectiveness and generalization performance of our method.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Learning and NLP in Cryptocurrency Forecasting: Integrating Financial, Blockchain, and Social Media Data</title>
<link>https://arxiv.org/abs/2311.14759</link>
<guid>https://arxiv.org/abs/2311.14759</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币价格预测、机器学习、自然语言处理、BART MNLI、深度学习NLP模型

总结:

本文介绍了利用机器学习（ML）和自然语言处理（NLP）技术进行加密货币价格预测的新方法，重点关注比特币和以太坊。研究中，通过分析Twitter和Reddit上的新闻与社交媒体内容，评估公众情绪对加密货币市场的影响。文章采用BART MNLI零样本分类模型检测市场趋势，超越了传统的 sentiment 分析方法。此外，还系统对比了一系列预训练和微调的深度学习NLP模型与常规基于词典的sentiment分析方法。另一重要贡献在于采用局部极值和每日价格变动作为预测目标，降低了交易频率并减小了投资组合波动性。实验结果表明，将文本数据融入加密货币价格预测不仅提高了预测准确性，而且在多种验证场景下持续提升了投资回报率和夏普比率，特别是应用深度学习NLP技术时。全部实验代码已通过在线仓库公开可供访问。 <div>
arXiv:2311.14759v2 Announce Type: replace-cross 
Abstract: We introduce novel approaches to cryptocurrency price forecasting, leveraging Machine Learning (ML) and Natural Language Processing (NLP) techniques, with a focus on Bitcoin and Ethereum. By analysing news and social media content, primarily from Twitter and Reddit, we assess the impact of public sentiment on cryptocurrency markets. A distinctive feature of our methodology is the application of the BART MNLI zero-shot classification model to detect bullish and bearish trends, significantly advancing beyond traditional sentiment analysis. Additionally, we systematically compare a range of pre-trained and fine-tuned deep learning NLP models against conventional dictionary-based sentiment analysis methods. Another key contribution of our work is the adoption of local extrema alongside daily price movements as predictive targets, reducing trading frequency and portfolio volatility. Our findings demonstrate that integrating textual data into cryptocurrency price forecasting not only improves forecasting accuracy but also consistently enhances the profitability and Sharpe ratio across various validation scenarios, particularly when applying deep learning NLP techniques. The entire codebase of our experiments is made available via an online repository: https://anonymous.4open.science/r/crypto-forecasting-public
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Edge General Intelligence via Large Language Models: Opportunities and Challenges</title>
<link>https://arxiv.org/abs/2410.18125</link>
<guid>https://arxiv.org/abs/2410.18125</guid>
<content:encoded><![CDATA[
<div> 关键词: Edge Intelligence, Edge General Intelligence, Large Language Models, Small Language Models, decentralized

总结:
本文介绍了Edge Intelligence(EI)的概念及其通过结合Large Language Models(LLMs)进化为Edge General Intelligence(EGI)的过程，概述了EGI与传统EI的区别。文章将LLM赋能的EGI分为集中式、混合式和去中心化三种概念系统，并对各系统的框架设计及现有实现进行了详细阐述。此外，还评估了适合在边缘设备上开发的小型语言模型(SLMs)的性能和吞吐量。该调查提供了对EGI全面的认识，揭示了其巨大潜力，并为这一快速发展的领域未来的进步奠定了基础。 <div>
arXiv:2410.18125v1 Announce Type: new 
Abstract: Edge Intelligence (EI) has been instrumental in delivering real-time, localized services by leveraging the computational capabilities of edge networks. The integration of Large Language Models (LLMs) empowers EI to evolve into the next stage: Edge General Intelligence (EGI), enabling more adaptive and versatile applications that require advanced understanding and reasoning capabilities. However, systematic exploration in this area remains insufficient. This survey delineates the distinctions between EGI and traditional EI, categorizing LLM-empowered EGI into three conceptual systems: centralized, hybrid, and decentralized. For each system, we detail the framework designs and review existing implementations. Furthermore, we evaluate the performance and throughput of various Small Language Models (SLMs) that are more suitable for development on edge devices. This survey provides researchers with a comprehensive vision of EGI, offering insights into its vast potential and establishing a foundation for future advancements in this rapidly evolving field.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Enterprise Security with Zero Trust Architecture</title>
<link>https://arxiv.org/abs/2410.18291</link>
<guid>https://arxiv.org/abs/2410.18291</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero Trust Architecture (ZTA)，现代网络安全，身份和访问管理(IAM)，微分割，连续监控

总结:
文章探讨了零信任架构（ZTA）作为现代网络安全的一种转型策略，它针对传统基于边界的安防模型的不足，尤其在云计算、远程工作以及日益复杂的网络威胁背景下。ZTA通过默认不信任任何用户、设备或系统并要求对所有实体进行持续验证和实行最小权限访问来转变安全范式。文中分析了ZTA的关键组成部分，如身份和访问管理（IAM）、微分割、持续监控和行为分析，并评估了它们在金融、医疗和科技等行业中降低风险的有效性。文章还通过案例研究和行业报告讨论了ZTA在抵御内部威胁和缩小攻击面方面的优势。同时，文章指出了实施ZTA所面临的挑战，如可扩展性、集成复杂性和成本问题，并提出了克服这些障碍的最佳实践。最后，文章展望了未来的研究方向，关注AI、机器学习、区块链等新兴技术如何进一步提升ZTA的能力。 <div>
arXiv:2410.18291v1 Announce Type: new 
Abstract: Zero Trust Architecture (ZTA) represents a transformative approach to modern cybersecurity, directly addressing the shortcomings of traditional perimeter-based security models. With the rise of cloud computing, remote work, and increasingly sophisticated cyber threats, perimeter defenses have proven ineffective at mitigating risks, particularly those involving insider threats and lateral movement within networks. ZTA shifts the security paradigm by assuming that no user, device, or system can be trusted by default, requiring continuous verification and the enforcement of least privilege access for all entities. This paper explores the key components of ZTA, such as identity and access management (IAM), micro-segmentation, continuous monitoring, and behavioral analytics, and evaluates their effectiveness in reducing vulnerabilities across diverse sectors, including finance, healthcare, and technology. Through case studies and industry reports, the advantages of ZTA in mitigating insider threats and minimizing attack surfaces are discussed. Additionally, the paper addresses the challenges faced during ZTA implementation, such as scalability, integration complexity, and costs, while providing best practices for overcoming these obstacles. Lastly, future research directions focusing on emerging technologies like AI, machine learning, blockchain, and their integration into ZTA are examined to enhance its capabilities further.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>RediSwap: MEV Redistribution Mechanism for CFMMs</title>
<link>https://arxiv.org/abs/2410.18434</link>
<guid>https://arxiv.org/abs/2410.18434</guid>
<content:encoded><![CDATA[
<div> 关键词: Automated Market Maker (AMM), Maximal Extractable Value (MEV), RediSwap, Liquidity Providers (LPs), Incentive-Compatible

总结:
本文介绍了RediSwap，一种新的自动做市商（AMM）设计，旨在通过在应用层面捕获并公平地将Maximal Extractable Value（MEV）返还给用户和流动性提供者（LPs）。RediSwap的核心是一个MEV再分配机制，用于管理AMM池内的套利机会。文章形式化了机制设计问题及期望的游戏理论性质，并证明了该机制具有激励相容性和Sybil防护性，同时展示了对套利者的友好参与性。通过回放历史AMM交易进行实证比较，结果显示RediSwap在89%的交易中相比UniswapX能实现更好的执行效果，并且大多数情况下可以将LPs的损失降低到原始LVR的0.5%以下。 <div>
arXiv:2410.18434v1 Announce Type: new 
Abstract: Automated Market Makers (AMMs) are essential to decentralized finance, offering continuous liquidity and enabling intermediary-free trading on blockchains. However, participants in AMMs are vulnerable to Maximal Extractable Value (MEV) exploitation. Users face threats such as front-running, back-running, and sandwich attacks, while liquidity providers (LPs) incur the loss-versus-rebalancing (LVR).
  In this paper, we introduce RediSwap, a novel AMM designed to capture MEV at the application level and refund it fairly among users and liquidity providers. At its core, RediSwap features an MEV-redistribution mechanism that manages arbitrage opportunities within the AMM pool. We formalize the mechanism design problem and the desired game-theoretical properties. A central insight underpinning our mechanism is the interpretation of the maximal MEV value as the sum of LVR and individual user losses. We prove that our mechanism is incentive-compatible and Sybil-proof, and demonstrate that it is easy for arbitrageurs to participate.
  We empirically compared RediSwap with existing solutions by replaying historical AMM trades. Our results suggest that RediSwap can achieve better execution than UniswapX in 89% of trades and reduce LPs' loss to under 0.5% of the original LVR in most cases.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains</title>
<link>https://arxiv.org/abs/2410.18631</link>
<guid>https://arxiv.org/abs/2410.18631</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习（MARL）、图神经网络（GNN）、库存控制、供应链、动态适应性

总结:
本文提出了一种结合多智能体强化学习（MARL）和图神经网络（GNN）的框架用于现代供应链中的库存控制问题。该框架通过参数化启发式库存控制策略重新定义行动空间，使其能够根据系统条件动态调整，具有更好的动态适应性。利用供应链的固有图结构，使各智能体能够学习系统拓扑，并采用集中式学习、分布式执行的方式，使得智能体能够在克服信息分享约束的同时进行协同学习。此外，还引入了全局均值池化和正则化技术以提升性能。通过在四种不同的供应链配置上测试以及敏感性分析，验证了所提方法的有效性，为复杂、去中心化的供应链环境中的库存管理提供了新的思路。 <div>
arXiv:2410.18631v1 Announce Type: new 
Abstract: Inventory control in modern supply chains has attracted significant attention due to the increasing number of disruptive shocks and the challenges posed by complex dynamics, uncertainties, and limited collaboration. Traditional methods, which often rely on static parameters, struggle to adapt to changing environments. This paper proposes a Multi-Agent Reinforcement Learning (MARL) framework with Graph Neural Networks (GNNs) for state representation to address these limitations.
  Our approach redefines the action space by parameterizing heuristic inventory control policies, making it adaptive as the parameters dynamically adjust based on system conditions. By leveraging the inherent graph structure of supply chains, our framework enables agents to learn the system's topology, and we employ a centralized learning, decentralized execution scheme that allows agents to learn collaboratively while overcoming information-sharing constraints. Additionally, we incorporate global mean pooling and regularization techniques to enhance performance.
  We test the capabilities of our proposed approach on four different supply chain configurations and conduct a sensitivity analysis. This work paves the way for utilizing MARL-GNN frameworks to improve inventory management in complex, decentralized supply chain environments.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A New Definition of Demand Response in the Distributed Energy Resource Era</title>
<link>https://arxiv.org/abs/2410.18768</link>
<guid>https://arxiv.org/abs/2410.18768</guid>
<content:encoded><![CDATA[
<div> 关键词：需求响应、分布式能源资源、电力市场改革、脱碳、管理策略

总结:
本文讨论了随着电力系统向自由化/去中心化和脱碳方向发展，以及分布式能源资源时代的到来，需求响应这一概念的重要性日益凸显。文章回顾了现有需求响应的定义，指出了它们的不足之处，并提出了一个新的定义，以更好地利用需求响应实现经济、技术、环境和社会目标。作者还基于对需求响应障碍与推动因素的讨论，提出了一项相关研究议程。 <div>
arXiv:2410.18768v1 Announce Type: new 
Abstract: Demand response is a concept that has been around since the very first electric power systems. However, we have seen an explosion of research on demand response and demand-side technologies in the past 30 years, coinciding with the shift towards liberalized/deregulated electricity markets and efforts to decarbonize the power sector. Now we are also seeing a shift towards more distributed/decentralized electric systems; we have entered the era of "distributed energy resources," which require new grid management, operational, and control strategies. Given this paradigm shift, we argue that the concept of demand response needs to be revisited, and more carefully/consistently defined to enable us to better utilize this massive resource for economic, technical, environmental, and societal aims. In this paper, we survey existing demand response definitions, highlight their shortcomings, propose a new definition, and describe how this new definition enables us to more effectively harness the value of demand response in modern power systems. We conclude with a demand response research agenda informed by a discussion of demand response barriers and enablers.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2410.18862</link>
<guid>https://arxiv.org/abs/2410.18862</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、去中心化、个性化、FedSPD、通信成本

总结:
<br />
本文提出了一个名为FedSPD的高效个性化联邦学习算法，特别适用于去中心化的环境。该算法能够在低连通性网络下仍能保持准确模型训练。与现有假设所有客户端训练共享模型的去中心化框架不同，FedSPD强调每个客户端的模型个性化，尤其适合于数据分布异构的情况。为了提供收敛性的理论保证，文章引入了一个基于聚类的框架，允许对不同数据聚类达成模型共识，并根据各个客户端的独特数据混合进行个性化定制，从而显著降低了通信成本。实验结果显示，FedSPD在实际数据集上优于多种去中心化的个性化联邦学习算法，特别是在低连通性网络场景中表现更优。 <div>
arXiv:2410.18862v1 Announce Type: new 
Abstract: Federated learning has recently gained popularity as a framework for distributed clients to collaboratively train a machine learning model using local data. While traditional federated learning relies on a central server for model aggregation, recent advancements adopt a decentralized framework, enabling direct model exchange between clients and eliminating the single point of failure. However, existing decentralized frameworks often assume all clients train a shared model. Personalizing each client's model can enhance performance, especially with heterogeneous client data distributions. We propose FedSPD, an efficient personalized federated learning algorithm for the decentralized setting, and show that it learns accurate models even in low-connectivity networks. To provide theoretical guarantees on convergence, we introduce a clustering-based framework that enables consensus on models for distinct data clusters while personalizing to unique mixtures of these clusters at different clients. This flexibility, allowing selective model updates based on data distribution, substantially reduces communication costs compared to prior work on personalized federated learning in decentralized settings. Experimental results on real-world datasets show that FedSPD outperforms multiple decentralized variants of personalized federated learning algorithms, especially in scenarios with low-connectivity networks.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully Stochastic Primal-dual Gradient Algorithm for Non-convex Optimization on Random Graphs</title>
<link>https://arxiv.org/abs/2410.18774</link>
<guid>https://arxiv.org/abs/2410.18774</guid>
<content:encoded><![CDATA[
<div> 关键词：stochastic decentralized optimization, asynchronous, sparsified communication, local stochastic gradient updates, FSPDA<br /><br />总结:

本文提出了一个名为$\underline{\rm F}$ully $\underline{\rm S}$tochastic $\underline{\rm P}$rimal $\underline{\rm D}$ual gradient $\underline{\rm A}$lgorithm (FSPDA)的全新算法，旨在解决随机分布式优化问题中的同步开销和间歇性通信问题。FSPDA具备两个特点：(1)在随机无向图上进行非阻塞的稀疏化异步通信；(2)执行局部随机梯度更新。该算法允许进行多次局部梯度步骤以加速收敛到平衡点，同时通过随机的原-对偶更新找到共识解。对于具有平滑（可能非凸）目标函数的问题，文章证明了FSPDA在不假设数据异质性的条件下，经过$\mathrm{\it T}$轮迭代后可达到$\mathrm{\mathcal{O}( {\it \sigma /\sqrt{nT}} )}$-准静态解的收敛率。此外，FSPDA的表现与依赖静态图和同步更新的现有最优算法相当。据作者所知，FSPDA是在非凸设置下首个能实现精确收敛的异步算法。数值实验展示了FSPDA的优势。 <div>
arXiv:2410.18774v1 Announce Type: cross 
Abstract: Stochastic decentralized optimization algorithms often suffer from issues such as synchronization overhead and intermittent communication. This paper proposes a $\underline{\rm F}$ully $\underline{\rm S}$tochastic $\underline{\rm P}$rimal $\underline{\rm D}$ual gradient $\underline{\rm A}$lgorithm (FSPDA) that suggests an asynchronous decentralized procedure with (i) sparsified non-blocking communication on random undirected graphs and (ii) local stochastic gradient updates. FSPDA allows multiple local gradient steps to accelerate convergence to stationarity while finding a consensual solution with stochastic primal-dual updates. For problems with smooth (possibly non-convex) objective function, we show that FSPDA converges to an $\mathrm{\mathcal{O}( {\it \sigma /\sqrt{nT}} )}$-stationary solution after $\mathrm{\it T}$ iterations without assuming data heterogeneity. The performance of FSPDA is on par with state-of-the-art algorithms whose convergence depend on static graph and synchronous updates. To our best knowledge, FSPDA is the first asynchronous algorithm that converges exactly under the non-convex setting. Numerical experiments are presented to show the benefits of FSPDA.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Send Message to the Future? Blockchain-based Time Machines for Decentralized Reveal of Locked Information</title>
<link>https://arxiv.org/abs/2401.05947</link>
<guid>https://arxiv.org/abs/2401.05947</guid>
<content:encoded><![CDATA[
<div> 关键词：conditional information reveal systems、timed-release cryptography、secret sharing scheme、blockchain、e-voting

<br /><br />总结:
本文介绍了在安全和去中心化条件下，对信息条件揭示系统有重大突破的研究。研究内容包括设计一种新的实用定时释放密码系统和具有可验证揭示性的秘密共享方案，以此构建了一个基于区块链的未来信息发送系统，能够实现高度精确的解密时间。提出的秘密共享方案也可应用于需要验证揭示的秘密份额的其他场景。论文提供了该创新范式的全面评估框架，涵盖了理论分析结果、Tamarin Prover 验证其鲁棒性以及全球范围内实际部署的开源系统原型性能评估。此外，通过使用真实世界的选举数据，文章还展示了这一创新系统在电子投票中的应用，证明了它对于确保安全、公正电子投票过程的能力。 <div>
arXiv:2401.05947v3 Announce Type: replace 
Abstract: Conditional information reveal systems automate the release of information upon meeting specific predefined conditions, such as time or location. This paper introduces a breakthrough in the understanding, design, and application of conditional information reveal systems that are highly secure and decentralized. By designing a new practical timed-release cryptography system and a secret sharing scheme with reveal-verifiability, a novel data sharing system is devised on the blockchain that "sends messages in the future" with highly accurate decryption times. Notably, the proposed secret sharing scheme applies to other applications requiring verifiability of revealed secret shares. This paper provides a complete evaluation portfolio of this pioneering paradigm, including analytical results, a validation of its robustness in the Tamarin Prover and a performance evaluation of a real-world, open-source system prototype deployed across the globe. Using real-world election data, we also demonstrate the applicability of this innovative system in e-voting, illustrating its capacity to secure and ensure fair electronic voting processes.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>How To Save Fees in Bitcoin Smart Contracts: a Simple Optimistic Off-chain Protocol</title>
<link>https://arxiv.org/abs/2403.09880</link>
<guid>https://arxiv.org/abs/2403.09880</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin、智能合约、交易费用、离链执行、安全协议

总结:

我们关注的是在比特币上执行智能合约的情况。在此场景中，每个合同步骤都对应于向区块链追加一个新的交易，该交易消费代表旧合同状态的输出，并为更新的状态创建新的输出。这一标准程序要求合同参与者为每次执行步骤支付交易费用。本文提出了一种将大部分比特币合同执行移至链下的协议。当所有参与者遵循此协议时，他们能够节省大量的交易费用。然而，当对手试图破坏离链执行时，任何诚实的参与者仍能通过回归到链上执行来确保正确的合同行为得到强制执行，从而保持安全性与正确性。<br /><br /> <div>
arXiv:2403.09880v3 Announce Type: replace 
Abstract: We consider the execution of smart contracts on Bitcoin. There, every contract step corresponds to appending to the blockchain a new transaction that spends the output representing the old contract state, creating a new one for the updated state. This standard procedure requires the contract participants to pay transaction fees for every execution step. In this paper, we introduce a protocol that moves most of the execution of a Bitcoin contract off-chain. When all participants follow this protocol, they are able to save on transaction fees, drastically reducing them. By contrast, whenever adversaries try to disrupt the off-chain execution, any honest participant is still able to enforce the correct contract behaviour, by continuing its execution on-chain.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Failed Migration of Academic Twitter</title>
<link>https://arxiv.org/abs/2406.04005</link>
<guid>https://arxiv.org/abs/2406.04005</guid>
<content:encoded><![CDATA[
<div> 关键词: Twitter, Mastodon, 学术界, 用户迁移, 内部网络<br /><br />总结:

随着Twitter所有权变更及其内容审核政策的变化，学术界的许多人士开始寻求转移讨论阵地，部分人选择了迁移到Mastodon。这项研究考察了这一迁移动态。通过对公开用户账户数据的分析，研究人员追踪了一年内学者们在Mastodon上的发帖活动，并收集了关注关系以描绘内部网络结构。研究发现，迁移至Mastodon的学术群体内部联系紧密，但这种强连接并未能阻止用户重返Twitter或其他平台如Bluesky和Threads。研究显示，由于其去中心化的结构以及来自其他平台的竞争，Mastodon上维持用户参与度存在显著挑战。初期的热情高峰过后，迁移运动失去了势头，大部分用户未能保持活跃度，而坚持使用Mastodon的用户则面临较低的互动水平。研究结果突显了将专业社区过渡到去中心化平台所面临的困难，强调了长期用户参与需要重视社区建设的重要性。 <div>
arXiv:2406.04005v2 Announce Type: replace 
Abstract: Following changes in Twitter's ownership and subsequent changes to content moderation policies, many in academia looked to move their discourse elsewhere and migration to Mastodon was pursued by some. Our study looks at the dynamics of this migration. Utilizing publicly available user account data, we track the posting activity of academics on Mastodon over a one year period. We also gathered follower-followee relationships to map internal networks, finding that the subset of academics who engaged in migration were well-connected. However, this strong internal connectivity was insufficient to prevent users from returning to Twitter/X. Our analyses reveal significant challenges sustaining user engagement on Mastodon due to its decentralized structure as well as competition from other platforms such as Bluesky and Threads. The movement lost momentum after an initial surge of enthusiasm where the main network was fully established as most users did not maintain their activity levels, and those who did faced lower levels of engagement. Our findings highlight the challenges involved in transitioning professional communities to decentralized platforms, emphasizing the need for focus on community building for long-term user engagement.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Code-Driven Law NO, Normware SI!</title>
<link>https://arxiv.org/abs/2410.17257</link>
<guid>https://arxiv.org/abs/2410.17257</guid>
<content:encoded><![CDATA[
<div> 关键词: digitalization, code, law, artificial intelligence, normware

<br />
总结:
随着社会的数字化进程，对于“代码”、“法律”和“人工智能”及其相互关系的关注、讨论与研究日益增多。然而，大多数观点主要集中在现代计算方法和人工制品（如机器学习构建的推理模型、规则系统、智能合约等）上，而非探寻更深层次的基本机制。为突破这一概念局限，本文提出了一个新的视角——“规范软件”（normware），作为与软件和硬件互补的明确立场。通过一些例子，文章论证了以规范软件为中心的观点更能适切地用于研究和设计人工智能设备与人类制度之间的互动，并有助于在更广泛的社会技术视野中设计和发展技术干预措施。 <div>
arXiv:2410.17257v1 Announce Type: new 
Abstract: With the digitalization of society, the interest, the debates and the research efforts concerning "code", "law", "artificial intelligence", and their various relationships, have been widely increasing. Yet, most arguments primarily focus on contemporary computational methods and artifacts (inferential models constructed via machine-learning methods, rule-based systems, smart contracts, ...), rather than attempting to identify more fundamental mechanisms. Aiming to go beyond this conceptual limitation, this paper introduces and elaborates on "normware" as an explicit additional stance -- complementary to software and hardware -- for the interpretation and the design of artificial devices. By means of a few examples, we argue that normware-centred views provide a more adequate abstraction to study and design interactions between computational systems and human institutions, and may help with the design and development of technical interventions within wider socio-technical views.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing Federated Learning Against Novel and Classic Backdoor Threats During Foundation Model Integration</title>
<link>https://arxiv.org/abs/2410.17573</link>
<guid>https://arxiv.org/abs/2410.17573</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习(Federated Learning)，基础模型(Foundation Models)，后门攻击(Backdoor Attacks)，防御策略(Defense Strategy)，异常激活(Abnormal Activations)

<br /><br />总结:
该文针对将基础模型融入联邦学习后引入的一种新型后门攻击机制进行了研究。这种攻击利用基础模型生成的合成数据来嵌入后门，进而通过知识共享在无需参与长期联邦学习过程的情况下影响所有客户端模型。鉴于现有联邦学习后门防御方法对此类新型攻击无效，文中提出了一种创新的数据无关防御策略，即在服务器端进行模型聚合时，通过对隐藏特征空间中的异常激活进行约束来抵御攻击。这种方法在协同训练过程中利用合成数据优化激活约束，能够在不影响模型性能的同时减轻攻击的影响。实验表明，这一新策略对于新型和经典后门攻击均具有显著的防御效果，同时保持了模型性能。 <div>
arXiv:2410.17573v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized model training while preserving privacy. Recently, integrating Foundation Models (FMs) into FL has boosted performance but also introduced a novel backdoor attack mechanism. Attackers can exploit the FM's capabilities to embed backdoors into synthetic data generated by FMs used for model fusion, subsequently infecting all client models through knowledge sharing without involvement in the long-lasting FL process. These novel attacks render existing FL backdoor defenses ineffective, as they primarily detect anomalies among client updates, which may appear uniformly malicious under this attack. Our work proposes a novel data-free defense strategy by constraining abnormal activations in the hidden feature space during model aggregation on the server. The activation constraints, optimized using synthetic data alongside FL training, mitigate the attack while barely affecting model performance, as the parameters remain untouched. Extensive experiments demonstrate its effectiveness against both novel and classic backdoor attacks, outperforming existing defenses while maintaining model performance.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection</title>
<link>https://arxiv.org/abs/2410.17792</link>
<guid>https://arxiv.org/abs/2410.17792</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 非独立同分布数据, 准确性下降, 动态数据队列驱动联邦学习(DDFL), 数据熵

总结:
本文研究了在非独立同分布数据环境下，联邦学习（Federated Learning, FL）中的统计复杂性问题，指出此类情况下模型准确度可能降低约10%-30%，尤其是在每个边缘设备仅训练单一类别数据的偏斜场景中。为解决这一问题，文章提出了一种名为动态数据队列驱动联邦学习（DDFL）的方法，该方法通过在服务器端创建全局数据子集并动态地分配到各个设备进行训练，从而减少权重分歧带来的偏差项（\(\delta_k\)）。同时，利用数据熵指标监控每轮训练过程并指导合理设备选择参与聚合。此外，文中还对所提DDFL进行了收敛性分析，证明其在实际FL场景中的可行性和对于改进设备选择、实现非次优全局模型以及加快收敛速度的效果。实验结果显示，DDFL方法相较于当前最先进的聚合算法，在MNIST、CIFAR-10和CIFAR-100数据集上分别实现了约5%、18%和20%的准确性提升，其中仅使用了10%的全局数据子集。<br /><br /> <div>
arXiv:2410.17792v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized approach for collaborative model training on edge devices. This distributed method of model training offers advantages in privacy, security, regulatory compliance, and cost-efficiency. Our emphasis in this research lies in addressing statistical complexity in FL, especially when the data stored locally across devices is not identically and independently distributed (non-IID). We have observed an accuracy reduction of up to approximately 10\% to 30\%, particularly in skewed scenarios where each edge device trains with only 1 class of data. This reduction is attributed to weight divergence, quantified using the Euclidean distance between device-level class distributions and the population distribution, resulting in a bias term (\(\delta_k\)). As a solution, we present a method to improve convergence in FL by creating a global subset of data on the server and dynamically distributing it across devices using a Dynamic Data queue-driven Federated Learning (DDFL). Next, we leverage Data Entropy metrics to observe the process during each training round and enable reasonable device selection for aggregation. Furthermore, we provide a convergence analysis of our proposed DDFL to justify their viability in practical FL scenarios, aiming for better device selection, a non-sub-optimal global model, and faster convergence. We observe that our approach results in a substantial accuracy boost of approximately 5\% for the MNIST dataset, around 18\% for CIFAR-10, and 20\% for CIFAR-100 with a 10\% global subset of data, outperforming the state-of-the-art (SOTA) aggregation algorithms.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning</title>
<link>https://arxiv.org/abs/2410.17933</link>
<guid>https://arxiv.org/abs/2410.17933</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，医疗数据共享，区块链，联合学习，隐私保护

总结:
本文提出了一种利用来自欧洲、北美和亚洲多地的数据集进行全球医疗健康建模的框架，而无需分享本地数据集，以血糖管理为研究模型验证其有效性。该框架采用了适应医疗数据隐私与安全要求的区块链赋能的联合学习技术，并通过链上激励机制奖励诚实参与并惩罚恶意行为。实验结果显示，所提出的框架有效、高效且能保护隐私，其预测精度优于仅使用有限个人数据训练的模型，甚至接近或略高于集中式数据集的结果。这项工作为国际间医疗项目的合作开辟了道路，对于减少偏见并为人类带来更多福祉提供了重要支持。 <div>
arXiv:2410.17933v1 Announce Type: new 
Abstract: One of the biggest challenges of building artificial intelligence (AI) model in healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausted, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America and Asia) while without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaption to make it meet with the privacy and safety requirements of healthcare data, meanwhile rewards honest participation and penalize malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy preserved. Its prediction accuracy is much better than the models trained from limited personal data and is similar to, and even slightly better than, the results from a centralized dataset. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancements in Electric Vehicle Charging Optimization: A Survey of Reinforcement Learning Approaches</title>
<link>https://arxiv.org/abs/2410.16425</link>
<guid>https://arxiv.org/abs/2410.16425</guid>
<content:encoded><![CDATA[
<div> 关键词: 全球变暖、可再生能源、电动汽车、智能电网、强化学习

总结:
随着全球变暖和能源短缺问题凸显，可再生能源、储能系统以及电动汽车的整合日益受到重视。将电动汽车融入智能电网中，有助于减少碳排放。然而，电动汽车作为分布式电源的充放电管理面临挑战，同时还要应对间歇性可再生能源、电动车参数不确定性、电价波动及负荷变化等问题。有效的电动汽车电池充电管理系统对于协调这些过程并确保电力系统的稳定运行至关重要。其中，强化学习结合深度学习因其无模型化方法和实时优化能力，在电动车辆充电协调策略方面展现出巨大潜力。文章综述了现有基于强化学习的电动汽车充电协调策略的研究，按照集中式和分散式两大类进行了分类讨论，并对未来研究方向提出了建议。 <div>
arXiv:2410.16425v1 Announce Type: new 
Abstract: In response to global warming and energy shortages, there has been a significant shift towards integrating renewable energy sources, energy storage systems, and electric vehicles. Deploying electric vehicles within smart grids offers a promising solution to reduce carbon emissions. However, managing the charging and discharging processes of them as distributed power supplies present significant challenges. Additionally, the intermittent nature of renewable energy, uncertainties in electric vehicle-related parameters, fluctuating energy prices, and varying loads make maintaining stable power system operations more complex. Effective management systems for electric vehicle battery charging are crucial to coordinating these processes and ensuring a secure, efficient, and reliable power system. Reinforcement learning, enhanced by deep learning, has gained substantial interest for its model-free approach and real-time optimization, effectively managing electric vehicle charging by maximizing cumulative rewards. This review synthesizes existing literature on reinforcement learning-based frameworks, objectives, and architectures for electric vehicle charging coordination strategies in power systems, classifying methods into centralized and decentralized categories. Additionally, the article offers suggestions for future research directions to further enhance reinforcement learning-based electric vehicle charging optimization.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>RGMDT: Return-Gap-Minimizing Decision Tree Extraction in Non-Euclidean Metric Space</title>
<link>https://arxiv.org/abs/2410.16517</link>
<guid>https://arxiv.org/abs/2410.16517</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习（Deep Reinforcement Learning, DRL）、可解释性、决策树（Decision Tree, DT）、多智能体、回报差距上界

总结:

本文关注深度强化学习的可解释性问题，提出了一种新的方法用于从DRL策略中提取具有决策树结构的策略。研究者建立了专家策略与最优决策树策略之间回报差距上界的理论框架。在此基础上，他们将决策树提取问题转化为非欧几里得聚类问题，并设计了一个迭代生长决策树的算法来适应多智能体的分布式场景。此外，文章提出了“回报差距最小化决策树”（Return-Gap-Minimization Decision Tree, RGMDT）算法，该算法通过结合强化学习和新颖的正则化信息最大化损失函数进行集成。实验表明，RGMDT算法在如D4RL等任务上显著优于基于启发式的DT基线，并能在给定的决策树复杂度约束下实现接近最优的回报。 <div>
arXiv:2410.16517v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) algorithms have achieved great success in solving many challenging tasks while their black-box nature hinders interpretability and real-world applicability, making it difficult for human experts to interpret and understand DRL policies. Existing works on interpretable reinforcement learning have shown promise in extracting decision tree (DT) based policies from DRL policies with most focus on the single-agent settings while prior attempts to introduce DT policies in multi-agent scenarios mainly focus on heuristic designs which do not provide any quantitative guarantees on the expected return. In this paper, we establish an upper bound on the return gap between the oracle expert policy and an optimal decision tree policy. This enables us to recast the DT extraction problem into a novel non-euclidean clustering problem over the local observation and action values space of each agent, with action values as cluster labels and the upper bound on the return gap as clustering loss. Both the algorithm and the upper bound are extended to multi-agent decentralized DT extractions by an iteratively-grow-DT procedure guided by an action-value function conditioned on the current DTs of other agents. Further, we propose the Return-Gap-Minimization Decision Tree (RGMDT) algorithm, which is a surprisingly simple design and is integrated with reinforcement learning through the utilization of a novel Regularized Information Maximization loss. Evaluations on tasks like D4RL show that RGMDT significantly outperforms heuristic DT-based baselines and can achieve nearly optimal returns under given DT complexity constraints (e.g., maximum number of DT nodes).
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>NodeOP: Optimizing Node Management for Decentralized Networks</title>
<link>https://arxiv.org/abs/2410.16720</link>
<guid>https://arxiv.org/abs/2410.16720</guid>
<content:encoded><![CDATA[
<div> 关键词：NodeOP、Agent-Based Modeling (ABM)、Tendermint BFT、共识机制、分布式网络

总结:<br />
本文介绍了NodeOP，这是一个针对去中心化网络中通用节点运营商管理的新颖优化框架。该框架通过将Agent-Based Modeling (ABM)与基于Tendermint拜占庭容错(BFT)的共识机制相结合，解决了任务分配、共识形成和系统稳定性等关键挑战。通过严谨的数学建模和形式化优化，NodeOP确保了节点任务分布的稳定均衡。文章通过收敛分析和交易吞吐量、系统延迟及容错性等性能指标验证了框架的有效性。此外，作者通过两个实际应用案例——Layer 2网络中的去中心化序列器管理和离链支付验证，展示了NodeOP如何提高验证效率并创造大规模去中心化环境下的新的收益机会。这些结果表明，NodeOP是一个可扩展且灵活的解决方案，能显著提升分布式系统的运营效率和经济可持续性。 <div>
arXiv:2410.16720v1 Announce Type: new 
Abstract: We present NodeOP, a novel framework designed to optimize the management of General Node Operators in decentralized networks. By integrating Agent-Based Modeling (ABM) with a Tendermint Byzantine Fault Tolerance (BFT)-based consensus mechanism, NodeOP addresses key challenges in task allocation, consensus formation, and system stability. Through rigorous mathematical modeling and formal optimization, NodeOP ensures stable equilibrium in node task distribution. We validate the framework via convergence analysis and performance metrics such as transaction throughput, system latency, and fault tolerance. We further demonstrate NodeOP's practical utility through two use cases: decentralized sequencer management in Layer 2 networks and off-chain payment validation. These examples underscore how NodeOP enhances validation efficiency and unlocks new revenue opportunities in large-scale decentralized environments. Our results position NodeOP as a scalable and flexible solution, significantly improving operational efficiency and economic sustainability in decentralized systems.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering the Grid: Decentralized Autonomous Control for Effective Utilization and Resilience</title>
<link>https://arxiv.org/abs/2410.17143</link>
<guid>https://arxiv.org/abs/2410.17143</guid>
<content:encoded><![CDATA[
<div> 关键词：低惯性微电网、电网形成型逆变器(GFMs)、分布式自主控制器(DACs)、韧性约束操作、实时执行

<br /><br />总结:
本文关注于由逆变器基础发电构成的低惯性微电网的运行韧性感问题。为了解决这一问题，文章提出了基于局部、最小侵入式调整的分散式自主控制器（DACs），这些控制器可在现有的初级和次级控制层级结构中并存，以确保在各种 cyber-物理中断下的韧性约束操作，例如在暂态过程中维持关键的安全运行限值。该 DAC 控制方案具有计算效率高（仅需代数运算）的特点，能实现快速实时执行。通过使用 GridLAB-D-HELICS 基的控制-电网联合仿真，在IEEE 123节点网络化微电网中验证了该方法的有效性。最后，研究表明，开发的 DAC 能够充分利用可用资源，确保电网韧性，保持频率安全限制。 <div>
arXiv:2410.17143v1 Announce Type: new 
Abstract: With the emergence of low-inertia microgrids powered by inverter-based generation, there remains a concern about the operational resilience of these systems. Grid-forming inverters (GFMs), enabled by various device-level (primary) and system-level (secondary) control methods, are poised to play a significant role in achieving certain operational objectives, such as the effective utilization of clean energy resources while maintaining stability. However, despite the recent advances in GFMs, there is a lack of suitable controls that can ascertain resilience-constrained operations, like maintaining critical operational safety limits during transients under various cyber-physical disruptions. In this work, we develop decentralized autonomous controllers (DACs) that enforce resilience-constrained operation via local, minimally invasive adjustments (e.g., changes in set-points) while co-existing within the hierarchy of existing (primary and secondary) controls. The DACs work autonomously by sensing only local GFM measurements and act only when operational resilience constraints are violated. The proposed DAC scheme is computationally efficient (only algebraic computations), which enables fast, real-time execution and demonstrates the efficacy of the proposed control framework on GridLAB-D-HELICS-based control-grid co-simulations on the IEEE 123-node networked microgrid. Finally, we show how the developed DACs empower the grid by utilizing the available resources entirely to ensure resilience (maintain frequency safe limits).
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vulnerability anti-patterns in Solidity: Increasing smart contracts security by reducing false alarms</title>
<link>https://arxiv.org/abs/2410.17204</link>
<guid>https://arxiv.org/abs/2410.17204</guid>
<content:encoded><![CDATA[
<div> 关键词：Turing完备性、Ethereum智能合约、安全性工具、静态分析、误报率

总结:

本文探讨了以太坊智能合约由于图灵完备性而备受区块链开发者和攻击者的关注。为提升代码安全性，已有许多工具能够检测出大部分已知漏洞，但这些工具的误报率高达99%，导致其在实际工业应用中不切实际，进而引发了学术研究方向的疑问。文章提出了一种融合与拓展当前分析方法的轻量级静态检查方案，该方案基于开发人员中心化的漏洞概念，用于验证其他工具的输出、标记潜在的误报并提供验证建议。作者实现了一个开源原型并在其中针对排名前10的三个高危漏洞，在从区块链中挑选出的60个存在真实（和虚假）漏洞的去重智能合约上进行了测试。结果显示，对于这三个漏洞，该原型成功将其他工具产生的324个警告标记为误报，实现了对这三种漏洞误报率92%至100%的降低。 <div>
arXiv:2410.17204v1 Announce Type: new 
Abstract: Turing completeness has made Ethereum smart contracts attractive to blockchain developers and attackers alike. To increase code security, many tools can now spot most known vulnerabilities$-$at the cost of production efficiency. Recent studies show false-positive ratios over 99% in state-of-the-art technologies: this makes them impractical for use in industry and have raised questions on the direction of academic research. In this work we show how integrating and extending current analyses is not only feasible, but also a next logical step in smart-contract security. We propose light-weight static checks on the morphology and dynamics of Solidity code, stemming from a developer-centric notion of vulnerability, that we use to verify the output of other tools, flag potential false alarms, and suggest verifications. Besides technical details we implemented an open-source prototype. For three top-10 vulnerabilities it flags 324 warnings of other tools as false-positives, in 60 verified de-duplicated smart contracts selected from the blockchain by the presence of true (and false) vulnerabilities. This amounts to a 92%- to 100%-reduction in the number of false-positives for these vulnerabilities.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Causal Inference: Multi-Centric ATE Estimation beyond Meta-Analysis</title>
<link>https://arxiv.org/abs/2410.16870</link>
<guid>https://arxiv.org/abs/2410.16870</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Causal Inference、平均治疗效果(Average Treatment Effect, ATE)、插值G公式、联邦学习、随机对照试验(Randomized Controlled Trials, RCT)

总结:

本文研究了Federated Causal Inference，这是一种用于从分布式数据中估计治疗效果的方法。文章对比分析了三种基于Plug-in G-Formula的ATE估计器，包括简单的元分析以及一拍和多拍联邦学习方法，后者利用全部数据来学习结果模型（尽管需要更多的通信）。针对随机对照试验(RCT)，文中为线性模型下的这些估计器导出了渐近方差。研究结果为不同场景下选择合适的估计器提供了实践指导，考虑到了样本量差异、协变量分布、治疗分配方案及中心效应等异质性因素。此外，作者通过模拟研究验证了这些发现。 <div>
arXiv:2410.16870v1 Announce Type: cross 
Abstract: We study Federated Causal Inference, an approach to estimate treatment effects from decentralized data across centers. We compare three classes of Average Treatment Effect (ATE) estimators derived from the Plug-in G-Formula, ranging from simple meta-analysis to one-shot and multi-shot federated learning, the latter leveraging the full data to learn the outcome model (albeit requiring more communication). Focusing on Randomized Controlled Trials (RCTs), we derive the asymptotic variance of these estimators for linear models. Our results provide practical guidance on selecting the appropriate estimator for various scenarios, including heterogeneity in sample sizes, covariate distributions, treatment assignment schemes, and center effects. We validate these findings with a simulation study.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory Planner</title>
<link>https://arxiv.org/abs/2406.10060</link>
<guid>https://arxiv.org/abs/2406.10060</guid>
<content:encoded><![CDATA[
<div> 关键词： decentralized multiagent trajectory planners, localization errors, PARM, PARM*, PRIMER

总结:

本文提出了解决在存在定位误差的分布式多智能体轨迹规划问题的方法。首先，为了解决由于不确定性导致的轨迹冲突，文章介绍了两个感知感知型、分布式的异步多智能体轨迹规划器——PARM和PARM*，它们利用感知信息使团队中的智能体能在不确定环境中实现避障与轨迹解冲突。其中，PARM*相较于PARM更为优化但计算量较大。然而，这类基于优化的方法面临高计算成本的问题，使得智能体难以高频重规划。为此，文章提出了第二个关键贡献——PRIMER，这是一种基于模仿学习（IL）训练的学习型规划器，它以PARM*作为专家演示者进行训练。PRIMER利用神经网络在部署时的低计算需求，实现了相对于优化方法高达5500倍的计算速度提升。 <div>
arXiv:2406.10060v2 Announce Type: replace 
Abstract: In decentralized multiagent trajectory planners, agents need to communicate and exchange their positions to generate collision-free trajectories. However, due to localization errors/uncertainties, trajectory deconfliction can fail even if trajectories are perfectly shared between agents. To address this issue, we first present PARM and PARM*, perception-aware, decentralized, asynchronous multiagent trajectory planners that enable a team of agents to navigate uncertain environments while deconflicting trajectories and avoiding obstacles using perception information. PARM* differs from PARM as it is less conservative, using more computation to find closer-to-optimal solutions. While these methods achieve state-of-the-art performance, they suffer from high computational costs as they need to solve large optimization problems onboard, making it difficult for agents to replan at high rates. To overcome this challenge, we present our second key contribution, PRIMER, a learning-based planner trained with imitation learning (IL) using PARM* as the expert demonstrator. PRIMER leverages the low computational requirements at deployment of neural networks and achieves a computation speed up to 5500 times faster than optimization-based approaches.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility</title>
<link>https://arxiv.org/abs/2202.08967</link>
<guid>https://arxiv.org/abs/2202.08967</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、加密货币、波动性、CoMForE模型、多模态预测

<br /><br />总结:

本文研究了影响比特币-美元汇率波动性的多种独立因素，并提出了一个多模态AdaBoost-LSTM集成模型——CoMForE。该模型不仅利用历史交易数据，还结合了与比特币相关的推文情绪、搜索量以及区块链哈希率等数据。通过全面实验验证，CoMForE模型能够更准确地预测加密货币价值分布的变化，相比现有预测工具和方法有显著优势，表现出了19.29%的提升，强调了外部独立因素对加密货币市场波动性的影响。 <div>
arXiv:2202.08967v2 Announce Type: replace-cross 
Abstract: Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have become a worldwide phenomenon as important decentralized financial assets. Their decentralized nature, however, leads to notable volatility against traditional fiat currencies, making the task of accurately forecasting the crypto-fiat exchange rate complex. This study examines the various independent factors that affect the volatility of the Bitcoin-Dollar exchange rate. To this end, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not only utilizes historical trading data but also incorporates public sentiments from related tweets, public interest demonstrated by search volumes, and blockchain hash-rate data. Our developed model goes a step further by predicting fluctuations in the overall cryptocurrency value distribution, thus increasing its value for investment decision-making. We have subjected this method to extensive testing via comprehensive experiments, thereby validating the importance of multimodal combination over exclusive reliance on trading data. Further experiments show that our method significantly surpasses existing forecasting tools and methodologies, demonstrating a 19.29% improvement. This result underscores the influence of external independent factors on cryptocurrency volatility.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Domain Isolation and Sample Clustered Federated Learning for Semantic Segmentation</title>
<link>https://arxiv.org/abs/2410.14693</link>
<guid>https://arxiv.org/abs/2410.14693</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、非独立同分布、协变量偏移、深度域隔离、样例聚类联邦学习

<br /><br />总结:
该文首次探究了联邦学习在二维分割任务中因参与者数据间的协变量偏移而带来的收敛问题，发现其影响虽小于标签偏移但仍存在。现有的个性化联邦学习（PFL）和集群联邦学习（CFL）方法假设每个参与者的数据集内部是一致且与未来测试样本相匹配的。为了解决这一问题，文中提出了深度域隔离（DDI）技术，能够在模型梯度空间中直接隔离图像域。进一步地，文章提出了一种样例聚类联邦学习（SCFL）框架，结合了联邦高斯混合模型和谱聚类算法，以标准联邦学习方式训练针对不同分散图像域的独立模型。最后，通过训练一个分类器，可以在推理时将测试样本关联到对应的域簇，从而实现对每个参与者测试分布假设的无关性。实验证明，该方法在玩具分割数据集以及Cityscapes和GTA5数据集的不同划分上使用EfficientVIT-B0模型进行实验，相比其他方法有显著的性能提升。研究成果已开源发布于GitHub仓库https://github.com/MatthisManthe/DDI_SCFL 。 <div>
arXiv:2410.14693v1 Announce Type: new 
Abstract: Empirical studies show that federated learning exhibits convergence issues in Non Independent and Identically Distributed (IID) setups. However, these studies only focus on label distribution shifts, or concept shifts (e.g. ambiguous tasks). In this paper, we explore for the first time the effect of covariate shifts between participants' data in 2D segmentation tasks, showing an impact way less serious than label shifts but still present on convergence. Moreover, current Personalized (PFL) and Clustered (CFL) Federated Learning methods intrinsically assume the homogeneity of the dataset of each participant and its consistency with future test samples by operating at the client level. We introduce a more general and realistic framework where each participant owns a mixture of multiple underlying feature domain distributions. To diagnose such pathological feature distributions affecting a model being trained in a federated fashion, we develop Deep Domain Isolation (DDI) to isolate image domains directly in the gradient space of the model. A federated Gaussian Mixture Model is fit to the sample gradients of each class, while the results are combined with spectral clustering on the server side to isolate decentralized sample-level domains. We leverage this clustering algorithm through a Sample Clustered Federated Learning (SCFL) framework, performing standard federated learning of several independent models, one for each decentralized image domain. Finally, we train a classifier enabling to associate a test sample to its corresponding domain cluster at inference time, offering a final set of models that are agnostic to any assumptions on the test distribution of each participant. We validate our approach on a toy segmentation dataset as well as different partitionings of a combination of Cityscapes and GTA5 datasets using an EfficientVIT-B0 model, showing a significant performance gain compared to other approaches. Our code is available at https://github.com/MatthisManthe/DDI_SCFL .
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FACMIC: Federated Adaptative CLIP Model for Medical Image Classification</title>
<link>https://arxiv.org/abs/2410.14707</link>
<guid>https://arxiv.org/abs/2410.14707</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、通信成本、视觉基础模型、对比语言图像预训练（Contrastive Language Image Pretraining, CLIP）、特征注意力模块（Feature Attention Module）

总结:<br />
本文提出了一种用于分类任务的联邦学习环境下自适应的CLIP模型，名为FACMIC。该模型旨在解决在保证数据隐私的同时，进行深度模型训练时面临的通信成本问题。FACMIC采用了一个轻量级且高效的特征注意力模块，可以根据每个客户端的数据选择合适的特征。此外，还提出了一个领域适应技术以减小客户端间数据分布的差异。实验结果表明，FACMIC在处理真实世界和多源医学影像数据方面表现优越。相关代码已开源，可在https://github.com/AIPMLab/FACMIC获取。 <div>
arXiv:2410.14707v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a promising approach to medical image analysis that allows deep model training using decentralized data while ensuring data privacy. However, in the field of FL, communication cost plays a critical role in evaluating the performance of the model. Thus, transferring vision foundation models can be particularly challenging due to the significant resource costs involved. In this paper, we introduce a federated adaptive Contrastive Language Image Pretraining CLIP model designed for classification tasks. We employ a light-weight and efficient feature attention module for CLIP that selects suitable features for each client's data. Additionally, we propose a domain adaptation technique to reduce differences in data distribution between clients. Experimental results on four publicly available datasets demonstrate the superior performance of FACMIC in dealing with real-world and multisource medical imaging data. Our codes are available at https://github.com/AIPMLab/FACMIC.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title>
<link>https://arxiv.org/abs/2410.14803</link>
<guid>https://arxiv.org/abs/2410.14803</guid>
<content:encoded><![CDATA[
<div> 关键词: on-device control agents, Multimodal Large Language Models (MLLMs), DistRL, reinforcement learning (RL), training efficiency

<br /><br />总结:

本文介绍了一种针对移动设备控制代理的新型框架DistRL，该框架旨在提高集成多模态大型语言模型（MLLMs）的在线强化学习（RL）微调效率。针对数据有限和在线训练过程低效的问题，DistRL采用集中式训练与分布式数据采集相结合的方式，确保动态在线交互下的高效微调。此外，DistRL还配备了一个定制的RL算法，有效地平衡了探索性与收集数据的优先使用，以实现稳定而健壮的训练。实验结果显示，相比于领先的同步多机器方法，DistRL的训练效率提高了3倍，训练数据收集速度提高了2.4倍。在完成实际设备控制任务方面，经过训练后，DistRL在公开基准测试中的成功率相对提升了20%，显著优于现有方法的同时，保持了相同的训练时间。这些结果验证了DistRL是一个可扩展、高效的解决方案，为现实世界中的设备控制任务提供了显著提升的训练效率和代理性能。 <div>
arXiv:2410.14803v1 Announce Type: new 
Abstract: On-device control agents, especially on mobile devices, are responsible for operating mobile devices to fulfill users' requests, enabling seamless and intuitive interactions. Integrating Multimodal Large Language Models (MLLMs) into these agents enhances their ability to understand and execute complex commands, thereby improving user experience. However, fine-tuning MLLMs for on-device control presents significant challenges due to limited data availability and inefficient online training processes. This paper introduces DistRL, a novel framework designed to enhance the efficiency of online RL fine-tuning for mobile device control agents. DistRL employs centralized training and decentralized data acquisition to ensure efficient fine-tuning in the context of dynamic online interactions. Additionally, the framework is backed by our tailor-made RL algorithm, which effectively balances exploration with the prioritized utilization of collected data to ensure stable and robust training. Our experiments show that, on average, DistRL delivers a 3X improvement in training efficiency and enables training data collection 2.4X faster than the leading synchronous multi-machine methods. Notably, after training, DistRL achieves a 20% relative improvement in success rate compared to state-of-the-art methods on general Android tasks from an open benchmark, significantly outperforming existing approaches while maintaining the same training time. These results validate DistRL as a scalable and efficient solution, offering substantial improvements in both training efficiency and agent performance for real-world, in-the-wild device control tasks.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordinated Frequency Regulation in Grid-Forming Storage Network via Safety-Consensus</title>
<link>https://arxiv.org/abs/2410.14877</link>
<guid>https://arxiv.org/abs/2410.14877</guid>
<content:encoded><![CDATA[
<div> 关键词: 变流器存储、电网、有源发电机控制、共识算法、安全限制<br /><br />总结:

本文探讨了变流器储能系统在未来大规模可再生能源并网中的关键作用。为了实现类似同步发电机特性的电网形成型逆变器(GFM)通过初级控制环路参与频率调节和故障后恢复频率至正常水平。然而，确保在电网从预扰动到后扰动运行点过渡期间，暂态频率跃变不会超出安全极限至关重要。文章提出了一种层次化的安全强制共识方法，该方法结合设备层（分布式）瞬态安全性滤波器与二级层（分布式）共识协调，以实现三个目标：将暂态频率跃变限制在安全范围内、最小化频率偏离额定值以及确保GFM接口存储单元间的协同功率共享。通过在IEEE 68节点系统上使用GFM接口储能网络模拟多种电网暂态场景，验证了所提出的两层安全共识技术的有效性。 <div>
arXiv:2410.14877v1 Announce Type: new 
Abstract: Inverter-based storages are poised to play a prominent role in future power grids with massive renewable generation. Grid-forming inverters (GFMs) are emerging as a dominant technology with synchronous generators (SG)-like characteristics through primary control loops. Advanced secondary control schemes, e.g., consensus algorithms, allow GFM-interfaced storage units to participate in frequency regulations and restore nominal frequency following grid disturbances. However, it is imperative to ensure transient frequency excursions do not violate critical safety limits while the grid transitions from pre- to post-disturbance operating point. This paper presents a hierarchical safety-enforced consensus method -- combining a device-layer (decentralized) transient safety filter with a secondary-layer (distributed) consensus coordination -- to achieve three distinct objectives: limiting transient frequency excursions to safe limits, minimizing frequency deviations from nominal, and ensuring coordinated power sharing among GFM-storage units. The proposed hierarchical (two-layered) safety-consensus technique is illustrated using a GFM-interfaced storage network on an IEEE 68-bus system under multiple grid transient scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperation and Fairness in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.14916</link>
<guid>https://arxiv.org/abs/2410.14916</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、公平性、强化学习、导航、效率

总结:
本文研究了在多智能体环境中使用强化学习实现公平导航的问题。为了解决效率与公平之间的平衡，作者提出了一个结合最小最大公平距离目标分配和鼓励公平性的奖励机制的训练方法。通过这种方法，智能体能够在仅依赖局部观测的情况下，学习到公平的目标分配并几乎完美地覆盖导航任务。实验结果显示，相比于随机目标分配基线，该模型在保持平均14%的效率提升的同时，实现了平均5%的公平性提升；相较于最优效率分配模型，虽然以7%的效率下降为代价，但公平性提升了21%。此外，该方法还被扩展到了需要按预定阵型完成覆盖任务的环境，并展示了无需针对特定阵型定制模型即可实现这一目标的可能性。 <div>
arXiv:2410.14916v1 Announce Type: new 
Abstract: Multi-agent systems are trained to maximize shared cost objectives, which typically reflect system-level efficiency. However, in the resource-constrained environments of mobility and transportation systems, efficiency may be achieved at the expense of fairness -- certain agents may incur significantly greater costs or lower rewards compared to others. Tasks could be distributed inequitably, leading to some agents receiving an unfair advantage while others incur disproportionately high costs. It is important to consider the tradeoffs between efficiency and fairness. We consider the problem of fair multi-agent navigation for a group of decentralized agents using multi-agent reinforcement learning (MARL). We consider the reciprocal of the coefficient of variation of the distances traveled by different agents as a measure of fairness and investigate whether agents can learn to be fair without significantly sacrificing efficiency (i.e., increasing the total distance traveled). We find that by training agents using min-max fair distance goal assignments along with a reward term that incentivizes fairness as they move towards their goals, the agents (1) learn a fair assignment of goals and (2) achieve almost perfect goal coverage in navigation scenarios using only local observations. For goal coverage scenarios, we find that, on average, our model yields a 14% improvement in efficiency and a 5% improvement in fairness over a baseline trained using random assignments. Furthermore, an average of 21% improvement in fairness can be achieved compared to a model trained on optimally efficient assignments; this increase in fairness comes at the expense of only a 7% decrease in efficiency. Finally, we extend our method to environments in which agents must complete coverage tasks in prescribed formations and show that it is possible to do so without tailoring the models to specific formation shapes.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration</title>
<link>https://arxiv.org/abs/2410.15048</link>
<guid>https://arxiv.org/abs/2410.15048</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 分布式多智能体系统 (MAS), 变形代理 (MorphAgent), 自我演进的代理配置文件, 动态角色演化

总结:
本文介绍了MorphAgent，这是一种用于分布式多智能体协作的新颖框架，允许代理动态地进化其角色和能力。该框架利用自我演进的代理配置文件，通过三个关键指标进行优化，引导代理在保持互补团队动态的同时细化各自的专长。MorphAgent实现了一个两阶段过程：初始配置文件优化的预热阶段，以及根据任务反馈持续调整角色的任务执行阶段。实验结果显示，与传统的静态角色MAS相比，MorphAgent在任务性能和适应变化需求方面表现出优越性，为构建更强大和灵活的多智能体协作系统开辟了道路。相关代码将在 https://github.com/LINs-lab/learn2collaborate 公开可用。<br /><br /> <div>
arXiv:2410.15048v1 Announce Type: new 
Abstract: Large Language Model (LLM) based multi-agent systems (MAS) have shown promise in tackling complex tasks, but often rely on predefined roles and centralized coordination, limiting their adaptability to evolving challenges. This paper introduces MorphAgent, a novel framework for decentralized multi-agent collaboration that enables agents to dynamically evolve their roles and capabilities. Our approach employs self-evolving agent profiles, optimized through three key metrics, guiding agents in refining their individual expertise while maintaining complementary team dynamics. MorphAgent implements a two-phase process: a warm-up phase for initial profile optimization, followed by a task execution phase where agents continuously adapt their roles based on task feedback. Our experimental results show that MorphAgent outperforms traditional static-role MAS in terms of task performance and adaptability to changing requirements, paving the way for more robust and versatile multi-agent collaborative systems. Our code will be publicly available at \url{https://github.com/LINs-lab/learn2collaborate}.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer</title>
<link>https://arxiv.org/abs/2410.15073</link>
<guid>https://arxiv.org/abs/2410.15073</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Personalized FL（个性化联邦学习）、Non-IID数据、FedAFK、性能提升

<br /><br />总结:
本文提出了一种名为FedAFK的新方法，用于解决联邦学习中的统计异质性挑战，特别是针对非独立同分布(Non-IID)数据的个性化联邦学习（pFL）问题。FedAFK通过自适应特征聚合和知识转移机制，旨在更好地训练特征提取器，同时在保证全局模型知识利用的同时实现客户端的个性化。实验结果表明，在三个数据集和两种常用的异构设置下，FedAFK相比于十三种主流基线方法具有更优的性能表现。 <div>
arXiv:2410.15073v1 Announce Type: new 
Abstract: Federated Learning(FL) is popular as a privacy-preserving machine learning paradigm for generating a single model on decentralized data. However, statistical heterogeneity poses a significant challenge for FL. As a subfield of FL, personalized FL (pFL) has attracted attention for its ability to achieve personalized models that perform well on non-independent and identically distributed (Non-IID) data. However, existing pFL methods are limited in terms of leveraging the global model's knowledge to enhance generalization while achieving personalization on local data. To address this, we proposed a new method personalized Federated learning with Adaptive Feature Aggregation and Knowledge Transfer (FedAFK), to train better feature extractors while balancing generalization and personalization for participating clients, which improves the performance of personalized models on Non-IID data. We conduct extensive experiments on three datasets in two widely-used heterogeneous settings and show the superior performance of our proposed method over thirteen state-of-the-art baselines.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning</title>
<link>https://arxiv.org/abs/2410.15093</link>
<guid>https://arxiv.org/abs/2410.15093</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, contribution evaluation, Shapley value, Dynamic Pruning Validation Set Shapley (DPVS-Shapley), data privacy

总结:<br />
本文介绍了在人工智能时代下，为了解决集中式学习中的数据隐私问题而出现的联邦学习。该分散式学习模型提出了一个新的挑战，即如何公平准确地评估每个参与者的贡献。为此，提出了一种名为动态修剪验证集沙利值（DPVS-Shapley）的方法，用于加速贡献评估过程并保持准确性。DPVS-Shapley方法能够根据不同样本的重要性赋予不同权重，使那些能区分困难示例的客户端获得更高的贡献评分。此外，有效的贡献评估机制可以激励参与者积极贡献数据和计算资源，从而提升整个联邦学习系统的性能并确保公平对待每个参与者。 <div>
arXiv:2410.15093v1 Announce Type: new 
Abstract: In the current era of artificial intelligence, federated learning has emerged as a novel approach to addressing data privacy concerns inherent in centralized learning paradigms. This decentralized learning model not only mitigates the risk of data breaches but also enhances the system's scalability and robustness. However, this approach introduces a new challenge: how to fairly and accurately assess the contribution of each participant. Developing an effective contribution evaluation mechanism is crucial for federated learning. Such a mechanism incentivizes participants to actively contribute their data and computational resources, thereby improving the overall performance of the federated learning system. By allocating resources and rewards based on the size of the contributions, it ensures that each participant receives fair treatment, fostering sustained engagement.Currently, Shapley value-based methods are widely used to evaluate participants' contributions, with many researchers proposing modifications to adapt these methods to real-world scenarios. In this paper, we introduce a component called Dynamic Pruning Validation Set Shapley (DPVS-Shapley). This method accelerates the contribution assessment process by dynamically pruning the original dataset without compromising the evaluation's accuracy. Furthermore, this component can assign different weights to various samples, thereby allowing clients capable of distinguishing difficult examples to receive higher contribution scores.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Augmented Lagrangian-Based Safe Reinforcement Learning Approach for Distribution System Volt/VAR Control</title>
<link>https://arxiv.org/abs/2410.15188</link>
<guid>https://arxiv.org/abs/2410.15188</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据驱动、有功无功控制、约束马尔科夫决策过程、强化学习、分布式系统

总结:<br />
本文提出了一种数据驱动的解决主动配电系统中伏特-瓦特(Volt-VAR)控制问题的方法。针对配电系统模型往往不准确和不完整的问题，该文将Volt-VAR控制问题建模为约束马尔科夫决策过程(CMDP)。通过结合增广拉格朗日法与软策略迭代算法，文中创新性地提出了一种安全的离线强化学习方法来求解CMDP。该算法利用拉格朗日值函数对策略网络进行梯度更新，并采用双批评网络同步估计动作价值函数以避免过估计偏差。此方法无需被优化问题具有强凸性保证，并具备样本效率。采取两阶段策略分别进行离线训练和在线执行，因此不再需要精确的配电系统模型。为了实现可扩展性，文章采用了集中式训练分布式执行的多智能体框架，实现了大规模配电系统的去中心化Volt-VAR控制。通过使用真实电力数据的综合数值实验表明，所提出的算法能够达到较高的解决方案最优性和约束满足性。 <div>
arXiv:2410.15188v1 Announce Type: new 
Abstract: This paper proposes a data-driven solution for Volt-VAR control problem in active distribution system. As distribution system models are always inaccurate and incomplete, it is quite difficult to solve the problem. To handle with this dilemma, this paper formulates the Volt-VAR control problem as a constrained Markov decision process (CMDP). By synergistically combining the augmented Lagrangian method and soft actor critic algorithm, a novel safe off-policy reinforcement learning (RL) approach is proposed in this paper to solve the CMDP. The actor network is updated in a policy gradient manner with the Lagrangian value function. A double-critics network is adopted to synchronously estimate the action-value function to avoid overestimation bias. The proposed algorithm does not require strong convexity guarantee of examined problems and is sample efficient. A two-stage strategy is adopted for offline training and online execution, so the accurate distribution system model is no longer needed. To achieve scalability, a centralized training distributed execution strategy is adopted for a multi-agent framework, which enables a decentralized Volt-VAR control for large-scale distribution system. Comprehensive numerical experiments with real-world electricity data demonstrate that our proposed algorithm can achieve high solution optimality and constraints compliance.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Can Enhance Creativity in Social Networks</title>
<link>https://arxiv.org/abs/2410.15264</link>
<guid>https://arxiv.org/abs/2410.15264</guid>
<content:encoded><![CDATA[
<div> 关键词：peer推荐引擎、创意表现、自组织社交网络、数据收集、干预设计<br /><br />总结: 该研究探索了在自组织社交网络中，同伴推荐引擎是否能够提升人们的创新表现。为了解答这一问题，文章解决了数据收集（如追踪灵感链接和节点的心理社会属性）和干预设计（如平衡思想刺激与信息环境中冗余的进化）方面的挑战。研究者训练了一个模型，用于预测在线平台上个人的创新表现，并基于此构建了SocialMuse系统，该系统能最大化预测的个人表现以生成同行推荐。实验结果显示，采用SocialMuse的处理组网络在多项创造力指标上优于不依赖AI的对照组网络。此外，处理组网络在较大的网络规模下更为去中心化，SocialMuse在推荐过程中更加重视网络结构特征，这种去中心化有助于分散人们的灵感来源，使受启发的想法更易于突出。这项研究为构建提升创新力的智能系统提供了可操作的见解。 <div>
arXiv:2410.15264v1 Announce Type: new 
Abstract: Can peer recommendation engines elevate people's creative performances in self-organizing social networks? Answering this question requires resolving challenges in data collection (e.g., tracing inspiration links and psycho-social attributes of nodes) and intervention design (e.g., balancing idea stimulation and redundancy in evolving information environments). We trained a model that predicts people's ideation performances using semantic and network-structural features in an online platform. Using this model, we built SocialMuse, which maximizes people's predicted performances to generate peer recommendations for them. We found treatment networks leveraging SocialMuse outperforming AI-agnostic control networks in several creativity measures. The treatment networks were more decentralized than the control, as SocialMuse increasingly emphasized network-structural features at large network sizes. This decentralization spreads people's inspiration sources, helping inspired ideas stand out better. Our study provides actionable insights into building intelligent systems for elevating creativity.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract</title>
<link>https://arxiv.org/abs/2410.15275</link>
<guid>https://arxiv.org/abs/2410.15275</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3, 智能合约, 编译器, Move AI Decompiler (MAD), 审计

总结:
本文介绍了针对Sui区块链平台上的智能合约审计问题，研究者开发了一种名为Move AI Decompiler (MAD)的新工具。MAD是一个基于大型语言模型（LLM）的网络应用，能够将智能合约字节码反编译为逻辑正确、可读性强且可以直接重新编译的源代码。评估结果显示，MAD生成的代码逻辑正确并通过了原始单元测试，对真实世界的智能合约有66.7%的成功再编译率。在一项涉及12名开发人员的研究中，相比于传统反编译器，MAD显著降低了审计工作量，其输出的代码被参与者认为与原始源代码相当，简化了智能合约逻辑理解和审计的过程。尽管存在偶尔的幻象错误和编译错误等问题，但MAD仍然明显优于传统反编译器。MAD对于提高区块链智能合约的透明度、审计效率以及教育具有实际意义，并有望扩展到如Solidity等其他智能合约语言，从而推动不同区块链平台的透明度提升。 <div>
arXiv:2410.15275v1 Announce Type: new 
Abstract: Web3 aims to enhance user control over data and assets, but this vision is challenged by non-transparent, scam-prone applications and vulnerable smart contracts. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code.
  Our evaluation shows that MAD produces logically correct code that successfully passes original unit tests and achieves a 66.7% recompilation success rate on real-world smart contracts. Additionally, in a user study involving 12 developers, MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, simplifying the process of smart contract logic comprehension and auditing. Despite some limitations, such as occasional hallucinations and compile errors, MAD still provides significant improvements over traditional decompilers.
  MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to review and audit non-open-source smart contracts, fostering trust and accountability. Additionally, MAD's approach could potentially extend to other smart contract languages, like Solidity, promoting transparency across various blockchains.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Attention Is All You Need for LLM-based Code Vulnerability Localization</title>
<link>https://arxiv.org/abs/2410.15288</link>
<guid>https://arxiv.org/abs/2410.15288</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件系统、漏洞定位、大型语言模型、LOVA、自注意力机制

总结:
本文介绍了随着软件系统的快速发展和越来越多的安全漏洞报告，准确识别易受攻击的代码段变得愈发重要。传统的漏洞定位方法如手动代码审查或基于规则的工具效率低下，且范围有限。近年来，GPT和LLaMA等大型语言模型为自动化漏洞检测开辟了新途径，但它们在处理长代码上下文时保持准确性方面存在挑战。为此，文章提出了LOVA这一新颖框架，它利用大型语言模型内在的自注意力机制增强漏洞定位能力。LOVA的核心思想是通过分析模型对输入代码各部分的不同关注度来追踪并重点考察可能具有更高风险的代码行。实验结果显示，LOVA在F1分数上相对于现有LLM基线方法表现出显著优势，提高了高达5.3倍的性能；同时，它在C、Python、Java和Solidity等多种编程语言的智能合约漏洞定位中展现出出色的可扩展性，效能提升达到14.6倍，并证明了其在不同LLM架构下的稳健性能。 <div>
arXiv:2410.15288v1 Announce Type: new 
Abstract: The rapid expansion of software systems and the growing number of reported vulnerabilities have emphasized the importance of accurately identifying vulnerable code segments. Traditional methods for vulnerability localization, such as manual code audits or rule-based tools, are often time-consuming and limited in scope, typically focusing on specific programming languages or types of vulnerabilities. In recent years, the introduction of large language models (LLMs) such as GPT and LLaMA has opened new possibilities for automating vulnerability detection. However, while LLMs show promise in this area, they face challenges, particularly in maintaining accuracy over longer code contexts. This paper introduces LOVA, a novel framework leveraging the self-attention mechanisms inherent in LLMs to enhance vulnerability localization. Our key insight is that self-attention mechanisms assign varying importance to different parts of the input, making it possible to track how much attention the model focuses on specific lines of code. In the context of vulnerability localization, the hypothesis is that vulnerable lines of code will naturally attract higher attention weights because they have a greater influence on the model's output. By systematically tracking changes in attention weights and focusing on specific lines of code, LOVA improves the precision of identifying vulnerable lines across various programming languages. Through rigorous experimentation and evaluation, we demonstrate that LOVA significantly outperforms existing LLM-based approaches, achieving up to a 5.3x improvement in F1-scores. LOVA also demonstrated strong scalability, with up to a 14.6x improvement in smart contract vulnerability localization across languages like C, Python, Java, and Solidity. Its robustness was proven through consistent performance across different LLM architectures.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Primal-Dual Method for Constrained Multi-agent Reinforcement Learning with General Parameterization</title>
<link>https://arxiv.org/abs/2410.15335</link>
<guid>https://arxiv.org/abs/2410.15335</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式、约束多智能体强化学习(CMARL)、全局目标函数、局部估计、对偶变量

总结:
<br />
本文提出了一种新颖的分布式方法来解决合作型约束多智能体强化学习问题。该方法允许智能体在完全去中心化的在线学习环境中，独立维护局部的原变量和对偶变量估计值。具体而言，文章开发了一个基于actor-critic方法的分布式原-对偶算法，利用局部信息来估计拉格朗日乘子，并实现了这些乘子在各智能体间的共识。此外，文中证明了该算法能收敛到一个平衡点，并分析了这个平衡点相对于无参数化问题精确解的次优性。为了验证算法在复杂现实场景中的性能，文中引入了一个具有随机动态的受约束的合作Cournot博弈作为测试环境。 <div>
arXiv:2410.15335v1 Announce Type: new 
Abstract: This paper proposes a novel distributed approach for solving a cooperative Constrained Multi-agent Reinforcement Learning (CMARL) problem, where agents seek to minimize a global objective function subject to shared constraints. Unlike existing methods that rely on centralized training or coordination, our approach enables fully decentralized online learning, with each agent maintaining local estimates of both primal and dual variables. Specifically, we develop a distributed primal-dual algorithm based on actor-critic methods, leveraging local information to estimate Lagrangian multipliers. We establish consensus among the Lagrangian multipliers across agents and prove the convergence of our algorithm to an equilibrium point, analyzing the sub-optimality of this equilibrium compared to the exact solution of the unparameterized problem. Furthermore, we introduce a constrained cooperative Cournot game with stochastic dynamics as a test environment to evaluate the algorithm's performance in complex, real-world scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Semi-decentralized and Variational-Equilibrium-Based Trajectory Planner for Connected and Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2410.15394</link>
<guid>https://arxiv.org/abs/2410.15394</guid>
<content:encoded><![CDATA[
<div> 关键词：车辆通信技术(V2X)，自动驾驶车辆(CAVs)，轨迹规划，交互公平性，变分均衡(VE)，半分布式规划器，计算效率，安全性，规模化。

总结:
本文提出了一种利用车辆通信技术（V2X）解决自动驾驶车辆（CAVs）未经协调方法中的计算效率和安全问题的新颖轨迹规划方法。该研究将CAVs的轨迹规划问题建模为具有耦合安全约束的游戏，并定义了交互公平的轨迹，证明它们对应于该游戏的变分均衡（VE）。文章设计了一个半分布式规划器，使车辆能够寻求基于VE的公平轨迹，从而通过CAVs之间的并行计算显著提高计算效率，并通过确保CAVs之间的均衡一致性增强规划轨迹的安全性。实验结果证实了该方法的优势，包括快速计算速度、高可扩展性、均衡一致性以及安全性。 <div>
arXiv:2410.15394v1 Announce Type: new 
Abstract: This paper designs a novel trajectory planning approach to resolve the computational efficiency and safety problems in uncoordinated methods by exploiting vehicle-to-everything (V2X) technology. The trajectory planning for connected and autonomous vehicles (CAVs) is formulated as a game with coupled safety constraints. We then define interaction-fair trajectories and prove that they correspond to the variational equilibrium (VE) of this game. We propose a semi-decentralized planner for the vehicles to seek VE-based fair trajectories, which can significantly improve computational efficiency through parallel computing among CAVs and enhance the safety of planned trajectories by ensuring equilibrium concordance among CAVs. Finally, experimental results show the advantages of the approach, including fast computation speed, high scalability, equilibrium concordance, and safety.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Power Plays: Unleashing Machine Learning Magic in Smart Grids</title>
<link>https://arxiv.org/abs/2410.15423</link>
<guid>https://arxiv.org/abs/2410.15423</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、智能电网、效率、可持续性、数据隐私

总结:<br />
本文探讨了将机器学习融入智能电网系统对于提升现代能源网络效率、可靠性和可持续性的变革性影响。通过高级数据分析，这些系统能更好地管理可再生能源整合、需求响应和预测性维护等方面的复杂性。利用机器学习算法分析来自智能电表、传感器等设备的大数据，可以优化能源分配、预测需求并检测可能预示故障的异常情况，从而实现更精确的负荷平衡、降低运营成本并增强对电网扰动的韧性。此外，预测模型有助于预见设备故障，进而提高能源供应的可靠性。随着智能电网的发展，机器学习在管理分布式能源源和实现实时决策中的作用将愈发关键。然而，部署这些技术也带来了关于数据隐私、安全以及对强大基础设施需求的挑战。本文的研究重点在于利用机器学习技术充分发掘智能电网的潜力，确保它们在满足日益增长的能源需求的同时，兼顾可持续性和效率。同时，文中还对比分析了多种机器学习算法及其优缺点，并展望了这些算法的未来应用前景。 <div>
arXiv:2410.15423v1 Announce Type: new 
Abstract: The integration of machine learning into smart grid systems represents a transformative step in enhancing the efficiency, reliability, and sustainability of modern energy networks. By adding advanced data analytics, these systems can better manage the complexities of renewable energy integration, demand response, and predictive maintenance. Machine learning algorithms analyze vast amounts of data from smart meters, sensors, and other grid components to optimize energy distribution, forecast demand, and detect irregularities that could indicate potential failures. This enables more precise load balancing, reduces operational costs, and enhances the resilience of the grid against disturbances. Furthermore, the use of predictive models helps in anticipating equipment failures, thereby improving the reliability of the energy supply. As smart grids continue to evolve, the role of machine learning in managing decentralized energy sources and enabling real-time decision-making will become increasingly critical. However, the deployment of these technologies also raises challenges related to data privacy, security, and the need for robust infrastructure. Addressing these issues in this research authors will focus on realizing the full potential of smart grids, ensuring they meet the growing energy demands while maintaining a focus on sustainability and efficiency using Machine Learning techniques. Furthermore, this research will help determine the smart grid's essentiality with the aid of Machine Learning. Multiple ML algorithms have been integrated along with their pros and cons. The future scope of these algorithms are also integrated.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Hybrid Precoding for Massive MU-MIMO ISAC</title>
<link>https://arxiv.org/abs/2410.15659</link>
<guid>https://arxiv.org/abs/2410.15659</guid>
<content:encoded><![CDATA[
<div> 关键词：集成感知与通信(ISAC)，大规模多用户多输入多输出(Massive MU MIMO-ISAC)，多用户干扰(MUI)，分布式基带处理(DBP)预编码，部分连接结构(PCS)，瑟姆林森-原田预编码(THP)

<br /><br />总结:

本文提出了一个针对大规模多用户多输入多输出集成感知与通信系统(Massive MU MIMO-ISAC)中密集用户接入引起的严重多用户干扰问题的解决方案。该方案采用分布式基带处理(DBP)预编码方法，将最小化Cramer-Rao下界(CRB)作为目标函数来建模密集用户场景下的MUI问题。同时，结合部分连接结构(PCS)的混合预编码技术，有效降低了硬件成本和功耗。通过应用瑟姆林森-原田预编码(THP)进一步减轻用户间的MUI。仿真实验表明，相较于现有方法，所提方法能显著提升密集用户接入场景下的通信数据速率和能源效率，并降低Massive MU MIMO-ISAC系统的硬件复杂度，验证了其在解决ISAC系统中密集用户接入场景下的MUI问题上的有效性。 <div>
arXiv:2410.15659v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) is a very promising technology designed to provide both high rate communication capabilities and sensing capabilities. However, in Massive Multi User Multiple-Input Multiple-Output (Massive MU MIMO-ISAC) systems, the dense user access creates a serious multi-user interference (MUI) problem, leading to degradation of communication performance. To alleviate this problem, we propose a decentralized baseband processing (DBP) precoding method. We first model the MUI of dense user scenarios with minimizing Cramer-Rao bound (CRB) as an objective function.Hybrid precoding is an attractive ISAC technique, and hybrid precoding using Partially Connected Structures (PCS) can effectively reduce hardware cost and power consumption. We mitigate the MUI between dense users based on ThomlinsonHarashima Precoding (THP). We demonstrate the effectiveness of the proposed method through simulation experiments. Compared with the existing methods, it can effectively improve the communication data rates and energy efficiency in dense user access scenario, and reduce the hardware complexity of Massive MU MIMO-ISAC systems. The experimental results demonstrate the usefulness of our method for improving the MUI problem in ISAC systems for dense user access scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Geographical Node Clustering and Grouping to Guarantee Data IIDness in Federated Learning</title>
<link>https://arxiv.org/abs/2410.15693</link>
<guid>https://arxiv.org/abs/2410.15693</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习 (Federated Learning)，非IID数据集问题，物联网设备 (IoT)，地理特性，动态聚类算法<br /><br />总结: 这篇文章主要探讨了联邦学习中非IID数据集问题对模型性能的影响。研究发现物联网设备的数据独立性和相同性与其相互间的距离有关。为此，文章提出了一个新颖的方法，利用设备的地理位置信息进行动态聚类和部分稳定分组算法，旨在确保每个FL小组内部的数据达到近似的IID性。实验结果显示，该机制相比于基准分组算法，在联合成本（包括设备掉线数量与各组设备数均衡度）上至少提高了110倍，同时仅使组别数量最多增加了0.93组。 <div>
arXiv:2410.15693v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized AI mechanism suitable for a large number of devices like in smart IoT. A major challenge of FL is the non-IID dataset problem, originating from the heterogeneous data collected by FL participants, leading to performance deterioration of the trained global model. There have been various attempts to rectify non-IID dataset, mostly focusing on manipulating the collected data. This paper, however, proposes a novel approach to ensure data IIDness by properly clustering and grouping mobile IoT nodes exploiting their geographical characteristics, so that each FL group can achieve IID dataset. We first provide an experimental evidence for the independence and identicalness features of IoT data according to the inter-device distance, and then propose Dynamic Clustering and Partial-Steady Grouping algorithms that partition FL participants to achieve near-IIDness in their dataset while considering device mobility. Our mechanism significantly outperforms benchmark grouping algorithms at least by 110 times in terms of the joint cost between the number of dropout devices and the evenness in per-group device count, with a mild increase in the number of groups only by up to 0.93 groups.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient and Universally Accessible Cross-Chain Options without Upfront Holder Collateral</title>
<link>https://arxiv.org/abs/2410.15724</link>
<guid>https://arxiv.org/abs/2410.15724</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、期权交易、无需抵押品、双认证防止签名(DAPS)、跨链

总结:<br />
本文提出了一种新的区块链期权交易协议，旨在解决现有机制中资产支持有限、交易延迟高以及期权持有者需要提供前期抵押品等问题。该协议实现了无需期权持有者提供抵押品即可高效、广泛地进行期权交易，且其创新性地运用了双认证防止签名（DAPS）技术，显著降低了交易延迟。此外，通过引入期权发行方的保证，本协议消除了持有人的预付抵押需求。评估结果显示，所提方案将期权转移延迟降低到现有方法的一半以下。同时，严格的security分析证明，即使面对恶意行为，该协议也能实现安全的期权交易。此协议还支持任意两条不同区块链之间几乎任何资产的跨链期权交易，只要这两条链的编程语言能够执行和强制实施必要的合同逻辑。 <div>
arXiv:2410.15724v1 Announce Type: new 
Abstract: Options are fundamental to blockchain-based financial markets, offering essential tools for risk management and price speculation, which enhance liquidity, flexibility, and market efficiency in decentralized finance (DeFi). Despite the growing interest in options for blockchain-resident assets, such as cryptocurrencies, current option mechanisms face significant challenges, including limited asset support, high trading delays, and the requirement for option holders to provide upfront collateral.
  In this paper, we present a protocol that addresses the aforementioned issues by facilitating efficient and universally accessible option trading without requiring holders to post collateral when establishing options. Our protocol's universality allows for cross-chain options involving nearly $\textit{any}$ assets on $\textit{any}$ two different blockchains, provided the chains' programming languages can enforce and execute the necessary contract logic. A key innovation in our approach is the use of Double-Authentication-Preventing Signatures (DAPS), which significantly reduces trading latency. Additionally, by introducing a guarantee from the option writer, our protocol removes the need of upfront collateral from holders. Our evaluation demonstrates that the proposed scheme reduces option transfer latency to less than half of that in existing methods. Rigorous security analysis proves that our protocol achieves secure option trading, even when facing adversarial behaviors.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Efficient Collaboration via Graph Modeling in Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.15841</link>
<guid>https://arxiv.org/abs/2410.15841</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning, centralized training, decentralized execution, Factor-based Multi-Agent Transformer ($f$-MAT), transformer

总结:

本文研究了多智能体强化学习中的集中训练与分散执行框架，并针对执行阶段因局部观察限制而难以实现协调策略的问题进行了探讨。文章提出了一种新的编码器-解码器架构——基于因子的多智能体变换器（$f$-MAT），该架构利用变压器在训练和执行过程中实现相邻智能体间的通信。通过将智能体划分为不同的重叠组并用每个组的因子进行表示，$f$-MAT能够借助因子注意力层实现在智能体之间的高效信息传递。实验结果表明，相比于强大的基线算法，$f$-MAT在网络系统如交通调度和电力控制等场景中表现出了优越性能，为解决复杂协作问题开辟了新途径。 <div>
arXiv:2410.15841v1 Announce Type: new 
Abstract: In multi-agent reinforcement learning, a commonly considered paradigm is centralized training with decentralized execution. However, in this framework, decentralized execution restricts the development of coordinated policies due to the local observation limitation. In this paper, we consider the cooperation among neighboring agents during execution and formulate their interactions as a graph. Thus, we introduce a novel encoder-decoder architecture named Factor-based Multi-Agent Transformer ($f$-MAT) that utilizes a transformer to enable the communication between neighboring agents during both training and execution. By dividing agents into different overlapping groups and representing each group with a factor, $f$-MAT fulfills efficient message passing among agents through factor-based attention layers. Empirical results on networked systems such as traffic scheduling and power control demonstrate that $f$-MAT achieves superior performance compared to strong baselines, thereby paving the way for handling complex collaborative problems.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AdChain: Decentralized Header Bidding</title>
<link>https://arxiv.org/abs/2410.16141</link>
<guid>https://arxiv.org/abs/2410.16141</guid>
<content:encoded><![CDATA[
<div> 关键词: AdChain、去中心化、广告印象差异、共识协议、区块链

总结:
<br />
AdChain 是一种针对在线广告中因多方中介缺乏信任、法规不完善和供应链复杂导致的广告印象差异问题提出的解决方案。该文介绍了一个去中心化、分布式和可验证的 AdChain 系统，它利用多个独立代理接收并记录日志级数据，并采用共识协议来验证每个广告数据，从而建立信任。AdChain 具有可扩展性、效率高并且与现有基础设施兼容的特点。实验结果显示，在超过五十万条广告数据上运行，AdChain 可以达到 98% 的准确性，将广告差异率从 20% 降低到 2%。此外，分析还表明 AdChain 上活跃节点的利润可以与比特币等主要区块链网络上的矿工相当。 <div>
arXiv:2410.16141v1 Announce Type: new 
Abstract: Due to the involvement of multiple intermediaries without trusted parties, lack of proper regulations, and a complicated supply chain, ad impression discrepancy affects online advertising. This issue causes up to $82 billion annual revenue loss for honest parties. The loss can be significantly reduced with a precise and trusted decentralized mechanism. This paper presents AdChain, a decentralized, distributed, and verifiable solution that detects and minimizes online advertisement impression discrepancies. AdChain establishes trust by employing multiple independent agents to receive and record log-level data, along with a consensus protocol to validate each ad data. AdChain is scalable, efficient, and compatible with the current infrastructure. Our experimental evaluation, using over half a million ad data points, identifies system parameters that achieve 98% accuracy, reducing the ad discrepancy rate from 20% to 2%. Our cost analysis shows that active nodes on AdChain can generate profits comparable to miners on major blockchain networks like Bitcoin.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Model for Multi-Agent Autonomy That Uses Opinion Dynamics and Multi-Objective Behavior Optimization</title>
<link>https://arxiv.org/abs/2311.11144</link>
<guid>https://arxiv.org/abs/2311.11144</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主多机器人系统(MRSs), 非线性动力学意见过程, 多目标行为优化, 分布式控制, 通信成本

总结:
本文提出了一种用于建模自主多机器人系统（MRSs）的新颖分层架构。该架构使用非线性动态意见过程来模拟高层级群体选择，并利用多目标行为优化方法来模拟个体决策。通过先前的理论结果，论文表明仅通过选取相对较小的一组参数即可设计MRS的行为，并且这种行为——包括集体行动和个体行动——可以直观地理解。该方法完全分布式实现，通信成本随群组选项的数量而非代理数量而增加。通过在一个假设的“探索-开发-迁移”场景中进行两小时的实地演示，利用八艘无人驾驶水面舰艇（USVs），实验结果显示即使在网络拓扑和代理退出等时间变化情况下，集体行为依然保持稳健。 <div>
arXiv:2311.11144v3 Announce Type: replace 
Abstract: This paper reports a new hierarchical architecture for modeling autonomous multi-robot systems (MRSs): a nonlinear dynamical opinion process is used to model high-level group choice, and multi-objective behavior optimization is used to model individual decisions. Using previously reported theoretical results, we show it is possible to design the behavior of the MRS by the selection of a relatively small set of parameters. The resulting behavior - both collective actions and individual actions - can be understood intuitively. The approach is entirely decentralized and the communication cost scales by the number of group options, not agents. We demonstrated the effectiveness of this approach using a hypothetical `explore-exploit-migrate' scenario in a two hour field demonstration with eight unmanned surface vessels (USVs). The results from our preliminary field experiment show the collective behavior is robust even with time-varying network topology and agent dropouts.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Connected and Automated Vehicles Control: Recent Advancements and Future Prospects</title>
<link>https://arxiv.org/abs/2312.11084</link>
<guid>https://arxiv.org/abs/2312.11084</guid>
<content:encoded><![CDATA[
<div> 关键词：Connected and Automated Vehicles (CAVs)，Multi-Agent Reinforcement Learning (MARL)，Control Dimensions，Simulation Platforms，Challenges and Solutions

<br /><br />总结：
本文针对互联与自动驾驶车辆（CAVs）领域的复杂协调控制问题，重点介绍了多智能体强化学习（MARL）的应用。文章首先阐述了MARL在处理复杂多智能体场景中的独特优势；接着，详细梳理了MARL在CAV控制的不同维度上的应用，如车队控制、变道和无信号交叉口管理等关键场景；同时，也回顾了用于开发和测试MARL算法的重要仿真平台。此外，文章还探讨了将MARL应用于CAV控制面临的挑战，包括宏观微观优化、通信、混合交通以及模拟到现实的转化等问题，并提出了可能的解决方案，如层次化MARL、去中心化MARL、自适应交互以及离线MARL等。 <div>
arXiv:2312.11084v3 Announce Type: replace 
Abstract: Connected and automated vehicles (CAVs) are considered a potential solution for future transportation challenges, aiming to develop systems that are efficient, safe, and environmentally friendly. However, CAV control presents significant challenges due to the complexity of interconnectivity and coordination required among vehicles. Multi-agent reinforcement learning (MARL), which has shown notable advancements in addressing complex problems in autonomous driving, robotics, and human-vehicle interaction, emerges as a promising tool to enhance CAV capabilities. Despite its potential, there is a notable absence of current reviews on mainstream MARL algorithms for CAVs. To fill this gap, this paper offers a comprehensive review of MARL's application in CAV control. The paper begins with an introduction to MARL, explaining its unique advantages in handling complex and multi-agent scenarios. It then presents a detailed survey of MARL applications across various control dimensions for CAVs, including critical scenarios such as platooning control, lane-changing, and unsignalized intersections. Additionally, the paper reviews prominent simulation platforms essential for developing and testing MARL algorithms. Lastly, it examines the current challenges in deploying MARL for CAV control, including macro-micro optimization, communication, mixed traffic, and sim-to-real challenges. Potential solutions discussed include hierarchical MARL, decentralized MARL, adaptive interactions, and offline MARL.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigating Side Effects in Multi-Agent Systems Using Blame Assignment</title>
<link>https://arxiv.org/abs/2405.04702</link>
<guid>https://arxiv.org/abs/2405.04702</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、协同优化、负外部性、分散式Markov决策过程、信用分配

<br />
总结:
本文针对在共享环境中独立训练或设计的机器人可能产生的意外负面效应问题，提出了将该问题建模为双目标优先级分散式Markov决策过程的方法。研究假设机器人任务间的转换和奖励相互独立，但联合的负面效应惩罚则在这种情况下形成了依赖关系。为提高可扩展性，文章利用信用分配方法将联合负面效应惩罚分解为每个机器人的个体惩罚，从而便于进行分散式的策略计算。通过移动机器人以及模拟实验，作者实证展示了所提出方法在减轻负面效应方面的有效性和可扩展性。 <div>
arXiv:2405.04702v2 Announce Type: replace 
Abstract: When independently trained or designed robots are deployed in a shared environment, their combined actions can lead to unintended negative side effects (NSEs). To ensure safe and efficient operation, robots must optimize task performance while minimizing the penalties associated with NSEs, balancing individual objectives with collective impact. We model the problem of mitigating NSEs in a cooperative multi-agent system as a bi-objective lexicographic decentralized Markov decision process. We assume independence of transitions and rewards with respect to the robots' tasks, but the joint NSE penalty creates a form of dependence in this setting. To improve scalability, the joint NSE penalty is decomposed into individual penalties for each robot using credit assignment, which facilitates decentralized policy computation. We empirically demonstrate, using mobile robots and in simulation, the effectiveness and scalability of our approach in mitigating NSEs.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-Critical Formation Control of Non-Holonomic Multi-Robot Systems in Communication-Limited Environments</title>
<link>https://arxiv.org/abs/2406.13707</link>
<guid>https://arxiv.org/abs/2406.13707</guid>
<content:encoded><![CDATA[
<div> 关键词: 非holonomic移动机器人, 形状控制, 通信限制环境, 控制 Barrier 函数, 状态估计算法

总结:
本文提出了一种针对非holonomic移动机器人在通信受限环境中的安全关键控制器，用于编队形状控制。该新颖的分布式框架将鲁棒状态估计算法与编队跟踪控制律相结合，解决了使用控制Barrier函数实现的相互避碰和扰动衰减问题。该估计器设计考虑了常量和时变速度剖面，增强了系统对动态场景的适应性。通过采用闭合形式解的跟踪控制器，实现了有效实施并保持编队完整性。通过引入串行稳定性指标，进一步强化了框架抵抗由前车传播的扰动的能力。利用Lyapunov函数进行严格稳定性分析，确保了估计误差的稳定性和编队向期望配置的收敛性。数值模拟和基于Gazebo的真实实验验证了所提方法在各种操作和仓库环境中保持安全性、实现精确编队控制以及缓解无通信条件下的干扰抑制的有效性和鲁棒性。 <div>
arXiv:2406.13707v2 Announce Type: replace 
Abstract: This paper presents a novel estimator-based safety-critical controller for formation control of non-holonomic mobile robots in communication-limited environments. The proposed decentralized framework integrates a robust state estimator with a formation tracking control law, addressing the challenges of inter-agent collision avoidance and disturbance attenuation in leader-follower formations using control barrier functions. The estimator's design accounts for both constant and time-varying velocity profiles, enhancing the system's adaptability to dynamic scenarios. A closed-form solution for the tracking controller facilitates efficient implementation while maintaining formation integrity. The incorporation of string stability metrics further reinforces the framework's resilience against propagating disturbances from predecessors. Rigorous stability analysis using Lyapunov functions ensures the stability of estimation errors and the convergence of the formation to desired configurations. The effectiveness and robustness of the proposed approach are validated through numerical simulations of various maneuvers and realistic Gazebo experiments involving formations in a warehouse environment. The results demonstrate the controller's ability to maintain safety, achieve precise formation control, and mitigate disturbances in scenarios without inter-robot communication.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Fine-Tuned Language Models for Efficient and Accurate Smart Contract Auditing</title>
<link>https://arxiv.org/abs/2410.13918</link>
<guid>https://arxiv.org/abs/2410.13918</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、大型语言模型、FTSmartAudit框架、安全性审计

<br /><br />总结:
随着区块链技术的发展和智能合约的应用普及，其安全问题日益凸显。本文针对智能合约的安全审计挑战，提出了一种新的解决方案——FTSmartAudit框架。该框架利用大型语言模型（LLMs）进行自动化安全漏洞检测，并探讨了通过微调较小规模的模型来达到与大型模型相当甚至更优的效果的可能性。研究内容包括：(1) 设计了一个单一任务学习框架，用于简化数据准备、训练、评估及持续学习流程；(2) 提出一种基于领域专业知识蒸馏的方法生成高质量训练数据集，这些数据源自如GPT-4等先进模型；(3) 开发了一种自适应学习策略，以保持模型的准确性和鲁棒性；(4) 证明了经过微调的小型模型在识别特定安全漏洞和复杂逻辑错误方面的有效性；(5) 强调了该框架可以扩展到其他需要LLM解决方案的领域。实验结果显示，经过微调的小型模型在检测智能合约中的漏洞方面能够超越现有商业模型和工具。 <div>
arXiv:2410.13918v1 Announce Type: new 
Abstract: The rise of blockchain technologies has greatly accelerated the development and deployment of smart contracts. However, their inherent vulnerabilities and susceptibility to bugs have led to significant financial losses, underscoring the challenges in securing smart contracts. While traditional auditing methods are crucial, they often fall short in addressing the increasing complexity and volume of smart contracts. Recent advancements in Large Language Models (LLMs) offer promising solutions for enhancing software auditing by automatically identifying security vulnerabilities. Despite their potential, the practical application of these models is hindered by substantial computational demands. This paper investigates the feasibility of using smaller, fine-tuned models to achieve comparable or even superior results in smart contract auditing. We introduce the FTSmartAudit framework, which is designed to develop cost-effective, specialized models for smart contract auditing through the fine-tuning of LLMs. Our contributions include: (1) a single-task learning framework that streamlines data preparation, training, evaluation, and continuous learning; (2) a robust dataset generation method utilizing domain-special knowledge distillation to produce high-quality datasets from advanced models like GPT-4o; (3) an adaptive learning strategy to maintain model accuracy and robustness; (4) the proven effectiveness of fine-tuned models in detecting specific vulnerabilities and complex logical errors; and (5) a framework that can be extended to other domains requiring LLM solutions. Our experimental results demonstrate that smaller models can surpass state-of-the-art commercial models and tools in detecting vulnerabilities in smart contracts.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Diffusion Models for Multi-Agent Partial Observability: Shared Attractors, Error Bounds, and Composite Flow</title>
<link>https://arxiv.org/abs/2410.13953</link>
<guid>https://arxiv.org/abs/2410.13953</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、部分可观测性、分布式部分可观测马尔科夫决策过程、扩散模型、深度学习

总结:
本文探讨了多智能体系统中处理部分可观测性的挑战，重点关注分布式部分可观测马尔科夫决策过程（Dec-POMDP）中的全局状态重构问题。研究发现，基于局部行动-观测历史的扩散模型能够将可能的状态表示为稳定固定点。在集体可观察的Dec-POMDP中，各智能体的条件扩散模型共享一个与全局状态相对应的独特固定点；而在非集体可观察场景下，则会产生一个由联合历史给出的可能状态分布。当涉及到深度学习近似误差时，固定点可能偏离真实状态，且这种偏差与雅可比矩阵秩负相关。为此，文章提出了一种利用低秩特性构建的代理线性回归模型来约束该偏差，并设计了一个迭代各智能体的复合扩散过程，理论上保证其收敛到真实状态。 <div>
arXiv:2410.13953v1 Announce Type: new 
Abstract: Multiagent systems grapple with partial observability (PO), and the decentralized POMDP (Dec-POMDP) model highlights the fundamental nature of this challenge. Whereas recent approaches to address PO have appealed to deep learning models, providing a rigorous understanding of how these models and their approximation errors affect agents' handling of PO and their interactions remain a challenge. In addressing this challenge, we investigate reconstructing global states from local action-observation histories in Dec-POMDPs using diffusion models. We first find that diffusion models conditioned on local history represent possible states as stable fixed points. In collectively observable (CO) Dec-POMDPs, individual diffusion models conditioned on agents' local histories share a unique fixed point corresponding to the global state, while in non-CO settings, the shared fixed points yield a distribution of possible states given joint history. We further find that, with deep learning approximation errors, fixed points can deviate from true states and the deviation is negatively correlated to the Jacobian rank. Inspired by this low-rank property, we bound the deviation by constructing a surrogate linear regression model that approximates the local behavior of diffusion models. With this bound, we propose a composite diffusion process iterating over agents with theoretical convergence guarantees to the true state.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Conformal Prediction for Federated Graph Neural Networks with Missing Neighbor Information</title>
<link>https://arxiv.org/abs/2410.14010</link>
<guid>https://arxiv.org/abs/2410.14010</guid>
<content:encoded><![CDATA[
<div> 关键词：Graphs, Federated Learning, Missing Links, Conformal Prediction, Variational Autoencoder

总结:<br />
本文研究了图数据在数据挖掘和机器学习中的重要性，特别是在大规模、分布式子图管理的联邦学习框架下。针对联邦学习中缺失邻居信息导致模型可靠性下降的问题，文章提出了将确立的不确定性量化方法——Conformal Prediction（CP）扩展应用于联邦图学习。为了减小缺失链接对CP集合大小的影响，作者探讨了分布式子图间的数据依赖关系并建立了保持CP有效性和精确测试时间覆盖的条件。文中还介绍了一种基于变分自编码器的方法，用于重建缺失的邻居以缓解缺失数据的负面影响。实验证明，该方法在确保覆盖率保证的同时，能有效地减小预测集的大小。 <div>
arXiv:2410.14010v1 Announce Type: new 
Abstract: Graphs play a crucial role in data mining and machine learning, representing real-world objects and interactions. As graph datasets grow, managing large, decentralized subgraphs becomes essential, particularly within federated learning frameworks. These frameworks face significant challenges, including missing neighbor information, which can compromise model reliability in safety-critical settings. Deployment of federated learning models trained in such settings necessitates quantifying the uncertainty of the models. This study extends the applicability of Conformal Prediction (CP), a well-established method for uncertainty quantification, to federated graph learning. We specifically tackle the missing links issue in distributed subgraphs to minimize its adverse effects on CP set sizes. We discuss data dependencies across the distributed subgraphs and establish conditions for CP validity and precise test-time coverage. We introduce a Variational Autoencoder-based approach for reconstructing missing neighbors to mitigate the negative impact of missing data. Empirical evaluations on real-world datasets demonstrate the efficacy of our approach, yielding smaller prediction sets while ensuring coverage guarantees.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedPAE: Peer-Adaptive Ensemble Learning for Asynchronous and Model-Heterogeneous Federated Learning</title>
<link>https://arxiv.org/abs/2410.14075</link>
<guid>https://arxiv.org/abs/2410.14075</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、个性化联邦学习、模型异质性、去中心化、Federated Peer-Adaptive Ensemble Learning (FedPAE)

总结:<br />
本文提出了一种名为Federated Peer-Adaptive Ensemble Learning (FedPAE)的新颖去中心化个性化联邦学习算法。该算法旨在解决现有联邦学习中的数据分布和系统能力异质性问题以及对中央实体的依赖。FedPAE支持模型异质性并采用异步学习方式，通过点对点模型分享机制和集成选择策略，更好地平衡了局部与全局信息的利用。实验结果显示，FedPAE相比现有的个性化联邦学习算法表现出更优的性能，有效应对了不同客户端的能力差异，并展现出对抗统计异质性的鲁棒性。 <div>
arXiv:2410.14075v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple clients with distributed data sources to collaboratively train a shared model without compromising data privacy. However, existing FL paradigms face challenges due to heterogeneity in client data distributions and system capabilities. Personalized federated learning (pFL) has been proposed to mitigate these problems, but often requires a shared model architecture and a central entity for parameter aggregation, resulting in scalability and communication issues. More recently, model-heterogeneous FL has gained attention due to its ability to support diverse client models, but existing methods are limited by their dependence on a centralized framework, synchronized training, and publicly available datasets. To address these limitations, we introduce Federated Peer-Adaptive Ensemble Learning (FedPAE), a fully decentralized pFL algorithm that supports model heterogeneity and asynchronous learning. Our approach utilizes a peer-to-peer model sharing mechanism and ensemble selection to achieve a more refined balance between local and global information. Experimental results show that FedPAE outperforms existing state-of-the-art pFL algorithms, effectively managing diverse client capabilities and demonstrating robustness against statistical heterogeneity.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Communication and Computation Efficient Fully First-order Method for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2410.14115</link>
<guid>https://arxiv.org/abs/2410.14115</guid>
<content:encoded><![CDATA[
<div> 关键词：bilevel优化，分布式联邦学习（DFL），第二秩序导数，通信效率，$\text{C}^2$DFB

总结:<br />
本文针对分布式联邦学习中的双层优化问题，提出了一种新的、计算和通信效率均高的完全一阶分布式双层优化算法——$\text{C}^2$DFB。该方法创新地仅依赖梯度信息来逼近上层模型的超梯度，避免了获取和共享二阶导数带来的计算和通信开销。为减轻解决下层问题时的内部循环通信负担，$\text{C}^2$DFB引入了一个轻量级通信协议，用于高效传输本地参数压缩残差。文章提供了严格的理论分析证明其收敛性，并通过在超参数调优和超表示任务上的实验验证了$\text{C}^2$DFB在各种网络拓扑和异构数据分布下的优越性能。 <div>
arXiv:2410.14115v1 Announce Type: new 
Abstract: Bilevel optimization, crucial for hyperparameter tuning, meta-learning and reinforcement learning, remains less explored in the decentralized learning paradigm, such as decentralized federated learning (DFL). Typically, decentralized bilevel methods rely on both gradients and Hessian matrices to approximate hypergradients of upper-level models. However, acquiring and sharing the second-order oracle is compute and communication intensive. % and sharing this information incurs heavy communication overhead. To overcome these challenges, this paper introduces a fully first-order decentralized method for decentralized Bilevel optimization, $\text{C}^2$DFB which is both compute- and communicate-efficient. In $\text{C}^2$DFB, each learning node optimizes a min-min-max problem to approximate hypergradient by exclusively using gradients information. To reduce the traffic load at the inner-loop of solving the lower-level problem, $\text{C}^2$DFB incorporates a lightweight communication protocol for efficiently transmitting compressed residuals of local parameters. % during the inner loops. Rigorous theoretical analysis ensures its convergence % of the algorithm, indicating a first-order oracle calls of $\tilde{\mathcal{O}}(\epsilon^{-4})$. Experiments on hyperparameter tuning and hyper-representation tasks validate the superiority of $\text{C}^2$DFB across various typologies and heterogeneous data distributions.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMSE: Federated learning for IoT network intrusion detection</title>
<link>https://arxiv.org/abs/2410.14121</link>
<guid>https://arxiv.org/abs/2410.14121</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网(IoT)，联邦学习(federated learning)，半监督学习(semi-supervised learning)，自编码器(Shrink Autoencoder)，中心点分类器(Centroid classifier)，均方误差(Mean Square Error)，入侵检测(intrusion detection)

<br /><br />总结:

本文提出了一种新颖的用于提升物联网网络入侵检测性能的联邦学习方法。针对传统集中式机器学习方法在处理 IoT 网络数据可用性、计算资源、传输成本以及特别是隐私保护方面存在的不足，研究者开发了一个结合了收缩自编码器和中心点一类分类器(SAE-CEN)的半监督联邦学习模型。该模型能有效地表征正常网络数据并准确识别分布式环境中的异常行为。同时，文中还引入了一个基于均方误差的聚合算法(MSEAvg)，通过优先考虑更精确的局部模型来提高全局模型的性能。实验结果表明，在使用N-BaIoT数据集和Dirichlet分布的不同设置下，这种方法在实际异构物联网网络中显著提高了检测精度（从93.98$\pm$2.90提升到97.30$\pm$0.49），并且在仅需要50%网关参与训练的情况下降低了学习成本，同时在大规模网络中表现出良好的鲁棒性。 <div>
arXiv:2410.14121v1 Announce Type: new 
Abstract: This paper proposes a novel federated learning approach for improving IoT network intrusion detection. The rise of IoT has expanded the cyber attack surface, making traditional centralized machine learning methods insufficient due to concerns about data availability, computational resources, transfer costs, and especially privacy preservation. A semi-supervised federated learning model was developed to overcome these issues, combining the Shrink Autoencoder and Centroid one-class classifier (SAE-CEN). This approach enhances the performance of intrusion detection by effectively representing normal network data and accurately identifying anomalies in the decentralized strategy. Additionally, a mean square error-based aggregation algorithm (MSEAvg) was introduced to improve global model performance by prioritizing more accurate local models. The results obtained in our experimental setup, which uses various settings relying on the N-BaIoT dataset and Dirichlet distribution, demonstrate significant improvements in real-world heterogeneous IoT networks in detection accuracy from 93.98$\pm$2.90 to 97.30$\pm$0.49, reduced learning costs when requiring only 50\% of gateways participating in the training process, and robustness in large-scale networks.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Cryptocurrency Market Forecasting: Advanced Machine Learning Techniques and Industrial Engineering Contributions</title>
<link>https://arxiv.org/abs/2410.14475</link>
<guid>https://arxiv.org/abs/2410.14475</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、机器学习、价格预测、工业工程师、市场情绪分析

<br /><br />总结:

本文回顾了从2014年至2024年间应用于加密货币价格预测的机器学习技术，重点关注线性模型、树基方法及深度学习架构（如变压器和大型语言模型）。文章强调了市场情绪分析在利用社交媒体和新闻文本数据预测价格波动中的作用。同时指出，工业工程师凭借其在系统优化、效率提升和风险减缓方面的专业知识，对改进这些预测模型起到关键作用。随着新兴技术的整合与预测模型的发展，该章节旨在解决现有局限并探索未来研究方向，以期构建更精确、稳健的预测系统，进而支持更为明智的投资决策和稳定市场行为。 <div>
arXiv:2410.14475v1 Announce Type: new 
Abstract: Cryptocurrencies, as decentralized digital assets, have experienced rapid growth and adoption, with over 23,000 cryptocurrencies and a market capitalization nearing \$1.1 trillion (about \$3,400 per person in the US) as of 2023. This dynamic market presents significant opportunities and risks, highlighting the need for accurate price prediction models to manage volatility. This chapter comprehensively reviews machine learning (ML) techniques applied to cryptocurrency price prediction from 2014 to 2024. We explore various ML algorithms, including linear models, tree-based approaches, and advanced deep learning architectures such as transformers and large language models. Additionally, we examine the role of sentiment analysis in capturing market sentiment from textual data like social media posts and news articles to anticipate price fluctuations. With expertise in optimizing complex systems and processes, industrial engineers are pivotal in enhancing these models. They contribute by applying principles of process optimization, efficiency, and risk mitigation to improve computational performance and data management. This chapter highlights the evolving landscape of cryptocurrency price prediction, the integration of emerging technologies, and the significant role of industrial engineers in refining predictive models. By addressing current limitations and exploring future research directions, this chapter aims to advance the development of more accurate and robust prediction systems, supporting better-informed investment decisions and more stable market behavior.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safeguarding Blockchain Ecosystem: Understanding and Detecting Attack Transactions on Cross-chain Bridges</title>
<link>https://arxiv.org/abs/2410.14493</link>
<guid>https://arxiv.org/abs/2410.14493</guid>
<content:encoded><![CDATA[
<div> 关键词: cross-chain bridges、attacks、security、BridgeGuard、graph mining

总结:
本文关注了跨链桥这一促进不同区块链网络间互操作性的关键去中心化应用，由于其涉及线上线下信息协作，面临着更广泛的安全攻击风险。据统计，自2021年以来，针对跨链桥的攻击已导致近43亿美元的损失。因此，理解和检测这类攻击至关重要。文章收集了迄今为止最大的跨链桥攻击事件数据集，共涵盖2021年6月至2024年9月间的49起攻击事件。分析发现，针对跨链业务逻辑的攻击造成的损害远大于非跨链攻击。为了应对此类严重损失及相关研究的稀缺性，本文提出了一种名为BridgeGuard的新工具，用于检测针对跨链业务逻辑的攻击。具体来说，BridgeGuard从图视角建模跨链交易，并采用两阶段检测框架，包括全局和局部图挖掘来识别跨链交易中的攻击模式。实验证明，在包含203笔攻击交易和4万笔正常跨链交易的数据集上，BridgeGuard报告的召回率比现有最先进的工具高出36.32%，并且能够检测未知攻击交易。 <div>
arXiv:2410.14493v1 Announce Type: new 
Abstract: Cross-chain bridges are essential decentralized applications (DApps) to facilitate interoperability between different blockchain networks. Unlike regular DApps, the functionality of cross-chain bridges relies on the collaboration of information both on and off the chain, which exposes them to a wider risk of attacks. According to our statistics, attacks on cross-chain bridges have resulted in losses of nearly 4.3 billion dollars since 2021. Therefore, it is particularly necessary to understand and detect attacks on cross-chain bridges. In this paper, we collect the largest number of cross-chain bridge attack incidents to date, including 49 attacks that occurred between June 2021 and September 2024. Our analysis reveal that attacks against cross-chain business logic cause significantly more damage than those that do not. These cross-chain attacks exhibit different patterns compared to normal transactions in terms of call structure, which effectively indicates potential attack behaviors. Given the significant losses in these cases and the scarcity of related research, this paper aims to detect attacks against cross-chain business logic, and propose the BridgeGuard tool. Specifically, BridgeGuard models cross-chain transactions from a graph perspective, and employs a two-stage detection framework comprising global and local graph mining to identify attack patterns in cross-chain transactions. We conduct multiple experiments on the datasets with 203 attack transactions and 40,000 normal cross-chain transactions. The results show that BridgeGuard's reported recall score is 36.32\% higher than that of state-of-the-art tools and can detect unknown attack transactions.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Based Trust and Transparency in Airline Reservation Systems using Microservices Architecture</title>
<link>https://arxiv.org/abs/2410.14518</link>
<guid>https://arxiv.org/abs/2410.14518</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、航空公司预订系统、信任、透明度、效率提升

<br /><br />总结:
该研究详细分析了区块链技术应用于航空公司的预订系统中，旨在增强客户信任、提高透明度和运营效率。通过利用区块链的去中心化数据库、永久交易记录以及通过代码执行的交易条款等功能，成功减少了预订差异达30%，并实现了数据同步性的提升。实施区块链技术包括采用多个API自动化的多方面记录保存系统及智能合约执行，使得流程周期时间平均减少40%，同时确保协议不会被违反。系统的架构无单点故障，可靠性超过98%，加强的安全措施使85%的客户对服务表示信任。然而，尽管区块链有望重塑航空行业的预订业务，但仍面临可扩展性和法规遵从性等挑战。此研究为进一步针对这些问题进行更深入、更适用航空行业的研究奠定了基础。 <div>
arXiv:2410.14518v1 Announce Type: new 
Abstract: This research gives a detailed analysis of the application of blockchain technology to the airline reservation systems in order to bolster trust, transparency, and operational efficiency by overcoming several challenges including customer control and data integrity issues. The study investigates the major components of blockchain technology such as decentralised databases, permanent records of transactions and transactional clauses executed via codes of programs and their impacts on automated systems and real-time tracking of audits. The results show a 30% decrease in booking variations together with greater data synchronization as a result of consensus processes and resistant data formations. The approach to the implementation of a blockchain technology for the purpose of this paper includes many APIs for the automatic multi-faceted record-keeping system including the smart contract execution and controllable end-users approach. Smart contracts organized the processes improving the cycle times by 40% on the average while guaranteeing no breach of agreements. In addition to this, the architecture of the system has no single point failure with over 98% reliability while measures taken to improve security have led to 85% of the customers expressing trust in the services provided. In summation, the results suggest that reservations in the airline sector stand a chance of being redefined with blockchain through savoring the benefits of a single source of truth while attempting to resolve this intrinsic problem of overcomplexity. Although the system improves the experience of customers and the level of operational transparency, issues concerning scalability and regulatory adherence. This research is also a stepping stone for further studies that are intended to address these challenges and more applicable to the airline industry.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Using Sentiment and Technical Analysis to Predict Bitcoin with Machine Learning</title>
<link>https://arxiv.org/abs/2410.14532</link>
<guid>https://arxiv.org/abs/2410.14532</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、价格预测、市场情绪、技术分析指标、机器学习

总结:
本文研究了一种新的比特币价格预测方法，该方法结合了市场情绪指标“恐惧与贪婪指数”、技术分析指标以及机器学习算法。相较于现有文献，本工作着重关注将市场情绪指标应用于加密货币预测中的重要性。初步实验显示，该模型在投资回报上超越了买入并持有的基准策略，证明了情绪和市场指标相结合在数字货币预测模型中的有效性。 <div>
arXiv:2410.14532v1 Announce Type: new 
Abstract: Cryptocurrencies have gained significant attention in recent years due to their decentralized nature and potential for financial innovation. Thus, the ability to accurately predict its price has become a subject of great interest for investors, traders, and researchers. Some works in the literature show how Bitcoin's market sentiment correlates with its price fluctuations in the market. However, papers that consider the sentiment of the market associated with financial Technical Analysis indicators in order to predict Bitcoin's price are still scarce. In this paper, we present a novel approach for predicting Bitcoin price movements by combining the Fear & Greedy Index, a measure of market sentiment, Technical Analysis indicators, and the potential of Machine Learning algorithms. This work represents a preliminary study on the importance of sentiment metrics in cryptocurrency forecasting. Our initial experiments demonstrate promising results considering investment returns, surpassing the Buy & Hold baseline, and offering valuable insights about the combination of indicators of sentiment and market in a cryptocurrency prediction model.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>$\pi$QLB: A Privacy-preserving with Integrity-assuring Query Language for Blockchain</title>
<link>https://arxiv.org/abs/2212.14141</link>
<guid>https://arxiv.org/abs/2212.14141</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据查询机制、安全性、隐私保护、$\pi$QLB<br /><br />总结:<br />
本文提出了一个名为$\pi$QLB的新颖区块链查询语言，旨在确保区块链系统中查询输入的机密性和查询结果的完整性。随着区块链技术在不同领域的广泛应用，如医疗系统和供应链管理，对支持安全及隐私保障的数据查询机制的需求日益增长。现有的区块链系统无法满足这一需求，用户需以明文形式提交查询给运营商，这可能导致用户隐私泄露。同时，用户若要验证查询结果的完整性，则需要存储整个区块链数据库并进行本地查询，这种方法成本高昂，不适用于轻量级设备（如智能手机）。为解决这些问题，$\pi$QLB引入了关系数据语义，使区块链数据库能够支持类似于SQL的查询，并利用最新的加密原语——函数秘密分享（FSS）来实现查询输入的机密性。此外，为了保证完整性，$\pi$QLB扩展了传统FSS设置，使得能高效验证FSS结果的正确性，从而让用户能信任没有恶意行为的服务器产生的结果。据作者所知，$\pi$QLB是首个支持机密性、完整性和类似SQL查询功能的区块链数据库查询模型。 <div>
arXiv:2212.14141v2 Announce Type: replace 
Abstract: The increase in the adoption of blockchain technology in different application domains e.g., healthcare systems, supplychain management, has raised the demand for a data query mechanism on blockchain. Since current blockchain systems lack the support for querying data with embedded security and privacy guarantees, there exists inherent security and privacy concerns on those systems. In particular, existing systems require users to submit queries to blockchain operators (e.g., a node validator) in plaintext. This directly jeopardizes users' privacy as the submitted queries may contain sensitive information, e.g., location or gender preferences, that the users may not be comfortable sharing. On the other hand, currently, the only way for users to ensure integrity of the query result is to maintain the entire blockchain database and perform the queries locally. Doing so incurs high storage and computational costs on the users, precluding this approach to be practically deployable on common light-weight devices (e.g., smartphones). To this end, this paper proposes $\pi$QLB, a query language for blockchain systems that ensures both confidentiality of query inputs and integrity of query results. Additionally, $\pi$QLB enables SQL-like queries over the blockchain data by introducing relational data semantics into the existing blockchain database. $\pi$QLB has applied the recent cryptography primitive, i.e., function secret sharing (FSS), to achieve confidentiality. To support integrity, we extend the traditional FSS setting in such a way that integrity of FSS results can be efficiently verified. Successful verification indicates absence of malicious behaviors on the servers, allowing the user to establish trust from the result. To the best of our knowledge, $\pi$QLB is the first query model designed for blockchain databases with support for confidentiality, integrity, and SQL-like queries.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning-Augmented Decentralized Online Convex Optimization in Networks</title>
<link>https://arxiv.org/abs/2306.10158</link>
<guid>https://arxiv.org/abs/2306.10158</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized online convex optimization, LADO算法, local online information, worst-case robustness, machine learning policy

总结:<br />
本文研究了网络化多智能体系统的分布式在线凸优化问题，并提出了一种新颖的算法——学习增强型分布式在线优化（LADO）。LADO允许每个代理仅基于本地在线信息选择行动，利用基准策略保障最坏情况下的鲁棒性保证，同时尽可能接近机器学习（ML）策略以提升平均性能。与现有关注集中式设置的学习增强型在线算法形成鲜明对比，LADO在分布式环境中实现了强大的鲁棒性保证。此外，文中还证明了LADO的平均成本界，揭示了平均性能与最坏情况鲁棒性之间的权衡，并表明通过明确考虑鲁棒性要求来训练ML策略的优势。 <div>
arXiv:2306.10158v3 Announce Type: replace 
Abstract: This paper studies decentralized online convex optimization in a networked multi-agent system and proposes a novel algorithm, Learning-Augmented Decentralized Online optimization (LADO), for individual agents to select actions only based on local online information. LADO leverages a baseline policy to safeguard online actions for worst-case robustness guarantees, while staying close to the machine learning (ML) policy for average performance improvement. In stark contrast with the existing learning-augmented online algorithms that focus on centralized settings, LADO achieves strong robustness guarantees in a decentralized setting. We also prove the average cost bound for LADO, revealing the tradeoff between average performance and worst-case robustness and demonstrating the advantage of training the ML policy by explicitly considering the robustness requirement.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Distributed Deep Learning via Federated Dynamic Averaging</title>
<link>https://arxiv.org/abs/2405.20988</link>
<guid>https://arxiv.org/abs/2405.20988</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式深度学习（DDL）、通信瓶颈、Federated Dynamic Averaging (FDA)、模型同步、数据异质性

<br /><br />总结:
为了解决分布式深度学习(DDL)中因频繁模型同步导致的通信瓶颈和效率问题，本文提出了Federated Dynamic Averaging (FDA)策略。FDA是一种基于模型差异度动态触发同步的通信高效方法，仅当从全局模型初始化的局部模型发生显著偏离时才进行昂贵的同步步骤。每个分布式节点发送少量本地状态信息以辅助该决策。实验表明，与传统和前沿的通信效率算法相比，FDA能大幅降低通信成本并保持在不同数据异质性设置下的稳健性能。 <div>
arXiv:2405.20988v3 Announce Type: replace 
Abstract: Driven by the ever-growing volume and decentralized nature of data, coupled with the need to harness this data and generate knowledge from it, has led to the extensive use of distributed deep learning (DDL) techniques for training. These techniques rely on local training that is performed at the distributed nodes based on locally collected data, followed by a periodic synchronization process that combines these models to create a global model. However, frequent synchronization of DL models, encompassing millions to many billions of parameters, creates a communication bottleneck, severely hindering scalability. Worse yet, DDL algorithms typically waste valuable bandwidth, and make themselves less practical in bandwidth-constrained federated settings, by relying on overly simplistic, periodic, and rigid synchronization schedules. These drawbacks also have a direct impact on the time required for the training process, necessitating excessive time for data communication. To address these shortcomings, we propose Federated Dynamic Averaging (FDA), a communication-efficient DDL strategy that dynamically triggers synchronization based on the value of the model variance. In essence, the costly synchronization step is triggered only if the local models, which are initialized from a common global model after each synchronization, have significantly diverged. This decision is facilitated by the communication of a small local state from each distributed node/worker. Through extensive experiments across a wide range of learning tasks we demonstrate that FDA reduces communication cost by orders of magnitude, compared to both traditional and cutting-edge communication-efficient algorithms. Additionally, we show that FDA maintains robust performance across diverse data heterogeneity settings.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dyna-5G: A Dynamic, Flexible, and Self-Organizing 5G Network for M2M Ecosystems</title>
<link>https://arxiv.org/abs/2406.15681</link>
<guid>https://arxiv.org/abs/2406.15681</guid>
<content:encoded><![CDATA[
<div> 关键词: Dyna-5G, 5G-NR, 异构网络, 自组织, 机器间通信

总结:
本文介绍了Dyna-5G，这是一种针对大规模机器间通信（M2M）网络设计的动态、自组织的5G新无线（5G-NR）网络。传统集中式架构的5G NR网络在支持需要动态、分散通信的应用（如自动驾驶车辆和应急响应无人机群）时面临挑战，因为这些场景常常受到中心化模型单点故障的影响，从而削弱了对关键和全自主应用所需的高度可靠性。Dyna-5G解决了这些问题，允许网络中的每个设备同时充当无线接入网（RAN）、核心网络或用户设备（UE），即使常规基础设施组件受损也能保持网络功能。此外，Dyna-5G内置了专门针对M2M网络的设计机制，如故障恢复和临时加入与退出。通过定制的测试平台模拟实际任务来展示Dyna-5G的性能和可行性，结果显示该网络具有强大的鲁棒性、适应性和快速故障恢复能力，整个网络模型能在最多6秒内完全重新组织，而不影响任务执行。 <div>
arXiv:2406.15681v2 Announce Type: replace 
Abstract: In this work, we present Dyna-5G, a dynamic, self-organizing 5G New Radio (5G-NR) network designed for massive Machine-to-Machine (M2M) networks. Traditional 5G NR networks, characterized by their centralized architecture, face challenges in supporting applications that require dynamic, decentralized communication, such as autonomous vehicles and drone swarms for emergency responses. These scenarios often suffer from the centralized model's single point of failure, undermining the reliability required in critical and fully autonomous applications. Dyna-5G addresses these challenges by allowing each device in the network to function as either part of the Radio Access Network (RAN) and Core Network, or as User Equipment (UE), thus maintaining network functionality even when conventional infrastructure components are compromised. Dyna-5G has built-in mechanisms carefully designed specifically for M2M networks, such as failure-recovery and ad-hoc entry and exit. We demonstrate the performance and feasibility of Dyna-5G using a custom-built testbed that simulates real-world missions, demonstrating our network's robustness, adaptability, and failure recovery capabilities. The results indicate that our entire 5G network model can fully re-organize in 6 seconds at maximum, without compromising the mission.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design of an Efficient Fan-Shaped Clustered Trust-Based Routing Model with QoS &amp; Security-Aware Side-Chaining for IoV Deployments</title>
<link>https://arxiv.org/abs/2410.12798</link>
<guid>https://arxiv.org/abs/2410.12798</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网车辆, 可信路由模型, 服务质量, 安全, 旁链管理<br /><br />总结:<br /><br />本文介绍了一种针对物联网车辆(IoV)部署的新型扇形信任基础路由模型，该模型结合了服务质量(QoS)和安全意识旁链管理。通过使用细菌觅食优化器(BFO)算法动态调整旁链配置，提高了系统性能。研究采用了扇形聚类技术来提高通信效率和资源利用，并通过实验验证了其有效性。该模型在延迟、吞吐量、数据包递送率(PDR)和能量消耗方面均优于现有方法，分别减少了9.5%、提高了10.5%、提高了2.9%和减少了4.5%。此外，该模型对Sybil、伪装和泛洪攻击等常见IoV威胁具有更强的抵抗力，确保了持续和可靠的数据传输。这些成果对于智能城市、工业自动化、医疗系统、交通网络和环境监测等领域具有广泛应用价值。 <div>
arXiv:2410.12798v1 Announce Type: new 
Abstract: The rapid expansion of Internet of Vehicles (IoV) deployments has necessitated the creation of efficient and secure routing models to manage the massive data traffic generated by interconnected devices & vehicles. For IoV deployments, we propose a novel fan-shaped trust-based routing model with Quality of Service (QoS) and security-aware side-chaining. Our method employs temporal levels of delay, throughput, Packet Delivery Ratio (PDR), and energy consumption to determine optimal routing paths, thereby ensuring efficient data transmissions. We employ the Bacterial Foraging Optimizer (BFO) algorithm to manage side-chains within the network, which dynamically adjusts side-chain configurations to optimize system performance. The technique of fan-shaped clustering is used to group nodes into efficient clusters, allowing for more efficient communication and resource utilization sets. Extensive experimentation and performance analysis are utilized to evaluate the proposed model. Existing blockchain-based security models have been significantly improved by our findings. Our model achieves a remarkable 9.5% reduction in delay, a 10.5% improvement in throughput, a 2.9% improvement in PDR, and a 4.5% reduction in energy consumption compared to alternative approaches. In addition, we evaluate the model's resistance to Sybil, Masquerading, and Flooding attacks, which are prevalent security threats for IoV deployments. Even under these attack scenarios, our model provides consistently higher QoS levels compared to existing solutions, ensuring uninterrupted and reliable data transmissions. In IoV deployments, the proposed routing model and side-chaining management approach have numerous applications and use-cases like Smart cities, industrial automation, healthcare systems, transportation networks, and environmental monitoring.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation</title>
<link>https://arxiv.org/abs/2410.12926</link>
<guid>https://arxiv.org/abs/2410.12926</guid>
<content:encoded><![CDATA[
<div> 关键词: 低秩适应, 联邦学习, 差分隐私, 聚合偏差, 噪声调节<br /><br />总结:<br />
本文介绍了一种新的隐私保护联邦微调框架DEeR，旨在解决低秩适应（LoRA）与联邦学习（FL）结合时出现的聚合偏差和差分隐私（DP）噪声放大问题。首先，理论证明了消除聚合偏差的关键在于保证客户端LoRA参数的等价性，并设计了偏差消除器来优化LoRA参数矩阵，确保训练过程中聚合偏差为零。其次，对噪声放大效应进行了深入分析，发现该问题主要由DP噪声与LoRA参数之间的线性关系引起，因此提出了噪声调节器来解耦这种关系，从而实现更好的隐私保护和微调性能。最后，通过全面的实验验证了偏差消除器和噪声调节器的有效性，结果显示DEeR在公共医疗数据集上优于现有最先进的方法。相关代码已开源。 <div>
arXiv:2410.12926v1 Announce Type: new 
Abstract: Integrating low-rank adaptation (LoRA) with federated learning (FL) has received widespread attention recently, aiming to adapt pretrained foundation models (FMs) to downstream medical tasks via privacy-preserving decentralized training. However, owing to the direct combination of LoRA and FL, current methods generally undergo two problems, i.e., aggregation deviation, and differential privacy (DP) noise amplification effect. To address these problems, we propose a novel privacy-preserving federated finetuning framework called \underline{D}eviation \underline{E}liminating and Nois\underline{e} \underline{R}egulating (DEeR). Specifically, we firstly theoretically prove that the necessary condition to eliminate aggregation deviation is guaranteing the equivalence between LoRA parameters of clients. Based on the theoretical insight, a deviation eliminator is designed to utilize alternating minimization algorithm to iteratively optimize the zero-initialized and non-zero-initialized parameter matrices of LoRA, ensuring that aggregation deviation always be zeros during training. Furthermore, we also conduct an in-depth analysis of the noise amplification effect and find that this problem is mainly caused by the ``linear relationship'' between DP noise and LoRA parameters. To suppress the noise amplification effect, we propose a noise regulator that exploits two regulator factors to decouple relationship between DP and LoRA, thereby achieving robust privacy protection and excellent finetuning performance. Additionally, we perform comprehensive ablated experiments to verify the effectiveness of the deviation eliminator and noise regulator. DEeR shows better performance on public medical datasets in comparison with state-of-the-art approaches. The code is available at https://github.com/CUHK-AIM-Group/DEeR.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Future of Algorithmic Organization: Large-Scale Analysis of Decentralized Autonomous Organizations (DAOs)</title>
<link>https://arxiv.org/abs/2410.13095</link>
<guid>https://arxiv.org/abs/2410.13095</guid>
<content:encoded><![CDATA[
<div> DAO 去中心化 自治组织 治理模型 参与度<br /><br />总结:<br />本文研究了去中心化自治组织（DAO）的运作机制，分析了包括pleasrdao、lexdao等在内的100个DAO。研究发现，大规模的实证分析显示，DAO中草根参与度的提高与更高的去中心化水平相关，而投票权力分配的均衡性也影响着DAO的去中心化程度。这些发现对于政治科学领域关于决策中的权力分配及治理模型的影响有着重要启示，同时为新兴应用中民主治理系统的构建提供了参考依据。 <div>
arXiv:2410.13095v1 Announce Type: new 
Abstract: Decentralized Autonomous Organizations (DAOs) resemble early online communities, particularly those centered around open-source projects, and present a potential empirical framework for complex social-computing systems by encoding governance rules within "smart contracts" on the blockchain. A key function of a DAO is collective decision-making, typically carried out through a series of proposals where members vote on organizational events using governance tokens, signifying relative influence within the DAO. In just a few years, the deployment of DAOs surged with a total treasury of $24.5 billion and 11.1M governance token holders collectively managing decisions across over 13,000 DAOs as of 2024. In this study, we examine the operational dynamics of 100 DAOs, like pleasrdao, lexdao, lootdao, optimism collective, uniswap, etc. With large-scale empirical analysis of a diverse set of DAO categories and smart contracts and by leveraging on-chain (e.g., voting results) and off-chain data, we examine factors such as voting power, participation, and DAO characteristics dictating the level of decentralization, thus, the efficiency of management structures. As such, our study highlights that increased grassroots participation correlates with higher decentralization in a DAO, and lower variance in voting power within a DAO correlates with a higher level of decentralization, as consistently measured by Gini metrics. These insights closely align with key topics in political science, such as the allocation of power in decision-making and the effects of various governance models. We conclude by discussing the implications for researchers, and practitioners, emphasizing how these factors can inform the design of democratic governance systems in emerging applications that require active engagement from stakeholders in decision-making.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity</title>
<link>https://arxiv.org/abs/2410.13141</link>
<guid>https://arxiv.org/abs/2410.13141</guid>
<content:encoded><![CDATA[
<div> 关键词：神经网络 联邦学习 科学机器学习 偏微分方程 数据异质性<br /><br />总结:<br />
本文研究了联邦学习（FL）与科学机器学习（SciML）的结合，以解决数据分布、隐私和传输问题。文章提出了两种新模型：联邦物理信息神经网络（FedPINN）和联邦深度算子网络（FedDeepONet），并介绍了多种数据生成方法来控制非独立同分布（non-iid）数据的程度。通过使用1-瓦瑟斯坦距离量化函数逼近和偏微分方程（PDE）学习中的数据异质性，系统地探讨了数据异质性与联邦模型性能之间的关系。此外，文章提出了一种权重发散度量，并开发了一个理论框架，以建立联邦学习与传统集中式学习之间权重发散的增长界限。实验结果表明，所提出的联邦方法不仅优于仅使用本地数据训练的模型，而且在准确性上可与使用所有数据训练的集中式模型相媲美。 <div>
arXiv:2410.13141v1 Announce Type: new 
Abstract: By leveraging neural networks, the emerging field of scientific machine learning (SciML) offers novel approaches to address complex problems governed by partial differential equations (PDEs). In practical applications, challenges arise due to the distributed essence of data, concerns about data privacy, or the impracticality of transferring large volumes of data. Federated learning (FL), a decentralized framework that enables the collaborative training of a global model while preserving data privacy, offers a solution to the challenges posed by isolated data pools and sensitive data issues. Here, this paper explores the integration of FL and SciML to approximate complex functions and solve differential equations. We propose two novel models: federated physics-informed neural networks (FedPINN) and federated deep operator networks (FedDeepONet). We further introduce various data generation methods to control the degree of non-independent and identically distributed (non-iid) data and utilize the 1-Wasserstein distance to quantify data heterogeneity in function approximation and PDE learning. We systematically investigate the relationship between data heterogeneity and federated model performance. Additionally, we propose a measure of weight divergence and develop a theoretical framework to establish growth bounds for weight divergence in federated learning compared to traditional centralized learning. To demonstrate the effectiveness of our methods, we conducted 10 experiments, including 2 on function approximation, 5 PDE problems on FedPINN, and 3 PDE problems on FedDeepONet. These experiments demonstrate that proposed federated methods surpass the models trained only using local data and achieve competitive accuracy of centralized models trained using all data.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pricing Factors and TFMs for Scalability-Focused ZK-Rollups</title>
<link>https://arxiv.org/abs/2410.13277</link>
<guid>https://arxiv.org/abs/2410.13277</guid>
<content:encoded><![CDATA[
<div> ZK-Rollups 交易费机制 序列化 数据可用性 零知识证明 激励相容<br /><br />总结:<br />本文探讨了ZK-Rollups中的交易费机制（TFMs）设计，重点分析了序列化、数据可用性和零知识证明等关键组件如何相互作用影响成本结构。文章提出了适合TFMs应具备的特性，如激励相容和净盈利性，并讨论了不同TFM方案的权衡及开放问题，这些都需要进一步研究。 <div>
arXiv:2410.13277v1 Announce Type: new 
Abstract: ZK-Rollups have emerged as a leading solution for blockchain scalability, leveraging succinct proofs primarily based on ZKP protocols. This paper explores the design of transaction fee mechanisms (TFMs) for ZK-Rollups, focusing on how key components like sequencing, data availability~(DA), and ZK proving interact to influence cost structures. We outline the properties that a suitable TFM should possess, such as incentive compatibility and net profitability. In addition, we propose alternatives for TFMs, discuss trade-offs, and highlight open questions that require further investigation in the context of ZK-Rollups.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assessing the techno-economic benefits of LEMs for different grid topologies and prosumer shares</title>
<link>https://arxiv.org/abs/2410.13330</link>
<guid>https://arxiv.org/abs/2410.13330</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式能源资源, 本地能源市场, 经济效率, 网格稳定性, 可再生能源

<br /><br />总结:<br />
本文探讨了本地能源市场在整合分布式能源资源（如光伏系统、电动汽车和热泵）方面相对于传统市场设计的优势。研究使用自开发的基于代理的能量系统仿真工具，通过模拟不同电网拓扑结构（乡村、农村、郊区和城市）及不同的分布式能源渗透水平，证明了本地能源市场的引入能够提升经济效率并增强电网稳定性。具体而言，99%的场景显示平均能源价格降低，80%的场景显示运营峰值功率降低。研究表明，在高比例光伏和热泵地区，如果能将额外基础设施、管理成本和官僚复杂性控制在最低限度，本地能源市场将在未来能源系统中发挥重要作用。 <div>
arXiv:2410.13330v1 Announce Type: new 
Abstract: The shift towards decentralized and renewable energy sources has introduced significant challenges to traditional power systems, necessitating innovative market designs. Local energy markets present a viable solution for integrating distributed energy resources such as photovoltaic systems, electric vehicles, and heat pumps within various grid topologies. This study investigates the techno-economic benefits of local energy markets compared to conventional market designs, focusing on their impact on average energy prices and operational peak power, using a self-developed agent-based energy system simulation tool. Through comprehensive simulations across the countryside, rural, suburban, and urban grid topologies with varying penetration levels of the distributed energy resources, totaling 400 simulation setups, we demonstrate that local energy markets can enhance economic efficiency and grid stability with 99 % of the scenarios boasting lower average energy prices and 80 % lower operational peak power levels. Our findings suggest that local energy markets can play a role in the future energy system, especially in areas with high shares of PV and HP, provided that additional infrastructure, management costs, and bureaucratic complexity are kept to a minimum.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Formal Verification of Federated Learning Orchestration Protocols on Satellites</title>
<link>https://arxiv.org/abs/2410.13429</link>
<guid>https://arxiv.org/abs/2410.13429</guid>
<content:encoded><![CDATA[
<div> 关键词：Python Testbed、联邦学习、定时自动机、随机模型、航天器运动<br /><br />总结:<br />本文介绍了Python测试平台（PTB-FLA），这是一个用于智能物联网边缘系统的联邦学习算法框架，支持集中式和分布式联邦学习算法。这些算法通过CSP过程代数进行了形式化验证。然而，该方法适用于静态节点系统，不适用于移动节点系统。因此，本文使用天体力学建模航天器运动，并采用定时自动机（TA）对集中式联邦学习编排协议进行形式化和验证。验证分为两个阶段：第一阶段，创建传统TA模型以证明无死锁性和终止性；第二阶段，构建随机TA模型以验证时间正确性和估计终止概率。 <div>
arXiv:2410.13429v1 Announce Type: new 
Abstract: Python Testbed for Federated Learning Algorithms (PTB-FLA) is a simple FL framework targeting smart Internet of Things in edge systems that provides both generic centralized and decentralized FL algorithms, which implement the corresponding FL orchestration protocols that were formally verified using the process algebra CSP. This approach is appropriate for systems with stationary nodes but cannot be applied to systems with moving nodes. In this paper, we use celestial mechanics to model spacecraft movement, and timed automata (TA) to formalize and verify the centralized FL orchestration protocol, in two phases. In the first phase, we created a conventional TA model to prove traditional properties, namely deadlock freeness and termination. In the second phase, we created a stochastic TA model to prove timing correctness and to estimate termination probability.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal MEV Extraction Using Absolute Commitments</title>
<link>https://arxiv.org/abs/2410.13624</link>
<guid>https://arxiv.org/abs/2410.13624</guid>
<content:encoded><![CDATA[
<div> 攻击 去中心化交易所 绝对承诺 智能合约 垄断价格<br /><br />总结:<br />文章提出了一种针对去中心化交易所的新攻击方法。该攻击利用了绝对承诺，即承诺可以依赖于其他参与者的行为策略。通过这种策略，攻击者能够以垄断价格进行收费，从而从用户那里榨取最大可能的价格，甚至可能通过规避通常费用和低效性的侧信道来实现。这比现有的“三明治攻击”更为高效，后者主要通过诱导市场价波动来获利。文章指出，这种新攻击可以通过智能合约实现，因为智能合约具有不可撤销和自动执行的特点，广泛存在于主流区块链中。因此，这种攻击可能会严重损害受影响的去中心化交易所的功能。 <div>
arXiv:2410.13624v1 Announce Type: new 
Abstract: We propose a new, more potent attack on decentralized exchanges. This attack leverages absolute commitments, which are commitments that can condition on the strategies made by other agents. This attack allows an adversary to charge monopoly prices by committing to undercut those other miners that refuse to charge an even higher fee. This allows the miner to extract the maximum possible price from the user, potentially through side channels that evade the inefficiencies and fees usually incurred. This is considerably more efficient than the prevailing strategy of `sandwich attacks', wherein the adversary induces and profits from fluctuations in the market price to the detriment of users. The attack we propose can, in principle, be realized by the irrevocable and self-executing nature of smart contracts, which are readily available on many major blockchains. Thus, the attack could potentially be used against a decentralized exchange and could drastically reduce the utility of the affected exchange.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unconstrained Model Merging for Enhanced LLM Reasoning</title>
<link>https://arxiv.org/abs/2410.13699</link>
<guid>https://arxiv.org/abs/2410.13699</guid>
<content:encoded><![CDATA[
<div> 模型融合 专家模型 推理任务 去中心化 模型架构<br /><br />总结:<br />本文探讨了将多个专家模型融合成单一大语言模型（LLM）的潜力，作为资源友好型替代方案。研究重点在于推理任务，提出了一种不受约束的模型融合框架，适用于同构和异构模型架构。对于同构模型，设计了细粒度的层权重融合策略；对于异构模型，则基于指令响应微调数据的概率分布知识构建。实验结果显示，通过模型融合产生的组合推理能力超越了简单的加法效应。这表明，不受约束的模型融合可以作为去中心化LLM的基础，标志着从现有集中式LLM框架的重要进步，有助于促进更广泛参与和人工智能领域的进一步发展。 <div>
arXiv:2410.13699v1 Announce Type: new 
Abstract: Recent advancements in building domain-specific large language models (LLMs) have shown remarkable success, especially in tasks requiring reasoning abilities like logical inference over complex relationships and multi-step problem solving. However, creating a powerful all-in-one LLM remains challenging due to the need for proprietary data and vast computational resources. As a resource-friendly alternative, we explore the potential of merging multiple expert models into a single LLM. Existing studies on model merging mainly focus on generalist LLMs instead of domain experts, or the LLMs under the same architecture and size. In this work, we propose an unconstrained model merging framework that accommodates both homogeneous and heterogeneous model architectures with a focus on reasoning tasks. A fine-grained layer-wise weight merging strategy is designed for homogeneous models merging, while heterogeneous model merging is built upon the probabilistic distribution knowledge derived from instruction-response fine-tuning data. Across 7 benchmarks and 9 reasoning-optimized LLMs, we reveal key findings that combinatorial reasoning emerges from merging which surpasses simple additive effects. We propose that unconstrained model merging could serve as a foundation for decentralized LLMs, marking a notable progression from the existing centralized LLM framework. This evolution could enhance wider participation and stimulate additional advancement in the field of artificial intelligence, effectively addressing the constraints posed by centralized models.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On-device Federated Learning in Smartphones for Detecting Depression from Reddit Posts</title>
<link>https://arxiv.org/abs/2410.13709</link>
<guid>https://arxiv.org/abs/2410.13709</guid>
<content:encoded><![CDATA[
<div> 关键词：抑郁检测, 深度学习, 联邦学习, 异构环境, 通信成本<br /><br />总结:<br />本文研究了使用深度学习模型进行抑郁症检测，并特别关注联邦学习（FL）在该领域的应用。研究采用了GRU、RNN和LSTM三种神经网络架构，基于Reddit帖子数据进行抑郁迹象的识别。实验表明，联邦模型在异构环境下与集中式模型性能相当。此外，通过使用通用标记器减少计算负载，并分析了智能手机上的资源消耗和通信成本，证明了FL方法在保护用户隐私的同时，能够实现高效安全的模型训练。这项研究强调了FL在边缘设备上进行去中心化心理健康预测的潜力。 <div>
arXiv:2410.13709v1 Announce Type: new 
Abstract: Depression detection using deep learning models has been widely explored in previous studies, especially due to the large amounts of data available from social media posts. These posts provide valuable information about individuals' mental health conditions and can be leveraged to train models and identify patterns in the data. However, distributed learning approaches have not been extensively explored in this domain. In this study, we adopt Federated Learning (FL) to facilitate decentralized training on smartphones while protecting user data privacy. We train three neural network architectures--GRU, RNN, and LSTM on Reddit posts to detect signs of depression and evaluate their performance under heterogeneous FL settings. To optimize the training process, we leverage a common tokenizer across all client devices, which reduces the computational load. Additionally, we analyze resource consumption and communication costs on smartphones to assess their impact in a real-world FL environment. Our experimental results demonstrate that the federated models achieve comparable performance to the centralized models. This study highlights the potential of FL for decentralized mental health prediction by providing a secure and efficient model training process on edge devices.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Decentralized AI with Confidential Computing</title>
<link>https://arxiv.org/abs/2410.13752</link>
<guid>https://arxiv.org/abs/2410.13752</guid>
<content:encoded><![CDATA[
<div> Confidential Computing, Decentralized AI, Privacy Protection, Trusted Execution Environments, Atoma Network<br /><br />总结: 本文探讨了在去中心化人工智能（Decentralized AI）中利用保密计算（Confidential Computing）保护隐私的问题。文章指出，虽然去中心化AI可以提高透明度和鲁棒性，但其分布式特性也带来了隐私泄露的风险。为解决这一问题，文中提出使用基于硬件的可信执行环境（Trusted Execution Environments, TEEs）来保护敏感数据，确保模型参数和用户数据的安全。该方案被应用于Atoma网络，这是一个专为Web3领域设计的去中心化AI平台。尽管存在一些限制，作者认为这种技术可以有效填补去中心化AI中的隐私保护空白。 <div>
arXiv:2410.13752v1 Announce Type: new 
Abstract: This paper addresses privacy protection in decentralized Artificial Intelligence (AI) using Confidential Computing (CC) within the Atoma Network, a decentralized AI platform designed for the Web3 domain. Decentralized AI distributes AI services among multiple entities without centralized oversight, fostering transparency and robustness. However, this structure introduces significant privacy challenges, as sensitive assets such as proprietary models and personal data may be exposed to untrusted participants. Cryptography-based privacy protection techniques such as zero-knowledge machine learning (zkML) suffers prohibitive computational overhead. To address the limitation, we propose leveraging Confidential Computing (CC). Confidential Computing leverages hardware-based Trusted Execution Environments (TEEs) to provide isolation for processing sensitive data, ensuring that both model parameters and user data remain secure, even in decentralized, potentially untrusted environments. While TEEs face a few limitations, we believe they can bridge the privacy gap in decentralized AI. We explore how we can integrate TEEs into Atoma's decentralized framework.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Exposition of Pathfinding Strategies Within Lightning Network Clients</title>
<link>https://arxiv.org/abs/2410.13784</link>
<guid>https://arxiv.org/abs/2410.13784</guid>
<content:encoded><![CDATA[
<div> 路径搜索策略 路由费用 支付可靠性 连通性 费用锁<br /><br />总结:<br />本文研究了闪电网络中不同节点实现采用的路径搜索策略差异，包括成本函数、约束条件和最短路径贪心算法的不同。研究发现大多数LN节点实现的问题是NP完全问题，无法保证通过目前生产部署的Dijkstra算法变体得到最优解。通过比较分析和模拟实验，文中指出LND策略在支付可靠性方面占优；Eclair策略产生的路径费用较低；LDK策略在小金额支付下可靠性一般但费用较高；CLN则以最小时间锁定路径为特点。此外，文章还探讨了闪电网络节点连接水平对路由效率的影响。这些发现为未来改进路径搜索策略提供了见解。 <div>
arXiv:2410.13784v1 Announce Type: new 
Abstract: The Lightning Network is a peer-to-peer network designed to address Bitcoin's scalability challenges, facilitating rapid, cost-effective, and instantaneous transactions through bidirectional, blockchain-backed payment channels among network peers. Due to a source-based routing of payments, different pathfinding strategies are used in practice, trading off different objectives for each other such as payment reliability and routing fees. This paper explores differences within pathfinding strategies used by prominent Lightning Network node implementations, which include different underlying cost functions and different constraints, as well as different greedy algorithms of shortest path-type. Surprisingly, we observe that the pathfinding problems that most LN node implementations attempt to solve are NP-complete, and cannot be guaranteed to be optimally solved by the variants of Dijkstra's algorithm currently deployed in production. Through comparative analysis and simulations, we evaluate efficacy of different pathfinding strategies across metrics such as success rate, fees, path length, and timelock. Our experiments indicate that the strategies used by LND tend to be advantageous in terms of payment reliability, Eclair tends to result in paths with low fees, and that LDK exhibits average reliability with larger fee levels for smaller payment amounts; furthermore, CLN stands out for its minimal timelock paths. Additionally, we investigate the impact of Lightning node connectivity levels on routing efficiency. The findings of our analysis provide insights towards future improvements of pathfinding strategies and algorithms used within the Lightning Network.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Smart Contract Intent Detection</title>
<link>https://arxiv.org/abs/2211.10724</link>
<guid>https://arxiv.org/abs/2211.10724</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、开发意图、深度学习、F1得分、多标签分类<br /><br />总结:<br />本文介绍了智能合约领域的一个新研究，重点关注如何检测智能合约中的开发意图。由于恶意意图导致了巨大的经济损失，而现有研究缺乏有效的方法来识别这些意图。为了解决这个问题，作者提出了SmartIntentNN（智能合约意图神经网络），这是一种深度学习模型，旨在自动检测智能合约中的开发意图。该模型使用预训练的句子编码器生成智能合约代码的上下文表示，K-means聚类模型识别和突出显示显著的意图特征，并使用双向LSTM进行多标签分类。实验表明，SmartIntentNN在10个不同类别中识别意图的F1得分为0.8633，优于所有基线模型。这项研究填补了智能合约检测中意图分析的空白。 <div>
arXiv:2211.10724v2 Announce Type: replace 
Abstract: In recent years, researchers in the software security field have focused on detecting vulnerabilities in smart contracts to avoid significant losses of crypto assets on the blockchain. Despite early successes in this domain, detecting developers' intents in smart contracts is a more pressing issue, as malicious intents have resulted in substantial financial losses. Unfortunately, existing research lacks effective methods for detecting development intents in smart contracts. To address this gap, we propose \textsc{SmartIntentNN} (Smart Contract Intent Neural Network), a deep learning model designed to automatically detect development intent in smart contracts. \textsc{SmartIntentNN} utilizes a pre-trained sentence encoder to generate contextual representations of smart contract code, a K-means clustering model to identify and highlight prominent intent features, and a bidirectional LSTM-based deep neural network for multi-label classification. We trained and evaluated \textsc{SmartIntentNN} on a dataset comprising over 40,000 real-world smart contracts, employing self-comparison baselines in our experimental setup. The results demonstrate that \textsc{SmartIntentNN} achieves an F1-score of 0.8633 in identifying intents across 10 distinct categories, outperforming all baselines and filling the gap in smart contract detection by incorporating intent analysis.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Airdrops: Giving Money Away Is Harder Than It Seems</title>
<link>https://arxiv.org/abs/2312.02752</link>
<guid>https://arxiv.org/abs/2312.02752</guid>
<content:encoded><![CDATA[
<div> 设计空间 共识机制 经济激励 数据分析 指导方针<br /><br />总结:<br />本文研究了区块链领域中常见的吸引用户策略——空投。文章界定了空投的设计空间，并提出了有效的空投策略的关键成果。通过对六个大规模空投的数据分析，发现大量代币被“空投农民”出售。基于此，文章指出了空投设计中的常见问题，并提供了改进建议，旨在提高空投的有效性和长期社区参与度。 <div>
arXiv:2312.02752v3 Announce Type: replace 
Abstract: Airdrops are a common strategy used by blockchain protocols to attract and grow an initial user base. Tokens are typically distributed to select users as a "reward" for engaging with the protocol, aiming to foster long-term community loyalty and sustained economic activity. Despite their prevalence, there is limited understanding of what makes an airdrop successful. This paper outlines the design space for airdrops and proposes key outcomes for an effective strategy. We analyze on-chain data from six large-scale airdrops to assess their success and find that a substantial portion of tokens is often sold off by "airdrop farmers." Based on this analysis, we highlight common pitfalls and offer guidelines for improving airdrop design.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bluesky and the AT Protocol: Usable Decentralized Social Media</title>
<link>https://arxiv.org/abs/2402.03239</link>
<guid>https://arxiv.org/abs/2402.03239</guid>
<content:encoded><![CDATA[
<div> 关键词：Bluesky, AT协议, 去中心化, 用户切换, 内容管理<br /><br />总结:<br />本文介绍了基于AT协议构建的新社交网络Bluesky。Bluesky自2023年2月私人测试版推出以来，到2024年10月已拥有超过1000万注册用户。文章详细描述了Bluesky和AT协议的架构，并解释了其技术设计如何服务于去中心化、用户自由切换服务提供商、用户对内容的控制以及提供简洁用户体验的目标。系统开放性允许任何人参与内容管理和社区治理，同时鼓励研究界将Bluesky作为数据集和实验平台，用于探索社交媒体管理的新方法。 <div>
arXiv:2402.03239v2 Announce Type: replace 
Abstract: Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media. It was launched in private beta in February 2023, and has grown to over 10 million registered users by October 2024. In this paper we introduce the architecture of Bluesky and the AT Protocol, and explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature. The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>NFT1000: A Cross-Modal Dataset for Non-Fungible Token Retrieval</title>
<link>https://arxiv.org/abs/2402.16872</link>
<guid>https://arxiv.org/abs/2402.16872</guid>
<content:encoded><![CDATA[
<div> NFT 数据集 CLIP 动态掩码微调 综合方差指数 元数据<br /><br />总结:<br />本文介绍了名为“NFT Top1000 Visual-Text Dataset”(NFT1000)的数据集，该数据集包含来自以太坊区块链上销量最高的1000个PFP NFT集合的756万张图像和文本对。基于此数据集，作者采用CLIP系列预训练模型并提出了一种动态掩码微调方案，这种方法仅使用13%的训练数据就将top1准确率提高了7.4%。此外，文中还提出了一种新的评估指标——综合方差指数(CVI)，用于衡量视觉-文本对数据的相似性和检索难度。该数据集将作为开源资源发布。 <div>
arXiv:2402.16872v2 Announce Type: replace 
Abstract: With the rise of "Metaverse" and "Web 3.0", Non-Fungible Token (NFT) has emerged as a kind of pivotal digital asset, garnering significant attention. By the end of March 2024, more than 1.7 billion NFTs have been minted across various blockchain platforms. To effectively locate a desired NFT, conducting searches within a vast array of NFTs is essential. The challenge in NFT retrieval is heightened due to the high degree of similarity among different NFTs, regarding regional and semantic aspects. In this paper, we will introduce a benchmark dataset named "NFT Top1000 Visual-Text Dataset" (NFT1000), containing 7.56 million image-text pairs, and being collected from 1000 most famous PFP1 NFT collections2 by sales volume on the Ethereum blockchain. Based on this dataset and leveraging the CLIP series of pre-trained models as our foundation, we propose the dynamic masking fine-tuning scheme. This innovative approach results in a 7.4\% improvement in the top1 accuracy rate, while utilizing merely 13\% of the total training data (0.79 million vs. 6.1 million). We also propose a robust metric Comprehensive Variance Index (CVI) to assess the similarity and retrieval difficulty of visual-text pairs data. The dataset will be released as an open-source resource. For more details, please refer to: https://github.com/ShuxunoO/NFT-Net.git.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Writing is on the Wall: Analyzing the Boom of Inscriptions and its Impact on EVM-compatible Blockchains</title>
<link>https://arxiv.org/abs/2405.15288</link>
<guid>https://arxiv.org/abs/2405.15288</guid>
<content:encoded><![CDATA[
<div> 关键词：rollups, 高负载性能, 交易激增, inscriptions, 扩展性<br /><br />总结:<br />
本文研究了在高负载情况下rollups的性能表现，特别是在2023年末至2024年初由inscriptions（一种在区块链上记录数据的方法）引发的交易激增。文章指出，在某些日期，inscriptions几乎占到了Arbitrum和ZKsync Era平台上交易量的90%，而Ethereum上则达到了53%。此外，99%的这些inscriptions与meme币铸造有关。<br />
研究还发现，在交易激增期间，ZKsync和Arbitrum平台的中位gas费用较低，其中ZKsync Era作为零知识rollup，其费用降低幅度大于所研究的乐观rollups（包括Arbitrum、Base和Optimism）。这表明，ZK-rollups在处理大规模交易激增时具有更好的扩展性和成本效益。<br /> <div>
arXiv:2405.15288v2 Announce Type: replace 
Abstract: Although rollups have attracted significant attention, there is limited empirical research on their performance under high load. To address this, we present a data-driven analysis of the transaction surge in late 2023 and early 2024, attributed to inscriptions -- a method for recording data on the blockchain. Initially introduced on Bitcoin, inscriptions enable the representation of NFTs or ERC-20-like tokens without smart contracts, and have since expanded to other blockchains. This paper examines inscription-related transactions on Ethereum and major EVM-compatible rollups, assessing their impact on scalability during transaction surges. Our results show that, on certain days, inscriptions accounted nearly 90% of transactions on Arbitrum and ZKsync Era, while 53% on Ethereum, with 99% of these inscriptions involving meme coin minting. Furthermore, we show that ZKsync and Arbitrum saw lower median gas fees during these surges. ZKsync Era, a ZK-rollup, showed a greater fee reduction than the optimistic rollups studied -- Arbitrum, Base, and Optimism.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-Rollup MEV: Non-Atomic Arbitrage Across L2 Blockchains</title>
<link>https://arxiv.org/abs/2406.02172</link>
<guid>https://arxiv.org/abs/2406.02172</guid>
<content:encoded><![CDATA[
<div> 关键词：Layer-2区块链, 三明治攻击, 价格差异, 套利机会, LVR指标

<br /><br />总结:<br />
本文研究了Layer-2（L2）区块链上的非原子MEV（最大可提取价值），通过测量跨Rollup和DEX-CEX之间的套利机会来量化。近年来，交易活动从以太坊转向Rollups，尽管Rollups上的交易量较低，但其频率更高。文章分析了L2上的交易成本和跨Rollup与DEX-CEX的价格差异，发现超过500,000次未被利用的套利机会。这些机会平均持续10到20个区块，需要修改LVR（损失对再平衡）指标以避免重复计算。研究发现，Arbitrum、Base和Optimism的套利机会占交易量的0.03%至0.05%，而ZKsync的套利机会波动在0.25%左右。 <div>
arXiv:2406.02172v2 Announce Type: replace 
Abstract: This study quantifies the potential non-atomic MEV on Layer-2 (L2) blockchains by measuring the arbitrage opportunities between cross-rollup and DEX-CEX. Over recent years, we observe a shift in trading activities from Ethereum to rollups, with swaps on rollups occurring 2-3 times more frequently, albeit with lower trade volumes. By analyzing the costs of swap on L2s and price discrepancies cross-rollup and DEX-CEX, we identify more than 500 000 unexplored arbitrage opportunities. In particular, we find that these opportunities persist, on average, for 10 to 20 blocks, necessitating the modification of the Loss Versus Rebalancing (LVR) metric to prevent double-counting. Our findings indicate that the arbitrage opportunities in Arbitrum, Base, and Optimism range between 0.03% and 0.05% of the trading volume, while in the ZKsync it fluctuates around 0.25%.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>From promise to practice: realizing high-performance decentralized training</title>
<link>https://arxiv.org/abs/2410.11998</link>
<guid>https://arxiv.org/abs/2410.11998</guid>
<content:encoded><![CDATA[
<div> 关键词: 去中心化训练, 深度神经网络, Adam算法, 变异积累技术, 迭代预算

<br /><br />总结:<br />
本文研究了去中心化训练深度神经网络的优势，并指出通信拓扑、计算模式和优化算法三个关键因素对提升性能的重要性。作者提出了一种去中心化的Adam算法，支持通信与计算的重叠，证明了其收敛性，并引入变异积累技术以应对小批量本地数据带来的高方差问题。实验部署显示，该方法在多达64个GPU的集群中展现出更优的运行时间和泛化性能，在固定迭代预算下具有显著优势。 <div>
arXiv:2410.11998v1 Announce Type: new 
Abstract: Decentralized training of deep neural networks has attracted significant attention for its theoretically superior scalability over synchronous data-parallel methods like All-Reduce. However, realizing this potential in multi-node training is challenging due to the complex design space that involves communication topologies, computation patterns, and optimization algorithms. This paper identifies three key factors that can lead to speedups over All-Reduce training and constructs a runtime model to determine when, how, and to what degree decentralization can yield shorter per-iteration runtimes. Furthermore, to support the decentralized training of transformer-based models, we study a decentralized Adam algorithm that allows for overlapping communications and computations, prove its convergence, and propose an accumulation technique to mitigate the high variance caused by small local batch sizes. We deploy the proposed approach in clusters with up to 64 GPUs and demonstrate its practicality and advantages in both runtime and generalization performance under a fixed iteration budget.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation</title>
<link>https://arxiv.org/abs/2410.12062</link>
<guid>https://arxiv.org/abs/2410.12062</guid>
<content:encoded><![CDATA[
<div> 'MAIF, 分布式, 意图保持, 偏好无关, 平均场控制'<br /><br />总结:<br />本文研究了分布式移动智能体队形（MAiF）问题，这是一种多智能体路径寻找变体，目标是在有限通信和部分观测条件下，让多个智能体快速达到目标同时保持期望队形。文章提出了一种名为平均场控制与包络Q学习（MFC-EQ）的可扩展适应性学习框架，该框架通过平均场理论近似所有智能体的动力学，并通过包络Q学习学习一个通用的偏好无关策略。实验结果表明，MFC-EQ不仅在多个实例中优于现有的集中式MAiF基线，还能有效处理动态变化队形的复杂情况。 <div>
arXiv:2410.12062v1 Announce Type: new 
Abstract: We study a decentralized version of Moving Agents in Formation (MAiF), a variant of Multi-Agent Path Finding aiming to plan collision-free paths for multiple agents with the dual objectives of reaching their goals quickly while maintaining a desired formation. The agents must balance these objectives under conditions of partial observation and limited communication. The formation maintenance depends on the joint state of all agents, whose dimensionality increases exponentially with the number of agents, rendering the learning process intractable. Additionally, learning a single policy that can accommodate different linear preferences for these two objectives presents a significant challenge. In this paper, we propose Mean-Field Control with Envelop $Q$-learning (MFC-EQ), a scalable and adaptable learning framework for this bi-objective multi-agent problem. We approximate the dynamics of all agents using mean-field theory while learning a universal preference-agnostic policy through envelop $Q$-learning. Our empirical evaluation of MFC-EQ across numerous instances shows that it outperforms state-of-the-art centralized MAiF baselines. Furthermore, MFC-EQ effectively handles more complex scenarios where the desired formation changes dynamically -- a challenge that existing MAiF planners cannot address.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof of Team Sprint: A Collaborative Consensus Algorithm for Reducing Energy Consumption in Blockchain Systems</title>
<link>https://arxiv.org/abs/2410.12135</link>
<guid>https://arxiv.org/abs/2410.12135</guid>
<content:encoded><![CDATA[
<div> Proof of Team Sprint 能源效率 共识算法 区块链 安全性<br /><br />总结:<br />本文介绍了名为Proof of Team Sprint (PoTS)的新共识算法，旨在解决传统工作量证明（PoW）系统中的能源低效问题。PoTS将共识机制从个体竞争转变为团队协作模式，通过组织参与者为小组来协同解决加密难题以验证交易和添加新区块，从而显著降低网络整体能耗并保持高水平的安全性和去中心化。<br />研究显示，与PoW相比，PoTS能将能耗降低N倍，其中N是每组的参与者数量。此外，PoTS还保证了奖励分配的公平性，确保持续参与和网络完整性。文章还讨论了采用PoTS的可扩展性、安全性和潜在挑战，将其定位为可持续区块链技术的一个有前景的替代方案。 <div>
arXiv:2410.12135v1 Announce Type: new 
Abstract: This paper introduces Proof of Team Sprint (PoTS), a novel consensus algorithm designed to address the significant energy inefficiencies inherent in traditional Proof of Work (PoW) systems. PoTS shifts the consensus mechanism from an individual competition model to a collaborative team-based approach. Participants are organized into groups, with each group collaboratively working to solve cryptographic puzzles required to validate transactions and add new blocks to the blockchain. This collaborative approach significantly reduces the overall energy consumption of the network while maintaining high levels of security and decentralization. Our analysis shows that PoTS can reduce energy consumption by a factor of 1/N, where N is the number of participants in each group, compared to PoW. Furthermore, PoTS maintains a fair and equitable reward distribution among participants, ensuring continued engagement and network integrity. The paper also discusses the scalability, security implications, and potential challenges of adopting PoTS, positioning it as a promising alternative for sustainable blockchain technology.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>fAmulet: Finding Finalization Failure Bugs in Polygon zkRollup</title>
<link>https://arxiv.org/abs/2410.12210</link>
<guid>https://arxiv.org/abs/2410.12210</guid>
<content:encoded><![CDATA[
<div> 零知识二层协议 最终化失败漏洞 模糊测试 行为模型 漏洞检测<br /><br />总结:<br />
本文介绍了针对零知识二层协议中最终化失败漏洞的第一项系统性研究，并定义了两种此类漏洞。研究人员开发了fAmulet工具，通过模糊测试来检测Polygon zkRollup中的最终化失败漏洞。为了有效触发这些漏洞，引入了最终化行为模型指导模糊器生成和变异交易。此外，还根据不同的漏洞定义设计了漏洞探测器。评估显示，fAmulet发现了十二个Polygon zkRollup中的零日最终化失败漏洞，并覆盖了比基线更多的代码分支。初步研究表明，fAmulet也可应用于其他零知识二层协议，如Scroll zkRollup，目前所有发现的漏洞已被相关团队确认并修复。 <div>
arXiv:2410.12210v1 Announce Type: new 
Abstract: Zero-knowledge layer 2 protocols emerge as a compelling approach to overcoming blockchain scalability issues by processing transactions through the transaction finalization process. During this process, transactions are efficiently processed off the main chain. Besides, both the transaction data and the zero-knowledge proofs of transaction executions are reserved on the main chain, ensuring the availability of transaction data as well as the correctness and verifiability of transaction executions. Hence, any bugs that cause the transaction finalization failure are crucial, as they impair the usability of these protocols and the scalability of blockchains.
  In this work, we conduct the first systematic study on finalization failure bugs in zero-knowledge layer 2 protocols, and define two kinds of such bugs. Besides, we design fAmulet, the first tool to detect finalization failure bugs in Polygon zkRollup, a prominent zero-knowledge layer 2 protocol, by leveraging fuzzing testing. To trigger finalization failure bugs effectively, we introduce a finalization behavior model to guide our transaction fuzzer to generate and mutate transactions for inducing diverse behaviors across each component (e.g., Sequencer) in the finalization process. Moreover, we define bug oracles according to the distinct bug definitions to accurately detect bugs. Through our evaluation, fAmulet can uncover twelve zero-day finalization failure bugs in Polygon zkRollup, and cover at least 20.8% more branches than baselines. Furthermore, through our preliminary study, fAmulet uncovers a zero-day finalization failure bug in Scroll zkRollup, highlighting the generality of fAmulet to be applied to other zero-knowledge layer 2 protocols. At the time of writing, all our uncovered bugs have been confirmed and fixed by Polygon zkRollup and Scroll zkRollup teams.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Temporal Graph Clustering</title>
<link>https://arxiv.org/abs/2410.12343</link>
<guid>https://arxiv.org/abs/2410.12343</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习, 时序图聚类, 图神经网络, 数据隐私, 动态图<br /><br />总结:<br />本文提出了一种名为联邦时序图聚类（FTGC）的新框架，旨在解决时序图聚类中的隐私和通信问题。该方法通过联邦学习策略实现在多个客户端上的分布式训练，同时利用时序聚合机制捕捉图结构随时间的变化。FTGC框架在保护数据隐私的同时减少了通信开销，实现了与集中式方法相当的性能。这使得它成为处理动态数据且需保护隐私的实际应用中的一个有前景解决方案。 <div>
arXiv:2410.12343v1 Announce Type: new 
Abstract: Temporal graph clustering is a complex task that involves discovering meaningful structures in dynamic graphs where relationships and entities change over time. Existing methods typically require centralized data collection, which poses significant privacy and communication challenges. In this work, we introduce a novel Federated Temporal Graph Clustering (FTGC) framework that enables decentralized training of graph neural networks (GNNs) across multiple clients, ensuring data privacy throughout the process. Our approach incorporates a temporal aggregation mechanism to effectively capture the evolution of graph structures over time and a federated optimization strategy to collaboratively learn high-quality clustering representations. By preserving data privacy and reducing communication overhead, our framework achieves competitive performance on temporal graph datasets, making it a promising solution for privacy-sensitive, real-world applications involving dynamic data.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Private Order Flows and Builder Bidding Dynamics: The Road to Monopoly in Ethereum's Block Building Market</title>
<link>https://arxiv.org/abs/2410.12352</link>
<guid>https://arxiv.org/abs/2410.12352</guid>
<content:encoded><![CDATA[
<div> 关键词: Proposer Builder Separation, PBS, MEV-Boost拍卖, 私有订单流, 市场垄断<br /><br />总结:<br />本文研究了以太坊采用的Proposer Builder Separation (PBS)框架在引入私有订单流后的效果。文章提出了一种名为MEV-Boost拍卖的不对称拍卖模型，并对2023年1月至2024年5月间的以太坊区块进行了实证分析。结果显示，私有订单流占区块价值的54.59%，且拥有更多私有订单流的构建者更有可能赢得区块并保留更大比例的利润。这导致市场逐渐形成垄断。研究发现，当前阶段的PBS未能平衡利润分配，反而将利润集中到了垄断构建者手中，而非机构质押者。 <div>
arXiv:2410.12352v1 Announce Type: new 
Abstract: Ethereum, as a representative of Web3, adopts a novel framework called Proposer Builder Separation (PBS) to prevent the centralization of block profits in the hands of institutional Ethereum stakers. Introducing builders to generate blocks based on public transactions, PBS aims to ensure that block profits are distributed among all stakers. Through the auction among builders, only one will win the block in each slot. Ideally, the equilibrium strategy of builders under public information would lead them to bid all block profits. However, builders are now capable of extracting profits from private order flows. In this paper, we explore the effect of PBS with private order flows. Specifically, we propose the asymmetry auction model of MEV-Boost auction. Moreover, we conduct empirical study on Ethereum blocks from January 2023 to May 2024. Our analysis indicates that private order flows contribute to 54.59% of the block value, indicating that different builders will build blocks with different valuations. Interestingly, we find that builders with more private order flows (i.e., higher block valuations) are more likely to win the block, while retain larger proportion of profits. In return, such builders will further attract more private order flows, resulting in a monopolistic market gradually. Our findings reveal that PBS in current stage is unable to balance the profit distribution, which just transits the centralization of block profits from institutional stakers to the monopolistic builder.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SEMSO: A Secure and Efficient Multi-Data Source Blockchain Oracle</title>
<link>https://arxiv.org/abs/2410.12540</link>
<guid>https://arxiv.org/abs/2410.12540</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链预言机, 多数据源, 数据可靠性, 贝叶斯博弈, TBLS协议<br /><br />总结:<br />本文提出了一种名为SEMSO的新型多数据源区块链预言机框架，旨在通过减少资源开销和响应时间来提高系统的效率和安全性。首先，设计了一种名为TBLS的新协议以低成本保证数据源的多样性和可靠性。其次，基于不完全信息下的贝叶斯博弈模型，对节点的数据源选择任务进行建模和求解，从而在最大化节点收益的同时提升数据聚合成功率和系统响应速度。安全分析验证了所提方案的可靠性，实验表明，在相同环境假设下，SEMSO在保持数据多样性的同时，将响应时间减少了23.5%。 <div>
arXiv:2410.12540v1 Announce Type: new 
Abstract: In recent years, blockchain oracle, as the key link between blockchain and real-world data interaction, has greatly expanded the application scope of blockchain. In particular, the emergence of the Multi-Data Source (MDS) oracle has greatly improved the reliability of the oracle in the case of untrustworthy data sources. However, the current MDS oracle scheme requires nodes to obtain data redundantly from multiple data sources to guarantee data reliability, which greatly increases the resource overhead and response time of the system. Therefore, in this paper, we propose a Secure and Efficient Multi-data Source Oracle framework (SEMSO), which nodes only need to access one data source to ensure the reliability of final data. First, we design a new off-chain data aggregation protocol TBLS, to guarantee data source diversity and reliability at low cost. Second, according to the rational man assumption, the data source selection task of nodes is modeled and solved based on the Bayesian game under incomplete information to maximize the node's revenue while improving the success rate of TBLS aggregation and system response speed. Security analysis verifies the reliability of the proposed scheme, and experiments show that under the same environmental assumptions, SEMSO takes into account data diversity while reducing the response time by 23.5\%.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Communication Consistent Approach to Signal Temporal Logic Task Decomposition in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2410.12563</link>
<guid>https://arxiv.org/abs/2410.12563</guid>
<content:encoded><![CDATA[
<div> 任务分解 通信限制 信号时间逻辑 一致性优化 分布式算法<br /><br />总结:<br />本文研究了在多智能体系统中基于信号时间逻辑（STL）表达的全局任务分解问题，特别是在通信范围有限的情况下。文中提出了将任务依赖关系表示为任务图中的边，并利用通信图来定义哪些智能体可以访问彼此的状态。当任务依赖关系与通信链不匹配时，会导致不一致。作者提出了一种任务分解机制，通过重新分配非通信智能体的任务来保持任务和通信图之间的一致性。该机制假设STL任务中的超级水平集为有界多面体，并将其转化为参数优化问题，通过分布式凸优化算法解决。文章还讨论了任务不可满足的情况，并给出了确保任务可满足的充分条件。 <div>
arXiv:2410.12563v1 Announce Type: new 
Abstract: We consider the problem of decomposing a global task assigned to a multi-agent system, expressed as a formula within a fragment of Signal Temporal Logic (STL), under range-limited communication. Given a global task expressed as a conjunction of local tasks defined over the individual and relative states of agents in the system, we propose representing task dependencies among agents as edges of a suitably defined task graph. At the same time, range-limited communication naturally induces the definition of a communication graph that defines which agents have access to each other's states. Within these settings, inconsistencies arise when a task dependency between a pair of agents is not supported by a corresponding communication link due to the limited communication range. As a result, state feedback control laws previously derived to achieve the tasks' satisfaction can not be leveraged. We propose a task decomposition mechanism to distribute tasks assigned to pairs of non-communicating agents in the system as conjunctions of tasks defined over the relative states of communicating agents, thus enforcing consistency between task and communication graphs. Assuming the super-level sets of the predicate functions composing the STL tasks are bounded polytopes, our task decomposition mechanism can be cast as a parameter optimization problem and solved via state-of-the-art decentralized convex optimization algorithms. To guarantee the soundness of our approach, we present various conditions under which the tasks defined in the applied STL fragment are unsatisfiable, and we show sufficient conditions such that our decomposition approach yields satisfiable global tasks after decomposition.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression</title>
<link>https://arxiv.org/abs/2410.12707</link>
<guid>https://arxiv.org/abs/2410.12707</guid>
<content:encoded><![CDATA[
<div> FusionLLM 去中心化训练 网络通信 模型定义 异构硬件 自动微分<br /><br />总结: 本文介绍了FusionLLM，一种为解决大型深度神经网络（尤其是大规模语言模型）训练过程中硬件资源稀缺问题而设计的去中心化训练系统。该系统通过利用地理分布的不同计算集群或单个设备中的GPU来实现。为了解决去中心化训练中遇到的系统设计和效率问题，如远程自动微分、灵活的模型定义支持、异构硬件导致的资源利用率低或慢节点问题以及网络通信速度慢等，FusionLLM采用了一种基于操作有向无环图（OP-DAG）的设计方法。此外，系统还实现了工作负载估计器、OP-Fence调度器以及自适应TopK压缩器以提高效率。实验结果表明，使用FusionLLM系统与方法在不同网络条件下进行ResNet-101和GPT-2模型训练时，相比基线方法可获得1.45至9.39倍的速度提升，同时保证了模型的收敛性。 <div>
arXiv:2410.12707v1 Announce Type: new 
Abstract: To alleviate hardware scarcity in training large deep neural networks (DNNs), particularly large language models (LLMs), we present FusionLLM, a decentralized training system designed and implemented for training DNNs using geo-distributed GPUs across different computing clusters or individual devices. Decentralized training faces significant challenges regarding system design and efficiency, including: 1) the need for remote automatic differentiation (RAD), 2) support for flexible model definitions and heterogeneous software, 3) heterogeneous hardware leading to low resource utilization or the straggler problem, and 4) slow network communication. To address these challenges, in the system design, we represent the model as a directed acyclic graph of operators (OP-DAG). Each node in the DAG represents the operator in the DNNs, while the edge represents the data dependency between operators. Based on this design, 1) users are allowed to customize any DNN without caring low-level operator implementation; 2) we enable the task scheduling with the more fine-grained sub-tasks, offering more optimization space; 3) a DAG runtime executor can implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an OP-Fence scheduler to cluster devices with similar bandwidths together and partition the DAG to increase throughput. Additionally, we propose an AdaTopK compressor to adaptively compress intermediate activations and gradients at the slowest communication links. To evaluate the convergence and efficiency of our system and algorithms, we train ResNet-101 and GPT-2 on three real-world testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental results demonstrate that our system and method can achieve 1.45 - 9.39x speedup compared to baseline methods while ensuring convergence.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Control and Coordinate Mixed Traffic Through Robot Vehicles at Complex and Unsignalized Intersections</title>
<link>https://arxiv.org/abs/2301.05294</link>
<guid>https://arxiv.org/abs/2301.05294</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习 交通拥堵 混合交通 无人车 交叉口控制<br /><br />总结:<br />本文提出了一种基于多智能体强化学习的方法来管理和协调混合交通（包括人类驾驶车辆和机器人车辆）在复杂交叉口的运行。研究结果表明，即使只有5%的无人车辆存在，也能有效防止交通拥堵的发生，而在没有无人车辆的情况下，当交通流量达到每小时200辆车时就开始出现拥堵。当无人车辆占比超过60%时，该方法的表现可与传统红绿灯系统相媲美甚至更优。此外，该方法还显示出了对突发状况和无人车辆比例变化的鲁棒性和良好的泛化能力，并成功应用于两个未见过的交叉口场景。 <div>
arXiv:2301.05294v3 Announce Type: replace 
Abstract: Intersections are essential road infrastructures for traffic in modern metropolises. However, they can also be the bottleneck of traffic flows as a result of traffic incidents or the absence of traffic coordination mechanisms such as traffic lights. Recently, various control and coordination mechanisms that are beyond traditional control methods have been proposed to improve the efficiency of intersection traffic. Amongst these methods, the control of foreseeable mixed traffic that consists of human-driven vehicles (HVs) and robot vehicles (RVs) has emerged. In this project, we propose a decentralized multi-agent reinforcement learning approach for the control and coordination of mixed traffic at real-world, complex intersections--a topic that has not been previously explored. Comprehensive experiments are conducted to show the effectiveness of our approach. In particular, we show that using 5% RVs, we can prevent congestion formation inside a complex intersection under the actual traffic demand of 700 vehicles per hour. In contrast, without RVs, congestion starts to develop when the traffic demand reaches as low as 200 vehicles per hour. When there exist more than 60% RVs in traffic, our method starts to achieve comparable or even better performance to traffic signals on the average waiting time of all vehicles at the intersection. Our method is also robust against both blackout events and sudden RV percentage drops, and enjoys excellent generalizablility, which is illustrated by its successful deployment in two unseen intersections.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Robust Blockchain Price Oracle: A Study on Human-Centric Node Selection Strategy and Incentive Mechanism</title>
<link>https://arxiv.org/abs/2309.04689</link>
<guid>https://arxiv.org/abs/2309.04689</guid>
<content:encoded><![CDATA[
<div> 匿名节点选择 安全性 服务质量 激励机制 Stackelberg博弈<br /><br />总结:<br />本文针对区块链预言机在节点选择过程中面临的安全和服务质量困境，提出了一种匿名节点选择方案。该方案通过匿名方式选择高声誉节点参与任务，确保系统安全和服务质量。同时，文章分析了支付结算和资产估值场景中各利益相关方的需求和行为动机，并基于理性人假设提出了一个Stackelberg博弈激励机制，以平衡任务发布者和执行者的收益。实验结果表明，所提方案能够将获取价格数据的方差减少约55%，同时保证系统安全和各方收益。 <div>
arXiv:2309.04689v2 Announce Type: replace 
Abstract: As a trusted middleware connecting the blockchain and the real world, the blockchain oracle can obtain trusted real-time price information for financial applications such as payment and settlement, and asset valuation on the blockchain. However, the current oracle schemes face the dilemma of security and service quality in the process of node selection, and the implicit interest relationship in financial applications leads to a significant conflict of interest between the task publisher and the executor, which reduces the participation enthusiasm of both parties and system security. Therefore, this paper proposes an anonymous node selection scheme that anonymously selects nodes with high reputations to participate in tasks to ensure the security and service quality of nodes. Then, this paper also details the interest requirements and behavioral motives of all parties in the payment settlement and asset valuation scenarios. Under the hypothesis of rational man, an incentive mechanism based on the Stackelberg game is proposed. It can achieve equilibrium under the pursuit of the revenue of task publishers and executors, thereby ensuring the revenue of all types of users and improving the enthusiasm for participation. Finally, we verify the security of the proposed scheme through security analysis. The experimental results show that the proposed scheme can reduce the variance of obtaining price data by about 55\% while ensuring security, and meeting the revenue of all parties.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoViS-Net: A Cooperative Visual Spatial Foundation Model for Multi-Robot Applications</title>
<link>https://arxiv.org/abs/2405.01107</link>
<guid>https://arxiv.org/abs/2405.01107</guid>
<content:encoded><![CDATA[
<div> 关键词：自主机器人, 视觉空间理解, 去中心化, 相对姿态估计, 局部鸟瞰图<br /><br />总结:<br />本文介绍了一种名为CoViS-Net的去中心化视觉空间基础模型，该模型能够从数据中学习空间先验知识，实现姿态估计和空间理解。CoViS-Net适用于多个自主机器人在非结构化环境中的协同操作，能够在没有现有网络基础设施的情况下实现实时计算。该模型提供相对姿态估计和局部鸟瞰图表示，即使机器人之间没有相机重叠也能工作。研究展示了CoViS-Net在多机器人编队控制任务中的应用，并提供了在线代码、模型和补充材料。 <div>
arXiv:2405.01107v3 Announce Type: replace 
Abstract: Autonomous robot operation in unstructured environments is often underpinned by spatial understanding through vision. Systems composed of multiple concurrently operating robots additionally require access to frequent, accurate and reliable pose estimates. In this work, we propose CoViS-Net, a decentralized visual spatial foundation model that learns spatial priors from data, enabling pose estimation as well as spatial comprehension. Our model is fully decentralized, platform-agnostic, executable in real-time using onboard compute, and does not require existing networking infrastructure. CoViS-Net provides relative pose estimates and a local bird's-eye-view (BEV) representation, even without camera overlap between robots (in contrast to classical methods). We demonstrate its use in a multi-robot formation control task across various real-world settings. We provide code, models and supplementary material online. https://proroklab.github.io/CoViS-Net/
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-critical Motion Planning for Collaborative Legged Loco-Manipulation over Discrete Terrain</title>
<link>https://arxiv.org/abs/2410.11023</link>
<guid>https://arxiv.org/abs/2410.11023</guid>
<content:encoded><![CDATA[
<div> 关键词：腿足机器人, 协同操作, 预测控制, 离散地形, 自适应控制<br /><br />总结:<br />本文介绍了一种针对腿足机器人在未知负载和复杂地形中进行安全运动规划的方法。该方法使用两组模型预测控制器（MPC），一组全局MPC生成团队的安全轨迹以避免障碍物，另一组去中心化MPC确保每个机器人在离散地形上的稳定步态。通过模型参考自适应全身控制器（MRA-WBC）来跟踪期望路径，并补偿未知负载带来的模型不确定性。实验结果表明，该方法能够在模拟和硬件测试中成功引导机器人团队穿越障碍物，包括平面定位和高度调整，且所有操作均在离散地形上完成。 <div>
arXiv:2410.11023v1 Announce Type: new 
Abstract: As legged robots are deployed in industrial and autonomous construction tasks requiring collaborative manipulation, they must handle object manipulation while maintaining stable locomotion. The challenge intensifies in real-world environments, where they should traverse discrete terrain, avoid obstacles, and coordinate with other robots for safe loco-manipulation. This work addresses safe motion planning for collaborative manipulation of an unknown payload on discrete terrain while avoiding obstacles. Our approach uses two sets of model predictive controllers (MPCs) as motion planners: a global MPC generates a safe trajectory for the team with obstacle avoidance, while decentralized MPCs for each robot ensure safe footholds on discrete terrain as they follow the global trajectory. A model reference adaptive whole-body controller (MRA-WBC) then tracks the desired path, compensating for model uncertainties from the unknown payload. We validated our method in simulation and hardware on a team of Unitree robots. The results demonstrate that our approach successfully guides the team through obstacle courses, requiring planar positioning and height adjustments, and all happening on discrete terrain such as stepping stones.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments</title>
<link>https://arxiv.org/abs/2410.11134</link>
<guid>https://arxiv.org/abs/2410.11134</guid>
<content:encoded><![CDATA[
<div> 功能性适应签名 隐私保护 区块链 智能合约 线性函数<br /><br />总结:<br />本文介绍了一种新型的加密原语——功能性适应签名（FAS），旨在解决卖家持有敏感数据如病历，而买家需要评估特定函数$f(x)$的问题。FAS结合了智能合约和基于适配器签名方案的优点，同时提供隐私保护。作者定义了FAS的安全属性，包括见证隐私的概念，确保买家只能获取$f(x)$而无法获取额外信息。文章提出了两种基于素数阶群和格的高效构造方法来支持线性函数，并展示了其在普通硬件上的高效执行能力。通过揭示功能加密与适配器签名之间的联系，本文为实现公平的功能销售提供了新的解决方案。 <div>
arXiv:2410.11134v1 Announce Type: new 
Abstract: In scenarios where a seller holds sensitive data $x$, like patient records, and a buyer seeks to obtain an evaluation of a function $f$ on $x$, solutions in trustless environments like blockchain fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions using tools such as adaptor signatures. The former offers atomic transactions where the buyer learns $f(x)$ upon payment. However, this approach is inefficient, costly, lacks privacy for the seller's data, and is incompatible with blockchains such as bitcoin. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an "all-or-nothing" guarantee, where the buyer fully extracts $x$ and does not support extracting $f(x)$. In this work, we bridge the gap between these approaches, developing a solution that enables fair functional sales while offering all the above properties like adaptor signatures.
  Towards this, we propose functional adaptor signatures (FAS), a novel cryptographic primitive and show how it can be used to enable functional sales. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond $f(x)$. We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge.
  We introduce two efficient constructions of FAS supporting linear functions based on groups of prime-order and lattices, that satisfy the strongest notion of witness privacy. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption and adaptor signatures. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, all operations are quite efficient even for commodity hardware.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Objective-Optimization Multi-AUV Assisted Data Collection Framework for IoUT Based on Offline Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.11282</link>
<guid>https://arxiv.org/abs/2410.11282</guid>
<content:encoded><![CDATA[
<div> 关键词：水下物联网, 多智能体, 离线强化学习, 数据收集, 能量消耗

<br /><br />总结:<br />
本文提出了一种基于多智能体离线强化学习的水下物联网（IoUT）数据收集框架，旨在解决现有方法中计算成本高和数据利用率低的问题。该框架通过最大化数据速率和信息价值（VoI），同时最小化能耗并确保碰撞避免，有效应对了动态海洋环境带来的挑战。文中引入了半通信去中心化训练与执行（SC-DTDE）范式和多智能体独立保守Q学习算法（MAICQL）。模拟实验表明，所提出的框架具有高适用性、鲁棒性和数据收集效率。 <div>
arXiv:2410.11282v1 Announce Type: new 
Abstract: The Internet of Underwater Things (IoUT) offers significant potential for ocean exploration but encounters challenges due to dynamic underwater environments and severe signal attenuation. Current methods relying on Autonomous Underwater Vehicles (AUVs) based on online reinforcement learning (RL) lead to high computational costs and low data utilization. To address these issues and the constraints of turbulent ocean environments, we propose a multi-AUV assisted data collection framework for IoUT based on multi-agent offline RL. This framework maximizes data rate and the value of information (VoI), minimizes energy consumption, and ensures collision avoidance by utilizing environmental and equipment status data. We introduce a semi-communication decentralized training with decentralized execution (SC-DTDE) paradigm and a multi-agent independent conservative Q-learning algorithm (MAICQL) to effectively tackle the problem. Extensive simulations demonstrate the high applicability, robustness, and data collection efficiency of the proposed framework.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>WPFed: Web-based Personalized Federation for Decentralized Systems</title>
<link>https://arxiv.org/abs/2410.11378</link>
<guid>https://arxiv.org/abs/2410.11378</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化学习, 邻居选择, 数据隐私, 区块链, 性能提升<br /><br />总结:<br />本文介绍了一种名为WPFed的全新去中心化、基于网络的学习框架，旨在优化客户端之间的协作。该框架采用动态通信图和加权邻居选择机制，通过局部敏感哈希（LSH）评估客户端间相似性，并根据同行排名评价模型质量，从而实现个性化最优邻居的选择。WPFed还集成了验证机制，以确保数据隐私和系统安全，同时利用区块链技术增强透明度和可验证性。实验表明，与传统联邦学习方法相比，WPFed显著提升了学习效果和系统的鲁棒性，适用于多种现实世界的数据集。 <div>
arXiv:2410.11378v1 Announce Type: new 
Abstract: Decentralized learning has become crucial for collaborative model training in environments where data privacy and trust are paramount. In web-based applications, clients are liberated from traditional fixed network topologies, enabling the establishment of arbitrary peer-to-peer (P2P) connections. While this flexibility is highly promising, it introduces a fundamental challenge: the optimal selection of neighbors to ensure effective collaboration. To address this, we introduce WPFed, a fully decentralized, web-based learning framework designed to enable globally optimal neighbor selection. WPFed employs a dynamic communication graph and a weighted neighbor selection mechanism. By assessing inter-client similarity through Locality-Sensitive Hashing (LSH) and evaluating model quality based on peer rankings, WPFed enables clients to identify personalized optimal neighbors on a global scale while preserving data privacy. To enhance security and deter malicious behavior, WPFed integrates verification mechanisms for both LSH codes and performance rankings, leveraging blockchain-driven announcements to ensure transparency and verifiability. Through extensive experiments on multiple real-world datasets, we demonstrate that WPFed significantly improves learning outcomes and system robustness compared to traditional federated learning methods. Our findings highlight WPFed's potential to facilitate effective and secure decentralized collaborative learning across diverse and interconnected web environments.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOOGD: Federated Collaboration for Both Out-of-distribution Generalization and Detection</title>
<link>https://arxiv.org/abs/2410.11397</link>
<guid>https://arxiv.org/abs/2410.11397</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习, 分布外数据, 语义偏移, 变异系数偏移, 概率密度估计<br /><br />总结:<br />本文提出了一种名为FOOGD的方法，用于处理联邦学习（FL）中分布外（OOD）数据的问题。FOOGD通过估计每个客户端的概率密度，从而获得可靠的全局分布，作为后续FL过程的指导。具体而言，FOOGD中的SM3D模块能够无约束地估计任意分布的得分模型，有效地检测语义偏移数据；而SAG模块则为局部变异系数偏移泛化和客户端性能泛化提供了不变且多样化的知识。实验验证表明，FOOGD具有三个主要优势：可靠地估计非标准化的去中心化分布、通过得分值检测语义偏移数据以及通过正则化特征提取器泛化到变异系数偏移数据。该研究项目的代码已开源。 <div>
arXiv:2410.11397v1 Announce Type: new 
Abstract: Federated learning (FL) is a promising machine learning paradigm that collaborates with client models to capture global knowledge. However, deploying FL models in real-world scenarios remains unreliable due to the coexistence of in-distribution data and unexpected out-of-distribution (OOD) data, such as covariate-shift and semantic-shift data. Current FL researches typically address either covariate-shift data through OOD generalization or semantic-shift data via OOD detection, overlooking the simultaneous occurrence of various OOD shifts. In this work, we propose FOOGD, a method that estimates the probability density of each client and obtains reliable global distribution as guidance for the subsequent FL process. Firstly, SM3D in FOOGD estimates score model for arbitrary distributions without prior constraints, and detects semantic-shift data powerfully. Then SAG in FOOGD provides invariant yet diverse knowledge for both local covariate-shift generalization and client performance generalization. In empirical validations, FOOGD significantly enjoys three main advantages: (1) reliably estimating non-normalized decentralized distributions, (2) detecting semantic shift data via score values, and (3) generalizing to covariate-shift data by regularizing feature extractor. The prejoct is open in https://github.com/XeniaLLL/FOOGD-main.git.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CroCoDai: A Stablecoin for Cross-Chain Commerce</title>
<link>https://arxiv.org/abs/2306.09754</link>
<guid>https://arxiv.org/abs/2306.09754</guid>
<content:encoded><![CDATA[
<div> 跨链交易 稳定币 去中心化金融 执行开销 链平台<br /><br />总结:<br />本文介绍了一种用于跨链商业活动的实用稳定币设计，称为CroCoDai。该设计旨在解决支持大量区块链和抵御价格波动及区块链平台故障的问题。现有跨链交易方法通过锁定资产增加财务风险，而稳定币虽能缓解价格波动风险，但受限于单一区块链平台。CroCoDai通过原型实现展示了其小额执行开销，从而提供了一个高效且稳定的跨链解决方案。 <div>
arXiv:2306.09754v4 Announce Type: replace 
Abstract: Decentralized Finance (DeFi), in which digital assets are exchanged without trusted intermediaries, has grown rapidly in value in recent years. The global DeFi ecosystem is fragmented into multiple blockchains, fueling the demand for cross-chain commerce. Existing approaches for cross-chain transactions, e.g., bridges and cross-chain deals, achieve atomicity by locking assets in escrow. However, locking up assets increases the financial risks for the participants, especially due to price fluctuations and the long latency of cross-chain transactions. Stablecoins, which are pegged to a non-volatile asset such as the US dollar, help mitigate the risk associated with price fluctuations. However, existing stablecoin designs are tied to individual blockchain platforms, and trusted parties or complex protocols are needed to exchange stablecoin tokens between blockchains.
  Our goal is to design a practical stablecoin for cross-chain commerce. Realizing this goal requires addressing two challenges. The first challenge is to support a large and growing number of blockchains efficiently. The second challenge is to be resilient to price fluctuations and blockchain platform failures. We present CroCoDai to address these challenges. We also present three prototype implementations of our stablecoin system, and show that it incurs small execution overhead.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Hybrid Model Pruning in Federated Learning through Loss Exploration</title>
<link>https://arxiv.org/abs/2405.10271</link>
<guid>https://arxiv.org/abs/2405.10271</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习, 自动化, 模型剪枝, 非IID数据, 计算效率<br /><br />总结:<br />文章介绍了AutoFLIP，一种针对联邦学习（FL）的创新方法，旨在通过自适应混合剪枝来优化计算和通信效率。面对6G网络和智能设备普及带来的挑战，如高通信成本、计算限制以及非独立同分布（non-IID）数据的复杂性，AutoFLIP通过探索联邦损失来识别并剪枝模型子结构，从而提高模型性能和加速全局收敛。实验表明，AutoFLIP在多种数据集和FL任务上不仅提高了准确性与鲁棒性，还平均减少了48.8%的计算开销和35.5%的通信成本，为FL在实际应用中的高效部署提供了可能。 <div>
arXiv:2405.10271v2 Announce Type: replace 
Abstract: The rapid proliferation of smart devices coupled with the advent of 6G networks has profoundly reshaped the domain of collaborative machine learning. Alongside growing privacy-security concerns in sensitive fields, these developments have positioned federated learning (FL) as a pivotal technology for decentralized model training. Despite its vast potential, specially in the age of complex foundation models, FL encounters challenges such as elevated communication costs, computational constraints, and the complexities of non-IID data distributions. We introduce AutoFLIP, an innovative approach that utilizes a federated loss exploration phase to drive adaptive hybrid pruning, operating in a structured and unstructured way. This innovative mechanism automatically identifies and prunes model substructure by distilling knowledge on model gradients behavior across different non-IID client losses topology, thereby optimizing computational efficiency and enhancing model performance on resource constrained scenarios. Extensive experiments on various datasets and FL tasks reveal that AutoFLIP not only efficiently accelerates global convergence, but also achieves superior accuracy and robustness compared to traditional methods. On average, AutoFLIP reduces computational overhead by 48.8% and communication costs by 35.5%, while improving global accuracy. By significantly reducing these overheads, AutoFLIP offer the way for efficient FL deployment in real-world applications for a scalable and broad applicability.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intellectual Property Blockchain Odyssey: Navigating Challenges and Seizing Opportunities</title>
<link>https://arxiv.org/abs/2410.08359</link>
<guid>https://arxiv.org/abs/2410.08359</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、知识产权、透明度、安全性、操作效率

总结:

本文深入探讨了区块链技术与保护知识产权之间的动态关系。研究通过全面的文献回顾、案例分析和论文综述，揭示了区块链对知识产权领域的深远影响。研究结果表明，将区块链应用于知识产权管理，可以显著提升透明度、安全性和运营效率。同时，文章也指出了这一领域面临的主要挑战与机遇。

研究提出了一套综合框架，旨在指导区块链技术与知识产权的有效整合，涵盖已存在或由区块链解决的技术组件，以及需要特别关注的方面。这套框架为知识产权领域的多层面操作提供了全面视角，有望重塑知识产权景观。

通过构建这个框架，文章为知识产权领域引入了系统化的新视角，确保了从不同层面的覆盖，包括但不限于运营流程、数据管理、法律合规等关键领域。这不仅有助于提升知识产权管理的现代化水平，也为相关实践者提供了宝贵的参考依据。 <div>
arXiv:2410.08359v1 Announce Type: new 
Abstract: This paper investigates the evolving relationship between protecting Intellectual Property Rights (IPRs) and blockchain technology. We conducted a comprehensive literature review, supplemented by case study analyses and research paper reviews, to understand the scope and implications of blockchain about intellectual property rights. Our study demonstrates how applying blockchain technology for IPR could revolutionize transparency, security, and operational efficiency. It also identifies the primary challenges and openings in this area. We provide an extensive framework for integrating blockchain technology with intellectual property rights and other technical components (some of which already exist or are resolved by blockchain; some might need attention), drawing on current research and best practices. This framework has the potential to give a new perspective in a structured manner for the intellectual property landscape by providing 360-degree coverage across different layers of operation.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Identifying Money Laundering Subgraphs on the Blockchain</title>
<link>https://arxiv.org/abs/2410.08394</link>
<guid>https://arxiv.org/abs/2410.08394</guid>
<content:encoded><![CDATA[
<div> 关键词：RevTrack、RevClassify、RevFilter、AML、Elliptic2

<br />
<br />总结:

本文提出了一种名为RevTrack的框架，旨在通过跟踪资金的初始发送者和最终接收者来实现大规模的反洗钱（AML）分析，从而降低成本并提高准确性。RevTrack的核心理念在于识别资金流动的起点和终点，以此作为判断其所属子图性质的关键指标。

在此基础上，作者进一步开发了RevClassify，这是一种用于子图分类的神经网络模型，能够更准确地识别可疑活动。同时，为了解决实际操作中可能缺乏可疑子图候选的问题，文章还引入了RevFilter方法。该方法通过迭代筛选合法交易来发现新的可疑子图，有效提高了在真实世界场景中的应用价值。

在Elliptic2这一新的AML标准基准上，与现有最先进的子图分类技术相比，RevClassify在成本和准确度方面均表现出显著优势。此外，RevFilter在发现新可疑子图方面的实用性得到了验证，证明了其对于实际反洗钱工作的有效性。 <div>
arXiv:2410.08394v1 Announce Type: new 
Abstract: Anti-Money Laundering (AML) involves the identification of money laundering crimes in financial activities, such as cryptocurrency transactions. Recent studies advanced AML through the lens of graph-based machine learning, modeling the web of financial transactions as a graph and developing graph methods to identify suspicious activities. For instance, a recent effort on opensourcing datasets and benchmarks, Elliptic2, treats a set of Bitcoin addresses, considered to be controlled by the same entity, as a graph node and transactions among entities as graph edges. This modeling reveals the "shape" of a money laundering scheme - a subgraph on the blockchain. Despite the attractive subgraph classification results benchmarked by the paper, competitive methods remain expensive to apply due to the massive size of the graph; moreover, existing methods require candidate subgraphs as inputs which may not be available in practice. In this work, we introduce RevTrack, a graph-based framework that enables large-scale AML analysis with a lower cost and a higher accuracy. The key idea is to track the initial senders and the final receivers of funds; these entities offer a strong indication of the nature (licit vs. suspicious) of their respective subgraph. Based on this framework, we propose RevClassify, which is a neural network model for subgraph classification. Additionally, we address the practical problem where subgraph candidates are not given, by proposing RevFilter. This method identifies new suspicious subgraphs by iteratively filtering licit transactions, using RevClassify. Benchmarking these methods on Elliptic2, a new standard for AML, we show that RevClassify outperforms state-of-the-art subgraph classification techniques in both cost and accuracy. Furthermore, we demonstrate the effectiveness of RevFilter in discovering new suspicious subgraphs, confirming its utility for practical AML.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uncertainty-Aware Active Search with a Team of Aerial Robots</title>
<link>https://arxiv.org/abs/2410.08507</link>
<guid>https://arxiv.org/abs/2410.08507</guid>
<content:encoded><![CDATA[
<div> 关键词：快速救援、大型灾害区域、无人机系统、自主搜索、不确定目标

总结:

文章主要讨论了在自然灾害后的快速救援行动中，如何有效地使用无人机系统进行搜索和救援。文章指出，现有的方法存在需要预先规划路径、依赖人工操作或仅在模拟环境中评估的问题。为解决这些问题，研究团队开发了一种分散式的主动搜索系统，该系统能够根据不确定的目标位置调整飞行轨迹，以实现快速覆盖通信受限场景。在通信可用的情况下，无人机之间共享位置信息、目标信息和目标数据，从而加速搜索过程。

实验结果显示，与基于贪婪覆盖的计划相比，在通信受限的场景下，主动搜索方法表现更优，同时在有通信支持的场景中也能保持相近的性能。这表明，该系统在提高搜索效率和生存率方面具有显著优势，特别是在通信基础设施受损的紧急情况下。研究为多无人机自主搜索系统在实际应用中的部署提供了理论基础和技术支持。 <div>
arXiv:2410.08507v1 Announce Type: new 
Abstract: Rapid search and rescue is critical to maximizing survival rates following natural disasters. However, these efforts are challenged by the need to search large disaster zones, lack of reliability in the communications infrastructure, and a priori unknown numbers of objects of interest (OOIs), such as injured survivors. Aerial robots are increasingly being deployed for search and rescue due to their high mobility, but there remains a gap in deploying multi-robot autonomous aerial systems for methodical search of large environments. Prior works have relied on preprogrammed paths from human operators or are evaluated only in simulation. We bridge these gaps in the state of the art by developing and demonstrating a decentralized active search system, which biases its trajectories to take additional views of uncertain OOIs. The methodology leverages stochasticity for rapid coverage in communication denied scenarios. When communications are available, robots share poses, goals, and OOI information to accelerate the rate of search. Extensive simulations and hardware experiments in Bloomingdale, OH, are conducted to validate the approach. The results demonstrate the active search approach outperforms greedy coverage-based planning in communication-denied scenarios while maintaining comparable performance in communication-enabled scenarios.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhanced Robot Planning and Perception through Environment Prediction</title>
<link>https://arxiv.org/abs/2410.08560</link>
<guid>https://arxiv.org/abs/2410.08560</guid>
<content:encoded><![CDATA[
<div> 关键词：移动机器人、地图构建、预测能力、学习方法、环境导航

总结:
本文主要探讨了移动机器人如何通过学习方法提高其在未知环境中的导航能力。文章首先强调了地图在机器人导航中的重要性，接着指出在没有预设地图的情况下，机器人需要通过在线构建地图来适应环境。传统方法仅依赖直接观察，而人类则能够通过识别环境模式并做出预测。文章提出，通过结合学习方法和大量训练数据，机器人可以有效地模仿人类的模式识别能力。

在第一部分中，作者介绍了如何使用几何和结构模式进行预测。利用部分观测的地图作为线索，文章展示了如何通过通用的学习方法来建模这些模式，适用于不同类型的顶部视图地图。为了提高室内导航效率，文章进一步应用了任务特定的学习方法，预测附近区域的二维占用情况，并扩展到三维点云表示进行物体重建，从仅有的部分视角预测完整物体的形状。

第二部分关注于利用空间时间模式进行预测，特别是在动态任务如目标跟踪和覆盖中实现更高效的分散式协调。文章展示了如何使用图神经网络进行更具扩展性和速度的推理。

综上所述，本文旨在通过学习方法增强移动机器人的预测能力，使其在未知环境中更加高效和安全地导航，同时实现动态任务的分散式执行。 <div>
arXiv:2410.08560v1 Announce Type: new 
Abstract: Mobile robots rely on maps to navigate through an environment. In the absence of any map, the robots must build the map online from partial observations as they move in the environment. Traditional methods build a map using only direct observations. In contrast, humans identify patterns in the observed environment and make informed guesses about what to expect ahead. Modeling these patterns explicitly is difficult due to the complexity of the environments. However, these complex models can be approximated well using learning-based methods in conjunction with large training data. By extracting patterns, robots can use direct observations and predictions of what lies ahead to better navigate an unknown environment. In this dissertation, we present several learning-based methods to equip mobile robots with prediction capabilities for efficient and safer operation. In the first part of the dissertation, we learn to predict using geometrical and structural patterns in the environment. Partially observed maps provide invaluable cues for accurately predicting the unobserved areas. We first demonstrate the capability of general learning-based approaches to model these patterns for a variety of overhead map modalities. Then we employ task-specific learning for faster navigation in indoor environments by predicting 2D occupancy in the nearby regions. This idea is further extended to 3D point cloud representation for object reconstruction. Predicting the shape of the full object from only partial views, our approach paves the way for efficient next-best-view planning.
  In the second part of the dissertation, we learn to predict using spatiotemporal patterns in the environment. We focus on dynamic tasks such as target tracking and coverage where we seek decentralized coordination between robots. We first show how graph neural networks can be used for more scalable and faster inference.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-chain Sharing of Personal Health Records: Heterogeneous and Interoperable Blockchains</title>
<link>https://arxiv.org/abs/2410.08762</link>
<guid>https://arxiv.org/abs/2410.08762</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗信息化、区块链技术、数据共享、跨链技术、物联网设备

<br /><br />
总结:本文探讨了医疗信息化时代背景下，个人健康记录（PHR）的广泛生成与区块链技术对医疗机构安全性的提升。然而，医疗机构作为独立的数据孤岛限制了PHR价值的最大化利用。随着不同医院间区块链上的数据共享需求增长，跨链数据共享成为关键挑战。文章提出了一种在异构可互操作区块链间共享PHR的方案，通过将实时PHR加密存储于星际文件系统中，简化数据共享流程，仅需执行基本操作。为解决不同区块链加密系统的差异，文章引入改进的代理重加密（PRE）算法。多维分析表明，该方案提供了强大的安全性与出色的性能。 <div>
arXiv:2410.08762v1 Announce Type: new 
Abstract: With the widespread adoption of medical informatics, a wealth of valuable personal health records (PHR) has been generated. Concurrently, blockchain technology has enhanced the security of medical institutions. However, these institutions often function as isolated data silos, limiting the potential value of PHRs. As the demand for data sharing between hospitals on different blockchains grows, addressing the challenge of cross-chain data sharing becomes crucial. When sharing PHRs across blockchains, the limited storage and computational capabilities of medical Internet of Things (IoT) devices complicate the storage of large volumes of PHRs and the handling of complex calculations. Additionally, varying blockchain cryptosystems and the risk of internal attacks further complicate the cross-chain sharing of PHRs. This paper proposes a scheme for sharing PHRs across heterogeneous and interoperable blockchains. Medical IoT devices can encrypt and store real-time PHRs in an InterPlanetary File System, requiring only simple operations for data sharing. An enhanced proxy re-encryption(PRE) algorithm addresses the differences in blockchain cryptosystems. Multi-dimensional analysis demonstrates that this scheme offers robust security and excellent performance.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rapid Grassmannian Averaging with Chebyshev Polynomials</title>
<link>https://arxiv.org/abs/2410.08956</link>
<guid>https://arxiv.org/abs/2410.08956</guid>
<content:encoded><![CDATA[
<div> 关键词：新算法、Grassmannian平均、集中式、分布式、优化

总结:
本文提出了一种新的Grassmannian平均算法——Rapid Grassmannian Averaging (RGrAv)，以及其分布式版本Decentralized Rapid Grassmannian Averaging (DRGrAv)。Grassmannian点在机器学习、计算机视觉和信号处理领域广泛用于表示通过（通常是低维）子空间的数据。现有的方法由于需要考虑非欧几何的特性，计算成本较高。RGrAv和DRGrAv通过利用问题的谱结构，仅使用小矩阵乘法和QR分解快速计算平均值，从而解决了这一挑战。文中提供了算法最优性的理论保证，并通过数值实验展示了与现有最佳方法相比，我们的算法在提供高精度解决方案的同时节省了时间。此外，实验还展示了算法在视频运动数据K-means聚类任务中的应用，证明了RGrAv和DRGrAv是处理一般Grassmannian平均任务的强大工具。 <div>
arXiv:2410.08956v1 Announce Type: new 
Abstract: We propose new algorithms to efficiently average a collection of points on a Grassmannian manifold in both the centralized and decentralized settings. Grassmannian points are used ubiquitously in machine learning, computer vision, and signal processing to represent data through (often low-dimensional) subspaces. While averaging these points is crucial to many tasks (especially in the decentralized setting), existing methods unfortunately remain computationally expensive due to the non-Euclidean geometry of the manifold. Our proposed algorithms, Rapid Grassmannian Averaging (RGrAv) and Decentralized Rapid Grassmannian Averaging (DRGrAv), overcome this challenge by leveraging the spectral structure of the problem to rapidly compute an average using only small matrix multiplications and QR factorizations. We provide a theoretical guarantee of optimality and present numerical experiments which demonstrate that our algorithms outperform state-of-the-art methods in providing high accuracy solutions in minimal time. Additional experiments showcase the versatility of our algorithms to tasks such as K-means clustering on video motion data, establishing RGrAv and DRGrAv as powerful tools for generic Grassmannian averaging.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockMEDC: Blockchain Smart Contracts for Securing Moroccan Higher Education Digital Certificates</title>
<link>https://arxiv.org/abs/2410.07258</link>
<guid>https://arxiv.org/abs/2410.07258</guid>
<content:encoded><![CDATA[
<div> 关键词：Morocco、Vision 2030、Pacte ESRI 2030、BlockMEDC、区块链

总结:

本文聚焦于摩洛哥为实现其2030年数字愿景所采取的战略举措。摩洛哥通过“Maroc Digital 2030”计划，旨在将国家定位为地区数字技术领导者，重点提升数字基础设施，促进创新并加强数字技能。同时，2023年推出的“Pacte ESRI 2030”战略，旨在通过整合最新数字技术来改造高等教育、研究和创新领域。

为了与这些国家级策略相协调，文章介绍了一项名为“BlockMEDC”的创新项目，这是一个基于区块链技术的系统，用于保护和管理摩洛哥教育领域的电子证书。该系统利用以太坊智能合约和星际文件系统（InterPlanetary File System）自动化了学术证书的发行、管理和验证流程，覆盖了摩洛哥的多所大学。

BlockMEDC解决了一系列关键问题，包括文档的真实性、手动验证的繁琐以及缺乏互操作性等，提供了一个安全、透明且成本效益高的解决方案，这与摩洛哥教育部门的数字化转型目标紧密相关。 <div>
arXiv:2410.07258v1 Announce Type: new 
Abstract: Morocco's Vision 2030, known as Maroc Digital 2030, aims to position the country as a regional leader in digital technology by boosting digital infrastructure, fostering innovation, and advancing digital skills. Complementing this initiative, the Pacte ESRI 2030 strategy, launched in 2023, seeks to transform the higher education, research, and innovation sectors by integrating state-of-the-art digital technologies. In alignment with these national strategies, this paper introduces BlockMEDC, a blockchain-based system for securing and managing Moroccan educational digital certificates. Leveraging Ethereum smart contracts and the InterPlanetary File System, BlockMEDC automates the issuance, management, and verification of academic credentials across Moroccan universities. The proposed system addresses key issues such as document authenticity, manual verification, and lack of interoperability, delivering a secure, transparent, and cost-effective solution that aligns with Morocco's digital transformation goals for the education sector.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Boosting the Performance of Decentralized Federated Learning via Catalyst Acceleration</title>
<link>https://arxiv.org/abs/2410.07272</link>
<guid>https://arxiv.org/abs/2410.07272</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning、DFedCata、Catalyst Acceleration、Moreau envelope function、Nesterov's extrapolation step

<br /><br />
总结:
本文提出了一种名为DFedCata的加速分布式联邦学习算法，以解决分布式联邦学习中数据异质性导致的模型聚合方差增大、训练收敛速度慢和测试泛化性能差的问题。DFedCata由两个主要组件组成：Moreau envelope函数，用于解决由数据异质性引起客户端参数不一致的问题；以及Nesterov的外推步骤，用于加速聚合阶段。理论分析证明了算法的优化误差界和泛化误差界，为算法的性质提供了更深入的理解，并从理论上探讨了超参数选择。实验结果显示，DFedCata在CIFAR10/100上不同非iid数据分布下，不仅在收敛速度上有优势，而且在泛化性能上也表现出色。此外，实验证实了DFedCata的理论特性。

通过引入Catalyst加速方法，DFedCata有效地处理了数据异质性带来的问题，通过Moreau envelope函数优化参数一致性，使用Nesterov外推加速聚合过程。理论与实验结果均表明，该算法在分布式联邦学习场景下具有显著的性能提升，特别是在处理非iid数据分布时，能有效提高训练效率和模型泛化能力。 <div>
arXiv:2410.07272v1 Announce Type: new 
Abstract: Decentralized Federated Learning has emerged as an alternative to centralized architectures due to its faster training, privacy preservation, and reduced communication overhead. In decentralized communication, the server aggregation phase in Centralized Federated Learning shifts to the client side, which means that clients connect with each other in a peer-to-peer manner. However, compared to the centralized mode, data heterogeneity in Decentralized Federated Learning will cause larger variances between aggregated models, which leads to slow convergence in training and poor generalization performance in tests. To address these issues, we introduce Catalyst Acceleration and propose an acceleration Decentralized Federated Learning algorithm called DFedCata. It consists of two main components: the Moreau envelope function, which primarily addresses parameter inconsistencies among clients caused by data heterogeneity, and Nesterov's extrapolation step, which accelerates the aggregation phase. Theoretically, we prove the optimization error bound and generalization error bound of the algorithm, providing a further understanding of the nature of the algorithm and the theoretical perspectives on the hyperparameter choice. Empirically, we demonstrate the advantages of the proposed algorithm in both convergence speed and generalization performance on CIFAR10/100 with various non-iid data distributions. Furthermore, we also experimentally verify the theoretical properties of DFedCata.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain and Artificial Intelligence based System for Halal Food Traceability</title>
<link>https://arxiv.org/abs/2410.07305</link>
<guid>https://arxiv.org/abs/2410.07305</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、人工智能、Halal食品、供应链追溯、原料溯源

<br />
<br />
总结:本文探讨了Halal食品市场的需求增长及其面临的挑战，尤其是消费者对产品真伪的疑虑。为解决这一问题，作者提出了一种结合区块链技术和人工智能的创新系统。该系统旨在通过提供供应链中所有操作和流程的可追溯性，以及对原料来源的追踪，确保Halal食品的正宗性。通过在本地超市进行的测试，结果显示该解决方案有效，并得到了测试者的积极反馈，表明其有潜力在实际环境中实施。此系统利用区块链的分布式账本特性，确保信息的不可篡改性，同时AI则用于模式识别，共同构建起信任桥梁，促进Halal食品市场的健康发展。 <div>
arXiv:2410.07305v1 Announce Type: new 
Abstract: The demand of the halal food products is increasing rapidly around the world. The consumption of halal food product is just not among the Muslims but also among non-Muslims, due to the purity of the halal food products. However, there are several challenges that are faced by the halal food consumers. The challenges raise a doubt among the halal food consumers about the authenticity of the product being halal. Therefore, a solution that can address these issues and can establish trust between consumers and producers. Blockchain technology can provide a distributed ledger of an immutable record of the information. Artificial intelligence supports developing a solution for pattern identification. The proposed research utilizes blockchain an artificial intelligence-based system for developing a system that ensure the authenticity of the halal food products by providing the traceability related to all the operations and processes of the supply chain and sourcing the raw material. The proposed system has been tested with a local supermarket. The results and tests of the developed solution seemed effective and the testers expressed interest in real-world implementation of the proposed system.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revisiting the Primitives of Transaction Fee Mechanism Design</title>
<link>https://arxiv.org/abs/2410.07566</link>
<guid>https://arxiv.org/abs/2410.07566</guid>
<content:encoded><![CDATA[
<div> 关键词：交易费机制设计、矿工、用户、协同策略、不可离链影响证明

总结:

本文探讨了区块链中由不信任的矿工运行的交易纳入拍卖机制的设计。首先，作者提出了一种新的评估标准——“不可离链影响证明”，指出了在当前的评估标准下，以太坊改进提案EIP-1559并不能满足这一要求。因为一个能够最大化预期收益的矿工可能会通过威胁离链转移资金给其增加额外收入来误导竞标者。

其次，文章重新审视了基于多方计算的第二价格拍卖机制，虽然该机制不符合前文提出的“简单对矿工”的标准，但作者发现，如果允许矿工直接设定保留价，该机制不仅能满足“简单对用户和矿工”的条件，还能满足“不可离链影响证明”的要求。

最后，文章指出，要同时满足所有已考虑的属性以及“不可离链影响证明”这一新标准，即使在供给无限的情况下，甚至在向矿工征询意见后，也没有任何机制能实现这一目标。这表明在设计交易费机制时需要权衡多种因素，包括安全性、公平性以及操作的复杂性。 <div>
arXiv:2410.07566v1 Announce Type: new 
Abstract: Transaction Fee Mechanism Design studies auctions run by untrusted miners for transaction inclusion in a blockchain. Under previously-considered desiderata, an auction is considered `good' if, informally-speaking, each party (i.e., the miner, the users, and coalitions of both miners and users) has no incentive to deviate from the fixed and pre-determined protocol.
  In this paper, we propose a novel desideratum for transaction fee mechanisms. We say that a TFM is off-chain influence proof when the miner cannot achieve additional revenue by running a separate auction off-chain. While the previously-highlighted EIP-1559 is the gold-standard according to prior desiderata, we show that it does not satisfy off-chain influence proofness. Intuitively, this holds because a Bayesian revenue-maximizing miner can strictly increase profits by persuasively threatening to censor any bids that do not transfer a tip directly to the miner off-chain.
  On the other hand, we reconsider the Cryptographic (multi-party computation assisted) Second Price Auction mechanism, which is technically not `simple for miners' according to previous desiderata (since miners may wish to set a reserve by fabricating bids). We show that, in a slightly different model where the miner is allowed to set the reserve directly, this auction satisfies simplicity for users and miners, and off-chain influence proofness.
  Finally, we prove a strong impossibility result: no mechanism satisfies all previously-considered properties along with off-chain influence proofness, even with unlimited supply, and even after soliciting input from the miner.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Cloud in the Sky: Geo-Aware On-board Data Services for LEO Satellites</title>
<link>https://arxiv.org/abs/2410.07586</link>
<guid>https://arxiv.org/abs/2410.07586</guid>
<content:encoded><![CDATA[
<div> 关键词：卫星数据基础设施、区块链、直接到细胞连接、低地球轨道、分布式交易

<br /><br />
总结:
本文提出了一种为提供通信服务（如直接到细胞连接）的低地球轨道（LEO）星座设计的卫星数据基础设施架构与协议。该设计充分利用了LEO卫星在地球上未被居住地区（如海洋）上空运行时的未使用或利用率低的计算和通信资源。通过利用区块链技术支持的分布式交易，文章展示了如何在该架构上高效运行智能合约服务。不同于其他区块链系统，迁移账本不仅是为了应对故障，还定期且连续地进行，以适应卫星在轨道上的移动和进入或离开区块链服务区域的情况。文章通过模拟展示了如何使用不同大小的动态地理感知服务区域来控制消息和区块链处理的开销。这一创新方法为卫星网络提供了更高效的资源管理和服务交付机制。 <div>
arXiv:2410.07586v1 Announce Type: new 
Abstract: We propose an architecture with accompanying protocol for on-board satellite data infrastructure designed for Low Earth Orbit (LEO) constellations offering communication services, such as direct-to-cell connectivity. Our design leverages the unused or under-used computing and communication resources of LEO satellites that are orbiting over uninhabited parts of the earth, like the oceans. We show how blockchain-backed distributed transactions can be run efficiently on this architecture to offer smart contract services. A key aspect of the proposed architecture that sets it apart from other blockchain systems is that migration of the ledger is not done solely to recover from failures. Rather, migration is also performed periodically and continuously as the satellites circle around in their orbits and enter and leave the blockchain service area. We show in simulations how message and blockchain processing overhead can be contained using different sizes of dynamic geo-aware service areas.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedEP: Tailoring Attention to Heterogeneous Data Distribution with Entropy Pooling for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2410.07678</link>
<guid>https://arxiv.org/abs/2410.07678</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、非独立同分布、Federated Entropy Pooling、Kullback-Leibler（KL）散度、全局数据分布

总结:
本文聚焦于解决联邦学习(Federated Learning, FL)中非独立同分布(non-IID)问题，特别是针对去中心化联邦学习(Decentralized FL, DFL)场景。研究发现，数据分布的不均匀性导致了模型收敛速度减慢和性能下降。为了应对这一挑战，文章提出了一种创新的去中心化联邦学习聚合算法——Federated Entropy Pooling (FedEP)。

FedEP通过引入局部数据分布的统计特性来缓解客户端漂移问题，而不是直接使用实际数据。每个客户端在训练前使用高斯混合模型(Gaussian Mixture Model, GMM)对本地分布进行拟合，并与邻居共享这些统计特性。之后，每个节点试图拟合全球数据分布。在聚合阶段，每个节点计算其本地数据分布与拟合后的全球数据分布之间的Kullback-Leibler（KL）散度，以此作为权重生成聚合模型。

实验结果表明，FedEP能够实现更快的收敛速度并展现出优于现有方法的测试性能。这一研究为解决非IID问题提供了新的思路，尤其是对于去中心化联邦学习环境而言，具有重要的实践价值和理论意义。 <div>
arXiv:2410.07678v1 Announce Type: new 
Abstract: Federated Learning (FL) performance is highly influenced by data distribution across clients, and non-Independent and Identically Distributed (non-IID) leads to a slower convergence of the global model and a decrease in model effectiveness. The existing algorithms for solving the non-IID problem are focused on the traditional centralized FL (CFL), where a central server is used for model aggregation. However, in decentralized FL (DFL), nodes lack the overall vision of the federation. To address the non-IID problem in DFL, this paper proposes a novel DFL aggregation algorithm, Federated Entropy Pooling (FedEP). FedEP mitigates the client drift problem by incorporating the statistical characteristics of local distributions instead of any actual data. Prior to training, each client conducts a local distribution fitting using a Gaussian Mixture Model (GMM) and shares the resulting statistical characteristics with its neighbors. After receiving the statistical characteristics shared by its neighbors, each node tries to fit the global data distribution. In the aggregation phase, each node calculates the Kullback-Leibler (KL) divergences of the local data distribution over the fitted global data distribution, giving the weights to generate the aggregated model. Extensive experiments have demonstrated that FedEP can achieve faster convergence and show higher test performance than state-of-the-art approaches.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ormer: A Manipulation-resistant and Gas-efficient Blockchain Pricing Oracle for DeFi</title>
<link>https://arxiv.org/abs/2410.07893</link>
<guid>https://arxiv.org/abs/2410.07893</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化金融（DeFi）、时间加权平均价格（TWAP）、价格操纵攻击、中值估计算法（Ormer）

<br /><br />
总结:

文章主要探讨了区块链Oracle在去中心化金融（DeFi）中的重要性以及当前广泛使用的基于时间加权平均价格（TWAP）的Oracle面临的价格操纵攻击风险。针对这一问题，作者提出了一种新型的链上高效定价算法（Ormer），旨在通过利用分段抛物线公式和融合不同观察窗口大小的估计来准确估算实时资产价格流的中值，从而减少价格误差和延迟。相较于TWAP，Ormer在实证分析中显著降低了平均绝对价格误差（减少了15.3%）和时间延迟（减少了49.3%）。此外，为了优化智能合约设计并确保存储需求的稳定性，不随价格观测数量变化，作者还提出了针对Ormer的优化策略。

<br /><br /> <div>
arXiv:2410.07893v1 Announce Type: new 
Abstract: Blockchain oracle is a critical third-party web service for Decentralized Finance (DeFi) protocols. Oracles retrieve external information such as token prices from exchanges and feed them as trusted data sources into smart contracts, enabling core DeFi applications such as loaning protocols. Currently, arithmetic mean based time-weighted average price (TWAP) oracles are widely used in DeFi by averaging external price data with fixed time frame, which is considered reliable and gas-efficient for protocol execution. However, recent research shows that TWAP price feeds are vulnerable to price manipulation attack even with long time frame setting, which would further introduce long time delays and price errors hindering the service quality of DeFi applications. To address this issue, we propose a novel on-chain gas-efficient pricing algorithm (Ormer) that heuristically estimates the median of the current streaming asset price feed based on a piecewise-parabolic formula, while the time delay is suppressed by fusing estimations with different observation window size. Our evaluation based on Ethereum WETH/USDT swapping pair price feed shows that Ormer reduces the mean absolute price error by 15.3% and the time delay by 49.3% compared to TWAP. For gas efficiency, an optimized smart contract design and constant storage requirement regardless of the number of price observations is developed for Ormer.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Penalty-Based Method for Communication-Efficient Decentralized Bilevel Programming</title>
<link>https://arxiv.org/abs/2211.04088</link>
<guid>https://arxiv.org/abs/2211.04088</guid>
<content:encoded><![CDATA[
<div> 关键词：Bilevel编程、共识、分布式、交替梯度算法、去中心化

总结:

本文提出了一个基于惩罚函数的去中心化算法，旨在解决具有理论保证的共识双层优化问题。该方法在去中心化的网络环境中发展了一种分布式交替梯度类型算法来解决共识双层编程问题。其核心特征是通过去中心化的矩阵向量乘法和少量向量通信估计惩罚函数的超梯度。这种方法将估计集成到求解原问题惩罚形式化后的交替算法中。在适当的步长和惩罚参数下，理论框架确保了在各种凸性条件下非渐近收敛至原始问题的最优解。该理论结果强调了去中心化双层优化迭代复杂性的改进，同时高效利用向量通信。

文章主要贡献包括：

1. **算法设计**：提出一种基于惩罚函数的去中心化算法，能够有效解决共识双层优化问题。
   
2. **理论分析**：证明了在特定条件下的非渐近收敛性，确保算法的有效性和可靠性。
   
3. **步骤优化**：强调了在保证算法性能的同时，对通信成本的优化，通过减少中心节点的通信负担。
   
4. **实践验证**：通过实际案例展示算法在真实世界场景中的良好表现，证实了其实际应用价值。

该研究不仅丰富了双层优化问题的理论基础，也为实际应用提供了新的策略和工具，特别是在需要低通信开销和高扩展性的场景下。 <div>
arXiv:2211.04088v4 Announce Type: replace 
Abstract: Bilevel programming has recently received attention in the literature due to its wide range of applications, including reinforcement learning and hyper-parameter optimization. However, it is widely assumed that the underlying bilevel optimization problem is solved either by a single machine or, in the case of multiple machines connected in a star-shaped network, i.e., in a federated learning setting. The latter approach suffers from a high communication cost on the central node (e.g., parameter server). Hence, there is an interest in developing methods that solve bilevel optimization problems in a communication-efficient, decentralized manner. To that end, this paper introduces a penalty function-based decentralized algorithm with theoretical guarantees for this class of optimization problems. Specifically, a distributed alternating gradient-type algorithm for solving consensus bilevel programming over a decentralized network is developed. A key feature of the proposed algorithm is the estimation of the hyper-gradient of the penalty function through decentralized computation of matrix-vector products and a few vector communications. The estimation is integrated into an alternating algorithm for solving the penalized reformulation of the bilevel optimization problem. Under appropriate step sizes and penalty parameters, our theoretical framework ensures non-asymptotic convergence to the optimal solution of the original problem under various convexity conditions. Our theoretical result highlights improvements in the iteration complexity of decentralized bilevel optimization, all while making efficient use of vector communication. Empirical results demonstrate that the proposed method performs well in real-world settings.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SelfFed: Self-supervised Federated Learning for Data Heterogeneity and Label Scarcity in IoMT</title>
<link>https://arxiv.org/abs/2307.01514</link>
<guid>https://arxiv.org/abs/2307.01514</guid>
<content:encoded><![CDATA[
<div> 关键词：自监督学习、联邦学习、数据异质性、标签稀缺、医疗物联网

<br /><br />
总结:
文章提出了一种名为SelfFed的框架，专为医疗物联网（IoMT）设计。该框架分为两个阶段：预训练和微调。预训练阶段采用分布式方式，利用基于Swin Transformer的编码器进行增强建模，旨在解决数据异质性问题。微调阶段引入对比网络和新颖聚合策略，用于在有限标注数据上进行目标任务训练，以克服标签稀缺问题。实验在公开的医疗影像数据集上进行，结果表明，与现有基线相比，SelfFed框架在非独立同分布（non-IID）数据和标签稀缺情况下表现更优。特别是在Retina和COVID-FL数据集上，该方法分别实现了最大8.8%和4.1%的性能提升。即使在少量（10%）标注实例上训练，SelfFed也超越了现有基线，证明了其在资源受限环境下的有效性和适应性。 <div>
arXiv:2307.01514v2 Announce Type: replace 
Abstract: Self-supervised learning in federated learning paradigm has been gaining a lot of interest both in industry and research due to the collaborative learning capability on unlabeled yet isolated data. However, self-supervised based federated learning strategies suffer from performance degradation due to label scarcity and diverse data distributions, i.e., data heterogeneity. In this paper, we propose the SelfFed framework for Internet of Medical Things (IoMT). Our proposed SelfFed framework works in two phases. The first phase is the pre-training paradigm that performs augmentive modeling using Swin Transformer based encoder in a decentralized manner. The first phase of SelfFed framework helps to overcome the data heterogeneity issue. The second phase is the fine-tuning paradigm that introduces contrastive network and a novel aggregation strategy that is trained on limited labeled data for a target task in a decentralized manner. This fine-tuning stage overcomes the label scarcity problem. We perform our experimental analysis on publicly available medical imaging datasets and show that our proposed SelfFed framework performs better when compared to existing baselines concerning non-independent and identically distributed (IID) data and label scarcity. Our method achieves a maximum improvement of 8.8% and 4.1% on Retina and COVID-FL datasets on non-IID dataset. Further, our proposed method outperforms existing baselines even when trained on a few (10%) labeled instances.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockEmulator: An Emulator Enabling to Test Blockchain Sharding Protocols</title>
<link>https://arxiv.org/abs/2311.03612</link>
<guid>https://arxiv.org/abs/2311.03612</guid>
<content:encoded><![CDATA[
<div> 关键词：BlockEmulator、区块链模拟器、共识算法、区块链分片、实验平台

<br />
<br />总结:

本文介绍了一款名为BlockEmulator的新型区块链模拟器，旨在为研究者提供一个开发和评估新共识算法以及区块链分片系统新协议的实验平台。其特点在于采用轻量级区块链架构，使开发者能够专注于实现新协议或机制，而无需过多关注底层技术细节。BlockEmulator通过层次化模块和提供的编程接口，大大降低了新协议实现的难度。

在验证BlockEmulator的正确性时，作者通过理论分析与实验结果的对比，证明了模拟结果的准确性。进一步的实验展示了该工具在衡量吞吐量、交易确认延迟、跨分片交易比例、交易池排队状态、区块链分片工作负载分布等关键指标方面的应用价值。

此外，BlockEmulator已被开源发布在GitHub上，鼓励社区参与，促进区块链技术的研究与发展。

总之，BlockEmulator为区块链领域的研究提供了有力工具，不仅简化了新协议的开发流程，还支持了对区块链系统性能和行为的深入研究，为推动区块链技术进步做出了贡献。 <div>
arXiv:2311.03612v3 Announce Type: replace 
Abstract: Numerous blockchain simulators have been proposed to allow researchers to simulate mainstream blockchains. However, we have not yet found a testbed that enables researchers to develop and evaluate their new consensus algorithms or new protocols for blockchain sharding systems. To fill this gap, we developed BlockEmulator, which is designed as an experimental platform, particularly for emulating blockchain sharding mechanisms. BlockEmulator adopts a lightweight blockchain architecture so developers can only focus on implementing their new protocols or mechanisms. Using layered modules and useful programming interfaces offered by BlockEmulator, researchers can implement a new protocol with minimum effort. Through experiments, we test various functionalities of BlockEmulator in two steps. Firstly, we prove the correctness of the emulation results yielded by BlockEmulator by comparing the theoretical analysis with the observed experiment results. Secondly, other experimental results demonstrate that BlockEmulator can facilitate measuring a series of metrics, including throughput, transaction confirmation latency, cross-shard transaction ratio, the queuing status of transaction pools, workload distribution across blockchain shards, etc. We have made BlockEmulator open-source in Github.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Remeasuring the Arbitrage and Sandwich Attacks of Maximal Extractable Value in Ethereum</title>
<link>https://arxiv.org/abs/2405.17944</link>
<guid>https://arxiv.org/abs/2405.17944</guid>
<content:encoded><![CDATA[
<div> 关键词：Maximal Extractable Value（MEV）、区块链生态系统、盈利能力识别算法、私有交易架构、回滚机制

总结:
本文聚焦于Maximal Extractable Value（MEV）在区块链生态系统的驱动作用，特别是以太坊中的MEV现象。文章首先指出当前识别MEV活动的方法存在依赖于笨拙的规则基模式的问题，导致误报和漏报；同时，早期研究基于的以太坊阶段在合并后已不再适用。为解决这些挑战，作者创新性地提出了一个盈利能力识别算法，并基于此设计了两个强大的算法来识别在最大数据集上的MEV活动。

通过分析识别结果，研究全面描绘了以太坊MEV生态系统的整体图景，探讨了私有交易架构的影响以及回滚机制的采用情况。研究结果为未来MEV相关工作提供了洞察，揭示了MEV活动对区块链生态系统的重要性及其潜在影响。

文章的主要贡献在于提供了一种更准确、有效的MEV活动识别方法，以及对MEV生态系统深入的分析，为后续研究者提供了宝贵的参考信息。通过改进MEV检测技术，有助于提升区块链系统的透明度和公平性，促进其长期健康发展。 <div>
arXiv:2405.17944v2 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) drives the prosperity of the blockchain ecosystem. By strategically including, excluding, or reordering transactions within blocks, block producers can extract additional value, which in turn incentivizes them to keep the decentralization of the whole blockchain platform. Before September 2022, around $675M was extracted in terms of MEV in Ethereum. Despite its importance, current work on identifying MEV activities suffers from two limitations. On the one hand, current methods heavily rely on clumsy heuristic rule-based patterns, leading to numerous false negatives or positives. On the other hand, the observations and conclusions are drawn from the early stage of Ethereum, which cannot be used as effective guiding principles after The Merge. To address these challenges, in this work, we innovatively proposed a profitability identification algorithm. Based on this, we designed two robust algorithms to identify MEV activities on our collected largest-ever dataset. Based on the identified results, we have characterized the overall landscape of the Ethereum MEV ecosystem, the impact the private transaction architectures bring in, and the adoption of back-running mechanisms. Our research sheds light on future MEV-related work.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Towards Security and Safety of Edge AI</title>
<link>https://arxiv.org/abs/2410.05349</link>
<guid>https://arxiv.org/abs/2410.05349</guid>
<content:encoded><![CDATA[
<div> 关键词：AI应用、边缘计算、安全、性能瓶颈、集成

总结:

本文探讨了高级人工智能(AI)应用的普及及其带来的风险与性能瓶颈。随着大型语言模型(Large Language Models, LLMs)等AI应用的集中化管理，AI系统的安全性和性能面临挑战。边缘人工智能(Edge AI)作为解决这些问题的一种潜在方案，通过分布式计算提高了响应速度和隐私保护能力，但同时也带来了新的安全和可靠性问题。

文章首先分析了边缘AI面临的两大主要挑战：一是安全威胁，包括数据泄露、恶意攻击和系统脆弱性等；二是确保系统的安全性和可靠性，尤其是在缺乏集中管理的情况下，如何保证算法的正确执行和结果的可信度成为关键问题。文章指出，安全性和可靠性是边缘AI发展的核心要素，两者需要协同优化以克服现有挑战。

为推动边缘AI领域的发展，文章提出了一系列开放性研究问题，旨在鼓励科研人员探索更有效的安全防护机制、可靠性验证方法以及边缘计算环境下的系统设计策略，以构建更加安全、高效和可靠的AI生态系统。 <div>
arXiv:2410.05349v1 Announce Type: new 
Abstract: Advanced AI applications have become increasingly available to a broad audience, e.g., as centrally managed large language models (LLMs). Such centralization is both a risk and a performance bottleneck - Edge AI promises to be a solution to these problems. However, its decentralized approach raises additional challenges regarding security and safety. In this paper, we argue that both of these aspects are critical for Edge AI, and even more so, their integration. Concretely, we survey security and safety threats, summarize existing countermeasures, and collect open challenges as a call for more research in this area.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modeling Buffer Occupancy in bittide Systems</title>
<link>https://arxiv.org/abs/2410.05432</link>
<guid>https://arxiv.org/abs/2410.05432</guid>
<content:encoded><![CDATA[
<div> 关键词：bittide机制、分布式系统、弹性缓冲区、连续帧传输、逻辑同步计算

<br />
总结:
本文详细分析了bittide机制在分布式系统中实现逻辑同步计算的方式。它利用有线网络如以太网固有的连续帧传输特性，通过分散式控制系统调整各节点的本地时钟频率，确保所有节点以一致的时间概念运行。每个节点上的弹性缓冲区吸收频率变化，避免了对全局时钟的依赖。研究通过流模型分析了这些弹性缓冲区的稳态占用率，这是影响系统延迟的关键因素。文中证明了缓冲区占用率的收敛性，并推导出了稳态值的明确公式，该公式基于系统参数包括网络拓扑、物理延迟和控制器增益。这一分析为优化bittide基础分布式系统的缓冲区大小和最小化延迟提供了宝贵的见解。 <div>
arXiv:2410.05432v1 Announce Type: new 
Abstract: The bittide mechanism enables logically synchronous computation across distributed systems by leveraging the continuous frame transmission inherent to wired networks such as Ethernet. Instead of relying on a global clock, bittide uses a decentralized control system to adjust local clock frequencies, ensuring all nodes operate with a consistent notion of time by utilizing elastic buffers at each node to absorb frequency variations. This paper presents an analysis of the steady-state occupancy of these elastic buffers, a critical factor influencing system latency. Using a fluid model of the bittide system, we prove that buffer occupancy converges and derive an explicit formula for the steady-state value in terms of system parameters, including network topology, physical latencies, and controller gains. This analysis provides valuable insights for optimizing buffer sizes and minimizing latency in bittide-based distributed systems.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game of Coding: Sybil Resistant Decentralized Machine Learning with Minimal Trust Assumption</title>
<link>https://arxiv.org/abs/2410.05540</link>
<guid>https://arxiv.org/abs/2410.05540</guid>
<content:encoded><![CDATA[
<div> 关键词：编码理论、数据恢复、激励导向环境、节点数量、游戏编码框架

总结:

本文聚焦于编码理论在确保数据完整性和可靠性方面的关键作用，特别是在通信、计算和存储系统中。然而，编码理论依赖于信任假设进行数据恢复，这在新兴的去中心化系统中提出了重大挑战，因为这些系统中的信任稀缺。为解决这一问题，文章引入了“游戏编码”框架，旨在揭示激励导向环境中数据恢复策略的洞察。

文章特别关注了由一个诚实节点和多个敌对节点构成的场景。研究发现，尽管敌对节点数量增加为它们提供了更多的灵活性，但增加的权力实际上并不利于敌对节点，也不损害数据收集者，因此该方案具有抗Sybil攻击性。

此外，文章还阐述了数据收集者在接纳或拒绝输入方面的最优策略，并对敌对节点的最优噪声分布进行了特征分析。这一研究为理解在不同节点配置下编码理论的应用提供了新的视角，并为设计更安全、高效的去中心化系统提供了理论基础。 <div>
arXiv:2410.05540v1 Announce Type: new 
Abstract: Coding theory plays a crucial role in ensuring data integrity and reliability across various domains, from communication to computation and storage systems. However, its reliance on trust assumptions for data recovery poses significant challenges, particularly in emerging decentralized systems where trust is scarce. To address this, the game of coding framework was introduced, offering insights into strategies for data recovery within incentive-oriented environments. The focus of the earliest version of the game of coding was limited to scenarios involving only two nodes. This paper investigates the implications of increasing the number of nodes in the game of coding framework, particularly focusing on scenarios with one honest node and multiple adversarial nodes. We demonstrate that despite the increased flexibility for the adversary with an increasing number of adversarial nodes, having more power is not beneficial for the adversary and is not detrimental to the data collector, making this scheme sybil-resistant. Furthermore, we outline optimal strategies for the data collector in terms of accepting or rejecting the inputs, and characterize the optimal noise distribution for the adversary.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain-Enhanced Framework for Privacy and Data Integrity in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2410.05653</link>
<guid>https://arxiv.org/abs/2410.05653</guid>
<content:encoded><![CDATA[
<div> 关键词：消费者级无人机、 bushfire管理、数据隐私、澳大利亚隐私法、区块链

<br />
<br />
总结:
文章介绍了一种创新框架，旨在将消费者级无人机融入到丛林火灾管理中，同时考虑了服务改进和数据隐私保护问题，符合澳大利亚隐私法1988年规定。该系统构建了一个市场平台，其中丛林火灾管理部门作为数据消费者获取来自无人机运营商的数据。运营商作为数据提供者，其隐私通过本地差分隐私技术得到保护，确保了所有系统实体之间的隐私安全。此外，采用区块链技术处理数据和费用交换，保证了交易的公平性和不可篡改记录，增强了责任性。该框架通过概念验证实施进行了验证，展现出在大规模、实际应用中的可扩展性和适应性，适用于广泛的丛林火灾管理场景。 <div>
arXiv:2410.05653v1 Announce Type: new 
Abstract: We present an innovative framework that integrates consumer-grade drones into bushfire management, addressing both service improvement and data privacy concerns under Australia's Privacy Act 1988. This system establishes a marketplace where bushfire management authorities, as data consumers, access critical information from drone operators, who serve as data providers. The framework employs local differential privacy to safeguard the privacy of data providers from all system entities, ensuring compliance with privacy standards. Additionally, a blockchain-based solution facilitates fair data and fee exchanges while maintaining immutable records for enhanced accountability. Validated through a proof-of-concept implementation, the framework's scalability and adaptability make it well-suited for large-scale, real-world applications in bushfire management.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Scalable State Sharing Protocol for Low-Resource Validator Nodes in Blockchain Networks</title>
<link>https://arxiv.org/abs/2410.05854</link>
<guid>https://arxiv.org/abs/2410.05854</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据存储、Kademlia协议、Merkle证明、Verkle证明

总结:

本文提出了一种新的区块链网络参与协议，旨在让验证节点无需在每个节点上存储整个网络状态，以降低存储成本。该协议的核心理念是将区块链网络作为复制状态机和分布式存储系统使用，通过分布式状态和基于Kademlia启发式路由协议的高效数据检索机制来减少验证节点的存储需求。使用加密证明（如Merkle证明）允许节点验证其他节点存储的数据，而无需直接信任这些节点。

为了验证该状态共享协议的有效性，文章进行了对以太坊数据存储和访问模式的广泛定量分析。结果表明，虽然该协议显著降低了存储需求，但带来了从1.5MB到5MB不等的每区块额外带宽使用量，相当于每月额外319GB到1065GB的带宽消耗。尽管如此，这个增量仍然足够小，可以在以太坊的12秒块验证窗口内传递给所有节点并进行验证。进一步的分析显示，Merkle证明是增加带宽的主要因素。为了解决这一问题，文章还分析了转向更空间高效的Verkle证明的影响。 <div>
arXiv:2410.05854v1 Announce Type: new 
Abstract: The perpetual growth of data stored on popular blockchains such as Ethereum leads to significant scalability challenges and substantial storage costs for operators of full nodes. Increasing costs may lead to fewer independently operated nodes in the network, which poses risks to decentralization (and hence network security), but also pushes decentralized app developers towards centrally hosted API services.
  This paper introduces a new protocol that allows validator nodes to participate in a blockchain network without the need to store the full state of the network on each node. The key idea is to use the blockchain network as both a replicated state machine and as a distributed storage system. By distributing states across nodes and enabling efficient data retrieval through a Kademlia-inspired routing protocol, we reduce storage costs for validators. Cryptographic proofs (such as Merkle proofs) are used to allow nodes to verify data stored by other nodes without having to trust those nodes directly. While the protocol trades off data storage for increased network bandwidth, we show how gossiping and caching can minimize the increased bandwidth needs.
  To validate our state sharing protocol, we conduct an extensive quantitative analysis of Ethereum's data storage and data access patterns. Our findings indicate that while our protocol significantly lowers storage needs, it comes with an increased bandwidth usage ranging from 1.5 MB to 5 MB per block, translating to an additional monthly bandwidth of 319 GB to 1,065 GB. Despite this, the size remains small enough such that it can be passed to all nodes and validated within Ethereum's 12-second block validation window. Further analysis shows that Merkle proofs are the most significant contributor to the additional bandwidth. To address this concern, we also analyze the impact of switching to the more space-efficient Verkle Proofs.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Tomographic Reconstruction with Quantization</title>
<link>https://arxiv.org/abs/2410.06106</link>
<guid>https://arxiv.org/abs/2410.06106</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式重建、交替方向乘子法（ADMM）、可配置量化、K-均值聚类、JPEG压缩

<br /><br />
总结:

本文提出了一种基于分布式交替方向乘子法（ADMM）的图像重建方法，该方法通过将数据和计算任务分散到多个节点上，有效解决了传统集中式重建方法中遇到的内存限制和数据隐私问题。引入的可配置量化技术进一步增强了系统的灵活性和效率。为了优化节点间的通信效率，文中提出了基于K-均值聚类和JPEG压缩的两种量化策略。实验结果表明，这种方法在保持高重建精度的同时，能够有效降低通信开销和内存使用，实现了高效、低资源消耗的图像重建过程。这种方法特别适用于资源受限环境或对数据隐私有严格要求的应用场景。 <div>
arXiv:2410.06106v1 Announce Type: new 
Abstract: Conventional tomographic reconstruction typically depends on centralized servers for both data storage and computation, leading to concerns about memory limitations and data privacy. Distributed reconstruction algorithms mitigate these issues by partitioning data across multiple nodes, reducing server load and enhancing privacy. However, these algorithms often encounter challenges related to memory constraints and communication overhead between nodes. In this paper, we introduce a decentralized Alternating Directions Method of Multipliers (ADMM) with configurable quantization. By distributing local objectives across nodes, our approach is highly scalable and can efficiently reconstruct images while adapting to available resources. To overcome communication bottlenecks, we propose two quantization techniques based on K-means clustering and JPEG compression. Numerical experiments with benchmark images illustrate the tradeoffs between communication efficiency, memory use, and reconstruction accuracy.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>De-VertiFL: A Solution for Decentralized Vertical Federated Learning</title>
<link>https://arxiv.org/abs/2410.06127</link>
<guid>https://arxiv.org/abs/2410.06127</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Vertical Federated Learning（VFL）、De-VertiFL、模型训练、数据隐私

<br /><br />
总结:

本文介绍了De-VertiFL，一种专为垂直联邦学习（VFL）设计的新型解决方案。VFL在实际场景中尤为重要，特别是在客户端持有关于同一实体的不同但敏感数据的去中心化环境中。与传统的水平联邦学习（FL）不同，VFL关注于数据特征的差异性而非一致性。De-VertiFL的核心创新包括一种新的网络架构分布、一种创新的知识交换方案以及一个分布式联邦训练过程。

De-VertiFL允许联邦客户端共享隐藏层输出，通过这种方式，参与者可以利用中间计算结果来提高学习效率。该方法不仅在F1分数性能上优于当前最先进的方法，而且维持了去中心化和数据隐私保护的框架。研究团队使用了多种著名数据集进行评估，包括图像和表格数据，覆盖二分类和多类分类任务，证明了De-VertiFL的有效性和优越性。

通过引入这些关键组件，De-VertiFL为VFL环境下的模型训练提供了一种更为高效、灵活且安全的方法，显著提升了学习性能，同时保障了参与者的隐私安全。 <div>
arXiv:2410.06127v1 Announce Type: new 
Abstract: Federated Learning (FL), introduced in 2016, was designed to enhance data privacy in collaborative model training environments. Among the FL paradigm, horizontal FL, where clients share the same set of features but different data samples, has been extensively studied in both centralized and decentralized settings. In contrast, Vertical Federated Learning (VFL), which is crucial in real-world decentralized scenarios where clients possess different, yet sensitive, data about the same entity, remains underexplored. Thus, this work introduces De-VertiFL, a novel solution for training models in a decentralized VFL setting. De-VertiFL contributes by introducing a new network architecture distribution, an innovative knowledge exchange scheme, and a distributed federated training process. Specifically, De-VertiFL enables the sharing of hidden layer outputs among federation clients, allowing participants to benefit from intermediate computations, thereby improving learning efficiency. De-VertiFL has been evaluated using a variety of well-known datasets, including both image and tabular data, across binary and multiclass classification tasks. The results demonstrate that De-VertiFL generally surpasses state-of-the-art methods in F1-score performance, while maintaining a decentralized and privacy-preserving framework.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>blockLAW: Blockchain Technology for Legal Automation and Workflow -- Cyber Ethics and Cybersecurity Platforms</title>
<link>https://arxiv.org/abs/2410.06143</link>
<guid>https://arxiv.org/abs/2410.06143</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、blockLAW、法律自动化、网络安全、伦理问题

总结:
本文探讨了区块链技术，特别是以blockLAW形式存在的区块链，在促进法律自动化、增强网络安全以及处理伦理问题方面的作用。区块链通过其去中心化和不可篡改的特性，为简化法律程序、利用智能合约自动执行合同以及提高法律交易透明度提供了机会。它被视为更新法律流程、同时保持道德标准、解决诸如可扩展性、合规性和隐私公平等关键问题的重要工具。文章分析了区块链技术在法律结构中的最新发展，评估了其对法律程序改进和法律体系透明度保障的潜力。此外，文章强调了区块链技术如何改变法律专业人员处理敏感信息的方式，从而实现更强大、更有效、更可靠的法律程序。文章还讨论了将区块链技术整合到法律系统中时需要考虑的技术层面，包括规划、实施策略、创新、进步和趋势，提出了区块链集成框架在法律系统中的应用。

通过区块链技术的应用，可以实现法律流程的自动化，减少人为错误，提高效率；同时，确保数据的安全性和完整性，保护用户隐私；此外，区块链的透明特性有助于建立公众对法律系统的信任。然而，技术的引入也带来了一系列挑战，如法律法规的适应性、技术复杂性的管理、以及对伦理和隐私保护的考量。因此，制定合理的策略和框架至关重要，以确保区块链技术能够安全、有效地融入并提升现有的法律体系。 <div>
arXiv:2410.06143v1 Announce Type: new 
Abstract: In the current legal environment, it is essential to prioritize the protection and reliability of data to promote trust and effectiveness. This study examines how blockchain technology in the form of blockLAW can be applicable to investigate its effects on legal automation, cybersecurity, and ethical concerns. The decentralized ledger and unchangeable characteristics of Blockchain provide opportunities to simplify legal procedures, automate contract execution with smart contracts, and improve transparency in legal transactions. Blockchain is seen as a crucial instrument for updating legal processes while maintaining ethical standards, tackling issues like scalability, regulatory adherence, and ethical dilemmas such as privacy and fairness. The study examines recent developments and evaluates blockchain impact on legal structures, offering perspectives on its potential to enhance legal procedures and guarantee transparency in legal systems. It further emphasizes blockchain ability to redefine how legal professionals handle and protect sensitive information, leading to stronger, more effective, and reliable legal procedures. We have also discussed the technological considerations when it comes to blockchain integration into legal systems like integration planning, implementation strategies, innovations, advancements, trends with Blockchain Integration Framework for legal systems.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SC-Bench: A Large-Scale Dataset for Smart Contract Auditing</title>
<link>https://arxiv.org/abs/2410.06176</link>
<guid>https://arxiv.org/abs/2410.06176</guid>
<content:encoded><![CDATA[
<div> 关键词：SC-Bench、GPT-4、智能合约审计、自动化技术、机器学习

<br /><br />
总结:

文章介绍了SC-Bench，这是首个针对智能合约自动审计研究的数据集。数据集包含了5377个真实运行在以太坊区块链平台上的智能合约和15975个违反以太坊标准（ERCs）的实例。其中139个是程序员实际犯下的错误，其余则是通过系统性注入来反映不同ERC规则的错误。研究使用了GPT-4模型，首先不提供任何上下文信息，GPT-4只能检测到约0.9%的违规情况；当提供了上下文信息后，其检测比例提升至22.9%。

该结果揭示了智能合约审计领域中基于机器学习的自动化技术仍有巨大的改进空间。SC-Bench为智能合约审计的自动化研究提供了宝贵的资源，同时指出了现有技术在精确识别和定位违规情况方面的局限性。通过这个数据集和模型的应用，研究人员和开发人员可以更好地理解智能合约中的潜在风险，并推动更安全、更可靠的智能合约开发实践。 <div>
arXiv:2410.06176v1 Announce Type: new 
Abstract: There is a huge demand to ensure the compliance of smart contracts listed on blockchain platforms to safety and economic standards. Today, manual efforts in the form of auditing are commonly used to achieve this goal. ML-based automated techniques have the promise to alleviate human efforts and the resulting monetary costs. However, unlike other domains where ML techniques have had huge successes, no systematic ML techniques have been proposed or applied to smart contract auditing. We present SC-Bench, the first dataset for automated smart-contract auditing research. SC-Bench consists of 5,377 real-world smart contracts running on Ethereum, a widely used blockchain platform, and 15,975 violations of standards on Ehereum called ERCs. Out of these violations, 139 are real violations programmers made. The remaining are errors we systematically injected to reflect the violations of different ERC rules. We evaluate SC-Bench using GPT-4 by prompting it with both the contracts and ERC rules. In addition, we manually identify each violated rule and the corresponding code site (i.e., oracle) and prompt GPT-4 with the information asking for a True-or-False question. Our results show that without the oracle, GPT-4 can only detect 0.9% violations, and with the oracle, it detects 22.9% violations. These results show the potential room for improvement in ML-based techniques for smart-contract auditing.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FRESCO: Fast and Reliable Edge Offloading with Reputation-based Hybrid Smart Contracts</title>
<link>https://arxiv.org/abs/2410.06715</link>
<guid>https://arxiv.org/abs/2410.06715</guid>
<content:encoded><![CDATA[
<div> 关键词：FRESCO、区块链、可靠性、分布式边缘环境、智能合约

总结:
文章介绍了一种名为FRESCO的新框架，旨在解决移动设备在分布式不可靠边缘环境中为满足服务质量(QoS)截止时间而卸载延迟敏感应用任务时面临的挑战。FRESCO利用基于区块链的声誉系统来提高分布式边缘环境中的卸载可靠性。该系统通过历史性能跟踪边缘服务器的表现，并利用区块链共识机制确保敏感声誉信息的安全性，防止篡改。为了克服区块链共识带来的高延迟问题，FRESCO采用了混合智能合约(HSC)，在链上安全地管理声誉状态的同时，允许快速的离链卸载决策。卸载决策引擎利用声誉评分进行快速决策，基于此决策，应用延迟敏感且需要高可靠性的任务能够被分配到可靠的服务器上。FRESCO通过结合链上HSC声誉状态管理和离线SMT决策引擎，实现了在不阻碍区块链共识的情况下，快速、可靠地卸载任务。在对真实可用性轨迹和模拟应用程序的评估中，FRESCO将响应时间减少了高达7.86倍，节省了高达5.4%的能源，同时将QoS违规降至0.4%，平均决策时间为5.05毫秒。 <div>
arXiv:2410.06715v1 Announce Type: new 
Abstract: Mobile devices offload latency-sensitive application tasks to edge servers to satisfy applications' Quality of Service (QoS) deadlines. Consequently, ensuring reliable offloading without QoS violations is challenging in distributed and unreliable edge environments. However, current edge offloading solutions are either centralized or do not adequately address challenges in distributed environments. We propose FRESCO, a fast and reliable edge offloading framework that utilizes a blockchain-based reputation system, which enhances the reliability of offloading in the distributed edge. The distributed reputation system tracks the historical performance of edge servers, while blockchain through a consensus mechanism ensures that sensitive reputation information is secured against tampering. However, blockchain consensus typically has high latency, and therefore we employ a Hybrid Smart Contract (HSC) that automatically computes and stores reputation securely on-chain (i.e., on the blockchain) while allowing fast offloading decisions off-chain (i.e., outside of blockchain). The offloading decision engine uses a reputation score to derive fast offloading decisions, which are based on Satisfiability Modulo Theory (SMT). The SMT models edge resource constraints, and QoS deadlines, and can formally guarantee a feasible solution that is valuable for latency-sensitive applications that require high reliability. With a combination of on-chain HSC reputation state management and an off-chain SMT decision engine, FRESCO offloads tasks to reliable servers without being hindered by blockchain consensus. We evaluate FRESCO against real availability traces and simulated applications. FRESCO reduces response time by up to 7.86 times and saves energy by up to 5.4% compared to all baselines while minimizing QoS violations to 0.4% and achieving an average decision time of 5.05 milliseconds.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hybrid Renewable-Battery-Electrolyzer Facility under the Single Imbalance Pricing Scheme</title>
<link>https://arxiv.org/abs/2410.06773</link>
<guid>https://arxiv.org/abs/2410.06773</guid>
<content:encoded><![CDATA[
<div> 关键词：欧洲能源市场、不平衡管理、可再生能源、单不平衡定价、灵活资产

<br /><br />
总结:本文探讨了在欧洲分散式能源市场环境下，结合不可控可再生能源（RES）、电池和电解槽的混合设施的行为。研究旨在通过数学模型最大化日前瞻市场收益并最小化不平衡成本。文章采用随机场景捕捉RES输出不确定性，并提出了一种新的鲁棒方法来模拟电力系统偏差方向，这是单不平衡定价的一部分。研究结果表明，在预期有利的不平衡价格情况下，灵活资产可能会诱使故意偏离平衡。这一发现强调了在实施单不平衡定价机制时需要考虑的策略性行为风险。 <div>
arXiv:2410.06773v1 Announce Type: new 
Abstract: European energy markets are decentralized and entail balance responsibility of each market player. This stresses the importance of imbalance management of renewable energy sources (RES), as the imbalance payments can strongly reduce their profitability. According to the EU Electricity Balancing Guideline, each European transmission system operator should use the single imbalance pricing method which treats both deviation directions the same, no matter if a deviation helps the system or pushes it away from the balance. This paper aims to investigate the behavior of a hybrid facility consisting of an uncontrollable RES, a battery and an electrolyzer under such market setting. The formulated mathematical model of the hybrid facility seeks to maximize profit in the day-ahead energy market, while minimizing the imbalance costs. Uncertainty of the RES output is captured using stochastic scenarios, while the direction of the power system deviation, relevant for the imbalance pricing, is modeled using a newly proposed robust approach. Results of the case study indicate that the single imbalance pricing scheme might bring flexible assets to temptation of intentional deviations should they anticipate favorable imbalance prices.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph Network Models To Detect Illicit Transactions In Block Chain</title>
<link>https://arxiv.org/abs/2410.07150</link>
<guid>https://arxiv.org/abs/2410.07150</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、反洗钱、图注意力网络、残差网络、区块链

总结:
本文研究了加密货币领域中反洗钱与打击恐怖融资（AML/CFT）活动的挑战，特别是随着加密货币使用增加，传统基于规则的方法在检测和预防非法活动方面变得不那么有效。为此，作者提出了一种创新方法，即结合图注意力网络（GAT）与类似残差网络架构（ResNet）的模型，以提高在区块链上检测非法交易的能力。

具体而言，作者利用Elliptic Bitcoin交易数据集训练了多种模型，包括逻辑回归、随机森林、XGBoost、GCN（图卷积网络）、GAT（图注意力网络）以及他们提出的GAT-ResNet模型。研究结果表明，GAT-ResNet模型在准确性、可靠性和可扩展性方面可能优于现有的图网络模型。

这项研究为使用图相关机器学习模型来增强打击金融犯罪的努力提供了新的视角，并为未来在这方面的研究奠定了基础。通过比较不同模型的表现，研究揭示了图注意力网络架构在检测加密货币领域的非法活动中的潜在优势，为提升反洗钱系统效能提供了理论支持和实践指导。 <div>
arXiv:2410.07150v1 Announce Type: new 
Abstract: The use of cryptocurrencies has led to an increase in illicit activities such as money laundering, with traditional rule-based approaches becoming less effective in detecting and preventing such activities. In this paper, we propose a novel approach to tackling this problem by applying graph attention networks with residual network-like architecture (GAT-ResNet) to detect illicit transactions related to anti-money laundering/combating the financing of terrorism (AML/CFT) in blockchains. We train various models on the Elliptic Bitcoin Transaction dataset, implementing logistic regression, Random Forest, XGBoost, GCN, GAT, and our proposed GAT-ResNet model. Our results demonstrate that the GAT-ResNet model has a potential to outperform the existing graph network models in terms of accuracy, reliability and scalability. Our research sheds light on the potential of graph related machine learning models to improve efforts to combat financial crime and lays the foundation for further research in this area.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Immersion and Presence in the Metaverse with Over-the-Air Brain-Computer Interface</title>
<link>https://arxiv.org/abs/2303.10577</link>
<guid>https://arxiv.org/abs/2303.10577</guid>
<content:encoded><![CDATA[
<div> 关键词：脑机接口、无线边缘服务器、混合学习算法、元学习算法、资源分配

<br /><br />
总结:本文提出了一种创新框架，利用空中脑机接口(BCI)学习元宇宙用户的期望。通过解析用户的大脑活动，该框架能够优化物理资源并提升用户体验质量(QoE)。实现这一目标的关键在于，通过无线边缘服务器(WES)使用上行无线信道处理脑电图(EEG)信号，从而减轻元宇宙用户设备的计算负担。WES可以学习人类行为、调整系统配置并分配射频资源，以实现个性化的用户设置。尽管BCI具有潜力，但其固有的无线通道噪声和EEG信号不确定性使得相关资源分配和学习问题极具挑战性。本文将联合学习与资源分配问题建模为混合整数规划问题，并提出了两种算法：一种是结合学习算法，可有效求解此问题；另一种是元学习算法，能进一步利用多个用户间EEG信号的神经多样性，提高分类准确性。实验证明，基于真实BCI数据集的模拟结果充分展示了该框架的高效性，同时实现了低延迟和高EEG信号分类精度。 <div>
arXiv:2303.10577v3 Announce Type: replace 
Abstract: This article proposes a novel framework that utilizes an over-the-air Brain-Computer Interface (BCI) to learn Metaverse users' expectations. By interpreting users' brain activities, our framework can optimize physical resources and enhance Quality-of-Experience (QoE) for users. To achieve this, we leverage a Wireless Edge Server (WES) to process electroencephalography (EEG) signals via uplink wireless channels, thus eliminating the computational burden for Metaverse users' devices. As a result, the WES can learn human behaviors, adapt system configurations, and allocate radio resources to tailor personalized user settings. Despite the potential of BCI, the inherent noisy wireless channels and uncertainty of the EEG signals make the related resource allocation and learning problems especially challenging. We formulate the joint learning and resource allocation problem as a mixed integer programming problem. Our solution involves two algorithms: a hybrid learning algorithm and a meta-learning algorithm. The hybrid learning algorithm can effectively find the solution for the formulated problem. Specifically, the meta-learning algorithm can further exploit the neurodiversity of the EEG signals across multiple users, leading to higher classification accuracy. Extensive simulation results with real-world BCI datasets show the effectiveness of our framework with low latency and high EEG signal classification accuracy.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research</title>
<link>https://arxiv.org/abs/2410.03855</link>
<guid>https://arxiv.org/abs/2410.03855</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、联邦学习、群体公平性、敏感属性、数据分布

总结:

本文是一篇关于联邦学习中群体公平性的全面综述。主要关注在多元化的数据分布下，如何通过联邦学习实现不同群体间的公正结果。随着联邦学习的普及，确保模型对不同敏感属性（如性别、种族等）群体的公平性成为重要议题。文中指出，已有47项研究专门探讨了这一问题，但尚未有一份专注于此的全面综述。

首先，文章构建了一个基于数据分割、位置和实施策略的创新分类框架，系统梳理了相关研究方法。接着，文章深入探讨了这一领域面临的关键挑战及广泛考虑因素，强调了如何有效处理各种敏感群体及其交集带来的复杂性。

此外，文章还回顾了当前研究中常用的数据库和应用案例，为后续工作提供了参考。最后，文章提出未来研究的方向，着重于开发更多方法以解决联邦系统中群体公平性的复杂问题，旨在推动该领域的深入发展。

通过这一综合分析，文章不仅为现有研究提供了清晰的视角，也为未来在联邦学习中追求更高质量的群体公平性指明了路径。 <div>
arXiv:2410.03855v1 Announce Type: new 
Abstract: Group fairness in machine learning is a critical area of research focused on achieving equitable outcomes across different groups defined by sensitive attributes such as race or gender. Federated learning, a decentralized approach to training machine learning models across multiple devices or organizations without sharing raw data, amplifies the need for fairness due to the heterogeneous data distributions across clients, which can exacerbate biases. The intersection of federated learning and group fairness has attracted significant interest, with 47 research works specifically dedicated to addressing this issue. However, no dedicated survey has focused comprehensively on group fairness in federated learning. In this work, we present an in-depth survey on this topic, addressing the critical challenges and reviewing related works in the field. We create a novel taxonomy of these approaches based on key criteria such as data partitioning, location, and applied strategies. Additionally, we explore broader concerns related to this problem and investigate how different approaches handle the complexities of various sensitive groups and their intersections. Finally, we review the datasets and applications commonly used in current research. We conclude by highlighting key areas for future research, emphasizing the need for more methods to address the complexities of achieving group fairness in federated systems.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>YOLO-MARL: You Only LLM Once for Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.03997</link>
<guid>https://arxiv.org/abs/2410.03997</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、深度学习、大型语言模型、策略生成、决策协作

总结:

本文提出了一种名为“你只需要一次大型语言模型”（YOLO-MARL）的新框架，旨在利用大型语言模型（LLM）的高级任务规划能力来增强多智能体在合作游戏中的决策过程。YOLO-MARL的主要创新点在于，对于每个特定的游戏环境，它仅需要一次与LLM的交互，分别完成策略生成、状态解释和规划函数生成模块的任务，从而在多智能体策略训练阶段避免了频繁调用LLM API的成本和计算时间。

具体而言，该框架通过将LLM的决策过程前置，使得训练后的分布式小型神经网络基线策略能够独立运行，无需依赖于持续的LLM支持。这种方法在三个不同环境中进行了评估，并展示了与传统多智能体强化学习算法相比的显著性能提升。

综上所述，YOLO-MARL通过优化策略生成流程并减少对大型语言模型的依赖，为多智能体系统在复杂合作场景下的高效决策提供了新的解决方案。 <div>
arXiv:2410.03997v1 Announce Type: new 
Abstract: Advancements in deep multi-agent reinforcement learning (MARL) have positioned it as a promising approach for decision-making in cooperative games. However, it still remains challenging for MARL agents to learn cooperative strategies for some game environments. Recently, large language models (LLMs) have demonstrated emergent reasoning capabilities, making them promising candidates for enhancing coordination among the agents. However, due to the model size of LLMs, it can be expensive to frequently infer LLMs for actions that agents can take. In this work, we propose You Only LLM Once for MARL (YOLO-MARL), a novel framework that leverages the high-level task planning capabilities of LLMs to improve the policy learning process of multi-agents in cooperative games. Notably, for each game environment, YOLO-MARL only requires one time interaction with LLMs in the proposed strategy generation, state interpretation and planning function generation modules, before the MARL policy training process. This avoids the ongoing costs and computational time associated with frequent LLMs API calls during training. Moreover, the trained decentralized normal-sized neural network-based policies operate independently of the LLM. We evaluate our method across three different environments and demonstrate that YOLO-MARL outperforms traditional MARL algorithms.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Compositional Planning for Logically Constrained Multi-Agent Markov Decision Processes</title>
<link>https://arxiv.org/abs/2410.04004</link>
<guid>https://arxiv.org/abs/2410.04004</guid>
<content:encoded><![CDATA[
<div> 关键词：大型分布式系统、时间逻辑规格、Constrained Markov Decision Processes（CMDPs）、假设-保证分解、多代理环境

<br /><br />
总结:
本文探讨了设计大型分布式系统控制策略的挑战，特别是在满足关键的时间逻辑基于规格（如安全性）方面，这些规格必须以高概率实现。为了解决这个问题，文章提出了一种基于Constrained Markov Decision Processes（CMDPs）的框架，提供了一种假设-保证的分解方法，用于合成多代理环境下的去中心化控制策略，同时满足逻辑约束。该方法确保策略以高概率满足约束，并提供达到目标奖励的下限。通过实验证明，这种方法返回的策略不仅实现了接近最优的奖励，还显著减少了问题规模和执行时间，达到了约一个数量级的减少。这一成果对于提高大型分布式系统的效率和可靠性具有重要意义。

<br /><br /> <div>
arXiv:2410.04004v1 Announce Type: new 
Abstract: Designing control policies for large, distributed systems is challenging, especially in the context of critical, temporal logic based specifications (e.g., safety) that must be met with high probability. Compositional methods for such problems are needed for scalability, yet relying on worst-case assumptions for decomposition tends to be overly conservative. In this work, we use the framework of Constrained Markov Decision Processes (CMDPs) to provide an assume-guarantee based decomposition for synthesizing decentralized control policies, subject to logical constraints in a multi-agent setting. The returned policies are guaranteed to satisfy the constraints with high probability and provide a lower bound on the achieved objective reward. We empirically find the returned policies to achieve near-optimal rewards while enjoying an order of magnitude reduction in problem size and execution time.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockFound: Customized blockchain foundation model for anomaly detection</title>
<link>https://arxiv.org/abs/2410.04039</link>
<guid>https://arxiv.org/abs/2410.04039</guid>
<content:encoded><![CDATA[
<div> 关键词：BlockFound、基础模型、异常检测、区块链交易、定制设计

总结:
文章介绍了名为BlockFound的基础模型，这是一个专门用于检测区块链交易异常的新方法。与依赖于规则系统或直接应用现成大型语言模型的传统方法不同，BlockFound引入了一系列定制化的设计来适应区块链交易的独特数据结构。首先，它设计了一个模块化的分词器来处理多模态输入，平衡了不同模态的信息。其次，设计了一种定制的掩码语言学习机制进行预训练，使用RoPE嵌入和FlashAttention来处理更长的序列。

在对以太坊和索拉纳交易的广泛评估中，BlockFound展示了其在异常检测方面的卓越能力，同时保持了较低的误报率。值得注意的是，BlockFound是唯一能够以高精度在索拉纳上成功检测到异常交易的方法，而其他所有方法的检测召回分数都非常低甚至为零。这项工作不仅提供了新的区块链基础模型，还为将大型语言模型应用于区块链数据设定了新基准。 <div>
arXiv:2410.04039v1 Announce Type: new 
Abstract: We propose BlockFound, a customized foundation model for anomaly blockchain transaction detection. Unlike existing methods that rely on rule-based systems or directly apply off-the-shelf large language models, BlockFound introduces a series of customized designs to model the unique data structure of blockchain transactions. First, a blockchain transaction is multi-modal, containing blockchain-specific tokens, texts, and numbers. We design a modularized tokenizer to handle these multi-modal inputs, balancing the information across different modalities. Second, we design a customized mask language learning mechanism for pretraining with RoPE embedding and FlashAttention for handling longer sequences. After training the foundation model, we further design a novel detection method for anomaly detection. Extensive evaluations on Ethereum and Solana transactions demonstrate BlockFound's exceptional capability in anomaly detection while maintaining a low false positive rate. Remarkably, BlockFound is the only method that successfully detects anomalous transactions on Solana with high accuracy, whereas all other approaches achieved very low or zero detection recall scores. This work not only provides new foundation models for blockchain but also sets a new benchmark for applying LLMs in blockchain data.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>180 Days After EIP-4844: Will Blob Sharing Solve Dilemma for Small Rollups?</title>
<link>https://arxiv.org/abs/2410.04111</link>
<guid>https://arxiv.org/abs/2410.04111</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP-4844、数据可用性（DA）、Blob共享、成本降低、服务质量提升

<br /><br />
总结: 文章主要探讨了在以太坊网络中引入EIP-4844之后，通过使用Blob共享技术来优化数据可用性（DA）成本的问题。在实施EIP-4844后，Blob的固定大小为128KB，导致数据吞吐量低的Rollup面临两难选择：要么不充分利用Blob资源，要么减少DA提交频率。文章提出并验证了Blob共享策略，即多个Rollup共享一个Blob，能够显著改善小规模Rollup的成本和DA服务质量，有效解决了上述问题。实证分析表明，当Rollup合作进行Blob共享时，成本降低幅度超过90%，这主要归因于通过Blob共享实现的Blob基础费用平滑效果。 <div>
arXiv:2410.04111v1 Announce Type: new 
Abstract: The introduction of blobs through EIP-4844 has significantly reduced the Data Availability (DA) costs for rollups on Ethereum. However, due to the fixed size of blobs at 128 KB, rollups with low data throughput face a dilemma: they either use blobs inefficiently or decrease the frequency of DA submissions. Blob sharing, where multiple rollups share a single blob, has been proposed as a solution to this problem. This paper examines the effectiveness of blob sharing based on real-world data collected approximately six months after the implementation of EIP-4844. By simulating cost changes using a simple blob sharing format, we demonstrate that blob sharing can substantially improve the costs and DA service quality for small rollups, effectively resolving their dilemma. Notably, we observed cost reductions in USD exceeding 90% for most of the rollups when they cooperate, attributable to the smoothing effect of the blob base fee achieved through blob sharing.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>ConDa: Fast Federated Unlearning with Contribution Dampening</title>
<link>https://arxiv.org/abs/2410.04144</link>
<guid>https://arxiv.org/abs/2410.04144</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、联邦卸载、隐私保护、效率、非IID数据

总结:

本文提出了贡献衰减(ConDa)框架，旨在解决联邦学习中卸载特定参与者及其相关数据的问题。在联邦卸载中，移除参与者的数据对模型性能的影响是一个挑战。ConDa通过追踪每个客户端影响全局模型的参数，并对具有隐私侵犯贡献的全局模型参数进行突触衰减，实现了高效卸载。该方法无需使用客户端数据或重新训练模型，也不对客户端或服务器端造成任何计算负担。

ConDa的实验结果在MNIST、CIFAR10和CIFAR100等数据集上得到了验证，证明了其在卸载客户端数据方面的有效性和速度优势，相比现有最先进的方法至少快100倍。特别地，本文强调了在非独立同分布（non-IID）联邦学习环境下卸载的挑战性，并展示了ConDa在此环境下的鲁棒性。此外，通过对抗后门攻击和成员推断攻击，验证了ConDa的防御能力。这项工作对于满足法律和伦理要求的联邦学习至关重要。 <div>
arXiv:2410.04144v1 Announce Type: new 
Abstract: Federated learning (FL) has enabled collaborative model training across decentralized data sources or clients. While adding new participants to a shared model does not pose great technical hurdles, the removal of a participant and their related information contained in the shared model remains a challenge. To address this problem, federated unlearning has emerged as a critical research direction, seeking to remove information from globally trained models without harming the model performance on the remaining data. Most modern federated unlearning methods use costly approaches such as the use of remaining clients data to retrain the global model or methods that would require heavy computation on client or server side. We introduce Contribution Dampening (ConDa), a framework that performs efficient unlearning by tracking down the parameters which affect the global model for each client and performs synaptic dampening on the parameters of the global model that have privacy infringing contributions from the forgetting client. Our technique does not require clients data or any kind of retraining and it does not put any computational overhead on either the client or server side. We perform experiments on multiple datasets and demonstrate that ConDa is effective to forget a client's data. In experiments conducted on the MNIST, CIFAR10, and CIFAR100 datasets, ConDa proves to be the fastest federated unlearning method, outperforming the nearest state of the art approach by at least 100x. Our emphasis is on the non-IID Federated Learning setting, which presents the greatest challenge for unlearning. Additionally, we validate ConDa's robustness through backdoor and membership inference attacks. We envision this work as a crucial component for FL in adhering to legal and ethical requirements.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Equitable Energy Access in Energy Communities</title>
<link>https://arxiv.org/abs/2410.04300</link>
<guid>https://arxiv.org/abs/2410.04300</guid>
<content:encoded><![CDATA[
<div> 关键词：能源社区、公平性、福利最大化、分散式实施、定价策略

总结:

本文探讨了在多元社会经济背景下的能源社区中实现公平能源接入的问题。文章关注点在于如何在确保整体福利最大化的前提下，同时考虑成员间公平性问题，这与目前优化能源消耗调度研究中较少涉及的公平性集成形成了鲜明对比。

首先，文章引入了“公平相关福利最大化”(EqWM)模型，这是一个旨在优化能源调度以最大化总体福利的框架，同时考虑到公平性约束条件。这一模型旨在平衡社区内不同成员的利益，确保每个人都能从能源使用中获益，而不仅仅是整体效益的最大化。

其次，为了实现EqWM模型的分散式实施，文章提出了“分散式公平最大化”(D-EqWM)概念。这是一种两层优化策略，其中非营利运营者设计了一种社区定价政策，以最大化整体福利，同时遵守确保公平接入的限制。社区成员根据这些价格优化他们的个人能源消费。

接着，文章详细阐述了最优定价政策及其关键特性。这包括了如何制定能够促进公平性、同时最大化整体福利的定价机制，以及这种机制如何在实际操作中运行。

最后，通过分析和讨论，文章为解决能源社区中的公平性挑战提供了一个理论框架和实践路径，即通过结合福利最大化和公平性原则来优化能源调度和定价策略，从而实现资源的更高效、更公平利用。 <div>
arXiv:2410.04300v1 Announce Type: new 
Abstract: We address the issue of equitable energy access within an energy community consisting of members with diverse socioeconomic backgrounds, including varying income levels and differing capacities to access distributed energy resources such as solar power and storage systems. While optimal energy consumption scheduling is well-studied, integrating equity into decentralized real-time energy access remains under-explored. This paper formulates Equity-regarding Welfare Maximization (EqWM)--a welfare optimization energy scheduling subject to equity constraints. We further develop a decentralized implementation (D-EqWM) as a bi-level optimization, where a non-profit operator designs a community pricing policy aimed at maximizing overall welfare, subject to constraints that ensure equitable access. Community members, in turn, optimize their individual consumption based on these prices. We present the optimal pricing policy along with its key properties.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CONFINE: Preserving Data Secrecy in Decentralized Process Mining</title>
<link>https://arxiv.org/abs/2410.04453</link>
<guid>https://arxiv.org/abs/2410.04453</guid>
<content:encoded><![CDATA[
<div> 关键词：过程矿工、跨组织协作、数据保密、可信执行环境、分布式架构

总结:
本文提出了一种名为CONFINE的系统，旨在解决跨组织过程事件数据的共享与分析过程中存在的数据保密问题。该系统通过采用分布式架构和运行在可信执行环境（TEE）中的受信任应用来确保数据的安全性和完整性。在跨组织合作中，通常会遇到对敏感数据暴露的担忧，这主要源于隐私和安全风险。CONFINE系统正是针对这些挑战而设计，其核心目标是在不泄露原始记录信息的前提下，实现多提供者间的流程挖掘。

CONFINE系统基于一个去中心化的结构，这意味着数据处理和分析在各个参与方的TEE中进行，减少了对外部和参与方的直接暴露，从而保护了敏感信息。通过这种方式，系统确保了在进行流程优化和协同工作的同时，数据的安全性和隐私得到了充分保障。

系统的主要组件和功能包括数据收集、数据加密、数据处理和分析、以及结果的解密和展示等，所有操作都在TEE环境下进行，以确保数据处理过程的安全性。此外，系统还详细描述了如何在保证数据安全的前提下，实现跨组织的合作与协调，为业务流程的改进提供了可能。 <div>
arXiv:2410.04453v1 Announce Type: new 
Abstract: In the contemporary business landscape, collaboration across multiple organizations offers a multitude of opportunities, including reduced operational costs, enhanced performance, and accelerated technological advancement. The application of process mining techniques in an inter-organizational setting, exploiting the recorded process event data, enables the coordination of joint effort and allows for a deeper understanding of the business. Nevertheless, considerable concerns pertaining to data confidentiality emerge, as organizations frequently demonstrate a reluctance to expose sensitive data demanded for process mining, due to concerns related to privacy and security risks. The presence of conflicting interests among the parties involved can impede the practice of open data sharing. To address these challenges, we propose our approach and toolset named CONFINE, which we developed with the intent of enabling process mining on process event data from multiple providers while preserving the confidentiality and integrity of the original records. To ensure that the presented interaction protocol steps are secure and that the processed information is hidden from both involved and external actors, our approach is based on a decentralized architecture and consists of trusted applications running in Trusted Execution Environments (TEE). In this demo paper, we provide an overview of the core components and functionalities as well as the specific details of its application.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models</title>
<link>https://arxiv.org/abs/2410.04810</link>
<guid>https://arxiv.org/abs/2410.04810</guid>
<content:encoded><![CDATA[
<div> 关键词：One-Shot Federated Learning（OSFL）、Latent Diffusion Models（LDM）、Federated Bi-Level Personalization（FedBiP）、Feature Space Heterogeneity、Client Data Scarcity

<br /><br />
总结:
文章主要讨论了针对One-Shot Federated Learning（OSFL）系统中遇到的数据异质性和数据量限制问题，提出了一种名为Federated Bi-Level Personalization（FedBiP）的方法。FedBiP旨在通过在实例级别和概念级别个性化预训练的Latent Diffusion Models（LDM），来合成遵循客户端本地数据分布的高质量图像。该方法不仅解决了特征空间异质性的问题，还应对了客户端数据稀缺的挑战。通过在三个具有特征空间异质性的OSFL基准上以及具有标签异质性的医疗和卫星图像数据集上的实验验证了FedBiP的有效性，结果显示其性能显著优于其他OSFL方法。FedBiP在解决OSFL系统中的数据异质性和数据量限制问题上提供了一种创新解决方案，对实际应用具有重要意义。 <div>
arXiv:2410.04810v1 Announce Type: new 
Abstract: One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and mitigates privacy threats compared to traditional FL. Despite these promising prospects, existing methods face challenges due to client data heterogeneity and limited data quantity when applied to real-world OSFL systems. Recently, Latent Diffusion Models (LDM) have shown remarkable advancements in synthesizing high-quality images through pretraining on large-scale datasets, thereby presenting a potential solution to overcome these issues. However, directly applying pretrained LDM to heterogeneous OSFL results in significant distribution shifts in synthetic data, leading to performance degradation in classification models trained on such data. This issue is particularly pronounced in rare domains, such as medical imaging, which are underrepresented in LDM's pretraining data. To address this challenge, we propose Federated Bi-Level Personalization (FedBiP), which personalizes the pretrained LDM at both instance-level and concept-level. Hereby, FedBiP synthesizes images following the client's local data distribution without compromising the privacy regulations. FedBiP is also the first approach to simultaneously address feature space heterogeneity and client data scarcity in OSFL. Our method is validated through extensive experiments on three OSFL benchmarks with feature space heterogeneity, as well as on challenging medical and satellite image datasets with label heterogeneity. The results demonstrate the effectiveness of FedBiP, which substantially outperforms other OSFL methods.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Block MedCare: Advancing healthcare through blockchain integration</title>
<link>https://arxiv.org/abs/2410.05251</link>
<guid>https://arxiv.org/abs/2410.05251</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、电子健康记录（EHR）、智能合约、数字签名、角色基于访问控制

总结:

本文深入探讨了区块链技术在医疗健康领域的应用，特别是在电子健康记录管理与数据共享方面的潜力。通过利用以太坊为基础的区块链技术和智能合约，研究团队提出了一种创新系统，旨在让患者安全存储和管理其医疗信息。该研究重点关注了实施区块链技术于医疗行业面临的挑战，如可扩展性、用户隐私保护和法规遵从性。

为解决这些挑战，提出了结合数字签名、角色基于访问控制以及多层次架构的安全解决方案。系统的关键功能，包括用户注册、数据追加和数据检索，通过智能合约得以实现，从而提供了一个既安全又高效的健康信息管理系统。为了验证这一方法的有效性，开发了一个去中心化应用（dApp），展示了基于区块链的医疗解决方案的实际应用。该dApp提供了面向患者、医生和管理员的用户界面，展示了如何简化医疗流程同时保持数据安全性和完整性。

此外，进行的一项调查揭示了医疗专业人士和IT专家对区块链采用的积极态度，同时也指出了整合成本和技术复杂性等潜在问题。研究结果强调了区块链技术在医疗健康领域应用的前景与挑战。 <div>
arXiv:2410.05251v1 Announce Type: new 
Abstract: In an era driven by information exchange, transparency and security hold crucial importance, particularly within the healthcare industry, where data integrity and confidentiality are paramount. This paper investigates the integration of blockchain technology in healthcare, focusing on its potential to revolutionize Electronic Health Records (EHR) management and data sharing. By leveraging Ethereum-based blockchain implementations and smart contracts, we propose a novel system that empowers patients to securely store and manage their medical data. Our research addresses critical challenges in implementing blockchain in healthcare, including scalability, user privacy, and regulatory compliance. We propose a solution that combines digital signatures, Role-Based Access Control, and a multi-layered architecture to enhance security and ensure controlled access. The system's key functions, including user registration, data append, and data retrieval, are facilitated through smart contracts, providing a secure and efficient mechanism for managing health information. To validate our approach, we developed a decentralized application (dApp) that demonstrates the practical implementation of our blockchain-based healthcare solution. The dApp incorporates user-friendly interfaces for patients, doctors, and administrators, showcasing the system's potential to streamline healthcare processes while maintaining data security and integrity. Additionally, we conducted a survey to gain insights into the perceived benefits and challenges of blockchain adoption in healthcare. The results indicate strong interest among healthcare professionals and IT experts, while also highlighting concerns about integration costs and technological complexity. Our findings...
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>pFedGame -- Decentralized Federated Learning using Game Theory in Dynamic Topology</title>
<link>https://arxiv.org/abs/2410.04058</link>
<guid>https://arxiv.org/abs/2410.04058</guid>
<content:encoded><![CDATA[
<div> 关键词：pFedGame、游戏理论、去中心化联邦学习、动态网络、模型中毒攻击

总结:

文章提出了一种基于游戏理论的新方法——pFedGame，用于解决去中心化联邦学习中的问题。该方法旨在避免中心化服务器的性能瓶颈、数据偏斜、模型收敛性差和模型中毒攻击风险，同时增强对集中式基础设施的信任。pFedGame通过两阶段过程工作：首先，参与者选择合适的协作伙伴；其次，执行两个玩家的常数和合作博弈，以达到收敛并应用最优的联邦学习聚合策略。实验结果显示，pFedGame在异构数据集上具有超过70%的准确率，与现有方法相比表现出色。

pFedGame的关键创新在于其去中心化的结构和引入游戏理论来优化协作过程。这种方法不仅能够提升模型训练效率，还能够确保在动态网络环境下稳定运行，为解决联邦学习面临的挑战提供了一个有前景的解决方案。 <div>
arXiv:2410.04058v1 Announce Type: cross 
Abstract: Conventional federated learning frameworks suffer from several challenges including performance bottlenecks at the central aggregation server, data bias, poor model convergence, and exposure to model poisoning attacks, and limited trust in the centralized infrastructure. In the current paper, a novel game theory-based approach called pFedGame is proposed for decentralized federated learning, best suitable for temporally dynamic networks. The proposed algorithm works without any centralized server for aggregation and incorporates the problem of vanishing gradients and poor convergence over temporally dynamic topology among federated learning participants. The solution comprises two sequential steps in every federated learning round, for every participant. First, it selects suitable peers for collaboration in federated learning. Secondly, it executes a two-player constant sum cooperative game to reach convergence by applying an optimal federated learning aggregation strategy. Experiments performed to assess the performance of pFedGame in comparison to existing methods in decentralized federated learning have shown promising results with accuracy higher than 70% for heterogeneous data.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing</title>
<link>https://arxiv.org/abs/2311.09592</link>
<guid>https://arxiv.org/abs/2311.09592</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式密钥生成、DLog基密码系统、抗适应性对手、随机信任组、扩展广播通道

<br /><br />
总结:
本文提出了一种针对DLog基密码系统的实用分布式密钥生成（DKG）协议。该协议通过使用共通硬币技术，实现了节点层面几乎线性的计算和通信成本，即使在面临最大数量的拜占庭节点时也是如此。此外，该协议具备对抗适应性对手的能力，可以抵御不超过全部节点一半的节点被恶意控制的情况。其创新之处在于将最耗资源的操作委托给一个随机选取的“随机信任组”，并结合了针对适应性安全性的多种技术。这个组由少量个体组成，群体仅信任其中至少有一个成员是诚实的，而无需知晓具体是哪位。文章还提供了一个通用转换器，使得传统的分布式协议能够在参与者具有不同权重的情况下高效部署。同时，引入了一种基于区块链和数据分散网络（如IPFS）的扩展广播通道，能够以常数大小的区块链存储成本可靠地广播任意大小的消息。 <div>
arXiv:2311.09592v4 Announce Type: replace 
Abstract: The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical large-scale deployments are still yet to come due to various challenges, including the heavy computation and communication (particularly broadcast) overhead in their adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to an Any-Trust group together with a set of techniques for adaptive security. This group is randomly sampled and consists of a small number of individuals. The population only trusts that at least one member in the group is honest, without knowing which one. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have different weights. Additionally, we introduce an extended broadcast channel based on a blockchain and data dispersal network (such as IPFS), enabling reliable broadcasting of arbitrary-size messages at the cost of constant-size blockchain storage.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Necessity of Collaboration for Online Model Selection with Decentralized Data</title>
<link>https://arxiv.org/abs/2404.09494</link>
<guid>https://arxiv.org/abs/2404.09494</guid>
<content:encoded><![CDATA[
<div> 关键词：在线模型选择、分散数据、合作必要性、计算约束、联邦学习

总结:
本文研究了在M个客户端上的在线模型选择问题，重点探讨了客户端间合作的必要性。通过引入计算约束这一新颖视角，文章提出了以下关键发现：

1. **无计算约束情况下的合作可有可无**：当客户端没有计算限制时，合作并不必要。这意味着，如果客户端能够轻松处理大量数据和计算任务，那么他们可以独立进行模型选择，无需与他人协作。

2. **有限计算成本下的合作必要性**：当每个客户端的计算成本限制在o(K)时（其中K为候选假设空间的数量），合作变得至关重要。这表明，当客户端资源有限时，共享信息和资源可以显著提高整体性能。

3. **澄清先前联邦算法的误解**：文章揭示了先前用于分布式在线多核学习的联邦算法中合作的不必要性，并通过改进的贝茨不等式、联邦在线镜像下降框架以及解耦模型选择与预测三个新技巧，提供了更优的性能边界。

4. **改进的性能边界**：通过上述方法，文章不仅澄清了合作的必要性，还提高了在较小计算和通信成本下的性能边界。

5. **独立贡献**：除了主要发现外，文章还提出了新的技术贡献，包括改进的贝茨不等式、联邦在线镜像下降框架以及解耦模型选择与预测的概念，这些可能对其他领域也具有独立价值。

综上所述，文章从计算约束的角度深入探讨了在线模型选择中的合作问题，通过理论分析和算法设计，为理解合作在不同资源条件下的作用提供了新的见解，并为后续研究提供了有价值的工具和技术。 <div>
arXiv:2404.09494v4 Announce Type: replace 
Abstract: We consider online model selection with decentralized data over $M$ clients, and study the necessity of collaboration among clients. Previous work proposed various federated algorithms without demonstrating their necessity,while we answer the question from a novel perspective of computational constraints. We prove lower bounds on the regret, and propose a federated algorithm and analyze the upper bound.Our results show (i) collaboration is unnecessary in the absence of computational constraints on clients; (ii) collaboration is necessary if the computational cost on each client is limited to $o(K)$, where $K$ is the number of candidate hypothesis spaces. We clarify the unnecessary nature of collaboration in previous federated algorithms for distributed online multi-kernel learning,and improve the regret bounds at a smaller computational and communication cost. Our algorithm relies on three new techniques including an improved Bernstein's inequality for martingale, a federated online mirror descent framework, and decoupling model selection and prediction, which might be of independent interest.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</title>
<link>https://arxiv.org/abs/2407.18074</link>
<guid>https://arxiv.org/abs/2407.18074</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、强化学习、代理理论、元算法、多智能体系统

总结:

本文探讨了AI在互联网未来生态中的角色，提出了通过结合强化学习与经济学中的代理理论来协调AI智能体之间互动的框架。强化学习提供了一种允许AI智能体进行自由干预的方法，但存在难以扩展到连续场景的问题；而代理理论则解决了个体利益与社会福利之间的冲突，但在大规模应用中遇到了挑战。通过将两者结合，本文提出了一种元算法框架，该框架允许智能体在马尔可夫决策过程中接受指导，通过一系列合同来规定基于智能体行动结果的支付方式。

元算法通过迭代优化智能体和引导者（即“主”）的策略，并证明其等价于引导者的Q函数上的收敛操作器，最终达到子博弈完美均衡状态。为了解决实际应用中的计算复杂性问题，作者进一步引入深度强化学习技术，并分析了在存在近似误差情况下的算法收敛性。针对多智能体系统，文章以组合硬币游戏为例，展示了如何应用上述方法解决更复杂的、具有社会困境特征的问题。这一研究为构建更加高效、协调的多智能体系统提供了理论基础和技术路径，预示着AI在社会协作领域的重要应用前景。 <div>
arXiv:2407.18074v2 Announce Type: replace 
Abstract: The increasing deployment of AI is shaping the future landscape of the internet, which is set to become an integrated ecosystem of AI agents. Orchestrating the interaction among AI agents necessitates decentralized, self-sustaining mechanisms that harmonize the tension between individual interests and social welfare. In this paper we tackle this challenge by synergizing reinforcement learning with principal-agent theory from economics. Taken separately, the former allows unrealistic freedom of intervention, while the latter struggles to scale in sequential settings. Combining them achieves the best of both worlds. We propose a framework where a principal guides an agent in a Markov Decision Process (MDP) using a series of contracts, which specify payments by the principal based on observable outcomes of the agent's actions. We present and analyze a meta-algorithm that iteratively optimizes the policies of the principal and agent, showing its equivalence to a contraction operator on the principal's Q-function, and its convergence to subgame-perfect equilibrium. We then scale our algorithm with deep Q-learning and analyze its convergence in the presence of approximation error, both theoretically and through experiments with randomly generated binary game-trees. Extending our framework to multiple agents, we apply our methodology to the combinatorial Coin Game. Addressing this multi-agent sequential social dilemma is a promising first step toward scaling our approach to more complex, real-world instances.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Robust Data-driven Predictive Control for Smoothing Mixed Traffic Flow</title>
<link>https://arxiv.org/abs/2401.15826</link>
<guid>https://arxiv.org/abs/2401.15826</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、预测控制、分散式、鲁棒优化、自动化车辆

<br />
<br />
总结:本文提出了一种名为“分散式鲁棒 DeeP-LCC”的方法，旨在通过分散式预测控制策略改善混合交通中自动驾驶车辆（CAV）与传统人工驾驶车辆（HDV）共存的交通性能。该方法的核心在于每个 CAV 基于本地可用数据独立计算控制输入，同时考虑到相邻子系统之间的交互作为扰动源，并提出相应的估计方法。为了确保系统的鲁棒性并减少计算负担，本文提出了一个鲁棒优化问题，并提供了可解的计算解决方案。与集中式设置相比，这种方法显著降低了计算复杂度，同时提高了安全性，并自然保护了数据隐私。通过广泛的交通模拟验证，该方法展现了其平滑交通流、安全性能以及计算效率的优势。 <div>
arXiv:2401.15826v2 Announce Type: replace-cross 
Abstract: In a mixed traffic with connected automated vehicles (CAVs) and human-driven vehicles (HDVs) coexisting, data-driven predictive control of CAVs promises system-wide traffic performance improvements. Yet, most existing approaches focus on a centralized setup, which is not computationally scalable while failing to protect data privacy. The robustness against unknown disturbances has not been well addressed either, causing safety concerns. In this paper, we propose a decentralized robust DeeP-LCC (Data-EnablEd Predictive Leading Cruise Control) approach for CAVs to smooth mixed traffic flow. In particular, each CAV computes its control input based on locally available data from its involved subsystem. Meanwhile, the interaction between neighboring subsystems is modeled as a bounded disturbance, for which appropriate estimation methods are proposed. Then, we formulate a robust optimization problem and present its tractable computational solutions. Compared with the centralized formulation, our method greatly reduces computation burden with better safety performance, while naturally preserving data privacy. Extensive traffic simulations validate its wave-dampening ability, safety performance, and computational benefits.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedCert: Federated Accuracy Certification</title>
<link>https://arxiv.org/abs/2410.03067</link>
<guid>https://arxiv.org/abs/2410.03067</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedCert、Robustness Evaluation、Certified Accuracy、Client Grouping Algorithm

<br /><br />
总结:

本文聚焦于Federated Learning（FL）领域的一个关键问题：如何评估模型在面对客户端数据扰动时的鲁棒性。在传统的集中式训练中，通过认证精度可以确保一定比例的预测即使在输入数据被扰动后也能保持正确。然而，这一评估方式难以直接应用于FL，因为FL模型的训练依赖于分散在不同客户端的数据，而这些数据的具体分布未知。

为解决这一挑战，研究团队提出了FedCert方法，这是评估FL系统鲁棒性的第一步。FedCert通过估计全局模型的认证精度，基于每个客户端的认证精度和类分布来实现这一目标。考虑到现实世界中数据非独立同分布（Non-IID）的特性，研究引入了客户端分组算法，以确保聚合步骤中的认证精度可靠性。

理论分析证明了FedCert的有效性，实验结果在CIFAR-10和CIFAR-100数据集下的多种场景下显示，FedCert能显著降低与基准方法相比的估计误差。这项工作为评估FL系统的鲁棒性和可靠性提供了解决方案，并为未来增强分散学习的可靠性铺平了道路。 <div>
arXiv:2410.03067v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for training machine learning models in a decentralized manner, preserving data privacy by keeping local data on clients. However, evaluating the robustness of these models against data perturbations on clients remains a significant challenge. Previous studies have assessed the effectiveness of models in centralized training based on certified accuracy, which guarantees that a certain percentage of the model's predictions will remain correct even if the input data is perturbed. However, the challenge of extending these evaluations to FL remains unresolved due to the unknown client's local data. To tackle this challenge, this study proposed a method named FedCert to take the first step toward evaluating the robustness of FL systems. The proposed method is designed to approximate the certified accuracy of a global model based on the certified accuracy and class distribution of each client. Additionally, considering the Non-Independent and Identically Distributed (Non-IID) nature of data in real-world scenarios, we introduce the client grouping algorithm to ensure reliable certified accuracy during the aggregation step of the approximation algorithm. Through theoretical analysis, we demonstrate the effectiveness of FedCert in assessing the robustness and reliability of FL systems. Moreover, experimental results on the CIFAR-10 and CIFAR-100 datasets under various scenarios show that FedCert consistently reduces the estimation error compared to baseline methods. This study offers a solution for evaluating the robustness of FL systems and lays the groundwork for future research to enhance the dependability of decentralized learning. The source code is available at https://github.com/thanhhff/FedCert/.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research Directions for Verifiable Crypto-Physically Secure TEEs</title>
<link>https://arxiv.org/abs/2410.03183</link>
<guid>https://arxiv.org/abs/2410.03183</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、Trusted Execution Environments（TEE）、物理不可复制函数（PUFs）、硬件安全、云计算信任问题

总结:

本文探讨了Web3领域如何利用硬件可信执行环境(TEE)构建去中心化基础设施的可能性，以及当前TEE存在的物理攻击风险和制造商信任问题。文章提出通过采用物理不可复制函数(Physical Unclonable Functions, PUFs)、计算保护的掩码和冗余技术、开源硬件以及验证芯片设计一致性的方法，来构建一种无需依赖云提供商和制造商信任的安全TEE架构。具体来说：

1. **物理不可复制函数（PUFs）**：用于确保TEE的安全基础，防止克隆和复制，提高TEE的物理安全性。
   
2. **计算保护的掩码和冗余技术**：用于保护TEE内的计算过程，增加数据处理的安全性，即使在面临攻击的情况下也能保持数据完整性和隐私。

3. **开源硬件**：提倡使用开源硬件方案，减少对特定制造商的依赖，增加透明度和可验证性，有助于构建更可信的TEE系统。

4. **验证芯片设计一致性**：通过先进的成像技术，确保芯片的设计与预期相符，进一步增强TEE系统的可信度和安全性。

5. **减少对云提供商和制造商的信任**：通过上述措施，旨在构建一种TEE系统，使得Web3应用程序能够直接信任硬件的安全性，而无需完全依赖于云服务提供商或制造商的信任。

综上所述，本文旨在激发Web3社区认识到现有硬件安全研究的价值，并探索通过结合PUFs、计算保护技术、开源硬件和验证方法，构建一个更加安全、自主可控的TEE体系，从而解决当前TEE面临的物理攻击和信任问题，为Web3应用提供更加可靠的基础设施支持。 <div>
arXiv:2410.03183v1 Announce Type: new 
Abstract: A niche corner of the Web3 world is increasingly making use of hardware-based Trusted Execution Environments (TEEs) to build decentralized infrastructure. One of the motivations to use TEEs is to go beyond the current performance limitations of cryptography-based alternatives such as zero-knowledge proofs (ZKP), fully homomorphic encryption (FHE), and multi-party computation (MPC). Despite their appealing advantages, current TEEs suffer from serious limitations as they are not secure against physical attacks, and their attestation mechanism is rooted in the chip manufacturer's trust. As a result, Web3 applications have to rely on cloud infrastruture to act as trusted guardians of hardware-based TEEs and have to accept to trust chip manufacturers. This work aims at exploring how we could potentially architect and implement chips that would be secure against physical attacks and would not require putting trust in chip manufacturers. One goal of this work is to motivate the Web3 movement to acknowledge and leverage the substantial amount of relevant hardware research that already exists. In brief, a combination of: (1) physical unclonable functions (PUFs) to secure the root-of-trust; (2) masking and redundancy techniques to secure computations; (3) open source hardware and imaging techniques to verify that a chip matches its expected design; can help move towards attesting that a given TEE can be trusted without the need to trust a cloud provider and a chip manufacturer.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning</title>
<link>https://arxiv.org/abs/2410.03281</link>
<guid>https://arxiv.org/abs/2410.03281</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（FL）、Batch Normalization（BN）、FedTAN、SCAFFOLD、BN-SCAFFOLD

<br /><br />
总结:
文章主要探讨了在异构联邦学习(Federated Learning, FL)环境中，如何有效地利用批量归一化(Batch Normalization, BN)来训练深度神经网络(Depth Neural Networks, DNN)。文章首先指出，尽管联邦学习作为一种分散式机器学习范式正逐渐受到关注，但传统的批量归一化方法在异构环境中可能会降低模型性能。为此，作者提出了一种名为FedTAN的算法，旨在通过聚合所有客户端的批量归一化统计和梯度来减轻异构性的影响。然而，该算法存在较高的通信成本问题，其复杂度与DNN的深度成线性关系。

接着，文章引入了SCAFFOLD算法，这是一种能够以高效方式减少客户端漂移的偏差减少算法。虽然SCAFFOLD在异构联邦学习中显示出良好的潜力，但其在具有批量归一化的模型上表现不佳。为了解决这个问题，作者提出了BN-SCAFFOLD算法，它将SCAFFOLD的客户端漂移修正策略扩展到批量归一化统计。通过引入统一的理论框架，基于Wang等人2023年的工作，文章证明了BN-SCAFFOLD算法能够有效消除批量归一化引入的偏见，并通过实验验证了理论结果在MNIST和CIFAR-10数据集上的有效性。实验结果表明，BN-SCAFFOLD算法在性能上与FedTAN相当，但无需后者高昂的通信成本，同时优于传统的联邦平均(FedAvg)方法和其他旨在缓解批量归一化异构性的联邦学习算法。 <div>
arXiv:2410.03281v1 Announce Type: new 
Abstract: Federated Learning (FL) is gaining traction as a learning paradigm for training Machine Learning (ML) models in a decentralized way. Batch Normalization (BN) is ubiquitous in Deep Neural Networks (DNN), as it improves convergence and generalization. However, BN has been reported to hinder performance of DNNs in heterogeneous FL. Recently, the FedTAN algorithm has been proposed to mitigate the effect of heterogeneity on BN, by aggregating BN statistics and gradients from all the clients. However, it has a high communication cost, that increases linearly with the depth of the DNN. SCAFFOLD is a variance reduction algorithm, that estimates and corrects the client drift in a communication-efficient manner. Despite its promising results in heterogeneous FL settings, it has been reported to underperform for models with BN. In this work, we seek to revive SCAFFOLD, and more generally variance reduction, as an efficient way of training DNN with BN in heterogeneous FL. We introduce a unified theoretical framework for analyzing the convergence of variance reduction algorithms in the BN-DNN setting, inspired of by the work of Wang et al. 2023, and show that SCAFFOLD is unable to remove the bias introduced by BN. We thus propose the BN-SCAFFOLD algorithm, which extends the client drift correction of SCAFFOLD to BN statistics. We prove convergence using the aforementioned framework and validate the theoretical results with experiments on MNIST and CIFAR-10. BN-SCAFFOLD equals the performance of FedTAN, without its high communication cost, outperforming Federated Averaging (FedAvg), SCAFFOLD, and other FL algorithms designed to mitigate BN heterogeneity.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Practical Light Clients for Committee-Based Blockchains</title>
<link>https://arxiv.org/abs/2410.03347</link>
<guid>https://arxiv.org/abs/2410.03347</guid>
<content:encoded><![CDATA[
<div> 关键词：轻客户端、区块链、验证效率、通信成本、计算成本

总结:
本文通过实证研究发现，大部分用户并不经常处于离线状态超过一周，且在受权限控制的区块链以及Cosmos、Polkadot等无权限区块链中，验证节点变动的可能性较小。基于此，文章提出了一种新型的轻客户端系统，旨在优化现实情况下的需求，减少轻客户端的通信和计算成本。相较于现有文献中的两种先进轻客户端实现，该新系统在端到端延迟上降低了最高达90%，证明大小减少了最高达40000倍，且在某些情况下，证明大小甚至缩小了高达10000倍。这显著提高了轻客户端在实际应用中的效率和性能。 <div>
arXiv:2410.03347v1 Announce Type: new 
Abstract: Light clients are gaining increasing attention in the literature since they obviate the need for users to set up dedicated blockchain full nodes. While the literature features a number of light client instantiations, most light client protocols optimize for long offline phases and implicitly assume that the block headers to be verified are signed by highly dynamic validators.
  In this paper, we show that (i) most light clients are rarely offline for more than a week, and (ii) validators are unlikely to drastically change in most permissioned blockchains and in a number of permissionless blockchains, such as Cosmos and Polkadot. Motivated by these findings, we propose a novel practical system that optimizes for such realistic assumptions and achieves minimal communication and computational costs for light clients when compared to existing protocols. By means of a prototype implementation of our solution, we show that our protocol achieves a reduction by up to $90$ and $40000\times$ (respectively) in end-to-end latency and up to $1000$ and $10000\times$ (respectively) smaller proof size when compared to two state-of-the-art light client instantiations from the literature.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator</title>
<link>https://arxiv.org/abs/2410.03499</link>
<guid>https://arxiv.org/abs/2410.03499</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedStein、James-Stein Estimator、多域学习、数据非独立同分布

<br /><br />
总结:
文章介绍了针对多域联邦学习(Federated Learning)中数据来源不同、特征分布各异这一挑战的新方法——FedStein。FedStein通过使用詹姆斯-斯蒂恩(James-Stein)估计器来共享批量归一化(Batch Normalization, BN)统计量的估计值，同时保持本地BN参数不变，以此来提高多域联邦学习的性能和收敛性。该方法允许非BN层参数通过标准联邦学习技术进行交换，从而在多个数据集和模型上展现出显著优于现有方法（如FedAvg和FedBN）的准确性提升，特别是在特定领域的准确性提高了14%以上，增强了模型的泛化能力。此外，研究团队提供了实现FedStein方法的代码，以便其他研究者和开发者可以复现和扩展相关工作。 <div>
arXiv:2410.03499v1 Announce Type: new 
Abstract: Federated Learning (FL) facilitates data privacy by enabling collaborative in-situ training across decentralized clients. Despite its inherent advantages, FL faces significant challenges of performance and convergence when dealing with data that is not independently and identically distributed (non-i.i.d.). While previous research has primarily addressed the issue of skewed label distribution across clients, this study focuses on the less explored challenge of multi-domain FL, where client data originates from distinct domains with varying feature distributions. We introduce a novel method designed to address these challenges FedStein: Enhancing Multi-Domain Federated Learning Through the James-Stein Estimator. FedStein uniquely shares only the James-Stein (JS) estimates of batch normalization (BN) statistics across clients, while maintaining local BN parameters. The non-BN layer parameters are exchanged via standard FL techniques. Extensive experiments conducted across three datasets and multiple models demonstrate that FedStein surpasses existing methods such as FedAvg and FedBN, with accuracy improvements exceeding 14% in certain domains leading to enhanced domain generalization. The code is available at https://github.com/sunnyinAI/FedStein
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>What Matters for Model Merging at Scale?</title>
<link>https://arxiv.org/abs/2410.03617</link>
<guid>https://arxiv.org/abs/2410.03617</guid>
<content:encoded><![CDATA[
<div> 关键词：模型合并、大规模模型、综合性能提升、专家模型、分散式开发

<br /><br />总结:

本文主要探讨了模型合并技术在大规模模型中的应用与效果。首先，研究发现当合并的专家模型源自高质量的基础模型时，合并的效果更为显著，即零样本性能较好的基础模型有助于提高合并模型的整体性能。其次，较大的模型更容易进行有效合并，这意味着大模型在合并过程中表现出更好的适应性和融合性。第三，合并模型在泛化能力上普遍表现出优势，尤其是在合并多个大型专家模型时，合并后的模型往往在未见过的任务上表现得更好，相较于多任务训练的模型。第四，随着合并的专家模型数量增加，使用更大规模的模型可以更有效地进行合并，这揭示了在合并过程中的规模效应。最后，不同合并方法在大规模场景下的行为表现相似，说明选择何种合并策略对最终模型性能的影响在大型模型中可能不是决定性的。

通过这些发现，研究为未来在大规模模型合并领域的工作提供了有价值的参考点，对于促进高效、高质量模型的开发和利用具有重要意义。 <div>
arXiv:2410.03617v1 Announce Type: new 
Abstract: Model merging aims to combine multiple expert models into a more capable single model, offering benefits such as reduced storage and serving costs, improved generalization, and support for decentralized model development. Despite its promise, previous studies have primarily focused on merging a few small models. This leaves many unanswered questions about the effect of scaling model size and how it interplays with other key factors -- like the base model quality and number of expert models -- , to affect the merged model's performance. This work systematically evaluates the utility of model merging at scale, examining the impact of these different factors. We experiment with merging fully fine-tuned models using 4 popular merging methods -- Averaging, Task~Arithmetic, Dare, and TIES -- across model sizes ranging from 1B-64B parameters and merging up to 8 different expert models. We evaluate the merged models on both held-in tasks, i.e., the expert's training tasks, and zero-shot generalization to unseen held-out tasks. Our experiments provide several new insights about model merging at scale and the interplay between different factors. First, we find that merging is more effective when experts are created from strong base models, i.e., models with good zero-shot performance. Second, larger models facilitate easier merging. Third merging consistently improves generalization capabilities. Notably, when merging 8 large expert models, the merged models often generalize better compared to the multitask trained models. Fourth, we can better merge more expert models when working with larger models. Fifth, different merging methods behave very similarly at larger scales. Overall, our findings shed light on some interesting properties of model merging while also highlighting some limitations. We hope that this study will serve as a reference point on large-scale merging for upcoming research.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>TOB-SVD: Total-Order Broadcast with Single-Vote Decisions in the Sleepy Model</title>
<link>https://arxiv.org/abs/2310.11331</link>
<guid>https://arxiv.org/abs/2310.11331</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式共识、区块链、动态参与、总序广播、TOB-SVD

总结:
本文聚焦于大型、无许可系统中分布式共识研究的新方向，特别针对动态参与的挑战。对比传统的静态参与者模型，这类系统需要适应参与者数量和在线状态的频繁变化。比特币和“沉睡模型”等先驱工作为这一领域奠定了基础。

Momose和Ren（2022年CCS）的研究及后续工作引入了利用分级协议的总序广播机制，旨在支持动态参与度。然而，这些方法通常需要每个决策过程中的多轮投票，可能成为大规模实时系统的瓶颈。

针对这一问题，本文提出了一种新的总序广播协议——TOB-SVD，它在“沉睡模型”下工作，能够抵抗最多半数的敌对参与者。TOB-SVD的创新之处在于，它在最佳情况下只需一轮投票即可完成决策，同时实现与现有最优敌对方抗性方案相比更低的预期延迟。这项工作为在大型参与度波动的实时系统中实施更实用的总序广播协议铺平了道路。 <div>
arXiv:2310.11331v2 Announce Type: replace 
Abstract: Over the past years, distributed consensus research has extended its focus towards addressing challenges in large-scale, permissionless systems, such as blockchains. This shift is characterized by the need to accommodate dynamic participation, contrasting the traditional approach of a static set of continuously online participants. Works like Bitcoin and the sleepy model have set the stage for this evolving framework.
  Notable contributions from Momose and Ren (CCS 2022) and subsequent works have introduced Total-Order Broadcast protocols leveraging Graded Agreement primitives and supporting dynamic participation. However, these approaches often require multiple phases of voting per decision, creating a potential bottleneck for real-world large-scale systems.
  Addressing this, our paper introduces TOB-SVD, a novel Total-Order Broadcast protocol in the sleepy model, which is resilient to up to 1/2 of adversarial participants. TOB-SVD requires only a single phase of voting per decision in the best case and achieves lower expected latency compared to existing approaches offering the same optimal adversarial resilience. This work paves the way to more practical Total-Order Broadcast protocols to be implemented in real-world systems where a large number of participants are involved simultaneously and their participation level might fluctuate over time.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Insights and caveats from mining local and global temporal motifs in cryptocurrency transaction networks</title>
<link>https://arxiv.org/abs/2402.09272</link>
<guid>https://arxiv.org/abs/2402.09272</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式账本技术、交易数据、异常检测、反洗钱、时间网络

总结:
本文探讨了分布式账本技术（DLT）在加密货币如比特币和以太坊中产生的精细交易数据，为研究问题如异常检测、反洗钱、模式挖掘和活动聚类提供了可能。时间网络的框架为表示这些数据提供了一种自然的方式，并且提供了丰富的度量标准和模型。然而，大规模的数据对传统图分析技术构成了挑战。作者使用时间模式分析了两个比特币数据集和一个NFT数据集，利用了三个交易和最多三个用户序列。他们发现仅通过所有用户和所有时间的模式计数可能会导致误导性的结论。进一步的研究表明，每个用户的贡献模式分布呈重尾现象，关键参与者具有多样化的模式特征。通过对不同时间段发生的事件和异常活动进行分析，发现仅通过整个数据集的计数无法揭示的内容。此外，研究模式完成时间揭示了由人类行为和算法行为驱动的动力学。

文章详细阐述了如何使用时间模式分析大规模交易数据集，以及这种方法如何帮助识别异常行为和事件。研究结果不仅对理解加密货币市场的运作机制有重要意义，也为设计更有效的监控系统和策略提供了理论基础。通过对比特币和NFT数据集的应用，文章展示了时间网络方法在实际场景中的潜在应用价值。 <div>
arXiv:2402.09272v2 Announce Type: replace 
Abstract: Distributed ledger technologies have opened up a wealth of fine-grained transaction data from cryptocurrencies like Bitcoin and Ethereum. This allows research into problems like anomaly detection, anti-money laundering, pattern mining and activity clustering (where data from traditional currencies is rarely available). The formalism of temporal networks offers a natural way of representing this data and offers access to a wealth of metrics and models. However, the large scale of the data presents a challenge using standard graph analysis techniques. We use temporal motifs to analyse two Bitcoin datasets and one NFT dataset, using sequences of three transactions and up to three users. We show that the commonly used technique of simply counting temporal motifs over all users and all time can give misleading conclusions. Here we also study the motifs contributed by each user and discover that the motif distribution is heavy-tailed and that the key players have diverse motif signatures. We study the motifs that occur in different time periods and find events and anomalous activity that cannot be seen just by a count on the whole dataset. Studying motif completion time reveals dynamics driven by human behaviour as well as algorithmic behaviour.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dense Passage Retrieval: Is it Retrieving?</title>
<link>https://arxiv.org/abs/2402.11035</link>
<guid>https://arxiv.org/abs/2402.11035</guid>
<content:encoded><![CDATA[
<div> 关键词：Dense Passage Retrieval（DPR）、大型语言模型（LLM）、模型编辑、知识分散、知识不确定性

总结:
本文深入探讨了密集段落检索（Dense Passage Retrieval, DPR）在检索增强生成（RAG）范式中的作用及其对大型语言模型（LLM）性能提升的影响。研究者通过结合探针、层激活分析和模型编辑的方法，对经过DPR训练的模型进行了机制性探索。主要发现包括：

1. **知识分散**：DPR训练过程导致网络内部知识存储方式发生改变，使得相同信息可以通过多个途径访问，提高了检索效率。
   
2. **知识上限**：预训练模型内部的知识限制了检索模型的检索能力，表明了当前DPR训练风格的局限性。

3. **潜在改进方向**：
   - **更多知识暴露**：增加对DPR训练过程的知识输入，以促进更多知识的分散化。
   - **事实注入**：将具体事实作为分散表示注入到模型中，以丰富其检索能力。
   - **知识不确定性建模**：在检索过程中考虑知识的不确定性和不完整性，提高检索结果的可靠性。
   - **内部知识映射**：直接将模型内部的知识映射到知识库中，增强模型的可解释性和实用性。

这些发现为未来改进DPR和相关技术提供了理论基础和实践指导，旨在更全面地挖掘和利用模型内部的知识资源，进一步提升大规模语言模型的性能和应用潜力。 <div>
arXiv:2402.11035v3 Announce Type: replace 
Abstract: Dense passage retrieval (DPR) is the first step in the retrieval augmented generation (RAG) paradigm for improving the performance of large language models (LLM). DPR fine-tunes pre-trained networks to enhance the alignment of the embeddings between queries and relevant textual data. A deeper understanding of DPR fine-tuning will be required to fundamentally unlock the full potential of this approach. In this work, we explore DPR-trained models mechanistically by using a combination of probing, layer activation analysis, and model editing. Our experiments show that DPR training decentralizes how knowledge is stored in the network, creating multiple access pathways to the same information. We also uncover a limitation in this training style: the internal knowledge of the pre-trained model bounds what the retrieval model can retrieve. These findings suggest a few possible directions for dense retrieval: (1) expose the DPR training process to more knowledge so more can be decentralized, (2) inject facts as decentralized representations, (3) model and incorporate knowledge uncertainty in the retrieval process, and (4) directly map internal model knowledge to a knowledge base.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Experts to the Public: Governing Multimodal Language Models in Politically Sensitive Video Analysis</title>
<link>https://arxiv.org/abs/2410.01817</link>
<guid>https://arxiv.org/abs/2410.01817</guid>
<content:encoded><![CDATA[
<div> 关键词：大型多模态语言模型、集体决策、视频分析、民主治理、去中心化自治组织

总结:

本文探讨了通过个体与集体讨论来治理大型多模态语言模型（MM-LLMs）的方法，特别关注对政治敏感视频的分析。研究分为两步：首先，与10名记者进行访谈以建立专家对视频解读的基本理解；其次，114名普通公众通过Inclusive.AI平台参与讨论，该平台通过去中心化自治组织（DAO）机制促进民主决策。

研究发现，专家侧重于情感和叙事性，而公众更重视事实清晰度、情况客观性和情感中立性。此外，研究还探索了不同治理机制的影响，如二次投票与加权排名投票以及平等与20-80权力分配对用户决策的影响。结果显示，二次投票增强了对自由民主和平等政治的看法，而对AI持乐观态度的参与者认为投票过程具有更高的参与式民主水平。

本文建议将DAO机制应用于AI治理，以实现民主化，让AI的行为决策更加公正和透明。 <div>
arXiv:2410.01817v1 Announce Type: new 
Abstract: This paper examines the governance of multimodal large language models (MM-LLMs) through individual and collective deliberation, focusing on analyses of politically sensitive videos. We conducted a two-step study: first, interviews with 10 journalists established a baseline understanding of expert video interpretation; second, 114 individuals from the general public engaged in deliberation using Inclusive.AI, a platform that facilitates democratic decision-making through decentralized autonomous organization (DAO) mechanisms. Our findings show that while experts emphasized emotion and narrative, the general public prioritized factual clarity, objectivity of the situation, and emotional neutrality. Additionally, we explored the impact of different governance mechanisms: quadratic vs. weighted ranking voting and equal vs. 20-80 power distributions on users decision-making on how AI should behave. Specifically, quadratic voting enhanced perceptions of liberal democracy and political equality, and participants who were more optimistic about AI perceived the voting process to have a higher level of participatory democracy. Our results suggest the potential of applying DAO mechanisms to help democratize AI governance.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>NTK-DFL: Enhancing Decentralized Federated Learning in Heterogeneous Settings via Neural Tangent Kernel</title>
<link>https://arxiv.org/abs/2410.01922</link>
<guid>https://arxiv.org/abs/2410.01922</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式联邦学习、神经张量核（NTK）、模型平均、数据异质性、性能提升

总结:

本文探讨了分散式联邦学习(Distributed Federated Learning, DFL)领域的一个关键挑战——数据异质性。在没有中央服务器或原始数据交换的情况下，参与者合作训练模型。研究发现，传统的梯度下降方法在处理数据异质性方面存在局限性，而神经张量核(NTK)方法在集中式框架下的应用可以显著提高性能。

文章提出了一种利用NTK在分散式环境中训练客户端模型的新策略，并引入了NTK驱动的演化与模型平均之间的协同作用。这种协同作用通过利用模型间的差异来提升准确性和收敛速度，特别是在数据高度异质性的场景中。文中提出的方法在多个基准测试中显示出了明显的性能优势，尤其是在对比其他方法在高度异质性环境中的表现时，其准确性提升了至少10%，并且在达到目标性能所需通信轮数上减少了4.6倍。

此外，该方法的稳健性和普适性得到了多组数据集、网络拓扑结构和不同异质性设置的验证，确保了其在各种条件下的可靠性和广泛适用性。 <div>
arXiv:2410.01922v1 Announce Type: new 
Abstract: Decentralized federated learning (DFL) is a collaborative machine learning framework for training a model across participants without a central server or raw data exchange. DFL faces challenges due to statistical heterogeneity, as participants often possess different data distributions reflecting local environments and user behaviors. Recent work has shown that the neural tangent kernel (NTK) approach, when applied to federated learning in a centralized framework, can lead to improved performance. The NTK-based update mechanism is more expressive than typical gradient descent methods, enabling more efficient convergence and better handling of data heterogeneity. We propose an approach leveraging the NTK to train client models in the decentralized setting, while introducing a synergy between NTK-based evolution and model averaging. This synergy exploits inter-model variance and improves both accuracy and convergence in heterogeneous settings. Our model averaging technique significantly enhances performance, boosting accuracy by at least 10% compared to the mean local model accuracy. Empirical results demonstrate that our approach consistently achieves higher accuracy than baselines in highly heterogeneous settings, where other approaches often underperform. Additionally, it reaches target performance in 4.6 times fewer communication rounds. We validate our approach across multiple datasets, network topologies, and heterogeneity settings to ensure robustness and generalizability.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aerial-based Crisis Management Center (ACMC)</title>
<link>https://arxiv.org/abs/2410.01970</link>
<guid>https://arxiv.org/abs/2410.01970</guid>
<content:encoded><![CDATA[
<div> 关键词：危机管理、无人机系统、高性能计算资源、动态响应、分布式目标覆盖

总结:

本文研究了在应对关键基础设施危机、自然灾害、恐怖活动或社会动荡等情况下，高效通信和连接以及访问高性能计算资源对于及时动态响应的需求。文章提出了利用无人自主系统（UAS）提供空中危机管理中心（ACMC）的概念，以满足第一响应者所需的通信服务和计算资源。ACMC的服务被建模为深度神经网络（DNN）的物质传输方法，采用分散式方式覆盖分布的目标，这是一个具有时间变化通信权重的新颖分散式覆盖策略。通过分析证明了基于DNN的物质传输方法在团队UAS（如四旋翼无人机）中的稳定性和收敛性，每架无人机使用反馈非线性控制独立地达到预期的覆盖轨迹，从而实现分散式的操作。

无人机系统被动态组合以满足危机管理任务的通信和计算需求。这种架构能够检测、识别并传播大量异构动态事件，处理危机事件并开发实时响应，特别是在通讯和计算资源受限或严重受危机影响的情况下。文章所提出的方法为危机管理提供了创新的解决方案，通过利用无人机和深度学习技术，提高了危机响应的效率和灵活性。 <div>
arXiv:2410.01970v1 Announce Type: new 
Abstract: Crisis management (CM) for critical infrastructures, natural disasters such as wildfires and hurricanes, terrorist actions, or civil unrest requires high speed communications and connectivity, and access to high performance computational resources to deliver timely dynamic responses to the crisis being managed by different first responders. CM systems should detect, recognize, and disseminate huge amounts of heterogeneous dynamic events that operate at different speeds and formats. Furthermore, the processing of crisis events and the development of real-time responses are major research challenges when the communications and computational resources needed by CM stakeholders are not available or severely degraded by the crisis. The main goal of the research presented in this paper is to utilize Unmanned Autonomous Systems (UAS) to provide Aerial-based Crisis Management Center (ACMC) that will provide the required communications services and the computational resources that are critically needed by first responders. In our approach to develop an ACMC architecture, we utilize a set of flexible Unmanned Aerial Systems (UAS) that can be dynamically composed to meet the communications and computational requirements of CM tasks. The ACMC services will be modeled as a deep neural network (DNN) mass transport approach to cover a distributed target in a decentralized manner. This is indeed a new decentralized coverage approach with time-varying communication weights. Furthermore, our analysis proves the stability and convergence of the proposed DNN-based mass transport for a team of UAS (e.g., quadcopters), where each quadcopter uses a feedback nonlinear control to independently attain the intended coverage trajectory in a decentralized manner.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Addressing Data Heterogeneity in Federated Learning with Adaptive Normalization-Free Feature Recalibration</title>
<link>https://arxiv.org/abs/2410.02006</link>
<guid>https://arxiv.org/abs/2410.02006</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、统计异质性、自适应归一化、特征重校准、通道注意力

总结:

本文提出了一种名为Adaptive Normalization-free Feature Recalibration (ANFR) 的方法，以解决联邦学习中因客户端数据统计差异导致的系统性能下降问题。ANFR结合了权重标准化和通道注意力两种技术，旨在提升模型在不同条件下的性能。

- **权重标准化**：相较于激活标准化，权重标准化在层级别对权重进行归一化处理，这使得模型更加鲁棒，能更好地应对统计异质性带来的挑战。
- **通道注意力**：该技术生成可学习的特征图缩放因子，通过抑制因统计差异而产生的不一致特征，进一步优化模型性能。
- **独立于聚合方法**：ANFR在全局和个性化联邦学习场景下均有效，且在保持计算开销较低的情况下实现了性能提升。
- **隐私与性能的平衡**：在差分隐私训练中，ANFR能够提供强大的隐私保护同时保持高效率，实现性能与隐私的双赢。
- **跨领域应用**：实验结果显示，ANFR在多种聚合方法、数据集和异质性条件下，均能超越现有基准，表现出色。

综上所述，ANFR为应对联邦学习中的统计异质性挑战提供了一个新颖且灵活的解决方案，通过创新地结合权重标准化与通道注意力机制，显著提升了模型的泛化能力和性能表现。 <div>
arXiv:2410.02006v1 Announce Type: new 
Abstract: Federated learning is a decentralized collaborative training paradigm that preserves stakeholders' data ownership while improving performance and generalization. However, statistical heterogeneity among client datasets poses a fundamental challenge by degrading system performance. To address this issue, we propose Adaptive Normalization-free Feature Recalibration (ANFR), an architecture-level approach that combines weight standardization and channel attention. Weight standardization normalizes the weights of layers instead of activations. This is less susceptible to mismatched client statistics and inconsistent averaging, thereby more robust under heterogeneity. Channel attention produces learnable scaling factors for feature maps, suppressing those that are inconsistent between clients due to heterogeneity. We demonstrate that combining these techniques boosts model performance beyond their individual contributions, by enhancing class selectivity and optimizing channel attention weight distribution. ANFR operates independently of the aggregation method and is effective in both global and personalized federated learning settings, with minimal computational overhead. Furthermore, when training with differential privacy, ANFR achieves an appealing balance between privacy and utility, enabling strong privacy guarantees without sacrificing performance. By integrating weight standardization and channel attention in the backbone model, ANFR offers a novel and versatile approach to the challenge of statistical heterogeneity. We demonstrate through extensive experiments that ANFR consistently outperforms established baselines across various aggregation methods, datasets, and heterogeneity conditions.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>XChainWatcher: Monitoring and Identifying Attacks in Cross-Chain Bridges</title>
<link>https://arxiv.org/abs/2410.02029</link>
<guid>https://arxiv.org/abs/2410.02029</guid>
<content:encoded><![CDATA[
<div> 关键词：XChainWatcher、跨链桥、漏洞、Ronin桥、Nomad桥

<br /><br />
总结:

文章主要介绍了XChainWatcher，这是一种全新的跨链桥监控机制，旨在检测和预防跨链桥可能遭受的攻击。通过使用Datalog引擎驱动的跨链模型，XChainWatcher能够被轻松集成到任何跨链桥中。该系统通过对Ronin和Nomad桥的数据分析，成功识别出了导致6.11亿美元和1.9亿美元损失的交易。

XChainWatcher不仅能够发现成功的攻击行为，还揭示了未被注意的行为模式，如不应接受的37次跨链交易（cctx），对Nomad的未成功的攻击尝试，锁定在一条链上的超过780万美元但未能在以太坊上释放的资金，以及因与桥接交互不足而导致的20万美元损失。文章还提供了关于Nomad和Ronin桥上总计58.5亿美元和370亿美元代币转移的第一份开源数据集。

总的来说，XChainWatcher为跨链桥的安全性提供了一个重要的工具，通过检测潜在的攻击和异常行为，帮助保护区块链网络免受经济损失和安全威胁。 <div>
arXiv:2410.02029v1 Announce Type: new 
Abstract: Cross-chain bridges are widely used blockchain interoperability mechanisms. However, several of these bridges have vulnerabilities that have caused 3.2 billion dollars in losses since May 2021. Some studies have revealed the existence of these vulnerabilities, but little quantitative research is available, and there are no safeguard mechanisms to protect bridges from such attacks. We propose XChainWatcher, the first mechanism for monitoring bridges and detecting attacks against them. XChainWatcher relies on a cross-chain model powered by a Datalog engine, designed to be pluggable into any cross-chain bridge. Analyzing data from the Ronin and Nomad bridges, we successfully identified the transactions that led to losses of \$611M and \$190M USD, respectively. XChainWatcher not only uncovers successful attacks but also reveals unintended behavior, such as 37 cross-chain transactions (cctx) that these bridges should not have accepted, failed attempts to exploit Nomad, over \$7.8M locked on one chain but never released on Ethereum, and \$200K lost due to inadequate interaction with bridges. We provide the first open-source dataset of 81,000 cctxs across three blockchains, capturing \$585M and \$3.7B in token transfers in Nomad and Ronin, respectively.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>RiskSEA : A Scalable Graph Embedding for Detecting On-chain Fraudulent Activities on the Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2410.02160</link>
<guid>https://arxiv.org/abs/2410.02160</guid>
<content:encoded><![CDATA[
<div> 关键词：风险评分系统、区块链、节点2vec嵌入、动态性、交易行为特征

<br /><br />
总结:
本文提出了RiskSEA，一种旨在快速高效地识别与欺诈活动相关的加密货币地址的风险评分系统。该系统针对以太坊区块链进行了实施，其核心包括三个关键组件：一种用于整个地址集的可扩展节点2vec嵌入生成方法，以捕捉图结构；基于交易的特征，以捕获地址的交易行为模式；以及结合节点2vec嵌入和行为特征的分类模型来生成风险分数。为了应对大规模动态变化的区块链交易图的挑战，作者还引入了两种创新的节点2vec嵌入生成方法：节点2vec嵌入传播和动态节点2vec嵌入。通过实验证明，将行为特征与节点2vec嵌入相结合能够显著提升分类性能，而动态节点2vec嵌入在实验中表现出了优于传播嵌入的性能。 <div>
arXiv:2410.02160v1 Announce Type: new 
Abstract: Like any other useful technology, cryptocurrencies are sometimes used for criminal activities. While transactions are recorded on the blockchain, there exists a need for a more rapid and scalable method to detect addresses associated with fraudulent activities. We present RiskSEA, a scalable risk scoring system capable of effectively handling the dynamic nature of large-scale blockchain transaction graphs. The risk scoring system, which we implement for Ethereum, consists of 1. a scalable approach to generating node2vec embedding for entire set of addresses to capture the graph topology 2. transaction-based features to capture the transactional behavioral pattern of an address 3. a classifier model to generate risk score for addresses that combines the node2vec embedding and behavioral features. Efficiently generating node2vec embedding for large scale and dynamically evolving blockchain transaction graphs is challenging, we present two novel approaches for generating node2vec embeddings and effectively scaling it to the entire set of blockchain addresses: 1. node2vec embedding propagation and 2. dynamic node2vec embedding. We present a comprehensive analysis of the proposed approaches. Our experiments show that combining both behavioral and node2vec features boosts the classification performance significantly, and that the dynamic node2vec embeddings perform better than the node2vec propagated embeddings.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security</title>
<link>https://arxiv.org/abs/2410.02191</link>
<guid>https://arxiv.org/abs/2410.02191</guid>
<content:encoded><![CDATA[
<div> 关键词：智能手机、位置基社交网络、点兴趣推荐系统、新兴架构、安全考虑

总结:
本文是一篇关于点兴趣推荐系统的新颖性综述，旨在填补现有文献在深入探索现代方法、架构发展及安全考量方面的空白。文章围绕三个关键领域进行了详细阐述：第一，模型的演进，从传统的推荐算法过渡到先进的大型语言模型，揭示了技术进步如何推动个性化体验的提升；第二，架构的变革，从集中的服务器部署转向分散式和联邦学习架构，以增强系统的可扩展性和保护用户隐私；第三，安全与隐私的挑战，分析了当前推荐系统可能遭遇的安全漏洞，并探讨了保障用户数据安全的策略。

文章通过构建全面的分类体系，不仅回顾了点兴趣推荐系统的最新进展，还前瞻性地指出了未来研究的潜在方向，为该领域的学术研究和技术创新提供了宝贵的参考。这一研究对于促进智能设备和社交网络中更加精准、安全和个性化的服务具有重要意义。 <div>
arXiv:2410.02191v1 Announce Type: new 
Abstract: The widespread adoption of smartphones and Location-Based Social Networks has led to a massive influx of spatio-temporal data, creating unparalleled opportunities for enhancing Point-of-Interest (POI) recommendation systems. These advanced POI systems are crucial for enriching user experiences, enabling personalized interactions, and optimizing decision-making processes in the digital landscape. However, existing surveys tend to focus on traditional approaches and few of them delve into cutting-edge developments, emerging architectures, as well as security considerations in POI recommendations. To address this gap, our survey stands out by offering a comprehensive, up-to-date review of POI recommendation systems, covering advancements in models, architectures, and security aspects. We systematically examine the transition from traditional models to advanced techniques such as large language models. Additionally, we explore the architectural evolution from centralized to decentralized and federated learning systems, highlighting the improvements in scalability and privacy. Furthermore, we address the increasing importance of security, examining potential vulnerabilities and privacy-preserving approaches. Our taxonomy provides a structured overview of the current state of POI recommendation, while we also identify promising directions for future research in this rapidly advancing field.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Decentralized Learning</title>
<link>https://arxiv.org/abs/2410.02541</link>
<guid>https://arxiv.org/abs/2410.02541</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、特征异质性、模型公平性、集群化、Facade算法

<br /><br />
总结:

本文探讨了在存在特征异质性的数据集中实现公平机器学习模型训练的问题。通过引入一种名为Facade的创新集群化分布式学习算法，研究者解决了如何在无需节点预先知道所属集群的情况下，动态地将节点分配到与它们本地数据特征相似的集群中。Facade算法允许节点在完全去中心化的环境中为每个集群协作训练专门的模型，从而提高了模型的准确性和公平性。

理论分析证明了Facade算法的收敛性，实验证明了其在三个数据集上的性能优于三种最先进的基线方法。特别是在CIFAR-10数据集上，Facade算法在集群大小不平衡的情况下，不仅显著提高了模型准确性，还减少了通信成本达32.3%，充分体现了其在处理特征异质性数据集中的高效性和实用性。

<br /><br /> <div>
arXiv:2410.02541v1 Announce Type: new 
Abstract: Decentralized learning (DL) is an emerging approach that enables nodes to collaboratively train a machine learning model without sharing raw data. In many application domains, such as healthcare, this approach faces challenges due to the high level of heterogeneity in the training data's feature space. Such feature heterogeneity lowers model utility and negatively impacts fairness, particularly for nodes with under-represented training data. In this paper, we introduce \textsc{Facade}, a clustering-based DL algorithm specifically designed for fair model training when the training data exhibits several distinct features. The challenge of \textsc{Facade} is to assign nodes to clusters, one for each feature, based on the similarity in the features of their local data, without requiring individual nodes to know apriori which cluster they belong to. \textsc{Facade} (1) dynamically assigns nodes to their appropriate clusters over time, and (2) enables nodes to collaboratively train a specialized model for each cluster in a fully decentralized manner. We theoretically prove the convergence of \textsc{Facade}, implement our algorithm, and compare it against three state-of-the-art baselines. Our experimental results on three datasets demonstrate the superiority of our approach in terms of model accuracy and fairness compared to all three competitors. Compared to the best-performing baseline, \textsc{Facade} on the CIFAR-10 dataset also reduces communication costs by 32.3\% to reach a target accuracy when cluster sizes are imbalanced.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploiting Structure in Offline Multi-Agent RL: The Benefits of Low Interaction Rank</title>
<link>https://arxiv.org/abs/2410.01101</link>
<guid>https://arxiv.org/abs/2410.01101</guid>
<content:encoded><![CDATA[
<div> 关键词：离线多智能体强化学习、低交互秩、结构假设、函数类、分布偏移

总结:
本文研究了在离线多智能体强化学习（MARL）环境下学习近似均衡的问题。引入了“交互秩”这一结构性假设，指出具有较低交互秩的函数在面对分布偏移时更为稳健，相较于一般函数。利用这一观察结果，文章展示了通过结合低交互秩的函数类、正则化和无后悔学习策略，可以在离线MARL中实现去中心化的、计算上和统计上高效的算法设计。理论分析与实验验证相结合，展示了具有低交互秩的批评架构在离线MARL中的潜力，与常用的单智能体价值分解架构形成鲜明对比。实验结果进一步证实了低交互秩函数类在解决复杂多智能体任务时的优势。 <div>
arXiv:2410.01101v1 Announce Type: new 
Abstract: We study the problem of learning an approximate equilibrium in the offline multi-agent reinforcement learning (MARL) setting. We introduce a structural assumption -- the interaction rank -- and establish that functions with low interaction rank are significantly more robust to distribution shift compared to general ones. Leveraging this observation, we demonstrate that utilizing function classes with low interaction rank, when combined with regularization and no-regret learning, admits decentralized, computationally and statistically efficient learning in offline MARL. Our theoretical results are complemented by experiments that showcase the potential of critic architectures with low interaction rank in offline MARL, contrasting with commonly used single-agent value decomposition architectures.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Count of Monte Crypto: Accounting-based Defenses for Cross-Chain Bridges</title>
<link>https://arxiv.org/abs/2410.01107</link>
<guid>https://arxiv.org/abs/2410.01107</guid>
<content:encoded><![CDATA[
<div> 关键词：加密资产、桥梁服务、跨链交易、价值会计、安全审计

总结:

本文研究了2021年至2023年间，超过26亿美元的加密资产因“桥梁”攻击而被盗的情况。这些攻击的核心问题在于，缺乏跨链交易中的端到端价值会计机制。通过分析关键桥梁在这段时间内的二十万笔交易，作者发现了一个简单但有效的不变量——平衡跨链流入和流出的价值——既符合合法使用需求，又能准确识别已知的攻击事件（以及可能的攻击）。此外，该方法不仅适用于事后审计，还能集成到现有桥梁设计中，为防止多种桥梁漏洞提供通用保护。这种方法不仅能够追溯和识别攻击，还能在实际操作中预防未来的安全风险。 <div>
arXiv:2410.01107v1 Announce Type: new 
Abstract: Between 2021 and 2023, crypto assets valued at over \$US2.6 billion were stolen via attacks on "bridges" -- decentralized services designed to allow inter-blockchain exchange. While the individual exploits in each attack vary, a single design flaw underlies them all: the lack of end-to-end value accounting in cross-chain transactions. In this paper, we empirically analyze twenty million transactions used by key bridges during this period. We show that a simple invariant that balances cross-chain inflows and outflows is compatible with legitimate use, yet precisely identifies every known attack (and several likely attacks) in this data. Further, we show that this approach is not only sufficient for post-hoc audits, but can be implemented in-line in existing bridge designs to provide generic protection against a broad array of bridge vulnerabilities.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Expectation Propagation for Semi-Blind Channel Estimation in Cell-Free Networks</title>
<link>https://arxiv.org/abs/2410.01303</link>
<guid>https://arxiv.org/abs/2410.01303</guid>
<content:encoded><![CDATA[
<div> 关键词：cell-free、MA-MIMO、Semi-blind、Expectation Propagation、Central Limit Theorem

<br /><br />
总结:
本文探讨了在无基站(Cell-Free)大规模多输入多输出(MaMIMO)系统中上行通信的问题。通过使用半盲传输结构，旨在减轻试点污染现象。研究提出了一种基于期望传播(EP)的简化、去中心化方法进行半盲信道估计。利用正交试点预处理接收信号，从而建立了一个简化等效因子分解方案来优化传输过程。进一步地，该研究将中心极限定理与EP相结合，避免在因子分解方案中引入额外辅助变量。通过评估涉及的变量尺度，对算法进行了改进。最后，提出了一个去中心化的解决方案，显著降低了中央处理器(CPU)的计算需求。此工作为无基站MA-MIMO系统的高效上行通信提供了一种创新性的解决方案，通过简化信道估计和优化传输过程，提高了系统性能和资源利用率。 <div>
arXiv:2410.01303v1 Announce Type: new 
Abstract: This paper serves as a correction to the conference version. In this work, we explore uplink communication in cell-free (CF) massive multiple-input multiple-output (MaMIMO) systems, employing semi-blind transmission structures to mitigate pilot contamination. We propose a simplified, decentralized method based on Expectation Propagation (EP) for semi-blind channel estimation. By utilizing orthogonal pilots, we preprocess the received signals to establish a simplified equivalent factorization scheme for the transmission process. Moreover, this study integrates Central Limit Theory (CLT) with EP, eliminating the need to introduce new auxiliary variables in the factorization scheme. We also refine the algorithm by assessing the variable scales involved. Finally, a decentralized approach is proposed to significantly reduce the computational demands on the Central Processing Unit (CPU).
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Overpredictive Signal Analytics in Federated Learning: Algorithms and Analysis</title>
<link>https://arxiv.org/abs/2410.01399</link>
<guid>https://arxiv.org/abs/2410.01399</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘信号处理、分布式学习、联邦学习、信号近似、通信成本

<br /><br />
总结:
本文探讨了边缘信号处理在客户端-服务器模型中的应用，该模型是联邦学习的基础。在传统的机器学习框架中，收集原始信号样本的物联网设备（客户端）能够通过在第三方位置汇总这些分布式样本，协助数据中心（服务器）学习全局信号模型。然而，物联网部署面临着敏感隐私数据保护和通信速率限制的挑战。因此，本文提出了一种新的方法——分布式信号分析，通过在客户端计算信号的近似值而非原始信号来进行分散式学习。

文中提出了利用高效凸优化框架计算客户端设备上的过预测信号近似值的算法。通过数学分析，量化了通信成本、采样率与信号近似误差之间的权衡关系。此外，还展示了所提出分布式算法在公共住宅能源消耗数据集上的性能表现。

此研究为在通信受限和隐私保护环境下，利用边缘计算进行大规模分布式信号处理提供了一种可行的解决方案，对于网络需求规划等应用具有重要意义。 <div>
arXiv:2410.01399v1 Announce Type: cross 
Abstract: Edge signal processing facilitates distributed learning and inference in the client-server model proposed in federated learning. In traditional machine learning, clients (IoT devices) that acquire raw signal samples can aid a data center (server) learn a global signal model by pooling these distributed samples at a third-party location. Despite the promising capabilities of IoTs, these distributed deployments often face the challenge of sensitive private data and communication rate constraints. This necessitates a learning approach that communicates a processed approximation of the distributed samples instead of the raw signals. Such a decentralized learning approach using signal approximations will be termed distributed signal analytics in this work. Overpredictive signal approximations may be desired for distributed signal analytics, especially in network demand (capacity) planning applications motivated by federated learning. In this work, we propose algorithms that compute an overpredictive signal approximation at the client devices using an efficient convex optimization framework. Tradeoffs between communication cost, sampling rate, and the signal approximation error are quantified using mathematical analysis. We also show the performance of the proposed distributed algorithms on a publicly available residential energy consumption dataset.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Scaling LT-Coded Blockchains in Heterogeneous Networks and their Vulnerabilities to DoS Threats</title>
<link>https://arxiv.org/abs/2402.05620</link>
<guid>https://arxiv.org/abs/2402.05620</guid>
<content:encoded><![CDATA[
<div> 关键词：存储成本、区块链、Luby Transform（LT）编码、分布式网络、安全漏洞

总结:

本文研究了编码区块链技术在降低存储成本和促进可扩展性方面的重要性。文章首先指出传统的Luby Transform（LT）解码器如信念传播和在线飞行高斯消元法可能不适合具有不同计算和下载能力的异构网络。为了解决这个问题，作者提出了一种混合解码器家族，并为它们制定了最优操作模式以在最低解码成本下恢复区块链。

接着，文章指出了编码区块链架构在存储节省和可扩展性方面的研究，但对安全性漏洞了解不足的问题。作者提出了针对具有特定解码能力节点的新颖拒绝服务攻击，这些攻击旨在阻止节点加入网络。所提出的攻击是非盲目的，攻击者可以访问存档块并基于编码方案选择要执行攻击的部分块集。文章显示，优化的攻击能够与盲攻击达到相同的破坏水平，但所需的资源却有限。

最后，本文为设计同时提供存储节省、可扩展性和对抗优化威胁的编码区块链开辟了新的研究方向。 <div>
arXiv:2402.05620v2 Announce Type: replace 
Abstract: Coded blockchains have acquired prominence as a promising solution to reduce storage costs and facilitate scalability. Within this class, Luby Transform (LT) coded blockchains are an appealing choice for scalability owing to the availability of a wide range of low-complexity decoders. In the first part of this work, we identify that traditional LT decoders like Belief Propagation and On-the-Fly Gaussian Elimination may not be optimal for heterogeneous networks with nodes that have varying computational and download capabilities. To address this, we introduce a family of hybrid decoders for LT codes and propose optimal operating regimes for them to recover the blockchain at the lowest decoding cost. While LT coded blockchain architecture has been studied from the aspects of storage savings and scalability, not much is known in terms of its security vulnerabilities. Pointing at this research gap, in the second part, we present novel denial-of-service threats on LT coded blockchains that target nodes with specific decoding capabilities, preventing them from joining the network. Our proposed threats are non-oblivious in nature, wherein adversaries gain access to the archived blocks, and choose to execute their attack on a subset of them based on underlying coding scheme. We show that our optimized threats can achieve the same level of damage as that of blind attacks, however, with limited amount of resources. Overall, this is the first work of its kind that opens up new questions on designing coded blockchains to jointly provide storage savings, scalability and also resilience to optimized threats.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Web3 and the State: Indian state's redescription of blockchain</title>
<link>https://arxiv.org/abs/2405.00320</link>
<guid>https://arxiv.org/abs/2405.00320</guid>
<content:encoded><![CDATA[
<div> 关键词：文章、讨论、策略、印度国家转型机构、电子与信息技术部

<br /><br />
总结:

本文详细分析了印度国家转型机构(NITI Aayog)的一份讨论文件和电子与信息技术部(MeitY)的一份策略文件，这两份文件都强调了区块链技术在印度的非金融应用案例。研究发现，从文件中的语言表述可以看出，印度政府对区块链的理解经历了从强调透明度到信任，再到可调整的透明性的转变。这一转变不仅反映出区块链技术被定义为“去中心化”，但实际上却有强化中央控制的趋势，即政府重新定位自己作为中介角色。文中还指出，关于信任、透明度、(去)中心化和(去)中介化的论述是理解新兴社会技术系统再描述的关键领域。

通过这些讨论，文章揭示了政府在区块链政策制定过程中的角色转变和战略调整，以及这些调整如何影响技术的实施和应用。此外，它还强调了政府如何在理论上推崇技术的去中心化特性，但在实践中却倾向于强化其自身的作用，这涉及到对区块链技术潜在功能的复杂再解释。整体而言，该文旨在探讨技术政策制定中话语的力量及其对技术发展和应用的影响。 <div>
arXiv:2405.00320v2 Announce Type: replace 
Abstract: The article closely reads a discussion paper by the National Institution for Transforming India (NITI) Aayog and a strategy paper by the Ministry of Electronics and Information Technology (MeitY) advocating non-financial use cases of blockchain in India. By noting the discursive shift from transparency to trust to adjustably transparent enacted in these two documents, and consequently the Indian state's redescription of blockchain, the paper foregrounds how blockchain systems are being designated as "decentral" but have recentralizing effects where the state reinvents and re-establishes itself as an intermediary. The paper illustrates how discursive shifts concerning trust, transparency, (de)centralization and (dis)intermediation are crucial sites for investigating redescriptions of emerging sociotechnical systems.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Optimization in Time-Varying Networks with Arbitrary Delays</title>
<link>https://arxiv.org/abs/2405.19513</link>
<guid>https://arxiv.org/abs/2405.19513</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式优化、通信延迟、虚拟节点、共识算法、时间变异性

总结:

本文探讨了受通信延迟影响的网络中的分散式优化问题。通过引入虚拟非计算节点，构建了具有方向性的图结构，以此来模拟通信延迟。现有的解决方案往往假设节点已知其出度数，这限制了其应用范围。为克服这一局限性，本文提出了一种新颖的基于问候的算法——DT-GO，该算法无需知晓出度数即可应用于一般的方向性网络，如具有延迟或有限确认能力的网络。

对于凸性和非凸性目标函数，本文推导了收敛率，表明该算法在复杂度上与集中式随机梯度下降法具有相同的阶数。换句话说，图拓扑和延迟的影响仅体现在高阶项中。此外，分析还考虑了网络拓扑随时间变化的情况。为了支持理论发现，提供了数值仿真结果。 <div>
arXiv:2405.19513v2 Announce Type: replace 
Abstract: We consider a decentralized optimization problem for networks affected by communication delays. Examples of such networks include collaborative machine learning, sensor networks, and multi-agent systems. To mimic communication delays, we add virtual non-computing nodes to the network, resulting in directed graphs. This motivates investigating decentralized optimization solutions on directed graphs. Existing solutions assume nodes know their out-degrees, resulting in limited applicability. To overcome this limitation, we introduce a novel gossip-based algorithm, called DT-GO, that does not need to know the out-degrees. The algorithm is applicable in general directed networks, for example networks with delays or limited acknowledgment capabilities. We derive convergence rates for both convex and non-convex objectives, showing that our algorithm achieves the same complexity order as centralized Stochastic Gradient Descent. In other words, the effects of the graph topology and delays are confined to higher-order terms. Additionally, we extend our analysis to accommodate time-varying network topologies. Numerical simulations are provided to support our theoretical findings.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prediction and Detection of Terminal Diseases Using Internet of Medical Things: A Review</title>
<link>https://arxiv.org/abs/2410.00034</link>
<guid>https://arxiv.org/abs/2410.00034</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、物联网、医疗健康、机器学习、深度学习

总结:

本文探讨了人工智能（AI）与互联网医疗事物（IoMT）在医疗健康领域的应用，特别是通过机器学习（ML）和深度学习（DL）技术在慢性疾病预测与诊断方面的进展。AI驱动的模型如XGBoost、随机森林、卷积神经网络（CNNs）和长短期记忆循环神经网络（LSTM RNNs）在心脏病、慢性肾病（CKD）、阿尔茨海默症和肺癌的预测上取得了超过98%的准确率，数据来源包括Kaggle、UCI、私人机构和实时IoMT资源。

然而，这一领域仍面临挑战，包括数据质量的差异、患者人口统计学的多样性以及来自不同医院和研究来源的数据格式不一致。整合来自广泛且异构的IoMT数据增加了确保互操作性和保护患者隐私的复杂性。AI模型经常遇到过拟合问题，尽管在受控环境中表现良好，但在实际临床环境中效果较差。对于多病共存的情况，尤其是罕见疾病如痴呆症、中风和癌症的研究不足。未来的研究应集中在数据标准化和高级预处理技术上，以提高数据质量和互操作性。迁移学习和集成方法对于提高跨临床环境的模型泛化能力至关重要。此外，需要探索疾病之间的相互作用并开发慢性疾病交集的预测模型。创建标准化框架和开源工具，将联邦学习、区块链和差分隐私融入IoMT系统，将确保数据隐私和安全。 <div>
arXiv:2410.00034v1 Announce Type: new 
Abstract: The integration of Artificial Intelligence (AI) and the Internet of Medical Things (IoMT) in healthcare, through Machine Learning (ML) and Deep Learning (DL) techniques, has advanced the prediction and diagnosis of chronic diseases. AI-driven models such as XGBoost, Random Forest, CNNs, and LSTM RNNs have achieved over 98\% accuracy in predicting heart disease, chronic kidney disease (CKD), Alzheimer's disease, and lung cancer, using datasets from platforms like Kaggle, UCI, private institutions, and real-time IoMT sources. However, challenges persist due to variations in data quality, patient demographics, and formats from different hospitals and research sources. The incorporation of IoMT data, which is vast and heterogeneous, adds complexities in ensuring interoperability and security to protect patient privacy. AI models often struggle with overfitting, performing well in controlled environments but less effectively in real-world clinical settings. Moreover, multi-morbidity scenarios especially for rare diseases like dementia, stroke, and cancers remain insufficiently addressed. Future research should focus on data standardization and advanced preprocessing techniques to improve data quality and interoperability. Transfer learning and ensemble methods are crucial for improving model generalizability across clinical settings. Additionally, the exploration of disease interactions and the development of predictive models for chronic illness intersections is needed. Creating standardized frameworks and open-source tools for integrating federated learning, blockchain, and differential privacy into IoMT systems will also ensure robust data privacy and security.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial intelligence-based blockchain-driven financial default prediction</title>
<link>https://arxiv.org/abs/2410.00044</link>
<guid>https://arxiv.org/abs/2410.00044</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、人工智能、金融风险、数据存储、预测模型

<br />
<br />总结:
本文探讨了区块链与人工智能在金融领域的应用，特别是在信贷风险缓解和金融系统稳定方面的新思路。区块链技术通过去中心化和安全性，解决了传统系统中数据存储和管理的安全问题，为金融行业提供了可信且一致的数据环境。而人工智能则凭借强大的算法建模能力，在金融预测和风险管理上展现出巨大优势，能够通过大数据分析构建高级违约预测模型。

结合区块链与人工智能，金融机构得以优化信用风险控制策略，提升决策效率和准确性。区块链确保数据的真实性与一致性，增强了数据的安全性；人工智能则通过深度学习等技术，从海量数据中挖掘出预测违约的关键指标，构建出更加精准的预测模型。这一创新应用不仅有助于降低金融风险，还能促进金融系统的稳定性和可持续发展。未来，随着技术的不断进步，这种集成方案有望在更多领域展现出其独特价值。 <div>
arXiv:2410.00044v1 Announce Type: new 
Abstract: With the rapid development of technology, blockchain and artificial intelligence technology are playing a huge role in all walks of life. In the financial sector, blockchain solves many security problems in data storage and management in traditional systems with its advantages of decentralization and security. And artificial intelligence has huge advantages in financial forecasting and risk management through its powerful algorithmic modeling capabilities. In financial default prediction using blockchain and artificial intelligence technology is a very powerful application. Blockchain technology guarantees the credibility of data and consistency on all nodes, and machine learning builds a high-level default prediction model through detailed analysis of big data. This study offers financial institutions new thoughts on financial technology in terms of credit risk mitigation and financial system stabilization.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models</title>
<link>https://arxiv.org/abs/2410.00131</link>
<guid>https://arxiv.org/abs/2410.00131</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（FL）、Large Language Models（LLMs）、Fisher Information、Efficient Curriculum Federated Learning、LoRA

<br /><br />
总结:

本文提出了一种名为FibecFed的高效课程联邦学习框架，旨在通过利用Federated Learning（FL）在分布式数据上协作训练模型。针对大型语言模型（LLMs）参数量巨大和训练数据非独立同分布（non-IID）的问题，FibecFed引入了两个创新方法：自适应联邦课程学习和高效的稀疏参数更新。

首先，文章提出了基于费雪信息的方法，用于在每个设备上适当地采样数据，以提高FL微调过程的有效性。其次，通过动态选择合适的层进行全局聚合以及为本地更新选择合适的稀疏参数，FibecFed进一步优化了FL微调过程的效率。

实验结果表明，与17个基线方法相比，FibecFed在准确率上最高提高了45.35%，在微调速度上最快提高了98.61%，充分展示了其在提升性能和加速训练速度方面的显著优势。 <div>
arXiv:2410.00131v1 Announce Type: new 
Abstract: As a promising paradigm to collaboratively train models with decentralized data, Federated Learning (FL) can be exploited to fine-tune Large Language Models (LLMs). While LLMs correspond to huge size, the scale of the training data significantly increases, which leads to tremendous amounts of computation and communication costs. The training data is generally non-Independent and Identically Distributed (non-IID), which requires adaptive data processing within each device. Although Low Rank Adaptation (LoRA) can significantly reduce the scale of parameters to update in the fine-tuning process, it still takes unaffordable time to transfer the low-rank parameters of all the layers in LLMs. In this paper, we propose a Fisher Information-based Efficient Curriculum Federated Learning framework (FibecFed) with two novel methods, i.e., adaptive federated curriculum learning and efficient sparse parameter update. First, we propose a fisher information-based method to adaptively sample data within each device to improve the effectiveness of the FL fine-tuning process. Second, we dynamically select the proper layers for global aggregation and sparse parameters for local update with LoRA so as to improve the efficiency of the FL fine-tuning process. Extensive experimental results based on 10 datasets demonstrate that FibecFed yields excellent performance (up to 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61% faster) compared with 17 baseline approaches).
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Input and State Estimation for Multi-agent System with Dynamic Topology and Heterogeneous Sensor Network</title>
<link>https://arxiv.org/abs/2410.00272</link>
<guid>https://arxiv.org/abs/2410.00272</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统、状态估计、未知输入、信息滤波、动态拓扑结构

<br /><br />
总结:

本文研究了在分布式系统中，特别是在具有异构传感器网络和动态拓扑结构的情况下，面对未知输入时的状态估计问题。传统的共识算法往往需要大量的信息交换或多次通信迭代来确保估计的准确性。文章提出了一种高效算法，该算法通过信息滤波分解和协方差交集的输入融合实现了与拥有其他代理完整信息的滤波器相媲美的无偏置、最优解。这一方法只需要一次通信迭代来交换个体估计值，避免了分享明确观察和系统方程，从而保护了代理的隐私。

此外，针对动态通信拓扑带来的挑战，文章提出了两种实用策略来处理因间歇性观测和不完整状态估计导致的问题，以增强估计过程的鲁棒性和准确性。实验和消融研究在静态和动态环境中均表明，该算法优于其他基准，并且在某些情况下甚至表现得更好于那些拥有所有邻居全局视图的算法。 <div>
arXiv:2410.00272v1 Announce Type: new 
Abstract: A crucial challenge in decentralized systems is state estimation in the presence of unknown inputs, particularly within heterogeneous sensor networks with dynamic topologies. While numerous consensus algorithms have been introduced, they often require extensive information exchange or multiple communication iterations to ensure estimation accuracy. This paper proposes an efficient algorithm that achieves an unbiased and optimal solution comparable to filters with full information about other agents. This is accomplished through the use of information filter decomposition and the fusion of inputs via covariance intersection. Our method requires only a single communication iteration for exchanging individual estimates between agents, instead of multiple rounds of information exchange, thus preserving agents' privacy by avoiding the sharing of explicit observations and system equations. Furthermore, to address the challenges posed by dynamic communication topologies, we propose two practical strategies to handle issues arising from intermittent observations and incomplete state estimation, thereby enhancing the robustness and accuracy of the estimation process. Experiments and ablation studies conducted in both stationary and dynamic environments demonstrate the superiority of our algorithm over other baselines. Notably, it performs as well as, or even better than, algorithms that have a global view of all neighbors.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Contract Vulnerability Detection based on Static Analysis and Multi-Objective Search</title>
<link>https://arxiv.org/abs/2410.00282</link>
<guid>https://arxiv.org/abs/2410.00282</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、静态分析、多目标优化算法、Etherscan数据集

总结:

本文提出了一种基于静态分析与多目标优化算法的智能合约漏洞检测方法。该方法主要针对四种类型的漏洞进行检测，包括重入性（reentrancy）、调用栈溢出（call stack overflow）、整数溢出（integer overflow）和时间戳依赖（timestamp dependency）。首先，通过编译将智能合约转化为抽象语法树（AST），以此来分析合约之间的关系，如调用、继承和数据流等，并将其转化为静态评估和中间表示，以揭示内部关系。然后，通过对函数、变量和数据依赖性的检查，识别上述四种漏洞。

为了提高检测的准确性和覆盖率，文章引入了多目标优化算法。该算法对初始输入数据赋予数值，并监控语句覆盖度和检测准确度的变化。使用覆盖度和准确度作为适应度值，通过计算帕累托前沿和拥挤距离来选择最佳个体用于下一代父群体的生成，直至满足优化条件。实验结果表明，与现有最先进的工具相比，该方法在覆盖度、准确度、效率和检测效果方面均表现出色。

文章最后，通过收集自Etherscan的开源数据集验证了方法的有效性，该数据集包含了6693个智能合约，进一步证明了该方法在实际应用中的可行性和高效性。 <div>
arXiv:2410.00282v1 Announce Type: new 
Abstract: This paper introduces a method for detecting vulnerabilities in smart contracts using static analysis and a multi-objective optimization algorithm. We focus on four types of vulnerabilities: reentrancy, call stack overflow, integer overflow, and timestamp dependencies. Initially, smart contracts are compiled into an abstract syntax tree to analyze relationships between contracts and functions, including calls, inheritance, and data flow. These analyses are transformed into static evaluations and intermediate representations that reveal internal relations. Based on these representations, we examine contract's functions, variables, and data dependencies to detect the specified vulnerabilities. To enhance detection accuracy and coverage, we apply a multi-objective optimization algorithm to the static analysis process. This involves assigning initial numeric values to input data and monitoring changes in statement coverage and detection accuracy. Using coverage and accuracy as fitness values, we calculate Pareto front and crowding distance values to select the best individuals for the new parent population, iterating until optimization criteria are met. We validate our approach using an open-source dataset collected from Etherscan, containing 6,693 smart contracts. Experimental results show that our method outperforms state-of-the-art tools in terms of coverage, accuracy, efficiency, and effectiveness in detecting the targeted vulnerabilities.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Mathematical Theory of Hyper-simplex Fractal Network for Blockchain: Part I</title>
<link>https://arxiv.org/abs/2410.00583</link>
<guid>https://arxiv.org/abs/2410.00583</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、Web 3.0、新型网络拓扑、数学理论、无限扩展

总结:

本文提出了一种基于分形N维简单体的创新区块链网络拓扑结构理论。这种Hyper-simplex分形网络通过将一维数据块折叠成几何形状，反映了网络的内在和外层连接性。该理论为实现近无限扩展提供了可能，能够容纳数十亿节点的同时保持高效运行。通过推导生成和描述这些网络拓扑的基础数学，证明了节点数量、连接模式和分形维度等关键属性。此结构支持层次化的共识机制，并允许确定性地址映射以实现快速路由。这一理论框架为下一代区块链架构奠定了基础，有望彻底改变大规模去中心化系统的运作方式。研究工作于2024年3月至9月期间进行。

通过构建这种新型网络拓扑，文章旨在解决当前区块链技术在可扩展性方面的挑战，特别是在Web 3.0背景下。分形N维简单体的使用不仅提供了理论上无限的扩展能力，还优化了网络效率和性能。理论证明了该网络模型在节点规模、连接性和结构复杂性方面具有优越性。此外，通过引入层次化的共识机制和确定性地址映射，该理论还提出了实现高效数据路由的方法。这项研究的成果对于推动区块链技术在大规模应用中的发展具有重要意义，有可能引领未来区块链架构的变革。 <div>
arXiv:2410.00583v1 Announce Type: new 
Abstract: Blockchain technology holds promise for Web 3.0, but scalability remains a critical challenge. Here, we present a mathematical theory for a novel blockchain network topology based on fractal N-dimensional simplexes. This Hyper-simplex fractal network folds one-dimensional data blocks into geometric shapes, reflecting both underlying and overlaying network connectivities. Our approach offers near-infinite scalability, accommodating trillions of nodes while maintaining efficiency.
  We derive the mathematical foundations for generating and describing these network topologies, proving key properties such as node count, connectivity patterns, and fractal dimension. The resulting structure facilitates a hierarchical consensus mechanism and enables deterministic address mapping for rapid routing. This theoretical framework lays the groundwork for next-generation blockchain architectures, potentially revolutionizing large-scale decentralized systems. The Part I work was conducted between March and September 2024.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Web Spam Detection through a Blockchain-Enabled Crowdsourcing Mechanism</title>
<link>https://arxiv.org/abs/2410.00860</link>
<guid>https://arxiv.org/abs/2410.00860</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、激励机制、数据质量、机器学习、反垃圾邮件

<br /><br />
总结:
本文探讨了通过区块链技术实现的激励式众包方法，以提高网络反垃圾邮件系统的效能。关键点如下：

1. **动态挑战与现有解决方案的局限性**：文中首先指出了网络垃圾邮件的不断演变和复杂性对传统机器学习模型构成的挑战，即模型难以跟上攻击者的创新步伐。

2. **区块链技术的应用**：作者提出利用区块链的去中心化和透明特性，创建一种激励机制，鼓励用户参与数据收集和标注过程。通过智能合约，参与者需要以加密货币作为抵押，确保其贡献的准确性和诚信度。

3. **提升数据质量**：激励机制旨在提高数据质量和准确性，因为参与者有动机提供精确的信息，从而为机器学习算法提供更可靠的数据集。

4. **改进机器学习模型性能**：高质量的数据通过改善机器学习模型的训练效果，最终提升了垃圾邮件检测的准确率和效率。

5. **解决传统方法的局限性**：这种基于区块链的激励式众包方法提供了一种可扩展和适应性强的解决方案，旨在克服传统方法在应对动态垃圾邮件攻击时的不足。

通过上述分析，本文提出了一个创新的策略来增强反垃圾邮件系统，不仅解决了数据质量的问题，还通过引入激励机制和区块链技术提高了整个系统的效率和响应能力。 <div>
arXiv:2410.00860v1 Announce Type: new 
Abstract: The proliferation of spam on the Web has necessitated the development of machine learning models to automate their detection. However, the dynamic nature of spam and the sophisticated evasion techniques employed by spammers often lead to low accuracy in these models. Traditional machine-learning approaches struggle to keep pace with spammers' constantly evolving tactics, resulting in a persistent challenge to maintain high detection rates. To address this, we propose blockchain-enabled incentivized crowdsourcing as a novel solution to enhance spam detection systems. We create an incentive mechanism for data collection and labeling by leveraging blockchain's decentralized and transparent framework. Contributors are rewarded for accurate labels and penalized for inaccuracies, ensuring high-quality data. A smart contract governs the submission and evaluation process, with participants staking cryptocurrency as collateral to guarantee integrity. Simulations show that incentivized crowdsourcing improves data quality, leading to more effective machine-learning models for spam detection. This approach offers a scalable and adaptable solution to the challenges of traditional methods.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Review of blockchain application with Graph Neural Networks, Graph Convolutional Networks and Convolutional Neural Networks</title>
<link>https://arxiv.org/abs/2410.00875</link>
<guid>https://arxiv.org/abs/2410.00875</guid>
<content:encoded><![CDATA[
<div> 关键词：Graph Neural Networks（GNNs）、Graph Convolutional Networks（GCNs）、Convolutional Neural Networks（CNNs）、Blockchain Technology、Deep Learning Models

总结:
本文主要探讨了图神经网络（GNNs）、图卷积网络（GCNs）和卷积神经网络（CNNs）在区块链技术中的应用。随着区块链网络的复杂性和采用度持续增长，传统的分析方法在捕捉去中心化系统中复杂的关联和动态行为方面显得力不从心。为解决这一问题，深度学习模型如GNNs、GCNs和CNNs提供了强大的解决方案，它们通过利用区块链架构中固有的图结构和时间序列特性来建模节点与交易的关系。

GNNs和GCNs特别擅长处理区块链中节点间的关联数据，因此适用于欺诈检测、交易验证和智能合约分析等应用。同时，当区块链数据以结构化的矩阵形式表示时，CNNs可以通过分析揭示隐藏的时空模式在交易流中的模式。

本文还深入研究了这些模型如何增强线性区块链和有向无环图（DAG）为基础系统的效率、安全性和可扩展性，提供了一个全面的分析模型优势及其未来研究方向的概述。通过整合先进的神经网络技术，旨在展示这些模型在区块链分析领域革命性的潜力，从而为更高级的去中心化应用和网络性能改进铺平道路。 <div>
arXiv:2410.00875v1 Announce Type: new 
Abstract: This paper reviews the applications of Graph Neural Networks (GNNs), Graph Convolutional Networks (GCNs), and Convolutional Neural Networks (CNNs) in blockchain technology. As the complexity and adoption of blockchain networks continue to grow, traditional analytical methods are proving inadequate in capturing the intricate relationships and dynamic behaviors of decentralized systems. To address these limitations, deep learning models such as GNNs, GCNs, and CNNs offer robust solutions by leveraging the unique graph-based and temporal structures inherent in blockchain architectures. GNNs and GCNs, in particular, excel in modeling the relational data of blockchain nodes and transactions, making them ideal for applications such as fraud detection, transaction verification, and smart contract analysis. Meanwhile, CNNs can be adapted to analyze blockchain data when represented as structured matrices, revealing hidden temporal and spatial patterns in transaction flows. This paper explores how these models enhance the efficiency, security, and scalability of both linear blockchains and Directed Acyclic Graph (DAG)-based systems, providing a comprehensive overview of their strengths and future research directions. By integrating advanced neural network techniques, we aim to demonstrate the potential of these models in revolutionizing blockchain analytics, paving the way for more sophisticated decentralized applications and improved network performance.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning with Reduced Information Leakage and Computation</title>
<link>https://arxiv.org/abs/2310.06341</link>
<guid>https://arxiv.org/abs/2310.06341</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、信息泄露、隐私保护、模型更新、迭代过程

总结:

本文提出了Upcycled-FL策略，这是一种简单而有效的联邦学习方法，旨在通过在每一轮模型更新的偶数轮次中应用一阶近似，减少信息泄露和计算传输成本。该策略使得一半的模型更新不再产生信息泄露，从而在保证隐私的同时提高效率。

理论分析表明，Upcycled-FL在收敛速度上仍然具有良好的性能，并且通过引入两种扰动机制进一步增强了隐私保护能力。实验证明，这种策略可以适应多种现有的联邦学习框架，并且在合成数据和真实世界数据上均表现出一致的隐私-准确性权衡改善效果。

总的来说，Upcycled-FL策略通过优化联邦学习中的模型更新过程，不仅减少了信息泄露的风险，还降低了计算和通信的成本，同时保持了良好的收敛性能，为实现高效且隐私保护的联邦学习提供了新的途径。 <div>
arXiv:2310.06341v2 Announce Type: replace 
Abstract: Federated learning (FL) is a distributed learning paradigm that allows multiple decentralized clients to collaboratively learn a common model without sharing local data. Although local data is not exposed directly, privacy concerns nonetheless exist as clients' sensitive information can be inferred from intermediate computations. Moreover, such information leakage accumulates substantially over time as the same data is repeatedly used during the iterative learning process. As a result, it can be particularly difficult to balance the privacy-accuracy trade-off when designing privacy-preserving FL algorithms. This paper introduces Upcycled-FL, a simple yet effective strategy that applies first-order approximation at every even round of model update. Under this strategy, half of the FL updates incur no information leakage and require much less computational and transmission costs. We first conduct the theoretical analysis on the convergence (rate) of Upcycled-FL and then apply two perturbation mechanisms to preserve privacy. Extensive experiments on both synthetic and real-world data show that the Upcycled-FL strategy can be adapted to many existing FL frameworks and consistently improve the privacy-accuracy trade-off.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MEV Sharing with Dynamic Extraction Rates</title>
<link>https://arxiv.org/abs/2402.15849</link>
<guid>https://arxiv.org/abs/2402.15849</guid>
<content:encoded><![CDATA[
<div> 关键词：Maximal Extractable Value (MEV), 协议设计空间, EIP-1559, 动态机制, 目标值

总结:

本文探讨了区块链系统中一个新兴领域——最大可提取价值（MEV）的设计问题。MEV是区块生产者通过操纵交易顺序以获取利润的一种方式。研究提出将MEV提取率纳入协议设计空间，旨在通过动态调整该参数来平衡区块生产者和用户的利益。借鉴EIP-1559的思路，设计了一种动态机制，目标是使MEV提取率稳定在一个预定值上。

研究发现，该动态机制在特定参数下能确保向目标值收敛，但在其他情况下可能出现不稳定甚至混沌现象。然而，在一般条件下，系统会在目标均衡点附近集中，显示出长期性能的稳定性。

这项工作首次提出了动态框架来解决MEV在区块生产者与用户之间的共享问题，为MEV管理提供了理论基础和实践指导。通过动态调整MEV提取率，可以实现更公平合理的利益分配，促进区块链系统的健康发展。 <div>
arXiv:2402.15849v2 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) has emerged as a new frontier in the design of blockchain systems. In this paper, we propose making the MEV extraction rate as part of the protocol design space. Our aim is to leverage this parameter to maintain a healthy balance between block producers (who need to be compensated) and users (who need to feel encouraged to transact). We follow the approach introduced by EIP-1559 and design a similar mechanism to dynamically update the MEV extraction rate with the goal of stabilizing it at a target value. We study the properties of this dynamic mechanism and show that, while convergence to the target can be guaranteed for certain parameters, instability, and even chaos, can occur in other cases. Despite these complexities, under general conditions, the system concentrates in a neighborhood of the target equilibrium implying high long-term performance. Our work establishes, the first to our knowledge, dynamic framework for the integral problem of MEV sharing between extractors and users.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tax Policy Handbook for Crypto Assets</title>
<link>https://arxiv.org/abs/2403.15074</link>
<guid>https://arxiv.org/abs/2403.15074</guid>
<content:encoded><![CDATA[
<div> 关键词：金融系统、区块链技术、税收政策、监管挑战、全球数字基础设施

<br /><br />
总结:

本文深入探讨了金融科技领域的重大变革，尤其是比特币和其他基于分布式账本技术的加密资产的兴起，对传统金融体系的影响。文章指出，这些变化带来了监管和税收政策上的盲点，因为政府和税务机构需要时间来理解并制定相应的政策回应。创新和技术发展速度之快使得政策干预往往滞后于技术进步。

文章解释了加密资产的工作原理及其底层技术，并将这些概念与税收问题和生态系统中产生的可税事件联系起来。它还提到了在不同司法管辖区实施的现有税收和监管政策响应实例，包括金融行动特别工作组(FATF)和经济合作与发展组织(OECD)最近在报告标准方面的变化。

文章分析了加密资产相关的直接和间接税收问题，并详细讨论了更近期的技术发展，如权益证明和最大提取价值。此外，文章还提出创建全球公共数字基础设施的建议，以解决与匿名性和跨领土性相关的问题。

总的来说，本文旨在提供一个全面的视角，帮助理解加密资产领域内的税收和监管挑战，并提出了促进全球协调和有效管理这一新兴资产类别的潜在解决方案。 <div>
arXiv:2403.15074v3 Announce Type: replace-cross 
Abstract: The Financial system has witnessed rapid technological changes. The rise of Bitcoin and other crypto assets based on Distributed Ledger Technology mark a fundamental change in the way people transact and transmit value over a decentralized network, spread across geographies. This has created regulatory and tax policy blind spots, as governments and tax administrations take time to understand and provide policy responses to this innovative, revolutionary, and fast-paced technology. Due to the breakneck speed of innovation in blockchain technology and advent of Decentralized Finance, Decentralized Autonomous Organizations and the Metaverse, it is unlikely that the policy interventions and guidance by regulatory authorities or tax administrations would be ahead or in sync with the pace of innovation. This paper tries to explain the principles on which crypto assets function, their underlying technology and relates them to the tax issues and taxable events which arise within this ecosystem. It also provides instances of tax and regulatory policy responses already in effect in various jurisdictions, including the recent changes in reporting standards by the FATF and the OECD. This paper tries to explain the rationale behind existing laws and policies and the challenges in their implementation. It also attempts to present a ballpark estimate of tax potential of this asset class and suggests creation of global public digital infrastructure that can address issues related to pseudonymity and extra-territoriality. The paper analyses both direct and indirect taxation issues related to crypto assets and discusses more recent aspects like proof-of-stake and maximal extractable value in greater detail.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematisation of Knowledge: Connecting European Digital Identities with Web3</title>
<link>https://arxiv.org/abs/2409.19032</link>
<guid>https://arxiv.org/abs/2409.19032</guid>
<content:encoded><![CDATA[
<div> 关键词：自主权身份、去中心化身份、欧洲数字身份框架、开放身份认证、Web3

总结:

本文旨在澄清“自主权身份”(SSI)与“去中心化身份”之间的概念差异，特别是在修订后的《关于建立欧盟数字身份框架（eIDAS 2.0）》背景下。研究采用了归纳探索性方法，历时九个月，收集了从2005年到2024年的相关文献。

研究发现，去中心化身份领域在OpenID Connect（OIDC）的开放身份认证范式旁发展，而SSI则标志着该领域的转向区块链解决方案。文章指出，将SSI和去中心化身份混用与OIDC上的新协议相重合。

第一部分区分了OIDC与去中心化身份，强调了它们在技术上的区别。第二部分探讨了OIDC在eIDAS 2.0下的局限性以及与Web3的不兼容性。

最后，文章建议进一步研究以建立一个数字身份桥梁，连接基于公共无权限的区块链的应用程序与eIDAS 2.0提供的数据，以及使用OIDC进行展示的数据。这一研究成果有助于推动数字身份领域的标准化与互操作性，促进不同技术平台之间的融合与协同作用。 <div>
arXiv:2409.19032v1 Announce Type: new 
Abstract: The terms self-sovereign identity (SSI) and decentralised identity are often used interchangeably, which results in increasing ambiguity when solutions are being investigated and compared. This article aims to provide a clear distinction between the two concepts in relation to the revised Regulation as Regards establishing the European Digital Identity Framework (eIDAS 2.0) by providing a systematisation of knowledge of technological developments that led up to implementation of eIDAS 2.0. Applying an inductive exploratory approach, relevant literature was selected iteratively in waves over a nine months time frame and covers literature between 2005 and 2024. The review found that the decentralised identity sector emerged adjacent to the OpenID Connect (OIDC) paradigm of Open Authentication, whereas SSI denotes the sector's shift towards blockchain-based solutions. In this study, it is shown that the interchangeable use of SSI and decentralised identity coincides with novel protocols over OIDC. While the first part of this paper distinguishes OIDC from decentralised identity, the second part addresses the incompatibility between OIDC under eIDAS 2.0 and Web3. The paper closes by suggesting further research for establishing a digital identity bridge for connecting applications on public-permissionless ledgers with data originating from eIDAS 2.0 and being presented using OIDC.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Multiparty Generative AI</title>
<link>https://arxiv.org/abs/2409.19120</link>
<guid>https://arxiv.org/abs/2409.19120</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式AI、敏感信息、数据泄露、模型提供者、分布式计算

总结:

文章讨论了随着生成式人工智能工具的使用激增，敏感信息暴露给这些模型和中央模型提供商的问题日益严重。例如，三星的机密源代码通过ChatGPT的文本提示遭遇数据泄露就是一个实例。越来越多的公司因为数据泄露或保密问题而限制了大型语言模型（LLMs）的使用，包括苹果、Verizon、摩根大通等。此外，一些集中式的生成模型提供商也在限制、过滤、对齐或审查可以使用的数据。

针对这一问题，作者提出了一种安全且私密的方法来处理生成式人工智能，以防止敏感数据或模型暴露给第三方AI供应商。该方法修改了现代生成式AI算法的关键组成部分，如变换器，并引入了分布式网络中的保密和可验证多方计算。这不仅保护了用户输入的隐私和模型输出的混淆，还为模型本身引入了隐私性。分片过程减少了任何单个节点的计算负担，使得大型生成式AI进程的资源能够分散到多个较小的节点上。研究显示，只要计算中存在一个诚实的节点，安全性就能得到保障。同时，即使只有计算中大多数节点成功，推理过程仍然可以成功进行。因此，这种方法在分布式网络中提供了安全且可验证的计算能力。 <div>
arXiv:2409.19120v1 Announce Type: new 
Abstract: As usage of generative AI tools skyrockets, the amount of sensitive information being exposed to these models and centralized model providers is alarming. For example, confidential source code from Samsung suffered a data leak as the text prompt to ChatGPT encountered data leakage. An increasing number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing number of centralized generative model providers are restricting, filtering, aligning, or censoring what can be used. Midjourney and RunwayML, two of the major image generation platforms, restrict the prompts to their system via prompt filtering. Certain political figures are restricted from image generation, as well as words associated with women's health care, rights, and abortion.
  In our research, we present a secure and private methodology for generative artificial intelligence that does not expose sensitive data or models to third-party AI providers. Our work modifies the key building block of modern generative AI algorithms, e.g. the transformer, and introduces confidential and verifiable multiparty computations in a decentralized network to maintain the 1) privacy of the user input and obfuscation to the output of the model, and 2) introduce privacy to the model itself. Additionally, the sharding process reduces the computational burden on any one node, enabling the distribution of resources of large generative AI processes across multiple, smaller nodes. We show that as long as there exists one honest node in the decentralized computation, security is maintained. We also show that the inference process will still succeed if only a majority of the nodes in the computation are successful. Thus, our method offers both secure and verifiable computation in a decentralized network.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>IM: Optimizing Byzantine Consensus for High-Performance Distributed Networks</title>
<link>https://arxiv.org/abs/2409.19286</link>
<guid>https://arxiv.org/abs/2409.19286</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Fault Tolerant、Mempool、Coding Techniques、Fast-HotStuff、Throughput

总结:

本文提出了一种名为IM（Mempool）的新颖共识协议，旨在提升拜占庭容错（BFT）共识机制在故障节点和网络不稳定环境下的性能。通过将微块组织成链并结合编码技术，IM协议能够高效实现一致性与可用性。该协议易于集成到现有的BFT协议中，以增强其性能。

作为示例，作者将IM与Fast-HotStuff协议结合，形成了IM-FHS，该协议具备保持顺序、带宽适应性和抵抗过量分布等特性。在具有最高可达256个节点的系统中进行了IM-FHS的实验验证，结果显示，相比于当前最先进的Stratus-FHS协议，IM-FHS在处理故障节点时表现出更高的吞吐量和更小的延迟。随着故障节点数量的增加，IM-FHS的吞吐量优势更加显著。在100个节点中有33个故障节点的系统中，IM-FHS的吞吐量几乎是Stratus-FHS的9倍，同时保持了1/10的延迟水平，充分展示了其在高容错性场景下的优越性能。 <div>
arXiv:2409.19286v1 Announce Type: new 
Abstract: Byzantine Fault Tolerant (BFT) consensus, a crucial component of blockchains, has made significant advancements. However, the efficiency of existing protocols can still be damaged by certain attacks from faulty nodes and network instability. In this paper, we propose a novel Shared Mempool (SMP) protocol, namely IM, that enhances performance under these attacks. Technically, IM organizing microblocks into chains, combined with coding techniques, achieves totality and availability efficiently. IM can be easily integrated into a BFT protocol. We take Fast-HotStuff as an example and obtain the IM-FHS with guarantees of \emph{order keeping}, \emph{bandwidth adaptability} and \emph{over-distribution resistance}. IM-FHS is conducted in a system with up to 256 nodes, and experimental results validate the efficiency of our approach. IM-FHS achieves higher throughput and smaller latency with faulty nodes than Stratus-FHS, the state-of-the-art protocol, and the throughput gain increases as the number of fault nodes. In a system with 100 nodes with 33 faulty nodes, IM-FHS achieves 9 times the throughput of Stratus-FHS while maintaining 1/10 the latency when dealing with maximum resilience against faulty nodes.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secret Use of Large Language Models</title>
<link>https://arxiv.org/abs/2409.19450</link>
<guid>https://arxiv.org/abs/2409.19450</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、透明度、AI使用、秘密使用、用户行为

<br /><br />
总结:

文章探讨了大型语言模型（LLM）在现代社会中的应用与透明度问题。随着LLM的发展，用户被鼓励或要求公开其使用生成内容进行实际任务的情况。然而，发现了一种名为“秘密使用”的现象，即用户在不公开的情况下使用LLM。研究通过问卷调查和控制实验，收集了125个实际案例，并对300名参与者进行了实验，旨在深入理解秘密使用LLM的行为背景和原因。

研究发现，秘密使用行为往往由特定任务触发，不受用户年龄、性别等人口统计学特征的影响。任务类型影响着用户对秘密使用行为的意图，主要通过改变他们对外部对LLM使用的判断感知来实现。研究结果为未来设计促进更多透明披露LLM或其他AI技术使用的干预措施提供了重要见解。这一发现强调了在AI技术普及中确保透明度和责任的重要性，并提出了需要针对性策略以促进用户更负责任地使用这些工具。 <div>
arXiv:2409.19450v1 Announce Type: new 
Abstract: The advancements of Large Language Models (LLMs) have decentralized the responsibility for the transparency of AI usage. Specifically, LLM users are now encouraged or required to disclose the use of LLM-generated content for varied types of real-world tasks. However, an emerging phenomenon, users' secret use of LLM, raises challenges in ensuring end users adhere to the transparency requirement. Our study used mixed-methods with an exploratory survey (125 real-world secret use cases reported) and a controlled experiment among 300 users to investigate the contexts and causes behind the secret use of LLMs. We found that such secretive behavior is often triggered by certain tasks, transcending demographic and personality differences among users. Task types were found to affect users' intentions to use secretive behavior, primarily through influencing perceived external judgment regarding LLM usage. Our results yield important insights for future work on designing interventions to encourage more transparent disclosure of the use of LLMs or other AI technologies.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Infighting in the Dark: Multi-Labels Backdoor Attack in Federated Learning</title>
<link>https://arxiv.org/abs/2409.19601</link>
<guid>https://arxiv.org/abs/2409.19601</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Multi-Label Backdoor Attack、M2M、Trigger Pattern、Target Class Distribution

总结:
本文首先深入探讨了将现有研究应用于多标签后门攻击（MBA）时所面临的局限性。随后，提出了一种名为M2M的新颖多标签后门攻击方法，旨在联邦学习（FL）框架中通过巧妙地调整后门触发器，确保被后门化的样本在全局模型中被处理为干净的目标样本。M2M的关键创新在于建立触发模式与目标类分布之间的联系，使得不同的触发器能够在目标类别的清洁激活路径上激活后门，而无需担心潜在的抑制作用。通过全面的评估，该方法被证明优于各种先进的攻击技术。这项工作旨在提醒研究人员和开发者注意这一潜在威胁，并激发有效检测方法的设计。

本文的主要贡献在于：
1. 指出了现有方法在应用到MBA时存在的问题。
2. 提出了M2M策略，利用多标签数据的特点，实现后门化样本在全局模型中的有效激活。
3. 通过实验验证了M2M方法的有效性和优越性。
4. 强调了对联邦学习系统中多标签后门攻击威胁的认识，以及对防御策略的需求。
5. 表明了开发和部署针对性防御措施的重要性，以保护联邦学习系统的安全性和可靠性。 <div>
arXiv:2409.19601v1 Announce Type: new 
Abstract: Federated Learning (FL) has been demonstrated to be vulnerable to backdoor attacks. As a decentralized machine learning framework, most research focuses on the Single-Label Backdoor Attack (SBA), where adversaries share the same target but neglect the fact that adversaries may be unaware of each other's existence and hold different targets, i.e., Multi-Label Backdoor Attack (MBA). Unfortunately, directly applying prior work to the MBA would not only be ineffective but also potentially mitigate each other. In this paper, we first investigate the limitations of applying previous work to the MBA. Subsequently, we propose M2M, a novel multi-label backdoor attack in federated learning (FL), which adversarially adapts the backdoor trigger to ensure that the backdoored sample is processed as clean target samples in the global model. Our key intuition is to establish a connection between the trigger pattern and the target class distribution, allowing different triggers to activate backdoors along clean activation paths of the target class without concerns about potential mitigation. Extensive evaluations comprehensively demonstrate that M2M outperforms various state-of-the-art attack methods. This work aims to alert researchers and developers to this potential threat and to inspire the design of effective detection methods. Our code will be made available later.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Programming on Bitcoin: A Survey of Layer 1 and Layer 2 Technologies in Bitcoin Ecosystem</title>
<link>https://arxiv.org/abs/2409.19622</link>
<guid>https://arxiv.org/abs/2409.19622</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、编程功能、创新协议、Taproot升级、非同质化代币

<br />
<br />总结:

本文综述了增强比特币区块链编程功能的创新性协议，特别是围绕比特币生态系统的核心部分。比特币采用UTXO模型和基于堆栈的脚本语言，为点对点支付提供高效解决方案，但其在编程能力和吞吐量方面存在局限性。2021年的Taproot升级引入了Schnorr签名算法和P2TR交易类型，显著提升了比特币的隐私性和编程能力。

文章探讨了利用Taproot特性进行非同质化代币（NFT）编程的协议，如Ordinals和Atomicals，并分析了BRC-20和ARC-20等代币标准。此外，文章还分类了一些作为比特币生态层2解决方案的协议，类似于以太坊的方案，评估它们对比特币主网性能的影响。

通过分析比特币区块链数据，收集了关于区块容量、矿工费用和Taproot交易增长的指标。研究结果确认了这些协议对提升比特币编程能力和生态系统的积极效果，填补了关于比特币编程能力和生态协议研究的空白，并为实践者和研究者提供了有价值的信息。 <div>
arXiv:2409.19622v1 Announce Type: new 
Abstract: This paper surveys innovative protocols that enhance the programming functionality of the Bitcoin blockchain, a key part of the "Bitcoin Ecosystem." Bitcoin utilizes the Unspent Transaction Output (UTXO) model and a stack-based script language for efficient peer-to-peer payments, but it faces limitations in programming capability and throughput. The 2021 Taproot upgrade introduced the Schnorr signature algorithm and P2TR transaction type, significantly improving Bitcoin's privacy and programming capabilities. This upgrade has led to the development of protocols like Ordinals, Atomicals, and BitVM, which enhance Bitcoin's programming functionality and enrich its ecosystem. We explore the technical aspects of the Taproot upgrade and examine Bitcoin Layer 1 protocols that leverage Taproot's features to program non-fungible tokens (NFTs) into transactions, including Ordinals and Atomicals, along with the fungible token standards BRC-20 and ARC-20.
  Additionally, we categorize certain Bitcoin ecosystem protocols as Layer 2 solutions similar to Ethereum's, analyzing their impact on Bitcoin's performance. By analyzing data from the Bitcoin blockchain, we gather metrics on block capacity, miner fees, and the growth of Taproot transactions. Our findings confirm the positive effects of these protocols on Bitcoin's mainnet, bridging gaps in the literature regarding Bitcoin's programming capabilities and ecosystem protocols and providing valuable insights for practitioners and researchers.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Centric Design: Introducing An Informatics Domain Model And Core Data Ontology For Computational Systems</title>
<link>https://arxiv.org/abs/2409.19653</link>
<guid>https://arxiv.org/abs/2409.19653</guid>
<content:encoded><![CDATA[
<div> 关键词：Core Data Ontology（CDO）、Informatics Domain Model、数据为中心、AI开发、分布式数据生态系统

<br />
总结:

本文提出了Core Data Ontology（CDO）和Informatics Domain Model的创新概念，旨在通过从传统的节点中心设计转向数据为中心的范式来革新计算系统。数据被划分为四类模态：对象、事件、概念和行动，这一四元模态结构增强了数据安全、语义互操作性和分布式数据生态系统中的可扩展性。

CDO提供了一个全面的本体论框架，支持人工智能开发、基于角色的访问控制以及多模态数据管理。它重新定义了系统架构，优先考虑数据安全、来源证明和审计性，以解决当前模型中的脆弱性问题。文章详细介绍了CDO的开发方法，并探讨了其在人工智能、机器人技术和法律合规等领域的实际应用案例。同时，还展望了构建可扩展、去中心化和互操作性强的数据生态系统的未来方向。 <div>
arXiv:2409.19653v1 Announce Type: new 
Abstract: The Core Data Ontology (CDO) and the Informatics Domain Model represent a transformative approach to computational systems, shifting from traditional node-centric designs to a data-centric paradigm. This paper introduces a framework where data is categorized into four modalities: objects, events, concepts, and actions. This quadrimodal structure enhances data security, semantic interoperability, and scalability across distributed data ecosystems. The CDO offers a comprehensive ontology that supports AI development, role-based access control, and multimodal data management. By focusing on the intrinsic value of data, the Informatics Domain Model redefines system architectures to prioritize data security, provenance, and auditability, addressing vulnerabilities in current models. The paper outlines the methodology for developing the CDO, explores its practical applications in fields such as AI, robotics, and legal compliance, and discusses future directions for scalable, decentralized, and interoperable data ecosystems.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System</title>
<link>https://arxiv.org/abs/2409.19756</link>
<guid>https://arxiv.org/abs/2409.19756</guid>
<content:encoded><![CDATA[
<div> 关键词：学习型医疗系统、隐私保护、联邦学习、数据共享、医疗生态系统

<br />
<br />
总结:
文章探讨了学习型医疗系统(LHS)的概念及其面临的挑战，尤其是数据共享与隐私保护的问题。提出了通过隐私保护联邦学习(PPFL)技术来解决这些问题的愿景。PPFL允许在不共享原始数据的情况下进行跨机构学习，从而在保护患者隐私的同时，实现数据的有效利用。文中指出，将PPFL集成到医疗生态系统中，可以促进形成一个真正意义上的LHS，即能够自我改进并持续优化未来医疗服务的网络。这需要医疗机构、研究者和政策制定者之间的紧密合作，共同构建安全、高效的数据共享框架，以支持临床决策和医学研究的发展。实现这一目标的关键在于平衡数据的利用与隐私保护，确保医疗信息的安全性和患者的权益得到充分尊重。 <div>
arXiv:2409.19756v1 Announce Type: new 
Abstract: The concept of a learning healthcare system (LHS) envisions a self-improving network where multimodal data from patient care are continuously analyzed to enhance future healthcare outcomes. However, realizing this vision faces significant challenges in data sharing and privacy protection. Privacy-Preserving Federated Learning (PPFL) is a transformative and promising approach that has the potential to address these challenges by enabling collaborative learning from decentralized data while safeguarding patient privacy. This paper proposes a vision for integrating PPFL into the healthcare ecosystem to achieve a truly LHS as defined by the Institute of Medicine (IOM) Roundtable.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-enhanced Integrity Verification in Educational Content Assessment Platform: A Lightweight and Cost-Efficient Approach</title>
<link>https://arxiv.org/abs/2409.19828</link>
<guid>https://arxiv.org/abs/2409.19828</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、电子平台、教育内容评估、Polygon网络、成本节约

总结:

本文提出了一种基于区块链技术的新型框架，用于增强电子平台（EPEC）的可信度和透明度。该框架旨在解决教育数字化过程中数据完整性和信任度问题，特别是针对教师专业活动评估的透明和安全需求。通过集成Polygon网络作为Ethereum的Layer-2解决方案，实现加密评论的安全存储与检索，同时保障隐私和责任。利用Python、Flask和Web3.py进行与Solidity智能合约的交互，确保每个评论与唯一标识符（UID）相关联，从而实现链上数据与现实数据库的无缝链接。借助Docker容器化部署，系统提供了易于部署和集成的API端点，显著降低了交易费用，与Ethereum相比减少了98%的gas费用。此研究对教育内容验证中的区块链应用具有重要意义，提供了一个实用、安全的框架，有效增强了数字教育环境中的信任与透明度。 <div>
arXiv:2409.19828v1 Announce Type: new 
Abstract: The growing digitization of education presents significant challenges in maintaining the integrity and trustworthiness of educational content. Traditional systems often fail to ensure data authenticity and prevent unauthorized alterations, particularly in the evaluation of teachers' professional activities, where demand for transparent and secure assessment mechanisms is increasing. In this context, Blockchain technology offers a novel solution to address these issues. This paper introduces a Blockchain-enhanced framework for the Electronic Platform for Expertise of Content (EPEC), a platform used for reviewing and assessing educational materials. Our approach integrates the Polygon network, a Layer-2 solution for Ethereum, to securely store and retrieve encrypted reviews, ensuring both privacy and accountability. By leveraging Python, Flask, and Web3.py, we interact with a Solidity-based smart contract to securely link each review to a unique identifier (UID) that connects on-chain data with real-world databases. The system, containerized using Docker, facilitates easy deployment and integration through API endpoints. Our implementation demonstrates significant cost savings, with a 98\% reduction in gas fees compared to Ethereum, making it a scalable and cost-effective solution. This research contributes to the ongoing effort to implement Blockchain in educational content verification, offering a practical and secure framework that enhances trust and transparency in the digital education landscape.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalizability of Graph Neural Networks for Decentralized Unlabeled Motion Planning</title>
<link>https://arxiv.org/abs/2409.19829</link>
<guid>https://arxiv.org/abs/2409.19829</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人系统、分散式策略、图神经网络（GNN）、集中式匈牙利算法、强化学习

<br />
<br />总结:
本文探讨了在多机器人系统中解决无标签运动规划问题的方法，即在确保碰撞避免的前提下，将一组机器人分配至目标位置，以最小化总移动距离。该问题在探索、监控和运输等应用中扮演着关键角色。研究在分散式环境中进行，其中每个机器人仅知晓其最近的$k$个机器人与目标的位置信息，这一设置结合了组合分配与连续空间路径规划的特点，对传统的集中式方法提出了重大挑战。为解决这些挑战，提出了一种基于图神经网络（GNN）的分散式策略。GNN使机器人能够决定与邻居交流的信息类型以及如何整合接收到的信息与本地观察结果以做出决策。通过模仿学习和专家政策（集中式匈牙利算法）进行训练，进一步使用强化学习优化策略以避免碰撞并提升性能。实验结果表明，该方法具有良好的可扩展性和有效性，所训练的GNN策略在100个机器人的情况下，可以扩展到最多500个机器人的情景，并在平均性能上优于现有最佳解决方案8.6%，远超简单的分散式贪心方法。这项工作为解决大规模多机器人协调问题提供了基础。 <div>
arXiv:2409.19829v1 Announce Type: new 
Abstract: Unlabeled motion planning involves assigning a set of robots to target locations while ensuring collision avoidance, aiming to minimize the total distance traveled. The problem forms an essential building block for multi-robot systems in applications such as exploration, surveillance, and transportation. We address this problem in a decentralized setting where each robot knows only the positions of its $k$-nearest robots and $k$-nearest targets. This scenario combines elements of combinatorial assignment and continuous-space motion planning, posing significant scalability challenges for traditional centralized approaches. To overcome these challenges, we propose a decentralized policy learned via a Graph Neural Network (GNN). The GNN enables robots to determine (1) what information to communicate to neighbors and (2) how to integrate received information with local observations for decision-making. We train the GNN using imitation learning with the centralized Hungarian algorithm as the expert policy, and further fine-tune it using reinforcement learning to avoid collisions and enhance performance. Extensive empirical evaluations demonstrate the scalability and effectiveness of our approach. The GNN policy trained on 100 robots generalizes to scenarios with up to 500 robots, outperforming state-of-the-art solutions by 8.6\% on average and significantly surpassing greedy decentralized methods. This work lays the foundation for solving multi-robot coordination problems in settings where scalability is important.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Plug and Play Distributed Secondary Controller for Microgrids with Grid-Forming Inverters</title>
<link>https://arxiv.org/abs/2409.19866</link>
<guid>https://arxiv.org/abs/2409.19866</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式控制器、微电网、电网形成逆变器、二次控制、硬件在环实验

总结:
本文介绍了一种为基于电网形成的逆变器资源的微电网设计的分布式控制器，用于解决二次控制问题。该控制器基于分布式优化技术，实现分布式合成与实施，使每个电网形成逆变器资源能够利用本地测量和通信网络中的邻域信息。文章提供了一种收敛性分析，以验证电压调节和无功功率共享的特性。通过控制器-硬件在环实验，评估了提出控制器的性能。实验结果证明了所提出的分布式控制器在二次控制方面的有效性。

文章的主要内容包括：
1. **控制器设计**：提出了一种基于分布式优化的控制器，旨在解决微电网中的二次控制问题。
2. **实现方式**：控制器的实现依赖于分布式合成和实施，允许每个电网形成逆变器资源利用本地信息进行操作。
3. **性能分析**：进行了收敛性分析，以确保控制器能够有效地执行电压调节和无功功率共享。
4. **实验验证**：通过控制器-硬件在环实验，实际验证了控制器的性能和有效性。
5. **结论**：实验结果表明，所设计的分布式控制器在微电网的二次控制方面具有良好的应用前景。 <div>
arXiv:2409.19866v1 Announce Type: new 
Abstract: A distributed controller for secondary control problems in microgrids with grid-forming (GFM) inverter-based resources (IBRs) is developed. The controller is based on distributed optimization and is synthesized and implemented distributively enabling each GFM IBR to utilize decentralized measurements and the neighborhood information in the communication network. We present a convergence analysis establishing voltage regulation and reactive power sharing properties. A controller-hardware-in-the-loop experiment is conducted to evaluate the performance of the proposed controller. The experimental results corroborate the efficacy of the proposed distributed controller for secondary control.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal RANDAO Manipulation in Ethereum</title>
<link>https://arxiv.org/abs/2409.19883</link>
<guid>https://arxiv.org/abs/2409.19883</guid>
<content:encoded><![CDATA[
<div> 关键词：RANDAO、操纵、以太坊、提案率、战略参与者

总结:

本文探讨了在以太坊网络中，如果攻击者控制了一定比例的代币，即“stake”，他们能够操纵RANDAO（随机性权威证明）机制的程度。RANDAO是用于生成区块头随机性的关键组件。文章提出了计算方法，以确定攻击者拥有不同比例stake时，能控制的轮次提案比例的最大值。这种方法考虑了攻击者对最后几个周期的提案者进行操纵的可能性。

具体来说，作者通过数学建模和分析，得出结论：

- 拥有5% stake的战略参与者理论上可以控制约5.048%的提案。
- 当该比例增加到10%，攻击者理论上可以控制约10.19%的提案。
- 对于20%的stake，理论上的控制比例提高至约20.68%。

这些发现揭示了在以太坊网络中，即使在相对分散的系统下，通过集中stake也能实现对关键流程的操纵，从而影响区块链的安全性和公平性。这强调了加强系统安全机制和提高抗攻击能力的重要性。 <div>
arXiv:2409.19883v1 Announce Type: new 
Abstract: It is well-known that RANDAO manipulation is possible in Ethereum if an adversary controls the proposers assigned to the last slots in an epoch. We provide a methodology to compute, for any fraction $\alpha$ of stake owned by an adversary, the maximum fraction $f(\alpha)$ of rounds that a strategic adversary can propose. We further implement our methodology and compute $f(\cdot)$ for all $\alpha$. For example, we conclude that an optimal strategic participant with $5\%$ of the stake can propose a $5.048\%$ fraction of rounds, $10\%$ of the stake can propose a $10.19\%$ fraction of rounds, and $20\%$ of the stake can propose a $20.68\%$ fraction of rounds.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Pre-trained Models for Robust Federated Learning for Kidney Stone Type Recognition</title>
<link>https://arxiv.org/abs/2409.19934</link>
<guid>https://arxiv.org/abs/2409.19934</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、医疗影像、联邦学习、肾结石诊断、数据隐私

<br />
<br />
总结:
文章探讨了深度学习在医疗影像诊断领域的应用，特别是通过改进模型准确度来提升肾结石诊断效率。然而，面对数据量庞大和数据交换法律限制的挑战，研究提出联邦学习（FL）作为一种解决方案，它允许在不共享原始数据的情况下进行模型训练，从而保护数据隐私。但同时，FL模型面临数据污染的风险，可能影响其性能。

为解决这一问题，研究中引入了一种结合预训练模型与FL的新框架，旨在提高诊断准确性并增强对图像污染的鲁棒性。实验采用两个包含六类不同图像的肾结石数据集，结果显示，在学习参数优化阶段（LPO），模型达到84.1%的峰值准确率；而在联邦鲁棒验证阶段（FRV），准确率为77.2%，表明该方法有效提升了诊断精度和鲁棒性。

这项研究强调了将预训练模型与FL相结合的重要性，以解决医疗诊断中的隐私和性能问题，从而促进更优质的患者护理并增强公众对基于FL的医疗系统的信任。 <div>
arXiv:2409.19934v1 Announce Type: new 
Abstract: Deep learning developments have improved medical imaging diagnoses dramatically, increasing accuracy in several domains. Nonetheless, obstacles continue to exist because of the requirement for huge datasets and legal limitations on data exchange. A solution is provided by Federated Learning (FL), which permits decentralized model training while maintaining data privacy. However, FL models are susceptible to data corruption, which may result in performance degradation. Using pre-trained models, this research suggests a strong FL framework to improve kidney stone diagnosis. Two different kidney stone datasets, each with six different categories of images, are used in our experimental setting. Our method involves two stages: Learning Parameter Optimization (LPO) and Federated Robustness Validation (FRV). We achieved a peak accuracy of 84.1% with seven epochs and 10 rounds during LPO stage, and 77.2% during FRV stage, showing enhanced diagnostic accuracy and robustness against image corruption. This highlights the potential of merging pre-trained models with FL to address privacy and performance concerns in medical diagnostics, and guarantees improved patient care and enhanced trust in FL-based medical systems.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DBNode: A Decentralized Storage System for Big Data Storage in Consortium Blockchains</title>
<link>https://arxiv.org/abs/2409.20123</link>
<guid>https://arxiv.org/abs/2409.20123</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、存储系统、Hyperledger Fabric、数据隐私、访问控制

<br /><br />
总结:

本文提出了一种专为Hyperledger Fabric设计的去中心化存储系统。Hyperledger Fabric作为知名的合作区块链平台，具有独特属性如数据隐私和访问控制需求。为解决直接将大数据存储于区块链上的挑战，文章采用错误校正编码对文件进行分割，并构建层次结构以实现高效稳定的数据存储。同时，通过双层哈希槽机制与镜像策略确保高数据可用性。此外，基于智能合约设计了访问控制机制，以管理文件访问权限，满足Hyperledger Fabric特定需求，提升整体性能并保障数据安全。此存储系统旨在优化合作区块链环境下的数据存储与管理，兼顾性能与隐私保护。 <div>
arXiv:2409.20123v1 Announce Type: new 
Abstract: Storing big data directly on a blockchain poses a substantial burden due to the need to maintain a consistent ledger across all nodes. Numerous studies in decentralized storage systems have been conducted to tackle this particular challenge. Most state-of-the-art research concentrates on developing a general storage system that can accommodate diverse blockchain categories. However, it is essential to recognize the unique attributes of a consortium blockchain, such as data privacy and access control. Beyond ensuring high performance, these specific needs are often overlooked by general storage systems. This paper proposes a decentralized storage system for Hyperledger Fabric, which is a well-known consortium blockchain. First, we employ erasure coding to partition files, subsequently organizing these chunks into a hierarchical structure that fosters efficient and dependable data storage. Second, we design a two-layer hash-slots mechanism and a mirror strategy, enabling high data availability. Third, we design an access control mechanism based on a smart contract to regulate file access.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARLadona -- Towards Cooperative Team Play Using Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.20326</link>
<guid>https://arxiv.org/abs/2409.20326</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、MARLadona、深度学习、机器人足球、全球实体编码器

总结:

本文介绍了一种名为MARLadona的新方法，它利用多智能体强化学习（MARL）为机器人足球提供了一种更高级的团队协作策略。与传统的工程启发式策略相比，这种方法更加稳健和适应性强。通过使用一种基于深度学习的框架，MARLadona能够生成具有复杂团队行为的智能体，这在当前的机器人足球研究中是一个显著的进步。

为了验证MARLadona的有效性，作者们创建了一个基于Isaac Gym的开源多智能体足球环境。在这个环境中，他们将MARLadona与一个采用最先进的启发式策略的HELIOS智能体进行了对比。结果显示，MARLadona的智能体在对抗HELIOS时取得了66.8%的胜率，这表明其策略的优越性。

此外，文章还对MARLadona智能体的行为进行了深入分析，并通过批评网络解释了智能体的意图，提供了对策略决策过程的洞察。这一分析不仅有助于理解智能体如何做出决策，也为进一步改进和优化MARLadona提供了指导。整体而言，MARLadona代表了机器人足球领域的一个重要进展，展示了深度学习技术在解决复杂任务中的潜力。 <div>
arXiv:2409.20326v1 Announce Type: new 
Abstract: Robot soccer, in its full complexity, poses an unsolved research challenge. Current solutions heavily rely on engineered heuristic strategies, which lack robustness and adaptability. Deep reinforcement learning has gained significant traction in various complex robotics tasks such as locomotion, manipulation, and competitive games (e.g., AlphaZero, OpenAI Five), making it a promising solution to the robot soccer problem. This paper introduces MARLadona. A decentralized multi-agent reinforcement learning (MARL) training pipeline capable of producing agents with sophisticated team play behavior, bridging the shortcomings of heuristic methods. Further, we created an open-source multi-agent soccer environment based on Isaac Gym. Utilizing our MARL framework and a modified a global entity encoder as our core architecture, our approach achieves a 66.8% win rate against HELIOS agent, which employs a state-of-the-art heuristic strategy. Furthermore, we provided an in-depth analysis of the policy behavior and interpreted the agent's intention using the critic network.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials</title>
<link>https://arxiv.org/abs/2401.11735</link>
<guid>https://arxiv.org/abs/2401.11735</guid>
<content:encoded><![CDATA[
<div> 关键词：zkLogin、零知识证明（ZKP）、身份令牌、Sui区块链、数字内容验证

总结:
文章主要介绍了zkLogin，一种新型技术，旨在简化区块链应用的用户认证过程。通过利用主流平台提供的OpenID Connect身份令牌，zkLogin允许用户使用现有账户进行交易认证，无需记忆额外秘密，显著提升用户体验。其核心是结合签名方案和零知识证明，确保安全性和隐私性，同时依赖于平台的认证机制，无需额外信任方。zkLogin不仅适用于区块链场景，还能让数十亿用户利用现有数字身份生产可验证的数字内容，如通过电子邮件地址签署新闻文章，实现作者身份的透明验证。该技术已在Sui区块链上实施并部署，提供了一种替代传统数字签名地址的方案。 <div>
arXiv:2401.11735v2 Announce Type: replace 
Abstract: For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications.
  We develop zkLogin, a novel technique that leverages identity tokens issued by popular platforms (any OpenID Connect enabled platform e.g., Google, Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a signature scheme allowing the signer to sign using their existing OpenID accounts and nothing else. This improves the user experience significantly as users do not need to remember a new secret and can reuse their existing accounts.
  zkLogin provides strong security and privacy guarantees. Unlike prior works, zkLogin's security relies solely on the underlying platform's authentication mechanism without the need for any additional trusted parties (e.g., trusted hardware or oracles). As the name suggests, zkLogin leverages zero-knowledge proofs (ZKP) to ensure that the sensitive link between a user's off-chain and on-chain identities is hidden, even from the platform itself.
  zkLogin enables a number of important applications outside blockchains. It allows billions of users to produce \textit{verifiable digital content leveraging their existing digital identities}, e.g., email address. For example, a journalist can use zkLogin to sign a news article with their email address, allowing verification of the article's authorship by any party.
  We have implemented and deployed zkLogin on the Sui blockchain as an additional alternative to traditional digital signature-based addresses.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAVED: Data Acquisition via Experimental Design for Data Markets</title>
<link>https://arxiv.org/abs/2403.13893</link>
<guid>https://arxiv.org/abs/2403.13893</guid>
<content:encoded><![CDATA[
<div> 关键词：数据市场、数据收购、联邦学习、预测误差、数据估值

总结:
本文探讨了在数据市场环境下，如何高效地进行数据收购以提升机器学习应用的性能。主要贡献包括：
1. 提出了基于联邦学习框架的数据收购方法，旨在解决数据稀缺领域如医疗保健中数据供应不足的问题。
2. 与传统数据估值方法不同，该方法不依赖于集中化数据访问，而是采用激励机制吸引潜在数据提供者加入市场。
3. 方法通过直接估计收购数据对测试集预测的影响来选择最有价值的数据点，这与当前市场设置高度兼容。
4. 实现了无需额外标注验证数据的低预测误差目标，优化过程快速且分布式，有助于提高数据利用效率。
5. 该研究揭示了在分散式市场环境中，一种直接评估数据获取对测试集预测效果的方法特别适用，为数据买家提供了策略上的指导。 <div>
arXiv:2403.13893v2 Announce Type: replace 
Abstract: The acquisition of training data is crucial for machine learning applications. Data markets can increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data providers to join the market. A major challenge for a data buyer in such a market is choosing the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data acquisition problem that is inspired by linear experimental design. Our proposed data acquisition method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hypergraph Approach to Distributed Broadcast</title>
<link>https://arxiv.org/abs/2404.16376</link>
<guid>https://arxiv.org/abs/2404.16376</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式广播、网络通信、超图理论、数据共享、算法优化

<br /><br />
总结:本文深入探讨了网络通信中的分布式广播问题，这是分散式信息传播的关键挑战。通过提出一种基于超图的新颖方法，旨在最小化广播次数以确保所有网络用户的全面数据共享。主要贡献包括使用超图的最小割容量建立问题的一般下限，以及为具有独特结构的准树设计的分布式广播算法（DBQT），证明其为最优解。这项研究不仅推进了网络通信策略和超图理论的发展，而且对各种实际应用具有重要意义，例如车用网络、传感器网络和分布式存储系统等。通过优化数据传输过程，提高了网络效率和资源利用率，为未来复杂网络环境下的信息传播提供了理论基础和实践指导。 <div>
arXiv:2404.16376v2 Announce Type: replace 
Abstract: This paper explores the distributed broadcast problem within the context of network communications, a critical challenge in decentralized information dissemination. We put forth a novel hypergraph-based approach to address this issue, focusing on minimizing the number of broadcasts to ensure comprehensive data sharing among all network users. The key contributions of this work include the establishment of a general lower bound for the problem using the min-cut capacity of hypergraphs, and a distributed broadcast for quasi-trees (DBQT) algorithm tailored for the unique structure of quasi-trees, which is proven to be optimal. This paper advances both network communication strategies and hypergraph theory, with implications for a wide range of real-world applications, from vehicular and sensor networks to distributed storage systems.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable UTXO Smart Contracts via Fine-Grained Distributed State</title>
<link>https://arxiv.org/abs/2406.07700</link>
<guid>https://arxiv.org/abs/2406.07700</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、UTXO模型、效率瓶颈、分布式状态、并行化验证

总结:

文章探讨了基于UTXO模型的智能合约平台所面临的效率问题，即任何发送给合约的交易都必须指定整个更新后的合约状态。这种需求在许多应用场景中变得尤为棘手，尤其是当合约状态包含动态数据结构时，用于追踪用户与合约之间的交互。问题主要体现在两个方面：一方面，交易中的大状态意味着高昂的交易费用；另一方面，大集中式状态阻碍了交易的并行化，这是UTXO区块链相对于账户型区块链的一大优势。

为了解决这个问题，文章提出了一种技术，允许在扩展的UTXO区块链上执行智能合约，使得合约状态可以分布在多个UTXO中。这样一来，交易只需要指定需要访问的部分状态，从而减少了交易大小（和费用）。作者展示了如何利用此模型在多核CPU上并行化交易验证过程，并实施了该技术，提供了其有效性的实证验证。通过这种方式，不仅降低了交易成本，还提高了系统性能和可扩展性。 <div>
arXiv:2406.07700v2 Announce Type: replace 
Abstract: Smart contract platforms based on the UTXO model face an efficiency bottleneck, in that any transaction sent to a contract must specify the entire updated contract state. This requirement becomes particularly burdensome when the contract state contains dynamic data structures, as needed in many use cases to track interactions between users and the contract. The problem is twofold: on the one hand, a large state in transactions implies a large transaction fee; on the other hand, a large centralized state is detrimental to the parallelization of transactions -- a feature that is often cited as a key advantage of UTXO-based blockchains over account-based ones. We propose a technique to efficiently execute smart contracts on an extended UTXO blockchain, which allows the contract state to be distributed across multiple UTXOs. In this way, transactions only need to specify the part of the state they need to access, reducing their size (and fees). We show how to exploit our model to parallelize the validation of transactions on multi-core CPUs. We implement our technique and provide an empirical validation of its effectiveness.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence</title>
<link>https://arxiv.org/abs/2301.05872</link>
<guid>https://arxiv.org/abs/2301.05872</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、压缩梯度方法、适应性步长、强凸性函数、非凸性函数

<br /><br />
总结:
本文研究了在通信受限环境下的多代理网络分布式优化问题。提出了“压缩精确扩散与自适应步长（CEDAS）”方法，这是一种压缩分散随机梯度方法。在无偏压缩操作下，CEDAS方法能够实现与集中式随机梯度下降（SGD）相似的收敛率，适用于平滑强凸目标函数和平滑非凸目标函数。特别地，当目标函数为平滑强凸时，CEDAS的暂态时间（与图特性相关）较短，表现为$\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$；对于平滑非凸目标函数，暂态时间为$\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$，其中$(1-\lambda_2)$表示混合矩阵的谱间隙，$C>0$是压缩相关的参数。当$C < \mathcal{O}(1/(1 - \lambda_2)^2)$时，CEDAS表现出最短的暂态时间，这一情况在实践中常见。数值实验进一步验证了所提算法的有效性。

<br /><br /> <div>
arXiv:2301.05872v3 Announce Type: replace-cross 
Abstract: In this paper, we consider solving the distributed optimization problem over a multi-agent network under the communication restricted setting. We study a compressed decentralized stochastic gradient method, termed ``compressed exact diffusion with adaptive stepsizes (CEDAS)", and show the method asymptotically achieves comparable convergence rate as centralized { stochastic gradient descent (SGD)} for both smooth strongly convex objective functions and smooth nonconvex objective functions under unbiased compression operators. In particular, to our knowledge, CEDAS enjoys so far the shortest transient time (with respect to the graph specifics) for achieving the convergence rate of centralized SGD, which behaves as $\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$ under smooth strongly convex objective functions, and $\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$ under smooth nonconvex objective functions, where $(1-\lambda_2)$ denotes the spectral gap of the mixing matrix, and $C>0$ is the compression-related parameter. In particular, CEDAS exhibits the shortest transient times when $C < \mathcal{O}(1/(1 - \lambda_2)^2)$, which is common in practice. Numerical experiments further demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Architecture for Protecting Data Privacy in Decentralized Social Networks</title>
<link>https://arxiv.org/abs/2409.18360</link>
<guid>https://arxiv.org/abs/2409.18360</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式社交网络、区块链技术、分散式储存网络、存取控制智能合约、用户隐私保护

<br /><br />
总结:

本文主要探讨了分散式社交网络的构建与应用，特别是通过结合区块链技术与分散式储存网络，并利用存取控制智能合约，以期解决传统集中式社交网络所面临的信息安全与隐私保护问题。研究首先进行了深入的文献回顾，对现有分散式社交网络进行分析，并指出其在隐私保护、数据控制权等方面的优点与局限性。

在回顾的基础上，作者提出了一种新的分散式社交网络架构设计，旨在为用户提供更强的数据主权和隐私保护。该架构通过区块链技术确保信息的不可篡改性与透明度，利用分散式储存网络降低数据存储成本和提高数据安全性，同时，存取控制智能合约则确保用户对其发布的信息有完全的控制权，符合通用数据保护条例（GDPR）的要求。

研究的主要成果强调了分散式社交网络在保护用户隐私方面的潜力，相较于传统集中式平台，用户能够更自主地管理自己的信息，享有更高的数据控制权。此外，该架构也展示了在实现高效、安全的信息分享的同时，兼顾了用户对隐私的保护需求，为未来社交网络的发展提供了一个可行的方向。 <div>
arXiv:2409.18360v1 Announce Type: new 
Abstract: Centralized social networks have experienced a transformative impact on our digital era communication, connection, and information-sharing information. However, it has also raised significant concerns regarding users' privacy and individual rights. In response to these concerns, this paper proposes a novel Decentralized Social Network employing Blockchain technology and Decentralized Storage Networks completed by Access Control Smart Contracts. The initial phase comprises a comprehensive literature review, delving into decentralized social networks, explaining the review methodology, and presenting the resulting findings. Building upon these findings and an analysis of previous research gaps, we propose a novel architecture for decentralized social networks. In conclusion, the principal results highlight the benefit of our decentralized social network to protect user privacy. Moreover, the users have all rights to their posted information following the General Data Protection Regulation (GDPR).
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Review of Digital Asset Development with Graph Neural Network Unlearning</title>
<link>https://arxiv.org/abs/2409.18455</link>
<guid>https://arxiv.org/abs/2409.18455</guid>
<content:encoded><![CDATA[
<div> 关键词：Graph Neural Networks、数据隐私、合规性、机器学习、数字资产

总结:
本文探讨了图神经网络（GNN）在数字资产管理中的关键作用，并引入了针对GNN架构的创新卸载技术。研究将卸载策略分为两大类：数据驱动的近似和模型驱动的近似。数据驱动的近似通过调整图结构来隔离并移除特定节点的影响；而模型驱动的近似则修改GNN的内部参数和架构。文章通过分析这些卸载方法的最新进展，强调了它们在欺诈检测、风险评估、代币关系预测和去中心化治理等应用场景中的适用性。同时，文章讨论了在实时金融应用中平衡模型性能与数据卸载需求的挑战。为了解决这一问题，提出了结合两种卸载策略优势的混合方法，以提高GNN在数字资产生态系统中的效率和有效性。最终目标是提供一个全面框架，用于理解并实施GNN卸载技术，为机器学习在数字资产领域的安全合规部署铺平道路。 <div>
arXiv:2409.18455v1 Announce Type: new 
Abstract: In the rapidly evolving landscape of digital assets, the imperative for robust data privacy and compliance with regulatory frameworks has intensified. This paper investigates the critical role of Graph Neural Networks (GNNs) in the management of digital assets and introduces innovative unlearning techniques specifically tailored to GNN architectures. We categorize unlearning strategies into two primary classes: data-driven approximation, which manipulates the graph structure to isolate and remove the influence of specific nodes, and model-driven approximation, which modifies the internal parameters and architecture of the GNN itself. By examining recent advancements in these unlearning methodologies, we highlight their applicability in various use cases, including fraud detection, risk assessment, token relationship prediction, and decentralized governance. We discuss the challenges inherent in balancing model performance with the requirements for data unlearning, particularly in the context of real-time financial applications. Furthermore, we propose a hybrid approach that combines the strengths of both unlearning strategies to enhance the efficiency and effectiveness of GNNs in digital asset ecosystems. Ultimately, this paper aims to provide a comprehensive framework for understanding and implementing GNN unlearning techniques, paving the way for secure and compliant deployment of machine learning in the digital asset domain.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartReco: Detecting Read-Only Reentrancy via Fine-Grained Cross-DApp Analysis</title>
<link>https://arxiv.org/abs/2409.18468</link>
<guid>https://arxiv.org/abs/2409.18468</guid>
<content:encoded><![CDATA[
<div> 关键词：SmartReco、Read-Only Reentrancy、DApps、智能合约、漏洞检测

总结:
本文提出了一种名为SmartReco的新框架，用于检测去中心化应用（DApps）中的读取只读重入（ROR）漏洞。SmartReco结合了静态分析和动态分析（即模糊测试）来检测智能合约中的漏洞。其核心设计包括：识别不同DApps之间的边界；对关键点进行精细静态分析；利用链上交易数据跨多个DApps执行多函数模糊测试验证ROR的存在。通过评估包含45个ROR的手动标记数据集，SmartReco实现了88.63%的精确度和86.36%的召回率。此外，SmartReco成功检测到123个流行DApps中的43个新ROR，受影响的资产总额约为52万美元。这表明SmartReco在提高DApps安全性方面具有显著潜力，能够有效识别和检测导致重大经济损失的新型漏洞。 <div>
arXiv:2409.18468v1 Announce Type: new 
Abstract: Despite the increasing popularity of Decentralized Applications (DApps), they are suffering from various vulnerabilities that can be exploited by adversaries for profits. Among such vulnerabilities, Read-Only Reentrancy (called ROR in this paper), is an emerging type of vulnerability that arises from the complex interactions between DApps. In the recent three years, attack incidents of ROR have already caused around 30M USD losses to the DApp ecosystem. Existing techniques for vulnerability detection in smart contracts can hardly detect Read-Only Reentrancy attacks, due to the lack of tracking and analyzing the complex interactions between multiple DApps. In this paper, we propose SmartReco, a new framework for detecting Read-Only Reentrancy vulnerability in DApps through a novel combination of static and dynamic analysis (i.e., fuzzing) over smart contracts. The key design behind SmartReco is threefold: (1) SmartReco identifies the boundary between different DApps from the heavy-coupled cross-contract interactions. (2) SmartReco performs fine-grained static analysis to locate points of interest (i.e., entry functions) that may lead to ROR. (3) SmartReco utilizes the on-chain transaction data and performs multi-function fuzzing (i.e., the entry function and victim function) across different DApps to verify the existence of ROR. Our evaluation of a manual-labeled dataset with 45 RORs shows that SmartReco achieves a precision of 88.63% and a recall of 86.36%. In addition, SmartReco successfully detects 43 new RORs from 123 popular DApps. The total assets affected by such RORs reach around 520,000 USD.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.18718</link>
<guid>https://arxiv.org/abs/2409.18718</guid>
<content:encoded><![CDATA[
<div> 关键词：GAIL、NTN、RL、IRL、Federated Learning

<br />
总结:

本文提出了一种基于生成对抗式模仿学习（GAIL）的新型策略学习方法，用于优化非地面网络（NTN）中的波束形成、频谱分配和远程用户设备（RUE）关联。该方法通过集成逆强化学习（IRL）与异步联邦学习，旨在最大化频谱效率（SE），同时满足RUE的最小信息速率要求。为了解决该问题的非凸性与NP-hard性质，引入了多对一匹配理论结合多代理异步联邦IRL（MA-AFIRL）框架。这种方法允许代理通过异步环境交互学习，提高了训练效率和可扩展性。

为了生成专家策略，使用鲸鱼优化算法（WOA）进行训练，以此作为GAIL框架中自动奖励函数的训练数据。实验结果表明，提出的MA-AFIRL方法在收敛速度和奖励值上相较于传统强化学习方法有14.6%的提升，这标志着6G NTN优化领域的一个新的基准。

本文的贡献在于提出了一种自动化、高效、可扩展的NTN优化策略学习方法，通过GAIL和联邦学习技术克服了传统RL方法的局限性，显著提高了网络性能并降低了人工设计奖励函数的复杂度。 <div>
arXiv:2409.18718v1 Announce Type: new 
Abstract: In this paper, a novel generative adversarial imitation learning (GAIL)-powered policy learning approach is proposed for optimizing beamforming, spectrum allocation, and remote user equipment (RUE) association in NTNs. Traditional reinforcement learning (RL) methods for wireless network optimization often rely on manually designed reward functions, which can require extensive parameter tuning. To overcome these limitations, we employ inverse RL (IRL), specifically leveraging the GAIL framework, to automatically learn reward functions without manual design. We augment this framework with an asynchronous federated learning approach, enabling decentralized multi-satellite systems to collaboratively derive optimal policies. The proposed method aims to maximize spectrum efficiency (SE) while meeting minimum information rate requirements for RUEs. To address the non-convex, NP-hard nature of this problem, we combine the many-to-one matching theory with a multi-agent asynchronous federated IRL (MA-AFIRL) framework. This allows agents to learn through asynchronous environmental interactions, improving training efficiency and scalability. The expert policy is generated using the Whale optimization algorithm (WOA), providing data to train the automatic reward function within GAIL. Simulation results show that the proposed MA-AFIRL method outperforms traditional RL approaches, achieving a $14.6\%$ improvement in convergence and reward value. The novel GAIL-driven policy learning establishes a novel benchmark for 6G NTN optimization.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Drawing the boundaries between Blockchain and Blockchain-like systems: A Comprehensive Survey on Distributed Ledger Technologies</title>
<link>https://arxiv.org/abs/2409.18799</link>
<guid>https://arxiv.org/abs/2409.18799</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、区块链、分类、参考模型、挑战

<br /><br />
总结:

本文是对区块链及其类似系统进行的一次全面的回顾和分类。首先，文章提出了一种以数据、共识、执行和应用四个关键层为基础的参考模型，为理解区块链的不同方面提供了一个框架。其次，引入了一种新的分类体系，旨在更准确地界定和区分各种分布式账本技术(DLT)和共识机制。通过对比分析44个DLT解决方案和26种共识机制，研究揭示了当前领域面临的几个主要挑战，并为未来的学术研究提供了方向。

这一研究有助于澄清“区块链”这一术语在不同系统中的应用，指出哪些系统遵循了区块链的核心原则，而哪些则偏离了这些原则，增加了生态系统中技术多样性和复杂性。此外，它强调了需要进一步研究的关键领域，以便更好地理解、设计和优化DLT和共识机制，从而推动区块链技术的发展与应用。 <div>
arXiv:2409.18799v1 Announce Type: new 
Abstract: Bitcoin's global success has led to the rise of blockchain, but many systems labeled as "blockchain" deviate from its core principles, adding complexity to the ecosystem. This survey addresses the need for a comprehensive review and taxonomy to clarify the differences between blockchain and blockchain-like systems. We propose a reference model with four key layers: data, consensus, execution, and application, and introduce a new taxonomy for better classification. Through a qualitative and quantitative analysis of 44 DLT solutions and 26 consensus mechanisms, we highlight key challenges and offer research directions in the field.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.18862</link>
<guid>https://arxiv.org/abs/2409.18862</guid>
<content:encoded><![CDATA[
<div> 关键词：安全控制、分散式多代理机器人、不确定黑盒模型、决策理论、控制障碍函数

<br /><br />
总结:本文聚焦于分散式多代理机器人环境中的安全控制问题，特别关注于利用不确定的黑盒模型预测其他代理行为轨迹的挑战。研究团队引入了近期提出的形变决策理论，以此来调整基于控制障碍函数的安全约束的严格程度，这些约束依赖于观察到的预测误差。通过这种方法，他们能够合成控制器，以平衡安全性和任务完成度之间的目标，即使存在预测误差。

为了验证理论的有效性，研究者们提供了时间平均值的上界，该值衡量了基于预测轨迹和实际轨迹的安全约束之间差别的单调函数价值。实验结果展示了在斯坦福无人机数据集中导航机器人时，所提出控制器的表现，证实了该方法在实际场景中的应用潜力与效果。

此研究为分散式多代理系统中的安全控制提供了一种新颖的方法，通过结合预测误差的动态适应性和任务目标的优化，旨在提高复杂环境下的机器人自主操作安全性。 <div>
arXiv:2409.18862v1 Announce Type: new 
Abstract: We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>XDC Gasless Subnet: Gasless Subnet Staking dApp for XDC Network</title>
<link>https://arxiv.org/abs/2409.17176</link>
<guid>https://arxiv.org/abs/2409.17176</guid>
<content:encoded><![CDATA[
<div> 关键词：XDPoS共识机制、XDC网络、低能耗、高效交易、无gas费

总结:

本文主要介绍了XDC网络，一个专注于企业应用的区块链平台。它结合了公共和私有区块链的优势，提供快速交易时间、低能耗和经济的气体费用。XDC设计用于互操作性，支持去中心化应用程序(dApps)，并能平滑地与金融系统集成。特别适合贸易融资和实物资产代币化，由于其强调安全性和可扩展性。

然而，文章指出了一些限制因素，阻碍了某些高频应用的广泛接受和使用。为解决这一问题，提出了一种创新的去中心化应用(dApp)，旨在创建一个无需gas费的子网。用户可以在主网上质押XDC，生成一个类似于非加密网络的子网，接受XDC网络上的货币费用。这使得质押过程更有效率、成本效益更高，并同时增强可扩展性。性能评估显示，在吞吐量、延迟、可扩展性、安全性和成本效率方面都有出色的结果。此外，文章讨论了此方法的应用案例、挑战以及应对策略。 <div>
arXiv:2409.17176v1 Announce Type: new 
Abstract: With a delegated proof-of-stake (XDPoS) consensus mechanism, the XDC Network is an enterprise-focused blockchain platform that combines the strength of public and private blockchains to provide quick transaction times, low energy consumption, and economical gas fees. XDC is designed for interoperability and supports decentralized apps (dApps) and integrates smoothly with financial systems. It is perfect for trade financing and tokenisation of physical assets because of its emphasis on security and scalability. However, there are a few critical issues that hamper wider acceptance and usability for certain high-frequency applications. This whitepaper introduces a novel and enthralling dApp for establishing a gasless subnet in which mainnet XDC can be staked to spin off a subnet that functions similarly to a non-crypto network, accepting currency fees on the XDC network. This would allow users to stake their tokens without incurring gas fees making the staking process more efficient, cost-effective, and simultaneously enhancing scalability. Performance evaluation of the dApp shows promising results in terms of throughput, latency, scalability, security, and cost efficiency. The use cases and applications of this approach along with challenges and ensuing solutions are included.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Variational Information Bottleneck for Data Extraction Based on Mutual Information in Internet of Vehicles</title>
<link>https://arxiv.org/abs/2409.17287</link>
<guid>https://arxiv.org/abs/2409.17287</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、车辆网络（IoV）、数据压缩、VIB技术、安全性增强

总结:

本文探讨了将区块链技术与车辆网络（IoV）结合的应用，以解决IoV网络中的计算资源限制和数据处理能力问题，同时加强用户隐私保护。文章提出了名为BVIB（Blockchain and VIB）的新方法，旨在减轻计算负载并增强网络安全性。BVIB通过分离编码和解码网络来解决计算负担问题，并提出了一种新的算法来提高IoV网络的安全性。研究还分析了数据提取率对系统延迟的影响，以确定最佳的数据提取率。为验证BVIB的有效性，构建了一个结合Python和C++的实验框架。全面的模拟研究表明，与基础方法相比，BVIB在多个指标上表现出色。

文章主要贡献如下：

1. **区块链与VIB技术整合**：BVIB方法将区块链技术与VIB（一种用于训练编码和解码模型的技术）相结合，以优化IoV网络的数据处理和传输。

2. **减轻计算负担**：通过分离编码和解码网络，BVIB设计减少了每个车辆需要处理的数据量，从而减轻了计算负担。

3. **增强网络安全**：BVIB不仅优化了数据传输效率，还通过引入区块链机制提高了网络的整体安全性，防止数据泄露和篡改。

4. **数据提取率优化**：文章研究了不同数据提取率对系统性能的影响，为实际应用提供了指导，确保在保证数据传输效率的同时，达到最佳的系统响应速度。

5. **实验验证与模拟研究**：通过构建实验框架并进行模拟研究，证明了BVIB方法在提升IoV网络效率和安全性方面的有效性。 <div>
arXiv:2409.17287v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV) network can address the issue of limited computing resources and data processing capabilities of individual vehicles, but it also brings the risk of privacy leakage to vehicle users. Applying blockchain technology can establish secure data links within the IoV, solving the problems of insufficient computing resources for each vehicle and the security of data transmission over the network. However, with the development of the IoV, the amount of data interaction between multiple vehicles and between vehicles and base stations, roadside units, etc., is continuously increasing. There is a need to further reduce the interaction volume, and intelligent data compression is key to solving this problem. The VIB technique facilitates the training of encoding and decoding models, substantially diminishing the volume of data that needs to be transmitted. This paper introduces an innovative approach that integrates blockchain with VIB, referred to as BVIB, designed to lighten computational workloads and reinforce the security of the network. We first construct a new network framework by separating the encoding and decoding networks to address the computational burden issue, and then propose a new algorithm to enhance the security of IoV networks. We also discuss the impact of the data extraction rate on system latency to determine the most suitable data extraction rate. An experimental framework combining Python and C++ has been established to substantiate the efficacy of our BVIB approach. Comprehensive simulation studies indicate that the BVIB consistently excels in comparison to alternative foundational methodologies.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Nonlinear Model Predictive Control for Safe Collision Avoidance in Quadrotor Teams with Limited Detection Range</title>
<link>https://arxiv.org/abs/2409.17379</link>
<guid>https://arxiv.org/abs/2409.17379</guid>
<content:encoded><![CDATA[
<div> 关键词：多旋翼系统、分散式控制、安全保证、动作约束、感知范围限制

总结:

本文主要探讨了多旋翼系统在分散式控制下的挑战，特别是安全性和协调性，当面临传感和通信限制时。当前的方法通常依赖于控制障碍函数（CBFs）来提供安全性保障，但往往忽视了动作约束和有限的检测范围。为解决这一问题，研究团队提出了一种新的分散式非线性模型预测控制（NMPC），该方法整合了指数CBF（ECBFs），以增强多旋翼系统的安全性和优化性能。

通过设置保守和实用的最小范围界限，以保持ECBFs的安全性，研究者确保了系统在实际应用中的可靠性。他们进行了大量模拟实验，涉及多达10个旋翼体和20个障碍物，并通过现实世界的实验验证了3个旋翼体的可行性。结果表明，所提出的方法在真实场景中表现良好，显示出其在可靠多旋翼团队操作中的潜力。

这一研究不仅扩展了CBFs的应用范围，还为多旋翼系统的分散式控制提供了更安全、更高效的技术路径，对未来的无人机团队操作具有重要意义。 <div>
arXiv:2409.17379v1 Announce Type: new 
Abstract: Multi-quadrotor systems face significant challenges in decentralized control, particularly with safety and coordination under sensing and communication limitations. State-of-the-art methods leverage Control Barrier Functions (CBFs) to provide safety guarantees but often neglect actuation constraints and limited detection range. To address these gaps, we propose a novel decentralized Nonlinear Model Predictive Control (NMPC) that integrates Exponential CBFs (ECBFs) to enhance safety and optimality in multi-quadrotor systems. We provide both conservative and practical minimum bounds of the range that preserve the safety guarantees of the ECBFs. We validate our approach through extensive simulations with up to 10 quadrotors and 20 obstacles, as well as real-world experiments with 3 quadrotors. Results demonstrate the effectiveness of the proposed framework in realistic settings, highlighting its potential for reliable quadrotor teams operations.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hierarchical Gradient Tracking Algorithm for Mitigating Subnet-Drift in Fog Learning Networks</title>
<link>https://arxiv.org/abs/2409.17430</link>
<guid>https://arxiv.org/abs/2409.17430</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Semi-decentralized FL、Gradient Tracking、Convergence、Efficiency

<br /><br />
总结:
本文主要探讨了在雾网络环境下，传统星型拓扑架构的联邦学习(Federated Learning, FL)所面临的可扩展性问题。针对基于设备到设备(D2D)通信的网络，提出了一种称为半去中心化联邦学习(Semi-decentralized Federated Learning, SD-FL)的方法。SD-FL将模型协作分为两个阶段：下层利用D2D通信在子网络内进行局部模型聚合，上层则负责设备到服务器(DEVICE-SERVER, DS)通信以实现全局模型聚合。然而，现有的SD-FL方案依赖于梯度多样性假设，当数据分布更加不均匀时，这些假设会成为性能瓶颈。

为了解决这一问题，作者提出了半去中心化梯度跟踪(Semi-decentralized Gradient Tracking, SD-GT)，这是第一个无需梯度多样性假设的SD-FL方法。通过在每个通信层中引入跟踪项，SD-GT能够改进模型训练质量和通信成本。作者对SD-GT进行了理论分析，给出了非凸、凸和强凸问题中的收敛性上界，并展示了如何通过调整子网采样率和D2D轮数来优化性能与效率之间的权衡。数值评估显示，与SD-FL和其他梯度跟踪基线相比，SD-GT在多个数据集上均表现出显著的改进。

通过上述研究，SD-GT提供了一种有效解决雾网络环境下联邦学习可扩展性问题的新方法，同时改善了模型性能并降低了通信成本。 <div>
arXiv:2409.17430v1 Announce Type: new 
Abstract: Federated learning (FL) encounters scalability challenges when implemented over fog networks that do not follow FL's conventional star topology architecture. Semi-decentralized FL (SD-FL) has proposed a solution for device-to-device (D2D) enabled networks that divides model cooperation into two stages: at the lower stage, D2D communications is employed for local model aggregations within subnetworks (subnets), while the upper stage handles device-server (DS) communications for global model aggregations. However, existing SD-FL schemes are based on gradient diversity assumptions that become performance bottlenecks as data distributions become more heterogeneous. In this work, we develop semi-decentralized gradient tracking (SD-GT), the first SD-FL methodology that removes the need for such assumptions by incorporating tracking terms into device updates for each communication layer. Our analytical characterization of SD-GT reveals upper bounds on convergence for non-convex, convex, and strongly-convex problems. We show how the bounds enable the development of an optimization algorithm that navigates the performance-efficiency trade-off by tuning subnet sampling rate and D2D rounds for each global training interval. Our subsequent numerical evaluations demonstrate that SD-GT obtains substantial improvements in trained model quality and communication cost relative to baselines in SD-FL and gradient tracking on several datasets.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Does Worst-Performing Agent Lead the Pack? Analyzing Agent Dynamics in Unified Distributed SGD</title>
<link>https://arxiv.org/abs/2409.17499</link>
<guid>https://arxiv.org/abs/2409.17499</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、统一分布式SGD（UD-SGD）、联邦学习（FL）、采样策略、中央极限定理（CLT）

<br /><br />
总结:
本文对统一分布式随机梯度下降(UD-SGD)进行了渐近分析，研究了包括去中心化SGD、局部SGD在内的多种通信模式以及联邦学习(Federa ted Learning, FL)中的通信间隔递增。文章探讨了不同的采样策略，如i.i.d.采样、打乱采样和马尔科夫采样，如何影响UD-SGD的收敛速度。通过考虑中央极限定理描述的代理动态对限制协方差矩阵的影响，研究发现，各种采样策略对整体收敛性有显著影响。模拟结果显示，采用高效采样的少数代理能够实现或超越采用改进但不甚高效的多数代理的整体性能。这一发现提供了超越传统聚焦于表现最差代理分析的新见解，证明了在UD-SGD中，高效采样策略的贡献至关重要。此外，研究支持了线性加速和网络依赖性的现有理论，并展示了个体代理所采取的高效采样策略对整体收敛性的积极促进作用。 <div>
arXiv:2409.17499v1 Announce Type: new 
Abstract: Distributed learning is essential to train machine learning algorithms across heterogeneous agents while maintaining data privacy. We conduct an asymptotic analysis of Unified Distributed SGD (UD-SGD), exploring a variety of communication patterns, including decentralized SGD and local SGD within Federated Learning (FL), as well as the increasing communication interval in the FL setting. In this study, we assess how different sampling strategies, such as i.i.d. sampling, shuffling, and Markovian sampling, affect the convergence speed of UD-SGD by considering the impact of agent dynamics on the limiting covariance matrix as described in the Central Limit Theorem (CLT). Our findings not only support existing theories on linear speedup and asymptotic network independence, but also theoretically and empirically show how efficient sampling strategies employed by individual agents contribute to overall convergence in UD-SGD. Simulations reveal that a few agents using highly efficient sampling can achieve or surpass the performance of the majority employing moderately improved strategies, providing new insights beyond traditional analyses focusing on the worst-performing agent.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BioZero: An Efficient and Privacy-Preserving Decentralized Biometric Authentication Protocol on Open Blockchain</title>
<link>https://arxiv.org/abs/2409.17509</link>
<guid>https://arxiv.org/abs/2409.17509</guid>
<content:encoded><![CDATA[
<div> 关键词：数字身份、生物识别、区块链、去中心化、零知识证明

<br /><br />
总结:本文提出了BioZero，一种基于开放区块链的高效、隐私保护的去中心化生物特征认证协议。该协议利用Pedersen承诺和同态计算保护用户生物特征隐私的同时，实现高效验证。通过引入非交互式同态计算和零知识证明，BioZero实现了安全的链上验证。其独特的特性在于完全去中心化，并能由区块链智能合约高效执行。文章分析了BioZero的安全性，并通过原型实现验证了其性能。结果表明，BioZero在去中心化认证场景中具有有效性、效率和安全性。本研究对使用生物特征进行分散式身份认证的进展做出了贡献。 <div>
arXiv:2409.17509v1 Announce Type: new 
Abstract: Digital identity plays a vital role in enabling secure access to resources and services in the digital world. Traditional identity authentication methods, such as password-based and biometric authentications, have limitations in terms of security, privacy, and scalability. Decentralized authentication approaches leveraging blockchain technology have emerged as a promising solution. However, existing decentralized authentication methods often rely on indirect identity verification (e.g. using passwords or digital signatures as authentication credentials) and face challenges such as Sybil attacks. In this paper, we propose BioZero, an efficient and privacy-preserving decentralized biometric authentication protocol that can be implemented on open blockchain. BioZero leverages Pedersen commitment and homomorphic computation to protect user biometric privacy while enabling efficient verification. We enhance the protocol with non-interactive homomorphic computation and employ zero-knowledge proofs for secure on-chain verification. The unique aspect of BioZero is that it is fully decentralized and can be executed by blockchain smart contracts in a very efficient way. We analyze the security of BioZero and validate its performance through a prototype implementation. The results demonstrate the effectiveness, efficiency, and security of BioZero in decentralized authentication scenarios. Our work contributes to the advancement of decentralized identity authentication using biometrics.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AsIf: Asset Interface Analysis of Industrial Automation Devices</title>
<link>https://arxiv.org/abs/2409.17593</link>
<guid>https://arxiv.org/abs/2409.17593</guid>
<content:encoded><![CDATA[
<div> 关键词：工业控制系统、威胁建模、资产分析、物理威胁、ISO/OSI参考模型

<br /><br />
总结:
本文探讨了随着工业4.0和工业物联网的发展，工业控制系统如何采用IT解决方案，特别是通信标准和协议。文章强调了在系统变得更加分散和互联时，增强安全措施的需求日益迫切。传统的威胁建模方法往往依赖于结构化的头脑风暴会议，由领域专家和安全专家参与，但这种方法经常未能提供全面的资产和接口识别，导致威胁建模不足，进而影响到安全架构的构建。

为解决这一问题，作者提出了一种方法，用于分析工业系统中的资产，特别关注物理威胁。该方法借鉴了ISO/OSI参考模型，引入了一种系统化的方法来识别并分类资产接口。通过这种方法，可以生成一个包含资产详细信息的丰富系统模型，以可视化形式呈现为接口树，从而为后续的威胁建模步骤打下基础。

为了验证所提方法的有效性，作者对一组12名安全专家进行了研究，展示了方法应用于可编程逻辑控制器（PLC）的结果。研究不仅展示了方法的应用实例，还提供了专家们对威胁建模的一般观点和工作流程的宝贵见解。这些发现对于理解当前威胁建模实践以及改进方法论具有重要意义。 <div>
arXiv:2409.17593v1 Announce Type: new 
Abstract: As Industry 4.0 and the Industrial Internet of Things continue to advance, industrial control systems are increasingly adopting IT solutions, including communication standards and protocols. As these systems become more decentralized and interconnected, a critical need for enhanced security measures arises. Threat modeling is traditionally performed in structured brainstorming sessions involving domain and security experts. Such sessions, however, often fail to provide an exhaustive identification of assets and interfaces due to the lack of a systematic approach. This is a major issue, as it leads to poor threat modeling, resulting in insufficient mitigation strategies and, lastly, a flawed security architecture.
  We propose a method for the analysis of assets in industrial systems, with special focus on physical threats. Inspired by the ISO/OSI reference model, a systematic approach is introduced to help identify and classify asset interfaces. This results in an enriched system model of the asset, offering a comprehensive overview visually represented as an interface tree, thereby laying the foundation for subsequent threat modeling steps. To demonstrate the proposed method, the results of its application to a programmable logic controller (PLC) are presented. In support of this, a study involving a group of 12 security experts was conducted. Additionally, the study offers valuable insights into the experts' general perspectives and workflows on threat modeling.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Verifying Randomized Consensus Protocols with Common Coins</title>
<link>https://arxiv.org/abs/2409.17627</link>
<guid>https://arxiv.org/abs/2409.17627</guid>
<content:encoded><![CDATA[
<div> 关键词：随机化、容错共识、公共硬币、阈值自动机、概率阈值自动机

<br />
<br />总结:

本文探讨了随机化容错共识协议在云计算和区块链平台中的广泛应用。这些协议的关键在于确保其正确性，因此需要一种形式化的模型进行验证。文章提出了一种扩展，将概率阈值自动机（PTA）应用于验证具有公共硬币的随机化容错共识协议。这与传统的PTA不同，后者仅适用于具有本地硬币的协议。

首先，作者引入了一个过程来模拟公共硬币（即“公共硬币过程”），以克服由于添加此过程而引发的对称性的破坏和技术挑战。通过一系列创新方法，他们证明了如何适应PTA以克服这些挑战。

接着，应用这一新方法验证了8个具有公共硬币的随机化共识协议的三个关键属性：一致性、有效性以及几乎必然终止。这表明该扩展的PTA模型不仅能够处理具有公共硬币的协议，而且能够有效地验证其核心特性，为确保此类协议的可靠性提供了坚实基础。 <div>
arXiv:2409.17627v1 Announce Type: new 
Abstract: Randomized fault-tolerant consensus protocols with common coins are widely used in cloud computing and blockchain platforms. Due to their fundamental role, it is vital to guarantee their correctness. Threshold automata is a formal model designed for the verification of fault-tolerant consensus protocols. It has recently been extended to probabilistic threshold automata (PTAs) to verify randomized fault-tolerant consensus protocols. Nevertheless, PTA can only model randomized consensus protocols with local coins.
  In this work, we extend PTA to verify randomized fault-tolerant consensus protocols with common coins. Our main idea is to add a process to simulate the common coin (the so-called common-coin process). Although the addition of the common-coin process destroys the symmetry and poses technical challenges, we show how PTA can be adapted to overcome the challenges. We apply our approach to verify the agreement, validity and almost-sure termination properties of 8 randomized consensus protocols with common coins.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Robust Aggregation for Securing Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2409.17754</link>
<guid>https://arxiv.org/abs/2409.17754</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、去中心化联邦学习、拜占庭鲁棒性、聚合算法、动态分散拓扑

总结:
本文提出了一种名为WFAgg的新型去中心化联邦学习（DFL）中的拜占庭鲁棒聚合算法。WFAgg通过采用多重过滤器来识别并缓解拜占庭攻击，同时处理动态分散拓扑的恶劣条件和强度稳定性问题。实验结果表明，该算法在各种拜占庭攻击场景下，能够保持模型准确性和收敛性，并在与现有集中式拜占庭鲁棒聚合方案（如Multi-Krum或聚类）比较中表现出优越性能。研究进一步验证了WFAgg在集中式和去中心化场景下的应用效果，特别是针对同方差图像分类问题。

文章首先介绍了联邦学习作为分布式机器学习方法，特别强调了其在保护隐私方面的优势。接着，指出去中心化联邦学习通过消除中央服务器，增强了系统的扩展性和鲁棒性，但同时也面临安全性的新挑战，尤其是拜占庭攻击。为此，文章提出了WFAgg算法，旨在提高DFL环境的安全性。通过实验验证，证明了WFAgg在不同拜占庭攻击情况下的有效性和优越性，特别是在模型准确性、收敛性和对动态分散拓扑的适应性方面优于现有的集中式鲁棒聚合方案。最后，研究还探讨了WFAgg在集中式和去中心化设置下的应用，特别是在同方差图像分类任务上的表现。 <div>
arXiv:2409.17754v1 Announce Type: new 
Abstract: Federated Learning (FL) emerges as a distributed machine learning approach that addresses privacy concerns by training AI models locally on devices. Decentralized Federated Learning (DFL) extends the FL paradigm by eliminating the central server, thereby enhancing scalability and robustness through the avoidance of a single point of failure. However, DFL faces significant challenges in optimizing security, as most Byzantine-robust algorithms proposed in the literature are designed for centralized scenarios. In this paper, we present a novel Byzantine-robust aggregation algorithm to enhance the security of Decentralized Federated Learning environments, coined WFAgg. This proposal handles the adverse conditions and strength robustness of dynamic decentralized topologies at the same time by employing multiple filters to identify and mitigate Byzantine attacks. Experimental results demonstrate the effectiveness of the proposed algorithm in maintaining model accuracy and convergence in the presence of various Byzantine attack scenarios, outperforming state-of-the-art centralized Byzantine-robust aggregation schemes (such as Multi-Krum or Clustering). These algorithms are evaluated on an IID image classification problem in both centralized and decentralized scenarios.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stackelberg Attack on Protocol Fee Governance</title>
<link>https://arxiv.org/abs/2409.17756</link>
<guid>https://arxiv.org/abs/2409.17756</guid>
<content:encoded><![CDATA[
<div> 关键词：Stackelberg攻击、流动性提供者、智能合约、Grim Forker、AMM

总结:

本文探讨了流动性提供者利用智能合约进行的Stackelberg攻击策略，以影响自动化市场制作（AMM）的治理。通过Grim Forker智能合约，流动性提供者可以实施分叉和承诺策略，动态地调整AMM储备和交易量，从而对系统产生影响。文章构建了一个基于区块的AMM模型，分析了存在协议费用的情况下的均衡条件，并深入研究了智能合约行动下的Stackelberg均衡。

首先，文章阐述了流动性提供者如何通过智能合约实施Stackelberg攻击，这种攻击策略旨在操纵AMM的治理过程，为自身利益服务。接着，作者构建了一个动态模型，该模型考虑了区块级别的AMM储备变化和交易量调整，揭示了在竞争性分叉环境中的行为模式。进一步地，文章引入了协议费用的概念，详细分析了这些费用如何影响系统的均衡状态，以及流动性提供者如何在这些条件下优化其策略。

最后，文章集中研究了在智能合约干预下出现的Stackelberg均衡问题，即在流动性提供者采取先发制人的策略与后续反应之间寻找最优解的过程。整体而言，该研究提供了对AMM中复杂交互和动态决策机制的深刻洞察，对于理解AMM的运作机制以及潜在的攻击手段具有重要意义。 <div>
arXiv:2409.17756v1 Announce Type: new 
Abstract: We establish a Stackelberg attack by Liquidity Providers against Governance of an AMM, leveraging forking and commitments through a Grim Forker smart contract. We produce a dynamic, block-by-block model of AMM reserves and trading volume in the presence of competing forks, derive equilibrium conditions in the presence of protocol fees, and analyze Stackelberg equilibria with smart contract moves.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Swarm-LIO2: Decentralized, Efficient LiDAR-inertial Odometry for UAV Swarms</title>
<link>https://arxiv.org/abs/2409.17798</link>
<guid>https://arxiv.org/abs/2409.17798</guid>
<content:encoded><![CDATA[
<div> 关键词：Aerial swarm systems、Swarm-LIO2、LiDAR-inertial odometry、Decentralized、Plug-and-play

总结:

本文提出了一种名为Swarm-LIO2的全分布式、插拔式、计算效率高且带宽效率高的激光雷达惯性导航系统，专为无人机群系统设计。Swarm-LIO2采用全分布式、插拔式网络作为通信基础设施，仅交换高效且低维的信息，如身份、自身状态、相互观测测量和全局外参。为了实现新成员的无缝加入，系统能够自动检测潜在的队友无人机并初始化时间偏移和全局外参。为了提高初始化效率，文章提出了基于反射率的无人机检测方法、轨迹匹配技术和因子图优化方法。

在状态估计方面，Swarm-LIO2在有效扩展卡尔曼滤波框架下融合了激光雷达、IMU和相互观测数据，对时间延迟进行了精确补偿，并对测量进行了建模，以提升准确性和一致性。此系统旨在解决无人机群中自我与相互状态估计的挑战，对于推进无人机群在协作探索、目标跟踪、搜索救援等任务中的应用具有重要意义。 <div>
arXiv:2409.17798v1 Announce Type: new 
Abstract: Aerial swarm systems possess immense potential in various aspects, such as cooperative exploration, target tracking, search and rescue. Efficient, accurate self and mutual state estimation are the critical preconditions for completing these swarm tasks, which remain challenging research topics. This paper proposes Swarm-LIO2: a fully decentralized, plug-and-play, computationally efficient, and bandwidth-efficient LiDAR-inertial odometry for aerial swarm systems. Swarm-LIO2 uses a decentralized, plug-and-play network as the communication infrastructure. Only bandwidth-efficient and low-dimensional information is exchanged, including identity, ego-state, mutual observation measurements, and global extrinsic transformations. To support the plug-and-play of new teammate participants, Swarm-LIO2 detects potential teammate UAVs and initializes the temporal offset and global extrinsic transformation all automatically. To enhance the initialization efficiency, novel reflectivity-based UAV detection, trajectory matching, and factor graph optimization methods are proposed. For state estimation, Swarm-LIO2 fuses LiDAR, IMU, and mutual observation measurements within an efficient ESIKF framework, with careful compensation of temporal delay and modeling of measurements to enhance the accuracy and consistency.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hypergame Theory for Decentralized Resource Allocation in Multi-user Semantic Communications</title>
<link>https://arxiv.org/abs/2409.17985</link>
<guid>https://arxiv.org/abs/2409.17985</guid>
<content:encoded><![CDATA[
<div> 关键词：多用户、语义通信、Stackelberg超博弈、资源分配、感知偏差

总结:

本文提出了一种针对多用户语义通信系统的新框架，旨在高效地在去中心化环境中分配通信和计算资源，以最大化用户体验质量。该框架利用Stackelberg超博弈理论解决资源分配问题，特别考虑了用户对彼此通信与控制策略的感知偏差。通过引入第二级超游戏概念，文章构建了描述感知偏差的新型分析模型，并对学习到的资源分配协议的均衡性进行了平衡分析，确保了计算与通信策略收敛至局部Stackelberg均衡点。

该方法通过优化资源分配策略，不仅实现了高效的资源使用，还显著提升了用户的体验质量，相较于不考虑感知偏差的传统方法，表现出更好的性能。实验结果证实了所提Stackelberg超博弈方法的有效性和优越性，证明其在多用户语义通信系统中的应用潜力巨大。 <div>
arXiv:2409.17985v1 Announce Type: new 
Abstract: Semantic communications (SC) is an emerging communication paradigm in which wireless devices can send only relevant information from a source of data while relying on computing resources to regenerate missing data points. However, the design of a multi-user SC system becomes more challenging because of the computing and communication overhead required for coordination. Existing solutions for learning the semantic language and performing resource allocation often fail to capture the computing and communication tradeoffs involved in multiuser SC. To address this gap, a novel framework for decentralized computing and communication resource allocation in multiuser SC systems is proposed. The challenge of efficiently allocating communication and computing resources (for reasoning) in a decentralized manner to maximize the quality of task experience for the end users is addressed through the application of Stackelberg hyper game theory. Leveraging the concept of second-level hyper games, novel analytical formulations are developed to model misperceptions of the users about each other's communication and control strategies. Further, equilibrium analysis of the learned resource allocation protocols examines the convergence of the computing and communication strategies to a local Stackelberg equilibria, considering misperceptions. Simulation results show that the proposed Stackelberg hyper game results in efficient usage of communication and computing resources while maintaining a high quality of experience for the users compared to state-of-the-art that does not account for the misperceptions.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Federated Learning with Gradient Tracking over Time-Varying Directed Networks</title>
<link>https://arxiv.org/abs/2409.17189</link>
<guid>https://arxiv.org/abs/2409.17189</guid>
<content:encoded><![CDATA[
<div> 关键词：时间变化、分布式学习、联邦学习、共识算法、线性收敛

总结:

本文研究了在随时间变化的有向图中，多智能体之间的交互问题，提出了名为DSGTm-TV的基于共识的算法。该算法结合了梯度跟踪和重球动量方法，用于分布式优化全局目标函数，同时保护本地数据隐私。通过行和列概率转移矩阵实现邻近智能体之间信息交换，确保了共识和最优性的达成。

分析表明，当可用精确梯度信息时，DSGTm-TV表现出线性收敛至精确全局最优解；使用随机梯度时，收敛于全局最优解的邻域。与现有方法相比，DSGTm-TV在不协调的步长和动量参数下仍能保持收敛，提供明确的边界。这使得智能体能够在完全去中心化的环境中独立优化其本地超参数。

研究通过在真实世界图像分类和自然语言处理任务上的比较实验，验证了DSGTm-TV的有效性，相较于最先进的基线方法显示出更好的性能。 <div>
arXiv:2409.17189v1 Announce Type: cross 
Abstract: We investigate the problem of agent-to-agent interaction in decentralized (federated) learning over time-varying directed graphs, and, in doing so, propose a consensus-based algorithm called DSGTm-TV. The proposed algorithm incorporates gradient tracking and heavy-ball momentum to distributively optimize a global objective function, while preserving local data privacy. Under DSGTm-TV, agents will update local model parameters and gradient estimates using information exchange with neighboring agents enabled through row- and column-stochastic mixing matrices, which we show guarantee both consensus and optimality. Our analysis establishes that DSGTm-TV exhibits linear convergence to the exact global optimum when exact gradient information is available, and converges in expectation to a neighborhood of the global optimum when employing stochastic gradients. Moreover, in contrast to existing methods, DSGTm-TV preserves convergence for networks with uncoordinated stepsizes and momentum parameters, for which we provide explicit bounds. These results enable agents to operate in a fully decentralized manner, independently optimizing their local hyper-parameters. We demonstrate the efficacy of our approach via comparisons with state-of-the-art baselines on real-world image classification and natural language processing tasks.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain</title>
<link>https://arxiv.org/abs/2409.16444</link>
<guid>https://arxiv.org/abs/2409.16444</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、物联网、深强化学习、智能城市、数据安全

总结:
本文探讨了区块链与深度强化学习（DRL）在物联网（IoT）辅助智能城市中的整合应用，以优化移动传输和确保数据交换的安全性。研究通过将物联网应用系统进行聚类和分类，展示了DRL与区块链结合如何提升IoT网络性能，同时维持隐私与安全性。文章回顾了2015年至2024年间发表的论文，对提出的方法进行了分类和提供实用分类体系，为研究人员提供了关键视角并指出了未来研究的潜在领域。研究发现，将区块链的去中心化架构与DRL结合，可以解决隐私和安全问题，提高移动传输效率，并确保稳定、隐私保护的物联网系统。此外，文章还探讨了区块链集成在DRL中的应用以及DRL技术的显著应用。通过解决机器学习与区块链集成的挑战，该研究提出了跨学科视角下的新观点，为研究人员提供了宝贵的资源。 <div>
arXiv:2409.16444v1 Announce Type: new 
Abstract: The accelerated expansion of the Internet of Things (IoT) has raised critical challenges associated with privacy, security, and data integrity, specifically in infrastructures such as smart cities or smart manufacturing. Blockchain technology provides immutable, scalable, and decentralized solutions to address these challenges, and integrating deep reinforcement learning (DRL) into the IoT environment offers enhanced adaptability and decision-making. This paper investigates the integration of blockchain and DRL to optimize mobile transmission and secure data exchange in IoT-assisted smart cities. Through the clustering and categorization of IoT application systems, the combination of DRL and blockchain is shown to enhance the performance of IoT networks by maintaining privacy and security. Based on the review of papers published between 2015 and 2024, we have classified the presented approaches and offered practical taxonomies, which provide researchers with critical perspectives and highlight potential areas for future exploration and research. Our investigation shows how combining blockchain's decentralized framework with DRL can address privacy and security issues, improve mobile transmission efficiency, and guarantee robust, privacy-preserving IoT systems. Additionally, we explore blockchain integration for DRL and outline the notable applications of DRL technology. By addressing the challenges of machine learning and blockchain integration, this study proposes novel perspectives for researchers and serves as a foundational exploration from an interdisciplinary standpoint.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Flight: A FaaS-Based Framework for Complex and Hierarchical Federated Learning</title>
<link>https://arxiv.org/abs/2409.16495</link>
<guid>https://arxiv.org/abs/2409.16495</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Flight框架、复杂层级多级拓扑、异步聚合、控制平面与数据平面解耦

总结:
文章介绍了一种新型联邦学习（FL）框架——Flight。相较于现有框架，Flight支持复杂层级多级网络拓扑结构，允许设备在异步情况下进行聚合操作，并实现了控制平面和数据平面的分离。与当前最先进的FL框架Flower相比，Flight展现出更好的扩展性，能够同时支持高达2048台设备。实验证明，Flight能够显著减少联邦学习的完成时间（即FL完成周期），并且通过其层级化的FL模型，降低了通信开销超过60%。这一创新为处理大规模分布式系统中的机器学习任务提供了更高效的解决方案，特别适用于物联网等实际应用场景。 <div>
arXiv:2409.16495v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning paradigm where models are trained on distributed devices and are aggregated at a central server. Existing FL frameworks assume simple two-tier network topologies where end devices are directly connected to the aggregation server. While this is a practical mental model, it does not exploit the inherent topology of real-world distributed systems like the Internet-of-Things. We present Flight, a novel FL framework that supports complex hierarchical multi-tier topologies, asynchronous aggregation, and decouples the control plane from the data plane. We compare the performance of Flight against Flower, a state-of-the-art FL framework. Our results show that Flight scales beyond Flower, supporting up to 2048 simultaneous devices, and reduces FL makespan across several models. Finally, we show that Flight's hierarchical FL model can reduce communication overheads by more than 60%.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning with Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16720</link>
<guid>https://arxiv.org/abs/2409.16720</guid>
<content:encoded><![CDATA[
<div> 关键词：自主无人机、时间最优飞行、多无人机系统、强化学习、分散式策略网络

<br />
<br />总结:

本文提出了一种基于多智能体强化学习的分散式策略网络，用于实现多无人机系统的高效时间最优飞行。该方法通过引入软碰撞惩罚机制，结合优化方法的思想，平衡了飞行效率与碰撞规避。利用集中式训练、分散式执行（CTDE）方式定制PPO算法，显著提升了训练效率和稳定性，同时保证了轻量化实施。模拟实验结果显示，尽管与单无人机系统相比在性能上略有折衷，但多无人机方案仍能保持接近时间最优的表现，并具有较低的碰撞率。实验证明，两个四旋翼无人机使用相同的网络模型，在一个5.5米*5.5米*2.0米的空间内，以最大速度达到13.65米/秒和最大身体角速度达到13.4弧度/秒，完全依赖于机载计算完成各种轨道任务。 <div>
arXiv:2409.16720v1 Announce Type: new 
Abstract: Recent innovations in autonomous drones have facilitated time-optimal flight in single-drone configurations and enhanced maneuverability in multi-drone systems through the application of optimal control and learning-based methods. However, few studies have achieved time-optimal motion planning for multi-drone systems, particularly during highly agile maneuvers or in dynamic scenarios. This paper presents a decentralized policy network for time-optimal multi-drone flight using multi-agent reinforcement learning. To strike a balance between flight efficiency and collision avoidance, we introduce a soft collision penalty inspired by optimization-based methods. By customizing PPO in a centralized training, decentralized execution (CTDE) fashion, we unlock higher efficiency and stability in training, while ensuring lightweight implementation. Extensive simulations show that, despite slight performance trade-offs compared to single-drone systems, our multi-drone approach maintains near-time-optimal performance with low collision rates. Real-world experiments validate our method, with two quadrotors using the same network as simulation achieving a maximum speed of 13.65 m/s and a maximum body rate of 13.4 rad/s in a 5.5 m * 5.5 m * 2.0 m space across various tracks, relying entirely on onboard computation.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Robot Informative Path Planning for Efficient Target Mapping using Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16967</link>
<guid>https://arxiv.org/abs/2409.16967</guid>
<content:encoded><![CDATA[
<div> 关键词：自主机器人、多机器人、信息路径规划、深度强化学习、开源代码

<br /><br />总结:

本文提出了一种利用深度强化学习进行多机器人信息路径规划的新方法，以在未知三维环境中高效地发现目标。该方法的核心在于构建了一个增强图模型，用于预测和避免其他机器人的轨迹冲突，同时规划通信路径和避障策略。通过集中式训练和分散式执行的方式，我们的算法可以适应不同数量的机器人，并且不需要重新训练，具有良好的扩展性和鲁棒性。实验结果表明，与现有的多机器人目标映射技术相比，我们的方法在发现目标数量上提高了33.75%。为了促进研究和应用，我们还公开了实现这一算法的源代码和模型。

文章主要贡献如下：

1. **提出增强图模型**：构建了一个模型来预测和避免其他机器人之间的轨迹冲突，同时考虑通信路径的规划，以优化多机器人系统的整体性能。

2. **集中式训练与分散式执行**：采用这种策略训练分散的机器人政策，使得系统能够有效应对不同数量的机器人，而无需重新训练，增强了系统的灵活性和适应性。

3. **多目标发现能力**：通过优化路径规划，提高了在未知环境中的目标发现效率，与现有技术相比，显著提升了目标发现的数量。

4. **开源资源**：提供了一个开放的平台，使得其他研究人员和开发者可以访问和使用我们的代码及模型，促进了多机器人技术的研究和应用。

5. **实际应用潜力**：该方法不仅在理论上有创新，而且在实践中具有很高的应用价值，适用于各种需要多机器人协作进行数据收集和环境探索的任务场景。 <div>
arXiv:2409.16967v1 Announce Type: new 
Abstract: Autonomous robots are being employed in several mapping and data collection tasks due to their efficiency and low labor costs. In these tasks, the robots are required to map targets-of-interest in an unknown environment while constrained to a given resource budget such as path length or mission time. This is a challenging problem as each robot has to not only detect and avoid collisions from static obstacles in the environment but also has to model other robots' trajectories to avoid inter-robot collisions. We propose a novel deep reinforcement learning approach for multi-robot informative path planning to map targets-of-interest in an unknown 3D environment. A key aspect of our approach is an augmented graph that models other robots' trajectories to enable planning for communication and inter-robot collision avoidance. We train our decentralized reinforcement learning policy via the centralized training and decentralized execution paradigm. Once trained, our policy is also scalable to varying number of robots and does not require re-training. Our approach outperforms other state-of-the-art multi-robot target mapping approaches by 33.75% in terms of the number of discovered targets-of-interest. We open-source our code and model at: https://github.com/AccGen99/marl_ipp
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Agent Multi-Environment Mixed Q-Learning for Partially Decentralized Wireless Network Optimization</title>
<link>https://arxiv.org/abs/2409.16450</link>
<guid>https://arxiv.org/abs/2409.16450</guid>
<content:encoded><![CDATA[
<div> 关键词：Q-learning、多环境混合Q学习（MEMQ）、无线网络、多代理、部分去中心化

总结:
文章探讨了在部分去中心化的无线网络中，特别是由多个移动发射器（TXs）和基站（BSs）构成的网络环境下，如何有效利用多环境混合Q学习（MEMQ）算法进行策略优化。主要关注于解决大型状态空间带来的挑战，通过将多个Q学习算法集成在相关环境（所谓的“数字表亲”）中来提高性能并降低复杂性。然而，传统的MEMQ设计局限于单一集中式代理网络，不适用于分散或多代理网络。

为解决这一问题，研究提出了一种新型的多代理MEMQ算法，专门针对部分去中心化无线网络。在这个算法中，独立的TXs在非协调状态下各自行动以最小化个体成本，而在协调状态下，TXs使用贝叶斯方法根据本地观察结果估计联合状态，并与领导TX共享有限信息以最小化联合成本。这种信息共享的成本线性增长，与联合状态-动作空间的大小无关。

该算法的实施显著提高了效率，相比集中式MEMQ，平均策略误差（APE）增加了20%，但比几种先进的分散式Q学习算法快了25%，同时APE减少了40%。此外，算法的收敛性也得到了验证。通过对比实验，证明了该算法在处理部分去中心化无线网络中的高效性和实用性。 <div>
arXiv:2409.16450v1 Announce Type: cross 
Abstract: Q-learning is a powerful tool for network control and policy optimization in wireless networks, but it struggles with large state spaces. Recent advancements, like multi-environment mixed Q-learning (MEMQ), improves performance and reduces complexity by integrating multiple Q-learning algorithms across multiple related environments so-called digital cousins. However, MEMQ is designed for centralized single-agent networks and is not suitable for decentralized or multi-agent networks. To address this challenge, we propose a novel multi-agent MEMQ algorithm for partially decentralized wireless networks with multiple mobile transmitters (TXs) and base stations (BSs), where TXs do not have access to each other's states and actions. In uncoordinated states, TXs act independently to minimize their individual costs. In coordinated states, TXs use a Bayesian approach to estimate the joint state based on local observations and share limited information with leader TX to minimize joint cost. The cost of information sharing scales linearly with the number of TXs and is independent of the joint state-action space size. The proposed scheme is 50% faster than centralized MEMQ with only a 20% increase in average policy error (APE) and is 25% faster than several advanced decentralized Q-learning algorithms with 40% less APE. The convergence of the algorithm is also demonstrated.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Physics Enhanced Residual Policy Learning (PERPL) for safety cruising in mixed traffic platooning under actuator and communication delay</title>
<link>https://arxiv.org/abs/2409.15595</link>
<guid>https://arxiv.org/abs/2409.15595</guid>
<content:encoded><![CDATA[
<div> 关键词：线性控制模型、强化学习、物理信息政策、分散式控制、混合交通队列

<br /><br />
总结:

本文提出了一种名为“物理增强残差策略学习”（PERPL）的框架，旨在结合物理基础模型和强化学习的优点。物理基础模型提供高效的数据处理能力和可解释性，而强化学习则具备适应多目标场景和快速计算的能力。PERPL框架通过引入物理组件来提升模型的可解释性和稳定性，同时利用学习到的残差策略对物理模型进行调整以适应环境变化，从而优化决策过程。

该研究将PERPL应用于分散式控制的混合交通队列管理中，包括连接和自动化车辆（CAVs）与传统驾驶车辆（HVs）。使用恒定时间间隔（CTG）策略进行巡航，并考虑了执行器和通信延迟的影响。实验结果表明，相较于传统的线性模型和单独的强化学习方法，在极端条件和真实前车轨迹下，PERPL方法能够实现更小的车距误差和更好的振荡衰减效果。

此外，从宏观角度来看，随着采用PERPL方案的CAVs渗透率增加，整体交通振荡也得到了有效降低。这表明PERPL不仅在微观层面改善了车辆控制性能，也在宏观层面优化了交通流，展现了其在复杂动态环境下显著的应用潜力。 <div>
arXiv:2409.15595v1 Announce Type: new 
Abstract: Linear control models have gained extensive application in vehicle control due to their simplicity, ease of use, and support for stability analysis. However, these models lack adaptability to the changing environment and multi-objective settings. Reinforcement learning (RL) models, on the other hand, offer adaptability but suffer from a lack of interpretability and generalization capabilities. This paper aims to develop a family of RL-based controllers enhanced by physics-informed policies, leveraging the advantages of both physics-based models (data-efficient and interpretable) and RL methods (flexible to multiple objectives and fast computing). We propose the Physics-Enhanced Residual Policy Learning (PERPL) framework, where the physics component provides model interpretability and stability. The learning-based Residual Policy adjusts the physics-based policy to adapt to the changing environment, thereby refining the decisions of the physics model. We apply our proposed model to decentralized control to mixed traffic platoon of Connected and Automated Vehicles (CAVs) and Human-driven Vehicles (HVs) using a constant time gap (CTG) strategy for cruising and incorporating actuator and communication delays. Experimental results demonstrate that our method achieves smaller headway errors and better oscillation dampening than linear models and RL alone in scenarios with artificially extreme conditions and real preceding vehicle trajectories. At the macroscopic level, overall traffic oscillations are also reduced as the penetration rate of CAVs employing the PERPL scheme increases.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockprint Accuracy Study</title>
<link>https://arxiv.org/abs/2409.15808</link>
<guid>https://arxiv.org/abs/2409.15808</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockprint、Ethereum beacon chain、K-Nearest Neighbors（KNN）、Multi-Layer Perceptron（MLP）、模型准确性

总结:
本文主要探讨了MigaLabs团队对评估以太坊信标链客户端多样性的工具——Blockprint进行的实验改进。文章关注于优化K-Nearest Neighbors（KNN）分类器配置和探索使用Multi-Layer Perceptron（MLP）分类器作为潜在替代方案，以提高Blockprint的准确性。研究结果表明，MLP分类器在较小的数据集上通常能实现更高的准确度。

文中还揭示了运行在不同模式下的客户端（特别是订阅所有子网的客户端），其对验证纳入的影响存在差异，这一发现导致了对缓解模型准确性下降问题的建议方法。最终推荐采用结合默认配置和订阅所有子网客户端设置的训练数据集来训练MLP模型。

通过上述分析，研究旨在提升Blockprint工具在评估以太坊信标链客户端多样性方面的效能，为理解网络的去中心化程度提供更精确的依据。 <div>
arXiv:2409.15808v1 Announce Type: new 
Abstract: Blockprint, a tool for assessing client diversity on the Ethereum beacon chain, is essential for analyzing decentralization. This paper details experiments conducted at MigaLabs to enhance Blockprint's accuracy, evaluating various configurations for the K-Nearest Neighbors (KNN) classifier and exploring the Multi-Layer Perceptron (MLP) classifier as a proposed alternative. Findings suggest that the MLP classifier generally achieves superior accuracy with a smaller training dataset. The study revealed that clients running in different modes, especially those subscribed to all subnets, impact attestation inclusion differently, leading to proposed methods for mitigating the decline in model accuracy. Consequently, the recommendation is to employ an MLP model trained with a combined dataset of slots from both default and subscribed-to-all-subnets client configurations.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MHRC: Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models</title>
<link>https://arxiv.org/abs/2409.16030</link>
<guid>https://arxiv.org/abs/2409.16030</guid>
<content:encoded><![CDATA[
<div> 关键词：大语言模型、机器人、协作任务、多模态、任务规划

<br />
<br />
总结:本文介绍了一种利用大型语言模型(Large Language Models, LLMs)实现多模态异构机器人分散协作的新框架。该框架支持移动机器人、操作机器人和移动操作机器人三大类机器人共同完成探索、运输和组织等任务。通过开发丰富的文本反馈机制和链式思维提示，提高了任务规划效率和系统整体性能。移动操作机器人能够灵活调整基座位置，以最佳条件执行抓取任务；操作机器人能理解任务需求，必要时寻求帮助并适当地处理物体；同时，移动机器人能广泛探索环境，标记物品位置，并将信息传达给移动操作机器人，从而提高任务执行效率。研究团队在PyBullet中构建了三种不同房间布局和任务的场景进行测试，并评估了不同LLM模型及其组件的贡献。实验结果证实了所提出框架的有效性和必要性。 <div>
arXiv:2409.16030v1 Announce Type: new 
Abstract: The integration of large language models (LLMs) with robotics has significantly advanced robots' abilities in perception, cognition, and task planning. The use of natural language interfaces offers a unified approach for expressing the capability differences of heterogeneous robots, facilitating communication between them, and enabling seamless task allocation and collaboration. Currently, the utilization of LLMs to achieve decentralized multi-heterogeneous robot collaborative tasks remains an under-explored area of research. In this paper, we introduce a novel framework that utilizes LLMs to achieve decentralized collaboration among multiple heterogeneous robots. Our framework supports three robot categories, mobile robots, manipulation robots, and mobile manipulation robots, working together to complete tasks such as exploration, transportation, and organization. We developed a rich set of textual feedback mechanisms and chain-of-thought (CoT) prompts to enhance task planning efficiency and overall system performance. The mobile manipulation robot can adjust its base position flexibly, ensuring optimal conditions for grasping tasks. The manipulation robot can comprehend task requirements, seek assistance when necessary, and handle objects appropriately. Meanwhile, the mobile robot can explore the environment extensively, map object locations, and communicate this information to the mobile manipulation robot, thus improving task execution efficiency. We evaluated the framework using PyBullet, creating scenarios with three different room layouts and three distinct operational tasks. We tested various LLM models and conducted ablation studies to assess the contributions of different modules. The experimental results confirm the effectiveness and necessity of our proposed framework.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-LLM Debiasing Framework</title>
<link>https://arxiv.org/abs/2409.13884</link>
<guid>https://arxiv.org/abs/2409.13884</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型（LLMs）、社会偏见、多LLM方法、集中式方法、分布式方法

总结:
本文探讨了大型语言模型（LLMs）中的社会偏见问题及其解决策略。随着LLMs在社会各领域的广泛应用，它们所展现出来的偏见问题引起了广泛关注。文章首先指出，尽管通过数据增强、零样本提示和模型微调等技术在一定程度上缓解了偏见，但仍有持续存在的偏见，包括可能难以察觉的微妙偏见。为了进一步改进这一状况，作者提出了一个创新的多LLM去偏见框架，旨在减少LLMs中的偏见。

该框架包括两种不同的方法：集中式方法和分布式方法。在集中式方法中，对话由单一中心LLM协调；而在分布式方法中，所有模型直接通信。研究结果表明，多LLM框架在多个社会群体中显著降低了偏见，其性能超越了基线方法。这一发现为LLMs的公平性和可靠性提供了新的途径，有助于促进更广泛的社会应用。

通过引入多LLM方法，本文不仅展示了如何有效减少LLMs中的偏见，还强调了在设计和应用这些技术时需要考虑的社会责任。这一研究对于推动LLMs成为更加公正、透明和包容的技术具有重要意义。 <div>
arXiv:2409.13884v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are powerful tools with the potential to benefit society immensely, yet, they have demonstrated biases that perpetuate societal inequalities. Despite significant advancements in bias mitigation techniques using data augmentation, zero-shot prompting, and model fine-tuning, biases continuously persist, including subtle biases that may elude human detection. Recent research has shown a growing interest in multi-LLM approaches, which have been demonstrated to be effective in improving the quality of reasoning and factuality in LLMs. Building on this approach, we propose a novel multi-LLM debiasing framework aimed at reducing bias in LLMs. Our work is the first to introduce and evaluate two distinct approaches within this framework for debiasing LLMs: a centralized method, where the conversation is facilitated by a single central LLM, and a decentralized method, where all models communicate directly. Our findings reveal that our multi-LLM framework significantly reduces bias in LLMs, outperforming the baseline method across several social groups.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive bias for dissensus in nonlinear opinion dynamics with application to evolutionary division of labor games</title>
<link>https://arxiv.org/abs/2409.13964</link>
<guid>https://arxiv.org/abs/2409.13964</guid>
<content:encoded><![CDATA[
<div> 关键词：非线性意见动力学、适应性控制、偏置参数、多任务分配、演化博弈

总结:

本文探讨了如何通过适当地调整非线性意见动力学（NOD）中的偏差参数，以实现将代理智能体分配到任意大小的群体中，从而最大化集体奖励的问题。研究基于之前在多机器人系统中利用NOD与多目标行为优化相结合的算法进行自主任务分配的实地实验结果。受此启发，本文提出并分析了一个新的任务分配模型，该模型将NOD与演化博弈框架综合在一起。

通过理论证明，我们确定了能够使用分布式反馈控制意见状态至特定两任务间代理智能体分配比例所需的充分条件。随后，通过合作演化分工游戏的仿真研究验证了这些理论结果的有效性。

主要贡献包括：

1. **提出新模型**：结合NOD与演化博弈，形成一种新的任务分配策略。
2. **理论分析**：证明了通过动态调整偏差参数可以实现期望的任务分配。
3. **仿真验证**：通过合作演化分工游戏的仿真，展示了模型的有效性。
4. **适应性控制**：强调了通过适应性控制机制来优化任务分配的重要性。
5. **多目标优化**：考虑了在最大化集体奖励的同时满足其他潜在目标的复杂性。

该研究为多智能体系统中的任务分配问题提供了新的视角和解决方案，特别适用于需要动态调整任务负载以优化整体性能的场景。 <div>
arXiv:2409.13964v1 Announce Type: new 
Abstract: This paper addresses the problem of adaptively controlling the bias parameter in nonlinear opinion dynamics (NOD) to allocate agents into groups of arbitrary sizes for the purpose of maximizing collective rewards. In previous work, an algorithm based on the coupling of NOD with an multi-objective behavior optimization was successfully deployed as part of a multi-robot system in an autonomous task allocation field experiment. Motivated by the field results, in this paper we propose and analyze a new task allocation model that synthesizes NOD with an evolutionary game framework. We prove sufficient conditions under which it is possible to control the opinion state in the group to a desired allocation of agents between two tasks through an adaptive bias using decentralized feedback. We then verify the theoretical results with a simulation study of a collaborative evolutionary division of labor game.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cyber-Physical Authentication Scheme for Secure V2G Transactions Using Blockchain and Smart Contracts</title>
<link>https://arxiv.org/abs/2409.14008</link>
<guid>https://arxiv.org/abs/2409.14008</guid>
<content:encoded><![CDATA[
<div> 关键词：电车辆、车辆到电网、智能充电基础设施、区块链、网络安全

<br />
<br />总结:

本文探讨了全球电动汽车（EV）的快速普及对车辆到电网（V2G）网络所引发的网络安全需求。随着V2G网络被越来越多地集成到智能充电基础设施中，新的安全漏洞开始出现，威胁着电网稳定性和用户隐私。为此，文章提出了一种针对插桩充电（PnC）操作的基于区块链的V2G系统中的网络认证协议和智能合约。该协议利用高级加密技术和区块链技术确保电动汽车与充电站之间进行安全、透明和防篡改的能量交易。

主要贡献包括开发一种结合物理和网络安全性的认证方法，实现智能合约框架以支持安全的能量交易，并进行了详细的安全性和隐私性分析。该提案有效应对分布式拒绝服务（DDoS）、中间人（MitM）攻击和重放攻击等风险，同时保持用户匿名性和数据完整性。通过这种综合策略，文章旨在提升V2G网络的安全性和可靠性，为电动汽车的广泛采用提供坚实的技术支撑。 <div>
arXiv:2409.14008v1 Announce Type: new 
Abstract: The rapid adoption of electric vehicles (EVs) globally has catalyzed the need for robust cybersecurity measures within vehicle-to-grid (V2G) networks. As these networks are increasingly being integrated into smart charging infrastructures, they also introduce new vulnerabilities that threaten grid stability and user privacy This paper proposes a cyber-physical authentication protocol and trading smart contract tailored to plug and charge (PnC) operations within blockchain-based V2G systems. The protocol leverages advanced cryptographic techniques and blockchain to ensure secure, transparent, and tamper-proof energy transactions between EVs and charging stations. Key contributions include the development of a cyber-physical authentication method, the implementation of a smart contract framework for secure energy trading, and a detailed security and privacy analysis. The proposed protocol effectively mitigates risks such as distributed denial of service (DDoS) attacks, man-in-the-middle (MitM) attacks and replay attacks while preserving user anonymity and data integrity.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Re-Evaluating Privacy in Centralized and Decentralized Learning: An Information-Theoretical and Empirical Study</title>
<link>https://arxiv.org/abs/2409.14261</link>
<guid>https://arxiv.org/abs/2409.14261</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning（DFL）、Centralized Federated Learning（CFL）、Privacy、Mutual Information、Secure Aggregation（SA）

<br /><br />
总结:

本文主要探讨了去中心化联邦学习(DFL)与集中式联邦学习(CFL)在隐私保护方面的差异。研究发现，尽管DFL因其去中心化的特性被认为在一定程度上提高了数据隐私，但Pasquini等人的研究挑战了这一观点，指出在某些假设下，DFL并不能显著提高隐私保护能力。为了深入分析这一问题，文章引入了一种基于信息论的理论框架，通过计算互信息来量化隐私泄漏。

研究还对增强隐私的技术，如安全聚合(SA)，在DFL和CFL中的有效性进行了评估。通过模拟和实际实验，结果表明，在不完全信任服务器的情况下，DFL通常能提供更强的隐私保护。文章指出，前人研究中关于网络拓扑结构和隐私攻击假设的局限性未能充分反映联邦学习中的信息泄露情况。

最后，研究揭示了先前研究中存在的不足之处，特别是在对网络结构和攻击模式的假设上，这些假设可能过于理想化，无法全面反映现实场景中的信息泄露风险。因此，该文为理解联邦学习中的隐私保护机制提供了新的视角，并强调了构建更精确理论模型的重要性。 <div>
arXiv:2409.14261v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) has garnered attention for its robustness and scalability compared to Centralized Federated Learning (CFL). While DFL is commonly believed to offer privacy advantages due to the decentralized control of sensitive data, recent work by Pasquini et, al. challenges this view, demonstrating that DFL does not inherently improve privacy against empirical attacks under certain assumptions. For investigating fully this issue, a formal theoretical framework is required. Our study offers a novel perspective by conducting a rigorous information-theoretical analysis of privacy leakage in FL using mutual information. We further investigate the effectiveness of privacy-enhancing techniques like Secure Aggregation (SA) in both CFL and DFL. Our simulations and real-world experiments show that DFL generally offers stronger privacy preservation than CFL in practical scenarios where a fully trusted server is not available. We address discrepancies in previous research by highlighting limitations in their assumptions about graph topology and privacy attacks, which inadequately capture information leakage in FL.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cluster-based Network Time Synchronization for Resilience with Energy Efficiency</title>
<link>https://arxiv.org/abs/2409.14323</link>
<guid>https://arxiv.org/abs/2409.14323</guid>
<content:encoded><![CDATA[
<div> 关键词：时间同步、物联网、故障容忍、能效、分布式协议

总结:
本文提出了一种名为C-sync的基于聚类的分布式时间同步协议，旨在解决物联网网络中设备间的时间同步问题。该协议具有故障容忍性，能够在网络中检测并隔离故障，从而快速恢复。与现有解决方案相比，C-sync通过引入多个参考节点来限制任何节点到其时间源的最大跳数，从而实现规模扩展。此外，C-sync在Contiki平台上采用模块化结构，支持应用程序转换。研究团队在真实测试床上进行了实验，该测试床由分布在不同楼层的40多个Tmote Sky硬件节点组成。实验结果表明，C-sync在最坏和最佳情况下分别减少了56.12%和75.75%的功率消耗，同时保持了与最先进的协议相当的准确性。与提供无/有限容错的分布式协议（源自GTSP）进行比较时，C-sync在能效和故障恢复方面表现出色。 <div>
arXiv:2409.14323v1 Announce Type: new 
Abstract: Time synchronization of devices in Internet-of-Things (IoT) networks is one of the challenging problems and a pre-requisite for the design of low-latency applications. Although many existing solutions have tried to address this problem, almost all solutions assume all the devices (nodes) in the network are faultless. Furthermore, these solutions exchange a large number of messages to achieve synchronization, leading to significant communication and energy overhead. To address these shortcomings, we propose C-sync, a clustering-based decentralized time synchronization protocol that provides resilience against several types of faults with energy-efficient communication. C-sync achieves scalability by introducing multiple reference nodes in the network that restrict the maximum number of hops any node can have to its time source. The protocol is designed with a modular structure on the Contiki platform to allow application transitions. We evaluate C-sync on a real testbed that comprises over 40 Tmote Sky hardware nodes distributed across different levels in a building and show through experiments the fault resilience, energy efficiency, and scalability of the protocol. C-sync detects and isolates faults to a cluster and recovers quickly. The evaluation makes a qualitative comparison with state-of-the-art protocols and a quantitative comparison with a class of decentralized protocols (derived from GTSP) that provide synchronization with no/limited fault-tolerance. Results also show a reduction of 56.12% and 75.75% in power consumption in the worst-case and best-case scenarios, respectively, compared to GTSP, while achieving similar accuracy.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Based Information Security and Privacy Protection: Challenges and Future Directions using Computational Literature Review</title>
<link>https://arxiv.org/abs/2409.14472</link>
<guid>https://arxiv.org/abs/2409.14472</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、信息系统的安全性与隐私性、文献综述、计算文学审查、主题建模

总结:
本文主要探讨了区块链技术在增强信息系统安全性与隐私性方面的影响，以及随着研究文献数量激增，进行有效分析和综合所面临的挑战。为解决这一问题，作者采用了一种名为“计算文学审查（CLR）”的方法，结合了主题建模技术（使用了Latent Dirichlet Allocation，LDA）对相关文献进行了分析。通过此方法，作者识别出了与安全性和隐私性相关的十个关键主题，并对每个主题进行了详细描述。

在对文献进行深度分析后，作者揭示了当前研究中的一些局限性，并基于此提出了未来的研究方向。这表明尽管区块链技术在增强安全性与隐私性方面展现出巨大潜力，但仍然存在需要进一步探索和解决的问题。例如，如何更有效地利用区块链技术保护数据不被非法访问或滥用，以及如何确保在分布式网络环境下数据的安全传输等。这些发现对于推动区块链技术在实际应用中的发展和优化具有重要意义。 <div>
arXiv:2409.14472v1 Announce Type: new 
Abstract: Blockchain technology is an emerging digital innovation that has gained immense popularity in enhancing individual security and privacy within Information Systems (IS). This surge in interest is reflected in the exponential increase in research articles published on blockchain technology, highlighting its growing significance in the digital landscape. However, the rapid proliferation of published research presents significant challenges for manual analysis and synthesis due to the vast volume of information. The complexity and breadth of topics, combined with the inherent limitations of human data processing capabilities, make it difficult to comprehensively analyze and draw meaningful insights from the literature. To this end, we adopted the Computational Literature Review (CLR) to analyze pertinent literature impact and topic modelling using the Latent Dirichlet Allocation (LDA) technique. We identified 10 topics related to security and privacy and provided a detailed description of each topic. From the critical analysis, we have observed several limitations, and several future directions are provided as an outcome of this review.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Review of Scalable and Privacy-Preserving Multi-Agent Frameworks for Distributed Energy Resource Control</title>
<link>https://arxiv.org/abs/2409.14499</link>
<guid>https://arxiv.org/abs/2409.14499</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式能源资源（DERs）、隐私保护、规模化、多代理系统、电力系统操作

总结:

本文聚焦于分布式能源资源（DERs）在大规模电力系统中的管理挑战，特别是数据处理的隐私性和操作优化的规模化问题。文章从多代理系统的视角全面审视了现有和新兴解决方案。在规模化方面，文章回顾了依赖于分布式或去中心化信息交换结构的并行控制、优化与学习的前沿研究。在隐私保护方面，文章识别了可融入上述规模化结构的隐私保留措施。

尽管这些领域已取得进展，但仍面临挑战，因为这些高度跨学科的研究结合了来自不同领域的各种可扩展计算架构和隐私保护技术，使其难以在实践中应用。为解决这一问题，文章提供了从多代理视角全面审视大规模电力系统操作策略的综述，特别针对DER控制问题。此外，文章还提出了未来可扩展、隐私意识和网络安全路径的新方法，以解锁DER的全部潜力，通过控制、优化和学习通用的多代理基于物理系统的途径。 <div>
arXiv:2409.14499v1 Announce Type: new 
Abstract: Distributed energy resources (DERs) are gaining prominence due to their advantages in improving energy efficiency, reducing carbon emissions, and enhancing grid resilience. Despite the increasing deployment, the potential of DERs has yet to be fully explored and exploited. A fundamental question restrains the management of numerous DERs in large-scale power systems, "How should DER data be securely processed and DER operations be efficiently optimized?" To address this question, this paper considers two critical issues, namely privacy for processing DER data and scalability in optimizing DER operations, then surveys existing and emerging solutions from a multi-agent framework perspective. In the context of scalability, this paper reviews state-of-the-art research that relies on parallel control, optimization, and learning within distributed and/or decentralized information exchange structures, while in the context of privacy, it identifies privacy preservation measures that can be synthesized into the aforementioned scalable structures. Despite research advances in these areas, challenges remain because these highly interdisciplinary studies blend a wide variety of scalable computing architectures and privacy preservation techniques from different fields, making them difficult to adapt in practice. To mitigate this issue, this paper provides a holistic review of trending strategies that orchestrate privacy and scalability for large-scale power system operations from a multi-agent perspective, particularly for DER control problems. Furthermore, this review extrapolates new approaches for future scalable, privacy-aware, and cybersecure pathways to unlock the full potential of DERs through controlling, optimizing, and learning generic multi-agent-based cyber-physical systems.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Integrated Blockchain and IPFS Solution for Secure and Efficient Source Code Repository Hosting using Middleman Approach</title>
<link>https://arxiv.org/abs/2409.14530</link>
<guid>https://arxiv.org/abs/2409.14530</guid>
<content:encoded><![CDATA[
<div> 关键词：版本控制、区块链、IPFS、智能合约、加密

总结:

本文提出了一种新型的去中心化版本控制系统，旨在解决当前集中式版本控制系统（如SVN、Git等）存在的数据丢失、安全漏洞和所有权争议等问题。该系统基于以太坊区块链和IPFS（InterPlanetary File System）构建，旨在实现更安全、高效和可靠的代码仓库托管与治理。

系统架构采用混合设计，将区块链的不可篡改和去中心化特性与IPFS的高效率离线存储相结合。通过引入“中间人”IPFS，系统在保持长期安全性的同时，实现了快速的实时协作。智能合约被用于管理访问控制和密钥管理，动态验证用户权限，确保只有经过授权的用户能够访问和解密存储在IPFS上的数据。

此外，系统采用了结合对称和非对称加密的混合加密方案，将密钥存储在区块链上，而IPFS负责高效地存储代码库本身。中间人IPFS则提供了一种平衡集中化系统速度与去中心化架构韧性的机制，特别适合于需要多个同时访问共享资源的大规模协作编码项目。

这种集成方案不仅增强了系统的安全性，还支持了实时协作，为软件开发团队提供了更为灵活、高效的工作环境。 <div>
arXiv:2409.14530v1 Announce Type: new 
Abstract: Version control systems (VCS) are essential for software development, yet centralized VCS present risks such as data loss, security breaches, and ownership disputes. While blockchain-based approaches to decentralized source code repository hosting have been explored, many existing solutions struggle with challenges related to security, scalability, efficiency, and real-time collaboration. This study seeks to enhance these efforts by proposing a novel decentralized solution that leverages the Ethereum blockchain and IPFS for secure, efficient, and resilient code repository hosting and governance. Our approach introduces a hybrid architecture that combines the immutable and decentralized nature of blockchain with the efficiency of IPFS for off-chain storage. To facilitate real-time collaboration, we integrate a temporary centralized Middleman IPFS that manages transaction processing and enhances operational efficiency without compromising long-term security. This Middleman IPFS acts as an intermediary, balancing the speed of centralized systems with the resilience of decentralized architectures. Our system uses smart contracts to maintain access control and key management by dynamically verifying access rights, ensuring that only authorized users can retrieve and decrypt data stored on IPFS. This integration allows for secure, real-time collaboration in environments where multiple collaborators need concurrent access to shared resources. Our system employs a hybrid encryption scheme that combines symmetric and asymmetric cryptography. The encrypted keys are stored on the blockchain, while IPFS handles the efficient storage of the codebase itself, with a Middleman IPFS maintaining concurrent collaboration, providing a robust and scalable solution for managing large-scale, collaborative coding projects.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Brain Surgery: Ensuring GDPR Compliance in Large Language Models via Concept Erasure</title>
<link>https://arxiv.org/abs/2409.14603</link>
<guid>https://arxiv.org/abs/2409.14603</guid>
<content:encoded><![CDATA[
<div> 关键词：大型AI系统、GDPR、Brain Surgery、隐私管理、持续学习

总结:

本文介绍了名为“脑外科手术”的创新方法，旨在让每一种本地人工智能模型都符合《通用数据保护条例》（GDPR）的要求。通过实现实时隐私管理和针对特定情况的遗忘功能，该方法能确保人工智能系统的合规性。其核心包括嵌入式破坏提示（ECO提示）、基于区块链的隐私管理以及隐私意识持续学习等高级技术。

脑外科手术提供了一个模块化解决方案，适用于各种AI架构。它不仅确保了隐私法规的遵守，还赋予用户定义自身隐私界限的能力，从而开创了AI伦理和治理的新范式。通过引入这些先进的技术，该方法旨在为AI发展提供强大的隐私保护框架，确保在人工智能快速发展的时代，数据隐私能够得到充分尊重和保护。 <div>
arXiv:2409.14603v1 Announce Type: new 
Abstract: As large-scale AI systems proliferate, ensuring compliance with data privacy laws such as the General Data Protection Regulation (GDPR) has become critical. This paper introduces Brain Surgery, a transformative methodology for making every local AI model GDPR-ready by enabling real-time privacy management and targeted unlearning. Building on advanced techniques such as Embedding-Corrupted Prompts (ECO Prompts), blockchain-based privacy management, and privacy-aware continual learning, Brain Surgery provides a modular solution that can be deployed across various AI architectures. This tool not only ensures compliance with privacy regulations but also empowers users to define their own privacy limits, creating a new paradigm in AI ethics and governance.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MECURY: Practical Cross-Chain Exchange via Trusted Hardware</title>
<link>https://arxiv.org/abs/2409.14640</link>
<guid>https://arxiv.org/abs/2409.14640</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数字货币、可信执行环境（TEE）、跨链交易、成本优化

<br /><br />总结:

本文介绍了一种名为MERCURY的新型跨链数字货币交易平台。该平台通过利用可信执行环境（TEE）技术来实现信任最小化和高效运行，无需在线客户端，从而提升用户体验。MERCURY的创新之处在于其采用高效的挑战响应机制和智能合约执行方式来解决TEE的不可用问题，同时通过轻量级交易验证机制和多项优化措施来降低链上成本。

具体而言，MERCURY相较于现有解决方案（如XClaim、ZK-bridge和Tesseract），显著降低了约67.87%、45.01%和47.70%的链上成本。这不仅提升了交易效率，也增强了平台的安全性和可靠性。通过上述改进，MERCURY为数字货币的跨链交易提供了更为便捷、安全且经济的解决方案。 <div>
arXiv:2409.14640v1 Announce Type: new 
Abstract: The proliferation of blockchain-backed cryptocurrencies has sparked the need for cross-chain exchanges of diverse digital assets. Unfortunately, current exchanges suffer from high on-chain verification costs, weak threat models of central trusted parties, or synchronous requirements, making them impractical for currency trading applications. In this paper, we present MERCURY, a practical cryptocurrency exchange that is trust-minimized and efficient without online-client requirements. MERCURY leverages Trusted Execution Environments (TEEs) to shield participants from malicious behaviors, eliminating the reliance on trusted participants and making on-chain verification efficient. Despite the simple idea, building a practical TEE-assisted cross-chain exchange is challenging due to the security and unavailability issues of TEEs. MERCURY tackles the unavailability problem of TEEs by implementing an efficient challenge-response mechanism executed on smart contracts. Furthermore, MERCURY utilizes a lightweight transaction verification mechanism and adopts multiple optimizations to reduce on-chain costs. Comparative evaluations with XClaim, ZK-bridge, and Tesseract demonstrate that MERCURY significantly reduces on-chain costs by approximately 67.87%, 45.01%, and 47.70%, respectively.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>TeeRollup: Efficient Rollup Design Using Heterogeneous TEE</title>
<link>https://arxiv.org/abs/2409.14647</link>
<guid>https://arxiv.org/abs/2409.14647</guid>
<content:encoded><![CDATA[
<div> 关键词：TeeRollup、Trusted Execution Environments（TEEs）、sequencers、Data Availability Providers（DAPs）、laziness penalty game

总结:
文章主要介绍了TeeRollup，一种新型的区块链扩展解决方案。TeeRollup旨在通过在可信执行环境(TEEs)中运行交易的验证器来提高区块链的可扩展性，同时降低验证成本和缩短提款延迟。该方案采用分布式系统设计，确保即使部分TEEs被破坏，系统也能保持安全。此外，TeeRollup引入了挑战机制来应对TEEs不可用导致的赎回问题，并通过数据可用性提供者(DAPs)减少链上存储开销。为了约束DAP行为，引入了懒惰惩罚游戏机制。实验结果显示，与零知识证明卷积（zk-rollups）相比，TeeRollup显著降低了链上验证成本（约86%）并将提款延迟缩短至几分钟。这一创新为区块链技术在去中心化应用中的广泛应用提供了可能。 <div>
arXiv:2409.14647v1 Announce Type: new 
Abstract: Rollups have emerged as a promising approach to improving blockchains' scalability by offloading transactions execution off-chain. Existing rollup solutions either leverage complex zero-knowledge proofs or optimistically assume execution correctness unless challenged. However, these solutions have practical issues such as high gas costs and significant withdrawal delays, hindering their adoption in decentralized applications. This paper introduces TeeRollup, an efficient rollup design with low gas costs and short withdrawal delays. TeeRollup employs Trusted Execution Environments (TEEs)-supported sequencers to execute transactions, requiring the blockchain to verify only the TEEs' signatures. TeeRollup is designed under a realistic threat model in which the integrity and availability of sequencers' TEEs may be compromised. To address these issues, we first introduce a distributed system of sequencers with heterogeneous TEEs, ensuring system security even if a minority of TEEs are compromised. Second, we propose a challenge mechanism to solve the redeemability issue caused by TEE unavailability. Furthermore, TeeRollup incorporates Data Availability Providers (DAPs) to reduce on-chain storage overhead and uses a laziness penalty game to regulate DAP behavior. We implement a prototype of TeeRollup in Golang, using the Ethereum test network, Sepolia. Our experimental results indicate that TeeRollup outperforms zero-knowledge rollups (zk-rollups), reducing on-chain verification costs by approximately 86% and withdrawal delays to a few minutes.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Loopy Movements: Emergence of Rotation in a Multicellular Robot</title>
<link>https://arxiv.org/abs/2409.15187</link>
<guid>https://arxiv.org/abs/2409.15187</guid>
<content:encoded><![CDATA[
<div> 关键词：生物系统、Loopy机器人、分散式旋转、自组织、适应性

总结:

本文研究了Loopy多细胞机器人中的自发分散式旋转现象。Loopy由同质的、物理相连的单自由度单元组成，通过模拟化学物质（即形态发生器）的扩散、反应和主动运输进行简单的局部交互，而无需中央控制或全局形态知识。这些交互使机器人能够自我组织并实现协调的旋转运动，形成局部凸起——由电机细胞集群产生的局部突出。研究发现，Loopy表现出两种独特行为：1）内部山谷之间的旋转速度比外部峰顶快，与刚体动力学相反；2）细胞的旋转方向与整体形态相反。

实验表明，尽管Loopy的形态对相对环境而言的角速度没有影响，但较大的叶片会增加细胞的旋转速度并降低形态的旋转速度。即使有三分之一的执行器失效并经历显著的形态变化，Loopy仍能保持其旋转能力。这揭示了分散式、生物启发策略在构建具有韧性和适应性的机器人系统方面的潜力。 <div>
arXiv:2409.15187v1 Announce Type: new 
Abstract: Unlike most human-engineered systems, many biological systems rely on emergent behaviors from low-level interactions, enabling greater diversity and superior adaptation to complex, dynamic environments. This study explores emergent decentralized rotation in the Loopy multicellular robot, composed of homogeneous, physically linked, 1-degree-of-freedom cells. Inspired by biological systems like sunflowers, Loopy uses simple local interactions-diffusion, reaction, and active transport of simulated chemicals, called morphogens-without centralized control or knowledge of its global morphology. Through these interactions, the robot self-organizes to achieve coordinated rotational motion and forms lobes-local protrusions created by clusters of motor cells. This study investigates how these interactions drive Loopy's rotation, the impact of its morphology, and its resilience to actuator failures. Our findings reveal two distinct behaviors: 1) inner valleys between lobes rotate faster than the outer peaks, contrasting with rigid body dynamics, and 2) cells rotate in the opposite direction of the overall morphology. The experiments show that while Loopy's morphology does not affect its angular velocity relative to its cells, larger lobes increase cellular rotation and decrease morphology rotation relative to the environment. Even with up to one-third of its actuators disabled and significant morphological changes, Loopy maintains its rotational abilities, highlighting the potential of decentralized, bio-inspired strategies for resilient and adaptable robotic systems.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Solvent: liquidity verification of smart contracts</title>
<link>https://arxiv.org/abs/2404.17864</link>
<guid>https://arxiv.org/abs/2404.17864</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、攻击目标、流动性属性、验证工具、Solvent

<br /><br />
总结:
本文聚焦于智能合约领域中的安全问题，指出智能合约因其独特的性质而成为攻击者青睐的目标。现有的智能合约验证工具在表达和验证与加密资产交换相关的流动性属性方面存在局限性。为解决这一问题，作者提出了一种名为“Solvent”的新型验证工具。Solvent旨在验证那些现有验证工具难以处理的流动性属性，如用户是否能在任何可达状态下通过一系列交易提取特定数量的加密资产。

该研究通过使用常见智能合约基准进行了评估，以检验Solvent的有效性和性能。结果显示，Solvent在验证复杂流动性属性方面表现出色，提高了智能合约的安全性。这一工具的开发不仅推动了智能合约领域的安全性提升，也为未来智能合约的可靠性和实用性提供了重要支持。 <div>
arXiv:2404.17864v3 Announce Type: replace 
Abstract: Smart contracts are an attractive target for attackers, as evidenced by a long history of security incidents. A current limitation of smart contract verification tools is that they are not really effective in expressing and verifying liquidity properties regarding the exchange of crypto-assets: for example, is it true that in every reachable state a user can fire a sequence of transactions to withdraw a given amount of crypto-assets? We propose Solvent, a tool aimed at verifying these kinds of properties, which are beyond the reach of existing verification tools for Solidity. We evaluate the effectiveness and performance of Solvent through a common benchmark of smart contracts.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Dataset of Uniswap daily transaction indices by network</title>
<link>https://arxiv.org/abs/2312.02660</link>
<guid>https://arxiv.org/abs/2312.02660</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance (DeFi), Layer 2 (L2) solutions, Ethereum, Uniswap, Python框架

总结:
本文研究了去中心化金融(DeFi)如何通过直接交易和消除中介，重塑传统金融领域，并引入了Layer 2(L2)解决方案以增强DeFi生态系统的可扩展性和效率。然而，L2解决方案的影响仍需深入探索，主要是因为缺乏全面的交易数据索引供经济分析使用。为了填补这一空白，研究团队分析了来自Uniswap的主要去中心化交易所超过5千万笔交易的数据，横跨L1和L2网络。他们从以太坊区块链数据中创建了一系列每日指标，涵盖了DeFi采用、可扩展性、去中心化和财富分配等方面。此外，研究团队还开发了一个开源Python框架来计算去中心化指数，使得该数据集对高级机器学习研究极具价值。这项工作提供了宝贵的数据资源，对数据科学家而言意义重大，并有助于推动智能Web3生态系统的发展。 <div>
arXiv:2312.02660v2 Announce Type: replace-cross 
Abstract: Decentralized Finance (DeFi) is reshaping traditional finance by enabling direct transactions without intermediaries, creating a rich source of open financial data. Layer 2 (L2) solutions are emerging to enhance the scalability and efficiency of the DeFi ecosystem, surpassing Layer 1 (L1) systems. However, the impact of L2 solutions is still underexplored, mainly due to the lack of comprehensive transaction data indices for economic analysis. This study bridges that gap by analyzing over 50 million transactions from Uniswap, a major decentralized exchange, across both L1 and L2 networks. We created a set of daily indices from blockchain data on Ethereum, Optimism, Arbitrum, and Polygon, offering insights into DeFi adoption, scalability, decentralization, and wealth distribution. Additionally, we developed an open-source Python framework for calculating decentralization indices, making this dataset highly useful for advanced machine learning research. Our work provides valuable resources for data scientists and contributes to the growth of the intelligent Web3 ecosystem.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stabl: Blockchain Fault Tolerance</title>
<link>https://arxiv.org/abs/2409.13142</link>
<guid>https://arxiv.org/abs/2409.13142</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、故障容忍性、Algorand、Avalanche、Solana

<br /><br />
总结:
本文评估了五种现代区块链系统（Algorand、Aptos、Avalanche、Redbelly和Solana）的故障容忍能力。研究中引入了一种新颖的敏感度指标，通过比较基线环境和对抗环境下的两个累积分布函数的积分差来量化这一指标。结果显示：

1. 除了Redbelly外，所有区块链系统都对网络中一小部分节点的失效高度敏感。
2. Avalanche和Redbelly得益于冗余信息，这有助于实现拜占庭容错，而其他系统则因冗余而受到阻碍。
3. 更为显著的是，Avalanche和Solana无法从局部瞬态故障中恢复。

这项研究揭示了区块链系统的故障容忍性存在显著差异，特别是当考虑特定于系统的架构决策时。这些发现对于理解区块链在实际部署中的可靠性和选择最适合特定需求的区块链技术至关重要。 <div>
arXiv:2409.13142v1 Announce Type: new 
Abstract: Blockchain promises to make online services more fault tolerant due to their inherent distributed nature. Their ability to execute arbitrary programs in different geo-distributed regions and on diverse operating systems make them an alternative of choice to our dependence on unique software whose recent failure affected 8.5 millions of machines. As of today, it remains, however, unclear whether blockchains can truly tolerate failures.
  In this paper, we assess the fault tolerance of blockchain. To this end, we inject failures in controlled deployments of five modern blockchain systems, namely Algorand, Aptos, Avalanche, Redbelly and Solana. We introduce a novel sensitivity metric, interesting in its own right, as the difference between the integrals of two cumulative distribution functions, one obtained in a baseline environment and one obtained in an adversarial environment. Our results indicate that (i) all blockchains except Redbelly are highly impacted by the failure of a small part of their network, (ii) Avalanche and Redbelly benefit from the redundant information needed for Byzantine fault tolerance while others are hampered by it, and more dramatically (iii) Avalanche and Solana cannot recover from localised transient failures.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative distributed model predictive control for embedded systems: Experiments with hovercraft formations</title>
<link>https://arxiv.org/abs/2409.13334</link>
<guid>https://arxiv.org/abs/2409.13334</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式模型预测控制、多旋翼飞行器、空气曲棍球台、交替方向乘子法、集中式最优控制问题

<br /><br />
总结:
本文报告了一项关于在空气曲棍球台上对一组多旋翼飞行器进行嵌入式合作分布式模型预测控制的实验。这些飞行器通过一种稳定的去中心化实时迭代方案解决每个采样步骤中的集中式最优控制问题，该方案使用交替方向乘子法。此方法无需中央协调器，可在飞行器上独立执行，实现毫秒级的采样间隔。实验展示了控制策略在点对点转换、轨迹跟踪、碰撞避免和移动障碍物等场景下的灵活性。通过这些实验，证明了分布式模型预测控制在复杂动态环境中的高效性和适应性。 <div>
arXiv:2409.13334v1 Announce Type: new 
Abstract: This paper presents experiments for embedded cooperative distributed model predictive control applied to a team of hovercraft floating on an air hockey table. The hovercraft collectively solve a centralized optimal control problem in each sampling step via a stabilizing decentralized real-time iteration scheme using the alternating direction method of multipliers. The efficient implementation does not require a central coordinator, executes onboard the hovercraft, and facilitates sampling intervals in the millisecond range. The formation control experiments showcase the flexibility of the approach on scenarios with point-to-point transitions, trajectory tracking, collision avoidance, and moving obstacles.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noise-Robust and Resource-Efficient ADMM-based Federated Learning</title>
<link>https://arxiv.org/abs/2409.13451</link>
<guid>https://arxiv.org/abs/2409.13451</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、通信噪声、权重最小二乘法、交替方向乘子法（ADMM）、性能提升

总结:
本文提出了一种针对联邦学习(Federated Learning, FL)的新算法，旨在提高模型对通信噪声的鲁棒性同时减少通信负载。通过将权重最小二乘法(WLS)回归问题作为示例，构建了一个分布式凸优化问题，该问题在具有随机调度的联邦网络中进行了解。应用交替方向乘子法(ADMM)解决这一问题。为对抗累积通信噪声的负面影响，引入关键修改，通过消除双变量和在每个参与客户端实施新的局部模型更新，使得每个客户端只需使用一次有噪声的全局模型更新，而非两次，从而提高了对加性通信噪声的鲁棒性。此外，通过允许客户端在未被服务器选择时继续进行本地更新，进一步提升了算法性能。理论分析证实了算法在通信噪声和服务器随机选择客户端的迭代过程中的收敛性，无论是在均值还是均方意义上。数值结果验证了所提算法的有效性，并与理论发现相吻合。 <div>
arXiv:2409.13451v1 Announce Type: new 
Abstract: Federated learning (FL) leverages client-server communications to train global models on decentralized data. However, communication noise or errors can impair model accuracy. To address this problem, we propose a novel FL algorithm that enhances robustness against communication noise while also reducing communication load. We derive the proposed algorithm through solving the weighted least-squares (WLS) regression problem as an illustrative example. We first frame WLS regression as a distributed convex optimization problem over a federated network employing random scheduling for improved communication efficiency. We then apply the alternating direction method of multipliers (ADMM) to iteratively solve this problem. To counteract the detrimental effects of cumulative communication noise, we introduce a key modification by eliminating the dual variable and implementing a new local model update at each participating client. This subtle yet effective change results in using a single noisy global model update at each client instead of two, improving robustness against additive communication noise. Furthermore, we incorporate another modification enabling clients to continue local updates even when not selected by the server, leading to substantial performance improvements. Our theoretical analysis confirms the convergence of our algorithm in both mean and the mean-square senses, even when the server communicates with a random subset of clients over noisy links at each iteration. Numerical results validate the effectiveness of our proposed algorithm and corroborate our theoretical findings.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proxion: Uncovering Hidden Proxy Smart Contracts for Finding Collision Vulnerabilities in Ethereum</title>
<link>https://arxiv.org/abs/2409.13563</link>
<guid>https://arxiv.org/abs/2409.13563</guid>
<content:encoded><![CDATA[
<div> 关键词：Proxion、智能合约、升级性、安全性、漏洞检测

总结:
文章介绍了一款名为Proxion的自动化跨合约分析工具，其主要功能在于识别Ethereum中的代理智能合约及其可能存在的冲突。与以往工具相比，Proxion的独特之处在于它能分析那些缺乏源代码和历史交易记录的隐藏智能合约。通过采用多种提升效率和准确性的技术手段，Proxion在识别代理智能合约的数量和检测未被报道的冲突方面表现出色，显著超越了现有工具。研究发现，从2015年到2023年的活跃合约中，有54.2%是代理合约，约有150万个合约存在至少一个冲突问题。

Proxion的开发旨在解决代理智能合约设计模式中存在的安全问题，特别是函数碰撞和存储碰撞。这些安全漏洞曾在现实世界中导致用户大量数字资产被盗。通过使用Proxion进行深入分析，可以更全面地识别并预防这类风险，为智能合约的安全性和稳定性提供重要保障。同时，该工具的广泛应用有助于提高整个区块链生态系统的安全性，防止未来类似事件的发生。 <div>
arXiv:2409.13563v1 Announce Type: new 
Abstract: The proxy design pattern allows Ethereum smart contracts to be simultaneously immutable and upgradeable, in which an original contract is split into a proxy contract containing the data storage and a logic contract containing the implementation logic. This architecture is known to have security issues, namely function collisions and storage collisions between the proxy and logic contracts, and has been exploited in real-world incidents to steal users' millions of dollars worth of digital assets. In response to this concern, several previous works have sought to identify proxy contracts in Ethereum and detect their collisions. However, they all fell short due to their limited coverage, often restricting analysis to only contracts with available source code or past transactions.
  To bridge this gap, we present Proxion, an automated cross-contract analyzer that identifies all proxy smart contracts and their collisions in Ethereum. What sets Proxion apart is its ability to analyze hidden smart contracts that lack both source code and past transactions. Equipped with various techniques to enhance efficiency and accuracy, Proxion outperforms the state-of-the-art tools, notably identifying millions more proxy contracts and thousands of unreported collisions. We apply Proxion to analyze over 36 million alive contracts from 2015 to 2023, revealing that 54.2% of them are proxy contracts, and about 1.5 million contracts exhibit at least one collision issue.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Credential Status Management: A Paradigm Shift in Digital Trust</title>
<link>https://arxiv.org/abs/2406.11511</link>
<guid>https://arxiv.org/abs/2406.11511</guid>
<content:encoded><![CDATA[
<div> 关键词：公共密钥基础设施、互联网安全、证书管理、去中心化、区块链技术

总结:
本文探讨了从集中式到分散式体系结构中证书状态管理的演变，重点关注区块链技术和高级密码学。文章首先分析了集中式系统面临的挑战，如单点故障和信任集中问题，并讨论了现有分散式技术提供的机遇。研究发现，尽管区块链技术提高了安全性与信任分布，但也存在计算并行性受限和加密计算效率低下的瓶颈。为解决这些问题，文章提出了一个分散式技术组件框架，旨在促进向分散式凭证状态管理范式的转变。这一框架旨在克服现有技术的局限性，实现更高效、安全的证书管理。通过整合分散式技术的优势，该框架有望提升互联网整体安全性和可靠性。 <div>
arXiv:2406.11511v2 Announce Type: replace 
Abstract: Public key infrastructures are essential for Internet security, ensuring robust certificate management and revocation mechanisms. The transition from centralized to decentralized systems presents challenges such as trust distribution and privacy-preserving credential management. The transition from centralized to decentralized systems is motivated by addressing the single points of failure inherent in centralized systems and leveraging decentralized technologies' transparency and resilience. This paper explores the evolution of certificate status management from centralized to decentralized frameworks, focusing on blockchain technology and advanced cryptography. We provide a taxonomy of the challenges of centralized systems and discuss opportunities provided by existing decentralized technologies. Our findings reveal that, although blockchain technologies enhance security and trust distribution, they represent a bottleneck for parallel computation and face inefficiencies in cryptographic computations. For this reason, we propose a framework of decentralized technology components that addresses such shortcomings to advance the paradigm shift toward decentralized credential status management.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SplitVAEs: Decentralized scenario generation from siloed data for stochastic optimization problems</title>
<link>https://arxiv.org/abs/2409.12328</link>
<guid>https://arxiv.org/abs/2409.12328</guid>
<content:encoded><![CDATA[
<div> 关键词：Stochastic优化、分布式网络系统、数据驱动场景、变分自编码器（SplitVAEs）、隐私保护

<br /><br />
总结:

本文提出了一种名为SplitVAEs的分布式生成框架，旨在解决大型多利益相关者网络系统（如电力电网和供应链）中基于数据驱动的场景生成问题。SplitVAEs利用变分自编码器技术，无需移动数据即可生成高质量的场景，从而避免了数据孤岛带来的挑战。实验结果表明，SplitVAEs能够学习大规模网络中的空间和时间依赖性，以分散方式匹配多个利益相关者数据的历史联合分布。

通过在分布式内存系统上的实验，证明了SplitVAEs在不同领域中的广泛适用性，这些领域由大量利益相关者主导。与集中式最先进的基准方法相比，SplitVAEs显示出稳健的性能，并显著降低了数据传输成本，提供了比传统方法更可扩展、更注重隐私的场景生成替代方案。 <div>
arXiv:2409.12328v1 Announce Type: new 
Abstract: Stochastic optimization problems in large-scale multi-stakeholder networked systems (e.g., power grids and supply chains) rely on data-driven scenarios to encapsulate complex spatiotemporal interdependencies. However, centralized aggregation of stakeholder data is challenging due to the existence of data silos resulting from computational and logistical bottlenecks. In this paper, we present SplitVAEs, a decentralized scenario generation framework that leverages variational autoencoders to generate high-quality scenarios without moving stakeholder data. With the help of experiments on distributed memory systems, we demonstrate the broad applicability of SplitVAEs in a variety of domain areas that are dominated by a large number of stakeholders. Our experiments indicate that SplitVAEs can learn spatial and temporal interdependencies in large-scale networks to generate scenarios that match the joint historical distribution of stakeholder data in a decentralized manner. Our experiments show that SplitVAEs deliver robust performance compared to centralized, state-of-the-art benchmark methods while significantly reducing data transmission costs, leading to a scalable, privacy-enhancing alternative to scenario generation.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Data to Control: A Formal Compositional Framework for Large-Scale Interconnected Networks</title>
<link>https://arxiv.org/abs/2409.12469</link>
<guid>https://arxiv.org/abs/2409.12469</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、全分布式、安全控制器、未知模型、互联网络

总结:
本文提出了一种基于数据驱动的全分布式方法，用于设计适用于大规模互联网络的安全控制器，这些网络中的子系统具有未知的数学模型。该方法通过利用互联拓扑结构，将网络分析分解为对不同子系统的单独检查。为了捕获子系统之间的联合耗散性质，引入了控制存储证书（CSCs）的概念。CSCs在通过数据组成的推导中起着关键作用，以获得专为此互联网络设计的控制障碍证书（CBC），从而确保其安全性。

在数据驱动的方案中，仅需从每个未知子系统收集一段输入输出轨迹。通过满足特定的秩条件，可以构造出每个子系统的CSC。接着，遵循组成性耗散推理，将数据生成的CSCs组合起来，构建出未知网络的CBC，确保其在无限时间内的安全性，同时提供正确的保证。这种方法显著提高了CBC及其安全控制器在整个互联网络中的设计效率，通过将计算复杂度从与网络维度相关的多项式增长降低到与子系统数量成线性的比例，利用了互联拓扑的结构并可能不受子系统数量的影响来满足耗散型组成性条件。

通过应用于涉及未知模型和不同互联拓扑的物理网络的多种基准测试，证明了数据驱动方法的有效性和适用性。 <div>
arXiv:2409.12469v1 Announce Type: new 
Abstract: We introduce a compositional data-driven methodology for designing fully-decentralized safety controllers applicable to large-scale interconnected networks, encompassing subsystems with unknown mathematical models. Our compositional scheme leverages the interconnection topology and breaks down the network analysis into the examination of distinct subsystems. This is accompanied by utilizing a concept of control storage certificates (CSCs) to capture joint dissipativity-type properties among subsystems. These CSCs are instrumental in a compositional derivation of a control barrier certificate (CBC) specialized for the interconnected network, thereby ensuring its safety. In our data-driven scheme, we gather solely one input-output trajectory from each unknown subsystem within a specified time frame. By fulfilling a specific rank condition, this process facilitates the construction of a CSC for each subsystem. Following this, by adhering to compositional dissipativity reasoning, we compose CSCs derived from data and build a CBC for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We demonstrate that our compositional data-driven approach significantly enhances the design of a CBC and its safety controller across the interconnected network. This advancement is achieved by reducing the computational complexity from a polynomial growth in relation to network dimension, when using sum-of-squares (SOS) optimization, to a linear scale based on the number of subsystems. We additionally demonstrate that the dissipativity-type compositionality condition can benefit from the structure of interconnection topology and potentially be fulfilled regardless of the number of subsystems. We apply our data-driven findings to a variety of benchmarks, involving physical networks with unknown models and diverse interconnection topologies.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Hardness of Decentralized Multi-Agent Policy Evaluation under Byzantine Attacks</title>
<link>https://arxiv.org/abs/2409.12882</link>
<guid>https://arxiv.org/abs/2409.12882</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、分布式评估、拜占庭故障、模型中毒、共识算法

总结:
本文研究了在最多存在$f$个故障智能体的全分布式多智能体策略评估问题。特别关注了由拜占庭故障模型与模型中毒设定下的多智能体系统。通常情况下，策略评估是评估给定策略的价值函数。在协作多智能体系统中，系统总奖励被建模为所有智能体奖励的均匀平均值。文章探讨了在拜占庭智能体存在的背景下，特别是异构局部奖励设置下的多智能体策略评估问题。理想目标是评估累积系统总奖励，即正常智能体给定策略的均匀平均奖励值。然而，证明了该目标不可实现。因此，文章提出了一个放松版本的问题，目标是评估累积系统总奖励，这被视为正常智能体给定策略的加权平均奖励。进一步证明了没有正确的算法能够保证正权重总数超过$|\mathcal{N}|-f $，其中$|\mathcal{N}|$表示正常智能体的数量。最后，提出了一种基于标量函数近似的拜占庭容错分布式时间差分算法，能够确保在渐进共识下算法的有效性，并通过实验验证了算法的有效性。 <div>
arXiv:2409.12882v1 Announce Type: new 
Abstract: In this paper, we study a fully-decentralized multi-agent policy evaluation problem, which is an important sub-problem in cooperative multi-agent reinforcement learning, in the presence of up to $f$ faulty agents. In particular, we focus on the so-called Byzantine faulty model with model poisoning setting. In general, policy evaluation is to evaluate the value function of any given policy. In cooperative multi-agent system, the system-wide rewards are usually modeled as the uniform average of rewards from all agents. We investigate the multi-agent policy evaluation problem in the presence of Byzantine agents, particularly in the setting of heterogeneous local rewards. Ideally, the goal of the agents is to evaluate the accumulated system-wide rewards, which are uniform average of rewards of the normal agents for a given policy. It means that all agents agree upon common values (the consensus part) and furthermore, the consensus values are the value functions (the convergence part). However, we prove that this goal is not achievable. Instead, we consider a relaxed version of the problem, where the goal of the agents is to evaluate accumulated system-wide reward, which is an appropriately weighted average reward of the normal agents. We further prove that there is no correct algorithm that can guarantee that the total number of positive weights exceeds $|\mathcal{N}|-f $, where $|\mathcal{N}|$ is the number of normal agents. Towards the end, we propose a Byzantine-tolerant decentralized temporal difference algorithm that can guarantee asymptotic consensus under scalar function approximation. We then empirically test the effective of the proposed algorithm.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Model for Multi-Agent Heterogeneous Interaction Problems</title>
<link>https://arxiv.org/abs/2208.01430</link>
<guid>https://arxiv.org/abs/2208.01430</guid>
<content:encoded><![CDATA[
<div> 关键词：多代理交互、异质团队、交叉反应性、资源优化、免疫系统启发

总结:

本文提出了一种模型，用于研究异质团队的代理如何组织资源以应对异质攻击者。该模型灵感源自人体免疫系统对抗多样病原体的方式。关键特征是“交叉反应性”核函数，它使得特定防御类型能够强烈响应某些攻击类型，但对少数不同的攻击类型则响应较弱。研究表明，由于这种交叉反应性，防御团队可以使用非常少的防御代理类型来最优地对抗异质攻击团队，从而最小化其资源消耗。

文章在不同设置下研究了此模型，以识别控制问题中异质代理团队的指导原则，包括损害敏感性对非最优防御分布的影响以及防御者之间的竞争如何导致接近最优行为的分散式计算。此外，与现有的方法进行了比较，如基于强化学习的策略、围栏防御和覆盖控制等。

该模型提供了一个新颖的方法论框架，旨在通过借鉴免疫系统的策略，为复杂多代理系统的资源分配和协调提供理论基础与实践指导。 <div>
arXiv:2208.01430v4 Announce Type: replace 
Abstract: We introduce a model for multi-agent interaction problems to understand how a heterogeneous team of agents should organize its resources to tackle a heterogeneous team of attackers. This model is inspired by how the human immune system tackles a diverse set of pathogens. The key property of this model is a ``cross-reactivity'' kernel which enables a particular defender type to respond strongly to some attacker types but weakly to a few different types of attackers. We show how due to such cross-reactivity, the defender team can optimally counteract a heterogeneous attacker team using very few types of defender agents, and thereby minimize its resources. We study this model in different settings to characterize a set of guiding principles for control problems with heterogeneous teams of agents, e.g., sensitivity of the harm to sub-optimal defender distributions, and competition between defenders gives near-optimal behavior using decentralized computation of the control. We also compare this model with existing approaches including reinforcement-learned policies, perimeter defense, and coverage control.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAppSCAN: Building Large-Scale Datasets for Smart Contract Weaknesses in DApp Projects</title>
<link>https://arxiv.org/abs/2305.08456</link>
<guid>https://arxiv.org/abs/2305.08456</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart Contract Weakness Classification Registry、DApp、SWC Registry、DAPPSCAN、smart contract weakness detection tools

<br /><br />
总结:

本文主要关注于构建一个大规模的智能合约弱点数据集，以评估智能合约分析工具的性能。首先，通过分析1199份开源审计报告，从29个安全团队中识别出了9154个弱点，并创建了两个数据集：DAPPSCAN-SOURCE和DAPPSCAN-BYTECODE。其中，DAPPSCAN-SOURCE包含了39904个Solidity文件，以及源自682个真实DApp项目的1618个SWC弱点。然而，这些Solidity文件可能无法直接编译进行进一步分析。为了促进自动化分析，开发了一个工具来识别DApp项目中的依赖关系并完成缺失的公共库。基于此，创建了DAPPSCAN-BYTECODE数据集，其中包括6665个已编译的智能合约及888个SWC弱点。

在DAPPSCAN-BYTECODE数据集上进行了实证研究，评估了最先进的智能合约弱点检测工具的性能。结果显示，这些工具在有效性和成功检测率方面表现不佳，表明未来的研究应优先考虑现实世界的数据集，而非简单的玩具合同。 <div>
arXiv:2305.08456v3 Announce Type: replace 
Abstract: The Smart Contract Weakness Classification Registry (SWC Registry) is a widely recognized list of smart contract weaknesses specific to the Ethereum platform. Despite the SWC Registry not being updated with new entries since 2020, the sustained development of smart contract analysis tools for detecting SWC-listed weaknesses highlights their ongoing significance in the field. However, evaluating these tools has proven challenging due to the absence of a large, unbiased, real-world dataset. To address this problem, we aim to build a large-scale SWC weakness dataset from real-world DApp projects. We recruited 22 participants and spent 44 person-months analyzing 1,199 open-source audit reports from 29 security teams. In total, we identified 9,154 weaknesses and developed two distinct datasets, i.e., DAPPSCAN-SOURCE and DAPPSCAN-BYTECODE. The DAPPSCAN-SOURCE dataset comprises 39,904 Solidity files, featuring 1,618 SWC weaknesses sourced from 682 real-world DApp projects. However, the Solidity files in this dataset may not be directly compilable for further analysis. To facilitate automated analysis, we developed a tool capable of automatically identifying dependency relationships within DApp projects and completing missing public libraries. Using this tool, we created DAPPSCAN-BYTECODE dataset, which consists of 6,665 compiled smart contract with 888 SWC weaknesses. Based on DAPPSCAN-BYTECODE, we conducted an empirical study to evaluate the performance of state-of-the-art smart contract weakness detection tools. The evaluation results revealed sub-par performance for these tools in terms of both effectiveness and success detection rate, indicating that future development should prioritize real-world datasets over simplistic toy contracts.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CyberNFTs: Conceptualizing a decentralized and reward-driven intrusion detection system with ML</title>
<link>https://arxiv.org/abs/2409.11409</link>
<guid>https://arxiv.org/abs/2409.11409</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、区块链、机器学习、网络安全、非同质化代币

<br /><br />
总结:本文探讨了在Web3时代背景下，如何利用新兴技术构建去中心化的协作入侵检测网络（CIDN）。通过将区块链概念、机器学习算法以及出版/订阅架构整合，提出了一种新颖的信息安全模型。模型中引入了基于区块链的奖励机制——“CyberNFT”，旨在激励网络参与者进行安全贡献。文章还分析了该系统的优势和局限性，强调了去中心化在增强网络安全中的潜力。此研究为未来网络防御策略提供了创新思路，有望在保障数据安全与促进用户隐私保护之间找到平衡点。

通过结合区块链技术的透明性和不可篡改性，以及机器学习对异常行为的智能识别能力，该模型旨在实现更高效、更精准的入侵检测。同时，通过“CyberNFT”机制，鼓励用户或网络节点贡献安全信息或资源，形成一种正向的激励机制，促进整个网络的安全性和稳定性。然而，这一系统也面临着技术实现复杂性、经济激励可持续性等问题。因此，研究进一步讨论了这些挑战及其解决方案的可能性，为未来的网络安全建设提供了参考框架。 <div>
arXiv:2409.11409v1 Announce Type: new 
Abstract: The rapid evolution of the Internet, particularly the emergence of Web3, has transformed the ways people interact and share data. Web3, although still not well defined, is thought to be a return to the decentralization of corporations' power over user data. Despite the obsolescence of the idea of building systems to detect and prevent cyber intrusions, this is still a topic of interest. This paper proposes a novel conceptual approach for implementing decentralized collaborative intrusion detection networks (CIDN) through a proof-of-concept. The study employs an analytical and comparative methodology, examining the synergy between cutting-edge Web3 technologies and information security. The proposed model incorporates blockchain concepts, cyber non-fungible token (cyberNFT) rewards, machine learning algorithms, and publish/subscribe architectures. Finally, the paper discusses the strengths and limitations of the proposed system, offering insights into the potential of decentralized cybersecurity models.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multilevel Verification on a Single Digital Decentralized Distributed (DDD) Ledger</title>
<link>https://arxiv.org/abs/2409.11410</link>
<guid>https://arxiv.org/abs/2409.11410</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式数字（DDD）账本、区块链、多级验证、系统层次结构、系统故障概率

总结:

本文提出了一种利用具有多层次验证的去中心化分布式数字（DDD）账本（如区块链）的新方法。在传统的DDD账本中，仅提供单一级别的验证，这在需要在各个层级进行验证的系统中并不适用。引入层次结构意味着在同一层级内可以有多个验证，甚至多于一个级别的验证，从而引发不同层次间交互带来的新挑战，例如当前层级验证上一级层的工作。

文章旨在解决这些复杂性，为系统状态的追踪提供一种路线图，并计算系统的故障概率。通过多层次验证体系，能够更有效地处理存在自然层次结构的系统，确保数据的完整性和一致性。同时，这种方法还考虑了不同层次间的依赖关系和验证过程，以增强系统的整体稳定性和可靠性。

通过引入多层次验证机制，文章提供了一个全面的框架，不仅解决了传统DDD账本在处理层次化系统时的局限性，还为预测和管理系统故障提供了新的可能性。这一创新方法有望在需要高度可靠和透明数据记录的领域中得到广泛应用。 <div>
arXiv:2409.11410v1 Announce Type: new 
Abstract: This paper presents an approach to using decentralized distributed digital (DDD) ledgers like blockchain with multi-level verification. In regular DDD ledgers like Blockchain, only a single level of verification is available, which makes it not useful for those systems where there is a hierarchy and verification is required on each level. In systems where hierarchy emerges naturally, the inclusion of hierarchy in the solution for the problem of the system enables us to come up with a better solution. Introduction to hierarchy means there could be several verification within a level in the hierarchy and more than one level of verification, which implies other challenges induced by an interaction between the various levels of hierarchies that also need to be addressed, like verification of the work of the previous level of hierarchy by given level in the hierarchy. The paper will address all these issues, and provide a road map to trace the state of the system at any given time and probability of failure of the system.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advances in APPFL: A Comprehensive and Extensible Federated Learning Framework</title>
<link>https://arxiv.org/abs/2409.11585</link>
<guid>https://arxiv.org/abs/2409.11585</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、异构性、安全性、可扩展性、开源

总结:本文主要介绍了联邦学习（FL）作为分布式机器学习的一种范式，其在保护数据隐私的同时实现合作模型训练的潜力。特别是在医疗和电网等敏感领域，由于大多数数据为私有、机密且分布广泛，FL成为了一种有前景的方法来有效利用这些数据。然而，异构性和安全性是联邦学习面临的关键挑战，许多现有的联邦学习框架要么未能充分解决这些问题，要么缺乏灵活性以引入新的解决方案。为此，作者提出了一种名为APPFL的可扩展框架和基准测试套件，旨在全面解决异构性和安全问题，并提供用户友好的界面以集成新算法或适应新应用。

APPFL通过大量实验评估了联邦学习的各个方面，包括通信效率、隐私保护、计算性能和资源使用情况。此外，通过垂直、层级和去中心化联邦学习的案例研究，展示了APPFL的可扩展性。该框架已开源发布在GitHub上，为研究人员和开发者提供了宝贵的资源。 <div>
arXiv:2409.11585v1 Announce Type: new 
Abstract: Federated learning (FL) is a distributed machine learning paradigm enabling collaborative model training while preserving data privacy. In today's landscape, where most data is proprietary, confidential, and distributed, FL has become a promising approach to leverage such data effectively, particularly in sensitive domains such as medicine and the electric grid. Heterogeneity and security are the key challenges in FL, however; most existing FL frameworks either fail to address these challenges adequately or lack the flexibility to incorporate new solutions. To this end, we present the recent advances in developing APPFL, an extensible framework and benchmarking suite for federated learning, which offers comprehensive solutions for heterogeneity and security concerns, as well as user-friendly interfaces for integrating new algorithms or adapting to new applications. We demonstrate the capabilities of APPFL through extensive experiments evaluating various aspects of FL, including communication efficiency, privacy preservation, computational performance, and resource utilization. We further highlight the extensibility of APPFL through case studies in vertical, hierarchical, and decentralized FL. APPFL is open-sourced at https://github.com/APPFL/APPFL.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CountChain: A Decentralized Oracle Network for Counting Systems</title>
<link>https://arxiv.org/abs/2409.11592</link>
<guid>https://arxiv.org/abs/2409.11592</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、在线广告、精准计数系统、去中心化、Nash均衡

总结:
本文提出了CountChain，一种针对计数系统的去中心化预言机网络，旨在解决区块链在行业应用中与链下数据连接受限的问题。CountChain通过让所有节点接收数据并允许任意节点发起提议请求，实现了数据的广泛收集。每个提议包含足够的信息以判断事件的发生。随后，随机选择的节点参与游戏，通过提供证据和赌注来验证提议的真实性。只有经过验证为真的提议才会增加智能合约中的计数器。这种机制改变了传统的模式，即智能合约主动调用预言机获取数据，而是由预言机在数据可用时主动调用智能合约。

为了优化系统性能，作者进行了详细参数分析和大规模数据点实验，以确定最佳配置。基于博弈论的分析表明，在合理的参与者行为下，存在纳什均衡状态，确保了所有理性参与者都能以诚实的方式参与其中。此研究为区块链技术在在线广告等依赖精确计数系统的行业中的应用提供了新的思路和解决方案。 <div>
arXiv:2409.11592v1 Announce Type: new 
Abstract: Blockchain integration in industries like online advertising is hindered by its connectivity limitations to off-chain data. These industries heavily rely on precise counting systems for collecting and analyzing off-chain data. This requires mechanisms, often called oracles, to feed off-chain data into smart contracts. However, current oracle solutions are ill-suited for counting systems since the oracles do not know when to expect the data, posing a significant challenge.
  To address this, we present CountChain, a decentralized oracle network for counting systems. In CountChain, data is received by all oracle nodes, and any node can submit a proposition request. Each proposition contains enough data to evaluate the occurrence of an event. Only randomly selected nodes participate in a game to evaluate the truthfulness of each proposition by providing proof and some stake. Finally, the propositions with the outcome of True increment the counter in a smart contract. Thus, instead of a contract calling oracles for data, in CountChain, the oracles call a smart contract when the data is available. Furthermore, we present a formal analysis and experimental evaluation of the system's parameters on over half a million data points to obtain optimal system parameters. In such conditions, our game-theoretical analysis demonstrates that a Nash equilibrium exists wherein all rational parties participate with honesty.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled IoV: Secure Communication and Trustworthy Decision-Making</title>
<link>https://arxiv.org/abs/2409.11621</link>
<guid>https://arxiv.org/abs/2409.11621</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Vehicles（IoV）、区块链、安全认证、数据交换、自动驾驶

总结:
本文提出了一种用于解决车辆间通信安全和可靠自动化决策问题的去中心化框架。该框架包括主层管理车际通信和次层保障车内交互的安全性。通过采用区块链集成安全认证(BiSA)和分布式区块链名称解析(DBNR)等协议，框架确保了分散的身份管理和可靠的数据交换，为安全高效的自动驾驶车辆运营提供了支持。BiSA协议负责提供安全、分散的身份管理机制，而DBNR则确保了分散的名称解析服务，使得车辆间的通信更加安全和高效。整个框架旨在提升IoV环境下的通信安全性与可靠性，从而促进自动驾驶技术的广泛应用。 <div>
arXiv:2409.11621v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV), which enables interactions between vehicles, infrastructure, and the environment, faces challenges in maintaining communication security and reliable automated decisions. This paper introduces a decentralized framework comprising a primary layer for managing inter-vehicle communication and a sub-layer for securing intra-vehicle interactions. By implementing blockchain-based protocols like Blockchain-integrated Secure Authentication (BiSA) and Decentralized Blockchain Name Resolution (DBNR), the framework ensures secure, decentralized identity management and reliable data exchanges, thereby supporting safe and efficient autonomous vehicle operations.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Few-Shot Class-Incremental Learning with Non-IID Decentralized Data</title>
<link>https://arxiv.org/abs/2409.11657</link>
<guid>https://arxiv.org/abs/2409.11657</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、小样本学习、增量学习、知识遗忘、数据异构性

总结:

本文提出了一种针对小样本增量学习的联邦学习框架，旨在解决在保护数据隐私和安全的前提下，开发可扩展且适应性强的智能系统的问题。该框架允许客户端在本地更新模型以学习新类别的同时，保持数据的隐私性，并将模型更新发送到中央服务器进行全局聚合。

为应对小样本学习的挑战，如灾难性遗忘和数据异构性，作者引入了合成数据驱动的方法，通过回放缓冲区数据来维护已有知识并促进新知识的学习。具体地，他们设计了一个噪声感知生成回放模块，以平衡新数据和回放数据，对本地模型进行微调，同时生成新类别数据以进一步扩充回放缓冲区。此外，还提出了基于局部模型在合成数据上性能的分类特定加权聚合策略，以适应数据异构性问题，从而实现有效的全局模型优化，而无需直接访问客户端数据。

通过在三个常用数据集上的全面实验，证实了所提出的框架的有效性和优越性，证明了其在联邦环境下的小样本增量学习能力。 <div>
arXiv:2409.11657v1 Announce Type: new 
Abstract: Few-shot class-incremental learning is crucial for developing scalable and adaptive intelligent systems, as it enables models to acquire new classes with minimal annotated data while safeguarding the previously accumulated knowledge. Nonetheless, existing methods deal with continuous data streams in a centralized manner, limiting their applicability in scenarios that prioritize data privacy and security. To this end, this paper introduces federated few-shot class-incremental learning, a decentralized machine learning paradigm tailored to progressively learn new classes from scarce data distributed across multiple clients. In this learning paradigm, clients locally update their models with new classes while preserving data privacy, and then transmit the model updates to a central server where they are aggregated globally. However, this paradigm faces several issues, such as difficulties in few-shot learning, catastrophic forgetting, and data heterogeneity. To address these challenges, we present a synthetic data-driven framework that leverages replay buffer data to maintain existing knowledge and facilitate the acquisition of new knowledge. Within this framework, a noise-aware generative replay module is developed to fine-tune local models with a balance of new and replay data, while generating synthetic data of new classes to further expand the replay buffer for future tasks. Furthermore, a class-specific weighted aggregation strategy is designed to tackle data heterogeneity by adaptively aggregating class-specific parameters based on local models performance on synthetic data. This enables effective global model optimization without direct access to client data. Comprehensive experiments across three widely-used datasets underscore the effectiveness and preeminence of the introduced framework.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revolutionizing Pharmaceutical Manufacturing: Advances and Challenges of 3D Printing System and Control</title>
<link>https://arxiv.org/abs/2409.11712</link>
<guid>https://arxiv.org/abs/2409.11712</guid>
<content:encoded><![CDATA[
<div> 关键词：3D打印、制药行业、个性化医疗、材料科学、法规框架

<br />
<br />总结:

本文深入探讨了3D打印技术在制药行业的应用及其对传统制药方法的革新。通过3D打印，制药企业能够实现药物的精准制造，包括控制释放模式、剂量和结构复杂性，从而满足日益增长的个性化医疗需求。滴喷打印、紫外固化墨水、材料科学的进步以及相关的法规框架，为这一领域的技术发展提供了重要支持。

然而，尽管3D打印技术在降低成本、提高灵活性和促进分散化生产方面展现出巨大潜力，但在规模化生产、重现性和适应监管方面仍面临挑战。本文对此进行了详尽分析，旨在为该技术在制药制造领域的主流整合提供全面的视角和指导。未来的研究和发展方向将聚焦于解决这些挑战，以实现3D打印技术在制药行业的更广泛和深入应用。 <div>
arXiv:2409.11712v1 Announce Type: new 
Abstract: The advent of 3D printing has transformed the pharmaceutical industry, enabling precision drug manufacturing with controlled release profiles, dosing, and structural complexity. Additive manufacturing (AM) addresses the growing demand for personalized medicine, overcoming limitations of traditional methods. This technology facilitates tailored dosage forms, complex geometries, and real-time quality control. Recent advancements in drop-on-demand printing, UV curable inks, material science, and regulatory frameworks are discussed. Despite opportunities for cost reduction, flexibility, and decentralized manufacturing, challenges persist in scalability, reproducibility, and regulatory adaptation. This review provides an in-depth analysis of the current state of AM in pharmaceutical manufacturing, exploring recent developments, challenges, and future directions for mainstream integration.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering Visual Artists with Tokenized Digital Assets with NFTs</title>
<link>https://arxiv.org/abs/2409.11790</link>
<guid>https://arxiv.org/abs/2409.11790</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币（NFT）、艺术行业、区块链技术、创意实践、版权产业

<br />
<br />
总结:
本文深入探讨了非同质化代币（NFT）对视觉艺术行业的颠覆性影响。首先，文章介绍了区块链领域的关键技术特征和优势，为后续分析奠定了基础。随后，文章回顾了传统艺术创作过程，包括不同类型的创作、生产流程、交易方式以及盈利模式。紧接着，文章详细阐述了区块链生态系统的核心要素，如结构、共识算法、智能合约和数字钱包，进一步明确了NFT的概念。

接下来，文章聚焦于NFT，概述了其历史、运作机制、生命周期以及在艺术领域中的应用，特别是NFT的铸造与交易过程，以及市场动态与定价策略。同时，文章还关注了NFT领域的主要安全问题，如洗盘交易，强调了这一领域中关键的网络安全挑战。

最后，文章展望了未来的研究方向，强调了提升用户体验、增强安全性及保护隐私的重要性。通过综合创意产业界与网络安全专家的意见，本文提供了关于NFT如何赋能视觉艺术家并重塑整个版权产业的新见解。 <div>
arXiv:2409.11790v1 Announce Type: new 
Abstract: The Non-Fungible Tokens (NFTs) has the transformative impact on the visual arts industry by examining the nexus between empowering art practices and leveraging blockchain technology. First, we establish the context for this study by introducing some basic but critical technological aspects and affordances of the blockchain domain. Second, we revisit the creative practices involved in producing traditional artwork, covering various types, production processes, trading, and monetization methods. Third, we introduce and define the key fundamentals of the blockchain ecosystem, including its structure, consensus algorithms, smart contracts, and digital wallets. Fourth, we narrow the focus to NFTs, detailing their history, mechanics, lifecycle, and standards, as well as their application in the art world. In particular, we outline the key processes for minting and trading NFTs in various marketplaces and discuss the relevant market dynamics and pricing. We also consider major security concerns, such as wash trading, to underscore some of the central cybersecurity issues facing this domain. Finally, we conclude by considering future research directions, emphasizing improvements in user experience, security, and privacy. Through this innovative research overview, which includes input from creative industry and cybersecurity sdomain expertise, we offer some new insights into how NFTs can empower visual artists and reshape the wider copyright industries.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>LMMCoDrive: Cooperative Driving with Large Multimodal Model</title>
<link>https://arxiv.org/abs/2409.11981</link>
<guid>https://arxiv.org/abs/2409.11981</guid>
<content:encoded><![CDATA[
<div> 关键词：LMMCoDrive、Large Multimodal Model（LMM）、Decentralized Optimization、Cooperative Autonomous Vehicles（CAVs）、Autonomous Mobility-on-Demand（AMoD）

<br />
<br />总结:
文章介绍了LMMCoDrive，一种利用大型多模态模型（LMM）来提升动态城市环境中交通效率的新型协同驾驶框架。LMMCoDrive将车辆与乘客请求的空间关系抽象为鸟瞰视图（BEV），充分利用了LMM的潜力，并通过安全约束谨慎地细化每个车辆的轨迹以避免碰撞。提出了一种基于交替方向乘子法（ADMM）的分散优化策略，用于驱动车辆图的演化。通过模拟结果，文章展示了LMM在优化车辆调度和增强分散协同优化过程中的关键作用，这标志着向实现高效、安全且实用的AMoD系统迈进的重要一步，旨在彻底改变城市交通格局。代码已开源在https://github.com/henryhcliu/LMMCoDrive。 <div>
arXiv:2409.11981v1 Announce Type: new 
Abstract: To address the intricate challenges of decentralized cooperative scheduling and motion planning in Autonomous Mobility-on-Demand (AMoD) systems, this paper introduces LMMCoDrive, a novel cooperative driving framework that leverages a Large Multimodal Model (LMM) to enhance traffic efficiency in dynamic urban environments. This framework seamlessly integrates scheduling and motion planning processes to ensure the effective operation of Cooperative Autonomous Vehicles (CAVs). The spatial relationship between CAVs and passenger requests is abstracted into a Bird's-Eye View (BEV) to fully exploit the potential of the LMM. Besides, trajectories are cautiously refined for each CAV while ensuring collision avoidance through safety constraints. A decentralized optimization strategy, facilitated by the Alternating Direction Method of Multipliers (ADMM) within the LMM framework, is proposed to drive the graph evolution of CAVs. Simulation results demonstrate the pivotal role and significant impact of LMM in optimizing CAV scheduling and enhancing decentralized cooperative optimization process for each vehicle. This marks a substantial stride towards achieving practical, efficient, and safe AMoD systems that are poised to revolutionize urban transportation. The code is available at https://github.com/henryhcliu/LMMCoDrive.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs</title>
<link>https://arxiv.org/abs/2409.12171</link>
<guid>https://arxiv.org/abs/2409.12171</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、健康3.0、标准接口、知识图谱

<br /><br />
总结:

本文主要探讨了如何利用区块链技术中的智能合约来实现健康3.0背景下的分布式决策。健康3.0允许基于多个机构的长期数据进行决策，这需要一种中立的中介来实施可信赖的决策过程。为了解决这一需求，文章提出了使用符合行业标准（如HL7 FHIR）的结构化数据和智能合约之间的互操作性。通过将智能合约逻辑编码到高阶语义知识图谱中，并在区块链上部署此知识图谱，可以实现数据在不同机构之间的无缝传输与处理。

文章介绍了生成智能合约的离链代码流程，该流程首先将知识图谱编译成具体的智能合约代码，然后在区块链上部署。这种方法避免了在区块链上使用可能成本更高且不可预测的规则引擎，从而遵循了区块链的经济规则。

文章以三个医疗保险案例为例，展示了生成的智能合约在正确性和执行成本（"gas"）方面的良好性能。此外，还讨论了这种基于知识图谱的智能合约生成方法在医疗保健领域的适用性以及未来研究方向，包括探索大型语言模型（LLM）在这一过程中的应用。

通过这种方式，文章证明了在尊重区块链经济规则的前提下，自动根据语义知识图谱生成智能合约是可行的，为医疗保健领域提供了新的技术支持。 <div>
arXiv:2409.12171v1 Announce Type: new 
Abstract: Background: Health 3.0 allows decision making to be based on longitudinal data from multiple institutions, from across the patient's healthcare journey. In such a distributed setting, blockchain smart contracts can act as neutral intermediaries to implement trustworthy decision making.
  Objective: In a distributed setting, transmitted data will be structured using standards (such as HL7 FHIR) for semantic interoperability. In turn, the smart contract will require interoperability with this standard, implement a complex communication setup (e.g., using oracles), and be developed using blockchain languages (e.g., Solidity). We propose the encoding of smart contract logic using a high-level semantic Knowledge Graph, using concepts from the domain standard. We then deploy this semantic KG on blockchain.
  Methods: Off-chain, a code generation pipeline compiles the KG into a concrete smart contract, which is then deployed on-chain. Our pipeline targets an intermediary bridge representation, which can be transpiled into a specific blockchain language. Our choice avoids on-chain rule engines, with unpredictable and likely higher computational cost; it is thus in line with the economic rules of blockchain.
  Results: We applied our code generation approach to generate smart contracts for 3 health insurance cases from Medicare. We discuss the suitability of our approach - the need for a neutral intermediary - for a number of healthcare use cases. Our evaluation finds that the generated contracts perform well in terms of correctness and execution cost ("gas") on blockchain.
  Conclusions: We showed that it is feasible to automatically generate smart contract code based on a semantic KG, in a way that respects the economic rules of blockchain. Future work includes studying the use of Large Language Models (LLM) in our approach, and evaluations on other blockchains.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedVeca: Federated Vectorized Averaging on Non-IID Data with Adaptive Bi-directional Global Objective</title>
<link>https://arxiv.org/abs/2209.13803</link>
<guid>https://arxiv.org/abs/2209.13803</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedVeca方法、非独立同分布数据、本地更新次数、全局模型优化

<br />
总结:
文章提出了一种名为FedVeca的新方法，旨在解决在非独立同分布数据(FedVeca)下的联邦学习问题。该方法通过定义局部梯度为具有步长和方向的双向向量来改进联邦学习过程。步长表示本地更新次数，而方向则根据特定定义分为正负两部分。FedVeca通过平均这些双向向量，以减少不同步长对全局模型优化的影响。作者进一步分析了步长与全局目标之间的关系，并根据此关系设计了一个算法，使服务器和客户端能够适应性地调整步长，使其接近最优值。实验结果表明，FedVeca方法在不同数据集、模型和场景中都能有效提高联邦学习的效果和效率。 <div>
arXiv:2209.13803v3 Announce Type: replace 
Abstract: Federated Learning (FL) is a distributed machine learning framework to alleviate the data silos, where decentralized clients collaboratively learn a global model without sharing their private data. However, the clients' Non-Independent and Identically Distributed (Non-IID) data negatively affect the trained model, and clients with different numbers of local updates may cause significant gaps to the local gradients in each communication round. In this paper, we propose a Federated Vectorized Averaging (FedVeca) method to address the above problem on Non-IID data. Specifically, we set a novel objective for the global model which is related to the local gradients. The local gradient is defined as a bi-directional vector with step size and direction, where the step size is the number of local updates and the direction is divided into positive and negative according to our definition. In FedVeca, the direction is influenced by the step size, thus we average the bi-directional vectors to reduce the effect of different step sizes. Then, we theoretically analyze the relationship between the step sizes and the global objective, and obtain upper bounds on the step sizes per communication round. Based on the upper bounds, we design an algorithm for the server and the client to adaptively adjusts the step sizes that make the objective close to the optimum. Finally, we conduct experiments on different datasets, models and scenarios by building a prototype system, and the experimental results demonstrate the effectiveness and efficiency of the FedVeca method.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Multi-Cell Spectrum and Power Allocation</title>
<link>https://arxiv.org/abs/2312.05746</link>
<guid>https://arxiv.org/abs/2312.05746</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式方法、多代理强化学习（MARL）、交通驱动、可扩展性、QoS性能

<br /><br />
总结:本文提出了一种基于分布式多代理强化学习(MARL)框架的新型多小区无线网络射频资源分配策略。通过让每个代理控制单个小区并根据局部信息进行频谱和功率分配，该方法实现了与使用全局信息的集中式方法相媲美的服务质量(QoS)表现，同时显著降低了执行时间。此研究将问题转化为分布式学习问题，利用多代理近端策略优化(MAPPO)算法结合循环神经网络和队列动力学来解决。这种交通驱动的MARL解决方案支持去中心化的训练与执行，确保了大型网络的可扩展性。通过广泛模拟验证，该方法不仅达到了与具备完美信息集中式算法相似的QoS性能，还展示了在不同网络规模和流量条件下的可扩展性和鲁棒性。 <div>
arXiv:2312.05746v2 Announce Type: replace 
Abstract: This paper introduces a novel approach to radio resource allocation in multi-cell wireless networks using a fully scalable multi-agent reinforcement learning (MARL) framework. A distributed method is developed where agents control individual cells and determine spectrum and power allocation based on limited local information, yet achieve quality of service (QoS) performance comparable to centralized methods using global information. The objective is to minimize packet delays across devices under stochastic arrivals and applies to both conflict graph abstractions and cellular network configurations. This is formulated as a distributed learning problem, implementing a multi-agent proximal policy optimization (MAPPO) algorithm with recurrent neural networks and queueing dynamics. This traffic-driven MARL-based solution enables decentralized training and execution, ensuring scalability to large networks. Extensive simulations demonstrate that the proposed methods achieve comparable QoS performance to genie-aided centralized algorithms with significantly less execution time. The trained policies also exhibit scalability and robustness across various network sizes and traffic conditions.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detection Made Easy: Potentials of Large Language Models for Solidity Vulnerabilities</title>
<link>https://arxiv.org/abs/2409.10574</link>
<guid>https://arxiv.org/abs/2409.10574</guid>
<content:encoded><![CDATA[
<div> 关键词：Solidity智能合约、大型语言模型（LLMs）、OWASP Top Ten漏洞、VulSmart数据集、SmartVD框架

<br /><br />
总结:
本文研究了大型语言模型（LLMs）在检测以太坊主网上使用Solidity编写的智能合约中的OWASP Top Ten漏洞的能力。研究团队创建了一个名为VulSmart的新型、平衡分类、结构化和标注的数据集，用于评估开源LLMs如CodeLlama、Llama2、CodeT5和Falcon，以及闭源模型GPT-3.5 Turbo和GPT-4o Mini的表现。他们提出了一个名为SmartVD的框架，通过广泛的自动化和人工评估来测试这些模型，利用BLEU和ROUGE指标来评估漏洞检测的有效性。研究还探索了零样本、少量样本和链式思维三种不同的提示策略，以评估SmartVD框架的多类分类和生成能力。研究发现，SmartVD在检测漏洞方面优于其开源同辈，甚至超越了闭源基础模型GPT-3.5和GPT-4 Mini的性能。在微调后，闭源模型GPT-3.5 Turbo和GPT-4o Mini在检测漏洞方面达到了99%的准确率，在识别漏洞类型和确定严重程度方面的表现分别为94%和98%。特别地，SmartVD在“链式思维”提示技术上表现最佳，而微调后的闭源模型则在“零样本”提示方法上表现出色。 <div>
arXiv:2409.10574v1 Announce Type: new 
Abstract: The large-scale deployment of Solidity smart contracts on the Ethereum mainnet has increasingly attracted financially-motivated attackers in recent years. A few now-infamous attacks in Ethereum's history includes DAO attack in 2016 (50 million dollars lost), Parity Wallet hack in 2017 (146 million dollars locked), Beautychain's token BEC in 2018 (900 million dollars market value fell to 0), and NFT gaming blockchain breach in 2022 ($600 million in Ether stolen). This paper presents a comprehensive investigation of the use of large language models (LLMs) and their capabilities in detecting OWASP Top Ten vulnerabilities in Solidity. We introduce a novel, class-balanced, structured, and labeled dataset named VulSmart, which we use to benchmark and compare the performance of open-source LLMs such as CodeLlama, Llama2, CodeT5 and Falcon, alongside closed-source models like GPT-3.5 Turbo and GPT-4o Mini. Our proposed SmartVD framework is rigorously tested against these models through extensive automated and manual evaluations, utilizing BLEU and ROUGE metrics to assess the effectiveness of vulnerability detection in smart contracts. We also explore three distinct prompting strategies-zero-shot, few-shot, and chain-of-thought-to evaluate the multi-class classification and generative capabilities of the SmartVD framework. Our findings reveal that SmartVD outperforms its open-source counterparts and even exceeds the performance of closed-source base models like GPT-3.5 and GPT-4 Mini. After fine-tuning, the closed-source models, GPT-3.5 Turbo and GPT-4o Mini, achieved remarkable performance with 99% accuracy in detecting vulnerabilities, 94% in identifying their types, and 98% in determining severity. Notably, SmartVD performs best with the `chain-of-thought' prompting technique, whereas the fine-tuned closed-source models excel with the `zero-shot' prompting approach.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deterministic Bounds in Committee Selection: Enhancing Decentralization and Scalability in Distributed Ledgers</title>
<link>https://arxiv.org/abs/2409.10727</link>
<guid>https://arxiv.org/abs/2409.10727</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式共识、随机委员会选择、公平性、确定性边界、敌对影响

总结:
本文聚焦于分布式共识系统中的公平随机委员会选举过程，特别是采用加密抽签方法确保委员会大小恒定的方案。与现有协议提供的概率性保证不同，本文提出的新方法旨在提供确定性的边界，以限制委员会中敌对方的影响。通过引入创新方法和进行数值实验，文章证明了这种方法能够有效增强系统的去中心化特性。

具体而言，文章首先概述了区块链系统中基于稀缺资源（如股权、存储、内存或计算能力）的加权彩票机制在选择负责共识过程及添加新信息至区块链的委员会成员中的重要性。接着，作者对比了两种主要的随机委员会选择方法：一种是每个验证候选者在共识阶段本地检查是否当选并展示证明；另一种是使用排序算法决定固定大小的全球验证委员会。

文章的重点在于后者，特别是加密抽签方法，该方法确保委员会大小恒定，同时提供确定性边界来限制委员会中敌对方的影响力。这种策略克服了现有协议仅提供概率性保证的局限性，通常导致委员会规模过大，不适合许多基于多数原则的应用场景，如原子广播和随机信标协议。通过引入新的方法和分析，文章为实现更强大、更公平的去中心化系统提供了理论基础和实践指导。 <div>
arXiv:2409.10727v1 Announce Type: new 
Abstract: Consensus plays a crucial role in distributed ledger systems, impacting both scalability and decentralization. Many blockchain systems use a weighted lottery based on a scarce resource such as a stake, storage, memory, or computing power to select a committee whose members drive the consensus and are responsible for adding new information to the ledger. Therefore, ensuring a robust and fair committee selection process is essential for maintaining security, efficiency, and decentralization.
  There are two main approaches to randomized committee selection. In one approach, each validator candidate locally checks whether they are elected to the committee and reveals their proof during the consensus phase. In contrast, in the second approach, a sortition algorithm decides a fixed-sized committee that is globally verified. This paper focuses on the latter approach, with cryptographic sortition as a method for fair committee selection that guarantees a constant committee size. Our goal is to develop deterministic guarantees that strengthen decentralization. We introduce novel methods that provide deterministic bounds on the influence of adversaries within the committee, as evidenced by numerical experiments. This approach overcomes the limitations of existing protocols that only offer probabilistic guarantees, often providing large committees that are impractical for many quorum-based applications like atomic broadcast and randomness beacon protocols.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Anti-disguise Authentication System Using the First Impression of Avatar in Metaverse</title>
<link>https://arxiv.org/abs/2409.10850</link>
<guid>https://arxiv.org/abs/2409.10850</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、身份认证、反伪装、签加密、区块链存储

<br /><br />
总结:
本文提出了一个基于元宇宙环境的反伪装身份认证方法，旨在解决虚拟世界中用户通过创建个性化数字形象（即头像）进行交互时可能出现的身份欺骗问题。该方法借鉴了现实世界中初次印象的作用，利用首次会面的场景信息来辅助用户间的身份验证过程。为防止对手替换和伪造初次印象，文中构建了一种基于变色龙的签加密机制，并设计了一个密文认证协议以确保加密身份的公开可验证性。安全分析显示，该签加密机制不仅满足了安全性需求，还实现了公开可验证性。此外，密文认证协议具备防御对手对初次印象进行替换和伪造的能力。实验结果显示，所提出的头像认证系统能够在区块链上以较低的存储消耗实现有效的反伪装身份认证。 <div>
arXiv:2409.10850v1 Announce Type: new 
Abstract: Metaverse is a vast virtual world parallel to the physical world, where the user acts as an avatar to enjoy various services that break through the temporal and spatial limitations of the physical world. Metaverse allows users to create arbitrary digital appearances as their own avatars by which an adversary may disguise his/her avatar to fraud others. In this paper, we propose an anti-disguise authentication method that draws on the idea of the first impression from the physical world to recognize an old friend. Specifically, the first meeting scenario in the metaverse is stored and recalled to help the authentication between avatars. To prevent the adversary from replacing and forging the first impression, we construct a chameleon-based signcryption mechanism and design a ciphertext authentication protocol to ensure the public verifiability of encrypted identities. The security analysis shows that the proposed signcryption mechanism meets not only the security requirement but also the public verifiability. Besides, the ciphertext authentication protocol has the capability of defending against the replacing and forging attacks on the first impression. Extensive experiments show that the proposed avatar authentication system is able to achieve anti-disguise authentication at a low storage consumption on the blockchain.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Inside Alameda Research: A Multi-Token Network Analysis</title>
<link>https://arxiv.org/abs/2409.10949</link>
<guid>https://arxiv.org/abs/2409.10949</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、Alameda Research、DeFi生态系统、网络分析、时间演变

<br /><br />
总结:

本文聚焦于对以太坊上与Alameda Research相关的代币转移网络进行的深入分析。Alameda Research是一家涉及FTX客户资金不当使用的加密货币交易公司。研究通过多代币网络表示法，分析节点中心性和网络骨架，以识别关键账户、代币和活动群体。对Alameda账户随时间的变化进行的研究揭示了其在破产前（2022年11月）的代币积累和分配模式的转变。通过网络分析，本文提供了关于塑造去中心化金融(DeFi)生态系统的活动和动态的见解。这一研究不仅有助于理解特定实体在加密市场中的行为，也为更广泛地理解DeFi生态系统中的资金流动和风险提供了洞见。 <div>
arXiv:2409.10949v1 Announce Type: new 
Abstract: We analyze the token transfer network on Ethereum, focusing on accounts associated with Alameda Research, a cryptocurrency trading firm implicated in the misuse of FTX customer funds. Using a multi-token network representation, we examine node centralities and the network backbone to identify critical accounts, tokens, and activity groups. The temporal evolution of Alameda accounts reveals shifts in token accumulation and distribution patterns leading up to its bankruptcy in November 2022. Through network analysis, our work offers insights into the activities and dynamics that shape the DeFi ecosystem.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Delay Analysis of EIP-4844</title>
<link>https://arxiv.org/abs/2409.11043</link>
<guid>https://arxiv.org/abs/2409.11043</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum改进提案、Proto-Danksharding、数据分片、数据可用性、延迟模型

总结:
文章主要讨论了Ethereum改进提案EIP-4844中提出的Proto-Danksharding技术，该技术旨在通过引入名为blob-carrying交易的新类型来逐步提高以太坊区块链的可扩展性。这些交易将大型二进制对象（blob）存储于链下，但通过在链上引用和验证来确保数据可用性。通过将数据可用性与交易执行分离，Proto-Danksharding缓解了网络拥堵并降低了气体费用，为更高级的数据分片解决方案打下了基础。

文章提供了一个分析模型，用于推导这些新交易的延迟。通过将系统建模为$\mathrm{M/D}^B/1$队列，并通过嵌入马尔可夫链和辅助变量方法找到其稳态分布，作者证明了与较低blob数量但更高频率的交易相比，具有更多blob但更少频率的交易对系统的延迟影响更大。这一发现对于优化交易处理和提高整体网络效率至关重要。 <div>
arXiv:2409.11043v1 Announce Type: new 
Abstract: Proto-Danksharding, proposed in Ethereum Improvement Proposal 4844 (EIP-4844), aims to incrementally improve the scalability of the Ethereum blockchain by introducing a new type of transaction known as blob-carrying transactions. These transactions incorporate binary large objects (blobs) of data that are stored off-chain but referenced and verified on-chain to ensure data availability. By decoupling data availability from transaction execution, Proto-Danksharding alleviates network congestion and reduces gas fees, laying the groundwork for future, more advanced sharding solutions. This letter provides an analytical model to derive the delay for these new transactions. We model the system as an $\mathrm{M/D}^B/1$ queue which we then find its steady state distribution through embedding a Markov chain and use of supplementary variable method. We show that transactions with more blobs but less frequent impose higher delays on the system compared to lower blobs but more frequent.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-UAV Uniform Sweep Coverage in Unknown Environments: A Mergeable Nervous System (MNS)-Based Random Exploration</title>
<link>https://arxiv.org/abs/2409.11116</link>
<guid>https://arxiv.org/abs/2409.11116</guid>
<content:encoded><![CDATA[
<div> 关键词：多无人机、均匀覆盖、随机漫步、自组织网络、未知环境

<br /><br />
总结:本文研究了多无人飞行器（UAV）在未知环境下进行均匀覆盖的问题。研究发现，基于随机游走的探索策略适用于此类覆盖场景，因为它们不需要定位信息，易于在机器人集群中实现。文中提出了一种基于自组织神经系统（MNS）框架的随机游走方法，该方法允许无人机群自我组织成一种基于局部通信的层次化自适应通信网络，并以线性队形的形式进行移动。通过模拟比较，该方法在达到全面覆盖所需的总时间以及覆盖均匀性方面，均优于几种分散的随机游走基准策略。实验结果表明，MNS基于的随机游走策略在环境覆盖效率和覆盖一致性上表现出色。 <div>
arXiv:2409.11116v1 Announce Type: new 
Abstract: This paper investigates the problem of multi-UAV uniform sweep coverage, where a homogeneous swarm of UAVs must collectively and evenly visit every portion of an unknown environment for a sampling task without having access to their own location and orientation. Random walk-based exploration strategies are practical for such a coverage scenario as they do not rely on localization and are easily implementable in robot swarms. We demonstrate that the Mergeable Nervous System (MNS) framework, which enables a robot swarm to self-organize into a hierarchical ad-hoc communication network using local communication, is a promising control approach for random exploration in unknown environments by UAV swarms. To this end, we propose an MNS-based random walk approach where UAVs self-organize into a line formation using the MNS framework and then follow a random walk strategy to cover the environment while maintaining the formation. Through simulations, we test the efficiency of our approach against several decentralized random walk-based strategies as benchmarks. Our results show that the MNS-based random walk outperforms the benchmarks in terms of the time required to achieve full coverage and the coverage uniformity at that time, assessed across both the entire environment and within local regions.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Incredible Shrinking Context... in a decompiler near you</title>
<link>https://arxiv.org/abs/2409.11157</link>
<guid>https://arxiv.org/abs/2409.11157</guid>
<content:encoded><![CDATA[
<div> 关键词：Shrknr、Elipmoc、静态分析、符号执行、智能合约

总结:

本文介绍了一种名为Shrknr的新一代智能合约二进制代码反编译工具。Shrknr通过引入“缩减上下文敏感性”这一创新技术，相较于现有的反编译工具如Elipmoc，在可扩展性、完整性、精确度等关键维度上实现了显著提升。具体而言，Shrknr能够处理更多的智能合约代码（覆盖更多代码的比例提高了67%，并达到99.5%的合约覆盖率），同时将关键的不精确度指标降低了超过65%。

Shrknr采用了基于静态分析的方法进行反编译，与依赖于符号执行的技术相比，它通过深挖静态分析上下文并积极“遗忘”控制流历史来释放进一步精确推理的空间，从而实现性能的提升。在标准基准测试集中，Shrknr的表现远超其他同类工具，展现了其在智能合约反编译领域的先进性和实用性。 <div>
arXiv:2409.11157v1 Announce Type: new 
Abstract: Decompilation of binary code has arisen as a highly-important application in the space of Ethereum VM (EVM) smart contracts. Major new decompilers appear nearly every year and attain popularity, for a multitude of reverse-engineering or tool-building purposes. Technically, the problem is fundamental: it consists of recovering high-level control flow from a highly-optimized continuation-passing-style (CPS) representation. Architecturally, decompilers can be built using either static analysis or symbolic execution techniques.
  We present Shrknr, a static-analysis-based decompiler succeeding the state-of-the-art Elipmoc decompiler. Shrknr manages to achieve drastic improvements relative to the state of the art, in all significant dimensions: scalability, completeness, precision. Chief among the techniques employed is a new variant of static analysis context: shrinking context sensitivity. Shrinking context sensitivity performs deep cuts in the static analysis context, eagerly "forgetting" control-flow history, in order to leave room for further precise reasoning.
  We compare Shrnkr to state-of-the-art decompilers, both static-analysis- and symbolic-execution-based. In a standard benchmark set, Shrnkr scales to over 99.5% of contracts (compared to ~95%), covers (i.e., reaches and manages to decompile) 67% more code, and reduces key imprecision metrics by over 65%.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Biometric Authentication based on Fuzzy Commitments and Blockchain</title>
<link>https://arxiv.org/abs/2409.11303</link>
<guid>https://arxiv.org/abs/2409.11303</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、生物识别认证、去中心化、隐私保护、模糊承诺方案

<br /><br />
总结:
本文聚焦于利用区块链技术实现生物识别认证的去中心化与隐私保护。传统上，生物识别认证依赖于中心化的系统进行，而区块链作为公开基础设施，其特性与生物识别需求存在矛盾——即需要保护个人生物特征的隐私性。为解决这一冲突，作者提出了一种基于区块链的生物识别认证协议，该协议通过引入模糊承诺方案，确保了在无需泄露生物数据的情况下完成认证过程。此外，文章还对所提出的协议进行了安全分析，考虑到可能的攻击方式，以确保其安全性。这一创新旨在为生物识别领域引入去中心化和增强的隐私保护机制，同时保持系统的可靠性和安全性。 <div>
arXiv:2409.11303v1 Announce Type: new 
Abstract: Blockchain technology, which was introduced for supporting cryptocurrencies, today provides a decentralized infrastructure for general information storage and execution of algorithms, thus enabling the conversion of many applications and services from a centralized and intermediated model to a decentralized and disintermediated one. In this paper we focus on biometric authentication, which is classically performed using centralized systems, and could hence benefit from decentralization. For such a purpose, however, an inherent contradiction between biometric applications and blockchain technology must be overcome, as the former require keeping biometric features private, while blockchain is a public infrastructure. We propose a blockchain-based biometric authentication protocol that enables decentralization and resilience while protecting the privacy, personal data, and, in particular, biometric features of users. The protocol we propose leverages fuzzy commitment schemes to allow biometric authentication to be performed without disclosing biometric data. We also analyze the security of the protocol we propose by considering some relevant attacks.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Constrained Learning for Decentralized Multi-Objective Coverage Control</title>
<link>https://arxiv.org/abs/2409.11311</link>
<guid>https://arxiv.org/abs/2409.11311</guid>
<content:encoded><![CDATA[
<div> 关键词：多目标优化、公平覆盖、约束覆盖、分布式学习、感知-行动-通信网络

<br /><br />
总结:
本文研究了机器人集群在多个异构重要性密度场（IDFs）上同时提供传感器覆盖的多目标覆盖控制问题。提出了公平覆盖和约束覆盖两种不同形式的问题，并探讨了在有限通信和局部感知能力下的分散设置。为了解决这一复杂问题，作者提出了一种新颖的分散式约束学习方法，结合了普鲁-杜尔优化和可学习感知-行动-通信（LPAC）神经网络架构。该方法将对偶问题的拉格朗日乘子重新表述为IDF的线性组合，使LPAC策略能够作为求解器。实验结果表明，该方法在覆盖成本上平均比现有最先进的分散控制器高出30%，并且在更大的环境和更多机器人的情况下表现出良好的转移性和可扩展性，特别是在处理数量更多的领域和集群机器人时。 <div>
arXiv:2409.11311v1 Announce Type: new 
Abstract: The multi-objective coverage control problem requires a robot swarm to collaboratively provide sensor coverage to multiple heterogeneous importance density fields (IDFs) simultaneously. We pose this as an optimization problem with constraints and study two different formulations: (1) Fair coverage, where we minimize the maximum coverage cost for any field, promoting equitable resource distribution among all fields; and (2) Constrained coverage, where each field must be covered below a certain cost threshold, ensuring that critical areas receive adequate coverage according to predefined importance levels. We study the decentralized setting where robots have limited communication and local sensing capabilities, making the system more realistic, scalable, and robust. Given the complexity, we propose a novel decentralized constrained learning approach that combines primal-dual optimization with a Learnable Perception-Action-Communication (LPAC) neural network architecture. We show that the Lagrangian of the dual problem can be reformulated as a linear combination of the IDFs, enabling the LPAC policy to serve as a primal solver. We empirically demonstrate that the proposed method (i) significantly outperforms existing state-of-the-art decentralized controllers by 30% on average in terms of coverage cost, (ii) transfers well to larger environments with more robots and (iii) is scalable in the number of fields and robots in the swarm.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Survey of Threshold Signatures: NIST Standards, Post-Quantum Cryptography, Exotic Techniques, and Real-World Applications</title>
<link>https://arxiv.org/abs/2311.05514</link>
<guid>https://arxiv.org/abs/2311.05514</guid>
<content:encoded><![CDATA[
<div> 关键词：阈值签名、分布式签名、后量子密码学、标准签名、安全多方计算

总结:

本文提供了一篇关于具有高级功能的阈值和分布式签名的全面系统综述。研究涵盖了传统和后量子密码学（PQC）环境下的阈值签名，以及定制设计和标准签名（如常规NIST和NIST-PQC）。文章深入探讨了各种签名家族中的通用（通过安全多方计算实现）和自定义阈值技术，同时考察了奇特签名、实际应用案例及其未来研究方向。该综述旨在为理解新兴去中心化下一代网络系统的安全性提供参考。

本文首先概述了阈值数字签名的概念与重要性，指出它们在确保分布式系统安全方面的关键作用。接着，详细对比分析了传统和后量子密码学环境下不同类型的阈值签名方案，强调了其在不同应用场景下的适用性和优势。文中还特别关注了安全多方计算在构建高效、安全的阈值签名机制中的作用，以及如何利用这一技术优化签名过程，提高系统的整体安全性。

此外，文章深入探讨了标准签名（如NIST和NIST-PQC）在现代网络安全体系中的角色，通过比较分析，揭示了它们在性能、安全性和实用性方面与其他签名方案的区别。同时，对于奇特签名的介绍，不仅展示了签名技术的多样性，也为未来的创新提供了灵感。

最后，文章展望了未来研究的方向，包括如何结合最新技术（如区块链、零知识证明等）进一步提升签名机制的安全性和效率，以及在实际应用中面临的挑战与机遇。通过全面审视阈值和分布式签名的现状与未来，本文旨在为相关领域的研究人员和实践者提供有价值的见解和指导。 <div>
arXiv:2311.05514v2 Announce Type: replace 
Abstract: Threshold digital signatures enable a distributed execution of signature functionalities and will play a crucial role in the security of emerging decentralized next-generation networked systems and applications. In this paper, we provide a comprehensive and systematic survey of threshold and distributed signatures with advanced features. Our survey encompasses threshold signatures in conventional and post-quantum cryptography (PQC) settings and captures custom-design and standard signatures (e.g., conventional NIST and NIST-PQC). We examine both generic (via secure multi-party computation) and custom thresholding techniques for a myriad of signature families while investigating exotic signatures, real-life applications, and potential future research direction.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Billing for Local Energy Markets</title>
<link>https://arxiv.org/abs/2404.15886</link>
<guid>https://arxiv.org/abs/2404.15886</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、本地能源市场、去中心化、信息论安全、多方计算

<br /><br />
总结:本文提出了一种名为PBP-LEM的隐私保护计费协议，旨在为本地能源市场提供一种方法，以确保市场参与者能够从其投标中偏离的能源量进行联合计算，同时保持私密性并避免内部勾结的风险。该协议基于一个高效且具有信息论安全性的个体计费方案，作为构建基础。通过结合多方计算、内积功能加密和佩尔森承诺等技术，PBP-LEM确保了数据的机密性和准确性。文章还提出了三种不同隐私保护级别和性能的实现方式。经过验证，无论使用哪种最复杂或最简单的方法，该协议都能满足其安全性和隐私要求，并适用于实际部署。例如，对于4000名用户，最复杂的计算方法可在不到五分钟内完成计费计算，而最简单的方法只需0.18秒。 <div>
arXiv:2404.15886v2 Announce Type: replace 
Abstract: We propose a privacy-preserving billing protocol for local energy markets (PBP-LEM) that takes into account market participants' energy volume deviations from their bids. PBP-LEM enables a group of market entities to jointly compute participants' bills in a decentralized and privacy-preserving manner without sacrificing correctness. It also mitigates risks on individuals' privacy arising from any potential internal collusion. We first propose an efficient and privacy-preserving individual billing scheme, achieving information-theoretic security, which serves as a building block. PBP-LEM utilizes this scheme, along with other techniques such as multiparty computation, inner product functional encryption and Pedersen commitments to ensure data confidentiality and accuracy. Additionally, we present three approaches, resulting in different levels of privacy protection and performance. We prove that the protocol meets its security and privacy requirements and is feasible for deployment in real LEMs: bills can be computed in less than five minutes for 4,000 users using the most computationally intensive approach, and in just 0.18 seconds using the least intensive one.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Give and Take: An End-To-End Investigation of Giveaway Scam Conversion Rates</title>
<link>https://arxiv.org/abs/2405.09757</link>
<guid>https://arxiv.org/abs/2405.09757</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、诈骗、社交媒体、直播、区块链

总结:
本文聚焦于加密货币赠品诈骗的规模性运作，通过整合Twitter、YouTube直播、Twitch、着陆页面与区块链数据，揭示了诈骗的模式与影响。研究发现，每1000条诈骗推文和每10万次直播观看中就有1人成为受害者，而诈骗者在观测期内从数百名受害者中榨取了近462万美元。这揭示了诈骗活动如何利用社交媒体和直播平台进行传播，以及加密货币的匿名特性为诈骗提供了便利。此外，通过区块链数据的分析，可以追踪资金流动路径，为制定更有效的反诈骗策略提供依据。此研究强调了理解诈骗生态系统的重要性，以设计出更具针对性的干预措施。 <div>
arXiv:2405.09757v2 Announce Type: replace 
Abstract: Scams -- fraudulent schemes designed to swindle money from victims -- have existed for as long as recorded history. However, the Internet's combination of low communication cost, global reach, and functional anonymity has allowed scam volumes to reach new heights. Designing effective interventions requires first understanding the context: how scammers reach potential victims, the earnings they make, and any potential bottlenecks for durable interventions. In this short paper, we focus on these questions in the context of cryptocurrency giveaway scams, where victims are tricked into irreversibly transferring funds to scammers under the pretense of even greater returns. Combining data from Twitter, YouTube and Twitch livestreams, landing pages, and cryptocurrency blockchains, we measure how giveaway scams operate at scale. We find that 1 in 1000 scam tweets, and 4 in 100,000 livestream views, net a victim, and that scammers managed to extract nearly \$4.62 million from just hundreds of victims during our measurement window.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reputation-Driven Peer-to-Peer Live Streaming Architecture for Preventing Free-Riding</title>
<link>https://arxiv.org/abs/2409.09329</link>
<guid>https://arxiv.org/abs/2409.09329</guid>
<content:encoded><![CDATA[
<div> 关键词：P2P、直播流、声誉系统、免费乘车、恶意节点

<br />
总结:

本文提出了一种用于解决P2P直播流中常见问题的新架构。该架构通过集成声誉系统，旨在激励积极参与的节点，同时惩罚机会主义行为和恶意节点。其核心机制包括：

1. **声誉系统激励**：该系统通过奖励积极贡献的节点（如提供资源或带宽的节点）并惩罚那些利用他人资源而未做贡献的“免费乘车者”和恶意行为者。

2. **动态策略更新**：算法持续评估和调整策略以应对网络中的变化，如节点的加入与离开，确保系统稳定性。

3. **请求加入机制**：在突发高流量情况下，源节点能够将请求分配给子节点，形成树状结构，有效管理流量高峰并保持系统稳定。

4. **去中心化声誉管理**：通过去中心化的声誉管理系统促进长期的可持续性，确保所有节点在公平条件下运行。

5. **高效需求处理**：通过上述机制的结合，系统能够有效地处理高流量需求，同时维持网络的稳定性和效率。

该架构旨在构建一个更加公平、高效、稳定的P2P直播流网络环境，通过声誉机制激励合理行为，优化资源分配，适应网络变化，最终实现系统整体性能的提升。 <div>
arXiv:2409.09329v1 Announce Type: new 
Abstract: We present a peer-to-peer (P2P) live-streaming architecture designed to address challenges such as free-riding, malicious peers, churn, and network instability through the integration of a reputation system. The proposed algorithm incentivizes active peer participation while discouraging opportunistic behaviors, with a reputation mechanism that rewards altruistic peers and penalizes free riders and malicious actors. To manage peer dynamics, the algorithm continuously updates the strategies and adjusts to changing neighbors. It also implements a request-to-join mechanism for flash crowd scenarios, allowing the source node to delegate requests to child nodes, forming an interconnected tree structure that efficiently handles high demand and maintains system stability. The decentralized reputation mechanism promotes long-term sustainability in the P2P live streaming system.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Safe and Scalable Multi-Agent Control under Limited Actuation</title>
<link>https://arxiv.org/abs/2409.09573</link>
<guid>https://arxiv.org/abs/2409.09573</guid>
<content:encoded><![CDATA[
<div> 关键词：安全、敏捷机器人、分散式控制器、输入限制、大规模扩展

总结:

本文提出了一种全新的算法，旨在为拥挤环境中的机器人部署提供安全且灵活的控制策略。该算法通过三个关键步骤实现目标：

1. **学习分散式神经积分控制障碍函数（神经ICBF）**：此步骤涉及构建一个可扩展的、针对输入受限控制设计的分散式神经网络模型，以确保在大量代理的情况下仍能有效运行。

2. **嵌入轻量级分散式模型预测控制基于积分控制障碍函数（MPC-ICBF）**：在神经网络策略中集成MPC-ICBF机制，以确保安全性的同时保持算法的可扩展性。

3. **引入基于机器学习的梯度优化技术来最小化死锁**：通过解决局部最小值问题，该方法有效减少系统中的死锁现象。

文中提供的数值模拟结果表明，该方法在安全性、输入约束满足和死锁最小化方面均优于当前最先进的多代理控制系统。此外，实验还展示了该方法在不同场景下对不同代理数量的强泛化能力，最高可达1000个代理。 <div>
arXiv:2409.09573v1 Announce Type: new 
Abstract: To deploy safe and agile robots in cluttered environments, there is a need to develop fully decentralized controllers that guarantee safety, respect actuation limits, prevent deadlocks, and scale to thousands of agents. Current approaches fall short of meeting all these goals: optimization-based methods ensure safety but lack scalability, while learning-based methods scale but do not guarantee safety. We propose a novel algorithm to achieve safe and scalable control for multiple agents under limited actuation. Specifically, our approach includes: $(i)$ learning a decentralized neural Integral Control Barrier function (neural ICBF) for scalable, input-constrained control, $(ii)$ embedding a lightweight decentralized Model Predictive Control-based Integral Control Barrier Function (MPC-ICBF) into the neural network policy to ensure safety while maintaining scalability, and $(iii)$ introducing a novel method to minimize deadlocks based on gradient-based optimization techniques from machine learning to address local minima in deadlocks. Our numerical simulations show that this approach outperforms state-of-the-art multi-agent control algorithms in terms of safety, input constraint satisfaction, and minimizing deadlocks. Additionally, we demonstrate strong generalization across scenarios with varying agent counts, scaling up to 1000 agents.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning in Adversarial Environments: Testbed Design and Poisoning Resilience in Cybersecurity</title>
<link>https://arxiv.org/abs/2409.09794</link>
<guid>https://arxiv.org/abs/2409.09794</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Flower框架、Poisoning攻击、网络安全、数据隐私

<br /><br />
总结:

本文介绍了一个设计用于网络安全领域的Federated Learning（FL）测试床。该测试床利用Flower框架构建，旨在评估FL在多个客户端协作训练全球模型时的数据隐私保护能力与分布式学习性能，特别是在敏感领域如网络安全中。通过实验分析了不同FL框架的性能、可扩展性和集成便捷性。

测试床的一个具体应用案例展示了如何使用联邦入侵检测系统进行异常检测和关键基础设施的安全保护，同时不泄露敏感网络数据。测试还对系统进行了全面的Poisoning攻击测试，以评估其在对抗敌对条件下的鲁棒性。

研究结果表明，尽管FL增强了数据隐私并支持分布式学习，但在实际应用中仍存在对Poisoning攻击的脆弱性，需要采取措施确保其可靠性。 <div>
arXiv:2409.09794v1 Announce Type: new 
Abstract: This paper presents the design and implementation of a Federated Learning (FL) testbed, focusing on its application in cybersecurity and evaluating its resilience against poisoning attacks. Federated Learning allows multiple clients to collaboratively train a global model while keeping their data decentralized, addressing critical needs for data privacy and security, particularly in sensitive fields like cybersecurity. Our testbed, built using the Flower framework, facilitates experimentation with various FL frameworks, assessing their performance, scalability, and ease of integration. Through a case study on federated intrusion detection systems, we demonstrate the testbed's capabilities in detecting anomalies and securing critical infrastructure without exposing sensitive network data. Comprehensive poisoning tests, targeting both model and data integrity, evaluate the system's robustness under adversarial conditions. Our results show that while federated learning enhances data privacy and distributed learning, it remains vulnerable to poisoning attacks, which must be mitigated to ensure its reliability in real-world applications.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordination-free Collaborative Replication based on Operational Transformation</title>
<link>https://arxiv.org/abs/2409.09934</link>
<guid>https://arxiv.org/abs/2409.09934</guid>
<content:encoded><![CDATA[
<div> 关键词：Coordination-free Collaborative Replication（CCR）、Distributed Systems、Data-sharing systems、Conflict-free Replicated Data Type（CRDT）、Operational Transformation（OT）

<br />
<br />总结:
文章引入了协调自由协作复制(Coordination-free Collaborative Replication, CCR)，这是一种新的分布式系统一致性维护方法，无需明确的协调消息。相比传统数据共享系统依赖中心化更新管理和预定义一致性规则，CCR自动化冲突解决，提供了一种更直观和高效的数据协作方案。

具体而言，CCR通过基于数据流汇聚的通用协议，自动处理冲突，避免了如操作转换(OT)和冲突免费复制数据类型(CRDT)等方法的复杂性和潜在问题。OT虽然保证了文档一致性，但依赖于服务器协调，不适合现代去中心化的P2P环境。而CRDT虽然确保最终一致性，但可能导致非直觉的行为，如从购物车中移除的商品无法重新添加。

相比之下，CCR允许直接更新并基于当前数据状态进行冲突解决，提高了清晰度和易用性。此外，它解决了传统方法中的消息效率问题，提供了在分布式系统中进行高效和实际协作数据共享的解决方案。 <div>
arXiv:2409.09934v1 Announce Type: new 
Abstract: We introduce Coordination-free Collaborative Replication (CCR), a new method for maintaining consistency across replicas in distributed systems without requiring explicit coordination messages. CCR automates conflict resolution, contrasting with traditional Data-sharing systems that typically involve centralized update management or predefined consistency rules.
  Operational Transformation (OT), commonly used in collaborative editing, ensures consistency by transforming operations while maintaining document integrity across replicas. However, OT assumes server-based coordination, which is unsuitable for modern, decentralized Peer-to-Peer (P2P) systems.
  Conflict-free Replicated Data Type (CRDT), like Two-Phase Sets (2P-Sets), guarantees eventual consistency by allowing commutative and associative operations but often result in counterintuitive behaviors, such as failing to re-add an item to a shopping cart once removed.
  In contrast, CCR employs a more intuitive approach to replication. It allows for straightforward updates and conflict resolution based on the current data state, enhancing clarity and usability compared to CRDTs. Furthermore, CCR addresses inefficiencies in messaging by developing a versatile protocol based on data stream confluence, thus providing a more efficient and practical solution for collaborative data sharing in distributed systems.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimality Gap of Decentralized Submodular Maximization under Probabilistic Communication</title>
<link>https://arxiv.org/abs/2409.09979</link>
<guid>https://arxiv.org/abs/2409.09979</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式子模最大值、分区马尔杜姆约束、序贯贪心算法、概率性信息传递、通信意识框架

总结:

本文探讨了在不确定通信环境下的分布式子模最大值问题，特别是当系统受到分区马尔杜姆约束时。研究引入了一个通信意识框架，其中考虑了连接设备之间成功通信的概率。这一创新使得优化过程能够更好地适应实际网络中的不确定性。

首先，文章提出了概率最优性差距的概念，这一概念强调了在资源有限的环境中，基于代理广播可靠性和策略性决策来确定消息传递序列的重要性。具体而言，它关注于如何根据代理的广播能力（包括是否允许多次广播）和其在通信链路中的可靠性来优化信息传播路径。

其次，该框架不仅提供了理论上的分析工具，还具有实践意义，可以帮助设计和评估在通信不稳定环境下的分布式系统。通过考虑通信概率，可以更精确地预测系统的性能，从而优化资源配置和提高整体效率。

最后，文章通过一个数值示例直观地展示了所提出方法的有效性，证明了在不同通信概率下，优化策略对最终结果的影响。这不仅验证了理论分析的正确性，也为实际应用提供了参考。

综上所述，本文通过构建一个通信意识框架，为解决分布式子模最大值问题提供了一种新的视角，特别关注于在不确定性通信环境下，如何通过概率性信息传递来优化系统性能，具有重要的理论价值和实践指导意义。 <div>
arXiv:2409.09979v1 Announce Type: new 
Abstract: This paper considers the problem of decentralized submodular maximization subject to partition matroid constraint using a sequential greedy algorithm with probabilistic inter-agent message-passing. We propose a communication-aware framework where the probability of successful communication between connected devices is considered. Our analysis introduces the notion of the probabilistic optimality gap, highlighting its potential influence on determining the message-passing sequence based on the agent's broadcast reliability and strategic decisions regarding agents that can broadcast their messages multiple times in a resource-limited environment. This work not only contributes theoretical insights but also has practical implications for designing and analyzing decentralized systems in uncertain communication environments. A numerical example demonstrates the impact of our results.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An integrated design of robust decentralized observer and controller for load frequency control</title>
<link>https://arxiv.org/abs/2409.10098</link>
<guid>https://arxiv.org/abs/2409.10098</guid>
<content:encoded><![CDATA[
<div> 关键词：多区域电力系统、全局优化性能、集成设计、H_∞优化、区域特征值分配

总结:

本文集中于为多区域电力系统设计完全去中心化的负荷频率控制(LFC)，以实现全球优化性能。通过引入集成设计概念，同时在线下设计去中心化LFC观察器和控制器，考虑了区域之间的相互作用以及每个区域内本地观察器与控制器之间的双向效应。集成设计通过单步线性矩阵不等式(LMI)形式的H_∞优化实现。进一步地，将H_∞优化与区域特征值分配技术结合，以提高闭环系统的瞬态性能。

为了验证所提出集成设计的优势，文中使用了一个三区域电力系统进行仿真。结果显示，与传统的去中心化设计相比，该集成设计能更有效地优化多区域电力系统的整体性能，特别是在改善瞬态响应方面展现出显著优势。通过集成设计方法，不仅能够确保各区域间的协调运行，还能够在保证系统稳定性的前提下，最大化系统的整体效率和性能。 <div>
arXiv:2409.10098v1 Announce Type: new 
Abstract: This paper focuses on designing completely decentralized load frequency control (LFC) for multi-area power systems to achieve global optimized performance. To this end, a new concept of integrated design is introduced for designing the decentralized LFC observers and controllers simultaneously off-line, by taking into account of the interactions between areas and the bidirectional effects between the local observer and controller in each area. The integrated design in this paper is realized via $H_\infty$ optimization with a single-step linear matrix inequality (LMI) formulation. The LMI regional eigenvalue assignment technique is further incorporated with $H_\infty$ optimization to improve the closed-loop system transient performance. A three-area power system is simulated to validate the superiority of the proposed integrated design over the conventional decentralized designs.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Analysing Attacks on Blockchain Systems in a Layer-based Approach</title>
<link>https://arxiv.org/abs/2409.10109</link>
<guid>https://arxiv.org/abs/2409.10109</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、攻击分类、层基方法、框架、系统强化

总结:

本文对23起针对区块链系统的攻击事件进行了全面研究，并采用了一种基于层次的方法来对这些攻击进行分类。这种方法深入探讨了这些攻击的可行性和动机，为理解区块链系统中的潜在威胁提供了新的视角。研究进一步提出了一个框架，旨在系统地分析各种攻击的影响及其相互关联性，这有助于识别可能的攻击路径，并设计适当的防御措施以增强区块链系统的安全性。

通过这种方法和框架，研究者能够更好地理解不同攻击之间的关系，从而识别出那些最有可能对系统造成损害的攻击类型，并据此制定更有效的防御策略。这一工作对于提升区块链系统的整体安全性和信任度具有重要意义，为未来的研究和实践提供了宝贵指导。 <div>
arXiv:2409.10109v1 Announce Type: new 
Abstract: Blockchain is a growing decentralized system built for transparency and immutability. There have been several major attacks on blockchain-based systems, leaving a gap in the trustability of this system. This article presents a comprehensive study of 23 attacks on blockchain systems and categorizes them using a layer-based approach. This approach provides an in-depth analysis of the feasibility and motivation of these attacks. In addition, a framework is proposed that enables a systematic analysis of the impact and interconnection of these attacks, thereby providing a means of identifying potential attack vectors and designing appropriate countermeasures to strengthen any blockchain system.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>PrePaMS: Privacy-Preserving Participant Management System for Studies with Rewards and Prerequisites</title>
<link>https://arxiv.org/abs/2409.10192</link>
<guid>https://arxiv.org/abs/2409.10192</guid>
<content:encoded><![CDATA[
<div> 关键词：PrePaMS、隐私保护、奖励支付、参与管理系统、安全解决方案

<br />
<br />总结:

文章主要介绍了一种名为PrePaMS的高效参与管理系统，该系统旨在通过隐私保护方式支持参与资格检查和奖励发放。其核心特点是利用匿名凭证和零知识证明等加密技术，确保参与者的身份在奖励过程中不被服务提供者或组织者识别，从而实现了对参与者的隐私保护。

PrePaMS系统能够组织与潜在的合格或不合格依赖关系相关的参与活动，并允许进行安全的奖励支付。它涵盖了参与者是否参与过调查、实验或研究的信息，并且当与这些事件中的实际数据收集安全解决方案结合使用时，PrePaMS可以成为更隐私保护的实证研究的基础。

为了验证PrePaMS的有效性和性能，文章设计并实现了一个原型，并在现实工作负载下进行了评估。通过这一系统，研究者可以在保护参与者隐私的同时，有效地管理和激励参与，为更广泛的隐私保护实证研究提供了可能。 <div>
arXiv:2409.10192v1 Announce Type: new 
Abstract: Taking part in surveys, experiments, and studies is often compensated by rewards to increase the number of participants and encourage attendance. While privacy requirements are usually considered for participation, privacy aspects of the reward procedure are mostly ignored. To this end, we introduce PrePaMS, an efficient participation management system that supports prerequisite checks and participation rewards in a privacy-preserving way. Our system organizes participations with potential (dis-)qualifying dependencies and enables secure reward payoffs. By leveraging a set of proven cryptographic primitives and mechanisms such as anonymous credentials and zero-knowledge proofs, participations are protected so that service providers and organizers cannot derive the identity of participants even within the reward process. In this paper, we have designed and implemented a prototype of PrePaMS to show its effectiveness and evaluated its performance under realistic workloads. PrePaMS covers the information whether subjects have participated in surveys, experiments, or studies. When combined with other secure solutions for the actual data collection within these events, PrePaMS can represent a cornerstone for more privacy-preserving empirical research.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Escaping Local Minima: Hybrid Artificial Potential Field with Wall-Follower for Decentralized Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2409.10332</link>
<guid>https://arxiv.org/abs/2409.10332</guid>
<content:encoded><![CDATA[
<div> 关键词：非凸障碍物、局部最小值、多机器人导航、局部传感器信息、无图导航

<br /><br />
总结:

本文提出了解决在非凸障碍物环境下进行多机器人导航的挑战，这些环境的特点是没有完整的环境知识。传统的反应式方法如人工势场法（APF）虽然简单高效，但容易陷入局部最小值，导致机器人被困，这是因为它们缺乏全局环境意识。现有的解决方案要么依赖于机器人间的通信，要么局限于单机器人场景，或者在处理非凸障碍物时表现不佳。

为了解决这些问题，本文提出了利用仅本地传感器和状态信息进行无图导航的方法。通过将墙壁跟随（WF）行为融入APF方法中，机器人能够避免陷入局部最小值，即使在存在非凸动态障碍物（包括其他机器人）的情况下。为了实现这一目标，文章引入了两种算法用于在APF和WF之间切换：一种基于规则的系统和一种使用专家演示训练的编码器网络。实验结果表明，这种方法在复杂环境中相比现有技术实现了显著更高的成功率，突显了其克服局部最小值限制的能力。 <div>
arXiv:2409.10332v1 Announce Type: new 
Abstract: We tackle the challenges of decentralized multi-robot navigation in environments with nonconvex obstacles, where complete environmental knowledge is unavailable. While reactive methods like Artificial Potential Field (APF) offer simplicity and efficiency, they suffer from local minima, causing robots to become trapped due to their lack of global environmental awareness. Other existing solutions either rely on inter-robot communication, are limited to single-robot scenarios, or struggle to overcome nonconvex obstacles effectively.
  Our proposed methods enable collision-free navigation using only local sensor and state information without a map. By incorporating a wall-following (WF) behavior into the APF approach, our method allows robots to escape local minima, even in the presence of nonconvex and dynamic obstacles including other robots. We introduce two algorithms for switching between APF and WF: a rule-based system and an encoder network trained on expert demonstrations. Experimental results show that our approach achieves substantially higher success rates compared to state-of-the-art methods, highlighting its ability to overcome the limitations of local minima in complex environments
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized and Asymmetric Multi-Agent Learning in Construction Sites</title>
<link>https://arxiv.org/abs/2409.10375</link>
<guid>https://arxiv.org/abs/2409.10375</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作、建筑工地、表面整平、学习算法、去中心化

总结:

本文探讨了在建筑工地上利用多智能体系统进行表面整平作业的合作模式。主要关注两个关键角色：推土机和铲车。研究提出了一种名为“去中心化和异构多智能体学习方法在建筑工地应用（DAMALCS）”的策略，旨在减少操作车辆间的预期碰撞。

DAMALCS通过设计两种专家级智能体来优化作业流程，它们能够通过一种创新的优先级分配方法，高效地实现共同目标。在这种机制下，推土机的操作优先于铲车，以确保道路畅通无阻，从而保证两台车辆的连续作业。尽管仅依赖启发式规则可能不足以应对现实世界的复杂性，但本文表明，将这些规则整合进人工智能训练过程中，能够显著提高其性能。

为了验证这一理论的有效性，研究人员在模拟环境以及真实世界实验室中对智能体进行了测试，同时考虑了视觉噪音和定位误差等变量因素。结果显示，与传统方法相比，DAMALCS策略显著降低了车辆间的碰撞率，提高了整体的工作效率和沙土处理能力。 <div>
arXiv:2409.10375v1 Announce Type: new 
Abstract: Multi-agent collaboration involves multiple participants working together in a shared environment to achieve a common goal. These agents share information, divide tasks, and synchronize their actions. Key aspects of multi agent collaboration include coordination, communication, task allocation, cooperation, adaptation, and decentralization. On construction sites, surface grading is the process of leveling sand piles to increase a specific area's height. In this scenario, a bulldozer grades while a dumper allocates sand piles. Our work aims to utilize a multi-agent approach to enable these vehicles to collaborate effectively. To this end, we propose a decentralized and asymmetric multi-agent learning approach for construction sites (DAMALCS). We formulate DAMALCS to reduce expected collisions for operating vehicles. Therefore, we develop two heuristic experts capable of achieving their joint goal optimally by applying an innovative prioritization method. In this approach, the bulldozer's movements take precedence over the dumper's operations, enabling the bulldozer to clear the path for the dumper and ensure continuous operation of both vehicles. Since heuristics alone are insufficient in real-world scenarios, we utilize them to train AI agents, which proves to be highly effective. We simultaneously train the bulldozer and dumper agents to operate within the same environment, aiming to avoid collisions and optimize performance in terms of time efficiency and sand volume handling. Our trained agents and heuristics are evaluated in both simulation and real-world lab experiments, testing them under various conditions, such as visual noise and localization errors. The results demonstrate that our approach significantly reduces collision rates for these vehicles.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Knowledge Proof-of-Identity: Sybil-Resistant, Anonymous Authentication on Permissionless Blockchains and Incentive Compatible, Strictly Dominant Cryptocurrencies</title>
<link>https://arxiv.org/abs/1905.09093</link>
<guid>https://arxiv.org/abs/1905.09093</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、身份验证、区块链、共识协议、社会网络

总结:

文章主要介绍了将基于受信任公共证书（如国家身份证、电子护照、eSIM）的零知识证明（Zero-Knowledge Proof）应用于无许可区块链的方案。该方案旨在解决现有区块链技术中效率低下问题，如工作量证明（Proof-of-Work）导致的高能源消耗和环境压力，以及权益证明（Proof-of-Stake）引发的资本囤积与交易量降低。通过限制单个个体可运行的挖矿节点数量，同时保持成员开放性，以规避完全去中心化和区块链可扩展性三难困境。同时，考虑了防止合谋的可能性。

文章提出了具有以下优势的零知识证明加密货币：

1. **激励兼容性**：设计了一种基于独特纳什均衡的激励兼容协议，用于根据唯一纳什均衡发放加密货币奖励。
2. **主导地位**：通过严格证明，零知识证明加密货币成为挖矿者的首选，证明了其作为纳什均衡和演化稳定策略的地位。
3. **社会最优效率**：零知识证明加密货币实现了社会最优效率，因此无需支付加密无政府主义的价格，而其他基于工作量证明或权益证明的加密货币则需承担此成本。
4. **帕累托改进**：零知识证明加密货币在流通方面优于其他工作量证明或权益证明加密货币。
5. **社会网络效应**：利用国家身份证、电子护照和eSIM固有的社交网络带来的网络效应，零知识证明加密货币主导其他支付形式。
6. **基础设施成本效益**：较低的基础设施成本意味着存在一个独特的均衡状态，其中它主导其他支付方式。

综上所述，文章提出的零知识证明加密货币解决方案旨在优化区块链技术的性能，通过创新的激励机制、提高效率、降低成本和促进社会网络效应，为区块链应用提供更高效、环保且公平的支付系统。 <div>
arXiv:1905.09093v3 Announce Type: replace 
Abstract: Zero-Knowledge Proof-of-Identity from trusted public certificates (e.g., national identity cards and/or ePassports; eSIM) is introduced here to permissionless blockchains in order to remove the inefficiencies of Sybil-resistant mechanisms such as Proof-of-Work (i.e., high energy and environmental costs) and Proof-of-Stake (i.e., capital hoarding and lower transaction volume). The proposed solution effectively limits the number of mining nodes a single individual would be able to run while keeping membership open to everyone, circumventing the impossibility of full decentralization and the blockchain scalability trilemma when instantiated on a blockchain with a consensus protocol based on the cryptographic random selection of nodes. Resistance to collusion is also considered.
  Solving one of the most pressing problems in blockchains, a zk-PoI cryptocurrency is proved to have the following advantageous properties:
  - an incentive-compatible protocol for the issuing of cryptocurrency rewards based on a unique Nash equilibrium
  - strict domination of mining over all other PoW/PoS cryptocurrencies, thus the zk-PoI cryptocurrency becoming the preferred choice by miners is proved to be a Nash equilibrium and the Evolutionarily Stable Strategy
  - PoW/PoS cryptocurrencies are condemned to pay the Price of Crypto-Anarchy, redeemed by the optimal efficiency of zk-PoI as it implements the social optimum
  - the circulation of a zk-PoI cryptocurrency Pareto dominates other PoW/PoS cryptocurrencies
  - the network effects arising from the social networks inherent to national identity cards and ePassports dominate PoW/PoS cryptocurrencies
  - the lower costs of its infrastructure imply the existence of a unique equilibrium where it dominates other forms of payment
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts</title>
<link>https://arxiv.org/abs/2401.07261</link>
<guid>https://arxiv.org/abs/2401.07261</guid>
<content:encoded><![CDATA[
<div> 关键词：DeFi攻击、智能合约漏洞、私有交易池、对抗性合约、机器学习

<br /><br />
总结:
本文针对去中心化金融（DeFi）中由智能合约漏洞引发的攻击事件，提出了一种新的检测方法，即通过识别对抗性合约而非攻击性交易来预防攻击。研究团队构建了一个综合数据集，包括从以太坊和BSC区块链上部署的合约中提取和构造的特征。他们设计了一种称为Pruned Semantic-Control Flow Tokenization (PSCFT)的智能合约程序精简语义控制流标记化方法，并利用此方法对基于函数调用、控制流程和其他符合模式特征的恶意代码行为进行训练。最终，该研究提供了LookAhead系统的完整实现以及其性能指标的评估，用于检测对抗性合约。这种新方法旨在提高DeFi系统的安全性，通过更早地识别潜在的攻击载体，从而防止可能的零日攻击。 <div>
arXiv:2401.07261v3 Announce Type: replace 
Abstract: Decentralized Finance (DeFi) incidents stemming from the exploitation of smart contract vulnerabilities have culminated in financial damages exceeding 3 billion US dollars. Existing defense mechanisms typically focus on detecting and reacting to malicious transactions executed by attackers that target victim contracts. However, with the emergence of private transaction pools where transactions are sent directly to miners without first appearing in public mempools, current detection tools face significant challenges in identifying attack activities effectively.
  Based on the fact that most attack logic rely on deploying one or more intermediate smart contracts as supporting components to the exploitation of victim contracts, in this paper, we propose a new direction for detecting DeFi attacks that focuses on identifying adversarial contracts instead of adversarial transactions. Our approach allows us to leverage common attack patterns, code semantics and intrinsic characteristics found in malicious smart contracts to build the LookAhead system based on Machine Learning (ML) classifiers and a transformer model that is able to effectively distinguish adversarial contracts from benign ones, and make just-in-time predictions of potential zero-day attacks. Our contributions are three-fold: First, we construct a comprehensive dataset consisting of features extracted and constructed from recent contracts deployed on the Ethereum and BSC blockchains. Secondly, we design a condensed representation of smart contract programs called Pruned Semantic-Control Flow Tokenization (PSCFT) and use it to train a combination of ML models that understand the behaviour of malicious codes based on function calls, control flows and other pattern-conforming features. Lastly, we provide the complete implementation of LookAhead and the evaluation of its performance metrics for detecting adversarial contracts.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aegis: A Decentralized Expansion Blockchain</title>
<link>https://arxiv.org/abs/2406.05904</link>
<guid>https://arxiv.org/abs/2406.05904</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、扩张链、EigenLayer、Aegis、安全

总结:

本文提出了一种基于主链质押的扩张链系统——Aegis。Aegis旨在利用现有的强大区块链基础设施，通过创建附加功能或独立功能的扩展链来增强原有系统的功能性与安全性。该系统的核心机制包括：

1. **使用主链质押**：节点通过向主链存入抵押品（即存款作为担保）来参与扩张链的运营。这一机制激励节点保持行为正确，因为违约将导致抵押品被削减（撤销）。

2. **参考与验证**：Aegis使用来自Aegis区块的主链区块引用来定义委员会成员，确保决策的连续性和稳定性。同时，主链上的检查点用于持续维护决策，而主链的重置则用于在先前的委员会变得过时后建立新的委员会。

3. **保证安全性与快速进展**：Aegis系统设计确保了在所有时间点的安全性，并在Aegis节点间延迟较低时实现了快速进展。

4. **应对挑战**：面对节点可能因撤回质押而不再保持正确性的挑战，Aegis通过假设主链写入时间有界，来解决新出现的难题。

综上所述，Aegis通过创新地结合主链质押与扩张链概念，为区块链技术提供了新的应用方向，旨在提升现有区块链系统的功能和安全性。 <div>
arXiv:2406.05904v2 Announce Type: replace 
Abstract: Blockchains implement monetary systems operated by committees of nodes. The robustness of established blockchains presents an opportunity to leverage their infrastructure for creating expansion chains. Expansion chains can provide additional functionality to the primary chain they leverage or implement separate functionalities, while benefiting from the primary chain's security and the stability of its tokens. Indeed, tools like Ethereum's EigenLayer enable nodes to stake (deposit collateral) on a primary chain to form a committee responsible for operating an expansion chain.
  But here is the rub. Classical protocols assume correct, well-behaved nodes stay correct indefinitely. Yet in our case, the stake incentivizes correctness--it will be slashed (revoked) if its owner deviates. Once a node withdraws its stake, there is no basis to assume its correctness.
  To address the new challenge, we present Aegis, an expansion chain based on primary-chain stake, assuming a bounded primary-chain write time. Aegis uses references from Aegis blocks to primary blocks to define committees, checkpoints on the primary chain to perpetuate decisions, and resets on the primary chain to establish a new committee if the previous one becomes obsolete. It ensures safety at all times and rapid progress when latency among Aegis nodes is low.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Supervised Inference of Agents in Trustless Environments</title>
<link>https://arxiv.org/abs/2409.08386</link>
<guid>https://arxiv.org/abs/2409.08386</guid>
<content:encoded><![CDATA[
<div> 关键词：新型方法、数据推理、LLM、恶意代理攻击、高效验证延迟

总结:

本文提出了一种新颖的方法，旨在通过让智能体形成群集来生成高质量的响应。该方法利用了具备数据推断和排名能力的智能体，通过采用语言模型（LLM）作为响应分类器得以实现。研究首先评估了现有的无信任代理推断策略，随后定义了其方法论并估算实际参数，同时对不同类型的恶意代理攻击进行了建模。这种方法的优势在于它能够利用群集的集体智慧，从而在分布式AI推理中实现更加可靠、安全和高效的系统，其准确率、安全性和稳定性均有所提升。实验结果显示，相较于其他无信任的推理策略，该方法在验证延迟上快了一个数量级，仅需不到125毫秒的时间。

通过将智能体组织成群集，我们不仅提高了响应的质量，而且确保了系统的整体效率和安全性。数据推断能力使得智能体能够从现有信息中进行有效的学习和决策，而LLM的应用则进一步增强了这一过程的智能化水平。此外，对恶意代理攻击的建模和防御策略的开发，确保了系统的鲁棒性，即使在面临潜在威胁的情况下，系统也能保持稳定运行。最终，通过实验证明，这种群集化的方法在速度和性能上都展现出了显著优势，为未来分布式AI系统的构建提供了新的思路和参考。 <div>
arXiv:2409.08386v1 Announce Type: new 
Abstract: In this paper, we propose a novel approach where agents can form swarms to produce high-quality responses effectively. This is accomplished by utilizing agents capable of data inference and ranking, which can be effectively implemented using LLMs as response classifiers. We assess existing approaches for trustless agent inference, define our methodology, estimate practical parameters, and model various types of malicious agent attacks. Our method leverages the collective intelligence of swarms, ensuring robust and efficient decentralized AI inference with better accuracy, security, and reliability. We show that our approach is an order of magnitude faster than other trustless inference strategies reaching less than 125 ms validation latency.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Cybersecurity Compliance and Threat Response Using AI, Blockchain &amp; Smart Contracts</title>
<link>https://arxiv.org/abs/2409.08390</link>
<guid>https://arxiv.org/abs/2409.08390</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、区块链、智能合约、安全政策、威胁响应

<br /><br />
总结:本文提出了一种集成人工智能(AI)、区块链和智能合约的创新框架，旨在解决组织内部安全政策遵守和动态威胁应对的挑战。通过自动化安全政策的执行，减少人工操作并降低人为错误的可能性。利用AI快速分析网络威胁情报，识别违规行为，并自动调整防御机制。区块链提供不可篡改的日志记录，确保透明的安全行动追踪，而智能合约确保了安全措施的一致应用。该框架通过模拟验证，显示了在遵守率和响应时间方面相对于传统方法的改进。最终，文章讨论了实施的实际影响，并提出了未来研究方向，以进一步优化系统并解决实施挑战。 <div>
arXiv:2409.08390v1 Announce Type: new 
Abstract: To address the challenges of internal security policy compliance and dynamic threat response in organizations, we present a novel framework that integrates artificial intelligence (AI), blockchain, and smart contracts. We propose a system that automates the enforcement of security policies, reducing manual effort and potential human error. Utilizing AI, we can analyse cyber threat intelligence rapidly, identify non-compliances and automatically adjust cyber defence mechanisms. Blockchain technology provides an immutable ledger for transparent logging of compliance actions, while smart contracts ensure uniform application of security measures. The framework's effectiveness is demonstrated through simulations, showing improvements in compliance enforcement rates and response times compared to traditional methods. Ultimately, our approach provides for a scalable solution for managing complex security policies, reducing costs and enhancing the efficiency while achieving compliance. Finally, we discuss practical implications and propose future research directions to further refine the system and address implementation challenges.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research on Data Right Confirmation Mechanism of Federated Learning based on Blockchain</title>
<link>https://arxiv.org/abs/2409.08476</link>
<guid>https://arxiv.org/abs/2409.08476</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、数据所有权、区块链、智能合约、分布式计算

<br />
总结:本文提出了一种基于区块链和智能合约的联邦学习数据所有权确认机制。该机制利用去中心化的区块链技术记录每个参与者对联邦学习的贡献，并通过区块链分配联邦学习成果的收益。在区块链的本地模拟环境中，相关智能合约和数据结构被模拟并实现，初步证明了方案的可行性。通过这一机制，确保了参与联邦学习各方的数据所有权、使用权和收益权得到保护与合理分配，实现了数据共享的安全与高效。同时，采用区块链技术保证了数据透明度与不可篡改性，有效提升了联邦学习合作的信任度与效率。 <div>
arXiv:2409.08476v1 Announce Type: new 
Abstract: Federated learning can solve the privacy protection problem in distributed data mining and machine learning, and how to protect the ownership, use and income rights of all parties involved in federated learning is an important issue. This paper proposes a federated learning data ownership confirmation mechanism based on blockchain and smart contract, which uses decentralized blockchain technology to save the contribution of each participant on the blockchain, and distributes the benefits of federated learning results through the blockchain. In the local simulation environment of the blockchain, the relevant smart contracts and data structures are simulated and implemented, and the feasibility of the scheme is preliminarily demonstrated.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Observer-Based Control of Second-Order Multi-vehicle Systems in Bearing-Persistently Exciting Formations</title>
<link>https://arxiv.org/abs/2409.08675</link>
<guid>https://arxiv.org/abs/2409.08675</guid>
<content:encoded><![CDATA[
<div> 关键词：多车辆系统、第二阶运动动力学、轴承持续激励（BPE）、分布式观测器、形成跟踪控制

<br /><br />
总结:
本文提出了一种基于观测器的多车辆系统形成跟踪控制方法，适用于第二阶运动动力学的系统，其中车辆无法直接获得相对或全局位置和速度测量。假设所有车辆都装备了能够感知邻近车辆相对方位的传感器，并且仅有一辆领航车辆能够访问其全球位置信息。通过利用相对方位测量以及网络接收的相邻车辆状态估计，每辆车都能够估算其绝对位置和速度。设计了一个依赖于方位和加速度测量的分布式观测器控制器。

进一步地，文章探索了基于方位的定位与状态估计的“轴承持续激励”（BPE）形成概念，提出了中央集权和去中心化方式下的新算法。研究了目标形成条件，以确保分布式观测器形成跟踪控制器的指数稳定性。为了支持理论结果的有效性，文章还提供了模拟结果，展示所提出的观测器及其基于观测器的跟踪控制器的性能。 <div>
arXiv:2409.08675v1 Announce Type: new 
Abstract: This paper proposes an observer-based formation tracking control approach for multi-vehicle systems with second-order motion dynamics, assuming that vehicles' relative or global position and velocity measurements are unavailable. It is assumed that all vehicles are equipped with sensors capable of sensing the bearings relative to neighboring vehicles and only one leader vehicle has access to its global position. Each vehicle estimates its absolute position and velocity using relative bearing measurements and the estimates of neighboring vehicles received over a communication network. A distributed observer-based controller is designed, relying only on bearing and acceleration measurements.
  This work further explores the concept of the \textit{Bearing Persistently Exciting} (BPE) formation by proposing new algorithms for bearing-based localization and state estimation of second-order systems in centralized and decentralized manners. It also examines conditions on the desired formation to guarantee the exponential stability of distributed observer-based formation tracking controllers. In support of our theoretical results, some simulation results are presented to illustrate the performance of the proposed observers as well as the observer-based tracking controllers.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BE-RAN: Blockchain-enabled Open RAN for 6G with DID and Privacy-Preserving Communication</title>
<link>https://arxiv.org/abs/2101.10856</link>
<guid>https://arxiv.org/abs/2101.10856</guid>
<content:encoded><![CDATA[
<div> 关键词：6G网络、区块链、认证、隐私保护、分布式系统

总结:
本文探讨了6G通信网络向通信、传感和计算协同系统的演进过程中，对分布式无线电接入网络（RAN）带来的挑战与需求。主要提出了“区块链增强型无线电接入网络”（Blockchain-enabled Radio Access Networks, BE-RAN）这一创新架构，旨在通过利用分布式账本技术来提升网络的安全性、隐私性和效率。BE-RAN架构的核心优势包括：

1. **信任建立**：借助区块链技术，构建了一个去中心化的信任基础，为用户提供了基于身份管理的认证服务。

2. **互认证**：实现终端设备间的相互认证，增强网络中各元素之间的安全交互。

3. **点对点通信**：支持基于区块链的点对点（P2P）通信机制，允许UE（用户设备）之间的直接通信，同时确保通信过程的透明性和可追溯性。

4. **公共网络用户服务**：为公共网络用户提供可追溯的计费和日志记录服务，确保服务的公正性和安全性。

5. **CSC集成**：BE-RAN设计旨在无缝融合通信、传感和计算功能，推动6G网络向更高效、更安全的方向发展。

通过这些特性，BE-RAN不仅减少了通信和计算开销，还通过分散的身份管理机制增强了隐私保护，为6G网络的未来发展提供了一种可行的解决方案。 <div>
arXiv:2101.10856v4 Announce Type: replace 
Abstract: As 6G networks evolve towards a synergistic system of Communication, Sensing, and Computing, Radio Access Networks become more distributed, necessitating robust end-to-end authentication. We propose Blockchain-enabled Radio Access Networks, a novel decentralized RAN architecture enhancing security, privacy, and efficiency in authentication processes. BE-RAN leverages distributed ledger technology to establish trust, offering user-centric identity management, enabling mutual authentication, and facilitating on-demand point-to-point inter-network elements and UE-UE communication with accountable logging and billing service add-on for public network users, all without relying on centralized authorities. We envision a thoroughly decentralized RAN model and propose a privacy-preserving P2P communication approach that complements existing security measures while supporting the CSC paradigm. Results demonstrate BE-RAN significantly reduces communication and computation overheads, enhances privacy through decentralized identity management, and facilitates CSC integration, advancing towards more efficient and secure 6G networks.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Elliptic Curve Pairing Stealth Address Protocols</title>
<link>https://arxiv.org/abs/2312.12131</link>
<guid>https://arxiv.org/abs/2312.12131</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、隐私保护、加密协议、椭圆曲线配对、零知识证明

总结:
本文探讨了保护区块链交易隐私的重要性，并介绍了四种使用椭圆曲线配对（ECPDKSAP）作为加密解决方案的隐蔽地址协议。这四种协议分别为ECPDKSAP、ECPSKSAP、Protocol 1和Protocol 2。ECPDKSAPs采用查看密钥和支出密钥的组合方式，而ECPSKSAP则使用单一密钥来生成查看和支出密钥。实验结果显示，Protocol 3（Elliptic Curve Pairing Dual Key Stealth Address Protocol）在视图标签方面表现最佳，特别适用于以太坊生态系统。

值得注意的是，ECPSKSAP虽然在速度上相对较慢，但其仅使用一个私有密钥的独特性质提供了理论上的价值。文章还对比了ECPDKSAP与传统方法（如DKSAP）的性能，表明前者在隐私保护方面具有显著优势。整体而言，这些协议旨在通过椭圆曲线配对技术提高区块链交易的匿名性和安全性，为用户提供更强大的隐私保护机制。 <div>
arXiv:2312.12131v3 Announce Type: replace 
Abstract: Protecting the privacy of blockchain transactions is extremely important for users. Stealth address protocols (SAP) allow users to receive assets via stealth addresses that they do not associate with their stealth meta-addresses. SAP can be generated using different cryptographic approaches. DKSAP uses an elliptic curve multiplication and hashing of the resulting shared secret. Another approach is to use a elliptic curve pairing. This paper presents four SA protocols that use elliptic curve pairing as a cryptographic solution. ECPDKSAPs are pairing-based protocols that include viewing key and spending key, while ECPSKSAP is a pairing-based protocol that uses a single key with which spending and the viewing key are derived. We find that ECPDKSAPs give significantly better results than DKSAP with the view tag. The best results are achieved with Protocol 3 (Elliptic Curve Pairing Dual Key Stealth Address Protocol), which is Ethereum-friendly. ECPSKSAP is significantly slower, but it provides an interesting theoretical result as it uses only one private key.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distribution-Free Fair Federated Learning with Small Samples</title>
<link>https://arxiv.org/abs/2402.16158</link>
<guid>https://arxiv.org/abs/2402.16158</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、公平性、分布自由、小样本、后处理算法

<br />
<br />总结:

本文提出了一种名为FedFaiREE的分布式设置下的公平学习后处理算法，专门针对小样本、分布自由的环境。该方法旨在解决联邦学习中数据分散训练带来的公平性问题，特别是在面对客户端异质性、通信成本和小样本数量的独特挑战时。FedFaiREE不仅提供了理论上的公平性和准确性保证，还在实验中得到了实证验证，证明了其在分布式系统中的有效性和实用性。

文章首先指出，随着联邦学习在实际应用中的重要性日益凸显，确保不同群体间的公平性变得至关重要。然而，现有的大多数用于保障公平性的机器学习算法设计基于集中式数据环境，并通常需要大量样本和分布假设，这与分布式、异构系统的特性不完全匹配。因此，提出了FedFaiREE这一创新解决方案。

FedFaiREE通过引入后处理算法的概念，实现了在有限样本和无分布假设条件下的公平学习。它旨在适应并克服分布式环境中常见的挑战，如客户端差异、通信开销以及样本量小等问题。理论分析和实验结果共同展示了FedFaiREE在实现公平性和保持模型性能方面的能力，验证了其在小样本、分布式学习场景中的适用性和有效性。

通过这种专门设计的方法，FedFaiREE为解决联邦学习中的公平性问题提供了一个有力的工具，不仅能够确保算法的公平性，同时还能在资源有限的环境下保持良好的性能表现。这为促进更加公平、高效的数据驱动决策过程奠定了基础。 <div>
arXiv:2402.16158v2 Announce Type: replace-cross 
Abstract: As federated learning gains increasing importance in real-world applications due to its capacity for decentralized data training, addressing fairness concerns across demographic groups becomes critically important. However, most existing machine learning algorithms for ensuring fairness are designed for centralized data environments and generally require large-sample and distributional assumptions, underscoring the urgent need for fairness techniques adapted for decentralized and heterogeneous systems with finite-sample and distribution-free guarantees. To address this issue, this paper introduces FedFaiREE, a post-processing algorithm developed specifically for distribution-free fair learning in decentralized settings with small samples. Our approach accounts for unique challenges in decentralized environments, such as client heterogeneity, communication costs, and small sample sizes. We provide rigorous theoretical guarantees for both fairness and accuracy, and our experimental results further provide robust empirical validation for our proposed method.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A proof of contribution in blockchain using game theoretical deep learning model</title>
<link>https://arxiv.org/abs/2409.07460</link>
<guid>https://arxiv.org/abs/2409.07460</guid>
<content:encoded><![CDATA[
<div> 关键词：智能城市、边缘计算、游戏理论、深度学习、区块链

总结:
本文针对智能城市服务中边缘资源弹性与可扩展性的需求，提出了一个利用游戏理论和深度学习相结合的方法，以解决边缘计算面临的资源限制问题。文章首先指出了智能城市服务对低延迟应用的需求以及边缘设备资源有限的挑战。接着，引入了游戏理论的概念，提出了一种激励服务提供商主动贡献资源并提供低延迟协作计算能力的机制。通过结合区块链技术实现资源的去中心化交易与调度，文章提出了一种基于贡献的证明机制来确保边缘计算的低延迟服务。

文中详细介绍了深度学习模型的设计，包括双编码器和单解码器结构，其中GNN（图神经网络）编码器处理结构化的决策行动数据，RNN（循环神经网络）编码器处理时间序列任务调度数据。实验结果表明，该模型相比现有最先进的方法能显著降低584%的延迟。

这一研究为智能城市服务提供了创新的边缘资源管理方案，通过优化任务调度和资源分配策略，提高了边缘计算系统的效率和响应速度，对促进智能城市基础设施的建设和运营具有重要意义。 <div>
arXiv:2409.07460v1 Announce Type: new 
Abstract: Building elastic and scalable edge resources is an inevitable prerequisite for providing platform-based smart city services. Smart city services are delivered through edge computing to provide low-latency applications. However, edge computing has always faced the challenge of limited resources. A single edge device cannot undertake the various intelligent computations in a smart city, and the large-scale deployment of edge devices from different service providers to build an edge resource platform has become a necessity. Selecting computing power from different service providers is a game-theoretic problem. To incentivize service providers to actively contribute their valuable resources and provide low-latency collaborative computing power, we introduce a game-theoretic deep learning model to reach a consensus among service providers on task scheduling and resource provisioning. Traditional centralized resource management approaches are inefficient and lack credibility, while the introduction of blockchain technology can enable decentralized resource trading and scheduling. We propose a contribution-based proof mechanism to provide the low-latency service of edge computing. The deep learning model consists of dual encoders and a single decoder, where the GNN (Graph Neural Network) encoder processes structured decision action data, and the RNN (Recurrent Neural Network) encoder handles time-series task scheduling data. Extensive experiments have demonstrated that our model reduces latency by 584% compared to the state-of-the-art.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning</title>
<link>https://arxiv.org/abs/2409.07494</link>
<guid>https://arxiv.org/abs/2409.07494</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum, 交易语言模型, 图形方法, 交易属性相似图, 账户交互图

<br />
<br />总结:
文章针对以太坊面临的日益严重的欺诈威胁问题，提出了一种名为TLMG4Eth的新方法。该方法结合了交易语言模型和图形方法，旨在捕获以太坊交易数据中的语义、相似性和结构特征。首先，通过构建交易语言模型，将数字交易数据转换为有意义的交易句子，以便模型学习交易的明确语义。其次，引入交易属性相似图，用于学习交易之间的相似信息，从而捕捉交易异常的直观见解。此外，还创建了一个账户交互图来捕捉账户交易网络的结构信息。通过深度多头注意力网络融合交易语义和相似性嵌入，并提出联合训练方法，使多头注意力网络和账户交互图协同工作，以获取两种方法的协同优势。

<br />
文章的主要贡献在于，通过整合交易语言模型与图形方法，TLMG4Eth能够更全面地分析交易数据，不仅考虑了交易的语义信息，还考虑了交易间的相似性以及账户间的交互关系，从而提供了一种更为有效的欺诈检测策略。这种方法的提出，有望提高以太坊等区块链平台的欺诈检测能力，增强系统的安全性。 <div>
arXiv:2409.07494v1 Announce Type: new 
Abstract: Ethereum faces growing fraud threats. Current fraud detection methods, whether employing graph neural networks or sequence models, fail to consider the semantic information and similarity patterns within transactions. Moreover, these approaches do not leverage the potential synergistic benefits of combining both types of models. To address these challenges, we propose TLMG4Eth that combines a transaction language model with graph-based methods to capture semantic, similarity, and structural features of transaction data in Ethereum. We first propose a transaction language model that converts numerical transaction data into meaningful transaction sentences, enabling the model to learn explicit transaction semantics. Then, we propose a transaction attribute similarity graph to learn transaction similarity information, enabling us to capture intuitive insights into transaction anomalies. Additionally, we construct an account interaction graph to capture the structural information of the account transaction network. We employ a deep multi-head attention network to fuse transaction semantic and similarity embeddings, and ultimately propose a joint training approach for the multi-head attention network and the account interaction graph to obtain the synergistic benefits of both.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DV-FSR: A Dual-View Target Attack Framework for Federated Sequential Recommendation</title>
<link>https://arxiv.org/abs/2409.07500</link>
<guid>https://arxiv.org/abs/2409.07500</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated推荐（FedRec）、隐私保护、目标攻击、协同攻击、防御机制

<br />
<br />
总结:

本文主要探讨了联邦推荐系统（FedRec）中的隐私保护问题以及其对目标攻击的脆弱性。FedRec作为一种分布式训练模型，旨在保护用户隐私，但同时也面临来自商业和社交影响的威胁。研究发现，现有针对FedRec系统的攻击方法在实现效果上存在局限性，尤其是在联邦序列推荐（FSR）任务中。

为了解决这一问题，作者提出了一种新的双视角攻击框架——DV-FSR。该框架创新性地结合了基于采样的显式策略与基于对比学习的隐式梯度策略，以实现协同攻击。同时，为了应对目标攻击，文章还引入了一种针对性的防御机制，旨在评估所提出的攻击方法的缓解效果。

通过广泛的实验验证，证明了所提出的方法在代表性的序列模型上的有效性，展示了在保护用户隐私的同时对抗目标攻击的可能性。此研究不仅为理解FedRec系统在安全方面的挑战提供了新的视角，也为开发更安全、更有效的推荐系统提供了理论基础和技术手段。 <div>
arXiv:2409.07500v1 Announce Type: new 
Abstract: Federated recommendation (FedRec) preserves user privacy by enabling decentralized training of personalized models, but this architecture is inherently vulnerable to adversarial attacks. Significant research has been conducted on targeted attacks in FedRec systems, motivated by commercial and social influence considerations. However, much of this work has largely overlooked the differential robustness of recommendation models. Moreover, our empirical findings indicate that existing targeted attack methods achieve only limited effectiveness in Federated Sequential Recommendation (FSR) tasks. Driven by these observations, we focus on investigating targeted attacks in FSR and propose a novel dualview attack framework, named DV-FSR. This attack method uniquely combines a sampling-based explicit strategy with a contrastive learning-based implicit gradient strategy to orchestrate a coordinated attack. Additionally, we introduce a specific defense mechanism tailored for targeted attacks in FSR, aiming to evaluate the mitigation effects of the attack method we proposed. Extensive experiments validate the effectiveness of our proposed approach on representative sequential models.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Analyzing the Impact of Copying-and-Pasting Vulnerable Solidity Code Snippets from Question-and-Answer Websites</title>
<link>https://arxiv.org/abs/2409.07586</link>
<guid>https://arxiv.org/abs/2409.07586</guid>
<content:encoded><![CDATA[
<div> 关键词：漏洞代码重用、智能合约、Stack Overflow、代码片段、代码克隆检测

总结:

本文研究了智能合约开发过程中从问答网站如Stack Overflow中重用可能含有漏洞代码的问题。研究发现，由于智能合约一旦部署便不可更改，且管理着价值数百万美元的资产，使得这类问题尤为重要。研究团队开发了一种基于模式的漏洞检测工具，该工具能够分析完整和不完整的智能合约代码片段，以识别潜在的漏洞代码模式。此外，他们还提出了一种利用模糊哈希技术快速检测部署智能合约中代码克隆的方法。

研究结果表明，这种新的检测方法在处理代码片段时与现有最佳实践相当，并且同样有效。大规模研究分析了18,660个代码片段，结果显示有4,596个存在漏洞，其中616个漏洞代码片段出现在7,852个已部署的智能合约中。这一发现强调了在当前已部署的智能合约中重用可能含有漏洞的代码片段是一个严重问题。

文章通过实证研究揭示了智能合约开发过程中的安全风险，并提供了有效的检测工具和方法来识别和预防此类风险，对提高智能合约的安全性具有重要意义。 <div>
arXiv:2409.07586v1 Announce Type: new 
Abstract: Ethereum smart contracts are executable programs deployed on a blockchain. Once deployed, they cannot be updated due to their inherent immutability. Moreover, they often manage valuable assets that are worth millions of dollars, making them attractive targets for attackers. The introduction of vulnerabilities in programs due to the reuse of vulnerable code posted on Q&amp;A websites such as Stack Overflow is not a new issue. However, little effort has been made to analyze the extent of this issue on deployed smart contracts. In this paper, we conduct a study on the impact of vulnerable code reuse from Q&amp;A websites during the development of smart contracts and provide tools uniquely fit to detect vulnerable code patterns in complete and incomplete Smart Contract code. This paper proposes a pattern-based vulnerability detection tool that is able to analyze code snippets (i.e., incomplete code) as well as full smart contracts based on the concept of code property graphs. We also propose a methodology that leverages fuzzy hashing to quickly detect code clones of vulnerable snippets among deployed smart contracts. Our results show that our vulnerability search, as well as our code clone detection, are comparable to state-of-the-art while being applicable to code snippets. Our large-scale study on 18,660 code snippets reveals that 4,596 of them are vulnerable, out of which 616 can be found in 7,852 deployed smart contracts. These results highlight that the reuse of vulnerable code snippets is indeed an issue in currently deployed smart contracts.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>HERL: Tiered Federated Learning with Adaptive Homomorphic Encryption using Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.07631</link>
<guid>https://arxiv.org/abs/2409.07631</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Homomorphic Encryption、Reinforcement Learning、Q-Learning、HERL

总结:
本文提出了一种名为HERL（Heterogeneous Environment Reinforced Learning）的方法，它结合了强化学习与联邦学习技术，旨在优化同态加密参数，特别是多项式模数N和系数模数q。该方法首先通过聚类分析对客户端进行分级，根据它们的计算能力和安全需求。随后，使用强化学习中的Q-learning算法动态选择最适合当前客户端层级的加密参数。

实验结果显示，HERL能够显著降低计算开销，同时保持良好的实用性和安全性水平。具体而言，其在提高模型实用性方面有17%的提升，将收敛时间缩短了高达24%，并且在增强收敛效率上提高了30%，同时保持了较低的安全风险。

通过这种方式，HERL不仅解决了同态加密在异构环境下的应用挑战，还有效平衡了隐私保护与性能优化之间的矛盾，为未来的联邦学习系统提供了更为灵活和高效的加密策略。 <div>
arXiv:2409.07631v1 Announce Type: new 
Abstract: Federated Learning is a well-researched approach for collaboratively training machine learning models across decentralized data while preserving privacy. However, integrating Homomorphic Encryption to ensure data confidentiality introduces significant computational and communication overheads, particularly in heterogeneous environments where clients have varying computational capacities and security needs. In this paper, we propose HERL, a Reinforcement Learning-based approach that uses Q-Learning to dynamically optimize encryption parameters, specifically the polynomial modulus degree, $N$, and the coefficient modulus, $q$, across different client tiers. Our proposed method involves first profiling and tiering clients according to the chosen clustering approach, followed by dynamically selecting the most suitable encryption parameters using an RL-agent. Experimental results demonstrate that our approach significantly reduces the computational overhead while maintaining utility and a high level of security. Empirical results show that HERL improves utility by 17%, reduces the convergence time by up to 24%, and increases convergence efficiency by up to 30%, with minimal security loss.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning Discovers Efficient Decentralized Graph Path Search Strategies</title>
<link>https://arxiv.org/abs/2409.07932</link>
<guid>https://arxiv.org/abs/2409.07932</guid>
<content:encoded><![CDATA[
<div> 关键词：图路径搜索、强化学习、多代理系统、社会网络、异构结构

<br /><br />
总结:
文章提出了一种基于强化学习的多代理系统，专门针对图路径搜索问题。该方法在不依赖全局网络视图的情况下，利用多个具有局部网络视图的代理进行协作，成功地结合了同质性和异构性网络结构的特点。实验结果表明，这种方法在合成和实际社会网络上的性能显著优于现有的学习和启发式基线方法。此外，研究发现，通过奖励驱动的学习，可以构建出对图导航有意义的嵌入表示，为解决图路径搜索问题提供了新的视角和解决方案。这种基于局部信息的多代理协作策略，对于处理大型、动态和隐私敏感的网络环境具有潜在优势。 <div>
arXiv:2409.07932v1 Announce Type: new 
Abstract: Graph path search is a classic computer science problem that has been recently approached with Reinforcement Learning (RL) due to its potential to outperform prior methods. Existing RL techniques typically assume a global view of the network, which is not suitable for large-scale, dynamic, and privacy-sensitive settings. An area of particular interest is search in social networks due to its numerous applications. Inspired by seminal work in experimental sociology, which showed that decentralized yet efficient search is possible in social networks, we frame the problem as a collaborative task between multiple agents equipped with a limited local view of the network. We propose a multi-agent approach for graph path search that successfully leverages both homophily and structural heterogeneity. Our experiments, carried out over synthetic and real-world social networks, demonstrate that our model significantly outperforms learned and heuristic baselines. Furthermore, our results show that meaningful embeddings for graph navigation can be constructed using reward-driven learning.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Study on Asynchronous Vote-based Blockchains</title>
<link>https://arxiv.org/abs/2409.08161</link>
<guid>https://arxiv.org/abs/2409.08161</guid>
<content:encoded><![CDATA[
<div> 关键词：投票式区块链、异步网络、验证强一致性、拜占庭容错共识、线性视图变化

总结:
本文提出了一种基于验证强一致性的拜占庭容错（BFT）共识模型，旨在解决投票式区块链在异步网络环境下的局限性。通过该模型，节点可以在异步设置中使用基于领导者的协调机制进行状态机复制（SMR），同时保持与二进制拜占庭协议相同的容错能力，但无需在投票前确保诚实节点的一致性。这意味着，节点可以操作在不同的、暂时互斥的状态上，直到最终达成共识并统一到相同的状态。

为实现这一目标，文章设计了一个针对投票式区块链的异步BFT协议。该协议解决了关键挑战，包括如何确保节点在投票轮次中最终达成一致，如何保证区块链在达成共识的同时持续前进，以及如何维持强大的拜占庭容错性。此外，该协议显著降低了消息复杂度，并首次实现了不依赖阈签名的线性视图变化。

通过采用这种新型的共识模型和协议，构建的异步区块链能够以与使用如HotStuff-2等部分同步区块链相同的方式运行，简单高效地部署于大规模网络中。 <div>
arXiv:2409.08161v1 Announce Type: new 
Abstract: Vote-based blockchains construct a state machine replication (SMR) system among participating nodes, using Byzantine Fault Tolerance (BFT) consensus protocols to transition from one state to another. Currently, they rely on either synchronous or partially synchronous networks with leader-based coordination or costly Asynchronous Common Subset (ACS) protocols in asynchronous settings, making them impractical for large-scale asynchronous applications.
  To make Asynchronous SMR scalable, this paper proposes a \emph{validated strong} BFT consensus model that allows leader-based coordination in asynchronous settings. Our BFT consensus model offers the same level of tolerance as binary byzantine agreement but does not demand consistency among honest nodes before they vote. An SMR using our model allows nodes to operate in different, tentative, but mutually exclusive states until they eventually converge on the same state. We propose an asynchronous BFT protocol for vote-based blockchains employing our consensus model to address several critical challenges: how to ensure that nodes eventually converge on the same state across voting rounds, how to assure that a blockchain will steadily progress through epochs while reaching consensus for previous epochs, and how to maintain robust byzantine fault tolerance.
  Our protocol greatly reduces message complexity and is the first one to achieve linear view changes without relying on threshold signatures. We prove that an asynchronous blockchain built on our protocol can operate with the \emph{same} simplicity and efficiency as partially synchronous blockchains built on, e.g. HotStuff-2. This facilitates deploying asynchronous blockchains across large-scale networks.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Secure Standard for NFT Fractionalization</title>
<link>https://arxiv.org/abs/2409.08190</link>
<guid>https://arxiv.org/abs/2409.08190</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币（NFT）、市场流动性、所有权分割、标准化框架、安全挑战

<br /><br />
总结:
本文聚焦于非同质化代币（NFT）市场面临的挑战，尤其是由于高准入门槛和有限的市场流动性导致的市场需求下降。为解决这一问题，文章提出了一种名为“所有权分割”的创新方法，允许多个实体共同持有单一NFT的一部分，从而降低投资者的准入门槛，提高市场流动性，并使有价值的数字资产更易于大众获取。然而，当前的NFT所有权分割领域缺乏统一的标准框架，这阻碍了安全、互操作性和可访问性平台的发展。因此，该文旨在提供深入的分析，着重于所有权分割的安全挑战，并引入一个标准化解决方案，以解决这些问题并促进更安全、更兼容和更广泛的NFT所有权分割平台的建立。 <div>
arXiv:2409.08190v1 Announce Type: new 
Abstract: Non-fungible tokens (NFTs) offer a unique method for representing digital and physical assets on the blockchain. However, the NFT market has recently experienced a downturn in interest, mainly due to challenges related to high entry barriers and limited market liquidity. Fractionalization emerges as a promising solution, allowing multiple parties to hold a stake in a single NFT. By breaking down ownership into fractional shares, this approach lowers the entry barrier for investors, enhances market liquidity, and democratizes access to valuable digital assets. Despite these benefits, the current landscape of NFT fractionalization is fragmented, with no standardized framework to guide the secure and interoperable implementation of fractionalization mechanisms. This paper contributions are twofold: first, we provide a detailed analysis of the current NFT fractionalization landscape focusing on security challenges; second, we introduce a standardized approach that addresses these challenges, paving the way for more secure, interoperable, and accessible NFT fractionalization platforms.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal Operation of Distribution System Operator and the Impact of Peer-to-Peer Transactions</title>
<link>https://arxiv.org/abs/2409.08191</link>
<guid>https://arxiv.org/abs/2409.08191</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统运营商、能源交易、用户侧分散化、能量匹配、实时功率一致性

总结:

本文提出了一种针对分布式系统运营商（DSO）的最优操作方法，该方法考虑了内部生产者与消费者之间的点对点（P2P）交易。研究假设DSO为中立财务实体，负责聚合生产者在P2P交易后的盈余能源和需求缺口，同时调度分布式能源资源并考虑网络完整性。文章探讨了P2P交易对DSO最优操作的影响。

1. 能量匹配型P2P交易影响了DSO与批发市场之间交换的能源数量，但不会改变DSO内部的调度决策。
   
2. 实时功率一致性水平不同会导致配电网总盈余的不同。
   
3. 对于实时功率匹配型P2P交易，提供的能源和总盈余不受影响，因此DSO可以安全地忽略遵循本文定义格式的P2P交易。
   
4. 案例研究表明，P2P交易不会影响整个系统的物理功率流动，而是影响DSO与生产者之间的财务分配。

5. 结论强调了P2P交易对DSO物理系统运行的独立性以及其对DSO与生产者之间财务关系的影响。 <div>
arXiv:2409.08191v1 Announce Type: new 
Abstract: Peer-to-peer (P2P) energy trading, commonly recognized as a decentralized approach, has emerged as a popular way to better utilize distributed energy resources (DERs). In order to better manage this user-side decentralized approach from a system operator's point of view, this paper proposes an optimal operation approach for distribution system operators (DSO), comprising internal prosumers who engage in P2P transactions. The DSO is assumed to be a financial neutral entity, holding the responsibility of aggregating the surplus energy and deficit demand of prosumers after their P2P transactions while dispatching DERs and considering network integrity. Impacts of P2P transactions on DSO's optimal operation have been studied. Results indicate that energy matching P2P trading where only the total amount of energy over a given period of time is defined may affect quantities of energy exchanged between the DSO and the wholesale market, but not internal dispatch decisions of the DSO. Different levels of real-time power consistency may lead to different total surpluses in the distribution network. For the real-time power matching P2P trading, as a special case of energy matching P2P trading, the provided energy and total surplus are not affected. In other words, DSO can safely ignore P2P transactions if they follow the format defined in this paper. Case studies verify these conclusions and further demonstrate that P2P trading will not affect physical power flow of the whole system, but the financial distribution between the DSO and prosumers.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Kronos: A Secure and Generic Sharding Blockchain Consensus with Optimized Overhead</title>
<link>https://arxiv.org/abs/2403.03655</link>
<guid>https://arxiv.org/abs/2403.03655</guid>
<content:encoded><![CDATA[
<div> 关键词：Kronos、跨区块交易、安全共识、低延迟、高吞吐量

<br /><br />
总结:本文提出了一种名为Kronos的安全分片区块链共识机制，旨在优化分片网络的性能和安全性。Kronos通过引入一种新的分片共识模式，利用共享缓冲区管理交易，实现高效传输有效交易和快速拒绝无效交易。该系统在恶意客户端攻击下，能保持原子性，并确保安全的同时，将内部分片的开销控制在最优水平。Kronos还提出了基于批处理认证和可靠跨分片传输的安全跨分片认证方法，进一步提高了系统的可靠性和效率。通过使用两种先进的分片容错协议（异步速Dumbo和部分同步Hotstuff），Kronos实现在数千节点下的高效共识，并展现出显著的吞吐量（每秒320千次交易）和较低的延迟。与以往解决方案相比，Kronos在吞吐量上提升了至少12倍，延迟减少了50%，充分展示了其在区块链领域内的创新和技术优势。 <div>
arXiv:2403.03655v3 Announce Type: replace 
Abstract: Sharding enhances blockchain scalability by dividing the network into shards, each managing specific unspent transaction outputs or accounts. As an introduced new transaction type, cross-shard transactions pose a critical challenge to the security and efficiency of sharding blockchains. Currently, there is a lack of a generic sharding consensus pattern that achieves both security and low overhead. In this paper, we present Kronos, a secure sharding blockchain consensus achieving optimized overhead. In particular, we propose a new secure sharding consensus pattern, based on a buffer managed jointly by shard members. Valid transactions are transferred to the payee via the buffer, while invalid ones are rejected through happy or unhappy paths. Kronos is proved to achieve security with atomicity under malicious clients with optimal intra-shard overhead $kB$ ($k$ for involved shard number and $B$ for a Byzantine fault tolerance (BFT) cost). Besides, we propose secure cross-shard certification methods based on batch certification and reliable cross-shard transfer. The former combines hybrid trees or vector commitments, while the latter integrates erasure coding. Handling $b$ transactions, Kronos is proved to achieve reliability with low cross-shard overhead $O(n b \lambda)$ ($n$ for shard size and $\lambda$ for the security parameter). Notably, Kronos imposes no restrictions on BFT and does not rely on time assumptions, offering optional constructions in various modules. We implement Kronos using two prominent BFT protocols: asynchronous Speeding Dumbo and partial synchronous Hotstuff. Extensive experiments demonstrate Kronos scales the consensus nodes to thousands, achieving a substantial throughput of 320 ktx/sec with 2.0 sec latency. Compared with the past solutions, Kronos outperforms, achieving up to a 12* improvement in throughput and a 50% reduction in latency.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolutionary Game Dynamics Applied to Strategic Adoption of Immersive Technologies in Cultural Heritage and Tourism</title>
<link>https://arxiv.org/abs/2409.06720</link>
<guid>https://arxiv.org/abs/2409.06720</guid>
<content:encoded><![CDATA[
<div> 关键词：arXiv, 2409.06720v1, 全新发表, 历史保护, 旅游增强

文章摘要：

文章探讨了元宇宙、AR和VR等沉浸式技术在文化与旅游业中的应用及其对行业的影响。当前，这些技术正处于发展的十字路口，各相关方正在考虑其采用的可能性，以及它们可能如何改变行业格局。文章指出，不同利益相关者的看法对于技术的采纳速度和范围至关重要。沉浸式技术有望彻底改变体验方式，因此，文化与旅游领域的决策者在权衡利弊的同时，也在考虑创新的潜在影响。

研究方法：

研究通过Q方法学将利益相关者观点分解为主要成分，并结合进化博弈模型，试图描绘可能的发展情景，揭示决策路径的潜在模式。这种方法强调了复杂系统中各种利益相关者共存动态下，如何通过演化动力学识别出长期主导策略。

总结：

文章通过分析沉浸式技术在文化与旅游业的应用前景，强调了利益相关者观点的重要性。它展示了技术如何重塑历史保存与旅游体验，同时探讨了决策过程中的复杂性。通过Q方法学和进化博弈模型的应用，文章揭示了技术采纳可能带来的长远影响和潜在策略方向。这一研究不仅提供了对未来趋势的洞察，也为决策者在采纳新技术时提供了理论依据。 <div>
arXiv:2409.06720v1 Announce Type: new 
Abstract: Immersive technologies such as Metaverse, AR, and VR are at a crossroads, with many actors pondering their adoption and potential sectors interested in integration. The cultural and tourism industries are particularly impacted, facing significant pressure to make decisions that could shape their future landscapes. Stakeholders' perceptions play a crucial role in this process, influencing the speed and extent of technology adoption. As immersive technologies promise to revolutionize experiences, stakeholders in these fields weigh the benefits and challenges of embracing such innovations. The current choices will likely determine the trajectory of cultural preservation and tourism enhancement, potentially transforming how we engage with history, art, and travel. Starting from a decomposition of stakeholders' perceptions into principal components using Q-methodology, this article employs an evolutionary game model to attempt to map possible scenarios and highlight potential decision-making trajectories. The proposed approach highlights how evolutionary dynamics lead to identifying a dominant long-term strategy that emerges from the complex system of coexistence among various stakeholders.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Cooperative AI for Large-Scale Eigenvalue Computations Using Neural Networks</title>
<link>https://arxiv.org/abs/2409.06746</link>
<guid>https://arxiv.org/abs/2409.06746</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式、神经网络、合作计算、大规模矩阵、最小特征值

<br /><br />
总结:

本文提出了一种新颖的方法，利用分布式的合作神经网络框架进行特征值计算。与传统技术在大型系统中难以实现可扩展性不同，我们的去中心化算法允许多个自主代理协作估计大型矩阵的最小特征值。每个代理使用局部神经网络模型，通过与其他代理的通信不断优化其估计结果。该方法保证即使在通信失败或网络中断的情况下也能收敛至真实特征值。理论分析证实了方法的稳健性和准确性，而实验证明了其相对于某些传统的集中式算法具有更好的性能。

文章详细介绍了算法的设计原理，包括代理间的通信机制和神经网络模型的更新规则。通过理论证明确保了算法的正确性和效率，并通过实验对比展示了在实际应用中的优势。此方法为大规模数据处理和高维问题求解提供了新的思路，特别是在分布式计算环境中，能有效提升计算速度和资源利用率。 <div>
arXiv:2409.06746v1 Announce Type: new 
Abstract: This paper presents a novel method for eigenvalue computation using a distributed cooperative neural network framework. Unlike traditional techniques that struggle with scalability in large systems, our decentralized algorithm enables multiple autonomous agents to collaboratively estimate the smallest eigenvalue of large matrices. Each agent uses a localized neural network model, refining its estimates through inter-agent communication. Our approach guarantees convergence to the true eigenvalue, even with communication failures or network disruptions. Theoretical analysis confirms the robustness and accuracy of the method, while empirical results demonstrate its better performance compared to some traditional centralized algorithms
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Synchronization Control-Plane Protocol for Quantum Link Layer</title>
<link>https://arxiv.org/abs/2409.07049</link>
<guid>https://arxiv.org/abs/2409.07049</guid>
<content:encoded><![CDATA[
<div> 关键词：量子互联网、节点间纠缠生成、分布式队列、网络仿真、同步协议

总结:
本文提出了一种面向未来量子互联网的去中心化同步协议，旨在解决节点间纠缠生成的协调挑战。该协议运行在链路层的古典控制平面，为多节点量子网络提供了一种可扩展的协调机制，以管理纠缠请求。通过NetSquid进行的量子网络仿真显示，与简单的分布式队列方法相比，该协议能够显著降低纠缠请求的平均延迟时间。具体而言，随着量子网络链接数量的增加，延迟增长减少了六倍。论文中的“事件最终同步协议”(ESP)允许网络中的多个节点以可扩展的方式协调纠缠生成过程，这是关于管理纠缠请求的第一个去中心化同步协议。这一创新对于推动量子通信和量子互联网的发展具有重要意义。 <div>
arXiv:2409.07049v1 Announce Type: new 
Abstract: Heralded entanglement generation between nodes of a future quantum internet is a fundamental operation that unlocks the potential for quantum communication. In this paper, we propose a decentralized synchronization protocol that operates at the classical control-plane of the link layer, to navigate the coordination challenges of generating heralded entanglement across few-qubit quantum network nodes. Additionally, with quantum network simulations using NetSquid, we show that our protocol achieves lower entanglement request latencies than a naive distributed queue approach. We observe a sixfold reduction in average request latency growth as the number of quantum network links increases. The Eventual Synchronization Protocol (ESP) allows nodes to coordinate on heralded entanglement generation in a scalable manner within multi-peer quantum networks. To the best of our knowledge, this is the first decentralized synchronization protocol for managing heralded entanglement requests.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Voting System for Medical Catalogues in National Health Insurance</title>
<link>https://arxiv.org/abs/2409.07057</link>
<guid>https://arxiv.org/abs/2409.07057</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗保险、治疗投票系统、蒙特卡洛模拟、患者结果激励机制、区块链智能合约

总结:
本文探讨了一种医疗保险目录投票系统的概念发展。该系统的核心方法是让医生对治疗项目进行投票，以实现决策的透明度和诚信性。通过蒙特卡洛模拟，研究发现该系统能够有效地达成药物和治疗项目的共识选择。进一步的理论研究提出，应引入基于患者结果的激励机制，旨在通过优化和公平的保险目录来平衡多方利益，同时利用区块链智能合约确保透明性和诚信度。这一概念性的方法旨在改进医疗保健领域的决策过程，使其更加依赖于患者的结果和满意度。 <div>
arXiv:2409.07057v1 Announce Type: new 
Abstract: This study explores the conceptual development of a medical insurance catalogue voting system. The methodology is centred on creating a model where doctors would vote on treatment inclusions, aiming to demonstrate transparency and integrity. The results from Monte Carlo simulations suggest a robust consensus on the selection of medicines and treatments. Further theoretical investigations propose incorporating a patient outcome-based incentive mechanism. This conceptual approach could enhance decision-making in healthcare by aligning stakeholder interests with patient outcomes, aiming for an optimised, equitable insurance catalogue with potential blockchain-based smart-contracts to ensure transparency and integrity.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>XDC Staking and Tokenomics -- Improvement Proposal: Enhancing Sustainability and Decentralization on the Eve of XDC 2.0</title>
<link>https://arxiv.org/abs/2409.07420</link>
<guid>https://arxiv.org/abs/2409.07420</guid>
<content:encoded><![CDATA[
<div> 关键词：XDC网络、五周年、XDC 2.0、全面改进计划、稳定主网运营

<br /><br />
总结:
文章围绕着XDC网络的五周年庆祝和即将到来的XDC 2.0版本发布，提出了一项旨在优化网络中质押和通证经济机制的全面改进计划。此计划的核心目标在于构建一个更加可持续、去中心化和韧性的生态系统。通过引入创新概念如验证者NFT、去中心化治理和基于功能的通证经济学，该研究旨在增加验证节点的流动性并促进质押参与。提案的最终目的是为XDC 2.0建立一个坚实的基础，以培养一个既能奖励验证者、利益相关者也能惠及所有用户的繁荣生态体系。通过解决质押和通证经济学的复杂性，这项研究为XDC巩固其作为领先去中心化网络的地位铺平了道路，使其能够实现长期的成功与增长。 <div>
arXiv:2409.07420v1 Announce Type: new 
Abstract: As the XDC network celebrates five years of stable mainnet operation and prepares for the highly anticipated launch of XDC 2.0, this research proposes a comprehensive improvement plan for the network's staking and tokenomics mechanisms. Our analysis reveals opportunities to optimize the current model, ensuring a more sustainable, decentralized, and resilient ecosystem. We introduce novel concepts, including validator NFTs, decentralized governance, and utility-based tokenomics, to increase validator node liquidity and promote staking participation. Our proposal aims to establish a robust foundation for XDC 2.0, fostering a thriving ecosystem that rewards validators, stakeholders, and users alike. By addressing the intricacies of staking and tokenomics, this research paves the way for XDC to solidify its position as a leading decentralized network, poised for long-term success and growth.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Effect of Crypto Rewards in Fundraising: From a Quasi-Experiment to a Dictator Game</title>
<link>https://arxiv.org/abs/2207.07490</link>
<guid>https://arxiv.org/abs/2207.07490</guid>
<content:encoded><![CDATA[
<div> 关键词：感谢礼物、加密货币、非同质化代币（NFT）、慈善捐赠、激励设计

总结:
本文探讨了慈善捐赠中使用感谢礼物的激励设计，特别是加密货币和非同质化代币（NFT）的使用。通过分析乌克兰政府接受以太坊和比特币捐赠的案例，研究发现，以太坊比比特币更有效吸引捐赠，但捐赠金额减少更为明显。实验表明，没有实际价值的NFT感谢礼物未能有效激发捐赠行为，传统的一对一捐赠匹配策略效果更好。然而，当NFT的设计与捐赠者身份相关联并体现慈善受益方时，NFT感谢礼物能够增加捐赠规模。此研究表明，虽然加密货币在慈善捐赠中具有潜力，但其应用需考虑与捐赠者的心理关联和捐赠行为的影响。 <div>
arXiv:2207.07490v3 Announce Type: replace 
Abstract: Conditional thank-you gifts are one of the most widely used incentives for charitable giving. Past studies explored non-monetary thank-you gifts (e.g., mugs and shirts) and monetary thank-you gifts (e.g., rebates that return some of the donations to the giver). Following the rapid growth of blockchain technology, a novel form of thank-you gifts emerged: the crypto rewards. Through two studies, we analyze crypto thank-you gifts to shed light on fundraising designs in the digital world. In Study I, we examine the Ukrainian government's crypto fundraising plea that accepts donations in both Ethereum and Bitcoin. We find that Ethereum is substantially more effective in enticing giving than Bitcoin, as the hourly donation count increased 706.07% more for Ethereum than for Bitcoin when crypto rewards are present. This is likely because the crypto rewards are more likely to be issued on Ethereum than Bitcoin. However, the decrease in contribution sizes is also more substantial in Ethereum than in Bitcoin in response to the crypto rewards. In Study II, we conducted a laboratory experiment following a dictator game design to investigate the impact of crypto rewards in a more general scenario, with the crypto rewards specified as non-fungible tokens (NFTs). The crypto rewards in Study II carry no monetary value but only serve to recognize donors symbolically. As such, the NFT thank-you gifts did not effectively induce people to donate; a traditional 1:1 donation matching strictly outperforms both the condition without thank-you gifts and the condition with NFT thank-you gifts. Nevertheless, the NFT thank-you gifts effectively increased the contribution sizes, conditional on the choice to give, when the NFT's graphic design primes donor identity and encompasses the charity recipient.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Effectiveness of Local Updates for Decentralized Learning under Data Heterogeneity</title>
<link>https://arxiv.org/abs/2403.15654</link>
<guid>https://arxiv.org/abs/2403.15654</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Gradient Tracking（DGT）、Decentralized Gradient Descent（DGD）、Local Updates、Communication Complexity、Second-Order Heterogeneity

总结:

本文重新审视了在多轮本地更新情况下分布式优化方法中的两种基本技术：Decentralized Gradient Tracking（DGT）与Decentralized Gradient Descent（DGD）。研究主要集中在两个方面：

1. **通信复杂性与本地更新数量的关系**：文章通过理论分析证明，增加本地更新的数量（即K > 1），可以在保持一定网络连通性和降低数据异构性的情况下，有效减少通信复杂性。具体来说，对于μ强凸和L光滑的损失函数，DGT的通信复杂性为$\tilde{\mathcal{O}} \Big(\frac{L}{\mu K} + \frac{\delta}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$，其中ρ衡量网络连通性，δ衡量局部损失的第二阶异构性。

2. **过参数化情况下的DGD**：在局部损失具有相同最小值的过参数化场景中，即使DGD不进行梯度校正，引入本地更新也能达到与DGT相似的效果，从而进一步减少通信复杂性。

3. **理论结果的验证**：通过数值实验，文章验证了其理论分析的正确性，展示了在低数据异构性和良好网络连通性的条件下，增加本地更新次数可以显著降低通信成本。

4. **理论与应用的结合**：研究不仅提供了理论上的深入理解，还指出了在实际应用中如何更有效地利用分布式优化方法，特别是在考虑通信成本和数据分布特性时。

5. **潜在影响与未来方向**：通过揭示通信与计算之间的权衡关系，该研究为设计更高效、更具适应性的分布式学习算法提供了理论基础，未来可能在大数据处理、机器学习等领域有广泛的应用前景。 <div>
arXiv:2403.15654v2 Announce Type: replace 
Abstract: We revisit two fundamental decentralized optimization methods, Decentralized Gradient Tracking (DGT) and Decentralized Gradient Descent (DGD), with multiple local updates. We consider two settings and demonstrate that incorporating $K > 1$ local update steps can reduce communication complexity. Specifically, for $\mu$-strongly convex and $L$-smooth loss functions, we proved that local DGT achieves communication complexity $\tilde{\mathcal{O}} \Big(\frac{L}{\mu K} + \frac{\delta}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$, where $\rho$ measures the network connectivity and $\delta$ measures the second-order heterogeneity of the local loss. Our result reveals the tradeoff between communication and computation and shows increasing $K$ can effectively reduce communication costs when the data heterogeneity is low and the network is well-connected. We then consider the over-parameterization regime where the local losses share the same minimums, we proved that employing local updates in DGD, even without gradient correction, can yield a similar effect as DGT in reducing communication complexity. Numerical experiments validate our theoretical results.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Responsible Blockchain: STEADI Principles and the Actor-Network Theory-based Development Methodology (ANT-RDM)</title>
<link>https://arxiv.org/abs/2409.06179</link>
<guid>https://arxiv.org/abs/2409.06179</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、挑战与争议、负责任发展、STEADI原则、ANT-RDM方法

总结:

本文全面分析了区块链技术面临的挑战和争议。首先，它识别了技术挑战，如可扩展性、安全性、隐私性和互操作性，以及业务和采用挑战。此外，文章还探讨了当前区块链系统中存在的一些社会、经济、伦理和环境争议。

为了克服这些挑战并实现大规模采用，作者强调了“负责任的区块链开发”至关重要。为此，文章定义了“负责任的区块链”概念，并提出了“可持续性（Sustainable）、透明度（Transparent）、伦理（Ethical）、适应性（Adaptive）、去中心化（Decentralized）和包容性（Inclusive）”的六项原则（STEADI原则），作为负责任区块链发展的指导方针。

接着，文章介绍了基于行动者网络理论的区块链负责任发展方法（ANT-RDM）。此方法由四个步骤组成：问题化、兴趣投资、注册和动员。通过这四个步骤，可以系统地促进区块链的负责任发展，确保技术的进步不仅满足技术需求，而且考虑到社会、伦理和环境的影响。 <div>
arXiv:2409.06179v1 Announce Type: new 
Abstract: This paper provides a comprehensive analysis of the challenges and controversies associated with blockchain technology. It identifies technical challenges such as scalability, security, privacy, and interoperability, as well as business and adoption challenges, and the social, economic, ethical, and environmental controversies present in current blockchain systems. We argue that responsible blockchain development is key to overcoming these challenges and achieving mass adoption. This paper defines Responsible Blockchain and introduces the STEADI principles (sustainable, transparent, ethical, adaptive, decentralized, and inclusive) for responsible blockchain development. Additionally, it presents the Actor-Network Theory-based Responsible Development Methodology (ANT-RDM) for blockchains, which includes the steps of problematization, interessement, enrollment, and mobilization.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BACKRUNNER: Mitigating Smart Contract Attacks in the Real World</title>
<link>https://arxiv.org/abs/2409.06213</link>
<guid>https://arxiv.org/abs/2409.06213</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、攻击预执行、攻击反向执行、资产保护、程序修复

总结:
本文揭示了智能合约漏洞导致的巨额经济损失问题。研究人员提出了防御性措施，旨在通过在恶意交易前插入“白帽”交易来预防攻击，从而保护资产安全。然而，作者发现现有的防御手段在实际场景中已失效，141起真实世界中的攻击案例成功绕过了最先进的防御技术。

为解决这一问题，文章提出了一种创新方法，包括预执行劫持和攻击反向执行。该方法通过将攻击利用应用到攻击前后相似或相同的合同上，以保护资产。作者将这种适应攻击的技术视为一种程序修复问题，并运用现有技术构建了一个名为BACKRUNNER的完整框架。在对2023年历史攻击的测试中，BACKRUNNER成功拯救了超过4.1亿美元的资产。而在现实世界中，它仅在两个月内就帮助拯救了价值超过1120万美元的资产，涉及28起独立事件。

这种方法不仅展示了对现有防御机制的突破，还提供了有效的资产保护策略，通过预执行和反向执行机制，有效地防止和应对智能合约攻击。 <div>
arXiv:2409.06213v1 Announce Type: new 
Abstract: Billions of dollars have been lost due to vulnerabilities in smart contracts. To counteract this, researchers have proposed attack frontrunning protections designed to preempt malicious transactions by inserting "whitehat" transactions ahead of them to protect the assets. In this paper, we demonstrate that existing frontrunning protections have become ineffective in real-world scenarios. Specifically, we collected 158 recent real-world attack transactions and discovered that 141 of them can bypass state-of-the-art frontrunning protections. We systematically analyze these attacks and show how inherent limitations of existing frontrunning techniques hinder them from protecting valuable assets in the real world. We then propose a new approach involving 1) preemptive hijack, and 2) attack backrunning, which circumvent the existing limitations and can help protect assets before and after an attack. Our approach adapts the exploit used in the attack to the same or similar contracts before and after the attack to safeguard the assets. We conceptualize adapting exploits as a program repair problem and apply established techniques to implement our approach into a full-fledged framework, BACKRUNNER. Running on previous attacks in 2023, BACKRUNNER can successfully rescue more than \$410M. In the real world, it has helped rescue over \$11.2M worth of assets in 28 separate incidents within two months.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models</title>
<link>https://arxiv.org/abs/2409.06277</link>
<guid>https://arxiv.org/abs/2409.06277</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型（LLMs）、参数高效微调（PEFT）、联邦学习、共享随机性、全参数调整

总结:
本文介绍了一种名为Ferret的新方法，旨在解决大规模细调大型语言模型（LLMs）时面临的数据隐私和通信效率问题。Ferret是首个在分散数据源上实现大规模全参数调整的联邦学习方法，同时保持了较高的模型准确度。其主要创新点在于：

1. **采用第一阶方法**：Ferret利用广泛应用于优化领域的第一阶方法进行本地更新，以提高计算效率。
2. **低维空间投影**：通过将这些更新投影到低维空间中，显著减少了通信开销，使得大规模数据集的传输更加经济。
3. **共享随机性重建**：Ferret使用共享随机性从低维空间中重建局部更新，以此促进有效全局聚合，确保快速收敛和最终性能的竞争力。
4. **理论分析与实验验证**：文章提供了详细的理论分析和广泛的实验结果，证明了Ferret在保持高计算效率、降低通信成本和加速收敛的同时，还能维持与现有方法相当的模型准确度。

综上所述，Ferret为大规模全参数调整LMLs提供了更高效的解决方案，不仅提高了模型训练的效率，还保护了数据隐私，为未来的多模态和多任务学习提供了有力支持。 <div>
arXiv:2409.06277v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have become indispensable in numerous real-world applications. Unfortunately, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical, presents significant challenges. Existing methods often resort to parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but this typically comes at the cost of model accuracy. To address these limitations, we propose federated full-parameter tuning at scale for LLMs (Ferret), the first first-order method with shared randomness to enable scalable full-parameter tuning of LLMs across decentralized data sources while maintaining competitive model accuracy. Ferret accomplishes this through three aspects: (1) it employs widely applied first-order methods for efficient local updates; (2) it projects these updates into a low-dimensional space to considerably reduce communication overhead; and (3) it reconstructs local updates from this low-dimensional space with shared randomness to facilitate effective full-parameter global aggregation, ensuring fast convergence and competitive final performance. Our rigorous theoretical analyses and insights along with extensive experiments, show that Ferret significantly enhances the scalability of existing federated full-parameter tuning approaches by achieving high computational efficiency, reduced communication overhead, and fast convergence, all while maintaining competitive model accuracy. Our implementation is available at https://github.com/allen4747/Ferret.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DroneXNFT: An NFT-Driven Framework for Secure Autonomous UAV Operations and Flight Data Management</title>
<link>https://arxiv.org/abs/2409.06507</link>
<guid>https://arxiv.org/abs/2409.06507</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币、无人机、飞行数据管理、数据共享、加密技术

总结:
本文提出了一种利用非同质化代币（NFT）来管理无人机飞行数据的理论框架。通过集成加密方法、智能合约和访问控制机制，该框架旨在实现无人机飞行数据的不可篡改性和隐私保护，确保数据完整性、所有权转移以及各相关方之间的安全数据共享。NFT在此背景下扮演了重要角色，作为数字资产的唯一标识符，提供透明且安全的产权记录。加密技术确保数据的安全性，防止未经授权的访问或修改；智能合约自动执行合同条款，确保数据交换过程的公正与高效；而访问控制机制则进一步限制了数据的使用权限，只允许授权的用户访问特定信息。整体而言，该框架为无人机飞行数据管理提供了一个创新、高效且安全的解决方案。 <div>
arXiv:2409.06507v1 Announce Type: new 
Abstract: Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for managing digital assets, providing transparency and secure ownership records on a blockchain. In this paper, we present a theoretical framework for leveraging NFTs to manage UAV (Unmanned Aerial Vehicle) flight data. Our approach focuses on ensuring data integrity, ownership transfer, and secure data sharing among stakeholders. This framework utilizes cryptographic methods, smart contracts, and access control mechanisms to enable a tamper-proof and privacy-preserving management system for UAV flight data.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Agentic AI on Particle Accelerators</title>
<link>https://arxiv.org/abs/2409.06336</link>
<guid>https://arxiv.org/abs/2409.06336</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、多代理框架、自主加速器系统、人工智能应用、复杂系统管理

总结:

本文探讨了大型语言模型（LLM）在粒子加速器控制领域的潜在应用，提出了一种基于分布式多代理系统的新型控制架构。该系统旨在通过智能化的代理来处理高级任务与通信，同时每个代理专注于控制特定的加速器组件，实现自适应和自我改进。文章指出，未来AI在粒子加速器中的应用可能包括更高效的任务分配、实时故障检测与预防以及优化运行参数等。

实施这样的自主复杂系统时，需要考虑如何通过经验与人类反馈让代理逐渐学习和提升性能。引入“人机循环”（human-in-the-loop）机制对于标注操作数据、提供专业知识指导具有重要意义，有助于确保系统的可靠性和准确性。

文章通过两个案例演示了这种架构的可行性，表明了通过利用LLM驱动的多代理系统，可以有效提高粒子加速器的控制效率与精度，为粒子物理研究提供更强有力的支持。这一创新不仅推动了加速器技术的发展，也为AI在物理科学领域中的广泛应用开辟了新路径。 <div>
arXiv:2409.06336v1 Announce Type: cross 
Abstract: As particle accelerators grow in complexity, traditional control methods face increasing challenges in achieving optimal performance. This paper envisions a paradigm shift: a decentralized multi-agent framework for accelerator control, powered by Large Language Models (LLMs) and distributed among autonomous agents. We present a proposition of a self-improving decentralized system where intelligent agents handle high-level tasks and communication and each agent is specialized control individual accelerator components.
  This approach raises some questions: What are the future applications of AI in particle accelerators? How can we implement an autonomous complex system such as a particle accelerator where agents gradually improve through experience and human feedback? What are the implications of integrating a human-in-the-loop component for labeling operational data and providing expert guidance? We show two examples, where we demonstrate viability of such architecture.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Concealing Backdoor Model Updates in Federated Learning by Trigger-Optimized Data Poisoning</title>
<link>https://arxiv.org/abs/2405.06206</link>
<guid>https://arxiv.org/abs/2405.06206</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Backdoor攻击、DPOT、模型更新、数据污染

<br /><br />
总结:文章主要探讨了Federated Learning（FL）领域中的一种新型后门攻击策略——DPOT（Dynamic Poisoning Objective Tuning）。该策略通过动态构建后门目标并优化后门触发器，使得后门数据对模型更新的影响降至最低，从而巧妙地隐藏恶意行为。与现有的基于分析客户端模型更新的防御措施相比，DPOT能够有效对抗这些防御，且在多种数据集上的实验结果表明其性能优于当前的后门攻击技术。文章提供了对DPOT攻击原理的理论证明，并强调了其在FL环境下的隐秘性和破坏性。这一研究揭示了FL系统在对抗针对性攻击时面临的挑战，并为开发更有效的防御机制提供了新的视角。

<br /><br /> <div>
arXiv:2405.06206v2 Announce Type: replace 
Abstract: Federated Learning (FL) is a decentralized machine learning method that enables participants to collaboratively train a model without sharing their private data. Despite its privacy and scalability benefits, FL is susceptible to backdoor attacks, where adversaries poison the local training data of a subset of clients using a backdoor trigger, aiming to make the aggregated model produce malicious results when the same backdoor condition is met by an inference-time input. Existing backdoor attacks in FL suffer from common deficiencies: fixed trigger patterns and reliance on the assistance of model poisoning. State-of-the-art defenses based on analyzing clients' model updates exhibit a good defense performance on these attacks because of the significant divergence between malicious and benign client model updates. To effectively conceal malicious model updates among benign ones, we propose DPOT, a backdoor attack strategy in FL that dynamically constructs backdoor objectives by optimizing a backdoor trigger, making backdoor data have minimal effect on model updates. We provide theoretical justifications for DPOT's attacking principle and display experimental results showing that DPOT, via only a data-poisoning attack, effectively undermines state-of-the-art defenses and outperforms existing backdoor attack techniques on various datasets.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Edge Computing for IoT: Novel Insights from a Comparative Analysis of Access Control Models</title>
<link>https://arxiv.org/abs/2405.07685</link>
<guid>https://arxiv.org/abs/2405.07685</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、边缘计算、数据安全、访问控制、区块链技术

<br /><br />
总结:
文章主要探讨了物联网（IoT）边缘计算中数据安全与访问控制的挑战及解决方案。首先，边缘计算通过将计算资源部署靠近数据源，有效降低了延迟，减轻了云网络带宽压力，并提升了数据安全性。然而，边缘计算环境下的数据安全仍然面临重大威胁，如数据泄露等，因此访问控制成为了保护数据的关键手段。

文章创新性地将访问控制措施按照数据生命周期的不同阶段——数据收集、存储和使用——进行了分类整理，并结合区块链技术进行了深入分析。这种分类方法提供了新的研究视角，有助于系统地识别现有技术的不足之处，并为未来的研究方向提供指导。通过这种方式，该文不仅为物联网边缘计算领域的研究人员提供了全面的综述，还为访问控制技术的发展指明了可能的路径。

文章强调了在边缘计算环境下，如何利用区块链技术等创新手段来优化访问控制策略，以实现资源节约、低延迟、灵活和可扩展的目标。这对于推动物联网边缘计算领域的发展具有重要意义，特别是对于构建更安全、高效的数据管理系统至关重要。 <div>
arXiv:2405.07685v3 Announce Type: replace 
Abstract: IoT edge computing positions computing resources closer to the data sources to reduce the latency, relieve the bandwidth pressure on the cloud, and enhance data security. Nevertheless, data security in IoT edge computing still faces critical threats (e.g., data breaches). Access control is fundamental for mitigating these threats. However, IoT edge computing introduces notable challenges for achieving resource-conserving, low-latency, flexible, and scalable access control. To review recent access control measures, we novelly organize them according to different data lifecycles--data collection, storage, and usage--and, meanwhile, review blockchain technology in this novel organization. In this way, we provide novel insights and envisage several potential research directions. This survey can help readers find gaps systematically and prompt the development of access control techniques in IoT edge computing under the intricacy of innovations in access control.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Buggy Contracts via Smart Testing</title>
<link>https://arxiv.org/abs/2409.04597</link>
<guid>https://arxiv.org/abs/2409.04597</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart合同、动态分析、基础模型、性能瓶颈、智能系统

总结:
文章主要探讨了针对Smart合同的脆弱性检测问题。作者指出，目前流行的混合动态分析方法，如基于约束的执行辅助模糊测试和基于基础模型的辅助模糊测试，在实际基准测试中显示出了初步的潜力，但仍然面临低可扩展性的问题，尤其是对于复杂代码模式中的深层bug。研究发现，现有动态分析的性能瓶颈和基础模型的幻觉是限制这种混合方法扩展性的两个主要因素。

为了克服这些挑战，作者设计了一种交互式、自我决定的基础模型支持系统——SmartSys，以支持Smart合同的混合动态分析。SmartSys通过教授基础模型不同动态分析技术的性能瓶颈，使其能够预测最适合的技术并生成有效的模糊目标，这些目标能够触及到深层、隐藏的bug。此外，系统利用动态分析期间的编译反馈和运行时反馈来过滤掉错误的模糊目标。

研究结果表明，SmartSys成功地发现了逃过11个工具和多次审计超过一年的Smart合同协议漏洞，并在真实世界基准测试中将覆盖率提高了14.3%相比基线。这证明了SmartSys在提高Smart合同安全性方面的有效性和潜力。 <div>
arXiv:2409.04597v1 Announce Type: new 
Abstract: Smart contracts are susceptible to critical vulnerabilities. Hybrid dynamic analyses, such as concolic execution assisted fuzzing and foundation model assisted fuzzing, have emerged as highly effective testing techniques for smart contract bug detection recently. This hybrid approach has shown initial promise in real-world benchmarks, but it still suffers from low scalability to find deep bugs buried in complex code patterns. We observe that performance bottlenecks of existing dynamic analyses and model hallucination are two main factors limiting the scalability of this hybrid approach in finding deep bugs.
  To overcome the challenges, we design an interactive, self-deciding foundation model based system, called SmartSys, to support hybrid smart contract dynamic analyses. The key idea is to teach foundation models about performance bottlenecks of different dynamic analysis techniques, making it possible to forecast the right technique and generates effective fuzz targets that can reach deep, hidden bugs. To prune hallucinated, incorrect fuzz targets, SmartSys feeds foundation models with feedback from dynamic analysis during compilation and at runtime.
  The interesting results of SmartSys include: i) discovering a smart contract protocol vulnerability that has escaped eleven tools and survived multiple audits for over a year; ii) improving coverage by up to 14.3\% on real-world benchmarks compared to the baselines.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Learning in General-sum Markov Games</title>
<link>https://arxiv.org/abs/2409.04613</link>
<guid>https://arxiv.org/abs/2409.04613</guid>
<content:encoded><![CDATA[
<div> 关键词：Markov游戏、近势函数、演员-评论家算法、分布式学习、纳什均衡

<br /><br />
总结:

本文研究了一种用于设计一般和动态社会系统中具有异质效用的代理之间的分布式学习算法的新框架。主要贡献包括：

1. **提出Markov近势函数（MNPF）**：为了解决设计能够收敛到精确纳什均衡的分布式算法的困难，作者引入了MNPF这一概念。MNPF在确保算法收敛至近似纳什均衡方面扮演着核心角色。

2. **利用双时间尺度方法**：通过快速更新Q函数估计并慢速更新策略，该方法加速了算法的收敛过程。这种方法确保了系统的长期稳定性和收敛性。

3. **证明收敛性**：文章证明了基于演员-评论家架构的分布式学习算法在长期运行中会收敛到MNPF定义的近似纳什均衡集合。如果纳什均衡集有限，则此收敛性更加强大。

4. **理论与实际应用结合**：研究不仅提供了理论分析，还为多代理系统中的分布式学习算法的设计与实现提供了新的视角，有助于解决现实世界中的复杂交互问题。

5. **扩展游戏类型**：该工作特别关注于一般和混合性的马尔科夫游戏，这比传统的零和或潜力游戏更具挑战性，因为它们既不是完全竞争也不是完全合作的。

通过这些创新，本文为分布式学习算法在多代理系统中的应用提供了坚实的理论基础和实用策略。 <div>
arXiv:2409.04613v1 Announce Type: new 
Abstract: The Markov game framework is widely used to model interactions among agents with heterogeneous utilities in dynamic and uncertain societal-scale systems. In these systems, agents typically operate in a decentralized manner due to privacy and scalability concerns, often acting without any information about other agents. The design and analysis of decentralized learning algorithms that provably converge to rational outcomes remain elusive, especially beyond Markov zero-sum games and Markov potential games, which do not adequately capture the nature of many real-world interactions that is neither fully competitive nor fully cooperative. This paper investigates the design of decentralized learning algorithms for general-sum Markov games, aiming to provide provable guarantees of convergence to approximate Nash equilibria in the long run. Our approach builds on constructing a Markov Near-Potential Function (MNPF) to address the intractability of designing algorithms that converge to exact Nash equilibria. We demonstrate that MNPFs play a central role in ensuring the convergence of an actor-critic-based decentralized learning algorithm to approximate Nash equilibria. By leveraging a two-timescale approach, where Q-function estimates are updated faster than policy updates, we show that the system converges to a level set of the MNPF over the set of approximate Nash equilibria. This convergence result is further strengthened if the set of Nash equilibria is assumed to be finite. Our findings provide a new perspective on the analysis and design of decentralized learning algorithms in multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Optimal Stable Matches in Decentralized Markets with Unknown Preferences</title>
<link>https://arxiv.org/abs/2409.04669</link>
<guid>https://arxiv.org/abs/2409.04669</guid>
<content:encoded><![CDATA[
<div> 关键词：匹配算法、分散式系统、有限信息、在线学习、稳定匹配

总结:

本文探讨了在缺乏中心协调和大量信息的情况下，设计分散式、有限信息匹配算法的可能性。主要关注的是两个独立集合（提案者和接受者）之间的双侧市场匹配问题，每个集合的成员都试图与市场对面的最理想伙伴进行匹配。然而，提案者并不了解自己的偏好，因此需要在形成匹配的同时学习其偏好。

研究中提出了一个简单的在线学习规则，该规则能够保证以概率方式收敛到游戏的福利最大化均衡点，即提案者最优稳定的匹配。这是首次报道的完全解耦、无通信算法，能够在不考虑市场结构的情况下保证概率收敛到最优稳定匹配。此工作为在有限信息条件下实现高效、分散式的匹配系统提供了理论基础和实用策略。 <div>
arXiv:2409.04669v1 Announce Type: new 
Abstract: Matching algorithms have demonstrated great success in several practical applications, but they often require centralized coordination and plentiful information. In many modern online marketplaces, agents must independently seek out and match with another using little to no information. For these kinds of settings, can we design decentralized, limited-information matching algorithms that preserve the desirable properties of standard centralized techniques? In this work, we constructively answer this question in the affirmative. We model a two-sided matching market as a game consisting of two disjoint sets of agents, referred to as proposers and acceptors, each of whom seeks to match with their most preferable partner on the opposite side of the market. However, each proposer has no knowledge of their own preferences, so they must learn their preferences while forming matches in the market. We present a simple online learning rule that guarantees a strong notion of probabilistic convergence to the welfare-maximizing equilibrium of the game, referred to as the proposer-optimal stable match. To the best of our knowledge, this represents the first completely decoupled, communication-free algorithm that guarantees probabilistic convergence to an optimal stable match, irrespective of the structure of the matching market.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal decentralized wavelength control in light sources for lithography</title>
<link>https://arxiv.org/abs/2409.04721</link>
<guid>https://arxiv.org/abs/2409.04721</guid>
<content:encoded><![CDATA[
<div> 关键词：脉冲光源、细光束波长控制、多光学模块、分散式线性二次高斯问题、时间延迟补偿

<br /><br />
总结:
本文探讨了在存在时间延迟的情况下，如何通过分散式线性二次高斯（LQG）方法实现最优的波长控制，这对于现代光刻中的精细光束波长控制至关重要。研究中将用于生成所需波长的多光学模块（包括光学元件和执行器）视为在有向无环图（DAG）上协作交互的系统。研究结果表明，任何测量和其它连续时间延迟都能被精确补偿，进而实现了在个体光学级别上的最佳控制器实施，这显著优于现有的波长控制技术。这一创新方法为提高光刻工艺的精度和效率提供了新的途径，对半导体制造领域具有重要意义。 <div>
arXiv:2409.04721v1 Announce Type: new 
Abstract: Pulsed light sources are a critical component of modern lithography, with fine light beam wavelength control paramount for wafer etching accuracy. We study optimal wavelength control by casting it as a decentralized linear quadratic Gaussian (LQG) problem in presence of time-delays. In particular, we consider the multi-optics module (optics and actuators) used for generating the requisite wavelength in light sources as cooperatively interacting systems defined over a directed acyclic graph (DAG). We show that any measurement and other continuous time-delays can be exactly compensated, and the resulting optimal controller implementation at the individual optics-level outperforms any existing wavelength control techniques.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noise-Based Authentication: Is It Secure?</title>
<link>https://arxiv.org/abs/2409.04931</link>
<guid>https://arxiv.org/abs/2409.04931</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、生物识别、热噪声、去中心化身份网络、安全认证

总结:

本文提出了一种基于区块链的去中心化身份网络中的三点生物特征认证系统。该系统利用现有生物识别技术，展示了每个个体独有的生物特性指纹及其生物特征信息泄露的可能性。通过探索每个用户生成的独特热噪声振幅，作者提出了一个全新的认证概念。这一方法旨在实现无条件安全的认证过程，其安全性基于热噪声的不可预测性和唯一性。文章还讨论了该认证系统在实际应用中可能遇到的挑战和需要解决的问题，特别是在确保其稳定性和可靠性方面。此研究为未来在区块链环境下构建更安全、隐私保护更强的身份验证机制提供了新的思路。 <div>
arXiv:2409.04931v1 Announce Type: new 
Abstract: This paper introduces a three-point biometric authentication system for a blockchain-based decentralized identity network. We use existing biometric authentication systems to demonstrate the unique noise fingerprints that belong to each individual human and the respective information leak from the biological characteristics. We then propose the concept of using unique thermal noise amplitudes generated by each user and explore the open questions regarding the robustness of unconditionally secure authentication.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CONNECTOR: Enhancing the Traceability of Decentralized Bridge Applications via Automatic Cross-chain Transaction Association</title>
<link>https://arxiv.org/abs/2409.04937</link>
<guid>https://arxiv.org/abs/2409.04937</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized bridge、Cross-chain transaction、Bridge smart contract、Automated association、DeFi ecosystem

<br /><br />
总结:

本文主要探讨了跨链交易关联在去中心化金融（DeFi）生态系统中的重要性。在多链环境下运行的DeFi生态系统中，去中心化桥应用扮演着连接不同区块链和促进跨链资产转移的关键角色。然而，现有方法完全依赖于不可见的内部账本或API，这与区块链开放和去中心化的特性相违背。针对这一问题，本文提出了基于桥接智能合约的自动化跨链交易关联分析方法——CONNECTOR。

CONNECTOR首先通过从桥接合约的交易轨迹中提取独特的和通用的特征来识别存款交易。利用准确的存款交易，CONNECTOR进一步挖掘桥接合约的执行日志以实现提款交易匹配。通过在不同类型的桥梁上进行实际世界实验，证明了CONNECTOR的有效性。实验结果表明，CONNECTOR成功识别了100%的存款交易，关联了95.81%的提款交易，并在传统金融（CeFi）桥梁方法中表现出超越。基于关联结果，文章揭示了DeFi桥应用中的跨链交易行为，并分析了CONNECTOR的追踪能力，为DeFi桥应用提供辅助。 <div>
arXiv:2409.04937v1 Announce Type: new 
Abstract: Decentralized bridge applications are important software that connects various blockchains and facilitates cross-chain asset transfer in the decentralized finance (DeFi) ecosystem which currently operates in a multi-chain environment. Cross-chain transaction association identifies and matches unique transactions executed by bridge DApps, which is important research to enhance the traceability of cross-chain bridge DApps. However, existing methods rely entirely on unobservable internal ledgers or APIs, violating the open and decentralized properties of blockchain. In this paper, we analyze the challenges of this issue and then present CONNECTOR, an automated cross-chain transaction association analysis method based on bridge smart contracts. Specifically, CONNECTOR first identifies deposit transactions by extracting distinctive and generic features from the transaction traces of bridge contracts. With the accurate deposit transactions, CONNECTOR mines the execution logs of bridge contracts to achieve withdrawal transaction matching. We conduct real-world experiments on different types of bridges to demonstrate the effectiveness of CONNECTOR. The experiment demonstrates that CONNECTOR successfully identifies 100% deposit transactions, associates 95.81% withdrawal transactions, and surpasses methods for CeFi bridges. Based on the association results, we obtain interesting findings about cross-chain transaction behaviors in DeFi bridges and analyze the tracing abilities of CONNECTOR to assist the DeFi bridge apps.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balancing Security and Accuracy: A Novel Federated Learning Approach for Cyberattack Detection in Blockchain Networks</title>
<link>https://arxiv.org/abs/2409.04972</link>
<guid>https://arxiv.org/abs/2409.04972</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据共享、差分隐私、协作式网络攻击检测、模型融合

总结:
本文提出了一种创新的协作式网络攻击检测（CCD）系统，旨在通过解决联邦学习模型中噪声添加的复杂挑战，增强基于区块链的数据共享网络的安全性。该系统利用差分隐私的理论基础，通过在训练子模型后添加噪声，再通过传输重建全局模型的方式，实现了对网络攻击的高效检测。研究分析了不同类型的噪声（高斯、拉普拉斯和动量会计）对关键性能指标的影响，包括攻击检测准确性、深度学习模型收敛时间以及全球模型生成的整体运行时间。

研究发现，在确保数据隐私与维持系统性能之间存在微妙的权衡关系。通过深入的模拟实验，文章提供了优化这些参数以适应不同CCD环境的实用建议，旨在实现数据保护与系统效率之间的最佳平衡，为构建安全可靠的区块链网络做出贡献。 <div>
arXiv:2409.04972v1 Announce Type: new 
Abstract: This paper presents a novel Collaborative Cyberattack Detection (CCD) system aimed at enhancing the security of blockchain-based data-sharing networks by addressing the complex challenges associated with noise addition in federated learning models. Leveraging the theoretical principles of differential privacy, our approach strategically integrates noise into trained sub-models before reconstructing the global model through transmission. We systematically explore the effects of various noise types, i.e., Gaussian, Laplace, and Moment Accountant, on key performance metrics, including attack detection accuracy, deep learning model convergence time, and the overall runtime of global model generation. Our findings reveal the intricate trade-offs between ensuring data privacy and maintaining system performance, offering valuable insights into optimizing these parameters for diverse CCD environments. Through extensive simulations, we provide actionable recommendations for achieving an optimal balance between data protection and system efficiency, contributing to the advancement of secure and reliable blockchain networks.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Practical Overlay Networks for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2409.05331</link>
<guid>https://arxiv.org/abs/2409.05331</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized federated learning、Overlay network、FedLay、Fast training、Low communication

总结:

本文探讨了分布式设备上机器学习任务中分散式联邦学习(DFL)的关键网络挑战。DFL通过去中心化的通信方式避免了集中式联邦学习中的单点故障问题，被认为是具有吸引力的解决方案。然而，现有的研究主要集中在DFL的拓扑结构上，而缺乏实现去中心化构建和维护网络的协议。

为解决这一问题，作者提出了一种名为FedLay的去中心化网络解决方案。FedLay旨在提供快速训练和低通信成本，以实现实际应用中的高效DFL。其独特之处在于能够以去中心化的方式构建接近随机规则的拓扑结构，并在节点加入和失败的情况下维持拓扑。

实验结果表明，基于原型实现和模拟的测试显示，FedLay在真实数据集上的模型收敛速度最快，准确度最高，同时通信成本较低，并具备对节点加入和失败的鲁棒性。这一成果填补了现有DFL拓扑结构在构建和维护协议方面的空白，为DFL的实用性和效率提供了重要支持。 <div>
arXiv:2409.05331v1 Announce Type: new 
Abstract: Decentralized federated learning (DFL) uses peer-to-peer communication to avoid the single point of failure problem in federated learning and has been considered an attractive solution for machine learning tasks on distributed devices. We provide the first solution to a fundamental network problem of DFL: what overlay network should DFL use to achieve fast training of highly accurate models, low communication, and decentralized construction and maintenance? Overlay topologies of DFL have been investigated, but no existing DFL topology includes decentralized protocols for network construction and topology maintenance. Without these protocols, DFL cannot run in practice. This work presents an overlay network, called FedLay, which provides fast training and low communication cost for practical DFL. FedLay is the first solution for constructing near-random regular topologies in a decentralized manner and maintaining the topologies under node joins and failures. Experiments based on prototype implementation and simulations show that FedLay achieves the fastest model convergence and highest accuracy on real datasets compared to existing DFL solutions while incurring small communication costs and being resilient to node joins and failures.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning</title>
<link>https://arxiv.org/abs/2409.05701</link>
<guid>https://arxiv.org/abs/2409.05701</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedAvg、Personalized FL、Diffusion Model、pFedGPA

总结:

本文提出了一种名为pFedGPA的个性化联邦学习框架，旨在解决联邦学习中参数聚合问题。传统的联邦学习方法如FedAvg通常通过线性聚合参数，这在处理异构数据分布时可能会忽略参数空间的复杂性和高维性，从而影响模型性能。而个人化联邦学习虽然能在一定程度上缓解这一问题，但线性聚合的问题仍未得到解决。

pFedGPA利用生成模型的思路，通过在服务器端部署扩散模型来整合各客户端的参数分布，并引入了一个参数反转方法。该方法将上传的参数转换为潜在代码，然后通过去噪采样进行聚合，生成最终的个性化参数。通过使用具有高容量的扩散模型编码客户端模型参数对特定数据分布的依赖性，pFedGPA能够有效地分解所有客户端模型参数分布的整体复杂性与每个个体客户端参数分布的复杂性。

实验结果表明，pFedGPA在多个数据集上的表现均优于基线方法，证明了其在提升联邦学习性能方面的有效性和潜力。 <div>
arXiv:2409.05701v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized approach to model training, where data remains local and only model parameters are shared between the clients and the central server. Traditional methods, such as Federated Averaging (FedAvg), linearly aggregate these parameters which are usually trained on heterogeneous data distributions, potentially overlooking the complex, high-dimensional nature of the parameter space. This can result in degraded performance of the aggregated model. While personalized FL approaches can mitigate the heterogeneous data issue to some extent, the limitation of linear aggregation remains unresolved. To alleviate this issue, we investigate the generative approach of diffusion model and propose a novel generative parameter aggregation framework for personalized FL, \texttt{pFedGPA}. In this framework, we deploy a diffusion model on the server to integrate the diverse parameter distributions and propose a parameter inversion method to efficiently generate a set of personalized parameters for each client. This inversion method transforms the uploaded parameters into a latent code, which is then aggregated through denoising sampling to produce the final personalized parameters. By encoding the dependence of a client's model parameters on the specific data distribution using the high-capacity diffusion model, \texttt{pFedGPA} can effectively decouple the complexity of the overall distribution of all clients' model parameters from the complexity of each individual client's parameter distribution. Our experimental results consistently demonstrate the superior performance of the proposed method across multiple datasets, surpassing baseline approaches.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative Decision-Making for CAVs at Unsignalized Intersections: A MARL Approach with Attention and Hierarchical Game Priors</title>
<link>https://arxiv.org/abs/2409.05712</link>
<guid>https://arxiv.org/abs/2409.05712</guid>
<content:encoded><![CDATA[
<div> 关键词：自主驾驶车辆、复杂场景决策、多智能体强化学习、注意力机制、安全监督模块

总结:

本文针对复杂人类与机器混合交通场景中的决策问题，特别是无信号交叉口的自主驾驶车辆（CAV）决策，提出了一种创新方法——Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient（MA-GA-DDPG）。该方法将CAV的决策问题视为分布式多智能体强化学习问题，并引入注意力机制来捕捉CAV与其他代理之间的互动依赖性。通过计算CAV与其他代理之间的注意力权重，筛选互动对象并构建先验层次游戏关系，设计了安全监督模块以提升交通安全。研究通过仿真和硬件在环实验验证了该方法在驾驶安全性、效率和舒适性方面的优越性，相较于其他基准方法表现出显著优势。 <div>
arXiv:2409.05712v1 Announce Type: new 
Abstract: The development of autonomous vehicles has shown great potential to enhance the efficiency and safety of transportation systems. However, the decision-making issue in complex human-machine mixed traffic scenarios, such as unsignalized intersections, remains a challenge for autonomous vehicles. While reinforcement learning (RL) has been used to solve complex decision-making problems, existing RL methods still have limitations in dealing with cooperative decision-making of multiple connected autonomous vehicles (CAVs), ensuring safety during exploration, and simulating realistic human driver behaviors. In this paper, a novel and efficient algorithm, Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient (MA-GA-DDPG), is proposed to address these limitations. Our proposed algorithm formulates the decision-making problem of CAVs at unsignalized intersections as a decentralized multi-agent reinforcement learning problem and incorporates an attention mechanism to capture interaction dependencies between ego CAV and other agents. The attention weights between the ego vehicle and other agents are then used to screen interaction objects and obtain prior hierarchical game relations, based on which a safety inspector module is designed to improve the traffic safety. Furthermore, both simulation and hardware-in-the-loop experiments were conducted, demonstrating that our method outperforms other baseline approaches in terms of driving safety, efficiency, and comfort.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Double Tracking Method for Optimization with Decentralized Generalized Orthogonality Constraints</title>
<link>https://arxiv.org/abs/2409.04998</link>
<guid>https://arxiv.org/abs/2409.04998</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、泛化正交约束、约束消解操作、无约束惩罚模型、全局收敛性

<br />
<br />
总结:
本文研究了具有广义正交约束的分布式优化问题。这类问题在实际应用中普遍存在，但在存在分布约束的情况下，现有的算法无法解决。为了解决这一难题，作者将原始问题转化为一个无约束惩罚模型，通过引入最近提出的约束消解操作。然而，这种转换破坏了惩罚函数的分离性质，使得现有的算法无法应用。为此，作者提出了一种新颖的算法，该算法同时跟踪目标函数的梯度和约束映射的雅可比矩阵，确保了全局收敛性，并给出了迭代复杂性的证明。为了验证所提算法的有效性和效率，作者使用合成数据集和真实世界数据集进行了数值结果分析，充分展示了算法的性能优势。 <div>
arXiv:2409.04998v1 Announce Type: cross 
Abstract: In this paper, we consider the decentralized optimization problems with generalized orthogonality constraints, where both the objective function and the constraint exhibit a distributed structure. Such optimization problems, albeit ubiquitous in practical applications, remain unsolvable by existing algorithms in the presence of distributed constraints. To address this issue, we convert the original problem into an unconstrained penalty model by resorting to the recently proposed constraint-dissolving operator. However, this transformation compromises the essential property of separability in the resulting penalty function, rendering it impossible to employ existing algorithms to solve. We overcome this difficulty by introducing a novel algorithm that tracks the gradient of the objective function and the Jacobian of the constraint mapping simultaneously. The global convergence guarantee is rigorously established with an iteration complexity. To substantiate the effectiveness and efficiency of our proposed algorithm, we present numerical results on both synthetic and real-world datasets.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Summarizing and Analyzing the Privacy-Preserving Techniques in Bitcoin and other Cryptocurrencies</title>
<link>https://arxiv.org/abs/2109.07634</link>
<guid>https://arxiv.org/abs/2109.07634</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、隐私保护算法、匿名性、攻击技术、法律与伦理

总结:
本文探讨了比特币和类似加密货币在隐私保护方面的挑战及其解决方案。首先，文章概述了比特币以及其它加密货币如何通过分散化和伪匿名性特征来实现去中心化的交易记录。然而，尽管比特币声称提供了伪匿名用户身份，但多次成功地将用户匿名性破解的攻击表明，实际隐私保护存在漏洞。

接着，文章分析了几种已知的攻击技术，这些技术利用特定策略和数据挖掘方法来揭示用户的实际身份。同时，文章也探讨了隐私保护算法，这些算法旨在解决协议中存在的隐私问题，如增强用户数据的加密、混淆交易路径等。通过这些技术，可以显著提高加密货币系统的隐私性，使得追踪和识别用户变得困难。

最后，文章触及了隐私保护算法的伦理、社会影响、法律框架以及它们在市场上的接受度。讨论了在实施这些算法时需要平衡的多方面因素，包括对个人隐私的保护、对金融系统透明度的需求以及可能引发的法律问题。

综上所述，比特币和加密货币在隐私保护方面面临着复杂挑战，通过采用先进的隐私保护技术和深入理解其伦理、法律和社会影响，可以促进更安全、更私密的数字交易环境。 <div>
arXiv:2109.07634v3 Announce Type: replace 
Abstract: Bitcoin and many other similar Cryptocurrencies have been in existence for over a decade, prominently focusing on decentralized, pseudo-anonymous ledger-based transactions. Many protocol improvements and changes have resulted in new variants of Cryptocurrencies that are known for their peculiar characteristics. For instance, Storjcoin is a Proof-of-Storage-based Cryptocurrency that incentivizes its peers based on the amount of storage owned by them. Cryptocurrencies like Monero strive for user privacy by using privacy-centric cryptographic algorithms. While Cryptocurrencies strive to maintain peer transparency by making the transactions and the entire ledger public, user privacy is compromised at times. Monero and many other privacy-centric Cryptocurrencies have significantly improved from the original Bitcoin protocol after several problems were found in the protocol. Most of these deficiencies were related to the privacy of users. Even though Bitcoin claims to have pseudo-anonymous user identities, many attacks have managed to successfully de-anonymize users. In this paper, we present some well-known attacks and analysis techniques that have compromised the privacy of Bitcoin and many other similar Cryptocurrencies. We also analyze and study different privacy-preserving algorithms and the problems these algorithms manage to solve. Lastly, we touch upon the ethics, impact, legality, and acceptance of imposing these privacy algorithms.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game of Coding: Beyond Honest-Majority Assumptions</title>
<link>https://arxiv.org/abs/2401.16643</link>
<guid>https://arxiv.org/abs/2401.16643</guid>
<content:encoded><![CDATA[
<div> 关键词：编码理论、游戏论、区块链、数据恢复、激励设计

<br />
<br />
总结:本文提出了一种新颖的游戏理论框架——“编码游戏”，用于探索在分布式系统中，特别是在区块链相关应用中，编码技术如何在信任不足的情况下，通过博弈论的方法优化编码策略以实现更高效的数据保护与恢复。文章首先指出了传统编码理论对节点数量的假设在现实世界中的局限性，尤其是在区块链等去中心化平台中，这种假设往往不成立。接着，文章引入了编码游戏中敌手和数据收集者（解码器）之间的互动，其中敌手在数据可恢复给数据收集者时受益，并且偏好于提高数据恢复的错误率，以此来最大化自己的收益。

文章的主要贡献在于，对于重复编码（repetition code）和特定类别的效用函数，研究并确定了编码游戏的均衡状态。这为理解在敌手和数据收集者之间的博弈关系下，如何设计有效的编码策略提供了一个基础模型。该模型不仅考虑了数据完整性和恢复效率，还考虑了参与方的激励机制，旨在找到最优策略以平衡数据安全与效率。此外，这一研究为未来在分布式系统中进一步发展更为复杂的编码策略提供了理论基础，有望在区块链等领域实现更安全、更高效的数字资产管理和数据存储解决方案。 <div>
arXiv:2401.16643v5 Announce Type: replace 
Abstract: Coding theory revolves around the incorporation of redundancy into transmitted symbols, computation tasks, and stored data to guard against adversarial manipulation. However, error correction in coding theory is contingent upon a strict trust assumption. In the context of computation and storage, it is required that honest nodes outnumber adversarial ones by a certain margin. However, in several emerging real-world cases, particularly, in decentralized blockchain-oriented applications, such assumptions are often unrealistic. Consequently, despite the important role of coding in addressing significant challenges within decentralized systems, its applications become constrained. Still, in decentralized platforms, a distinctive characteristic emerges, offering new avenues for secure coding beyond the constraints of conventional methods. In these scenarios, the adversary benefits when the legitimate decoder recovers the data, and preferably with a high estimation error. This incentive motivates them to act rationally, trying to maximize their gains. In this paper, we propose a game theoretic formulation for coding, called the game of coding, that captures this unique dynamic where each of the adversaries and the data collector (decoder) have respective utility functions to optimize. The utility functions reflect the fact that both the data collector and the adversary are interested in increasing the chance of data being recoverable by the data collector. Moreover, the utility functions express the interest of the data collector to estimate the input with lower estimation error, but the opposite interest of the adversary. As a first, still highly non-trivial step, we characterize the equilibrium of the game for the repetition code with a repetition factor of 2 for a wide class of utility functions with minimal assumptions.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resilient Fleet Management for Energy-Aware Intra-Factory Logistics</title>
<link>https://arxiv.org/abs/2403.11034</link>
<guid>https://arxiv.org/abs/2403.11034</guid>
<content:encoded><![CDATA[
<div> 关键词：电池供电机器人、工厂物流、中央管理策略、蒙特卡洛树搜索、实时更新

<br />
总结:本文提出了一种针对电池供电机器人队列的创新管理策略，这些机器人负责自主制造设施内的内部物流任务。面对诸如道路堵塞和设备故障等实际不确定性，该策略通过中央管理方式增强系统的韧性，实现任务分配的即时调整。为解决计算成本问题，作者提出了两步法，首先使用蒙特卡洛树搜索算法预先解决理想状态下的任务分配问题，生成一个预先搜索树。当发生中断时，该预先搜索树能够快速更新以反映新问题的成本，并同时产生可行解决方案。通过计算实验，证明了所提算法在各种场景下的实时能力，并与未使用预先搜索树和不尝试重新分配任务的分散式方法进行了比较。这种方法不仅提高了系统响应中断的灵活性，还优化了资源利用效率，展现出在复杂动态环境中的适应性和有效性。 <div>
arXiv:2403.11034v2 Announce Type: replace 
Abstract: This paper presents a novel fleet management strategy for battery-powered robot fleets tasked with intra-factory logistics in an autonomous manufacturing facility. In this environment, repetitive material handling operations are subject to real-world uncertainties such as blocked passages, and equipment or robot malfunctions. In such cases, centralized approaches enhance resilience by immediately adjusting the task allocation between the robots. To overcome the computational expense, a two-step methodology is proposed where the nominal problem is solved a priori using a Monte Carlo Tree Search algorithm for task allocation, resulting in a nominal search tree. When a disruption occurs, the nominal search tree is rapidly updated a posteriori with costs to the new problem while simultaneously generating feasible solutions. Computational experiments prove the real-time capability of the proposed algorithm for various scenarios and compare it with the case where the search tree is not used and the decentralized approach that does not attempt task reassignment.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralization of Ethereum's Builder Market</title>
<link>https://arxiv.org/abs/2405.01329</link>
<guid>https://arxiv.org/abs/2405.01329</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、分散性、以太坊、区块构建市场、验证者集中化

总结:

本文通过实证研究了以太坊区块链中分散性最低的部分——区块构建市场。区块构建市场旨在公平分配最大可提取价值（MEV）并避免验证者集中化。然而，当前数据显示，仅有三个构建者主导了大部分区块生成，集中度超过80%，这一现象引发了对集中化的担忧。尽管社区认为这种集中不会导致验证者集中化，但研究挑战了这一观点。

主要发现表明，区块构建者的集中导致了验证者的利益损失，并可能进一步促进验证者的集中化。此外，旨在缓解MEV问题的即将实施解决方案也会受到影响，因为它们依赖于区块构建市场作为MEV的参考，而市场因集中化而失真。

研究揭示了区块构建者集中化的两个主要原因，并提出了一种对现有MEV供应链的结构改变和基于新结构的解决方案。然而，长期可持续性分析仍是一个开放课题，需要未来的研究来探讨新供应链结构是否能持续稳定。 <div>
arXiv:2405.01329v3 Announce Type: replace 
Abstract: Blockchains protect an ecosystem worth more than $500bn with strong security properties derived from the principle of decentralization. Is today's blockchain decentralized? In this paper, we empirically studied one of the least decentralized parts of Ethereum, its builder market.
  The builder market was introduced to fairly distribute Maximal Extractable Values (MEV) among validators and avoid validator centralization. As of the time of writing, three builders produced the vast majority (more than 80%) of blocks in Ethereum, creating a concerning centralization factor. However, the community believes that such centralization is okay, arguing that builder centralization will not lead to validator centralization. In this empirical study, we interrogate the causes and implications of builder centralization and challenge this belief that it is acceptable.
  Our main finding is that builder centralization has led to a significant loss by validators and, if left uncontrolled, could lead to validator centralization. Moreover, MEV mitigation solutions slated for adoption are affected too because they rely on the builder market as an MEV oracle, which is made inaccurate by centralization.
  Our investigation revealed two reasons behind builder centralization. We propose a structural change to the existing MEV supply chain and a solution based on the new supply chain structure. However, future work is required to analyze if the new supply chain structure is sustainable in the long term, which we leave open.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Socially Acceptable Competitive Equilibrium in Energy Markets</title>
<link>https://arxiv.org/abs/2409.04157</link>
<guid>https://arxiv.org/abs/2409.04157</guid>
<content:encoded><![CDATA[
<div> 关键词：价格接受者、分散式主对偶梯度动态、竞争均衡、社会可接受的均衡、动态反馈控制器

总结:

本文探讨了在价格接受者群体中通过分散式主对偶梯度动力学寻找竞争均衡（CE）的问题。尽管CE具有高效性，但它可能不保证公平性，并可能导致高价格。鉴于代理和市场运营商的社会责任是保持价格低于某个社会可接受的阈值，文章提出了一种方法，即代理通过分散的方式修改其效用函数。为此，引入了一个动态反馈控制器来引导代理向社会可接受的竞争均衡（SCE）移动。通过理论分析和案例研究，文章证明了这种方法的有效性，从而确保了均衡既高效又公平。这一解决方案强调了在市场机制中融入社会价值的重要性，以促进更广泛的经济和社会福祉。 <div>
arXiv:2409.04157v1 Announce Type: new 
Abstract: This paper addresses the problem of energy sharing between a population of price-taking agents who adopt decentralized primal-dual gradient dynamics to find the Competitive Equilibrium (CE). Although the CE is efficient, it does not ensure fairness and can potentially lead to high prices. As the agents and market operator share a social responsibility to keep the price below a certain socially acceptable threshold, we propose an approach where the agents modify their utility functions in a decentralized way. We introduce a dynamic feedback controller for the primal-dual dynamics to steer the agents to a Socially acceptable Competitive Equilibrium (SCE). We demonstrate our theoretical findings in a case study.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SPACE: A Python-based Simulator for Evaluating Decentralized Multi-Robot Task Allocation Algorithms</title>
<link>https://arxiv.org/abs/2409.04230</link>
<guid>https://arxiv.org/abs/2409.04230</guid>
<content:encoded><![CDATA[
<div> 关键词：SPACE、Python、Multi-Robot Task Allocation（MRTA）、simulator、swarm robotics

总结:

文章介绍了一种名为SPACE的新Python基模拟器，专门用于支持分散式多机器人任务分配（MRTA）算法的研究、评估与比较。SPACE简化了核心算法开发过程，允许用户通过Python插件实现决策算法，使用直观图形用户界面（GUI）构建代理行为树，并利用内置功能支持代理间通信和局部任务意识。

SPACE通过实施并评估两种MRTA算法——CBBA（基于集体平衡的算法）和GRAPE（基于资源分配的路径选择算法）——展示了其在不同场景中动态引入任务时，对算法性能进行严格标准化比较的实用性。该模拟器有助于支持未来在群体机器人领域中的研究工作，提供了一个标准平台来测试和优化复杂的多机器人系统协同工作能力。 <div>
arXiv:2409.04230v1 Announce Type: new 
Abstract: Swarm robotics explores the coordination of multiple robots to achieve collective goals, with collective decision-making being a central focus. This process involves decentralized robots autonomously making local decisions and communicating them, which influences the overall emergent behavior. Testing such decentralized algorithms in real-world scenarios with hundreds or more robots is often impractical, underscoring the need for effective simulation tools. We propose SPACE (Swarm Planning and Control Evaluation), a Python-based simulator designed to support the research, evaluation, and comparison of decentralized Multi-Robot Task Allocation (MRTA) algorithms. SPACE streamlines core algorithmic development by allowing users to implement decision-making algorithms as Python plug-ins, easily construct agent behavior trees via an intuitive GUI, and leverage built-in support for inter-agent communication and local task awareness. To demonstrate its practical utility, we implement and evaluate CBBA and GRAPE within the simulator, comparing their performance across different metrics, particularly in scenarios with dynamically introduced tasks. This evaluation shows the usefulness of SPACE in conducting rigorous and standardized comparisons of MRTA algorithms, helping to support future research in the field.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deanonymizing Ethereum Validators: The P2P Network Has a Privacy Issue</title>
<link>https://arxiv.org/abs/2409.04366</link>
<guid>https://arxiv.org/abs/2409.04366</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名性、区块链网络、以太坊、验证方法、隐私保护

<br /><br />
总结:

本文揭示了以太坊区块链网络中验证者身份的匿名性存在漏洞。研究团队通过创新的方法，证明了在以太坊的点对点(P2P)网络中，任何节点都能够识别并定位连接到同一节点的验证者IP地址。实验结果表明，使用收集的数据，研究者能够发现超过15%的以太坊验证者位置信息。这一发现不仅揭示了验证者分布的地理和组织特性，还暴露了网络中缺乏匿名性的风险。

文章进一步讨论了这一发现对以太坊生态系统的影响和潜在风险，强调了保护验证者隐私的重要性。研究团队提出了若干策略建议，旨在帮助验证者增强其在网络环境中的隐私保护。以太坊基金会对此项研究成果给予了认可，通过颁发漏洞赏金来表彰研究团队的贡献。

<br /><br /> <div>
arXiv:2409.04366v1 Announce Type: new 
Abstract: Many blockchain networks aim to preserve the anonymity of validators in the peer-to-peer (P2P) network, ensuring that no adversary can link a validator's identifier to the IP address of a peer due to associated privacy and security concerns. This work demonstrates that the Ethereum P2P network does not offer this anonymity. We present a methodology that enables any node in the network to identify validators hosted on connected peers and empirically verify the feasibility of our proposed method. Using data collected from four nodes over three days, we locate more than 15% of Ethereum validators in the P2P network. The insights gained from our deanonymization technique provide valuable information on the distribution of validators across peers, their geographic locations, and hosting organizations. We further discuss the implications and risks associated with the lack of anonymity in the P2P network and propose methods to help validators protect their privacy. The Ethereum Foundation has awarded us a bug bounty, acknowledging the impact of our results.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Potential of Self-Regulation for Front-Running Prevention on DEXes</title>
<link>https://arxiv.org/abs/2306.05756</link>
<guid>https://arxiv.org/abs/2306.05756</guid>
<content:encoded><![CDATA[
<div> 关键词：交易排序依赖、智能合约、去中心化交易所（DEX）、前端攻击、市场设计

总结:

本文通过构建一个博弈论模型，深入研究了去中心化交易所（DEX）中专业交易者、散户交易者和流动性提供者的行为。该模型揭示了在低比例（低于1%）的订单流量来自散户交易者的情况下，交易者和流动性提供者的个人利益与市场的社会利益一致，从而有效消除前端攻击。然而，当散户交易者在订单流量中所占比例增加到约10%时，流动性提供者倾向于留在不保护免受前端攻击的池中。

文章指出，尽管在特定条件下市场能够自我调节以防止前端攻击，但其收益可能较小，不足以激励市场参与者。为了实现这一目标，需要对交易者进行教育并提供额外的激励措施，以确保市场的自我监管机制得到采纳。这强调了在去中心化交易所环境中，平衡个人利益与社会利益的重要性，以及促进市场健康发展的多方面策略的必要性。 <div>
arXiv:2306.05756v2 Announce Type: replace 
Abstract: The transaction ordering dependency of the smart contracts building decentralized exchanges (DEXes) allow for predatory trading strategies. In particular, front-running attacks present a constant risk for traders on DEXes. Whereas legal regulation outlaws most front-running practices in traditional finance, such measures are ineffective in preventing front-running on DEXes. While novel market designs hindering front-running may emerge, it remains unclear whether the market's participants, in particular, liquidity providers, would be willing to adopt these new designs. A misalignment of the participant's private incentives and the market's social incentives can hinder the market from adopting an effective prevention mechanism.
  We present a game-theoretic model to study the behavior of sophisticated traders, retail traders, and liquidity providers in DEXes. Sophisticated traders adjust for front-running attacks, while retail traders do not, likely due to lack of knowledge or irrationality. Our findings show that with less than 1% of order flow from retail traders, traders' and liquidity providers' interests align with the market's social incentives - eliminating front-running attacks. However, the benefit from embracing this novel market is often small and may not suffice to entice them. With retail traders making up a larger proportion (around 10%) of the order flow, liquidity providers tend to stay in pools that do not protect against front-running. This suggests both educating traders and providing additional incentives for liquidity providers are necessary for market self-regulation.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups</title>
<link>https://arxiv.org/abs/2405.00138</link>
<guid>https://arxiv.org/abs/2405.00138</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、Maximal Extractable Value（MEV）、Layer-2解决方案、rollup、Ethereum

<br /><br />
总结:
本文探讨了去中心化金融的兴起如何改变了区块链上的资产交易，并引入了被称为Maximal Extractable Value (MEV)的一系列剥削性经济实践。同时，去中心化金融采用了基于Layer-2的解决方案，如Arbitrum、Optimism和zkSync，以较低的交易成本促进资产交易，相比底层解决方案如Ethereum。然而，这些Layer-2解决方案缺乏类似于Ethereum的公共内存池，这使得从MEV中获利变得更加困难。研究发现，尽管在Rollup上进行的交易量与Ethereum相当，但Rollup上的MEV成本较低，利润也显著低于Ethereum。此外，研究还关注了Rollup上的“三明治攻击”现象，虽然没有直接检测到这类攻击在流行Rollup上的活动，但识别到了通过跨Rollup和Ethereum的交易实现的潜在“三明治攻击”。最终，研究提出了三种利用跨层交易的新攻击模式，并估计攻击者可能已经通过跨层“三明治攻击”赚取了约2百万美元。 <div>
arXiv:2405.00138v2 Announce Type: replace 
Abstract: The emergence of decentralized finance has transformed asset trading on the blockchain, making traditional financial instruments more accessible while also introducing a series of exploitative economic practices known as Maximal Extractable Value (MEV). Concurrently, decentralized finance has embraced rollup-based Layer-2 solutions to facilitate asset trading at reduced transaction costs compared to Layer-1 solutions such as Ethereum. However, rollups lack a public mempool like Ethereum, making the extraction of MEV more challenging. In this paper, we investigate the prevalence and impact of MEV on Ethereum and prominent rollups such as Arbitrum, Optimism, and zkSync over a nearly three-year period. Our analysis encompasses various metrics including volume, profits, costs, competition, and response time to MEV opportunities. We discover that MEV is widespread on rollups, with trading volume comparable to Ethereum. We also find that, although MEV costs are lower on rollups, profits are also significantly lower compared to Ethereum. Additionally, we examine the prevalence of sandwich attacks on rollups. While our findings did not detect any sandwiching activity on popular rollups, we did identify the potential for cross-layer sandwich attacks facilitated by transactions that are sent across rollups and Ethereum. Consequently, we propose and evaluate the feasibility of three novel attacks that exploit cross-layer transactions, revealing that attackers could have already earned approximately 2 million USD through cross-layer sandwich attacks.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Survey of Blockchain Scalability: Shaping Inner-Chain and Inter-Chain Perspectives</title>
<link>https://arxiv.org/abs/2409.02968</link>
<guid>https://arxiv.org/abs/2409.02968</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、物流、金融、农业、可扩展性

总结:
本文是一篇关于区块链可扩展性的综述文章，旨在全面概述区块链在物流、金融和农业等领域的应用与面临的挑战。文章从物理层（数据和协议）、逻辑层（区块链架构）以及内链、跨链和科技维度的角度，对区块链的可扩展性进行了深入分析。物理层关注数据存储与通信协议，逻辑层则聚焦于区块链系统的结构设计。研究从内链视角出发，探讨了单链内部如何优化资源分配以提升性能；同时，从跨链视角出发，考虑了不同区块链系统之间的交互与协作方式。技术因素作为核心考量点，贯穿于整个分析过程，旨在帮助研究人员深入了解区块链体系结构、数据管理和协议设计，从而推动区块链可扩展性研究的进展。通过这一全面的分析框架，文章为未来区块链技术的发展提供了宝贵的方向与启示。 <div>
arXiv:2409.02968v1 Announce Type: new 
Abstract: Blockchain is widely applied in logistics, finance, and agriculture. As single blockchain users grow, scalability becomes crucial. However, existing works lack a comprehensive summary of blockchain scalability. They focus on single chains or cross-chain technologies. This survey summarizes scalability across the physical and logical layers, as well as inner-chain, inter-chain, and technology dimensions. The physical layer covers data and protocols, while the logical layer represents blockchain architecture. Each component is analyzed from inner-chain and inter-chain perspectives, considering technological factors. The aim is to enhance researchers' understanding of blockchain's architecture, data, and protocols to advance scalability research.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Introduction to Centralized Training for Decentralized Execution in Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.03052</link>
<guid>https://arxiv.org/abs/2409.03052</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、集中式训练与执行、集中式训练分散式执行、分散式训练与执行、合作性

总结:
本文旨在介绍并总结集中式训练与分散式执行（CTDE）在合作性多智能体强化学习（MARL）中的应用。CTDE方法结合了集中式信息的优势进行训练，但在执行阶段采用分散式策略，仅使用每个智能体在执行过程中可获取的信息。这种范式要求在训练阶段进行专门的集中式处理，以利用所有可用信息，如其他智能体的策略或环境状态等。相较于集中式训练与执行（CTE），CTDE在扩展性方面通常更为优越，执行阶段无需通信，且往往能表现出良好的性能。

CTDE方法特别适用于合作场景，但根据所假设的观察信息，也可能应用于竞争或混合设置。CTDE在多智能体系统中提供了一种平衡集中化和分散化优势的策略，有助于解决复杂任务中的协作问题，同时保持系统的灵活性和效率。

尽管本文不涵盖CTDE MARL领域的所有工作，作者已选取具有重要性的研究来阐述主要概念，并对未能提及的研究表示歉意。通过此文本，读者可以更好地理解CTDE在多智能体系统中的作用及其在不同场景下的应用潜力。 <div>
arXiv:2409.03052v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) has exploded in popularity in recent years. Many approaches have been developed but they can be divided into three main types: centralized training and execution (CTE), centralized training for decentralized execution (CTDE), and Decentralized training and execution (DTE).
  CTDE methods are the most common as they can use centralized information during training but execute in a decentralized manner -- using only information available to that agent during execution. CTDE is the only paradigm that requires a separate training phase where any available information (e.g., other agent policies, underlying states) can be used. As a result, they can be more scalable than CTE methods, do not require communication during execution, and can often perform well. CTDE fits most naturally with the cooperative case, but can be potentially applied in competitive or mixed settings depending on what information is assumed to be observed.
  This text is an introduction to CTDE in cooperative MARL. It is meant to explain the setting, basic concepts, and common methods. It does not cover all work in CTDE MARL as the subarea is quite extensive. I have included work that I believe is important for understanding the main concepts in the subarea and apologize to those that I have omitted.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Prototype-based Contrastive Learning for Privacy-Preserving Cross-domain Recommendation</title>
<link>https://arxiv.org/abs/2409.03294</link>
<guid>https://arxiv.org/abs/2409.03294</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、联邦学习、原型聚类、对比学习、跨域推荐

<br /><br />
总结:

文章介绍了一种名为FedPCL-CDR的新方法，用于隐私保护下的跨域推荐（Cross-domain recommendation, CDR）。该方法通过利用非重叠用户信息和原型聚类来提高多领域性能，同时保护用户隐私。FedPCL-CDR由本地域学习模块和全局服务器聚合模块组成。在本地域中，FedPCL-CDR通过聚类所有用户数据生成代表性的原型，有效利用非重叠用户信息并解决用户稀疏重叠问题。通过在本地和全局原型之间进行对比学习，它促进了知识转移。全局服务器则从本地域收集代表原型，学习本地和全局原型。该方法结合了原型和联邦学习（FL），确保敏感用户数据保持去中心化，仅共享原型跨域，从而保护用户隐私。实验证明，FedPCL-CDR在四个实际世界跨域任务上的表现优于现有的基线方法。 <div>
arXiv:2409.03294v1 Announce Type: new 
Abstract: Cross-domain recommendation (CDR) aims to improve recommendation accuracy in sparse domains by transferring knowledge from data-rich domains. However, existing CDR methods often assume the availability of user-item interaction data across domains, overlooking user privacy concerns. Furthermore, these methods suffer from performance degradation in scenarios with sparse overlapping users, as they typically depend on a large number of fully shared users for effective knowledge transfer. To address these challenges, we propose a Federated Prototype-based Contrastive Learning (CL) method for Privacy-Preserving CDR, named FedPCL-CDR. This approach utilizes non-overlapping user information and prototypes to improve multi-domain performance while protecting user privacy. FedPCL-CDR comprises two modules: local domain (client) learning and global server aggregation. In the local domain, FedPCL-CDR clusters all user data to learn representative prototypes, effectively utilizing non-overlapping user information and addressing the sparse overlapping user issue. It then facilitates knowledge transfer by employing both local and global prototypes returned from the server in a CL manner. Simultaneously, the global server aggregates representative prototypes from local domains to learn both local and global prototypes. The combination of prototypes and federated learning (FL) ensures that sensitive user data remains decentralized, with only prototypes being shared across domains, thereby protecting user privacy. Extensive experiments on four CDR tasks using two real-world datasets demonstrate that FedPCL-CDR outperforms the state-of-the-art baselines.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tyche: Collateral-Free Coalition-Resistant Multiparty Lotteries with Arbitrary Payouts</title>
<link>https://arxiv.org/abs/2409.03464</link>
<guid>https://arxiv.org/abs/2409.03464</guid>
<content:encoded><![CDATA[
<div> 关键词：Tyche、多党彩票、区块链、匿名性、公平性

总结:
文章提出了Tyche，一种基于承诺和揭示方法的多党彩票协议家族。这些协议旨在实现高效、抗退出和抵抗多数联盟攻击，仅需使用碰撞抵抗哈希函数。Tyche协议利用区块链作为公共公告板、买进资金收集及结算工具，但不依赖其或任何第三方提供随机性。协议设计确保了任何诚实参与者都能最终解决彩票问题，而欺诈行为不会降低任何诚实参与者的中奖概率。

进一步地，文章将所有三个协议转换为匿名彩票，满足特定条件时，中奖者与特定参与者无法关联。证明了Tyche协议的安全性、公平性和隐私保护特性。最后，通过在Sui区块链上实施，评估了协议的性能，特别是在交易费用方面的表现，发现单用户交易费用相对较低，这表明协议有可能支持数百万参与者的应用。 <div>
arXiv:2409.03464v1 Announce Type: new 
Abstract: We propose Tyche, a family of protocols for performing practically (as well as asymptotically) efficient multiparty lotteries, resistant against aborts and majority coalitions. Our protocols are based on a commit-and-reveal approach, requiring only a collision-resistant hash function.
  All our protocols use a blockchain as a public bulletin board and for buy-in collection and payout settlement. Importantly though, they do not rely on it or any other third party for providing randomness. Also, participants are not required to post any collateral beyond their buy-in. Any honest participant can eventually settle the lottery, and dishonest behavior never reduces the winning probability of any honest participant.
  Further, we adapt all three protocols into anonymous lotteries, where (under certain conditions) the winner is unlinkable to any particular participant. We show that our protocols are secure, fair, and some preserve the participants' privacy.
  Finally, we evaluate the performance of our protocols, particularly in terms of transaction fees, by implementing them on the Sui blockchain. There we see that per user transaction fees are reasonably low and our protocols could potentially support millions of participants.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Compliance of Self-Sovereign Identity with GDPR Principles: A Critical Review</title>
<link>https://arxiv.org/abs/2409.03624</link>
<guid>https://arxiv.org/abs/2409.03624</guid>
<content:encoded><![CDATA[
<div> 关键词：Identity Management Systems、Self-sovereign identity、Blockchain、General Data Protection Regulation、Research Gaps

总结:

本文聚焦于身份管理系统的演进与自主权身份（SSI）框架的现状。首先，作者强调了传统身份管理系统（包括孤立式、集中式和联邦式）在电子服务中的作用，这些系统主要依赖身份提供者（IdPs）来在用户和服务提供商之间建立信任。然而，这些过程涉及收集、处理或存储个人数据的风险，可能导致数据泄露。

为了解决这一问题，自主权身份作为一种新兴的身份管理系统模型被引入，旨在通过赋予数据所有者对个人数据的控制权来减少数据泄露的可能性。在SSI中，数据所有者的数字钱包负责存储其个人数据，并拥有完全控制权。

文章回顾了区块链解决方案在通用数据保护条例（GDPR）下的应用，并系统地搜索了近期的SSI和区块链提案。通过对检索到的文档进行合规性评估，探讨了它们的潜力、限制和局限性。此外，该研究还识别了研究缺口和机遇，指出在SSI领域仍需进一步探索和解决的问题。

通过分析和比较不同方法，文章旨在为身份管理和数据保护领域提供有价值的见解，促进更安全、更私密的在线环境的发展。 <div>
arXiv:2409.03624v1 Announce Type: new 
Abstract: Identity Management Systems (IdMs) have complemented how users are identified, authenticated, and authorised on e-services. Among the methods used for this purpose are traditional IdMs (isolated, centralised and federated) that mostly rely on identity providers (IdPs) to broker trust between a user and service-providers (SPs). An IdP also identifies and authenticates a user on-behalf of the SP, who then determines the authorisation of the user. In these processes, both SP and IdP collect, process or store private users' data, which can be prone to breach. One approach to address the data breach is to relieve the IdP, and return control and storage of personal data to the owner. Self-sovereign identity (SSI) was introduced as an IdM model to reduce the possibility of data breaches by offering control of personal data to the owner. SSI is a decentralised IdM, where the data owner has sovereign control of personal data stored in their digital wallet. Since SSI is an emerging technology, its components and methods require careful evaluation. This paper provides an evolution to IdMs and reviews the state-of-the-art SSI frameworks. We explored articles in the literature that reviewed blockchain solutions for General Data Protection Regulation (GDPR). We systematically searched recent SSI and blockchain proposals, evaluated the compliance of the retrieved documents with the GDPR privacy principles, and discussed their potentials, constraints, and limitations. This work identifies potential research gaps and opportunities.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Practical Forecasting of Cryptocoins Timeseries using Correlation Patterns</title>
<link>https://arxiv.org/abs/2409.03674</link>
<guid>https://arxiv.org/abs/2409.03674</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、分布式账本、安全加密技术、交易价格、时间序列预测

总结:

本文研究了加密货币（如比特币、以太币、莱特币）作为可交易的数字资产，其所有权记录在分布式账本（区块链）上。通过安全加密技术确保交易的安全性，并保证在账本中注册的交易（即不同所有者之间的硬币转移）。加密货币之间存在特定的交易价格，这些价格的极端波动性在所有不同的加密资产集中是公认的事实。然而，不同加密货币之间的交易价格关系仍然缺乏深入探索。

主要发现包括：

1. **强相关模式**：研究揭示了交易量最大的加密货币（如比特币和以太坊）与其他类型加密货币之间的强烈相关模式。
   
2. **趋势因果关系**：分析了这些趋势之间的因果关系，为理解加密货币价格趋势的准确性提供了基础。

3. **时间序列预测算法**：利用状态最先进的时间序列预测技术（如GBMs、LSTM和GRU）来预测加密货币的价格趋势，展示了这些方法的有效性。

4. **数据与代码释放**：为了促进学术界的研究，研究团队提供了用于复制分析的数据集和代码。

5. **行业应用价值**：此研究不仅为加密货币市场的理解和预测提供了科学依据，也为投资者和市场分析师提供了有价值的工具和洞察。

这项研究对加密货币市场有重要影响，不仅加深了对加密货币间关系的理解，还促进了更准确的市场预测和决策制定。 <div>
arXiv:2409.03674v1 Announce Type: new 
Abstract: Cryptocoins (i.e., Bitcoin, Ether, Litecoin) are tradable digital assets. Ownerships of cryptocoins are registered on distributed ledgers (i.e., blockchains). Secure encryption techniques guarantee the security of the transactions (transfers of coins among owners), registered into the ledger. Cryptocoins are exchanged for specific trading prices. The extreme volatility of such trading prices across all different sets of crypto-assets remains undisputed. However, the relations between the trading prices across different cryptocoins remains largely unexplored. Major coin exchanges indicate trend correlation to advise for sells or buys. However, price correlations remain largely unexplored. We shed some light on the trend correlations across a large variety of cryptocoins, by investigating their coin/price correlation trends over the past two years. We study the causality between the trends, and exploit the derived correlations to understand the accuracy of state-of-the-art forecasting techniques for time series modeling (e.g., GBMs, LSTM and GRU) of correlated cryptocoins. Our evaluation shows (i) strong correlation patterns between the most traded coins (e.g., Bitcoin and Ether) and other types of cryptocurrencies, and (ii) state-of-the-art time series forecasting algorithms can be used to forecast cryptocoins price trends. We released datasets and code to reproduce our analysis to the research community.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartIntentNN: Towards Smart Contract Intent Detection</title>
<link>https://arxiv.org/abs/2211.13670</link>
<guid>https://arxiv.org/abs/2211.13670</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链、恶意意图检测、深度学习、神经网络

总结:
本文提出了SmartIntentNN，一种基于深度学习的工具，旨在自动化检测智能合约开发者的目的。该工具通过集成Universal Sentence Encoder来对智能合约代码进行上下文表示，利用K-means聚类算法突出与意图相关的代码特征，并结合双向LSTM基的多标签分类网络预测十个高风险意图类型。在对10,000个智能合约的数据集评估中，SmartIntentNN超越了所有基线模型，实现了高达0.8633的F1分数。此外，提供了一个演示视频供用户参考。这一研究为智能合约的安全性提供了新的视角，通过识别潜在的恶意意图，有助于降低经济损失和提升区块链生态系统的安全性。 <div>
arXiv:2211.13670v3 Announce Type: replace 
Abstract: Smart contracts on the blockchain offer decentralized financial services but often lack robust security measures, resulting in significant economic losses. Although substantial research has focused on identifying vulnerabilities, a notable gap remains in evaluating the malicious intent behind their development. To address this, we introduce \textsc{SmartIntentNN} (Smart Contract Intent Neural Network), a deep learning-based tool designed to automate the detection of developers' intent in smart contracts. Our approach integrates a Universal Sentence Encoder for contextual representation of smart contract code, employs a K-means clustering algorithm to highlight intent-related code features, and utilizes a bidirectional LSTM-based multi-label classification network to predict ten distinct types of high-risk intent. Evaluations on a dataset of 10,000 smart contracts demonstrate that \textsc{SmartIntentNN} surpasses all baselines, achieving an F1-score of up to 0.8633. A demo video is available at \url{https://youtu.be/otT0fDYjwK8}.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fast Decentralized State Estimation for Legged Robot Locomotion via EKF and MHE</title>
<link>https://arxiv.org/abs/2405.20567</link>
<guid>https://arxiv.org/abs/2405.20567</guid>
<content:encoded><![CDATA[
<div> 关键词：快速、去中心化、状态估计、腿部运动控制、优化结构

总结:
本文提出了一种用于腿部运动控制的高效去中心化状态估计框架。该框架将浮动基座状态的非线性估计分解为两个部分：通过扩展卡尔曼滤波器（EKF）进行的姿态估计和通过移动窗口估计（MHE）进行的线性速度估计。EKF利用惯性传感器与视觉数据融合以估算浮动基座姿态，而MHE则利用过去时间窗口内的传感器数据以及已估计的姿态来基于随时间变化的线性动力学模型估计线性速度，同时考虑到状态约束。文章还提出了一种基于全信息滤波器（FIF）优化结构的边际化方法，将具有等式约束的FIF转换为等效的MHE，从而实现了状态估计的解耦，提高了计算效率、估计精度并确保了状态约束的考虑。所提出的方案在多个腿部机器人上进行了验证，包括动态跳跃机器人PogoX、双足机器人Cassie和四足机器人Unitree Go1，均在200Hz频率下实现了准确的状态估计，时间窗口间隔为0.1秒。 <div>
arXiv:2405.20567v2 Announce Type: replace 
Abstract: In this paper, we present a fast and decentralized state estimation framework for the control of legged locomotion. The nonlinear estimation of the floating base states is decentralized to an orientation estimation via Extended Kalman Filter (EKF) and a linear velocity estimation via Moving Horizon Estimation (MHE). The EKF fuses the inertia sensor with vision to estimate the floating base orientation. The MHE uses the estimated orientation with all the sensors within a time window in the past to estimate the linear velocities based on a time-varying linear dynamics formulation of the interested states with state constraints. More importantly, a marginalization method based on the optimization structure of the full information filter (FIF) is proposed to convert the equality-constrained FIF to an equivalent MHE. This decoupling of state estimation promotes the desired balance of computation efficiency, accuracy of estimation, and the inclusion of state constraints. The proposed method is shown to be capable of providing accurate state estimation to several legged robots, including the highly dynamic hopping robot PogoX, the bipedal robot Cassie, and the quadrupedal robot Unitree Go1, with a frequency at 200 Hz and a window interval of 0.1s.
]]></content:encoded>
<pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Role of Transformer Models in Advancing Blockchain Technology: A Systematic Review</title>
<link>https://arxiv.org/abs/2409.02139</link>
<guid>https://arxiv.org/abs/2409.02139</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、Transformer模型、应用调研、挑战与机遇、未来研究方向

总结:

本文旨在填补Transformer模型在区块链领域应用的系统性研究空白。通过综合分析超过200篇相关文献，文章全面回顾了Transformer在区块链应用中的实践案例和研究进展，重点关注异常检测、智能合约安全分析、加密货币预测与趋势分析、代码摘要生成等关键领域。

首先，文章从各区块链领域背景及目标出发，详细审视了现有代表性方法及其局限性，进而展示了Transformer模型在此类问题上的突破性贡献。此外，文章还深入探讨了利用Transformer模型面临的挑战，如数据隐私保护、模型复杂度管理和实时处理需求等，并提出了相应的解决策略。

最后，文章展望了未来研究方向，强调深入探索Transformer架构以适应特定区块链应用的重要性，并讨论了其促进区块链技术发展的潜力。此研究为区块链技术与机器学习的整合发展提供了新的视角和研究基础，支持了区块链技术的创新与应用拓展。

通过系统梳理现有研究，本文不仅为学者和从业者提供了一个全面的资源库，也为推动区块链技术的进一步发展指明了方向。 <div>
arXiv:2409.02139v1 Announce Type: new 
Abstract: As blockchain technology rapidly evolves, the demand for enhanced efficiency, security, and scalability grows.Transformer models, as powerful deep learning architectures,have shown unprecedented potential in addressing various blockchain challenges. However, a systematic review of Transformer applications in blockchain is lacking. This paper aims to fill this research gap by surveying over 200 relevant papers, comprehensively reviewing practical cases and research progress of Transformers in blockchain applications. Our survey covers key areas including anomaly detection, smart contract security analysis, cryptocurrency prediction and trend analysis, and code summary generation. To clearly articulate the advancements of Transformers across various blockchain domains, we adopt a domain-oriented classification system, organizing and introducing representative methods based on major challenges in current blockchain research. For each research domain,we first introduce its background and objectives, then review previous representative methods and analyze their limitations,and finally introduce the advancements brought by Transformer models. Furthermore, we explore the challenges of utilizing Transformer, such as data privacy, model complexity, and real-time processing requirements. Finally, this article proposes future research directions, emphasizing the importance of exploring the Transformer architecture in depth to adapt it to specific blockchain applications, and discusses its potential role in promoting the development of blockchain technology. This review aims to provide new perspectives and a research foundation for the integrated development of blockchain technology and machine learning, supporting further innovation and application expansion of blockchain technology.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaboratively Learning Federated Models from Noisy Decentralized Data</title>
<link>https://arxiv.org/abs/2409.02189</link>
<guid>https://arxiv.org/abs/2409.02189</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Noisy Data, Gradient Space, Client Identification, Noise-Aware Aggregation

<br /><br />
总结:

文章探讨了联邦学习(Federated Learning, FL)中一个关键问题——如何处理分布式设备贡献的噪声数据。在联邦学习中，模型通过在各设备上训练并共享参数来协作学习，而数据的分散存储有助于保护用户隐私。然而，由于设备端数据可能受到各种噪声和干扰的影响，这直接影响到模型聚合过程的准确性和最终模型的质量。

为解决这一问题，研究者提出了一种全面评估客户端输入在梯度空间中的方法，基于对模型在干净与噪声输入数据上训练后梯度范数分布差异的观察。他们引入了一种简单而有效的策略，用于在联邦学习的初始阶段识别出数据质量较低的客户端。接着，他们提出了名为Federated Noise-Sifting (FedNS) 的噪声感知联邦学习聚合方法，该方法可作为现有联邦学习策略的插件使用，以增强模型性能。

通过在不同基准数据集下的广泛实验，研究结果表明，FedNS能够显著提高在有噪声的分散数据上的全局模型性能。在独立同分布(IID)和非独立同分布(non-IID)设置下，与标准联邦学习策略相比，FedNS可以分别提升高达13.68%和15.85%的性能。这一发现强调了在联邦学习中识别和处理噪声数据的重要性，并提供了一种有效的方法来改进模型的泛化能力和整体性能。 <div>
arXiv:2409.02189v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a prominent method for collaboratively training machine learning models using local data from edge devices, all while keeping data decentralized. However, accounting for the quality of data contributed by local clients remains a critical challenge in FL, as local data are often susceptible to corruption by various forms of noise and perturbations, which compromise the aggregation process and lead to a subpar global model. In this work, we focus on addressing the problem of noisy data in the input space, an under-explored area compared to the label noise. We propose a comprehensive assessment of client input in the gradient space, inspired by the distinct disparity observed between the density of gradient norm distributions of models trained on noisy and clean input data. Based on this observation, we introduce a straightforward yet effective approach to identify clients with low-quality data at the initial stage of FL. Furthermore, we propose a noise-aware FL aggregation method, namely Federated Noise-Sifting (FedNS), which can be used as a plug-in approach in conjunction with widely used FL strategies. Our extensive evaluation on diverse benchmark datasets under different federated settings demonstrates the efficacy of FedNS. Our method effortlessly integrates with existing FL strategies, enhancing the global model's performance by up to 13.68% in IID and 15.85% in non-IID settings when learning from noisy decentralized data.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantifying Liveness and Safety of Avalanche's Snowball</title>
<link>https://arxiv.org/abs/2409.02217</link>
<guid>https://arxiv.org/abs/2409.02217</guid>
<content:encoded><![CDATA[
<div> 关键词：雪球协议、雪崩协议、网络韧性、模拟实验、拜占庭容错

总结:
本文探讨了雪球和雪崩这两种底层协议在流行雪崩区块链中的鲁棒性特性。通过在Rust中实现的模拟实验，研究者量化了在对手策略性重新平衡网络以延迟终止的情况下雪球协议的鲁棒性。结果显示，在节点数量为n的同等权益网络中，当对手控制超过$\Omega(\sqrt{n})$节点时，可破坏活锁。具体而言，对于n=2000的网络，只需控制约5.2%的权益就能成功攻击活锁。若对手获得有关网络状态的额外信息（无通信或其他优势），所需的权益比例降低至仅需2.8%即可成功攻击。研究还表明，对手可以以指数时间依赖于其权益、与网络规模成反比的方式破坏安全性，例如在3000节点网络中，当对手控制25%权益时，预期需要大约265轮次。

研究结论指出，雪球和雪崩协议类似于拜占庭可靠广播协议，而非共识机制，这揭示了它们在网络安全性和稳定性方面的关键特性。 <div>
arXiv:2409.02217v1 Announce Type: new 
Abstract: This work examines the resilience properties of the Snowball and Avalanche protocols that underlie the popular Avalanche blockchain. We experimentally quantify the resilience of Snowball using a simulation implemented in Rust, where the adversary strategically rebalances the network to delay termination.
  We show that in a network of $n$ nodes of equal stake, the adversary is able to break liveness when controlling $\Omega(\sqrt{n})$ nodes. Specifically, for $n = 2000$, a simple adversary controlling $5.2\%$ of stake can successfully attack liveness. When the adversary is given additional information about the state of the network (without any communication or other advantages), the stake needed for a successful attack is as little as $2.8\%$. We show that the adversary can break safety in time exponentially dependent on their stake, and inversely linearly related to the size of the network, e.g. in 265 rounds in expectation when the adversary controls $25\%$ of a network of 3000.
  We conclude that Snowball and Avalanche are akin to Byzantine reliable broadcast protocols as opposed to consensus.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Neighbourhood conditions for network stability with link uncertainty</title>
<link>https://arxiv.org/abs/2409.02350</link>
<guid>https://arxiv.org/abs/2409.02350</guid>
<content:encoded><![CDATA[
<div> 关键词：输入输出模型、网络不确定性、结构化鲁棒稳定性、分散型条件、集成二次约束

总结:

本文的主要结果涉及对包含链接不确定性的网络输入-输出模型的结构化鲁棒稳定性分析。通过构建一系列集成二次约束，这些约束共同保证了网络动态的鲁棒稳定性。与现有依赖于单一节点邻域信息的分散型条件相比，新提出的条件覆盖了更广泛的邻域，从而提供了更宽松、更灵活的稳定性评估框架。

具体而言，新条件不仅在逻辑上更加全面地考虑了网络中各个节点及其邻域的信息，而且在实践应用中能够显著降低对局部问题数据的保守性依赖，从而提高稳定性分析的精确度和效率。这为复杂网络系统的设计和优化提供了更为有效的工具，尤其是在面对不确定性因素时，能够提供更强的鲁棒性和适应性。

为了验证这一方法的有效性，文章还通过一个数值实例进行了展示，说明了新提出的广域条件相对于传统局部条件在稳定性分析上的优势。这一研究成果对于网络科学、控制系统理论以及相关工程领域的研究和应用具有重要的参考价值。 <div>
arXiv:2409.02350v1 Announce Type: new 
Abstract: The main result relates to structured robust stability analysis of an input-output model for networks with link uncertainty. It constitutes a collection of integral quadratic constraints, which together imply robust stability of the uncertain networked dynamics. Each condition is decentralized in the sense that it depends on model data pertaining to the neighbourhood of a specific agent. By contrast, pre-existing conditions for the network model are link-wise decentralized, with each involving conservatively more localized problem data. A numerical example is presented to illustrate the advantage of the new broader neighbourhood conditions.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dissecting Payload-based Transaction Phishing on Ethereum</title>
<link>https://arxiv.org/abs/2409.02386</link>
<guid>https://arxiv.org/abs/2409.02386</guid>
<content:encoded><![CDATA[
<div> 关键词：新型钓鱼攻击、以太坊、智能合约、检测方法、损失评估

总结:

本文针对以太坊上出现的一种新型钓鱼攻击——基于交易的智能合约钓鱼（PTXPHISH），进行了全面研究。PTXPHISH通过操纵智能合约交互执行恶意载荷来欺骗用户，其威胁程度已导致2023年超过7000万美元的损失。目前，这是首次对PTXPHISH进行全面分析的研究。

研究首先收集了长期数据并构建了首个PTXPHISH真实案例集，包含5000笔受骗交易。通过对这些数据进行深入分析，将PTXPHISH的诈骗手法分为四大类和十一种子类别。其次，提出了一种基于规则的多维度检测方法，准确率超过99%，并应用于大规模检测中，历时300天，共发现130,637笔钓鱼交易，涉及总损失超过3.419亿美元。

此外，研究还报告了1,726个钓鱼地址给社区，并发送了2,539条链上警报信息，帮助了1,980名受害者，为防范此类新型威胁提供了重要参考。 <div>
arXiv:2409.02386v1 Announce Type: new 
Abstract: In recent years, a more advanced form of phishing has arisen on Ethereum, surpassing early-stage, simple transaction phishing. This new form, which we refer to as payload-based transaction phishing (PTXPHISH), manipulates smart contract interactions through the execution of malicious payloads to deceive users. PTXPHISH has rapidly emerged as a significant threat, leading to incidents that caused losses exceeding \$70 million in 2023 reports. Despite its substantial impact, no previous studies have systematically explored PTXPHISH
  In this paper, we present the first comprehensive study of the PTXPHISH on Ethereum. Firstly, we conduct a long-term data collection and put considerable effort into establishing the first ground-truth PTXPHISH dataset, consisting of 5,000 phishing transactions. Based on the dataset, we dissect PTXPHISH, categorizing phishing tactics into four primary categories and eleven sub-categories. Secondly, we propose a rule-based multi-dimensional detection approach to identify PTXPHISH, achieving over 99% accuracy in the ground-truth dataset. Finally, we conducted a large-scale detection spanning 300 days and discovered a total of 130,637 phishing transactions on Ethereum, resulting in losses exceeding $341.9 million. Our in-depth analysis of these phishing transactions yielded valuable and insightful findings.
  Furthermore, our work has made significant contributions to mitigating real-world threats. We have reported 1,726 phishing addresses to the community, accounting for 42.7% of total community contributions during the same period. Additionally, we have sent 2,539 on-chain alert messages, assisting 1,980 victims. This research serves as a valuable reference in combating the emerging PTXPHISH and safeguarding users' assets.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Occlusion-Based Cooperative Transport for Concave Objects with a Swarm of Miniature Mobile Robots</title>
<link>https://arxiv.org/abs/2409.02436</link>
<guid>https://arxiv.org/abs/2409.02436</guid>
<content:encoded><![CDATA[
<div> 关键词：集体运输、凹面物体、移动机器人、去凹化策略、凸形伪物体

总结:
本文提出了一种基于遮挡的策略，用于利用一群移动机器人进行凹面物体的集体运输。该研究旨在通过分布式方法解决使用凹面物体时遇到的挑战。特别之处在于，机器人在执行任务时无需了解物体的具体几何形状，也不需要直接交流信息。基本思路是通过填充一定数量的机器人到物体的凹陷部分，从而形成一个新的凸形“伪物体”，随后对这个新形成的物体实施基于遮挡的集体运输策略。

文章将工作分为两部分：第一部分涉及对各种不同形状的凹面物体进行凹陷填充；第二部分则关注于如何对新形成的凸形物体进行集体运输。整个研究旨在探索和优化机器人在未知复杂环境下进行高效协作的可能途径，特别是针对具有特定几何特性的物体，如凹面物体。通过实施这一策略，研究人员希望提高机器人系统在实际应用中的灵活性和适应性，特别是在处理非标准或难以预测的物体时。 <div>
arXiv:2409.02436v1 Announce Type: new 
Abstract: An occlusion based strategy for collective transport of a concave object using a swarm of mobile robots has been proposed in this paper. We aim to overcome the challenges of transporting concave objects using decentralized approach. The interesting aspect of this task is that the agents have no prior knowledge about the geometry of the object and do not explicitly communicate with each other. The concept is to eliminate the concavity of the object by filling a number of robots in its cavity and then carry out an occlusion based transport strategy on the newly formed convex object or "pseudo object". We divide our work into two parts: concavity filling of various concave objects and occlusion based collective transport of convex objects.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AirFogSim: A Light-Weight and Modular Simulator for UAV-Integrated Vehicular Fog Computing</title>
<link>https://arxiv.org/abs/2409.02518</link>
<guid>https://arxiv.org/abs/2409.02518</guid>
<content:encoded><![CDATA[
<div> 关键词：Vehicular Fog Computing（VFC）、Unmanned Aerial Vehicles（UAVs）、Intelligent Transportation Systems（ITS）、AirFogSim、Simulation Platform

总结:

本文主要探讨了Vehicular Fog Computing（VFC）与Unmanned Aerial Vehicles（UAVs）在Intelligent Transportation Systems（ITS）中的应用与融合。VFC通过提供高效、安全和强大的计算能力，显著提升了ITS的性能。UAVs的加入进一步增强了这一优势，提供了灵活和辅助的服务。然而，这同时也带来了空中-地面交互计算网络复杂动态建模的挑战，以及缺乏全面和灵活的仿真平台的问题。

为解决这一问题，作者提出并设计了一个轻量级、模块化的空中-地面协作仿真平台——AirFogSim。该平台旨在为UAV-integrated VFC的研究提供一个强有力的工具，通过模拟五项关键任务验证了其功能和效用。这些任务涵盖了无人机轨迹规划、任务卸载、资源分配以及区块链技术的应用。通过多场景案例分析，证明了AirFogSim在理论设计与实际验证之间的桥梁作用，为未来智能交通领域的发展开辟了新路径。

AirFogSim的开发不仅解决了当前仿真平台的缺失，还为研究者提供了一个全面评估和优化UAV-integrated VFC系统性能的平台，从而推动了该领域的技术创新和实践应用。此外，作者承诺将提供开源代码，促进社区合作与共享，加速相关研究的进展。 <div>
arXiv:2409.02518v1 Announce Type: new 
Abstract: Vehicular Fog Computing (VFC) is significantly enhancing the efficiency, safety, and computational capabilities of Intelligent Transportation Systems (ITS), and the integration of Unmanned Aerial Vehicles (UAVs) further elevates these advantages by incorporating flexible and auxiliary services. This evolving UAV-integrated VFC paradigm opens new doors while presenting unique complexities within the cooperative computation framework. Foremost among the challenges, modeling the intricate dynamics of aerial-ground interactive computing networks is a significant endeavor, and the absence of a comprehensive and flexible simulation platform may impede the exploration of this field. Inspired by the pressing need for a versatile tool, this paper provides a lightweight and modular aerial-ground collaborative simulation platform, termed AirFogSim. We present the design and implementation of AirFogSim, and demonstrate its versatility with five key missions in the domain of UAV-integrated VFC. A multifaceted use case is carried out to validate AirFogSim's effectiveness, encompassing several integral aspects of the proposed AirFogSim, including UAV trajectory, task offloading, resource allocation, and blockchain. In general, AirFogSim is envisioned to set a new precedent in the UAV-integrated VFC simulation, bridge the gap between theoretical design and practical validation, and pave the way for future intelligent transportation domains. Our code will be available at https://github.com/ZhiweiWei-NAMI/AirFogSim.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Formation Learning Control for Cooperative AUVs under Complete Uncertainty</title>
<link>https://arxiv.org/abs/2409.02745</link>
<guid>https://arxiv.org/abs/2409.02745</guid>
<content:encoded><![CDATA[
<div> 关键词：两层控制框架、不确定非线性动态、自主水下车辆（AUV）、分散式确定学习控制器、径向基函数神经网络

总结:
本文提出了一种针对自主水下车辆(AUV)的两层控制框架，旨在处理未知的不确定非线性动力学问题，如质量矩阵。与以往研究不同的是，此框架使控制器独立于机器人配置和变化的环境条件。该框架适用于不同环境条件下的AUV操作，能有效管理如水粘度和流体流动变化等环境因素对AUV的有效质量和阻尼动态的影响。

第一层为协同估计器，能够通过共享关键系统估计来实现多Agent之间的无缝通信，无需依赖全局信息。第二层则是一个分散式确定学习控制器，利用局部反馈调整每个AUV的轨迹，确保形成控制的准确性和动态适应性。

文章中采用径向基函数神经网络进行局部学习和知识存储，使AUV能够在系统重启后高效重用学习到的动力学特性。通过仿真验证了该框架的有效性，标志着分布式自适应控制系统在AUV领域的重大进展，显著提升了在不可预测海洋环境中的操作灵活性和韧性。 <div>
arXiv:2409.02745v1 Announce Type: new 
Abstract: This paper presents a two-layer control framework for Autonomous Underwater Vehicles (AUVs) designed to handle uncertain nonlinear dynamics, including the mass matrix, previously assumed known. Unlike prior studies, this approach makes the controller independent of the robot's configuration and varying environmental conditions. The proposed framework applies across different environmental conditions affecting AUVs. It features a first-layer cooperative estimator and a second-layer decentralized deterministic learning controller. This architecture supports robust operation under diverse underwater scenarios, managing environmental effects like changes in water viscosity and flow, which impact the AUV's effective mass and damping dynamics. The first-layer estimator enables seamless inter-agent communication by sharing crucial system estimates without relying on global information. The second-layer controller uses local feedback to adjust each AUV's trajectory, ensuring accurate formation control and dynamic adaptability. Radial basis function neural networks enable local learning and knowledge storage, allowing AUVs to efficiently reapply learned dynamics after system restarts. Simulations validate the effectiveness of this framework, marking it as a significant advancement in distributed adaptive control systems for AUVs, enhancing operational flexibility and resilience in unpredictable marine environments.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Global Public Sentiment on Decentralized Finance: A Spatiotemporal Analysis of Geo-tagged Tweets from 150 Countries</title>
<link>https://arxiv.org/abs/2409.00843</link>
<guid>https://arxiv.org/abs/2409.00843</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、非同质化代币（NFT）、全球影响、经济因素、地理权重回归

总结:

本文研究了区块链技术、加密货币和非同质化代币在全球范围内的公众关注与情感变化。通过分析从2012年到2022年的15亿多条带有地理位置信息的推文，使用基于BERT的多语言情感模型计算出情感分数。研究结果揭示了不同国家间的情感差异受到经济因素的影响，发达地区在讨论中更为活跃，而发展中国家则表现出更高的情感水平。地理权重回归显示，在比特币价格飙升后，GDP与推文互动的相关性加强。通过主题建模，发现具有相似经济特征的国家共享讨论趋势，而不同经济集群则关注不同的主题。这一研究强调了全球范围内对去中心化金融情感的差异，这些差异由经济和区域因素塑造，对缓解贫困、打击加密货币犯罪以及促进可持续发展具有重要影响。相关数据集和代码已公开发布在GitHub上。 <div>
arXiv:2409.00843v1 Announce Type: cross 
Abstract: In the digital era, blockchain technology, cryptocurrencies, and non-fungible tokens (NFTs) have transformed financial and decentralized systems. However, existing research often neglects the spatiotemporal variations in public sentiment toward these technologies, limiting macro-level insights into their global impact. This study leverages Twitter data to explore public attention and sentiment across 150 countries, analyzing over 150 million geotagged tweets from 2012 to 2022. Sentiment scores were derived using a BERT-based multilingual sentiment model trained on 7.4 billion tweets. The analysis integrates global cryptocurrency regulations and economic indicators from the World Development Indicators database. Results reveal significant global sentiment variations influenced by economic factors, with more developed nations engaging more in discussions, while less developed countries show higher sentiment levels. Geographically weighted regression indicates that GDP-tweet engagement correlation intensifies following Bitcoin price surges. Topic modeling shows that countries within similar economic clusters share discussion trends, while different clusters focus on distinct topics. This study highlights global disparities in sentiment toward decentralized finance, shaped by economic and regional factors, with implications for poverty alleviation, cryptocurrency crime, and sustainable development. The dataset and code are publicly available on GitHub.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Decentralized Optimization: Leveraging Both First- and Zeroth-Order Optimizers for Faster Convergence</title>
<link>https://arxiv.org/abs/2210.07703</link>
<guid>https://arxiv.org/abs/2210.07703</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、零阶优化、一阶优化、混合优化、深度神经网络

<br /><br />
总结:

本文探讨了分布式优化领域中一种新颖的研究方向——混合分布式优化。它关注于在一个分布式系统中，同时存在具备零阶优化能力（无法计算梯度）与一阶优化能力（能够计算梯度）的节点，共同解决联合优化任务的情况。研究发现，在合理的参数设置下，这种混合系统不仅能够容忍并利用噪声较高的零阶优化节点，甚至可以从中获益，而不仅仅是忽略它们的信息。该研究的核心贡献在于对带有噪音和潜在偏差梯度估计的分布式优化过程的新分析，这一成果可能具有独立的学术价值。此分析适用于凸性和非凸性目标函数。

实验结果在标准优化任务上验证了理论分析，表明即使在训练深度神经网络的过程中，混合的一阶-零阶优化方法也具有实践可行性。这为在实际应用中处理资源有限或计算能力不均等的分布式环境提供了新的策略和理论支持。 <div>
arXiv:2210.07703v2 Announce Type: replace 
Abstract: Distributed optimization is the standard way of speeding up machine learning training, and most of the research in the area focuses on distributed first-order, gradient-based methods. Yet, there are settings where some computationally-bounded nodes may not be able to implement first-order, gradient-based optimization, while they could still contribute to joint optimization tasks. In this paper, we initiate the study of hybrid decentralized optimization, studying settings where nodes with zeroth-order and first-order optimization capabilities co-exist in a distributed system, and attempt to jointly solve an optimization task over some data distribution. We essentially show that, under reasonable parameter settings, such a system can not only withstand noisier zeroth-order agents but can even benefit from integrating such agents into the optimization process, rather than ignoring their information. At the core of our approach is a new analysis of distributed optimization with noisy and possibly-biased gradient estimators, which may be of independent interest. Our results hold for both convex and non-convex objectives. Experimental results on standard optimization tasks confirm our analysis, showing that hybrid first-zeroth order optimization can be practical, even when training deep neural networks.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Partially Observable Multi-Agent Reinforcement Learning with Information Sharing</title>
<link>https://arxiv.org/abs/2308.08705</link>
<guid>https://arxiv.org/abs/2308.08705</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、部分可观测随机游戏、信息共享、近似模型、团队最优解

总结:

本文研究了在部分可观测随机游戏（POSGs）框架下的可证明多智能体强化学习（RL）。文章首先通过几个计算复杂性结果论证了信息共享和可观测性假设对于解决POSGs的必要性。信息共享与多智能体控制系统的通信模型密切相关，是实证多智能体RL中常见的做法。为了克服实际规划在真实模型中的低效问题，作者提出构建一个近似的共享公共信息模型，以创建一个近似模型的POSG，在此模型中，基于近似均衡的规划可以实现快速解决，即近多项式时间。此外，文章开发了一个同时在统计学和计算上都高效的部分可观测多智能体RL算法。

最后，文章扩展了算法框架，用于寻找合作POSGs的团队最优解，即分布式部分可观测马尔可夫决策过程，这一目标更具挑战性。文章在多种模型结构假设下，建立了具体的计算和样本复杂性。通过这些研究，作者希望激发利用和设计不同信息结构的潜力，从而为发展高效的部分可观测多智能体RL提供可能。 <div>
arXiv:2308.08705v3 Announce Type: replace 
Abstract: We study provable multi-agent reinforcement learning (RL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical multi-agent RL, and a standard model for multi-agent control systems with communications. We first establish several computational complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for efficiently solving POSGs. {Inspired by the inefficiency of planning in the ground-truth model,} we then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate \emph{equilibrium} (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable multi-agent RL algorithm that is \emph{both} statistically and computationally quasi-efficient. {Finally, beyond equilibrium learning, we extend our algorithmic framework to finding the \emph{team-optimal solution} in cooperative POSGs, i.e., decentralized partially observable Markov decision processes, a much more challenging goal. We establish concrete computational and sample complexities under several common structural assumptions of the model.} We hope our study could open up the possibilities of leveraging and even designing different \emph{information structures}, a well-studied notion in control theory, for developing both sample- and computation-efficient partially observable multi-agent RL.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MetaDigiHuman: Haptic Interfaces for Digital Humans in Metaverse</title>
<link>https://arxiv.org/abs/2409.00615</link>
<guid>https://arxiv.org/abs/2409.00615</guid>
<content:encoded><![CDATA[
<div> 关键词：MetaDigiHuman、数字人类、混合现实、触觉反馈、沉浸式体验

<br /><br />
总结:本文介绍了一种名为MetaDigiHuman的创新框架，它将虚拟的数字人类与先进的触觉反馈技术结合，旨在提升用户在元宇宙中的沉浸式体验。通过这一框架，用户能够模拟真实的触感，仿佛与数字世界中的实体进行互动，从而获得更加逼真和沉浸的体验。MetaDigiHuman利用前沿科技，实现了数字与物理世界的无缝融合，为元宇宙的未来发展开辟了新的可能。

MetaDigiHuman框架的核心在于创建了一个混合现实环境，其中数字人类可以以真实的方式与用户互动，提供触觉反馈，使用户感觉仿佛置身于一个真实的环境中。这不仅增强了用户的参与度，还提高了他们在元宇宙中的体验质量。通过MetaDigiHuman，未来的元宇宙将不仅仅是视觉和听觉的盛宴，更是触觉和情感的全方位沉浸体验，为用户带来前所未有的虚拟现实互动可能性。 <div>
arXiv:2409.00615v1 Announce Type: new 
Abstract: The way we engage with digital spaces and the digital world has undergone rapid changes in recent years, largely due to the emergence of the Metaverse. As technology continues to advance, the demand for sophisticated and immersive interfaces to interact with the Metaverse has become increasingly crucial. Haptic interfaces have been developed to meet this need and provide users with tactile feedback and realistic touch sensations. These interfaces play a vital role in creating a more authentic and immersive experience within the Metaverse. This article introduces the concept of MetaDigiHuman, a groundbreaking framework that combines blended digital humans and haptic interfaces. By harnessing cutting-edge technologies, MetaDigiHuman enables seamless and immersive interaction within the Metaverse. Through this framework, users can simulate the sensation of touching, feeling, and interacting with digital beings as if they were physically present in the environments, offering a more compelling and immersive experience within the Metaverse.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Price of Decentralization in Decentralized Detection</title>
<link>https://arxiv.org/abs/2409.00728</link>
<guid>https://arxiv.org/abs/2409.00728</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式检测、社会学习规则、错误概率、网络不平衡、改进学习规则

总结:

本文探讨了分布式检测领域中，特别是Lalitha等人提出的基于有向图的社会学习规则的固有限制。在分布式检测框架下，网络中的节点通过与邻居交换观察到的数据信息，共同推断未知假设。每个节点根据接收到的邻居信息调整其私人信念，仅需了解其观测数据的生成分布。

首先指出，原始的社会学习规则能够实现随样本数量无限增大而趋向于零的错误概率，但相较于集中式处理方式，它在可达到的错误指数方面存在差距。这种差距源于节点自定义权重选择导致的网络不平衡问题。为解决这一问题，文章提出了改进的学习规则，证明该规则可以达到与集中式设置相等的错误指数大小。这表明，分布式处理在错误概率的指数衰减速率上几乎不存在一阶代价。简而言之，通过优化节点间的权重分配策略，可以有效缩小分布式检测与集中式检测在性能上的差距，提高系统整体的决策准确性。 <div>
arXiv:2409.00728v1 Announce Type: new 
Abstract: Fundamental limits on the error probabilities of a family of decentralized detection algorithms (eg., the social learning rule proposed by Lalitha et al. over directed graphs are investigated. In decentralized detection, a network of nodes locally exchanging information about the samples they observe with their neighbors to collectively infer the underlying unknown hypothesis. Each node in the network weighs the messages received from its neighbors to form its private belief and only requires knowledge of the data generating distribution of its observation. In this work, it is first shown that while the original social learning rule of Lalitha et al. achieves asymptotically vanishing error probabilities as the number of samples tends to infinity, it suffers a gap in the achievable error exponent compared to the centralized case. The gap is due to the network imbalance caused by the local weights that each node chooses to weigh the messages received from its neighbors. To close this gap, a modified learning rule is proposed and shown to achieve error exponents as large as those in the centralized setup. This implies that there is essentially no first-order penalty caused by decentralization in the exponentially decaying rate of error probabilities.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Subgoal based Path Formation and Task Allocation: A NeuroFleets Approach to Scalable Swarm Robotics</title>
<link>https://arxiv.org/abs/2409.00766</link>
<guid>https://arxiv.org/abs/2409.00766</guid>
<content:encoded><![CDATA[
<div> 关键词：未知环境、演化群体机器人、路径形成、任务分配、视觉子目标

总结:

本文从演化群体机器人视角探讨了在未知环境下进行探索与导航的挑战。重点在于路径形成，这是使协同工作群体机器人有效导航的基础。研究设计了一个基于有限状态机的任务分配和路径形成过程，确保了决策的系统性和状态转换的高效性。该方法采用去中心化策略，允许每个机器人基于局部信息独立作出决策，从而提高系统的可扩展性和鲁棒性。

研究提出了一种基于视觉子目标的路径形成新方法，通过连接视觉上相连的子目标来建立地点之间的路径。在Argos模拟器上进行的仿真实验表明，这种方法在大多数试验中成功形成了路径。然而，大量机器人在路径形成期间的相互碰撞（交通）问题可能影响性能。为解决这一问题，研究提出了一种任务分配策略，利用局部通信协议和光信号通信管理机器人部署。该策略评估两点间的距离并确定执行路径形成任务所需的最优机器人数量，从而减少不必要的探索和交通拥堵。

研究比较了基于视觉子目标的路径形成方法和任务分配策略与A*算法的性能，包括路径长度、时间以及资源使用情况。仿真结果证明了所提出方法的有效性，突出了其在规模性、鲁棒性和故障容错方面的优势。 <div>
arXiv:2409.00766v1 Announce Type: new 
Abstract: This paper addresses the challenges of exploration and navigation in unknown environments from the perspective of evolutionary swarm robotics. A key focus is on path formation, which is essential for enabling cooperative swarm robots to navigate effectively. We designed the task allocation and path formation process based on a finite state machine, ensuring systematic decision-making and efficient state transitions. The approach is decentralized, allowing each robot to make decisions independently based on local information, which enhances scalability and robustness. We present a novel subgoal-based path formation method that establishes paths between locations by leveraging visually connected subgoals. Simulation experiments conducted in the Argos simulator show that this method successfully forms paths in the majority of trials. However, inter-collision (traffic) among numerous robots during path formation can negatively impact performance. To address this issue, we propose a task allocation strategy that uses local communication protocols and light signal-based communication to manage robot deployment. This strategy assesses the distance between points and determines the optimal number of robots needed for the path formation task, thereby reducing unnecessary exploration and traffic congestion. The performance of both the subgoal-based path formation method and the task allocation strategy is evaluated by comparing the path length, time, and resource usage against the A* algorithm. Simulation results demonstrate the effectiveness of our approach, highlighting its scalability, robustness, and fault tolerance.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Container Data Item: An Abstract Datatype for Efficient Container-based Edge Computing</title>
<link>https://arxiv.org/abs/2409.00801</link>
<guid>https://arxiv.org/abs/2409.00801</guid>
<content:encoded><![CDATA[
<div> 关键词：Container Data Item（CDI）、微服务、数据共享、安全性、隔离性

总结:
本文介绍了Container Data Item（CDI）这一抽象数据类型，旨在使多个容器能够高效地操作共同的数据项，同时保持其强大的安全性和隔离性。通过使用CDI，应用开发者能够在运行时控制共享数据项的所有权，实现不同容器之间的同步执行与数据共享。

CDI设计用于支持由一组相互连接的微服务组成的微服务架构，每个微服务由独立的容器实现。它确保在任何时刻只有一个容器拥有特定的CDI对象，并且只有当前CDI对象的所有者才能转移该对象的所有权。文章提供了三种不同的CDI实现方案，允许位于同一服务器或不同服务器上的容器利用CDI高效地操作共同的数据项。

此外，论文还对CDI进行了全面的性能评估，并展示了两个典型应用案例：增强现实应用和去中心化的流程编排器。通过这些实例，详细阐述了CDI如何在实际场景中提供高效、安全的数据共享解决方案。 <div>
arXiv:2409.00801v1 Announce Type: new 
Abstract: We present Container Data Item (CDI), an abstract datatype that allows multiple containers to efficiently operate on a common data item while preserving their strong security and isolation semantics. Application developers can use CDIs to enable multiple containers to operate on the same data, synchronize execution among themselves, and control the ownership of the shared data item during runtime. These containers may reside on the same server or different servers. CDI is designed to support microservice based applications comprised of a set of interconnected microservices, each implemented by a separate dedicated container. CDI preserves the important isolation semantics of containers by ensuring that exactly one container owns a CDI object at any instant and the ownership of a CDI object may be transferred from one container to another only by the current CDI object owner. We present three different implementations of CDI that allow different containers residing on the same server as well containers residing on different servers to use CDI for efficiently operating on a common data item. The paper provides an extensive performance evaluation of CDI along with two representative applications, an augmented reality application and a decentralized workflow orchestrator.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CyberCortex.AI: An AI-based Operating System for Autonomous Robotics and Complex Automation</title>
<link>https://arxiv.org/abs/2409.01241</link>
<guid>https://arxiv.org/abs/2409.01241</guid>
<content:encoded><![CDATA[
<div> 关键词：CyberCortex.AI、操作系统、人工智能、自动化应用、实时通信

总结:
本文介绍了一种名为CyberCortex.AI的新型机器人操作系统，其旨在为异构AI驱动的机器人和复杂自动化应用提供支撑。该系统具有分布式和去中心化特性，能够使机器人之间以及与云中的高性能计算机（HPC）进行通信。它通过将传感器和控制数据流式传输至HPC系统以用于AI算法的训练，然后将这些算法部署回机器人中。每个机器人功能（如传感器数据采集、路径规划、运动控制等）均在共享互联网的称为“DataBlock”的过滤器集合中执行，这些过滤器可以在机器人本地计算或在不同的机器人系统上远程计算。数据通过称为“Temporal Addressable Memory”（TAM）的组件存储和访问，该组件充当过滤器输入和输出之间的桥梁。CyberCortex.AI由两个主要组件构成：i) 在机器人嵌入式硬件上运行的实时实现的CyberCortex.AI.inference系统，以及ii) 在云中的HPC计算机上运行的CyberCortex.AI.dojo，用于设计、训练和部署AI算法。

为了评估此方法的性能，文章使用了两种协作机器人应用进行了定量和定性分析：i) 一个基于Unitree A1腿式机器人和Anafi Parrot 4K无人机的森林火灾预防系统，以及ii) 一个使用CyberCortex.AI进行协作感知和运动控制的自主驾驶系统。 <div>
arXiv:2409.01241v1 Announce Type: new 
Abstract: The underlying framework for controlling autonomous robots and complex automation applications are Operating Systems (OS) capable of scheduling perception-and-control tasks, as well as providing real-time data communication to other robotic peers and remote cloud computers. In this paper, we introduce CyberCortex.AI, a robotics OS designed to enable heterogeneous AI-based robotics and complex automation applications. CyberCortex.AI is a decentralized distributed OS which enables robots to talk to each other, as well as to High Performance Computers (HPC) in the cloud. Sensory and control data from the robots is streamed towards HPC systems with the purpose of training AI algorithms, which are afterwards deployed on the robots. Each functionality of a robot (e.g. sensory data acquisition, path planning, motion control, etc.) is executed within a so-called DataBlock of Filters shared through the internet, where each filter is computed either locally on the robot itself, or remotely on a different robotic system. The data is stored and accessed via a so-called \textit{Temporal Addressable Memory} (TAM), which acts as a gateway between each filter's input and output. CyberCortex.AI has two main components: i) the CyberCortex.AI.inference system, which is a real-time implementation of the DataBlock running on the robots' embedded hardware, and ii) the CyberCortex.AI.dojo, which runs on an HPC computer in the cloud, and it is used to design, train and deploy AI algorithms. We present a quantitative and qualitative performance analysis of the proposed approach using two collaborative robotics applications: \textit{i}) a forest fires prevention system based on an Unitree A1 legged robot and an Anafi Parrot 4K drone, as well as \textit{ii}) an autonomous driving system which uses CyberCortex.AI for collaborative perception and motion control.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey and Comparison of Post-quantum and Quantum Blockchains</title>
<link>https://arxiv.org/abs/2409.01358</link>
<guid>https://arxiv.org/abs/2409.01358</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算、区块链、后量子区块链、量子区块链、安全威胁

总结:

本文探讨了量子计算对现有区块链技术构成的安全威胁及其应对策略。主要提出了两种方法：后量子区块链和量子区块链。

1. **后量子区块链**：利用抗量子攻击的经典加密算法来增强区块链的安全性。这种方法旨在保持传统区块链的基本结构和功能，同时抵御量子计算机可能带来的风险。

2. **量子区块链**：探索利用量子计算机的强大能力重构区块链的基础架构。这种创新方法旨在发挥量子计算的潜力，以实现超越当前区块链的性能和安全性。

文章进一步对比了这两种方法在结构、安全、隐私等方面的差异，并讨论了它们面临的挑战和未来研究趋势。通过深入分析，旨在为区块链技术的量子时代提供指导方向和解决方案。 <div>
arXiv:2409.01358v1 Announce Type: new 
Abstract: Blockchains have gained substantial attention from academia and industry for their ability to facilitate decentralized trust and communications. However, the rapid progress of quantum computing poses a significant threat to the security of existing blockchain technologies. Notably, the emergence of Shor's and Grover's algorithms raises concerns regarding the compromise of the cryptographic systems underlying blockchains. Consequently, it is essential to develop methods that reinforce blockchain technology against quantum attacks. In response to this challenge, two distinct approaches have been proposed. The first approach involves post-quantum blockchains, which aim to utilize classical cryptographic algorithms resilient to quantum attacks. The second approach explores quantum blockchains, which leverage the power of quantum computers and networks to rebuild the foundations of blockchains. This paper aims to provide a comprehensive overview and comparison of post-quantum and quantum blockchains while exploring open questions and remaining challenges in these domains. It offers an in-depth introduction, examines differences in blockchain structure, security, privacy, and other key factors, and concludes by discussing current research trends.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-based Federated Recommendation with Incentive Mechanism</title>
<link>https://arxiv.org/abs/2409.01563</link>
<guid>https://arxiv.org/abs/2409.01563</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、激励机制、联邦推荐系统、NeuMF、FedAvg

<br /><br />
总结:
文章提出了一种基于区块链的联邦推荐系统，通过引入激励机制来解决联邦推荐技术面临的成本增加、模型攻击和数据污染等问题。该系统采用NeuMF（深度神经网络推荐算法）和FedAvg（平均梯度下降法）构建，旨在提高推荐服务的安全性、可信性和效率。通过设计一种逆拍卖机制，系统能够选择最优参与客户以最大化社会总收益。同时，利用区块链技术存储模型的链上证据，确保联邦推荐系统的安全性。实验结果显示，该激励机制可以吸引拥有优质训练数据的客户参与，从而降低联邦推荐的成本，提升经济收益和推荐性能。这项工作为构建和谐健康的联邦推荐应用生态提供了理论和技术支持。 <div>
arXiv:2409.01563v1 Announce Type: new 
Abstract: Nowadays, federated recommendation technology is rapidly evolving to help multiple organisations share data and train models while meeting user privacy, data security and government regulatory requirements. However, federated recommendation increases customer system costs such as power, computational and communication resources. Besides, federated recommendation systems are also susceptible to model attacks and data poisoning by participating malicious clients. Therefore, most customers are unwilling to participate in federated recommendation without any incentive. To address these problems, we propose a blockchain-based federated recommendation system with incentive mechanism to promote more trustworthy, secure, and efficient federated recommendation service. First, we construct a federated recommendation system based on NeuMF and FedAvg. Then we introduce a reverse auction mechanism to select optimal clients that can maximize the social surplus. Finally, we employ blockchain for on-chain evidence storage of models to ensure the safety of the federated recommendation system. The experimental results show that our proposed incentive mechanism can attract clients with superior training data to engage in the federal recommendation at a lower cost, which can increase the economic benefit of federal recommendation by 54.9\% while improve the recommendation performance. Thus our work provides theoretical and technological support for the construction of a harmonious and healthy ecological environment for the application of federal recommendation.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Buffer-based Gradient Projection for Continual Federated Learning</title>
<link>https://arxiv.org/abs/2409.01585</link>
<guid>https://arxiv.org/abs/2409.01585</guid>
<content:encoded><![CDATA[
<div> 关键词：连续联邦学习、灾难性遗忘、数据分布异构、任务边界、自适应联邦学习

总结:

本文聚焦于连续联邦学习（CFL）领域中的关键挑战——如何在多个分散客户端不断适应新数据流的同时，避免模型知识的遗忘。研究者提出了一种名为Fed-A-GEM的新方法，该方法是对已有A-GEM算法的联邦版本改编，旨在通过本地缓冲样本和聚合缓冲梯度来缓解灾难性遗忘问题。Fed-A-GEM通过利用这些技术，实现了在保持已学知识的同时，高效地学习新任务的能力。

文章指出，现有的CFL解决方案在设备存储限制和数据分布异质性方面存在局限性，而Fed-A-GEM通过结合现有CFL技术，显著提升了性能。实验结果表明，在CIFAR-100等基准数据集上，Fed-A-GEM能够将准确率提升高达27%，充分验证了其在多任务学习场景下的有效性。此外，作者还提供了实现代码，使得这一创新方法能够被更广泛的社区应用和研究。 <div>
arXiv:2409.01585v1 Announce Type: new 
Abstract: Continual Federated Learning (CFL) is essential for enabling real-world applications where multiple decentralized clients adaptively learn from continuous data streams. A significant challenge in CFL is mitigating catastrophic forgetting, where models lose previously acquired knowledge when learning new information. Existing approaches often face difficulties due to the constraints of device storage capacities and the heterogeneous nature of data distributions among clients. While some CFL algorithms have addressed these challenges, they frequently rely on unrealistic assumptions about the availability of task boundaries (i.e., knowing when new tasks begin). To address these limitations, we introduce Fed-A-GEM, a federated adaptation of the A-GEM method (Chaudhry et al., 2019), which employs a buffer-based gradient projection approach. Fed-A-GEM alleviates catastrophic forgetting by leveraging local buffer samples and aggregated buffer gradients, thus preserving knowledge across multiple clients. Our method is combined with existing CFL techniques, enhancing their performance in the CFL context. Our experiments on standard benchmarks show consistent performance improvements across diverse scenarios. For example, in a task-incremental learning scenario using the CIFAR-100 dataset, our method can increase the accuracy by up to 27%. Our code is available at https://github.com/shenghongdai/Fed-A-GEM.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On-chain Validation of Tracking Data Messages (TDM) Using Distributed Deep Learning on a Proof of Stake (PoS) Blockchain</title>
<link>https://arxiv.org/abs/2409.01614</link>
<guid>https://arxiv.org/abs/2409.01614</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、深学习、透明空间态势感知、信任无碍机制、空间物体追踪

<br /><br />
总结:

本文探讨了在太空态势感知(SSA)领域中，如何在缺乏完全信任的情况下，实现对居民空间物体(RSO)的无信任追踪。在当前环境下，RSO的位置信息可能被操纵，这引发了对RSO作为武器使用的担忧。传统的跟踪数据消息(TDM)格式存在数据质量参差不齐的问题，影响了SSA的可靠性。文章提出了一种基于区块链和深度学习的新型验证和验证机制。

通过利用区块链的去中心化和不可篡改特性，该机制可以实现无需中央权威的信任机制，确保共识为基础的真相。引入了一种先进的基于转换器的轨道推算器，其性能优于传统方法如SGP4，能够对单个RSO的多个观测结果进行交叉验证。此深度学习模型可分散部署在区块链上，允许参与方托管节点以包含分布式深度学习模型的一部分。

系统由分散观察者和基于权益证明(PoS)的区块链中的验证者组成。观察者通过贡献经过验证的TDM数据和股权来保证诚实，而验证者则运行推算和验证算法。对于贡献可信TDM的观察者，系统提供奖励；而对于提交无法验证数据的观察者，则施加惩罚。这一创新方法旨在提高SSA的可靠性和安全性，同时减少对单一数据源的信任依赖。 <div>
arXiv:2409.01614v1 Announce Type: new 
Abstract: Trustless tracking of Resident Space Objects (RSOs) is crucial for Space Situational Awareness (SSA), especially during adverse situations. The importance of transparent SSA cannot be overstated, as it is vital for ensuring space safety and security. In an era where RSO location information can be easily manipulated, the risk of RSOs being used as weapons is a growing concern. The Tracking Data Message (TDM) is a standardized format for broadcasting RSO observations. However, the varying quality of observations from diverse sensors poses challenges to SSA reliability. While many countries operate space assets, relatively few have SSA capabilities, making it crucial to ensure the accuracy and reliability of the data. Current practices assume complete trust in the transmitting party, leaving SSA capabilities vulnerable to adversarial actions such as spoofing TDMs. This work introduces a trustless mechanism for TDM validation and verification using deep learning over blockchain. By leveraging the trustless nature of blockchain, our approach eliminates the need for a central authority, establishing consensus-based truth. We propose a state-of-the-art, transformer-based orbit propagator that outperforms traditional methods like SGP4, enabling cross-validation of multiple observations for a single RSO. This deep learning-based transformer model can be distributed over a blockchain, allowing interested parties to host a node that contains a part of the distributed deep learning model. Our system comprises decentralised observers and validators within a Proof of Stake (PoS) blockchain. Observers contribute TDM data along with a stake to ensure honesty, while validators run the propagation and validation algorithms. The system rewards observers for contributing verified TDMs and penalizes those submitting unverifiable data.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Prediction-Powered Inference from Decentralized Data</title>
<link>https://arxiv.org/abs/2409.01730</link>
<guid>https://arxiv.org/abs/2409.01730</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、辅助数据、数据隔离、联邦学习、预测增强推断

<br /><br />
总结:

本文探讨了机器学习领域中，通过辅助数据进行统计推断的新方法——预测增强推断(Prediction-Powered Inference, PPI)，特别是在面对私有金标准数据不可共享的情况。这种情况下，数据隔离导致模型精度降低，进而影响统计有效性。为解决这一问题，作者提出了一种名为联邦预测增强推断(Federated Prediction-Powered Inference, Fed-PPI)的框架。

Fed-PPI框架通过以下步骤实现目标：

1. **本地模型训练**：在私有数据上独立训练多个局部模型。
2. **联邦学习聚合**：通过联邦学习技术将这些局部模型聚合起来，以减少数据集中性风险并保持数据隐私。
3. **PPI计算**：基于聚合后的模型，使用预测增强推断方法来计算置信区间，从而得出有效的统计结论。

实验结果验证了Fed-PPI框架的有效性，能够生成准确的置信区间，即使在面临数据隔离和私有信息保护的情况下也能保证统计推断的可靠性。 <div>
arXiv:2409.01730v1 Announce Type: new 
Abstract: In various domains, the increasing application of machine learning allows researchers to access inexpensive predictive data, which can be utilized as auxiliary data for statistical inference. Although such data are often unreliable compared to gold-standard datasets, Prediction-Powered Inference (PPI) has been proposed to ensure statistical validity despite the unreliability. However, the challenge of `data silos' arises when the private gold-standard datasets are non-shareable for model training, leading to less accurate predictive models and invalid inferences. In this paper, we introduces the Federated Prediction-Powered Inference (Fed-PPI) framework, which addresses this challenge by enabling decentralized experimental data to contribute to statistically valid conclusions without sharing private information. The Fed-PPI framework involves training local models on private data, aggregating them through Federated Learning (FL), and deriving confidence intervals using PPI computation. The proposed framework is evaluated through experiments, demonstrating its effectiveness in producing valid confidence intervals.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DogeFuzz: A Simple Yet Efficient Grey-box Fuzzer for Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2409.01788</link>
<guid>https://arxiv.org/abs/2409.01788</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、智能合约、灰盒模糊测试、DogeFuzz、智能发现

总结:

本文介绍了一项关于以太坊（Ethereum）的研究，重点在于智能合约的模糊测试技术。研究发现，名为DogeFuzz的新型模糊测试框架在识别智能合约中的漏洞方面表现出色。DogeFuzz包括了黑盒模糊测试和两种灰盒模糊测试策略：基于覆盖率的灰盒模糊测试（DogeFuzz-G）和定向灰盒模糊测试（DogeFuzz-DG）。尽管DogeFuzz没有利用高级输入生成技术，如符号执行或机器学习，它仍然在性能上超过了sFuzz和ILF这两款最先进的智能合约模糊测试器。

研究还指出，Smartian模糊测试器在代码覆盖率和漏洞发现能力方面具有优势。然而，DogeFuzz在不依赖这些高级技术的情况下，仍能显著提升智能合约的漏洞检测效率，填补了现有研究中对简单灰盒模糊测试与更复杂方法比较的空白。这表明，即使在资源有限的情况下，设计合理的模糊测试策略也能有效提高智能合约的安全性。 <div>
arXiv:2409.01788v1 Announce Type: new 
Abstract: Ethereum is a distributed, peer-to-peer blockchain infrastructure that has attracted billions of dollars. Perhaps due to its success, Ethereum has become a target for various kinds of attacks, motivating researchers to explore different techniques to identify vulnerabilities in EVM bytecode (the language of the Ethereum Virtual Machine), including formal verification, symbolic execution, and fuzz testing. Although recent studies empirically compare smart contract fuzzers, there is a lack of literature investigating how simpler greybox fuzzers compare to more advanced ones. To fill this gap, in this paper, we present DogeFuzz, an extensible infrastructure for fuzzing Ethereum smart contracts, currently supporting black-box fuzzing and two grey-box fuzzing strategies: coverage-guided grey-box fuzzing (DogeFuzz-G) and directed grey-box fuzzing (DogeFuzz-DG). We conduct a series of experiments using benchmarks already available in the literature and compare the DogeFuzz strategies with state-of-the-art fuzzers for smart contracts. Surprisingly, although DogeFuzz does not leverage advanced techniques for improving input generation (such as symbolic execution or machine learning), DogeFuzz outperforms sFuzz and ILF, two state-of-the-art fuzzers. Nonetheless, the Smartian fuzzer shows higher code coverage and bug-finding capabilities than DogeFuzz.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strengthening Solidity Invariant Generation: From Post- to Pre-Deployment</title>
<link>https://arxiv.org/abs/2409.01804</link>
<guid>https://arxiv.org/abs/2409.01804</guid>
<content:encoded><![CDATA[
<div> 关键词：Solidity、智能合约、不变量生成、预部署、安全性

总结:
本文介绍了一种名为InvSol的新框架，专门用于为以Solidity语言编写的智能合约生成预部署不变量。与现有依赖于以太坊主网交易历史的工具如InvCon、InvCon+和Trace2Inv不同，InvSol在部署前就识别不变量，覆盖了Solidity语言的全部构造，包括循环，这在同类工具中是前所未有的。此外，InvSol引入了自定义模板来有效防止重入性、耗尽gas错误和异常等问题。

文章通过使用一组基准智能合约集对InvSol进行了严格评估，并将其性能与最先进的解决方案进行了比较。研究结果表明，InvSol在识别常见漏洞方面显著优于InvCon+，并能够利用特定不变量模板解决某些关键漏洞，超越了Trace2Inv。这些发现强调了InvSol在处理具有有限交易历史的新合同时的有效性和潜力，从而提高了智能合约的安全性和正确性。 <div>
arXiv:2409.01804v1 Announce Type: new 
Abstract: Invariants are essential for ensuring the security and correctness of Solidity smart contracts, particularly in the context of blockchain's immutability and decentralized execution. This paper introduces InvSol, a novel framework for pre-deployment invariant generation tailored specifically for Solidity smart contracts. Unlike existing solutions, namely InvCon, InvCon+, and Trace2Inv, that rely on post-deployment transaction histories on Ethereum mainnet, InvSol identifies invariants before deployment and offers comprehensive coverage of Solidity language constructs, including loops. Additionally, InvSol incorporates custom templates to effectively prevent critical issues such as reentrancy, out-of-gas errors, and exceptions during invariant generation. We rigorously evaluate InvSol using a benchmark set of smart contracts and compare its performance with state-of-the-art solutions. Our findings reveal that InvSol significantly outperforms these tools, demonstrating its effectiveness in handling new contracts with limited transaction histories. Notably, InvSol achieves a 15% improvement in identifying common vulnerabilities compared to InvCon+ and is able to address certain crucial vulnerabilities using specific invariant templates, better than Trace2Inv.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations</title>
<link>https://arxiv.org/abs/2409.01823</link>
<guid>https://arxiv.org/abs/2409.01823</guid>
<content:encoded><![CDATA[
<div> 关键词：DAOs、复杂系统、集体智能、数字民主、自组织机制

<br /><br />
总结:
本文探讨了去中心化自治组织（DAOs）作为复杂系统的特点及其面临的挑战。主要关键词包括DAOs、复杂系统、集体智能、数字民主和自组织机制。文章首先指出DAOs通过区块链和加密经济学从传统层级控制转向去中心化的转变，成功重塑了组织结构并管理着大量资金与全球网络。然而，随着参与度下降、中央集权趋势增加以及对环境变化适应能力的不足，DAOs面临着创新受阻的问题。

文章接着应用复杂科学理论来解释DAOs的效率问题，深入讨论了DAOs面临的挑战，强调其复杂性，并引入了集体智能、数字民主和自组织机制的概念。这些机制被视为改进DAO设计与构建的关键。基于这些机制，作者提出了一个实用的设计框架，旨在为DAOs的发展提供理论基础。这一贡献为复杂科学与DAOs交叉领域内的未来研究铺平了道路，期待未来能够进一步探索如何利用复杂科学原理优化DAOs的运作效率与创新能力。 <div>
arXiv:2409.01823v1 Announce Type: new 
Abstract: Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechansims to improve DAO design and construction, a practical design framework for DAOs is created. This contribution lays a foundation for future research at the intersection of complexity science and DAOs.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing Federated Learning in Robot Swarms using Blockchain Technology</title>
<link>https://arxiv.org/abs/2409.01900</link>
<guid>https://arxiv.org/abs/2409.01900</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、机器人集群、区块链技术、去中心化、智能合约

总结:
本文提出了一种基于区块链技术的联邦学习方案，旨在实现机器人集群中的去中心化模型训练。该方案利用区块链确保集群内的机器人能够安全同步共享模型，而无需依赖中央服务器。然而，研究发现单个故障机器人的介入会严重干扰训练过程。为解决这一问题，作者设计并实施了通过区块链智能合约实现的安全防篡改机制。实验使用ARGoS物理仿真平台和以太坊区块链协议进行，以模拟真实的机器人集群环境。

通过引入区块链技术，本文展示了联邦学习在机器人集群中应用的可能性以及面临的挑战。区块链不仅提供了数据安全与一致性保障，同时也揭示了系统对单点故障的敏感性。为此，开发的保护机制对于确保分布式训练过程的稳定性和可靠性至关重要。此研究为联邦学习在复杂、动态的机器人集群环境中的实际应用提供了理论依据和技术支撑。 <div>
arXiv:2409.01900v1 Announce Type: new 
Abstract: Federated learning is a new approach to distributed machine learning that offers potential advantages such as reducing communication requirements and distributing the costs of training algorithms. Therefore, it could hold great promise in swarm robotics applications. However, federated learning usually requires a centralized server for the aggregation of the models. In this paper, we present a proof-of-concept implementation of federated learning in a robot swarm that does not compromise decentralization. To do so, we use blockchain technology to enable our robot swarm to securely synchronize a shared model that is the aggregation of the individual models without relying on a central server. We then show that introducing a single malfunctioning robot can, however, heavily disrupt the training process. To prevent such situations, we devise protection mechanisms that are implemented through secure and tamper-proof blockchain smart contracts. Our experiments are conducted in ARGoS, a physics-based simulator for swarm robotics, using the Ethereum blockchain protocol which is executed by each simulated robot.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking ZK-Friendly Hash Functions and SNARK Proving Systems for EVM-compatible Blockchains</title>
<link>https://arxiv.org/abs/2409.01976</link>
<guid>https://arxiv.org/abs/2409.01976</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-Knowledge Proofs（ZKPs）、Succinct Non-Interactive Arguments of Knowledge（SNARKs）、ZK-friendly hash functions、Privacy-preserving transaction protocols、Ethereum Virtual Machine（EVM）

<br />
<br />总结:

本文研究了零知识证明（ZKPs）领域中的关键组件——特别是简洁非交互性知识论证（SNARKs）——以及与区块链相关的ZK友好哈希函数。随着ZK技术的发展，对各种ZK工具进行基准测试已成为一项有价值的任务。文章着重于评估这些算法在ZK电路中的表现，并通过“批处理”策略来优化成本效率，以解决区块链上的高成本和合规性问题。

文章首先对比了三种SNARK证明系统和五种ZK友好哈希函数的性能，包括自定义的Poseidon2、Neptune和GMiMC电路模板，这些均在bn254曲线的circom-snarkjs框架下进行了测试。此外，引入了一种名为“sequencer”的角色，以提高基于SNARK的隐私保护交易方案的效率，并支持灵活审计。通过实施和评估在以太坊虚拟机兼容链上，研究发现Poseidon和Poseidon2在Groth16下的证明生成阶段展现出更好的内存使用率和运行时间。与基线相比，Poseidon2不仅加快了证明生成速度，而且在以太坊虚拟机链上降低了73%的链上成本，在Hedera链上减少了约26%。

本文为ZK友好哈希函数和ZK工具提供了基准测试，同时也探索了在基于ZKP的隐私保护交易协议中实现成本效益和合规性的可能性。 <div>
arXiv:2409.01976v1 Announce Type: new 
Abstract: With the rapid development of Zero-Knowledge Proofs (ZKPs), particularly Succinct Non-Interactive Arguments of Knowledge (SNARKs), benchmarking various ZK tools has become a valuable task. ZK-friendly hash functions, as key algorithms in blockchain, have garnered significant attention. Therefore, comprehensive benchmarking and evaluations of these evolving algorithms in ZK circuits present both promising opportunities and challenges. Additionally, we focus on a popular ZKP application, privacy-preserving transaction protocols, aiming to leverage SNARKs' cost-efficiency through "batch processing" to address high on-chain costs and compliance issues.
  To this end, we benchmarked three SNARK proving systems and five ZK-friendly hash functions, including our self-developed circuit templates for Poseidon2, Neptune, and GMiMC, on the bn254 curve within the circom-snarkjs framework. We also introduced the role of "sequencer" in our SNARK-based privacy-preserving transaction scheme to enhance efficiency and enable flexible auditing. We conducted privacy and security analyses, as well as implementation and evaluation on Ethereum Virtual Machine (EVM)-compatible chains. The results indicate that Poseidon and Poseidon2 demonstrate superior memory usage and runtime during proof generation under Groth16. Moreover, compared to the baseline, Poseidon2 not only generates proofs faster but also reduces on-chain costs by 73% on EVM chains and nearly 26% on Hedera. Our work provides a benchmark for ZK-friendly hash functions and ZK tools, while also exploring cost efficiency and compliance in ZKP-based privacy-preserving transaction protocols.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SGP-RI: A Real-Time-Trainable and Decentralized IoT Indoor Localization Model Based on Sparse Gaussian Process with Reduced-Dimensional Inputs</title>
<link>https://arxiv.org/abs/2409.00078</link>
<guid>https://arxiv.org/abs/2409.00078</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网（IoT）、室内定位、去中心化、稀疏高斯过程、减少维度输入

总结:

本文提出了一种基于稀疏高斯过程与减少维度输入（SGP-RI）的去中心化物联网（IoT）室内定位模型。该模型通过实时训练，将传统室内定位方法中的离线和在线阶段结合在一起，旨在解决基于集中式服务器的传统室内定位方法所面临的挑战。这些挑战包括数据库无法适应动态多变的室内电磁环境、模型重新训练成本高昂以及集中式服务器容易遭受安全攻击。

SGP-RI模型利用参考点和无线接入点过滤技术减少输入数据的数量和维度，从而以远少于标准高斯过程模型所需训练样本数量的量进行训练，但仍能实现相当的定位性能。实验结果表明，使用SGP-RI模型，即使使用少量的诱导输入样本，也能达到与使用整个训练样本的标准高斯过程模型相媲美的定位效果。

此模型的引入使得室内定位能够分散到资源受限的物联网设备上，提供增强的安全性和隐私保护，降低成本和网络依赖性。同时，其实时训练能力使其能够快速适应不断变化的室内电磁环境。 <div>
arXiv:2409.00078v1 Announce Type: cross 
Abstract: Internet of Things (IoT) devices are deployed in the filed, there is an enormous amount of untapped potential in local computing on those IoT devices. Harnessing this potential for indoor localization, therefore, becomes an exciting research area. Conventionally, the training and deployment of indoor localization models are based on centralized servers with substantial computational resources. This centralized approach faces several challenges, including the database's inability to accommodate the dynamic and unpredictable nature of the indoor electromagnetic environment, the model retraining costs, and the susceptibility of centralized servers to security breaches. To mitigate these challenges we aim to amalgamate the offline and online phases of traditional indoor localization methods using a real-time-trainable and decentralized IoT indoor localization model based on Sparse Gaussian Process with Reduced-dimensional Inputs (SGP-RI), where the number and dimension of the input data are reduced through reference point and wireless access point filtering, respectively. The experimental results based on a multi-building and multi-floor static database as well as a single-building and single-floor dynamic database, demonstrate that the proposed SGP-RI model with less than half the training samples as inducing inputs can produce comparable localization performance to the standard Gaussian Process model with the whole training samples. The SGP-RI model enables the decentralization of indoor localization, facilitating its deployment to resource-constrained IoT devices, and thereby could provide enhanced security and privacy, reduced costs, and network dependency. Also, the model's capability of real-time training makes it possible to quickly adapt to the time-varying indoor electromagnetic environment.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Lightweight Human Pose Estimation Approach for Edge Computing-Enabled Metaverse with Compressive Sensing</title>
<link>https://arxiv.org/abs/2409.00087</link>
<guid>https://arxiv.org/abs/2409.00087</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘计算、5G/6G网络、深度学习、压缩感知、生成模型

总结:

本文探讨了在5G/6G等边缘计算网络中，通过无线方式估计用户3D移动能力的关键性，以支持扩展现实（XR）和元宇宙应用。深度学习技术在基于传感器信号（如集成式测量单元(IMU)）的3D人体姿态估计中显示出优于优化方法的优势。然而，现有研究未充分考虑无线系统中传输IMU信号的挑战，以及信号冗余问题导致的高能耗和资源浪费。

针对上述问题，本文提出了一种创新方法，旨在减少IMU信号的冗余并实现轻量级的无线传输。该方法利用随机高斯矩阵将原始信号投影到低维空间中，同时利用压缩感知理论确保在功率传输约束下，设计的高斯矩阵能够保持集限制特征值条件，从而有效降低信号维度而不丢失关键信息。接收端开发了一种深度生成模型，从噪声压缩数据中恢复原始IMU信号，进而实现对用户3D人体动作的创建，满足XR和元宇宙应用需求。

实验结果使用实际IMU数据集验证了方法的有效性，证明仅使用原始信号82%的测量数据，就能达到与优化方法（如Lasso）相当的3D人体姿态精度，但处理速度却快了一个数量级。这表明，本文提出的框架不仅提高了数据传输效率，还保证了精度，为未来XR和元宇宙的应用提供了有力支持。 <div>
arXiv:2409.00087v1 Announce Type: cross 
Abstract: The ability to estimate 3D movements of users over edge computing-enabled networks, such as 5G/6G networks, is a key enabler for the new era of extended reality (XR) and Metaverse applications. Recent advancements in deep learning have shown advantages over optimization techniques for estimating 3D human poses given spare measurements from sensor signals, i.e., inertial measurement unit (IMU) sensors attached to the XR devices. However, the existing works lack applicability to wireless systems, where transmitting the IMU signals over noisy wireless networks poses significant challenges. Furthermore, the potential redundancy of the IMU signals has not been considered, resulting in highly redundant transmissions. In this work, we propose a novel approach for redundancy removal and lightweight transmission of IMU signals over noisy wireless environments. Our approach utilizes a random Gaussian matrix to transform the original signal into a lower-dimensional space. By leveraging the compressive sensing theory, we have proved that the designed Gaussian matrix can project the signal into a lower-dimensional space and preserve the Set-Restricted Eigenvalue condition, subject to a power transmission constraint. Furthermore, we develop a deep generative model at the receiver to recover the original IMU signals from noisy compressed data, thus enabling the creation of 3D human body movements at the receiver for XR and Metaverse applications. Simulation results on a real-world IMU dataset show that our framework can achieve highly accurate 3D human poses of the user using only $82\%$ of the measurements from the original signals. This is comparable to an optimization-based approach, i.e., Lasso, but is an order of magnitude faster.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Double-Linked Blockchain Approach Based on Proof-of-Refundable-Tax Consensus Algorithm</title>
<link>https://arxiv.org/abs/2109.06520</link>
<guid>https://arxiv.org/abs/2109.06520</guid>
<content:encoded><![CDATA[
<div> 关键词：双链区块链、性能提升、单链结构、PoRT共识算法、可靠高效区块链操作

<br /><br />
总结:
本文提出了一种创新的双链区块链数据结构，旨在显著提升区块链性能并确保单一无分叉的链。通过引入“可退还税收证明”（PoRT）共识算法，该方案构建了高度可靠、高效、公平和稳定的区块链操作环境。PoRT算法利用可验证随机函数而非挖矿来选择未来区块维护者，其概率与参与者个人的可退还税收成正比，有效防止了Sybil攻击。同时，通过从维护者可退还税收中扣除区块完成奖励，该系统维持了财富分配的稳定，避免了“富者越富”的问题。研究团队已成功实现并测试了这一方法，结果非常乐观。 <div>
arXiv:2109.06520v2 Announce Type: replace 
Abstract: In this paper we propose a double-linked blockchain data structure that greatly improves blockchain performance and guarantees single chain with no forks. Additionally, with the proposed proof-of-refundable-tax (PoRT) consensus algorithm, our approach can construct highly reliable, efficient, fair and stable blockchain operations. The PoRT algorithm adopts a verifiable random function instead of mining to select future block maintainers with the probability proportional to each participant's personal refundable tax. The individual refundable tax serves as an index of the activeness of participation and hence PoRT can effectively prevent Sybil attacks. Also, with the block-completion reward deducted from each maintainer's refundable tax, our blockchain system maintains a stable wealth distribution and avoids the "rich become richer" problem. We have implemented the approach and tested with very promising results.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Token Spammers, Rug Pulls, and SniperBots: An Analysis of the Ecosystem of Tokens in Ethereum and in the Binance Smart Chain (BNB)</title>
<link>https://arxiv.org/abs/2206.08202</link>
<guid>https://arxiv.org/abs/2206.08202</guid>
<content:encoded><![CDATA[
<div> 关键词：BNB智能链、以太坊区块链、流动性池、1天拉盘、狙击机器人

总结:

本文对BNB智能链和以太坊区块链进行了纵向分析，从它们诞生到2022年3月。研究了两个区块链上的代币和流动性池生态系统，发现了显著的相似性和差异性。发现大约60%的代币活动时间少于一天，1%的地址创造了异常数量的代币（占比20%-25%）。这些代币被用于执行一种特定类型的拉盘操作，即“1天拉盘”。通过量化这两种操作在两个区块链上的存在，发现BNB智能链上的1天拉盘更为普遍，估计产生的利润约为2.4亿美元。此外，文章揭示了狙击机器人的存在及其在拉盘操作中的活动，这是一种新型交易机器人，参与了这些活动。 <div>
arXiv:2206.08202v3 Announce Type: replace 
Abstract: In this work, we perform a longitudinal analysis of the BNB Smart Chain and Ethereum blockchain from their inception to March 2022. We study the ecosystem of the tokens and liquidity pools, highlighting analogies and differences between the two blockchains. We discover that about 60% of tokens are active for less than one day. Moreover, we find that 1% of addresses create an anomalous number of tokens (between 20% and 25%). We discover that these tokens are used as disposable tokens to perform a particular type of rug pull, which we call 1-day rug pull. We quantify the presence of this operation on both blockchains discovering its prevalence on the BNB Smart Chain. We estimate that 1-day rug pulls generated $240 million in profits. Finally, we present sniper bots, a new kind of trader bot involved in these activities, and we detect their presence and quantify their activity in the rug pull operations.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Game of NFTs: Characterizing NFT Wash Trading in the Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2212.01225</link>
<guid>https://arxiv.org/abs/2212.01225</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币（NFT）、洗盘交易、市场操纵、Ethereum、虚拟货币市场

<br />
<br />总结:

文章分析了在以太坊区块链上非同质化代币（NFT）市场的洗盘交易现象，研究从市场启动到2022年1月的全时间段。主要发现包括：

1. **洗盘交易规模**：研究发现，洗盘交易影响了约5.66%的所有NFT集合，累计创造了价值340多亿美元的虚假交易量。

2. **盈利方式**：洗盘交易者通过两种方式获利：一是人为提高NFT价格，二是利用某些市场提供的代币奖励系统。后者被发现比单纯通过洗盘交易提高售价更赚钱、成功率更高且风险更低。

3. **市场影响**：该研究揭示了洗盘交易在以太坊NFT市场中的普遍性，并强调了需要采取措施防止此类非法行为，以保护市场秩序和投资者利益。

4. **市场响应**：鉴于洗盘交易对市场的影响，研究建议NFT市场管理方应实施预防机制，以打击这种市场操纵行为。

5. **结论与建议**：综上所述，研究不仅揭示了洗盘交易在以太坊NFT市场中的常见性，还提供了有关如何有效识别和防止这类活动的见解，为市场参与者和监管机构提供了重要的参考信息。 <div>
arXiv:2212.01225v3 Announce Type: replace 
Abstract: The Non-Fungible Token (NFT) market in the Ethereum blockchain experienced explosive growth in 2021, with a monthly trade volume reaching \$6 billion in January 2022. However, concerns have emerged about possible wash trading, a form of market manipulation in which one party repeatedly trades an NFT to inflate its volume artificially. Our research examines the effects of wash trading on the NFT market in Ethereum from the beginning until January 2022, using multiple approaches. We find that wash trading affects 5.66% of all NFT collections, with a total artificial volume of \$3,406,110,774. We look at two ways to profit from wash trading: Artificially increasing the price of the NFT and taking advantage of the token reward systems provided by some marketplaces. Our findings show that exploiting the token reward systems of NFTMs is much more profitable (mean gain of successful operations is \$1.055M on LooksRare), more likely to succeed (more than 80% of operations), and less risky than reselling an NFT at a higher price using wash trading (50% of activities result in a loss). Our research highlights that wash trading is frequent in Ethereum and that NFTMs should implement protective mechanisms to stop such illicit behavior.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Credible, Optimal Auctions via Public Broadcast</title>
<link>https://arxiv.org/abs/2301.12532</link>
<guid>https://arxiv.org/abs/2301.12532</guid>
<content:encoded><![CDATA[
<div> 关键词：拍卖设计、分散式通信、策略证明、可信度、强正相关性

<br /><br />
总结:

本文探讨了在去中心化的通信环境下设计拍卖机制的问题。主要关注于利用不可审查广播信道（如公共区块链）进行通信的场景。与传统机制设计框架不同的是，这里通信不是由拍卖人集中控制，而是通过分散式的渠道实现。这种模型允许设计出比传统框架下更广泛的可信拍卖机制，因为拍卖人无法删除、延迟或修改合法竞买者的信息，从而削弱了其操纵能力。

文章的主要贡献包括：

1. 提出了一种仅在通信分散的情况下才具有可信性的拍卖实例。
2. 构建了一个两轮的拍卖机制，该机制同时具备可信性、策略证明和当竞买者估值呈现$\alpha$-强正相关性（$\alpha > 0$）时达到最优性。
3. 实现这些结果的前提条件相对宽松，包括存在广播通道和加密承诺等基本假设。

通过这些研究成果，作者揭示了分散式通信在设计拍卖机制中的重要性和潜在优势，特别是在对抗可能存在的拍卖人策略行为方面。 <div>
arXiv:2301.12532v2 Announce Type: replace 
Abstract: We study auction design in a setting where agents can communicate over a censorship-resistant broadcast channel like the ones we can implement over a public blockchain. We seek to design credible, strategyproof auctions in a model that differs from the traditional mechanism design framework because communication is not centralized via the auctioneer. We prove this allows us to design a larger class of credible auctions where the auctioneer has no incentive to be strategic. Intuitively, a decentralized communication model weakens the auctioneer's adversarial capabilities because they can only inject messages into the communication channel but not delete, delay, or modify the messages from legitimate buyers. Our main result is a separation in the following sense: we give the first instance of an auction that is credible only if communication is decentralized. Moreover, we construct the first two-round auction that is credible, strategyproof, and optimal when bidder valuations are $\alpha$-strongly regular, for $\alpha > 0$. Our result relies on mild assumptions -- namely, the existence of a broadcast channel and cryptographic commitments.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revolutionizing Modern Networks: Advances in AI, Machine Learning, and Blockchain for Quantum Satellites and UAV-based Communication</title>
<link>https://arxiv.org/abs/2303.11753</link>
<guid>https://arxiv.org/abs/2303.11753</guid>
<content:encoded><![CDATA[
<div> 关键词：量子通信、卫星、无人机、区块链、人工智能

总结:
本文概述了量子卫星和基于无人机的量子网络的最新发展。量子通信作为当前最安全的数据传输技术，通过光纤通信线路和卫星到地面链接，已被用于构建最成功的量子网络。利用卫星或无人机进行自由空间量子通信，减少了对永久地面连接的需求，并利用太空中的较低损耗极限，提高了效率。

文章重点探讨了量子人工智能、区块链量子机器学习、量子卫星和量子无人机等最新技术在网络安全领域的应用，从网络视角进行了深入分析。同时，文中还讨论了基于卫星的图像和人工智能在现代网络技术中的作用，展示了这些技术如何相互融合，为量子网络的未来提供了新的可能性和解决方案。

综上所述，本文不仅介绍了量子通信技术的前沿进展，还强调了量子技术与人工智能、区块链等其他领域交叉融合的重要性，预示了量子网络在未来信息安全领域可能带来的革命性变化。 <div>
arXiv:2303.11753v3 Announce Type: replace 
Abstract: Quantum communication is the most secure technique of transmitting data available today. Fiber communication lines and satellite-to-ground links have served as the basis for the most successful quantum networks that have been developed so far. Using a UAV, satellite or both for free-space quantum communication reduces the need for permanent ground connections and takes advantage of the lower loss limit in space, which makes it more efficient. This work surveys the recent development in Quantum Satellites and Quantum UAVs-based networks. Here, the importance of the latest technologies, including quantum artificial intelligence, blockchain quantum machine learning, quantum satellites and quantum UAVs, are explored from network perspectives. Further, this work discussed the role of satellite-based images and artificial intelligence.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent-Agnostic Centralized Training for Decentralized Multi-Agent Cooperative Driving</title>
<link>https://arxiv.org/abs/2403.11914</link>
<guid>https://arxiv.org/abs/2403.11914</guid>
<content:encoded><![CDATA[
<div> 关键词：主动交通管理、自动驾驶车辆、无限时间框架、部分可观测性、分散式合作驾驶策略

<br /><br />
总结:本文提出了一种基于单个代理强化学习的不对称演员-评论家模型，用于学习自动驾驶车辆在真实世界场景下的分散式合作驾驶策略。该模型通过注意力神经网络与遮罩技术有效地处理了现实世界的交通动力学和部分可观测性问题，避免了多代理强化学习中预先定义的代理或特定于代理的经验缓冲的需求。在各种交通场景下的广泛评估显示了该方法在关键瓶颈点改善交通流的巨大潜力。此外，本文还探讨了保守的自动驾驶行为对遵守交通规则的挑战，并证明了我们的合作策略能够有效缓解潜在的减速情况，同时不牺牲安全性。 <div>
arXiv:2403.11914v2 Announce Type: replace 
Abstract: Active traffic management with autonomous vehicles offers the potential for reduced congestion and improved traffic flow. However, developing effective algorithms for real-world scenarios requires overcoming challenges related to infinite-horizon traffic flow and partial observability. To address these issues and further decentralize traffic management, we propose an asymmetric actor-critic model that learns decentralized cooperative driving policies for autonomous vehicles using single-agent reinforcement learning. By employing attention neural networks with masking, our approach efficiently manages real-world traffic dynamics and partial observability, eliminating the need for predefined agents or agent-specific experience buffers in multi-agent reinforcement learning. Extensive evaluations across various traffic scenarios demonstrate our method's significant potential in improving traffic flow at critical bottleneck points. Moreover, we address the challenges posed by conservative autonomous vehicle driving behaviors that adhere strictly to traffic rules, showing that our cooperative policy effectively alleviates potential slowdowns without compromising safety.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DIDChain: Advancing Supply Chain Data Management with Decentralized Identifiers and Blockchain</title>
<link>https://arxiv.org/abs/2406.11356</link>
<guid>https://arxiv.org/abs/2406.11356</guid>
<content:encoded><![CDATA[
<div> 关键词：DIDChain、区块链技术、Decentralized Identifiers、InterPlanetary File System、cheqd基础设施

总结:

本文介绍了一种名为DIDChain的框架，它利用区块链技术、去中心化标识符（Decentralized Identifiers）和星际文件系统（InterPlanetary File System）来解决供应链数据管理中面临的挑战，包括可追溯性、透明度和信任问题。DIDChain通过结合公共区块链的透明性和私有系统的控制能力，采用混合区块链架构，旨在保护供应链事件的真实性与可靠性，同时满足供应链参与者的数据隐私需求。

该框架的核心是cheqd基础设施，它能够追踪资产事件，如从奶牛场到奶酪制造商的原材料和产品的移动过程。通过整合区块链技术，DIDChain提供了解决数据孤岛和沟通障碍的解决方案，旨在推动各行业供应链基础设施的变革。此研究贡献在于展示了区块链增强的供应链系统中DIDChain的稳健性，证明了其作为改善供应链数据管理的有效工具。 <div>
arXiv:2406.11356v2 Announce Type: replace 
Abstract: Supply chain data management faces challenges in traceability, transparency, and trust. These issues stem from data silos and communication barriers. This research introduces DIDChain, a framework leveraging blockchain technology, Decentralized Identifiers, and the InterPlanetary File System. DIDChain improves supply chain data management. To address privacy concerns, DIDChain employs a hybrid blockchain architecture that combines public blockchain transparency with the control of private systems. Our hybrid approach preserves the authenticity and reliability of supply chain events. It also respects the data privacy requirements of the participants in the supply chain. Central to DIDChain is the cheqd infrastructure. The cheqd infrastructure enables digital tracing of asset events, such as an asset moving from the milk-producing dairy farm to the cheese manufacturer. In this research, assets are raw materials and products. The cheqd infrastructure ensures the traceability and reliability of assets in the management of supply chain data. Our contribution to blockchain-enabled supply chain systems demonstrates the robustness of DIDChain. Integrating blockchain technology through DIDChain offers a solution to data silos and communication barriers. With DIDChain, we propose a framework to transform the supply chain infrastructure across industries.
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Prototype Model of Zero-Trust Architecture Blockchain with EigenTrust-Based Practical Byzantine Fault Tolerance Protocol to Manage Decentralized Clinical Trials</title>
<link>https://arxiv.org/abs/2408.16885</link>
<guid>https://arxiv.org/abs/2408.16885</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19、临床试验、区块链技术、零信任架构、物联网

总结:

本文探讨了COVID-19大流行背景下，为应对患者保留、加速试验进程、提高数据可访问性、促进虚拟护理以及实现无缝通信的需求，临床试验转向了去中心化模式。然而，这种模式在集成系统时，可能会导致临床数据面临安全威胁，如信息被盗取、协议偏离及监控困难等问题。为解决这些问题，文章提出利用区块链技术构建一个名为“零信任架构区块链”(Zero-Trust Architecture Blockchain, z-TAB)的原型模型，旨在安全整合患者生成的临床试验数据。通过结合基于EigenTrust的实用拜占庭容错(T-PBFT)算法和Hyperledger Fabric作为共识机制，以及集成物联网(IoT)设备以优化区块链平台内部各利益相关者的数据处理流程，该模型旨在提供一个高效、安全的临床试验管理框架。通过详细评估，验证了系统的质量与性能。 <div>
arXiv:2408.16885v1 Announce Type: new 
Abstract: The COVID-19 pandemic necessitated the emergence of decentralized Clinical Trials (DCTs) due to patient retention, accelerate trials, improve data accessibility, enable virtual care, and facilitate seamless communication through integrated systems. However, integrating systems in DCTs exposes clinical data to potential security threats, making them susceptible to theft at any stage, a high risk of protocol deviations, and monitoring issues. To mitigate these challenges, blockchain technology serves as a secure framework, acting as a decentralized ledger, creating an immutable environment by establishing a zero-trust architecture, where data are deemed untrusted until verified. In combination with Internet of Things (IoT)-enabled wearable devices, blockchain secures the transfer of clinical trial data on private blockchains during DCT automation and operations. This paper proposes a prototype model of the Zero-Trust Architecture Blockchain (z-TAB) to integrate patient-generated clinical trial data during DCT operation management. The EigenTrust-based Practical Byzantine Fault Tolerance (T-PBFT) algorithm has been incorporated as a consensus protocol, leveraging Hyperledger Fabric. Furthermore, the Internet of Things (IoT) has been integrated to streamline data processing among stakeholders within the blockchain platforms. Rigorous evaluation has been done to evaluate the quality of the system.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SPOQchain: Platform for Secure, Scalable, and Privacy-Preserving Supply Chain Tracing and Counterfeit Protection</title>
<link>https://arxiv.org/abs/2408.17049</link>
<guid>https://arxiv.org/abs/2408.17049</guid>
<content:encoded><![CDATA[
<div> 关键词：SPOQchain、区块链、产品生命周期追踪、隐私保护、效率优化

总结:

本文提出了一种名为SPOQchain的新型区块链平台，旨在提供全面的产品生命周期追踪和原创性验证服务，同时确保高效率和用户隐私。SPOQchain通过采用一种精巧的批量处理机制来消除生命周期中的重复信息，从而提高了整体效率。不同于现有系统可能对隐私造成损害并影响可扩展性的做法，SPOQchain特别关注隐私和安全性问题，并提供了全面的分析，证明了其在供应链追踪领域的未来潜力。

文章指出，当前的供应链追踪系统主要依赖于区块链技术，但较少利用安全标识如物理不可克隆功能（PUFs）。此外，公开个体产品数据的系统在透明度与规模性和用户隐私之间存在冲突。为解决这些问题，SPOQchain不仅强调了区块链在确保数据完整性和不可篡改性方面的优势，还着重于通过创新机制提升效率，并采取措施保护用户隐私。

通过成功评估SPOQchain的可扩展性，研究团队展示了该平台在应对未来供应链追踪需求方面的适应性和可靠性。这一工作不仅为供应链管理领域引入了新的解决方案，也为后续研究提供了有价值的参考点，特别是在隐私保护和效率优化方面。 <div>
arXiv:2408.17049v1 Announce Type: new 
Abstract: Product lifecycle tracing is increasingly in the focus of regulators and producers, as shown with the initiative of the Digital Product Pass. Likewise, new methods of counterfeit detection are developed that are, e.g., based on Physical Unclonable Functions (PUFs). In order to ensure trust and integrity of product lifecycle data, multiple existing supply chain tracing systems are built on blockchain technology. However, only few solutions employ secure identifiers such as PUFs. Furthermore, existing systems that publish the data of individual products, in part fully transparently, have a detrimental impact on scalability and the privacy of users. This work proposes SPOQchain, a novel blockchain-based platform that provides comprehensive lifecycle traceability and originality verification while ensuring high efficiency and user privacy. The improved efficiency is achieved by a sophisticated batching mechanism that removes lifecycle redundancies. In addition to the successful evaluation of SPOQchain's scalability, this work provides a comprehensive analysis of privacy and security aspects, demonstrating the need and qualification of SPOQchain for the future of supply chain tracing.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition</title>
<link>https://arxiv.org/abs/2408.17090</link>
<guid>https://arxiv.org/abs/2408.17090</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Variational Autoencoders（VAEs）、非IID数据、FissionVAE、生成质量

总结:
本文研究了联邦学习在非独立同分布（non-IID）数据环境下的应用，特别是针对不同类别的图像。通过引入一种名为FissionVAE的新方法，该文提出了解决非IID数据带来的挑战，尤其是保持一致的潜在空间和避免不同纹理特征的本地生成器在聚合过程中混合的问题。FissionVAE通过分解潜在空间并为每个客户端群体构建定制的解码分支，实现了与各群体独特数据分布相匹配的学习。此外，文章还探讨了层次化VAE架构的应用，并展示了在FissionVAE中使用异构解码架构的可能性。为了评估该方法的效果，作者创建了两个复合数据集，包括混合的MNIST和FashionMNIST数据以及不同类型的RGB图像。实验结果显示，FissionVAE在这些数据集上的生成质量显著优于传统的联邦VAE模型。

通过将数据集分为多个类别并设计相应的解码分支，FissionVAE能够更好地适应不同数据分布的特点，从而提高生成图像的质量。这种方法不仅适用于非IID数据环境，还能增强联邦学习在复杂多样的图像生成任务中的应用能力。 <div>
arXiv:2408.17090v1 Announce Type: new 
Abstract: Federated learning is a machine learning paradigm that enables decentralized clients to collaboratively learn a shared model while keeping all the training data local. While considerable research has focused on federated image generation, particularly Generative Adversarial Networks, Variational Autoencoders have received less attention. In this paper, we address the challenges of non-IID (independently and identically distributed) data environments featuring multiple groups of images of different types. Specifically, heterogeneous data distributions can lead to difficulties in maintaining a consistent latent space and can also result in local generators with disparate texture features being blended during aggregation. We introduce a novel approach, FissionVAE, which decomposes the latent space and constructs decoder branches tailored to individual client groups. This method allows for customized learning that aligns with the unique data distributions of each group. Additionally, we investigate the incorporation of hierarchical VAE architectures and demonstrate the use of heterogeneous decoder architectures within our model. We also explore strategies for setting the latent prior distributions to enhance the decomposition process. To evaluate our approach, we assemble two composite datasets: the first combines MNIST and FashionMNIST; the second comprises RGB datasets of cartoon and human faces, wild animals, marine vessels, and remote sensing images of Earth. Our experiments demonstrate that FissionVAE greatly improves generation quality on these datasets compared to baseline federated VAE models.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Traceable AI-driven Avatars Using Multi-factors of Physical World and Metaverse</title>
<link>https://arxiv.org/abs/2408.17121</link>
<guid>https://arxiv.org/abs/2408.17121</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、AI模型、身份认证、代理签名、虚拟-物理可追溯性

<br /><br />
总结:本文提出了一种结合多因素的身份认证方法，旨在确保AI驱动的化身与其原始操作者的可追溯性。首先，构建用户身份模型，融合操纵者虹膜特征和AI代理的公钥，以确保AI驱动的化身与原操纵者关联。其次，引入一种支持原始操作者将签名能力委托给AI代理的雪人代理签名方案。最后，设计基于身份模型和雪人代理签名的三种认证协议，确保包括人类驱动和AI驱动化身在内的虚拟到物理的可追溯性。安全分析显示，该签名方案具有不可伪造性，认证方法能够抵御虚假指控。广泛的评估表明，设计的认证协议能够在约1秒内完成用户登录、化身委托、相互认证和化身追踪等操作，满足实际应用需求，并有助于减轻由AI驱动的化身引发的假冒攻击。 <div>
arXiv:2408.17121v1 Announce Type: new 
Abstract: Metaverse allows users to delegate their AI models to an AI engine, which builds corresponding AI-driven avatars to provide immersive experience for other users. Since current authentication methods mainly focus on human-driven avatars and ignore the traceability of AI-driven avatars, attackers may delegate the AI models of a target user to an AI proxy program to perform impersonation attacks without worrying about being detected.
  In this paper, we propose an authentication method using multi-factors to guarantee the traceability of AI-driven avatars. Firstly, we construct a user's identity model combining the manipulator's iris feature and the AI proxy's public key to ensure that an AI-driven avatar is associated with its original manipulator. Secondly, we propose a chameleon proxy signature scheme that supports the original manipulator to delegate his/her signing ability to an AI proxy. Finally, we design three authentication protocols for avatars based on the identity model and the chameleon proxy signature to guarantee the virtual-to-physical traceability including both the human-driven and AI-driven avatars.
  Security analysis shows that the proposed signature scheme is unforgeability and the authentication method is able to defend against false accusation. Extensive evaluations show that the designed authentication protocols complete user login, avatar delegation, mutual authentication, and avatar tracing in about 1s, meeting the actual application needs and helping to mitigate impersonation attacks by AI-driven avatars.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Traversal Queries of Sensor Data Using a Rule-Based Reachability Approach</title>
<link>https://arxiv.org/abs/2408.17157</link>
<guid>https://arxiv.org/abs/2408.17157</guid>
<content:encoded><![CDATA[
<div> 关键词：链接遍历查询、完整性、执行时间、超媒体控制词汇、链接修剪

总结:

本文主要探讨了链接遍历查询中的挑战，特别是由于网络规模导致的不完整性和长时间执行问题。传统的解决方法通过可达性标准来定义完整性，限制查询引擎遵循的链接数量，但这并未解决根本问题——即需要处理的链接数量仍然庞大。文章提出了一种基于规则的可达性标准，该标准能够捕捉链接数据文档中表示的逻辑语句，从而帮助精简无关的资源来源。

该策略通过修改Comunica链接遍历引擎，使其能够从超媒体控制词汇中获取提示，进一步优化链接修剪过程。实验结果表明，采用这种方法可以显著减少HTTP请求次数和查询执行时间，同时不影响结果的完整性。这表明研究链接修剪中对超媒体控制的利用，对于优化未索引的去中心化数据库的网络查询具有重要意义。 <div>
arXiv:2408.17157v1 Announce Type: new 
Abstract: Link Traversal queries face challenges in completeness and long execution time due to the size of the web. Reachability criteria define completeness by restricting the links followed by engines. However, the number of links to dereference remains the bottleneck of the approach. Web environments often have structures exploitable by query engines to prune irrelevant sources. Current criteria rely on using information from the query definition and predefined predicate. However, it is difficult to use them to traverse environments where logical expressions indicate the location of resources. We propose to use a rule-based reachability criterion that captures logical statements expressed in hypermedia descriptions within linked data documents to prune irrelevant sources. In this poster paper, we show how the Comunica link traversal engine is modified to take hints from a hypermedia control vocabulary, to prune irrelevant sources. Our preliminary findings show that by using this strategy, the query engine can significantly reduce the number of HTTP requests and the query execution time without sacrificing the completeness of results. Our work shows that the investigation of hypermedia controls in link pruning of traversal queries is a worthy effort for optimizing web queries of unindexed decentralized databases.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Blockchain and ANFIS for Optimal Supply Chain Management</title>
<link>https://arxiv.org/abs/2408.17161</link>
<guid>https://arxiv.org/abs/2408.17161</guid>
<content:encoded><![CDATA[
<div> 关键词：供应链、多目标优化、神经模糊推理系统（ANFIS）、去中心化金融（DeFi）、物联网（IoT）

<br /><br />
总结:
本文探讨了供应链管理中的风险与不确定性，强调了提高供应链灵活性的重要性。文章以家禽供应链为例，阐述了定制服务的发展如何推动制造业转向提供个性化产品。为确保数据安全和成本透明度，提出了结合区块链、物联网和多签去中心化金融协议的解决方案。面对诸如零售商送货时间、补货周期和订单需求量等不确定因素，研究采用了神经模糊推理系统（ANFIS），将神经网络与模糊逻辑相结合，以适应数据不足的情况。通过MATLAB仿真，研究分析了平均店铺配送时间、补货周期和每订单商品数量的变化。实施提议的技术后，平均配送时间从40分钟减少到37分钟，补货周期从5天缩短至4天，每订单商品数量从6件增加到11件。此外，ANFIS模型相较于传统系统的交易时间减少了15%，提升了供应链的实时响应能力和透明度，有效解决了运营问题。 <div>
arXiv:2408.17161v1 Announce Type: new 
Abstract: The supply chain is a critical segment of the product manufacturing cycle, continuously influenced by risky, uncertain, and undesirable events. Optimizing flexibility in the supply chain presents a complex, multi-objective, and nonlinear programming challenge. In the poultry supply chain, the development of mass customization capabilities has led manufacturing companies to increasingly focus on offering tailored and customized services for individual products. To safeguard against data tampering and ensure the integrity of setup costs and overall profitability, a multi-signature decentralized finance (DeFi) protocol, integrated with the IoT on a blockchain platform, is proposed. Managing the poultry supply chain involves uncertainties that may not account for parameters such as delivery time to retailers, reorder time, and the number of requested products. To address these challenges, this study employs an adaptive neuro-fuzzy inference system (ANFIS), combining neural networks with fuzzy logic to compensate for the lack of data training in parameter identification. Through MATLAB simulations, the study investigates the average shop delivery duration, the reorder time, and the number of products per order. By implementing the proposed technique, the average delivery time decreases from 40 to 37 minutes, the reorder time decreases from five to four days, and the quantity of items requested per order grows from six to eleven. Additionally, the ANFIS model enhances overall supply chain performance by reducing transaction times by 15\% compared to conventional systems, thereby improving real-time responsiveness and boosting transparency in supply chain operations, effectively resolving operational issues.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Ownership Management and Transfer of Consumer Internet of Things Devices with Self-sovereign Identity</title>
<link>https://arxiv.org/abs/2408.17184</link>
<guid>https://arxiv.org/abs/2408.17184</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、自主权身份（SSI）、区块链技术、去中心化标识符（DID）、可验证凭证（VC）

总结:
本文提出了一种基于自主权身份（SSI）的系统，旨在解决消费者物联网设备的身份管理和所有权转移问题。该系统利用了区块链、去中心化标识符（DID）、可验证凭证（VC）等新兴技术。通过威胁模型和需求分析，构建了系统的架构，并基于此系统设计了一个概念验证。文中详细阐述了几种应用场景及其协议流程，并使用ProVerif这一先进的协议验证工具进行了安全分析，同时评估了系统的性能。该系统旨在提供一种用户为中心、安全高效的身份管理和所有权转移机制，通过结合SSI的核心理念，实现物联网设备的自主控制与管理，从而提升用户体验和数据安全性。 <div>
arXiv:2408.17184v1 Announce Type: new 
Abstract: The popularity of the Internet of Things (IoT) has driven its usage in our homes and industries over the past 10-12 years. However, there have been some major issues related to identity management and ownership transfer involving IoT devices, particularly for consumer IoT devices, e. g. smart appliances such as smart TVs, smart refrigerators, and so on. There have been a few attempts to address this issue; however, user-centric and effective ownership and identity management of IoT devices have not been very successful so far. Recently, blockchain technology has been used to address these issues with limited success. This article presents a Self-sovereign Identity (SSI) based system that facilitates a secure and user-centric ownership management and transfer of consumer IoT devices. The system leverages a number of emerging technologies, such as blockchain and decentralized identifiers (DID), verifiable credentials (VC), under the umbrella of SSI. We present the architecture of the system based on a threat model and requirement analysis, discuss the implementation of a Proof-of-Concept based on the proposed system and illustrate a number of use-cases with their detailed protocol flows. Furthermore, we analyse its security using ProVerif, a state-of-the art protocol verification tool and examine its performance.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Graph Neural Networks to Forecast Electricity Consumption</title>
<link>https://arxiv.org/abs/2408.17366</link>
<guid>https://arxiv.org/abs/2408.17366</guid>
<content:encoded><![CDATA[
<div> 关键词：电力需求预测、图表示、分布式网络、模型性能、解释性

总结:
本文提出了一种基于图表示的电力需求预测方法，旨在解决分布式网络环境下电力需求预测的复杂性和不确定性问题。该方法通过利用图神经网络（如Graph Convolutional Networks或Graph SAGE）来捕捉网络中的空间分布和关系细节，这超越了传统的广义加性模型框架。每个节点代表一组消费者（例如国家的地区）的总消耗量。

研究工作包括开发一系列方法以定制适用于消费预测的图结构，并提供了一个评估模型性能和可解释性的框架。实验在合成数据集和法国大陆地区的实际数据集上进行，展示了所提出方法的性能和优点。

主要贡献在于：
1. 提出了一种基于图结构的电力需求预测模型，适应分布式网络环境。
2. 开发了定制化图结构的方法，以提高预测精度。
3. 设计了性能和可解释性评估框架，增强模型实用性。
4. 在合成数据和真实数据上验证了方法的有效性。
5. 展示了在电力消费预测领域的应用潜力，特别是考虑可再生能源和分散网络转型背景下的挑战。 <div>
arXiv:2408.17366v1 Announce Type: new 
Abstract: Accurate electricity demand forecasting is essential for several reasons, especially as the integration of renewable energy sources and the transition to a decentralized network paradigm introduce greater complexity and uncertainty. The proposed methodology leverages graph-based representations to effectively capture the spatial distribution and relational intricacies inherent in this decentralized network structure. This research work offers a novel approach that extends beyond the conventional Generalized Additive Model framework by considering models like Graph Convolutional Networks or Graph SAGE. These graph-based models enable the incorporation of various levels of interconnectedness and information sharing among nodes, where each node corresponds to the combined load (i.e. consumption) of a subset of consumers (e.g. the regions of a country). More specifically, we introduce a range of methods for inferring graphs tailored to consumption forecasting, along with a framework for evaluating the developed models in terms of both performance and explainability. We conduct experiments on electricity forecasting, in both a synthetic and a real framework considering the French mainland regions, and the performance and merits of our approach are discussed.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Framework for Digital Asset Risks with Insurance Applications</title>
<link>https://arxiv.org/abs/2408.17227</link>
<guid>https://arxiv.org/abs/2408.17227</guid>
<content:encoded><![CDATA[
<div> 关键词：数字资产、保险、量化模型、区块链技术、风险管理

总结:

本文旨在为精算师提供理解并量化数字资产生态系统中所面临颠覆性技术风险的框架。文章首先概述了自2009年比特币诞生以来，数字资产市场的惊人增长，达到1万亿美元市值，反映了全球对数字资产的巨大需求与兴趣。

### 1. **教育与理解**  
文章通过深入探讨区块链技术及其相关风险，提供了关于数字资产生态系统的清晰教育，帮助精算师和行业参与者理解这个快速发展的领域所涉及的各种风险。

### 2. **量化框架**  
提出了一种科学严谨的量化方法，用于在数字资产保险组合中度量和模型化网络安全风险。这包括基于实际损失数据开发频率-严重性模型以及利用蒙特卡洛模拟估算尾部风险，为风险管理策略提供实用见解。

### 3. **定价策略**  
基于所提出的量化模型，文章提供了针对数字资产中网络风险定价的策略，这在数字资产持续重塑金融领域的大背景下显得尤为重要。

### 4. **系统性和微观视角**  
强调了从系统性和微观层面增强对网络安全风险的理解的重要性，不仅关注个体资产的风险，也考虑整个数字资产生态系统可能面临的系统性风险。

### 5. **风险管理与策略**  
最后，文章提供了风险管理和尾部风险控制的具体应用，帮助行业应对不断变化的数字资产市场带来的挑战，确保其稳定性和完整性。

通过这一综合性的研究框架，文章为数字资产领域的风险管理提供了坚实的基础，为未来的保险策略和风险控制提供了指导。 <div>
arXiv:2408.17227v1 Announce Type: cross 
Abstract: The remarkable growth of digital assets, starting from the inception of Bitcoin in 2009 into a 1 trillion market in 2024, underscores the momentum behind disruptive technologies and the global appetite for digital assets. This paper develops a framework to enhance actuaries' understanding of the cyber risks associated with the developing digital asset ecosystem, as well as their measurement methods in the context of digital asset insurance. By integrating actuarial perspectives, we aim to enhance understanding and modeling of cyber risks at both the micro and systemic levels. The qualitative examination sheds light on blockchain technology and its associated risks, while our quantitative framework offers a rigorous approach to modeling cyber risks in digital asset insurance portfolios. This multifaceted approach serves three primary objectives: i) offer a clear and accessible education on the evolving digital asset ecosystem and the diverse spectrum of cyber risks it entails; ii) develop a scientifically rigorous framework for quantifying cyber risks in the digital asset ecosystem; iii) provide practical applications, including pricing strategies and tail risk management. Particularly, we develop frequency-severity models based on real loss data for pricing cyber risks in digit assets and utilize Monte Carlo simulation to estimate the tail risks, offering practical insights for risk management strategies. As digital assets continue to reshape finance, our work serves as a foundational step towards safeguarding the integrity and stability of this rapidly evolving landscape.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Integer Linear Programming Model for Earth Observation Missions</title>
<link>https://arxiv.org/abs/2408.17288</link>
<guid>https://arxiv.org/abs/2408.17288</guid>
<content:encoded><![CDATA[
<div> 关键词：优化问题、卫星观测任务规划、分散决策、数学建模、时间变化通信图

总结:
本文探讨了卫星观测任务规划中的优化问题，特别关注于卫星间的分散决策挑战，这对于动态观测环境下的策略优化至关重要。研究通过整合数学建模方法（特别是整数规划）和时间变化通信图来解决这一问题，旨在实现高效的任务调度。文中采用分布式拉格朗日松弛技术以应对问题的复杂性。为了验证方法的有效性，进行了数值模拟实验，以探讨其在处理复杂卫星操作和不断变化的通信动态时的可行性。这种方法为卫星观测任务的规划提供了新的视角，有助于提高任务执行效率和资源利用效果。 <div>
arXiv:2408.17288v1 Announce Type: cross 
Abstract: This paper addresses an optimization problem in satellite observation mission planning, focusing on the challenges of decentralized decision-making among satellites, which is crucial for optimizing strategies in dynamic observation environments. The method integrates mathematical modeling using integer programming and time-varying communication graphs, which are essential for efficient task scheduling. Specifically, the approach utilizes distributed Lagrangian relaxation techniques to manage the complexity of the problem. Numerical simulations are conducted to explore the feasibility of the proposed approach for handling complex satellite operations under evolving communication dynamics.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedAgg: Adaptive Federated Learning with Aggregated Gradients</title>
<link>https://arxiv.org/abs/2303.15799</link>
<guid>https://arxiv.org/abs/2303.15799</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、非独立同分布数据、模型收敛率、隐私泄漏、自适应学习率

总结:

本文主要探讨了Federated Learning（FL）领域的一个关键问题——如何在保证模型性能的同时，提高在非独立同分布数据下的模型收敛率，并减少隐私泄漏的风险。针对这一挑战，作者提出了FedAgg算法，一种通过改进传统的随机梯度下降方法来实现的自适应Federated学习策略。

首先，FedAgg算法引入了聚合梯度的概念，旨在减少本地模型参数与全局平均模型之间的差异，从而加速模型的收敛过程。同时，该算法通过动态调整学习率，进一步优化了训练效率，使得模型能够更快速地达到最优解。

其次，考虑到在FL中信息交换可能导致的数据泄露风险，作者设计了两个平均场项，用于近似计算每个客户端在不同时间点的平均局部参数和梯度。这不仅有助于减轻信息交换对隐私的影响，还为每个客户端提供了一个自适应的学习率，使系统能够根据当前状态灵活调整训练速度。

最后，理论分析表明，FedAgg算法在理论上是可行的，其收敛性得到了证明，并给出了一个关于算法收敛速度的上界。实验结果则验证了该算法在同分布和非同分布数据集上的有效性，相较于现有的先进FL策略，FedAgg算法在提升模型性能和加快收敛速度方面表现出明显优势。 <div>
arXiv:2303.15799v5 Announce Type: replace 
Abstract: Federated Learning (FL) has emerged as a crucial distributed training paradigm, enabling discrete devices to collaboratively train a shared model under the coordination of a central server, while leveraging their locally stored private data. Nonetheless, the non-independent-and-identically-distributed (Non-IID) data generated on heterogeneous clients and the incessant information exchange among participants may significantly impede training efficacy, retard the model convergence rate and increase the risk of privacy leakage. To alleviate the divergence between the local and average model parameters and obtain a fast model convergence rate, we propose an adaptive FEDerated learning algorithm called FedAgg by refining the conventional stochastic gradient descent (SGD) methodology with an AGgregated Gradient term at each local training epoch and adaptively adjusting the learning rate based on a penalty term that quantifies the local model deviation. To tackle the challenge of information exchange among clients during local training and design a decentralized adaptive learning rate for each client, we introduce two mean-field terms to approximate the average local parameters and gradients over time. Through rigorous theoretical analysis, we demonstrate the existence and convergence of the mean-field terms and provide a robust upper bound on the convergence of our proposed algorithm. The extensive experimental results on real-world datasets substantiate the superiority of our framework in comparison with existing state-of-the-art FL strategies for enhancing model performance and accelerating convergence rate under IID and Non-IID datasets.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Elevator: Self-* and Persistent Hub Sampling Service in Unstructured Peer-to-Peer Networks</title>
<link>https://arxiv.org/abs/2406.07946</link>
<guid>https://arxiv.org/abs/2406.07946</guid>
<content:encoded><![CDATA[
<div> 关键词：Elevator算法、peer-to-peer网络、hub采样、拓扑结构、网络鲁棒性

<br /><br />
总结: 

文章介绍了Elevator算法，这是一种创新的去中心化网络中hub采样的方法。该算法基于偏好附着原理，能够自发形成hub节点，从而构建具有低直径和高鲁棒性的网络拓扑结构。它特别适用于需要同时具备低延迟通信和对故障有良好抵抗能力的网络应用。通过Elevator算法，可以构造出随机图与星形网络之间的拓扑关系，以及具有hub特性和抗故障能力的网络结构，为各种依赖高效和可靠连接的应用提供了基础。此算法不仅简化了网络构建过程，还提高了网络的整体性能和稳定性。 <div>
arXiv:2406.07946v2 Announce Type: replace 
Abstract: We present Elevator, a novel algorithm for hub samplingin peer-to-peer networks, enabling the construction of overlays with atopology between a random graph and a star network, and networksthat have both hubs and are resilient to failures. Our approach emergesfrom principles of preferential attachment, forming hubs spontaneously,offering an innovative solution for decentralized networks that can benefituse cases requiring a network with both low diameter and resilience tofailures.
]]></content:encoded>
<pubDate>Mon, 02 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Monadring: A lightweight consensus protocol to offer Validation-as-a-Service to AVS nodes</title>
<link>https://arxiv.org/abs/2408.16094</link>
<guid>https://arxiv.org/abs/2408.16094</guid>
<content:encoded><![CDATA[
<div> 关键词：Monadring、共识协议、小型子网络、Verifiable Random Function、全同态加密

总结:
本文提出了一种名为Monadring的轻量级共识协议，旨在解决现有区块链网络中的大规模同步问题以及高昂的链上计算成本。Monadring通过构建小型子网络，允许网络中的节点进行更快、更经济的计算，同时保持主区块链网络的安全性。为了进一步增强Monadring的安全性，引入了基于可验证随机函数（VRF）和全同态加密（FHE）的节点轮转机制。这一机制通过隐藏投票信息，消除了投票过程中的“最后行动优势”，不同于传统的基于投票选举验证节点的方法。

研究详细阐述了Monadring协议的设计与实现，并通过模拟实验评估其性能和可行性。本研究为提升区块链技术在大规模应用场景中的实用性做出了贡献，特别是在提高计算效率和增强安全性方面提供了新的思路。 <div>
arXiv:2408.16094v1 Announce Type: new 
Abstract: Existing blockchain networks are often large-scale, requiring transactions to be synchronized across the entire network to reach consensus. On-chain computations can be prohibitively expensive, making many CPU-intensive computations infeasible. Inspired by the structure of IBM's token ring networks, we propose a lightweight consensus protocol called Monadring to address these issues. Monadring allows nodes within a large blockchain network to form smaller subnetworks, enabling faster and more cost-effective computations while maintaining the security guarantees of the main blockchain network.
  To further enhance Monadring's security, we introduce a node rotation mechanism based on Verifiable Random Function (VRF) and blind voting using Fully Homomorphic Encryption (FHE) within the smaller subnetwork. Unlike the common voting-based election of validator nodes, Monadring leverages FHE to conceal voting information, eliminating the advantage of the last mover in the voting process.
  This paper details the design and implementation of the Monadring protocol and evaluates its performance and feasibility through simulation experiments. Our research contributes to enhancing the practical utility of blockchain technology in large-scale application scenarios.
]]></content:encoded>
<pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intrinsic Action Tendency Consistency for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2406.18152</link>
<guid>https://arxiv.org/abs/2406.18152</guid>
<content:encoded><![CDATA[
<div> 关键词：合作多智能体系统、集中训练、分散执行、行动倾向一致性、奖励增强集中训练

总结:

本文聚焦于合作多智能体系统中的集中训练与分散执行（CTDE）模式，指出该模式下智能体间行动分歧是提高训练效率的主要障碍。这种分歧源于智能体在CTDE过程中的信用分配阶段缺乏足够的团队共识相关指导信号。为解决这一问题，作者提出了一种名为“内在行动倾向一致性”的新方法，用于协同多智能体强化学习。

内在行动倾向一致性方法通过构建一种动作模型，使周围智能体能够预测中央智能体的动作倾向。基于这些预测，计算合作内在奖励，激励智能体与其邻居的预测相匹配。通过理论分析，证明了RA-CTDE与CTDE之间的等价性，即CTDE的训练过程可以用各智能体的个人目标来实现。在此基础上，引入了一种结合内在奖励和CTDE的新方法。

实验结果在SMAC和GRF基准任务上展示了该方法的性能提升，验证了其在复杂任务中的有效性。 <div>
arXiv:2406.18152v2 Announce Type: replace 
Abstract: Efficient collaboration in the centralized training with decentralized execution (CTDE) paradigm remains a challenge in cooperative multi-agent systems. We identify divergent action tendencies among agents as a significant obstacle to CTDE's training efficiency, requiring a large number of training samples to achieve a unified consensus on agents' policies. This divergence stems from the lack of adequate team consensus-related guidance signals during credit assignments in CTDE. To address this, we propose Intrinsic Action Tendency Consistency, a novel approach for cooperative multi-agent reinforcement learning. It integrates intrinsic rewards, obtained through an action model, into a reward-additive CTDE (RA-CTDE) framework. We formulate an action model that enables surrounding agents to predict the central agent's action tendency. Leveraging these predictions, we compute a cooperative intrinsic reward that encourages agents to match their actions with their neighbors' predictions. We establish the equivalence between RA-CTDE and CTDE through theoretical analyses, demonstrating that CTDE's training process can be achieved using agents' individual targets. Building on this insight, we introduce a novel method to combine intrinsic rewards and CTDE. Extensive experiments on challenging tasks in SMAC and GRF benchmarks showcase the improved performance of our method.
]]></content:encoded>
<pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CrossInspector: A Static Analysis Approach for Cross-Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2408.15292</link>
<guid>https://arxiv.org/abs/2408.15292</guid>
<content:encoded><![CDATA[
<div> 关键词：CrossInspector、智能合约、跨合约漏洞、字节码静态分析、Transformer模型

<br /><br />
总结:

文章介绍了一种名为CrossInspector的新框架，旨在通过字节码静态分析检测智能合约之间的跨合约漏洞。该框架的核心创新在于利用训练有素的Transformer模型恢复语义信息，并考虑控制流、数据流和与智能合约状态变量相关的依赖关系，以构建状态依赖图进行精细的跨程序分析。此外，CrossInspector还集成了剪枝方法和两个并行优化机制来加速漏洞检测过程。

实验结果表明，CrossInspector在精确度（97%）和召回率（96.75%）上均优于现有工具，并显著缩短了整体时间（从16.34秒降至7.83秒），几乎与最快的使用字节码进行检测的工具相匹敌。更重要的是，对300个真实世界智能合约的测试显示，CrossInspector发现了11个先前工具未发现的跨合约漏洞。

因此，CrossInspector提供了一种高效、准确的方法来检测智能合约之间的复杂交互中的潜在安全风险，对于增强区块链生态系统的安全性具有重要意义。 <div>
arXiv:2408.15292v1 Announce Type: new 
Abstract: With the development of blockchain technology, the detection of smart contract vulnerabilities is increasingly emphasized. However, when detecting vulnerabilities in inter-contract interactions (i.e., cross-contract vulnerabilities) using smart contract bytecode, existing tools often produce many false positives and false negatives due to insufficient recovery of semantic information and inadequate consideration of contract dependencies. We present CrossInspector, a novel framework for detecting cross-contract vulnerabilities at the bytecode level through static analysis. CrossInspector utilizes a trained Transformer model to recover semantic information and considers control flow, data flow, and dependencies related to smart contract state variables to construct a state dependency graph for fine-grained inter-procedural analysis. Additionally, CrossInspector incorporates a pruning method and two parallel optimization mechanisms to accelerate the vulnerability detection process. Experiments on our manually constructed dataset demonstrate that CrossInspector outperforms the state-of-the-art tools in both precision (97\%) and recall (96.75\%), while also significantly reducing the overall time from 16.34 seconds to 7.83 seconds, almost on par with the fastest tool that utilizes bytecode for detection. Additionally, we ran CrossInspector on a randomly selected set of 300 real-world smart contracts and identified 11 cross-contract vulnerabilities that were missed by prior tools.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An evidence-based and critical analysis of the Fediverse decentralization promises</title>
<link>https://arxiv.org/abs/2408.15383</link>
<guid>https://arxiv.org/abs/2408.15383</guid>
<content:encoded><![CDATA[
<div> 关键词：Fediverse、中央化、商业平台、社会网络、分散技术

总结:

本文探讨了Fediverse作为分散式社交媒体和内容平台网络，对抗商业平台在社会互联网上的集中化与主导地位的可能性。研究从支撑Fediverse的技术（特别是ActivityPub协议）、Fediverse用户在不同实例上的分布统计数据以及两个较早的分散技术电子邮件和网络的状态出发。

文章指出，Fediverse面临着实现其分散化承诺的重大挑战，这可能限制其在大规模影响社会互联网的能力。尽管Fediverse提供了一种替代传统的分散式社交网络模型，但其在用户增长、跨平台兼容性和用户体验方面的局限性，可能会阻碍它成为与现有商业平台竞争的有效解决方案。同时，文章对比了Fediverse与电子邮件和网络的历史，试图揭示分散技术在实现广泛采纳过程中的共性和差异，从而为理解Fediverse的未来潜力提供参考。 <div>
arXiv:2408.15383v1 Announce Type: new 
Abstract: This paper examines the potential of the Fediverse, a federated network of social media and content platforms, to counter the centralization and dominance of commercial platforms on the social Web. We gather evidence from the technology powering the Fediverse (especially the ActivityPub protocol), current statistical data regarding Fediverse user distribution over instances, and the status of two older, similar, decentralized technologies: e-mail and the Web. Our findings suggest that Fediverse will face significant challenges in fulfilling its decentralization promises, potentially hindering its ability to positively impact the social Web on a large scale.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>EdgeLinker: Practical Blockchain-based Framework for Healthcare Fog Applications to Enhance Security in Edge-IoT Data Communications</title>
<link>https://arxiv.org/abs/2408.15838</link>
<guid>https://arxiv.org/abs/2408.15838</guid>
<content:encoded><![CDATA[
<div> 关键词：EdgeLinker、区块链、物联网、医疗健康、雾计算

总结:

文章主要介绍了一种名为EdgeLinker的综合解决方案，旨在解决医疗物联网(IoT)应用中的安全性和隐私问题。该方案结合了权威证明(Proof-of-Authority)共识机制、智能合约以及高级加密算法，用于在医疗雾应用中实现物联网边缘设备与雾层之间的安全数据通信。EdgeLinker通过集成这些技术，确保了数据的机密性、访问控制和完整性。

EdgeLinker已在商用雾测试床中实施，使用现成的技术进行雾设备部署。根据全面评估，该框架在安全性、隐私保护、成本效益方面表现良好，适用于医疗雾应用。相较于现有技术，EdgeLinker在不显著增加写入区块链时间的前提下，实现了数据读取时间35%的改进，并在读写交易吞吐量上提供了更好的性能。

此外，EdgeLinker在能源消耗、资源占用和信道延迟方面的表现也优于非安全模式，展示了其在安全性和效率上的显著优势。这一创新为医疗物联网安全提供了一个有前景的解决方案，有助于推动医疗数字化进程的同时，保障敏感数据的安全。 <div>
arXiv:2408.15838v1 Announce Type: new 
Abstract: The pervasive adoption of Internet of Things (IoT) has significantly advanced healthcare digitization and modernization. Nevertheless, the sensitive nature of medical data presents security and privacy challenges. On the other hand, resource constraints of IoT devices often necessitates cloud services for data handling, introducing single points of failure, processing delays, and security vulnerabilities. Meanwhile, the blockchain technology offers potential solutions for enhancing security, decentralization, and data ownership. An ideal solution should ensure confidentiality, access control, and data integrity while being scalable, cost-effective, and integrable with the existing systems. However, current blockchain-based studies only address some of these requirements. Accordingly, this paper proposes EdgeLinker; a comprehensive solution incorporating Proof-of-Authority consensus, integrating smart contracts on the Ethereum blockchain for access control, and advanced cryptographic algorithms for secure data communication between IoT edge devices and the fog layer in healthcare fog applications. This novel framework has been implemented in a real-world fog testbed, using COTS fog devices. Based on a comprehensive set of evaluations, EdgeLinker demonstrates significant improvements in security and privacy with reasonable costs, making it an affordable and practical system for healthcare fog applications. Compared with the state-of-the-art, without significant changes in the write-time to the blockchain, EdgeLinker achieves a 35% improvement in data read time. Additionally, it is able to provide better throughput in both reading and writing transactions compared to the existing studies. EdgeLinker has been also examined in terms of energy, resource consumption and channel latency in both secure and non-secure modes, which has shown remarkable improvements.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized LLM Inference over Edge Networks with Energy Harvesting</title>
<link>https://arxiv.org/abs/2408.15907</link>
<guid>https://arxiv.org/abs/2408.15907</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、资源受限环境、分布式技术、能源限制、协作推理

<br /><br />
总结:

本文聚焦于大型语言模型在资源有限的边缘网络环境中的应用挑战。随着这些模型在自然语言处理任务中展现出卓越性能，它们在实际部署中遇到了在边缘设备上运行时的能效问题。为了解决这一问题，研究提出了一个基于互联、电池供电的边缘设备的协作推理可持续模型，这些设备通过能量收集来补充电力。

研究中，开发了一种半马尔可夫模型来描述设备状态，考虑了处理参数和平均绿色能源到达情况，以指导设计旨在最小化设备停机时间和最大化网络吞吐量的调度算法。通过实证分析和模拟运行验证了该方法的有效性，为边缘网络上能效优化的分布式推理提供了新的途径。

通过这种方法，不仅提高了设备的能效，也使得模型能够在资源有限的环境中持续运行，满足实际应用场景的需求。这为构建更高效、可持续的边缘计算基础设施铺平了道路，对于推动人工智能技术在实际场景中的广泛应用具有重要意义。 <div>
arXiv:2408.15907v1 Announce Type: new 
Abstract: Large language models have significantly transformed multiple fields with their exceptional performance in natural language tasks, but their deployment in resource-constrained environments like edge networks presents an ongoing challenge. Decentralized techniques for inference have emerged, distributing the model blocks among multiple devices to improve flexibility and cost effectiveness. However, energy limitations remain a significant concern for edge devices. We propose a sustainable model for collaborative inference on interconnected, battery-powered edge devices with energy harvesting. A semi-Markov model is developed to describe the states of the devices, considering processing parameters and average green energy arrivals. This informs the design of scheduling algorithms that aim to minimize device downtimes and maximize network throughput. Through empirical evaluations and simulated runs, we validate the effectiveness of our approach, paving the way for energy-efficient decentralized inference over edge networks.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Anomaly Detection in Time Series of EDFA Pump Currents to Monitor Degeneration Processes using Fuzzy Clustering</title>
<link>https://arxiv.org/abs/2408.15268</link>
<guid>https://arxiv.org/abs/2408.15268</guid>
<content:encoded><![CDATA[
<div> 关键词：模糊聚类、异常检测、泵电流时间序列、EDFA系统、变化检测框架

总结:
本文提出了一种基于模糊聚类的新型异常检测方法，专门用于EDFA系统的泵电流时间序列。该方法通过结合熵分析（EA）和主成分分析（PCA）的优势，以及模糊聚类过程，形成了一种创新的框架——变化检测框架（CDF）。通过EA动态选择特征以减少特征空间并提高计算性能，PCA则从原始特征空间中提取特征，以增强后续模糊聚类过程的泛化能力。

本文评估了三种不同的模糊聚类方法：模糊聚类算法、概率聚类算法和可能性聚类算法，以比较它们的性能和泛化能力。与商业使用的EDFA中预先定义的警报不同，该框架能够早于任意操作点检测泵电流时间序列的变化。此外，该框架通过实验数据进行了实现和测试，并为进一步的光缆网络分散式预测性维护提供了可能途径。

该方法不仅提高了EDFA系统异常检测的精度和效率，还为光缆网络的预测性维护提供了一种新的策略，有助于提升网络的稳定性和可靠性。 <div>
arXiv:2408.15268v1 Announce Type: cross 
Abstract: This article proposes a novel fuzzy clustering based anomaly detection method for pump current time series of EDFA systems. The proposed change detection framework (CDF) strategically combines the advantages of entropy analysis (EA) and principle component analysis (PCA) with fuzzy clustering procedures. In the framework, EA is applied for dynamic selection of features for reduction of the feature space and increase of computational performance. Furthermore, PCA is utilized to extract features from the raw feature space to enable generalization capability of the subsequent fuzzy clustering procedures. Three different fuzzy clustering methods, more precisely the fuzzy clustering algorithm, a probabilistic clustering algorithm and a possibilistic clustering algorithm are evaluated for performance and generalization. Hence, the proposed framework has the innovative feature to detect changes in pump current time series at an early stage for arbitrary points of operation, compared to state-of-the-art predefined alarms in commercially used EDFAs. Moreover, the approach is implemented and tested using experimental data. In addition, the proposed framework enables further approaches of applying decentralized predictive maintenance for optical fiber networks.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chop Chop: Byzantine Atomic Broadcast to the Network Limit</title>
<link>https://arxiv.org/abs/2304.07081</link>
<guid>https://arxiv.org/abs/2304.07081</guid>
<content:encoded><![CDATA[
<div> 关键词：原子广播、Chop Chop系统、分布式部署、性能优化、应用实例

总结:

本文介绍了一种名为“Chop Chop”的新型拜占庭原子广播系统。该系统利用一种创新的认证内存池技术，实现了对消息的快速排序、验证和去重，即便处理小至8字节的消息也能达到“线速率”，即与无任何排序、验证或拜占庭容错性的协议相比，其复杂度几乎相同。Chop Chop通过一种称为“蒸馏”的新型批量处理方式实现这一目标，即创建一组易于认证、去重和排序的消息集合。

在一项地理分布式的部署中，包含64台中型服务器的情况下，Chop Chop每秒可处理高达4360万条消息，平均延迟为3.6秒。相比之下，当前最佳替代方案在同一条件下只能提供相同延迟下的处理能力，仅为Chop Chop的十分之一。此外，文章还展示了Chop Chop在支付系统、拍卖平台和像素战争游戏等三个简单应用中的实际表现，分别实现了32、2.3和35百万次操作/秒的性能。 <div>
arXiv:2304.07081v2 Announce Type: replace 
Abstract: At the heart of state machine replication, the celebrated technique enabling decentralized and secure universal computation, lies Atomic Broadcast, a fundamental communication primitive that orders, authenticates, and deduplicates messages. This paper presents Chop Chop, a Byzantine Atomic Broadcast system that uses a novel authenticated memory pool to amortize the cost of ordering, authenticating and deduplicating messages, achieving "line rate" (i.e., closely matching the complexity of a protocol that does not ensure any ordering, authentication or Byzantine resilience) even when processing messages as small as 8 bytes. Chop Chop attains this performance by means of a new form of batching we call distillation. A distilled batch is a set of messages that are fast to authenticate, deduplicate, and order. Batches are distilled using a novel interactive protocol involving brokers, an untrusted layer of facilitating processes between clients and servers. In a geo-distributed deployment of 64 medium-sized servers, Chop Chop processes 43,600,000 messages per second with an average latency of 3.6 seconds. Under the same conditions, state-of-the-art alternatives offer two orders of magnitude less throughput for the same latency. We showcase three simple Chop Chop applications: a Payment system, an Auction house and a "Pixel war" game, respectively achieving 32, 2.3 and 35 million operations per second.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Behavior-Based Detection of GPU Cryptojacking</title>
<link>https://arxiv.org/abs/2408.14554</link>
<guid>https://arxiv.org/abs/2408.14554</guid>
<content:encoded><![CDATA[
<div> 关键词：GPU、加密货币挖矿、检测技术、历史回顾、决策树

<br />
<br />总结:
文章探讨了基于区块链的加密货币崛起后，非法加密货币挖矿，特别是GPU挖矿的兴起及其对网络安全的威胁。文章首先回顾了加密货币挖矿的历史与定义，并概述了先前针对此类威胁的检测技术尝试。接着，作者提出了一种基于GPU应用负载和显存消耗的复杂暴露机制，以检测浏览器和主机基于的挖矿样本。

文章设计并实现了一个基于上述技术的原型决策树检测程序。该程序在受控虚拟机环境中进行测试，结果显示其对选定的GPU挖矿样本具有80%的成功检测率，同时对合法的高GPU负载应用有20%的误报率。这表明所提出的方法在检测非法加密货币挖矿活动方面具有一定的有效性与实用性。 <div>
arXiv:2408.14554v1 Announce Type: new 
Abstract: With the surge in blockchain-based cryptocurrencies, illegal mining for cryptocurrency has become a popular cyberthreat. Host-based cryptojacking, where malicious actors exploit victims systems to mine cryptocurrency without their knowledge, is on the rise. Regular cryptojacking is relatively well-known and well-studied threat, however, recently attackers started switching to GPU cryptojacking, which promises greater profits due to high GPU hash rates and lower detection chance. Additionally, GPU cryptojackers can easily propagate using, for example, modified graphic card drivers. This article considers question of GPU cryptojacking detection. First, we discuss brief history and definition of GPU cryptojacking as well as previous attempts to design a detection technique for such threats. We also propose complex exposure mechanism based on GPU load by an application and graphic card RAM consumption, which can be used to detect both browser-based and host-based cryptojacking samples. Then we design a prototype decision tree detection program based on our technique. It was tested in a controlled virtual machine environment with 80% successful detection rate against selected set of GPU cryptojacking samples and 20% false positive rate against selected number of legitimate GPU-heavy applications.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Centralized Critics in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2408.14597</link>
<guid>https://arxiv.org/abs/2408.14597</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、集中式训练、分散式执行、集中式批评家、状态值

总结:

本文探讨了集中式训练与分散式执行在多智能体强化学习（MARL）中的应用，其中智能体在离线阶段以集中式方式训练，而在在线执行阶段则以分散式方式操作。特别地，研究了利用集中式批评家的方法，该批评家能够访问整个系统的真实状态信息。尽管此类方法在多个领域表现出色并成为MARL的标准实践，但集中式批评家的使用在理论上和实践中尚未得到充分分析。

文章首先对比了集中式与分散式批评家策略，以及在部分可观测环境中的状态值与历史值批评家的使用。理论分析揭示了与直觉相反的结果：集中式批评家并非绝对有益，反而可能引入意外的偏差和方差问题。特别是，状态值批评家可能会导致与基于历史的批评家相比出现不可预测的问题。

为了验证理论分析的实际影响，作者通过比较不同形式的批评家在广泛多智能体基准上的表现进行了实验。结果表明，特别是在部分可观测性环境中，代表学习的难度增加了理论问题的复杂性，这解释了为什么这些问题在文献中往往被忽视。 <div>
arXiv:2408.14597v1 Announce Type: new 
Abstract: Centralized Training for Decentralized Execution where agents are trained offline in a centralized fashion and execute online in a decentralized manner, has become a popular approach in Multi-Agent Reinforcement Learning (MARL). In particular, it has become popular to develop actor-critic methods that train decentralized actors with a centralized critic where the centralized critic is allowed access global information of the entire system, including the true system state. Such centralized critics are possible given offline information and are not used for online execution. While these methods perform well in a number of domains and have become a de facto standard in MARL, using a centralized critic in this context has yet to be sufficiently analyzed theoretically or empirically. In this paper, we therefore formally analyze centralized and decentralized critic approaches, and analyze the effect of using state-based critics in partially observable environments. We derive theories contrary to the common intuition: critic centralization is not strictly beneficial, and using state values can be harmful. We further prove that, in particular, state-based critics can introduce unexpected bias and variance compared to history-based critics. Finally, we demonstrate how the theory applies in practice by comparing different forms of critics on a wide range of common multi-agent benchmarks. The experiments show practical issues such as the difficulty of representation learning with partial observability, which highlights why the theoretical problems are often overlooked in the literature.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Instrumenting Transaction Trace Properties in Smart Contracts: Extending the EVM for Real-Time Security</title>
<link>https://arxiv.org/abs/2408.14621</link>
<guid>https://arxiv.org/abs/2408.14621</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约安全、交易恶意检测、实时验证、读取交易痕迹、过去时间线性时态逻辑

总结:
本文探讨了智能合约安全领域中的交易恶意检测技术，该技术通过利用交易痕迹的特性来实现对黑客攻击的高度准确识别。然而，这种方法无法在实际操作中即时回滚恶意交易，因此智能合约通常会集成一些可编程的安全特性以增强安全性。但这些可编程的安全特性存在局限性，无法阻止如读取重入等特定类型的攻击。

文章提出了对以太坊虚拟机（EVM）和以太坊客户端进行修改的建议，旨在使智能合约能够实时验证交易痕迹属性，而不会影响传统的EVM执行过程。通过使用过去时间线性时态逻辑（PLTL），可以正式化交易痕迹属性，表明大多数现有的检测指标都可以用PLTL表示。

此外，文章还讨论了所提议修改的潜在影响，强调了它们显著提升智能合约安全性的能力。改进后的系统将允许智能合约实时验证交易行为，从而有效防止特定类型的攻击，提高整体安全性，同时避免了因执行额外验证步骤而导致的高Gas消耗问题。 <div>
arXiv:2408.14621v1 Announce Type: new 
Abstract: In the realm of smart contract security, transaction malice detection has been able to leverage properties of transaction traces to identify hacks with high accuracy. However, these methods cannot be applied in real-time to revert malicious transactions. Instead, smart contracts are often instrumented with some safety properties to enhance their security. However, these instrumentable safety properties are limited and fail to block certain types of hacks such as those which exploit read-only re-entrancy. This limitation primarily stems from the Ethereum Virtual Machine's (EVM) inability to allow a smart contract to read transaction traces in real-time. Additionally, these instrumentable safety properties can be gas-intensive, rendering them impractical for on-the-fly validation. To address these challenges, we propose modifications to both the EVM and Ethereum clients, enabling smart contracts to validate these transaction trace properties in real-time without affecting traditional EVM execution. We also use past-time linear temporal logic (PLTL) to formalize transaction trace properties, showcasing that most existing detection metrics can be expressed using PLTL. We also discuss the potential implications of our proposed modifications, emphasizing their capacity to significantly enhance smart contract security.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy Concerns</title>
<link>https://arxiv.org/abs/2408.14753</link>
<guid>https://arxiv.org/abs/2408.14753</guid>
<content:encoded><![CDATA[
<div> 关键词：机器异常声音检测、工业物联网、去中心化设置、隐私保护、CoopASD框架

<br /><br />
总结:
本文提出了一种名为CoopASD的新框架，旨在解决在工业物联网（IIoT）环境下，机器异常声音检测（ASD）任务的去中心化设置问题。CoopASD框架允许各个工厂在其本地数据集上独立训练ASD模型，并通过中央服务器周期性聚合这些模型，从而实现大规模ASD模型的协同开发，同时保护了工厂的数据隐私。为提高模型的鲁棒性和稳定性，该框架利用预训练模型作为基础，并针对非iid和域迁移情况开发了专门技术。相较于在集中式设置下训练的当前最佳模型，CoopASD在性能上仅略有下降（0.08%），同时提供了更优的隐私保护。研究还进行了详尽的消融实验，以证明CoopASD的有效性。 <div>
arXiv:2408.14753v1 Announce Type: new 
Abstract: Machine anomalous sound detection (ASD) has emerged as one of the most promising applications in the Industrial Internet of Things (IIoT) due to its unprecedented efficacy in mitigating risks of malfunctions and promoting production efficiency. Previous works mainly investigated the machine ASD task under centralized settings. However, developing the ASD system under decentralized settings is crucial in practice, since the machine data are dispersed in various factories and the data should not be explicitly shared due to privacy concerns. To enable these factories to cooperatively develop a scalable ASD model while preserving their privacy, we propose a novel framework named CoopASD, where each factory trains an ASD model on its local dataset, and a central server aggregates these local models periodically. We employ a pre-trained model as the backbone of the ASD model to improve its robustness and develop specialized techniques to stabilize the model under a completely non-iid and domain shift setting. Compared with previous state-of-the-art (SOTA) models trained in centralized settings, CoopASD showcases competitive results with negligible degradation of 0.08%. We also conduct extensive ablation studies to demonstrate the effectiveness of CoopASD.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Unlabeled Multi-agent Pathfinding Via Target And Priority Swapping (With Supplementary)</title>
<link>https://arxiv.org/abs/2408.14948</link>
<guid>https://arxiv.org/abs/2408.14948</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名多智能体路径规划（AMAPF）、完全分布式、目标交换与优先级调整（TP-SWAP）、理论完备性、性能优化

<br /><br />
总结:

本文研究了多智能体路径规划问题的一个挑战性变种——匿名多智能体路径规划(AMAPF)，即一组智能体必须到达一组目标位置，但关键在于哪个智能体到达特定位置并不重要。当前的最优和次优AMAPF解决方案依赖于中心控制器，负责目标分配和路径查找。文章提出了一种新的方法，即TP-SWAP（目标交换与优先级调整），这是第一个能够以完全分布式方式解决该问题的AMAPF算法，每个智能体独立决策并仅依靠与其他智能体的局部通信。

TP-SWAP的核心是一个针对产生一致目标分配（确保没有两个智能体同时前往同一目标）的优先级和目标交换程序，结合了成熟的规则基路径规划策略。理论证明了TP-SWAP的完备性，即TP-SWAP能够保证每个目标由某个智能体到达。实验结果显示，TP-SWAP在广泛设置下优于现有的完全分布式基准，并且在某些情况下甚至超过了依赖初始一致目标分配的半分布式解决方案，特别是在考虑流时间（MAPF中广泛应用的成本指标）时。 <div>
arXiv:2408.14948v1 Announce Type: new 
Abstract: In this paper we study a challenging variant of the multi-agent pathfinding problem (MAPF), when a set of agents must reach a set of goal locations, but it does not matter which agent reaches a specific goal - Anonymous MAPF (AMAPF). Current optimal and suboptimal AMAPF solvers rely on the existence of a centralized controller which is in charge of both target assignment and pathfinding. We extend the state of the art and present the first AMAPF solver capable of solving the problem at hand in a fully decentralized fashion, when each agent makes decisions individually and relies only on the local communication with the others. The core of our method is a priority and target swapping procedure tailored to produce consistent goal assignments (i.e. making sure that no two agents are heading towards the same goal). Coupled with an established rule-based path planning, we end up with a TP-SWAP, an efficient and flexible approach to solve decentralized AMAPF. On the theoretical side, we prove that TP-SWAP is complete (i.e. TP-SWAP guarantees that each target will be reached by some agent). Empirically, we evaluate TP-SWAP across a wide range of setups and compare it to both centralized and decentralized baselines. Indeed, TP-SWAP outperforms the fully-decentralized competitor and can even outperform the semi-decentralized one (i.e. the one relying on the initial consistent goal assignment) in terms of flowtime (a widespread cost objective in MAPF
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>IoT Monitoring with Blockchain: Generating Smart Contracts from Service Level Agreements</title>
<link>https://arxiv.org/abs/2408.15016</link>
<guid>https://arxiv.org/abs/2408.15016</guid>
<content:encoded><![CDATA[
<div> 关键词：服务级别协议（SLA）、区块链技术、智能合约、物联网（IoT）系统、Java库

总结:

本文探讨了区块链技术在物联网服务监控中的应用，以确保服务提供者和客户之间的信任。研究重点关注开发一个Java库，该库能够从给定的服务级别协议（SLA）生成智能合约。通过一个远程患者监测的物联网系统模拟场景，验证了由该库生成的智能合约的有效性。结果表明，该系统成功捕捉到了所有模拟的违规行为，成功率达到了100%。

文章首先定义了服务级别协议（SLA），它是在服务购买中客户与提供者之间达成的关于服务质量的承诺。然而，SLA违反的证据可能被服务提供者或消费者操纵，导致合同双方之间出现信任问题。为了解决这一问题，作者提出使用区块链技术和智能合约来监控物联网系统，确保SLA违反情况的不可否认性。

研究设计了一个Java库，用于根据给定的SLA自动生成智能合约。这些智能合约通过一个远程患者监测的物联网系统模拟场景进行了验证。结果显示，该系统能够成功捕获所有模拟的违规行为，证明了其在监控服务质量和维护信任方面的有效性。

综上所述，本文展示了区块链技术在物联网服务监控中的潜在应用价值，通过智能合约确保了服务提供者与客户之间的SLA遵守情况的公正性和透明性。这为建立更可靠、可信赖的物联网生态系统提供了新的解决方案。 <div>
arXiv:2408.15016v1 Announce Type: new 
Abstract: A Service Level Agreement (SLA) is a commitment between a client and provider that assures the quality of service (QoS) a client can expect to receive when purchasing a service. However, evidence of SLA violations in Internet of Things (IoT) service monitoring data can be manipulated by the provider or consumer, resulting in an issue of trust between contracted parties. The following research aims to explore the use of blockchain technology in monitoring IoT systems using smart contracts so that SLA violations captured are irrefutable amongst service providers and clients. The research focuses on the development of a Java library that is capable of generating a smart contract from a given SLA. A smart contract generated by this library is validated through a mock scenario presented in the form of a Remote Patient Monitoring IoT system. In this scenario, the findings demonstrate a 100 percent success rate in capturing all emulated violations.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Encoding Process in Decentralized Systems</title>
<link>https://arxiv.org/abs/2408.15203</link>
<guid>https://arxiv.org/abs/2408.15203</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统、线性编码、数据融合、集体通信、编码优化

<br /><br />
总结:
本文探讨了在没有中央协调器的N=K+R分布式系统中编码信息的问题。其中，K个源处理器持有数据向量，R个目标处理器需要获取所有数据向量的线性组合。这些组合由系统线性错误更正码的生成矩阵定义。文章采用线性网络模型描述通信过程，每轮每个处理器通过p个端口发送和接收一次消息。为了允许处理器传输其数据和先前接收数据的线性组合，文章借鉴了线性网络编码文献中的概念。为解决分布式编码问题，文章提出了一种双层框架。在通用层上，提供了解决任何可能的线性编码问题的解决方案。在特定层上，进一步优化了解决方案，针对系统中常用的系统Reed-Solomon码及其变体Lagrange码进行了优化。这些解决方案基于一种新的集体通信操作——全对全编码。 <div>
arXiv:2408.15203v1 Announce Type: new 
Abstract: We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Anti-Matthew FL: Bridging the Performance Gap in Federated Learning to Counteract the Matthew Effect</title>
<link>https://arxiv.org/abs/2309.16338</link>
<guid>https://arxiv.org/abs/2309.16338</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、Matthew 效应、公平性、性能优化、多目标优化

总结:

本文研究了联邦学习（FL）中的Matthew效应问题，即全球模型性能的不均衡导致数据资源较少的客户端产生更大的数据资源差距。针对这一挑战，作者提出了反Matthew公平性概念，旨在使全球模型在各客户端上具有相同的准确性和决策偏差。为了解决性能优化与公平性之间的权衡问题，文章将反Matthew联邦学习（反Matthew FL）定义为一个多约束多目标优化（MCMOO）问题，并设计了一个三阶段多梯度下降算法来寻找帕累托最优解。

通过理论分析，证明了所提算法的收敛性和时间复杂性。实验结果表明，与现有联邦学习算法相比，提出的反Matthew FL不仅能够构建高性能的全局模型，还能有效缩小客户端之间的性能差距，从而促进数据资源的均衡分配，对提升社会福利有潜在贡献。此工作揭示了在联邦学习等分散式学习场景中Matthew效应的表现，并为设计更公平的学习机制提供了理论依据和实践指导。 <div>
arXiv:2309.16338v2 Announce Type: replace 
Abstract: Federated learning (FL) stands as a paradigmatic approach that facilitates model training across heterogeneous and diverse datasets originating from various data providers. However, conventional FLs fall short of achieving consistent performance, potentially leading to performance degradation for clients who are disadvantaged in data resources. Influenced by the Matthew effect, deploying a performance-imbalanced global model in applications further impedes the generation of high-quality data from disadvantaged clients, exacerbating the disparities in data resources among clients. In this work, we propose anti-Matthew fairness for the global model at the client level, requiring equal accuracy and equal decision bias across clients. To balance the trade-off between achieving anti-Matthew fairness and performance optimality, we formalize the anti-Matthew effect federated learning (anti-Matthew FL) as a multi-constrained multi-objectives optimization (MCMOO) problem and propose a three-stage multi-gradient descent algorithm to obtain the Pareto optimality. We theoretically analyze the convergence and time complexity of our proposed algorithms. Additionally, through extensive experimentation, we demonstrate that our proposed anti-Matthew FL outperforms other state-of-the-art FL algorithms in achieving a high-performance global model while effectively bridging performance gaps among clients. We hope this work provides valuable insights into the manifestation of the Matthew effect in FL and other decentralized learning scenarios and can contribute to designing fairer learning mechanisms, ultimately fostering societal welfare.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Role of Game Networking in the Fusion of Physical and Digital Worlds through 6G Wireless Networks</title>
<link>https://arxiv.org/abs/2302.01672</link>
<guid>https://arxiv.org/abs/2302.01672</guid>
<content:encoded><![CDATA[
<div> 关键词：6G、游戏网络、数字孪生、扩展现实、元宇宙

<br />
总结:

文章主要探讨了第六代（6G）无线技术在构建实时融合物理与数字世界的潜力，特别是针对数字孪生、扩展现实和元宇宙等应用。6G被视为实现沉浸式在线三维虚拟环境的关键技术，这些环境允许人们在社交网络中互动、工作和娱乐。

从通信和网络的角度看，6G代表了游戏网络技术的演进，旨在连接大规模用户于实时在线游戏环境。文章详细阐述了游戏网络的基本原理及其如何演变以满足元宇宙及类似应用的需求。

讨论了多个开放研究挑战，包括但不限于网络容量、延迟、安全性、用户体验优化等问题，并通过实验案例研究提出了可能的解决方案。例如，通过改进网络架构、利用边缘计算、增强数据压缩技术等方式，来提高网络性能并降低延迟，以支持元宇宙中复杂交互和高带宽需求的应用场景。文章强调了研究者需解决的关键问题，并展示了通过创新方法和技术进步实现未来网络愿景的潜力。 <div>
arXiv:2302.01672v4 Announce Type: replace-cross 
Abstract: The sixth generation (6G) of wireless technology is seen as one of the enablers of real-time fusion of the physical and digital realms, as in Digital Twin, eXtended reality, or the Metaverse. This would allow people to interact, work, and entertain themselves in an immersive social network of online 3D~virtual environments. From the viewpoint of communication and networking, this will represent an evolution of the \emph{game networking} technology, designed to interconnect massive users in real-time online gaming environments. This article presents the basic principles of game networking and discusses their evolution towards meeting the requirements of the Metaverse and similar applications. Several open research challenges are discussed, along with possible solutions through experimental case studies.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hidden Risks: The Centralization of NFT Metadata and What It Means for the Market</title>
<link>https://arxiv.org/abs/2408.13281</link>
<guid>https://arxiv.org/abs/2408.13281</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币、存储、分布式技术、安全风险、数字签名

总结:

本文研究了非同质化代币（NFT）市场中元数据存储的现状，揭示了对集中式平台的严重依赖性，这带来了数据完整性、安全性以及去中心化的威胁。通过对OpenSea市场上的顶级NFT进行深入分析，发现大量元数据托管于中央服务器，使其易受审查、数据泄露和管理篡改的风险。相比之下，分散式存储解决方案，特别是星际文件系统（IPFS），被证明是一种更安全、更坚韧的选择，提供增强的透明度、抗篡改性和创作者及收藏者更大的控制权。

文章呼吁广泛采用分散式存储架构，并结合数字签名验证所有权，以保护NFT的价值和可靠性。研究强调了NFT平台在确保NFT长期可持续性和完整性方面优先考虑分散式方法的重要性。通过实施分散式存储和数字签名机制，可以有效提升NFT市场的信任度和安全性，促进其健康发展。 <div>
arXiv:2408.13281v1 Announce Type: new 
Abstract: The rapid expansion of the non-fungible token (NFT) market has catalyzed new opportunities for artists, collectors, and investors, yet it has also unveiled critical challenges related to the storage and distribution of associated metadata. This paper examines the current landscape of NFT metadata storage, revealing a significant reliance on centralized platforms, which poses risks to the integrity, security, and decentralization of these digital assets. Through a detailed analysis of top-selling NFTs on the OpenSea marketplace, it was found that a substantial portion of metadata is hosted on centralized servers, making them susceptible to censorship, data breaches, and administrative alterations. Conversely, decentralized storage solutions, particularly the InterPlanetary File System (IPFS), were identified as a more secure and resilient alternative, offering enhanced transparency, resistance to tampering, and greater control for creators and collectors. This study advocates for the widespread adoption of decentralized storage architectures, incorporating digital signatures to verify ownership, as a means to preserve the value and trustworthiness of NFTs in an increasingly digital world. The findings underscore the necessity for NFT platforms to prioritize decentralized methodologies to ensure the long-term sustainability and integrity of the NFT
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Blockchain: Transforming Blockchain from Transaction Recording to Transaction Generation through Proof-of-Merit</title>
<link>https://arxiv.org/abs/2408.13367</link>
<guid>https://arxiv.org/abs/2408.13367</guid>
<content:encoded><![CDATA[
<div> 关键词：新型区块链、生成式区块链、Proof-of-Merit（PoM）、共识机制、Decentralized Control Parameter（DCP）

<br /><br />
总结:
本文提出了一种创新的区块链概念——生成式区块链，其核心目标是将交易的生成与记录集成到单一系统中，而非仅专注于记录交易。该理论引入了Proof-of-Merit（PoM）共识机制，旨在为需要解决复杂问题后才能记录交易的企业环境提供解决方案。与当前主要侧重于记录现有交易的共识机制不同，PoM将交易的生成和记录过程融合在一个统一的区块链框架内。

在具体应用层面，文章以即需即行的乘车服务平台为例，演示了PoM机制如何运作。在这个场景中，匹配者（问题解决者）被分配任务来匹配乘客与司机，他们的解决方案根据“功绩”进行评估，最佳方案的提出者负责将交易记录至区块链，并获得相应的奖励。

为了平衡效率与公平性，文章提出了Decentralized Control Parameter（DCP），用于调整系统参数，以达到最优的性能平衡。通过基于代理的模拟，研究如何确定合适的DCP值，以实现生成式区块链中的高效与公平之间的理想平衡。 <div>
arXiv:2408.13367v1 Announce Type: new 
Abstract: This paper proposes a new paradigm: generative blockchain, which aims to transform conventional blockchain technology by combining transaction generation and recording, rather than focusing solely on transaction recording. Central to our design is a novel consensus mechanism, Proof-of-Merit (PoM), specifically crafted for environments where businesses must solve complex problems before transactions can be recorded. PoM integrates the generation and recording of transactions within a unified blockchain system, fundamentally differing from prevailing consensus mechanisms that primarily record existing transactions. We demonstrate PoM on a ride service on-demand platform, where the task of solving complex transaction-generating problems is delegated to a pool of independent problem solvers. These solvers generate transactions, and their solutions are selected based on merit. The winning solvers then register these transactions onto the blockchain and are rewarded accordingly. We introduce a Decentralized Control Parameter (DCP) to balance two key performance metrics: efficiency and equity. The applicability of our generative blockchain is illustrated through a ridesharing context, where matchers (solvers) are tasked with matching riders to drivers. We demonstrate PoM's performance and nuanced properties using agent-based simulation, exploring how to find the optimal DCP value to achieve a desirable balance of efficiency and equity in a generative blockchain.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Training for Enhanced Multi-task Generalization in Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2408.13567</link>
<guid>https://arxiv.org/abs/2408.13567</guid>
<content:encoded><![CDATA[
<div> 关键词：HyGen、在线学习、离线学习、多任务泛化、强化学习

总结:

本文提出了一种名为HyGen的新型混合多智能体强化学习框架，旨在解决多任务泛化问题。HyGen融合了在线和离线学习方法，以提高多任务泛化的效率和效果。该框架首先从离线多任务数据集中提取潜在的一般性技能，然后在集中式训练和分布式执行（CTDE）范式下训练策略，选择最佳技能。通过集成离线数据与在线交互的回放缓冲区，HyGen有效地提炼和优化了一般性技能，展现出对未见任务的强大泛化能力。在星战多智能体挑战赛中的对比分析显示，HyGen显著优于现有单一在线和离线方法。

HyGen的关键贡献在于其创新的混合学习策略，通过结合离线数据的优势和在线学习的灵活性，实现了高效且广泛的多任务适应性。这不仅减少了计算资源的浪费，还增强了模型在实际应用中的实用性，特别是在面对多样化的任务需求时。 <div>
arXiv:2408.13567v1 Announce Type: new 
Abstract: In multi-agent reinforcement learning (MARL), achieving multi-task generalization to diverse agents and objectives presents significant challenges. Existing online MARL algorithms primarily focus on single-task performance, but their lack of multi-task generalization capabilities typically results in substantial computational waste and limited real-life applicability. Meanwhile, existing offline multi-task MARL approaches are heavily dependent on data quality, often resulting in poor performance on unseen tasks. In this paper, we introduce HyGen, a novel hybrid MARL framework, Hybrid Training for Enhanced Multi-Task Generalization, which integrates online and offline learning to ensure both multi-task generalization and training efficiency. Specifically, our framework extracts potential general skills from offline multi-task datasets. We then train policies to select the optimal skills under the centralized training and decentralized execution paradigm (CTDE). During this stage, we utilize a replay buffer that integrates both offline data and online interactions. We empirically demonstrate that our framework effectively extracts and refines general skills, yielding impressive generalization to unseen tasks. Comparative analyses on the StarCraft multi-agent challenge show that HyGen outperforms a wide range of existing solely online and offline methods.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Receding-Horizon Games with Tullock-Based Profit Functions for Electric Ride-Hailing Markets</title>
<link>https://arxiv.org/abs/2408.13595</link>
<guid>https://arxiv.org/abs/2408.13595</guid>
<content:encoded><![CDATA[
<div> 关键词：电动力、游戏理论、充电规划、动态需求、市场共享

<br /><br />
总结:

本文提出了一种基于退化视野的游戏理论充电规划机制，针对电动汽车在叫车市场的应用。随着对叫车服务需求的增长和环保法规的严格，将电动车整合进市场成为必然趋势。该框架旨在应对动态需求模式、能源成本波动以及市场竞争中的挑战。通过引入退化视野游戏概念，优化了预设时间窗口内的车辆充电调度。模型中加入修改后的Tullock竞赛，考虑了顾客因等待时间过长而放弃的可能性，同时考虑到基于需求的电力充电，构建了一个描述两家公司在时间窗口内互动的游戏。首先证明了纳什均衡的存在性和唯一性，然后提出了一个半分散化的迭代方法来计算这一均衡。最后，在模拟的数值案例研究中，以开环和闭环方式评估了该方法的效果。 <div>
arXiv:2408.13595v1 Announce Type: new 
Abstract: This paper proposes a receding-horizon, game-theoretic charging planning mechanism for electric ride-hailing markets. As the demand for ride-hailing services continues to surge and governments advocate for stricter environmental regulations, integrating electric vehicles into these markets becomes inevitable. The proposed framework addresses the challenges posed by dynamic demand patterns, fluctuating energy costs, and competitive dynamics inherent in such markets. Leveraging the concept of receding-horizon games, we propose a method to optimize proactive dispatching of vehicles for recharging over a predefined time horizon. We integrate a modified Tullock contest that accounts for customer abandonment due to long waiting times to model the expected market share, and by factoring in the demand-based electricity charging, we construct a game capturing interactions between two companies over the time horizon. For this game, we first establish the existence and uniqueness of the Nash equilibrium and then present a semi-decentralized, iterative method to compute it. Finally, the method is evaluated in an open-loop and a closed-loop manner in a simulated numerical case study.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy-aware Distributed Microservice Request Placement at the Edge</title>
<link>https://arxiv.org/abs/2408.13748</link>
<guid>https://arxiv.org/abs/2408.13748</guid>
<content:encoded><![CDATA[
<div> 关键词：微服务、分散式请求放置（DRP）、旅行购买者问题、整数线性规划、能源消耗

总结:

本文探讨了使用微服务架构时的分散式请求放置（DRP）问题。研究将DRP问题视为旅行购买者问题的一个实例，并提出了一种整数线性规划形式化方法，旨在最小化能源消耗同时满足延迟要求。研究考虑了整体或边际能源消耗两种不同的能源消耗度量方式，以研究优化这些度量方式如何影响请求放置决策。

研究发现，选择的能源度量方式确实能够影响请求放置决策，从而导致不同的能源减少策略。通过模拟实验，验证了整数线性规划模型的有效性和实用性。结果表明，优化能源消耗策略不仅有助于提高能源效率，还能在一定程度上改善系统性能和用户体验。因此，为实现绿色高效的数据中心运营，采用合理的分散式请求放置策略对于平衡性能与能源消耗至关重要。 <div>
arXiv:2408.13748v1 Announce Type: new 
Abstract: Microservice is a way of splitting the logic of an application into small blocks that can be run on different computing units and used by other applications. It has been successful for cloud applications and is now increasingly used for edge applications. This new architecture brings many benefits but it makes deciding where a given service request should be executed (i.e. its placement) more complex as every small block needed for the request has to be placed.
  In this paper, we investigate decentralized request placement (DRP) for services using the microservice architecture. We consider the DRP problem as an instance of a traveling purchaser problem and propose an integer linear programming formulation. This formulation aims at minimizing energy consumption while respecting latency requirements. We consider two different energy consumption metrics, namely overall or marginal energy, to study how optimizing towards these impacts the request placement decision.
  Our simulations show that the request placement decision can indeed be influenced by the energy metric chosen, leading to different energy reduction strategies.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Speeding Ticket: Unveiling the Energy and Emission Burden of AI-Accelerated Distributed and Decentralized Power Dispatch Models</title>
<link>https://arxiv.org/abs/2408.13968</link>
<guid>https://arxiv.org/abs/2408.13968</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、机器学习、电力调度、能源消耗、碳排放

总结:

本文研究了人工智能（AI）和机器学习（ML）技术在电力调度中的应用及其对环境的影响。随着现代电网向分布式系统转变，快速决策工具的需求日益增长。AI/ML模型能够显著提高电力调度效率，但同时也带来了高能耗和碳排放的问题。文章首次对比分析了集中式、分布式和去中心化ML驱动电力调度模型的能效与碳足迹。

研究采用IEEE 33节点系统进行了详细分析，揭示了不同模型在连续运行过程中的能源需求与碳排放差异。该研究强调了在提升电力系统管理效率的同时，确保生态可持续性的关键贸易-off。通过这一比较，文章旨在指导未来AI在能源领域的实施，确保其不仅提高效率，还重视生态完整性。这一工作对于促进绿色、智能电网的发展具有重要意义，为AI技术在电力行业的应用提供了环境考量框架。 <div>
arXiv:2408.13968v1 Announce Type: new 
Abstract: As the modern electrical grid shifts towards distributed systems, there is an increasing need for rapid decision-making tools. Artificial Intelligence (AI) and Machine Learning (ML) technologies are now pivotal in enhancing the efficiency of power dispatch operations, effectively overcoming the constraints of traditional optimization solvers with long computation times. However, this increased efficiency comes at a high environmental cost, escalating energy consumption and carbon emissions from computationally intensive AI/ML models. Despite their potential to transform power systems management, the environmental impact of these technologies often remains an overlooked aspect. This paper introduces the first comparison of energy demands across centralized, distributed, and decentralized ML-driven power dispatch models. We provide a detailed analysis of the energy and carbon footprint required for continuous operations on an IEEE 33 bus system, highlighting the critical trade-offs between operational efficiency and environmental sustainability. This study aims to guide future AI implementations in energy systems, ensuring they enhance not only efficiency but also prioritize ecological integrity.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>ORBITAAL: A Temporal Graph Dataset of Bitcoin Entity-Entity Transactions</title>
<link>https://arxiv.org/abs/2408.14147</link>
<guid>https://arxiv.org/abs/2408.14147</guid>
<content:encoded><![CDATA[
<div> 关键词：ORBITAAL、比特币交易、时间网络、数据集、经济与网络科学

<br /><br />
总结:

本文介绍了一项关于比特币交易的研究工作，旨在为经济与网络科学领域提供有价值的数据支持。研究关注点在于比特币（BTC）的去中心化系统特性，尽管其交易细节公开，但分析原始区块链数据具有挑战性。为此，研究人员开发了ORBITAAL，这是首个基于时间网络形式的全面数据集。该数据集涵盖了从2009年1月到2021年1月的所有比特币交易，提供了实体之间的交易网络的时间序列表示、快照和流图。每个交易的价值都以比特币和美元表示，参照每日的汇率转换。此外，数据集还详细记录了实体的全球BTC余额以及关联的公共地址信息。这项工作对于深入理解比特币生态系统的演化、交易模式及其对经济的影响具有重要意义。通过ORBITAAL，研究者和分析师可以更便捷地进行复杂数据分析，促进学术研究和行业应用的发展。 <div>
arXiv:2408.14147v1 Announce Type: new 
Abstract: Research on Bitcoin (BTC) transactions is a matter of interest for both economic and network science fields. Although this cryptocurrency is based on a decentralized system, making transaction details freely accessible, making raw blockchain data analyzable is not straightforward due to the Bitcoin protocol specificity and data richness. To address the need for an accessible dataset, we present ORBITAAL, the first comprehensive dataset based on temporal graph formalism. The dataset covers all Bitcoin transactions from January 2009 to January 2021. ORBITAAL provides temporal graph representations of entity-entity transaction networks, snapshots and stream graph. Each transaction value is given in Bitcoin and US dollar regarding daily-based conversion rate. This dataset also provides details on entities such as their global BTC balance and associated public addresses.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Probabilistic Analysis and Empirical Validation of Patricia Tries in Ethereum State Management</title>
<link>https://arxiv.org/abs/2408.14217</link>
<guid>https://arxiv.org/abs/2408.14217</guid>
<content:encoded><![CDATA[
<div> 关键词：Patricia tries、Ethereum、数据结构分析、理论与实验验证、区块链优化

总结:
本文对以太坊状态管理系统的基础数据结构——Patricia tries进行了全面的理论和实证分析。研究开发了一种概率模型，用于描述包含随机以太坊地址的Patricia tries路径长度分布，并通过大量计算实验验证了这一模型。发现平均路径长度随地址数量呈对数级增长，这证实了以太坊可扩展性的关键属性。研究显示了预测平均路径长度的高精度，实验结果与理论结果之间的偏差不超过0.01，适用于从100到100,000个地址的不同规模测试。识别并验证了路径长度分布的右偏特性，提供了理解最坏情况场景的洞察，并为优化策略提供了信息。统计分析，包括卡方拟合优度检验，强烈支持模型的准确性。研究揭示了特定尝试级别节点集中度的结构洞察，建议优化存储和检索机制的方向。这些发现加深了对以太坊基本数据结构的理解，并为未来优化提供了坚实基础。研究还指出了未来研究可能的方向，包括极端规模行为、动态尝试性能以及模型对非均匀地址分布和其他区块链系统的适用性。 <div>
arXiv:2408.14217v1 Announce Type: new 
Abstract: This study presents a comprehensive theoretical and empirical analysis of Patricia tries, the fundamental data structure underlying Ethereum's state management system. We develop a probabilistic model characterizing the distribution of path lengths in Patricia tries containing random Ethereum addresses and validate this model through extensive computational experiments. Our findings reveal the logarithmic scaling of average path lengths with respect to the number of addresses, confirming a crucial property for Ethereum's scalability. The study demonstrates high precision in predicting average path lengths, with discrepancies between theoretical and experimental results not exceeding 0.01 across tested scales from 100 to 100,000 addresses. We identify and verify the right-skewed nature of path length distributions, providing insights into worst-case scenarios and informing optimization strategies. Statistical analysis, including chi-square goodness-of-fit tests, strongly supports the model's accuracy. The research offers structural insights into node concentration at specific trie levels, suggesting avenues for optimizing storage and retrieval mechanisms. These findings contribute to a deeper understanding of Ethereum's fundamental data structures and provide a solid foundation for future optimizations. The study concludes by outlining potential directions for future research, including investigations into extreme-scale behavior, dynamic trie performance, and the applicability of the model to non-uniform address distributions and other blockchain systems.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hyperdimensional Computing Empowered Federated Foundation Model over Wireless Networks for Metaverse</title>
<link>https://arxiv.org/abs/2408.14416</link>
<guid>https://arxiv.org/abs/2408.14416</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、联邦学习、超维计算、资源约束、实时交互

<br /><br />
总结:
文章探讨了元宇宙背景下，联邦学习（FL）技术在支持沉浸式和互动体验方面的作用，以及它面临的挑战，如高通信开销和巨大的计算需求。针对神经网络模型，提出了一种创新的联邦分裂学习与超维计算（FSL-HDC）框架，旨在减少通信成本、计算负载和隐私风险，使其更适合元宇宙中资源受限的边缘设备。此框架确保了实时响应的交互性。此外，引入了一种优化算法，同时优化传输功率和带宽，以最小化所有用户到服务器的最大传输时间。基于MNIST数据集的模拟结果显示，FSL-HDC在准确率上略低于FL-HDC，但其收敛速度明显更快，大约是FSL-NN的3.733倍，并且对非同质分布数据具有更强的鲁棒性。提出的优化算法可将最大传输时间降低至最多64%。 <div>
arXiv:2408.14416v1 Announce Type: new 
Abstract: The Metaverse, a burgeoning collective virtual space merging augmented reality and persistent virtual worlds, necessitates advanced artificial intelligence (AI) and communication technologies to support immersive and interactive experiences. Federated learning (FL) has emerged as a promising technique for collaboratively training AI models while preserving data privacy. However, FL faces challenges such as high communication overhead and substantial computational demands, particularly for neural network (NN) models. To address these issues, we propose an integrated federated split learning and hyperdimensional computing (FSL-HDC) framework for emerging foundation models. This novel approach reduces communication costs, computation load, and privacy risks, making it particularly suitable for resource-constrained edge devices in the Metaverse, ensuring real-time responsive interactions. Additionally, we introduce an optimization algorithm that concurrently optimizes transmission power and bandwidth to minimize the maximum transmission time among all users to the server. The simulation results based on the MNIST dataset indicate that FSL-HDC achieves an accuracy rate of approximately 87.5%, which is slightly lower than that of FL-HDC. However, FSL-HDC exhibits a significantly faster convergence speed, approximately 3.733x that of FSL-NN, and demonstrates robustness to non-IID data distributions. Moreover, our proposed optimization algorithm can reduce the maximum transmission time by up to 64% compared with the baseline.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Stochastic Control in Standard Borel Spaces: Centralized MDP Reductions, Near Optimality of Finite Window Local Information, and Q-Learning</title>
<link>https://arxiv.org/abs/2408.13828</link>
<guid>https://arxiv.org/abs/2408.13828</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式、随机控制、信息共享模式、弱费力性、近最优策略

<br /><br />
总结:本文探讨了分散式随机控制问题中的几个关键挑战。首先，它通过统一的主题，即一阶段延迟和K阶段周期的信息共享模式以及完全分散的信息结构，解决了分散式随机控制问题的复杂性。对于一阶段延迟和K阶段周期的问题，文章展示了如何将它们转化为集中式的马尔可夫决策过程（MDP），这扩展了先前研究中仅考虑有限、线性或静态模型的结果，并解决了与之相关的测量问题。此外，文章还证明了在两种信息结构下，政策具有分离性质。

文章进一步提供条件，确保集中式转换后的转移核具有弱费力性，这对于实现精确的近似和学习理论结果至关重要。接着，文章提出了一种联合条件混合性下的充分条件，表明在完全分散控制问题中，具有有限记忆的地方策略几乎是最优的。这通过证明随着记忆大小增加，有限记忆策略的界限趋于零来实现。

最后，文章展示了在周期信息共享模式下，量化Q学习算法可以收敛到接近最优解。这是首次在文献中提出的新贡献。这些发现为分散式随机控制领域提供了重要的理论基础和实践指导。 <div>
arXiv:2408.13828v1 Announce Type: cross 
Abstract: Decentralized stochastic control problems are intrinsically difficult to study because of the inapplicability of standard tools from centralized control such as dynamic programming and the resulting computational complexity. In this paper, we address some of these challenges for decentralized stochastic control with Borel spaces under three different but tightly related information structures under a unified theme: the one-step delayed information sharing pattern, the K-step periodic information sharing pattern, and the completely decentralized information structure where no sharing of information occurs. We will show that the one-step delayed and K-step periodic problems can be reduced to a centralized MDP, generalizing prior results which considered finite, linear, or static models, by addressing several measurability questions. The separated nature of policies under both information structures is then established. We then provide sufficient conditions for the transition kernels of both centralized reductions to be weak-Feller, which facilitates rigorous approximation and learning theoretic results. We will then show that for the completely decentralized control problem finite memory local policies are near optimal under a joint conditional mixing condition. This is achieved by obtaining a bound for finite memory policies which goes to zero as memory size increases. We will also provide a performance bound for the K-periodic problem, which results from replacing the full common information by a finite sliding window of information. The latter will depend on the condition of predictor stability in expected total variation, which we will establish. We finally show that under the periodic information sharing pattern, a quantized Q-learning algorithm converges asymptotically towards a near optimal solution. Each of the above, to our knowledge, is a new contribution to the literature.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Singular Value Decomposition for Extremely Large-scale Antenna Array Systems</title>
<link>https://arxiv.org/abs/2408.14292</link>
<guid>https://arxiv.org/abs/2408.14292</guid>
<content:encoded><![CDATA[
<div> 关键词：d-SVD、d-PCA、ELAA系统、低秩矩阵完成、被动雷达检测

<br />
<br />总结:

本文研究了分布式奇异值分解(d-SVD)和分布式主成分分析(d-PCA)，这两个方法在各种信号处理应用中是基础。文章提出了两种场景下的d-SVD算法，分别适用于数据矩阵在每个本地节点以行方式可用的情况，以及数据矩阵通过两个不同测量系列生成外积隐式形成的情况。为了应对这些场景，文章利用轻量级局部有理函数近似方法和并行平均一致性算法，设计了两种d-SVD算法。此外，还提出了一种非平凡的裁剪技术，通过使用与主信号子空间正交的代表向量来进一步降低通信成本。通过在极大规模天线阵列(ELAA)系统的两个应用示例中应用这些算法——分散式传感器定位通过低秩矩阵完成和分散式被动雷达检测——证明了算法的有效性。仿真结果表明，与现有技术支持的分散式功率方法相比，提出的d-SVD算法能够收敛到中心解决方案，并具有较低的通信成本。 <div>
arXiv:2408.14292v1 Announce Type: cross 
Abstract: In this article, the problems of decentralized Singular Value Decomposition (d-SVD) and decentralized Principal Component Analysis (d-PCA) are studied, which are fundamental in various signal processing applications. Two scenarios of d-SVD are considered depending on the availability of the data matrix under consideration. In the first scenario, the matrix of interest is row-wisely available in each local node in the network. In the second scenario, the matrix of interest implicitly forms an outer product generated from two different series of measurements. Combining the lightweight local rational function approximation approach and parallel averaging consensus algorithms, two d-SVD algorithms are proposed to cope with the two aforementioned scenarios. We demonstrate the proposed algorithms with two respective application examples for Extremely Large-scale Antenna Array (ELAA) systems: decentralized sensor localization via low-rank matrix completion and decentralized passive radar detection. Moreover, a non-trivial truncation technique, which employs a representative vector that is orthonormal to the principal signal subspace, is proposed to further reduce the associated communication cost with the d-SVD algorithms. Simulation results show that the proposed d-SVD algorithms converge to the centralized solution with reduced communication cost compared to those facilitated with the state-of-the-art decentralized power method.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>UAMM: Price-oracle based Automated Market Maker</title>
<link>https://arxiv.org/abs/2308.06375</link>
<guid>https://arxiv.org/abs/2308.06375</guid>
<content:encoded><![CDATA[
<div> 关键词：自动化市场制作器(AMM)、去中心化交易所(DEX)、外部市场价格、流动性提供者、永久性损失

<br /><br />
总结:
本文提出了一种名为UBET AMM（UAMM）的新方法，它通过考虑外部市场的价格以及流动性池的潜在永久性损失来计算价格。这一创新之处在于，尽管依赖于外部市场价格，UAMM仍能保持常数乘积曲线计算滑点的特性，从而确保了交易的公平性和效率。关键在于，UAMM通过设定目标余额来决定合适的滑点量，鼓励流动性提供者最小化永久性损失。文章证明，在外部市场价格有效的情况下，这种方法能够消除套利机会，显著提高了去中心化交易所的运作效率和稳定性。 <div>
arXiv:2308.06375v2 Announce Type: replace 
Abstract: Automated market makers (AMMs) are pricing mechanisms utilized by decentralized exchanges (DEX). Traditional AMM approaches are constrained by pricing solely based on their own liquidity pool, without consideration of external markets or risk management for liquidity providers. In this paper, we propose a new approach known as UBET AMM (UAMM), which calculates prices by considering external market prices and the impermanent loss of the liquidity pool. Despite relying on external market prices, our method maintains the desired properties of a constant product curve when computing slippages. The key element of UAMM is determining the appropriate slippage amount based on the desired target balance, which encourages the liquidity pool to minimize impermanent loss. We demonstrate that our approach eliminates arbitrage opportunities when external market prices are efficient.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal AoI-based Block Propagation and Incentive Mechanism for Blockchain Networks in Web 3.0</title>
<link>https://arxiv.org/abs/2403.12807</link>
<guid>https://arxiv.org/abs/2403.12807</guid>
<content:encoded><![CDATA[
<div> 关键词：Web 3.0、区块链、Age of Block Information（AoBI）、矿工状态分类、激励机制

<br />
总结:本文提出了一种针对Web 3.0的创新性框架，旨在优化区块链中的区块传播过程。首先，引入了基于年龄信息概念的新鲜度指标——Block Information Age（AoBI），用于量化区块的时效性。AoBI衡量从最新交易生成到完成区块共识的时间间隔。其次，通过将矿工分为五种不同状态，并借鉴流行病模型构建了一个区块传播模型，以提高传播效率。考虑到矿工的有限理性，作者提出了基于演化博弈的激励机制，进一步优化区块传播。实验结果表明，与现有机制相比，所提出的方案提高了区块转发概率，降低了平均AoBI的最小值，从而提升了整体的区块传播效率。 <div>
arXiv:2403.12807v2 Announce Type: replace 
Abstract: Web 3.0 is regarded as a revolutionary paradigm that enables users to securely manage data without a centralized authority. Blockchains, which enable data to be managed in a decentralized and transparent manner, are key technologies for achieving Web 3.0 goals. However, Web 3.0 based on blockchains is still in its infancy, such as ensuring block freshness and optimizing block propagation for improving blockchain performance. In this paper, we develop a freshness-aware block propagation optimization framework for Web 3.0. We first propose a novel metric called Age of Block Information (AoBI) based on the concept of age of information to quantify block freshness. AoBI measures the time elapsed from the freshest transaction generation to the completion of block consensus. To make block propagation optimization tractable, we classify miners into five different states and propose a block propagation model for public blockchains inspired by epidemic models. Moreover, considering that the miners are bounded rational, we propose an incentive mechanism based on the evolutionary game for block propagation to improve block propagation efficiency. Numerical results demonstrate that compared with other block propagation mechanisms in public blockchains, the proposed scheme has a higher block forwarding probability, which improves block propagation efficiency and decreases the minimum value of average AoBI.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized MIMO Systems with LMMSE Receivers and Imperfect CSI</title>
<link>https://arxiv.org/abs/2408.12811</link>
<guid>https://arxiv.org/abs/2408.12811</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模MIMO系统、分散式基带处理、线性最小均方误差接收机、随机矩阵理论、信号干扰与噪声比

<br />
总结:

本文针对大规模多输入多输出（MIMO）系统的全潜力实现，讨论了集中式基带处理（CBP）面临的数据互联和高维计算两大挑战。为解决这些问题，提出了分散式基带处理（DBP），通过将基站的天线分割成多个集群，每个集群连接独立的射频电路并配备独立的计算单元。然而，现有文献中缺乏适用于一般集群间空间相关性和不完整信道状态信息（CSI）的最优融合方案及性能分析。

文章首先构建了一个所有集群都采用线性最小均方误差（LMMSE）接收器的分散式MIMO系统模型，且考虑了不完善的CSI情况。通过利用随机矩阵理论（RMT），建立了最优线性融合方案，并分析了其高计算和数据I/O成本。为了降低成本，进一步提出了两种具有较低复杂性的次优融合方案。对所有三种方案，均推导了信号干扰与噪声比（SINR）的封闭形式表达式，并阐述了在何种条件下次优方案能成为最优选择。此外，确定了分散式LMMSE接收器的最优正则化参数，识别了最佳天线分区策略，并证明了随着集群数量的增加，SINR会下降。数值模拟验证了理论结果的准确性。 <div>
arXiv:2408.12811v1 Announce Type: new 
Abstract: Centralized baseband processing (CBP) is required to achieve the full potential of massive multiple-input multiple-output (MIMO) systems. However, due to the large number of antennas, CBP suffers from two major issues: 1) Tremendous data interconnection between radio frequency (RF) circuitry and processing fabrics; and 2) high-dimensional computation. To this end, decentralized baseband processing (DBP) has been proposed, where the antennas at the BS are partitioned into clusters connected to separate RF circuits and equipped with separate computing units. Unfortunately, due to the decentralized structure, the optimal fusion scheme and performance analysis for DBP with general spatial correlation between clusters and imperfect channel state information (CSI) are not available in the literature. In this paper, we consider a decentralized MIMO system where all clusters adopt linear minimum mean-square error (LMMSE) receivers with imperfect CSI. Specifically, we first establish the optimal linear fusion scheme which has high computational and data input/output (I/O) costs. To reduce the costs, we further propose two sub-optimal fusion schemes with reduced complexity. For all three schemes, we derive the closed-form expressions for the signal-to-interference-and-noise ratio (SINR) by leveraging random matrix theory (RMT) and demonstrate the conditions under which the sub-optimal schemes are optimal. Furthermore, we determine the optimal regularization parameter for decentralized LMMSE receivers, identify the best antenna partitioning strategy, and prove that the SINR will decrease as the number of clusters increases. Numerical simulations validate the accuracy of the theoretical results.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Optimally Solving Simultaneous-Move Dec-POMDPs: The Sequential Central Planning Approach</title>
<link>https://arxiv.org/abs/2408.13139</link>
<guid>https://arxiv.org/abs/2408.13139</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式执行、贝尔曼原则、价值函数、规划复杂度、单代理方法

总结:

本文提出了一种新的分散式执行范式——顺序行动集中训练，以解决分散式部分可观测马尔可夫决策过程中的ε最优问题。该范式在保持贝尔曼原则的适用性的同时，引入了三个关键特性：

1. **集中规划者视角转变**：允许集中规划者基于顺序行动统计数据进行决策，而非先前的并行行动统计数据。这为集中规划者提供了一种更有效的信息基础。

2. **ε最优价值函数性质**：证明了在充分的顺序行动统计数据下，ε最优价值函数具有分段线性和凸性。这一性质简化了对价值函数的分析和优化过程。

3. **降低规划复杂度**：通过采用顺序行动策略，将备份操作者的复杂度从双指数级降低至多项式级，尽管这可能需要更长的规划时间。

4. **兼容单代理方法**：这一范式使得现有的单代理学习算法，如增强SARSA，能够直接应用于多代理系统中，同时仍能保证收敛性。

5. **实验验证**：通过在两种及多种代理的领域与ε最优并行行动解决方案进行比较，实验证明了新方法的优越性。

这种新型范式为多代理系统的高效规划和强化学习方法开辟了新的路径，显著提高了处理复杂多代理环境的能力。 <div>
arXiv:2408.13139v1 Announce Type: new 
Abstract: Centralized training for decentralized execution paradigm emerged as the state-of-the-art approach to epsilon-optimally solving decentralized partially observable Markov decision processes. However, scalability remains a significant issue. This paper presents a novel and more scalable alternative, namely sequential-move centralized training for decentralized execution. This paradigm further pushes the applicability of Bellman's principle of optimality, raising three new properties. First, it allows a central planner to reason upon sufficient sequential-move statistics instead of prior simultaneous-move ones. Next, it proves that epsilon-optimal value functions are piecewise linear and convex in sufficient sequential-move statistics. Finally, it drops the complexity of the backup operators from double exponential to polynomial at the expense of longer planning horizons. Besides, it makes it easy to use single-agent methods, e.g., SARSA algorithm enhanced with these findings applies while still preserving convergence guarantees. Experiments on two- as well as many-agent domains from the literature against epsilon-optimal simultaneous-move solvers confirm the superiority of the novel approach. This paradigm opens the door for efficient planning and reinforcement learning methods for multi-agent systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reconfigurable Heterogeneous Quorum Systems</title>
<link>https://arxiv.org/abs/2304.02156</link>
<guid>https://arxiv.org/abs/2304.02156</guid>
<content:encoded><![CDATA[
<div> 关键词：拜占庭容错、异构信任模型、开放成员身份、一致性、可重构性

总结:

本文探讨了异构拜占庭容错（Byzantine Fault Tolerance, BFT）系统，作为分布式网络中的一类高效、低能耗且具备确定性活性的共识机制。这些系统相较于工作量证明机制（Proof-of-Work），在吞吐量和能源效率方面展现出优势，同时保证了一致性和确定性，使其成为区块链基础设施的潜在选择。

文章首先构建了一个异构拜占庭容错系统的通用模型，允许参与者自定义自己的共识集（quorums）。通过这一模型，研究者揭示了这些系统在一致性、可用性和包容性方面的特性。为了支持开放成员身份，文章提出了针对异构拜占庭容错系统的动态重组协议，包括加入/退出过程以及共识集的增删操作，并证明了这些协议在面对恶意节点攻击时的正确性。

文章还深入分析了重新配置过程中对系统关键属性的影响，例如一致性、可用性和包容性，从而指导了协议设计时的权衡考虑。进一步地，作者提出了一种基于图论的异构拜占庭容错系统表示方法，为优化系统重组过程提供了理论基础。

综上所述，本文不仅为异构拜占庭容错系统的设计与实现提供了理论框架和技术指导，也为未来分布式网络和区块链技术的发展提供了新的视角和可能性。 <div>
arXiv:2304.02156v2 Announce Type: replace 
Abstract: In contrast to proof-of-work replication, Byzantine quorum systems maintain consistency across replicas with higher throughput modest energy consumption, and deterministic liveness guarantees. If complemented with heterogeneous trust and open membership, they have the potential to serve as blockchains backbone. This paper presents a general model of heterogeneous quorum systems where each participant can declare its own quorums, and captures the consistency, availability and inclusion properties of these systems. In order to support open membership, it then presents reconfiguration protocols for heterogeneous quorum systems including joining and leaving of a process, and adding and removing of a quorum, and further, proves their correctness in the face of Byzantine attacks. The design of the protocols is informed by the trade-offs that the paper proves for the properties that reconfigurations can preserve. The paper further presents a graph characterization of heterogeneous quorum systems, and its application for reconfiguration optimization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Evaluation of Hash Algorithm Performance for Cryptocurrency Exchanges Based on Blockchain System</title>
<link>https://arxiv.org/abs/2408.11950</link>
<guid>https://arxiv.org/abs/2408.11950</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链系统、哈希值、安全性、执行效率、Proof of Work

总结:
本文主要探讨了主流哈希算法（SHA-2、SHA-3、BLAKE2）在区块链系统中的安全性和执行效率，特别是它们在工作量证明（PoW）计算中的应用。研究通过提出评价指标并进行对比实验，对这些算法进行了全面评估。

实验结果表明，SHA-2、SHA-3和BLAKE2在安全性方面表现相近，均能有效保障区块链系统的完整性。然而，在执行效率上，SHA-2和BLAKE2展现出更短的计算时间，意味着更高的执行效率。

综上所述，虽然SHA-2、SHA-3和BLAKE2在安全性方面表现出色，但SHA-2和BLAKE2由于其更快的计算速度，可能在实际应用中提供更好的性能。这对于寻求在保证数据安全的同时优化系统响应时间和资源利用的区块链开发者来说，具有重要意义。 <div>
arXiv:2408.11950v1 Announce Type: new 
Abstract: The blockchain system has emerged as one of the focal points of research in recent years, particularly in applications and services such as cryptocurrencies and smart contracts. In this context, the hash value serves as a crucial element in linking blocks within the blockchain, ensuring the integrity of block contents. Therefore, hash algorithms represent a vital security technology for ensuring the integrity and security of blockchain systems. This study primarily focuses on analyzing the security and execution efficiency of mainstream hash algorithms in the Proof of Work (PoW) calculations within blockchain systems. It proposes an evaluation factor and conducts comparative experiments to evaluate each hash algorithm. The experimental results indicate that there are no significant differences in the security aspects among SHA-2, SHA-3, and BLAKE2. However, SHA-2 and BLAKE2 demonstrate shorter computation times, indicating higher efficiency in execution.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decoding SEC Actions: Enforcement Trends through Analyzing Blockchain litigation using LLM-based Thematic Factor Mapping</title>
<link>https://arxiv.org/abs/2408.11961</link>
<guid>https://arxiv.org/abs/2408.11961</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链实体、监管行动、美国证券交易委员会(SEC)、法律诉讼、系统分析

总结:

本文聚焦于美国证券交易委员会(SEC)对区块链实体的法律诉讼情况，特别是自2012年至2024年的投诉记录。研究通过前沿预训练语言模型和大型语言模型，系统地将这些投诉与研究中概念化的主题因素进行映射，以揭示驱动SEC行动的关键因素。研究量化了这些主题因素，并评估了它们对投诉中引用的具体法律法案的影响，从而揭示了监管重点、模式和行为趋势。

文章首先通过构建一个全面的数据库，汇集了SEC针对区块链公司的所有投诉信息，接着运用先进的自然语言处理技术，识别并分类了投诉中的关键主题。这不仅帮助理解SEC执法行动的动机，还为行业参与者提供了指导，帮助他们更好地遵守法律法规，避免潜在的法律风险。同时，对于投资者而言，这项研究提供了深入的洞察，有助于其做出更明智的投资决策。

研究发现，SEC对区块链领域的关注点随着时间的推移而变化，反映了全球加密资产法规的发展趋势。通过分析不同年份的投诉，可以清晰地看到哪些法律条款成为了SEC执法的重点，以及这些焦点如何影响了区块链行业的合规环境。这为未来的政策制定者、行业从业者以及投资者提供了一个宝贵的参考框架，有助于构建更加透明、规范的区块链生态系统。 <div>
arXiv:2408.11961v1 Announce Type: new 
Abstract: The proliferation of blockchain entities (persons or enterprises) exposes them to potential regulatory actions (e.g., being litigated) by regulatory authorities. Regulatory frameworks for crypto assets are actively being developed and refined, increasing the likelihood of such actions. The lack of systematic analysis of the factors driving litigation against blockchain entities leaves companies in need of clarity to navigate compliance risks. This absence of insight also deprives investors of the information for informed decision-making. This study focuses on U.S. litigation against blockchain entities, particularly by the U.S. Securities and Exchange Commission (SEC) given its influence on global crypto regulation. Utilizing frontier pretrained language models and large language models, we systematically map all SEC complaints against blockchain companies from 2012 to 2024 to thematic factors conceptualized by our study to delineate the factors driving SEC actions. We quantify the thematic factors and assess their influence on specific legal Acts cited within the complaints on an annual basis, allowing us to discern the regulatory emphasis, patterns and conduct trend analysis.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decoding Decentralized Finance Transactions through Ego Network Motif Mining</title>
<link>https://arxiv.org/abs/2408.12311</link>
<guid>https://arxiv.org/abs/2408.12311</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance（DeFi）、智能合约、网络图谱、账户活动、交易分析

<br /><br />
总结:

本文探讨了如何通过分析去中心化金融(DeFi)中的令牌转移网络来理解投资者的使用模式及提供监管依据。研究面临的主要挑战是数据的不完整性和准确性问题。为解决这一难题，作者提出了一种方法，即从令牌转移网络中提取“ego网络模态”，以捕捉用户与智能合约之间的令牌转移情况。

通过这种方法，研究人员能够高效地识别执行特定DeFi操作的智能合约方法，同时揭示账户活动的细节。该技术不仅有助于深入了解DeFi的应用场景和参与者行为，也为制定合理的监管政策提供了数据支持。进一步地，这种分析手段能够帮助金融机构和监管机构更好地监控DeFi生态系统，预防潜在风险，促进金融市场的健康发展。 <div>
arXiv:2408.12311v1 Announce Type: new 
Abstract: Decentralized Finance (DeFi) is increasingly studied and adopted for its potential to provide accessible and transparent financial services. Analyzing how investors use DeFi is important for reaching a better understanding of their usage and for regulation purposes. However, analyzing DeFi transactions is challenging due to often incomplete or inaccurate labeled data. This paper presents a method to extract ego network motifs from the token transfer network, capturing the transfer of tokens between users and smart contracts. Our results demonstrate that smart contract methods performing specific DeFi operations can be efficiently identified by analyzing these motifs while providing insights into account activities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi Agent Framework for Collective Intelligence Research</title>
<link>https://arxiv.org/abs/2408.12391</link>
<guid>https://arxiv.org/abs/2408.12391</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式多代理框架、信息交换、合成局部感知图、无人机、实现实验室

文章主要介绍了一种可扩展的分布式多代理体系结构，旨在通过计算机网络促进计算单元之间的信息交流。该体系结构具备实现从简单的消息交换到复杂的实体交互（如虚拟无人机之间的位置共享或与真实Crazyflie无人机在VU阿姆斯特丹实验室内的信息交换）的能力。通过引入领域调制理论来构建代理的合成局部感知地图，这些地图基于相邻代理的位置和环境中的兴趣点。实验设定在2维环境中，具有固定的行动、速度和参数，以适应VU阿姆斯特丹实验室的条件。实验中，运行着爬山控制器的无人机能够遵循无碰撞轨迹，并成功跨越了仿真与实际操作之间的差距。

总结:
该研究提出了一种分布式多代理框架，旨在通过计算机网络促进信息交换。关键特性包括：
1. 实现从简单消息到复杂实体交互的信息交换。
2. 使用领域调制理论构建合成局部感知地图。
3. 设定在2维环境下的实验，适用于VU阿姆斯特丹实验室。
4. 无人机使用爬山控制器，能遵循无碰撞轨迹。
5. 成功跨越了仿真与实际操作之间的差距。 <div>
arXiv:2408.12391v1 Announce Type: new 
Abstract: This paper presents a scalable decentralized multi agent framework that facilitates the exchange of information between computing units through computer networks. The architectural boundaries imposed by the tool make it suitable for collective intelligence research experiments ranging from agents that exchange hello world messages to virtual drone agents exchanging positions and eventually agents exchanging information via radio with real Crazyflie drones in VU Amsterdam laboratory. The field modulation theory is implemented to construct synthetic local perception maps for agents, which are constructed based on neighbouring agents positions and neighbouring points of interest dictated by the environment. By constraining the experimental setup to a 2D environment with discrete actions, constant velocity and parameters tailored to VU Amsterdam laboratory, UAV Crazyflie drones running hill climbing controller followed collision-free trajectories and bridged sim-to-real gap.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Looking AT the Blue Skies of Bluesky</title>
<link>https://arxiv.org/abs/2408.12449</link>
<guid>https://arxiv.org/abs/2408.12449</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized social networks, Bluesky, Microblogging platform, Third party stakeholders, User activity

总结:

本文通过大型分析探讨了Bluesky这一主要去中心化微型博客平台。与Mastodon等替代方法不同，Bluesky将平台的关键功能分解为可由第三方提供者提供的子组件。研究收集并分析了覆盖Bluesky所有关键元素的全面数据集，以评估每个子组件提供商的多样性。去中心化社交网络旨在赋权用户，但也带来了自身的权衡和挑战。Bluesky的独特之处在于其开放性设计，允许第三方参与平台核心功能的提供，从而实现更大程度的灵活性和社区自治。研究发现，这种架构不仅增强了用户活动的多样性，也为探索更加民主、透明的在线交流模式提供了新的可能性。然而，去中心化的复杂性也意味着管理和协调的难度增加，如何平衡技术发展与社会需求成为未来研究的重要方向。 <div>
arXiv:2408.12449v1 Announce Type: new 
Abstract: The pitfalls of centralized social networks, such as Facebook and Twitter/X, have led to concerns about control, transparency, and accountability. Decentralized social networks have emerged as a result with the goal of empowering users. These decentralized approaches come with their own tradeoffs, and therefore multiple architectures exist. In this paper, we conduct the first large-scale analysis of Bluesky, a prominent decentralized microblogging platform. In contrast to alternative approaches (e.g. Mastodon), Bluesky decomposes and opens the key functions of the platform into subcomponents that can be provided by third party stakeholders. We collect a comprehensive dataset covering all the key elements of Bluesky, study user activity and assess the diversity of providers for each sub-components.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Adaptive Layer Splitting for Wireless LLM Inference in Edge Computing: A Model-Based Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2406.02616</link>
<guid>https://arxiv.org/abs/2406.02616</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、边缘计算、优化部署、无线推理、模型强化学习

<br /><br />
总结:

本文聚焦于提升大型语言模型（LLM）在边缘计算环境中的部署效率与隐私保护。研究首先全面分析了主流开源LLM在不同划分点上的影响，以此为基础，提出了一种基于模型强化学习（MBRL）框架的方法来确定边缘设备与用户终端间的最优划分点。该方法通过引入奖励代理模型，显著降低了频繁性能评估的计算成本。通过大量模拟实验，证明了这种方法在不同网络条件下能够有效平衡推理性能与计算负载，提供了一种在分布式设置中稳健的LLM部署解决方案。 <div>
arXiv:2406.02616v4 Announce Type: replace 
Abstract: Optimizing the deployment of large language models (LLMs) in edge computing environments is critical for enhancing privacy and computational efficiency. Toward efficient wireless LLM inference in edge computing, this study comprehensively analyzes the impact of different splitting points in mainstream open-source LLMs. On this basis, this study introduces a framework taking inspiration from model-based reinforcement learning (MBRL) to determine the optimal splitting point across the edge and user equipment (UE). By incorporating a reward surrogate model, our approach significantly reduces the computational cost of frequent performance evaluations. Extensive simulations demonstrate that this method effectively balances inference performance and computational load under varying network conditions, providing a robust solution for LLM deployment in decentralized settings.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>MEV Capture and Decentralization in Execution Tickets</title>
<link>https://arxiv.org/abs/2408.11255</link>
<guid>https://arxiv.org/abs/2408.11255</guid>
<content:encoded><![CDATA[
<div> 关键词：经济模型、执行票、MEV捕获、风险厌恶、中央化

<br /><br />
总结:

本文构建了一个经济模型来研究执行票（Execution Tickets）如何帮助以太坊协议从区块构建中捕获最大提取价值（MEV）。研究发现：

1. 当所有购买者在同质、无风险偏好和无资本成本的情况下，执行票能够完全捕获MEV。

2. 随着风险厌恶程度和资本成本的增加，MEV捕获能力会下降。

3. 在购买者存在异质性时，MEV捕获可能会非常低，单一主导购买者可以大量捕获MEV。然而，通过提案构建分离（Proposer-Builder Separation, PBS）机制，执行票购买者可以访问专业构建者的市场，这在一定程度上缓解了集中化问题。

4. 实际中，尽管引入了PBS机制，但仍然存在集中化趋势。在PBS机制下，执行票主要集中在那些具有最高前向MEV提取能力和最低资本成本的参与者手中。

5. 文章指出，即使非构建者的大投资者，如果在资本成本上有显著优势，也可能主导执行票市场。这揭示了以太坊生态系统中可能存在的集中化风险及其复杂性。 <div>
arXiv:2408.11255v1 Announce Type: new 
Abstract: We provide an economic model of Execution Tickets and use it to study the ability of the Ethereum protocol to capture MEV from block construction. We demonstrate that Execution Tickets extract all MEV when all buyers are homogeneous, risk neutral and face no capital costs. We also show that MEV capture decreases with risk aversion and capital costs. Moreover, when buyers are heterogeneous, MEV capture can be especially low and a single dominant buyer can extract much of the MEV. This adverse effect can be partially mitigated by the presence of a Proposer Builder Separation (PBS) mechanism, which gives ET buyers access to a market of specialized builders, but in practice centralization vectors still persist. With PBS, ETs are concentrated among those with the highest ex-ante MEV extraction ability and lowest cost of capital. We show how it is possible that large investors that are not builders but have substantial advantage in capital cost can come to dominate the ET market.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-Preserving Data Management using Blockchains</title>
<link>https://arxiv.org/abs/2408.11263</link>
<guid>https://arxiv.org/abs/2408.11263</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、隐私保护、数据管理、查询处理、安全

<br /><br />
总结:

本文提出了一种基于区块链的隐私保护方法，旨在解决数据提供者在数据存储和使用过程中隐私保护的问题。传统隐私保护策略往往忽略了数据提供者对隐私偏好随时间变化的需求。针对这一问题，研究提出了将数据提供者的私有属性数据元素与隐私偏好紧密结合，同时将数据访问者数据元素与隐私元组关联起来的新框架。该框架结合了关系型数据库和区块链技术，构建了一个高效、防篡改的数据管理和查询处理平台。

实施阶段，研究设计了一个紧密耦合的数据库和区块链架构，以实现数据的安全性、抗篡改性和高效的查询性能。通过实证分析，验证了在该基础设施上执行隐私意识查询的效率。该方法不仅提高了数据安全性，还允许数据提供者灵活地更新其隐私偏好，以适应不断变化的数据使用场景。 <div>
arXiv:2408.11263v1 Announce Type: new 
Abstract: Privacy-preservation policies are guidelines formulated to protect data providers private data. Previous privacy-preservation methodologies have addressed privacy in which data are permanently stored in repositories and disconnected from changing data provider privacy preferences. This occurrence becomes evident as data moves to another data repository. Hence, the need for data providers to control and flexibly update their existing privacy preferences due to changing data usage continues to remain a problem. This paper proposes a blockchain-based methodology for preserving data providers private and sensitive data. The research proposes to tightly couple data providers private attribute data element to privacy preferences and data accessor data element into a privacy tuple. The implementation presents a framework of tightly-coupled relational database and blockchains. This delivers secure, tamper-resistant, and query-efficient platform for data management and query processing. The evaluation analysis from the implementation validates efficient query processing of privacy-aware queries on the privacy infrastructure.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Deep Reinforcement Learning for Decentralized Multi-Robot Control: A DQN Approach to Robustness and Information Integration</title>
<link>https://arxiv.org/abs/2408.11339</link>
<guid>https://arxiv.org/abs/2408.11339</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Robot Systems、Deep Q-Network (DQN)、Decentralized Control、Deep Reinforcement Learning、Robustness

<br /><br />
总结:
本文提出了一种基于深度强化学习中的深度Q网络（DQN）算法的新颖分布式控制器设计方法，旨在提高多机器人系统中局部信息整合与整体系统的鲁棒性。该控制器允许每个机器人独立地根据其本地观察结果做出决策，同时通过共享学习机制增强系统协作效率和对动态环境的适应性。研究在模拟环境中进行了测试，证明了此控制器能有效提升任务执行效率，增强系统故障容忍度，并提高环境适应能力。此外，文章还探讨了DQN参数调整对系统性能的影响，为控制器设计的进一步优化提供了见解。研究成果不仅展示了DQN算法在多机器人系统分布式控制领域的应用潜力，也提供了通过集成局部信息来提升系统整体性能和鲁棒性的新视角。 <div>
arXiv:2408.11339v1 Announce Type: new 
Abstract: The superiority of Multi-Robot Systems (MRS) in various complex environments is unquestionable. However, in complex situations such as search and rescue, environmental monitoring, and automated production, robots are often required to work collaboratively without a central control unit. This necessitates an efficient and robust decentralized control mechanism to process local information and guide the robots' behavior. In this work, we propose a new decentralized controller design method that utilizes the Deep Q-Network (DQN) algorithm from deep reinforcement learning, aimed at improving the integration of local information and robustness of multi-robot systems. The designed controller allows each robot to make decisions independently based on its local observations while enhancing the overall system's collaborative efficiency and adaptability to dynamic environments through a shared learning mechanism. Through testing in simulated environments, we have demonstrated the effectiveness of this controller in improving task execution efficiency, strengthening system fault tolerance, and enhancing adaptability to the environment. Furthermore, we explored the impact of DQN parameter tuning on system performance, providing insights for further optimization of the controller design. Our research not only showcases the potential application of the DQN algorithm in the decentralized control of multi-robot systems but also offers a new perspective on how to enhance the overall performance and robustness of the system through the integration of local information.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Systematic Literature Review on the Use of Blockchain Technology in Transition to a Circular Economy</title>
<link>https://arxiv.org/abs/2408.11664</link>
<guid>https://arxiv.org/abs/2408.11664</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、循环经济、资源效率、透明供应链、系统架构

总结:

文章通过系统文献综述，探讨了区块链技术在循环经济中的应用与挑战。主要发现包括：

1. **区块链技术与循环经济的关系**：区块链因其去中心化和防篡改特性，能够提升供应链透明度与安全性，增强产品追溯性，对循环经济的资源效率提升有显著作用。

2. **术语与区块链形式**：文章讨论了相关术语，并介绍了区块链的不同形式如何适应循环经济的需求，如智能合约、去中心化自治组织（DAO）等。

3. **面临的挑战与障碍**：尽管区块链在循环经济中潜力巨大，但需解决的挑战包括可扩展性、互操作性、数据保护以及法律合规性等问题。

4. **促进资源节约、价格优化与效率改进**：通过区块链驱动的循环经济模型，可以实现资源消耗最小化、成本降低和流程优化，鼓励产品的再利用、回收和循环。

5. **需要更多研究与参与**：为了克服上述挑战并充分发挥区块链技术的潜力，文章强调了进一步研究与利益相关者参与的重要性，以确保循环经济模式的有效实施。

文章揭示了区块链技术在推动循环经济转型中的关键作用，同时也指出了实现这一目标所需面对的复杂性与挑战，呼吁学术界与行业共同努力，克服障碍，最大化利用技术优势，促进可持续发展。 <div>
arXiv:2408.11664v1 Announce Type: new 
Abstract: The circular economy has the potential to increase resource efficiency and minimize waste through the 4R framework of reducing, reusing, recycling, and recovering. Blockchain technology is currently considered a valuable aid in the transition to a circular economy. Its decentralized and tamper-resistant nature enables the construction of transparent and secure supply chain management systems, thereby improving product accountability and traceability. However, the full potential of blockchain technology in circular economy models will not be realized until a number of concerns, including scalability, interoperability, data protection, and regulatory and legal issues, are addressed. More research and stakeholder participation are required to overcome these limitations and achieve the benefits of blockchain technology in promoting a circular economy. This article presents a systematic literature review (SLR) that identified industry use cases for blockchain-driven circular economy models and offered architectures to minimize resource consumption, prices, and inefficiencies while encouraging the reuse, recycling, and recovery of end-of-life products. Three main outcomes emerged from our review of 41 documents, which included scholarly publications, Twitter-linked information, and Google results. The relationship between blockchain and the 4R framework for circular economy; discussion the terminology and various forms of blockchain and circular economy; and identification of the challenges and obstacles that blockchain technology may face in enabling a circular economy. This research shows how blockchain technology can help with the transition to a circular economy. Yet, it emphasizes the importance of additional study and stakeholder participation to overcome potential hurdles and obstacles in implementing blockchain-driven circular economy models.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>RFID based Health Adherence Medicine Case Using Fair Federated Learning</title>
<link>https://arxiv.org/abs/2408.11782</link>
<guid>https://arxiv.org/abs/2408.11782</guid>
<content:encoded><![CDATA[
<div> 关键词：非依从性、智能药盒、RFID、NFC、联邦学习

总结:

文章主要探讨了医药非依从性的问题以及智能药盒在解决这一问题中的应用。非依从性指的是患者未能遵循医生开具的药物使用指导，这不仅降低了治疗效果，还可能增加死亡和住院风险。当前市场上已有诸如智能给药系统(IDAS)和智能药片等工具来帮助患者管理用药时间，但这些工具在商业推广中面临挑战。

为了解决这些问题，作者提出了一种基于物联网（IoT）原理的智能健康依从性工具——智能药盒。该药盒利用RFID进行数据记录和NFC进行数据提取，配备负载传感器以精确测量剂量，并配备Android应用程序监控用药情况、提供建议并发出警告。为了进一步提高工具的有效性和个性化，文章提出了将联邦学习整合到系统中。联邦学习允许智能药盒从多个用户的数据中学习，而不侵犯个人隐私。通过在不同智能药盒收集的分散数据上训练机器学习模型，系统可以不断改进其推荐和警报，适应用户的多样化需求和行为模式。这种方法不仅增强了工具支持用药依从性的能力，同时也确保了敏感用户数据的安全性和隐私性。 <div>
arXiv:2408.11782v1 Announce Type: new 
Abstract: Medication nonadherence significantly reduces the effectiveness of therapies, yet it remains prevalent among patients. Nonadherence has been linked to adverse outcomes, including increased risks of mortality and hospitalization. Although various methods exist to help patients track medication schedules, such as the Intelligent Drug Administration System (IDAS) and Smart Blister, these tools often face challenges that hinder their commercial viability. Building on the principles of dosage measurement and information communication in IoT, we introduce the Smart Pill Case a smart health adherence tool that leverages RFID-based data recording and NFC-based data extraction. This system incorporates a load cell for precise dosage measurement and features an Android app to monitor medication intake, offer suggestions, and issue warnings. To enhance the effectiveness and personalization of the Smart Pill Case, we propose integrating federated learning into the system. Federated learning allows the Smart Pill Case to learn from medication adherence patterns across multiple users without compromising individual privacy. By training machine learning models on decentralized data collected from various Smart Pill Cases, the system can continuously improve its recommendations and warnings, adapting to the diverse needs and behaviors of users. This approach not only enhances the tools ability to support medication adherence but also ensures that sensitive user data remains secure and private.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are We?</title>
<link>https://arxiv.org/abs/2309.05520</link>
<guid>https://arxiv.org/abs/2309.05520</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、智能合约、大型语言模型、ChatGPT、漏洞检测

总结:

本文探讨了大型语言模型（以ChatGPT为代表）在智能合约漏洞检测领域的应用与效能。研究首先通过评估ChatGPT在公开智能合约数据集上的表现，发现尽管其召回率较高，但在精确识别漏洞方面存在局限性。不同类型的漏洞对ChatGPT的影响也有所差异。

其次，对比分析显示，对于某些特定的7种漏洞类型，ChatGPT的F分数低于其他最先进的智能合约漏洞检测工具。然而，在另外四种漏洞中，ChatGPT则展现出轻微的优势。

最后，研究揭示了ChatGPT在智能合约漏洞检测领域存在的局限性，主要体现在其回答问题的不确定性以及检测代码长度的限制上。该研究为理解大型语言模型在智能合约安全领域的应用提供了深入见解，并指出了未来改进的方向。 <div>
arXiv:2309.05520v4 Announce Type: replace 
Abstract: With the development of blockchain technology, smart contracts have become an important component of blockchain applications. Despite their crucial role, the development of smart contracts may introduce vulnerabilities and potentially lead to severe consequences, such as financial losses. Meanwhile, large language models, represented by ChatGPT, have gained great attentions, showcasing great capabilities in code analysis tasks. In this paper, we presented an empirical study to investigate the performance of ChatGPT in identifying smart contract vulnerabilities. Initially, we evaluated ChatGPT's effectiveness using a publicly available smart contract dataset. Our findings discover that while ChatGPT achieves a high recall rate, its precision in pinpointing smart contract vulnerabilities is limited. Furthermore, ChatGPT's performance varies when detecting different vulnerability types. We delved into the root causes for the false positives generated by ChatGPT, and categorized them into four groups. Second, by comparing ChatGPT with other state-of-the-art smart contract vulnerability detection tools, we found that ChatGPT's F-score is lower than others for 3 out of the 7 vulnerabilities. In the case of the remaining 4 vulnerabilities, ChatGPT exhibits a slight advantage over these tools. Finally, we analyzed the limitation of ChatGPT in smart contract vulnerability detection, revealing that the robustness of ChatGPT in this field needs to be improved from two aspects: its uncertainty in answering questions; and the limited length of the detected code. In general, our research provides insights into the strengths and weaknesses of employing large language models, specifically ChatGPT, for the detection of smart contract vulnerabilities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Bi-CL: A Reinforcement Learning Framework for Robots Coordination Through Bi-level Optimization</title>
<link>https://arxiv.org/abs/2404.14649</link>
<guid>https://arxiv.org/abs/2404.14649</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人系统、协调学习、双层优化、集中式训练、分布式执行

总结:
本文提出了一种名为“双层协调学习”（Bi-CL）的新方法，旨在解决多机器人系统中协调任务的挑战。该方法通过在集中式训练和分布式执行框架下构建双层优化结构来实现这一目标。双层优化将原始问题分解为具有减小动作空间的强化学习层和从全局优化器获得示范的模仿学习层，从而提高了学习效率和可扩展性。然而，由于机器人信息不完整，导致了两个学习模型之间的不匹配。为了解决这个问题，Bi-CL引入了一个对齐惩罚机制，旨在最小化两层学习模型之间的差异，同时保持其训练效率。通过一个运行示例的概念化问题描述以及在基于路线和图的场景中的应用，文章展示了Bi-CL能够更高效地学习，并与传统的多代理强化学习基线在多机器人协调任务上达到相当的表现。 <div>
arXiv:2404.14649v2 Announce Type: replace 
Abstract: In multi-robot systems, achieving coordinated missions remains a significant challenge due to the coupled nature of coordination behaviors and the lack of global information for individual robots. To mitigate these challenges, this paper introduces a novel approach, Bi-level Coordination Learning (Bi-CL), that leverages a bi-level optimization structure within a centralized training and decentralized execution paradigm. Our bi-level reformulation decomposes the original problem into a reinforcement learning level with reduced action space, and an imitation learning level that gains demonstrations from a global optimizer. Both levels contribute to improved learning efficiency and scalability. We note that robots' incomplete information leads to mismatches between the two levels of learning models. To address this, Bi-CL further integrates an alignment penalty mechanism, aiming to minimize the discrepancy between the two levels without degrading their training efficiency. We introduce a running example to conceptualize the problem formulation and apply Bi-CL to two variations of this example: route-based and graph-based scenarios. Simulation results demonstrate that Bi-CL can learn more efficiently and achieve comparable performance with traditional multi-agent reinforcement learning baselines for multi-robot coordination.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Insights on Microservice Architecture Through the Eyes of Industry Practitioners</title>
<link>https://arxiv.org/abs/2408.10434</link>
<guid>https://arxiv.org/abs/2408.10434</guid>
<content:encoded><![CDATA[
<div> 关键词：微服务架构、迁移策略、数据一致性、挑战、云技术

总结:
本文研究了从传统的单体架构向微服务架构迁移的过程。研究基于对53位使用微服务的软件开发人员的调查，覆盖了国际多角度的观点。研究发现，迁移的主要驱动力包括提升维护效率、增强可扩展性以及优化部署流程。在迁移活动中，开发人员面临着复杂的测试环境构建、动态微服务管理以及数据一致性保障等挑战。特别是在数据库管理方面，虽然大多数参与者倾向于采用分布式数据库以获得自主性和可扩展性，但仍存在确保数据一致性的困难。此外，公司还利用现代云技术来降低网络延迟，这凸显了云基础设施在促进高效微服务通信中的重要性。研究强调了在迁移过程中面临的多种实践和挑战，为未来的企业架构转型提供了宝贵的见解。 <div>
arXiv:2408.10434v1 Announce Type: new 
Abstract: The adoption of microservice architecture has seen a considerable upswing in recent years, mainly driven by the need to modernize legacy systems and address their limitations. Legacy systems, typically designed as monolithic applications, often struggle with maintenance, scalability, and deployment inefficiencies. This study investigates the motivations, activities, and challenges associated with migrating from monolithic legacy systems to microservices, aiming to shed light on common practices and challenges from a practitioner's point of view. We conducted a comprehensive study with 53 software practitioners who use microservices, expanding upon previous research by incorporating diverse international perspectives. Our mixed-methods approach includes quantitative and qualitative analyses, focusing on four main aspects: (i) the driving forces behind migration, (ii) the activities to conduct the migration, (iii) strategies for managing data consistency, and (iv) the prevalent challenges. Thus, our results reveal diverse practices and challenges practitioners face when migrating to microservices. Companies are interested in technical benefits, enhancing maintenance, scalability, and deployment processes. Testing in microservice environments remains complex, and extensive monitoring is crucial to managing the dynamic nature of microservices. Database management remains challenging. While most participants prefer decentralized databases for autonomy and scalability, challenges persist in ensuring data consistency. Additionally, many companies leverage modern cloud technologies to mitigate network overhead, showcasing the importance of cloud infrastructure in facilitating efficient microservice communication.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fast Collective Evasion in Self-Localized Swarms of Unmanned Aerial Vehicles</title>
<link>https://arxiv.org/abs/2408.10596</link>
<guid>https://arxiv.org/abs/2408.10596</guid>
<content:encoded><![CDATA[
<div> 关键词：新型方法、快速规避、自组织无人机群、动态障碍物、集体行为

总结:
本文提出了一种针对受动态障碍物威胁的自定位无人机群的快速规避新策略。该策略灵感来源于自然群体生物（如鱼类学校和鸟群）的集体行为，通过利用有限的传感器信息和分散控制来实现群体动作的可靠性和有效性。系统设计旨在安全协调大量无人机，使其能够快速、协同地逃离接近的障碍物。与动物类似，系统通过内部传播关于检测到的障碍物的快速信息流，以实现动态和集体规避。整个系统采用分散式结构，仅依赖机载传感器进行相互定位，避免了对个体状态（位置和速度）信息的通信过载，同时保证了在通信中断情况下的可靠性。该理论与实践已被数值评估并通过实地实验验证。 <div>
arXiv:2408.10596v1 Announce Type: new 
Abstract: A novel approach for achieving fast evasion in self-localized swarms of Unmanned Aerial Vehicles (UAVs) threatened by an intruding moving object is presented in this paper. Motivated by natural self-organizing systems, the presented approach of fast and collective evasion enables the UAV swarm to avoid dynamic objects (interferers) that are actively approaching the group. The main objective of the proposed technique is the fast and safe escape of the swarm from an interferer ~discovered in proximity. This method is inspired by the collective behavior of groups of certain animals, such as schools of fish or flocks of birds. These animals use the limited information of their sensing organs and decentralized control to achieve reliable and effective group motion. The system presented in this paper is intended to execute the safe coordination of UAV swarms with a large number of agents. Similar to natural swarms, this system propagates a fast shock of information about detected interferers throughout the group to achieve dynamic and collective evasion. The proposed system is fully decentralized using only onboard sensors to mutually localize swarm agents and interferers, similar to how animals accomplish this behavior. As a result, the communication structure between swarm agents is not overwhelmed by information about the state (position and velocity) of each individual and it is reliable to communication dropouts. The proposed system and theory were numerically evaluated and verified in real-world experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fast Grid Emissions Sensitivities using Parallel Decentralized Implicit Differentiation</title>
<link>https://arxiv.org/abs/2408.10620</link>
<guid>https://arxiv.org/abs/2408.10620</guid>
<content:encoded><![CDATA[
<div> 关键词：电力系统、边际排放率、分布式算法、稀疏矩阵、并行计算

总结:

本文研究了电力系统中计算边际排放率（LME）的方法，边际排放率衡量了碳排放对电力需求的敏感性，对于评估减排措施的影响至关重要。文章指出，与位置边际价格（LMPs）类似，LME在地理上可能有很大差异，甚至在同一区域内也会随时间变化，这主要是由于储能和调节限制等因素导致的时间耦合现象。这种时间耦合使得在大型电力网络中计算LME变得非常耗时。

为了解决这个问题，文章提出了一种基于分布式算法的并行计算方法，通过分解不同时间步骤来减少计算复杂度。然而，作者发现这种方法在实际应用中并未能有效提高效率，原因在于电力系统问题通常具有稀疏结构，这限制了分布式算法的性能提升潜力。

针对这一挑战，作者进一步引入了一种全新的并行、反向模式的分布式求导方案，该方案无需显式构建解决方案映射雅可比矩阵，从而实现了在计算电网排放敏感性时的高效并行化处理。理论分析和实验结果均表明，与集中式和传统分布式方法相比，这种方法可以实现超过10倍的加速效果。

总的来说，本文提出了一个创新的计算框架，旨在克服分布式算法在电力系统中计算边际排放率时面临的局限性，通过并行计算显著提高了计算效率，为电力系统的减排策略评估提供了更快速、准确的支持工具。 <div>
arXiv:2408.10620v1 Announce Type: new 
Abstract: Marginal emissions rates -- the sensitivity of carbon emissions to electricity demand -- are important for evaluating the impact of emissions mitigation measures. Like locational marginal prices, locational marginal emissions rates (LMEs) can vary geographically, even between nearby locations, and may be coupled across time periods because of, for example, storage and ramping constraints. This temporal coupling makes computing LMEs computationally expensive for large electricity networks with high storage and renewable penetrations. Recent work demonstrates that decentralized algorithms can mitigate this problem by decoupling timesteps during differentiation. Unfortunately, we show these potential speedups are negated by the sparse structure inherent in power systems problems. We address these limitations by introducing a parallel, reverse-mode decentralized differentiation scheme that never explicitly instantiates the solution map Jacobian. We show both theoretically and empirically that parallelization is necessary to achieve non-trivial speedups when computing grid emissions sensitivities. Numerical results on a 500 node system indicate that our method can achieve greater than 10x speedups over centralized and serial decentralized approaches.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Smart Contract Coordinated Privacy Preserving Crowd-Sensing Campaigns</title>
<link>https://arxiv.org/abs/2408.10648</link>
<guid>https://arxiv.org/abs/2408.10648</guid>
<content:encoded><![CDATA[
<div> 关键词：Crowd-sensing、数据隐私、区块链技术、智能合约、数据管理

总结:

本文探讨了基于区块链技术和智能合约的新型众包感应系统，旨在解决数据可用性与隐私保护问题。该系统通过智能合约实现用户订阅管理、数据加密以及去中心化存储，构建了一个安全的数据市场。智能合约内置的激励政策鼓励用户参与并促进数据多样性。

系统采用去中心化数据管理，减少对单一服务器的依赖，增强安全性与信任度。通过将数据进行匿名化、聚合和分割处理，进一步保护用户隐私。实验证明，系统的可行性得到验证，强调了用户参与对数据可信度的重要性以及地理数据稀缺性对奖励的影响。此方法旨在平衡数据来源，降低欺诈风险，从而建立更可靠、安全的众包感应生态系统。 <div>
arXiv:2408.10648v1 Announce Type: new 
Abstract: Crowd-sensing has emerged as a powerful data retrieval model, enabling diverse applications by leveraging active user participation. However, data availability and privacy concerns pose significant challenges. Traditional methods like data encryption and anonymization, while essential, may not fully address these issues. For instance, in sparsely populated areas, anonymized data can still be traced back to individual users. Additionally, the volume of data generated by users can reveal their identities. To develop credible crowd-sensing systems, data must be anonymized, aggregated and separated into uniformly sized chunks. Furthermore, decentralizing the data management process, rather than relying on a single server, can enhance security and trust. This paper proposes a system utilizing smart contracts and blockchain technologies to manage crowd-sensing campaigns. The smart contract handles user subscriptions, data encryption, and decentralized storage, creating a secure data marketplace. Incentive policies within the smart contract encourage user participation and data diversity. Simulation results confirm the system's viability, highlighting the importance of user participation for data credibility and the impact of geographical data scarcity on rewards. This approach aims to balance data origin and reduce cheating risks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ETGuard: Malicious Encrypted Traffic Detection in Blockchain-based Power Grid Systems</title>
<link>https://arxiv.org/abs/2408.10657</link>
<guid>https://arxiv.org/abs/2408.10657</guid>
<content:encoded><![CDATA[
<div> 关键词：加密协议、恶意攻击、电力系统、区块链、增量学习

总结:

本文针对加密协议日益普及带来的恶意攻击问题，特别是其在电力系统和区块链技术中的挑战。主要关注点包括：

1. **背景与挑战**：文章指出，随着加密协议的广泛应用，隐藏在加密流量中的恶意攻击数量激增。传统检测方法基于静态预训练模型，对于动态环境中的新类型加密攻击难以应对。

2. **创新框架**：提出了一种新的框架，旨在自动检测区块链基础电力系统中的恶意加密流量，并实现对新恶意流量的增量学习。这一框架旨在解决传统方法在动态环境下的局限性。

3. **数学损失函数**：通过数学推导，设计了增量学习损失函数，确保模型既能抵抗旧攻击模式的记忆丢失，又能适应并处理新的加密攻击模式。

4. **实验验证**：实验证明，该方法在三个不同基准数据集上的性能达到当前最优水平。此外，构建了首个针对区块链基础电力场景的恶意加密流量数据集。

5. **开源与贡献**：提供开源代码和数据集（https://github.com/PPPmzt/ETGuard），为后续研究者提供了宝贵资源，鼓励并推动了相关领域的进一步探索与创新。

通过上述分析，本文不仅提出了针对电力系统和区块链环境中加密攻击检测的新方法，还提供了实际应用的案例和工具，为网络安全领域带来了显著的贡献。 <div>
arXiv:2408.10657v1 Announce Type: new 
Abstract: The escalating prevalence of encryption protocols has led to a concomitant surge in the number of malicious attacks that hide in encrypted traffic. Power grid systems, as fundamental infrastructure, are becoming prime targets for such attacks. Conventional methods for detecting malicious encrypted packets typically use a static pre-trained model. We observe that these methods are not well-suited for blockchain-based power grid systems. More critically, they fall short in dynamic environments where new types of encrypted attacks continuously emerge. Motivated by this, in this paper we try to tackle these challenges from two aspects: (1) We present a novel framework that is able to automatically detect malicious encrypted traffic in blockchain-based power grid systems and incrementally learn from new malicious traffic. (2) We mathematically derive incremental learning losses to resist the forgetting of old attack patterns while ensuring the model is capable of handling new encrypted attack patterns. Empirically, our method achieves state-of-the-art performance on three different benchmark datasets. We also constructed the first malicious encrypted traffic dataset for blockchain-based power grid scenario. Our code and dataset are available at https://github.com/PPPmzt/ETGuard, hoping to inspire future research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions</title>
<link>https://arxiv.org/abs/2408.10664</link>
<guid>https://arxiv.org/abs/2408.10664</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Unsupervised、Federated Clustering、FedCRef、Data Representation

<br /><br />
总结:
本文提出了一种新颖的无监督联邦学习方法——Federated Cluster-Wise Refinement (FedCRef)，旨在识别多个客户端中的完整类别集（全局K），特别是在无标签、非均匀数据分布的情况下进行联邦聚类。该方法首先让具有不同本地数据分布的客户端训练模型以识别其各自的数据集群，并生成压缩的数据表示。随后，这些本地模型在网络中共享，通过重构误差分析比较模型，形成联邦群体。在这些群体中，客户端合作训练代表每个数据分布的共享模型，同时不断细化本地集群，以提高数据关联的准确性。此迭代过程使系统能够识别网络中的所有潜在数据分布，并为每个数据分布开发稳健的表示模型。

通过与传统的集中式方法进行比较，本文建立了性能基准，并展示了分布式解决方案的优势。实验结果表明，FedCRef能够对集群模型进行精细调整和对齐，显著提高了无监督联邦设置下的数据表示精度。 <div>
arXiv:2408.10664v1 Announce Type: new 
Abstract: Federated Learning (FL) is a pivotal approach in decentralized machine learning, especially when data privacy is crucial and direct data sharing is impractical. While FL is typically associated with supervised learning, its potential in unsupervised scenarios is underexplored. This paper introduces a novel unsupervised federated learning methodology designed to identify the complete set of categories (global K) across multiple clients within label-free, non-uniform data distributions, a process known as Federated Clustering. Our approach, Federated Cluster-Wise Refinement (FedCRef), involves clients that collaboratively train models on clusters with similar data distributions. Initially, clients with diverse local data distributions (local K) train models on their clusters to generate compressed data representations. These local models are then shared across the network, enabling clients to compare them through reconstruction error analysis, leading to the formation of federated groups.In these groups, clients collaboratively train a shared model representing each data distribution, while continuously refining their local clusters to enhance data association accuracy. This iterative process allows our system to identify all potential data distributions across the network and develop robust representation models for each. To validate our approach, we compare it with traditional centralized methods, establishing a performance baseline and showcasing the advantages of our distributed solution. We also conduct experiments on the EMNIST and KMNIST datasets, demonstrating FedCRef's ability to refine and align cluster models with actual data distributions, significantly improving data representation precision in unsupervised federated settings.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-Agent Based Simulation for Investigating Centralized Charging Strategies and their Impact on Electric Vehicle Home Charging Ecosystem</title>
<link>https://arxiv.org/abs/2408.10773</link>
<guid>https://arxiv.org/abs/2408.10773</guid>
<content:encoded><![CDATA[
<div> 关键词：电能车辆（EVs）、电力电网、碳中和、集中式充电策略、多代理系统

总结:

本文探讨了电动汽车(EVs)如何融入电力电网，以实现2050年的碳中和目标。随着EV数量急剧增加，现有的电网基础设施面临巨大挑战，特别是在管理不断增长的电力需求和避免电网过载方面。研究对比分析了集中式充电策略与分散式策略，发现集中式策略在优化电网稳定性和效率方面具有潜在优势。

研究通过多代理系统仿真模型构建了一个详细的Strib丹麦地区家庭充电生态系统案例研究。结果显示，Earliest-deadline-first和Round Robin算法在100%EV采用率下，对EV用户满意度最高。该模拟考虑了真实的采用曲线、充电策略、车型和驾驶模式，以高分辨率(每小时一次)捕捉长期生态系统的动态变化。

此外，研究提供了未来配电网络的详细负荷曲线，证明了集中式充电策略如何有效地管理电网负载并防止过载。这一发现对于促进电网适应EV大规模采用，确保电力系统的稳定性和可靠性具有重要意义。 <div>
arXiv:2408.10773v1 Announce Type: new 
Abstract: This paper addresses the critical integration of electric vehicles (EVs) into the electricity grid, which is essential for achieving carbon neutrality by 2050. The rapid increase in EV adoption poses significant challenges to the existing grid infrastructure, particularly in managing the increasing electricity demand and mitigating the risk of grid overloads. Centralized EV charging strategies are investigated due to their potential to optimize grid stability and efficiency, compared to decentralized approaches that may exacerbate grid stress. Utilizing a multi-agent based simulation model, the study provides a realistic representation of the electric vehicle home charging ecosystem in a case study of Strib, Denmark. The findings show that the Earliest-deadline-first and Round Robin perform best with 100% EV adoption in terms of EV user satisfaction. The simulation considers a realistic adoption curve, EV charging strategies, EV models, and driving patterns to capture the full ecosystem dynamics over a long-term period with high resolution (hourly). Additionally, the study offers detailed load profiles for future distribution grids, demonstrating how centralized charging strategies can efficiently manage grid loads and prevent overloads.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-Agent Based Simulation for Decentralized Electric Vehicle Charging Strategies and their Impacts</title>
<link>https://arxiv.org/abs/2408.10790</link>
<guid>https://arxiv.org/abs/2408.10790</guid>
<content:encoded><![CDATA[
<div> 关键词：智能电网、电动汽车、分布式网络、实时定价、多代理系统

总结:
本文探讨了智能电网转型中的挑战，特别是大规模电动汽车(EV)采用对电力和交通领域的影响。研究通过丹麦一个126户家庭的辐射型配电网案例，验证了一个基于多代理系统的仿真模型的有效性。结果显示，传统的充电方式可能导致电网在2031年67%的EV渗透率下过载，而分散化的策略如实时电价也可能在2028年前导致过载。该模型能够提供详细的、小时级别的未来负载分布分析，适用于相似能源系统的其他潜在情景。因此，该研究为解决电动汽车集成与智能电网管理提供了理论依据和技术方案。 <div>
arXiv:2408.10790v1 Announce Type: new 
Abstract: The growing shift towards a Smart Grid involves integrating numerous new digital energy solutions into the energy ecosystems to address problems arising from the transition to carbon neutrality, particularly in linking the electricity and transportation sectors. Yet, this shift brings challenges due to mass electric vehicle adoption and the lack of methods to adequately assess various EV charging algorithms and their ecosystem impacts. This paper introduces a multi-agent based simulation model, validated through a case study of a Danish radial distribution network serving 126 households. The study reveals that traditional charging leads to grid overload by 2031 at 67% EV penetration, while decentralized strategies like Real-Time Pricing could cause overloads as early as 2028. The developed multi-agent based simulation demonstrates its ability to offer detailed, hourly analysis of future load profiles in distribution grids, and therefore, can be applied to other prospective scenarios in similar energy systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Distributed Graph Coloring II: degree+1-Coloring Virtual Graphs</title>
<link>https://arxiv.org/abs/2408.11041</link>
<guid>https://arxiv.org/abs/2408.11041</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式计算、虚拟图着色、嵌入性、复杂度、去中心化操作

总结:
本文探讨了分布式计算中的虚拟图着色问题。虚拟图着色是在通信图中局部嵌套目标图进行的，这既扩展了经典分布式图着色的概念（即目标图与通信图相等），也涵盖了群集图和功率图等先前研究的场景。

文章的主要发现是，虚拟图的着色复杂度依赖于其嵌入的边缘拥塞。特别引人注目的是，对于具有常数拥塞的虚拟图，其着色速度几乎可以与普通图一样快。为此，作者提出了一种在O(log^4 log n)轮次内的算法解决deg+1着色问题，其中节点被分配的颜色数量多于其度数。

这一结果表明，即使在节点操作去中心化的条件下，某些分布式图问题也能得到解决。这不仅丰富了分布式计算领域的理论知识，也为实际网络设计和优化提供了新的视角。 <div>
arXiv:2408.11041v1 Announce Type: new 
Abstract: Graph coloring is fundamental to distributed computing. We give the first general treatment of the coloring of virtual graphs, where the graph $H$ to be colored is locally embedded within the communication graph $G$. Besides generalizing classical distributed graph coloring (where $H=G$), this captures other previously studied settings, including cluster graphs and power graphs.
  We find that the complexity of coloring a virtual graph depends on the edge congestion of its embedding. The main question of interest is how fast we can color virtual graphs of constant congestion. We find that, surprisingly, these graphs can be colored nearly as fast as ordinary graphs. Namely, we give a $O(\log^4\log n)$-round algorithm for the deg+1-coloring problem, where each node is assigned more colors than its degree.
  This can be viewed as a case where a distributed graph problem can be solved even when the operation of each node is decentralized.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Exploiting Defenses against GAN-Based Feature Inference Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2004.12571</link>
<guid>https://arxiv.org/abs/2004.12571</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、生成对抗网络、防御策略、图像重建、模型准确性

<br /><br />
总结:
文章探讨了在联邦学习(Federated Learning, FL)框架下，如何利用防御策略来对抗基于生成对抗网络(Generative Adversarial Network, GAN)的攻击。联邦学习旨在整合分散的数据孤岛同时保持数据隐私。然而，近期研究揭示了GAN攻击能够学习私人数据集的分布并重构可识别的图像。针对这一问题，本文提出了名为Anti-GAN的框架，旨在防止攻击者学习到受害者数据的真实分布。

Anti-GAN的核心理念是通过操纵私有训练图像的视觉特征，使得即使是攻击者也无法仅凭肉眼识别这些特征。具体实现上，Anti-GAN将私有数据集投影至GAN的生成器中，并将生成的假图像与实际图像结合，形成用于联邦模型训练的训练集。实验结果表明，Anti-GAN在有效防止攻击者学习到私有图像分布的同时，对联邦模型的准确性影响较小。这为在保护数据隐私的前提下进行模型训练提供了一种有效的方法。 <div>
arXiv:2004.12571v3 Announce Type: replace 
Abstract: Federated learning (FL) is a decentralized model training framework that aims to merge isolated data islands while maintaining data privacy. However, recent studies have revealed that Generative Adversarial Network (GAN) based attacks can be employed in FL to learn the distribution of private datasets and reconstruct recognizable images. In this paper, we exploit defenses against GAN-based attacks in FL and propose a framework, Anti-GAN, to prevent attackers from learning the real distribution of the victim's data. The core idea of Anti-GAN is to manipulate the visual features of private training images to make them indistinguishable to human eyes even restored by attackers. Specifically, Anti-GAN projects the private dataset onto a GAN's generator and combines the generated fake images with the actual images to create the training dataset, which is then used for federated model training. The experimental results demonstrate that Anti-GAN is effective in preventing attackers from learning the distribution of private images while causing minimal harm to the accuracy of the federated model.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Framework for Empowering Reinforcement Learning Agents with Causal Analysis: Enhancing Automated Cryptocurrency Trading</title>
<link>https://arxiv.org/abs/2310.09462</link>
<guid>https://arxiv.org/abs/2310.09462</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、自动交易系统、数字货币市场、强化学习、因果推断网络

总结:

本文研究了在快速发展的数字货币市场上，利用增强学习（RL）框架构建自动化交易系统的挑战。重点介绍了CausalReinforceNet（CRN）框架，该框架结合了贝叶斯和动态贝叶斯网络技术，为交易决策提供支持。研究中开发了两个基于不同RL算法的代理，与买入并持有基准策略和基线RL模型进行了比较。结果显示，CRN框架在盈利能力上超越了其他模型，尽管其有效性在不同的数字货币之间有所差异。这一发现强调了CRN在自动化交易领域的潜在优势，特别是在应对市场复杂性和不确定性时。 <div>
arXiv:2310.09462v2 Announce Type: replace 
Abstract: Despite advances in artificial intelligence-enhanced trading methods, developing a profitable automated trading system remains challenging in the rapidly evolving cryptocurrency market. This research focuses on developing a reinforcement learning (RL) framework to tackle the complexities of trading five prominent altcoins: Binance Coin, Ethereum, Litecoin, Ripple, and Tether. To this end, we present the CausalReinforceNet~(CRN) framework, which integrates both Bayesian and dynamic Bayesian network techniques to empower the RL agent in trade decision-making. We develop two agents using the framework based on distinct RL algorithms to analyse performance compared to the Buy-and-Hold benchmark strategy and a baseline RL model. The results indicate that our framework surpasses both models in profitability, highlighting CRN's consistent superiority, although the level of effectiveness varies across different cryptocurrencies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Circuit Approach to Constructing Blockchains on Blockchains</title>
<link>https://arxiv.org/abs/2402.00220</link>
<guid>https://arxiv.org/abs/2402.00220</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、多链世界、安全、活络性、组合操作

总结:

本文研究了在多条区块链并存的环境中，如何构建具有更高安全性和活络性的叠加区块链。通过类比电子电路中的串行和并行连接，作者提出了两种基本的组合操作——串行和三角形组合，并使用这些操作作为构建块来构造通用的叠加区块链。

在部分同步环境下，本文给出了以下结果：
1. 串行组合两个区块链产生的叠加区块链在至少一个基础区块链安全的情况下保持安全性，在两个基础区块链都活络的情况下保持活络性。
2. 三角形组合三个区块链类似于电路中并行组合，产生的叠加区块链在所有基础区块链都安全的情况下保持安全性，在超过一半的基础区块链活络的情况下保持活络性。
3. 这些基本操作的重复组合可以产生任意数量基础区块链上构建的叠加区块链可能的安全性和活络性权衡。

此外，这些结果也扩展到了完全同步的环境。通过这种方式，文章提供了一种方法，允许在多链系统中创建具有特定安全性和活络性特性的叠加区块链，以适应不同的需求和场景。 <div>
arXiv:2402.00220v4 Announce Type: replace 
Abstract: Since the creation of Bitcoin 15 years ago, there has been an explosion in the number of permissionless blockchains. Each of these blockchains provides an open ledger that anyone can read from and write to. In this multi-chain world, an important question emerges: how can we build a more secure overlay blockchain by reading from and writing to a given set of blockchains? Drawing an analogy with switching circuits, we approach the problem by defining two basic compositional operations between blockchains, serial and triangular compositions, and use these operations as building blocks to construct general overlay blockchains. Under the partially synchronous setting, we have the following results: 1) the serial composition, between two blockchains, yields an overlay blockchain that is safe if at least one of the two underlay blockchains is safe and that is live if both of them are live; 2) the triangular composition between three blockchains, akin to parallel composition of switching circuits, yields an overlay blockchain that is safe if all underlay blockchains are safe and that is live if over half of them are live; 3) repeated composition of these two basic operations can yield all possible tradeoffs of safety and liveness for an overlay blockchain built on arbitrary number of underlay chains. The results are also extended to the synchronous setting.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Batch-Schedule-Execute: On Optimizing Concurrent Deterministic Scheduling for Blockchains (Extended Version)</title>
<link>https://arxiv.org/abs/2402.05535</link>
<guid>https://arxiv.org/abs/2402.05535</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链性能、并行执行、冲突图、状态机复制

总结:

本文研究了在区块链领域中，如何在保证数据一致性和系统安全的前提下，最大化利用多核计算资源来提升智能合约执行效率的问题。文章首先指出，当前区块链系统的性能瓶颈主要在于智能合约的执行过程，这涉及到大量的计算和存储需求。随着现代计算机硬件向多核心发展，提高程序执行的并行度成为提升性能的有效途径。

为了深入理解这一问题，作者引入了“冲突图”这一概念，用来表示同一区块中交易之间的依赖关系。文章发现，现有的区块链并发解决方案依赖于全序阶段来确保所有副本之间的一致性，但这种做法可能被区块创建者利用来降低整体性能。为了解决这一问题，作者提出了一种新的框架——Active State Machine Replication（ASMR），旨在实现严格可串行化的同时，允许一定程度的并行执行。

文章还定义了“图形调度”和“最小延迟调度问题”，并证明了该问题的NP难度。进一步地，作者将这个问题与经典的图顶点着色问题进行了对比，揭示了同质交易与异构交易场景下的复杂性差异。最后，文章讨论了这些理论成果对实际应用的影响，包括可能的技术挑战和改进方向。

通过以上分析，文章为区块链领域的并发执行优化提供了一个全新的视角，为后续研究和实践提供了理论基础和参考。 <div>
arXiv:2402.05535v2 Announce Type: replace 
Abstract: Executing smart contracts is a compute and storage-intensive task, which currently dominates modern blockchain's performance. Given that computers are becoming increasingly multicore, concurrency is an attractive approach to improve programs' execution runtime. A unique challenge of blockchains is that all replicas (miners or validators) must execute all smart contracts in the same logical order to maintain the semantics of State Machine Replication (SMR).
  In this work, we study the maximal level of parallelism attainable when focusing on the conflict graph between transactions packaged in the same block. This exposes a performance vulnerability that block creators may exploit against existing blockchain concurrency solutions, which rely on a total ordering phase for maintaining consistency amongst all replicas. To facilitate the formal aspects of our study, we develop a novel generic framework for Active State Machine Replication (ASMR) that is strictly serializable. We introduce the concept of graph scheduling and the definition of the minimal latency scheduling problem, which we prove to be NP-hard. We show that the restricted version of this problem for homogeneous transactions is equivalent to the classic Graph Vertex Coloring Problem, yet show that the heterogeneous case is more complex. We discuss the practical implications of these results.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Efficient Signature-Free Validated Agreement</title>
<link>https://arxiv.org/abs/2403.08374</link>
<guid>https://arxiv.org/abs/2403.08374</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine协议、同步性、最优复杂度、HashExt、ErrorFreeExt

总结:

本文探讨了在同步环境中，即使存在最多t个任意故障，n个进程如何达成一致的L位值问题，即Byzantine协议。文章指出，长期以来，研究者一直在努力优化这一协议在同步环境下的位复杂度，最终成果是COOL，这是一种在计算能力无限的对手面前具有确定安全性的无错误解决方案，其最坏情况下的位复杂度为O(nL + n^2 logn)，这是根据Dolev-Reischuk下界对于L >= n logn来说的最优结果。然而，COOL满足的强一致性条件并不适用于现代状态机复制（SMR）和区块链协议，这些系统更看重进度，要求决定的值始终有效，而不仅仅是当有共识时才有效。

为了满足这些系统的需求，文章提出了两个新的同步算法：HashExt和ErrorFreeExt。HashExt仅使用哈希函数，复杂度为O(nL + n^3 kappa)，其中kappa为哈希大小，对于L >= n^2 kappa来说是最佳选择。ErrorFreeExt则完全不使用任何加密技术，实现无错误的解决方案，其复杂度接近O((nL + n^2) logn)，对于任何L来说都是接近最优的。这两个算法都具有最佳鲁棒性（容忍最多t < n/3的故障），并能在实际故障数f + 1轮内停止运行。 <div>
arXiv:2403.08374v3 Announce Type: replace 
Abstract: Byzantine agreement enables n processes to agree on a common L-bit value, despite up to t > 0 arbitrary failures. A long line of work has been dedicated to improving the bit complexity of Byzantine agreement in synchrony. This has culminated in COOL, an error-free (deterministically secure against a computationally unbounded adversary) solution that achieves O(nL + n^2 logn) worst-case bit complexity (which is optimal for L >= n logn according to the Dolev-Reischuk lower bound). COOL satisfies strong unanimity: if all correct processes propose the same value, only that value can be decided. Strong unanimity is, however, not sufficient for today's state machine replication (SMR) and blockchain protocols. These systems value progress and require a decided value to always be valid, excluding default decisions (such as EMPTY) even in cases where there is no unanimity a priori. Validated Byzantine agreement satisfies this property (called external validity). Yet, the best error-free (or even signature-free) validated agreement solutions achieve only O(n^2L) bit complexity, a far cry from the Omega(nL + n^2) Dolev-Reishcuk lower bound. In this paper, we present two new synchronous algorithms for validated Byzantine agreement, HashExt and ErrorFreeExt, with different trade-offs. Both algorithms are (1) signature-free, (2) optimally resilient (tolerate up to t < n / 3 failures), and (3) early-stopping (terminate in O(f+1) rounds, where f <= t is the actual number of failures). On the one hand, HashExt uses only hashes and achieves O(nL + n^3 kappa) bit complexity, which is optimal for L >= n^2 kappa (where kappa is the size of a hash). On the other hand, ErrorFreeExt is error-free, using no cryptography whatsoever, and achieves O( (nL + n^2) logn ) bit complexity, which is near-optimal for any L.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Introduction to Decentralized Training and Execution in Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.06161</link>
<guid>https://arxiv.org/abs/2405.06161</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、分散式训练与执行、集中式训练与分散式执行、分布式强化学习、合作性多智能体问题

总结:
本文主要探讨了分散式、合作性多智能体强化学习（MARL）领域。首先，文章概述了合作性MARL问题的框架，即分解性部分观测马尔可夫决策过程（Decentralized Partially Observable Markov Decision Process, Dec-POMDP）。随后，文章深入分析了基于价值的分散式训练与执行方法，从独立Q学习及其扩展开始，到深度Q网络（Deep Q-Networks, DQN）的应用，讨论了在深度学习背景下的挑战以及应对策略。接着，文章转向了基于策略梯度的分散式训练与执行方法，从独立REINFORCE（即基础策略梯度）出发，延伸至Actor-Critic框架及其深度变种（如独立PPO），详细阐述了各自的特点和解决复杂性问题的方法。最后，文章还涵盖了分散式训练与执行方法的一般主题及未来发展方向，旨在为读者提供对分散式合作性MARL领域的全面理解。 <div>
arXiv:2405.06161v3 Announce Type: replace 
Abstract: Multi-agent reinforcement learning (MARL) has exploded in popularity in recent years. Many approaches have been developed but they can be divided into three main types: centralized training and execution (CTE), centralized training for decentralized execution (CTDE), and Decentralized training and execution (DTE). Decentralized training and execution methods make the fewest assumptions and are often simple to implement. In fact, as I'll discuss, any single-agent RL method can be used for DTE by just letting each agent learn separately. Of course, there are pros and cons to such approaches. It is worth noting that DTE is required if no offline coordination is available. That is, if all agents must learn during online interactions without prior coordination, learning and execution must both be decentralized. DTE methods can be applied in cooperative, competitive, or mixed cases but this text will focus on the cooperative MARL case.
  This text is an introduction to the field of decentralized, cooperative MARL. As such, I will first give a brief description of the cooperative MARL problem in the form of the Dec-POMDP. Then, I will discuss value-based DTE methods starting with independent Q-learning and its extensions and then discuss the extension to the deep case with DQN, the additional complications this causes, and methods that have been developed to (attempt to) address these issues. Next, I will discuss policy gradient DTE methods starting with independent REINFORCE (i.e., vanilla policy gradient), and then extending to the actor-critic case and deep variants (such as independent PPO). Finally, I will discuss some general topics related to DTE and future directions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Adjacent Leader Decentralized Stochastic Gradient Descent</title>
<link>https://arxiv.org/abs/2405.11389</link>
<guid>https://arxiv.org/abs/2405.11389</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Deep Learning、AL-DSGD、Performance Improvement、Convergence Acceleration、Communication Overhead Reduction

<br />
总结:
本文聚焦于分布式深度学习优化框架，提出了一种名为“相邻领袖分布式梯度下降”（AL-DSGD）的方法。AL-DSGD旨在通过提升最强学习者的影响力来改善最终模型性能，加速收敛过程并降低分布式深度学习优化器的通信开销。该方法的核心思想包括：根据邻居工作者的性能和度数对它们进行加权平均，并引入一种由当前表现最佳的邻居和最大度数的邻居决定的校正力；同时，通过动态通信图允许节点与更多节点通信，从而减轻低度节点收敛速度和性能恶化的风险。实验结果表明，AL-DSGD能够加速现有分布式技术的收敛速度，并特别在通信受限环境中提高测试性能。此外，文章还证明了所提出方案的收敛性，并提供了一个支持任意分布式深度学习方法（同步/异步、中心化/去中心化）的通用且简洁的PyTorch库，便于社区使用和进一步研究。 <div>
arXiv:2405.11389v2 Announce Type: replace 
Abstract: This work focuses on the decentralized deep learning optimization framework. We propose Adjacent Leader Decentralized Gradient Descent (AL-DSGD), for improving final model performance, accelerating convergence, and reducing the communication overhead of decentralized deep learning optimizers. AL-DSGD relies on two main ideas. Firstly, to increase the influence of the strongest learners on the learning system it assigns weights to different neighbor workers according to both their performance and the degree when averaging among them, and it applies a corrective force on the workers dictated by both the currently best-performing neighbor and the neighbor with the maximal degree. Secondly, to alleviate the problem of the deterioration of the convergence speed and performance of the nodes with lower degrees, AL-DSGD relies on dynamic communication graphs, which effectively allows the workers to communicate with more nodes while keeping the degrees of the nodes low. Experiments demonstrate that AL-DSGD accelerates the convergence of the decentralized state-of-the-art techniques and improves their test performance especially in the communication constrained environments. We also theoretically prove the convergence of the proposed scheme. Finally, we release to the community a highly general and concise PyTorch-based library for distributed training of deep learning models that supports easy implementation of any distributed deep learning approach ((a)synchronous, (de)centralized).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Limited Communications Distributed Optimization via Deep Unfolded Distributed ADMM</title>
<link>https://arxiv.org/abs/2309.14353</link>
<guid>https://arxiv.org/abs/2309.14353</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、D-ADMM、深展开、通信效率、多代理系统

总结:

本文研究了在分布式多代理系统中进行协作推理和决策的框架——分布式优化。主要关注的是如何通过迭代结合本地计算和消息交换来最小化共享目标函数的问题。其中，D-ADMM算法是一个常用的解决方法，但其面临的主要挑战是需要大量的通信来达成共识，这在实际应用中可能会消耗大量的功率、延迟和信道资源。

为了解决这个问题，作者提出了“展开D-ADMM”（Unfolded D-ADMM），这是一种利用深度学习技术来优化D-ADMM算法的方法。通过数据驱动调整算法的超参数，使得每个代理只需要预定义数量的消息即可可靠地运行D-ADMM。这种展开方式不仅保持了原始D-ADMM的可解释性和灵活性，还显著减少了通信量，而不会影响性能。

具体而言，展开D-ADMM适用于两种典型场景：分布式估计任务，如稀疏恢复；以及分布式学习情景，多个代理合作学习机器学习模型。数值结果表明，该方法能够大幅度降低D-ADMM的通信需求，同时保持其性能。 <div>
arXiv:2309.14353v2 Announce Type: replace-cross 
Abstract: Distributed optimization is a fundamental framework for collaborative inference and decision making in decentralized multi-agent systems. The operation is modeled as the joint minimization of a shared objective which typically depends on observations gathered locally by each agent. Distributed optimization algorithms, such as the common D-ADMM, tackle this task by iteratively combining local computations and message exchanges. One of the main challenges associated with distributed optimization, and particularly with D-ADMM, is that it requires a large number of communications, i.e., messages exchanged between the agents, to reach consensus. This can make D-ADMM costly in power, latency, and channel resources. In this work we propose unfolded D-ADMM, which follows the emerging deep unfolding methodology to enable D-ADMM to operate reliably with a predefined and small number of messages exchanged by each agent. Unfolded D-ADMM fully preserves the operation of D-ADMM, while leveraging data to tune the hyperparameters of each iteration of the algorithm. These hyperparameters can either be agent-specific, aiming at achieving the best performance within a fixed number of iterations over a given network, or shared among the agents, allowing to learn to distributedly optimize over different networks. For both settings, our unfolded D-ADMM operates with limited communications, while preserving the interpretability and flexibility of the original D-ADMM algorithm. We specialize unfolded D-ADMM for two representative settings: a distributed estimation task, considering a sparse recovery setup, and a distributed learning scenario, where multiple agents collaborate in learning a machine learning model. Our numerical results demonstrate that the proposed approach dramatically reduces the number of communications utilized by D-ADMM, without compromising on its performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Two-Timescale Optimization Framework for Decentralized Linear-Quadratic Optimal Control</title>
<link>https://arxiv.org/abs/2406.11168</link>
<guid>https://arxiv.org/abs/2406.11168</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式、线性-二次最优控制、稀疏性促进函数、两阶段算法、非凸优化

<br />
<br />总结:

本文研究了一个分散式的线性-二次最优控制问题，并首次基于稀疏性促进函数的选择，提出了几个近似的约束优化问题。首先，针对带有加权ℓ1稀疏性促进函数的优化问题，采用了基于BSUM框架和微分方程求解器的两阶段算法。其次，引入了一种分段二次型稀疏性促进函数，由相同两阶段算法处理的优化问题显示了加速的收敛率。最后，考虑了带有ℓ0稀疏性促进函数的优化问题，该问题是非凸且不连续的，可以通过连续的坐标方向凸优化问题进行近似。研究为解决分散式系统中的复杂优化问题提供了新的方法和技术路径。 <div>
arXiv:2406.11168v2 Announce Type: replace-cross 
Abstract: This study investigates a decentralized linear-quadratic optimal control problem, and several approximate separable constrained optimization problems are formulated for the first time based on the selection of sparsity promoting functions. First, for the optimization problem with weighted $\ell_1$ sparsity promoting function, a two-timescale algorithm is adopted that is based on the BSUM (Block Successive Upper-bound Minimization) framework and a differential equation solver. Second, a piecewise quadratic sparsity promoting function is introduced, and the induced optimization problem demonstrates an accelerated convergence rate by performing the same two-timescale algorithm. Finally, the optimization problem with $\ell_0$ sparsity promoting function is considered that is nonconvex and discontinuous, and can be approximated by successive coordinatewise convex optimization problems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ServerFi: A New Symbiotic Relationship Between Games and Players</title>
<link>https://arxiv.org/abs/2408.08895</link>
<guid>https://arxiv.org/abs/2408.08895</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链游戏、GameFi、市场稳定性、玩家留存、服务器金融化

总结:
本文探讨了区块链游戏领域的演变及其面临的关键挑战，包括市场稳定性、玩家留存和代币价值可持续性。文章利用熵增加理论分析现有通证经济模型的不足，并提出了两种创新模型：ServerFi和持续奖励模式。

首先，ServerFi模型通过资产合成强调私有化，旨在提高玩家参与度并确保游戏生态系统的长期活力。该模型被数学框架正式化，并通过群体行为模拟实验验证其有效性。

其次，持续奖励模式针对高留存率玩家设计，旨在激励长期参与，进一步增强游戏的吸引力和持久性。

通过这两种模型的提出与验证，本文为未来区块链游戏的发展提供了新的方向，特别是如何在保证市场稳定性和玩家留存的同时，促进代币价值的可持续增长。这些创新尝试有望推动GameFi领域实现更健康、更平衡的发展。 <div>
arXiv:2408.08895v1 Announce Type: new 
Abstract: Blockchain-based games have introduced novel economic models that blend traditional gaming with decentralized ownership and financial incentives, leading to the rapid emergence of the GameFi sector. However, despite their innovative appeal, these games face significant challenges, particularly in terms of market stability, player retention, and the sustainability of token value. This paper explores the evolution of blockchain games and identifies key shortcomings in current tokenomics models using entropy increase theory. We propose two new models - ServerFi, which emphasizes Privatization through Asset Synthesis, and a model focused on Continuous Rewards for High-Retention Players. These models are formalized into mathematical frameworks and validated through group behavior simulation experiments. Our findings indicate that the ServerFi is particularly effective in maintaining player engagement and ensuring the long-term viability of the gaming ecosystem, offering a promising direction for future blockchain game development.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy in Federated Learning</title>
<link>https://arxiv.org/abs/2408.08904</link>
<guid>https://arxiv.org/abs/2408.08904</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、隐私保护、模型更新、数据安全、监管框架

总结:

本文深入探讨了联邦学习（FL）中的核心隐私问题。首先，它指出了联邦学习带来的隐私挑战，包括数据重建风险、模型反转攻击和成员推断。接着，文章介绍了用于减轻这些风险的隐私保护技术，如差分隐私（DP）和安全多方计算（SMPC）。同时，文章强调了在实际应用中平衡模型准确性和隐私的重要性，并讨论了监管框架（如GDPR）在塑造FL隐私标准方面的作用。

文章还分析了现有隐私增强技术的潜力与局限性，并提出了未来研究方向和发展更强大解决方案的见解。通过提供对当前FL隐私状态的全面概述，本文旨在为研究人员和实践者提供必要的知识，以应对安全联邦学习环境中的复杂性。 <div>
arXiv:2408.08904v1 Announce Type: new 
Abstract: Federated Learning (FL) represents a significant advancement in distributed machine learning, enabling multiple participants to collaboratively train models without sharing raw data. This decentralized approach enhances privacy by keeping data on local devices. However, FL introduces new privacy challenges, as model updates shared during training can inadvertently leak sensitive information. This chapter delves into the core privacy concerns within FL, including the risks of data reconstruction, model inversion attacks, and membership inference. It explores various privacy-preserving techniques, such as Differential Privacy (DP) and Secure Multi-Party Computation (SMPC), which are designed to mitigate these risks. The chapter also examines the trade-offs between model accuracy and privacy, emphasizing the importance of balancing these factors in practical implementations. Furthermore, it discusses the role of regulatory frameworks, such as GDPR, in shaping the privacy standards for FL. By providing a comprehensive overview of the current state of privacy in FL, this chapter aims to equip researchers and practitioners with the knowledge necessary to navigate the complexities of secure federated learning environments. The discussion highlights both the potential and limitations of existing privacy-enhancing techniques, offering insights into future research directions and the development of more robust solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Survey on Blockchain-based Supply Chain Finance with Progress and Future directions</title>
<link>https://arxiv.org/abs/2408.08915</link>
<guid>https://arxiv.org/abs/2408.08915</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、供应链金融、信息共享、智能合约、系统性回顾

总结:

本文主要探讨了区块链技术在供应链金融领域的应用及其对供应链金融的贡献。首先，区块链技术通过其数据不可篡改、防伪造、加密、共识验证和去中心化的特点，解决了供应链金融中信息不对称、信用拆分和融资成本等问题。其次，通过智能合约，区块链技术能够实现供应链金融的智能化运作，提升运营效率。此外，区块链与人工智能、云计算和数据挖掘等技术的结合，为供应链金融提供了更为丰富的应用场景。

文章指出，当前关于基于区块链的供应链金融研究已经出现了一些成果，包括提出了概念框架或简单地将区块链应用于供应链金融中。然而，这些工作大多停留在管理层面，缺乏深入探索区块链技术的深层应用潜力。因此，需要进行系统性的回顾，全面总结当前区块链在供应链金融领域的研究现状，以期为未来的研究提供指导和启发。

总之，区块链技术在供应链金融中的应用展现出巨大的潜力，不仅可以优化传统供应链金融的流程和效率，还能够促进数据安全共享，加强信用体系的建设，为供应链金融的创新和发展提供技术支持。未来的研究应更加注重深入挖掘区块链技术的潜能，探索其与其他技术的融合应用，以推动供应链金融行业的进一步发展。 <div>
arXiv:2408.08915v1 Announce Type: new 
Abstract: Supply Chain Finance is very important for supply chain competition, which is an important tool to activate the capital flow in the supply chain. Supply Chain Finance-related research can support multiple applications and services, such as providing accounts receivable financing, enhancing risk management, and optimizing supply chain management. For more than a decade, the development of Blockchain has attracted widely attention in various fields, especially in finance. With the characteristics of data tamper-proof, forgery-proof, cryptography, consensus verification, and decentralization, Blockchain fits well with the realistic needs of Supply Chain Finance, which requires data integrity, authenticity, privacy, and information sharing. Therefore, it is time to summarize the applications of Blockchain technology in the field of Supply Chain Finance. What Blockchain technology brings to Supply Chain Finance is not only to alleviate the problems of information asymmetry, credit disassembly, and financing cost, but also to improve Supply Chain Finance operations through smart contracts to intelligent Supply Chain Finance and in combination with other technologies, such as artificial intelligence, cloud computing, and data mining, jointly. So there has been some work in Blockchain-based Supply Chain Finance research for different Supply Chain Finance oriented applications, but most of these work are at the management level to propose conceptual frameworks or simply use Blockchain without exploiting its deep applications. Moreover, there are few systematic reviews providing a comprehensive summary of current work in the area of Blockchain-based Supply Chain Finance. In this paper, we ...
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FedFQ: Federated Learning with Fine-Grained Quantization</title>
<link>https://arxiv.org/abs/2408.08977</link>
<guid>https://arxiv.org/abs/2408.08977</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、量化技术、非均匀数据分布、通信效率、自适应量化策略

<br /><br />
总结:本文提出了一种名为FedFQ的通信高效联邦学习算法，它通过引入参数级量化和采用约束引导模拟退火算法来确定特定的量化方案，以解决联邦学习中大量边缘集群向服务器传输更新导致的通信瓶颈问题。FedFQ策略能够平衡高通信压缩比与优秀的收敛性能之间的关系。理论分析证明了其优于现有量化联邦学习算法的收敛性能。实验结果表明，在保持无损性能的同时，FedFQ实现了与基线实验相比高达27至63倍的压缩比。这一研究为提高联邦学习的通信效率提供了新的视角和方法。 <div>
arXiv:2408.08977v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized approach, enabling multiple participants to collaboratively train a model while ensuring the protection of data privacy. The transmission of updates from numerous edge clusters to the server creates a significant communication bottleneck in FL. Quantization is an effective compression technology, showcasing immense potential in addressing this bottleneck problem. The Non-IID nature of FL renders it sensitive to quantization. Existing quantized FL frameworks inadequately balance high compression ratios and superior convergence performance by roughly employing a uniform quantization bit-width on the client-side. In this work, we propose a communication-efficient FL algorithm with a fine-grained adaptive quantization strategy (FedFQ). FedFQ addresses the trade-off between achieving high communication compression ratios and maintaining superior convergence performance by introducing parameter-level quantization. Specifically, we have designed a Constraint-Guided Simulated Annealing algorithm to determine specific quantization schemes. We derive the convergence of FedFQ, demonstrating its superior convergence performance compared to existing quantized FL algorithms. We conducted extensive experiments on multiple benchmarks and demonstrated that, while maintaining lossless performance, FedFQ achieves a compression ratio of 27 times to 63 times compared to the baseline experiment.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Der Weg zur digitalen Arbeitsmappe: Digitales Pr\"ufungswesen mit Zertifizierung</title>
<link>https://arxiv.org/abs/2408.09184</link>
<guid>https://arxiv.org/abs/2408.09184</guid>
<content:encoded><![CDATA[
<div> 关键词：数字档案、区块链、智能合约、学习成果、透明度

总结:

本文旨在提出一种新型学生表现记录与评估方法，其核心目标是构建一个可持续、全面的数字档案系统，以替代传统的证书形式评价。该系统将工作样本作为主要记录内容，而非单一的证书或论文，从而实现对学习进度和技能的综合评估，而不仅仅是特定成果的挑选性评价。

技术上，该方法依托于区块链和智能合约等先进工具，以确保高透明度、可追溯性和低管理成本。通过智能合约，系统能安全地认证提供方的服务，确保学术成就的真实性和可靠性。

不同于当前仅依赖论文和期末考试评价学生的方式，本文构想在未来逐步取代高年级的最终作品和表现测试，引入基于教学项目支持的电子档案考试。这一转变旨在为学生提供个性化、全面的绩效记录，同时增强评价的透明度和理解性，从而促进教育过程的公平性和有效性。 <div>
arXiv:2408.09184v1 Announce Type: new 
Abstract: The aim of the work is to present an alternative approach to recording and evaluating student performance that enables sustainable performance recording with the possibility of integrating practical components in particular. The intended result is a digital portfolio with work samples - and not just certificates, which can be understood as a portfolio examination in the context of academic assessment. This is more about the recording, evaluation and certification of learning progress and competencies than the selective evaluation of a performance review, as is the case today, for example, with the submission of final theses. The idea is to expand and later replace final papers and performance tests, particularly in higher semesters, and instead introduce electronically recorded portfolio examinations - based on the example of teaching projects.
  Technologically, the approach is based on blockchain and wallets/repositories and, in the broadest sense, on an implementation of smart contracts. The technological approach of smart contracts enables a high degree of traceability and transparency with little administrative effort. It also offers secure certification of services by the provider. It should be clearly stated that neither the portfolio examination nor the administration of academic achievements with smart contracts is the original idea, but rather the change in the recording of academic achievements towards an alternative approach to the recording and evaluation of student performance, which enables sustainable performance recording with the possibility of integrating practical components in particular. The desired result is a digital portfolio with work samples.
  The primary aim of this idea sketch is to develop an individualized performance record for students, which can also contribute to making performance more transparent and comprehensible.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection</title>
<link>https://arxiv.org/abs/2408.09227</link>
<guid>https://arxiv.org/abs/2408.09227</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Medical Knowledge Injection (FEDMEKI)、跨域联邦学习、医疗知识注入、数据隐私保护、基础模型应用

<br />
<br />总结:
文章介绍了Federated Medical Knowledge Injection（FEDMEKI）平台，这是一个全新的基准，旨在解决在隐私约束下将医学知识融入基础模型的挑战。该平台通过采用跨域联邦学习方法，避免了中央数据收集导致的问题，这在遵守如美国健康保险流通与责任法案（HIPAA）等法规时尤为重要。FEDMEKI平台精心设计以处理多站点、多模态和多任务的医学数据，包括图像、信号、文本、实验室测试结果、生命体征、输入变量和输出变量等7种模态。验证FEDMEKI的定制数据集覆盖了8项医学任务，包括6项分类任务（肺部模糊检测、COVID-19检测、心电图异常检测、死亡率预测、败血症预测和心脏腔室增大检测）和2项生成任务（医学视觉问题回答（MedVQA）和心电信号噪声澄清）。数据集被分割给多个客户端，以支持在16个基准方法下的分散训练过程。FEDMEKI不仅保护了数据隐私，还增强了医学基础模型的能力，使其能够从更广泛的医学知识中学习，而无需直接暴露数据，从而在医疗领域为基础模型的应用设立了新的基准。 <div>
arXiv:2408.09227v1 Announce Type: new 
Abstract: This study introduces the Federated Medical Knowledge Injection (FEDMEKI) platform, a new benchmark designed to address the unique challenges of integrating medical knowledge into foundation models under privacy constraints. By leveraging a cross-silo federated learning approach, FEDMEKI circumvents the issues associated with centralized data collection, which is often prohibited under health regulations like the Health Insurance Portability and Accountability Act (HIPAA) in the USA. The platform is meticulously designed to handle multi-site, multi-modal, and multi-task medical data, which includes 7 medical modalities, including images, signals, texts, laboratory test results, vital signs, input variables, and output variables. The curated dataset to validate FEDMEKI covers 8 medical tasks, including 6 classification tasks (lung opacity detection, COVID-19 detection, electrocardiogram (ECG) abnormal detection, mortality prediction, sepsis prediction, and enlarged cardiomediastinum detection) and 2 generation tasks (medical visual question answering (MedVQA) and ECG noise clarification). This comprehensive dataset is partitioned across several clients to facilitate the decentralized training process under 16 benchmark approaches. FEDMEKI not only preserves data privacy but also enhances the capability of medical foundation models by allowing them to learn from a broader spectrum of medical knowledge without direct data exposure, thereby setting a new benchmark in the application of foundation models within the healthcare sector.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Establishment of a Blockchain-based Architecture for Fake News Detection</title>
<link>https://arxiv.org/abs/2408.09264</link>
<guid>https://arxiv.org/abs/2408.09264</guid>
<content:encoded><![CDATA[
<div> 关键词：假新闻、区块链、软件系统、架构设计、Hoffmeister过程

总结:

本文主要贡献在于提出了一种基于区块链的假新闻管理软件系统的指导性架构解决方案。通过遵循Hoffmeister软件架构设计过程，作者旨在解决假新闻管理领域中区块链与其他技术共存的架构方案的缺失问题。此解决方案旨在确保一旦新闻被认定为虚假，即可以不可变的方式持久化存储，以供感兴趣的各方查询。

为了验证该解决方案的有效性，文章还实施了两个候选架构，并进行了简短的模拟评估，证明了其满足功能性和质量要求的可能性。这种架构设计能够有效地支持假新闻管理软件系统的核心需求，包括审计追踪、数据完整性以及对虚假信息的可靠记录与检索能力。通过将区块链技术整合到假新闻管理系统中，该研究不仅提供了技术实现的可能，也为未来在这一领域的应用和发展奠定了基础。 <div>
arXiv:2408.09264v1 Announce Type: new 
Abstract: Fake News are a contemporary phenomenon with potential devastating effects. For inquiry and auditability purposes, it is essential that the news, once classified as false, can be persisted in an immutable means so that interested parties can query it. Although Blockchain clearly satisfies the main requirements for Fake News Management Software Systems, the prescriptive architectural solutions for that domain that cohabit Blockchain with other technologies in a single proposal still need to be made available. This paper's main contribution is presenting a prescriptive architectural solution for blockchain-based fake news management software systems. The Hoffmeister process for software architecture design is systematically followed to culminate in a software solution for that domain. The implementation of two candidate architectures and a brief simulation-based evaluation show the feasibility of the solution to satisfy the functional and quality requirements.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Beyond Local Views: Global State Inference with Diffusion Models for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2408.09501</link>
<guid>https://arxiv.org/abs/2408.09501</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、局部观察、全局状态重构、扩散模型、强化学习

总结:
文章主要探讨了在部分可观测的多智能体系统中，智能体仅能获取局部信息，导致决策精确性受限的问题。为解决这一问题，作者借鉴图像补全技术，提出了一种名为State Inference with Diffusion Models（SIDIFF）的方法。SIDIFF通过使用扩散模型来基于局部观察重建原始全局状态，从而帮助智能体在考虑局部信息的同时，也能够利用到全局信息做出更精确的决策。

SIDIFF系统由状态生成器和状态提取器两部分组成，使得智能体在执行任务时能够选择合适的行动。此外，该方法能够轻松地集成到现有的多智能体强化学习算法中，以提升其性能。作者通过在多个实验平台上对SIDIFF进行测试，包括他们开发的一个新的、灵活的多智能体强化学习环境——Multi-Agent Battle City（MABC），验证了该方法的有效性和优越性。

综上所述，SIDIFF提供了一种有效的方法来增强多智能体系统的决策能力，通过重建全局状态，使智能体能够在局部信息的基础上作出更加精准的决策。同时，该方法的可集成性使其在多智能体强化学习领域具有广泛的应用潜力。 <div>
arXiv:2408.09501v1 Announce Type: new 
Abstract: In partially observable multi-agent systems, agents typically only have access to local observations. This severely hinders their ability to make precise decisions, particularly during decentralized execution. To alleviate this problem and inspired by image outpainting, we propose State Inference with Diffusion Models (SIDIFF), which uses diffusion models to reconstruct the original global state based solely on local observations. SIDIFF consists of a state generator and a state extractor, which allow agents to choose suitable actions by considering both the reconstructed global state and local observations. In addition, SIDIFF can be effortlessly incorporated into current multi-agent reinforcement learning algorithms to improve their performance. Finally, we evaluated SIDIFF on different experimental platforms, including Multi-Agent Battle City (MABC), a novel and flexible multi-agent reinforcement learning environment we developed. SIDIFF achieved desirable results and outperformed other popular algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Seamless Integration: Sampling Strategies in Federated Learning Systems</title>
<link>https://arxiv.org/abs/2408.09545</link>
<guid>https://arxiv.org/abs/2408.09545</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、新客户端、数据异质性、系统效率、稳定性

总结:

本文探讨了Federated Learning（FL）系统中整合新客户端所面临的挑战与机遇。FL作为一种分散式训练模型的新范式，允许在众多设备上进行学习，同时保护本地数据隐私。然而，FL系统的动态特性，包括不断加入具有不同数据分布和计算能力的新客户端，对系统稳定性和效率构成了重大挑战。文章深入分析了数据异质性如何影响模型训练、系统效能、可扩展性和稳定性。

尽管面临这些挑战，将新客户端集成到FL系统中提供了增强数据多样性、提高学习性能以及利用分布式计算资源的机会。相较于其他领域，如Gboard等应用中的分布式优化，生产环境中通常只有少数客户端，因此每个新客户端的信息变得尤为重要。

文章提出了有效的客户端选择策略以及确保系统可扩展性和稳定性的解决方案。以光学质量检查图像为例，提供了实用的方法论。结论指出，解决新客户端整合带来的挑战对于推动分布式学习网络的发展和提升其效率至关重要，这为FL在生产环境中的广泛应用铺平了道路。 <div>
arXiv:2408.09545v1 Announce Type: new 
Abstract: Federated Learning (FL) represents a paradigm shift in the field of machine learning, offering an approach for a decentralized training of models across a multitude of devices while maintaining the privacy of local data. However, the dynamic nature of FL systems, characterized by the ongoing incorporation of new clients with potentially diverse data distributions and computational capabilities, poses a significant challenge to the stability and efficiency of these distributed learning networks. The seamless integration of new clients is imperative to sustain and enhance the performance and robustness of FL systems. This paper looks into the complexities of integrating new clients into existing FL systems and explores how data heterogeneity and varying data distribution (not independent and identically distributed) among them can affect model training, system efficiency, scalability and stability. Despite these challenges, the integration of new clients into FL systems presents opportunities to enhance data diversity, improve learning performance, and leverage distributed computational power. In contrast to other fields of application such as the distributed optimization of word predictions on Gboard (where federated learning once originated), there are usually only a few clients in the production environment, which is why information from each new client becomes all the more valuable. This paper outlines strategies for effective client selection strategies and solutions for ensuring system scalability and stability. Using the example of images from optical quality inspection, it offers insights into practical approaches. In conclusion, this paper proposes that addressing the challenges presented by new client integration is crucial to the advancement and efficiency of distributed learning networks, thus paving the way for the adoption of Federated Learning in production environments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment</title>
<link>https://arxiv.org/abs/2408.09556</link>
<guid>https://arxiv.org/abs/2408.09556</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、数据异质性、模型训练、方法论、工业4.0

<br /><br />
总结:

本文深入探讨了联邦学习（FL）在制造业背景下的数据异质性问题，这一现象对模型训练效果和效率构成了挑战。数据异质性主要体现在非独立同分布（non-IID）数据、数据不平衡、数据质量差异以及统计异质性等方面。作者详细分析了这些异质性类型如何影响模型训练过程，并回顾了现有的减轻负面影响的方法。

首先，针对数据分布的非IID特性，提出了个性化和定制化的模型策略，旨在适应不同环境的数据特性。其次，通过采用鲁棒聚合技术，增强模型对数据异质性的容忍度，确保训练过程的稳定性和可靠性。此外，讨论了基于客户端选择的技术，以优化参与训练的设备或系统，从而提高整体训练效率。

文章强调了综合现有研究并提出新策略的重要性，以有效管理联邦学习中的数据异质性问题，增强模型的稳健性，并确保跨多样环境的公平和高效训练。同时，指出了未来研究方向，即开发适应性和可扩展性更强的解决方案，以进一步提升联邦学习在工业4.0时代的应用潜力。 <div>
arXiv:2408.09556v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a promising approach to training machine learning models across decentralized data sources while preserving data privacy, particularly in manufacturing and shared production environments. However, the presence of data heterogeneity variations in data distribution, quality, and volume across different or clients and production sites, poses significant challenges to the effectiveness and efficiency of FL. This paper provides a comprehensive overview of heterogeneity in FL within the context of manufacturing, detailing the types and sources of heterogeneity, including non-independent and identically distributed (non-IID) data, unbalanced data, variable data quality, and statistical heterogeneity. We discuss the impact of these types of heterogeneity on model training and review current methodologies for mitigating their adverse effects. These methodologies include personalized and customized models, robust aggregation techniques, and client selection techniques. By synthesizing existing research and proposing new strategies, this paper aims to provide insight for effectively managing data heterogeneity in FL, enhancing model robustness, and ensuring fair and efficient training across diverse environments. Future research directions are also identified, highlighting the need for adaptive and scalable solutions to further improve the FL paradigm in the context of Industry 4.0.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Faster Adaptive Decentralized Learning Algorithms</title>
<link>https://arxiv.org/abs/2408.09775</link>
<guid>https://arxiv.org/abs/2408.09775</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、自适应梯度方法、非凸优化、样本复杂性、去中心化算法

<br /><br />
总结:本文提出了一类更快的自适应分布式优化算法（AdaMDOS和AdaMDOF），用于分布式非凸随机优化和有限求和优化。通过提供一个坚实的方法论框架，该研究为这些方法的收敛性提供了理论支持。具体而言，AdaMDOS在寻找非凸随机优化问题的$\epsilon$-稳定解时，达到了近最优的样本复杂度$\tilde{O}(\epsilon^{-3})$。同时，AdaMDOF在寻找非凸有限求和优化问题的$\epsilon$-稳定解时，实现了$O(\sqrt{n}\epsilon^{-2})$的样本复杂度，其中$n$表示样本大小。这是首次有自适应去中心化算法针对非凸有限求和优化进行研究。实验结果证实了这些算法的有效性。 <div>
arXiv:2408.09775v1 Announce Type: new 
Abstract: Decentralized learning recently has received increasing attention in machine learning due to its advantages in implementation simplicity and system robustness, data privacy. Meanwhile, the adaptive gradient methods show superior performances in many machine learning tasks such as training neural networks. Although some works focus on studying decentralized optimization algorithms with adaptive learning rates, these adaptive decentralized algorithms still suffer from high sample complexity. To fill these gaps, we propose a class of faster adaptive decentralized algorithms (i.e., AdaMDOS and AdaMDOF) for distributed nonconvex stochastic and finite-sum optimization, respectively. Moreover, we provide a solid convergence analysis framework for our methods. In particular, we prove that our AdaMDOS obtains a near-optimal sample complexity of $\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary solution of nonconvex stochastic optimization. Meanwhile, our AdaMDOF obtains a near-optimal sample complexity of $O(\sqrt{n}\epsilon^{-2})$ for finding an $\epsilon$-stationary solution of nonconvex finite-sum optimization, where $n$ denotes the sample size. To the best of our knowledge, our AdaMDOF algorithm is the first adaptive decentralized algorithm for nonconvex finite-sum optimization. Some experimental results demonstrate efficiency of our algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Validation of the Results of Cross-chain Smart Contract Based on Confirmation Method</title>
<link>https://arxiv.org/abs/2408.09962</link>
<guid>https://arxiv.org/abs/2408.09962</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、跨链交互、数据验证、一致性证明、数据完整性

总结:
本文提出了一种针对跨链智能合约结果验证的新方法。该方法强调了消费者区块链执行生产者区块链的跨链智能合约，通过比较传入结果与执行结果，以检测潜在差异并确保跨链数据传播过程中的数据完整性。此外，引入了“确认与证明”方法，即将生产者区块链的区块链和相关跨链智能合约数据整合到消费者区块链中作为证据（或证明），以此建立统一且安全的跨链智能合约结果视角。

通过实施这种验证机制，可以显著提高跨链交互的安全性和可信度，特别是在智能合约的执行和结果传输过程中。实验结果证实了跨链验证在智能合约层面的可行性，为跨链技术的发展提供了重要的理论基础和实践指导。此方法不仅增强了区块链网络之间的互操作性，还强化了数据的一致性和安全性，对构建更加可靠和高效的分布式应用生态系统具有重要意义。 <div>
arXiv:2408.09962v1 Announce Type: new 
Abstract: Smart contracts are widely utilized in cross-chain interactions, where their results are transmitted from one blockchain (the producer blockchain) to another (the consumer blockchain). Unfortunately, the consumer blockchain often accepts these results without executing the smart contracts for validation, posing potential security risks. To address this, we propose a method for validating cross-chain smart contract results. Our approach emphasizes consumer blockchain execution of cross-chain smart contracts of producer blockchain, allowing comparison of results with the transmitted ones to detect potential discrepancies and ensure data integrity during cross-chain data dissemination. Additionally, we introduce the confirmation with proof method, which involves incorporating the chain of blocks and relevant cross-chain smart contract data from the producer blockchain into the consumer blockchain as evidence (or proof), establishing a unified and secure perspective of cross-chain smart contract results. Our verification results highlight the feasibility of cross-chain validation at the smart contract level.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>"EBK" : Leveraging Crowd-Sourced Social Media Data to Quantify How Hyperlocal Gang Affiliations Shape Personal Networks and Violence in Chicago's Contemporary Southside</title>
<link>https://arxiv.org/abs/2408.10018</link>
<guid>https://arxiv.org/abs/2408.10018</guid>
<content:encoded><![CDATA[
<div> 关键词：伦理学研究、芝加哥南区、微帮派“组”、跨帮派人际网络、自然语言处理

<br /><br />
总结:

本文基于近期的人类学研究，揭示了芝加哥南区帮派动态的新变化，主要表现为分散的微帮派“组”以及跨帮派的人际网络成为当代社会的特征。然而，传统警方数据集缺乏深度，难以进行细致的帮派暴力分析。为解决这一问题，研究团队采用了自然语言处理技术，分析了一个芝加哥帮派论坛的文本信息。通过识别专有名词、概率链接到帮派“组”，并假设提及名字之间的社会联系，他们构建了一个包含271个体和11个帮派“组”的社交网络数据集。

进一步的研究利用Louvain社区检测方法发现，这些个体往往与来自地理位置相近帮派“组”的帮派关联同伴建立联系。通过层次逻辑回归分析，研究指出，与被谋杀者有联系以及在整体帮派网络中处于中心位置的个体，不论其所属帮派，都面临更高的被害风险。这项研究证明了利用在线社群信息可以探索以往难以触及的话题和群体，从而为深入理解帮派活动提供了一种新的研究途径。 <div>
arXiv:2408.10018v1 Announce Type: new 
Abstract: Recent ethnographic research reveals that gang dynamics in Chicago's Southside have evolved with decentralized micro-gang "set" factions and cross-gang interpersonal networks marking the contemporary landscape. However, standard police datasets lack the depth to analyze gang violence with such granularity. To address this, we employed a natural language processing strategy to analyze text from a Chicago gangs message board. By identifying proper nouns, probabilistically linking them to gang sets, and assuming social connections among names mentioned together, we created a social network dataset of 271 individuals across 11 gang sets. Using Louvain community detection, we found that these individuals often connect with gang-affiliated peers from various gang sets that are physically proximal. Hierarchical logistic regression revealed that individuals with ties to homicide victims and central positions in the overall gang network were at increased risk of victimization, regardless of gang affiliation. This research demonstrates that utilizing crowd-sourced information online can enable the study of otherwise inaccessible topics and populations.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulseye: Detect Smart Contract Vulnerabilities via Stateful Directed Graybox Fuzzing</title>
<link>https://arxiv.org/abs/2408.10116</link>
<guid>https://arxiv.org/abs/2408.10116</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、灰盒模糊测试、状态导向、资源优化

总结:

本文针对当前智能合约模糊测试工具在效率和资源利用方面存在的问题，提出了一种名为Vulseye的状态导向灰盒模糊测试方法。Vulseye通过引入代码目标和状态目标，以及设计一种结合了代码空间和状态空间反馈的新型适应度度量，实现了对智能合约的高效、精准测试。与现有最先进的模糊测试工具相比，Vulseye在效果和效率上均表现出了显著优势。

Vulseye的主要创新点在于其状态导向的模糊测试策略。它通过优先测试更有可能存在漏洞的代码区域和状态，从而有效减少了对无害代码区域的资源浪费。此外，Vulseye利用静态分析和模式匹配来识别代码目标，采用可扩展的反向分析算法来指定状态目标。这种策略不仅提高了测试的针对性，还增强了模糊测试的全面性。

通过这些改进，Vulseye成功地解决了智能合约模糊测试中常见的资源分配不均和覆盖率不足的问题，为智能合约的安全性评估提供了更为高效和准确的手段。这将有助于提升用户资产的安全性和整体对去中心化系统的信任度。 <div>
arXiv:2408.10116v1 Announce Type: new 
Abstract: Smart contracts, the cornerstone of decentralized applications, have become increasingly prominent in revolutionizing the digital landscape. However, vulnerabilities in smart contracts pose great risks to user assets and undermine overall trust in decentralized systems. But current smart contract fuzzers fall short of expectations in testing efficiency for two primary reasons. Firstly, smart contracts are stateful programs, and existing approaches, primarily coverage-guided, lack effective feedback from the contract state. Consequently, they struggle to effectively explore the contract state space. Secondly, coverage-guided fuzzers, aiming for comprehensive program coverage, may lead to a wastage of testing resources on benign code areas. This wastage worsens in smart contract testing, as the mix of code and state spaces further complicates comprehensive testing.
  To address these challenges, we propose Vulseye, a stateful directed graybox fuzzer for smart contracts guided by vulnerabilities. Different from prior works, Vulseye achieves stateful directed fuzzing by prioritizing testing resources to code areas and contract states that are more prone to vulnerabilities. We introduce Code Targets and State Targets into fuzzing loops as the testing targets of Vulseye. We use static analysis and pattern matching to pinpoint Code Targets, and propose a scalable backward analysis algorithm to specify State Targets. We design a novel fitness metric that leverages feedback from both the contract code space and state space, directing fuzzing toward these targets. With the guidance of code and state targets, Vulseye alleviates the wastage of testing resources on benign code areas and achieves effective stateful fuzzing. In comparison with state-of-the-art fuzzers, Vulseye demonstrated superior effectiveness and efficiency.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-Envisioned UAV-Aided Disaster Relief Networks: Challenges and Solutions</title>
<link>https://arxiv.org/abs/2310.05180</link>
<guid>https://arxiv.org/abs/2310.05180</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、UAVs、灾害救援、智能合约、安全挑战

总结:

本文探讨了利用无人机辅助的灾害救援网络（UDRN）面临的关键问题及解决方案。随着对协作性、无信任性和透明度的需求日益增长，区块链技术被引入以增强UDRN的服务能力。然而，实施基于区块链的UDRN仍面临着效率和安全上的挑战，包括智能合约间的合作不足、智能合约漏洞的动态审计缺失以及对抗交易可变性攻击的取证鲁棒性低。

为解决这些挑战，本文提出了一系列创新性方法：
1. **协作智能合约**：设计一系列协同工作智能合约，用于协调救援管理过程中的资源分配和任务调度。
2. **动态合同审计机制**：建立一种能够检测已知和未知智能合约漏洞的动态审计系统，确保UDRN系统的安全性。
3. **鲁棒交易取证策略**：通过结合链上和链下合作的策略，构建强大的交易取证方案，有效抵御交易可变性攻击。

通过原型实现和实验结果验证，证明了上述方法的有效性和可行性。最后，文章还指出了未来研究领域中需要重点关注的关键问题，旨在推动这一新兴领域的持续发展。

这些措施不仅提升了UDRN的效率与安全性，也为未来的灾害救援提供了更为可靠的技术支撑。 <div>
arXiv:2310.05180v3 Announce Type: replace 
Abstract: Natural or man-made disasters pose significant challenges for delivering critical relief to affected populations due to disruptions in critical infrastructures and logistics networks. Unmanned aerial vehicles (UAVs)-aided disaster relief networks (UDRNs) leverage UAVs to assist existing ground relief networks by swiftly assessing affected areas and timely delivering lifesaving supplies. To meet the growing demands for collaborative, trust-free, and transparent UDRN services, blockchain-based UDRNs emerge as a promising approach through immutable ledgers and distributed smart contracts. However, several efficiency and security challenges hinder the deployment of blockchain-based UDRNs, including the lack of cooperation between smart contracts, lack of dynamic audit for smart contract vulnerabilities, and low forensics robustness against transaction malleability attacks. Towards efficient and secure blockchain-based UDRNs, this paper presents potential solutions: (i) a series of collaborative smart contracts for coordinated relief management, (ii) a dynamic contract audit mechanism to prevent known/unknown contract vulnerabilities; and (iii) a robust transaction forensics strategy with on/off-chain cooperation to resist transaction malleability attacks. Our prototype implementation and experimental results demonstrate the feasibility and effectiveness of our approach. Lastly, we outline key open research issues crucial to advancing this emerging field.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Orchestrated Robust Controller for the Precision Control of Heavy-duty Hydraulic Manipulators</title>
<link>https://arxiv.org/abs/2312.06304</link>
<guid>https://arxiv.org/abs/2312.06304</guid>
<content:encoded><![CDATA[
<div> 关键词：虚拟分解控制、径向基函数神经网络、鲁棒控制器、工业机器人、高精度控制

<br /><br />
总结:本文研究设计了一种基于虚拟分解控制（VDC）的鲁棒控制器，旨在解决大型工业投资和学术研究推动的液压重型机械臂自动化过程中遇到的挑战。该控制器针对具有类人手臂和球形腕部的一般机械臂系统进行设计，考虑了未知模型不确定性、未知干扰和复合输入非线性等因素。通过将整个机器人系统分解为子系统并在每个局部子系统中设计鲁棒控制器，引入径向基函数神经网络（RBFNNs）来处理未知干扰和不确定性，从而实现新型去中心化的RBFNNs。所设计的鲁棒局部控制器在各局部子系统之间协调工作，以实现高精度控制。首次在VDC背景下实现了半全局均匀终界收敛性。理论结果通过6自由度工业机械臂的广泛仿真和实验验证，该机械臂具有600公斤的额定提升能力，达到5米的延伸距离。与现有最先进的控制器相比，模拟结果和提供的实验数据证明了提出方法的所有承诺并表现卓越。 <div>
arXiv:2312.06304v2 Announce Type: replace 
Abstract: Vast industrial investment along with increased academic research on hydraulic heavy-duty manipulators has unavoidably paved the way for their automatization, necessitating the design of robust and high-precision controllers. In this study, an orchestrated robust controller is designed to address the mentioned issue for a generic manipulator with an anthropomorphic arm and spherical wrist. To do so, the entire robotic system is decomposed into subsystems, and a robust controller is designed at each local subsystem by considering unknown model uncertainties, unknown disturbances, and compound input nonlinearities, thanks to virtual decomposition control (VDC). As such, radial basic function neural networks (RBFNNs) are incorporated into VDC to tackle unknown disturbances and uncertainties, resulting in novel decentralized RBFNNs. All robust local controllers designed at each local subsystem, then, are orchestrated to accomplish high-precision control. In the end, for the first time in the context of VDC, a semi-globally uniformly ultimate boundedness is achieved under the designed controller. The validity of the theoretical results is verified by performing extensive simulations and experiments on a 6-degrees-of-freedom industrial manipulator with a nominal lifting capacity of 600 kg at 5 meters reach. Comparing the simulation result to the state-of-the-art controller along with provided experimental results, demonstrates that proposed method established all promises and performed excellently.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SCLA: Automated Smart Contract Summarization via LLMs and Semantic Augmentation</title>
<link>https://arxiv.org/abs/2402.04863</link>
<guid>https://arxiv.org/abs/2402.04863</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链系统、智能合约、代码摘要、大型语言模型、SCLA框架

总结:

本文探讨了在快速发展的区块链系统背景下，高效智能合约开发与维护的重要性。随着技术进步，对智能合约进行有效管理的需求日益凸显，而智能合约代码摘要能够显著提升这一过程的效率并降低潜在风险。然而，当前大型语言模型（LLMs）如GPT-4和Gemini-1.5-Pro在生成代码摘要方面仍存在局限性，其性能低于通过微调构建的模型（如CodeT5+、CodeBERT）。针对此问题，本文提出了一种名为SCLA的框架，该框架结合了LLM与语义增强技术，旨在提升代码摘要性能。

SCLA通过构建智能合约的抽象语法树（AST）来提取潜在语义信息，并以此为基础形成具有语义增强的提示。为了评估其效果，研究者利用了一个由4万份真实世界智能合约组成的大型数据集。实验结果显示，SCLA在生成高质量代码摘要方面表现出色，其BLEU-4、METEOR、ROUGE-L以及BLEURT指标分别达到37.53%、52.54%、56.97%和63.44%，远超当前领先模型（如CodeBERT、CodeT5和CodeT5+）的表现。这表明，SCLA框架通过改进提示策略，显著提升了大型语言模型在智能合约代码摘要任务上的表现。 <div>
arXiv:2402.04863v4 Announce Type: replace 
Abstract: In the rapidly evolving world of blockchain systems, the efficient development and maintenance of smart contracts has become a critical task. Smart contract code summarization can significantly facilitate the maintenance of smart contracts and mitigate their vulnerabilities. Large Language Models (LLMs), such as GPT-4o and Gemini-1.5-Pro, possess the capability to generate code summarizations from code examples embedded in prompts. However, the performance of LLMs in code summarization remains suboptimal compared to fine-tuning-based models (e.g., CodeT5+, CodeBERT). Therefore, we propose SCLA, a framework leveraging LLMs and semantic augmentation to improve code summarization performance. SCLA constructs the smart contract's Abstract Syntax Tree (AST) to extract latent semantics, thereby forming a semantically augmented prompt. For evaluation, we utilize a large-scale dataset comprising 40,000 real-world contracts. Experimental results demonstrate that SCLA, with its enhanced prompt, significantly improves the quality of code summarizations. SCLA surpasses other state-of-the-art models (e.g., CodeBERT, CodeT5, and CodeT5+), achieving 37.53% BLEU-4, 52.54% METEOR, 56.97% ROUGE-L, and 63.44% BLEURT, respectively.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications</title>
<link>https://arxiv.org/abs/2403.16073</link>
<guid>https://arxiv.org/abs/2403.16073</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、大型语言模型、审计、细调、iAudit框架

总结:
本文提出了一种名为iAudit的通用框架，旨在通过结合细调和基于大型语言模型（LLM）的代理来实现直观的智能合约审计及原因说明。iAudit灵感来源于专家审计员的审计流程，即首先感知潜在问题，然后深入分析代码以识别漏洞原因。该框架采用两阶段细调策略：首先对决策模型进行细调，然后对原因生成模型进行细调。然而，单纯的细调面临准确识别漏洞根本原因的挑战。因此，引入了两个LLM代理——排序器和批评者——通过迭代选择并辩论最合适的漏洞原因，基于细调后原因生成模型的输出。为了评估iAudit的效果，研究团队收集了一个平衡的数据集，包含1,734个正样本和1,810个负样本，用于细调iAudit。与传统的细调模型（如CodeBERT、GraphCodeBERT、CodeT5和UnixCoder）以及基于提示学习的LLM（如GPT4、GPT-3.5和CodeLlama-13b/34b）进行了对比。在包含263个真实智能合约漏洞的数据集上，iAudit实现了91.21%的F1得分和91.11%的准确性。iAudit生成的原因与真实原因的一致性约为38%。通过这一框架，研究团队展示了如何利用LLM和细调技术提升智能合约审计的效率和精确度。 <div>
arXiv:2403.16073v2 Announce Type: replace 
Abstract: Smart contracts are decentralized applications built atop blockchains like Ethereum. Recent research has shown that large language models (LLMs) have potential in auditing smart contracts, but the state-of-the-art indicates that even GPT-4 can achieve only 30% precision (when both decision and justification are correct). This is likely because off-the-shelf LLMs were primarily pre-trained on a general text/code corpus and not fine-tuned on the specific domain of Solidity smart contract auditing.
  In this paper, we propose iAudit, a general framework that combines fine-tuning and LLM-based agents for intuitive smart contract auditing with justifications. Specifically, iAudit is inspired by the observation that expert human auditors first perceive what could be wrong and then perform a detailed analysis of the code to identify the cause. As such, iAudit employs a two-stage fine-tuning approach: it first tunes a Detector model to make decisions and then tunes a Reasoner model to generate causes of vulnerabilities. However, fine-tuning alone faces challenges in accurately identifying the optimal cause of a vulnerability. Therefore, we introduce two LLM-based agents, the Ranker and Critic, to iteratively select and debate the most suitable cause of vulnerability based on the output of the fine-tuned Reasoner model. To evaluate iAudit, we collected a balanced dataset with 1,734 positive and 1,810 negative samples to fine-tune iAudit. We then compared it with traditional fine-tuned models (CodeBERT, GraphCodeBERT, CodeT5, and UnixCoder) as well as prompt learning-based LLMs (GPT4, GPT-3.5, and CodeLlama-13b/34b). On a dataset of 263 real smart contract vulnerabilities, iAudit achieves an F1 score of 91.21% and an accuracy of 91.11%. The causes generated by iAudit achieved a consistency of about 38% compared to the ground truth causes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A semi-centralized multi-agent RL framework for efficient irrigation scheduling</title>
<link>https://arxiv.org/abs/2408.08442</link>
<guid>https://arxiv.org/abs/2408.08442</guid>
<content:encoded><![CDATA[
<div> 关键词：Semi-Centralized Multi-Agent Reinforcement Learning（SCMARL）、灌溉调度、空间变异性、管理区、水节约

<br /><br />
总结:
本文提出了一种基于半集中式多智能体强化学习（SCMARL）的方法，用于解决具有空间变异性农田的灌溉调度问题。该方法采用层次结构设计，包括一个中央协调智能体和多个本地智能体。中央智能体负责做出全局性的日间灌溉决策，而本地智能体则根据各自管理区的具体条件来确定合适的灌溉量。为应对本地环境的非稳定性，引入了状态增强策略。

在加拿大莱斯布里奇的一个大规模实验田上，该SCMARL方法与基于学习的多智能体模型预测控制灌溉调度方法进行了对比。结果显示，SCMARL方法在保持灌溉效率的同时，实现了灌溉用水节约，具体表现为灌溉水使用效率提高了6.3%，同时节省了4.0%的灌溉用水。这一创新方法不仅提高了灌溉资源的利用效率，也为解决水资源短缺问题提供了新的策略。 <div>
arXiv:2408.08442v1 Announce Type: new 
Abstract: This paper proposes a Semi-Centralized Multi-Agent Reinforcement Learning (SCMARL) approach for irrigation scheduling in spatially variable agricultural fields, where management zones address spatial variability. The SCMARL framework is hierarchical in nature, with a centralized coordinator agent at the top level and decentralized local agents at the second level. The coordinator agent makes daily binary irrigation decisions based on field-wide conditions, which are communicated to the local agents. Local agents determine appropriate irrigation amounts for specific management zones using local conditions. The framework employs state augmentation approach to handle non-stationarity in the local agents' environments. An extensive evaluation on a large-scale field in Lethbridge, Canada, compares the SCMARL approach with a learning-based multi-agent model predictive control scheduling approach, highlighting its enhanced performance, resulting in water conservation and improved Irrigation Water Use Efficiency (IWUE). Notably, the proposed approach achieved a 4.0% savings in irrigation water while enhancing the IWUE by 6.3%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-Enabled Accountability in Data Supply Chain: A Data Bill of Materials Approach</title>
<link>https://arxiv.org/abs/2408.08536</link>
<guid>https://arxiv.org/abs/2408.08536</guid>
<content:encoded><![CDATA[
<div> 关键词：数据治理、数据供应链、数据可追溯性、软件物料清单、区块链技术

总结:

本文聚焦于当前人工智能时代中，大型生成模型如GPT-4的广泛应用背景下，确保数据集生命周期内的可追溯性、验证性和可重复性的重要性。研究指出，随着研究机构和科技公司依赖大量数据集进行AI模型的训练与微调，复杂的数据供应链要求建立有效的数据治理机制。然而，由于不同利益相关者可能使用不同的工具，缺乏足够的措施以确保数据责任和结果可靠性，这一问题变得更加突出。

为解决上述挑战，本文提出将“软件物料清单”概念引入数据管理领域，创新地提出了“数据物料清单”（DataBOM）的概念。通过存储特定元数据，DataBOM旨在捕捉不同数据集及参与者之间的依赖关系。文中详细介绍了基于区块链技术的DataBOM服务平台架构，阐述了各参与者的交互协议，并讨论了DataBOM所需元数据的最小需求。通过案例研究和定量分析，评估了该解决方案的可行性和性能。

最终，本文强调了DataBOM在增强数据透明度、提高数据供应链效率以及确保数据质量和责任方面的重要作用，为构建更加可靠和可信赖的数据生态系统提供了理论基础和技术框架。 <div>
arXiv:2408.08536v1 Announce Type: new 
Abstract: In the era of advanced artificial intelligence, highlighted by large-scale generative models like GPT-4, ensuring the traceability, verifiability, and reproducibility of datasets throughout their lifecycle is paramount for research institutions and technology companies. These organisations increasingly rely on vast corpora to train and fine-tune advanced AI models, resulting in intricate data supply chains that demand effective data governance mechanisms. In addition, the challenge intensifies as diverse stakeholders may use assorted tools, often without adequate measures to ensure the accountability of data and the reliability of outcomes. In this study, we adapt the concept of ``Software Bill of Materials" into the field of data governance and management to address the above challenges, and introduce ``Data Bill of Materials" (DataBOM) to capture the dependency relationship between different datasets and stakeholders by storing specific metadata. We demonstrate a platform architecture for providing blockchain-based DataBOM services, present the interaction protocol for stakeholders, and discuss the minimal requirements for DataBOM metadata. The proposed solution is evaluated in terms of feasibility and performance via case study and quantitative analysis respectively.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation</title>
<link>https://arxiv.org/abs/2408.08571</link>
<guid>https://arxiv.org/abs/2408.08571</guid>
<content:encoded><![CDATA[
<div> 关键词：业务过程模拟、资源优先方法、事件日志、多代理系统、仿真准确性

<br /><br />
总结:本文介绍了一种名为AgentSimulator的新型业务过程模拟（BPS）方法，该方法采取了资源优先视角，从事件日志中发现了一个多代理系统，以模拟业务流程中的不同资源行为和交互模式。这种方法不仅能够准确地捕捉现实世界中涉及资源行为和分散决策的实际过程动态，而且在实验中显示出与现有方法相比，拥有更高的仿真精确度、更低的计算时间以及更好的可解释性和适应性，适用于各种类型的业务执行场景。通过这种方式，AgentSimulator为理解和优化复杂业务流程提供了一种更为灵活和高效的方法。 <div>
arXiv:2408.08571v1 Announce Type: new 
Abstract: Business process simulation (BPS) is a versatile technique for estimating process performance across various scenarios. Traditionally, BPS approaches employ a control-flow-first perspective by enriching a process model with simulation parameters. Although such approaches can mimic the behavior of centrally orchestrated processes, such as those supported by workflow systems, current control-flow-first approaches cannot faithfully capture the dynamics of real-world processes that involve distinct resource behavior and decentralized decision-making. Recognizing this issue, this paper introduces AgentSimulator, a resource-first BPS approach that discovers a multi-agent system from an event log, modeling distinct resource behaviors and interaction patterns to simulate the underlying process. Our experiments show that AgentSimulator achieves state-of-the-art simulation accuracy with significantly lower computation times than existing approaches while providing high interpretability and adaptability to different types of process-execution scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A survey on secure decentralized optimization and learning</title>
<link>https://arxiv.org/abs/2408.08628</link>
<guid>https://arxiv.org/abs/2408.08628</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、安全分散优化、联邦学习、鲁棒算法、加密工具

总结:

本文提供了一篇关于分散式优化和学习领域中隐私保护与安全性的综合教程。文章首先概述了分散式优化的基本概念，强调了在联邦学习和分布式优化过程中，集中聚合和分布共识模块可能面临的安全风险。接着，文章深入探讨了隐私保护算法，详细介绍了三种加密工具及其在分散式优化和学习系统中的应用。此外，文章还分析了鲁棒算法设计与评估，着重讨论了支持这些系统的鲁棒聚合与共识协议的设计与实现。最后，文章总结了当前趋势，并展望了未来研究方向。

文章旨在为读者提供对分散式优化和学习领域中安全性与隐私保护问题的全面理解，通过详细阐述加密技术、隐私保护算法以及鲁棒性策略，为构建更安全、可靠的分散式计算环境提供了理论基础与实践指导。 <div>
arXiv:2408.08628v1 Announce Type: new 
Abstract: Decentralized optimization has become a standard paradigm for solving large-scale decision-making problems and training large machine learning models without centralizing data. However, this paradigm introduces new privacy and security risks, with malicious agents potentially able to infer private data or impair the model accuracy. Over the past decade, significant advancements have been made in developing secure decentralized optimization and learning frameworks and algorithms. This survey provides a comprehensive tutorial on these advancements. We begin with the fundamentals of decentralized optimization and learning, highlighting centralized aggregation and distributed consensus as key modules exposed to security risks in federated and distributed optimization, respectively. Next, we focus on privacy-preserving algorithms, detailing three cryptographic tools and their integration into decentralized optimization and learning systems. Additionally, we examine resilient algorithms, exploring the design and analysis of resilient aggregation and consensus protocols that support these systems. We conclude the survey by discussing current trends and potential future directions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Explore-then-Commit Algorithms for Decentralized Two-Sided Matching Markets</title>
<link>https://arxiv.org/abs/2408.08690</link>
<guid>https://arxiv.org/abs/2408.08690</guid>
<content:encoded><![CDATA[
<div> 关键词：在线学习、分散式双侧匹配市场、探索后承诺算法、碰撞避免探索后承诺（CA-ETC）、黑板通信基线

总结:

本文研究了分散式双侧匹配市场的在线学习问题，其中需求方（玩家）与供给方（臂）进行匹配。与以往工作相比，本文不假设手臂预先知道其对玩家的偏好排序（单向学习），并且不假设任何结构化问题假设。主要贡献包括：

1. **提出算法**：提出了一种基于多阶段探索后承诺的算法——epoch-based CA-ETC（碰撞避免探索后承诺算法），该算法无需跨代理（玩家和手臂）的通信，因此具有分散性。

2. **理论分析**：通过理论分析，证明了对于初始周期长度为$T_{\circ}$，后续周期长度为$2^{l/\gamma} T_{\circ}$（第$l$个周期，$\gamma \in (0,1)$是算法输入参数），CA-ETC算法为第$i$位玩家提供了玩家最优预期后悔值$\mathcal{O}\left(T_{\circ} (\frac{K \log T}{T_{\circ} \Delta^2})^{1/\gamma} + T_{\circ} (\frac{T}{T_{\circ}})^\gamma\right)$，其中$T$是学习时间跨度，$K$是手臂的数量，$\Delta$是适当定义的问题差距。

3. **对比分析**：文章还提出了一种基于黑板通信的基线算法，该算法在$T$的对数级别上实现了后悔。

4. **创新点**：该研究解决了没有预设手臂偏好排序的情况下分散式双侧匹配市场的在线学习问题，提供了高效的学习策略，同时通过比较分析展示了不同方法的性能差异。

5. **应用背景**：此研究有助于理解并优化实际匹配平台（如UpWork, TaskRabbit）中的复杂交互过程，为提高匹配效率提供理论基础和技术指导。 <div>
arXiv:2408.08690v1 Announce Type: new 
Abstract: Online learning in a decentralized two-sided matching markets, where the demand-side (players) compete to match with the supply-side (arms), has received substantial interest because it abstracts out the complex interactions in matching platforms (e.g. UpWork, TaskRabbit). However, past works assume that each arm knows their preference ranking over the players (one-sided learning), and each player aim to learn the preference over arms through successive interactions. Moreover, several (impractical) assumptions on the problem are usually made for theoretical tractability such as broadcast player-arm match Liu et al. (2020; 2021); Kong & Li (2023) or serial dictatorship Sankararaman et al. (2021); Basu et al. (2021); Ghosh et al. (2022). In this paper, we study a decentralized two-sided matching market, where we do not assume that the preference ranking over players are known to the arms apriori. Furthermore, we do not have any structural assumptions on the problem. We propose a multi-phase explore-then-commit type algorithm namely epoch-based CA-ETC (collision avoidance explore then commit) (\texttt{CA-ETC} in short) for this problem that does not require any communication across agents (players and arms) and hence decentralized. We show that for the initial epoch length of $T_{\circ}$ and subsequent epoch-lengths of $2^{l/\gamma} T_{\circ}$ (for the $l-$th epoch with $\gamma \in (0,1)$ as an input parameter to the algorithm), \texttt{CA-ETC} yields a player optimal expected regret of $\mathcal{O}\left(T_{\circ} (\frac{K \log T}{T_{\circ} \Delta^2})^{1/\gamma} + T_{\circ} (\frac{T}{T_{\circ}})^\gamma\right)$ for the $i$-th player, where $T$ is the learning horizon, $K$ is the number of arms and $\Delta$ is an appropriately defined problem gap. Furthermore, we propose a blackboard communication based baseline achieving logarithmic regret in $T$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ML Study of MaliciousTransactions in Ethereum</title>
<link>https://arxiv.org/abs/2408.08749</link>
<guid>https://arxiv.org/abs/2408.08749</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、Ethereum、恶意代码检测、GPT2、CodeLlama

<br /><br />
总结:

本文探讨了智能合约在以太坊交易中的关键作用及其潜在风险。研究指出，黑客通过在智能合约源代码中添加漏洞，进而执行恶意交易。为此，作者提出了两种检测恶意智能合约的方法：

1. **基于Opcode的方法**：利用GPT2模型识别智能合约中不常见的操作码，以此来检测可能存在的恶意行为。
   
2. **基于Solidity源代码的方法**：采用细调后的CodeLlama模型分析智能合约的源代码，识别可能隐藏的恶意逻辑。

此外，文章还提出了一种结合了交易gas属性和十六进制签名的XGBOOST模型，用于检测可能的恶意交易。该模型假设恶意行为通常表现为对合约功能的非典型使用以及交易努力度的提升。通过综合这些特征，模型能够更准确地识别出潜在的恶意活动。

总之，本文通过创新的技术手段，为智能合约安全检测提供了新的视角，旨在提高以太坊网络的安全性，减少由智能合约漏洞引发的恶意交易风险。 <div>
arXiv:2408.08749v1 Announce Type: new 
Abstract: Smart contracts are a major tool in Ethereum transactions. Therefore hackers can exploit them by adding code vulnerabilities to their sources and using these vulnerabilities for performing malicious transactions. This paper presents two successful approaches for detecting malicious contracts: one uses opcode and relies on GPT2 and the other uses the Solidity source and a LORA fine-tuned CodeLlama. Finally, we present an XGBOOST model that combines gas properties and Hexa-decimal signatures for detecting malicious transactions. This approach relies on early assumptions that maliciousness is manifested by the uncommon usage of the contracts' functions and the effort to pursue the transaction.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Beyond Proportional Individual Guarantees for Binary Perpetual Voting</title>
<link>https://arxiv.org/abs/2408.08767</link>
<guid>https://arxiv.org/abs/2408.08767</guid>
<content:encoded><![CDATA[
<div> 关键词：集体决策、二元决策、个体保证、最大化最小份额、在线算法

总结:

本文探讨了在需要作出大量决策的环境中实现公平集体决策的问题，特别关注于二元决策（是/否）及其对参与个体的个体保障。研究引入了一种新颖的概念，灵感来源于公平分配中的最大化最小份额（MMS）。这一概念设想每个参与者都希望获得与他们最佳划分决策给其他参与者相匹配的数量，而决策的分配则由假设的对手决定。

研究中提出了针对3名参与者的在线算法以确保MMS原则，以及针对4名参与者的离线算法。然而，对于7名或更多参与者的情况，证明了没有在线算法能够确保适应性MMS原则。此外，研究还揭示了最大纳什福利（MNW）结果在最坏情况下的表现只能达到MMS原则的大约1/n。

总的来说，这篇论文为理解复杂决策环境中的公平性提供了新的视角和方法，特别是通过引入和分析最大化最小份额概念，以及探讨在线和离线算法在不同参与者数量下的性能，为设计更公平的决策机制提供了理论基础和实践指导。 <div>
arXiv:2408.08767v1 Announce Type: new 
Abstract: Perpetual voting studies fair collective decision-making in settings where many decisions are to be made, and is a natural framework for settings such as parliaments and the running of blockchain Decentralized Autonomous Organizations (DAOs). We focus our attention on the binary case (YES/NO decisions) and \textit{individual} guarantees for each of the participating agents. We introduce a novel notion, inspired by the popular maxi-min-share (MMS) for fair allocation. The agent expects to get as many decisions as if they were to optimally partition the decisions among the agents, with an adversary deciding which of the agents decides on what bundle. We show an online algorithm that guarantees the MMS notion for $n=3$ agents, an offline algorithm for $n=4$ agents, and show that no online algorithm can guarantee the $MMS^{adapt}$ for $n\geq 7$ agents. We also show that the Maximum Nash Welfare (MNW) outcome can only guarantee $O(\frac{1}{n})$ of the MMS notion in the worst case.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Strategic Liquidity Provision in Uniswap v3</title>
<link>https://arxiv.org/abs/2106.12033</link>
<guid>https://arxiv.org/abs/2106.12033</guid>
<content:encoded><![CDATA[
<div> 关键词：Uniswap v3、战略流动性提供、神经网络优化框架、动态流动性提供问题、经济环境差异

总结:
本文探讨了Uniswap v3中流动性提供者（LP）的战略流动性提供问题。Uniswap v3允许LP将流动性分配到资产价格的特定区间，而非全价范围，这种设计引入了如何在风险与收益之间做出权衡的问题。当价格保持在指定区间内，流动性集中在该区间会带来较高的费用奖励，但同时也伴随着价格跳出该区间的高风险，导致可能无费用收入。

为了优化LP的收益，文章提出了一个基于神经网络的优化框架，用于解决动态流动性提供问题。该框架旨在为LP设计策略，以最大化其收益。通过模拟LP面临的历史价格变化序列，研究揭示了在不同经济环境下，最优LP行为的质性差异，并展示了与现有分配策略基线相比，该方法能显著提高LP的收益。

此研究不仅提供了对动态流动性管理的深入理解，也为LP在不确定市场环境中优化资源分配提供了实用工具。通过实验验证，证明了所提出的神经网络优化框架的有效性和实用性，为DeFi领域流动性管理策略的发展提供了新的视角和方法。 <div>
arXiv:2106.12033v5 Announce Type: replace 
Abstract: Uniswap v3 is the largest decentralized exchange for digital currencies. A novelty of its design is that it allows a liquidity provider (LP) to allocate liquidity to one or more closed intervals of the price of an asset instead of the full range of possible prices. An LP earns fee rewards proportional to the amount of its liquidity allocation when prices move in this interval. This induces the problem of {\em strategic liquidity provision}: smaller intervals result in higher concentration of liquidity and correspondingly larger fees when the price remains in the interval, but with higher risk as prices may exit the interval leaving the LP with no fee rewards. Although reallocating liquidity to new intervals can mitigate this loss, it comes at a cost, as LPs must expend gas fees to do so. We formalize the dynamic liquidity provision problem and focus on a general class of strategies for which we provide a neural network-based optimization framework for maximizing LP earnings. We model a single LP that faces an exogenous sequence of price changes that arise from arbitrage and non-arbitrage trades in the decentralized exchange. We present experimental results informed by historical price data that demonstrate large improvements in LP earnings over existing allocation strategy baselines. Moreover we provide insight into qualitative differences in optimal LP behaviour in different economic environments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Federated Natural Policy Gradient and Actor Critic Methods for Multi-task Reinforcement Learning</title>
<link>https://arxiv.org/abs/2311.00201</link>
<guid>https://arxiv.org/abs/2311.00201</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦强化学习、多任务设置、私有奖励函数、过渡核共享、全局最优策略

总结:

本文研究了联邦强化学习（Federated Reinforcement Learning, FRL）在多任务场景下的应用。在多任务设置中，每个代理拥有其特定的任务奖励函数，但共享相同的环境过渡核。目标是在分布式环境下，通过不共享本地数据轨迹的方式，学习能够最大化所有代理总奖励之和的全局最优策略。

首先，针对无限时区马尔科夫决策过程，文章提出了一种基于softmax参数化的联邦范式和熵正则化自然策略梯度方法。为了减轻信息共享不完美的影响，采用了梯度跟踪技术来估计全局Q函数。通过理论分析，文章给出了在精确策略评估下非渐进收敛的保证，并揭示了网络规模和连通性对收敛速度的影响。这是首次在联邦多任务强化学习中使用策略优化方法建立接近维度无关的全局收敛性。

其次，文章超越了表格设置，提出了联邦自然演员评论者（Federated Natural Actor Critic, FNAC）方法，用于具有功能近似的多任务强化学习。考虑到函数逼近误差，该方法建立了其有限时间样本复杂性。通过这一方法，文章为多任务强化学习提供了更广泛的应用场景，特别是当涉及复杂环境或大规模状态空间时，能够有效利用有限的数据资源进行策略学习。

总的来说，本文为联邦多任务强化学习领域提供了重要的理论基础和实践指导，不仅丰富了强化学习的分布式学习框架，也为解决实际世界中的大规模、分布式决策问题提供了新的思路和方法。 <div>
arXiv:2311.00201v2 Announce Type: replace 
Abstract: Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology.
  We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods in the tabular setting under softmax parameterization, where gradient tracking is applied to estimate the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, where the rates are nearly independent of the size of the state-action space and illuminate the impacts of network size and connectivity. To the best of our knowledge, this is the first time that near dimension-free global convergence is established for federated multi-task RL using policy optimization. We further go beyond the tabular setting by proposing a federated natural actor critic (NAC) method for multi-task RL with function approximation, and establish its finite-time sample complexity taking the errors of function approximation into account.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Implementation Study of Cost-Effective Verification for Pietrzak's Verifiable Delay Function in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2405.06498</link>
<guid>https://arxiv.org/abs/2405.06498</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Delay Function（VDF）、Pietrzak VDF、Ethereum Virtual Machine（EVM）、优化、区块链环境

总结:

本文针对Verifiable Delay Function（VDF）在区块链环境中的应用进行了深入研究，特别关注了Pietrzak提出的VDF协议。传统上，该协议存在证明大小长和递归协议计算复杂的问题。为了克服这些问题，作者在以太坊虚拟机（EVM）上对Pietrzak VDF的验证过程进行了实施研究。

首先，通过仔细分析Pietrzak原始论文中关于计算成本的讨论，作者发现EVM中可以实现清晰的优化，因为计算成本是预先定义的，与特定的气体量相对应。这种优化使VDF验证的成本从4M降低到2M气体单位，显著提高了效率。

其次，通过优化计算流程，作者成功将使用2048位RSA密钥长度的VDF证明长度压缩至8KB以内，远低于预期。这一成果不仅降低了存储需求，还提高了整体系统性能，对于区块链等资源受限环境尤为关键。

综上所述，本文通过在EVM上的实施研究，展示了如何优化Pietrzak VDF协议，使其在区块链环境中更加高效、经济，为VDF技术的实际应用提供了有价值的参考。 <div>
arXiv:2405.06498v4 Announce Type: replace 
Abstract: Verifiable Delay Function (VDF) is a cryptographic concept that ensures a minimum delay before output through sequential processing, which is resistant to parallel computing. One of the significant VDF protocols academically reviewed is the VDF protocol proposed by Pietrzak. However, for the blockchain environment, the Pietrzak VDF has drawbacks including long poof size and recursive protocol computation. In this paper, we present an implementation study of Pietrzak VDF verification on Ethereum Virtual Machine (EVM). We found that the discussion in the Pietrzak's original paper can help a clear optimization in EVM where the costs of computation are predefined as the specific amounts of gas. In our results, the cost of VDF verification can be reduced from 4M to 2M gas, and the proof length can be generated under 8 KB with the 2048-bit RSA key length, which is much smaller than the previous expectation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Fair Division</title>
<link>https://arxiv.org/abs/2408.07821</link>
<guid>https://arxiv.org/abs/2408.07821</guid>
<content:encoded><![CDATA[
<div> 关键词：公平分割、分散式系统、社区资源管理、社会福利、效率

总结:
本文探讨了一种基于分散式系统的公平分割模型，灵感源自社区导向的目标设定、互助网络与社区资源管理。这种模型与传统的集中式公平分割框架相对比，旨在评估在分散与集中策略下资源分配的公平性与社会福利保障。研究指出，现有文献中关于序列交换的模型由于无法实现理想结果而受到限制，而分散式模型则被视为这些约束条件下的放松。在模拟现实世界场景的设定下，两种资源分配模式展现出不同的公平性和社会福利保障。特别地，该分散式模型在满足特定条件时，能够以高效的方式确保高质量的分配决策。这一发现强调了在实际应用中考虑分散式策略的重要性，尤其是在追求高效和公平的资源管理情境中。 <div>
arXiv:2408.07821v1 Announce Type: new 
Abstract: Fair division is typically framed from a centralized perspective. We study a decentralized variant of fair division inspired by the dynamics observed in community-based targeting, mutual aid networks, and community resource management paradigms. We develop an approach for decentralized fair division and compare it with a centralized approach with respect to fairness and social welfare guarantees. In the context of the existing literature, our decentralized model can be viewed as a relaxation of previous models of sequential exchange in light of impossibility results concerning the inability of those models to achieve desirable outcomes. We find that in settings representative of many real world situations, the two models of resource allocation offer contrasting fairness and social welfare guarantees. In particular, we show that under appropriate conditions, our model of decentralized allocation can ensure high-quality allocative decisions in an efficient fashion.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Personhood credentials: Artificial intelligence and the value of privacy-preserving tools to distinguish who is real online</title>
<link>https://arxiv.org/abs/2408.07892</link>
<guid>https://arxiv.org/abs/2408.07892</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名性、AI、人身份证明（PHCs）、在线平台、政策制定者

<br /><br />
总结:

本文探讨了在线环境下平衡匿名性和信任度的挑战。随着AI能力的增强，恶意行为者能够通过创建误导性的身份进行欺诈、传播虚假信息等行为，这加剧了平衡匿名性和信任度的难度。文章提出了一种新的解决方案——“人身份证明”(PHCs)，这是一种数字凭证，用户可以在不泄露个人信息的情况下证明自己是真实的人，而不是AI，以此向在线服务提供商展示其可信度。

与当前针对自动化欺骗的防御措施如CAPTCHAs相比，PHCs更有效地应对了高度拟人化的AI和可扩展性问题。然而，实施PHC系统也面临部署风险和设计挑战，包括隐私保护、安全性和用户接受度等问题。文章强调了在政策制定者、技术专家和标准机构考虑实施前，需要与公众进行充分讨论的重要性。 <div>
arXiv:2408.07892v1 Announce Type: new 
Abstract: Anonymity is an important principle online. However, malicious actors have long used misleading identities to conduct fraud, spread disinformation, and carry out other deceptive schemes. With the advent of increasingly capable AI, bad actors can amplify the potential scale and effectiveness of their operations, intensifying the challenge of balancing anonymity and trustworthiness online. In this paper, we analyze the value of a new tool to address this challenge: "personhood credentials" (PHCs), digital credentials that empower users to demonstrate that they are real people -- not AIs -- to online services, without disclosing any personal information. Such credentials can be issued by a range of trusted institutions -- governments or otherwise. A PHC system, according to our definition, could be local or global, and does not need to be biometrics-based. Two trends in AI contribute to the urgency of the challenge: AI's increasing indistinguishability (i.e., lifelike content and avatars, agentic activity) from people online, and AI's increasing scalability (i.e., cost-effectiveness, accessibility). Drawing on a long history of research into anonymous credentials and "proof-of-personhood" systems, personhood credentials give people a way to signal their trustworthiness on online platforms, and offer service providers new tools for reducing misuse by bad actors. In contrast, existing countermeasures to automated deception -- such as CAPTCHAs -- are inadequate against sophisticated AI, while stringent identity verification solutions are insufficiently private for many use-cases. After surveying the benefits of personhood credentials, we also examine deployment risks and design challenges. We conclude with actionable next steps for policymakers, technologists, and standards bodies to consider in consultation with the public.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Centralized Network Utility Maximization with Accelerated Gradient Method</title>
<link>https://arxiv.org/abs/2408.08034</link>
<guid>https://arxiv.org/abs/2408.08034</guid>
<content:encoded><![CDATA[
<div> 关键词：网络优化、软件定义网络、集中式算法、高效性、可扩展性

总结:
本文研究了在软件定义网络(SDN)环境下，网络流量管理和资源分配的网络效能最大化(NUM)问题。针对大型企业管理和运营的云网络和数据中心网络中流量规模的日益增长，现有的集中式NUM算法主要关注于算法对流量数量的可扩展性，而忽略了效率问题。为此，作者设计了一种高效且可扩展的集中式NUM算法。

首先，通过构建平滑的效用函数和惩罚函数，将NUM问题转化为具有平滑目标函数的形式，从而可以应用Nesterov加速梯度法进行求解。理论分析证明了所提出方法的收敛速度为O(d/t^2)，这是在迭代次数t上最快的收敛速率，并且该方法在流量数量d上也表现出良好的可扩展性。

实验结果表明，该方法能够以更少的迭代次数获得准确的解决方案，并且在网络效能方面接近最优值，充分体现了其高效性和可扩展性的优势。 <div>
arXiv:2408.08034v1 Announce Type: new 
Abstract: Network utility maximization (NUM) is a well-studied problem for network traffic management and resource allocation. Because of the inherent decentralization and complexity of networks, most researches develop decentralized NUM algorithms.In recent years, the Software Defined Networking (SDN) architecture has been widely used, especially in cloud networks and inter-datacenter networks managed by large enterprises, promoting the design of centralized NUM algorithms. To cope with the large and increasing number of flows in such SDN networks, existing researches about centralized NUM focus on the scalability of the algorithm with respect to the number of flows, however the efficiency is ignored. In this paper, we focus on the SDN scenario, and derive a centralized, efficient and scalable algorithm for the NUM problem. By the designing of a smooth utility function and a smooth penalty function, we formulate the NUM problem with a smooth objective function, which enables the use of Nesterov's accelerated gradient method. We prove that the proposed method has $O(d/t^2)$ convergence rate, which is the fastest with respect to the number of iterations $t$, and our method is scalable with respect to the number of flows $d$ in the network. Experiments show that our method obtains accurate solutions with less iterations, and achieves close-to-optimal network utility.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Stochastic Real-Time Economic Dispatch for Integrated Electric and Gas Systems Considering Uncertainty Propagation and Pipeline Leakage</title>
<link>https://arxiv.org/abs/2408.08101</link>
<guid>https://arxiv.org/abs/2408.08101</guid>
<content:encoded><![CDATA[
<div> 关键词：燃气发电单元、快速调节能力、电力系统、天然气系统、实时经济调度

总结:

本文研究了具有快速调节能力的燃气发电单元（GFUs）在缓解可再生能源发电波动及增强电力系统（EPS）与天然气系统（NGS）耦合方面的作用。然而，这种紧密耦合也带来了不确定性传播的问题，对集成电气系统的实时调度构成了挑战。同时，NGS中的管道泄漏可能威胁到EPS的供电可靠性。针对这些问题，作者首先构建了一个考虑了NGS动态特性的燃气管道在不确定泄漏故障下的运行模型。

接着，提出了一种考虑不确定传播和管道泄漏不确定性的集成电气系统（IEGSs）实时经济调度（RTED）模型。为了解决复杂的大规模随机优化问题，提出了耦合边界动态调整区域（LCBDAR）的概念，用于描述连接GFUs的NGS边界动态特性。基于LCBDAR，提出了一种非迭代的分散式解决方案，将原始的随机RTED模型分解为两个子问题，分别由EPS和NGS操作者独立解决，以保护数据隐私。特别地，只需要NGS向EPS进行一次数据交互。

通过在不同规模的IEGS案例研究，验证了所提出方法的有效性。 <div>
arXiv:2408.08101v1 Announce Type: new 
Abstract: Gas-fired units (GFUs) with rapid regulation capabilities are considered an effective tool to mitigate fluctuations in the generation of renewable energy sources and have coupled electricity power systems (EPSs) and natural gas systems (NGSs) more tightly. However, this tight coupling leads to uncertainty propagation, a challenge for the real-time dispatch of such integrated electric and gas systems (IEGSs). Moreover, pipeline leakage failures in the NGS may threaten the electricity supply reliability of the EPS through GFUs. To address these problems, this paper first establishes an operational model considering gas pipeline dynamic characteristics under uncertain leakage failures for the NGS and then presents a stochastic IEGS real-time economic dispatch (RTED) model considering both uncertainty propagation and pipeline leakage uncertainty. To quickly solve this complicated large-scale stochastic optimization problem, a novel notion of the coupling boundary dynamic adjustment region considering pipeline leakage failure (LCBDAR) is proposed to characterize the dynamic characteristics of the NGS boundary connecting GFUs. Based on the LCBDAR, a noniterative decentralized solution is proposed to decompose the original stochastic RTED model into two subproblems that are solved separately by the EPS and NGS operators, thus preserving their data privacy. In particular, only one-time data interaction from the NGS to the EPS is required. Case studies on several IEGSs at different scales demonstrate the effectiveness of the proposed method.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DiffPMAE: Diffusion Masked Autoencoders for Point Cloud Reconstruction</title>
<link>https://arxiv.org/abs/2312.03298</link>
<guid>https://arxiv.org/abs/2312.03298</guid>
<content:encoded><![CDATA[
<div> 关键词：点云流式传输、高带宽消耗、大规模存储、点云重建、自监督学习

<br /><br />
总结:
本文提出了一种名为DiffPMAE的有效点云重建架构，旨在解决点云数据处理中面临的数据量大、带宽消耗高和存储需求大的问题。DiffPMAE结合了Masked Auto-Encoding和Diffusion Model机制，通过远程重构点云数据，实现自监督学习概念的应用。该方法不仅能够用于点云的高效重建，还能扩展到包括压缩、上采样和完成在内的多个下游任务。实验结果表明，DiffPMAE在自编码和考虑的下游任务性能方面均超越了现有最先进的方法。通过使用ShapeNet-55和ModelNet数据集，验证了其在大规模点云数据处理上的优势与潜力。 <div>
arXiv:2312.03298v3 Announce Type: replace 
Abstract: Point cloud streaming is increasingly getting popular, evolving into the norm for interactive service delivery and the future Metaverse. However, the substantial volume of data associated with point clouds presents numerous challenges, particularly in terms of high bandwidth consumption and large storage capacity. Despite various solutions proposed thus far, with a focus on point cloud compression, upsampling, and completion, these reconstruction-related methods continue to fall short in delivering high fidelity point cloud output. As a solution, in DiffPMAE, we propose an effective point cloud reconstruction architecture. Inspired by self-supervised learning concepts, we combine Masked Auto-Encoding and Diffusion Model mechanism to remotely reconstruct point cloud data. By the nature of this reconstruction process, DiffPMAE can be extended to many related downstream tasks including point cloud compression, upsampling and completion. Leveraging ShapeNet-55 and ModelNet datasets with over 60000 objects, we validate the performance of DiffPMAE exceeding many state-of-the-art methods in-terms of auto-encoding and downstream tasks considered.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Distributed Privacy Preserving Model for the Detection of Alzheimer's Disease</title>
<link>https://arxiv.org/abs/2312.10237</link>
<guid>https://arxiv.org/abs/2312.10237</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗数据分割、个人健康信息（PHI）、联邦学习模型、阿尔茨海默病（AD）、多模态垂直联邦学习（VFL）

总结:

本文探讨了联邦学习模型在医疗数据分割背景下，如何为诊断机器学习（DML）研究者提供隐私保护的机器学习算法。联邦学习模型允许分布在不同设备或服务器上的多个研究人员合作训练全球机器学习模型，无需交换本地数据，从而满足法定的个人健康信息（PHI）保护要求。

研究使用了第二版开放访问系列成像研究中的多元成像、临床评估和人口统计学数据集，测试了一种用于AD检测的多模态垂直联邦学习（VFL）模型。通过训练和验证该VFL模型在OASIS-2中的数据，实现了82.9%的准确率，与之前报告的结果一致。

提出的VFL架构提供了一种分布式框架，使医疗数据的多源协作学习成为可能，同时尊重法定的隐私限制。通过利用多种数据模态，AD检测的稳健性和准确性可以得到增强。这一模型不仅推动了联邦学习技术的进步，而且有望克服医疗研究中数据分割带来的挑战。 <div>
arXiv:2312.10237v3 Announce Type: replace 
Abstract: BACKGROUND: Segmentation of medical data, concerns about personal health information (PHI) breaches, and the direct and indirect costs of consolidating and managing such segmented date should motivate diagnostic machine learning (DML) researchers to identify privacy-preserving machine learning algorithms that can train on distributed or decentralized datasets of different modalities. Federated learning models provide such a decentralized machine learning framework in which multiple investigators in possession of disparate datasets and working on different devices or servers can train collaboratively a global machine learning models without ever having to exchange local data and thus can meet statutory PHI protections. To this end, a vertical federate learning model is devised and tested for efficacy in the detection of Alzheimer's Disease (AD).
  METHODS: The second version of Open Access Series of Imaging Studies -- with its panoply of demographic, imaging, and clinical assessment datasets -- was used to test a multimodal vertical federated learning (VFL) model for AD detection.
  RESULTS: By training and validating this VFL model on the demographic, clinical, and MRI data in OASIS-2, an 82.9\% accuracy rate is achieved, consistent with previously reported results.
  CONCLUSIONS: The VFL architecture proposed herein offers a novel distributed architecture, enabling collaborative learning across diverse sources of medical data while respecting statutory privacy constraints. By leveraging multiple modalities of data, the robustness and accuracy of AD detection can be enhanced. This model not only contributes to the advancement of federated learning techniques but also holds promise for overcoming the hurdles posed by data segmentation in medical research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OFL-W3: A One-shot Federated Learning System on Web 3.0</title>
<link>https://arxiv.org/abs/2408.07096</link>
<guid>https://arxiv.org/abs/2408.07096</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、区块链技术、Web 3.0、智能合约、Inter-Planetary File System

总结:
本文提出了一种专为Web 3.0设计的一次性联邦学习系统（OFL-W3），旨在解决数据孤岛问题。通过利用区块链技术中的智能合约进行交易管理，以及结合Inter-Planetary File System（IPFS）和Flask通信来优化后端服务器操作，该系统实现了传统联邦学习中单次客户端与服务器交互的高效模型。引入激励机制，使得OFL-W3不仅能够有效实现在Web 3.0环境下的联邦学习，还为人工智能与Web 3.0的融合研究提供了宝贵见解。这一创新解决方案旨在克服核心区块链如以太坊的交易速度限制和智能合约的延迟问题，为构建去中心化、安全、高效的在线协作学习平台铺平道路。 <div>
arXiv:2408.07096v1 Announce Type: new 
Abstract: Federated Learning (FL) addresses the challenges posed by data silos, which arise from privacy, security regulations, and ownership concerns. Despite these barriers, FL enables these isolated data repositories to participate in collaborative learning without compromising privacy or security. Concurrently, the advancement of blockchain technology and decentralized applications (DApps) within Web 3.0 heralds a new era of transformative possibilities in web development. As such, incorporating FL into Web 3.0 paves the path for overcoming the limitations of data silos through collaborative learning. However, given the transaction speed constraints of core blockchains such as Ethereum (ETH) and the latency in smart contracts, employing one-shot FL, which minimizes client-server interactions in traditional FL to a single exchange, is considered more apt for Web 3.0 environments. This paper presents a practical one-shot FL system for Web 3.0, termed OFL-W3. OFL-W3 capitalizes on blockchain technology by utilizing smart contracts for managing transactions. Meanwhile, OFL-W3 utilizes the Inter-Planetary File System (IPFS) coupled with Flask communication, to facilitate backend server operations to use existing one-shot FL algorithms. With the integration of the incentive mechanism, OFL-W3 showcases an effective implementation of one-shot FL on Web 3.0, offering valuable insights and future directions for AI combined with Web 3.0 studies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>V3rified: Revelation vs Non-Revelation Mechanisms for Decentralized Verifiable Computation</title>
<link>https://arxiv.org/abs/2408.07177</link>
<guid>https://arxiv.org/abs/2408.07177</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、分散技术、可验证计算、外包计算、机制设计

文章主要探讨了在Web3时代，分散技术作为新数字范式的基石所扮演的角色。随着数据共享和学习模型等应用中外包计算的普遍性增加，可验证计算使得这一实践更加可信，因为它允许客户端高效验证计算的完整性。文章关注于在考虑将可验证计算应用于Web3空间时，分散化与效率之间的权衡问题。

1. **机制设计与外包计算**：文章研究了客户端如何通过采用揭示机制（如拍卖）或非揭示机制（如承诺规则）来外包计算任务给战略理性的解决方案提供者时，分散化与效率之间的权衡问题。

2. **揭示机制**：在揭示机制下，解决方案提供者为完成任务并按时交付而竞标他们期望的报酬。客户端选择完成任务的提供者及其应得的报酬。文章完全分析了揭示机制的力量和局限性。

3. **非揭示机制**：在非揭示机制下，客户端承诺使用一套规则来映射特定时间点的解决方案到奖励，解决方案提供者决定是否接受任务。文章同样详细讨论了非揭示机制的性能和限制。

4. **权衡分析**：文章深入探讨了在分散化和效率之间进行权衡的必要性，以满足客户端快速完成计算任务的需求，同时确保系统的可靠性，避免任何单一实体抑制客户端。

5. **完全表征**：文章最终提供了一种方法，用于全面理解并限制揭示和非揭示机制在模型中的功能，为优化Web3空间中的外包计算过程提供了理论基础。

总结:
文章通过深入研究揭示机制和非揭示机制在外包计算中的应用，旨在解决Web3空间中分散化与效率之间的关键权衡问题。它通过分析两种机制的优缺点，为实现高效、可靠的计算外包服务提供了理论依据。揭示机制允许客户端根据解决方案提供者的报价进行选择，而非揭示机制则通过预先设定的规则来指导决策过程。文章的全面表征有助于开发者和研究者在构建Web3应用时做出更明智的选择，以优化计算资源的分配和利用。 <div>
arXiv:2408.07177v1 Announce Type: new 
Abstract: In the era of Web3, decentralized technologies have emerged as the cornerstone of a new digital paradigm. Backed by a decentralized blockchain architecture, the Web3 space aims to democratize all aspects of the web. From data-sharing to learning models, outsourcing computation is an established, prevalent practice. Verifiable computation makes this practice trustworthy as clients/users can now efficiently validate the integrity of a computation. As verifiable computation gets considered for applications in the Web3 space, decentralization is crucial for system reliability, ensuring that no single entity can suppress clients. At the same time, however, decentralization needs to be balanced with efficiency: clients want their computations done as quickly as possible.
  Motivated by these issues, we study the trade-off between decentralization and efficiency when outsourcing computational tasks to strategic, rational solution providers. Specifically, we examine this trade-off when the client employs (1) revelation mechanisms, i.e. auctions, where solution providers bid their desired reward for completing the task by a specific deadline and then the client selects which of them will do the task and how much they will be rewarded, and (2) simple, non-revelation mechanisms, where the client commits to the set of rules she will use to map solutions at specific times to rewards and then solution providers decide whether they want to do the task or not. We completely characterize the power and limitations of revelation and non-revelation mechanisms in our model.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Microgrid Building Blocks for Dynamic Decoupling and Black Start Applications</title>
<link>https://arxiv.org/abs/2408.07601</link>
<guid>https://arxiv.org/abs/2408.07601</guid>
<content:encoded><![CDATA[
<div> 关键词：微电网、BTB转换器、分布式发电、储能系统、综合相量域模型

文章主要探讨了在电力系统中，微电网通过BTB转换器与主电网和邻近微电网进行无缝集成的重要性。BTB转换器作为一种关键的接口技术，能够有效地连接微电网、混合AC/DC电网和主电网，利用综合相量域模型（结合到GridLAB-D中）进行高效仿真。文章以修改后的IEEE 13节点配电系统为基础，构建了一个双微电网网络，该网络配备了柴油发电机、光伏单元和电池储能系统（BESS），并通过模拟展示BTB转换器在动态解耦和受控支持方面的灵活性，以突出其对微电网功能的贡献。

总结:
本文研究了BTB转换器在微电网与主电网及邻近微电网之间集成中的作用，强调了综合相量域模型在GridLAB-D中的应用对于提高仿真效率的重要性。通过构建一个包含柴油发电机、光伏和电池储能系统的双微电网网络，本文展示了BTB转换器在动态解耦和提供受控支持方面的潜力，从而增强了微电网的经济和技术潜力。这一研究不仅为微电网的高效运行提供了理论基础，也为未来智能电网的建设提供了参考。 <div>
arXiv:2408.07601v1 Announce Type: new 
Abstract: Microgrids offer increased self-reliance and resilience at the grid's edge. They promote a significant transition to decentralized and renewable energy production by optimizing the utilization of local renewable sources. However, to maintain stable operations under all conditions and harness microgrids' full economic and technological potential, it is essential to integrate with the bulk grid and neighboring microgrids seamlessly. In this paper, we explore the capabilities of Back-to-Back (BTB) converters as a pivotal technology for interfacing microgrids, hybrid AC/DC grids, and bulk grids, by leveraging a comprehensive phasor-domain model integrated into GridLAB-D. The phasor-domain model is computationally efficient for simulating BTB with bulk grids and networked microgrids. We showcase the versatility of BTB converters (an integrated Microgrid Building Block) by configuring a two-microgrid network from a modified IEEE 13-node distribution system. These microgrids are equipped with diesel generators, photovoltaic units, and Battery Energy Storage Systems (BESS). The simulation studies are focused on use cases demonstrating dynamic decoupling and controlled support that a microgrid can provide via a BTB converter.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SigmaRL: A Sample-Efficient and Generalizable Multi-Agent Reinforcement Learning Framework for Motion Planning</title>
<link>https://arxiv.org/abs/2408.07644</link>
<guid>https://arxiv.org/abs/2408.07644</guid>
<content:encoded><![CDATA[
<div> 关键词：SigmaRL、多智能体强化学习、交通场景、信息密集观察、零射泛化

总结:

这篇论文提出了一种名为SigmaRL的开源、去中心化的框架，旨在提高连接和自动化车辆的运动规划中多智能体强化学习的样本效率与泛化能力。大多数强化学习代理在泛化方面存在局限性，往往只专注于特定情境。为了改善这一状况，作者引入了五种设计信息密集型观察的策略，这些策略适用于大多数交通场景的一般特征。通过在交叉路口对RL代理进行训练，并在完全未见过的交通场景（如新的交叉路口、上坡道和环岛）进行评估，以验证其泛化能力。

实验结果表明，使用信息密集型观察训练的RL代理能够在不到一小时的时间内完成单CPU训练，并且能够实现有效的零射泛化，即在未见过的情境下也能表现良好。此外，该研究还强调了观察设计在影响样本效率和泛化能力方面的关键作用，为未来的研究提供了一个重要的研究方向。 <div>
arXiv:2408.07644v1 Announce Type: new 
Abstract: This paper introduces an open-source, decentralized framework named SigmaRL, designed to enhance both sample efficiency and generalization of multi-agent Reinforcement Learning (RL) for motion planning of connected and automated vehicles. Most RL agents exhibit a limited capacity to generalize, often focusing narrowly on specific scenarios, and are usually evaluated in similar or even the same scenarios seen during training. Various methods have been proposed to address these challenges, including experience replay and regularization. However, how observation design in RL affects sample efficiency and generalization remains an under-explored area. We address this gap by proposing five strategies to design information-dense observations, focusing on general features that are applicable to most traffic scenarios. We train our RL agents using these strategies on an intersection and evaluate their generalization through numerical experiments across completely unseen traffic scenarios, including a new intersection, an on-ramp, and a roundabout. Incorporating these information-dense observations reduces training times to under one hour on a single CPU, and the evaluation results reveal that our RL agents can effectively zero-shot generalize. Code: github.com/cas-lab-munich/SigmaRL
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BlockFUL: Enabling Unlearning in Blockchained Federated Learning</title>
<link>https://arxiv.org/abs/2402.16294</link>
<guid>https://arxiv.org/abs/2402.16294</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、区块链、去学习、双链结构、继承模型

总结:
本文提出了Blockchained Federated Unlearning（BlockFUL）框架，旨在解决在联邦学习（FL）中进行去学习（unlearning）的挑战。BlockFUL采用了双链结构，包括实时链和归档链，以实现区块链环境下FL的去学习能力。该框架引入了并行和序列两种新的去学习范式，通过基于梯度上升的方法和重新训练的方法来执行去学习操作。

首先，BlockFUL通过在多个继承模型间建立高效共识操作，减少了数据依赖和操作开销，从而提高了去学习过程的性能。其次，基于梯度上升的去学习方法允许模型直接从历史记录中删除特定数据，而无需重建整个模型，进一步减少了计算成本。最后，重新训练的方法则侧重于在去除不希望的数据后，对模型进行局部调整，以保持其准确性。

通过在CIFAR-10和Fashion-MNIST数据集上使用AlexNet、ResNet18和MobileNetV2模型的广泛实验，验证了这些方法的有效性，证明了它们能够成功减少对数据的依赖和操作开销，从而显著提升BlockFUL整体性能。 <div>
arXiv:2402.16294v2 Announce Type: replace 
Abstract: Unlearning in Federated Learning (FL) presents significant challenges, as models grow and evolve with complex inheritance relationships. This complexity is amplified when blockchain is employed to ensure the integrity and traceability of FL, where the need to edit multiple interlinked blockchain records and update all inherited models complicates the process.In this paper, we introduce Blockchained Federated Unlearning (BlockFUL), a novel framework with a dual-chain structure comprising a live chain and an archive chain for enabling unlearning capabilities within Blockchained FL. BlockFUL introduces two new unlearning paradigms, i.e., parallel and sequential paradigms, which can be effectively implemented through gradient-ascent-based and re-training-based unlearning methods. These methods enhance the unlearning process across multiple inherited models by enabling efficient consensus operations and reducing computational costs. Our extensive experiments validate that these methods effectively reduce data dependency and operational overhead, thereby boosting the overall performance of unlearning inherited models within BlockFUL on CIFAR-10 and Fashion-MNIST datasets using AlexNet, ResNet18, and MobileNetV2 models.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Stackelberg Strategies in State-based Potential Games for Autonomous Decentralized Learning Manufacturing Systems</title>
<link>https://arxiv.org/abs/2408.06397</link>
<guid>https://arxiv.org/abs/2408.06397</guid>
<content:encoded><![CDATA[
<div> 关键词：新型游戏结构、自主优化、分散制造系统、多目标优化、分布式Stackelberg策略

<br /><br />
总结:

文章介绍了一种名为“基于状态的潜力游戏中的分布式Stackelberg策略（DS2-SbPG）”的新颖游戏结构，旨在自主优化具有多目标优化挑战的分散制造系统。DS2-SbPG将潜力游戏与Stackelberg游戏相结合，提高了潜力游戏的协同折衷能力以及Stackelberg游戏在多目标优化方面的处理能力。特别地，所有训练过程均以完全分布式方式进行。

DS2-SbPG提供了一种找到多目标之间最优折衷的有前景解决方案，解决了自学习领域中个体玩家设置联合目标优化函数的复杂性问题，尤其是在具有多样性和众多子系统之间目标的现实工业环境中。文章进一步证明，DS2-SbPG构成动态潜力游戏，具有相应的收敛保证。

通过在实验室规模的测试床上进行的实验验证，显示了DS2-SbPG及其两个变体——单领导-跟随者DS2-SbPG和多领导-跟随者Stack DS2-SbPG的有效性。结果表明，这些策略在显著降低功耗和提高整体性能方面表现出色，预示着DS2-SbPG在实际应用中的巨大潜力。 <div>
arXiv:2408.06397v1 Announce Type: new 
Abstract: This article describes a novel game structure for autonomously optimizing decentralized manufacturing systems with multi-objective optimization challenges, namely Distributed Stackelberg Strategies in State-Based Potential Games (DS2-SbPG). DS2-SbPG integrates potential games and Stackelberg games, which improves the cooperative trade-off capabilities of potential games and the multi-objective optimization handling by Stackelberg games. Notably, all training procedures remain conducted in a fully distributed manner. DS2-SbPG offers a promising solution to finding optimal trade-offs between objectives by eliminating the complexities of setting up combined objective optimization functions for individual players in self-learning domains, particularly in real-world industrial settings with diverse and numerous objectives between the sub-systems. We further prove that DS2-SbPG constitutes a dynamic potential game that results in corresponding converge guarantees. Experimental validation conducted on a laboratory-scale testbed highlights the efficacy of DS2-SbPG and its two variants, such as DS2-SbPG for single-leader-follower and Stack DS2-SbPG for multi-leader-follower. The results show significant reductions in power consumption and improvements in overall performance, which signals the potential of DS2-SbPG in real-world applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BFTBrain: Adaptive BFT Consensus with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2408.06432</link>
<guid>https://arxiv.org/abs/2408.06432</guid>
<content:encoded><![CDATA[
<div> 关键词：BFTBrain、强化学习（RL）、拜占庭容错（BFT）、动态适应、性能优化

总结:
本文介绍了一种名为BFTBrain的新颖系统，它将强化学习（RL）与拜占庭容错（BFT）相结合，旨在为广泛硬件和网络配置提供插件式解决方案。BFTBrain的关键特性包括实时适应能力，能够根据系统条件和应用需求调整工作负载和故障场景。其通过实时切换不同的BFT协议来实现这一目标。

系统的核心创新包括：
1. **全面性能模型**：BFTBrain建立了一个综合模型，该模型基于不同BFT协议在各种故障情况和工作负载下的性能指标。这些指标作为输入，帮助RL引擎做出最佳决策。
2. **去中心化强化学习**：通过节点间共享局部度量值并达成共识，BFTBrain实现了鲁棒的数据污染抵抗机制，确保了学习过程的稳定性和准确性。
3. **动态性能提升**：在动态条件下，BFTBrain能够显著提高吞吐量，相比于固定协议，提升幅度可达18%至119%。同时，它在与最先进的学习基方法对比中表现出44%至154%的性能优势。

综上所述，BFTBrain不仅提供了操作上的便利性，还通过实时调整策略和优化学习过程，实现了对传统BFT系统的超越，显著提升了系统性能和适应性。 <div>
arXiv:2408.06432v1 Announce Type: new 
Abstract: This paper presents BFTBrain, a reinforcement learning (RL) based Byzantine fault-tolerant (BFT) system that provides significant operational benefits: a plug-and-play system suitable for a broad set of hardware and network configurations, and adjusts effectively in real-time to changing fault scenarios and workloads. BFTBrain adapts to system conditions and application needs by switching between a set of BFT protocols in real-time. Two main advances contribute to BFTBrain's agility and performance. First, BFTBrain is based on a systematic, thorough modeling of metrics that correlate the performance of the studied BFT protocols with varying fault scenarios and workloads. These metrics are fed as features to BFTBrain's RL engine in order to choose the best-performing BFT protocols in real-time. Second, BFTBrain coordinates RL in a decentralized manner which is resilient to adversarial data pollution, where nodes share local metering values and reach the same learning output by consensus. As a result, in addition to providing significant operational benefits, BFTBrain improves throughput over fixed protocols by $18\%$ to $119\%$ under dynamic conditions and outperforms state-of-the-art learning based approaches by $44\%$ to $154\%$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Theorem-Carrying-Transaction: Runtime Certification to Ensure Safety for Smart Contract Transactions</title>
<link>https://arxiv.org/abs/2408.06478</link>
<guid>https://arxiv.org/abs/2408.06478</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、安全漏洞、陷阱门、定理携带交易（TCT）、静态代码验证

总结:

本文聚焦于解决智能合约领域中长期存在的安全问题，特别是针对以太坊社区的智能合约。研究发现，这些合约构成了一个庞大的程序，其行为由复杂的引用拓扑结构决定，这使得确保该程序符合设计级别的安全属性变得极为挑战。由于静态代码验证在面对如此大规模且高度多态的程序时显得力不从心，作者提出了一种名为“定理携带交易”（TCT）的技术路线图。

TCT结合了实际执行和符号证明的优点。在TCT协议下，每个交易都携带一个证明其遵循调用合约中指定属性的定理。运行时系统会在执行交易前检查此定理。一旦在合同中指定某个属性，它便被视为合同提供的无条件保证。通过这一方法，无需预见到代码层面的复杂性如整数溢出或重入等问题，就能确保令牌合约的安全性。此外，TCT成功应用于Uniswap代码库，展示了在复杂去中心化金融（DeFi）场景中的应用案例。

文章最后指出，尽管引入了TCT，但实际运行时的开销仅微乎其微，远低于当前最先进的方法，从而为智能合约领域的安全提供了显著的提升。 <div>
arXiv:2408.06478v1 Announce Type: new 
Abstract: Security bugs and trapdoors in smart contracts have been impacting the Ethereum community since its inception. Conceptually, the 1.45-million Ethereum's contracts form a single "gigantic program" whose behaviors are determined by the complex reference-topology between the contracts. Can the Ethereum community be assured that this gigantic program conforms to its design-level safety properties, despite unforeseeable code-level intricacies? Static code verification is inadequate due to the program's gigantic scale and high polymorphism. In this paper, we present a viable technological roadmap for the community toward this ambitious goal. Our technology, called Theorem-Carrying-Transaction (TCT), combines the benefits of concrete execution and symbolic proofs. Under the TCT protocol, every transaction carries a theorem that proves its adherence to the specified properties in the invoked contracts, and the runtime system checks the theorem before executing the transaction. Once a property is specified in a contract, it can be treated confidently as an unconditional guarantee made by the contract. As case studies, we demonstrate that TCT secures token contracts without foreseeing code-level intricacies like integer overflow and reentrancy. TCT is also successfully applied to a Uniswap codebase, showcasing a complex decentralized finance (DeFi) scenario. Our prototype incurs a negligible runtime overhead, two orders of magnitude lower than a state-of-the-art approach.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Cooperation in Heterogeneous Multi-Agent Reinforcement Learning via Graph Neural Network-Based Intrinsic Motivation</title>
<link>https://arxiv.org/abs/2408.06503</link>
<guid>https://arxiv.org/abs/2408.06503</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-agent Reinforcement Learning（MARL）、CoHet算法、Graph Neural Network（GNN）、intrinsic motivation、decentralized training

<br />
总结:

本文聚焦于多智能体强化学习（MARL）领域，针对多智能体系统中合作的重要性及其实现挑战。在现实世界应用中，多智能体系统的部署往往需要分散训练、多样化的智能体以及从稀疏环境奖励信号中学习的能力。特别是在部分可观测性和缺乏对智能体异质性先验知识的情况下，这些挑战更加突出。已有研究通过内在动机（IM）来解决分散设置中的奖励稀疏性或合作问题，但处理异质性时通常假设集中式训练、参数共享和智能体索引。

为了克服上述局限，本文提出了一种名为CoHet的算法。该算法利用基于图神经网络（GNN）的内在动机机制，旨在分散环境中学习异质智能体策略。CoHet在多智能体粒子环境（MPE）和向量化多智能体模拟器（VMAS）基准测试中，展示了在一系列合作多智能体场景中的优越性能，与现有最佳实践相比。

研究还深入分析了智能体动力学模型对内在动机模块的影响、不同CoHet变体的表现及其对增加的异质智能体数量的鲁棒性。这为理解如何有效设计和优化多智能体系统提供了宝贵的见解，特别是当面临异质性和部分可观测性等复杂挑战时。 <div>
arXiv:2408.06503v1 Announce Type: new 
Abstract: Multi-agent Reinforcement Learning (MARL) is emerging as a key framework for various sequential decision-making and control tasks. Unlike their single-agent counterparts, multi-agent systems necessitate successful cooperation among the agents. The deployment of these systems in real-world scenarios often requires decentralized training, a diverse set of agents, and learning from infrequent environmental reward signals. These challenges become more pronounced under partial observability and the lack of prior knowledge about agent heterogeneity. While notable studies use intrinsic motivation (IM) to address reward sparsity or cooperation in decentralized settings, those dealing with heterogeneity typically assume centralized training, parameter sharing, and agent indexing. To overcome these limitations, we propose the CoHet algorithm, which utilizes a novel Graph Neural Network (GNN) based intrinsic motivation to facilitate the learning of heterogeneous agent policies in decentralized settings, under the challenges of partial observability and reward sparsity. Evaluation of CoHet in the Multi-agent Particle Environment (MPE) and Vectorized Multi-Agent Simulator (VMAS) benchmarks demonstrates superior performance compared to the state-of-the-art in a range of cooperative multi-agent scenarios. Our research is supplemented by an analysis of the impact of the agent dynamics model on the intrinsic motivation module, insights into the performance of different CoHet variants, and its robustness to an increasing number of heterogeneous agents.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Centralization vs. decentralization in multi-robot coverage: Ground robots under UAV supervision</title>
<link>https://arxiv.org/abs/2408.06553</link>
<guid>https://arxiv.org/abs/2408.06553</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人覆盖、分散控制、集中控制、协同机器人、物理仿真

总结:
本文通过物理仿真的多机器人环境ARGoS，研究了分散控制与集中控制在多机器人覆盖任务中的权衡。研究发现，分散控制提供了更好的可扩展性，但与预期相反，在随机障碍物环境中，分散控制的表现并不优于集中控制。通过将无人机作为监督者加入地面机器人的队伍，并逐步增加监督者使用集中控制的程度（包括全球信息访问和中央协调实体），研究比较了四种控制方法：分散控制、混合控制、集中控制和预设控制。

在评估地面机器人执行覆盖任务的速度和效率优势（如覆盖率完整性和均匀性）以及分散控制的可扩展性和容错性优势的同时，也考虑了集中控制由于地面机器人和无人机不同能效消耗率带来的能源消耗劣势。这项研究强调了在特定应用中选择集中控制、分散控制或两者的组合时需要根据任务目标和约束条件进行权衡的重要性。 <div>
arXiv:2408.06553v1 Announce Type: new 
Abstract: In swarm robotics, decentralized control is often proposed as a more scalable and fault-tolerant alternative to centralized control. However, centralized behaviors are often faster and more efficient than their decentralized counterparts. In any given application, the goals and constraints of the task being solved should guide the choice to use centralized control, decentralized control, or a combination of the two. Currently, the tradeoffs that exist between centralization and decentralization have not been thoroughly studied. In this paper, we investigate these tradeoffs for multi-robot coverage, and find that they are more nuanced than expected. For instance, our findings reinforce the expectation that more decentralized control will provide better scalability, but contradict the expectation that more decentralized control will perform better in environments with randomized obstacles. Beginning with a group of fully independent ground robots executing coverage, we add unmanned aerial vehicles as supervisors and progressively increase the degree to which the supervisors use centralized control, in terms of access to global information and a central coordinating entity. We compare, using the multi-robot physics-based simulation environment ARGoS, the following four control approaches: decentralized control, hybrid control, centralized control, and predetermined control. In comparing the ground robots performing the coverage task, we assess the speed and efficiency advantages of centralization -- in terms of coverage completeness and coverage uniformity -- and we assess the scalability and fault tolerance advantages of decentralization. We also assess the energy expenditure disadvantages of centralization due to different energy consumption rates of ground robots and unmanned aerial vehicles, according to the specifications of robots available off-the-shelf.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation</title>
<link>https://arxiv.org/abs/2408.06885</link>
<guid>https://arxiv.org/abs/2408.06885</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化、联邦学习、可信执行环境（TEE）、并行执行策略

总结:
本文提出了一种名为Voltran的创新混合平台，旨在通过结合区块链技术和可信执行环境（TEE）来实现联邦学习（FL）中的信任、保密性和健壮性。Voltran通过将FL聚合计算卸载到TEE中，提供了一个隔离、受保护和可定制的离链执行环境，确保了聚合结果在区块链上的真实性与验证性。此外，通过引入多-SGX并行执行策略，Voltran实现了对大规模FL场景的强大扩展能力，有效减少了大规模联邦学习工作负载的压力。

实验结果显示，Voltran不仅在保证信任、保密性和真实性的前提下，增加了极小的额外开销，而且相比现有的基于密文的聚合方案，显著提高了执行速度。这一成果为构建更安全、高效、可扩展的联邦学习系统提供了有力的技术支撑。 <div>
arXiv:2408.06885v1 Announce Type: new 
Abstract: The decentralized Federated Learning (FL) paradigm built upon blockchain architectures leverages distributed node clusters to replace the single server for executing FL model aggregation. This paradigm tackles the vulnerability of the centralized malicious server in vanilla FL and inherits the trustfulness and robustness offered by blockchain. However, existing blockchain-enabled schemes face challenges related to inadequate confidentiality on models and limited computational resources of blockchains to perform large-scale FL computations. In this paper, we present Voltran, an innovative hybrid platform designed to achieve trust, confidentiality, and robustness for FL based on the combination of the Trusted Execution Environment (TEE) and blockchain technology. We offload the FL aggregation computation into TEE to provide an isolated, trusted and customizable off-chain execution, and then guarantee the authenticity and verifiability of aggregation results on the blockchain. Moreover, we provide strong scalability on multiple FL scenarios by introducing a multi-SGX parallel execution strategy to amortize the large-scale FL workload. We implement a prototype of Voltran and conduct a comprehensive performance evaluation. Extensive experimental results demonstrate that Voltran incurs minimal additional overhead while guaranteeing trust, confidentiality, and authenticity, and it significantly brings a significant speed-up compared to state-of-the-art ciphertext aggregation schemes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-Agent Continuous Control with Generative Flow Networks</title>
<link>https://arxiv.org/abs/2408.06920</link>
<guid>https://arxiv.org/abs/2408.06920</guid>
<content:encoded><![CDATA[
<div> 关键词：Generative Flow Networks、Multi-Agent、Continuous Flow Networks、Decentralized、Centralized Training

<br /><br />
总结:
本文提出了一种名为Multi-Agent generative Continuous Flow Networks（MACFN）的方法，旨在解决多智能体系统中的合作探索问题。该方法允许多个智能体共同探索多种复合连续对象，特别适用于需要多智能体协作的环境。MACFN的关键创新在于其采用分布式个体流策略进行训练，同时在全局上下文中匹配这些策略以确保整体目标的一致性。具体而言，通过引入连续流分解网络，MACFN能够仅基于全局奖励推断每个智能体在整体目标中的贡献。这种方法使得智能体能够在局部策略下独立行动，形成与奖励成比例的联合策略分布。为了确保连续流分解的表达能力，作者还提出了分解网络的一致性条件。

实验结果表明，与现有最先进的方法相比，MACFN在性能和探索能力方面均表现出显著优势。这一研究成果为多智能体系统的合作探索提供了一种新的、高效的方法，有望在诸如机器人协同作业、多无人机任务分配等领域得到应用。 <div>
arXiv:2408.06920v1 Announce Type: new 
Abstract: Generative Flow Networks (GFlowNets) aim to generate diverse trajectories from a distribution in which the final states of the trajectories are proportional to the reward, serving as a powerful alternative to reinforcement learning for exploratory control tasks. However, the individual-flow matching constraint in GFlowNets limits their applications for multi-agent systems, especially continuous joint-control problems. In this paper, we propose a novel Multi-Agent generative Continuous Flow Networks (MACFN) method to enable multiple agents to perform cooperative exploration for various compositional continuous objects. Technically, MACFN trains decentralized individual-flow-based policies in a centralized global-flow-based matching fashion. During centralized training, MACFN introduces a continuous flow decomposition network to deduce the flow contributions of each agent in the presence of only global rewards. Then agents can deliver actions solely based on their assigned local flow in a decentralized way, forming a joint policy distribution proportional to the rewards. To guarantee the expressiveness of continuous flow decomposition, we theoretically derive a consistency condition on the decomposition network. Experimental results demonstrate that the proposed method yields results superior to the state-of-the-art counterparts and better exploration capability. Our code is available at https://github.com/isluoshuang/MACFN.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Network-Constrained Demand Response Game for Procuring Energy Balancing Services</title>
<link>https://arxiv.org/abs/2306.17475</link>
<guid>https://arxiv.org/abs/2306.17475</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式网络、需求响应游戏、隐私保护、市场机制、物理约束

<br /><br />
总结:
本文提出了一种网络约束下的需求响应游戏模型——广义纳什博弈（GNG），旨在激励电力用户提供平衡服务。该模型采用基于供给函数的竞价方法，确保负荷调整满足特定要求。为了保证配电网络的安全运行，将线路容量和节点电压限制等物理约束融入到博弈框架中。通过分析，评估了此游戏的效率损失。以往引导用户达到博弈的广义纳什均衡（GNE）的方法往往需要共享部分敏感信息，这在实践中可能不可行或不被接受。为此，本文提出了一种去中心化的市场清算法，该算法仅需参与者与他人分享有限且非敏感的信息，就可实现收敛。数值分析显示，所提机制的市场效率损失较低，强调了物理约束集成的重要性。最后，通过IEEE 33-节点和69-节点测试系统进行的仿真验证了所提算法的可扩展性。 <div>
arXiv:2306.17475v2 Announce Type: replace 
Abstract: Securely and efficiently procuring energy balancing services in distribution networks remains challenging, especially within a privacy-preserving environment. This paper proposes a network-constrained demand response game, i.e., a Generalized Nash Game (GNG), to incentivize energy consumers to offer balancing services. Specifically, we adopt a supply function-based bidding method for our demand response problem, where a requisite load adjustment must be met. To ensure the secure operation of distribution networks, we incorporate physical network constraints, including line capacity and bus voltage limits, into the game formulation. In addition, we analytically evaluate the efficiency loss of this game. Previous approaches to steer energy consumers toward the Generalized Nash Equilibrium (GNE) of the game often necessitated sharing some private information, which might not be practically feasible or desired. To overcome this limitation, we propose a decentralized market clearing algorithm with analytical convergence guarantees, which only requires the participants to share limited, non-sensitive information with others. Numerical analyses illustrate that the proposed market mechanism exhibits a low market efficiency loss. Moreover, these analyses highlight the critical role of integrating physical network constraints. Finally, we demonstrate the scalability of our proposed algorithm by conducting simulations on the IEEE 33-bus and 69-bus test systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Building a Verifiable Logical Clock for P2P Networks</title>
<link>https://arxiv.org/abs/2405.13349</link>
<guid>https://arxiv.org/abs/2405.13349</guid>
<content:encoded><![CDATA[
<div> 关键词：逻辑时钟、拜占庭容错、分布式系统、去中心化应用、性能优化

总结:

本文介绍了一种名为Chrono的新颖逻辑时钟系统，该系统旨在解决开放网络中存在拜占庭故障参与者的问题。Chrono重新定义了分布式进程在拜占庭故障模型下的因果关系属性，并为此引入了一种新的验证器抽象来构建容错逻辑时钟。这种验证器抽象具有可定制性，Chrono包含了多个后端实现，每种实现都提供了不同的安全性和性能权衡。

Chrono被应用于构建两个去中心化的应用程序：互斥服务和弱一致性键值存储。与仅容忍无拜占庭故障的系统相比，Chrono只增加了轻微的开销。此外，它在性能上显著优于当前最先进的拜占庭容错总订单协议。

Chrono的出现为开放网络中的分布式系统提供了一种有效的解决方案，通过引入新的验证器抽象和后端实现，不仅保证了系统的安全性，还优化了性能，使其在去中心化应用领域展现出巨大的潜力。 <div>
arXiv:2405.13349v2 Announce Type: replace 
Abstract: Logical clocks are a fundamental tool to establish causal ordering of events in a distributed system. They have been applied in weakly consistent storage systems, causally ordered broadcast, distributed snapshots, deadlock detection, and distributed system debugging. However, prior logical clock constructs fail to work in an open network with Byzantine participants. In this work, we present Chrono, a novel logical clock system that targets such challenging environment. We first redefine causality properties among distributed processes under the Byzantine failure model. To enforce these properties, Chrono defines a new validator abstraction for building fault-tolerant logical clocks. Furthermore, our validator abstraction is customizable: Chrono includes multiple backend implementations for the abstraction, each with different security-performance trade-offs. We have applied Chrono to build two decentralized applications, a mutual exclusive service and a weakly consistent key-value store. Chrono adds only marginal overhead compared to systems that tolerate no Byzantine faults. It also out-performs state-of-the-art BFT total order protocols by significant margins.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Bluesky: Network Topology, Polarization, and Algorithmic Curation</title>
<link>https://arxiv.org/abs/2405.17571</link>
<guid>https://arxiv.org/abs/2405.17571</guid>
<content:encoded><![CDATA[
<div> 关键词：Bluesky、社交网络、政治倾向、网络结构、算法推荐

<br /><br />
总结:
文章通过研究从2023年2月到2024年5月的五百万用户数据，对Bluesky这个新兴的去中心化社交媒体平台进行了深入分析。Bluesky在设计上具有独特性，并提供了前所未有的数据访问能力。研究发现，其互动网络展现出与大型社交网络相似的特征，如重尾分布、高聚类性和短路径连接。Bluesky引入了定制化的“feeds”功能，用于个性化内容推荐，但用户对此的采纳程度有限。在内容分享方面，Bluesky用户倾向于分享左中立场的新闻来源，避开了争议性或可疑新闻。然而，在涉及以色列-巴勒斯坦冲突的问题上，出现了明显的基于议题的分歧，支持巴勒斯坦的声音超过支持以色列的用户，并且比例有所增加。尽管Bluesky拥有创新特性，但其网络结构与现有的大型社交平台并无本质差异，为社会科学家、网络科学家和政治科学家提供了宝贵的研究机会。 <div>
arXiv:2405.17571v2 Announce Type: replace 
Abstract: Bluesky is a nascent Twitter-like and decentralized social media network with novel features and unprecedented data access. This paper provides a characterization of its interaction network, studying the political leaning, polarization, network structure, and algorithmic curation mechanisms of five million users. The dataset spans from the website's first release in February of 2023 to May of 2024. We investigate the replies, likes, reposts, and follows layers of the Bluesky network. We find that all networks are characterized by heavy-tailed distributions, high clustering, and short connection paths, similar to other larger social networks. Bluesky introduced feeds - algorithmic content recommenders created for and by users. We analyze all feeds and find that while a large number of custom feeds have been created, users' uptake of them appears to be limited. We analyze the hyperlinks shared by Bluesky's users and find no evidence of polarization in terms of the political leaning of the news sources they share. They share predominantly left-center news sources and little to no links associated with questionable news sources. In contrast to the homogeneous political ideology, we find significant issues-based divergence by studying opinions related to the Israel-Palestine conflict. Two clear homophilic clusters emerge: Pro-Palestinian voices outnumber pro-Israeli users, and the proportion has increased. We conclude by claiming that Bluesky-for all its novel features - is very similar in its network structure to existing and larger social media sites and provides unprecedented research opportunities for social scientists, network scientists, and political scientists alike.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AirChain: A Novel Blockchain Framework and Low-Cost Device for Democratized Air Quality Data Aggregation</title>
<link>https://arxiv.org/abs/2408.05216</link>
<guid>https://arxiv.org/abs/2408.05216</guid>
<content:encoded><![CDATA[
<div> 关键词：空气污染、PM1.0、PM2.5、PM10.0、区块链技术

总结:

本文提出并实施了一种新型分布式低成本模型，旨在解决地面空气中导致超过670万人死亡的主要污染物浓度报告不准确的问题。主要关注的是PM1.0、PM2.5和PM10.0这三种颗粒物。该模型引入了AirChain概念，它利用区块链技术，结合简单的微控制器设备，来创建一种低维护成本的空气质量监测系统。

首先，现有的空气质量监测系统通常需要依赖于中央集权管理和分布模式，这要求用户对中央管理机构有高度的信任。而AirChain通过去中心化的区块链结构，减少了对中央权威的依赖，提高了系统的透明度和可靠性。

其次，传统监测设备成本较高，不适合普通消费者使用。AirChain采用低成本传感器与微控制器的组合，使得监测设备更加经济实惠，易于普及。

最后，现有系统在数据准确性上存在较大问题，导致其功能性较差。AirChain通过区块链技术确保数据的不可篡改性和高可信度，显著提高了数据的准确性与可靠性。

综上所述，AirChain项目旨在通过创新的技术手段，解决当前空气质量监测系统面临的信任、成本和准确性三大挑战，为公众提供更准确、更便捷、更低成本的空气质量监测服务。 <div>
arXiv:2408.05216v1 Announce Type: new 
Abstract: Air pollutant exposure kills over 6,700,000 people it per annum, yet there remains a systemic lack of accurate ground level data reporting the concentrations of the leading causes of such fatalities. Ambient particulate matter is a primary driver of this effect. Namely, PM1.0, PM2.5, and PM10.0 display a systemic lack of accurate and high-definition reporting. This project suggests and implements a prototype for a distributed and low cost model for reporting such data and designs a novel framework in order to remedy three main shortfalls of previously implemented systems. First, their central operation and distribution, and therefore their requirement of trust in a central governing body. Second, their requirement of the purchase of comparatively high-cost devices for ordinary consumers. Finally, their high degree of error and accordingly low functional certainty. This project explores the creation of AirChain, a prototype system utilizing blockchain technology that will demonstrate the effectiveness of low-cost sensors when paired with simple microcontroller devices.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FLASH: Federated Learning-Based LLMs for Advanced Query Processing in Social Networks through RAG</title>
<link>https://arxiv.org/abs/2408.05242</link>
<guid>https://arxiv.org/abs/2408.05242</guid>
<content:encoded><![CDATA[
<div> 关键词：社交网络、信息检索、用户参与、个性化聊天机器人、联邦学习GPT

总结:
本文提出了一种基于联邦学习GPT的新型个性化聊天机器人系统，旨在通过集成和精炼来自不同社交媒体的数据源（如用户帖子、多媒体内容和热门新闻）来实现社交网络信息检索与用户参与。该系统利用联邦学习技术训练GPT模型，确保隐私和安全的同时提供个性化的洞察和建议。用户通过直观界面与聊天机器人互动，获取定制信息和实时更新的社交媒体趋势及用户生成的内容。系统的创新架构支持输入文件的有效处理、文本数据元数据的解析和丰富以及高级语言模型生成相关问题和答案。通过这一个性化聊天机器人系统，社交网络信息的访问变得更为互动和丰富，代表了社交媒体通信与知识传播领域的显著进步。 <div>
arXiv:2408.05242v1 Announce Type: new 
Abstract: Our paper introduces a novel approach to social network information retrieval and user engagement through a personalized chatbot system empowered by Federated Learning GPT. The system is designed to seamlessly aggregate and curate diverse social media data sources, including user posts, multimedia content, and trending news. Leveraging Federated Learning techniques, the GPT model is trained on decentralized data sources to ensure privacy and security while providing personalized insights and recommendations. Users interact with the chatbot through an intuitive interface, accessing tailored information and real-time updates on social media trends and user-generated content. The system's innovative architecture enables efficient processing of input files, parsing and enriching text data with metadata, and generating relevant questions and answers using advanced language models. By facilitating interactive access to a wealth of social network information, this personalized chatbot system represents a significant advancement in social media communication and knowledge dissemination.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Monero Traceability Heuristics: Wallet Application Bugs and the Mordinal-P2Pool Perspective</title>
<link>https://arxiv.org/abs/2408.05332</link>
<guid>https://arxiv.org/abs/2408.05332</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私加密资产、Monero、追踪策略、钱包应用漏洞、去中心化挖矿池

总结:

本文系统地描述了自2019年至2023年间针对隐私导向加密货币Monero出现的追踪策略。文章重点分析了两种钱包应用漏洞——“差一”和“10区块诱饵漏洞”，以及一个名为P2Pool的去中心化挖矿池的兴起，还有Mordinals——一种有争议的UTXO NFT尝试。通过与实际数据对比和相互比较，研究评估了这些追踪策略的质量。结果表明大多数策略具有高精度，其中“10区块诱饵漏洞”和Coinbase诱饵识别策略在这段时间内影响最大。该研究还展示了随着时间推移，这些策略的有效性如何变化，以及在去除诱饵后剩余的有效环大小。最后，研究指出，“10区块诱饵漏洞”可用于评估未来策略，前提是它们在2019年至2023年期间同样适用。

通过分析Monero社区中的这些发展，研究人员提供了对隐私加密货币追踪策略的深入理解，为加密货币领域的隐私保护和追踪策略的发展提供了有价值的见解。 <div>
arXiv:2408.05332v1 Announce Type: new 
Abstract: Privacy-focused cryptoassets like Monero are intentionally difficult to trace. Over the years, several traceability heuristics have been proposed, most of which have been rendered ineffective with subsequent protocol upgrades. Between 2019 and 2023, Monero wallet application bugs "Differ By One" and "10 Block Decoy Bug" have been observed and identified and discussed in the Monero community. In addition, a decentralized mining pool named P2Pool has proliferated, and a controversial UTXO NFT imitation known as Mordinals has been tried for Monero. In this paper, we systematically describe the traceability heuristics that have emerged from these developments, and evaluate their quality based on ground truth, and through pairwise comparisons. We also explore the temporal perspective, and show which of these heuristics have been applicable over the past years, what fraction of decoys could be eliminated and what the remaining effective ring size is. Our findings illustrate that most of the heuristics have a high precision, that the "10 Block Decoy Bug" and the Coinbase decoy identification heuristics have had the most impact between 2019 and 2023, and that the former could be used to evaluate future heuristics, if they are also applicable during that time frame.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Effects of Vote Delegation in Blockchains: Who Wins?</title>
<link>https://arxiv.org/abs/2408.05410</link>
<guid>https://arxiv.org/abs/2408.05410</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、投票委托、二元集体决策、投票权重分布、多数优势

<br /><br />
总结:

本文探讨了区块链中二元集体决策中投票委托的替代性好处。研究首先对比了两种极端的投票权重分布情况：等权重（EW），即每位投票者拥有相等的投票权重；与主导权重（DW），即在任何委托发生前，单一投票者持有投票权重的多数。研究揭示了在等权重情况下，投票委托倾向于使初始获胜概率较低的选项（即前验少数）受益。相反，在主导权重下，情况则相反。通过数值模拟，研究将发现扩展到任意的投票权重分布，表明在投票权重分布更加均衡时，投票委托使初始获胜概率较高的选项（即前验多数）受益。最后，在所有参与者都具有相同投票权重的大规模社区中，投票委托对结果的影响微乎其微。这些见解为区块链治理决策提供了实用指导。 <div>
arXiv:2408.05410v1 Announce Type: new 
Abstract: This paper investigates which alternative benefits from vote delegation in binary collective decisions within blockchains. We begin by examining two extreme cases of voting weight distributions: Equal-Weight (EW), where each voter has equal voting weight, and Dominant-Weight (DW), where a single voter holds a majority of the voting weights before any delegation occurs. We show that vote delegation tends to benefit the ex-ante minority under EW, i.e., the alternative with a lower initial probability of winning. The converse holds under DW distribution. Through numerical simulations, we extend our findings to arbitrary voting weight distributions, showing that vote delegation benefits the ex-ante majority when it leads to a more balanced distribution of voting weights. Finally, in large communities where all agents have equal voting weight, vote delegation has a negligible impact on the outcome. These insights provide practical guidance for governance decisions in blockchains.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Convergence of Symbiotic Communications and Blockchain for Sustainable and Trustworthy 6G Wireless Networks</title>
<link>https://arxiv.org/abs/2408.05776</link>
<guid>https://arxiv.org/abs/2408.05776</guid>
<content:encoded><![CDATA[
<div> 关键词：Symbiotic Communication、Blockchain、6G、Energy Efficiency、Symbiotic Blockchain Network

<br /><br />
总结:

本文探讨了一种新型无线通信范式——共生通信（SC），它类似于自然生态系统中的物种相互依存关系，旨在使多个通信系统通过服务交换和资源共享实现合作与互惠。SC被视为解决第六代（6G）通信中频谱资源稀缺和能效低问题的重要潜在技术。然而，不同通信系统之间缺乏建立信任关系构成了确保SC框架内资源和服务交换高效可信的主要障碍。

针对这一挑战，作者提出了一种结合SC与区块链技术的解决方案——共生区块链网络（SBN）。首先，利用认知回波通信对区块链共识机制进行改造，形成共生区块链共识（SBC），使其更适应无线网络环境。接着，为SBC设计了一种高度节能的分片方案，以满足6G网络极低功耗的需求。最后，该区块链方案保证了SC中通信服务交易的可信性。

通过消融实验，所提出的SBN方案在对抗网络中显著降低了能量消耗和处理延迟，有望实现可持续和可信的6G无线网络。 <div>
arXiv:2408.05776v1 Announce Type: new 
Abstract: Symbiotic communication (SC) is known as a new wireless communication paradigm, similar to the natural ecosystem population, and can enable multiple communication systems to cooperate and mutualize through service exchange and resource sharing. As a result, SC is seen as an important potential technology for future sixth-generation (6G) communications, solving the problem of lack of spectrum resources and energy inefficiency. Symbiotic relationships among communication systems can complement radio resources in 6G. However, the absence of established trust relationships among diverse communication systems presents a formidable hurdle in ensuring efficient and trusted resource and service exchange within SC frameworks. To better realize trusted SC services in 6G, in this paper, we propose a solution that converges SC and blockchain, called a symbiotic blockchain network (SBN). Specifically, we first use cognitive backscatter communication to transform blockchain consensus, that is, the symbiotic blockchain consensus (SBC), so that it can be better suited for the wireless network. Then, for SBC, we propose a highly energy-efficient sharding scheme to meet the extremely low power consumption requirements in 6G. Finally, such a blockchain scheme guarantees trusted transactions of communication services in SC. Through ablation experiments, our proposed SBN demonstrates significant efficacy in mitigating energy consumption and reducing processing latency in adversarial networks, which is expected to achieve a sustainable and trusted 6G wireless network.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Hyperion: Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution</title>
<link>https://arxiv.org/abs/2408.06037</link>
<guid>https://arxiv.org/abs/2408.06037</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链平台、DApps、前端描述、后端智能合约、HYPERION

总结:

本文研究了区块链平台的快速发展对去中心化应用(DApps)的影响。主要关注的是DApps前端描述与后端智能合约之间的一致性问题。研究首先通过实证分析识别了七种类型的一致性差异，并以真实世界中的DApp为例进行了说明。然后，提出了一种名为HYPERION的方法，用于自动检测DApps中前端描述与后端代码实现之间的不一致。

HYPERION利用细调后的大型语言模型LLaMA2来分析DApp描述，并结合数据流导向的符号执行技术来解析合约字节码。该方法通过预定义的检测模式报告不一致性。在由54个DApps组成的基准数据集上的实验表明，HYPERION在报告DApp不一致性的总体召回率和精确度上分别达到了84.06%和92.06%。

为了验证其有效性，HYPERION还被应用于分析835个实际的DApps。结果发现，至少存在一种不一致性的DApps有459个。这一研究有助于提高用户对DApps的信任，并为开发者提供了一个有效的工具来确保前端描述与后端实现的一致性，从而提升DApps的质量和用户体验。 <div>
arXiv:2408.06037v1 Announce Type: new 
Abstract: The rapid advancement of blockchain platforms has significantly accelerated the growth of decentralized applications (DApps). Similar to traditional applications, DApps integrate front-end descriptions that showcase their features to attract users, and back-end smart contracts for executing their business logic. However, inconsistencies between the features promoted in front-end descriptions and those actually implemented in the contract can confuse users and undermine DApps's trustworthiness. In this paper, we first conducted an empirical study to identify seven types of inconsistencies, each exemplified by a real-world DApp. Furthermore, we introduce HYPERION, an approach designed to automatically identify inconsistencies between front-end descriptions and back-end code implementation in DApps. This method leverages a fine-tuned large language model LLaMA2 to analyze DApp descriptions and employs dataflow-guided symbolic execution for contract bytecode analysis. Finally, HYPERION reports the inconsistency based on predefined detection patterns. The experiment on our ground truth dataset consisting of 54 DApps shows that HYPERION reaches 84.06% overall recall and 92.06% overall precision in reporting DApp inconsistencies. We also implement HYPERION to analyze 835 real-world DApps. The experimental results show that HYPERION discovers 459 real-world DApps containing at least one inconsistency.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Practical System Architecture for Contract Automation: Design and Uses</title>
<link>https://arxiv.org/abs/2408.06084</link>
<guid>https://arxiv.org/abs/2408.06084</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、里卡迪安合同、合同网络架构、数字合同

总结:

本文主要探讨了在解决区块链和智能合约现有法律和技术难题的基础上，如何通过融合关键区块链技术与传统里卡迪安合同（Ricardoian Contract）概念，构建一种全新的数字化合同体系。这种体系旨在提供一个全面的、自动化的平台，支持合同从提出、谈判、执行、重新协商到终止的全过程。

首先，通过将里卡迪安合同融入到我们的合同网络架构中，文章提出了一个基础设施框架，使得合同能够以完全数字化和自动化的形式进行交易。该架构解决了区块链技术在应用层面的复杂性问题，同时也缓解了其作为计算机程序而非法律文件的局限性。

其次，文章详细介绍了该合同网络架构的四个应用场景：

1. 私人数据购买：通过智能合约确保数据交易的透明性和安全性，同时保护双方的隐私权益。
2. 财库管理：实现自动化资金流动管理，提高效率并减少人为错误。
3. 订单驱动制造：利用智能合约实现供应链的自动化，提高生产效率和响应速度。
4. 自动设备上线：简化设备接入流程，降低运营成本并提高设备管理的灵活性。

最后，通过这些应用场景的展示，文章强调了该合同网络架构在实际商业环境中应用的潜力，以及它如何克服传统合同和区块链技术的局限，提供了一种创新的解决方案。 <div>
arXiv:2408.06084v1 Announce Type: new 
Abstract: While the blockchain-based smart contract has become a hot topic of research over the last decade, not the least in the context of Industry 4.0, it now has well-known legal and technical shortcomings that currently prohibit its real-world application. These shortcomings come from (1) that a smart contract is a computer program, not a document describing legal obligations, and (2) that blockchain-based systems are complicated to use and operate. In this paper, we present a refined and extended summary of our work taking key technologies from the blockchain sphere and applying them to the ricardian contract, which is a traditional contract in digital form with machine-readable parameters. By putting the ricardian contract in the context of our contract network architecture, we facilitate the infrastructure required for contracts to be offered, negotiated, performed, renegotiated and terminated in a completely digital and automatable fashion. Our architecture circumvents the legal issues of blockchains by facilitating an artifact very much alike a traditional contract, as well as its operational complexity by requiring consensus only between nodes representing directly involved parties. To demonstrate its utility, we also present how it could be used for (1) private data purchasing, (2) treasury management, (3) order-driven manufacturing and (4) automated device on-boarding.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Intelligence Health Network (DIHN)</title>
<link>https://arxiv.org/abs/2408.06240</link>
<guid>https://arxiv.org/abs/2408.06240</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Intelligence Health Network（DIHN）、自主权、联邦学习（FL）、区块链、激励机制

总结:

《Decentralized Intelligence Health Network: 自主健康智能网络》一文提出了一种全新的理论框架——Decentralized Intelligence Health Network (DIHN)，旨在解决医疗数据主权和人工智能在医疗领域利用过程中因数据碎片化而产生的挑战。该框架首先构建了一个基于自主权的健康服务体系基础架构，以确保健康数据的主权性。其次，通过在公共区块链上实现可扩展的联邦学习协议，它克服了访问多样化的医疗数据来源的障碍，实现了分散的人工智能训练，同时确保了参与者的数据安全和隐私。

此外，DIHN还引入了一种可扩展、无信任的奖励机制，激励参与者的积极性，并确保奖励的公平分配。这一机制使得任何实体都无法阻止或控制对参与者提供的健康数据进行的训练过程，也无法决定由此产生的财务收益，因为这些操作都在不可篡改的公共区块链上进行。

患者通过参与联邦学习协议获得奖励，这不仅激励了他们的参与，还为他们提供了经济上的收益。长期规划还包括利用这种分散的生态系统为患者提供分散式保险解决方案的可能性。DIHN的实施将为医疗数据管理和人工智能应用带来变革，同时赋予患者控制权，从而实现更个性化、互补现有系统并重新定义全民覆盖的新型医疗保健模式。 <div>
arXiv:2408.06240v1 Announce Type: new 
Abstract: Decentralized Intelligence Health Network (DIHN) is a theoretical framework addressing significant challenges of health data sovereignty and AI utilization in healthcare caused by data fragmentation across providers and institutions. It establishes a sovereign architecture for healthcare provision as a prerequisite to a sovereign health network, then facilitates effective AI utilization by overcoming barriers to accessing diverse medical data sources. This comprehensive framework leverages: 1) self-sovereign identity architecture coupled with a personal health record (PHR) as a prerequisite for health data sovereignty; 2) a scalable federated learning (FL) protocol implemented on a public blockchain for decentralized AI training in healthcare, where health data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on health data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training in healthcare, allowing patients to maintain control over their health data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial healthcare algorithms. Patients receive rewards into their digital wallets as an incentive to opt-in to the FL protocol, with a long-term roadmap to funding decentralized insurance solutions. This approach introduces a novel, self-financed healthcare model that adapts to individual needs, complements existing systems, and redefines universal coverage. It highlights the potential to transform healthcare data management and AI utilization while empowering patients.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Integration of blockchain in smart systems: problems and opportunities for real-time sensor data storage</title>
<link>https://arxiv.org/abs/2408.06331</link>
<guid>https://arxiv.org/abs/2408.06331</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、区块链、安全存储、实时传感器数据、生态系统应用

总结:

本文深入探讨了将区块链技术应用于实时传感器数据安全存储系统中所面临的关键问题。首先，文章指出区块链的固有特性，如去中心化和不可篡改性，为安全、开放和分散的数据存储提供了可能。然而，区块链在实际部署过程中遇到了一些挑战，包括可扩展性限制、交易延迟和存储需求增加等问题，这些问题在高频率、大量数据的实时传感器应用场景中尤为突出。

为了克服这些挑战，作者提出了一种新的实用实验设置和区块链在智能系统应用中的分析方法。该研究不仅详细阐述了区块链解决方案在智能系统生态中的优势，如数据安全性、审计能力以及透明度，同时也讨论了其潜在的缺点，比如较高的计算成本和能源消耗。

通过对比分析，本文旨在为区块链技术在物联网和其他新兴普遍技术领域的实际应用提供有价值的见解和指导。研究强调了在设计和实施基于区块链的数据存储解决方案时需要权衡的复杂性和多方面考虑因素，以确保其在智能系统生态系统中的有效性和可行性。 <div>
arXiv:2408.06331v1 Announce Type: new 
Abstract: The internet of things (IoT) and other emerging ubiquitous technologies are supporting the rapid spread of smart systems, which has underlined the need for safe, open, and decentralized data storage solutions. With its inherent decentralization and immutability, blockchain offers itself as a potential solution for these requirements. However, the practicality of incorporating blockchain into real-time sensor data storage systems is a topic that demands in-depth examination. While blockchain promises unmatched data security and auditability, some intrinsic qualities, namely scalability restrictions, transactional delays, and escalating storage demands, impede its seamless deployment in high-frequency, voluminous data contexts typical of real-time sensors. This essay launches a methodical investigation into these difficulties, illuminating their underlying causes, potential effects, and potential countermeasures. In addition, we present a novel pragmatic experimental setup and analysis of blockchain for smart system applications, with an extended discussion of the benefits and disadvantages of deploying blockchain based solutions for smart system ecosystems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain and Artificial Intelligence: Synergies and Conflicts</title>
<link>https://arxiv.org/abs/2405.13462</link>
<guid>https://arxiv.org/abs/2405.13462</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、人工智能、市场资本化、应用挑战、理论兼容性

总结:
本文探讨了区块链技术和人工智能在各自领域中的变革性力量，并分析了结合这两者的最大项目，根据其市场资本化进行了研究。通过市场资本化的视角，文章揭示了当前区块链与人工智能结合应用的现状，指出尽管理论上两者相辅相成，但在实际应用层面，此类融合仍处于起步阶段。文章进一步提出了一种新颖的框架，用于分类现有和未来的区块链与人工智能应用场景。这一框架有助于更清晰地理解不同领域的应用潜力和挑战，为未来的发展提供方向和指导。同时，文章也指出了在实现区块链与人工智能高效协同过程中所面临的实际问题和限制，强调了理论与实践之间的差距需要进一步探索和解决。 <div>
arXiv:2405.13462v1 Announce Type: cross 
Abstract: Blockchain technology and Artificial Intelligence (AI) have emerged as transformative forces in their respective domains. This paper explores synergies and challenges between these two technologies. Our research analyses the biggest projects combining blockchain and AI, based on market capitalization, and derives a novel framework to categorize contemporary and future use cases. Despite the theoretical compatibility, current real-world applications combining blockchain and AI remain in their infancy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Graph Agent Network: Empowering Nodes with Decentralized Communications Capabilities for Adversarial Resilience</title>
<link>https://arxiv.org/abs/2306.06909</link>
<guid>https://arxiv.org/abs/2306.06909</guid>
<content:encoded><![CDATA[
<div> 关键词：图神经网络、端到端训练、全局优化、图代理网络、防御策略

<br /><br />
总结:

本文针对图神经网络（GNN）在节点分类任务中普遍采用的端到端训练方法所引发的对攻击者利用其开放输入输出接口进行边缘扰动攻击的脆弱性问题。文中提出了一种名为“图代理网络”（GAgN）的解决方案。GAgN设计为具有1跳视角的图结构代理网络，通过代理之间的分散交互，它们能够学习获取全局感知以执行包括推断节点嵌入、度量和邻居关系的任务。这一机制使节点能够在执行分类任务的同时过滤掉攻击性的边。此外，代理的有限视野防止了恶意信息在全球范围内传播，从而抵御基于全局优化的次级攻击。文章证明单隐藏层多层感知器（MLP）理论上足以实现上述功能。实验结果表明，GAgN成功实现了其所有预期的功能，并与现有最先进的防御策略相比，在被扰动的数据集上达到了最优的分类准确率。 <div>
arXiv:2306.06909v2 Announce Type: replace 
Abstract: End-to-end training with global optimization have popularized graph neural networks (GNNs) for node classification, yet inadvertently introduced vulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit the inherent opened interfaces of GNNs' input and output, perturbing critical edges and thus manipulating the classification results. Current defenses, due to their persistent utilization of global-optimization-based end-to-end training schemes, inherently encapsulate the vulnerabilities of GNNs. This is specifically evidenced in their inability to defend against targeted secondary attacks. In this paper, we propose the Graph Agent Network (GAgN) to address the aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent network in which each node is designed as an 1-hop-view agent. Through the decentralized interactions between agents, they can learn to infer global perceptions to perform tasks including inferring embeddings, degrees and neighbor relationships for given nodes. This empowers nodes to filtering adversarial edges while carrying out classification tasks. Furthermore, agents' limited view prevents malicious messages from propagating globally in GAgN, thereby resisting global-optimization-based secondary attacks. We prove that single-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient to achieve these functionalities. Experimental results show that GAgN effectively implements all its intended capabilities and, compared to state-of-the-art defenses, achieves optimal classification accuracy on the perturbed datasets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Collaborative Learning Framework to Detect Attacks in Transactions and Smart Contracts</title>
<link>https://arxiv.org/abs/2308.15804</link>
<guid>https://arxiv.org/abs/2308.15804</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链系统、恶意活动、攻击检测、协作学习、机器代码

总结:
本文提出了一种新型的协作学习框架，旨在通过分析交易特征来检测区块链系统中的攻击行为。该框架能够识别包括非法注入恶意代码以窃取用户资金在内的各种区块链攻击类型，特别是那些需要大量时间和专业安全知识才能检测到的低级机器代码攻击。为了实现这一目标，框架引入了一个独特的工具，将交易特征转换为可视化表示，从而便于高效地分析和分类低级机器代码。

此外，文章还提出了一种高级的协作学习模型，能够在分布式挖矿节点上实现实时的多类型攻击检测。该模型无需收集所有数据到中心服务器，即可高效检测区块链系统的智能合约和交易中的攻击行为。为了评估框架性能，基于私有以太坊网络部署了一个试点系统，并进行了多个攻击场景的实验，生成了用于检测区块链系统中网络攻击的最全面、最多样化的数据集。

该框架在广泛的模拟实验中达到了约94%的检测准确率，并在实时实验中实现了超过每秒2150笔交易的处理速度，达到91%的准确率。这表明该框架不仅在理论上具有可行性，而且在实际应用中也表现出高效性和准确性。 <div>
arXiv:2308.15804v3 Announce Type: replace 
Abstract: With the escalating prevalence of malicious activities exploiting vulnerabilities in blockchain systems, there is an urgent requirement for robust attack detection mechanisms. To address this challenge, this paper presents a novel collaborative learning framework designed to detect attacks in blockchain transactions and smart contracts by analyzing transaction features. Our framework exhibits the capability to classify various types of blockchain attacks, including intricate attacks at the machine code level (e.g., injecting malicious codes to withdraw coins from users unlawfully), which typically necessitate significant time and security expertise to detect. To achieve that, the proposed framework incorporates a unique tool that transforms transaction features into visual representations, facilitating efficient analysis and classification of low-level machine codes. Furthermore, we propose an advanced collaborative learning model to enable real-time detection of diverse attack types at distributed mining nodes. Our model can efficiently detect attacks in smart contracts and transactions for blockchain systems without the need to gather all data from mining nodes into a centralized server. In order to evaluate the performance of our proposed framework, we deploy a pilot system based on a private Ethereum network and conduct multiple attack scenarios to generate a novel dataset. To the best of our knowledge, our dataset is the most comprehensive and diverse collection of transactions and smart contracts synthesized in a laboratory for cyberattack detection in blockchain systems. Our framework achieves a detection accuracy of approximately 94% through extensive simulations and 91% in real-time experiments with a throughput of over 2,150 transactions per second.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Sui Lutris: A Blockchain Combining Broadcast and Consensus</title>
<link>https://arxiv.org/abs/2310.18042</link>
<guid>https://arxiv.org/abs/2310.18042</guid>
<content:encoded><![CDATA[
<div> 关键词：Sui Lutris、智能合约平台、次秒级确认、无共识协议、持续运行

总结:

Sui Lutris 是一款智能合约平台，它实现了低于一秒的最终确认时间，这是行业内的首次。它通过在简单支付之外，将无共识协议应用于多种交易中，达到了这一目标。与以往的工作不同，Sui Lutris 在不牺牲表达力和吞吐量的前提下，实现了持续运行而无需重启。其创新之处在于安全地将无共识协议与一个高吞吐量的共识协议结合，后者虽不在关键的最终性路径上运行，但确保了当交易面临不一致的并发访问风险时，其结算会在解决总排序问题后延迟进行。

为了处理重构事件中的系统安全性和长期活动生成潜在错误配置客户端的问题，Sui Lutris 开发了一种新型重构协议，这是首个证明了无共识区块链安全高效重构的协议。此外，Sui Lutris 目前已经在生产环境中运行，支撑着 Sui 智能合约平台。通过使用对象而非账户，它使得智能合约能够安全地执行，将对象作为第一类资源暴露。实验结果显示，Sui Lutris 的延迟低于 0.5 秒，吞吐量可达每秒 5000 证书（以每秒 150,000 操作为基准）。同时，它能够优雅地处理验证器崩溃恢复，且在重构期间不会出现明显的性能下降。 <div>
arXiv:2310.18042v4 Announce Type: replace 
Abstract: Sui Lutris is the first smart-contract platform to sustainably achieve sub-second finality. It achieves this significant decrease by employing consensusless agreement not only for simple payments but for a large variety of transactions. Unlike prior work, Sui Lutris neither compromises expressiveness nor throughput and can run perpetually without restarts. Sui Lutris achieves this by safely integrating consensuless agreement with a high-throughput consensus protocol that is invoked out of the critical finality path but ensures that when a transaction is at risk of inconsistent concurrent accesses, its settlement is delayed until the total ordering is resolved. Building such a hybrid architecture is especially delicate during reconfiguration events, where the system needs to preserve the safety of the consensusless path without compromising the long-term liveness of potentially misconfigured clients. We thus develop a novel reconfiguration protocol, the first to provably show the safe and efficient reconfiguration of a consensusless blockchain. Sui Lutris is currently running in production and underpins the Sui smart-contract platform. Combined with the use of Objects instead of accounts it enables the safe execution of smart contracts that expose objects as a first-class resource. In our experiments Sui Lutris achieves latency lower than 0.5 seconds for throughput up to 5,000 certificates per second (150k ops/s with transaction blocks), compared to the state-of-the-art real-world consensus latencies of 3 seconds. Furthermore, it gracefully handles validators crash-recovery and does not suffer visible performance degradation during reconfiguration.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Survey on Quality Assurance of Smart Contracts</title>
<link>https://arxiv.org/abs/2311.00270</link>
<guid>https://arxiv.org/abs/2311.00270</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、安全漏洞、攻击防御、工具支持、质量保证

总结:

本文是一篇关于智能合约质量保证的综述性文章。文章首先强调了随着智能合约应用的日益普及，确保其安全性的重要性日益凸显。文章指出，已有多起智能合约因安全漏洞而遭受攻击和利用，导致了严重的经济损失。为应对这一挑战，研究者们开发了一系列工具和技术以识别并预防智能合约中的安全漏洞。

文章通过将已知攻击归类，系统地梳理了智能合约中常见的安全漏洞类型和弱点，以便更好地理解问题的本质并针对性地采取措施。同时，为了更有效地保护智能合约免受威胁，文章构建了一个标注数据集，用于评估各种漏洞检测工具的性能，并进行效果比较。

通过这种方式，文章不仅为智能合约安全的研究提供了全面的视角，也为开发者和研究人员提供了一套实用的分析框架和工具，有助于提升智能合约的整体安全水平。 <div>
arXiv:2311.00270v3 Announce Type: replace 
Abstract: With the increasing adoption of smart contracts, ensuring their security has become a critical concern. Numerous vulnerabilities and attacks have been identified and exploited, resulting in significant financial losses. In response, researchers have developed various tools and techniques to identify and prevent vulnerabilities in smart contracts. In this survey, we present a systematic overview of the quality assurance of smart contracts, covering vulnerabilities, attacks, defenses, and tool support. By classifying vulnerabilities based on known attacks, we can identify patterns and common weaknesses that need to be addressed. Moreover, in order to effectively protect smart contracts, we have created a labeled dataset to evaluate various vulnerability detection tools and compare their effectiveness.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Settling Decentralized Multi-Agent Coordinated Exploration by Novelty Sharing</title>
<link>https://arxiv.org/abs/2402.02097</link>
<guid>https://arxiv.org/abs/2402.02097</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、协同探索、局部新颖性、全局新颖性、加权互信息

总结:
本文提出了一种名为MACE（Multi-Agent Coordinated Exploration）的简单而有效的多智能体协同探索方法。针对多智能体合作强化学习中面临的两个主要挑战——无法获取全局状态的新颖性，以及基于局部观察的新颖性存在偏差——MACE通过通信共享局部新颖性，使智能体能够考虑其他智能体的局部新颖性来近似全球新颖性。此外，引入了加权互信息作为衡量一个智能体动作对其他智能体累积新颖性影响的指标，并将其转换为事后奖励，激励智能体增强对其他智能体探索的影响，从而促进协同探索。实验结果表明，MACE在三个具有稀疏奖励的多智能体环境中取得了优于现有方法的表现。 <div>
arXiv:2402.02097v2 Announce Type: replace 
Abstract: Exploration in decentralized cooperative multi-agent reinforcement learning faces two challenges. One is that the novelty of global states is unavailable, while the novelty of local observations is biased. The other is how agents can explore in a coordinated way. To address these challenges, we propose MACE, a simple yet effective multi-agent coordinated exploration method. By communicating only local novelty, agents can take into account other agents' local novelty to approximate the global novelty. Further, we newly introduce weighted mutual information to measure the influence of one agent's action on other agents' accumulated novelty. We convert it as an intrinsic reward in hindsight to encourage agents to exert more influence on other agents' exploration and boost coordinated exploration. Empirically, we show that MACE achieves superior performance in three multi-agent environments with sparse rewards.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications</title>
<link>https://arxiv.org/abs/2408.04680</link>
<guid>https://arxiv.org/abs/2408.04680</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型（LLMs）、隐私保护、雾计算、分散式架构、SpeziLLM框架

总结:

本文探讨了大型语言模型（LLMs）在数据驱动医疗保健领域中的潜力，以及它们面临的挑战，包括数据隐私、信任问题和高昂的云服务成本。为了解决这些问题，作者提出了一种新的执行环境——分散且动态的雾计算架构，以替代传统的不透明、集中的云提供者。通过在用户边缘设备或本地网络内的雾层中执行开源权重的LLMs，旨在降低与云基人工智能服务相关的隐私、信任和财务挑战。

此外，文章介绍了SpeziLLM，一个旨在简化不同LLM执行层集成过程并降低数字健康应用中LLM整合障碍的开源框架。通过六个跨领域的数字健康应用案例研究，展示了SpeziLLM的广泛适用性和灵活性，证明其在各种医疗场景下的适应能力。 <div>
arXiv:2408.04680v1 Announce Type: new 
Abstract: The ability of large language models (LLMs) to transform, interpret, and comprehend vast quantities of heterogeneous data presents a significant opportunity to enhance data-driven care delivery. However, the sensitive nature of protected health information (PHI) raises valid concerns about data privacy and trust in remote LLM platforms. In addition, the cost associated with cloud-based artificial intelligence (AI) services continues to impede widespread adoption. To address these challenges, we propose a shift in the LLM execution environment from opaque, centralized cloud providers to a decentralized and dynamic fog computing architecture. By executing open-weight LLMs in more trusted environments, such as the user's edge device or a fog layer within a local network, we aim to mitigate the privacy, trust, and financial challenges associated with cloud-based LLMs. We further present SpeziLLM, an open-source framework designed to facilitate rapid and seamless leveraging of different LLM execution layers and lowering barriers to LLM integration in digital health applications. We demonstrate SpeziLLM's broad applicability across six digital health applications, showcasing its versatility in various healthcare settings.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Overlay-based Decentralized Federated Learning in Bandwidth-limited Networks</title>
<link>https://arxiv.org/abs/2408.04705</link>
<guid>https://arxiv.org/abs/2408.04705</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式联邦学习、网络拓扑学、带宽受限网络、优化问题、数据驱动模拟

<br /><br />
总结:

本文探讨了在带宽受限的网络环境下，如何通过结合网络拓扑学的最新进展来设计分布式联邦学习（DFL）中的通信需求与调度策略。主要贡献如下：

1. **针对性解决现有问题**：当前的DFL解决方案大多基于邻近节点物理相邻的假设，这在实际应用中如边缘网络中遇到的带宽受限情况并不准确。文章指出这一差距并提出了解决方案。

2. **利用网络拓扑学**：通过引入网络拓扑学概念，特别是网络汤米学，设计了一种无需底层网络明确合作的机制，以优化通信需求和调度。

3. **分解复杂问题**：将整体问题分解为一系列可高效求解的优化问题，从而在集体层面上最小化训练总时间。

4. **数据驱动的仿真**：通过大规模的数据驱动仿真验证了所提方法的有效性，结果显示相较于现有的最优设计，本文方法能显著加速分布式联邦学习过程。

5. **优化目标**：最终目标是通过有效的通信策略设计，提升分布式机器学习模型的训练效率，特别是在资源有限的网络环境中，实现更高效的AI部署。 <div>
arXiv:2408.04705v1 Announce Type: new 
Abstract: The emerging machine learning paradigm of decentralized federated learning (DFL) has the promise of greatly boosting the deployment of artificial intelligence (AI) by directly learning across distributed agents without centralized coordination. Despite significant efforts on improving the communication efficiency of DFL, most existing solutions were based on the simplistic assumption that neighboring agents are physically adjacent in the underlying communication network, which fails to correctly capture the communication cost when learning over a general bandwidth-limited network, as encountered in many edge networks. In this work, we address this gap by leveraging recent advances in network tomography to jointly design the communication demands and the communication schedule for overlay-based DFL in bandwidth-limited networks without requiring explicit cooperation from the underlying network. By carefully analyzing the structure of our problem, we decompose it into a series of optimization problems that can each be solved efficiently, to collectively minimize the total training time. Extensive data-driven simulations show that our solution can significantly accelerate DFL in comparison with state-of-the-art designs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Redefining Accountability: Navigating Legal Challenges of Participant Liability in Decentralized Autonomous Organizations</title>
<link>https://arxiv.org/abs/2408.04717</link>
<guid>https://arxiv.org/abs/2408.04717</guid>
<content:encoded><![CDATA[
<div> 关键词：数字时代、区块链技术、DAO（去中心化自治组织）、法律框架、参与者责任

文章主要探讨了在数字时代背景下，区块链技术驱动下新型组织形态——DAO（去中心化自治组织）对现有法律体系带来的挑战，特别是参与者责任问题。文章首先介绍了DAO的独特结构及其与传统组织形式的区别，强调了其去中心化治理和智能合约的应用导致的法律责任模糊性。其次，文章对比分析了DAO与其他传统组织形式（如公司和协会）在参与者责任方面的差异，指出现有法律框架在处理DAO相关问题上的不足之处。

文章的主要观点包括：

1. **法律框架挑战**：DAO的去中心化特性挑战了传统的法律框架，尤其是关于参与者责任的规定。

2. **智能合约与法律责任**：智能合约的自动执行特性以及参与者的匿名性进一步复杂化了法律责任的界定。

3. **责任界限模糊**：在DAO内部及与外部交互中，传统意义上的法律责任概念变得模糊，需要新的法律解决方案。

4. **现有法规适用性问题**：当前的法规可能无法充分应对DAO带来的新挑战，特别是在伙伴责任方面。

5. **创新法律解决方案**：文章呼吁探索和开发新的法律机制，以适应DAO及其参与者责任的特殊需求。

总结: 在数字时代背景下，随着区块链技术和DAO的发展，现有的法律框架面临着前所未有的挑战，尤其是在如何界定和处理DAO参与者责任方面。文章深入分析了DAO的独特结构如何影响法律责任的界定，通过与传统组织形式的比较揭示了现有法律体系在处理DAO相关问题上的局限性。同时，文章强调了需要创新性的法律解决方案来适应这一新兴领域的独特需求，以确保法律制度能够有效指导和规范DAO的运行和发展。 <div>
arXiv:2408.04717v1 Announce Type: new 
Abstract: In the digital era, where innovative technologies like blockchain are revolutionizing traditional organizational paradigms, Decentralized Autonomous Organizations (DAOs) emerge as avant-garde models of collective governance. However, their unique structure challenges existing legal frameworks, especially concerning the liability of participants. This study focuses on analyzing the legal implications of the decentralized nature of DAOs, with a particular emphasis on the aspects of participant liability. Such considerations are essential for understanding how current legal systems might be adapted or reformed to effectively address these novel challenges.
  The paper examines the specificity of DAOs, highlighting their decentralized governance structure and reliance on smart contracts, which introduce unique issues related to the blurring of liability boundaries. It underscores how the anonymity of DAO participants and the automatic execution of smart contracts complicate the traditional concept of legal liability, both within the DAO context and in interactions with external parties.
  The analysis also includes a comparison between DAOs and traditional organizational forms, such as corporations and associations, to identify potential analogies and differences in participant liability. It explores how existing regulations on partner liability might be insufficient or inapplicable in the DAO context, prompting the search for new, innovative legal solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Counter Denial of Service for Next-Generation Networks within the Artificial Intelligence and Post-Quantum Era</title>
<link>https://arxiv.org/abs/2408.04725</link>
<guid>https://arxiv.org/abs/2408.04725</guid>
<content:encoded><![CDATA[
<div> 关键词：网络系统、人工智能、拒绝服务攻击、后量子安全、协同防御

文章主要探讨了在网络系统面临日益复杂的拒绝服务（DoS）攻击背景下，当前研究领域存在的问题与挑战。主要包含以下几个方面：

1. **AI时代的DoS攻击**：文章指出，随着人工智能技术的发展和计算能力的增强，DoS攻击手段变得更加复杂且易于执行，直接威胁到系统的可用性。

2. **现有研究的局限性**：当前的研究主要集中在DoS攻击的预防、检测和缓解上，但存在孤立的对策、AI研究的不足以及缺乏集成特性如隐私、匿名性、认证和透明度等问题。

3. **后量子安全的考虑**：文章强调，尽管量子计算机的出现对DoS攻击和防御产生了重大影响，但这一领域仍处于研究的初级阶段，需要进一步探索。

4. **协同与分布式防御框架**：通过联邦学习和区块链技术构建协作和分布式反DoS框架，以提高系统的整体安全性。

5. **主动防御策略**：讨论了如蜜罐、谜题和认证方案等主动防御方法，旨在预防和缓解DoS攻击，为下一代网络系统提供安全保护。

总结: 文章深入分析了当前网络安全领域中DoS攻击的挑战，特别是AI时代背景下的新威胁和后量子安全的未探索领域。它提出了综合考虑AI机制、评估机器学习模型的网络安全属性、分析武器化AI、探索协作和分布式防御框架以及实施主动防御策略等多维度的解决方案。通过这些策略的整合应用，旨在构建更加安全、高效和适应未来技术挑战的网络系统架构。 <div>
arXiv:2408.04725v1 Announce Type: new 
Abstract: Given the rise in cyber threats to networked systems, coupled with the proliferation of AI techniques and enhanced processing capabilities, Denial of Service (DoS) attacks are becoming increasingly sophisticated and easily executable. They target system availability, compromising entire systems without breaking underlying security protocols. Consequently, numerous studies have focused on preventing, detecting, and mitigating DoS attacks. However, state-of-the-art systematization efforts have limitations such as isolated DoS countermeasures, shortcomings of AI-based studies, and a lack of DoS integration features like privacy, anonymity, authentication, and transparency. Additionally, the emergence of quantum computers is a game changer for DoS from attack and defense perspectives, yet it has remained largely unexplored. This study aims to address these gaps by examining (counter)-DoS in the AI era while also considering post-quantum (PQ) security when it applies. We highlight the deficiencies in the current literature and provide insights into synergistic techniques to bridge these gaps. We explore AI mechanisms for DoS intrusion detection, evaluate cybersecurity properties in cutting-edge machine learning models, and analyze weaponized AI in the context of DoS. We also investigate collaborative and distributed counter-DoS frameworks via federated learning and blockchains. Finally, we assess proactive approaches such as honeypots, puzzles, and authentication schemes that can be integrated into next-generation network systems for DoS prevention and mitigation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CTE-MLO: Continuous-time and Efficient Multi-LiDAR Odometry with Localizability-aware Point Cloud Sampling</title>
<link>https://arxiv.org/abs/2408.04901</link>
<guid>https://arxiv.org/abs/2408.04901</guid>
<content:encoded><![CDATA[
<div> 关键词：连续时间、高效、多激光雷达、实时性、高精度

总结:
本文提出了连续时间与高效多激光雷达定位与映射系统（CTE-MLO），旨在通过从多个激光雷达融合点云的角度来提高激光雷达定位与映射系统的性能。CTE-MLO采用连续时间视角，结合高斯过程估计与卡尔曼滤波，使每个激光雷达点在其时间间隔内查询相应的连续时间轨迹成为可能。此外，设计了一个去中心化的多激光雷达同步方案，无需主激光雷达的指定即可将来自不同激光雷达的点合并为单一点云。

CTE-MLO旨在实现准确且实时的状态估计，同时考虑了激光雷达点云的实时性能和鲁棒性。为了提升实时性能而不牺牲鲁棒性，设计了一种考虑局部可定位性的点云采样策略。实验结果表明，CTE-MLO能够以实时速度实现高精度的连续时间状态估计，并与当前最先进的方法相竞争。

通过在公共数据集和真实世界自动驾驶实验中的应用，CTE-MLO展示了其在实际场景中的有效性和竞争力，证明了其在激光雷达定位与映射领域的潜在价值。 <div>
arXiv:2408.04901v1 Announce Type: new 
Abstract: In recent years, LiDAR-based localization and mapping methods have achieved significant progress thanks to their reliable and real-time localization capability. Considering single LiDAR odometry often faces hardware failures and degradation in practical scenarios, Multi-LiDAR Odometry (MLO), as an emerging technology, is studied to enhance the performance of LiDAR-based localization and mapping systems. However, MLO can suffer from high computational complexity introduced by dense point clouds that are fused from multiple LiDARs, and the continuous-time measurement characteristic is constantly neglected by existing LiDAR odometry. This motivates us to develop a Continuous-Time and Efficient MLO, namely CTE-MLO, which can achieve accurate and real-time state estimation using multi-LiDAR measurements through a continuous-time perspective. In this paper, the Gaussian process estimation is naturally combined with the Kalman filter, which enables each LiDAR point in a point stream to query the corresponding continuous-time trajectory within its time instants. A decentralized multi-LiDAR synchronization scheme also be devised to combine points from separate LiDARs into a single point cloud without the requirement for primary LiDAR assignment. Moreover, with the aim of improving the real-time performance of MLO without sacrificing robustness, a point cloud sampling strategy is designed with the consideration of localizability. The effectiveness of the proposed method is demonstrated through various scenarios, including public datasets and real-world autonomous driving experiments. The results demonstrate that the proposed CTE-MLO can achieve high-accuracy continuous-time state estimations in real-time and is demonstratively competitive compared to other state-of-the-art methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Comprehensive System Architecture using Field Programmable Gate Arrays Technology, Dijkstra's Algorithm, and Edge Computing for Emergency Response in Smart Cities</title>
<link>https://arxiv.org/abs/2408.04924</link>
<guid>https://arxiv.org/abs/2408.04924</guid>
<content:encoded><![CDATA[
<div> 关键词：智能城市、应急响应系统、Chad、边缘计算、可编程门阵列(FPGA)

总结:

本文聚焦于智能城市中高效应急响应系统的构建，特别关注基础设施限制显著的地区如Chad。研究指出，现有解决方案往往假设有稳定基础设施和不间断连接，而这类条件在Chad等地区并不常见。传统云基系统在资源分配与路线规划方面存在不足。

为解决上述挑战，文章提出了一种综合系统架构，融合了可编程门阵列(FPGA)、迪杰斯特拉算法(Dijkstra's algorithm)以及边缘计算技术。其核心目标在于通过加速路线规划与资源分配，提升紧急情况下的响应效率。

该系统架构首先明确了所需系统的关键特性，随后详细描述了各组件并阐述了它们的集成方式。FPGA用于基于硬件的计算，以实现快速路径计算；Dijkstra's algorithm在分布式环境中实施，以寻找最短路径；边缘计算确保了数据处理的去中心化与韧性，从而实现资源的有效管理和应急响应的快速执行。

理论分析表明，该系统能够带来显著的响应时间改善和资源管理优化。此系统不仅提高了应急响应的效率，还能适应类似Chad的基础设施条件，展现出了广泛的应用前景。 <div>
arXiv:2408.04924v1 Announce Type: new 
Abstract: Efficient emergency response systems are crucial for smart cities. But their implementation is highly challenging, particularly in regions like Chad where infrastructural constraints are prevalent. The urgency for optimized response times and resource allocation in emergency scenarios is magnified in these contexts, yet existing solutions often assume robust infrastructure and uninterrupted connectivity, which is not always available. Most of the time, they are based on system architectures pre-designed for other purposes. This paper addresses these critical challenges by proposing a comprehensive system architecture that integrates Field Programmable Gate Arrays (FPGAs), Dijkstra's algorithm, and Edge Computing. The objective is to enhance emergency response through accelerated route planning and resource allocation, addressing gaps left by traditional cloud-based systems. Methodologically, key characteristics of the desired system are identified, then its components are described and their integration is explained; the system leverages FPGA-based computations and a distributed implementation of Dijkstra's algorithm to compute the shortest paths rapidly, while Edge Computing ensures decentralized and resilient processing. A theoretical analysis highlights promising improvements in response times and resource management. The proposed system architecture not only enhances emergency response efficiency but is also adaptable to infrastructural constraints of Chadian-like environments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Demystifying and Detecting Cryptographic Defects in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2408.04939</link>
<guid>https://arxiv.org/abs/2408.04939</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、智能合约、加密缺陷、CrySol工具、模糊测试

总结:

文章主要探讨了在以太坊区块链上使用智能合约时遇到的加密缺陷问题。以太坊提供了一套系统级的加密API，旨在增强智能合约的加密功能。然而，非专业开发者可能在实现这些功能时出现错误，导致安全漏洞。为了解决这一问题，研究团队进行了首项关于智能合约中加密缺陷的研究，分析了2406份真实世界的安全报告，定义了九种常见的加密缺陷类型，并提出了CrySol工具来自动化检测这些缺陷。

CrySol结合了交易重放和动态污点分析技术，能够深入解析与加密相关的语义，并利用特定于加密的技术生成测试案例。研究团队还收集了一个包含25745个真实世界加密相关智能合约的大规模数据集，用于评估CrySol的效果。结果显示，CrySol在检测精度和召回率方面分别达到了95.4%和91.2%，并且发现了25745个智能合约中有22.7%至少存在一种加密缺陷，揭示了此类缺陷的普遍性。

通过此研究和工具，开发者可以更有效地识别并修复智能合约中的加密缺陷，从而提高系统的安全性。 <div>
arXiv:2408.04939v1 Announce Type: new 
Abstract: Ethereum has officially provided a set of system-level cryptographic APIs to enhance smart contracts with cryptographic capabilities. These APIs have been utilized in over 10% of Ethereum transactions, motivating developers to implement various on-chain cryptographic tasks, such as digital signatures. However, since developers may not always be cryptographic experts, their ad-hoc and potentially defective implementations could compromise the theoretical guarantees of cryptography, leading to real-world security issues. To mitigate this threat, we conducted the first study aimed at demystifying and detecting cryptographic defects in smart contracts. Through the analysis of 2,406 real-world security reports, we defined nine types of cryptographic defects in smart contracts with detailed descriptions and practical detection patterns. Based on this categorization, we proposed CrySol, a fuzzing-based tool to automate the detection of cryptographic defects in smart contracts. It combines transaction replaying and dynamic taint analysis to extract fine-grained crypto-related semantics and employs crypto-specific strategies to guide the test case generation process. Furthermore, we collected a large-scale dataset containing 25,745 real-world crypto-related smart contracts and evaluated CrySol's effectiveness on it. The result demonstrated that CrySol achieves an overall precision of 95.4% and a recall of 91.2%. Notably, CrySol revealed that 5,847 (22.7%) out of 25,745 smart contracts contain at least one cryptographic defect, highlighting the prevalence of these defects.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Optimizing Crowd-Aware Multi-Agent Path Finding through Local Communication with Graph Neural Networks</title>
<link>https://arxiv.org/abs/2309.10275</link>
<guid>https://arxiv.org/abs/2309.10275</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Path Finding（MAPF）、crowd-aware、decentralized reinforcement learning、Graph Neural Networks（GNNs）、crashing and collision avoidance

总结:
本文提出了一种名为CRAMP的新颖方法，这是一种基于图神经网络（GNNs）的、考虑人群的分散式强化学习策略，旨在解决拥挤环境中多代理路径规划（MAPF）问题。CRAMP通过促进代理之间的高效局部通信，增强其对复杂环境的适应性，从而提高决策能力。与当前最先进的分散式MAPF方法相比，CRAMP在多个指标上表现出色：在模拟环境中，它在完成时间（makespan）和碰撞计数方面提高了59%，在成功率方面提高了35%。

CRAMP的关键特性在于其利用GNNs来实现高效的局部通信，这使得代理能够获取周围环境的即时信息，进而做出更明智的决策，以避免碰撞并优化路径。这种方法不仅克服了集中式规划中随代理数量增加而加剧的维数灾难问题，也弥补了分散式规划在密集环境中收敛速度慢和性能下降的问题。通过实验验证，CRAMP证明了其在处理复杂、拥挤场景时的有效性和优越性，为多代理系统在实际应用中的路径规划提供了有力的支持。 <div>
arXiv:2309.10275v3 Announce Type: replace 
Abstract: Multi-Agent Path Finding (MAPF) in crowded environments presents a challenging problem in motion planning, aiming to find collision-free paths for all agents in the system. MAPF finds a wide range of applications in various domains, including aerial swarms, autonomous warehouse robotics, and self-driving vehicles. Current approaches to MAPF generally fall into two main categories: centralized and decentralized planning. Centralized planning suffers from the curse of dimensionality when the number of agents or states increases and thus does not scale well in large and complex environments. On the other hand, decentralized planning enables agents to engage in real-time path planning within a partially observable environment, demonstrating implicit coordination. However, they suffer from slow convergence and performance degradation in dense environments. In this paper, we introduce CRAMP, a novel crowd-aware decentralized reinforcement learning approach to address this problem by enabling efficient local communication among agents via Graph Neural Networks (GNNs), facilitating situational awareness and decision-making capabilities in congested environments. We test CRAMP on simulated environments and demonstrate that our method outperforms the state-of-the-art decentralized methods for MAPF on various metrics. CRAMP improves the solution quality up to 59% measured in makespan and collision count, and up to 35% improvement in success rate in comparison to previous methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Teamwork Makes TEE Work: Open and Resilient Remote Attestation on Decentralized Trust</title>
<link>https://arxiv.org/abs/2402.08908</link>
<guid>https://arxiv.org/abs/2402.08908</guid>
<content:encoded><![CDATA[
<div> 关键词：远程验证、可信执行环境、物理不可克隆函数、智能合约、自动化切换机制

总结:
文章提出了一种名为JANUS的开放性和鲁棒性更强的远程验证（RA）方案，以解决现有可信执行环境（TEE）RA设计中集中式信任模型的脆弱性和固定流程的局限性。JANUS通过引入物理不可克隆功能（PUF）作为TEE中的内在根信任（RoT），提供直接的物理可信度量，从而分散了信任。同时，设计了基于智能合约的去中心化验证功能，包括结果审计和RA会话快照，增强了系统的透明性和可追溯性。此外，JANUS还设计了一个自动切换机制，允许系统在不同情况下保持鲁棒性并提供灵活的RA服务。

JANUS的创新之处在于其去中心化的信任模型、利用PUF增强TEE的安全性、智能合约的引入以实现验证过程的自动化和透明性，以及自动化切换机制以适应不断变化的安全需求。文章还提供了基于UC的安全性证明，展示了JANUS在实施原型中的可扩展性和通用性，证明了该方案在实际应用中的潜力和优势。 <div>
arXiv:2402.08908v2 Announce Type: replace 
Abstract: Remote Attestation (RA) enables the integrity and authenticity of applications in Trusted Execution Environment (TEE) to be verified. Existing TEE RA designs employ a centralized trust model where they rely on a single provisioned secret key and a centralized verifier to establish trust for remote parties. This model is however brittle and can be untrusted under advanced attacks nowadays. Besides, most designs only have fixed procedures once deployed, making them hard to adapt to different emerging situations and provide resilient functionalities.
  Therefore, we propose JANUS, an open and resilient TEE RA scheme. To decentralize trust, we, on one hand, introduce Physically Unclonable Function (PUF) as an intrinsic root of trust (RoT) in TEE to directly provide physical trusted measurements. On the other hand, we design novel decentralized verification functions on smart contract with result audits and RA session snapshot. Furthermore, we design an automated switch mechanism that allows JANUS to remain resilient and offer flexible RA services under various situations. We provide a UC-based security proof and demonstrate the scalability and generality of JANUS by implementing an complete prototype.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Supplementary File: Coded Cooperative Networks for Semi-Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2406.19002</link>
<guid>https://arxiv.org/abs/2406.19002</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、半去中心化、无线多样性、确定性编码网络、鲁棒性增强

总结:

本文提出了一种基于确定性编码网络的半去中心化联邦学习方法，旨在提高联邦学习系统的抗拖沓（straggler）能力。与现有方案不同的是，该方法不依赖于对整个网络拓扑结构的先验知识，而是利用无线通信的多样性来实现客户端间的协作。通过理论分析，文章详细阐述了所提方案在网络中断或延迟情况下的性能表现以及算法收敛速度。实验结果显示，与基准方法相比，新方法在保持学习效率的同时显著增强了系统的鲁棒性。

该研究为联邦学习系统在实际部署时提供了更为灵活和健壮的解决方案，特别是对于资源受限的边缘计算场景，通过减少对网络条件的依赖，提高了分布式机器学习任务的执行效率和稳定性。 <div>
arXiv:2406.19002v2 Announce Type: replace 
Abstract: To enhance straggler resilience in federated learning (FL) systems, a semi-decentralized approach has been recently proposed, enabling collaboration between clients. Unlike the existing semi-decentralized schemes, which adaptively adjust the collaboration weight according to the network topology, this letter proposes a deterministic coded network that leverages wireless diversity for semi-decentralized FL without requiring prior information about the entire network. Furthermore, the theoretical analyses of the outage and the convergence rate of the proposed scheme are provided. Finally, the superiority of our proposed method over benchmark methods is demonstrated through comprehensive simulations.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Simple Perturbations Subvert Ethereum Phishing Transactions Detection: An Empirical Analysis</title>
<link>https://arxiv.org/abs/2408.03441</link>
<guid>https://arxiv.org/abs/2408.03441</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、随机森林、决策树、K近邻、以太坊欺诈交易检测

总结:
本文探讨了在以太坊欺诈交易检测中，随机森林、决策树和K近邻等机器学习模型对简单单特征对抗攻击的脆弱性。通过广泛的实验，研究了不同对抗攻击策略对模型性能指标（如准确率、精确度、召回率和F1分数）的影响。研究发现，这些技术在对抗攻击面前极其脆弱，而不同算法对攻击效果的一致性不一，为攻击防御提供了方向。研究还分析了不同的缓解策略，包括对抗训练和增强特征选择，以提高模型的鲁棒性。

研究首先验证了随机森林、决策树和K近邻模型在对抗攻击下的表现，揭示了它们对简单单特征攻击的高度敏感性。随后，通过对比不同算法在遭受攻击后的性能变化，指出了一致性和差异性并存的现象，为后续研究提供了有价值的信息。最后，研究评估了对抗训练和改进特征选择方法的有效性，强调了它们在提升模型抗攻击能力方面的重要作用。 <div>
arXiv:2408.03441v1 Announce Type: new 
Abstract: This paper explores the vulnerability of machine learning models, specifically Random Forest, Decision Tree, and K-Nearest Neighbors, to very simple single-feature adversarial attacks in the context of Ethereum fraudulent transaction detection. Through comprehensive experimentation, we investigate the impact of various adversarial attack strategies on model performance metrics, such as accuracy, precision, recall, and F1-score. Our findings, highlighting how prone those techniques are to simple attacks, are alarming, and the inconsistency in the attacks' effect on different algorithms promises ways for attack mitigation. We examine the effectiveness of different mitigation strategies, including adversarial training and enhanced feature selection, in enhancing model robustness.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Asynchronous Credit Assignment Framework for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2408.03692</link>
<guid>https://arxiv.org/abs/2408.03692</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、异步决策、信用分配、分解价值、合作任务

<br /><br />
总结:本文提出了一种解决多智能体系统中信用分配问题的新框架，特别是针对异步决策的情况。该框架引入了一个名为ADEX-POMDP的问题模型，用于描述在不等待其他智能体的情况下进行决策的分布式部分可观测马尔可夫决策过程。同时，提出了一种名为MVD（Multiplicative Value Decomposition）的算法，通过利用乘法交互来高效捕捉异步决策之间的相互作用。理论证明了ADEX-POMDP模型能够保持任务平衡和算法收敛性。实验结果表明，MVD算法不仅在“Overcooked”和“POAC”等异步决策基准任务上持续优于现有最先进的多智能体强化学习方法，而且还能为异步合作提供可解释性。这一研究为解决实际合作任务中的异步决策问题提供了新的思路和工具。 <div>
arXiv:2408.03692v1 Announce Type: new 
Abstract: Credit assignment is a core problem that distinguishes agents' marginal contributions for optimizing cooperative strategies in multi-agent reinforcement learning (MARL). Current credit assignment methods usually assume synchronous decision-making among agents. However, a prerequisite for many realistic cooperative tasks is asynchronous decision-making by agents, without waiting for others to avoid disastrous consequences. To address this issue, we propose an asynchronous credit assignment framework with a problem model called ADEX-POMDP and a multiplicative value decomposition (MVD) algorithm. ADEX-POMDP is an asynchronous problem model with extra virtual agents for a decentralized partially observable markov decision process. We prove that ADEX-POMDP preserves both the task equilibrium and the algorithm convergence. MVD utilizes multiplicative interaction to efficiently capture the interactions of asynchronous decisions, and we theoretically demonstrate its advantages in handling asynchronous tasks. Experimental results show that on two asynchronous decision-making benchmarks, Overcooked and POAC, MVD not only consistently outperforms state-of-the-art MARL methods but also provides the interpretability for asynchronous cooperation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework</title>
<link>https://arxiv.org/abs/2408.03694</link>
<guid>https://arxiv.org/abs/2408.03694</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、联邦元学习、智能联盟形成、双博弈理论框架、区块链

总结:
本文研究了元宇宙中用户任务快速变化对模型个性化的需求，以及有限数据带来的挑战。提出了一种基于双博弈理论框架的元宇宙服务管理方法，旨在解决联邦元学习（FML）中的智能联盟形成问题。该框架通过构建基于区块链的协作联盟形成游戏，结合声誉度量、用户相似性和激励机制，实现了针对元宇宙中用户异质性（包括不同的数据结构、任务和样本大小）的定制化解决方案。引入了一种基于用户历史贡献和潜在贡献的新声誉系统，利用过去任务与新任务之间的相关性来预测用户表现。同时，提出了一种Stackelberg博弈为基础的激励机制，以吸引可靠的工作参与元学习过程，从而降低用户能源成本，提高收益，增强元学习效果，提升元宇宙整体效能，并相较于非区块链系统提高了训练效率达5%。实验结果表明，该双博弈理论框架优于最佳努力、随机和非均匀聚类方案，显著提升了训练性能，缩短了完成时间，增强了元宇宙的实用性，且有效应对了不良行为用户的挑战。 <div>
arXiv:2408.03694v1 Announce Type: new 
Abstract: The metaverse, envisioned as the next digital frontier for avatar-based virtual interaction, involves high-performance models. In this dynamic environment, users' tasks frequently shift, requiring fast model personalization despite limited data. This evolution consumes extensive resources and requires vast data volumes. To address this, meta-learning emerges as an invaluable tool for metaverse users, with federated meta-learning (FML), offering even more tailored solutions owing to its adaptive capabilities. However, the metaverse is characterized by users heterogeneity with diverse data structures, varied tasks, and uneven sample sizes, potentially undermining global training outcomes due to statistical difference. Given this, an urgent need arises for smart coalition formation that accounts for these disparities. This paper introduces a dual game-theoretic framework for metaverse services involving meta-learners as workers to manage FML. A blockchain-based cooperative coalition formation game is crafted, grounded on a reputation metric, user similarity, and incentives. We also introduce a novel reputation system based on users' historical contributions and potential contributions to present tasks, leveraging correlations between past and new tasks. Finally, a Stackelberg game-based incentive mechanism is presented to attract reliable workers to participate in meta-learning, minimizing users' energy costs, increasing payoffs, boosting FML efficacy, and improving metaverse utility. Results show that our dual game framework outperforms best-effort, random, and non-uniform clustering schemes - improving training performance by up to 10%, cutting completion times by as much as 30%, enhancing metaverse utility by more than 25%, and offering up to 5% boost in training efficiency over non-blockchain systems, effectively countering misbehaving users.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PeerSwap: A Peer-Sampler with Randomness Guarantees</title>
<link>https://arxiv.org/abs/2408.03829</link>
<guid>https://arxiv.org/abs/2408.03829</guid>
<content:encoded><![CDATA[
<div> 关键词：PeerSwap、随机样本、执行时间、网络规模、均匀分布

总结:
本文提出了PeerSwap，一种具有可证明随机性保证的对等网络采样协议。通过理论分析和实验验证，PeerSwap能够在合理的时间内为网络参与者提供均匀随机的其他节点样本。作者首先通过建立执行时间边界展示了PeerSwap的高效扩展性，表明其执行时间与网络规模N的关系可以低至对数阶，这得益于其基于交换过程模型的设计。此外，PeerSwap确保了通信图结构的不变性，同时允许节点位置的有序交换。通过对不同连通性的正则图进行实施和评估，结果表明PeerSwap能够快速生成均匀的随机样本，满足对等网络中分散式应用的需求。 <div>
arXiv:2408.03829v1 Announce Type: new 
Abstract: The ability of a peer-to-peer (P2P) system to effectively host decentralized applications often relies on the availability of a peer-sampling service, which provides each participant with a random sample of other peers. Despite the practical effectiveness of existing peer samplers, their ability to produce random samples within a reasonable time frame remains poorly understood from a theoretical standpoint. This paper contributes to bridging this gap by introducing PeerSwap, a peer-sampling protocol with provable randomness guarantees. We establish execution time bounds for PeerSwap, demonstrating its ability to scale effectively with the network size. We prove that PeerSwap maintains the fixed structure of the communication graph while allowing sequential peer position swaps within this graph. We do so by showing that PeerSwap is a specific instance of an interchange process, a renowned model for particle movement analysis. Leveraging this mapping, we derive execution time bounds, expressed as a function of the network size N. Depending on the network structure, this time can be as low as a polylogarithmic function of N, highlighting the efficiency of PeerSwap. We implement PeerSwap and conduct numerical evaluations using regular graphs with varying connectivity and containing up to 32768 (2^15) peers. Our evaluation demonstrates that PeerSwap quickly provides peers with uniform random samples of other peers.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Constrained Phi-Equilibria</title>
<link>https://arxiv.org/abs/2301.13600</link>
<guid>https://arxiv.org/abs/2301.13600</guid>
<content:encoded><![CDATA[
<div> 关键词：约束、均衡、计算复杂性、线性函数最大化、分散式学习算法

总结:

本文研究了在策略受到约束的背景下，多玩家博弈中的均衡问题。主要贡献包括：

1. **引入并定义了约束Φ-均衡**：这是一种比约束协整更广泛的均衡概念，适用于规范形式的博弈。

2. **探讨了计算复杂性**：证明了计算此类约束Φ-均衡的一般问题是不可解的，并指出均衡集可能不是凸集，与无约束协整形成鲜明对比。

3. **提供了一个算法**：当约束数量或行动数量固定时，提供了一个多项式时间算法来计算最大化给定线性函数的约束（近似）Φ-均衡。

4. **特殊情况下求解**：在每个玩家的约束不依赖于其他玩家策略的情况下，展示了如何使用多项式时间算法求解精确的最大化函数均衡。

5. **利用分散式学习算法**：提出了一种有效的分散式无后悔学习算法，用于找到（近似的）均衡，特别是当存在这样的约束时。

通过这些研究，文章不仅揭示了约束均衡计算的理论挑战，还提供了实用的解决方案和算法，为实际应用提供了理论基础和技术支持。 <div>
arXiv:2301.13600v2 Announce Type: replace 
Abstract: The computational study of equilibria involving constraints on players' strategies has been largely neglected. However, in real-world applications, players are usually subject to constraints ruling out the feasibility of some of their strategies, such as, e.g., safety requirements and budget caps. Computational studies on constrained versions of the Nash equilibrium have lead to some results under very stringent assumptions, while finding constrained versions of the correlated equilibrium (CE) is still unexplored. In this paper, we introduce and computationally characterize constrained Phi-equilibria -- a more general notion than constrained CEs -- in normal-form games. We show that computing such equilibria is in general computationally intractable, and also that the set of the equilibria may not be convex, providing a sharp divide with unconstrained CEs. Nevertheless, we provide a polynomial-time algorithm for computing a constrained (approximate) Phi-equilibrium maximizing a given linear function, when either the number of constraints or that of players' actions is fixed. Moreover, in the special case in which a player's constraints do not depend on other players' strategies, we show that an exact, function-maximizing equilibrium can be computed in polynomial time, while one (approximate) equilibrium can be found with an efficient decentralized no-regret learning algorithm.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Data Mesh: a Systematic Gray Literature Review</title>
<link>https://arxiv.org/abs/2304.01062</link>
<guid>https://arxiv.org/abs/2304.01062</guid>
<content:encoded><![CDATA[
<div> 关键词：数据网格、分散式数据架构、企业、服务导向架构、参考架构

总结:

本文旨在探索和构建数据网格（Data Mesh）这一新兴的领域驱动型分散式数据架构。数据网格的目标在于通过避免或减少集中式、大型化数据架构在企业中产生的运营瓶颈，来提升数据管理和使用效率。当前，尽管数据网格引起了实践者的广泛兴趣，学术界对于其概念的定义与深化研究却相对缺乏。

首先，文章深入探讨了数据网格的核心设计原则，包括将数据视为产品、实现领域级别的数据所有权、构建自助服务型数据平台以及实施联邦计算治理。这四个原则构成了数据网格的基础框架，旨在通过这些原则的实施，促进数据的高效管理和使用。

其次，为了更直观地理解数据网格的概念，文章将数据网格的研究发现与服务导向架构（SOA）的学术文献中的参考架构进行了对比映射。通过这种方式，构建了描述数据网格三个关键维度的参考架构：能力与角色的组织、开发过程和运行时环境。这不仅有助于对数据网格进行系统化的理解，也为后续的研究提供了清晰的视角。

最后，文章还指出了数据网格领域内的一些开放性研究问题，这些问题部分基于灰文文献的研究结果。这些研究问题为未来的学术探索提供了方向，旨在进一步深化对数据网格的理解，推动其在实际应用中的发展和优化。

综上所述，本文通过对数据网格的设计原则、核心概念、比较分析和开放研究问题的讨论，为读者提供了一个全面且深入的视角，帮助理解和推动数据网格这一创新架构在企业中的应用和发展。 <div>
arXiv:2304.01062v3 Announce Type: replace 
Abstract: Data mesh is an emerging domain-driven decentralized data architecture that aims to minimize or avoid operational bottlenecks associated with centralized, monolithic data architectures in enterprises. The topic has picked the practitioners' interest, and there is considerable gray literature on it. At the same time, we observe a lack of academic attempts at defining and building upon the concept. Hence, in this article, we aim to start from the foundations and characterize the data mesh architecture regarding its design principles, architectural components, capabilities, and organizational roles. We systematically collected, analyzed, and synthesized 114 industrial gray literature articles. The review provides insights into practitioners' perspectives on the four key principles of data mesh: data as a product, domain ownership of data, self-serve data platform, and federated computational governance. Moreover, due to the comparability of data mesh and SOA (service-oriented architecture), we mapped the findings from the gray literature into the reference architectures from the SOA academic literature to create the reference architectures for describing three key dimensions of data mesh: organization of capabilities and roles, development, and runtime. Finally, we discuss open research issues in data mesh, partially based on the findings from the gray literature.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Harmonization: Federated Clustered Batch Effect Adjustment and Generalization</title>
<link>https://arxiv.org/abs/2405.15081</link>
<guid>https://arxiv.org/abs/2405.15081</guid>
<content:encoded><![CDATA[
<div> 关键词：独立同分布（i.i.d.）、医疗领域、数据偏倚、ComBat算法、分布式集群谐波化

总结:
本文研究了在医疗数据分析中如何处理来自不同医疗机构的数据，这些数据可能因地理位置或设施差异而产生偏倚，违反了独立同分布（i.i.d.）原则。针对这一问题，作者提出了一种名为“分布式集群谐波化”的新方法，通过利用不同机构间数据的聚类模式来提高ComBat算法的兼容性和实用性。

首先，ComBat算法是一种流行的谐波化方法，用于校正来自不同地点的数据偏倚。然而，当需要处理新加入的机构或未知机构的数据时，传统的ComBat算法需要重新训练，这带来了巨大的计算和物流负担。为了解决这个问题，本文提出了“分布式集群谐波化”算法，该算法在保持ComBat算法优势的同时，提高了对新数据的适应性。

接着，通过广泛的模拟实验和ADNI（阿尔茨海默病神经影像学倡议）的真实医疗影像数据，证明了新方法的有效性。实验结果表明，与传统ComBat算法相比，分布式集群谐波化在保持数据一致性的同时，显著提高了处理新数据的能力，从而减少了重训的必要性。

最后，为了方便研究者和实践者使用，作者提供了实现该算法的代码库，以促进其在实际应用中的推广和应用。

总的来说，本文提出的分布式集群谐波化算法为处理医疗领域中来自不同机构的数据提供了一种有效且高效的方法，不仅解决了数据偏倚问题，还降低了计算和物流成本，具有重要的理论价值和实际应用前景。 <div>
arXiv:2405.15081v3 Announce Type: replace 
Abstract: Independent and identically distributed (i.i.d.) data is essential to many data analysis and modeling techniques. In the medical domain, collecting data from multiple sites or institutions is a common strategy that guarantees sufficient clinical diversity, determined by the decentralized nature of medical data. However, data from various sites are easily biased by the local environment or facilities, thereby violating the i.i.d. rule. A common strategy is to harmonize the site bias while retaining important biological information. The ComBat is among the most popular harmonization approaches and has recently been extended to handle distributed sites. However, when faced with situations involving newly joined sites in training or evaluating data from unknown/unseen sites, ComBat lacks compatibility and requires retraining with data from all the sites. The retraining leads to significant computational and logistic overhead that is usually prohibitive. In this work, we develop a novel Cluster ComBat harmonization algorithm, which leverages cluster patterns of the data in different sites and greatly advances the usability of ComBat harmonization. We use extensive simulation and real medical imaging data from ADNI to demonstrate the superiority of the proposed approach. Our codes are provided in https://github.com/illidanlab/distributed-cluster-harmonization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SoK: Attacks on DAOs</title>
<link>https://arxiv.org/abs/2406.15071</link>
<guid>https://arxiv.org/abs/2406.15071</guid>
<content:encoded><![CDATA[
<div> 关键词：DAOs、安全威胁、攻击类型、审计、风险因素

总结:

本文系统地分析了去中心化自治组织(DAOs)所面临的安全威胁。主要从三个方面进行了探讨：

1. **历史攻击**：分析了过去发生的针对DAO的攻击事件，揭示了攻击者利用的策略和手段。

2. **理论攻击**：探讨了理论上可能发生的攻击类型，以及这些攻击的潜在影响。

3. **预防性攻击**：介绍了在审计过程中发现并阻止的潜在攻击，展示了审计在提高系统安全性方面的作用。

研究指出，许多对DAO的攻击利用了治理过程中的人性复杂性和非实体因素，而审计则更侧重于代码和技术漏洞的检测。为了应对这些挑战，文章还收集了有关DAO漏洞的实证数据，指出了导致这些攻击的风险因素，并提出了相应的缓解策略，旨在增强DAO系统的整体安全防护能力。

通过上述分析，本研究为理解、预防和应对DAO面临的复杂安全挑战提供了深入见解，对于推动DAO领域的健康发展具有重要意义。 <div>
arXiv:2406.15071v2 Announce Type: replace 
Abstract: Decentralized Autonomous Organizations (DAOs) are blockchain-based organizations that facilitate decentralized governance. Today, DAOs not only hold billions of dollars in their treasury but also govern many of the most popular Decentralized Finance (DeFi) protocols. This paper systematically analyses security threats to DAOs, focusing on the types of attacks they face. We study attacks on DAOs that took place in the past, attacks that have been theorized to be possible, and potential attacks that were uncovered and prevented in audits. For each of these (potential) attacks, we describe and categorize the attack vectors utilized into four categories. This reveals that while many attacks on DAOs take advantage of the less tangible and more complex human nature involved in governance, audits tend to focus on code and protocol vulnerabilities. Thus, additionally, the paper examines empirical data on DAO vulnerabilities, outlines risk factors contributing to these attacks, and suggests mitigation strategies to safeguard against such vulnerabilities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application</title>
<link>https://arxiv.org/abs/2408.02998</link>
<guid>https://arxiv.org/abs/2408.02998</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、作物产量预测、长短期记忆网络（LSTM）、集中式、分布式

总结:
本文探讨了在物联网应用中使用联邦学习进行作物产量预测的技术。研究提出了两种框架：集中式和分布式联邦学习。在集中式框架下，多个客户端与一个服务器交互，服务器作为聚合器构建全局模型。在分布式框架中，设备通过环形拓扑或网格拓扑形成协作网络，互相交换模型更新以构建升级模型。实验结果显示，集中式和分布式联邦学习框架分别实现了≥97%和＞97.5%的预测准确性。值得注意的是，与仅使用云的框架相比，集中式联邦学习响应时间可减少约75%。此外，文章还探讨了联邦学习在作物产量预测领域的未来研究方向。

集中式联邦学习通过客户端与服务器的直接通信提高效率，而分布式联邦学习则利用设备间的直接交互实现模型优化。两种方法均显著提高了预测准确性和响应速度，为农业物联网提供了高效的数据分析解决方案。未来的研究将集中在进一步优化联邦学习算法、扩展其在农业领域的应用以及解决数据隐私和安全问题上。 <div>
arXiv:2408.02998v1 Announce Type: new 
Abstract: Federated learning has become an emerging technology for data analysis for IoT applications. This paper implements centralized and decentralized federated learning frameworks for crop yield prediction based on Long Short-Term Memory Network. For centralized federated learning, multiple clients and one server is considered, where the clients exchange their model updates with the server that works as the aggregator to build the global model. For the decentralized framework, a collaborative network is formed among the devices either using ring topology or using mesh topology. In this network, each device receives model updates from the neighbour devices, and performs aggregation to build the upgraded model. The performance of the centralized and decentralized federated learning frameworks are evaluated in terms of prediction accuracy, precision, recall, F1-Score, and training time. The experimental results present that $\geq$97% and $>$97.5% prediction accuracy are achieved using the centralized and decentralized federated learning-based frameworks respectively. The results also show that the using centralized federated learning the response time can be reduced by $\sim$75% than the cloud-only framework. Finally, the future research directions of the use of federated learning in crop yield prediction are explored in this paper.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Social Behavior as a Key to Learning-based Multi-Agent Pathfinding Dilemmas</title>
<link>https://arxiv.org/abs/2408.03063</link>
<guid>https://arxiv.org/abs/2408.03063</guid>
<content:encoded><![CDATA[
arXiv:2408.03063v1 Announce Type: new 
Abstract: The Multi-agent Path Finding (MAPF) problem involves finding collision-free paths for a team of agents in a known, static environment, with important applications in warehouse automation, logistics, or last-mile delivery. To meet the needs of these large-scale applications, current learning-based methods often deploy the same fully trained, decentralized network to all agents to improve scalability. However, such parameter sharing typically results in homogeneous behaviors among agents, which may prevent agents from breaking ties around symmetric conflict (e.g., bottlenecks) and might lead to live-/deadlocks. In this paper, we propose SYLPH, a novel learning-based MAPF framework aimed to mitigate the adverse effects of homogeneity by allowing agents to learn and dynamically select different social behaviors (akin to individual, dynamic roles), without affecting the scalability offered by parameter sharing. Specifically, SYLPH agents learn to select their Social Value Orientation (SVO) given the situation at hand, quantifying their own level of selfishness/altruism, as well as an SVO-conditioned MAPF policy dictating their movement actions. To these ends, each agent first determines the most influential other agent in the system by predicting future conflicts/interactions with other agents. Each agent selects its own SVO towards that agent, and trains its decentralized MAPF policy to enact this SVO until another agent becomes more influential. To further allow agents to consider each others' social preferences, each agent gets access to the SVO value of their neighbors. As a result of this hierarchical decision-making and exchange of social preferences, SYLPH endows agents with the ability to reason about the MAPF task through more latent spaces and nuanced contexts, leading to varied responses that can help break ties around symmetric conflicts. [...]
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Dawn of Decentralized Social Media: An Exploration of Bluesky's Public Opening</title>
<link>https://arxiv.org/abs/2408.03146</link>
<guid>https://arxiv.org/abs/2408.03146</guid>
<content:encoded><![CDATA[
<div> 关键词：Bluesky、社交平台、用户活动、内容特性、增长与监管

<br /><br />
总结:

这篇论文探讨了Bluesky，一个类似Twitter的去中心化社交媒体平台，在其向全球公众开放后的两个月内的用户活动情况。研究发现，平台用户活跃度分布广泛，与成熟平台相似，但原创内容比例较高，转发内容较少。此外，Bluesky的毒性内容水平极低，显示了良好的社区氛围。

在平台对外开放后，用户基数和活动量迅速增长，特别是英语和日语内容的发布。然而，一些新账号通过大量关注和分享低信誉新闻媒体的内容，引发了异常行为，显示出潜在的垃圾信息传播风险。部分账号已被识别为垃圾邮件或被暂停，这表明平台在实施有效的内容管理和用户行为监管方面表现出色。

总体而言，Bluesky在快速增长的同时保持了高质量的用户参与和积极的社区环境，但在应对新用户带来的挑战时，需要持续加强内容审核和用户行为管理。 <div>
arXiv:2408.03146v1 Announce Type: new 
Abstract: Bluesky is a Twitter-like decentralized social media platform that has recently grown in popularity. After an invite-only period, it opened to the public worldwide on February 6th, 2024. In this paper, we provide a longitudinal analysis of user activity in the two months around the opening, studying changes in the general characteristics of the platform due to the rapid growth of the user base. We observe a broad distribution of activity similar to more established platforms, but a higher volume of original than reshared content, and very low toxicity. After opening to the public, Bluesky experienced a large surge in new users and activity, especially posting English and Japanese content. In particular, several accounts entered the discussion with suspicious behavior, like following many accounts and sharing content from low-credibility news outlets. Some of these have already been classified as spam or suspended, suggesting effective moderation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Local Differential Privacy in Graph Neural Networks: a Reconstruction Approach</title>
<link>https://arxiv.org/abs/2309.08569</link>
<guid>https://arxiv.org/abs/2309.08569</guid>
<content:encoded><![CDATA[
<div> 关键词：图神经网络、隐私保护、局部差分隐私、特征扰动、标签扰动

总结:
本文提出了一种学习框架，旨在为用户级别的节点提供隐私保护，同时保持较低的实用性损失。该框架专注于本地差分隐私的概念，并在数据收集到中央服务器进行模型训练之前，对节点级的特征和标签数据应用随机化机制进行扰动。特别是在高维特征设置中，研究了随机化机制的应用，并提出了具有严格隐私保证的LDP协议。基于统计分析中的频率估计方法，开发了从扰动数据中近似特征和标签的方法。此外，该学习框架还被设计为利用图簇的频率估计在子图级别监督训练过程。通过在真实世界和半合成数据集上的大量实验，验证了所提出的模型的有效性。

本文的核心贡献包括：
1. 提出了在图神经网络中保护用户隐私的学习框架。
2. 应用了本地差分隐私概念，对特征和标签进行了节点级扰动。
3. 在高维特征场景下研究了随机化机制的应用，并设计了具有严格隐私保证的协议。
4. 利用频率估计方法，从扰动数据中重建特征和标签。
5. 设计了利用图簇频率估计在子图级别监督训练的过程，从而实现模型的有效性和隐私保护的平衡。 <div>
arXiv:2309.08569v2 Announce Type: replace 
Abstract: Graph Neural Networks have achieved tremendous success in modeling complex graph data in a variety of applications. However, there are limited studies investigating privacy protection in GNNs. In this work, we propose a learning framework that can provide node privacy at the user level, while incurring low utility loss. We focus on a decentralized notion of Differential Privacy, namely Local Differential Privacy, and apply randomization mechanisms to perturb both feature and label data at the node level before the data is collected by a central server for model training. Specifically, we investigate the application of randomization mechanisms in high-dimensional feature settings and propose an LDP protocol with strict privacy guarantees. Based on frequency estimation in statistical analysis of randomized data, we develop reconstruction methods to approximate features and labels from perturbed data. We also formulate this learning framework to utilize frequency estimates of graph clusters to supervise the training procedure at a sub-graph level. Extensive experiments on real-world and semi-synthetic datasets demonstrate the validity of our proposed model.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain Economic Denial of Sustainability Attack: Exploiting Latency Optimization in Ethereum Transaction Forwarding</title>
<link>https://arxiv.org/abs/2408.01508</link>
<guid>https://arxiv.org/abs/2408.01508</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、经济激励、延迟减少、EDoS攻击、成本效益分析

文章主要探讨了与区块链中的可提取价值（MEV/BEV）策略相关的经济激励如何促使网络节点减少延迟，特别是最小化交易验证时间。文章引入了一种修改后的节点模型，该节点忽视了过滤无效交易的过程，从而为区块链网络引入了新的攻击途径。文章详细描述了一个名为Blockchain Economic Denial of Sustainability（EDoS）的攻击模型，这种攻击能够导致操作修改节点的流量成本损失。研究通过数学定义、实证实例识别、参数测量和本地网络攻击模拟等步骤，展示了这种攻击能够显著增加网络流量，并造成巨大的经济损失。

文章指出，尽管存在经济风险，但减少验证过程的延迟仍然可能带来足够的利润，以支持修改节点的存在。为了评估这一权衡，文章模拟了交易验证过程并实测了部署修改节点后产生的延迟减少。最终，文章提出了针对这种攻击的缓解策略，并进行了成本效益分析。

总结:
文章深入探讨了区块链网络中，特别是以太坊P2P网络中，由MEV/BEV策略驱动的延迟减少带来的新安全挑战——EDoS攻击。通过实证研究和模拟实验，揭示了攻击者如何利用修改节点进行流量放大攻击，以及这种攻击对网络经济造成的严重威胁。文章不仅指出了减少验证延迟可能导致的安全风险，还通过成本效益分析强调了理解这种风险与潜在收益之间的平衡至关重要。为此，文章提供了对抗此类攻击的策略建议，旨在为区块链网络的安全性和稳定性提供指导。 <div>
arXiv:2408.01508v1 Announce Type: new 
Abstract: Strategies related to the blockchain concept of Extractable Value (MEV/BEV), such as arbitrage, front- or back-running create an economic incentive for network nodes to reduce latency, including minimizing transaction validation time -- a core feature to secure blockchain networks. A modified node, that neglects to filter invalid transactions in the Ethereum P2P network, introduces novel attack vectors. In this work, we formalize and evaluate a Blockchain Economic Denial of Sustainability (EDoS) attack, which can cause financial losses in traffic costs for operators of modified nodes. We 1) mathematically define the attack model, 2) identify thousands of empirical instances of this similar attack in the wild, 3) empirically measure the model parameters from our two monitoring nodes, and 4) conduct attack simulations on the local network to compare its performance with existing Denial-of-Service attacks. We show that an attacker can amplify network traffic at modified nodes by a factor of 3,600, and cause economic damages 13,800 times greater than the amount needed to carry out the attack. Despite these risks, aggressive latency reduction may still be profitable enough to justify the existence of modified nodes. To assess this trade-off, we 1) simulate the transaction validation process in the local network and 2) empirically measure the latency reduction by deploying our modified node in the Ethereum testnet. We conclude with a cost-benefit analysis of skipping validation and provide mitigation strategies against this attack.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Remote Staking with Economic Safety</title>
<link>https://arxiv.org/abs/2408.01896</link>
<guid>https://arxiv.org/abs/2408.01896</guid>
<content:encoded><![CDATA[
<div> 关键词：远程质押、经济安全、协议违规、智能合约、Cosmos SDK

总结:
本文提出了一种新型远程质押协议，旨在增强基于Cosmos SDK并运行Tendermint共识算法的消费者链的经济安全性。该协议的核心创新在于确保了在消费者链发生安全违规时，提供链至少有三分之一的质押资产会被削减。这一目标的实现依赖于两个关键贡献：首先，设计了一个远程解绑协议，当消费者链出现安全问题时，能够确保在提供链上解绑质押前执行削减操作；其次，即使提供链不支持智能合约，也能实现对质押资产的削减。

通过结合这些机制，该协议不仅为使用非本地代币进行远程质押的区块链网络提供了更强的安全保障，而且有效利用了不同区块链之间的资源，提高了整个生态系统抵御风险的能力。特别地，文章以比特币作为提供链的示例，展示了如何在实际应用中实施这种远程质押方案，从而进一步验证了其理论可行性与实用性。 <div>
arXiv:2408.01896v1 Announce Type: new 
Abstract: Proof-of-stake (PoS) blockchains require validators to lock their tokens as collateral, slashing these tokens if they are identified as protocol violators. PoS chains have mostly been secured by their native tokens. However, using only the native token upper-bounds the value eligible for staking by the market capitalization of the native token. In contrast, the remote staking of another crypto asset from a provider chain provides an avenue to improve the consumer chain's economic security. In this paper, we present the first known remote staking protocols with guaranteed optimal economic safety: whenever there is a safety violation on the consumer chain, at least one third of the provider's stake securing the consumer chain is slashed. To achieve this goal for a broad range of provider and consumer chains, two independent contributions are made: 1) a remote unbonding protocol that ensures slashing before the stake is unbonded on the provider chain if there is safety violation on the consumer chain; 2) a protocol to slash stake even without smart contracts on the provider chain. The remote staking protocol is analyzed and implemented in the case where the provider chain is Bitcoin and the consumer chain is a Cosmos SDK chain running the Tendermint consensus protocol.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Shaping Rewards, Shaping Routes: On Multi-Agent Deep Q-Networks for Routing in Satellite Constellation Networks</title>
<link>https://arxiv.org/abs/2408.01979</link>
<guid>https://arxiv.org/abs/2408.01979</guid>
<content:encoded><![CDATA[
<div> 关键词：卫星 mega-constellations、机器学习、深度强化学习、多代理系统、网络控制

总结:

本文聚焦于卫星大规模星座的有效路由问题，探讨在处理不断增长的流量负载、复杂网络架构以及融入6G网络背景下的挑战。研究指出，利用机器学习特别是深度强化学习方法，能增强网络的适应性和对不可预测流量需求的鲁棒性，同时高效解决动态路由环境中的问题。文章特别关注基于深度Q网络的多智能体系统在优化服务质量要求和维护网络稳定性的路径决策上的应用。

文中提到，通过奖励塑造和量化训练收敛性，研究人员在静态和动态场景下对联合优化延迟与负载平衡进行了深入探索。然而，现有的解决方案存在局限性，因此提出了一种基于集中式学习和分散式控制的创新混合策略，旨在克服现有方法的不足，提供更优的路由解决方案。此混合策略结合了集中式策略的全局优化能力和分散式策略的局部适应性，为卫星星座网络的路由问题提供了新的视角和可能的解决途径。 <div>
arXiv:2408.01979v1 Announce Type: new 
Abstract: Effective routing in satellite mega-constellations has become crucial to facilitate the handling of increasing traffic loads, more complex network architectures, as well as the integration into 6G networks. To enhance adaptability as well as robustness to unpredictable traffic demands, and to solve dynamic routing environments efficiently, machine learning-based solutions are being considered. For network control problems, such as optimizing packet forwarding decisions according to Quality of Service requirements and maintaining network stability, deep reinforcement learning techniques have demonstrated promising results. For this reason, we investigate the viability of multi-agent deep Q-networks for routing in satellite constellation networks. We focus specifically on reward shaping and quantifying training convergence for joint optimization of latency and load balancing in static and dynamic scenarios. To address identified drawbacks, we propose a novel hybrid solution based on centralized learning and decentralized control.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-Enabled Dynamic Spectrum Sharing for Satellite and Terrestrial Communication Networks</title>
<link>https://arxiv.org/abs/2408.02013</link>
<guid>https://arxiv.org/abs/2408.02013</guid>
<content:encoded><![CDATA[
<div> 关键词：动态频谱共享、卫星网络、区块链技术、资源限制、区域差异

总结:

本文提出了一种名为“分区自治和定制动态频谱共享方法（PSC-DSS）”的新型频谱共享策略，旨在解决卫星与地面网络之间频谱共享所面临的挑战。该方法采用分层架构，允许不同地区独立管理频谱资源，同时共同维护单一的区块链账本，从而实现高效、安全的频谱共享。

首先，PSC-DSS通过建立分片架构，确保各个地区能够根据自身需求进行频谱管理，同时保持全局一致性。这种设计不仅提高了系统的灵活性，还有效解决了由于地理覆盖范围广导致的频谱需求多样化问题。

其次，文中设计了一种结合频谱共识机制与区块链共识协议的集成方案，实现了频谱共享过程的并行化处理。这使得各个地区可以在不干扰其他地区的前提下，自主创新频谱共享方案，极大地提升了系统效率。

此外，作者还构建了一个理论框架，用于分析和验证PSC-DSS的稳定性性能。通过模拟实验和实际测试，证明了PSC-DSS在低开销、高效率和稳定性的表现上具有明显优势。

综上所述，PSC-DSS为卫星与地面网络之间的频谱共享提供了一种创新的解决方案，通过优化架构设计、引入高效共识机制以及验证理论分析，有效解决了资源限制和区域差异带来的挑战，展示了其在动态频谱共享领域的应用潜力。 <div>
arXiv:2408.02013v1 Announce Type: new 
Abstract: Dynamic spectrum sharing (DSS) between satellite and terrestrial networks has increasingly engaged the academic and industrial sectors. Nevertheless, facilitating secure, efficient and scalable sharing continues to pose a pivotal challenge. Emerging as a promising technology to bridge the trust gap among multiple participants, blockchain has been envisioned to enable DSS in a decentralized manner. However, satellites with limited resources may struggle to support the frequent interactions required by blockchain networks. Additionally,given the extensive coverage of satellites, spectrum sharing needs vary by regions, challenging traditional blockchain approaches to accommodate differences. In this work, a partitioned, self-governed, and customized dynamic spectrum sharing approach (PSC-DSS) is proposed for spectrum sharing between satellite access networks and terrestrial access networks. This approach establishes a sharded and tiered architecture which allows various regions to manage spectrum autonomously while jointly maintaining a single blockchain ledger. Moreover, a spectrum-consensus integrated mechanism, which decouples DSS process and couples it with blockchain consensus protocol, is designed to enable regions to conduct DSS transactions in parallel and dynamically innovate spectrum sharing schemes without affecting others. Furthermore, a theoretical framework is derived to justify the stability performance of PSC-DSS. Finally, simulations and experiments are conducted to validate the advantageous performance of PSC-DSS in terms of low-overhead, high efficiency, and robust stability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Secure and Transparent Medical Record Management System Using Python and Blockchain</title>
<link>https://arxiv.org/abs/2408.02081</link>
<guid>https://arxiv.org/abs/2408.02081</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、智能合约、数据安全、患者控制、健康管理

总结:

本文提出了一种基于区块链技术的健康新型存储和管理系统。该系统旨在解决传统医疗记录系统面临的挑战，通过区块链提供一个安全且去中心化的平台。区块链的分布式特性确保了数据的冗余和对网络攻击的抵御能力，从而增强了数据的安全性和隐私性，对于处理敏感的健康信息至关重要。智能合约被用于自动化与健康记录管理相关的过程，如数据访问、共享和更新，基于预设的权限和协议进行操作，这不仅简化了行政任务，还降低了人为错误的风险，确保了数据的准确性和一致性。此外，该系统强调患者的权力，使个人完全掌控自己的健康记录。患者可以通过加密密钥安全地访问和管理他们的数据，并根据需要向医疗保健提供者或其他授权实体授予访问权限。综上所述，本文提出的基于区块链的健康记录存储和管理系统相对于传统系统具有显著优势，包括增强的安全性、数据完整性、透明度和患者控制。通过利用区块链技术和智能合约，医疗保健机构可以彻底改变其记录管理实践，构建更安全的生态系统。 <div>
arXiv:2408.02081v1 Announce Type: new 
Abstract: In this paper, we propose a robust health record storage and management system built on blockchain technology to address the challenges faced by traditional healthcare record systems. The primary advantage of employing blockchain in healthcare record management is its ability to provide a secure and decentralized platform. Unlike traditional centralized databases, where a single point of failure can compromise data integrity and security, blockchain distributes data across a network of nodes, ensuring redundancy and resilience against cyber-attacks. This distributed nature of blockchain enhances data security and privacy, crucial considerations when dealing with sensitive health information. Central to our proposed system is the utilization of smart contracts, which are self-executing contracts with predefined rules and conditions. Smart contracts automate processes related to health record management, such as data access, sharing, and updating, based on predefined permissions and protocols. This automation not only streamlines administrative tasks but also reduces the risk of human errors and ensures data accuracy and consistency. Furthermore, our system prioritizes patient empowerment by granting individuals complete control over their health records. Patients can securely access and manage their data using cryptographic keys, granting permission to healthcare providers or other authorized entities as needed. Overall, our proposed health record storage and management system on the blockchain offer significant advantages over traditional systems, including enhanced security, data integrity, transparency, and patient control. By leveraging blockchain technology and smart contracts, healthcare organizations can revolutionize their record management practices, and maintaining secure ecosystems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Assessing the XDC Network: A Comprehensive Evaluation of its qualitative and technical aspects</title>
<link>https://arxiv.org/abs/2408.02115</link>
<guid>https://arxiv.org/abs/2408.02115</guid>
<content:encoded><![CDATA[
<div> 关键词：XDC网络、技术评估、安全性、业务维度、研究发现

总结:

本文对XDC网络进行了全面评估，聚焦于其技术、安全性和商业性。评估涵盖了去中心化程度、可扩展性和安全性方面，如Nakamoto系数、验证者参与度和客户端分布。此外，还分析了开发者生态系统，通过GitHub指标进行衡量，以及交易成本和可预测性等商业方面。研究发现为XDC网络的强项和弱点提供了洞察，帮助利益相关者和决策者判断其在贸易金融、资产代币化和企业区块链解决方案等领域的适用性。

文章详细地探讨了XDC网络的技术基础，包括其基于委托权益证明（XDPoS）共识机制的特性。从安全角度看，研究关注了网络的去中心化水平，通过Nakamoto系数等指标来量化节点分布的分散性。同时，评估了验证者参与度和客户端分布情况，以确保网络的可靠性和安全性。在业务维度上，文章分析了XDC网络的交易费用结构及其对未来可预测性的影响，这直接关系到网络的经济可行性和用户满意度。此外，文章还深入研究了开发者生态系统的健康状况，通过GitHub指标来衡量开发活动的活跃程度，从而反映社区支持和技术创新能力。最后，研究结果将为XDC网络的未来发展方向提供指导，特别是对于希望利用区块链技术解决贸易金融、资产代币化和企业级应用问题的行业参与者而言。 <div>
arXiv:2408.02115v1 Announce Type: new 
Abstract: This research provides a thorough assessment of the XDC Network, a delegated proof of stake (XDPoS) consensus-based blockchain technology, across its technical, security, and business dimensions. The study evaluates the network's decentralization, scalability, and security features, including its Nakamoto coefficient, validator participation, and client distribution. Additionally, it examines the developer ecosystem, including GitHub metrics, and business aspects such as transaction costs and predictability. The findings of this research will provide valuable insights into the strengths and weaknesses of the XDC Network, informing stakeholders and decision-makers about its suitability for various use cases, particularly in trade finance, asset tokenization, and enterprise blockchain solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PROF: Protected Order Flow in a Profit-Seeking World</title>
<link>https://arxiv.org/abs/2408.02303</link>
<guid>https://arxiv.org/abs/2408.02303</guid>
<content:encoded><![CDATA[
<div> 关键词：PROF、分散式金融（DeFi）、最大化可提取价值（MEV）、提案者-构建者分离（PBS）、交易顺序操纵

总结:

本文提出了一个名为PROF（保护订单流）的系统，旨在限制现有PBS体系中对有害形式的MEV的影响。PROF通过两个主要策略实现这一目标：首先，它对一组私有输入的交易进行排序，并确保在整个区块生产过程中执行此排序，从而防止交易顺序被操纵；其次，PROF创建了在区块生产者中具有盈利性的交易集合，确保这些集合能够及时被纳入区块。

PROF系统具有向后兼容性，可以与现有的和未来的PBS设计协同工作，无需对PBS实体增加额外的信任假设。此外，PROF在执行效率上表现出色，具有低延迟特性。文中还详细分析了PROF的激励结构，并与现有解决方案进行了比较，提供了关于PROF交易纳入概率的定量和定性分析结果，以及通过端到端实现获得的具体延迟数据。总的来说，PROF为解决分布式金融应用中的MEV问题提供了一种有效且高效的方法。 <div>
arXiv:2408.02303v1 Announce Type: new 
Abstract: Users of decentralized finance (DeFi) applications face significant risks from adversarial actions that manipulate the order of transactions to extract value from users. Such actions -- an adversarial form of what is called maximal-extractable value (MEV) -- impact both individual outcomes and the stability of the DeFi ecosystem. MEV exploitation, moreover, is being institutionalized through an architectural paradigm known Proposer-Builder Separation (PBS).
  This work introduces a system called PROF (PRotected Order Flow) that is designed to limit harmful forms of MEV in existing PBS systems. PROF aims at this goal using two ideas. First, PROF imposes an ordering on a set ("bundle") of privately input transactions and enforces that ordering all the way through to block production -- preventing transaction-order manipulation. Second, PROF creates bundles whose inclusion is profitable to block producers, thereby ensuring that bundles see timely inclusion in blocks.
  PROF is backward-compatible, meaning that it works with existing and future PBS designs. PROF is also compatible with any desired algorithm for ordering transactions within a PROF bundle (e.g., first-come, first-serve, fee-based, etc.). It executes efficiently, i.e., with low latency, and requires no additional trust assumptions among PBS entities. We quantitatively and qualitatively analyze incentive structure of PROF, and its utility to users compared with existing solutions. We also report on inclusion likelihood of PROF transactions, and concrete latency numbers through our end-to-end implementation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>XDC Network Assessment: Decentralization, Scalability and Security</title>
<link>https://arxiv.org/abs/2408.02318</link>
<guid>https://arxiv.org/abs/2408.02318</guid>
<content:encoded><![CDATA[
<div> 关键词：XinFin、XDC网络、XDC基金会、Nakamoto系数、去中心化评估

总结:

文章探讨了XinFin在2019年发布的XDC网络，这是一个企业级的混合区块链平台，专为现实世界的去中心化金融提供代币化服务。XDC网络由XDC基金会管理，该非营利组织旨在通过社区驱动项目促进XDC网络的增长、增强和采用。文章重点分析了XDC网络实时评估的去中心化、可扩展性和安全性方面，并提出了Nakamoto系数估计，这是一种衡量去中心化系统分散程度的方法，量化了最小节点或实体数量以破坏系统的可能性。高系数表明更高的分散性，而低数字则表示增加的破坏风险。XDC网络的实时计算高Nakamoto系数证明了其高度分散的特性。

文章还讨论了共识和执行客户端的多样性、主机分布、地理分布以及一些突出的问题和业务考虑。XDC网络强调了去中心化的重要性，并展示了其通过技术创新和社区合作实现这一目标的能力。此外，文章提到了XDC基金会的角色及其对推动XDC网络发展的贡献，包括通过GitHub等平台支持的社区项目。这些努力旨在解决当前区块链领域面临的挑战，如可扩展性和安全性问题，并促进更广泛的采用。 <div>
arXiv:2408.02318v1 Announce Type: new 
Abstract: XinFin, in 2019, unveiled the XDC network, an enterprise-ready hybrid blockchain platform that is open-source and specializes in tokenization for real-world decentralized finance. Overseeing the XDC network is currently the XDC Foundation, a non-profit organization established to encourage the growth, enhancement, and adoption of the XDC Network through community-driven projects such as GitHub. This whitepaper discusses the real-time assessment of the XDC network's decentralization, scalability, and security aspects as well as the Nakamoto coefficient estimation that follows, which is a measure of a decentralized system's decentralization nature that quantifies the minimal number of nodes or entities needed to compromise the system. A high coefficient denotes greater decentralization, while a low number denotes increased disruption risk. The XDC network's real-time computation of the high Nakamoto coefficient demonstrates its highly decentralized character. The article also addresses the diversity of consensus and execution clients, the host distribution, the geo-distribution, and some of the outstanding issues and business considerations.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Online Fair Allocation with Best-of-Many-Worlds Guarantees</title>
<link>https://arxiv.org/abs/2408.02403</link>
<guid>https://arxiv.org/abs/2408.02403</guid>
<content:encoded><![CDATA[
<div> 关键词：在线公平分配、PACe算法、非参数模型、最佳多世界保证、真实世界数据

总结:

本文探讨了在线公平分配问题，特别是在物品以序列形式到达的情况下，如何平衡公平与效率。研究提出了一种名为PACe（Pacing According to Current Estimated utility）的无约束动态分配算法，该算法无需任何关于输入的先验知识，仅使用整数分配。PACe算法在静态、非静态和对抗性输入类型下均能实现近最优收敛或近似保证，从而首次实现了在线公平分配的最佳多世界保证。

PACe算法不仅具有理论上的优越性，而且非常简单、高效且去中心化，因此预计在各种实际场景中表现良好。数值结果表明，PACe算法在多种输入模型下均表现出色。研究还发现，即使在数据中出现高度非静态的真实时间到达情况，PACe算法也能在两个真实世界数据集上表现出优异性能。 <div>
arXiv:2408.02403v1 Announce Type: new 
Abstract: We investigate the online fair allocation problem with sequentially arriving items under various input models, with the goal of balancing fairness and efficiency. We propose the unconstrained PACE (Pacing According to Current Estimated utility) algorithm, a parameter-free allocation dynamic that requires no prior knowledge of the input while using only integral allocations. PACE attains near-optimal convergence or approximation guarantees under stationary, stochastic-but-nonstationary, and adversarial input types, thereby achieving the first best-of-many-worlds guarantee in online fair allocation. Beyond theoretical bounds, PACE is highly simple, efficient, and decentralized, and is thus likely to perform well on a broad range of real-world inputs. Numerical results support the conclusion that PACE works well under a variety of input models. We find that PACE performs very well on two real-world datasets even under the true temporal arrivals in the data, which are highly nonstationary.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CLVR Ordering of Transactions on AMMs</title>
<link>https://arxiv.org/abs/2408.02634</link>
<guid>https://arxiv.org/abs/2408.02634</guid>
<content:encoded><![CDATA[
<div> 关键词：自动市场制作商（AMM）、交易顺序、价格稳定性、不平等、Clever Look-ahead Volatility Reduction（CLVR）算法

总结:

本文探讨了在去中心化交易所通过自动市场制作商（AMM）机制进行交易时的一个关键挑战——如何以“最优”方式安排交易顺序。研究发现，交易顺序对价格稳定性和不平等度有显著影响，因此选择一种平衡这两者的方法对于政策制定者至关重要。然而，为了实现这种平衡，可能会产生高昂的成本，尤其是在对交易排序进行全面搜索时。

为了解决这个问题，作者提出了一种名为Clever Look-ahead Volatility Reduction（CLVR）的简单算法。该算法旨在构建一个能够大约最小化价格波动性的排序方案，同时具有较低的计算成本。通过应用CLVR算法，可以优化交易顺序，从而提高市场的效率和公平性。

此外，文章还分析了如果交易者受到这种排序策略的影响，其交易策略可能会发生的变化。这些变化有助于理解在实施CLVR算法后市场行为的潜在调整。总之，本文为去中心化交易所中的交易顺序优化提供了一个实用的解决方案，有助于促进更稳定、更公平的市场环境。 <div>
arXiv:2408.02634v1 Announce Type: new 
Abstract: Trading on decentralized exchanges via an Automated Market Maker (AMM) mechanism has been massively adopted, with a daily trading volume reaching $1B. This trading method has also received close attention from researchers, central banks, and financial firms, who have the potential to adopt it to traditional financial markets such as foreign exchanges and stock markets. A critical challenge of AMM-powered trading is that transaction order has high financial value, so a policy or method to order transactions in a "good" (optimal) manner is vital. We offer economic measures of both price stability (low volatility) and inequality that inform how a "social planner" should pick an optimal ordering. We show that there is a trade-off between achieving price stability and reducing inequality, and that policymakers must choose which to prioritize. In addition, picking the optimal order can often be costly, especially when performing an exhaustive search over trade orderings (permutations). As an alternative we provide a simple algorithm, Clever Look-ahead Volatility Reduction (CLVR). This algorithm constructs an ordering which approximately minimizes price volatility with a small computation cost. We also provide insight into the strategy changes that may occur if traders are subject to this sequencing algorithm.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Trade-off of Security, Latency, and Throughput of the Nakamoto Consensus</title>
<link>https://arxiv.org/abs/2312.05506</link>
<guid>https://arxiv.org/abs/2312.05506</guid>
<content:encoded><![CDATA[
<div> 关键词：PoW、最长链规则、交易安全、延迟、吞吐量

总结:
本文深入探讨了工作量证明（PoW）最长链选择协议中的安全、延迟和吞吐量之间的基本权衡，即所谓的Nakamoto共识。研究通过新推导的交易安全违反概率的上界和下界，作为诚实与敌对挖矿率、块传播延迟上限以及交易确认时间和深度的函数，揭示了这些关键因素的关系。特别地，该研究提供了适用于所有延迟和挖矿率参数的首次非平凡有限延迟封闭形式边界，直到最终容错极限。

文章发现了一个基本的交易吞吐量与确认延迟之间的权衡，这一权衡最终由所需的容错水平和随着区块大小增加块传播延迟的增长所决定。值得注意的是，新得出的上下界差距小于比特币及其衍生币如Litecoin、Dogecoin和Ethereum Classic等参数下的最佳差距范围。此外，该研究还揭示了交易安全、延迟与吞吐量之间的复杂关系，为区块链系统的设计提供了一定程度的理论指导。 <div>
arXiv:2312.05506v4 Announce Type: replace 
Abstract: This paper delves into the fundamental trade-off between security, latency, and throughput in proof-of-work (PoW) longest-chain-fork-choice protocols, also known as the PoW Nakamoto consensus. New upper and lower bounds on the probability of violating transaction safety are derived as a function of honest and adversarial mining rates, an upper bound on block propagation delays, and transaction confirmation latency, both in time and in block depth. The results include a first non-trivial closed-form finite-latency bound applicable to all delays and mining rates up to the ultimate fault tolerance. Notably, the gap between the upper and lower bounds is narrower than the best gaps previously established for a wide range of parameters relevant to Bitcoin and its derivatives such as Litecoin and Dogecoin, as well as for Ethereum Classic. Furthermore, the paper reveals a fundamental trade-off between transaction throughput and confirmation latency, ultimately determined by the desired fault tolerance and the growth of block propagation delay as block size increases.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Advanced Intelligent Optimization Algorithms for Multi-Objective Optimal Power Flow in Future Power Systems: A Review</title>
<link>https://arxiv.org/abs/2404.09203</link>
<guid>https://arxiv.org/abs/2404.09203</guid>
<content:encoded><![CDATA[
<div> 关键词：智能优化算法、多目标最优功率流、现代电力系统、可再生能源、智能电网

总结:
本文回顾了智能优化算法在提升现代电力系统中的多目标最优功率流(MOPF)应用，聚焦于进化算法、群体智能和深度强化学习。文章探讨了可再生能源、智能电网与日益增长的能源需求带来的挑战，分析了这些算法的有效性、可扩展性和应用情况。研究指出，算法选择应根据具体MOPF问题进行，而混合方法显示出巨大潜力。强调了标准测试系统在验证解决方案中的重要性以及软件工具在分析过程中的作用。未来研究方向包括利用机器学习实现动态优化、拥抱分散式能源系统和适应不断变化的政策框架，以提高电力系统的效率和可持续性。本文旨在通过展示当前最先进的方法学，促进对未来能源挑战的创新解决方案的发展。 <div>
arXiv:2404.09203v2 Announce Type: replace 
Abstract: This review explores the application of intelligent optimization algorithms to Multi-Objective Optimal Power Flow (MOPF) in enhancing modern power systems. It delves into the challenges posed by the integration of renewables, smart grids, and increasing energy demands, focusing on evolutionary algorithms, swarm intelligence, and deep reinforcement learning. The effectiveness, scalability, and application of these algorithms are analyzed, with findings suggesting that algorithm selection is contingent on the specific MOPF problem at hand, and hybrid approaches offer significant promise. The importance of standard test systems for verifying solutions and the role of software tools in facilitating analysis are emphasized. Future research is directed towards exploiting machine learning for dynamic optimization, embracing decentralized energy systems, and adapting to evolving policy frameworks to improve power system efficiency and sustainability. This review aims to advance MOPF research by highlighting state-of-the-art methodologies and encouraging the development of innovative solutions for future energy challenges.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Competitive Policies for Online Collateral Maintenance</title>
<link>https://arxiv.org/abs/2406.17121</link>
<guid>https://arxiv.org/abs/2406.17121</guid>
<content:encoded><![CDATA[
<div> 关键词：层二区块链协议、费用、存储成本、确认延迟、在线策略

总结:
本文探讨了在层二区块链协议中，如何通过制定在线策略来优化和管理结算与充值过程中的抵押品，以最大化已结算交易的价值。研究涉及两种模型：一种是针对具有通用抵押品政策的实体，该政策决定是否接收或丢弃每笔新交易以及何时补充抵押品；另一种则是针对将总抵押品分为k个等额子账户的离散模型，当某个子账户满载无法接收更多交易时，需要进行补充。

研究中提出了一系列在线策略，并将其与拥有完整未来交易流知识的理想（离线）策略进行了比较，以评估其性能。这是首次在区块链背景下系统地研究并建立在线竞争性策略来管理抵押品和账户的填充问题。这一工作为提高层二协议的效率和安全性提供了新的思路，对于提升用户体验和降低交易成本具有重要意义。 <div>
arXiv:2406.17121v2 Announce Type: replace 
Abstract: Layer-two blockchain protocols emerged to address scalability issues related to fees, storage cost, and confirmation delay of on-chain transactions. They aggregate off-chain transactions into a fewer on-chain ones, thus offering immediate settlement and reduced transaction fees. To preserve security of the underlying ledger, layer-two protocols often work in a collateralized model; resources are committed on-chain to backup off-chain activities. A fundamental challenge that arises in this setup is determining a policy for establishing, committing, and replenishing the collateral in a way that maximizes the value of settled transactions.
  In this paper, we study this problem under two settings that model collateralized layer-two protocols. The first is a general model in which a party has an on-chain collateral C with a policy to decide on whether to settle or discard each incoming transaction. The policy also specifies when to replenish C based on the remaining collateral value. The second model considers a discrete setup in which C is divided among k wallets, each of which is of size C/k, such that when a wallet is full, and so cannot settle any incoming transactions, it will be replenished. We devise several online policies for these models, and show how competitive they are compared to optimal (offline) policies that have full knowledge of the incoming transaction stream. To the best of our knowledge, we are the first to study and formulate online competitive policies for collateral and wallet management in the blockchain setting.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles</title>
<link>https://arxiv.org/abs/2406.19269</link>
<guid>https://arxiv.org/abs/2406.19269</guid>
<content:encoded><![CDATA[
<div> 关键词：Max-pressure、OCC-MP、乘客占用率、交通信号控制、公共交通优先

<br /><br />
总结:

本文提出了一种名为OCC-MP的新颖算法，它在Max-pressure（MP）的基础上进行了改进，旨在提高公共交通和其他高占用率车辆的优先级。OCC-MP考虑了车辆队列和乘客占用率，通过给具有更高乘客占用率的移动赋予更高的权重，隐式地为公共交通和其他HOV提供了优先权，同时考虑到这种优先权对单人占用率车辆可能产生的负面影响。与基于规则的传统公共交通信号优先策略不同，OCC-MP能够自然地适应信号交叉口上冲突的公共交通线路，并促进它们的移动，即使在没有专用车道的混合交通中也是如此。

在网格网络下进行的模拟实验表明，OCC-MP不仅有效地提供了公共交通优先服务，同时还能减少对低占用率私车的负面影响。与集成到MP框架中的基于规则的公共交通优先策略相比，OCC-MP拥有更大的稳定区域以适应需求变化。此外，当存在乘客占用率信息错误或无法获取私车乘客占用率信息时，OCC-MP仍能表现出良好的性能。最后，当一部分车辆能够向信号控制器提供信息并在部分连接车辆（CV）环境中应用时，OCC-MP能够超越基线方法，特别是在低CV渗透率情况下。 <div>
arXiv:2406.19269v2 Announce Type: replace 
Abstract: Max-pressure (MP) is a decentralized adaptive traffic signal control approach that has been shown to maximize throughput for private vehicles. However, MP-based signal control algorithms do not differentiate the movement of transit vehicles from private vehicles or between high and single-occupancy private vehicles. Prioritizing the movement of transit or other high occupancy vehicles (HOVs) is vital to reduce congestion and improve the reliability and efficiency of transit operations. This study proposes OCC-MP: a novel MP-based algorithm that considers both vehicle queues and passenger occupancies in computing the weights of movements. By weighing movements with higher passenger occupancies more heavily, transit and other HOVs are implicitly provided with priority, while accounting for any negative impacts of that priority on single occupancy vehicles. And, unlike rule-based transit signal priority (TSP) strategies, OCC-MP more naturally also accommodates conflicting transit routes at a signalized intersection and facilitates their movement, even in mixed traffic without dedicated lanes. Simulations on a grid network under varying demands and transit configurations demonstrate the effectiveness of OCC-MP at providing TSP while simultaneously reducing the negative impact imparted onto lower occupancy private vehicles. Furthermore, OCC-MP is shown to have a larger stable region for demand compared to rule-based TSP strategies integrated into the MP framework. The performance of OCC-MP is also shown to be robust to errors in passenger occupancy information from transit vehicles and can be applied when passenger occupancies of private vehicles are not available. Finally, OCC-MP can be applied in a partially connected vehicle (CV) environment when a subset of vehicles is able to provide information to the signal controller, outperforming baseline methods at low CV penetration rates.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On Game Based Distributed Decision Approach for Multi-agent Optimal Coverage Problem with Application to Constellations Reconfiguration</title>
<link>https://arxiv.org/abs/2408.01193</link>
<guid>https://arxiv.org/abs/2408.01193</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、分布式决策、覆盖优化问题、全局性能目标、近最优覆盖

总结:
本文探讨了多智能体系统中的最优覆盖问题(OCP)，并提出了一种基于游戏的分布式决策方法。通过严格证明游戏的均衡状态与全球性能目标的最大值等价，构建了一个仅需局部信息即可获得全局近最优覆盖的分布式算法，并证明了其收敛性。最后，将该方法应用于卫星星座对目标的最大覆盖时间问题中。不同场景下的模拟结果显示，在一定的索引级别下，这种方法的计算时间远少于传统的集中式优化方法。

文章首先引入了多智能体系统中的覆盖优化问题，并指出了解决这一问题的挑战在于如何在分散的信息环境中实现高效的全局优化。接着，作者提出了一种创新的解决方案——基于游戏的分布式决策框架。这一框架巧妙地利用了博弈论的工具，将复杂的问题转化为更易于解决的均衡问题。通过严格的数学证明，作者展示了游戏的均衡状态与全局性能目标的最大值之间存在等价关系，为后续的算法设计奠定了理论基础。

随后，文章设计了一种仅依赖局部信息的分布式算法，旨在求解全局近最优覆盖问题。这一算法的设计充分考虑了多智能体系统的特点，确保了在分散的环境中能够高效地进行决策。作者进一步证明了该算法的收敛性，即在有限时间内，系统能够找到接近全局最优解的状态。这种能力对于实时应用和大规模系统的管理至关重要。

最后，文章将所提出的分布式决策方法应用于实际问题中，即通过最大化卫星星座对特定目标的覆盖时间来验证方法的有效性和实用性。通过对比分析在不同场景下的模拟结果，文章显示了所提方法相较于传统集中式优化方法在计算效率上的显著优势。这不仅证明了方法的可行性和有效性，也为未来在多智能体系统优化问题中的应用提供了有力支持。 <div>
arXiv:2408.01193v1 Announce Type: new 
Abstract: This paper focuses on the optimal coverage problem (OCP) for multi-agent systems with decentralized optimization. A game based distributed decision approach for the the multi-agent OCP is proposed. The equivalence between the equilibrium of the game and the extreme value of the global performance objective is strictly proved. Then, a distributed algorithm only using local information to obtain the global near-optimal coverage is developed, and its convergence is proved. Finally, the proposed method is applied to maximize the covering time of a satellite constellation for a target. The simulation results under different scenarios show our method costs much less computation time under some level index than traditional centralized optimization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Smoothing ADMM for Quantile Regression with Non-Convex Sparse Penalties</title>
<link>https://arxiv.org/abs/2408.01307</link>
<guid>https://arxiv.org/abs/2408.01307</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、分布式数据、非凸惩罚、平滑交替方向乘子法、去噪变分范数

<br />
总结:本文针对物联网环境下分布式数据处理的挑战，提出了一种基于去噪变分范数的平滑交替方向乘子法（DSAD）用于惩罚量化回归。该方法采用非凸惩罚项如最小最大化凹惩罚（MCP）和光滑剪切绝对偏差（SCAD），以提高关键预测因子的识别与保留能力。DSAD在平滑交替方向乘子法框架下引入总变分范数，实现了分布式节点间的共识，并确保了异构数据源间模型性能的一致性。这一创新解决了传统非凸惩罚在分散设置中遇到的收敛问题。通过理论证明和大量模拟实验，证实了DSAD在实现可靠收敛和增强估计精度方面优于现有方法。 <div>
arXiv:2408.01307v1 Announce Type: new 
Abstract: In the rapidly evolving internet-of-things (IoT) ecosystem, effective data analysis techniques are crucial for handling distributed data generated by sensors. Addressing the limitations of existing methods, such as the sub-gradient approach, which fails to distinguish between active and non-active coefficients effectively, this paper introduces the decentralized smoothing alternating direction method of multipliers (DSAD) for penalized quantile regression. Our method leverages non-convex sparse penalties like the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD), improving the identification and retention of significant predictors. DSAD incorporates a total variation norm within a smoothing ADMM framework, achieving consensus among distributed nodes and ensuring uniform model performance across disparate data sources. This approach overcomes traditional convergence challenges associated with non-convex penalties in decentralized settings. We present theoretical proofs and extensive simulation results to validate the effectiveness of the DSAD, demonstrating its superiority in achieving reliable convergence and enhancing estimation accuracy compared with prior methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Spike Talk: Genesis and Neural Coding Scheme Translations</title>
<link>https://arxiv.org/abs/2408.00773</link>
<guid>https://arxiv.org/abs/2408.00773</guid>
<content:encoded><![CDATA[
<div> 关键词：数字电网、信息通信技术、微电网、神经科学、信号编码

总结:
本文提出了一种名为Spike Talk的新架构，旨在通过统一表示电力和信息，利用尖峰（spikes）进行微电网协调控制的数据规范化。该技术允许每个分布式能源资源（DER）独立执行分散式二级控制策略，通过沿互连线的功率流动相互交互。灵感源自计算神经科学，Spike Talk基于大脑中精细并行的信息传输理论，特别是在神经元（作为DER）通过突触（作为互连线）传递信息时。与当前的网络物理架构操作瓶颈相比，Spike Talk简化并提供了无需信息通信技术层的解决方案，从而在基础设施开发、计算和建模方面提供了内在的操作和成本效益机会。研究重点放在了协调控制微电网上，探讨了几种负责将本地测量值转换为尖峰的神经编码方案对信号准确性和系统性能的影响。 <div>
arXiv:2408.00773v1 Announce Type: cross 
Abstract: Although digitalization of future power grids offer several coordination incentives, the reliability and security of information and communication technologies (ICT) hinders its overall performance. In this paper, we introduce a novel architecture Spike Talk via a unified representation of power and information as a means of data normalization using spikes for coordinated control of microgrids. This grid-edge technology allows each distributed energy resource (DER) to execute decentralized secondary control philosophy independently by interacting among each other using power flow along the tie-lines. Inspired from the field of computational neuroscience, Spike Talk basically builds on a fine-grained parallelism on the information transfer theory in our brains, particularly when neurons (modeled as DERs) transmit information (inferred from power streams measurable at each DER) through synapses (modeled as tie-lines). Not only does Spike Talk simplify and address the current bottlenecks of the cyber-physical architectural operation by dismissing the ICT layer, it provides intrinsic operational and cost-effective opportunities in terms of infrastructure development, computations and modeling. Hence, this paper provides a pedagogic illustration of the key concepts and design theories. Since we focus on coordinated control of microgrids in this paper, the signaling accuracy and system performance is studied for several neural coding schemes responsible for converting the real-valued local measurements into spikes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Secure Targeted Message Dissemination in IoT Using Blockchain Enabled Edge Computing</title>
<link>https://arxiv.org/abs/2401.06384</link>
<guid>https://arxiv.org/abs/2401.06384</guid>
<content:encoded><![CDATA[
<div> 关键词：智能设备、物联网、区块链、边缘计算、单签加密

总结:

本文主要探讨了如何利用区块链技术与高级加密技术解决物联网（IoT）中智能设备间消息传播时所遇到的安全性、隐私性和性能问题。文章引入了一种名为STarEdgeChain的解决方案，该方案通过结合权限受限的区块链和边缘计算技术，实现对特定目标设备群组进行高效的一次性单签加密消息传播。这一方法避免了传统多点广播方式的依赖，提高了效率并减少了资源消耗。

STarEdgeChain设计的核心在于利用区块链的分布式账本特性确保信息的完整性和不可篡改性，同时通过边缘计算将数据处理和存储任务就近分配给智能设备，降低了延迟并减轻了中心服务器的压力。此外，采用单签加密技术增强了信息传输过程中的安全性，保护了数据免受未经授权的访问和修改。

为了验证STarEdgeChain的实际应用可行性，作者还开发了一个软件原型，并将其源代码公开在GitHub上，供研究者和开发者进一步研究和使用。这一开源策略不仅促进了技术的共享和创新，也为实际部署提供了实践基础。总体而言，STarEdgeChain为物联网环境下智能设备间的高效、安全和私密通信提供了一种创新解决方案。 <div>
arXiv:2401.06384v2 Announce Type: replace 
Abstract: Smart devices are considered as an integral part of Internet of Things (IoT), have an aim to make a dynamic network to exchange information, collect data, analysis, and make optimal decisions in an autonomous way to achieve more efficient, automatic, and economical services. Message dissemination among these smart devices allows adding new features, sending updated instructions, alerts or safety messages, informing the pricing information or billing amount, incentives, and installing security patches. On one hand, such message disseminations are directly beneficial to the all parties involved in the IoT system. On the other hand, due to remote procedure, smart devices, vendors, and other involved authorities might have to meet a number of security, privacy, and performance related concerns while disseminating messages among targeted devices. To this end, in this paper, we design STarEdgeChain, a security and privacy aware targeted message dissemination in IoT to show how blockchain along with advanced cryptographic techniques are devoted to address such concerns. In fact, the STarEdgeChain employs a permissioned blockchain assisted edge computing in order to expedite a single signcrypted message dissemination among targeted groups of devices, at the same time avoiding the dependency of utilizing multiple unicasting approaches. Finally, we develop a software prototype of STarEdgeChain and show it's practicability for smart devices. The codes are publicly available at https://github.com/mbaqer/Blockchain-IoT
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Empirical Analysis of EIP-3675: Miner Dynamics, Transaction Fees, and Transaction Time</title>
<link>https://arxiv.org/abs/2403.17885</link>
<guid>https://arxiv.org/abs/2403.17885</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP-3675、矿工动态、用户优先费、网络去中心化、机器学习模型

<br /><br />
总结:

文章主要探讨了Ethereum改进提案3675(EIP-3675)对以太坊从工作量证明(PoW)转向权益证明(PoS)共识机制的影响。研究发现，这一转变导致了矿工参与度和分布的变化，矿工群体数量显著增加，提高了网络的去中心化程度。然而，这一变化也带来了一个意外的后果——矿工选择的随机性降低，这可能削弱了网络的去中心化性质。

在处理用户如何确定优先费用的问题上，研究采用了基于回归的机器学习模型进行预测。结果显示，梯度提升回归器表现最佳，而K-近邻回归器效果最差。这意味着在EIP-3675实施后，矿工动态的调整对提高网络效率和安全性具有潜在影响，同时对用户决策过程中的优先费用设置提出了挑战，需要更精确的预测模型来辅助决策，以平衡能源消耗与网络性能之间的关系。 <div>
arXiv:2403.17885v2 Announce Type: replace 
Abstract: The Ethereum Improvement Proposal 3675 (EIP-3675) marks a significant shift, transitioning from a Proof of Work (PoW) to a Proof of Stake (PoS) consensus mechanism. This transition resulted in a staggering 99.95% decrease in energy consumption. However, the transition prompts two critical questions: (1). How does EIP-3675 affect miners' dynamics? and (2). How do users determine priority fees, considering that paying too little may cause delays or non-inclusion, yet paying too much wastes money with little to no benefits? To address the first question, we present a comprehensive empirical study examining EIP-3675's effect on miner dynamics (i.e., miner participation, distribution, and the degree of randomness in miner selection). Our findings reveal that the transition has encouraged broader participation of miners in block append operation, resulting in a larger pool of unique miners ($\approx50\times$ PoW), and the change in miner distribution with the increased number of unique small category miners ($\approx60\times$ PoW). However, there is an unintended consequence: a reduction in the miner selection randomness, which signifies the negative impact of the transition to PoS-Ethereum on network decentralization. Regarding the second question, we employed regression-based machine learning models; the Gradient Boosting Regressor performed best in predicting priority fees, while the K-Neighbours Regressor was worst.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Load Balancing in Federated Learning</title>
<link>https://arxiv.org/abs/2408.00217</link>
<guid>https://arxiv.org/abs/2408.00217</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Age of Information、Markov调度策略、资源利用、数据隐私

<br />
<br />
总结:
本文提出了一种基于年龄信息的负载度量方法，旨在为联邦学习(Federated Learning, FL)中的设备调度提供依据。面对有限的通信资源和设备间数据异质性等挑战，该文通过最小化负载度量的方差，实现公平的工作负载分配与高效资源使用。此外，引入了一种去中心化的马尔可夫调度策略，该策略确保了负载的均衡分布，并通过使每个客户端独立决策来消除大规模网络管理的开销。通过建立马尔可夫链模型并优化其参数，文中的方法被验证有效。实验证明，减少负载度量的方差不仅能提升系统的公平性和运行效率，还能加速学习模型的收敛速度。此研究为联邦学习中的设备调度提供了理论与实践上的新视角。 <div>
arXiv:2408.00217v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning framework that enables learning from data distributed across multiple remote devices, enhancing communication efficiency and data privacy. Due to limited communication resources, a scheduling policy is often applied to select a subset of devices for participation in each FL round. The scheduling process confronts significant challenges due to the need for fair workload distribution, efficient resource utilization, scalability in environments with numerous edge devices, and statistically heterogeneous data across devices. This paper proposes a load metric for scheduling policies based on the Age of Information and addresses the above challenges by minimizing the load metric variance across the clients. Furthermore, a decentralized Markov scheduling policy is presented, that ensures a balanced workload distribution while eliminating the management overhead irrespective of the network size due to independent client decision-making. We establish the optimal parameters of the Markov chain model and validate our approach through simulations. The results demonstrate that reducing the load metric variance not only promotes fairness and improves operational efficiency, but also enhances the convergence rate of the learning models.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Survey on the Applications of Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2408.00243</link>
<guid>https://arxiv.org/abs/2408.00243</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明（ZKP）、zk-SNARKS、区块链隐私、零知识虚拟机（zkVM）、非区块链应用

<br /><br />
总结:
本文是一篇关于零知识证明（ZKP）的综述性文章，重点探讨了ZKP在分布式系统中的独特优势，特别是与同态加密和安全多方计算等其他隐私敏感计算方法相比。ZKP在区块链技术中用于增强隐私，同时在存储、可扩展性和跨链互操作性方面也发挥着关键作用。此外，它们在非区块链领域如投票、身份验证、定时器和机器学习的应用也日益广泛。

文章首先介绍了ZKP的基本工作原理，并特别关注了一种称为zk-SNARKS的越来越重要的ZKP子集。随后，它讨论了ZKP在实践中的应用，包括各种领域，如区块链隐私、可扩展性、存储、跨链交互以及非区块链应用如投票、身份验证、定时器和机器学习。

为了支持这些应用，文章还涵盖了基础组件和基础设施，如零知识虚拟机（zkVM）、领域特定语言（DSL）、支持库、框架和协议。最后，文章展望了ZKP未来的发展方向，强调了它们在加密实践和数字隐私领域的重要性。 <div>
arXiv:2408.00243v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKPs) represent a revolutionary advance in computational integrity and privacy technology, enabling the secure and private exchange of information without revealing underlying private data. ZKPs have unique advantages in terms of universality and minimal security assumptions when compared to other privacy-sensitive computational methods for distributed systems, such as homomorphic encryption and secure multiparty computation. Their application spans multiple domains, from enhancing privacy in blockchain to facilitating confidential verification of computational tasks. This survey starts with a high-level overview of the technical workings of ZKPs with a focus on an increasingly relevant subset of ZKPs called zk-SNARKS. While there have been prior surveys on the algorithmic and theoretical aspects of ZKPs, our work is distinguished by providing a broader view of practical aspects and describing many recently-developed use cases of ZKPs across various domains. These application domains span blockchain privacy, scaling, storage, and interoperability, as well as non-blockchain applications like voting, authentication, timelocks, and machine learning. Aimed at both practitioners and researchers, the survey also covers foundational components and infrastructure such as zero-knowledge virtual machines (zkVM), domain-specific languages (DSLs), supporting libraries, frameworks, and protocols. We conclude with a discussion on future directions, positioning ZKPs as pivotal in the advancement of cryptographic practices and digital privacy across many applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision</title>
<link>https://arxiv.org/abs/2408.00641</link>
<guid>https://arxiv.org/abs/2408.00641</guid>
<content:encoded><![CDATA[
arXiv:2408.00641v1 Announce Type: new 
Abstract: The rampant fraudulent activities on Ethereum hinder the healthy development of the blockchain ecosystem, necessitating the reinforcement of regulations. However, multiple imbalances involving account interaction frequencies and interaction types in the Ethereum transaction environment pose significant challenges to data mining-based fraud detection research. To address this, we first propose the concept of meta-interactions to refine interaction behaviors in Ethereum, and based on this, we present a dual self-supervision enhanced Ethereum fraud detection framework, named Meta-IFD. This framework initially introduces a generative self-supervision mechanism to augment the interaction features of accounts, followed by a contrastive self-supervision mechanism to differentiate various behavior patterns, and ultimately characterizes the behavioral representations of accounts and mines potential fraud risks through multi-view interaction feature learning. Extensive experiments on real Ethereum datasets demonstrate the effectiveness and superiority of our framework in detecting common Ethereum fraud behaviors such as Ponzi schemes and phishing scams. Additionally, the generative module can effectively alleviate the interaction distribution imbalance in Ethereum data, while the contrastive module significantly enhances the framework's ability to distinguish different behavior patterns. The source code will be released on GitHub soon.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Algorithms for Collaborative Machine Learning under Statistical Heterogeneity</title>
<link>https://arxiv.org/abs/2408.00050</link>
<guid>https://arxiv.org/abs/2408.00050</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、联邦学习、统计异质性、个性化方法、合成数据生成

总结:

本文主要探讨了在分布式数据环境中进行机器学习时面临的主要挑战，尤其是统计异质性问题。提出了三种解决策略来应对这一挑战：

1. **个性化方法**：“SuPerFed”：这是一种基于模式连通性的新颖个性化方法，旨在通过连接不同数据集中的模式，提高模型的泛化能力，特别是针对具有不同数据分布的客户端。

2. **适应性决策算法**：“AAggFF”：该算法采用在线凸优化框架，通过调整参与客户端的混合系数，以实现性能分布的一致性，从而改善整体模型性能。

3. **协作合成数据生成**：“FedEvg”：利用能量基模拟能力的灵活性和组合性，生成用于训练的合成数据，帮助减少统计异质性对模型性能的影响。

这些方法共同提供了分布式系统中协作机器学习应用的有效解决方案，有助于克服数据分散带来的挑战，推动分布式系统的进一步发展与应用。 <div>
arXiv:2408.00050v1 Announce Type: cross 
Abstract: Learning from distributed data without accessing them is undoubtedly a challenging and non-trivial task. Nevertheless, the necessity for distributed training of a statistical model has been increasing, due to the privacy concerns of local data owners and the cost in centralizing the massively distributed data. Federated learning (FL) is currently the de facto standard of training a machine learning model across heterogeneous data owners, without leaving the raw data out of local silos. Nevertheless, several challenges must be addressed in order for FL to be more practical in reality. Among these challenges, the statistical heterogeneity problem is the most significant and requires immediate attention. From the main objective of FL, three major factors can be considered as starting points -- \textit{parameter}, textit{mixing coefficient}, and \textit{local data distributions}. In alignment with the components, this dissertation is organized into three parts. In Chapter II, a novel personalization method, \texttt{SuPerFed}, inspired by the mode-connectivity is introduced. In Chapter III, an adaptive decision-making algorithm, \texttt{AAggFF}, is introduced for inducing uniform performance distributions in participating clients, which is realized by online convex optimization framework. Finally, in Chapter IV, a collaborative synthetic data generation method, \texttt{FedEvg}, is introduced, leveraging the flexibility and compositionality of an energy-based modeling approach. Taken together, all of these approaches provide practical solutions to mitigate the statistical heterogeneity problem in data-decentralized settings, paving the way for distributed systems and applications using collaborative machine learning methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reputation Gaming in Stack Overflow</title>
<link>https://arxiv.org/abs/2111.07101</link>
<guid>https://arxiv.org/abs/2111.07101</guid>
<content:encoded><![CDATA[
<div> 关键词：Stack Overflow、声誉操纵、算法、用户行为、平台管理

总结:

文章主要探讨了Stack Overflow平台上的声誉系统可能面临的操纵问题。通过分析1,697篇来自Meta Stack Exchange网站的帖子，研究发现了四种声誉欺诈场景，包括投票圈等。为了帮助平台管理者识别可疑的声誉游戏行为，文章开发了两种算法：一种用于识别可能存在声誉欺诈的孤立或半孤立社区，另一种则关注用户声誉分数突然异常增长的情况。

这些算法的性能通过检查Stack Overflow网站上用户的声誉历史记录进行了评估，结果显示，大约有60%-80%被算法标记为可疑的用户最终经历了声誉分数的减少。这一研究强调了Stack Overflow等问答平台在面对声誉操纵时所面临的挑战，并提出了有效监控和防止此类行为的方法，对于提升平台内容质量和用户行为的规范具有重要意义。 <div>
arXiv:2111.07101v2 Announce Type: replace 
Abstract: Stack Overflow incentive system awards users with reputation scores to ensure quality. The decentralized nature of the forum may make the incentive system prone to manipulation. This paper offers, for the first time, a comprehensive study of the reported types of reputation manipulation scenarios that might be exercised in Stack Overflow and the prevalence of such reputation gamers by a qualitative study of 1,697 posts from meta Stack Exchange sites. We found four different types of reputation fraud scenarios, such as voting rings where communities form to upvote each other repeatedly on similar posts. We developed algorithms that enable platform managers to automatically identify these suspicious reputation gaming scenarios for review. The first algorithm identifies isolated/semi-isolated communities where probable reputation frauds may occur mostly by collaborating with each other. The second algorithm looks for sudden unusual big jumps in the reputation scores of users. We evaluated the performance of our algorithms by examining the reputation history dashboard of Stack Overflow users from the Stack Overflow website. We observed that around 60-80% of users flagged as suspicious by our algorithms experienced reductions in their reputation scores by Stack Overflow.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FL-DECO-BC: A Privacy-Preserving, Provably Secure, and Provenance-Preserving Federated Learning Framework with Decentralized Oracles on Blockchain for VANETs</title>
<link>https://arxiv.org/abs/2407.21141</link>
<guid>https://arxiv.org/abs/2407.21141</guid>
<content:encoded><![CDATA[
<div> 关键词：VANETs、Federated Learning（FL）、区块链、数据隐私、安全

<br /><br />
总结:本文提出了一种名为FL-DECO-BC的新型隐私保护、可验证安全和可追溯性保护的联邦学习框架，专门针对车辆自组网络(VANETs)。该框架利用区块链上的去中心化仲裁机构安全访问外部数据源，同时通过高级技术确保数据隐私。FL-DECO-BC通过加密原语和形式验证方法提供了可证明的安全性。此外，该框架还集成了可追溯设计，用于追踪数据来源和历史记录，从而建立信任和责任机制。这种结合特性赋予了VANETs安全和隐私意识的机器学习能力，为先进的交通管理和安全应用铺平了道路。 <div>
arXiv:2407.21141v1 Announce Type: new 
Abstract: Vehicular Ad-Hoc Networks (VANETs) hold immense potential for improving traffic safety and efficiency. However, traditional centralized approaches for machine learning in VANETs raise concerns about data privacy and security. Federated Learning (FL) offers a solution that enables collaborative model training without sharing raw data. This paper proposes FL-DECO-BC as a novel privacy-preserving, provably secure, and provenance-preserving federated learning framework specifically designed for VANETs. FL-DECO-BC leverages decentralized oracles on blockchain to securely access external data sources while ensuring data privacy through advanced techniques. The framework guarantees provable security through cryptographic primitives and formal verification methods. Furthermore, FL-DECO-BC incorporates a provenance-preserving design to track data origin and history, fostering trust and accountability. This combination of features empowers VANETs with secure and privacy-conscious machine-learning capabilities, paving the way for advanced traffic management and safety applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach</title>
<link>https://arxiv.org/abs/2407.21294</link>
<guid>https://arxiv.org/abs/2407.21294</guid>
<content:encoded><![CDATA[
<div> 关键词：稳定匹配、分散式学习、纳什均衡、指数权重学习、局部收敛

总结:

本文研究了在全分散式和无协调的情况下学习稳定匹配的问题。具体来说，文章探讨了男性和女性各N人的情况，他们对对方有偏好，但男性并不知道女性对他们的偏好，只有在提出并成功匹配给女性后才能得知。稳定匹配指的是没有男性和女性会更喜欢彼此而非其当前匹配。

在已知偏好时，Gale和Shapley提出的递延接受算法提供了一种分散式和无协调的稳定匹配算法。然而，当偏好未知时，由于缺乏协调，开发这样的算法面临重大挑战。文章通过将稳定匹配问题与非合作博弈中的纳什均衡联系起来，实现了这一目标。首先，提出了一个完全信息博弈形式，其中纯纳什均衡与稳定匹配相匹配，混合纳什均衡可以通过分散方式转换为稳定匹配。

对于层级市场，采用指数权重（EXP）学习算法实现稳定匹配的学习，具有对玩家数量的多项式依赖的对数遗憾。此外，对于一般匹配市场，同样的EXP学习算法在局部以指数级速度收敛到稳定匹配。为了弥补这一点，文章引入了一个新的分散式和无协调学习算法，该算法在全球范围内以任意高概率收敛到稳定匹配，利用了稳定匹配游戏的弱循环性。 <div>
arXiv:2407.21294v1 Announce Type: new 
Abstract: We consider the problem of learning stable matchings in a fully decentralized and uncoordinated manner. In this problem, there are $n$ men and $n$ women, each having preference over the other side. It is assumed that women know their preferences over men, but men are not aware of their preferences over women, and they only learn them if they propose and successfully get matched to women. A matching is called stable if no man and woman prefer each other over their current matches. When all the preferences are known a priori, the celebrated Deferred-Acceptance algorithm proposed by Gale and Shapley provides a decentralized and uncoordinated algorithm to obtain a stable matching. However, when the preferences are unknown, developing such an algorithm faces major challenges due to a lack of coordination. We achieve this goal by making a connection between stable matchings and learning Nash equilibria (NE) in noncooperative games. First, we provide a complete information game formulation for the stable matching problem with known preferences such that its set of pure NE coincides with the set of stable matchings, while its mixed NE can be rounded in a decentralized manner to a stable matching. Relying on such a game-theoretic formulation, we show that for hierarchical markets, adopting the exponential weight (EXP) learning algorithm for the stable matching game achieves logarithmic regret with polynomial dependence on the number of players, thus answering a question posed in previous literature. Moreover, we show that the same EXP learning algorithm converges locally and exponentially fast to a stable matching in general matching markets. We complement this result by introducing another decentralized and uncoordinated learning algorithm that globally converges to a stable matching with arbitrarily high probability, leveraging the weak acyclicity property of the stable matching game.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Games in Public Announcement: How to Reduce System Losses in Optimistic Blockchain Mechanisms</title>
<link>https://arxiv.org/abs/2407.21413</link>
<guid>https://arxiv.org/abs/2407.21413</guid>
<content:encoded><![CDATA[
<div> 关键词：公告游戏、验证者、乐观汇总、游戏理论模型、机制优化

文章主要探讨了公告游戏的概念及其在现实世界中的应用，以乐观汇总为例进行了详细分析。乐观汇总是一种区块链扩展解决方案，通过公告发布者和验证者的互动提高了交易吞吐量和成本效益。作者构建了一个基于游戏理论的模型来研究参与者的潜在行为，识别了所有纳什均衡，并分析了不同纳什均衡下的系统损失。同时，他们还研究了系统参数如何影响纳什均衡下的系统损失，并提出了减少系统损失的机制优化建议。

总结:
文章首先介绍了公告游戏的概念及其在区块链技术中的应用，特别是以乐观汇总为例说明了这种游戏机制如何提高交易效率。接着，作者利用游戏理论构建模型，深入分析了公告游戏中的参与者行为，特别是公告发布者与验证者之间的动态关系。通过识别纳什均衡并分析其系统损失，文章揭示了在不同策略组合下系统的实际表现。此外，文章还探讨了系统参数对纳什均衡下系统损失的影响，为理解公告游戏的复杂性提供了理论依据。最后，基于上述分析结果，文章提出了一系列机制优化建议，旨在降低系统损失，提升整体效率。这些研究成果不仅对于理解公告游戏的内在机制具有重要意义，也为未来区块链技术的发展提供了宝贵的参考。 <div>
arXiv:2407.21413v1 Announce Type: new 
Abstract: Announcement games, where information is disseminated by announcers and challenged by validators, are prevalent in real-world scenarios. Validators take effort to verify the validity of the announcements, gaining rewards for successfully challenging invalid ones, while receiving nothing for valid ones. Optimistic Rollup, a Layer 2 blockchain scaling solution, exemplifies such games, offering significant improvements in transaction throughput and cost efficiency. We present a game-theoretic model of announcement games to analyze the potential behaviors of announcers and validators. We identify all Nash equilibria and study the corresponding system losses for different Nash equilibria. Additionally, we analyze the impact of various system parameters on system loss under the Nash equilibrium. Finally, we provide suggestions for mechanism optimization to reduce system losses.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Self-Sovereign Identity for Consented and Content-Based Access to Medical Records using Blockchain</title>
<link>https://arxiv.org/abs/2407.21559</link>
<guid>https://arxiv.org/abs/2407.21559</guid>
<content:encoded><![CDATA[
<div> 关键词：电子健康记录（EHRs）、区块链、自主权身份（SSI）、分散式标识符（DID）、属性基于加密（ABE）

总结:本文提出了一种基于区块链的解决方案，旨在安全地交换不同实体之间的电子健康记录（EHRs）。该方案结合了自主权身份（SSI）钱包和分散式标识符（DID），以及由用户完全控制的医疗数据。通过使用加密技术，用户可以在安全通信通道中以完全保密的方式共享其医疗数据。同时，利用IPFS网络进行离链存储，并通过属性基于加密（ABE）确保数据的机密性和完整性。此外，通过DID的使用增强用户隐私，并通过使用对等DID来限制任何可能的相关性或身份识别。整体而言，此方案保证了EHRs的安全交换、存储和管理，并从技术栈中继承了设计时的安全特性。 <div>
arXiv:2407.21559v1 Announce Type: new 
Abstract: Electronic Health Records (EHRs) and Medical Data are classified as personal data in every privacy law, meaning that any related service that includes processing such data must come with full security, confidentiality, privacy and accountability. Solutions for health data management, as in storing it, sharing and processing it, are emerging quickly and were significantly boosted by the Covid-19 pandemic that created a need to move things online. EHRs makes a crucial part of digital identity data, and the same digital identity trends -- as in self sovereign identity powered by decentralized ledger technologies like Blockchain, are being researched or implemented in contexts managing digital interactions between health facilities, patients and health professionals. In this paper, we propose a blockchain-based solution enabling secure exchange of EHRs between different parties powered by a self-sovereign identity (SSI) wallet and decentralized identifiers. We also make use of a consortium IPFS network for off-chain storage and attribute-based encryption (ABE) to ensure data confidentiality and integrity. Through our solution, we grant users full control over their medical data, and enable them to securely share it in total confidentiality over secure communication channels between user wallets using encryption. We also use DIDs for better user privacy and limit any possible correlations or identification by using pairwise DIDs. Overall, combining this set of technologies guarantees secure exchange of EHRs, secure storage and management along with by-design features inherited from the technological stack.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation</title>
<link>https://arxiv.org/abs/2407.21739</link>
<guid>https://arxiv.org/abs/2407.21739</guid>
<content:encoded><![CDATA[
<div> 关键词：基础模型、医疗影像分析、隐私保护、联邦学习、参数高效微调

总结:

本文研究了一种结合参数高效微调(PEFT)与联邦学习(Federated Learning, FL)的方法，以解决在医疗图像分析中调整基础模型时面临的通信成本高和数据隐私问题。通过在联邦环境下使用低秩适配器(Low-Rank Adapters, LoRA)，作者对“段任何模型”(Segment Anything Model, SAM)进行了适应性调整，用于3D医学图像分割任务。与以往工作不同的是，他们深入分析了SAM中每个组件在微调性能上的贡献，并识别出特定层进行联邦化，以保持通信成本低同时保证准确度。

在Fed-KiTS数据集上，该方法将通信成本降低了约48倍，同时提高了约6%的Dice分数。与SAMed相比，这种方法在通信量和需要微调的参数数量上分别实现了约2.8倍和2.8倍的减少。进一步地，通过在Fed-IXI和前列腺MRI数据集上的实验验证了其有效性。

主要贡献包括：

1. 提出了结合PEFT与FL的策略，以降低通信成本和提高效率。
2. 使用LoRA进行适应性调整，以优化3D医学图像分割任务。
3. 通过深入分析确定了关键层进行联邦化，以平衡通信成本和准确性。
4. 在多个数据集上展示了方法的有效性和优越性。
5. 实现了与现有方法相比显著的通信和参数减少，同时保持或提升性能。 <div>
arXiv:2407.21739v1 Announce Type: new 
Abstract: Adapting foundation models for medical image analysis requires finetuning them on a considerable amount of data because of extreme distribution shifts between natural (source) data used for pretraining and medical (target) data. However, collecting task-specific medical data for such finetuning at a central location raises many privacy concerns. Although Federated learning (FL) provides an effective means for training on private decentralized data, communication costs in federating large foundation models can quickly become a significant bottleneck, impacting the solution's scalability. In this work, we address this problem of efficient communication while ensuring effective learning in FL by combining the strengths of Parameter-Efficient Fine-tuning (PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA) in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical image segmentation. Unlike prior works that utilize LoRA and finetune the entire decoder, we critically analyze the contribution of each granular component of SAM on finetuning performance. Thus, we identify specific layers to be federated that are very efficient in terms of communication cost while producing on-par accuracy. Our experiments show that retaining the parameters of the SAM model (including most of the decoder) in their original state during adaptation is beneficial because fine-tuning on small datasets tends to distort the inherent capabilities of the underlying foundation model. On Fed-KiTS, our approach decreases communication cost (~48x) compared to full fine-tuning while increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach performs similar to SAMed while achieving ~2.8x reduction in communication and parameters to be finetuned. We further validate our approach with experiments on Fed-IXI and Prostate MRI datasets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Naeural AI OS -- Decentralized ubiquitous computing MLOps execution engine</title>
<link>https://arxiv.org/abs/2306.08708</link>
<guid>https://arxiv.org/abs/2306.08708</guid>
<content:encoded><![CDATA[
<div> 关键词：普遍计算、人工智能、深度学习、低代码开发、分布式社区

总结:
本文提出了一种创新的方法，旨在解决大规模采用人工智能（AI）和深度学习所面临的挑战。主要问题在于高昂的云基础设施成本以及对复杂数据科学和机器学习专业知识的需求。为了解决这些问题，作者提出了一种针对最终用户需求的低代码AI应用开发与部署策略。这种策略通过在分布式全球合作社区中利用基于代币经济的机制来优化基础设施分配、成本控制以及安全任务分发。具体来说，这种方法旨在降低AI系统的构建和运行成本，同时确保数据安全和资源的有效利用。通过实现这些目标，该方法不仅促进了AI技术的普及，还加强了社区之间的连接与协作，推动了更高效、可持续发展的社会。 <div>
arXiv:2306.08708v3 Announce Type: replace 
Abstract: Over the past few years, ubiquitous, or pervasive computing has gained popularity as the primary approach for a wide range of applications, including enterprise-grade systems, consumer applications, and gaming systems. Ubiquitous computing refers to the integration of computing technologies into everyday objects and environments, creating a network of interconnected devices that can communicate with each other and with humans. By using ubiquitous computing technologies, communities can become more connected and efficient, with members able to communicate and collaborate more easily. This enabled interconnectedness and collaboration can lead to a more successful and sustainable community. The spread of ubiquitous computing, however, has emphasized the importance of automated learning and smart applications in general. Even though there have been significant strides in Artificial Intelligence and Deep Learning, large scale adoption has been hesitant due to mounting pressure on expensive and highly complex cloud numerical-compute infrastructures. Adopting, and even developing, practical machine learning systems can come with prohibitive costs, not only in terms of complex infrastructures but also of solid expertise in Data Science and Machine Learning. In this paper we present an innovative approach for low-code development and deployment of end-to-end AI cooperative application pipelines. We address infrastructure allocation, costs, and secure job distribution in a fully decentralized global cooperative community based on tokenized economics.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CSDO: Enhancing Efficiency and Success in Large-Scale Multi-Vehicle Trajectory Planning</title>
<link>https://arxiv.org/abs/2405.20858</link>
<guid>https://arxiv.org/abs/2405.20858</guid>
<content:encoded><![CDATA[
<div> 关键词：CSDO算法、多车辆轨迹规划、高效算法、非凸约束、分布式优化

总结:
本文提出了一种名为Centralized Searching and Decentralized Optimization（CSDO）的高效算法，用于解决大规模多车辆轨迹规划问题。面对随代理数量增加而呈指数增长的非凸约束，探索不同的同调类（暗示不同凸域）对于找到可行解至关重要。现有方法在高效探索各种同调类方面遇到困难，因为这与寻找耗时精确轨迹解决方案相结合。CSDO通过将此过程分为不同层次并集成高效的多智能体路径查找（MAPF）算法来搜索同调类，首先使用大步长搜索粗略初始猜测，识别特定的同调类。随后的分散式二次规划（QP）则对这个猜测进行细化，有效地解决次要碰撞。实验结果显示，CSDO在大型、高密度场景中超越了现有MVTP算法，在50m×50m随机场景中实现高达95%的成功率，耗时约1秒。相关源代码已发布于https://github.com/YangSVM/CSDOTrajectoryPlanning。 <div>
arXiv:2405.20858v2 Announce Type: replace 
Abstract: This paper presents an efficient algorithm, naming Centralized Searching and Decentralized Optimization (CSDO), to find feasible solution for large-scale Multi-Vehicle Trajectory Planning (MVTP) problem. Due to the intractable growth of non-convex constraints with the number of agents, exploring various homotopy classes that imply different convex domains, is crucial for finding a feasible solution. However, existing methods struggle to explore various homotopy classes efficiently due to combining it with time-consuming precise trajectory solution finding. CSDO, addresses this limitation by separating them into different levels and integrating an efficient Multi-Agent Path Finding (MAPF) algorithm to search homotopy classes. It first searches for a coarse initial guess using a large search step, identifying a specific homotopy class. Subsequent decentralized Quadratic Programming (QP) refinement processes this guess, resolving minor collisions efficiently. Experimental results demonstrate that CSDO outperforms existing MVTP algorithms in large-scale, high-density scenarios, achieving up to 95% success rate in 50m $\times$ 50m random scenarios around one second. Source codes are released in https://github.com/YangSVM/CSDOTrajectoryPlanning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reward Schemes and Committee Sizes in Proof of Stake Governance</title>
<link>https://arxiv.org/abs/2406.10525</link>
<guid>https://arxiv.org/abs/2406.10525</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、奖励机制、委员会规模、治理系统、委托权益证明

<br /><br />
总结:

本文探讨了基于区块链社区的治理系统中奖励方案与委员会规模的影响。研究建立了一个选举模型，其中结果为二元空间，存在客观正确结果，参与者只能委托投票权给一组代表（DReps）。每个DRep的努力（成本）不仅影响其正确投票的能力，还影响她吸引的总委托量，从而增加其投票权重。此模型与委托权益证明（PoS）协议相似，其中委托的权益用于选举区块构建者。

为了激励代表付出努力，可以采用基于每位DRep吸引的委托量的奖励机制。文章分析了这一模型的游戏理论和优化对应方面，并重点研究了在固定预算下选择最大化正确结果概率的委员会的方法。研究成果为设计有效的奖励机制和确定最优委员会结构提供了见解，包括确定足够多的DReps数量。 <div>
arXiv:2406.10525v2 Announce Type: replace 
Abstract: In this paper, we investigate the impact of reward schemes and committee sizes motivated by governance systems over blockchain communities. We introduce a model for elections with a binary outcome space where there is a ground truth (i.e., a "correct" outcome), and where stakeholders can only choose to delegate their voting power to a set of delegation representatives (DReps). Moreover, the effort (cost) invested by each DRep positively influences both (i) her ability to vote correctly and (ii) the total delegation that she attracts, thereby increasing her voting power. This model constitutes the natural counterpart of delegated proof-of-stake (PoS) protocols, where delegated stakes are used to elect the block builders.
  As a way to motivate the representatives to exert effort, a reward scheme can be used based on the delegation attracted by each DRep. We analyze both the game-theoretic aspects and the optimization counterpart of this model. Our primary focus is on selecting a committee that maximizes the probability of reaching the correct outcome, given a fixed monetary budget allocated for rewarding the delegates. Our findings provide insights into the design of effective reward mechanisms and optimal committee structures (i.e., how many DReps are enough) in these PoS-like governance systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Legal Aspects of Decentralized and Platform-Driven Economies</title>
<link>https://arxiv.org/abs/2407.20301</link>
<guid>https://arxiv.org/abs/2407.20301</guid>
<content:encoded><![CDATA[
<div> 关键词：共享经济、数字平台、算法驱动公司、区块链技术、人工智能系统

<br />
总结:

文章主要探讨了共享经济在全球范围内的迅速扩张及其对传统商业模式的影响。文中提到了Zipcar、BlaBlaCar和Couchsurfing等早期平台驱动公司的兴起，以及Airbnb和Uber如何通过数字平台和算法驱动改变了交通和住宿行业。共享经济的核心理念是“使用权而非所有权”，这与传统的商业模式形成了鲜明对比。

随着数字平台、数据和算法驱动公司的崛起，以及区块链技术的广泛应用，共享经济正以惊人的速度发展。然而，这些新技术也带来了法律框架的挑战，特别是对于AI系统的责任归属问题。文章指出，传统的法律责任体系可能无法完全适应这些新兴技术带来的变革，因此需要建立更加前瞻性和灵活的监管结构，以确保公平、透明和安全的共享经济环境。

在未来的共享经济中，AI系统可能会进一步改变法律体系，涉及操作者、用户和制造商的责任划分。为了应对这些挑战，需要制定新的法规和指导原则，以确保共享经济的可持续发展，并保护各方权益。 <div>
arXiv:2407.20301v1 Announce Type: new 
Abstract: The sharing economy is sprawling across almost every sector and activity around the world. About a decade ago, there were only a handful of platform driven companies operating on the market. Zipcar, BlaBlaCar and Couchsurfing among them. Then Airbnb and Uber revolutionized the transportation and hospitality industries with a presence in virtually every major city. Access over ownership is the paradigm shift from the traditional business model that grants individuals the use of products or services without the necessity of buying them. Digital platforms, data and algorithm-driven companies as well as decentralized blockchain technologies have tremendous potential. But they are also changing the rules of the game. One of such technologies challenging the legal system are AI systems that will also reshape the current legal framework concerning the liability of operators, users and manufacturers. Therefore, this introductory chapter deals with explaining and describing the legal issues of some of these disruptive technologies. The chapter argues for a more forward-thinking and flexible regulatory structure.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Entrapment Problem in Random Walk Decentralized Learning</title>
<link>https://arxiv.org/abs/2407.20611</link>
<guid>https://arxiv.org/abs/2407.20611</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、随机游走、Metropolis-Hastings算法、Levy跳跃、收敛率

总结:

本文探讨了基于图的分布式学习环境中的去中心化学习。研究关注于利用随机游走更新全局模型的去中心化SGD算法，并对设计过渡概率矩阵以加速收敛进行了深入研究。与增强集中式学习的重采样技术不同，其去中心化等价物，即使用Metropolis-Hastings(MH)算法，可能会导致陷阱问题，使得随机游走停滞在某些节点上，从而减慢收敛速度。

为了解决这个问题，作者提出了一种名为Metropolis-Hastings with Levy Jumps(MHLJ)的算法，该算法通过引入随机扰动（跳跃）来克服陷阱。理论分析表明，MHLJ算法具有一定的收敛速率和误差差距，并通过数值实验验证了这些结论。

综上所述，本文旨在通过设计优化的过渡概率矩阵和引入Levy跳跃机制，改进去中心化SGD算法的性能，特别是在避免随机游走陷阱方面。通过理论分析和实验证明，MHLJ算法在加速分布式学习过程方面表现出显著优势。 <div>
arXiv:2407.20611v1 Announce Type: new 
Abstract: This paper explores decentralized learning in a graph-based setting, where data is distributed across nodes. We investigate a decentralized SGD algorithm that utilizes a random walk to update a global model based on local data. Our focus is on designing the transition probability matrix to speed up convergence. While importance sampling can enhance centralized learning, its decentralized counterpart, using the Metropolis-Hastings (MH) algorithm, can lead to the entrapment problem, where the random walk becomes stuck at certain nodes, slowing convergence. To address this, we propose the Metropolis-Hastings with L\'evy Jumps (MHLJ) algorithm, which incorporates random perturbations (jumps) to overcome entrapment. We theoretically establish the convergence rate and error gap of MHLJ and validate our findings through numerical experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mean of Means: A 10-dollar Solution for Human Localization with Calibration-free and Unconstrained Camera Settings</title>
<link>https://arxiv.org/abs/2407.20870</link>
<guid>https://arxiv.org/abs/2407.20870</guid>
<content:encoded><![CDATA[
<div> 关键词：高精度、低成本、人体定位、立体视觉、概率方法

总结:

文章主要探讨了在元宇宙时代下，准确的人体定位对于各种应用的重要性。现有的高精度解决方案通常依赖昂贵且需要标记的硬件设备，而基于视觉的方法则提供了一种成本更低、无需标记的替代方案。然而，当前基于立体视觉的人体定位方法受限于刚性透视变换原理和多阶段SVD求解器中的误差传播问题，同时还需要多个高分辨率摄像头并严格设定布局。

为了解决上述问题，作者提出了一种基于概率的方法，将人体上的所有点视为围绕身体几何中心生成的分布观察结果。这种方法显著提高了采样效率，使得每个感兴趣点的样本数量从数百个增加到数十亿个。通过利用中心极限定理来建模世界坐标与像素坐标的分布均值之间的关系，确保了正态分布，从而有利于学习过程。实验结果显示，使用两台分辨率为640x480像素的网络摄像头，仅需约10美元的成本，即可实现0.3米范围内95%的定位精度和0.5米范围内接近100%的定位准确性。 <div>
arXiv:2407.20870v1 Announce Type: new 
Abstract: Accurate human localization is crucial for various applications, especially in the Metaverse era. Existing high precision solutions rely on expensive, tag-dependent hardware, while vision-based methods offer a cheaper, tag-free alternative. However, current vision solutions based on stereo vision face limitations due to rigid perspective transformation principles and error propagation in multi-stage SVD solvers. These solutions also require multiple high-resolution cameras with strict setup constraints. To address these limitations, we propose a probabilistic approach that considers all points on the human body as observations generated by a distribution centered around the body's geometric center. This enables us to improve sampling significantly, increasing the number of samples for each point of interest from hundreds to billions. By modeling the relation between the means of the distributions of world coordinates and pixel coordinates, leveraging the Central Limit Theorem, we ensure normality and facilitate the learning process. Experimental results demonstrate human localization accuracy of 95% within a 0.3m range and nearly 100% accuracy within a 0.5m range, achieved at a low cost of only 10 USD using two web cameras with a resolution of 640x480 pixels.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SoK: Payment Channel Networks</title>
<link>https://arxiv.org/abs/2407.20968</link>
<guid>https://arxiv.org/abs/2407.20968</guid>
<content:encoded><![CDATA[
<div> 关键词：Payment Channel Networks（PCNs）、路径查找与路由、虚拟通道、状态通道、支付通道枢纽与重新平衡

<br /><br />
总结:

本文是一篇关于支付通道网络（PCNs）的研究综述，旨在深入探讨该领域当前的研究挑战和进展。PCNs作为一种解决区块链上链交易的扩展性、吞吐量和成本问题的替代方案，通过支持离链执行交易，显著减轻了区块链的压力，提高了交易处理速度，降低了交易费用，并增强了隐私保护。

文章首先概述了PCNs的关键方面，包括路径查找与路由、虚拟通道、状态通道、支付通道枢纽与重新平衡等，为读者提供了对当前PCN研究状态的全面理解。接着，文章强调了该领域存在的未解决问题，指出这些问题是学术界和研究社区迫切需要关注的问题。

具体而言，PCN研究面临的挑战包括但不限于：

1. **路径查找与路由**：高效、安全地在多个通道中找到最优路径以完成交易，同时保证交易隐私。
   
2. **虚拟通道**：设计灵活的机制，允许用户在不直接连接的情况下进行交易，提高网络的可扩展性和安全性。
   
3. **状态通道**：管理通道中的资金流动和状态更新，确保交易的最终一致性，同时防止欺诈行为。
   
4. **支付通道枢纽与重新平衡**：构建中央节点来协调不同通道之间的交易，以及在资金不平衡时自动调整通道的状态，以维持网络的稳定运行。

通过深入分析这些挑战和问题，本文不仅为读者提供了一个清晰的PCN研究全景图，还指出了未来研究的方向，鼓励相关领域的学者和实践者共同合作，解决这些难题，从而推动PCNs技术的发展，使其更加安全、高效、灵活，以适应不断变化的市场需求和技术环境。 <div>
arXiv:2407.20968v1 Announce Type: new 
Abstract: Payment Channel Networks (PCNs) have been proposed as an alternative solution to the scalability, throughput, and cost overhead associated with on-chain transactions. By facilitating offchain execution of transactions, PCNs significantly reduce the burden on the blockchain, leading to faster transaction processing, reduced transaction fees, and enhanced privacy. Despite these advantages, the current research in PCNs presents a variety of research challenges that require further exploration. In this paper, we survey the recent work in several aspects of PCNs, such as pathfinding and routing, virtual channels, state channels, payment channel hubs and rebalancing. This survey aims to provide the reader with a detailed understanding of the current state-of-the-art in PCN research, highlighting a few important advancements. Additionally, we highlight the various unresolved issues in the area of PCN research. Specifically, this paper seeks to answer the following crucial question: What are the various interesting and non-trivial challenges in PCN research that require immediate attention from the academic and research community? By addressing this question, we aim to identify the most pressing problems and future research directions that interested readers can immediately work on. Through this analysis, we hope to inspire researchers and practitioners to tackle these challenges to make PCNs more secure and versatile
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Impact of Conflicting Transactions in Blockchain: Detecting and Mitigating Potential Attacks</title>
<link>https://arxiv.org/abs/2407.20980</link>
<guid>https://arxiv.org/abs/2407.20980</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、冲突交易、攻击向量、防御策略、网络性能

总结:

本文研究了冲突交易对区块链网络攻击向量的影响。通过建模和模拟，分析了四种关键攻击——阻断挖掘、双重支付、余额调整和分布式拒绝服务（DDoS）——如何利用冲突交易进行操作。研究不仅探讨了这些攻击利用交易冲突的机制，还强调了它们对区块链网络完整性和可靠性可能产生的影响。此外，提出了缓解这些攻击的一系列对策。通过实施和评估，证明了这些对策的有效性，能够降低攻击率并增强整体网络性能，同时无需引入额外开销。研究结果强调了积极管理冲突交易对于加强区块链安全和性能的重要性。

本文通过深入分析，揭示了冲突交易如何成为攻击者利用的漏洞，导致性能下降和安全风险增加。为解决这一问题，作者提出了针对性的防御策略，旨在有效降低攻击概率，提升网络效率。研究方法包括了对四种主要攻击模式的模拟分析，以及对所提策略实际效果的验证。最终结论显示，通过合理管理和优化，可以显著改善区块链系统的安全性与运行效率，确保其稳定可靠地服务于用户。 <div>
arXiv:2407.20980v1 Announce Type: new 
Abstract: Conflicting transactions within blockchain networks not only pose performance challenges but also introduce security vulnerabilities, potentially facilitating malicious attacks. In this paper, we explore the impact of conflicting transactions on blockchain attack vectors. Through modeling and simulation, we delve into the dynamics of four pivotal attacks - block withholding, double spending, balance, and distributed denial of service (DDoS), all orchestrated using conflicting transactions. Our analysis not only focuses on the mechanisms through which these attacks exploit transaction conflicts but also underscores their potential impact on the integrity and reliability of blockchain networks. Additionally, we propose a set of countermeasures for mitigating these attacks. Through implementation and evaluation, we show their effectiveness in lowering attack rates and enhancing overall network performance seamlessly, without introducing additional overhead. Our findings emphasize the critical importance of actively managing conflicting transactions to reinforce blockchain security and performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Securing Proof of Stake Blockchains: Leveraging Multi-Agent Reinforcement Learning for Detecting and Mitigating Malicious Nodes</title>
<link>https://arxiv.org/abs/2407.20983</link>
<guid>https://arxiv.org/abs/2407.20983</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof of Stake (PoS)、Multi-agent Reinforcement Learning (MRL)、Malicious nodes、Penalty-reward scheme、Attack resilience

总结:
本文提出了MRL-PoS+，一种利用多智能体强化学习（MRL）技术增强PoS区块链安全性的新型共识算法。MRL-PoS+通过引入惩罚奖励机制来检测和消除潜在恶意节点，防止它们进行攻击行为。实验结果显示，与传统方案相比，MRL-PoS+显著提高了PoS区块链的抗攻击能力，同时并未增加额外的计算开销。该算法通过识别并惩罚可能引发网络攻击的行为，有效阻止了六种主要类型攻击的执行，证明了其在保护分布式网络免受恶意行为影响方面的高效性和实用性。 <div>
arXiv:2407.20983v1 Announce Type: new 
Abstract: Proof of Stake (PoS) blockchains offer promising alternatives to traditional Proof of Work (PoW) systems, providing scalability and energy efficiency. However, blockchains operate in a decentralized manner and the network is composed of diverse users. This openness creates the potential for malicious nodes to disrupt the network in various ways. Therefore, it is crucial to embed a mechanism within the blockchain network to constantly monitor, identify, and eliminate these malicious nodes without involving any central authority. In this paper, we propose MRL-PoS+, a novel consensus algorithm to enhance the security of PoS blockchains by leveraging Multi-agent Reinforcement Learning (MRL) techniques. Our proposed consensus algorithm introduces a penalty-reward scheme for detecting and eliminating malicious nodes. This approach involves the detection of behaviors that can lead to potential attacks in a blockchain network and hence penalizes the malicious nodes, restricting them from performing certain actions. Our developed Proof of Concept demonstrates effectiveness in eliminating malicious nodes for six types of major attacks. Experimental results demonstrate that MRL-PoS+ significantly improves the attack resilience of PoS blockchains compared to the traditional schemes without incurring additional computation overhead.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards a Novel Privacy-Preserving Distributed Multiparty Data Outsourcing Scheme for Cloud Computing with Quantum Key Distribution</title>
<link>https://arxiv.org/abs/2407.18923</link>
<guid>https://arxiv.org/abs/2407.18923</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、云存储、区块链技术、零知识证明、CRYSTALS Kyber

<br /><br />
总结:本文探讨了云存储、区块链技术和即将到来的量子计算时代交汇点的数据安全问题。研究提出了一套综合框架，结合量子密钥分发(QKD)、基于晶格的CRYSTALS Kyber加密和零知识证明(ZKPs)，旨在增强基于云的区块链系统中的数据安全性，特别是针对量子威胁。QKD提供量子安全的加密协议以强化数据保护，CRYSTALS Kyber以其对抗量子攻击的能力为基础，而ZKPs则增强了数据隐私与验证过程的安全性。研究通过全面评估，包括加密解密过程、量子密钥生成速率和系统整体效率，来检验该框架的实际可行性和效率。分析考虑了文件大小、响应时间和计算开销等关键因素，以确保其在实际云环境中的可行性。研究结果提供了定制化的量子安全与ZKPs集成的全面安全框架，为寻求抵御量子威胁的组织提供了理论与实践指导，强调了框架在量子计算和区块链技术与云环境整合背景下的高效性和可扩展性。 <div>
arXiv:2407.18923v1 Announce Type: new 
Abstract: The intersection of cloud computing, blockchain technology, and the impending era of quantum computing presents a critical juncture for data security. This research addresses the escalating vulnerabilities by proposing a comprehensive framework that integrates Quantum Key Distribution (QKD), CRYSTALS Kyber, and Zero-Knowledge Proofs (ZKPs) for securing data in cloud-based blockchain systems. The primary objective is to fortify data against quantum threats through the implementation of QKD, a quantum-safe cryptographic protocol. We leverage the lattice-based cryptographic mechanism, CRYSTALS Kyber, known for its resilience against quantum attacks. Additionally, ZKPs are introduced to enhance data privacy and verification processes within the cloud and blockchain environment. A significant focus of this research is the performance evaluation of the proposed framework. Rigorous analyses encompass encryption and decryption processes, quantum key generation rates, and overall system efficiency. Practical implications are scrutinized, considering factors such as file size, response time, and computational overhead. The evaluation sheds light on the framework's viability in real-world cloud environments, emphasizing its efficiency in mitigating quantum threats. The findings contribute a robust quantum-safe and ZKP-integrated security framework tailored for cloud-based blockchain storage. By addressing critical gaps in theoretical advancements, this research offers practical insights for organizations seeking to secure their data against quantum threats. The framework's efficiency and scalability underscore its practical feasibility, serving as a guide for implementing enhanced data security in the evolving landscape of quantum computing and blockchain integration within cloud environments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards A Post-Quantum Cryptography in Blockchain I: Basic Review on Theoretical Cryptography and Quantum Information Theory</title>
<link>https://arxiv.org/abs/2407.18966</link>
<guid>https://arxiv.org/abs/2407.18966</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算机、传统加密区块链、后量子密码学、量子抵抗、市场上的加密货币

总结:
文章探讨了量子计算机的出现对传统加密区块链所引发的革命性挑战，特别是对于市场上大部分加密货币的安全威胁。量子计算机的计算能力超越了现有技术，使得现有的加密算法面临失效风险。因此，为了抵御量子攻击，实施后量子密码学（也称为量子抵抗密码学）以增强区块链的安全性变得迫在眉睫。后量子密码学旨在开发新的加密算法，这些算法在面对量子计算机时仍然保持安全有效。文章强调了这一转变的重要性，并指出这将是确保区块链在未来能够继续提供安全服务的关键步骤。同时，它也提醒市场上的加密货币需要迅速适应这一新技术带来的挑战，以保护用户的资产和交易安全。 <div>
arXiv:2407.18966v1 Announce Type: new 
Abstract: Recently, the invention of quantum computers was so revolutionary that they bring transformative challenges in a variety of fields, especially for the traditional cryptographic blockchain, and it may become a real thread for most of the cryptocurrencies in the market. That is, it becomes inevitable to consider to implement a post-quantum cryptography, which is also referred to as quantum-resistant cryptography, for attaining quantum resistance in blockchains.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Task Offloading in Fog Computing with Deep Reinforcement Learning: Future Research Directions Based on Security and Efficiency Enhancements</title>
<link>https://arxiv.org/abs/2407.19121</link>
<guid>https://arxiv.org/abs/2407.19121</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、雾计算、深度强化学习、区块链、人工智能

<br />
总结:
本文探讨了物联网设备和数据生成的激增对传统云计算的挑战，指出雾计算作为一种解决方案的重要性。雾计算通过将计算、存储和网络资源推向数据源附近，旨在满足即时性、服务质量以及位置相关服务的需求。文章进一步研究了深度强化学习在提升雾计算任务卸载过程中的应用潜力，旨在优化运行效率与增强安全性。通过回顾现有策略并提出未来研究方向，作者强调了深度强化学习在资源使用优化、响应加速及抵御漏洞方面的作用。此外，文章建议深入研究深度强化学习在雾计算中的应用，探索区块链技术以提高安全性，并寻求能源效率更高的模型以改善物联网生态系统。人工智能的应用显示出了在关键指标如任务完成时间、能源消耗和安全事件减少方面的潜在改进，为未来的研究和实践提供了坚实的基础。 <div>
arXiv:2407.19121v1 Announce Type: new 
Abstract: The surge in Internet of Things (IoT) devices and data generation highlights the limitations of traditional cloud computing in meeting demands for immediacy, Quality of Service, and location-aware services. Fog computing emerges as a solution, bringing computation, storage, and networking closer to data sources. This study explores the role of Deep Reinforcement Learning in enhancing fog computing's task offloading, aiming for operational efficiency and robust security. By reviewing current strategies and proposing future research directions, the paper shows the potential of Deep Reinforcement Learning in optimizing resource use, speeding up responses, and securing against vulnerabilities. It suggests advancing Deep Reinforcement Learning for fog computing, exploring blockchain for better security, and seeking energy-efficient models to improve the Internet of Things ecosystem. Incorporating artificial intelligence, our results indicate potential improvements in key metrics, such as task completion time, energy consumption, and security incident reduction. These findings provide a concrete foundation for future research and practical applications in optimizing fog computing architectures.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reducing Spurious Correlation for Federated Domain Generalization</title>
<link>https://arxiv.org/abs/2407.19174</link>
<guid>https://arxiv.org/abs/2407.19174</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedCD、Spurious Correlation Intervener、Risk Extrapolation Aggregation、Cross-Domain Invariant

<br />
总结:

本文提出了FedCD（跨域不变联邦学习）框架，旨在解决开放世界场景中全球模型在未见新领域数据上的预测问题。FedCD通过整体优化框架在局部和全局层面进行优化。其中，引入了Spurious Correlation Intervener（SCIntervener），利用不变性理论以自监督方式生成特征干预者，减少模型对误导性相关特征的依赖。这种方法仅需与模型相关的梯度信息，而无需共享数据或特征。此外，FedCD还开发了Risk Extrapolation Aggregation（REA）策略，通过数学优化确定聚合系数，促进全局因果不变预测。

实验结果显示，FedCD方法在分类和目标检测任务上的平均准确率分别提高了至少1.45%，mAP50分别提高了4.8%和1.27%，显著优于基线方法。这表明FedCD能够有效解决跨域数据分布差异带来的预测挑战，提高模型在未见过的新领域数据上的泛化能力。 <div>
arXiv:2407.19174v1 Announce Type: new 
Abstract: The rapid development of multimedia has provided a large amount of data with different distributions for visual tasks, forming different domains. Federated Learning (FL) can efficiently use this diverse data distributed on different client media in a decentralized manner through model sharing. However, in open-world scenarios, there is a challenge: global models may struggle to predict well on entirely new domain data captured by certain media, which were not encountered during training. Existing methods still rely on strong statistical correlations between samples and labels to address this issue, which can be misleading, as some features may establish spurious short-cut correlations with the predictions. To comprehensively address this challenge, we introduce FedCD (Cross-Domain Invariant Federated Learning), an overall optimization framework at both the local and global levels. We introduce the Spurious Correlation Intervener (SCI), which employs invariance theory to locally generate interventers for features in a self-supervised manner to reduce the model's susceptibility to spurious correlated features. Our approach requires no sharing of data or features, only the gradients related to the model. Additionally, we develop the simple yet effective Risk Extrapolation Aggregation strategy (REA), determining aggregation coefficients through mathematical optimization to facilitate global causal invariant predictions. Extensive experiments and ablation studies highlight the effectiveness of our approach. In both classification and object detection generalization tasks, our method outperforms the baselines by an average of at least 1.45% in Acc, 4.8% and 1.27% in mAP50.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Smart Contracts, Smarter Payments: Innovating Cross Border Payments and Reporting Transactions</title>
<link>https://arxiv.org/abs/2407.19283</link>
<guid>https://arxiv.org/abs/2407.19283</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、智能合约、ISO20022、跨境支付、去中心化金融

<br /><br />
总结:

本文提出了一种利用区块链技术和智能合约的创新框架，旨在模拟和优化跨境支付流程。该框架的核心贡献包括实现智能合约原型及其与Web客户端的集成，以促进高效、透明的交易流程。此外，还设计了ISO20022标准消息的翻译机制，确保合规性和国际标准兼容性。通过这一解决方案，可以提供安全、高效的跨境交易方式，为全球金融体系和新兴的去中心化金融领域带来显著改进。具体而言，该框架旨在解决传统银行系统在跨境支付中面临的安全隐患、低效率和透明度不足的问题，通过引入区块链技术，实现支付过程的去中心化，提高支付速度，降低交易成本，同时增强交易的可追溯性和安全性。 <div>
arXiv:2407.19283v1 Announce Type: new 
Abstract: The global financial landscape is experiencing significant transformation driven by technological advancements and evolving market dynamics. Moreover, blockchain technology has become a pivotal platform with widespread applications, especially in finance. Cross-border payments have emerged as a key area of interest, with blockchain offering inherent benefits such as enhanced security, transparency, and efficiency compared to traditional banking systems. This paper presents a novel framework leveraging blockchain technology and smart contracts to emulate cross-border payments, ensuring interoperability and compliance with international standards such as ISO20022. Key contributions of this paper include a novel prototype framework for implementing smart contracts and web clients for streamlined transactions and a mechanism to translate ISO20022 standard messages. Our framework can provide a practical solution for secure, efficient, and transparent cross-border transactions, contributing to the ongoing evolution of global finance and the emerging landscape of decentralized finance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reputation-Driven Asynchronous Federated Learning for Enhanced Trajectory Prediction with Blockchain</title>
<link>https://arxiv.org/abs/2407.19428</link>
<guid>https://arxiv.org/abs/2407.19428</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、区块链、自动驾驶、数据质量审计、图神经网络

总结:
本文提出了一种基于图神经网络工具的可解释性声誉量化机制的异步联邦学习数据共享方法，旨在解决自动驾驶应用中日益复杂和粒度化车辆生成数据带来的数据质量审计问题。该方法在差分隐私约束下允许数据提供者共享数据结构，既保证了数据安全又减少了冗余数据的传输。通过深度强化学习，车辆被分类为不同声誉等级，从而优化了联邦学习的数据聚合效率。实验结果表明，该数据共享方案不仅增强了轨迹预测任务的安全性，还提高了预测精度，有效缓解了多方信任缺失的问题，并通过减少重复数据传输来提升整体性能。 <div>
arXiv:2407.19428v1 Announce Type: new 
Abstract: Federated learning combined with blockchain empowers secure data sharing in autonomous driving applications. Nevertheless, with the increasing granularity and complexity of vehicle-generated data, the lack of data quality audits raises concerns about multi-party mistrust in trajectory prediction tasks. In response, this paper proposes an asynchronous federated learning data sharing method based on an interpretable reputation quantization mechanism utilizing graph neural network tools. Data providers share data structures under differential privacy constraints to ensure security while reducing redundant data. We implement deep reinforcement learning to categorize vehicles by reputation level, which optimizes the aggregation efficiency of federated learning. Experimental results demonstrate that the proposed data sharing scheme not only reinforces the security of the trajectory prediction task but also enhances prediction accuracy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Breaking the Balance of Power: Commitment Attacks on Ethereum's Reward Mechanism</title>
<link>https://arxiv.org/abs/2407.19479</link>
<guid>https://arxiv.org/abs/2407.19479</guid>
<content:encoded><![CDATA[
<div> 关键词：承诺攻击、LMD GHOST、MEV、奖励机制、链重组

总结:

本文针对以太坊等无许可大规模区块链中的验证者行为进行了深入分析。验证者通常追求最大收益和理性行动，以获取正当激励，如正确及时投票的奖励，以确保区块链的安全。然而，外部激励，如区块提议者的最大可提取价值（MEV），可能会诱使验证者偏离诚实的协议参与。

文章揭示了一系列针对LMD GHOST——以太坊共识机制核心部分的承诺攻击。通过操纵以太坊的投票奖励系统，单个敌对区块提议者能够策划长程链重组，利用可信威胁来迫使前几轮的投票者支持与诚实链相冲突的区块，从而实现零成本的链重组。这种行为破坏了提议者与投票者之间权力平衡的目的。

为应对这一问题，文章提出了一个新颖的奖励机制，旨在恢复投票者对提议者权力的制约作用。该机制不仅更公平、去中心化，而且在不考虑这些攻击的情况下，也具有实施于以太坊的可行性。通过这种机制，验证者能够在提议者权力过大的情况下，重新获得其应有的角色和影响力，从而保护区块链网络的稳定性和安全性。 <div>
arXiv:2407.19479v1 Announce Type: new 
Abstract: Validators in permissionless, large-scale blockchains (e.g., Ethereum) are typically payoff-maximizing, rational actors. Ethereum relies on in-protocol incentives, like rewards for validators delivering correct and timely votes, to induce honest behavior and secure the blockchain. However, external incentives, such as the block proposer's opportunity to capture maximal extractable value (MEV), may tempt validators to deviate from honest protocol participation.
  We show a series of commitment attacks on LMD GHOST, a core part of Ethereum's consensus mechanism. We demonstrate how a single adversarial block proposer can orchestrate long-range chain reorganizations by manipulating Ethereum's reward system for timely votes. These attacks disrupt the intended balance of power between proposers and voters: by leveraging credible threats, the adversarial proposer can coerce voters from previous slots into supporting blocks that conflict with the honest chain, enabling a chain reorganization at no cost to the adversary. In response, we introduce a novel reward mechanism that restores the voters' role as a check against proposer power. Our proposed mitigation is fairer and more decentralized -- not only in the context of these attacks -- but also practical for implementation in Ethereum.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Maximal Extractable Value Mitigation Approaches in Ethereum and Layer-2 Chains: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2407.19572</link>
<guid>https://arxiv.org/abs/2407.19572</guid>
<content:encoded><![CDATA[
<div> 关键词：Maximal Extractable Value（MEV）、Ethereum、Layer 1（L1）、Layer 2（L2）、Decentralized Finance（DeFi）

<br />
<br />总结:

本文是一篇关于以太坊生态系统中最大可提取价值(MEV)问题的全面综述。MEV是一个关键挑战，它影响着以太坊主链(L1)和第二层网络(L2)的公平性、安全性和效率。MEV现象发生在矿工或验证者通过操纵交易顺序来获取额外价值时，这种行为往往以牺牲其他网络参与者为代价。这不仅影响用户体验，增加不确定性并可能导致财务损失，还威胁到区块链的去中心化和信任原则。

文章首先界定了MEV的概念及其对以太坊生态系统的影响。接着，作者提出了针对L1和各种L2解决方案的MEV缓解技术的分类。这些策略包括但不限于交易排序、加密方法以及重新配置去中心化应用(DApps)以减少前端运行的机会。文章还探讨了这些策略的有效性、实施挑战以及对网络性能的影响。

最后，该文旨在为研究人员、开发者和政策制定者提供一个详细路线图，帮助他们理解并对抗不断演变的区块链景观中的MEV问题。通过综合当前研究、实际应用和新兴趋势，本文为解决这一重要问题提供了有价值的见解和策略。 <div>
arXiv:2407.19572v1 Announce Type: new 
Abstract: Maximal Extractable Value (MEV) represents a pivotal challenge within the Ethereum ecosystem; it impacts the fairness, security, and efficiency of both Layer 1 (L1) and Layer 2 (L2) networks. MEV arises when miners or validators manipulate transaction ordering to extract additional value, often at the expense of other network participants. This not only affects user experience by introducing unpredictability and potential financial losses but also threatens the underlying principles of decentralization and trust. Given the growing complexity of blockchain applications, particularly with the increase of Decentralized Finance (DeFi) protocols, addressing MEV is crucial. This paper presents a comprehensive survey of MEV mitigation techniques as applied to both Ethereums L1 and various L2 solutions. We provide a novel categorization of mitigation strategies; we also describe the challenges, ranging from transaction sequencing and cryptographic methods to reconfiguring decentralized applications (DApps) to reduce front-running opportunities. We investigate their effectiveness, implementation challenges, and impact on network performance. By synthesizing current research, real-world applications, and emerging trends, this paper aims to provide a detailed roadmap for researchers, developers, and policymakers to understand and combat MEV in an evolving blockchain landscape.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Passivity based Stability Assessment for Four types of Droops for DC Microgrids</title>
<link>https://arxiv.org/abs/2407.19573</link>
<guid>https://arxiv.org/abs/2407.19573</guid>
<content:encoded><![CDATA[
<div> 关键词：DC微电网、Droop控制、稳定性评估、低通滤波器、系统集成

总结:

本文聚焦于DC微电网领域，特别是针对基于升压转换器的微电网中的Droop控制策略。研究了四种不同类型的Droop控制方法在提供功率共享方面的性能，并通过过阻尼的概念进行了稳定性评估。为了确保转换器的稳定性，文中引入了低通滤波器（LPF）作为反馈环节的一部分。此外，通过推导网络阻抗来确保整个系统的过阻尼状态，从而减少保守性。

文章还提出了一个实用的设计方法，用于为这四种类型的Droop控制器构建一个被动控制器，并通过时间域模拟验证了该设计的有效性。所使用的模拟对象是一个由恒定功率负载（CPL）供电的单个升压转换器构成的微电网。

EN标准50388-2为铁路系统提供了稳定性的参考标准，旨在确保从转换器到系统集成的整体稳定性。通过这些分析和验证，文章为DC微电网的稳定运行和高效管理提供了重要的理论依据和实践指导。 <div>
arXiv:2407.19573v1 Announce Type: new 
Abstract: DC microgrids are getting more and more applications due to simple converters, only voltage control and higher efficiencies compared to conventional AC grids. Droop control is a well know decentralized control strategy for power sharing among converter interfaced sources and loads in a DC microgrid. This work compares the stability assessment and control of four types of droops for boost converters using the concept of passivity. EN standard 50388-2 for railway systems provides a reference to ensure system stability in perspectives of converters and system integration. Low pass filter (LPF) in the feedback of the droop control is used to ensure converter passivity. Bus impedance is derived to ensure system passivity with less conservativeness. Analytical approach for design of passive controller for all four types of droops is verified through time domain simulations of a single boost converter based microgrid feeding a Constant Power Load (CPL).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Segmented Private Data Aggregation in the Multi-message Shuffle Model</title>
<link>https://arxiv.org/abs/2407.19639</link>
<guid>https://arxiv.org/abs/2407.19639</guid>
<content:encoded><![CDATA[
<div> 关键词：多消息混合模型、隐私保护、数据聚合、精度、通信效率

总结:
本文提出了一种新型的隐私保护数据聚合框架——分割私有数据聚合，该框架基于多消息混合模型，旨在提供用户自定义的隐私保护级别，同时增强聚合服务器的数据处理能力。通过将用户的贡献分为多个“遮蔽”消息，既保护了数据安全，又防止了隐私选择泄露的风险。为优化隐私、效能和通信之间的平衡，研究探讨了最佳的遮蔽消息数量配置，并进行了精确的隐私放大分析。

实验结果显示，与现有方法相比，新框架在估计误差上降低了约50%，显著提高了隐私保护水平和数据聚合的准确性，同时减少了通信开销。这一创新不仅解决了保守用户参与度低的问题，也激励了积极用户贡献更多信息，从而提高了整体数据集的利用价值。 <div>
arXiv:2407.19639v1 Announce Type: new 
Abstract: The shuffle model of differential privacy (DP) offers compelling privacy-utility trade-offs in decentralized settings (e.g., internet of things, mobile edge networks). Particularly, the multi-message shuffle model, where each user may contribute multiple messages, has shown that accuracy can approach that of the central model of DP. However, existing studies typically assume a uniform privacy protection level for all users, which may deter conservative users from participating and prevent liberal users from contributing more information, thereby reducing the overall data utility, such as the accuracy of aggregated statistics. In this work, we pioneer the study of segmented private data aggregation within the multi-message shuffle model of DP, introducing flexible privacy protection for users and enhanced utility for the aggregation server. Our framework not only protects users' data but also anonymizes their privacy level choices to prevent potential data leakage from these choices. To optimize the privacy-utility-communication trade-offs, we explore approximately optimal configurations for the number of blanket messages and conduct almost tight privacy amplification analyses within the shuffle model. Through extensive experiments, we demonstrate that our segmented multi-message shuffle framework achieves a reduction of about 50\% in estimation error compared to existing approaches, significantly enhancing both privacy and utility.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Performance Optimization of High-Conflict Transactions within the Hyperledger Fabric Blockchain</title>
<link>https://arxiv.org/abs/2407.19732</link>
<guid>https://arxiv.org/abs/2407.19732</guid>
<content:encoded><![CDATA[
<div> 关键词：Hyperledger Fabric、冲突交易、多版本并发控制（MVCC）、通过量、延迟

总结:
本文探讨了Hyperledger Fabric（HLF）平台在处理大量冲突性交易时面临的挑战，这些挑战导致了吞吐量和延迟性能下降。为了解决这些问题，文章提出了一种创新方法，将多版本并发控制（MVCC）验证阶段提前到交易流程中，以便更早地识别冲突交易。此方法引入了两种改进方案：Orderer Early MVCC（OEMVCC）和带有执行避免的OEMVCC（OEMVCC-EA）。实验结果表明，这两种方法在高冲突应用中显著提高了通过量和降低了延迟，提供了一种实用的高性能和可扩展性解决方案。 <div>
arXiv:2407.19732v1 Announce Type: new 
Abstract: Hyperledger Fabric (HLF) is a secure and robust blockchain (BC) platform that supports high-throughput and low-latency transactions. However, it encounters challenges in managing conflicting transactions that negatively affect throughput and latency. This paper proposes a novel solution to address these challenges and improve performance, especially in applications incorporating extensive volumes of highly conflicting transactions. Our solution involves reallocating the Multi-Version Concurrency Control (MVCC) of the validation phase to a preceding stage in the transaction flow to enable early detection of conflicting transactions. Specifically, we propose and evaluate two innovative modifications, called Orderer Early MVCC (OEMVCC) and OEMVCC with Execution Avoidance (OEMVCC-EA). Our experimental evaluation results demonstrate significant throughput and latency improvements, providing a practical solution for high-conflict applications that demand high performance and scalability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference</title>
<link>https://arxiv.org/abs/2407.19775</link>
<guid>https://arxiv.org/abs/2407.19775</guid>
<content:encoded><![CDATA[
<div> 关键词：Nesa、模型分片、区块链、分布式计算、安全措施

总结:
文章主要介绍了名为Nesa的模型分片框架，旨在解决大型AI模型在数据隐私、计算资源和可访问性方面带来的挑战。Nesa利用基于区块链的深度神经网络分片技术，将计算任务分散到多样化的节点网络上，通过个性化启发式算法和路由机制进行任务分配，以实现对近期大型模型的高效分布式训练和推理，即使在消费级硬件上也能够做到。

为了减少数据传输和内存需求，Nesa采用了动态块量化和混合矩阵分解等压缩技术。同时，系统还集成了硬件可信执行环境等安全措施，确保数据完整性和机密性不受损害。通过在自然语言处理和视觉任务上的评估，证实了这些压缩策略并未牺牲模型的准确性。

总的来说，Nesa框架为实现AI技术的民主化提供了可能，通过构建一个去中心化的网络，不仅提高了模型的可访问性，还保证了安全性与效率。 <div>
arXiv:2407.19775v1 Announce Type: new 
Abstract: The rapid growth of large-scale AI models, particularly large language models has brought significant challenges in data privacy, computational resources, and accessibility. Traditional centralized architectures often struggle to meet required data security and scalability needs which hinders the democratization of AI systems. Nesa introduces a model-agnostic sharding framework designed for decentralized AI inference. Our framework uses blockchain-based sequential deep neural network sharding to distribute computational tasks across a diverse network of nodes based on a personalised heuristic and routing mechanism. This enables efficient distributed training and inference for recent large-scale models even on consumer-grade hardware. We use compression techniques like dynamic blockwise quantization and mixed matrix decomposition to reduce data transfer and memory needs. We also integrate robust security measures, including hardware-based trusted execution environments to ensure data integrity and confidentiality. Evaluating our system across various natural language processing and vision tasks shows that these compression strategies do not compromise model accuracy. Our results highlight the potential to democratize access to cutting-edge AI technologies by enabling secure and efficient inference on a decentralized network.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Before and After Blockchain: Development and Principle of Distributed Fault Tolerance Consensus</title>
<link>https://arxiv.org/abs/2407.19863</link>
<guid>https://arxiv.org/abs/2407.19863</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式共识、拜占庭将军问题、区块链技术、Proof-of-X、拜占庭容错

<br /><br />
总结:
本文主要探讨了分布式共识的概念及其发展历史，特别是自2009年区块链技术问世以来的演变。分布式共识的核心在于允许网络中的节点达成一致状态，而无需中央控制。文章首先回顾了“拜占庭将军问题”对这一领域的影响，并介绍了区块链技术中使用的两种主要方法：Proof-of-X（PoX）和拜占庭容错（BFT）系统。PoX方法如工作量证明（Proof-of-Work）因其资源密集性和高能耗而较少用于区块链，而BFT方法则成为大多数许可区块链实现一致性选择的首选。

文章进一步详细讨论了在部分同步网络中的状态机复制（SMR）的故障容忍协议，以及异步模型下的共识算法，还提到了基于有向无环图（DAG）的新型共识机制。此外，文章还探讨了BFT共识与区块链技术之间的关系，分析了BFT协议设计的原理及核心组件，并讨论了未来BFT研究的驱动需求。通过这些分析，文章为理解分布式系统中的共识机制提供了全面视角，强调了BFT在确保去中心化网络中数据一致性方面的重要性，以及其在区块链技术发展中的关键作用。 <div>
arXiv:2407.19863v1 Announce Type: new 
Abstract: The concept of distributed consensus gained widespread attention following the publication of ``Byzantine Generals Problem'' by Leslie Lamport in the 1980s. This research topic has been active and extensively studied over the last four decades, particularly since the advent of blockchain technology in 2009. Blockchain technology employs Proof-of-X (PoX) or Byzantine-fault-tolerant (BFT) systems, where all participants follow a protocol to achieve a common state (i.e., consistency) eventually. However, because PoX consensus such as Proof-of-Work is is resource-intensive with high power consumption, most permissioned blockchains employ BFT to achieve consistency. In this article, we provide an introduction to the fundamental principles and history of distributed consensus. We then explore the well-known fault-tolerant state machine replication (SMR) in partially synchronous networks, as well as consensus protocols in asynchronous models and recently proposed DAG-based consensus. Additionally, we examine the relationship between BFT consensus and blockchain technology and discuss the following questions: What is the history and evolution of BFT? Why are BFT protocols designed in the way they are and what core components do they use? What is the connection between BFT and blockchain technology, and what are the driving needs for future BFT research?
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Prichain II: CloudGuardian Cloud Security Proposal with Blockchain</title>
<link>https://arxiv.org/abs/2407.19961</link>
<guid>https://arxiv.org/abs/2407.19961</guid>
<content:encoded><![CDATA[
<div> 关键词：云存储、数据安全、区块链技术、Ethereum网络、PostgreSQL数据库

总结:
本文主要探讨了在云环境下，随着云计算、数据存储和安全需求的不断增长，数据的隐私和所有权保护变得尤为重要。从2022年到2023年，云安全威胁增加了约48%，这凸显了迫切需要强大的安全解决方案。为了应对这些挑战，文章提出了一种创新方案，即结合Ethereum网络的区块链技术和位于云中的PostgreSQL数据库。

首先，区块链技术确保了交易的不可篡改性和透明性，为数据提供了一层坚实的保护。同时，PostgreSQL数据库因其高效性和可扩展性，为数据提供了可靠存储环境。通过在动态交通控制场景下进行严格测试，研究结果表明，该解决方案能够提供极高的安全性，得益于数据的去中心化特性。

此外，文章强调了区块链与云关系型数据库的集成不仅增强了信息安全性，还展示了其在实际应用中的可行性。这种双向对齐的方法显著提高了对网络攻击的防护能力，确保用户数据免受未经授权的访问和恶意修改。

综上所述，本文提出的解决方案不仅提升了云环境下的数据安全水平，也证明了区块链技术与传统数据库系统结合的潜力，为云计算领域的安全防护提供了新的思路和实践路径。 <div>
arXiv:2407.19961v1 Announce Type: new 
Abstract: With the advancement of cloud computing, data storage, and security have become crucial. The growing adoption of cloud services by companies, accompanied by increased threats from cybersecurity, highlights the importance of privacy and ownership of user data. Between 2022 and 2023, there has been an increase of around 48% in cloud security threats, emphasizing the urgent need for strong security solutions. To face these challenges, in this project, we propose integrating the Ethereum network's blockchain technology with a database located in the PostgreSQL cloud. The proposed solution aims to provide bidirectional data synchronization and strict control of access mechanisms. Blockchain technology ensures immutability and transparency of transactions, while PostgreSQL provides efficient and scalable storage. Through rigorous testing in an adaptive traffic control scenario, the results obtained indicate that this solution offers a significantly high level of security due to the decentralization of data, confirming that this solution is effective, and making it a powerful new option to improve security in cloud environments. In conclusion, the solution proposed in this project not only increases information security but also demonstrates the practical feasibility of integrating blockchain with cloud relational databases. This two-way alignment improves protection against cyberattacks and ensures that user data is protected from unauthorized access and malicious changes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain for Large Language Model Security and Safety: A Holistic Survey</title>
<link>https://arxiv.org/abs/2407.20181</link>
<guid>https://arxiv.org/abs/2407.20181</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、区块链、数据安全、攻击防御、研究综述

文章主要探讨了大型语言模型（LLMs）在商业和学术领域的兴起及其带来的新型攻击风险，以及区块链技术在此背景下作为数据保护手段的潜力。文章提出了区块链为大型语言模型（BC4LLM）的分类体系，详细定义了相关研究领域，并构建了研究框架，旨在全面评估区块链在保护LLMs免受漏洞侵害方面的应用，并探索其在新应用场景中的可能性。同时，文章指出了未来研究目标和面临的挑战。

总结:
本文首先指出大型语言模型（LLMs）的广泛应用导致了对其安全性需求的增加。随后，文章介绍了区块链技术作为一种新兴的数据保护手段，能够提供数据不可变性和可追溯性，从而帮助防御针对LLMs的攻击。接着，文章提出了一种BC4LLM的分类体系，对现有研究进行了系统梳理，并定义了不同研究领域的具体概念。此外，文章还构建了研究框架，为更深入的研究提供了结构化指导。最后，文章明确了未来研究的方向，包括进一步探索区块链在LLMs安全领域的应用潜力，以及解决当前面临的技术和实践挑战。 <div>
arXiv:2407.20181v1 Announce Type: new 
Abstract: With the advent of accessible interfaces for interacting with large language models, there has been an associated explosion in both their commercial and academic interest. Consequently, there has also been an sudden burst of novel attacks associated with large language models, jeopardizing user data on a massive scale. Situated at a comparable crossroads in its development, and equally prolific to LLMs in its rampant growth, blockchain has emerged in recent years as a disruptive technology with the potential to redefine how we approach data handling. In particular, and due to its strong guarantees about data immutability and irrefutability as well as inherent data provenance assurances, blockchain has attracted significant attention as a means to better defend against the array of attacks affecting LLMs and further improve the quality of their responses. In this survey, we holistically evaluate current research on how blockchains are being used to help protect against LLM vulnerabilities, as well as analyze how they may further be used in novel applications. To better serve these ends, we introduce a taxonomy of blockchain for large language models (BC4LLM) and also develop various definitions to precisely capture the nature of different bodies of research in these areas. Moreover, throughout the paper, we present frameworks to contextualize broader research efforts, and in order to motivate the field further, we identify future research goals as well as challenges present in the blockchain for large language model (BC4LLM) space.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy Amplification via Shuffling: Unified, Simplified, and Tightened</title>
<link>https://arxiv.org/abs/2304.05007</link>
<guid>https://arxiv.org/abs/2304.05007</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私、混合模型、隐私放大、总变异性减少、平行组成

总结:
本文提出了一种名为“总变异性减少”的全面框架，用于在单消息和多消息混合协议中进行隐私放大。该框架利用了本地消息的总变异性边界和毯子消息的概率比率边界两个新的参数化来确定不可区分性水平。理论结果表明，我们的框架提供了更紧的边界，特别是对于具有极端概率设计的本地随机化器，其中我们的边界恰好是紧的。此外，总变异性减少补充了混合模型中的并行组成，为统计查询（如范围查询、边缘查询和频繁项集挖掘）中常用的基于采样的随机化器提供了增强的隐私计数。实验发现，我们的数值放大边界超过了现有的边界，对于单消息协议保守高达30%的预算，对于多消息协议保守高达75%，并且对于并行组成保守高达75%-95%的预算。我们的边界还导致了一个非常高效的$\tilde{O}(n)$算法，在不到10秒的时间内为n=10^8用户实现了隐私的数值放大。

通过使用总变异性减少框架，文章解决了当前分析在分布式、隐私保护数据分析中关于隐私-效用平衡的挑战，提供了更紧、更通用的隐私放大边界。该框架不仅提高了对于特定类型随机化器的隐私保护效率，而且通过与并行组成的结合，进一步优化了隐私会计，使得在大规模数据集上进行隐私保护的数据分析成为可能。实验结果验证了理论分析的有效性和实用性，显示了在不同场景下显著提升的预算保守率。 <div>
arXiv:2304.05007v5 Announce Type: replace 
Abstract: The shuffle model of differential privacy provides promising privacy-utility balances in decentralized, privacy-preserving data analysis. However, the current analyses of privacy amplification via shuffling lack both tightness and generality. To address this issue, we propose the \emph{variation-ratio reduction} as a comprehensive framework for privacy amplification in both single-message and multi-message shuffle protocols. It leverages two new parameterizations: the total variation bounds of local messages and the probability ratio bounds of blanket messages, to determine indistinguishability levels. Our theoretical results demonstrate that our framework provides tighter bounds, especially for local randomizers with extremal probability design, where our bounds are exactly tight. Additionally, variation-ratio reduction complements parallel composition in the shuffle model, yielding enhanced privacy accounting for popular sampling-based randomizers employed in statistical queries (e.g., range queries, marginal queries, and frequent itemset mining). Empirical findings demonstrate that our numerical amplification bounds surpass existing ones, conserving up to $30\%$ of the budget for single-message protocols, $75\%$ for multi-message ones, and a striking $75\%$-$95\%$ for parallel composition. Our bounds also result in a remarkably efficient $\tilde{O}(n)$ algorithm that numerically amplifies privacy in less than $10$ seconds for $n=10^8$ users.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Security Analysis of Smart Contract Migration from Ethereum to Arbitrum</title>
<link>https://arxiv.org/abs/2307.14773</link>
<guid>https://arxiv.org/abs/2307.14773</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链平台迁移、安全风险、Arbitrum、Ethereum

总结:

本文主要探讨了将智能合约从以太坊（Ethereum）迁移到Arbitrum时所面临的安全风险。研究通过收集相关数据和分析智能合约迁移案例，深入探究了两个平台在跨链消息传输、区块属性、合约地址别名以及交易手续费等方面的差异。

关键发现包括：
1. **跨链消息传输**：Arbitrum与以太坊之间存在不同的消息传递机制，这可能导致在迁移过程中出现信息不一致或延迟的问题。
2. **区块属性**：两个平台的区块结构和特性不同，这可能影响智能合约的执行逻辑和效率。
3. **合约地址别名**：在迁移过程中，合约地址的别名处理不当可能会引发安全漏洞。
4. **交易费用**：Arbitrum与以太坊的Gas费用模型存在差异，这可能影响合约的经济性和安全性。
5. **公共区块链特性**：如数据获取的时效性问题、基于时间的逻辑错误、权限检查失败及分布式拒绝服务（DOS）攻击等安全风险。

研究提出了相应的规避方法，并为用户和开发者提供了安全迁移的指导，确保智能合约在迁移过程中的安全性。这是首次对从以太坊到Arbitrum的智能合约安全迁移进行深度分析的研究，对于促进跨平台智能合约迁移具有重要价值。 <div>
arXiv:2307.14773v3 Announce Type: replace 
Abstract: When migrating smart contracts from one blockchain platform to another, there are potential security risks. This is because different blockchain platforms have different environments and characteristics for executing smart contracts. The focus of this paper is to study the security risks associated with the migration of smart contracts from Ethereum to Arbitrum. We collected relevant data and analyzed smart contract migration cases to explore the differences between Ethereum and Arbitrum in areas such as Arbitrum cross-chain messaging, block properties, contract address alias, and gas fees. From the 36 types of smart contract migration cases we identified, we selected 4 typical types of cases and summarized their security risks. The research shows that smart contracts deployed on Ethereum may face certain potential security risks during migration to Arbitrum, mainly due to issues inherent in public blockchain characteristics, such as outdated off-chain data obtained by the inactive sequencer, logic errors based on time, the permission check failed, Denial of Service(DOS) attacks. To mitigate these security risks, we proposed avoidance methods and provided considerations for users and developers to ensure a secure migration process. It's worth noting that this study is the first to conduct an in-depth analysis of the secure migration of smart contracts from Ethereum to Arbitrum.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Democratization of Wealth Management: Hedged Mutual Fund Blockchain Protocol</title>
<link>https://arxiv.org/abs/2405.02302</link>
<guid>https://arxiv.org/abs/2405.02302</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、投资基金、传统金融、操作问题、智能合约

总结:

本文旨在将传统投资基金的最佳实践引入区块链领域，解决传统金融面临的一系列操作问题。通过四个关键创新点，文章详细阐述了如何利用区块链技术及传统财富管理策略，提升区块链投资基金的运作效率与安全性：

1. **定期更新基金价格**：借鉴传统基金的做法，实现基金价格的实时更新，为投资者提供透明、准确的价格信息。

2. **实施绩效收费机制**：类似于对冲基金的模式，引入绩效费用，确保基金管理人与投资者利益一致，促进长期稳定增长。

3. **引入保护机制**：通过设置“水位线”等投资者保护方案，确保在市场波动中投资者权益得到保障，增强信任度和吸引力。

4. **应对交易相关滑点成本**：提出策略以抵消赎回时可能产生的交易滑点成本，提高基金运营的效率与成本效益。

5. **优化智能合约设计**：通过提供详细的实施步骤、数学公式和指导性说明，克服区块链技术瓶颈，使智能合约更加高效、智能，从而加速区块链在传统金融领域的应用与普及。

综上所述，本文不仅揭示了区块链与传统金融结合的潜力，还提供了具体的实施方案，旨在推动区块链技术在财富管理领域的深入应用，同时解决传统基金面临的操作难题，促进金融行业的创新与发展。 <div>
arXiv:2405.02302v2 Announce Type: replace 
Abstract: We develop several innovations to bring the best practices of traditional investment funds to the blockchain landscape. Specifically, we illustrate how: 1) fund prices can be updated regularly like mutual funds; 2) performance fees can be charged like hedge funds; 3) mutually hedged blockchain investment funds can operate with investor protection schemes, such as high water marks; and 4) measures to offset trading related slippage costs when redemptions happen. Using our concepts - and blockchain technology - traditional funds can calculate performance fees in a simplified manner and alleviate several operational issues. Blockchain can solve many problems for traditional finance, while tried and tested wealth management techniques can benefit decentralization, speeding its adoption. We provide detailed steps - including mathematical formulations and instructive pointers - to implement these ideas and discuss how our designs overcome several blockchain bottlenecks, making smart contracts smarter. We provide numerical illustrations of several scenarios related to our mechanisms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fantastyc: Blockchain-based Federated Learning Made Secure and Practical</title>
<link>https://arxiv.org/abs/2406.03608</link>
<guid>https://arxiv.org/abs/2406.03608</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、区块链、完整性、机密性、可扩展性

总结:

本文提出了一种名为Fantastyc的解决方案，旨在解决当前联邦学习领域中尚未被同时满足的挑战，包括完整性、机密性、可扩展性。联邦学习作为一种分散化的框架，允许多个客户端在中央服务器的协调下共同训练机器学习模型，而无需共享本地数据。然而，这种框架的中心化特性构成了潜在的失败点，这在文献中得到了关注，并通过基于区块链的联邦学习方法进行了探讨。尽管区块链方法提供了全面去中心化的解决方案和可追溯性，它们仍然面临着关于完整性和保密性的实际部署挑战以及可扩展性问题。

Fantastyc解决方案的提出旨在克服这些局限性，通过集成区块链技术来确保数据的完整性和机密性，同时优化系统以提高可扩展性。这一创新的综合方法不仅提高了系统的安全性，还增强了其实用性，使其在实际应用中更具可行性。通过结合联邦学习的高效协同与区块链的分布式信任机制，Fantastyc为构建更安全、可靠且可扩展的机器学习生态系统提供了一种有前景的途径。 <div>
arXiv:2406.03608v2 Announce Type: replace 
Abstract: Federated Learning is a decentralized framework that enables multiple clients to collaboratively train a machine learning model under the orchestration of a central server without sharing their local data. The centrality of this framework represents a point of failure which is addressed in literature by blockchain-based federated learning approaches. While ensuring a fully-decentralized solution with traceability, such approaches still face several challenges about integrity, confidentiality and scalability to be practically deployed. In this paper, we propose Fantastyc, a solution designed to address these challenges that have been never met together in the state of the art.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future</title>
<link>https://arxiv.org/abs/2407.18358</link>
<guid>https://arxiv.org/abs/2407.18358</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、生成式人工智能、隐私保护、数据效率、模型性能

总结:
本文探讨了生成式人工智能在联邦学习中的应用潜力，旨在提升隐私保护、数据利用效率与模型性能。联邦学习作为分布式机器学习的一种方法，允许多个参与方在不共享原始数据的情况下协同训练模型，这为保护用户数据隐私提供了可能。引入生成式人工智能（如生成对抗网络GAN和变分自编码器VAE）后，研究发现可以通过生成与真实数据分布相匹配的合成数据来解决数据量不足的问题，从而增强模型的泛化能力。

此外，生成式AI在联邦学习中的应用还能够实现更个性化的解决方案，通过定制化模型来满足不同用户群体的需求。例如，通过生成特定领域的合成数据，可以为特定行业或特定用户群提供更加精准的服务。同时，生成的数据集还可以用于增强模型训练，提高模型性能，尤其是在数据稀疏或难以获取的真实数据集上。

总的来说，生成式人工智能与联邦学习的结合不仅能够促进数据隐私的保护，还能有效提升数据效率和模型性能，为构建更加个性化和高效的人工智能系统提供了新的路径。 <div>
arXiv:2407.18358v1 Announce Type: new 
Abstract: Federated learning has become a significant approach for training machine learning models using decentralized data without necessitating the sharing of this data. Recently, the incorporation of generative artificial intelligence (AI) methods has provided new possibilities for improving privacy, augmenting data, and customizing models. This research explores potential integrations of generative AI in federated learning, revealing various opportunities to enhance privacy, data efficiency, and model performance. It particularly emphasizes the importance of generative models like generative adversarial networks (GANs) and variational autoencoders (VAEs) in creating synthetic data that replicates the distribution of real data. Generating synthetic data helps federated learning address challenges related to limited data availability and supports robust model development. Additionally, we examine various applications of generative AI in federated learning that enable more personalized solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mini-Batch Gradient-Based MCMC for Decentralized Massive MIMO Detection</title>
<link>https://arxiv.org/abs/2407.18489</link>
<guid>https://arxiv.org/abs/2407.18489</guid>
<content:encoded><![CDATA[
<div> 关键词：MIMO、分散式基带处理、渐变式马尔可夫链蒙特卡洛方法、迷你批次随机梯度下降、性能增益

总结:
本文探讨了在大规模MIMO系统中采用分布式基带处理架构的可能性，以解决集中式处理所面临的计算复杂性和大量基带数据交换的问题。通过将天线阵列划分为多个处理单元，每个单元配备专用计算硬件进行并行处理，实现了计算负担的分散化。同时，结合渐变式马尔可夫链蒙特卡洛检测方法和迷你批次随机梯度下降算法，该研究提出了一种高效且性能优越的分布式检测器。仿真结果表明，与现有分布式检测器相比，新提出的检测器在多种场景下均表现出显著的性能提升。此外，复杂性分析显示，与传统的集中式检测器相比，提出的分布式策略在计算延迟和互联带宽方面具有明显优势。这一研究为大规模MIMO系统的实际应用提供了有效的解决方案，有望推动通信技术向更高性能、更高效的方向发展。 <div>
arXiv:2407.18489v1 Announce Type: new 
Abstract: Massive multiple-input multiple-output (MIMO) technology has significantly enhanced spectral and power efficiency in cellular communications and is expected to further evolve towards extra-large-scale MIMO. However, centralized processing for massive MIMO faces practical obstacles, including excessive computational complexity and a substantial volume of baseband data to be exchanged. To address these challenges, decentralized baseband processing has emerged as a promising solution. This approach involves partitioning the antenna array into clusters with dedicated computing hardware for parallel processing. In this paper, we investigate the gradient-based Markov chain Monte Carlo (MCMC) method -- an advanced MIMO detection technique known for its near-optimal performance in centralized implementation -- within the context of a decentralized baseband processing architecture. This decentralized design mitigates the computation burden at a single processing unit by utilizing computational resources in a distributed and parallel manner. Additionally, we integrate the mini-batch stochastic gradient descent method into the proposed decentralized detector, achieving remarkable performance with high efficiency. Simulation results demonstrate substantial performance gains of the proposed method over existing decentralized detectors across various scenarios. Moreover, complexity analysis reveals the advantages of the proposed decentralized strategy in terms of computation delay and interconnection bandwidth when compared to conventional centralized detectors.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Signalling and Control in Nonlinear Stochastic Systems: An Information State Approach with Applications</title>
<link>https://arxiv.org/abs/2407.18588</link>
<guid>https://arxiv.org/abs/2407.18588</guid>
<content:encoded><![CDATA[
<div> 关键词：信息理论优化、随机控制编码容量、非线性滤波、线性二次高斯系统、分离原理

<br /><br />
总结:

本文研究了离散时间非线性部分可观测随机系统的最优信号处理与控制问题。主要贡献如下：

1. **控制编码容量的定义与分析**：文章首先通过信息理论优化问题，定义并分析了控制编码容量$C_{FB}$，该容量衡量了在给定信道下，以最小化解码错误概率为条件，控制器和编码器策略能够传输的信息速率。

2. **随机策略与信息状态**：利用非线性滤波理论中的信息状态概念，分析了随机策略下的信号编码与解码过程。策略被表示为基于非均匀或任意分布的随机变量的实现，这些变量用于生成和恢复消息。

3. **线性二次高斯部分观测系统（LQG-POSS）的分析**：针对特定的LQG-POSS模型，文章展示了同时进行信号传递与控制的随机策略可以简化为仅依赖于有限维的充分统计量。这些统计量涉及两个卡尔曼滤波器，用于控制、估计和信号处理。

4. **分离原理与控制矩阵差分算子方程**：应用分散优化技术证明了分离原理，即信号处理和控制可以独立优化。进一步推导出控制部分的最优随机策略，其形式为控制矩阵差分算子方程（DRE）的解。

5. **结论**：综上所述，文章为非线性部分观测随机系统的信号处理与控制提供了理论基础与优化方法，特别是在LQG-POSS框架下，展示了如何通过信息理论工具解决复杂系统控制问题。 <div>
arXiv:2407.18588v1 Announce Type: new 
Abstract: We consider optimal signalling and control of discrete-time nonlinear partially observable stochastic systems in state space form. In the first part of the paper, we characterize the operational {\it control-coding capacity}, $C_{FB}$ in bits/second, by an information theoretic optimization problem of encoding signals or messages into randomized controller-encoder strategies, and reproducing the messages at the output of the system using a decoder or estimator with arbitrary small asymptotic error probability. Our analysis of $C_{FB}$ is based on realizations of randomized strategies (controller-encoders), in terms of information states of nonlinear filtering theory, and either uniform or arbitrary distributed random variables (RVs). In the second part of the paper, we analyze the linear-quadratic Gaussian partially observable stochastic system (LQG-POSS). We show that simultaneous signalling and control leads to randomized strategies described by finite-dimensional sufficient statistics, that involve two Kalman-filters, and consist of control, estimation and signalling strategies. We apply decentralized optimization techniques to prove a separation principle, and to derive the optimal control part of randomized strategies explicitly in terms of a control matrix difference Riccati equation (DRE).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulnerability Detection in Ethereum Smart Contracts via Machine Learning: A Qualitative Analysis</title>
<link>https://arxiv.org/abs/2407.18639</link>
<guid>https://arxiv.org/abs/2407.18639</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、安全漏洞检测、机器学习、区块链技术、风险评估

总结:
本文是对当前基于机器学习的以太坊智能合约安全漏洞检测方法的全面分析。文章首先概述了智能合约在区块链应用中的重要性以及它们面临的挑战，尤其是安全漏洞可能导致的经济损失。接下来，文章深入探讨了现有工具和方法的局限性，包括静态分析和机器学习两种主要策略的不足之处。这些局限性主要体现在覆盖范围有限、数据集构建问题等方面。

文章进一步提出了改进智能合约安全漏洞检测的方法和最佳实践，旨在提升检测的准确性和范围，同时提高效率。这些建议不仅解决了已知的问题，也为未来的研究和开发指明了方向。通过识别当前的挑战并提出创新解决方案，本文对智能合约的安全性、区块链技术的整体发展以及智能合约的可靠应用做出了贡献。

文章最后强调，通过增强安全漏洞检测能力，可以显著提升智能合约和整个区块链生态系统的技术安全性，为未来的区块链应用提供更可靠的基础。 <div>
arXiv:2407.18639v1 Announce Type: new 
Abstract: Smart contracts are central to a myriad of critical blockchain applications, from financial transactions to supply chain management. However, their adoption is hindered by security vulnerabilities that can result in significant financial losses. Most vulnerability detection tools and methods available nowadays leverage either static analysis methods or machine learning. Unfortunately, as valuable as they are, both approaches suffer from limitations that make them only partially effective. In this survey, we analyze the state of the art in machine-learning vulnerability detection for Ethereum smart contracts, by categorizing existing tools and methodologies, evaluating them, and highlighting their limitations. Our critical assessment unveils issues such as restricted vulnerability coverage and dataset construction flaws, providing us with new metrics to overcome the difficulties that restrain a sound comparison of existing solutions. Driven by our findings, we discuss best practices to enhance the accuracy, scope, and efficiency of vulnerability detection in smart contracts. Our guidelines address the known flaws while at the same time opening new avenues for research and development. By shedding light on current challenges and offering novel directions for improvement, we contribute to the advancement of secure smart contract development and blockchain technology as a whole.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Public Dataset For the ZKsync Rollup</title>
<link>https://arxiv.org/abs/2407.18699</link>
<guid>https://arxiv.org/abs/2407.18699</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链数据、ZKsync、数据集、分析代码、开放获取

总结:
本文报告了一项旨在解决区块链数据使用障碍的研究工作。面对公开但难以有效利用的区块链数据，特别是Layer 2（L2）生态系统中如ZKsync的数据，研究团队通过收集并整理了来自ZKsync Era归档节点的一年活动数据，形成了一个可自由获取的数据集。这一数据集的创建和可用性，旨在促进区块链领域的数据驱动型研究与探索。

文章详细介绍了数据集的构建过程，包括数据来源、处理方法和结构特点。同时，展示了几个基于该数据集的示例分析案例，这些案例不仅体现了数据集的丰富性和实用性，也为后续研究提供了方向。为了推动研究的透明度和可重复性，研究团队还公开分享了用于分析的数据处理代码，鼓励其他研究人员利用这些资源进行更深入的探索。

通过这一举措，研究团队不仅为区块链领域的数据研究者提供了宝贵的资源，还促进了社区内的知识共享和技术创新，有望加速区块链技术的发展和应用。 <div>
arXiv:2407.18699v1 Announce Type: new 
Abstract: Despite blockchain data being publicly available, practical challenges and high costs often hinder its effective use by researchers, thus limiting data-driven research and exploration in the blockchain space. This is especially true when it comes to Layer~2 (L2) ecosystems, and ZKsync, in particular. To address these issues, we have curated a dataset from 1 year of activity extracted from a ZKsync Era archive node and made it freely available to external parties. In this paper, we provide details on this dataset and how it was created, showcase a few example analyses that can be performed with it, and discuss some future research directions. We also publish and share the code used in our analysis on GitHub to promote reproducibility and to support further research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit</title>
<link>https://arxiv.org/abs/2402.04417</link>
<guid>https://arxiv.org/abs/2402.04417</guid>
<content:encoded><![CDATA[
<div> 关键词：多臂老虎机问题、区块链、协调机制、恶意参与者、最优策略

总结:
本文研究了在存在恶意参与者的分布式区块链环境中，多代理多臂老虎机问题的鲁棒性。多个参与者在完全去中心化的区块链上分布，其中一些可能是恶意的。奖励具有时间不变的随机分布，仅在满足一定条件后向诚实参与者揭示，以确保协调机制的安全性。目标是通过高效协调，最大化诚实参与者获得的累积奖励。

为了实现这一目标，文章首次将区块链技术与新型机制融入合作决策框架中，设计了适合诚实参与者的最优策略。该框架允许各种恶意行为，并维持了安全性和参与者隐私。具体措施包括选择验证者池，为验证者设计基于数字签名的共识机制，发明一种基于UCB算法的策略，通过安全多方计算减少参与者的信息需求，并设计链-参与者交互和激励机制鼓励参与。

文章首次证明了所提出算法的理论遗憾并声称其最优性。与现有工作侧重于通过计算实验展示区块链与学习问题（如联邦学习）集成的优化性不同，本文展示了在满足某些假设的情况下，诚实参与者的遗憾上限为$log{T}$。这一结果与没有恶意参与者的情况以及纯拜占庭攻击下（不破坏整个系统）的多代理多臂老虎机问题保持一致。 <div>
arXiv:2402.04417v2 Announce Type: replace 
Abstract: We study a robust, i.e. in presence of malicious participants, multi-agent multi-armed bandit problem where multiple participants are distributed on a fully decentralized blockchain, with the possibility of some being malicious. The rewards of arms are homogeneous among the honest participants, following time-invariant stochastic distributions, which are revealed to the participants only when certain conditions are met to ensure that the coordination mechanism is secure enough. The coordination mechanism's objective is to efficiently ensure the cumulative rewards gained by the honest participants are maximized. To this end, we are the first to incorporate advanced techniques from blockchains, as well as novel mechanisms, into such a cooperative decision making framework to design optimal strategies for honest participants. This framework allows various malicious behaviors and the maintenance of security and participant privacy. More specifically, we select a pool of validators who communicate to all participants, design a new consensus mechanism based on digital signatures for these validators, invent a UCB-based strategy that requires less information from participants through secure multi-party computation, and design the chain-participant interaction and an incentive mechanism to encourage participants' participation. Notably, we are the first to prove the theoretical regret of the proposed algorithm and claim its optimality. Unlike existing work that integrates blockchains with learning problems such as federated learning which mainly focuses on optimality via computational experiments, we demonstrate that the regret of honest participants is upper bounded by $\log{T}$ under certain assumptions. The regret bound is consistent with the multi-agent multi-armed bandit problem, both without malicious participants and with purely Byzantine attacks which do not affect the entire system.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Frosty: Bringing strong liveness guarantees to the Snow family of consensus protocols</title>
<link>https://arxiv.org/abs/2404.14250</link>
<guid>https://arxiv.org/abs/2404.14250</guid>
<content:encoded><![CDATA[
<div> 关键词：雪人协议、Avalanche区块链、正式一致性证明、活锁攻击、容错机制

总结:

本文聚焦于雪人协议（Snowman），它是Avalanche区块链中的共识算法，属于雪家族协议。雪人协议的主要优势在于其在普通情况下，即非严重拜占庭攻击条件下，每个共识决策的预期通信开销与处理器数量n无关，这为共识协议提供了一个关键特性，使其能够适应高达10,000或更多的独立验证器。然而，该协议仍存在两个主要问题：

1. **正式一致性证明**：提供雪人协议的一致性证明一直是一个挑战。
   
2. **活锁攻击**：当拜占庭对手控制超过$\sqrt{n}$数量级的处理器时，会引发活锁攻击，导致协议终止时间超过对数级别。

针对上述问题，文章提出以下解决方案：

- **一致性的证明**：通过简化方法提供了雪人协议的正式一致性证明。
  
- **活锁模块**：引入了活锁模块，当严重攻击发生时可以激活，以保证在这一特殊情况下协议的活锁性，同时确保协议在正常运行时不牺牲其低通信复杂度优势。

综上所述，本文旨在解决雪人协议面临的关键问题，通过提供一致性的正式证明和活锁模块的引入，增强了协议的安全性和鲁棒性，特别是针对拜占庭攻击的情况。 <div>
arXiv:2404.14250v4 Announce Type: replace 
Abstract: Snowman is the consensus protocol implemented by the Avalanche blockchain and is part of the Snow family of protocols, first introduced through the original Avalanche leaderless consensus protocol. A major advantage of Snowman is that each consensus decision only requires an expected constant communication overhead per processor in the `common' case that the protocol is not under substantial Byzantine attack, i.e. it provides a solution to the scalability problem which ensures that the expected communication overhead per processor is independent of the total number of processors $n$ during normal operation. This is the key property that would enable a consensus protocol to scale to 10,000 or more independent validators (i.e. processors). On the other hand, the two following concerns have remained:
  (1) Providing formal proofs of consistency for Snowman has presented a formidable challenge.
  (2) Liveness attacks exist in the case that a Byzantine adversary controls more than $O(\sqrt{n})$ processors, slowing termination to more than a logarithmic number of steps.
  In this paper, we address the two issues above. We consider a Byzantine adversary that controls at most $f<n/5$ processors. First, we provide a simple proof of consistency for Snowman. Then we supplement Snowman with a `liveness module' that can be triggered in the case that a substantial adversary launches a liveness attack, and which guarantees liveness in this event by temporarily forgoing the communication complexity advantages of Snowman, but without sacrificing these low communication complexity advantages during normal operation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SOK: Blockchain for Provenance</title>
<link>https://arxiv.org/abs/2407.17699</link>
<guid>https://arxiv.org/abs/2407.17699</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据证明、挑战、未来研究方向、设计考虑

总结:

本文聚焦于区块链技术在数据证明领域的应用，提出了三个关键的研究问题以全面探讨这一领域的问题与需求。首先，文章探讨了在非协作、单一来源环境中的挑战，强调了在确保数据完整性、可靠性和可信度方面的重要性。其次，它深入分析了在协作环境中，尤其是在供应链管理、科学合作和数字取证等不同领域中，数据证明可能遇到的问题和影响。最后，文章识别了组织间使用不同区块链进行通信和数据交换时所面临的复杂性。

文章进一步提供了针对基于区块链的数据证明系统的未来设计考虑，包括选择合适的区块链类型、构建查询机制、数据证明捕获方法以及考虑特定领域的具体需求。此外，还讨论了未来研究的方向和潜在的扩展领域，旨在推动区块链技术在数据证明领域的应用与发展。

通过这三个主要的研究问题，文章为理解区块链在数据证明领域的复杂性、挑战及未来的可能性提供了新的视角，旨在促进该领域的深入研究和技术创新。 <div>
arXiv:2407.17699v1 Announce Type: new 
Abstract: Provenance, which traces data from its creation to manipulation, is crucial for ensuring data integrity, reliability, and trustworthiness. It is valuable for single-user applications, collaboration within organizations, and across organizations. Blockchain technology has become a popular choice for implementing provenance due to its distributed, transparent, and immutable nature. Numerous studies on blockchain designs are specifically dedicated to provenance, and specialize in this area. Our goal is to provide a new perspective in blockchain based provenance field by identifying the challenges faced and suggesting future research directions. In this paper, we categorize the problem statement into three main research questions to investigate key issues comprehensively and propose a new outlook on the use of blockchains. The first focuses on challenges in non-collaborative, single-source environments, the second examines implications in collaborative environments and different domains such as supply chain, scientific collaboration and digital forensic, and the last one analyzes communication and data exchange challenges between organizations using different blockchains. The interconnected nature of these research questions ensures a thorough exploration of provenance requirements, leading to more effective and secure systems. After analyzing the requirements of provenance in different environments, we provide future design considerations for provenance-based blockchains, including blockchain type, query mechanisms, provenance capture methods, and domain-specific considerations. We also discuss future work and possible extensions in this field.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards the Blockchain Massive Adoption with Permissionless Storage</title>
<link>https://arxiv.org/abs/2407.17761</link>
<guid>https://arxiv.org/abs/2407.17761</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、成本问题、共识机制、安全性、大规模应用

总结:

本文主要探讨了区块链技术在大规模应用过程中面临的主要挑战——成本问题。随着区块链技术的成熟与普及，其高昂的使用成本成为阻碍其广泛采用的关键因素。文章指出，这种高成本与区块链的共识机制和安全策略紧密相关。为了解决这个问题，作者提出了创新性的解决方案：

1. **降低成本**：通过引入一种称为“有用工作量证明”（Useful Proof of Work）的新方法，将文件数据编码过程融入到Nakamoto共识算法中，以证明诚实数据的保存。这种方法不仅增强了安全性，还为存储需求者提供了支付存储资源的机会，从而间接降低了链上交易费用。

2. **保持去中心化**：基于上述理论，作者提出了一种新的去中心化存储网络作为区块链的安全引擎。该网络将存储用户的需求与区块链的安全需求相结合，实现了低成本的交易费用和对存储资源的有效利用，同时保证了区块链的去中心化特性。

3. **解决可扩展性问题**：为了满足日益增长的性能需求，作者提出了区块链分片（Sharding）方案，即通过将区块链分割成多个独立的分片，实现更高的事务处理能力（TPS），同时保持了区块链的去中心化特性。

这些解决方案旨在解决区块链大规模应用中的三大关键问题：降低使用成本、维持去中心化特性以及提升可扩展性。通过这些创新，本文为推动区块链技术的大规模应用提供了全面的策略和路径。 <div>
arXiv:2407.17761v1 Announce Type: new 
Abstract: Blockchain technology emerged with the advent of Bitcoin and rapidly developed over the past few decades, becoming widely accepted and known by the public. However, in the past decades, the massive adoption of blockchain technology has yet to come. Rather than the scalability issue, the blockchain application is challenged by its expensive usage cost. However, the high cost of blockchain usage is deeply connected with the blockchain consensus and security mechanism. The permissionless blockchain must maintain its high cost for security against the 51% Attack. Chain users indirectly cover the cost as coins are appointed for blockchain usage fees. This conflict prevents the massive adoption of blockchain. Thus, blockchain must be improved to solve those problems: 1. The cost of blockchain usage should be low enough. 2. The blockchain should remain decentralized. 3. The scalability of blockchain must meet the demand.
  In my thesis, new approaches are applied to solve the issues above. The key contribution is the discovery of the useful PoW. It extends the Nakamoto PoW with another usage of file data encoding during the same Nakamoto Consensus computation to prove honest data preservation. Based on this theory, a permissionless storage network is proposed as the new security engine for the blockchain. It bridges the high blockchain security cost to the storage users with real demands who are willing to pay for the storage resource. On the other hand, the chain users can benefit from the low transaction fee. Meanwhile, we also provide a scalability solution to shard the blockchain. It enables high TPS and keeps decentralization. The solutions in this thesis provide the answers to all the dependencies of the massive adoption.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Utilizing Blockchain and Smart Contracts for Enhanced Fraud Prevention and Minimization in Health Insurance through Multi-Signature Claim Processing</title>
<link>https://arxiv.org/abs/2407.17765</link>
<guid>https://arxiv.org/abs/2407.17765</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、保险理赔、欺诈预防、透明度

总结:

本文提出了一种基于区块链和智能合约的新型保险理赔处理机制，旨在通过引入所有相关方（患者、提供者和保险公司）的积极参与以及每一步操作的透明化来预防和减少保险欺诈。此机制采用多签名技术让各方在提交、审批和确认理赔过程中共同参与。每一项活动都将被智能合约记录在区块链上，确保所有行动的透明性和可追溯性，从而避免任何一方否认其行为或责任。区块链的不可篡改存储特性和强大的完整性保证了记录的操作不会被修改。

通过这一创新方法，可以显著降低欺诈行为，最终为保险公司和投保人带来利益。随着医疗系统和保险公司继续面临欺诈挑战，该提议的方法具有巨大的潜力，能够显著减少欺诈活动，为双方带来积极影响。 <div>
arXiv:2407.17765v1 Announce Type: new 
Abstract: Healthcare insurance provides financial support to access medical services for patients while ensuring timely and guaranteed payment for providers. Insurance fraud poses a significant challenge to insurance companies and policyholders, leading to increased costs and compromised healthcare treatment and service delivery. Most frauds, like phantom billing, upcoding, and unbundling, happen due to the lack of required entity participation. Also, claim activities are not transparent and accountable. Fraud can be prevented and minimized by involving every entity and making actions transparent and accountable. This paper proposes a blockchain-powered smart contract-based insurance claim processing mechanism to prevent and minimize fraud in response to this prevailing issue. All entities patients, providers, and insurance companies actively participate in the claim submission, approval, and acknowledgment process through a multi-signature technique. Also, every activity is captured and recorded in the blockchain using smart contracts to make every action transparent and accountable so that no entity can deny its actions and responsibilities. Blockchains' immutable storage property and strong integrity guarantee that recorded activities are not modified. As healthcare systems and insurance companies continue to deal with fraud challenges, this proposed approach holds the potential to significantly reduce fraudulent activities, ultimately benefiting both insurers and policyholders.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain Takeovers in Web 3.0: An Empirical Study on the TRON-Steem Incident</title>
<link>https://arxiv.org/abs/2407.17825</link>
<guid>https://arxiv.org/abs/2407.17825</guid>
<content:encoded><![CDATA[
<div> 关键词：Web 3.0、区块链网络接管、分散性、数据控制、价值交换

<br /><br />
总结:

本文深入分析了Web 3.0时代下区块链网络接管对分散性原则的威胁。研究以Tron-Steem接管事件为例，通过精细重建Steem区块链中的质押和选举快照，量化了事件前后分散度的变化。这揭示了区块链网络接管对Web 3.0愿景的重大挑战。同时，研究利用启发式方法识别异常投票者，并进行投票行为聚类分析，揭示了接管策略的内在机制。

研究建议采取预防措施，增强Web 3.0网络抵抗类似威胁的能力。这些见解有助于理解区块链网络接管对Web 3.0的挑战，推动分散技术与治理的发展，并加强Web 3.0用户权益保护。此研究为构建更安全、更分散的网络生态系统提供了重要参考。 <div>
arXiv:2407.17825v1 Announce Type: new 
Abstract: A fundamental goal of Web 3.0 is to establish a decentralized network and application ecosystem, thereby enabling users to retain control over their data while promoting value exchange. However, the recent Tron-Steem takeover incident poses a significant threat to this vision. In this paper, we present a thorough empirical analysis of the Tron-Steem takeover incident. By conducting a fine-grained reconstruction of the stake and election snapshots within the Steem blockchain, one of the most prominent social-oriented blockchains, we quantify the marked shifts in decentralization pre and post the takeover incident, highlighting the severe threat that blockchain network takeovers pose to the decentralization principle of Web 3.0. Moreover, by employing heuristic methods to identify anomalous voters and conducting clustering analyses on voter behaviors, we unveil the underlying mechanics of takeover strategies employed in the Tron-Steem incident and suggest potential mitigation strategies, which contribute to the enhanced resistance of Web 3.0 networks against similar threats in the future. We believe the insights gleaned from this research help illuminate the challenges imposed by blockchain network takeovers in the Web 3.0 era, suggest ways to foster the development of decentralized technologies and governance, as well as to enhance the protection of Web 3.0 user rights.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Lightweight Industrial Cohorted Federated Learning for Heterogeneous Assets</title>
<link>https://arxiv.org/abs/2407.17999</link>
<guid>https://arxiv.org/abs/2407.17999</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、工业应用、数据异质性、模型参数、自适应聚合算法

总结:

本文提出了一种针对工业环境的轻量级工业共聚联邦学习（LICFL）算法，旨在解决联邦学习中数据异质性导致的性能下降问题。LICFL算法通过利用模型参数进行客户分组，无需额外的边缘端计算和通信，从而在不增加资源消耗的情况下提高了联邦学习在工业数据场景中的适用性和效率。此外，文章还引入了适应性LICFL（ALICFL）算法，通过动态调整聚合策略来进一步提升全局模型性能并加速收敛速度。

研究通过实测数据实验验证了所提算法的有效性，并与现有方法进行了对比。实验结果表明，LICFL和ALICFL算法在处理工业环境中数据异质性方面表现出色，能够显著提升模型在不同设备上的性能一致性，并且具有较高的泛化能力，适用于实际工业应用场景。 <div>
arXiv:2407.17999v1 Announce Type: new 
Abstract: Federated Learning (FL) is the most widely adopted collaborative learning approach for training decentralized Machine Learning (ML) models by exchanging learning between clients without sharing the data and compromising privacy. However, since great data similarity or homogeneity is taken for granted in all FL tasks, FL is still not specifically designed for the industrial setting. Rarely this is the case in industrial data because there are differences in machine type, firmware version, operational conditions, environmental factors, and hence, data distribution. Albeit its popularity, it has been observed that FL performance degrades if the clients have heterogeneous data distributions. Therefore, we propose a Lightweight Industrial Cohorted FL (LICFL) algorithm that uses model parameters for cohorting without any additional on-edge (clientlevel) computations and communications than standard FL and mitigates the shortcomings from data heterogeneity in industrial applications. Our approach enhances client-level model performance by allowing them to collaborate with similar clients and train more specialized or personalized models. Also, we propose an adaptive aggregation algorithm that extends the LICFL to Adaptive LICFL (ALICFL) for further improving the global model performance and speeding up the convergence. Through numerical experiments on real-time data, we demonstrate the efficacy of the proposed algorithms and compare the performance with existing approaches.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Exploration Study on Developing Blockchain Systems the Practitioners Perspective</title>
<link>https://arxiv.org/abs/2407.18005</link>
<guid>https://arxiv.org/abs/2407.18005</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、软件开发、系统设计、学术研究、行业应用

总结:

本文通过两阶段的研究项目，旨在填补关于区块链软件（BBS）开发过程理解的空白。首先进行了一项系统文献综述，从58篇研究中提炼出构建BBS系统的23个任务流程。随后，对来自全球35个国家、覆盖六大洲的102名区块链从业者进行了问卷调查，以验证这些任务的重要性。研究结果发现，参与者对24个BBS任务的重要性的评价存在显著差异（p值<.001），仅两项任务（激励协议设计和粒度设计）未显示出显著性差异。

此研究是首个针对BBS开发过程深入理解的尝试，为研究人员和实践者提供了有关BBS系统开发挑战和建议的宝贵信息。它不仅揭示了BBS开发过程的关键步骤及其相对重要性，还强调了激励机制和粒度设计的特殊考虑。这一研究成果对于指导BBS的系统设计、实施与验证具有重要意义，有助于推动学术界与业界对BBS领域知识的深化与应用。 <div>
arXiv:2407.18005v1 Announce Type: new 
Abstract: Context: Blockchain-based software (BBS) exploits the concepts and technologies popularized by cryptocurrencies offering decentralized transaction ledgers with immutable content for security-critical and transaction critical systems. Recent research has explored the strategic benefits and technical limitations of BBS in various fields, including cybersecurity, healthcare, education, and financial technologies. Despite growing interest from academia and industry, there is a lack of empirical evidence, leading to an incomplete understanding of the processes, methods, and techniques necessary for systematic BBS development. Objectives: Existing research lacks a consolidated view, particularly empirically driven guidelines based on published evidence and development practices. This study aims to address the gap by consolidating empirical evidence and development practices to derive or leverage existing processes, patterns, and models for designing, implementing, and validating BBS systems. Method: Tied to this knowledge gap, we conducted a two-phase research project. First, a systematic literature review of 58 studies was performed to identify a development process comprising 23 tasks for BBS systems. Second, a survey of 102 blockchain practitioners from 35 countries across six continents was conducted to validate the BBS system development process. Results: Our results revealed a statistically significant difference (p-value <.001) in the importance ratings of 24 out of 26 BBS tasks by our participants. The only two tasks that were not statistically significant were incentive protocol design and granularity design. Conclusion: Our research is among the first to advance understanding on the aspect of development process for blockchain-based systems and helps researchers and practitioners in their quests on challenges and recommendations associated with the development of BBS systems
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On the Design of Ethereum Data Availability Sampling: A Comprehensive Simulation Study</title>
<link>https://arxiv.org/abs/2407.18085</link>
<guid>https://arxiv.org/abs/2407.18085</guid>
<content:encoded><![CDATA[
<div> 关键词：Data Availability Sampling（DAS）、区块链技术、分布式网络、模拟分析、系统性能

<br /><br />
总结:

本文深入探讨了数据可用性采样（DAS）和分片机制在去中心化系统中的应用，通过基于模拟的分析方法。DAS作为区块链技术和分布式网络的关键概念，文章对其进行了全面剖析，评估其对系统性能的影响。为了实现这一目标，作者开发了一款专为DAS设计的仿真器，以此来探究影响系统行为和效率的各种参数。

研究中包括了一系列实验，旨在验证理论假设并揭示DAS参数之间的相互作用。实验内容涉及行托管、每节点验证者数量以及恶意节点等不同策略。通过这些实验，研究团队得出了DAS协议的有效性结论，并据此提出了优化策略，旨在提升去中心化网络的整体性能。

此外，研究结果为未来的研究提供了指导，揭示了分布式系统内在复杂性的多维度理解。本研究不仅丰富了DAS的理论知识，还为分布式系统的构建、实施和优化提供了实际指导意义。 <div>
arXiv:2407.18085v1 Announce Type: new 
Abstract: This paper presents an in-depth exploration of Data Availability Sampling (DAS) and sharding mechanisms within decentralized systems through simulation-based analysis. DAS, a pivotal concept in blockchain technology and decentralized networks, is thoroughly examined to unravel its intricacies and assess its impact on system performance. Through the development of a simulator tailored explicitly for DAS, we embark on a comprehensive investigation into the parameters that influence system behavior and efficiency. A series of experiments are conducted within the simulated environment to validate theoretical formulations and dissect the interplay of DAS parameters. This includes an exploration of approaches such as custody by row, variations in validators per node, and malicious nodes. The outcomes of these experiments furnish insights into the efficacy of DAS protocols and pave the way for the formulation of optimization strategies geared towards enhancing decentralized network performance. Moreover, the findings serve as guidelines for future research endeavors, offering a nuanced understanding of the complexities inherent in decentralized systems. This study not only contributes to the theoretical understanding of DAS but also offers practical implications for the design, implementation, and optimization of decentralized systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review</title>
<link>https://arxiv.org/abs/2407.18096</link>
<guid>https://arxiv.org/abs/2407.18096</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、物联网、隐私保护、安全威胁、防御策略

<br /><br />
总结:
本文通过系统文献综述（SLR）方法，聚焦于2017年至2024年期间关于联邦学习（FL）在物联网（IoT）环境中的隐私威胁及其防御措施的研究。研究首先识别了FL在IoT环境中面临的三大主要隐私威胁：推理攻击、投毒攻击和窃听，并评估了差分隐私、安全多方计算等防御措施的有效性，这些措施旨在保护隐私同时保持FL功能的完整性。文章强调了为适应IoT环境需求而制定高效、强大的隐私保护策略的重要性。特别指出，需要针对重放、逃避和模型盗取攻击采取策略。此外，研究建议探索轻量级防御措施以及区块链等新兴技术，以增强FL在IoT中的隐私保护能力，从而开发能在不同网络条件下运行的FL模型。 <div>
arXiv:2407.18096v1 Announce Type: new 
Abstract: Federated Learning (FL) in the Internet of Things (IoT) environments can enhance machine learning by utilising decentralised data, but at the same time, it might introduce significant privacy and security concerns due to the constrained nature of IoT devices. This represents a research challenge that we aim to address in this paper. We systematically analysed recent literature to identify privacy threats in FL within IoT environments, and evaluate the defensive measures that can be employed to mitigate these threats. Using a Systematic Literature Review (SLR) approach, we searched five publication databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating relevant papers published between 2017 and April 2024, a period which spans from the introduction of FL until now. Guided by the PRISMA protocol, we selected 49 papers to focus our systematic review on. We analysed these papers, paying special attention to the privacy threats and defensive measures -- specifically within the context of IoT -- using inclusion and exclusion criteria tailored to highlight recent advances and critical insights. We identified various privacy threats, including inference attacks, poisoning attacks, and eavesdropping, along with defensive measures such as Differential Privacy and Secure Multi-Party Computation. These defences were evaluated for their effectiveness in protecting privacy without compromising the functional integrity of FL in IoT settings. Our review underscores the necessity for robust and efficient privacy-preserving strategies tailored for IoT environments. Notably, there is a need for strategies against replay, evasion, and model stealing attacks. Exploring lightweight defensive measures and emerging technologies such as blockchain may help improve the privacy of FL in IoT, leading to the creation of FL models that can operate under variable network conditions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Quantifying the Blockchain Trilemma: A Comparative Analysis of Algorand, Ethereum 2.0, and Beyond</title>
<link>https://arxiv.org/abs/2407.14335</link>
<guid>https://arxiv.org/abs/2407.14335</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、数字经济、元宇宙、证明权益（PoS）、区块链三难问题

总结:
本文探讨了区块链技术在数字经济和元宇宙领域的关键作用，特别是通过比较两种领先的权益证明（PoS）系统——Algorand 和 Ethereum 2.0。研究通过分析现有的指标体系来衡量去中心化程度，通过实际交易数据评估可扩展性，并通过识别潜在漏洞来评估安全性。研究发现，每种平台在解决“区块链三难问题”方面都有其独特的优势，并提出了通用方法来评估区块链的关键特性，这不仅适用于当前的系统，也对未来的区块链发展具有重要意义。数据和代码已作为开源资源在GitHub上提供，为研究人员和开发者提供了宝贵的资源，以进一步探索和优化区块链技术。 <div>
arXiv:2407.14335v1 Announce Type: cross 
Abstract: Blockchain technology is essential for the digital economy and metaverse, supporting applications from decentralized finance to virtual assets. However, its potential is constrained by the "Blockchain Trilemma," which necessitates balancing decentralization, security, and scalability. This study evaluates and compares two leading proof-of-stake (PoS) systems, Algorand and Ethereum 2.0, against these critical metrics. Our research interprets existing indices to measure decentralization, evaluates scalability through transactional data, and assesses security by identifying potential vulnerabilities. Utilizing real-world data, we analyze each platform's strategies in a structured manner to understand their effectiveness in addressing trilemma challenges. The findings highlight each platform's strengths and propose general methodologies for evaluating key blockchain characteristics applicable to other systems. This research advances the understanding of blockchain technologies and their implications for the future digital economy. Data and code are available on GitHub as open source.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>GeoFaaS: An Edge-to-Cloud FaaS Platform</title>
<link>https://arxiv.org/abs/2405.14413</link>
<guid>https://arxiv.org/abs/2405.14413</guid>
<content:encoded><![CDATA[
<div> 关键词：GeoFaaS、边缘计算、云计算、函数即服务（FaaS）、地理位置意识

<br /><br />
总结:本文提出了一种新型的边缘到云“函数即服务”(FaaS)平台——GeoFaaS。该平台利用实时客户端位置信息，将请求透明地执行在最近可用的FaaS节点上，以实现高效网络使用和降低延迟。当边缘资源过载时，GeoFaaS能够透明地将请求卸载到云端，确保一致的执行性能，无需用户干预。GeoFaaS具有模块化和分散化的架构，基于单节点FaaS系统tinyFaaS构建，可作为独立的边缘到云FaaS平台运行，同时也可以作为现有FaaS服务的路由层进行集成。为了评估这一方法的有效性，研究团队开发了一个开源概念验证原型，并通过实验研究了其性能和容错性。 <div>
arXiv:2405.14413v2 Announce Type: replace 
Abstract: The massive growth of mobile and IoT devices demands geographically distributed computing systems for optimal performance, privacy, and scalability. However, existing edge-to-cloud serverless platforms lack location awareness, resulting in inefficient network usage and increased latency.
  In this paper, we propose GeoFaaS, a novel edge-to-cloud Function-as-a-Service (FaaS) platform that leverages real-time client location information for transparent request execution on the nearest available FaaS node. If needed, GeoFaaS transparently offloads requests to the cloud when edge resources are overloaded, thus, ensuring consistent execution without user intervention. GeoFaaS has a modular and decentralized architecture: building on the single-node FaaS system tinyFaaS, GeoFaaS works as a stand-alone edge-to-cloud FaaS platform but can also integrate and act as a routing layer for existing FaaS services, e.g., in the cloud. To evaluate our approach, we implemented an open-source proof-of-concept prototype and studied performance and fault-tolerance behavior in experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Architectural Tactics to Improve the Environmental Sustainability of Microservices: A Rapid Review</title>
<link>https://arxiv.org/abs/2407.16706</link>
<guid>https://arxiv.org/abs/2407.16706</guid>
<content:encoded><![CDATA[
arXiv:2407.16706v1 Announce Type: new 
Abstract: Microservices are a popular architectural style adopted by the industry when it comes to deploying software that requires scalability, maintainability, and agile development. There is an increasing demand for improving the sustainability of microservice systems in the industry. This rapid review gathers 22 peer-reviewed studies and synthesizes architectural tactics that improve the environmental sustainability of microservices from them. We list 6 tactics that are presented in an actionable way and categorized according to their sustainability aspects and context. The sustainability aspects include energy efficiency, carbon efficiency, and resource efficiency, among which resource efficiency is the most researched one while energy efficiency and carbon efficiency are still in the early stage of study. The context categorization, including serverless platforms, decentralized networks, etc., helps to identify the tactics that we can use in a specific setting. Additionally, we present how the evidence of optimization after adopting these tactics is presented, like the measurement unit and statistical methods, and how experiments are generally set up so that this review is both instructive for our future study and our industrial practitioners' interest. We further study the insufficiencies of the current study and hope to provide insight for other researchers and the industry.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning</title>
<link>https://arxiv.org/abs/2407.16729</link>
<guid>https://arxiv.org/abs/2407.16729</guid>
<content:encoded><![CDATA[
arXiv:2407.16729v1 Announce Type: new 
Abstract: Generating human mobility trajectories is of great importance to solve the lack of large-scale trajectory data in numerous applications, which is caused by privacy concerns. However, existing mobility trajectory generation methods still require real-world human trajectories centrally collected as the training data, where there exists an inescapable risk of privacy leakage. To overcome this limitation, in this paper, we propose PateGail, a privacy-preserving imitation learning model to generate mobility trajectories, which utilizes the powerful generative adversary imitation learning model to simulate the decision-making process of humans. Further, in order to protect user privacy, we train this model collectively based on decentralized mobility data stored in user devices, where personal discriminators are trained locally to distinguish and reward the real and generated human trajectories. In the training process, only the generated trajectories and their rewards obtained based on personal discriminators are shared between the server and devices, whose privacy is further preserved by our proposed perturbation mechanisms with theoretical proof to satisfy differential privacy. Further, to better model the human decision-making process, we propose a novel aggregation mechanism of the rewards obtained from personal discriminators. We theoretically prove that under the reward obtained based on the aggregation mechanism, our proposed model maximizes the lower bound of the discounted total rewards of users. Extensive experiments show that the trajectories generated by our model are able to resemble real-world trajectories in terms of five key statistical metrics, outperforming state-of-the-art algorithms by over 48.03%. Furthermore, we demonstrate that the synthetic trajectories are able to efficiently support practical applications, including mobility prediction and location recommendation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain security for ransomware detection</title>
<link>https://arxiv.org/abs/2407.16862</link>
<guid>https://arxiv.org/abs/2407.16862</guid>
<content:encoded><![CDATA[
arXiv:2407.16862v1 Announce Type: new 
Abstract: Blockchain networks are critical for safeguarding digital transactions and assets, but they are increasingly targeted by ransomware attacks exploiting zero-day vulnerabilities. Traditional detection techniques struggle due to the complexity of these exploits and the lack of comprehensive datasets. The UGRansome dataset addresses this gap by offering detailed features for analysing ransomware and zero-day attacks, including timestamps, attack types, protocols, network flows, and financial impacts in bitcoins (BTC). This study uses the Lazy Predict library to automate machine learning (ML) on the UGRansome dataset. The study aims to enhance blockchain security through ransomware detection based on zero-day exploit recognition using the UGRansome dataset. Lazy Predict streamlines different ML model comparisons and identifies effective algorithms for threat detection. Key features such as timestamps, protocols, and financial data are used to predict anomalies as zero-day threats and to classify known signatures as ransomware. Results demonstrate that ML can significantly improve cybersecurity in blockchain environments. The DecisionTreeClassifier and ExtraTreeClassifier, with their high performance and low training times, are ideal candidates for deployment in real-time threat detection systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fostering Microservice Maintainability Assurance through a Comprehensive Framework</title>
<link>https://arxiv.org/abs/2407.16873</link>
<guid>https://arxiv.org/abs/2407.16873</guid>
<content:encoded><![CDATA[
arXiv:2407.16873v1 Announce Type: new 
Abstract: Cloud-native systems represent a significant leap in constructing scalable, large systems, employing microservice architecture as a key element in developing distributed systems through self-contained components. However, the decentralized nature of these systems, characterized by separate source codes and deployments, introduces challenges in assessing system qualities. Microservice-based systems, with their inherent complexity and the need for coordinated changes across multiple microservices, lack established best practices and guidelines, leading to difficulties in constructing and comprehending the holistic system view. This gap can result in performance degradation and increased maintenance costs, potentially requiring system refactoring. The main goal of this project is to offer maintainability assurance for microservice practitioners. It introduces an automated assessment framework tailored to microservice architecture, enhancing practitioners' understanding and analytical capabilities of the multiple system perspectives. The framework addresses various granularity levels, from artifacts to constructing holistic views of static and dynamic system characteristics. It integrates diverse perspectives, encompassing human-centric elements like architectural visualization and automated evaluations, including coupling detection, testing coverage measurement, and semantic clone identification. Validation studies involving practitioners demonstrate the framework's effectiveness in addressing diverse quality and maintainability issues, revealing insights not apparent when analyzing individual microservices in isolation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Profitable Manipulations of Cryptographic Self-Selection are Statistically Detectable</title>
<link>https://arxiv.org/abs/2407.16949</link>
<guid>https://arxiv.org/abs/2407.16949</guid>
<content:encoded><![CDATA[
arXiv:2407.16949v1 Announce Type: new 
Abstract: Cryptographic Self-Selection is a common primitive underlying leader-selection for Proof-of-Stake blockchain protocols. The concept was first popularized in Algorand [CM19], who also observed that the protocol might be manipulable. [FHWY22] provide a concrete manipulation that is strictly profitable for a staker of any size (and also prove upper bounds on the gains from manipulation).
  Separately, [YSZ23, BM24] initiate the study of undetectable profitable manipulations of consensus protocols with a focus on the seminal Selfish Mining strategy [ES14] for Bitcoin's Proof-of-Work longest-chain protocol. They design a Selfish Mining variant that, for sufficiently large miners, is strictly profitable yet also indistinguishable to an onlooker from routine latency (that is, a sufficiently large profit-maximizing miner could use their strategy to strictly profit over being honest in a way that still appears to the rest of the network as though everyone is honest but experiencing mildly higher latency. This avoids any risk of negatively impacting the value of the underlying cryptocurrency due to attack detection).
  We investigate the detectability of profitable manipulations of the canonical cryptographic self-selection leader selection protocol introduced in [CM19] and studied in [FHWY22], and establish that for any player with $\alpha < \frac{3-\sqrt{5}}{2} \approx 0.38$ fraction of the total stake, every strictly profitable manipulation is statistically detectable. Specifically, we consider an onlooker who sees only the random seed of each round (and does not need to see any other broadcasts by any other players). We show that the distribution of the sequence of random seeds when any player is profitably manipulating the protocol is inconsistent with any distribution that could arise by honest stakers being offline or timing out (for a natural stylized model of honest timeouts).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Bridging Trust into the Blockchain: A Systematic Review on On-Chain Identity</title>
<link>https://arxiv.org/abs/2407.17276</link>
<guid>https://arxiv.org/abs/2407.17276</guid>
<content:encoded><![CDATA[
arXiv:2407.17276v1 Announce Type: new 
Abstract: The ongoing regulation of blockchain-based services and applications requires the identification of users who are issuing transactions on the blockchain. This systematic review explores the current status, identifies research gaps, and outlines future research directions for establishing trusted and privacy-compliant identities on the blockchain (on-chain identity). A systematic search term was applied across various scientific databases, collecting 2232 potentially relevant research papers. These papers were narrowed down in two methodologically executed steps to 98 and finally to 13 relevant sources. The relevant articles were then systematically analyzed based on a set of screening questions. The results of the selected studies have provided insightful findings on the mechanisms of on-chain identities. On-chain identities are established using zero-knowledge proofs, public key infrastructure/certificates, and web of trust approaches. The technologies and architectures used by the authors are also highlighted. Trust has emerged as a key research gap, manifesting in two ways: firstly, a gap in how to trust the digital identity representation of a physical human; secondly, a gap in how to trust identity providers that issue identity confirmations on-chain. Potential future research avenues are suggested to help fill the current gaps in establishing trust and on-chain identities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Refined Bitcoin Security-Latency Under Network Delay</title>
<link>https://arxiv.org/abs/2212.01372</link>
<guid>https://arxiv.org/abs/2212.01372</guid>
<content:encoded><![CDATA[
arXiv:2212.01372v4 Announce Type: replace 
Abstract: We study security-latency bounds for Nakamoto consensus, i.e., how secure a block is after it becomes $k$-deep in the chain. We improve the state-of-the-art bounds by analyzing the race between adversarial and honest chains in three different phases. We find the probability distribution of the growth of the adversarial chains under models similar to those in [Guo, Ren; AFT 2022] when a target block becomes $k$-deep in the chain. We analyze certain properties of this race to model each phase with random walks that provide tighter bounds than the existing results. Combining all three phases provides novel upper and lower bounds for blockchains with small $\lambda\Delta$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Proof of Diligence: Cryptoeconomic Security for Rollups</title>
<link>https://arxiv.org/abs/2402.07241</link>
<guid>https://arxiv.org/abs/2402.07241</guid>
<content:encoded><![CDATA[
arXiv:2402.07241v2 Announce Type: replace 
Abstract: Layer 1 (L1) blockchains such as Ethereum are secured under an "honest supermajority of stake" assumption for a large pool of validators who verify each and every transaction on it. This high security comes at a scalability cost which not only effects the throughput of the blockchain but also results in high gas fees for executing transactions on chain. The most successful solution for this problem is provided by optimistic rollups, Layer 2 (L2) blockchains that execute transactions outside L1 but post the transaction data on L1.
  The security for such L2 chains is argued, informally, under the assumption that a set of nodes will check the transaction data posted on L1 and raise an alarm (a fraud proof) if faulty transactions are detected. However, all current deployments lack a proper incentive mechanism for ensuring that these nodes will do their job ``diligently'', and simply rely on a cursory incentive alignment argument for security.
  We solve this problem by introducing an incentivized watchtower network designed to serve as the first line of defense for rollups. Our main contribution is a ``Proof of Diligence'' protocol that requires watchtowers to continuously provide a proof that they have verified L2 assertions and get rewarded for the same. Proof of Diligence protocol includes a carefully-designed incentive mechanism that is provably secure when watchtowers are rational actors, under a mild rational independence assumption.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain in Healthcare: Implementing Hyperledger Fabric for Electronic Health Records at Frere Provincial Hospital</title>
<link>https://arxiv.org/abs/2407.15876</link>
<guid>https://arxiv.org/abs/2407.15876</guid>
<content:encoded><![CDATA[
arXiv:2407.15876v1 Announce Type: new 
Abstract: As healthcare systems worldwide continue to grapple with the challenges of interoperability, data security, and accessibility, integrating emerging technologies becomes imperative. This paper investigates the implementation of blockchain technology, specifically Hyperledger Fabric, for Electronic Health Records (EHR) management at Frere Hospital in the Eastern Cape province of South Africa. The paper examines the benefits and challenges of integrating blockchain into healthcare information systems. Hyperledger Fabric's modular architecture is harnessed to create a secure, transparent, and decentralized platform for storing, managing, and sharing EHRs among stakeholders. The study used a mixed-methods approach, integrating case studies and data collection methods through observation and informal questions, with the specific goal of understanding current record management methods and challenges. This method offers practical insights and validates the approach. The result demonstrates the role of blockchain in transforming healthcare, framed within a rigorous exploration and analysis. The findings of this study have broader implications for healthcare institutions seeking advanced solutions to address the persistent challenges in electronic health record management. Ultimately, the research underscores the transformative potential of blockchain technology in healthcare settings, fostering trust, security, and efficiency in the management of sensitive patient data.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach</title>
<link>https://arxiv.org/abs/2407.15879</link>
<guid>https://arxiv.org/abs/2407.15879</guid>
<content:encoded><![CDATA[
arXiv:2407.15879v1 Announce Type: new 
Abstract: The increasing security and privacy concerns in the Smart Grid sector have led to a significant demand for robust intrusion detection systems within critical smart grid infrastructure. To address the challenges posed by privacy preservation and decentralized power system zones with distinct data ownership, Federated Learning (FL) has emerged as a promising privacy-preserving solution which facilitates collaborative training of attack detection models without necessitating the sharing of raw data. However, FL presents several implementation limitations in the power system domain due to its heavy reliance on a centralized aggregator and the risks of privacy leakage during model update transmission. To overcome these technical bottlenecks, this paper introduces a novel decentralized federated anomaly detection scheme based on two main gossip protocols namely Random Walk and Epidemic. Our findings indicate that the Random Walk protocol exhibits superior performance compared to the Epidemic protocol, highlighting its efficacy in decentralized federated learning environments. Experimental validation of the proposed framework utilizing publicly available industrial control systems datasets demonstrates superior attack detection accuracy while safeguarding data confidentiality and mitigating the impact of communication latency and stragglers. Furthermore, our approach yields a notable 35% improvement in training time compared to conventional FL, underscoring the efficacy and robustness of our decentralized learning method.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Versioned Analysis of Software Quality Indicators and Self-admitted Technical Debt in Ethereum Smart Contracts with Ethstractor</title>
<link>https://arxiv.org/abs/2407.15967</link>
<guid>https://arxiv.org/abs/2407.15967</guid>
<content:encoded><![CDATA[
arXiv:2407.15967v1 Announce Type: new 
Abstract: The rise of decentralized applications (dApps) has made smart contracts imperative components of blockchain technology. As many smart contracts process financial transactions, their security is paramount. Moreover, the immutability of blockchains makes vulnerabilities in smart contracts particularly challenging because it requires deploying a new version of the contract at a different address, incurring substantial fees paid in Ether. This paper proposes Ethstractor, the first smart contract collection tool for gathering a dataset of versioned smart contracts. The collected dataset is then used to evaluate the reliability of code metrics as indicators of vulnerabilities in smart contracts. Our findings indicate that code metrics are ineffective in signalling the presence of vulnerabilities. Furthermore, we investigate whether vulnerabilities in newer versions of smart contracts are mitigated and identify that the number of vulnerabilities remains consistent over time. Finally, we examine the removal of self-admitted technical debt in contracts and uncover that most of the introduced debt has never been subsequently removed.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Addressing Trust Issues for Vehicle to Grid in Distributed Power Grids Using Blockchains</title>
<link>https://arxiv.org/abs/2407.16180</link>
<guid>https://arxiv.org/abs/2407.16180</guid>
<content:encoded><![CDATA[
arXiv:2407.16180v1 Announce Type: new 
Abstract: While blockchain offers inherent security, trust issues among stakeholders in vehicle-to-grid (V2G) applications remain unresolved due to a lack of regulatory frameworks and standardization. Additionally, a tailored decentralized privacy-preserved coordination scheme for blockchain in V2G networks is needed to ensure user privacy and efficient energy transactions. This paper proposes a V2G trading and coordination scheme tailored to the decentralized nature of blockchain as well as the interests of stakeholders utilizing smart charging points (SCPs) and Stackelberg game model. Case studies using real-world data from Southern University of Science and Technology demonstrate the efficacy of proposed scheme in reducing EV charging costs and the potential for supporting auxiliary grid services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Manifoldchain: Maximizing Blockchain Throughput via Bandwidth-Clustered Sharding</title>
<link>https://arxiv.org/abs/2407.16295</link>
<guid>https://arxiv.org/abs/2407.16295</guid>
<content:encoded><![CDATA[
arXiv:2407.16295v1 Announce Type: new 
Abstract: Bandwidth limitation is the major bottleneck that hinders scaling throughput of proof-of-work blockchains. To guarantee security, the mining rate of the blockchain is determined by the miners with the lowest bandwidth, resulting in an inefficient bandwidth utilization among fast miners. We propose Manifoldchain, an innovative blockchain sharding protocol that alleviates the impact of slow miners to maximize blockchain throughput. Manifoldchain utilizes a bandwidth-clustered shard formation mechanism that groups miners with similar bandwidths into the same shard. Consequently, this approach enables us to set an optimal mining rate for each shard based on its bandwidth, effectively reducing the waiting time caused by slow miners. Nevertheless, the adversary could corrupt miners with similar bandwidths, thereby concentrating hashing power and potentially creating an adversarial majority within a single shard. To counter this adversarial strategy, we introduce sharing mining, allowing the honest mining power of the entire network to participate in the secure ledger formation of each shard, thereby achieving the same level of security as an unsharded blockchain. Additionally, we introduce an asynchronous atomic commitment mechanism to ensure transaction atomicity across shards with various mining rates. Our theoretical analysis demonstrates that Manifoldchain scales linearly in throughput with the increase in shard numbers and inversely with network delay in each shard. We implement a full system prototype of Manifoldchain, comprehensively evaluated on both simulated and real-world testbeds. These experiments validate its vertical scalability with network bandwidth and horizontal scalability with network size, achieving a substantial improvement of 186% in throughput over baseline sharding protocols, for scenarios where bandwidths of miners range from 5Mbps to 60Mbps.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Real-Time Interactions Between Human Controllers and Remote Devices in Metaverse</title>
<link>https://arxiv.org/abs/2407.16591</link>
<guid>https://arxiv.org/abs/2407.16591</guid>
<content:encoded><![CDATA[
arXiv:2407.16591v1 Announce Type: new 
Abstract: Supporting real-time interactions between human controllers and remote devices remains a challenging goal in the Metaverse due to the stringent requirements on computing workload, communication throughput, and round-trip latency. In this paper, we establish a novel framework for real-time interactions through the virtual models in the Metaverse. Specifically, we jointly predict the motion of the human controller for 1) proactive rendering in the Metaverse and 2) generating control commands to the real-world remote device in advance. The virtual model is decoupled into two components for rendering and control, respectively. To dynamically adjust the prediction horizons for rendering and control, we develop a two-step human-in-the-loop continuous reinforcement learning approach and use an expert policy to improve the training efficiency. An experimental prototype is built to verify our algorithm with different communication latencies. Compared with the baseline policy without prediction, our proposed method can reduce 1) the Motion-To-Photon (MTP) latency between human motion and rendering feedback and 2) the root mean squared error (RMSE) between human motion and real-world remote devices significantly.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mobile Technology: A Panacea to Food Insecurity In Nigeria -- A Case Study of SELL HARVEST Application</title>
<link>https://arxiv.org/abs/2407.16614</link>
<guid>https://arxiv.org/abs/2407.16614</guid>
<content:encoded><![CDATA[
<div> 关键词：Sell Harvest、农业、技术、人工智能、数字农业

总结:
文章主要探讨了农业科技在解决全球贫困和饥饿问题上的潜力，特别是在尼日利亚这一农业产出占国内生产总值23%的国家。文中指出，尽管农业生产活动频繁，但尼日利亚仍未实现全民食物安全，主要原因是农业生产力低下与人口快速增长之间的矛盾。为了提升农业生产效率并促进食物安全，文章提出了一系列科技解决方案，包括室内垂直农业、自动化、机器人技术、现代温室实践、精准农业、人工智能以及区块链等。

此外，文章强调了手机在推广农业科技中的重要性，指出其高普及率使得数字农业成为可能。通过数字平台，消费者与农民可以更紧密地联系，实现最短供应链，从而减少农村地区的贫困和饥饿。最后，文章提出了一款名为“Sell Harvest”的移动应用提案，旨在通过数字化手段提高农业可持续性，确保食物安全。

综上所述，本文主要围绕农业技术的应用、手机在农业推广中的作用、以及一款名为“Sell Harvest”的创新移动应用展开讨论，旨在通过科技手段解决尼日利亚乃至全球的农业困境和食物安全问题。 <div>
arXiv:2407.16614v1 Announce Type: new 
Abstract: Over time, agriculture is the most consistent activity, and it evolves every day. It contributes to a vast majority of the Gross Domestic Product (GDP) of Nigeria but as ironic as it may be, there is still hunger in significant parts of the country due to low productivity in the agricultural sector and comparison to the geometric population growth. During the first half of 2022, agriculture contributed about 23% of the country's GDP while the industry and services sector had a share of the remaining 77%. This showed that with the high rate of agricultural activities, Nigeria has not achieved food security for the teeming population. and more productivity levels can be attained. Technology can/will assist Nigeria in overcoming global poverty and hunger quicker in both rural and urban areas. Today, there are many types of agricultural technologies available for farmers all over the world to increase productivity. Major technological advancements include indoor vertical farming, automation, robotics, livestock technology, modern greenhouse practices, precision agriculture, artificial intelligence, and blockchain. Mobile phones have one of the highest adoption rates of technologies developed within the last century. Digitalization will bring consumers and farmers closer together to access the shortest supply chain possible and reduce rural poverty and hunger. The paper will review the different agricultural technologies and propose a mobile solution, code Sell Harvest, to make farming more sustainable and secure food.
  Keywords: Sell Harvest, Agriculture, Technology, Artificial Intelligence, and Digital Farming.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Non-intrusive Enforcement of Decentralized Stability Protocol for IBRs in AC Microgrids</title>
<link>https://arxiv.org/abs/2310.09450</link>
<guid>https://arxiv.org/abs/2310.09450</guid>
<content:encoded><![CDATA[
arXiv:2310.09450v3 Announce Type: replace 
Abstract: This paper presents decentralized, passivity-based stability protocol for inverter-based resources (IBRs) in AC microgrids and a non-intrusive approach that enforces the protocol. By "non-intrusive" we mean that the approach does not require reprogramming IBRs' controllers to enforce the stability protocol. Implementing the approach only requires very minimal information of IBR dynamics, and sharing such information with the non-IBR-manufacturer parties does not cause any concerns on intellectual property privacy. Enforcing the protocol allows for plug-and-play operation of IBRs, while maintaining microgrid stability. The proposed method is tested by simulating two networked microgrids with tie lines and two IBRs modeled in the electromagnetic transient (EMT) time scale. Simulations show that oscillations with increasing amplitudes can occur, when two stable AC microgrids are networked. Simulations also suggest that the proposed approach can mitigate such a system-level symptom by changing less than 2 percent of energy produced by IBRs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Honeybee: Decentralized Peer Sampling with Verifiable Random Walks for Blockchain Data Sharding</title>
<link>https://arxiv.org/abs/2402.16201</link>
<guid>https://arxiv.org/abs/2402.16201</guid>
<content:encoded><![CDATA[
arXiv:2402.16201v2 Announce Type: replace 
Abstract: Data sharding$\unicode{x2013}$in which block data is sharded without sharding compute$\unicode{x2013}$is at the present the favored approach for scaling Ethereum and other popular blockchains. A key challenge toward implementing data sharding is verifying whether the entirety of a block's data is available in the network (across its shards). A central technique proposed to conduct this verification uses erasure-coded blocks and is called data availability sampling (DAS). While the high-level protocol details of DAS have been well discussed in the community, discussions around how such a protocol will be implemented at the peer-to-peer layer are lacking. We identify random sampling of nodes as a fundamental primitive necessary to carry out DAS and present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks. Honeybee is secure against attacks even in the presence of a large number of Byzantine nodes (e.g., 50% of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for DAS functions in both full nodes and light nodes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Personalized Federated Learning based on a Conditional Sparse-to-Sparser Scheme</title>
<link>https://arxiv.org/abs/2404.15943</link>
<guid>https://arxiv.org/abs/2404.15943</guid>
<content:encoded><![CDATA[
arXiv:2404.15943v3 Announce Type: replace 
Abstract: Decentralized Federated Learning (DFL) has become popular due to its robustness and avoidance of centralized coordination. In this paradigm, clients actively engage in training by exchanging models with their networked neighbors. However, DFL introduces increased costs in terms of training and communication. Existing methods focus on minimizing communication often overlooking training efficiency and data heterogeneity. To address this gap, we propose a novel \textit{sparse-to-sparser} training scheme: DA-DPFL. DA-DPFL initializes with a subset of model parameters, which progressively reduces during training via \textit{dynamic aggregation} and leads to substantial energy savings while retaining adequate information during critical learning periods.
  Our experiments showcase that DA-DPFL substantially outperforms DFL baselines in test accuracy, while achieving up to $5$ times reduction in energy costs. We provide a theoretical analysis of DA-DPFL's convergence by solidifying its applicability in decentralized and personalized learning. The code is available at:https://github.com/EricLoong/da-dpfl
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Electricity Consumption of Ethereum and Filecoin: Advances in Models and Estimates</title>
<link>https://arxiv.org/abs/2407.14519</link>
<guid>https://arxiv.org/abs/2407.14519</guid>
<content:encoded><![CDATA[
arXiv:2407.14519v1 Announce Type: new 
Abstract: The high electricity consumption of cryptocurrencies that rely on proof-of-work (PoW) consensus algorithms has raised serious environmental concerns due to its association with carbon emissions and strain on energy grids. There has been significant research into estimating the electricity consumption of PoW-based cryptocurrencies and developing alternatives to PoW.
  In this article, we introduce refined models to estimate the electricity consumption of two prominent alternatives: Ethereum, now utilizing proof-of-stake (PoS), and Filecoin, which employs proof-of-spacetime (PoSt). Ethereum stands as a leading blockchain platform for crafting decentralized applications, whereas Filecoin is recognized as the world's foremost decentralized data storage network.
  Prior studies for modeling electricity consumption have been criticized for methodological flaws and shortcomings, low-quality data, and unvalidated assumptions. We improve on this in several ways: we obtain more novel, validated data from the systems in question, extract information from existing data and research, and we improve transparency and reproducibility by clearly explaining and documenting the used methodology and explicitly stating unavoidable limitations and assumptions made. When comparing the current, most prominent models for Ethereum and Filecoin to our refined models, we find that given the wide error margins of both the refined models and the ones introduced in prior literature, the resulting average estimates are to a large extent in line with each other.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Alea-BFT: Practical Asynchronous Byzantine Fault Tolerance</title>
<link>https://arxiv.org/abs/2407.14538</link>
<guid>https://arxiv.org/abs/2407.14538</guid>
<content:encoded><![CDATA[
arXiv:2407.14538v1 Announce Type: new 
Abstract: Traditional Byzantine Fault Tolerance (BFT) state machine replication protocols assume a partial synchrony model, leading to a design where a leader replica drives the protocol and is replaced after a timeout. Recently, we witnessed a surge of asynchronous BFT protocols, which use randomization to remove the need for bounds on message delivery times, making them more resilient to adverse network conditions. However, existing research proposals still fall short of gaining practical adoption, plausibly because they are not able to combine good performance with a simple design that can be readily understood and adopted. In this paper, we present Alea-BFT, a simple and highly efficient asynchronous BFT protocol, which is gaining practical adoption, namely in Ethereum distributed validators. Alea-BFT brings the key design insight from classical protocols of concentrating part of the work on a single designated replica and incorporates this principle in a simple two-stage pipelined design, with an efficient broadcast led by the designated replica, followed by an inexpensive binary agreement. The evaluation of our research prototype implementation and two real-world integrations in cryptocurrency ecosystems shows excellent performance, improving on the fastest protocol (Dumbo-NG) in terms of latency and displaying good performance under faults.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Retrieval Augmented Generation Integrated Large Language Models in Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2407.14838</link>
<guid>https://arxiv.org/abs/2407.14838</guid>
<content:encoded><![CDATA[
arXiv:2407.14838v1 Announce Type: new 
Abstract: The rapid growth of Decentralized Finance (DeFi) has been accompanied by substantial financial losses due to smart contract vulnerabilities, underscoring the critical need for effective security auditing. With attacks becoming more frequent, the necessity and demand for auditing services has escalated. This especially creates a financial burden for independent developers and small businesses, who often have limited available funding for these services. Our study builds upon existing frameworks by integrating Retrieval-Augmented Generation (RAG) with large language models (LLMs), specifically employing GPT-4-1106 for its 128k token context window. We construct a vector store of 830 known vulnerable contracts, leveraging Pinecone for vector storage, OpenAI's text-embedding-ada-002 for embeddings, and LangChain to construct the RAG-LLM pipeline. Prompts were designed to provide a binary answer for vulnerability detection. We first test 52 smart contracts 40 times each against a provided vulnerability type, verifying the replicability and consistency of the RAG-LLM. Encouraging results were observed, with a 62.7% success rate in guided detection of vulnerabilities. Second, we challenge the model under a "blind" audit setup, without the vulnerability type provided in the prompt, wherein 219 contracts undergo 40 tests each. This setup evaluates the general vulnerability detection capabilities without hinted context assistance. Under these conditions, a 60.71% success rate was observed. While the results are promising, we still emphasize the need for human auditing at this time. We provide this study as a proof of concept for a cost-effective smart contract auditing process, moving towards democratic access to security.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Political Leanings in Web3 Betting: Decoding the Interplay of Political and Profitable Motives</title>
<link>https://arxiv.org/abs/2407.14844</link>
<guid>https://arxiv.org/abs/2407.14844</guid>
<content:encoded><![CDATA[
arXiv:2407.14844v1 Announce Type: new 
Abstract: Harnessing the transparent blockchain user behavior data, we construct the Political Betting Leaning Score (PBLS) to measure political leanings based on betting within Web3 prediction markets. Focusing on Polymarket and starting from the 2024 U.S. Presidential Election, we synthesize behaviors over 15,000 addresses across 4,500 events and 8,500 markets, capturing the intensity and direction of their political leanings by the PBLS. We validate the PBLS through internal consistency checks and external comparisons. We uncover relationships between our PBLS and betting behaviors through over 800 features capturing various behavioral aspects. A case study of the 2022 U.S. Senate election further demonstrates the ability of our measurement while decoding the dynamic interaction between political and profitable motives. Our findings contribute to understanding decision-making in decentralized markets, enhancing the analysis of behaviors within Web3 prediction environments. The insights of this study reveal the potential of blockchain in enabling innovative, multidisciplinary studies and could inform the development of more effective online prediction markets, improve the accuracy of forecast, and help the design and optimization of platform mechanisms. The data and code for the paper are accessible at the following link: https://github.com/anonymous.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AGORA: Open More and Trust Less in Binary Verification Service</title>
<link>https://arxiv.org/abs/2407.15062</link>
<guid>https://arxiv.org/abs/2407.15062</guid>
<content:encoded><![CDATA[
arXiv:2407.15062v1 Announce Type: new 
Abstract: Binary verification plays a pivotal role in software security, yet building a verification service that is both open and trustworthy poses a formidable challenge. In this paper, we introduce a novel binary verification service, AGORA, scrupulously designed to overcome the challenge. At the heart of this approach lies a strategic insight: certain tasks can be delegated to untrusted entities, while the corresponding validators are securely housed within the trusted computing base (TCB). AGORA can validate untrusted assertions generated for versatile policies. Through a novel blockchain-based bounty task manager, it also utilizes crowdsourcing to remove trust in theorem provers. These synergistic techniques successfully ameliorate the TCB size burden associated with two procedures: binary analysis and theorem proving. The design of AGORA allows untrusted parties to participate in these complex processes. Moreover, based on running the optimized TCB within trusted execution environments and recording the verification process on a blockchain, the public can audit the correctness of verification results. By implementing verification workflows for software-based fault isolation policy and side-channel mitigation, our evaluation demonstrates the efficacy of AGORA.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Secure Web Objects: Building Blocks for Metaverse Interoperability and Decentralization</title>
<link>https://arxiv.org/abs/2407.15221</link>
<guid>https://arxiv.org/abs/2407.15221</guid>
<content:encoded><![CDATA[
arXiv:2407.15221v1 Announce Type: new 
Abstract: This position paper explores how to support the Web's evolution through an underlying data-centric approach that better matches the data-orientedness of modern and emerging applications. We revisit the original vision of the Web as a hypermedia system that supports document composability and application interoperability via name-based data access. We propose the use of secure web objects (SWO), a data-oriented communication approach that can reduce complexity, centrality, and inefficiency, particularly for collaborative and local-first applications, such as the Metaverse and other collaborative applications. SWO are named, signed, application-defined objects that are secured independently of their containers or communications channels, an approach that leverages the results from over a decade-long data-centric networking research. This approach does not require intermediation by aggregators of identity, storage, and other services that are common today. We present a brief design overview, illustrated through prototypes for two editors of shared hypermedia documents: one for 3D and one for LaTeX. We also discuss our findings and suggest a roadmap for future research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Exploring the Design of Collaborative Applications via the Lens of NDN Workspace</title>
<link>https://arxiv.org/abs/2407.15234</link>
<guid>https://arxiv.org/abs/2407.15234</guid>
<content:encoded><![CDATA[
arXiv:2407.15234v1 Announce Type: new 
Abstract: Metaverse applications desire to communicate with semantically identified objects among a diverse set of cyberspace entities, such as cameras for collecting images from, sensors for sensing environment, and users collaborating with each other, all could be nearby or far away, in a timely and secure way. However, supporting the above function faces networking challenges. Today's metaverse implementations are, by and large, use secure transport connections to communicate with cloud servers instead of letting participating entities communicate directly. In this paper, we use the design and implementation of NDN Workspace, a web-based, multi-user collaborative app to showcase a new way to networking that supports many-to-many secure data exchanges among communicating entities directly. NDN Workspace users establish trust relations among each other, exchange URI-identified objects directly, and can collaborate through intermittent connectivity, all in the absence of cloud servers. Its data-centric design offers an exciting new approach to metaverse app development.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Sustainable broadcasting in Blockchain Network with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2407.15616</link>
<guid>https://arxiv.org/abs/2407.15616</guid>
<content:encoded><![CDATA[
arXiv:2407.15616v1 Announce Type: new 
Abstract: Recent estimates put the carbon footprint of Bitcoin and Ethereum at an average of 64 and 26 million tonnes of CO2 per year, respectively. To address this growing problem, several possible approaches have been proposed in the literature: creating alternative blockchain consensus mechanisms, applying redundancy reduction techniques, utilizing renewable energy sources, and employing energy-efficient devices, etc. In this paper, we follow the second avenue and propose an efficient approach based on reinforcement learning that improves the block broadcasting scheme in blockchain networks. The analysis and experimental results confirmed that the proposed improvement of the block propagation scheme could cleverly handle network dynamics and achieve better results than the default approach. Additionally, our technical integration of the simulator and developed RL environment can be used as a complete solution for further study of new schemes and protocols that use RL or other ML techniques.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dressed to Gamble: How Poker Drives the Dynamics of Wearables and Visits on Decentraland's Social Virtual World</title>
<link>https://arxiv.org/abs/2407.15625</link>
<guid>https://arxiv.org/abs/2407.15625</guid>
<content:encoded><![CDATA[
arXiv:2407.15625v1 Announce Type: new 
Abstract: Decentraland is a blockchain-based social virtual world touted to be a creative space owned by its community, unlike previous virtual worlds. Its users can create and publish wearables, virtual garments to customize avatars, which can be then sold or given away via the blockchain. Decentral Games (DG), a single project owning two prominent in-world casinos, has by far created the most wearables, with these being necessary to earn cryptocurrency in their flagship game ICE Poker. We thus present a comprehensive study that investigates how DG and ICE Poker influence the overall dynamics of Decentraland wearables and in-world visits. To this end, we analyzed 5.9 million wearable transfers made on the Polygon blockchain (and related sales) over a two-year period, and 677 million log events of in-world user positions in an overlapping 10-month period. We found that the influence of DG and Ice Poker is not only significant, but also substantial for transfers and sales monetary value of wearables, and very large for daily unique visitors and time spent in the virtual world. Despite several alternative in-world economic and artistic initiatives in Decentraland, some of which have attracted much attention from the general public, online poker appears to be the main driver of the analyzed dynamics. Our work thus contributes to the current understanding of user behavior in social virtual worlds and it is among the first to study the emerging phenomenon of blockchain-based online gambling in virtual spaces.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Preventing Out-of-Gas Exceptions by Typing</title>
<link>https://arxiv.org/abs/2407.15676</link>
<guid>https://arxiv.org/abs/2407.15676</guid>
<content:encoded><![CDATA[
arXiv:2407.15676v1 Announce Type: new 
Abstract: We continue the development of TinySol, a minimal object-oriented language based on Solidity, the standard smart-contract language used for the Ethereum platform. We first extend TinySol with exceptions and a gas mechanism, and equip it with a small-step operational semantics. Introducing the gas mechanism is fundamental for modelling real-life smart contracts in TinySol, since this is the way in which termination of Ethereum smart contracts is usually ensured. We then devise a type system for smart contracts guaranteeing that such programs never run out of gas at runtime. This is a desirable property for smart contracts, since a transaction that runs out of gas is aborted, but the price paid to run the code is not returned to the invoker.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cryptoeconomics and Tokenomics as Economics: A Survey with Opinions</title>
<link>https://arxiv.org/abs/2407.15715</link>
<guid>https://arxiv.org/abs/2407.15715</guid>
<content:encoded><![CDATA[
arXiv:2407.15715v1 Announce Type: new 
Abstract: This paper surveys products and studies on cryptoeconomics and tokenomics from an economic perspective, as these terms are still (i) ill-defined and (ii) disconnected from economic disciplines. We first suggest that they can be novel when integrated; we then conduct a literature review and case study following consensus-building for decentralization and token value for autonomy. Integration requires simultaneous consideration of strategic behavior, spamming, Sybil attacks, free-riding, marginal cost, marginal utility and stabilizers. This survey is the first systematization of knowledge on cryptoeconomics and tokenomics, aiming to bridge the contexts of economics and blockchain.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Entropic Optimal Transport for Distributed Distribution Comparison</title>
<link>https://arxiv.org/abs/2301.12065</link>
<guid>https://arxiv.org/abs/2301.12065</guid>
<content:encoded><![CDATA[
arXiv:2301.12065v2 Announce Type: replace 
Abstract: Distributed distribution comparison aims to measure the distance between the distributions whose data are scattered across different agents in a distributed system and cannot even be shared directly among the agents. In this study, we propose a novel decentralized entropic optimal transport (DEOT) method, which provides a communication-efficient and privacy-preserving solution to this problem with theoretical guarantees. In particular, we design a mini-batch randomized block-coordinate descent (MRBCD) scheme to optimize the DEOT distance in its dual form. The dual variables are scattered across different agents and updated locally and iteratively with limited communications among partial agents. The kernel matrix involved in the gradients of the dual variables is estimated by a decentralized kernel approximation method, in which each agent only needs to approximate and store a sub-kernel matrix by one-shot communication and without sharing raw data. Besides computing entropic Wasserstein distance, we show that the proposed MRBCD scheme and kernel approximation method also apply to entropic Gromov-Wasserstein distance. We analyze our method's communication complexity and, under mild assumptions, provide a theoretical bound for the approximation error caused by the convergence error, the estimated kernel, and the mismatch between the storage and communication protocols. In addition, we discuss the trade-off between the precision of the EOT distance and the strength of privacy protection when implementing our method. Experiments on synthetic data and real-world distributed domain adaptation tasks demonstrate the effectiveness of our method.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BAFFLE: A Baseline of Backpropagation-Free Federated Learning</title>
<link>https://arxiv.org/abs/2301.12195</link>
<guid>https://arxiv.org/abs/2301.12195</guid>
<content:encoded><![CDATA[
arXiv:2301.12195v3 Announce Type: replace 
Abstract: Federated learning (FL) is a general principle for decentralized clients to train a server model collectively without sharing local data. FL is a promising framework with practical applications, but its standard training paradigm requires the clients to backpropagate through the model to compute gradients. Since these clients are typically edge devices and not fully trusted, executing backpropagation on them incurs computational and storage overhead as well as white-box vulnerability. In light of this, we develop backpropagation-free federated learning, dubbed BAFFLE, in which backpropagation is replaced by multiple forward processes to estimate gradients. BAFFLE is 1) memory-efficient and easily fits uploading bandwidth; 2) compatible with inference-only hardware optimization and model quantization or pruning; and 3) well-suited to trusted execution environments, because the clients in BAFFLE only execute forward propagation and return a set of scalars to the server. Empirically we use BAFFLE to train deep models from scratch or to finetune pretrained models, achieving acceptable results. Code is available in https://github.com/FengHZ/BAFFLE.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>TrustRate: A Decentralized Platform for Hijack-Resistant Anonymous Reviews</title>
<link>https://arxiv.org/abs/2402.18386</link>
<guid>https://arxiv.org/abs/2402.18386</guid>
<content:encoded><![CDATA[
arXiv:2402.18386v3 Announce Type: replace 
Abstract: Reviews and ratings by users form a central component in several widely used products today (e.g., product reviews, ratings of online content, etc.), but today's platforms for managing such reviews are ad-hoc and vulnerable to various forms of tampering and hijack by fake reviews either by bots or motivated paid workers. We define a new metric called 'hijack-resistance' for such review platforms, and then present TrustRate, an end-to-end decentralized, hijack-resistant platform for authentic, anonymous, tamper-proof reviews. With a prototype implementation and evaluation at the scale of thousands of nodes, we demonstrate the efficacy and performance of our platform, towards a new paradigm for building products based on trusted reviews by end users without having to trust a single organization that manages the reviews.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Stochastic optimization with arbitrary recurrent data sampling</title>
<link>https://arxiv.org/abs/2401.07694</link>
<guid>https://arxiv.org/abs/2401.07694</guid>
<content:encoded><![CDATA[
arXiv:2401.07694v2 Announce Type: replace-cross 
Abstract: For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expected amount of time to visit a given data point either averaged (`target time') or supremized (`hitting time') over the current location. We demonstrate theoretically and empirically that convergence can be accelerated by selecting sampling algorithms that cover the data set most effectively. We discuss applications of our general framework to decentralized optimization and distributed non-negative matrix factorization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities</title>
<link>https://arxiv.org/abs/2406.11636</link>
<guid>https://arxiv.org/abs/2406.11636</guid>
<content:encoded><![CDATA[
arXiv:2406.11636v2 Announce Type: replace-cross 
Abstract: Segmentation models for brain lesions in MRI are commonly developed for a specific disease and trained on data with a predefined set of MRI modalities. Each such model cannot segment the disease using data with a different set of MRI modalities, nor can it segment any other type of disease. Moreover, this training paradigm does not allow a model to benefit from learning from heterogeneous databases that may contain scans and segmentation labels for different types of brain pathologies and diverse sets of MRI modalities. Additionally, the sensitivity of patient data often prevents centrally aggregating data, necessitating a decentralized approach. Is it feasible to use Federated Learning (FL) to train a single model on client databases that contain scans and labels of different brain pathologies and diverse sets of MRI modalities? We demonstrate promising results by combining appropriate, simple, and practical modifications to the model and training strategy: Designing a model with input channels that cover the whole set of modalities available across clients, training with random modality drop, and exploring the effects of feature normalization methods. Evaluation on 7 brain MRI databases with 5 different diseases shows that such FL framework can train a single model that is shown to be very promising in segmenting all disease types seen during training. Importantly, it is able to segment these diseases in new databases that contain sets of modalities different from those in training clients. These results demonstrate, for the first time, the feasibility and effectiveness of using Federated Learning to train a single 3D segmentation model on decentralised data with diverse brain diseases and MRI modalities, a necessary step towards leveraging heterogeneous real-world databases. Code will be made available at: https://github.com/FelixWag/FL-MultiDisease-MRI
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SecureVAX: A Blockchain-Enabled Secure Vaccine Passport System</title>
<link>https://arxiv.org/abs/2407.13852</link>
<guid>https://arxiv.org/abs/2407.13852</guid>
<content:encoded><![CDATA[
<div> 关键词：疫苗护照、区块链、智能合约、InterPlanetary File System (IPFS)、Ethereum。

总结:<br />
本文提出了一种基于区块链技术的新型疫苗护照系统，旨在解决现有系统的伪造、隐私和数据安全问题。该方案利用智能合约确保数据准确性和安全性，通过IPFS实现加密存储，防止个人信息泄露。原型在以太坊Sepolia测试网络上构建，评估了系统的性能和有效性。这一结合分布式存储与去中心化区块链的解决方案，旨在促进全球范围内疫苗接种管理的高效、安全和互操作性，支持全球范围内的全面疫苗接种计划。 <div>
arXiv:2407.13852v1 Announce Type: new 
Abstract: A vaccine passport serves as documentary proof, providing passport holders with greater freedom while roaming around during pandemics. It confirms vaccination against certain infectious diseases like COVID-19, Ebola, and flu. The key challenges faced by the digital vaccine passport system include passport forgery, unauthorized data access, and inaccurate information input by vaccination centers. Privacy concerns also need to be addressed to ensure that the user's personal identification information (PII) is not compromised. Additionally, it is necessary to track vaccine vials or doses to verify their authenticity, prevent misuse and illegal sales, as well as to restrict the illicit distribution of vaccines. To address these challenges, we propose a Blockchain-Enabled Secure Vaccine Passport System, leveraging the power of smart contracts. Our solution integrates off-chain and on-chain cryptographic computations, facilitating secure communication among various entities. We have utilized the InterPlanetary File System (IPFS) to store encrypted vaccine passports of citizens securely. Our prototype is built on the Ethereum platform, with smart contracts deployed on the Sepolia Test network, allowing for performance evaluation and validation of the system's effectiveness. By combining IPFS as a distributed data storage platform and Ethereum as a blockchain platform, our solution paves the way for secure, efficient, and globally interoperable vaccine passport management, supporting comprehensive vaccination initiatives worldwide.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-agent Coverage Control: From Discrete Assignments to Continuous Multi-agent Distribution Matching</title>
<link>https://arxiv.org/abs/2407.13890</link>
<guid>https://arxiv.org/abs/2407.13890</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent, spatial coverage, deployment strategies, discrete-task assignments, continuum task assignment

总结:<br />这篇论文探讨了多代理空间覆盖控制问题，这是一个广泛研究领域，涉及动态和静态部署、任务分配以及空间分布匹配。研究内容包括集中式或分散的本地交互方案，适用于有限资源和任务的离散描述，以及连续元素的混合或完全连续的情况。文章重点介绍了三种方法：<br />1) 静态覆盖通过并发区域划分和分配；<br />2) 将静态覆盖视为离散任务分配；<br />3) 大规模群体的连续任务分配。作者旨在揭示这些问题的共同特征，并引导读者关注相关的新研究方向。 <div>
arXiv:2407.13890v1 Announce Type: new 
Abstract: The multi-agent spatial coverage control problem encompasses a broad research domain, dealing with both dynamic and static deployment strategies, discrete-task assignments, and spatial distribution-matching deployment. Coverage control may involve the deployment of a finite number of agents or a continuum through centralized or decentralized, locally-interacting schemes. All these problems can be solved via a different taxonomy of deployment algorithms for multiple agents. Depending on the application scenario, these problems involve from purely discrete descriptions of tasks (finite loads) and agents (finite resources), to a mixture of discrete and continuous elements, to fully continuous descriptions of the same. Yet, it is possible to find common features that underline all the above formulations, which we aim to illustrate here. By doing so, we aim to point the reader to novel references related to these problems. The short article outline is the following: Static coverage via concurrent area partitioning and assignment; Static coverage as a discrete task assignment; and Continuum task assignment for large-scale swarms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Who Wins Ethereum Block Building Auctions and Why?</title>
<link>https://arxiv.org/abs/2407.13931</link>
<guid>https://arxiv.org/abs/2407.13931</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Boost、block auction、Ethereum、centralization、order flow

总结:
MEV-Boost块拍卖在以太坊中占据重要地位，贡献了约90%的区块。本文通过六个月的实证分析揭示了几个关键因素对区块建设者竞争力的影响。首先，多样化的订单流与市场占有率正相关；其次，独家供应商（如整合搜索者和有排他协议的外部提供者）的订单流对利润至关重要。顶级建设者的市场份额和利润率增加，受益于独家信号、非原子套利和Telegram流量等特征。这种现象形成了一种循环，即建设者需要差异化订单流才能盈利，而只有拥有较大份额时才可能获取。研究结果强调了维持以太坊去中心化和抗审查性的必要性，为改进拍卖设计提供了见解。 <div>
arXiv:2407.13931v1 Announce Type: new 
Abstract: The MEV-Boost block auction contributes approximately 90% of all Ethereum blocks. Between October 2023 and March 2024, only three builders produced 80% of them, highlighting the concentration of power within the block builder market. To foster competition and preserve Ethereum's decentralized ethos and censorship-resistance properties, understanding the dominant players' competitive edges is essential.
  In this paper, we identify features that play a significant role in builders' ability to win blocks and earn profits by conducting a comprehensive empirical analysis of MEV-Boost auctions over a six-month period. We reveal that block market share positively correlates with order flow diversity, while profitability correlates with access to order flow from Exclusive Providers, such as integrated searchers and external providers with exclusivity deals. Additionally, we show a positive correlation between market share and profit margin among the top ten builders, with features such as exclusive signal, non-atomic arbitrages, and Telegram bot flow strongly correlating with both metrics. This highlights a "chicken-and-egg" problem where builders need differentiated order flow to profit, but only receive such flow if they have a significant market share. Overall, this work provides an in-depth analysis of the key features driving the builder market towards centralization and offers valuable insights for designing further iterations of Ethereum block auctions, preserving Ethereum's censorship resistance properties.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A trustworthy blockchain-based energy trading scheme for V2G operations in distributed power grids via integrated scheduling and trading framework</title>
<link>https://arxiv.org/abs/2407.13988</link>
<guid>https://arxiv.org/abs/2407.13988</guid>
<content:encoded><![CDATA[
<div> 关键词：electric vehicles (EVs), vehicle-to-grid (V2G), blockchain, smart charging points (SCPs), fast-path practical Byzantine fault tolerance (PBFT).

总结:<br />
本文提出了一种集成的调度和交易框架，以应对电动汽车(V2G)对分布式电网的挑战。研究采用区块链技术，构建了基于智能充电桩(SCPs)的网络安全架构，利用快速路径实用拜占庭容错(fast-path PBFT)协议提高交易效率和可扩展性。通过博弈论定价策略和智能合约，实现电动汽车和运营商之间的自主决策，优化交易并提升经济效益。实验结果显示，该方法在SUSTech的实际数据上有效降低充电成本，并能支持辅助电网服务。区块链共识机制的改进在保证系统稳健的同时，显著提高了系统的扩展性。 <div>
arXiv:2407.13988v1 Announce Type: new 
Abstract: The rapid growth of electric vehicles (EVs) and the deployment of vehicle-to-grid (V2G) technology pose significant challenges for distributed power grids, particularly in fostering trust and ensuring effective coordination among stakeholders. In this paper, we developed an integrated scheduling and trading framework to conduct transparent and efficacious coordination in V2G operations. In blockchain implementation, we propose a cyber-physical blockchain architecture that enhances transaction efficiency and scalability by leveraging smart charging points (SCPs) for rapid transaction validation through a fast-path practical byzantine fault tolerance (fast-path PBFT) consensus mechanism. From the energy dispatching perspective, a game-theoretical pricing strategy is employed and smart contracts are utilized for autonomous decision-making between EVs and operators, aiming to optimize the trading process and maximize economic benefits. Numerical evaluation of blockchain consensus shows the effect of the fast-path PBFT consensus in improving systems scalability with a balanced trade-off in robustness. A case study, utilizing real-world data from the Southern University of Science and Technology (SUSTech), demonstrates significant reductions in EV charging costs and the framework potential to support auxiliary grid services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Theoretical Analysis on Block Time Distributions in Byzantine Fault-Tolerant Consensus Blockchains</title>
<link>https://arxiv.org/abs/2407.14299</link>
<guid>https://arxiv.org/abs/2407.14299</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine fault tolerance, proof-of-stake, block creation time, block propagation, block validation.

总结:<br />该论文研究了基于拜占庭容错共识的区块链网络，如Cosmos和Tezos，其特点在于证明权益机制。文章关注区块创建时间的波动性，提出数学模型分析传播验证过程。研究发现，节点间广播时间遵循Gumbel分布，且区块时间分布源于多Gumbel分布的卷积。作者还给出了适用于数据分析的近似公式，并通过实际数据验证了该模型的有效性，能够估计区块时间分布参数。这为理解此类区块链的时间行为提供了理论支持。 <div>
arXiv:2407.14299v1 Announce Type: new 
Abstract: Some blockchain networks employ a distributed consensus algorithm featuring Byzantine fault tolerance. Notably, certain public chains, such as Cosmos and Tezos, which operate on a proof-of-stake mechanism, have adopted this algorithm. While it is commonly assumed that these blockchains maintain a nearly constant block creation time, empirical analysis reveals fluctuations in this interval; this phenomenon has received limited attention. In this paper, we propose a mathematical model to account for the processes of block propagation and validation within Byzantine fault-tolerant consensus blockchains, aiming to theoretically analyze the probability distribution of block time. First, we propose stochastic processes governing the broadcasting communications among validator nodes. Consequently, we theoretically demonstrate that the probability distribution of broadcast time among validator nodes adheres to the Gumbel distribution. This finding indicates that the distribution of block time typically arises from convolving multiple Gumbel distributions. Additionally, we derive an approximate formula for the block time distribution suitable for data analysis purposes. By fitting this approximation to real-world block time data, we demonstrate the consistent estimation of block time distribution parameters.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Unravelling in Collaborative Learning</title>
<link>https://arxiv.org/abs/2407.14332</link>
<guid>https://arxiv.org/abs/2407.14332</guid>
<content:encoded><![CDATA[
<div> 关键词：collaborative learning, strategic agents, data quality, adverse selection, probabilistic verification

总结:<br />本文关注协作学习中的策略性行为，探讨了数据质量差异情况下，战略学习者组成的联盟可能遭遇“瓦解”现象。当数据质量信息不对称时，质量较差的参与者可能导致联盟收缩甚至消失。为解决这一问题，作者提出了一种基于概率验证的新方法，通过设计机制使优质和劣质数据都能公平参与，从而使得整体联盟成为纳什均衡，防止了“瓦解”现象的发生。这种方法无需外部转移，有效应对了信息不透明带来的挑战。 <div>
arXiv:2407.14332v1 Announce Type: new 
Abstract: Collaborative learning offers a promising avenue for leveraging decentralized data. However, collaboration in groups of strategic learners is not a given. In this work, we consider strategic agents who wish to train a model together but have sampling distributions of different quality. The collaboration is organized by a benevolent aggregator who gathers samples so as to maximize total welfare, but is unaware of data quality. This setting allows us to shed light on the deleterious effect of adverse selection in collaborative learning. More precisely, we demonstrate that when data quality indices are private, the coalition may undergo a phenomenon known as unravelling, wherein it shrinks up to the point that it becomes empty or solely comprised of the worst agent. We show how this issue can be addressed without making use of external transfers, by proposing a novel method inspired by probabilistic verification. This approach makes the grand coalition a Nash equilibrium with high probability despite information asymmetry, thereby breaking unravelling.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Stackelberg POMDP: A Reinforcement Learning Approach for Economic Design</title>
<link>https://arxiv.org/abs/2210.03852</link>
<guid>https://arxiv.org/abs/2210.03852</guid>
<content:encoded><![CDATA[
<div> 关键词：reinforcement learning, Stackelberg game, POMDP, no-regret learners, mechanism design

总结:<br />
本文提出了一种强化学习框架，将环境设计师（领导者）与参与者之间的互动建模为Stackelberg博弈。研究者构建了一个称为Stackelberg POMDP的决策过程模型，证明了在有限策略集下，Stackelberg博弈中的最优领导策略等于该POMDP的最优策略。针对跟随者采用无后悔学习者的假设，文章处理了复杂情境，如交替机制设计和有限交流。通过实验验证了训练框架的有效性，并扩展了关于粗相关均衡的收敛结果。这种方法有助于经济设计中智能规则制定。 <div>
arXiv:2210.03852v4 Announce Type: replace 
Abstract: We introduce a reinforcement learning framework for economic design where the interaction between the environment designer and the participants is modeled as a Stackelberg game. In this game, the designer (leader) sets up the rules of the economic system, while the participants (followers) respond strategically. We integrate algorithms for determining followers' response strategies into the leader's learning environment, providing a formulation of the leader's learning problem as a POMDP that we call the Stackelberg POMDP. We prove that the optimal leader's strategy in the Stackelberg game is the optimal policy in our Stackelberg POMDP under a limited set of possible policies, establishing a connection between solving POMDPs and Stackelberg games. We solve our POMDP under a limited set of policy options via the centralized training with decentralized execution framework. For the specific case of followers that are modeled as no-regret learners, we solve an array of increasingly complex settings, including problems of indirect mechanism design where there is turn-taking and limited communication by agents. We demonstrate the effectiveness of our training framework through ablation studies. We also give convergence results for no-regret learners to a Bayesian version of a coarse-correlated equilibrium, extending known results to correlated types.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Liquid Staking Tokens in Automated Market Makers</title>
<link>https://arxiv.org/abs/2403.10226</link>
<guid>https://arxiv.org/abs/2403.10226</guid>
<content:encoded><![CDATA[
<div> 关键词：liquid staking tokens (LSTs), automated market makers (AMMs), theoretical modeling, empirical analysis, Ethereum LSTs.

总结:<br />
本文研究了去中心化金融(DeFi)中的液态抵押代币(LSTs)在自动市场 maker(AMM)上的流动性。首先，理论模型探讨了哪种类型的AMM最适合LST流动性，并推导出交易费用需要提供足够补偿的公式，以应对LST价格波动导致的损失。文章关注两点：1)与将资金存入AMM外相比，持有LST的损失（"impermanent loss"）；2)相较于全额抵押，为LST提供流动性的相对盈利能力。实证分析发现，尽管交易费通常能弥补损失，但全押在某些情况下更赚钱，这引发了对当前LST在AMM中流动性分配可持续性的质疑。 <div>
arXiv:2403.10226v2 Announce Type: replace 
Abstract: This paper studies liquid staking tokens (LSTs) on automated market makers (AMMs), both theoretically and empirically. LSTs are tokenized representations of staked assets on proof-of-stake blockchains. First, we model LST-liquidity on AMMs theoretically, categorizing suitable AMM types for LST liquidity and deriving formulas for the necessary returns from trading fees to adequately compensate liquidity providers under the particular price trajectories of LSTs. For the latter, two relevant metrics are considered: (1) losses compared to holding the liquidity outside the AMM (loss-versus-holding, or "impermanent loss"), and (2) the relative profitability compared to fully staking the capital (loss-versus-staking) which is specifically tailored to the case of LST-liquidity. Next, we empirically measure these metrics for Ethereum LSTs across the most relevant AMM pools. We find that, while trading fees often compensate for impermanent loss, fully staking is more profitable for many pools, raising questions about the sustainability of the current LST liquidity allocation to AMMs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The need of a self for self-driving cars a theoretical model applying homeostasis to self driving</title>
<link>https://arxiv.org/abs/2407.12795</link>
<guid>https://arxiv.org/abs/2407.12795</guid>
<content:encoded><![CDATA[
<div> 关键词：self-driving cars, homeostatic architecture, inward sensors, outward sensors, blockchain technology

总结:<br />
本文探讨了一种新颖的自动驾驶汽车"自我"构建理念，基于家态架构。该架构强调通过内在传感器监测车辆状态（如金属部件、电池等），并利用外向传感器（如相机和LIDAR）评估对家态的影响，而非直接模仿人类视觉理解现实。虚拟环境被用于加速训练，车辆间通过区块链技术交流学习，避免重复错误。文章还提出了专为自动驾驶设计的语言，以支持精细的数据解读和响应。这种动态调整行为的方法促进了合作与持续优化。这一研究对于AI发展、应用及未来研究方向具有深远影响。 <div>
arXiv:2407.12795v1 Announce Type: new 
Abstract: This paper explores the concept of creating a "self" for self-driving cars through a homeostatic architecture designed to enhance their autonomy, safety, and efficiency. The proposed system integrates inward focused sensors to monitor the car's internal state, such as the condition of its metal bodywork, wheels, engine, and battery, establishing a baseline homeostatic state representing optimal functionality. Outward facing sensors, like cameras and LIDAR, are then interpreted via their impact on the car's homeostatic state by quantifying deviations from homeostasis. This contrasts with the approach of trying to make cars "see" reality in a similar way to humans and identify elements in their reality in the same way humans. Virtual environments would be leveraged to accelerate training. Additionally, cars are programmed to communicate and share experiences via blockchain technology, learning from each other's mistakes while maintaining individualized training models. A dedicated language for self-driving cars is proposed to enable nuanced interpretation and response to environmental data. This architecture allows self-driving cars to dynamically adjust their behavior based on internal and external feedback, promoting cooperation and continuous improvement. The study concludes by discussing the broader implications for AI development, potential real-world applications, and future research directions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Framework for testing Federated Learning algorithms using an edge-like environment</title>
<link>https://arxiv.org/abs/2407.12980</link>
<guid>https://arxiv.org/abs/2407.12980</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Edge Computing, Data Imbalance, Class Imbalance, Kubernetes.

总结:<br />Federated Learning (FL)是一种分布式机器学习方法，旨在保护数据隐私并提高边缘计算效率。然而，处理各客户端数据分布不均（数据不平衡或类别不平衡）是一个挑战。本文提出了一种框架，旨在简化和扩展评估FL算法的过程。该框架在基于容器编排平台Kubernetes的分布式边缘环境中进行了测试，为理解和优化FL性能提供了一种实用工具。 <div>
arXiv:2407.12980v1 Announce Type: new 
Abstract: Federated Learning (FL) is a machine learning paradigm in which many clients cooperatively train a single centralized model while keeping their data private and decentralized. FL is commonly used in edge computing, which involves placing computer workloads (both hardware and software) as close as possible to the edge, where the data is being created and where actions are occurring, enabling faster response times, greater data privacy, and reduced data transfer costs. However, due to the heterogeneous data distributions/contents of clients, it is non-trivial to accurately evaluate the contributions of local models in global centralized model aggregation. This is an example of a major challenge in FL, commonly known as data imbalance or class imbalance. In general, testing and assessing FL algorithms can be a very difficult and complex task due to the distributed nature of the systems. In this work, a framework is proposed and implemented to assess FL algorithms in a more easy and scalable way. This framework is evaluated over a distributed edge-like environment managed by a container orchestration platform (i.e. Kubernetes).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Automated Gateways: A Smart Contract-Powered Solution for Interoperability Across Blockchains</title>
<link>https://arxiv.org/abs/2407.13001</link>
<guid>https://arxiv.org/abs/2407.13001</guid>
<content:encoded><![CDATA[
<div> 关键词：Interoperability, Blockchain, Automated Gateways, Smart contracts, Cross-chain interactions.

总结:<br />本文探讨了区块链技术中的一个重要挑战——互操作性问题，阻碍了不同区块链网络间的数据和服务共享。作者提出了一种创新框架——自动门禁（Automated Gateways），它利用智能合约直接与区块链基础设施集成，提供内置的互操作性功能。通过精细访问控制机制，智能合约管理跨链交互的权限，简化服务在不同区块链之间的共享，同时保证交易的完整性和安全性。这个用户友好、自我管理权限且独立于外部平台的框架旨在促进区块链社区的更广泛应用。 <div>
arXiv:2407.13001v1 Announce Type: new 
Abstract: Interoperability is a significant challenge in blockchain technology, hindering seamless data and service sharing across diverse blockchain networks. This study introduces \textit {Automated Gateways} as a novel framework leveraging smart contracts to facilitate interoperability. Unlike existing solutions, which often require adopting new technologies or relying on external services, Automated Gateways framework is integrated directly with a blockchain's core infrastructure to enhance systems with built-in interoperability features. By implementing fine-grained access control mechanisms, smart contracts within this framework manage accessibility and authorization for cross-chain interactions and facilitate streamlining the selective sharing of services between blockchains. Our evaluation demonstrates the framework's capability to handle cross-chain interactions efficiently, significantly reduce operational complexities, and uphold transactional integrity and security across different blockchain networks. With its focus on user-friendliness, self-managed permissions, and independence from external platforms, this framework is designed to achieve broader adoption within the blockchain community.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Proof-of-Collaborative-Learning: A Multi-winner Federated Learning Consensus Algorithm</title>
<link>https://arxiv.org/abs/2407.13018</link>
<guid>https://arxiv.org/abs/2407.13018</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof-of-Work, Proof-of-Collaborative-Learning, federated learning, consensus mechanism, incentive mechanism

总结:
这篇文章提出了一种新的共识机制——Proof-of-Collaborative-Learning (PoCL)，它将区块链的计算能力转向联邦学习模型的训练。PoCL是一种多赢家机制，矿工们通过本地训练模型参与竞争，而文章设计了评估机制确保模型效率，并对可能的攻击进行了安全评估。此外，文章还介绍了一个公平的奖励分配系统，既激励获胜矿工，也保证了跨轮次的公平性。总的来说，PoCL旨在提高能源效率并重新定义区块链的激励结构，以适应分布式学习环境。 <div>
arXiv:2407.13018v1 Announce Type: new 
Abstract: Regardless of their variations, blockchains require a consensus mechanism to validate transactions, supervise added blocks, maintain network security, synchronize the network state, and distribute incentives. Proof-of-Work (PoW), one of the most influential implementations of consensus mechanisms, consumes an extraordinary amount of energy for a task that lacks direct productive output. In this paper, we propose Proof-of-Collaborative-Learning (PoCL), a multi-winner federated learning validated consensus mechanism that redirects the computation power of blockchains to train federated learning models. In addition, we present a novel evaluation mechanism to ensure the efficiency of the locally trained models of miners. We evaluated the security of our evaluation mechanism by introducing and conducting probable attacks. Moreover, we present a novel reward distribution mechanism to incentivize winning miners fairly, and demonstrate that our reward system is fair both within and across all rounds.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Identifying Smart Contract Security Issues in Code Snippets from Stack Overflow</title>
<link>https://arxiv.org/abs/2407.13271</link>
<guid>https://arxiv.org/abs/2407.13271</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contract, Stack Overflow (SO), code snippets, vulnerabilities, SOChecker.

总结:<br />本文研究了智能合约开发者在Stack Overflow上寻求问题解答时，对来自该平台的代码片段直接集成到智能合约可能带来的安全风险。大部分开发者（86.4%）在重用代码时忽视了安全性。目前的智能合约安全检测工具对不完整的代码片段效果不佳。为解决这个问题，作者提出了SOChecker，这是首个针对Stack Overflow智能合约相关代码片段的漏洞检测工具。SOChecker利用Llama2模型进行代码补全，然后应用符号执行方法检测漏洞。实验结果表明，SOChecker在897个代码片段测试集上的F1分数达到68.2%，远超GPT-3.5和GPT-4的20.9%和33.2%。研究强调了改进Q&amp;A网站代码片段安全性的必要性。 <div>
arXiv:2407.13271v1 Announce Type: new 
Abstract: Smart contract developers frequently seak solutions to developmental challenges on Q&amp;A platforms such as Stack Overflow (SO). Although community responses often provide viable solutions, the embedded code snippets can also contain hidden vulnerabilities. Integrating such code directly into smart contracts may make them susceptible to malicious attacks. We conducted an online survey and received 74 responses from smart contract developers. The results of this survey indicate that the majority (86.4%) of participants do not sufficiently consider security when reusing SO code snippets. Despite the existence of various tools designed to detect vulnerabilities in smart contracts, these tools are typically developed for analyzing fully-completed smart contracts and thus are ineffective for analyzing typical code snippets as found on SO. We introduce SOChecker, the first tool designed to identify potential vulnerabilities in incomplete SO smart contract code snippets. SOChecker first leverages a fine-tuned Llama2 model for code completion, followed by the application of symbolic execution methods for vulnerability detection. Our experimental results, derived from a dataset comprising 897 code snippets collected from smart contract-related SO posts, demonstrate that SOChecker achieves an F1 score of 68.2%, greatly surpassing GPT-3.5 and GPT-4 (20.9% and 33.2% F1 Scores respectively). Our findings underscore the need to improve the security of code snippets from Q&amp;A websites.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralised Governance for Autonomous Cyber-Physical Systems</title>
<link>https://arxiv.org/abs/2407.13566</link>
<guid>https://arxiv.org/abs/2407.13566</guid>
<content:encoded><![CDATA[
<div> 关键词：Cyber-Physical Systems (CPS), Decentralised Governance, Blockchain, Decentralised Autonomous Organisations (DAOs), Autonomous Cabin (no1s1).

总结:<br />
本文探讨了利用区块链技术实现Cyber-Physical Systems (CPS) 的去中心化治理的可能性。通过研究将计算集成到物理领域的Decentralised Autonomous Organisations (DAOs)，如自主小屋"no1s1"的例子，文章强调了区块链在管理自治物理系统中的作用。文章指出，这种自治不仅涉及技术挑战，还涉及到复杂的功能性和社会动态。作者提出，为了应对预期和突发问题，需要开发连续反馈回路和适应性治理框架。研究对基础设施研究和CPS工程领域有重要影响，为未来关于去中心化管理和物理空间自治的讨论提供了实践洞察和理论框架。 <div>
arXiv:2407.13566v1 Announce Type: new 
Abstract: This paper examines the potential for Cyber-Physical Systems (CPS) to be governed in a decentralised manner, whereby blockchain-based infrastructure facilitates the communication between digital and physical domains through self-governing and self-organising principles. Decentralised governance paradigms that integrate computation in physical domains (such as 'Decentralised Autonomous Organisations' (DAOs)) represent a novel approach to autono-mous governance and operations. These have been described as akin to cybernetic systems. Through the lens of a case study of an autonomous cabin called "no1s1" which demonstrates self-ownership via blockchain-based control and feedback loops, this research explores the potential for blockchain infrastructure to be utilised in the management of physical systems. By highlighting the considerations and challenges of decentralised governance in managing autonomous physical spaces, the study reveals that autonomy in the governance of autonomous CPS is not merely a technological feat but also involves a complex mesh of functional and social dynamics. These findings underscore the importance of developing continuous feedback loops and adaptive governance frameworks within decentralised CPS to address both expected and emergent challenges. This investigation contributes to the fields of infra-structure studies and Cyber-Physical Systems engineering. It also contributes to the discourse on decentralised governance and autonomous management of physical spaces by offering both practical insights and providing a framework for future research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Resilient Consensus Sustained Collaboratively</title>
<link>https://arxiv.org/abs/2302.02325</link>
<guid>https://arxiv.org/abs/2302.02325</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Proof-of-Work (PoW), Proof-of-Stake (PoS), Malicious Fault-Tolerant (MFT), Power-of-Collaboration (PoC).

总结:<br />
本文关注区块链技术的发展，特别是对Proof-of-Work (PoW)共识协议的能源消耗问题。作者指出PoW的局限性在于其对大量计算的需求和由此产生的能源浪费。为解决这一问题，文章提出了一种新的Power-of-Collaboration (PoC) 协议，旨在增强现有的Proof-of-Stake (PoS) 和 Malicious Fault-Tolerant (MFT) 协议的安全性，防止长期攻击。PoC设计易于集成到现有区块链中，对吞吐量的影响较小。通过协作保障安全，同时兼顾效率。 <div>
arXiv:2302.02325v4 Announce Type: replace 
Abstract: The recent growth of blockchain technology has accelerated research on decentralized platforms. Initial blockchain platforms decide on what should be added to the ledger based on Proof-of-Work (PoW) consensus protocol. PoW requires its participants to perform large computations and leads to massive energy wastage. Recent blockchains aim to replace PoW through Proof-of-Stake (PoS) and Malicious Fault-Tolerant (MFT) consensus protocols. However, the safety of the ledger created by these protocols is at the mercy of the long-term safe-keeping of the private keys of participants. As a result, these blockchains face long-range attacks. To ameliorate this situation, we present the design of our novel Power-of-Collaboration (PoC) protocol, which guards existing PoS and MFT blockchains against long-range attacks. We show that PoC can be easily appended to existing blockchains and only marginally degrades their throughputs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Improving the Accuracy of Transaction-Based Ponzi Detection on Ethereum</title>
<link>https://arxiv.org/abs/2308.16391</link>
<guid>https://arxiv.org/abs/2308.16391</guid>
<content:encoded><![CDATA[
<div> 关键词：Ponzi scheme, Ethereum blockchain, smart contract, transaction-based approach, time-series features.

总结:
本文关注于以太坊区块链上的庞氏骗局检测。尽管合同代码为基础的方法准确性高，但不具鲁棒性，因为诈骗者可通过代码混淆或创新未被检测的利润分配逻辑来欺骗。相反，基于交易的方法更稳健，但现有模型精度较低。作者提出利用时间序列特征改进这种模型，这些特征能捕捉庞氏应用的生命周期行为，而过去的研究忽视了这一点。他们提出一套新的85个特征（22个已知账户和63个时间序列），使得现成的机器学习算法在F1分数上比现有工作高出30%。这一方法旨在提高基于交易的庞氏骗局检测的准确性，增强模型的鲁棒性。 <div>
arXiv:2308.16391v2 Announce Type: replace 
Abstract: The Ponzi scheme, an old-fashioned fraud, is now popular on the Ethereum blockchain, causing considerable financial losses to many crypto investors. A few Ponzi detection methods have been proposed in the literature, most of which detect a Ponzi scheme based on its smart contract source code. This contract-code-based approach, while achieving very high accuracy, is not robust because a Ponzi developer can fool a detection model by obfuscating the opcode or inventing a new profit distribution logic that cannot be detected. On the contrary, a transaction-based approach could improve the robustness of detection because transactions, unlike smart contracts, are harder to be manipulated. However, the current transaction-based detection models achieve fairly low accuracy. In this paper, we aim to improve the accuracy of the transaction-based models by employing time-series features, which turn out to be crucial in capturing the life-time behaviour a Ponzi application but were completely overlooked in previous works. We propose a new set of 85 features (22 known account-based and 63 new time-series features), which allows off-the-shelf machine learning algorithms to achieve up to 30% higher F1-scores compared to existing works.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Effective Illicit Account Detection on Large Cryptocurrency MultiGraphs</title>
<link>https://arxiv.org/abs/2309.02460</link>
<guid>https://arxiv.org/abs/2309.02460</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptocurrency, illicit accounts, directed multi-graphs, Edge2Seq, MGD

总结: 这篇论文介绍了一种名为DIAM的方法，用于检测数字货币交易网络中的非法账户。DIAM通过Edge2Seq模块捕捉交易模式，考虑边属性和方向顺序生成节点表示。接着，它利用MGD模块和自适应消息传递机制，针对多图拓扑检测正常与非法节点之间的差异。DIAM实现了端到端训练，结果在四个比特币和以太坊数据集上优于15种现有方法，如在包含2000万个节点和2亿多边的比特币数据集中，DIAM的F1分数达到96.55%，远超第二名的83.92%。代码已开源。 <div>
arXiv:2309.02460v3 Announce Type: replace 
Abstract: Cryptocurrencies are rapidly expanding and becoming vital in digital financial markets. However, the rise in cryptocurrency-related illicit activities has led to significant losses for users. To protect the security of these platforms, it is critical to identify illicit accounts effectively. Current detection methods mainly depend on feature engineering or are inadequate to leverage the complex information within cryptocurrency transaction networks, resulting in suboptimal performance. In this paper, we present DIAM, an effective method for detecting illicit accounts in cryptocurrency transaction networks modeled by directed multi-graphs with attributed edges. DIAM first features an Edge2Seq module that captures intrinsic transaction patterns from parallel edges by considering edge attributes and their directed sequences, to generate effective node representations. Then in DIAM, we design a multigraph Discrepancy (MGD) module with a tailored message passing mechanism to capture the discrepant features between normal and illicit nodes over the multigraph topology, assisted by an attention mechanism. DIAM integrates these techniques for end-to-end training to detect illicit accounts from legitimate ones. Extensive experiments, comparing against 15 existing solutions on 4 large cryptocurrency datasets of Bitcoin and Ethereum, demonstrate that DIAM consistently outperforms others in accurately identifying illicit accounts. For example, on a Bitcoin dataset with 20 million nodes and 203 million edges, DIAM attains an F1 score of 96.55%, markedly surpassing the runner-up's score of 83.92%. The code is available at https://github.com/TommyDzh/DIAM.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FBChain: A Blockchain-based Federated Learning Model with Efficiency and Secure Communication</title>
<link>https://arxiv.org/abs/2312.00035</link>
<guid>https://arxiv.org/abs/2312.00035</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-based Federated Learning (FBChain), parameter transmission, privacy, security, efficiency.

总结:<br />
这篇文章关注于联邦学习中参数传输过程中的隐私和安全问题，特别是"参数泄漏"和"通信效率低下"。作者提出了一种基于区块链的联邦学习模型（FBChain），通过利用区块链的不可篡改性存储全局模型和本地参数哈希值，确保数据隐私并通过比较本地参数的哈希值验证一致性，从而解决"参数泄漏"。同时，采用Proof of Weighted Link Speed (PoWLS) 共识算法，选择具有较高加权链速的节点进行模型聚合和打包区块，解决了"通信效率低"的问题。实验结果证明了FBChain的有效性和在提升模型通信效率方面的优势。 <div>
arXiv:2312.00035v2 Announce Type: replace 
Abstract: Privacy and security in the parameter transmission process of federated learning are currently among the most prominent concerns. However, there are two thorny problems caused by unprotected communication methods: "parameter-leakage" and "inefficient-communication". This article proposes Blockchain-based Federated Learning (FBChain) model for federated learning parameter communication to overcome the above two problems. First, we utilize the immutability of blockchain to store the global model and hash value of local model parameters in case of tampering during the communication process, protect data privacy by encrypting parameters, and verify data consistency by comparing the hash values of local parameters, thus addressing the "parameter-leakage" problem. Second, the Proof of Weighted Link Speed (PoWLS) consensus algorithm comprehensively selects nodes with the higher weighted link speed to aggregate global model and package blocks, thereby solving the "inefficient-communication" problem. Experimental results demonstrate the effectiveness of our proposed FBChain model and its ability to improve model communication efficiency in federated learning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>User Connection and Resource Allocation Optimization in Blockchain Empowered Metaverse over 6G Wireless Communications</title>
<link>https://arxiv.org/abs/2403.05116</link>
<guid>https://arxiv.org/abs/2403.05116</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Metaverse, non-fungible tokens (NFTs), resource allocation, trust-cost ratio (TCR)

总结:<br />
本文关注区块链、Metaverse和NFT融合带来的机遇与挑战，特别是资源管理和用户隐私。研究提出一种优化方法，通过用户任务卸载、连接参数调整和服务器计算频率分配，提升数据处理效率。资源分配阶段，引入信任成本比(TCR)，平衡延迟和能源消耗，确保用户参与度和信任。核心算法DASHF结合了多项技术，如Dinkelbach算法、交替优化、SDR和新颖的分数编程。文章难点在于将问题转化为二次约束二次规划(QCQP)解决。大量模拟验证了DASHF的有效性，为改进区块链-Metaverse应用，尤其是NFT相关系统提供了关键见解。 <div>
arXiv:2403.05116v2 Announce Type: replace 
Abstract: The convergence of blockchain, Metaverse, and non-fungible tokens (NFTs) brings transformative digital opportunities alongside challenges like privacy and resource management. Addressing these, we focus on optimizing user connectivity and resource allocation in an NFT-centric and blockchain-enabled Metaverse in this paper. Through user work-offloading, we optimize data tasks, user connection parameters, and server computing frequency division. In the resource allocation phase, we optimize communication-computation resource distributions, including bandwidth, transmit power, and computing frequency. We introduce the trust-cost ratio (TCR), a pivotal measure combining trust scores from users' resources and server history with delay and energy costs. This balance ensures sustained user engagement and trust. The DASHF algorithm, central to our approach, encapsulates the Dinkelbach algorithm, alternating optimization, semidefinite relaxation (SDR), the Hungarian method, and a novel fractional programming technique from a recent IEEE JSAC paper [2]. The most challenging part of DASHF is to rewrite an optimization problem as Quadratically Constrained Quadratic Programming (QCQP) via carefully designed transformations, in order to be solved by SDR and the Hungarian algorithm. Extensive simulations validate the DASHF algorithm's efficacy, revealing critical insights for enhancing blockchain-Metaverse applications, especially with NFTs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing</title>
<link>https://arxiv.org/abs/2407.12011</link>
<guid>https://arxiv.org/abs/2407.12011</guid>
<content:encoded><![CDATA[
<div> 关键词：human action representation, nuclear power plant, digital twin, partial computation offloading, multiuser game

总结:<br />该论文关注在核电厂数字孪生（DT）中准确表示复杂人类动作（HA），以及利用第六代网络（COIN）辅助的多接入边缘计算（MEC）降低延迟的挑战。研究采用两阶段方法：首先，构建概率图形模型（PGM）来捕捉HA及其与核设施资产孪生之间的交互；其次，将部分计算任务卸载问题建模为多人博弈，设计去中心化算法优化决策和资源分配。结果表明，该方法有效处理复杂HA并优化DT环境下NPP的资源管理。 <div>
arXiv:2407.12011v1 Announce Type: new 
Abstract: This paper addresses the challenge of representing complex human action (HA) in a nuclear power plant (NPP) digital twin (DT) and minimizing latency in partial computation offloading (PCO) in sixth-generation-enabled computing in the network (COIN) assisted multiaccess edge computing (MEC). Accurate HA representation in the DT-HA model is vital for modeling human interventions that are crucial for the safe and efficient operation of NPPs. In this context, DT-enabled COIN-assisted MEC harnesses DT (known as a cybertwin) capabilities to optimize resource allocation and reduce latency effectively. A two-stage approach is employed to address system complexity. First, a probabilistic graphical model (PGM) is introduced to capture HAs in the DT abstraction. In the PGM, HA and NPP asset-twin abstractions form coupled systems that evolve and interact through observable data and control input. Next, the underlying PCO problem is formulated as a multiuser game, where NPP assets can partially offload tasks to COIN and MEC. We propose a decentralized algorithm to optimize offloading decisions, offloading ratios, and resource allocation. The simulation results demonstrate the effectiveness of the proposed method in capturing complex HAs and optimal resource allocation in DT-enabled NPPs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Gaming and Blockchain: Hype and Reality</title>
<link>https://arxiv.org/abs/2407.12134</link>
<guid>https://arxiv.org/abs/2407.12134</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, gaming industry, Enjin, Axie Infinity, transaction cost

总结: 这篇文章探讨了区块链技术在游戏行业的应用潜力与挑战。它关注了Enjin和Axie Infinity等热门区块链游戏项目，分析了分布式账本技术如何可能革新游戏经济并赋予玩家对虚拟资产的控制。然而，文章也指出实际问题，如高能耗和用户接纳度，以及对区块链是否真正必需的质疑。通过对比交易成本和玩家反馈，作者评估了区块链整合游戏的长期前景。<br /><br />总结: 区块链<br />游戏行业<br />Enjin<br />Axie Infinity<br />交易成本 <div>
arXiv:2407.12134v1 Announce Type: new 
Abstract: This paper explores the adoption of blockchain technology in the gaming industry. While supporters affirm that distributed ledger technology has potential to revolutionize gaming economies and provide players with control over their virtual assets, there are practical challenges such as energy consumption and user adoption to be addressed, and detractors question whether blockchain integration is even necessary. This report characterises popular blockchain-based gaming projects like Enjin and Axie Infinity, then compares metrics such as transaction cost and player feedback to evaluate the longevity of blockchain-integrated gaming as a whole.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Latency Price of Threshold Cryptosystem in Blockchains</title>
<link>https://arxiv.org/abs/2407.12172</link>
<guid>https://arxiv.org/abs/2407.12172</guid>
<content:encoded><![CDATA[
<div> 关键词：threshold cryptography, blockchain, latency, Byzantine-fault tolerance (BFT), proof-of-stake.

总结:
本文主要探讨了阈值密码学与使用拜占庭容错(BFT)共识协议的区块链之间的交互，重点关注延迟问题。研究者提出了一种机制，消除了紧阈值区块链上运行阈值密码学协议的一次性消息延迟。然而，许多现实中的权益证明型区块链倾向于使用阶梯阈值，这导致额外的延迟不可避免。文章还介绍了一种乐观方法来减少这种延迟，并在Aptos区块链的分布式随机数生成方案中进行了实施。实验结果显示，该乐观方法将延迟 overhead 降低了71%。 <div>
arXiv:2407.12172v1 Announce Type: new 
Abstract: Threshold cryptography is essential for many blockchain protocols. For example, many protocols rely on threshold common coin to implement asynchronous consensus, leader elections, and provide support for randomized applications. Similarly, threshold signature schemes are frequently used for protocol efficiency and state certification, and threshold decryption and threshold time-lock puzzles are often necessary for privacy.
  In this paper, we study the interplay between threshold cryptography and a class of blockchains that use Byzantine-fault tolerant (BFT) consensus protocols with a focus on latency. More specifically, we focus on blockchain-native threshold cryptosystem, where the blockchain validators seek to run a threshold cryptographic protocol once for every block with the block contents as an input to the threshold cryptographic protocol. All existing approaches for blockchain-native threshold cryptosystems introduce a latency overhead of at least one message delay for running the threshold cryptographic protocol. In this paper, we first propose a mechanism to eliminate this overhead for blockchain-native threshold cryptosystems with tight thresholds, i.e., in threshold cryptographic protocols where the secrecy and reconstruction thresholds are the same. However, many real-world proof-of-stake-based blockchain-native threshold cryptosystems rely on ramp thresholds, where reconstruction thresholds are strictly greater than secrecy thresholds. For these blockchains, we formally demonstrate that the additional delay is unavoidable. We then introduce a mechanism to minimize this delay in the optimistic case. We implement our optimistic protocol for the proof-of-stake distributed randomness scheme on the Aptos blockchain. Our measurements from the Aptos mainnet show that the optimistic approach reduces latency overhead by 71%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>L2AI: lightweight three-factor authentication and authorization in IOMT blockchain-based environment</title>
<link>https://arxiv.org/abs/2407.12187</link>
<guid>https://arxiv.org/abs/2407.12187</guid>
<content:encoded><![CDATA[
<div> 关键词：Medical IoT, Multi-factor authentication, Anonymous user authentication, Blockchain, L2AI

总结: 这篇论文关注医疗物联网（Medical IoT）的安全问题，提出了一种轻量级的多因素和匿名用户认证方案。该方案利用L2AI（一个不安全但高效的安全通道）在区块链环境中访问实时数据。L2AI通过伪身份和动态索引增强用户匿名性，支持大规模系统下的高效注册过程。它结合了单向哈希函数、异或运算及模糊挖掘算法，确保用户生物信息验证。文章采用ROR模型和BAN逻辑进行安全证明，并使用Proverif工具进行了形式化验证。总之，L2AI旨在为医疗IoT提供一个兼顾安全与效率的解决方案。 <div>
arXiv:2407.12187v1 Announce Type: new 
Abstract: Medical Internet of Things (IoMT) is the next frontier in the digital revolution and is utilized in healthcare. In this context, IoT enables individuals to remotely manage their essential activities with minimal interaction. However, the limitations of network resources and the challenges of establishing a secure channel, as well as sharing and collecting sensitive information through an insecure public channel, pose security challenges for the medical IoT. This paper presents a lightweight multi-factor authentication and anonymous user authentication scheme to access real-time data in a blockchain-based environment. The scheme utilizes an insecure channel called L2AI. L2AI ensures security and efficiency while enhancing user anonymity through the use of pseudo-identity and dynamic indexing. The proposed method supports highly scalable systems with an efficient user registration process, allowing authenticated users to access both existing and newly added system entities without additional processes. Although the scheme is primarily designed for large systems, such as health infrastructure, it is also suitable for resource-constrained devices. The scheme relies on one-way cryptographic hashing functions and bitwise XOR operations. Additionally, a fuzzy mining algorithm is employed on the user side to verify the user's biometric information. L2AI adopts the "Real-Or-Random (ROR)" model for security proof and employs BAN logic for proof of authenticity. Formal security verification is conducted using the "Automatic Validation of Internet Security Protocols and Programs" (Proverif) tool, complemented by informal security analysis demonstrating the proper functionality of L2AI.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Comparing Federated Stochastic Gradient Descent and Federated Averaging for Predicting Hospital Length of Stay</title>
<link>https://arxiv.org/abs/2407.12741</link>
<guid>https://arxiv.org/abs/2407.12741</guid>
<content:encoded><![CDATA[
<div> 关键词：医院长度 of stay (LOS), 预测, 隐私规则, 联邦学习, 优化算法

总结:<br />
该研究关注医院长度 of stay (LOS) 的预测问题，强调了在遵守隐私规则的前提下进行准确预测的重要性。文章提出将问题建模为一个分布式图，通过节点（医院）上的局部模型训练，采用全局总变分最小化（GTVMin）。联邦学习方法，如联邦随机梯度下降（FedSGD）和联邦平均（FedAVG），被应用于协作训练，确保数据不离开医疗机构。结果显示，这种方法既能实现精确的LOS预测，又能保护患者隐私。 <div>
arXiv:2407.12741v1 Announce Type: new 
Abstract: Predicting hospital length of stay (LOS) reliably is an essential need for efficient resource allocation at hospitals. Traditional predictive modeling tools frequently have difficulty acquiring sufficient and diverse data because healthcare institutions have privacy rules in place. In our study, we modeled this problem as an empirical graph where nodes are the hospitals. This modeling approach facilitates collaborative model training by modeling decentralized data sources from different hospitals without extracting sensitive data outside of hospitals. A local model is trained on a node (hospital) by aiming the generalized total variation minimization (GTVMin). Moreover, we implemented and compared two different federated learning optimization algorithms named federated stochastic gradient descent (FedSGD) and federated averaging (FedAVG). Our results show that federated learning enables accurate prediction of hospital LOS while addressing privacy concerns without extracting data outside healthcare institutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>To Trade Or Not To Trade: Cascading Waterfall Round Robin Rebalancing Mechanism for Cryptocurrencies</title>
<link>https://arxiv.org/abs/2407.12150</link>
<guid>https://arxiv.org/abs/2407.12150</guid>
<content:encoded><![CDATA[
<div> 关键词：Cascading Waterfall Round Robin Mechanism, Portfolio Rebalancing, Gas Fee, Slippage, Hyper-volatile Crypto Market

总结:<br />
本文介绍了一种创新的交易策略，名为"Cascading Waterfall Round Robin Mechanism"（瀑布轮转机制），专为波动性大的加密市场设计。该算法在考虑交易成本（如gas费和滑点）的同时，根据资产级别的微观特征和市场的宏观因素决定买卖时机。在高波动性下，它倾向于在价格下跌时买入，价格上涨时卖出，以减少噪音并确保稳健交易。这种机制可应用于各类投资基金，不局限于区块链，适用于任何交易频率和再平衡周期。总的来说，这是一种在动荡市场中实现智能资产配置的方法。 <div>
arXiv:2407.12150v1 Announce Type: cross 
Abstract: We have designed an innovative portfolio rebalancing mechanism termed the Cascading Waterfall Round Robin Mechanism. This algorithmic approach recommends an ideal size and number of trades for each asset during the periodic rebalancing process, factoring in the gas fee and slippage. The essence of the model we have created gives indications regarding whether trades should be made on individual assets depending on the uncertainty in the micro - asset level characteristics - and macro - aggregate market factors - environments. In the hyper-volatile crypto market, our approach to daily rebalancing will benefit from volatility. Price movements will cause our algorithm to buy assets that drop in prices and sell as they soar. In fact, the buying and selling happen only when certain boundaries are crossed in order to weed out any market noise and ensure sound trade execution. We have provided several numerical examples to illustrate the steps - including the calculation of several intermediate variables - of our rebalancing mechanism. The Algorithm we have developed can be easily applied outside blockchain to investment funds across all asset classes at any trading frequency and rebalancing duration.
  Shakespeare As A Crypto Trader:
  To Trade Or Not To Trade, that is the Question,
  Whether an Optimizer can Yield the Answer,
  Against the Spikes and Crashes of Markets Gone Wild,
  To Quench One's Thirst before Liquidity Runs Dry,
  Or Wait till the Tide of Momentum turns Mild.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Bribe &amp; Fork: Cheap Bribing Attacks via Forking Threat</title>
<link>https://arxiv.org/abs/2402.01363</link>
<guid>https://arxiv.org/abs/2402.01363</guid>
<content:encoded><![CDATA[
<div> 关键词：Payment Channel Networks (PCNs), bribing attacks, blockchain miners, punishment mechanism, Bribe & Fork

总结:<br />
这篇文章关注的是Payment Channel Networks (PCNs) 的安全性，尤其是对抗贿赂攻击的能力。以往的研究认为贿赂矿工忽略交易的成本高昂，但作者揭示这一成本可能大幅降低至约125美元，增加了攻击发生的可能性。他们提出了Bribe & Fork 攻击策略，结合了对分叉威胁的利用，并开发了一个新的挖矿游戏模型来分析。通过分析实际区块链实施的历史数据，研究量化了成本减少的程度。这些发现揭示了PCNs潜在的脆弱性，强调了需要强化其安全解决方案的紧迫性。 <div>
arXiv:2402.01363v2 Announce Type: replace 
Abstract: In this work, we reexamine the vulnerability of Payment Channel Networks (PCNs) to bribing attacks, where an adversary incentivizes blockchain miners to deliberately ignore a specific transaction to undermine the punishment mechanism of PCNs. While previous studies have posited a prohibitive cost for such attacks, we show that this cost may be dramatically reduced (to approximately \$125), thereby increasing the likelihood of these attacks. To this end, we introduce Bribe & Fork, a modified bribing attack that leverages the threat of a so-called feather fork which we analyze with a novel formal model for the mining game with forking. We empirically analyze historical data of some real-world blockchain implementations to evaluate the scale of this cost reduction. Our findings shed more light on the potential vulnerability of PCNs and highlight the need for robust solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Sensor-based Multi-agent Coverage Control with Spatial Separation in Unstructured Environments</title>
<link>https://arxiv.org/abs/2403.01710</link>
<guid>https://arxiv.org/abs/2403.01710</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人系统、搜索与覆盖、Voronoi方法、主动感知、碰撞避免

总结:
本文提出了一种创新的多机器人系统搜索与覆盖算法，利用Voronoi图在复杂、密集环境中实现高效导航。该方法结合了GIS和实时点云数据，通过局部感知生成非凸环境下的安全Voronoi区域，采用空间分解和球面镜像技术。此外，文中引入了死锁感知的引导地图和基于梯度优化的中心Voronoi覆盖策略，以避免全局搜索和局部感知陷阱，提高任务成功率、覆盖率和执行时间。仿真结果验证了算法的有效性，优于现有方法。 <div>
arXiv:2403.01710v3 Announce Type: replace 
Abstract: Multi-robot systems have increasingly become instrumental in tackling search and coverage problems. However, the challenge of optimizing task efficiency without compromising task success still persists, particularly in expansive, unstructured environments with dense obstacles.
  This paper presents an innovative, decentralized Voronoi-based approach for search and coverage to reactively navigate these complexities while maintaining safety.
  This approach leverages the active sensing capabilities of multi-robot systems to supplement GIS (Geographic Information System), offering a more comprehensive and real-time understanding of the environment. Based on point cloud data, which is inherently non-convex and unstructured, this method efficiently generates collision-free Voronoi regions using only local sensing information through spatial decomposition and spherical mirroring techniques.
  Then, deadlock-aware guided map integrated with a gradient-optimized, centroid Voronoi-based coverage control policy, is constructed to improve efficiency by avoiding exhaustive searches and local sensing pitfalls.
  The effectiveness of our algorithm has been validated through extensive numerical simulations in high-fidelity environments, demonstrating significant improvements in both task success rate, coverage ratio, and task execution time compared with others.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Efficacy of Various Large Language Models in Generating Smart Contracts</title>
<link>https://arxiv.org/abs/2407.11019</link>
<guid>https://arxiv.org/abs/2407.11019</guid>
<content:encoded><![CDATA[
<div> 关键词：code-generating, Large Language Models, Solidity smart contracts, Ethereum Blockchain, security.

总结:<br />本文研究了大型语言模型在生成以太坊区块链上的不可变Solidity智能合约中的应用。先前的工作（陈马克等，2012）探讨了AI代码生成能力，但这项研究扩大了范围，关注安全性和效率至关重要的领域。研究发现，虽然LLMs普遍在实现代码安全性方面有困难，但在常见合同类型上表现出惊人效果。此外，论文还提出了一种通过新提示策略生成智能合约的创新方法。总的来说，研究证实了LLMs在智能合约领域的潜力与挑战并存。 <div>
arXiv:2407.11019v1 Announce Type: new 
Abstract: This study analyzes the application of code-generating Large Language Models in the creation of immutable Solidity smart contracts on the Ethereum Blockchain. Other works such as Evaluating Large Language Models Trained on Code, Mark Chen et. al (2012) have previously analyzed Artificial Intelligence code generation abilities. This paper aims to expand this to a larger scope to include programs where security and efficiency are of utmost priority such as smart contracts. The hypothesis leading into the study was that LLMs in general would have difficulty in rigorously implementing security details in the code, which was shown through our results, but surprisingly generally succeeded in many common types of contracts. We also discovered a novel way of generating smart contracts through new prompting strategies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator</title>
<link>https://arxiv.org/abs/2407.11078</link>
<guid>https://arxiv.org/abs/2407.11078</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Class-Incremental Learning (FCIL), catastrophic forgetting, generative models, privacy-preserving, feature-generator.

总结:<br />Federated Class-Incremental Learning (FCIL) 是一种新兴的分布式学习方法，尤其适用于数据隐私保护场景。然而，传统的联邦学习算法如FedAVG 在处理连续任务时易出现知识遗忘问题。为解决这一问题，本文提出了FedGTG（Federated Global Twin Generator），它利用隐私保护的生成模型在不访问客户端数据的情况下进行全局训练。FedGTG通过在服务器端训练数据生成器和特征生成器，生成各类别的合成信息，并在客户端使用特征方向控制损失来保持旧任务知识和学习新任务。实验结果表明，FedGTG在CIFAR-10、CIFAR-100和tiny-ImageNet等数据集上表现出更好的准确性和遗忘抑制能力，同时具有更好的预测置信度。 <div>
arXiv:2407.11078v1 Announce Type: new 
Abstract: Federated Class-Incremental Learning (FCIL) increasingly becomes important in the decentralized setting, where it enables multiple participants to collaboratively train a global model to perform well on a sequence of tasks without sharing their private data. In FCIL, conventional Federated Learning algorithms such as FedAVG often suffer from catastrophic forgetting, resulting in significant performance declines on earlier tasks. Recent works, based on generative models, produce synthetic images to help mitigate this issue across all classes, but these approaches' testing accuracy on previous classes is still much lower than recent classes, i.e., having better plasticity than stability. To overcome these issues, this paper presents Federated Global Twin Generator (FedGTG), an FCIL framework that exploits privacy-preserving generative-model training on the global side without accessing client data. Specifically, the server trains a data generator and a feature generator to create two types of information from all seen classes, and then it sends the synthetic data to the client side. The clients then use feature-direction-controlling losses to make the local models retain knowledge and learn new tasks well. We extensively analyze the robustness of FedGTG on natural images, as well as its ability to converge to flat local minima and achieve better-predicting confidence (calibration). Experimental results on CIFAR-10, CIFAR-100, and tiny-ImageNet demonstrate the improvements in accuracy and forgetting measures of FedGTG compared to previous frameworks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-MedChain: Multi-Party Multi-Blockchain Medical Supply Chain Management System</title>
<link>https://arxiv.org/abs/2407.11207</link>
<guid>https://arxiv.org/abs/2407.11207</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19, Medical supply chain, Multi-party, Multi-blockchain, Smart contracts.

总结:<br />
该文章关注于COVID-19疫情期间医疗供应链管理系统的挑战，提出了Multi-MedChain，一个三层的多党、多区块链（MPMB）框架。它利用智能合约解决现有系统的不足，如端到端追踪、透明度和协作访问控制。Multi-MedChain旨在提高医疗供应链的效率和安全性，特别强调了对药品等易腐产品的监管和合规报告。作者已经实施并评估了这个解决方案，证明其实用性，并将其公开提供。总的来说，Multi-MedChain是一个创新的框架，旨在应对公共卫生危机期间的供应链管理需求。 <div>
arXiv:2407.11207v1 Announce Type: new 
Abstract: The challenges of healthcare supply chain management systems during the COVID-19 pandemic highlighted the need for an innovative and robust medical supply chain. The healthcare supply chain involves various stakeholders who must share information securely and actively. Regulatory and compliance reporting is also another crucial requirement for perishable products (e.g., pharmaceuticals) within a medical supply chain management system. Here, we propose Multi-MedChain as a three-layer multi-party, multi-blockchain (MPMB) framework utilizing smart contracts as a practical solution to address challenges in existing medical supply chain management systems. Multi-MedChain is a scalable supply chain management system for the healthcare domain that addresses end-to-end traceability, transparency, and collaborative access control to restrict access to private data. We have implemented our proposed system and report on our evaluation to highlight the practicality of the solution. The proposed solution is made publicly available.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A2E: Attribute-based Anonymity-Enhanced Authentication for Accessing Driverless Taxi Service</title>
<link>https://arxiv.org/abs/2407.11320</link>
<guid>https://arxiv.org/abs/2407.11320</guid>
<content:encoded><![CDATA[
<div> 关键词：Driverless vehicle, Authentication scheme, Attribute-based anonymity, Redactable signature, Decentralized credential issuance.

总结:<br />
这篇文章关注无人驾驶出租车（DT）服务的安全与隐私问题。提出了一种新的Attribute-based Anonymity Enhanced (A2E) 认证方案。A2E通过基于可编辑签名的用户属性凭证实现属性可验证性，同时保证匿名性和不可链接性，防止身份关联。利用环签名和秘密共享的去中心化凭证发放机制，保护用户属性隐私，提供追踪性和非诬告性。此外，A2E在追踪恶意用户和更新凭证时具有低开销，保持了可扩展性和轻量级特性，有利于实际应用。文章对A2E的安全性和性能进行了深入分析和评估。 <div>
arXiv:2407.11320v1 Announce Type: new 
Abstract: Driverless vehicle as a taxi is gaining more attention due to its potential to enhance urban transportation efficiency. However, both unforeseen incidents led by unsupervised physical users' driverless taxi (DT) rides and personalized needs of users when riding in a DT necessitate the authentication of user identity and attributes. Moreover, safeguarding user identity privacy and quickly tracing malicious users if necessary to enhance the adoption of DTs remains a challenge. This paper proposes a novel Attribute-based Anonymity Enhanced (A2E) authentication scheme for users to access DT service. From the security aspect, A2E has attribute verifiability, which is achieved by designing a user attribute credential based on redactable signature. Meanwhile, this attribute credential also satisfies unlinkability and unforgeability. In addition, A2E has enhanced anonymity, which is achieved by designing a decentralized credential issuance mechanism utilizing ring signature and secret sharing, safeguarding user attributes from association with anonymous identities. Moreover, this mechanism provides traceability and non-frameability to users. From the performance aspect, A2E causes low overhead when tracing malicious users and updating credentials. Besides, both scalability and lightweight are satisfied, which contributes to A2E's practicability. We conduct security analysis and performance evaluation to the security and performance capabilities of A2E.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>End-user Comprehension of Transfer Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2407.11440</link>
<guid>https://arxiv.org/abs/2407.11440</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, USD Tether (USDT), ERC-20 smart contracts, transfer risks, user comprehension.

总结: 这篇文章研究了用户对以太坊智能合约（如USD Tether）转移风险的理解，并调查了前78个ERC-20智能合约中的风险。研究发现，尽管用户自评技术水平各异，但对升级和黑名单风险的认知存在误区，认为其严重程度高。用户更倾向于发现成功的交易结果而非潜在风险。约19.2%的顶级ERC-20合同存在研究中的风险，还发现了其他占25.6%的风险。结果强调了提供可解释的智能合约、易于理解的用户界面和有关风险信息的必要性。 <div>
arXiv:2407.11440v1 Announce Type: new 
Abstract: Smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that end-users understand the transfer risks in smart contracts. To address this, we investigate end-user comprehension of risks in the most popular Ethereum smart contract (i.e., USD Tether (USDT)) and their prevalence in the top ERC-20 smart contracts. We focus on five transfer risks with severe impact on transfer outcomes and user objectives, including users being blacklisted, contract being paused, and contract being arbitrarily upgraded. Firstly, we conducted a user study investigating end-user comprehension of smart contract transfer risks with 110 participants and USDT/MetaMask. Secondly, we performed manual and automated source code analysis of the next top (78) ERC-20 smart contracts (after USDT) to identify the prevalence of these risks. Results show that end-users do not comprehend real risks: most (up to 71.8% of) users believe contract upgrade and blacklisting are highly severe/surprising. More importantly, twice as many users find it easier to discover successful outcomes than risky outcomes using the USDT/MetaMask UI flow. These results hold regardless of the self-rated programming and Web3 proficiency of participants. Furthermore, our source code analysis demonstrates that the examined risks are prevalent in up to 19.2% of the top ERC-20 contracts. Additionally, we discovered (three) other risks with up to 25.6% prevalence in these contracts. This study informs the need to provide explainable smart contracts, understandable UI and relevant information for risky outcomes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dataset Dictionary Learning in a Wasserstein Space for Federated Domain Adaptation</title>
<link>https://arxiv.org/abs/2407.11647</link>
<guid>https://arxiv.org/abs/2407.11647</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Source Domain Adaptation (MSDA), Decentralized, Wasserstein barycenters, Data privacy, Robustness.

总结:<br />
本文提出了一种新的方法——Decentralized Dataset Dictionary Learning（去中心化数据字典学习），解决多源领域适应（Multi-Source Domain Adaptation，MSDA）中的隐私问题。通过运用Wasserstein barycenters，该方法能够在不泄露数据隐私的前提下，捕捉多个客户端之间分布的差异，实现有效的适应。实验结果表明，与现有去中心化MSDA技术相比，新方法在五个视觉领域适应基准上表现出优越性能，并且在处理客户端并行性时更加强健，同时保持相对鲁棒性。总的来说，该工作为保护隐私的去中心化多源领域适应提供了一种创新且有效的方法。 <div>
arXiv:2407.11647v1 Announce Type: new 
Abstract: Multi-Source Domain Adaptation (MSDA) is a challenging scenario where multiple related and heterogeneous source datasets must be adapted to an unlabeled target dataset. Conventional MSDA methods often overlook that data holders may have privacy concerns, hindering direct data sharing. In response, decentralized MSDA has emerged as a promising strategy to achieve adaptation without centralizing clients' data. Our work proposes a novel approach, Decentralized Dataset Dictionary Learning, to address this challenge. Our method leverages Wasserstein barycenters to model the distributional shift across multiple clients, enabling effective adaptation while preserving data privacy. Specifically, our algorithm expresses each client's underlying distribution as a Wasserstein barycenter of public atoms, weighted by private barycentric coordinates. Our approach ensures that the barycentric coordinates remain undisclosed throughout the adaptation process. Extensive experimentation across five visual domain adaptation benchmarks demonstrates the superiority of our strategy over existing decentralized MSDA techniques. Moreover, our method exhibits enhanced robustness to client parallelism while maintaining relative resilience compared to conventional decentralized MSDA methodologies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging</title>
<link>https://arxiv.org/abs/2407.11652</link>
<guid>https://arxiv.org/abs/2407.11652</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Cross-Client Variations, Adaptive Federated Learning, Medical Images, Synthetic Data.

总结:<br />Federated Learning (FL)在医疗领域具有巨大潜力，但面临跨客户端医学图像数据变化和标注不足的挑战。本文提出Cross-Client Variations Adaptive Federated Learning (CCVA-FL)，通过将图像转换到共同特征空间来减少差异。方法包括专家标注部分图像，选择数据复杂度最低的客户端作为目标，使用Scalable Diffusion Models with Transformers (DiT)生成合成医学图像，并进行图像翻译。CCVA-FL通过共享这些多样性的合成图像，成功改善了Vanilla Federated Averaging在处理数据分布不均时的表现，同时保护了隐私。实验结果表明，这种方法显著提升了模型性能。 <div>
arXiv:2407.11652v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a privacy-preserving approach to train models on decentralized data. Its potential in healthcare is significant, but challenges arise due to cross-client variations in medical image data, exacerbated by limited annotations. This paper introduces Cross-Client Variations Adaptive Federated Learning (CCVA-FL) to address these issues. CCVA-FL aims to minimize cross-client variations by transforming images into a common feature space. It involves expert annotation of a subset of images from each client, followed by the selection of a client with the least data complexity as the target. Synthetic medical images are then generated using Scalable Diffusion Models with Transformers (DiT) based on the target client's annotated images. These synthetic images, capturing diversity and representing the original data, are shared with other clients. Each client then translates its local images into the target image space using image-to-image translation. The translated images are subsequently used in a federated learning setting to develop a server model. Our results demonstrate that CCVA-FL outperforms Vanilla Federated Averaging by effectively addressing data distribution differences across clients without compromising privacy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Self-Duplicating Random Walks for Resilient Decentralized Learning on Graphs</title>
<link>https://arxiv.org/abs/2407.11762</link>
<guid>https://arxiv.org/abs/2407.11762</guid>
<content:encoded><![CDATA[
<div> 关键词：random walks (RWs), decentralized learning, graph, node failures, link failures.

总结:<br />
文章讨论了在图中多个随机游走执行计算任务时，如何在面临节点或链路故障的情况下维持所需的随机游走数量以确保系统鲁棒性。DECAFORK是一个去中心化的算法，通过估计返回时间分布来持续监控生存的随机游走，并在预测到可能的失败时进行复制。实验结果表明，DECAFORK在快速检测和应对故障方面表现出色。理论分析也支持该算法的有效性能。 <div>
arXiv:2407.11762v1 Announce Type: new 
Abstract: Consider the setting of multiple random walks (RWs) on a graph executing a certain computational task. For instance, in decentralized learning via RWs, a model is updated at each iteration based on the local data of the visited node and then passed to a randomly chosen neighbor. RWs can fail due to node or link failures. The goal is to maintain a desired number of RWs to ensure failure resilience. Achieving this is challenging due to the lack of a central entity to track which RWs have failed to replace them with new ones by forking (duplicating) surviving ones. Without duplications, the number of RWs will eventually go to zero, causing a catastrophic failure of the system. We propose a decentralized algorithm called DECAFORK that can maintain the number of RWs in the graph around a desired value even in the presence of arbitrary RW failures. Nodes continuously estimate the number of surviving RWs by estimating their return time distribution and fork the RWs when failures are likely to happen. We present extensive numerical simulations that show the performance of DECAFORK regarding fast detection and reaction to failures. We further present theoretical guarantees on the performance of this algorithm.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Proportional Dynamics in Linear Fisher Markets with Auto-bidding: Convergence, Incentives and Fairness</title>
<link>https://arxiv.org/abs/2407.11872</link>
<guid>https://arxiv.org/abs/2407.11872</guid>
<content:encoded><![CDATA[
<div> 关键词：proportional dynamics, Fisher markets, competitive equilibrium, auto-bidding, seller-side deviation game.

总结:<br />
这篇论文探讨了比例动态在Fisher市场中的扩展，将卖家带来的物品视为一个整体进行预算分配。这种新型动态依然能导向竞争均衡，与在线广告竞标市场的自动投标有所关联。然而，虽然买家倾向于遵循比例规则，但卖家有偏离的盈利动机。作者研究了卖家偏离游戏，发现存在独特的纯纳什均衡，尽管它不等于竞争均衡，但在市场竞争充分且非严重垄断的情况下，它能提供良好的公平性保障。 <div>
arXiv:2407.11872v1 Announce Type: new 
Abstract: Proportional dynamics, originated from peer-to-peer file sharing systems, models a decentralized price-learning process in Fisher markets. Previously, items in the dynamics operate independently of one another, and each is assumed to belong to a different seller. In this paper, we show how it can be generalized to the setting where each seller brings multiple items and buyers allocate budgets at the granularity of sellers rather than individual items. The generalized dynamics consistently converges to the competitive equilibrium, and interestingly relates to the auto-bidding paradigm currently popular in online advertising auction markets. In contrast to peer-to-peer networks, the proportional rule is not imposed as a protocol in auto-bidding markets. Regarding this incentive concern, we show that buyers have a strong tendency to follow the rule, but it is easy for sellers to profitably deviate (given buyers' commitment to the rule). Based on this observation, we further study the seller-side deviation game and show that it admits a unique pure Nash equilibrium. Though it is generally different from the competitive equilibrium, we show that it attains a good fairness guarantee as long as the market is competitive enough and not severely monopolized.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Code Documentation and Analysis to Secure Software Development</title>
<link>https://arxiv.org/abs/2407.11934</link>
<guid>https://arxiv.org/abs/2407.11934</guid>
<content:encoded><![CDATA[
<div> 关键词：Code Documentation and Analysis Tool (CoDAT), consistency, code comments, large language model, semantic consistency

总结:
CoDAT是一个代码文档和分析工具，专注于维护代码与注释之间的连贯性。它利用大型语言模型检查代码片段与描述的注释的语义一致性，同时标记过时或不一致的注释，帮助开发者改进代码实现。CoDAT集成在IntelliJ IDEA中，利用Code Insight daemon和自定义正则表达式检测代码块变化，其后端设计为分布式，支持代码一致性追踪和架构编译记录。<br /><br />总结: <div>
arXiv:2407.11934v1 Announce Type: new 
Abstract: We present the Code Documentation and Analysis Tool (CoDAT). CoDAT is a tool designed to maintain consistency between the various levels of code documentation, e.g. if a line in a code sketch is changed, the comment that documents the corresponding code is also changed. That is, comments are linked and updated so as to remain internally consistent and also consistent with the code. By flagging "out of date" comments, CoDAT alerts the developer to maintain up-to-date documentation.
  We use a large language model to check the semantic consistency between a fragment of code and the comments that describe it. Thus we also flag semantic inconsistency as well as out of date comments. This helps programers write code that correctly implements a code sketch, and so provides machine support for a step-wise refinement approach, starting with a code sketch and proceeding down to code through one or more refinement iterations.
  CoDAT is implemented in the Intellij IDEA IDE where we use the Code Insight daemon package alongside a custom regular expression algorithm to mark tagged comments whose corresponding code blocks have changed. CoDAT's backend is structurally decentralized to allow a distributed ledger framework for code consistency and architectural compilation tracking.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Retrieval-Augmented Mixture of LoRA Experts for Uploadable Machine Learning</title>
<link>https://arxiv.org/abs/2406.16989</link>
<guid>https://arxiv.org/abs/2406.16989</guid>
<content:encoded><![CDATA[
<div> 关键词：Low-Rank Adaptation (LoRA), Uploadable Machine Learning (UML), Huggingface, Modelscope, Retrieval-Augmented Mixture of LoRA Experts (RAMoLE).

总结:<br />本文主要探讨了低秩适应（LoRA）在大型语言模型（LLMs）微调中的应用，尤其是在Uploadable Machine Learning（UML）平台如Huggingface和Modelscope中的作用。LoRA通过模块化和插件式设计可以集成特定领域的LoRA，增强LLM的功能。然而，UML环境中的动态LoRA库更新和混合任务需求需要一个通用的选优机制。为此，作者提出了Retrieval-Augmented Mixture of LoRA Experts (RAMoLE)框架，它包括LoraRetriever、实时的MoLE协调机制和批量推理，以适应未知LoRA并为混合任务提供个性化服务。实验结果表明，RAMoLE在性能和可扩展性上优于现有方法。 <div>
arXiv:2406.16989v2 Announce Type: replace 
Abstract: Low-Rank Adaptation (LoRA) offers an efficient way to fine-tune large language models (LLMs). Its modular and plug-and-play nature allows the integration of various domain-specific LoRAs, enhancing LLM capabilities. Open-source platforms like Huggingface and Modelscope have introduced a new computational paradigm, Uploadable Machine Learning (UML). In UML, contributors use decentralized data to train specialized adapters, which are then uploaded to a central platform to improve LLMs. This platform uses these domain-specific adapters to handle mixed-task requests requiring personalized service. Previous research on LoRA composition either focuses on specific tasks or fixes the LoRA selection during training. However, in UML, the pool of LoRAs is dynamically updated with new uploads, requiring a generalizable selection mechanism for unseen LoRAs. Additionally, the mixed-task nature of downstream requests necessitates personalized services. To address these challenges, we propose Retrieval-Augmented Mixture of LoRA Experts (RAMoLE), a framework that adaptively retrieves and composes multiple LoRAs based on input prompts. RAMoLE has three main components: LoraRetriever for identifying and retrieving relevant LoRAs, an on-the-fly MoLE mechanism for coordinating the retrieved LoRAs, and efficient batch inference for handling heterogeneous requests. Experimental results show that RAMoLE consistently outperforms baselines, highlighting its effectiveness and scalability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning</title>
<link>https://arxiv.org/abs/2407.09658</link>
<guid>https://arxiv.org/abs/2407.09658</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Poisoning Attacks, Backdoor Attacks, Non-IID Data, Anomaly Detection.

总结:<br />
本文主要探讨了联邦学习中面临的一项挑战：非独立同分布（Non-IID）数据对后门攻击检测的影响。传统的基于异常检测的方法在数据多样性下效果减弱。为解决这个问题，作者提出了一种新的分布感知异常检测机制BoBa。BoBa分为两步：首先，利用数据分布对客户端进行聚类；其次，通过投票机制进行后门攻击检测。文章引入了一种新颖的数据分布推理方法，并采用重叠聚类增强检测鲁棒性。实验结果显示，BoBa在多种攻击策略和环境下能有效降低攻击成功率至0.001以下，同时保持较高的主任务精度。 <div>
arXiv:2407.09658v1 Announce Type: new 
Abstract: Federated learning, while being a promising approach for collaborative model training, is susceptible to poisoning attacks due to its decentralized nature. Backdoor attacks, in particular, have shown remarkable stealthiness, as they selectively compromise predictions for inputs containing triggers. Previous endeavors to detect and mitigate such attacks are based on the Independent and Identically Distributed (IID) data assumption where benign model updates exhibit high-level similarity in multiple feature spaces due to IID data. Thus, outliers are detected as backdoor attacks. Nevertheless, non-IID data presents substantial challenges in backdoor attack detection, as the data variety introduces variance among benign models, making outlier detection-based mechanisms less effective.
  We propose a novel distribution-aware anomaly detection mechanism, BoBa, to address this problem. In order to differentiate outliers arising from data variety versus backdoor attack, we propose to break down the problem into two steps: clustering clients utilizing their data distribution followed by a voting-based detection. Based on the intuition that clustering and subsequent backdoor detection can drastically benefit from knowing client data distributions, we propose a novel data distribution inference mechanism. To improve detection robustness, we introduce an overlapping clustering method, where each client is associated with multiple clusters, ensuring that the trustworthiness of a model update is assessed collectively by multiple clusters rather than a single cluster. Through extensive evaluations, we demonstrate that BoBa can reduce the attack success rate to lower than 0.001 while maintaining high main task accuracy across various attack strategies and experimental settings.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OpenTracer: A Dynamic Transaction Trace Analyzer for Smart Contract Invariant Generation and Beyond</title>
<link>https://arxiv.org/abs/2407.10039</link>
<guid>https://arxiv.org/abs/2407.10039</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart contracts, Blockchain, Transaction history, Invariant, OpenTracer.

总结:
OpenTracer是一个开源工具，专注于智能合约的动态分析，填补了当前市场在全面跟踪交易信息、提取用户所需数据（如不变量）方面的空白。该工具设计用于确保每个执行步骤的完整追踪，已成功分析了350,800个以太坊交易，从预设模板中推断出23种不同类型的不变量。OpenTracer为开发者和研究人员提供了宝贵资源，他们可以借此研究交易行为或验证新的不变量。工具代码可从https://github.com/jeffchen006/OpenTracer获取。 <div>
arXiv:2407.10039v1 Announce Type: new 
Abstract: Smart contracts, self-executing programs on the blockchain, facilitate reliable value exchanges without centralized oversight. Despite the recent focus on dynamic analysis of their transaction histories in both industry and academia, no open-source tool currently offers comprehensive tracking of complete transaction information to extract user-desired data such as invariant-related data. This paper introduces OpenTracer, designed to address this gap. OpenTracer guarantees comprehensive tracking of every execution step, providing complete transaction information. OpenTracer has been employed to analyze 350,800 Ethereum transactions, successfully inferring 23 different types of invariant from predefined templates. The tool is fully open-sourced, serving as a valuable resource for developers and researchers aiming to study transaction behaviors or extract and validate new invariants from transaction traces. The source code of OpenTracer is available at https://github.com/jeffchen006/OpenTracer.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Identity Chain</title>
<link>https://arxiv.org/abs/2407.10187</link>
<guid>https://arxiv.org/abs/2407.10187</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptocurrencies, privacy, accountability, IdentityChain, KYC

总结:
IdentityChain是一个结合了隐私和问责性的新型区块链框架，旨在解决首代加密货币的隐私与监管合规问题。它建立在公共区块链（如以太坊、Ton或Polygon）之上，作为KYC（了解你的客户）服务。该系统强调隐私保护，通过加密技术确保用户信息安全，防止利益冲突。同时，问责原则防止用户不当行为，实现隐私和监管的有效平衡，推动区块链技术的稳健发展和更广泛接纳。 <div>
arXiv:2407.10187v1 Announce Type: new 
Abstract: The first generation of cryptocurrencies introduced revolutionary concepts, yet faced challenges in privacy and regulatory compliance. While subsequent cryptocurrencies aimed to address privacy concerns (like Zcash and Monero), they often conflicted with regulatory frameworks, hindering broader adoption. In response, inspired by recent researches about privacy and accountability and incentive techniques in Blockchain, we propose IdentityChain as a novel framework that integrates privacy and accountability principles, leading to a robust system equipped with adaptable rules.
  IdentityChain is a KYC (Know Your Customer) service on top of a public Blockchain (e.g., Ethereum, Ton, Polygon). The goal is to maintain privacy while ensuring compliance with existing regulations. Privacy is one of the key characteristics of IdentityChain, it's crucial for preventing conflicts of interests further discussed how. Accountability is also one of the main characteristics of IdentityChain and prevents from misbehave of users. Privacy and accountability together wouldn't be possible unless advancements in cryptography.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Error Analysis of the Secret Key Generation Algorithm Using Analog Function Computation</title>
<link>https://arxiv.org/abs/2407.10276</link>
<guid>https://arxiv.org/abs/2407.10276</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Approach, Gaussian primes, Secret key generation, Distributed nodes, Fading channel.

总结:
本文提出了一种去中心化的无线通信安全方法，利用分布式节点之间的Gaussian素数生成加密密钥。系统模型包括预处理和后处理步骤以在网络中共享密钥。研究考虑了热噪声功率和信道估计误差等错误因素，并通过模拟评估了因子分解成功率。文章指出路径损耗引起的大型衰落对信息和功率损失有重大影响。研究还探讨了不同因子分解容忍值对成功率的影响，并对比了2用户和3用户场景下的性能。总的来说，该工作提供了在一个衰落信道下，去中心化密钥生成方法的稳健性和效率分析。 <div>
arXiv:2407.10276v1 Announce Type: new 
Abstract: This study introduces a decentralized approach to secure wireless communication using a cryptographic secret key generation algorithm among distributed nodes. The system model employs Gaussian prime numbers, ensuring the collaborative generation of a secret key. Pre-processing and post-processing functions enable to generate a secret key across the network. An error model evaluates aspects like thermal noise power and channel estimation errors, while simulations assess the success rate to factorize the norm of the secret key. It is observed that path loss-induced large scale fading emerges as a critical component impacting information and power loss. The robustness of the proposed model under fading channel conditions is evaluated with a success rate. Additionally, it is also observed that the tolerance value set in the factorization algorithms has a significant impact on the success rate. Furthermore, the success rate is compared in two scenarios, one with 2 users and another with 3 users, to provide a comprehensive evaluation of the system performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Feasibility of a Smart Contract "Kill Switch"</title>
<link>https://arxiv.org/abs/2407.10302</link>
<guid>https://arxiv.org/abs/2407.10302</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, smart contract, termination mechanisms, EU Data Act, regulatory compliance

总结:<br />
本文探讨了区块链技术的快速发展与监管需求之间的碰撞，重点关注智能合约的终止机制。研究覆盖了多个主流平台如以太坊、BNB智能链等，分析它们在实现消费者保护、错误纠正和符合欧盟数据法（GDPR）方面的策略。文章指出，区块链存在多样化的终止合同方法，从不可更改的带有内置终止条件的合约到可升级允许后期修改的合约。实施“智能合约终结开关”面临平衡监管与去中心化、技术可行性以及对系统安全和信任影响的挑战。总的来说，文章揭示了区块链在法律适应性与技术复杂性之间寻找平衡的努力。 <div>
arXiv:2407.10302v1 Announce Type: new 
Abstract: The advent of blockchain technology and its adoption across various sectors have raised critical discussions about the need for regulatory mechanisms to ensure consumer protection, maintain financial stability, and address privacy concerns without compromising the foundational principles of decentralization and immutability inherent in blockchain platforms. We examine the existing mechanisms for smart contract termination across several major blockchain platforms, including Ethereum, BNB Smart Chain, Cardano, Solana, Hyperledger Fabric, Corda, IOTA, Apotos, and Sui. We assess the compatibility of these mechanisms with the requirements of the EU Data Act, focusing on aspects such as consumer protection, error correction, and regulatory compliance. Our analysis reveals a diverse landscape of approaches, from immutable smart contracts with built-in termination conditions to upgradable smart contracts that allow for post-deployment modifications. We discuss the challenges associated with implementing the so-called smart contract "kill switches," such as the balance between enabling regulatory compliance and preserving the decentralized ethos, the technical feasibility of such mechanisms, and the implications for security and trust in the ecosystem.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Investigating shocking events in the Ethereum stablecoin ecosystem through temporal multilayer graph structure</title>
<link>https://arxiv.org/abs/2407.10614</link>
<guid>https://arxiv.org/abs/2407.10614</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、blockchain、cryptocurrency、crash event、temporal analysis

总结:<br />
本文探讨了Web3时代区块链技术驱动的加密货币市场，重点关注Ethereum上稳定币TerraUSD和LUNA的崩溃事件。研究利用复杂网络分析和多层时间图，揭示了在不同时间尺度下，稳定币之间的强关联以及崩溃前后系统结构的变化。作者发现崩溃前后的异常信号对图结构指标和用户行为有显著影响。这一跨链、时间序列的图分析方法对于理解加密货币市场动态具有重要意义，对于监管机构监控风险和保护用户具有实践价值。总的来说，该研究强调了在Web衍生数据领域进行时间序列分析的必要性，以及图形分析如何增强传统经济计量学研究。 <div>
arXiv:2407.10614v1 Announce Type: new 
Abstract: In the dynamic landscape of the Web, we are witnessing the emergence of the Web3 paradigm, which dictates that platforms should rely on blockchain technology and cryptocurrencies to sustain themselves and their profitability. Cryptocurrencies are characterised by high market volatility and susceptibility to substantial crashes, issues that require temporal analysis methodologies able to tackle the high temporal resolution, heterogeneity and scale of blockchain data. While existing research attempts to analyse crash events, fundamental questions persist regarding the optimal time scale for analysis, differentiation between long-term and short-term trends, and the identification and characterisation of shock events within these decentralised systems. This paper addresses these issues by examining cryptocurrencies traded on the Ethereum blockchain, with a spotlight on the crash of the stablecoin TerraUSD and the currency LUNA designed to stabilise it. Utilising complex network analysis and a multi-layer temporal graph allows the study of the correlations between the layers representing the currencies and system evolution across diverse time scales. The investigation sheds light on the strong interconnections among stablecoins pre-crash and the significant post-crash transformations. We identify anomalous signals before, during, and after the collapse, emphasising their impact on graph structure metrics and user movement across layers. This paper pioneers temporal, cross-chain graph analysis to explore a cryptocurrency collapse. It emphasises the importance of temporal analysis for studies on web-derived data and how graph-based analysis can enhance traditional econometric results. Overall, this research carries implications beyond its field, for example for regulatory agencies aiming to safeguard users from shocks and monitor investment risks for citizens and clients.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>MARTSIA: Safeguarding Data Confidentiality in Blockchain-Driven Process Execution</title>
<link>https://arxiv.org/abs/2407.10684</link>
<guid>https://arxiv.org/abs/2407.10684</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain, Multi-Authority Approach, Transaction Systems, Interoperating Applications, MARTSIA.

总结:<br />
文章提出了一种新型区块链技术解决方案，名为MARTSIA（Multi-Authority Approach to Transaction Systems for Interoperating Applications）。MARTSIA专注于解决公共区块链在保证透明性和可靠性的同时，如何保护数据隐私的问题。它通过用户自定义策略和证书声明的属性，实现消息部分的读取访问控制，仅授权用户能够解读加密数据，而所有区块链节点仍能验证其完整性。MARTSIA结合了区块链、多权威属性基础加密和分布式哈希表数据存储技术，旨在促进多方协作的可信与保密性。 <div>
arXiv:2407.10684v1 Announce Type: new 
Abstract: Blockchain technology streamlines multi-party collaborations in decentralized settings, especially where trust is limited. While public blockchains enhance transparency and reliability, they conflict with confidentiality. To address this, we introduce Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA). MARTSIA provides read-access control at the message-part level through user-defined policies and certifier-declared attributes, so that only authorized actors can interpret encrypted data while all blockchain nodes can verify its integrity. To this end, MARTSIA resorts to blockchain, Multi-Authority Attribute-Based Encryption and distributed hash-table data-stores.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Thinking Fast and Slow: Data-Driven Adaptive DeFi Borrow-Lending Protocol</title>
<link>https://arxiv.org/abs/2407.10890</link>
<guid>https://arxiv.org/abs/2407.10890</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized finance (DeFi), borrowing, lending platforms, over-collateralization, adaptive protocol.

总结:<br />本文提出了一种适应性、数据驱动的去中心化金融借贷协议。该协议包含两个关键组件：高频控制器和低频规划器。控制器通过学习算法快速调整利率，以应对市场动态，降低用户在市场不匹配时的机会成本；规划器分析用户行为，设定最优的超额抵押比率，平衡风险与长期收益。文章提供了理论保证，包括短期组件的收敛速度和抗扰动能力，以及长期协议的有效性。实证结果验证了这些优势。这一创新方法有助于提高DeFi市场的稳定性和效率。 <div>
arXiv:2407.10890v1 Announce Type: new 
Abstract: Decentralized finance (DeFi) borrowing and lending platforms are crucial to the decentralized economy, involving two main participants: lenders who provide assets for interest and borrowers who offer collateral exceeding their debt and pay interest. Collateral volatility necessitates over-collateralization to protect lenders and ensure competitive returns. Traditional DeFi platforms use a fixed interest rate curve based on the utilization rate (the fraction of available assets borrowed) and determine over-collateralization offline through simulations to manage risk. This method doesn't adapt well to dynamic market changes, such as price fluctuations and evolving user needs, often resulting in losses for lenders or borrowers. In this paper, we introduce an adaptive, data-driven protocol for DeFi borrowing and lending. Our approach includes a high-frequency controller that dynamically adjusts interest rates to maintain market stability and competitiveness with external markets. Unlike traditional protocols, which rely on user reactions and often adjust slowly, our controller uses a learning-based algorithm to quickly find optimal interest rates, reducing the opportunity cost for users during periods of misalignment with external rates. Additionally, we use a low-frequency planner that analyzes user behavior to set an optimal over-collateralization ratio, balancing risk reduction with profit maximization over the long term. This dual approach is essential for adaptive markets: the short-term component maintains market stability, preventing exploitation, while the long-term planner optimizes market parameters to enhance profitability and reduce risks. We provide theoretical guarantees on the convergence rates and adversarial robustness of the short-term component and the long-term effectiveness of our protocol. Empirical validation confirms our protocol's theoretical benefits.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain Governance: An Empirical Analysis of User Engagement on DAOs</title>
<link>https://arxiv.org/abs/2407.10945</link>
<guid>https://arxiv.org/abs/2407.10945</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain DAOs, voting, minimal quorum, Ethereum blockchain, voter activity

总结:<br />
本文研究了四个主要的区块链去中心化自治组织（DAO）——Aave、Compound、Lido和Uniswap的投票情况。作者通过直接从以太坊区块链收集数据，发现大多数投票中所需的最小投票人数（即“最小多数”）相当小。为了深入了解这些DAO的实际决策者，文章利用了Ethereum Name Service（ENS）、Sybil.org和Compound的数据，将投票者分为不同的类别。这项分析揭示了区块链治理中参与度和权力分布的特点。 <div>
arXiv:2407.10945v1 Announce Type: new 
Abstract: In this note, we examine voting on four major blockchain DAOs: Aave, Compound, Lido and Uniswap. Using data directly collected from the Ethereum blockchain, we examine voter activity.
  We find that in most votes, the "minimal quorum," i.e., the smallest number of active voters who could swing the vote is quite small.
  To understand who is actually driving these DAOs, we use data from the Ethereum Name Service (ENS), Sybil.org, and Compound, to divide voters into different categories.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Blockchain Risk Parity Line: Moving From The Efficient Frontier To The Final Frontier Of Investments</title>
<link>https://arxiv.org/abs/2407.09536</link>
<guid>https://arxiv.org/abs/2407.09536</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, risk parity, risk managed portfolios, sub-funds (Alpha, Beta, Gamma), decentralized ledger technology

总结:
本文探讨了如何利用区块链技术构建风险平衡的投资组合，通过创建三个子基金（Alpha、Beta和Gamma）实现不同的风险与回报特征。Alpha基金承担高风险，Beta基金跟随市场表现，而Gamma基金提供风险调整后的保值增值。文章详细介绍了如何运用数学方法设定资产权重，确保每个资产对整体风险的贡献相等，即风险平等（risk parity）。投资者可以根据自身风险承受能力选择不同组合，无论市场状况如何，都能实现风险分散。通过区块链，全球投资者都能参与并根据自己的财务目标实现财富增长，这标志着投资前沿理论在实践中的突破。 <div>
arXiv:2407.09536v1 Announce Type: cross 
Abstract: We engineer blockchain based risk managed portfolios by creating three funds with distinct risk and return profiles: 1) Alpha - high risk portfolio; 2) Beta - mimics the wider market; and 3) Gamma - represents the risk free rate adjusted to beat inflation. Each of the sub-funds (Alpha, Beta and Gamma) provides risk parity because the weight of each asset in the corresponding portfolio is set to be inversely proportional to the risk derived from investing in that asset. This can be equivalently stated as equal risk contributions from each asset towards the overall portfolio risk.
  We provide detailed mechanics of combining assets - including mathematical formulations - to obtain better risk managed portfolios. The descriptions are intended to show how a risk parity based efficient frontier portfolio management engine - that caters to different risk appetites of investors by letting each individual investor select their preferred risk-return combination - can be created seamlessly on blockchain.
  Any Investor - using decentralized ledger technology - can select their desired level of risk, or return, and allocate their wealth accordingly among the sub funds, which balance one another under different market conditions. This evolution of the risk parity principle - resulting in a mechanism that is geared to do well under all market cycles - brings more robust performance and can be termed as conceptual parity.
  We have given several numerical examples that illustrate the various scenarios that arise when combining Alpha, Beta and Gamma to obtain Parity.
  The final investment frontier is now possible - a modification to the efficient frontier, thus becoming more than a mere theoretical construct - on blockchain since anyone from anywhere can participate at anytime to obtain wealth appreciation based on their financial goals.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mysticeti: Reaching the Limits of Latency with Uncertified DAGs</title>
<link>https://arxiv.org/abs/2310.14821</link>
<guid>https://arxiv.org/abs/2310.14821</guid>
<content:encoded><![CDATA[
<div> 关键词：DAG、Byzantine共识、Mysticeti-C、Mysticeti-FPC、资源效率。

总结:<br />
Mysticeti-C是一种基于有向无环图(DAG)的拜占庭共识协议，它实现了三项关键突破：首先，它将共识延迟降低到3轮消息，这是最低标准；其次，通过避免明确认证DAG块和采用新的提交规则，确保在崩溃失败下的最优延迟；最后，Mysticeti-FPC扩展了这一协议，提供更快的资产转移路径，减少签名和消息数量，进一步提升性能。该协议已被证明在拜占庭环境下安全且具有活性。在Sui区块链上的集成使得Mysticeti-C的共识提交延迟降低4倍，同时保持超过200k TPS的最高吞吐量，表现出卓越的低延迟和资源效率。 <div>
arXiv:2310.14821v4 Announce Type: replace 
Abstract: We introduce Mysticeti-C, the first DAG-based Byzantine consensus protocol to achieve the lower bounds of latency of 3 message rounds. Since Mysticeti-C is built over DAGs it also achieves high resource efficiency and censorship resistance. Mysticeti-C achieves this latency improvement by avoiding explicit certification of the DAG blocks and by proposing a novel commit rule such that every block can be committed without delays, resulting in optimal latency in the steady state and under crash failures. We further extend Mysticeti-C to Mysticeti-FPC, which incorporates a fast commit path that achieves even lower latency for transferring assets. Unlike prior fast commit path protocols, Mysticeti-FPC minimizes the number of signatures and messages by weaving the fast path transactions into the DAG. This frees up resources, which subsequently result in better performance. We prove the safety and liveness in a Byzantine context. We evaluate both Mysticeti protocols and compare them with state-of-the-art consensus and fast path protocols to demonstrate their low latency and resource efficiency, as well as their more graceful degradation under crash failures. Mysticeti-C is the first Byzantine consensus protocol to achieve WAN latency of 0.5s for consensus commit while simultaneously maintaining state-of-the-art throughput of over 200k TPS. Finally, we report on integrating Mysticeti-C as the consensus protocol into the Sui blockchain, resulting in over 4x latency reduction.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PILoRA: Prototype Guided Incremental LoRA for Federated Class-Incremental Learning</title>
<link>https://arxiv.org/abs/2401.02094</link>
<guid>https://arxiv.org/abs/2401.02094</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, catastrophic forgetting, data heterogeneity, prototype learning, Incremental LoRA

总结:<br />
本文提出了一种名为PILoRA的方法，针对动态增加新类别的联邦学习场景。该方法解决数据隐私和非独立同分布数据问题，通过原型学习获取更好的特征表示，并设计原型重权模块对抗分类器因数据异质性产生的偏差，无需重新训练分类器。此外，PILoRA将增量学习视为学习独立任务向量的过程，利用LoRA参数进行编码以缓解遗忘问题。实验结果表明，PILoRA在标准数据集上显著优于现有方法，对不同设置和数据异质性具有强大稳健性。代码可在[链接](https://github.com/Ghy0501/PILoRA)获取。 <div>
arXiv:2401.02094v2 Announce Type: replace 
Abstract: Existing federated learning methods have effectively dealt with decentralized learning in scenarios involving data privacy and non-IID data. However, in real-world situations, each client dynamically learns new classes, requiring the global model to classify all seen classes. To effectively mitigate catastrophic forgetting and data heterogeneity under low communication costs, we propose a simple and effective method named PILoRA. On the one hand, we adopt prototype learning to learn better feature representations and leverage the heuristic information between prototypes and class features to design a prototype re-weight module to solve the classifier bias caused by data heterogeneity without retraining the classifier. On the other hand, we view incremental learning as the process of learning distinct task vectors and encoding them within different LoRA parameters. Accordingly, we propose Incremental LoRA to mitigate catastrophic forgetting. Experimental results on standard datasets indicate that our method outperforms the state-of-the-art approaches significantly. More importantly, our method exhibits strong robustness and superiority in different settings and degrees of data heterogeneity. The code is available at \url{https://github.com/Ghy0501/PILoRA}.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fundamental Limits of Throughput and Availability: Applications to prophet inequalities &amp; transaction fee mechanism design</title>
<link>https://arxiv.org/abs/2402.19292</link>
<guid>https://arxiv.org/abs/2402.19292</guid>
<content:encoded><![CDATA[
<div> 关键词：availability, throughput, independent demands, heterogeneous distributions, capacity.

总结:
该论文研究了有限资源下独立且异质需求的可用性和吞吐量的基本限制。可用性指需求低于资源容量的概率，而吞吐量是需求利用资源的期望比例。作者提出了一种浓度不等式生成器，为给定容量和单位以内需求的独立分布提供了可用性和吞吐量的下界。这些界限适用于整个需求分布，支持了单位需求的已有理论（Chawla等人，2023），并扩展至多单位需求。此外，这些结果对多单位先知不平等性的改进有潜在贡献（Hajiaghayi等人，2007），以及区块链中交易费机制设计的应用，有助于限制用户-矿工联盟的盈利可能性（Chung和Shi，2023）。总的来说，该工作提供了一个分析工具，用于理解和优化资源分配策略。 <div>
arXiv:2402.19292v3 Announce Type: replace 
Abstract: This paper studies the fundamental limits of availability and throughput for independent and heterogeneous demands of a limited resource. Availability is the probability that the demands are below the capacity of the resource. Throughput is the expected fraction of the resource that is utilized by the demands. We offer a concentration inequality generator that gives lower bounds on feasible availability and throughput pairs with a given capacity and independent but not necessarily identical distributions of up-to-unit demands. We show that availability and throughput cannot both be poor. These bounds are analogous to tail inequalities on sums of independent random variables, but hold throughout the support of the demand distribution. This analysis gives analytically tractable bounds supporting the unit-demand characterization of Chawla, Devanur, and Lykouris (2023) and generalizes to up-to-unit demands. Our bounds also provide an approach towards improved multi-unit prophet inequalities (Hajiaghayi, Kleinberg, and Sandholm, 2007). They have applications to transaction fee mechanism design (for blockchains) where high availability limits the probability of profitable user-miner coalitions (Chung and Shi, 2023).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Demystifying Invariant Effectiveness for Securing Smart Contracts</title>
<link>https://arxiv.org/abs/2404.14580</link>
<guid>https://arxiv.org/abs/2404.14580</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contract, security attacks, invariant guards, Trace2Inv, Ethereum blockchain.

总结:<br />
本文主要探讨了智能合约中安全攻击相关的交易通常表现出与历史良性交易不同的行为模式。作者研究了23种常见的合约不变式，这些不变式被部署在知名协议或由审计公司和专家推荐。Trace2Inv工具利用这些不变式模板，根据合约的历史交易数据动态生成定制化的验证规则。实验结果表明，最有效的单一不变式守护者可以阻止27次攻击中的18次，且气耗较低。即使面对有经验的攻击者尝试绕过，大多数不变式仍然有效。同时，结合多个守护者可以阻挡23次攻击，误报率低至0.32%。Trace2Inv在智能合约不变式挖掘和交易攻击检测方面表现出色，甚至发现两个未报告的攻击交易。 <div>
arXiv:2404.14580v2 Announce Type: replace 
Abstract: Smart contract transactions associated with security attacks often exhibit distinct behavioral patterns compared with historical benign transactions before the attacking events. While many runtime monitoring and guarding mechanisms have been proposed to validate invariants and stop anomalous transactions on the fly, the empirical effectiveness of the invariants used remains largely unexplored. In this paper, we studied 23 prevalent invariants of 8 categories, which are either deployed in high-profile protocols or endorsed by leading auditing firms and security experts. Using these well-established invariants as templates, we developed a tool Trace2Inv which dynamically generates new invariants customized for a given contract based on its historical transaction data.
  We evaluated Trace2Inv on 42 smart contracts that fell victim to 27 distinct exploits on the Ethereum blockchain. Our findings reveal that the most effective invariant guard alone can successfully block 18 of the 27 identified exploits with minimal gas overhead. Our analysis also shows that most of the invariants remain effective even when the experienced attackers attempt to bypass them. Additionally, we studied the possibility of combining multiple invariant guards, resulting in blocking up to 23 of the 27 benchmark exploits and achieving false positive rates as low as 0.32%. Trace2Inv outperforms current state-of-the-art works on smart contract invariant mining and transaction attack detection in terms of both practicality and accuracy. Though Trace2Inv is not primarily designed for transaction attack detection, it surprisingly found two previously unreported exploit transactions, earlier than any reported exploit transactions against the same victim contracts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SAMM: Sharded Automated Market Makers</title>
<link>https://arxiv.org/abs/2406.05568</link>
<guid>https://arxiv.org/abs/2406.05568</guid>
<content:encoded><![CDATA[
<div> 关键词：Automated Market Makers (AMMs), Decentralized Finance (DeFi), Blockchain, Parallel Execution, Shards.

总结:
本文介绍了一种新型的去中心化金融(DeFi)自动化市场 maker (SAMM)，旨在解决现有区块链平台上的AMM性能限制。SAMM通过将AMM划分为多个独立的子池（shards），允许并行执行交易，从而显著提升吞吐量。传统AMM的非交换性导致交易串行化，限制了效率。文章提出了一种创新的交易费用设计，激励用户仅使用最小的子池进行交易，以避免资源分散。系统通过子游戏完美纳什均衡(Subgame-Perfect Nash Equilibria)机制保证了液 <div>
arXiv:2406.05568v2 Announce Type: replace 
Abstract: \emph{Automated Market Makers} (\emph{AMMs}) are a cornerstone of decentralized finance (DeFi) blockchain-based platforms.
  They are smart contracts, enabling the direct exchange of virtual tokens by maintaining \emph{liquidity pools}.
  Traders exchange tokens with the contract, paying a fee; liquidity comes from \emph{liquidity providers}, paid by those fees.
  But despite growing demand, the performance of AMMs is limited.
  State-of-the-art blockchain platforms allow for parallel execution of transactions.
  However, we show that AMMs do not enjoy these gains, since their operations are not commutative so transactions using them must be serialized.
  We present \emph{SAMM}, an AMM comprising multiple independent \emph{shards}.
  All shards are smart contracts operating in the same chain, but they allow for parallel execution as each is independent.
  The challenge is that trading in a standard AMM is cheaper if its liquidity pool is larger.
  Therefore, we show that simply using multiple smaller AMMs results in traders splitting each trade among all AMMs, which worsens performance.
  SAMM addresses this issue with a novel design of the trading fees.
  Traders are incentivized to use only a single smallest shard.
  We show that all Subgame-Perfect Nash Equilibria (SPNE) fit the desired behavior: Liquidity providers balance the liquidity among all pools, so the system converges to the state where trades are evenly distributed.
  Evaluation in the Sui blockchain shows that SAMM's throughput is over fivefold that of traditional AMMs, approaching the system's limit.
  SAMM is a directly deployable open-source smart contract, allowing trading at scale for individuals and DeFi applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Byzantine-Robust Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2406.10416</link>
<guid>https://arxiv.org/abs/2406.10416</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized Federated Learning, Poisoning Attacks, Byzantine Robustness, BALANCE.

总结:<br />
本文主要探讨了联邦学习中的一个问题——去中心化联邦学习（DFL）对抗毒攻击的挑战。DFL通过去中心化的架构避免了服务器依赖性问题，但易受恶意客户端操纵。研究者提出了BALANCE算法，该算法利用每个客户端的本地模型作为相似性参考，判断接收到的模型是否为恶意。BALANCE在强凸和非凸设置下都保证了在攻击下的收敛理论。此外，其在有毒攻击下的收敛速度与无攻击状态下最先进的方法相当。实验结果显示，BALANCE相较于现有DFL方法表现更优，有效抵御毒攻击。 <div>
arXiv:2406.10416v4 Announce Type: replace 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train machine learning models without revealing their private training data. In conventional FL, the system follows the server-assisted architecture (server-assisted FL), where the training process is coordinated by a central server. However, the server-assisted FL framework suffers from poor scalability due to a communication bottleneck at the server, and trust dependency issues. To address challenges, decentralized federated learning (DFL) architecture has been proposed to allow clients to train models collaboratively in a serverless and peer-to-peer manner. However, due to its fully decentralized nature, DFL is highly vulnerable to poisoning attacks, where malicious clients could manipulate the system by sending carefully-crafted local models to their neighboring clients. To date, only a limited number of Byzantine-robust DFL methods have been proposed, most of which are either communication-inefficient or remain vulnerable to advanced poisoning attacks. In this paper, we propose a new algorithm called BALANCE (Byzantine-robust averaging through local similarity in decentralization) to defend against poisoning attacks in DFL. In BALANCE, each client leverages its own local model as a similarity reference to determine if the received model is malicious or benign. We establish the theoretical convergence guarantee for BALANCE under poisoning attacks in both strongly convex and non-convex settings. Furthermore, the convergence rate of BALANCE under poisoning attacks matches those of the state-of-the-art counterparts in Byzantine-free settings. Extensive experiments also demonstrate that BALANCE outperforms existing DFL methods and effectively defends against poisoning attacks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Collaborative Safety-Critical Control for Dynamically Coupled Networked Systems</title>
<link>https://arxiv.org/abs/2310.03289</link>
<guid>https://arxiv.org/abs/2310.03289</guid>
<content:encoded><![CDATA[
<div> 关键词：复杂动态、协作控制、控制屏障函数、网络系统、安全控制。

总结:<br />本文探讨了在现代系统中，随着节点间复杂动态耦合关系的增长，确保个体代理的节点级安全定义与局部邻域动态之间的关联。作者提出了协作控制屏障函数（CCBF），并给出了这些函数定义的安全集向前不变性的条件。通过CCBF，他们设计了一种新的去中心化算法，用于保证协作网络代理的安全控制，并提供了算法收敛于安全控制动作可行集的条件。研究以网络化的易感-感染-易感（SIS）模型为例，展示了这些理论的应用。 <div>
arXiv:2310.03289v3 Announce Type: replace-cross 
Abstract: As modern systems become ever more connected with complex dynamic coupling relationships, developing safe control methods becomes paramount. In this paper, we discuss the relationship of node-level safety definitions for individual agents with local neighborhood dynamics. We define a collaborative control barrier function (CCBF) and provide conditions under which sets defined by these functions will be forward invariant. We use collaborative node-level control barrier functions to construct a novel \edit{decentralized} algorithm for the safe control of collaborating network agents and provide conditions under which the algorithm is guaranteed to converge to a viable set of safe control actions for all agents. We illustrate these results on a networked susceptible-infected-susceptible (SIS) model.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Detect Llama -- Finding Vulnerabilities in Smart Contracts using Large Language Models</title>
<link>https://arxiv.org/abs/2407.08969</link>
<guid>https://arxiv.org/abs/2407.08969</guid>
<content:encoded><![CDATA[
<div> 关键词：OpenAI、GPT-4、fine-tune、smart contract vulnerability detection、F1 score

总结:
在本文中，研究者测试了使用开源模型超越OpenAI GPT-4在智能合约漏洞检测领域的可能性。他们对Meta的Code Llama模型（Detect Llama - Foundation和Detect Llama - Instruct）以及GPT-3.5 Turbo（GPT-3.5FT）进行微调，使用17,000个提示数据集进行训练。实验结果显示，GPT-3.5FT和Detect Llama - Foundation在二分类任务中的F1分数分别为0.776和0.68，优于GPT-4的0.66和GPT-4 Turbo的0.675。对于针对特定漏洞的识别，这两个模型同样表现出色，其整体和前两个最常见漏洞的F1分数均超过GPT-4和GPT-4 Turbo。因此，经过微调的模型在智能合约漏洞检测上展现出更强性能。 <div>
arXiv:2407.08969v1 Announce Type: new 
Abstract: In this paper, we test the hypothesis that although OpenAI's GPT-4 performs well generally, we can fine-tune open-source models to outperform GPT-4 in smart contract vulnerability detection. We fine-tune two models from Meta's Code Llama and a dataset of 17k prompts, Detect Llama - Foundation and Detect Llama - Instruct, and we also fine-tune OpenAI's GPT-3.5 Turbo model (GPT-3.5FT). We then evaluate these models, plus a random baseline, on a testset we develop against GPT-4, and GPT-4 Turbo's, detection of eight vulnerabilities from the dataset and the two top identified vulnerabilities - and their weighted F1 scores.
  We find that for binary classification (i.e., is this smart contract vulnerable?), our two best-performing models, GPT-3.5FT and Detect Llama - Foundation, achieve F1 scores of $0.776$ and $0.68$, outperforming both GPT-4 and GPT-4 Turbo, $0.66$ and $0.675$. For the evaluation against individual vulnerability identification, our top two models, GPT-3.5FT and Detect Llama - Foundation, both significantly outperformed GPT-4 and GPT-4 Turbo in both weighted F1 for all vulnerabilities ($0.61$ and $0.56$ respectively against GPT-4's $0.218$ and GPT-4 Turbo's $0.243$) and weighted F1 for the top two identified vulnerabilities ($0.719$ for GPT-3.5FT, $0.674$ for Detect Llama - Foundation against GPT-4's $0.363$ and GPT-4 Turbo's $0.429$).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized multi-agent reinforcement learning algorithm using a cluster-synchronized laser network</title>
<link>https://arxiv.org/abs/2407.09124</link>
<guid>https://arxiv.org/abs/2407.09124</guid>
<content:encoded><![CDATA[
<div> 关键词：多Agent强化学习（MARL）、竞争性多臂_bandit（CMAB）、光子决策算法、激光耦合、分布式调整。

总结:<br />
本文提出了一种新颖的解决方案，将多Agent强化学习（MARL）应用于竞争性多臂Bandit问题。研究者利用光子技术，通过调控光耦合激光器的混沌振荡和集群同步，设计了一种分布式决策算法。这种算法在不共享信息的情况下促进了协作决策，实现了去中心化的强化学习，展示了物理过程与简单算法的有效结合，为无线网络和自动驾驶等领域提供了有前景的策略。 <div>
arXiv:2407.09124v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) studies crucial principles that are applicable to a variety of fields, including wireless networking and autonomous driving. We propose a photonic-based decision-making algorithm to address one of the most fundamental problems in MARL, called the competitive multi-armed bandit (CMAB) problem. Our numerical simulations demonstrate that chaotic oscillations and cluster synchronization of optically coupled lasers, along with our proposed decentralized coupling adjustment, efficiently balance exploration and exploitation while facilitating cooperative decision-making without explicitly sharing information among agents. Our study demonstrates how decentralized reinforcement learning can be achieved by exploiting complex physical processes controlled by simple algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization</title>
<link>https://arxiv.org/abs/2407.09324</link>
<guid>https://arxiv.org/abs/2407.09324</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized, Privacy, Information Theory, Deep Neural Networks.

总结:<br />Federated Learning (FL) 作为一种新兴的隐私保护方法，通过将数据保留在其源头以实现隐私核心化。本文与现有研究相悖，表明分布式优化的去中心化FL在理论上和实践上提供了比集中式模型更强的隐私保障。作者通过信息理论分析了FL的隐私损失，指出去中心化的关键区别在于迭代过程中本地梯度的差异和网络中各节点梯度的聚合，这使得攻击者难以推断个人信息。尽管在简单的模型中隐私泄露相似，但在深度神经网络等复杂模型中，去中心化FL的隐私风险较低。通过实证案例，证实了这些理论发现。 <div>
arXiv:2407.09324v1 Announce Type: new 
Abstract: Federated learning (FL) emerged as a paradigm designed to improve data privacy by enabling data to reside at its source, thus embedding privacy as a core consideration in FL architectures, whether centralized or decentralized. Contrasting with recent findings by Pasquini et al., which suggest that decentralized FL does not empirically offer any additional privacy or security benefits over centralized models, our study provides compelling evidence to the contrary. We demonstrate that decentralized FL, when deploying distributed optimization, provides enhanced privacy protection - both theoretically and empirically - compared to centralized approaches. The challenge of quantifying privacy loss through iterative processes has traditionally constrained the theoretical exploration of FL protocols. We overcome this by conducting a pioneering in-depth information-theoretical privacy analysis for both frameworks. Our analysis, considering both eavesdropping and passive adversary models, successfully establishes bounds on privacy leakage. We show information theoretically that the privacy loss in decentralized FL is upper bounded by the loss in centralized FL. Compared to the centralized case where local gradients of individual participants are directly revealed, a key distinction of optimization-based decentralized FL is that the relevant information includes differences of local gradients over successive iterations and the aggregated sum of different nodes' gradients over the network. This information complicates the adversary's attempt to infer private data. To bridge our theoretical insights with practical applications, we present detailed case studies involving logistic regression and deep neural networks. These examples demonstrate that while privacy leakage remains comparable in simpler models, complex models like deep neural networks exhibit lower privacy risks under decentralized FL.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Private Blockchain-based Procurement and Asset Management System with QR Code</title>
<link>https://arxiv.org/abs/2407.09353</link>
<guid>https://arxiv.org/abs/2407.09353</guid>
<content:encoded><![CDATA[
<div> 关键词：private blockchain, procurement process, distributed ledger, Proof-of-Authority, SHA3-512

总结:<br />
该研究介绍了一种旨在应用于供应办公室采购流程的新型区块链系统。通过集成私有区块链技术，系统利用分布式账本、对等网络、权威证明共识机制和SHA3-512加密算法，确保信息的安全与透明。极简原型模型被用于开发过程，提高了用户参与度，有助于早期发现并改进问题。相较于传统区块链，私有链提供了更高的隐私、安全和效率。SHA3-512作为加密算法，处理速度快且无长度扩展攻击风险。研究建议将这种技术应用于资产管理和采购记录，增强信任，降低数据篡改风险，推动供应链管理的创新与升级。 <div>
arXiv:2407.09353v1 Announce Type: new 
Abstract: The developed system aims to incorporate a private blockchain technology in the procurement process for the supply office. The procurement process includes the canvassing, purchasing, delivery and inspection of items, inventory, and disposal. The blockchain-based system includes a distributed ledger technology, peer-to-peer network, Proof-of-Authority consensus mechanism, and SHA3-512 cryptographic hash function algorithm. This will ensure trust and proper accountability to the custodian of the property while safeguarding sensitive information in the procurement records. The extreme prototyping model will be used as software development life cycle. It is mostly used for web-based applications and has an increased user involvement. The prototype version of the system allows the users get a better understanding of the system being developed. It also reduces the time and cost, has quicker user feedback, missing and difficult functions can be recognized, and confusing processes can be addressed on an early stage. The implementation of a private blockchain technology has an increased privacy, enhanced security, improved efficiency, and reduced complexity over traditional blockchain network. The use of SHA3-512 as cryptographic hash function algorithm is much faster than its predecessors when cryptography is handled by hardware components. Furthermore, it is not vulnerable to length extension attacks making it reliable in terms of security of data. The study recommends the use of private blockchain-based technology with the procurement and asset management system in the supply office. The procurement records will be protected against tampering using this technology. This will promote trust and confidence of the stakeholders. The implementation of blockchain technology in developing a system served as advancement and innovation in terms of securing data.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Thunderbolt: Causal Concurrent Consensus and Execution</title>
<link>https://arxiv.org/abs/2407.09409</link>
<guid>https://arxiv.org/abs/2407.09409</guid>
<content:encoded><![CDATA[
<div> 关键词：Directed acyclic graph (DAG), Thunderbolt, smart contracts, scalability, throughput.

总结:<br />本文介绍了一种名为Thunderbolt的新架构，它结合了DAG共识协议和Hyperledger的Execute-Order-Validate理念。Thunderbolt旨在为智能合约交易提供并行执行和并发处理，突破现有DAG协议的串行瓶颈。该架构在预执行阶段实现并行化，通过依赖性图动态调度交易以减少冲突导致的终止率。此外，还引入了恶意攻击防护机制，如shard重新配置。在SmallBank实验中，与Narwhal-Tusk的串行执行相比，Thunderbolt表现出50倍的速度提升，尤其是在64个副本时。 <div>
arXiv:2407.09409v1 Announce Type: new 
Abstract: In the realm of blockchain systems, smart contracts have gained widespread adoption owing to their programmability. Consequently, developing a system capable of facilitating high throughput and scalability is of paramount importance. Directed acyclic graph (DAG) consensus protocols have demonstrated notable enhancements in both throughput and latency, however, the serial execution is now becoming a bottleneck. Numerous approaches prove impractical for smart contracts by assuming that read/write sets are known in prior. This paper introduces Thunderbolt, a novel architecture based on DAG-based protocols, that aims to furnish a scalable and concurrent execution for smart contract transactions. Inspired by Hyperledger, Thunderbolt also expands Execute-Order-Validate architecture in which transactions are distributed into distinct replicas, with execution outcomes determined prior to ordering through the DAG-based protocol. Existing protocols adopt serial executions after the ordering to avoid non-determinism. However, Thunderbolt provides parallel pre-execution before the ordering as well as parallel verifications once any source of non-determinism is removed. Each replica validates the transaction results during the construction of the DAG other than after the ordering following the construction to improve the latency. In an effort to enhance smart contract execution, we implement an execution engine that constructs a dependency graph to dynamically assign transaction orders, thus mitigating abort rates due to execution conflicts. Additionally, we introduce a novel shard reconfiguration to withstand malicious attacks by relocating replicas from the current DAG to a new DAG, and rotating the shards among different replicas. Our comparison of the results on SmallBank with serial execution on Narwhal-Tusk revealed a remarkable 50 times speedup with 64 replicas.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>High-Speed Motion Planning for Aerial Swarms in Unknown and Cluttered Environments</title>
<link>https://arxiv.org/abs/2402.19033</link>
<guid>https://arxiv.org/abs/2402.19033</guid>
<content:encoded><![CDATA[
<div> 关键词：aerial swarm, motion planning, unknown environment, high-speed, decentralized

总结: 本文介绍了一种名为HDSM（High-Speed, Decentralized, and Synchronous Motion Planning）的创新方法，专为多无人机协作飞行设计。HDSM强调在未知环境中进行高效率、去中心化和同步路径规划，每个无人机仅需目标位置的全局信息。与现有四款最先进的方法相比，HDSM在成功率（100%到达目标）、飞行速度（提高97%）和飞行时间（减少50%）上表现出色。实验通过Crazyflie纳米无人机验证了HDSM的有效性和实用性，旨在提升多无人机任务执行的效率和安全性。<br /><br />总结: HDSM是一种用于多无人机的高速、去中心化路径规划框架，考虑未知环境；显著提升飞行效率与安全性；在实际硬件（Crazyflie）上验证成功。 <div>
arXiv:2402.19033v2 Announce Type: replace 
Abstract: Coordinated flight of multiple drones allows to achieve tasks faster such as search and rescue and infrastructure inspection. Thus, pushing the state-of-the-art of aerial swarms in navigation speed and robustness is of tremendous benefit. In particular, being able to account for unexplored/unknown environments when planning trajectories allows for safer flight. In this work, we propose the first high-speed, decentralized, and synchronous motion planning framework (HDSM) for an aerial swarm that explicitly takes into account the unknown/undiscovered parts of the environment. The proposed approach generates an optimized trajectory for each planning agent that avoids obstacles and other planning agents while moving and exploring the environment. The only global information that each agent has is the target location. The generated trajectory is high-speed, safe from unexplored spaces, and brings the agent closer to its goal. The proposed method outperforms four recent state-of-the-art methods in success rate (100% success in reaching the target location), flight speed (97% faster), and flight time (50% lower). Finally, the method is validated on a set of Crazyflie nano-drones as a proof of concept.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>It Takes Two: A Peer-Prediction Solution for Blockchain Verifier's Dilemma</title>
<link>https://arxiv.org/abs/2406.01794</link>
<guid>https://arxiv.org/abs/2406.01794</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Verifier's Dilemma, decentralized consensus, peer prediction, Bayesian truthful mechanisms.

总结:<br />
这篇论文关注区块链系统的安全性问题，特别是"Verifier's Dilemma"现象，即在几乎没有作弊者的情况下，确保验证者诚实执行验证的成本高昂，这可能威胁系统基础安全。作者提出利用peer prediction方法设计一种基于贝叶斯的真诚信实机制，旨在激励多个验证者在去中心化的环境中进行诚实验证，即使在验证过程中存在噪声也如此。这种机制理论上保证了真诚信实性，为增强区块链和其它分布式系统的安全性和稳健性提供了新框架。 <div>
arXiv:2406.01794v2 Announce Type: replace 
Abstract: The security of blockchain systems is fundamentally based on the decentralized consensus in which the majority of parties behave honestly, and the process of content verification is essential to keep the robustness of blockchain systems. However, the phenomenon that a secure blockchain system with few or no cheaters could not provide sufficient incentive for verifiers to honestly perform the costly verification, referred to as the Verifier's Dilemma, could severely undermine the fundamental security of blockchain systems. While existing works have attempted to insert deliberate errors to disincentivize lazy verification, the decentralized environment makes it impossible to judge the correctness of verification or detect malicious verifiers directly.
  In this paper, we initiate the research that leverages the peer prediction approach towards the design of Bayesian truthful mechanisms for the decentralized verification game among multiple verifiers, incentivizing all verifiers to perform honest verification without access to the ground truth even in the presence of noisy observations in the verification process. With theoretically guaranteed truthfulness of our mechanism for the verification game, our work provides a framework of verification mechanisms that enhances the security and robustness of the blockchain and potentially other decentralized systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Benchmarking GNNs Using Lightning Network Data</title>
<link>https://arxiv.org/abs/2407.07916</link>
<guid>https://arxiv.org/abs/2407.07916</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin Lightning Network, Layer 2 protocol, Channels, Graph Neural Networks (GNNs), Node properties.

总结:
比特币闪电网络（Bitcoin Lightning Network）是一种第二层协议，用于实现快速低成本的比特币交易。论文分析了该网络的图结构，利用机器学习中的图神经网络（GNNs）研究节点属性之间的统计关系。研究者设计任务来探索这些关系，并评估不同GNN模型的性能，发现它们在这些任务中有效，揭示了从图结构和邻居信息中获取的洞察。总的来说，这项工作展示了GNN在理解比特币 Lightning 网络中节点特征相互作用方面的潜力。 <div>
arXiv:2407.07916v1 Announce Type: new 
Abstract: The Bitcoin Lightning Network is a layer 2 protocol designed to facilitate fast and inexpensive Bitcoin transactions. It operates by establishing channels between users, where Bitcoin is locked and transactions are conducted off-chain until the channels are closed, with only the initial and final transactions recorded on the blockchain. Routing transactions through intermediary nodes is crucial for users without direct channels, allowing these routing nodes to collect fees for their services. Nodes announce their channels to the network, forming a graph with channels as edges. In this paper, we analyze the graph structure of the Lightning Network and investigate the statistical relationships between node properties using machine learning, particularly Graph Neural Networks (GNNs). We formulate a series of tasks to explore these relationships and provide benchmarks for GNN architectures, demonstrating how topological and neighbor information enhances performance. Our evaluation of several models reveals the effectiveness of GNNs in these tasks and highlights the insights gained from their application.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape</title>
<link>https://arxiv.org/abs/2407.07917</link>
<guid>https://arxiv.org/abs/2407.07917</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Backdoor Attacks, Triggers, Decentralized Nature, Robust Defenses

总结:<br />Federated Learning（FL）是一种分布式模型训练方法，旨在保护用户隐私。然而，它易受后门攻击，尤其是非合作式多触发攻击，这种攻击由独立的攻击者引入针对不同类别的独特触发器，利用FL的去中心化特性，使得检测困难。研究发现，即使单个后门被成功学习，不会影响主要任务，FL仍然面临严重威胁。这强调了对多样化的后门攻击防御的迫切需求。该研究通过实证分析，揭示了FL在现实场景中的脆弱性，提醒了未来研究关注更逼真的攻击设置，以及FL在构建抵御多类型后门威胁方面的重要性。相关代码可在指定链接获取。 <div>
arXiv:2407.07917v1 Announce Type: new 
Abstract: Despite the promise of Federated Learning (FL) for privacy-preserving model training on distributed data, it remains susceptible to backdoor attacks. These attacks manipulate models by embedding triggers (specific input patterns) in the training data, forcing misclassification as predefined classes during deployment. Traditional single-trigger attacks and recent work on cooperative multiple-trigger attacks, where clients collaborate, highlight limitations in attack realism due to coordination requirements. We investigate a more alarming scenario: non-cooperative multiple-trigger attacks. Here, independent adversaries introduce distinct triggers targeting unique classes. These parallel attacks exploit FL's decentralized nature, making detection difficult. Our experiments demonstrate the alarming vulnerability of FL to such attacks, where individual backdoors can be successfully learned without impacting the main task. This research emphasizes the critical need for robust defenses against diverse backdoor attacks in the evolving FL landscape. While our focus is on empirical analysis, we believe it can guide backdoor research toward more realistic settings, highlighting the crucial role of FL in building robust defenses against diverse backdoor threats. The code is available at \url{https://anonymous.4open.science/r/nba-980F/}.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Trustworthy AIoT-enabled Localization System via Federated Learning and Blockchain</title>
<link>https://arxiv.org/abs/2407.07921</link>
<guid>https://arxiv.org/abs/2407.07921</guid>
<content:encoded><![CDATA[
<div> 关键词：indoor localization, RF sensors, fingerprinting, federated learning, blockchain

总结:<br />
本文提出了一种新型的室内定位框架DFLoc，旨在解决使用RF传感器和机器学习进行智能建筑定位时遇到的安全与隐私问题。DFLoc利用区块链技术来分散依赖中央服务器的任务，如模型分发和聚合，以防止单点故障，确保系统的可靠性和精度。此外，它引入了更新的模型验证机制，以抵御恶意节点攻击。实验结果表明，DFLoc不仅能提供精确的三维位置预测，还比传统集中式联邦学习系统更能抵抗这些安全威胁。 <div>
arXiv:2407.07921v1 Announce Type: new 
Abstract: There is a significant demand for indoor localization technology in smart buildings, and the most promising solution in this field is using RF sensors and fingerprinting-based methods that employ machine learning models trained on crowd-sourced user data gathered from IoT devices. However, this raises security and privacy issues in practice. Some researchers propose to use federated learning to partially overcome privacy problems, but there still remain security concerns, e.g., single-point failure and malicious attacks. In this paper, we propose a framework named DFLoc to achieve precise 3D localization tasks while considering the following two security concerns. Particularly, we design a specialized blockchain to decentralize the framework by distributing the tasks such as model distribution and aggregation which are handled by a central server to all clients in most previous works, to address the issue of the single-point failure for a reliable and accurate indoor localization system. Moreover, we introduce an updated model verification mechanism within the blockchain to alleviate the concern of malicious node attacks. Experimental results substantiate the framework's capacity to deliver accurate 3D location predictions and its superior resistance to the impacts of single-point failure and malicious attacks when compared to conventional centralized federated learning systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulnerability Detection in Smart Contracts: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2407.07922</link>
<guid>https://arxiv.org/abs/2407.07922</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, machine learning, vulnerability detection, mitigation, systematic review

总结:
本文主要探讨了机器学习在智能合约安全领域的应用。研究通过系统性回顾88篇相关文献，发现古典机器学习方法如KNN、RF、DT、XG-Boost和SVM在检测智能合约漏洞方面优于静态工具。深度学习与传统方法结合的多模型策略显示出显著提高的精度和召回率。混合模型采用多种技术接近完美的检测准确性。文章强调了整合现有解决方案的重要性，揭示了研究空白，并为学术界、行业专家和对提升智能合约安全感兴趣的各方提供了未来研究方向的指引。 <div>
arXiv:2407.07922v1 Announce Type: new 
Abstract: In the growing field of blockchain technology, smart contracts exist as transformative digital agreements that execute transactions autonomously in decentralised networks. However, these contracts face challenges in the form of security vulnerabilities, posing significant financial and operational risks. While traditional methods to detect and mitigate vulnerabilities in smart contracts are limited due to a lack of comprehensiveness and effectiveness, integrating advanced machine learning technologies presents an attractive approach to increasing effective vulnerability countermeasures. We endeavour to fill an important gap in the existing literature by conducting a rigorous systematic review, exploring the intersection between machine learning and smart contracts. Specifically, the study examines the potential of machine learning techniques to improve the detection and mitigation of vulnerabilities in smart contracts. We analysed 88 articles published between 2018 and 2023 from the following databases: IEEE, ACM, ScienceDirect, Scopus, and Google Scholar. The findings reveal that classical machine learning techniques, including KNN, RF, DT, XG-Boost, and SVM, outperform static tools in vulnerability detection. Moreover, multi-model approaches integrating deep learning and classical machine learning show significant improvements in precision and recall, while hybrid models employing various techniques achieve near-perfect performance in vulnerability detection accuracy.
  By integrating state-of-the-art solutions, this work synthesises current methods, thoroughly investigates research gaps, and suggests directions for future studies. The insights gathered from this study are intended to serve as a seminal reference for academics, industry experts, and bodies interested in leveraging machine learning to enhance smart contract security.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities</title>
<link>https://arxiv.org/abs/2407.07966</link>
<guid>https://arxiv.org/abs/2407.07966</guid>
<content:encoded><![CDATA[
<div> 关键词：智能电网、安全、攻击策略、防御策略、机器学习

总结:<br />
本文对智能电网的安全进行了全面深入的研究，重点关注了系统架构、新型攻击手段和复杂协调攻击。文章探讨了各种防御策略，如游戏理论、图论、区块链和机器学习在对抗不断演变威胁中的应用，特别是详细分析了机器学习在识别和抵御攻击中的作用及其挑战。未来研究方向涉及现有技术的优化和新方法的探索，如大型语言模型（LLMs）以及对抗性机器学习的潜在威胁。总的来说，本文为智能电网安全领域的未来发展提供了有价值的见解和前瞻性思考。 <div>
arXiv:2407.07966v1 Announce Type: new 
Abstract: In this study, we conduct a comprehensive review of smart grid security, exploring system architectures, attack methodologies, defense strategies, and future research opportunities. We provide an in-depth analysis of various attack vectors, focusing on new attack surfaces introduced by advanced components in smart grids. The review particularly includes an extensive analysis of coordinated attacks that incorporate multiple attack strategies and exploit vulnerabilities across various smart grid components to increase their adverse impact, demonstrating the complexity and potential severity of these threats. Following this, we examine innovative detection and mitigation strategies, including game theory, graph theory, blockchain, and machine learning, discussing their advancements in counteracting evolving threats and associated research challenges. In particular, our review covers a thorough examination of widely used machine learning-based mitigation strategies, analyzing their applications and research challenges spanning across supervised, unsupervised, semi-supervised, ensemble, and reinforcement learning. Further, we outline future research directions and explore new techniques and concerns. We first discuss the research opportunities for existing and emerging strategies, and then explore the potential role of new techniques, such as large language models (LLMs), and the emerging threat of adversarial machine learning in the future of smart grid security.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Adaptive Aerospace Transportation of Unknown Loads Using A Team of Robots</title>
<link>https://arxiv.org/abs/2407.08084</link>
<guid>https://arxiv.org/abs/2407.08084</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized adaptive controller, aerospace robots, unknown objects, gravity environments, cooperative transportation

总结:<br />本文介绍了一种新颖的分布式自适应控制器设计，适用于不同类型的航空航天机器人，如多旋翼无人机和空间拖船。该控制器能够适应各种未知物体，并在不同重力条件下运行。研究通过实验验证了这一方法，包括使用全驱动六轴飞行器进行空中协同载物任务，以及空间拖船在太空环境中的操作。控制器展现出对运输过程中机器人损失等意外情况的适应能力，提高了任务执行的灵活性和可靠性。 <div>
arXiv:2407.08084v1 Announce Type: new 
Abstract: Transportation missions in aerospace are limited to the capability of each aerospace robot and the properties of the target transported object, such as mass, inertia, and grasping locations. We present a novel decentralized adaptive controller design for multiple robots that can be implemented in different kinds of aerospace robots. Our controller adapts to unknown objects in different gravity environments. We validate our method in an aerial scenario using multiple fully actuated hexarotors with grasping capabilities, and a space scenario using a group of space tugs. In both scenarios, the robots transport a payload cooperatively through desired three-dimensional trajectories. We show that our method can adapt to unexpected changes that include the loss of robots during the transportation mission.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>United We Stand: Decentralized Multi-Agent Planning With Attrition</title>
<link>https://arxiv.org/abs/2407.08254</link>
<guid>https://arxiv.org/abs/2407.08254</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized planning, Agent failures, Attritable MCTS (A-MCTS), Global reward function, Regret matching.

总结:<br />
本文提出了一种新型的分布式算法——Attritable MCTS (A-MCTS)，旨在解决大规模协作多代理系统中的信息采集任务。在频繁的代理失败情况下，当前方法存在无法收敛或资源利用效率低的问题。A-MCTS通过全局奖励函数评估每个代理的局部贡献，并采用后悔匹配进行协调，以实现及时且高效的适应性。实验结果表明，即使在高失败率环境中，A-MCTS也能显著提高全球效用和可扩展性，优于现有最佳方案。 <div>
arXiv:2407.08254v1 Announce Type: new 
Abstract: Decentralized planning is a key element of cooperative multi-agent systems for information gathering tasks. However, despite the high frequency of agent failures in realistic large deployment scenarios, current approaches perform poorly in the presence of failures, by not converging at all, and/or by making very inefficient use of resources (e.g. energy). In this work, we propose Attritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and efficient adaptation to changes in the set of active agents. It is based on the use of a global reward function for the estimation of each agent's local contribution, and regret matching for coordination. We evaluate its effectiveness in realistic data-harvesting problems under different scenarios. We show both theoretically and experimentally that A-MCTS enables efficient adaptation even under high failure rates. Results suggest that, in the presence of frequent failures, our solution improves substantially over the best existing approaches in terms of global utility and scalability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Performance Evaluation of Hashing Algorithms on Commodity Hardware</title>
<link>https://arxiv.org/abs/2407.08284</link>
<guid>https://arxiv.org/abs/2407.08284</guid>
<content:encoded><![CDATA[
<div> 关键词：Blake3, SHA-256, SHA-512, hashing algorithms, performance evaluation.

总结:<br />
这篇文章主要关注了三种广泛应用于区块链网络的哈希算法：Blake3、SHA-256和SHA-512。研究者对这些算法进行了性能评估，重点关注了计算速率（hash rate）、内存使用和延迟等指标。实验在不同硬件平台上进行，包括桌面和虚拟机，还涉及了合成基准测试。结果表明，Blake3通常在吞吐量和延迟方面优于SHA-256和SHA-512。然而，其优势取决于硬件和输入数据大小。报告给出了根据应用需求（如性能和安全性）选择合适哈希算法的建议，并为未来算法优化提供了依据。 <div>
arXiv:2407.08284v1 Announce Type: new 
Abstract: Hashing functions, which are created to provide brief and erratic digests for the message entered, are the primary cryptographic primitives used in blockchain networks. Hashing is employed in blockchain networks to create linked block lists, which offer safe and secure distributed repository storage for critical information. Due to the unique nature of the hash search problem in blockchain networks, the most parallelization of calculations is possible. This technical report presents a performance evaluation of three popular hashing algorithms Blake3, SHA-256, and SHA-512. These hashing algorithms are widely used in various applications, such as digital signatures, message authentication, and password storage. It then discusses the performance metrics used to evaluate the algorithms, such as hash rate/throughput and memory usage. The evaluation is conducted on a range of hardware platforms, including desktop and VMs. The evaluation includes synthetic benchmarks. The results of the evaluation show that Blake3 generally outperforms both SHA-256 and SHA-512 in terms of throughput and latency. However, the performance advantage of Blake3 varies depending on the specific hardware platform and the size of the input data. The report concludes with recommendations for selecting the most suitable hashing algorithm for a given application, based on its performance requirements and security needs. The evaluation results can also inform future research and development efforts to improve the performance and security of hashing algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BriDe Arbitrager: Enhancing Arbitrage in Ethereum 2.0 via Bribery-enabled Delayed Block Production</title>
<link>https://arxiv.org/abs/2407.08537</link>
<guid>https://arxiv.org/abs/2407.08537</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum 2.0、Proof-of-Stake、BriDe Arbitrager、Bribery-driven attacks、Arbitrage

总结:<br />
Ethereum 2.0的PoS转变引发了新的挑战，BriDe Arbitrager应运而生。这个工具利用贿赂策略延迟区块生产，为恶意提议者提供更多时间发现套利机会，设计有适应性贿赂策略和延迟交易排序算法，以增加利润。通过智能合约和贿赂客户端实现自动化与公平，即使在Proposer Builder分离等机制下也能保持有效性。实验数据显示，BriDe Arbitrager每天可实现平均8.66 ETH（约16,442.23 USD）的利润，且不触发惩罚机制。 <div>
arXiv:2407.08537v1 Announce Type: new 
Abstract: The advent of Ethereum 2.0 has introduced significant changes, particularly the shift to Proof-of-Stake consensus. This change presents new opportunities and challenges for arbitrage. Amidst these changes, we introduce BriDe Arbitrager, a novel tool designed for Ethereum 2.0 that leverages Bribery-driven attacks to Delay block production and increase arbitrage gains. The main idea is to allow malicious proposers to delay block production by bribing validators/proposers, thereby gaining more time to identify arbitrage opportunities. Through analysing the bribery process, we design an adaptive bribery strategy. Additionally, we propose a Delayed Transaction Ordering Algorithm to leverage the delayed time to amplify arbitrage profits for malicious proposers. To ensure fairness and automate the bribery process, we design and implement a bribery smart contract and a bribery client. As a result, BriDe Arbitrager enables adversaries controlling a limited (< 1/4) fraction of the voting powers to delay block production via bribery and arbitrage more profit. Extensive experimental results based on Ethereum historical transactions demonstrate that BriDe Arbitrager yields an average of 8.66 ETH (16,442.23 USD) daily profits. Furthermore, our approach does not trigger any slashing mechanisms and remains effective even under Proposer Builder Separation and other potential mechanisms will be adopted by Ethereum.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Generalization Error Matters in Decentralized Learning Under Byzantine Attacks</title>
<link>https://arxiv.org/abs/2407.08632</link>
<guid>https://arxiv.org/abs/2407.08632</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Learning, Byzantine-resilient, Stochastic Gradient Descent (DSGD), Generalization Errors, Theoretical Analysis.

总结:<br />
本文关注的是去中心化学习中的一个重要问题，尤其是在存在恶意（Byzantine）节点的情况下。研究者首次对一类流行的抗拜占庭分布式随机梯度下降（DSGD）算法的泛化误差进行了理论分析。他们的发现令人惊讶，即使训练样本数量无限大，由于拜占庭节点的存在，泛化误差也无法完全消除。实验结果进一步验证了这一理论。这项工作填补了当前去中心化学习中关于模型泛化性能理解的空白，对于实际应用具有重要指导意义。 <div>
arXiv:2407.08632v1 Announce Type: new 
Abstract: Recently, decentralized learning has emerged as a popular peer-to-peer signal and information processing paradigm that enables model training across geographically distributed agents in a scalable manner, without the presence of any central server. When some of the agents are malicious (also termed as Byzantine), resilient decentralized learning algorithms are able to limit the impact of these Byzantine agents without knowing their number and identities, and have guaranteed optimization errors. However, analysis of the generalization errors, which are critical to implementations of the trained models, is still lacking. In this paper, we provide the first analysis of the generalization errors for a class of popular Byzantine-resilient decentralized stochastic gradient descent (DSGD) algorithms. Our theoretical results reveal that the generalization errors cannot be entirely eliminated because of the presence of the Byzantine agents, even if the number of training samples are infinitely large. Numerical experiments are conducted to confirm our theoretical results.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SpiralShard: Highly Concurrent and Secure Blockchain Sharding via Linked Cross-shard Endorsement</title>
<link>https://arxiv.org/abs/2407.08651</link>
<guid>https://arxiv.org/abs/2407.08651</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain sharding, SpiralShard, malicious nodes, Linked Cross-shard Endorsement (LCE), throughput gain.

总结:<br />
区块链分片技术（Blockchain sharding）旨在提升系统扩展性，但现有方案因依赖大量安全的分片而限制了并发。SpiralShard提出了一种创新方法，通过容忍部分恶意节点的较大分片（即“脏”分片），减小单个分片大小，从而增加并发处理。文章的核心贡献是Linked Cross-shard Endorsement (LCE)协议，确保在存在脏分片的情况下，通过其他分片的协作验证和最终确认，维持系统的安全性。实验基于Harmony平台进行，结果显示，与Harmony相比，SpiralShard在大型网络（4000+节点）下能实现约19倍的吞吐量提升。 <div>
arXiv:2407.08651v1 Announce Type: new 
Abstract: Blockchain sharding improves the scalability of blockchain systems by partitioning the whole blockchain state, nodes, and transaction workloads into different shards. However, existing blockchain sharding systems generally suffer from a small number of shards, resulting in limited concurrency. The main reason is that existing sharding systems require large shard sizes to ensure security. To enhance the concurrency of blockchain sharding securely, we propose SpiralShard. The intuition is to allow the existence of some shards with a larger fraction of malicious nodes (i.e., corrupted shards), thus reducing shard sizes. SpiralShard can configure more and smaller shards for higher concurrency at the same network size. To ensure security with the existence of corrupted shards, we propose the Linked Cross-shard Endorsement (LCE) protocol. According to our LCE protocol, the blocks of each shard are sequentially verified and endorsed by a group of shards before being finalized. As a result, a corrupted shard can eliminate forks with the help of the other shards. We implement SpiralShard based on Harmony and conduct extensive evaluations. Experimental results show that, compared with Harmony, SpiralShard achieves around 19x throughput gain under a large network size with 4,000+ nodes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Balancing Participation and Decentralization in Proof-of-Stake Cryptocurrencies</title>
<link>https://arxiv.org/abs/2407.08686</link>
<guid>https://arxiv.org/abs/2407.08686</guid>
<content:encoded><![CDATA[
<div> 关键词：proof-of-stake, blockchain, stake delegation, payment schemes, decentralization

总结: 本文主要探讨了基于权益证明（Proof-of-Stake, PoS）的区块链协议中，一种称为权益委托（stake delegation）的参与形式。权益委托允许代理将其权益委托给活跃的验证者，即池操作员，以促进交易验证过程。研究了作为激励机制的支付方案，这些方案根据参与者集体行为调整奖励，旨在保持系统的去中心化同时鼓励参与。文章分析了不同支付方案之间的权衡，特别是在费用支出与平衡安全、去中心化目标之间的关系。最后，作者提出了一种能在贝叶斯博弈理论框架下达到不同目标均衡的支付方案家族。 <div>
arXiv:2407.08686v1 Announce Type: new 
Abstract: Proof-of-stake blockchain protocols have emerged as a compelling paradigm for organizing distributed ledger systems. In proof-of-stake (PoS), a subset of stakeholders participate in validating a growing ledger of transactions. For the safety and liveness of the underlying system, it is desirable for the set of validators to include multiple independent entities as well as represent a non-negligible percentage of the total stake issued. In this paper, we study a secondary form of participation in the transaction validation process, which takes the form of stake delegation, whereby an agent delegates their stake to an active validator who acts as a stake pool operator. We study payment schemes that reward agents as a function of their collective actions regarding stake pool operation and delegation. Such payment schemes serve as a mechanism to incentivize participation in the validation process while maintaining decentralization. We observe natural trade-offs between these objectives and the total expenditure required to run the relevant payment schemes. Ultimately, we provide a family of payment schemes which can strike different balances between these competing objectives at equilibrium in a Bayesian game theoretic framework.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Clap: a Semantic-Preserving Optimizing eDSL for Plonkish Proof Systems</title>
<link>https://arxiv.org/abs/2405.12115</link>
<guid>https://arxiv.org/abs/2405.12115</guid>
<content:encoded><![CDATA[
<div> 关键词：Plonkish、Rust eDSL、Clap、零知识证明系统、自动优化。

总结:<br />
Plonkish是一种流行的电路格式，用于开发零知识证明系统，在区块链项目中占据重要地位。然而，这些项目依赖于手工优化的电路，测试和审计耗时且复杂。为此，研究人员提出了Clap，这是一种基于Rust的eDSL（领域特定语言），它提供了一种与证明系统无关的电路格式。Clap将转换Plonkish约束系统和生成器视为一种保持语义的编译问题，确保了变换的正确性和完整性，避免了因过度或不足约束导致的潜在错误。实验表明，Clap的自动优化功能优于手动优化，并能自动生成定制门。总的来说，Clap为零知识证明系统的电路设计提供了更高效、可扩展和形式化的方法。 <div>
arXiv:2405.12115v2 Announce Type: replace 
Abstract: Plonkish is a popular circuit format for developing zero-knowledge proof systems that powers a number of major projects in the blockchain space, responsible for holding billions of dollars and processing millions of transactions per day. These projects, including zero-knowledge rollups, rely on highly hand-optimized circuits whose correctness comes at the cost of time-consuming testing and auditing.
  In this paper, we present Clap, the first Rust eDSL with a proof system agnostic circuit format, facilitating extensibility, automatic optimizations, and formal assurances for the resultant constraint system. Clap casts the problem of producing Plonkish constraint systems and their witness generators as a semantic-preserving compilation problem. Soundness and completeness of the transformation guarantees the absence of subtle bugs caused by under- or over-constraining. Our experimental evaluation shows that its automatic optimizations achieve better performance compared to manual circuit optimization. The optimizer can also be used to automatically derive custom gates from circuit descriptions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Optimal Sharding for Scalable Blockchains with Deconstructed SMR</title>
<link>https://arxiv.org/abs/2406.08252</link>
<guid>https://arxiv.org/abs/2406.08252</guid>
<content:encoded><![CDATA[
<div> 关键词：Sharding, Blockchain, Scalability, Byzantine Faults, Arete

总结:<br />
这篇文章探讨了区块链扩容中的"大小-安全"困境，即每个分片需要足够大以保证安全，但这样限制了分片的效率和数量。作者提出了Arete协议，通过提高单个分片对拜占庭故障的容忍度来解决这一问题。Arete将区块链的状态机复制（SMR）过程分为交易传播、排序和执行三个步骤，其中只有一个排序分片负责排序，多个处理分片负责传播和执行区块，从而实现更高安全性。同时，Arete分离了安全性和可用性，允许暂时容忍临时的可用性违反，以创建更小、更优化的分片。此外，Arete的SMR重构还支持新的认证-排序-执行架构，实现交易处理的完全并行，显著提升性能。实验结果表明，Arete在AWS环境下优于现有最先进的分片协议。 <div>
arXiv:2406.08252v2 Announce Type: replace 
Abstract: Sharding is proposed to enhance blockchain scalability. However, a size-security dilemma where every shard must be large enough to ensure its security constrains the efficacy of individual shards and the degree of sharding itself. Most existing sharding solutions therefore rely on either weakening the adversary or making stronger assumptions on network links.
  This paper presents Arete, an optimally scalable blockchain sharding protocol designed to resolve the dilemma based on an observation that if individual shards can tolerate a higher fraction of (Byzantine) faults, we can securely create smaller shards in a larger quantity. The key idea of Arete, therefore, is to improve the security resilience/threshold of shards by dividing the blockchain's State Machine Replication (SMR) process itself. Similar to modern blockchains, Arete first decouples SMR in three steps: transaction dissemination, ordering, and execution. However, unlike other blockchains, for Arete, a single ordering shard performs the ordering task while multiple processing shards perform the dissemination and execution of blocks. As processing shards do not run consensus, each of those can tolerate up to half compromised nodes. Moreover, the SMR process in the ordering shard is lightweight as it only operates on the block digests. Second, Arete considers safety and liveness against Byzantine failures separately to improve the safety threshold further while tolerating temporary liveness violations in a controlled manner. Apart from the creation of more optimal-size shards, such a deconstructed SMR scheme also empowers us to devise a novel certify-order-execute architecture to fully parallelize transaction handling, thereby improving the performance of sharded blockchain systems. We implement Arete and evaluate it on a geo-distributed AWS environment, showing that Arete outperforms the state-of-the-art sharding protocol.
]]></content:encoded>
<pubDate></pubDate>
</item>
</channel>
</rss>