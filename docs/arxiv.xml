<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>

<item>
<title>Load Balancing in Federated Learning</title>
<link>https://arxiv.org/abs/2408.00217</link>
<guid>https://arxiv.org/abs/2408.00217</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Age of Information、Markov调度策略、资源利用、数据隐私

<br>
<br>
总结:
本文提出了一种基于年龄信息的负载度量方法，旨在为联邦学习(Federated Learning, FL)中的设备调度提供依据。面对有限的通信资源和设备间数据异质性等挑战，该文通过最小化负载度量的方差，实现公平的工作负载分配与高效资源使用。此外，引入了一种去中心化的马尔可夫调度策略，该策略确保了负载的均衡分布，并通过使每个客户端独立决策来消除大规模网络管理的开销。通过建立马尔可夫链模型并优化其参数，文中的方法被验证有效。实验证明，减少负载度量的方差不仅能提升系统的公平性和运行效率，还能加速学习模型的收敛速度。此研究为联邦学习中的设备调度提供了理论与实践上的新视角。 <div>
arXiv:2408.00217v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning framework that enables learning from data distributed across multiple remote devices, enhancing communication efficiency and data privacy. Due to limited communication resources, a scheduling policy is often applied to select a subset of devices for participation in each FL round. The scheduling process confronts significant challenges due to the need for fair workload distribution, efficient resource utilization, scalability in environments with numerous edge devices, and statistically heterogeneous data across devices. This paper proposes a load metric for scheduling policies based on the Age of Information and addresses the above challenges by minimizing the load metric variance across the clients. Furthermore, a decentralized Markov scheduling policy is presented, that ensures a balanced workload distribution while eliminating the management overhead irrespective of the network size due to independent client decision-making. We establish the optimal parameters of the Markov chain model and validate our approach through simulations. The results demonstrate that reducing the load metric variance not only promotes fairness and improves operational efficiency, but also enhances the convergence rate of the learning models.
]]></content:encoded>


</item>
<item>
<title>A Survey on the Applications of Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2408.00243</link>
<guid>https://arxiv.org/abs/2408.00243</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明（ZKP）、zk-SNARKS、区块链隐私、零知识虚拟机（zkVM）、非区块链应用

<br><br>
总结:
本文是一篇关于零知识证明（ZKP）的综述性文章，重点探讨了ZKP在分布式系统中的独特优势，特别是与同态加密和安全多方计算等其他隐私敏感计算方法相比。ZKP在区块链技术中用于增强隐私，同时在存储、可扩展性和跨链互操作性方面也发挥着关键作用。此外，它们在非区块链领域如投票、身份验证、定时器和机器学习的应用也日益广泛。

文章首先介绍了ZKP的基本工作原理，并特别关注了一种称为zk-SNARKS的越来越重要的ZKP子集。随后，它讨论了ZKP在实践中的应用，包括各种领域，如区块链隐私、可扩展性、存储、跨链交互以及非区块链应用如投票、身份验证、定时器和机器学习。

为了支持这些应用，文章还涵盖了基础组件和基础设施，如零知识虚拟机（zkVM）、领域特定语言（DSL）、支持库、框架和协议。最后，文章展望了ZKP未来的发展方向，强调了它们在加密实践和数字隐私领域的重要性。 <div>
arXiv:2408.00243v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKPs) represent a revolutionary advance in computational integrity and privacy technology, enabling the secure and private exchange of information without revealing underlying private data. ZKPs have unique advantages in terms of universality and minimal security assumptions when compared to other privacy-sensitive computational methods for distributed systems, such as homomorphic encryption and secure multiparty computation. Their application spans multiple domains, from enhancing privacy in blockchain to facilitating confidential verification of computational tasks. This survey starts with a high-level overview of the technical workings of ZKPs with a focus on an increasingly relevant subset of ZKPs called zk-SNARKS. While there have been prior surveys on the algorithmic and theoretical aspects of ZKPs, our work is distinguished by providing a broader view of practical aspects and describing many recently-developed use cases of ZKPs across various domains. These application domains span blockchain privacy, scaling, storage, and interoperability, as well as non-blockchain applications like voting, authentication, timelocks, and machine learning. Aimed at both practitioners and researchers, the survey also covers foundational components and infrastructure such as zero-knowledge virtual machines (zkVM), domain-specific languages (DSLs), supporting libraries, frameworks, and protocols. We conclude with a discussion on future directions, positioning ZKPs as pivotal in the advancement of cryptographic practices and digital privacy across many applications.
]]></content:encoded>


</item>
<item>
<title>Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision</title>
<link>https://arxiv.org/abs/2408.00641</link>
<guid>https://arxiv.org/abs/2408.00641</guid>
<content:encoded><![CDATA[

arXiv:2408.00641v1 Announce Type: new 
Abstract: The rampant fraudulent activities on Ethereum hinder the healthy development of the blockchain ecosystem, necessitating the reinforcement of regulations. However, multiple imbalances involving account interaction frequencies and interaction types in the Ethereum transaction environment pose significant challenges to data mining-based fraud detection research. To address this, we first propose the concept of meta-interactions to refine interaction behaviors in Ethereum, and based on this, we present a dual self-supervision enhanced Ethereum fraud detection framework, named Meta-IFD. This framework initially introduces a generative self-supervision mechanism to augment the interaction features of accounts, followed by a contrastive self-supervision mechanism to differentiate various behavior patterns, and ultimately characterizes the behavioral representations of accounts and mines potential fraud risks through multi-view interaction feature learning. Extensive experiments on real Ethereum datasets demonstrate the effectiveness and superiority of our framework in detecting common Ethereum fraud behaviors such as Ponzi schemes and phishing scams. Additionally, the generative module can effectively alleviate the interaction distribution imbalance in Ethereum data, while the contrastive module significantly enhances the framework's ability to distinguish different behavior patterns. The source code will be released on GitHub soon.
]]></content:encoded>


</item>
<item>
<title>Algorithms for Collaborative Machine Learning under Statistical Heterogeneity</title>
<link>https://arxiv.org/abs/2408.00050</link>
<guid>https://arxiv.org/abs/2408.00050</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、联邦学习、统计异质性、个性化方法、合成数据生成

总结:

本文主要探讨了在分布式数据环境中进行机器学习时面临的主要挑战，尤其是统计异质性问题。提出了三种解决策略来应对这一挑战：

1. **个性化方法**：“SuPerFed”：这是一种基于模式连通性的新颖个性化方法，旨在通过连接不同数据集中的模式，提高模型的泛化能力，特别是针对具有不同数据分布的客户端。

2. **适应性决策算法**：“AAggFF”：该算法采用在线凸优化框架，通过调整参与客户端的混合系数，以实现性能分布的一致性，从而改善整体模型性能。

3. **协作合成数据生成**：“FedEvg”：利用能量基模拟能力的灵活性和组合性，生成用于训练的合成数据，帮助减少统计异质性对模型性能的影响。

这些方法共同提供了分布式系统中协作机器学习应用的有效解决方案，有助于克服数据分散带来的挑战，推动分布式系统的进一步发展与应用。 <div>
arXiv:2408.00050v1 Announce Type: cross 
Abstract: Learning from distributed data without accessing them is undoubtedly a challenging and non-trivial task. Nevertheless, the necessity for distributed training of a statistical model has been increasing, due to the privacy concerns of local data owners and the cost in centralizing the massively distributed data. Federated learning (FL) is currently the de facto standard of training a machine learning model across heterogeneous data owners, without leaving the raw data out of local silos. Nevertheless, several challenges must be addressed in order for FL to be more practical in reality. Among these challenges, the statistical heterogeneity problem is the most significant and requires immediate attention. From the main objective of FL, three major factors can be considered as starting points -- \textit{parameter}, textit{mixing coefficient}, and \textit{local data distributions}. In alignment with the components, this dissertation is organized into three parts. In Chapter II, a novel personalization method, \texttt{SuPerFed}, inspired by the mode-connectivity is introduced. In Chapter III, an adaptive decision-making algorithm, \texttt{AAggFF}, is introduced for inducing uniform performance distributions in participating clients, which is realized by online convex optimization framework. Finally, in Chapter IV, a collaborative synthetic data generation method, \texttt{FedEvg}, is introduced, leveraging the flexibility and compositionality of an energy-based modeling approach. Taken together, all of these approaches provide practical solutions to mitigate the statistical heterogeneity problem in data-decentralized settings, paving the way for distributed systems and applications using collaborative machine learning methods.
]]></content:encoded>


</item>
<item>
<title>Reputation Gaming in Stack Overflow</title>
<link>https://arxiv.org/abs/2111.07101</link>
<guid>https://arxiv.org/abs/2111.07101</guid>
<content:encoded><![CDATA[
<div> 关键词：Stack Overflow、声誉操纵、算法、用户行为、平台管理

总结:

文章主要探讨了Stack Overflow平台上的声誉系统可能面临的操纵问题。通过分析1,697篇来自Meta Stack Exchange网站的帖子，研究发现了四种声誉欺诈场景，包括投票圈等。为了帮助平台管理者识别可疑的声誉游戏行为，文章开发了两种算法：一种用于识别可能存在声誉欺诈的孤立或半孤立社区，另一种则关注用户声誉分数突然异常增长的情况。

这些算法的性能通过检查Stack Overflow网站上用户的声誉历史记录进行了评估，结果显示，大约有60%-80%被算法标记为可疑的用户最终经历了声誉分数的减少。这一研究强调了Stack Overflow等问答平台在面对声誉操纵时所面临的挑战，并提出了有效监控和防止此类行为的方法，对于提升平台内容质量和用户行为的规范具有重要意义。 <div>
arXiv:2111.07101v2 Announce Type: replace 
Abstract: Stack Overflow incentive system awards users with reputation scores to ensure quality. The decentralized nature of the forum may make the incentive system prone to manipulation. This paper offers, for the first time, a comprehensive study of the reported types of reputation manipulation scenarios that might be exercised in Stack Overflow and the prevalence of such reputation gamers by a qualitative study of 1,697 posts from meta Stack Exchange sites. We found four different types of reputation fraud scenarios, such as voting rings where communities form to upvote each other repeatedly on similar posts. We developed algorithms that enable platform managers to automatically identify these suspicious reputation gaming scenarios for review. The first algorithm identifies isolated/semi-isolated communities where probable reputation frauds may occur mostly by collaborating with each other. The second algorithm looks for sudden unusual big jumps in the reputation scores of users. We evaluated the performance of our algorithms by examining the reputation history dashboard of Stack Overflow users from the Stack Overflow website. We observed that around 60-80% of users flagged as suspicious by our algorithms experienced reductions in their reputation scores by Stack Overflow.
]]></content:encoded>


</item>

<item>
<title>FL-DECO-BC: A Privacy-Preserving, Provably Secure, and Provenance-Preserving Federated Learning Framework with Decentralized Oracles on Blockchain for VANETs</title>
<link>https://arxiv.org/abs/2407.21141</link>
<guid>https://arxiv.org/abs/2407.21141</guid>
<content:encoded><![CDATA[
<div> 关键词：VANETs、Federated Learning（FL）、区块链、数据隐私、安全

<br /><br />
总结:本文提出了一种名为FL-DECO-BC的新型隐私保护、可验证安全和可追溯性保护的联邦学习框架，专门针对车辆自组网络(VANETs)。该框架利用区块链上的去中心化仲裁机构安全访问外部数据源，同时通过高级技术确保数据隐私。FL-DECO-BC通过加密原语和形式验证方法提供了可证明的安全性。此外，该框架还集成了可追溯设计，用于追踪数据来源和历史记录，从而建立信任和责任机制。这种结合特性赋予了VANETs安全和隐私意识的机器学习能力，为先进的交通管理和安全应用铺平了道路。 <div>
arXiv:2407.21141v1 Announce Type: new 
Abstract: Vehicular Ad-Hoc Networks (VANETs) hold immense potential for improving traffic safety and efficiency. However, traditional centralized approaches for machine learning in VANETs raise concerns about data privacy and security. Federated Learning (FL) offers a solution that enables collaborative model training without sharing raw data. This paper proposes FL-DECO-BC as a novel privacy-preserving, provably secure, and provenance-preserving federated learning framework specifically designed for VANETs. FL-DECO-BC leverages decentralized oracles on blockchain to securely access external data sources while ensuring data privacy through advanced techniques. The framework guarantees provable security through cryptographic primitives and formal verification methods. Furthermore, FL-DECO-BC incorporates a provenance-preserving design to track data origin and history, fostering trust and accountability. This combination of features empowers VANETs with secure and privacy-conscious machine-learning capabilities, paving the way for advanced traffic management and safety applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach</title>
<link>https://arxiv.org/abs/2407.21294</link>
<guid>https://arxiv.org/abs/2407.21294</guid>
<content:encoded><![CDATA[
<div> 关键词：稳定匹配、分散式学习、纳什均衡、指数权重学习、局部收敛

总结:

本文研究了在全分散式和无协调的情况下学习稳定匹配的问题。具体来说，文章探讨了男性和女性各N人的情况，他们对对方有偏好，但男性并不知道女性对他们的偏好，只有在提出并成功匹配给女性后才能得知。稳定匹配指的是没有男性和女性会更喜欢彼此而非其当前匹配。

在已知偏好时，Gale和Shapley提出的递延接受算法提供了一种分散式和无协调的稳定匹配算法。然而，当偏好未知时，由于缺乏协调，开发这样的算法面临重大挑战。文章通过将稳定匹配问题与非合作博弈中的纳什均衡联系起来，实现了这一目标。首先，提出了一个完全信息博弈形式，其中纯纳什均衡与稳定匹配相匹配，混合纳什均衡可以通过分散方式转换为稳定匹配。

对于层级市场，采用指数权重（EXP）学习算法实现稳定匹配的学习，具有对玩家数量的多项式依赖的对数遗憾。此外，对于一般匹配市场，同样的EXP学习算法在局部以指数级速度收敛到稳定匹配。为了弥补这一点，文章引入了一个新的分散式和无协调学习算法，该算法在全球范围内以任意高概率收敛到稳定匹配，利用了稳定匹配游戏的弱循环性。 <div>
arXiv:2407.21294v1 Announce Type: new 
Abstract: We consider the problem of learning stable matchings in a fully decentralized and uncoordinated manner. In this problem, there are $n$ men and $n$ women, each having preference over the other side. It is assumed that women know their preferences over men, but men are not aware of their preferences over women, and they only learn them if they propose and successfully get matched to women. A matching is called stable if no man and woman prefer each other over their current matches. When all the preferences are known a priori, the celebrated Deferred-Acceptance algorithm proposed by Gale and Shapley provides a decentralized and uncoordinated algorithm to obtain a stable matching. However, when the preferences are unknown, developing such an algorithm faces major challenges due to a lack of coordination. We achieve this goal by making a connection between stable matchings and learning Nash equilibria (NE) in noncooperative games. First, we provide a complete information game formulation for the stable matching problem with known preferences such that its set of pure NE coincides with the set of stable matchings, while its mixed NE can be rounded in a decentralized manner to a stable matching. Relying on such a game-theoretic formulation, we show that for hierarchical markets, adopting the exponential weight (EXP) learning algorithm for the stable matching game achieves logarithmic regret with polynomial dependence on the number of players, thus answering a question posed in previous literature. Moreover, we show that the same EXP learning algorithm converges locally and exponentially fast to a stable matching in general matching markets. We complement this result by introducing another decentralized and uncoordinated learning algorithm that globally converges to a stable matching with arbitrarily high probability, leveraging the weak acyclicity property of the stable matching game.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Games in Public Announcement: How to Reduce System Losses in Optimistic Blockchain Mechanisms</title>
<link>https://arxiv.org/abs/2407.21413</link>
<guid>https://arxiv.org/abs/2407.21413</guid>
<content:encoded><![CDATA[
<div> 关键词：公告游戏、验证者、乐观汇总、游戏理论模型、机制优化

文章主要探讨了公告游戏的概念及其在现实世界中的应用，以乐观汇总为例进行了详细分析。乐观汇总是一种区块链扩展解决方案，通过公告发布者和验证者的互动提高了交易吞吐量和成本效益。作者构建了一个基于游戏理论的模型来研究参与者的潜在行为，识别了所有纳什均衡，并分析了不同纳什均衡下的系统损失。同时，他们还研究了系统参数如何影响纳什均衡下的系统损失，并提出了减少系统损失的机制优化建议。

总结:
文章首先介绍了公告游戏的概念及其在区块链技术中的应用，特别是以乐观汇总为例说明了这种游戏机制如何提高交易效率。接着，作者利用游戏理论构建模型，深入分析了公告游戏中的参与者行为，特别是公告发布者与验证者之间的动态关系。通过识别纳什均衡并分析其系统损失，文章揭示了在不同策略组合下系统的实际表现。此外，文章还探讨了系统参数对纳什均衡下系统损失的影响，为理解公告游戏的复杂性提供了理论依据。最后，基于上述分析结果，文章提出了一系列机制优化建议，旨在降低系统损失，提升整体效率。这些研究成果不仅对于理解公告游戏的内在机制具有重要意义，也为未来区块链技术的发展提供了宝贵的参考。 <div>
arXiv:2407.21413v1 Announce Type: new 
Abstract: Announcement games, where information is disseminated by announcers and challenged by validators, are prevalent in real-world scenarios. Validators take effort to verify the validity of the announcements, gaining rewards for successfully challenging invalid ones, while receiving nothing for valid ones. Optimistic Rollup, a Layer 2 blockchain scaling solution, exemplifies such games, offering significant improvements in transaction throughput and cost efficiency. We present a game-theoretic model of announcement games to analyze the potential behaviors of announcers and validators. We identify all Nash equilibria and study the corresponding system losses for different Nash equilibria. Additionally, we analyze the impact of various system parameters on system loss under the Nash equilibrium. Finally, we provide suggestions for mechanism optimization to reduce system losses.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Self-Sovereign Identity for Consented and Content-Based Access to Medical Records using Blockchain</title>
<link>https://arxiv.org/abs/2407.21559</link>
<guid>https://arxiv.org/abs/2407.21559</guid>
<content:encoded><![CDATA[
<div> 关键词：电子健康记录（EHRs）、区块链、自主权身份（SSI）、分散式标识符（DID）、属性基于加密（ABE）

总结:本文提出了一种基于区块链的解决方案，旨在安全地交换不同实体之间的电子健康记录（EHRs）。该方案结合了自主权身份（SSI）钱包和分散式标识符（DID），以及由用户完全控制的医疗数据。通过使用加密技术，用户可以在安全通信通道中以完全保密的方式共享其医疗数据。同时，利用IPFS网络进行离链存储，并通过属性基于加密（ABE）确保数据的机密性和完整性。此外，通过DID的使用增强用户隐私，并通过使用对等DID来限制任何可能的相关性或身份识别。整体而言，此方案保证了EHRs的安全交换、存储和管理，并从技术栈中继承了设计时的安全特性。 <div>
arXiv:2407.21559v1 Announce Type: new 
Abstract: Electronic Health Records (EHRs) and Medical Data are classified as personal data in every privacy law, meaning that any related service that includes processing such data must come with full security, confidentiality, privacy and accountability. Solutions for health data management, as in storing it, sharing and processing it, are emerging quickly and were significantly boosted by the Covid-19 pandemic that created a need to move things online. EHRs makes a crucial part of digital identity data, and the same digital identity trends -- as in self sovereign identity powered by decentralized ledger technologies like Blockchain, are being researched or implemented in contexts managing digital interactions between health facilities, patients and health professionals. In this paper, we propose a blockchain-based solution enabling secure exchange of EHRs between different parties powered by a self-sovereign identity (SSI) wallet and decentralized identifiers. We also make use of a consortium IPFS network for off-chain storage and attribute-based encryption (ABE) to ensure data confidentiality and integrity. Through our solution, we grant users full control over their medical data, and enable them to securely share it in total confidentiality over secure communication channels between user wallets using encryption. We also use DIDs for better user privacy and limit any possible correlations or identification by using pairwise DIDs. Overall, combining this set of technologies guarantees secure exchange of EHRs, secure storage and management along with by-design features inherited from the technological stack.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation</title>
<link>https://arxiv.org/abs/2407.21739</link>
<guid>https://arxiv.org/abs/2407.21739</guid>
<content:encoded><![CDATA[
<div> 关键词：基础模型、医疗影像分析、隐私保护、联邦学习、参数高效微调

总结:

本文研究了一种结合参数高效微调(PEFT)与联邦学习(Federated Learning, FL)的方法，以解决在医疗图像分析中调整基础模型时面临的通信成本高和数据隐私问题。通过在联邦环境下使用低秩适配器(Low-Rank Adapters, LoRA)，作者对“段任何模型”(Segment Anything Model, SAM)进行了适应性调整，用于3D医学图像分割任务。与以往工作不同的是，他们深入分析了SAM中每个组件在微调性能上的贡献，并识别出特定层进行联邦化，以保持通信成本低同时保证准确度。

在Fed-KiTS数据集上，该方法将通信成本降低了约48倍，同时提高了约6%的Dice分数。与SAMed相比，这种方法在通信量和需要微调的参数数量上分别实现了约2.8倍和2.8倍的减少。进一步地，通过在Fed-IXI和前列腺MRI数据集上的实验验证了其有效性。

主要贡献包括：

1. 提出了结合PEFT与FL的策略，以降低通信成本和提高效率。
2. 使用LoRA进行适应性调整，以优化3D医学图像分割任务。
3. 通过深入分析确定了关键层进行联邦化，以平衡通信成本和准确性。
4. 在多个数据集上展示了方法的有效性和优越性。
5. 实现了与现有方法相比显著的通信和参数减少，同时保持或提升性能。 <div>
arXiv:2407.21739v1 Announce Type: new 
Abstract: Adapting foundation models for medical image analysis requires finetuning them on a considerable amount of data because of extreme distribution shifts between natural (source) data used for pretraining and medical (target) data. However, collecting task-specific medical data for such finetuning at a central location raises many privacy concerns. Although Federated learning (FL) provides an effective means for training on private decentralized data, communication costs in federating large foundation models can quickly become a significant bottleneck, impacting the solution's scalability. In this work, we address this problem of efficient communication while ensuring effective learning in FL by combining the strengths of Parameter-Efficient Fine-tuning (PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA) in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical image segmentation. Unlike prior works that utilize LoRA and finetune the entire decoder, we critically analyze the contribution of each granular component of SAM on finetuning performance. Thus, we identify specific layers to be federated that are very efficient in terms of communication cost while producing on-par accuracy. Our experiments show that retaining the parameters of the SAM model (including most of the decoder) in their original state during adaptation is beneficial because fine-tuning on small datasets tends to distort the inherent capabilities of the underlying foundation model. On Fed-KiTS, our approach decreases communication cost (~48x) compared to full fine-tuning while increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach performs similar to SAMed while achieving ~2.8x reduction in communication and parameters to be finetuned. We further validate our approach with experiments on Fed-IXI and Prostate MRI datasets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Naeural AI OS -- Decentralized ubiquitous computing MLOps execution engine</title>
<link>https://arxiv.org/abs/2306.08708</link>
<guid>https://arxiv.org/abs/2306.08708</guid>
<content:encoded><![CDATA[
<div> 关键词：普遍计算、人工智能、深度学习、低代码开发、分布式社区

总结:
本文提出了一种创新的方法，旨在解决大规模采用人工智能（AI）和深度学习所面临的挑战。主要问题在于高昂的云基础设施成本以及对复杂数据科学和机器学习专业知识的需求。为了解决这些问题，作者提出了一种针对最终用户需求的低代码AI应用开发与部署策略。这种策略通过在分布式全球合作社区中利用基于代币经济的机制来优化基础设施分配、成本控制以及安全任务分发。具体来说，这种方法旨在降低AI系统的构建和运行成本，同时确保数据安全和资源的有效利用。通过实现这些目标，该方法不仅促进了AI技术的普及，还加强了社区之间的连接与协作，推动了更高效、可持续发展的社会。 <div>
arXiv:2306.08708v3 Announce Type: replace 
Abstract: Over the past few years, ubiquitous, or pervasive computing has gained popularity as the primary approach for a wide range of applications, including enterprise-grade systems, consumer applications, and gaming systems. Ubiquitous computing refers to the integration of computing technologies into everyday objects and environments, creating a network of interconnected devices that can communicate with each other and with humans. By using ubiquitous computing technologies, communities can become more connected and efficient, with members able to communicate and collaborate more easily. This enabled interconnectedness and collaboration can lead to a more successful and sustainable community. The spread of ubiquitous computing, however, has emphasized the importance of automated learning and smart applications in general. Even though there have been significant strides in Artificial Intelligence and Deep Learning, large scale adoption has been hesitant due to mounting pressure on expensive and highly complex cloud numerical-compute infrastructures. Adopting, and even developing, practical machine learning systems can come with prohibitive costs, not only in terms of complex infrastructures but also of solid expertise in Data Science and Machine Learning. In this paper we present an innovative approach for low-code development and deployment of end-to-end AI cooperative application pipelines. We address infrastructure allocation, costs, and secure job distribution in a fully decentralized global cooperative community based on tokenized economics.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CSDO: Enhancing Efficiency and Success in Large-Scale Multi-Vehicle Trajectory Planning</title>
<link>https://arxiv.org/abs/2405.20858</link>
<guid>https://arxiv.org/abs/2405.20858</guid>
<content:encoded><![CDATA[
<div> 关键词：CSDO算法、多车辆轨迹规划、高效算法、非凸约束、分布式优化

总结:
本文提出了一种名为Centralized Searching and Decentralized Optimization（CSDO）的高效算法，用于解决大规模多车辆轨迹规划问题。面对随代理数量增加而呈指数增长的非凸约束，探索不同的同调类（暗示不同凸域）对于找到可行解至关重要。现有方法在高效探索各种同调类方面遇到困难，因为这与寻找耗时精确轨迹解决方案相结合。CSDO通过将此过程分为不同层次并集成高效的多智能体路径查找（MAPF）算法来搜索同调类，首先使用大步长搜索粗略初始猜测，识别特定的同调类。随后的分散式二次规划（QP）则对这个猜测进行细化，有效地解决次要碰撞。实验结果显示，CSDO在大型、高密度场景中超越了现有MVTP算法，在50m×50m随机场景中实现高达95%的成功率，耗时约1秒。相关源代码已发布于https://github.com/YangSVM/CSDOTrajectoryPlanning。 <div>
arXiv:2405.20858v2 Announce Type: replace 
Abstract: This paper presents an efficient algorithm, naming Centralized Searching and Decentralized Optimization (CSDO), to find feasible solution for large-scale Multi-Vehicle Trajectory Planning (MVTP) problem. Due to the intractable growth of non-convex constraints with the number of agents, exploring various homotopy classes that imply different convex domains, is crucial for finding a feasible solution. However, existing methods struggle to explore various homotopy classes efficiently due to combining it with time-consuming precise trajectory solution finding. CSDO, addresses this limitation by separating them into different levels and integrating an efficient Multi-Agent Path Finding (MAPF) algorithm to search homotopy classes. It first searches for a coarse initial guess using a large search step, identifying a specific homotopy class. Subsequent decentralized Quadratic Programming (QP) refinement processes this guess, resolving minor collisions efficiently. Experimental results demonstrate that CSDO outperforms existing MVTP algorithms in large-scale, high-density scenarios, achieving up to 95% success rate in 50m $\times$ 50m random scenarios around one second. Source codes are released in https://github.com/YangSVM/CSDOTrajectoryPlanning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reward Schemes and Committee Sizes in Proof of Stake Governance</title>
<link>https://arxiv.org/abs/2406.10525</link>
<guid>https://arxiv.org/abs/2406.10525</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、奖励机制、委员会规模、治理系统、委托权益证明

<br /><br />
总结:

本文探讨了基于区块链社区的治理系统中奖励方案与委员会规模的影响。研究建立了一个选举模型，其中结果为二元空间，存在客观正确结果，参与者只能委托投票权给一组代表（DReps）。每个DRep的努力（成本）不仅影响其正确投票的能力，还影响她吸引的总委托量，从而增加其投票权重。此模型与委托权益证明（PoS）协议相似，其中委托的权益用于选举区块构建者。

为了激励代表付出努力，可以采用基于每位DRep吸引的委托量的奖励机制。文章分析了这一模型的游戏理论和优化对应方面，并重点研究了在固定预算下选择最大化正确结果概率的委员会的方法。研究成果为设计有效的奖励机制和确定最优委员会结构提供了见解，包括确定足够多的DReps数量。 <div>
arXiv:2406.10525v2 Announce Type: replace 
Abstract: In this paper, we investigate the impact of reward schemes and committee sizes motivated by governance systems over blockchain communities. We introduce a model for elections with a binary outcome space where there is a ground truth (i.e., a "correct" outcome), and where stakeholders can only choose to delegate their voting power to a set of delegation representatives (DReps). Moreover, the effort (cost) invested by each DRep positively influences both (i) her ability to vote correctly and (ii) the total delegation that she attracts, thereby increasing her voting power. This model constitutes the natural counterpart of delegated proof-of-stake (PoS) protocols, where delegated stakes are used to elect the block builders.
  As a way to motivate the representatives to exert effort, a reward scheme can be used based on the delegation attracted by each DRep. We analyze both the game-theoretic aspects and the optimization counterpart of this model. Our primary focus is on selecting a committee that maximizes the probability of reaching the correct outcome, given a fixed monetary budget allocated for rewarding the delegates. Our findings provide insights into the design of effective reward mechanisms and optimal committee structures (i.e., how many DReps are enough) in these PoS-like governance systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Legal Aspects of Decentralized and Platform-Driven Economies</title>
<link>https://arxiv.org/abs/2407.20301</link>
<guid>https://arxiv.org/abs/2407.20301</guid>
<content:encoded><![CDATA[
<div> 关键词：共享经济、数字平台、算法驱动公司、区块链技术、人工智能系统

<br />
总结:

文章主要探讨了共享经济在全球范围内的迅速扩张及其对传统商业模式的影响。文中提到了Zipcar、BlaBlaCar和Couchsurfing等早期平台驱动公司的兴起，以及Airbnb和Uber如何通过数字平台和算法驱动改变了交通和住宿行业。共享经济的核心理念是“使用权而非所有权”，这与传统的商业模式形成了鲜明对比。

随着数字平台、数据和算法驱动公司的崛起，以及区块链技术的广泛应用，共享经济正以惊人的速度发展。然而，这些新技术也带来了法律框架的挑战，特别是对于AI系统的责任归属问题。文章指出，传统的法律责任体系可能无法完全适应这些新兴技术带来的变革，因此需要建立更加前瞻性和灵活的监管结构，以确保公平、透明和安全的共享经济环境。

在未来的共享经济中，AI系统可能会进一步改变法律体系，涉及操作者、用户和制造商的责任划分。为了应对这些挑战，需要制定新的法规和指导原则，以确保共享经济的可持续发展，并保护各方权益。 <div>
arXiv:2407.20301v1 Announce Type: new 
Abstract: The sharing economy is sprawling across almost every sector and activity around the world. About a decade ago, there were only a handful of platform driven companies operating on the market. Zipcar, BlaBlaCar and Couchsurfing among them. Then Airbnb and Uber revolutionized the transportation and hospitality industries with a presence in virtually every major city. Access over ownership is the paradigm shift from the traditional business model that grants individuals the use of products or services without the necessity of buying them. Digital platforms, data and algorithm-driven companies as well as decentralized blockchain technologies have tremendous potential. But they are also changing the rules of the game. One of such technologies challenging the legal system are AI systems that will also reshape the current legal framework concerning the liability of operators, users and manufacturers. Therefore, this introductory chapter deals with explaining and describing the legal issues of some of these disruptive technologies. The chapter argues for a more forward-thinking and flexible regulatory structure.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Entrapment Problem in Random Walk Decentralized Learning</title>
<link>https://arxiv.org/abs/2407.20611</link>
<guid>https://arxiv.org/abs/2407.20611</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、随机游走、Metropolis-Hastings算法、Levy跳跃、收敛率

总结:

本文探讨了基于图的分布式学习环境中的去中心化学习。研究关注于利用随机游走更新全局模型的去中心化SGD算法，并对设计过渡概率矩阵以加速收敛进行了深入研究。与增强集中式学习的重采样技术不同，其去中心化等价物，即使用Metropolis-Hastings(MH)算法，可能会导致陷阱问题，使得随机游走停滞在某些节点上，从而减慢收敛速度。

为了解决这个问题，作者提出了一种名为Metropolis-Hastings with Levy Jumps(MHLJ)的算法，该算法通过引入随机扰动（跳跃）来克服陷阱。理论分析表明，MHLJ算法具有一定的收敛速率和误差差距，并通过数值实验验证了这些结论。

综上所述，本文旨在通过设计优化的过渡概率矩阵和引入Levy跳跃机制，改进去中心化SGD算法的性能，特别是在避免随机游走陷阱方面。通过理论分析和实验证明，MHLJ算法在加速分布式学习过程方面表现出显著优势。 <div>
arXiv:2407.20611v1 Announce Type: new 
Abstract: This paper explores decentralized learning in a graph-based setting, where data is distributed across nodes. We investigate a decentralized SGD algorithm that utilizes a random walk to update a global model based on local data. Our focus is on designing the transition probability matrix to speed up convergence. While importance sampling can enhance centralized learning, its decentralized counterpart, using the Metropolis-Hastings (MH) algorithm, can lead to the entrapment problem, where the random walk becomes stuck at certain nodes, slowing convergence. To address this, we propose the Metropolis-Hastings with L\'evy Jumps (MHLJ) algorithm, which incorporates random perturbations (jumps) to overcome entrapment. We theoretically establish the convergence rate and error gap of MHLJ and validate our findings through numerical experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mean of Means: A 10-dollar Solution for Human Localization with Calibration-free and Unconstrained Camera Settings</title>
<link>https://arxiv.org/abs/2407.20870</link>
<guid>https://arxiv.org/abs/2407.20870</guid>
<content:encoded><![CDATA[
<div> 关键词：高精度、低成本、人体定位、立体视觉、概率方法

总结:

文章主要探讨了在元宇宙时代下，准确的人体定位对于各种应用的重要性。现有的高精度解决方案通常依赖昂贵且需要标记的硬件设备，而基于视觉的方法则提供了一种成本更低、无需标记的替代方案。然而，当前基于立体视觉的人体定位方法受限于刚性透视变换原理和多阶段SVD求解器中的误差传播问题，同时还需要多个高分辨率摄像头并严格设定布局。

为了解决上述问题，作者提出了一种基于概率的方法，将人体上的所有点视为围绕身体几何中心生成的分布观察结果。这种方法显著提高了采样效率，使得每个感兴趣点的样本数量从数百个增加到数十亿个。通过利用中心极限定理来建模世界坐标与像素坐标的分布均值之间的关系，确保了正态分布，从而有利于学习过程。实验结果显示，使用两台分辨率为640x480像素的网络摄像头，仅需约10美元的成本，即可实现0.3米范围内95%的定位精度和0.5米范围内接近100%的定位准确性。 <div>
arXiv:2407.20870v1 Announce Type: new 
Abstract: Accurate human localization is crucial for various applications, especially in the Metaverse era. Existing high precision solutions rely on expensive, tag-dependent hardware, while vision-based methods offer a cheaper, tag-free alternative. However, current vision solutions based on stereo vision face limitations due to rigid perspective transformation principles and error propagation in multi-stage SVD solvers. These solutions also require multiple high-resolution cameras with strict setup constraints. To address these limitations, we propose a probabilistic approach that considers all points on the human body as observations generated by a distribution centered around the body's geometric center. This enables us to improve sampling significantly, increasing the number of samples for each point of interest from hundreds to billions. By modeling the relation between the means of the distributions of world coordinates and pixel coordinates, leveraging the Central Limit Theorem, we ensure normality and facilitate the learning process. Experimental results demonstrate human localization accuracy of 95% within a 0.3m range and nearly 100% accuracy within a 0.5m range, achieved at a low cost of only 10 USD using two web cameras with a resolution of 640x480 pixels.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SoK: Payment Channel Networks</title>
<link>https://arxiv.org/abs/2407.20968</link>
<guid>https://arxiv.org/abs/2407.20968</guid>
<content:encoded><![CDATA[
<div> 关键词：Payment Channel Networks（PCNs）、路径查找与路由、虚拟通道、状态通道、支付通道枢纽与重新平衡

<br /><br />
总结:

本文是一篇关于支付通道网络（PCNs）的研究综述，旨在深入探讨该领域当前的研究挑战和进展。PCNs作为一种解决区块链上链交易的扩展性、吞吐量和成本问题的替代方案，通过支持离链执行交易，显著减轻了区块链的压力，提高了交易处理速度，降低了交易费用，并增强了隐私保护。

文章首先概述了PCNs的关键方面，包括路径查找与路由、虚拟通道、状态通道、支付通道枢纽与重新平衡等，为读者提供了对当前PCN研究状态的全面理解。接着，文章强调了该领域存在的未解决问题，指出这些问题是学术界和研究社区迫切需要关注的问题。

具体而言，PCN研究面临的挑战包括但不限于：

1. **路径查找与路由**：高效、安全地在多个通道中找到最优路径以完成交易，同时保证交易隐私。
   
2. **虚拟通道**：设计灵活的机制，允许用户在不直接连接的情况下进行交易，提高网络的可扩展性和安全性。
   
3. **状态通道**：管理通道中的资金流动和状态更新，确保交易的最终一致性，同时防止欺诈行为。
   
4. **支付通道枢纽与重新平衡**：构建中央节点来协调不同通道之间的交易，以及在资金不平衡时自动调整通道的状态，以维持网络的稳定运行。

通过深入分析这些挑战和问题，本文不仅为读者提供了一个清晰的PCN研究全景图，还指出了未来研究的方向，鼓励相关领域的学者和实践者共同合作，解决这些难题，从而推动PCNs技术的发展，使其更加安全、高效、灵活，以适应不断变化的市场需求和技术环境。 <div>
arXiv:2407.20968v1 Announce Type: new 
Abstract: Payment Channel Networks (PCNs) have been proposed as an alternative solution to the scalability, throughput, and cost overhead associated with on-chain transactions. By facilitating offchain execution of transactions, PCNs significantly reduce the burden on the blockchain, leading to faster transaction processing, reduced transaction fees, and enhanced privacy. Despite these advantages, the current research in PCNs presents a variety of research challenges that require further exploration. In this paper, we survey the recent work in several aspects of PCNs, such as pathfinding and routing, virtual channels, state channels, payment channel hubs and rebalancing. This survey aims to provide the reader with a detailed understanding of the current state-of-the-art in PCN research, highlighting a few important advancements. Additionally, we highlight the various unresolved issues in the area of PCN research. Specifically, this paper seeks to answer the following crucial question: What are the various interesting and non-trivial challenges in PCN research that require immediate attention from the academic and research community? By addressing this question, we aim to identify the most pressing problems and future research directions that interested readers can immediately work on. Through this analysis, we hope to inspire researchers and practitioners to tackle these challenges to make PCNs more secure and versatile
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Impact of Conflicting Transactions in Blockchain: Detecting and Mitigating Potential Attacks</title>
<link>https://arxiv.org/abs/2407.20980</link>
<guid>https://arxiv.org/abs/2407.20980</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、冲突交易、攻击向量、防御策略、网络性能

总结:

本文研究了冲突交易对区块链网络攻击向量的影响。通过建模和模拟，分析了四种关键攻击——阻断挖掘、双重支付、余额调整和分布式拒绝服务（DDoS）——如何利用冲突交易进行操作。研究不仅探讨了这些攻击利用交易冲突的机制，还强调了它们对区块链网络完整性和可靠性可能产生的影响。此外，提出了缓解这些攻击的一系列对策。通过实施和评估，证明了这些对策的有效性，能够降低攻击率并增强整体网络性能，同时无需引入额外开销。研究结果强调了积极管理冲突交易对于加强区块链安全和性能的重要性。

本文通过深入分析，揭示了冲突交易如何成为攻击者利用的漏洞，导致性能下降和安全风险增加。为解决这一问题，作者提出了针对性的防御策略，旨在有效降低攻击概率，提升网络效率。研究方法包括了对四种主要攻击模式的模拟分析，以及对所提策略实际效果的验证。最终结论显示，通过合理管理和优化，可以显著改善区块链系统的安全性与运行效率，确保其稳定可靠地服务于用户。 <div>
arXiv:2407.20980v1 Announce Type: new 
Abstract: Conflicting transactions within blockchain networks not only pose performance challenges but also introduce security vulnerabilities, potentially facilitating malicious attacks. In this paper, we explore the impact of conflicting transactions on blockchain attack vectors. Through modeling and simulation, we delve into the dynamics of four pivotal attacks - block withholding, double spending, balance, and distributed denial of service (DDoS), all orchestrated using conflicting transactions. Our analysis not only focuses on the mechanisms through which these attacks exploit transaction conflicts but also underscores their potential impact on the integrity and reliability of blockchain networks. Additionally, we propose a set of countermeasures for mitigating these attacks. Through implementation and evaluation, we show their effectiveness in lowering attack rates and enhancing overall network performance seamlessly, without introducing additional overhead. Our findings emphasize the critical importance of actively managing conflicting transactions to reinforce blockchain security and performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Securing Proof of Stake Blockchains: Leveraging Multi-Agent Reinforcement Learning for Detecting and Mitigating Malicious Nodes</title>
<link>https://arxiv.org/abs/2407.20983</link>
<guid>https://arxiv.org/abs/2407.20983</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof of Stake (PoS)、Multi-agent Reinforcement Learning (MRL)、Malicious nodes、Penalty-reward scheme、Attack resilience

总结:
本文提出了MRL-PoS+，一种利用多智能体强化学习（MRL）技术增强PoS区块链安全性的新型共识算法。MRL-PoS+通过引入惩罚奖励机制来检测和消除潜在恶意节点，防止它们进行攻击行为。实验结果显示，与传统方案相比，MRL-PoS+显著提高了PoS区块链的抗攻击能力，同时并未增加额外的计算开销。该算法通过识别并惩罚可能引发网络攻击的行为，有效阻止了六种主要类型攻击的执行，证明了其在保护分布式网络免受恶意行为影响方面的高效性和实用性。 <div>
arXiv:2407.20983v1 Announce Type: new 
Abstract: Proof of Stake (PoS) blockchains offer promising alternatives to traditional Proof of Work (PoW) systems, providing scalability and energy efficiency. However, blockchains operate in a decentralized manner and the network is composed of diverse users. This openness creates the potential for malicious nodes to disrupt the network in various ways. Therefore, it is crucial to embed a mechanism within the blockchain network to constantly monitor, identify, and eliminate these malicious nodes without involving any central authority. In this paper, we propose MRL-PoS+, a novel consensus algorithm to enhance the security of PoS blockchains by leveraging Multi-agent Reinforcement Learning (MRL) techniques. Our proposed consensus algorithm introduces a penalty-reward scheme for detecting and eliminating malicious nodes. This approach involves the detection of behaviors that can lead to potential attacks in a blockchain network and hence penalizes the malicious nodes, restricting them from performing certain actions. Our developed Proof of Concept demonstrates effectiveness in eliminating malicious nodes for six types of major attacks. Experimental results demonstrate that MRL-PoS+ significantly improves the attack resilience of PoS blockchains compared to the traditional schemes without incurring additional computation overhead.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards a Novel Privacy-Preserving Distributed Multiparty Data Outsourcing Scheme for Cloud Computing with Quantum Key Distribution</title>
<link>https://arxiv.org/abs/2407.18923</link>
<guid>https://arxiv.org/abs/2407.18923</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、云存储、区块链技术、零知识证明、CRYSTALS Kyber

<br /><br />
总结:本文探讨了云存储、区块链技术和即将到来的量子计算时代交汇点的数据安全问题。研究提出了一套综合框架，结合量子密钥分发(QKD)、基于晶格的CRYSTALS Kyber加密和零知识证明(ZKPs)，旨在增强基于云的区块链系统中的数据安全性，特别是针对量子威胁。QKD提供量子安全的加密协议以强化数据保护，CRYSTALS Kyber以其对抗量子攻击的能力为基础，而ZKPs则增强了数据隐私与验证过程的安全性。研究通过全面评估，包括加密解密过程、量子密钥生成速率和系统整体效率，来检验该框架的实际可行性和效率。分析考虑了文件大小、响应时间和计算开销等关键因素，以确保其在实际云环境中的可行性。研究结果提供了定制化的量子安全与ZKPs集成的全面安全框架，为寻求抵御量子威胁的组织提供了理论与实践指导，强调了框架在量子计算和区块链技术与云环境整合背景下的高效性和可扩展性。 <div>
arXiv:2407.18923v1 Announce Type: new 
Abstract: The intersection of cloud computing, blockchain technology, and the impending era of quantum computing presents a critical juncture for data security. This research addresses the escalating vulnerabilities by proposing a comprehensive framework that integrates Quantum Key Distribution (QKD), CRYSTALS Kyber, and Zero-Knowledge Proofs (ZKPs) for securing data in cloud-based blockchain systems. The primary objective is to fortify data against quantum threats through the implementation of QKD, a quantum-safe cryptographic protocol. We leverage the lattice-based cryptographic mechanism, CRYSTALS Kyber, known for its resilience against quantum attacks. Additionally, ZKPs are introduced to enhance data privacy and verification processes within the cloud and blockchain environment. A significant focus of this research is the performance evaluation of the proposed framework. Rigorous analyses encompass encryption and decryption processes, quantum key generation rates, and overall system efficiency. Practical implications are scrutinized, considering factors such as file size, response time, and computational overhead. The evaluation sheds light on the framework's viability in real-world cloud environments, emphasizing its efficiency in mitigating quantum threats. The findings contribute a robust quantum-safe and ZKP-integrated security framework tailored for cloud-based blockchain storage. By addressing critical gaps in theoretical advancements, this research offers practical insights for organizations seeking to secure their data against quantum threats. The framework's efficiency and scalability underscore its practical feasibility, serving as a guide for implementing enhanced data security in the evolving landscape of quantum computing and blockchain integration within cloud environments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards A Post-Quantum Cryptography in Blockchain I: Basic Review on Theoretical Cryptography and Quantum Information Theory</title>
<link>https://arxiv.org/abs/2407.18966</link>
<guid>https://arxiv.org/abs/2407.18966</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算机、传统加密区块链、后量子密码学、量子抵抗、市场上的加密货币

总结:
文章探讨了量子计算机的出现对传统加密区块链所引发的革命性挑战，特别是对于市场上大部分加密货币的安全威胁。量子计算机的计算能力超越了现有技术，使得现有的加密算法面临失效风险。因此，为了抵御量子攻击，实施后量子密码学（也称为量子抵抗密码学）以增强区块链的安全性变得迫在眉睫。后量子密码学旨在开发新的加密算法，这些算法在面对量子计算机时仍然保持安全有效。文章强调了这一转变的重要性，并指出这将是确保区块链在未来能够继续提供安全服务的关键步骤。同时，它也提醒市场上的加密货币需要迅速适应这一新技术带来的挑战，以保护用户的资产和交易安全。 <div>
arXiv:2407.18966v1 Announce Type: new 
Abstract: Recently, the invention of quantum computers was so revolutionary that they bring transformative challenges in a variety of fields, especially for the traditional cryptographic blockchain, and it may become a real thread for most of the cryptocurrencies in the market. That is, it becomes inevitable to consider to implement a post-quantum cryptography, which is also referred to as quantum-resistant cryptography, for attaining quantum resistance in blockchains.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Task Offloading in Fog Computing with Deep Reinforcement Learning: Future Research Directions Based on Security and Efficiency Enhancements</title>
<link>https://arxiv.org/abs/2407.19121</link>
<guid>https://arxiv.org/abs/2407.19121</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、雾计算、深度强化学习、区块链、人工智能

<br />
总结:
本文探讨了物联网设备和数据生成的激增对传统云计算的挑战，指出雾计算作为一种解决方案的重要性。雾计算通过将计算、存储和网络资源推向数据源附近，旨在满足即时性、服务质量以及位置相关服务的需求。文章进一步研究了深度强化学习在提升雾计算任务卸载过程中的应用潜力，旨在优化运行效率与增强安全性。通过回顾现有策略并提出未来研究方向，作者强调了深度强化学习在资源使用优化、响应加速及抵御漏洞方面的作用。此外，文章建议深入研究深度强化学习在雾计算中的应用，探索区块链技术以提高安全性，并寻求能源效率更高的模型以改善物联网生态系统。人工智能的应用显示出了在关键指标如任务完成时间、能源消耗和安全事件减少方面的潜在改进，为未来的研究和实践提供了坚实的基础。 <div>
arXiv:2407.19121v1 Announce Type: new 
Abstract: The surge in Internet of Things (IoT) devices and data generation highlights the limitations of traditional cloud computing in meeting demands for immediacy, Quality of Service, and location-aware services. Fog computing emerges as a solution, bringing computation, storage, and networking closer to data sources. This study explores the role of Deep Reinforcement Learning in enhancing fog computing's task offloading, aiming for operational efficiency and robust security. By reviewing current strategies and proposing future research directions, the paper shows the potential of Deep Reinforcement Learning in optimizing resource use, speeding up responses, and securing against vulnerabilities. It suggests advancing Deep Reinforcement Learning for fog computing, exploring blockchain for better security, and seeking energy-efficient models to improve the Internet of Things ecosystem. Incorporating artificial intelligence, our results indicate potential improvements in key metrics, such as task completion time, energy consumption, and security incident reduction. These findings provide a concrete foundation for future research and practical applications in optimizing fog computing architectures.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reducing Spurious Correlation for Federated Domain Generalization</title>
<link>https://arxiv.org/abs/2407.19174</link>
<guid>https://arxiv.org/abs/2407.19174</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedCD、Spurious Correlation Intervener、Risk Extrapolation Aggregation、Cross-Domain Invariant

<br />
总结:

本文提出了FedCD（跨域不变联邦学习）框架，旨在解决开放世界场景中全球模型在未见新领域数据上的预测问题。FedCD通过整体优化框架在局部和全局层面进行优化。其中，引入了Spurious Correlation Intervener（SCIntervener），利用不变性理论以自监督方式生成特征干预者，减少模型对误导性相关特征的依赖。这种方法仅需与模型相关的梯度信息，而无需共享数据或特征。此外，FedCD还开发了Risk Extrapolation Aggregation（REA）策略，通过数学优化确定聚合系数，促进全局因果不变预测。

实验结果显示，FedCD方法在分类和目标检测任务上的平均准确率分别提高了至少1.45%，mAP50分别提高了4.8%和1.27%，显著优于基线方法。这表明FedCD能够有效解决跨域数据分布差异带来的预测挑战，提高模型在未见过的新领域数据上的泛化能力。 <div>
arXiv:2407.19174v1 Announce Type: new 
Abstract: The rapid development of multimedia has provided a large amount of data with different distributions for visual tasks, forming different domains. Federated Learning (FL) can efficiently use this diverse data distributed on different client media in a decentralized manner through model sharing. However, in open-world scenarios, there is a challenge: global models may struggle to predict well on entirely new domain data captured by certain media, which were not encountered during training. Existing methods still rely on strong statistical correlations between samples and labels to address this issue, which can be misleading, as some features may establish spurious short-cut correlations with the predictions. To comprehensively address this challenge, we introduce FedCD (Cross-Domain Invariant Federated Learning), an overall optimization framework at both the local and global levels. We introduce the Spurious Correlation Intervener (SCI), which employs invariance theory to locally generate interventers for features in a self-supervised manner to reduce the model's susceptibility to spurious correlated features. Our approach requires no sharing of data or features, only the gradients related to the model. Additionally, we develop the simple yet effective Risk Extrapolation Aggregation strategy (REA), determining aggregation coefficients through mathematical optimization to facilitate global causal invariant predictions. Extensive experiments and ablation studies highlight the effectiveness of our approach. In both classification and object detection generalization tasks, our method outperforms the baselines by an average of at least 1.45% in Acc, 4.8% and 1.27% in mAP50.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Smart Contracts, Smarter Payments: Innovating Cross Border Payments and Reporting Transactions</title>
<link>https://arxiv.org/abs/2407.19283</link>
<guid>https://arxiv.org/abs/2407.19283</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、智能合约、ISO20022、跨境支付、去中心化金融

<br /><br />
总结:

本文提出了一种利用区块链技术和智能合约的创新框架，旨在模拟和优化跨境支付流程。该框架的核心贡献包括实现智能合约原型及其与Web客户端的集成，以促进高效、透明的交易流程。此外，还设计了ISO20022标准消息的翻译机制，确保合规性和国际标准兼容性。通过这一解决方案，可以提供安全、高效的跨境交易方式，为全球金融体系和新兴的去中心化金融领域带来显著改进。具体而言，该框架旨在解决传统银行系统在跨境支付中面临的安全隐患、低效率和透明度不足的问题，通过引入区块链技术，实现支付过程的去中心化，提高支付速度，降低交易成本，同时增强交易的可追溯性和安全性。 <div>
arXiv:2407.19283v1 Announce Type: new 
Abstract: The global financial landscape is experiencing significant transformation driven by technological advancements and evolving market dynamics. Moreover, blockchain technology has become a pivotal platform with widespread applications, especially in finance. Cross-border payments have emerged as a key area of interest, with blockchain offering inherent benefits such as enhanced security, transparency, and efficiency compared to traditional banking systems. This paper presents a novel framework leveraging blockchain technology and smart contracts to emulate cross-border payments, ensuring interoperability and compliance with international standards such as ISO20022. Key contributions of this paper include a novel prototype framework for implementing smart contracts and web clients for streamlined transactions and a mechanism to translate ISO20022 standard messages. Our framework can provide a practical solution for secure, efficient, and transparent cross-border transactions, contributing to the ongoing evolution of global finance and the emerging landscape of decentralized finance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reputation-Driven Asynchronous Federated Learning for Enhanced Trajectory Prediction with Blockchain</title>
<link>https://arxiv.org/abs/2407.19428</link>
<guid>https://arxiv.org/abs/2407.19428</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、区块链、自动驾驶、数据质量审计、图神经网络

总结:
本文提出了一种基于图神经网络工具的可解释性声誉量化机制的异步联邦学习数据共享方法，旨在解决自动驾驶应用中日益复杂和粒度化车辆生成数据带来的数据质量审计问题。该方法在差分隐私约束下允许数据提供者共享数据结构，既保证了数据安全又减少了冗余数据的传输。通过深度强化学习，车辆被分类为不同声誉等级，从而优化了联邦学习的数据聚合效率。实验结果表明，该数据共享方案不仅增强了轨迹预测任务的安全性，还提高了预测精度，有效缓解了多方信任缺失的问题，并通过减少重复数据传输来提升整体性能。 <div>
arXiv:2407.19428v1 Announce Type: new 
Abstract: Federated learning combined with blockchain empowers secure data sharing in autonomous driving applications. Nevertheless, with the increasing granularity and complexity of vehicle-generated data, the lack of data quality audits raises concerns about multi-party mistrust in trajectory prediction tasks. In response, this paper proposes an asynchronous federated learning data sharing method based on an interpretable reputation quantization mechanism utilizing graph neural network tools. Data providers share data structures under differential privacy constraints to ensure security while reducing redundant data. We implement deep reinforcement learning to categorize vehicles by reputation level, which optimizes the aggregation efficiency of federated learning. Experimental results demonstrate that the proposed data sharing scheme not only reinforces the security of the trajectory prediction task but also enhances prediction accuracy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Breaking the Balance of Power: Commitment Attacks on Ethereum's Reward Mechanism</title>
<link>https://arxiv.org/abs/2407.19479</link>
<guid>https://arxiv.org/abs/2407.19479</guid>
<content:encoded><![CDATA[
<div> 关键词：承诺攻击、LMD GHOST、MEV、奖励机制、链重组

总结:

本文针对以太坊等无许可大规模区块链中的验证者行为进行了深入分析。验证者通常追求最大收益和理性行动，以获取正当激励，如正确及时投票的奖励，以确保区块链的安全。然而，外部激励，如区块提议者的最大可提取价值（MEV），可能会诱使验证者偏离诚实的协议参与。

文章揭示了一系列针对LMD GHOST——以太坊共识机制核心部分的承诺攻击。通过操纵以太坊的投票奖励系统，单个敌对区块提议者能够策划长程链重组，利用可信威胁来迫使前几轮的投票者支持与诚实链相冲突的区块，从而实现零成本的链重组。这种行为破坏了提议者与投票者之间权力平衡的目的。

为应对这一问题，文章提出了一个新颖的奖励机制，旨在恢复投票者对提议者权力的制约作用。该机制不仅更公平、去中心化，而且在不考虑这些攻击的情况下，也具有实施于以太坊的可行性。通过这种机制，验证者能够在提议者权力过大的情况下，重新获得其应有的角色和影响力，从而保护区块链网络的稳定性和安全性。 <div>
arXiv:2407.19479v1 Announce Type: new 
Abstract: Validators in permissionless, large-scale blockchains (e.g., Ethereum) are typically payoff-maximizing, rational actors. Ethereum relies on in-protocol incentives, like rewards for validators delivering correct and timely votes, to induce honest behavior and secure the blockchain. However, external incentives, such as the block proposer's opportunity to capture maximal extractable value (MEV), may tempt validators to deviate from honest protocol participation.
  We show a series of commitment attacks on LMD GHOST, a core part of Ethereum's consensus mechanism. We demonstrate how a single adversarial block proposer can orchestrate long-range chain reorganizations by manipulating Ethereum's reward system for timely votes. These attacks disrupt the intended balance of power between proposers and voters: by leveraging credible threats, the adversarial proposer can coerce voters from previous slots into supporting blocks that conflict with the honest chain, enabling a chain reorganization at no cost to the adversary. In response, we introduce a novel reward mechanism that restores the voters' role as a check against proposer power. Our proposed mitigation is fairer and more decentralized -- not only in the context of these attacks -- but also practical for implementation in Ethereum.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Maximal Extractable Value Mitigation Approaches in Ethereum and Layer-2 Chains: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2407.19572</link>
<guid>https://arxiv.org/abs/2407.19572</guid>
<content:encoded><![CDATA[
<div> 关键词：Maximal Extractable Value（MEV）、Ethereum、Layer 1（L1）、Layer 2（L2）、Decentralized Finance（DeFi）

<br />
<br />总结:

本文是一篇关于以太坊生态系统中最大可提取价值(MEV)问题的全面综述。MEV是一个关键挑战，它影响着以太坊主链(L1)和第二层网络(L2)的公平性、安全性和效率。MEV现象发生在矿工或验证者通过操纵交易顺序来获取额外价值时，这种行为往往以牺牲其他网络参与者为代价。这不仅影响用户体验，增加不确定性并可能导致财务损失，还威胁到区块链的去中心化和信任原则。

文章首先界定了MEV的概念及其对以太坊生态系统的影响。接着，作者提出了针对L1和各种L2解决方案的MEV缓解技术的分类。这些策略包括但不限于交易排序、加密方法以及重新配置去中心化应用(DApps)以减少前端运行的机会。文章还探讨了这些策略的有效性、实施挑战以及对网络性能的影响。

最后，该文旨在为研究人员、开发者和政策制定者提供一个详细路线图，帮助他们理解并对抗不断演变的区块链景观中的MEV问题。通过综合当前研究、实际应用和新兴趋势，本文为解决这一重要问题提供了有价值的见解和策略。 <div>
arXiv:2407.19572v1 Announce Type: new 
Abstract: Maximal Extractable Value (MEV) represents a pivotal challenge within the Ethereum ecosystem; it impacts the fairness, security, and efficiency of both Layer 1 (L1) and Layer 2 (L2) networks. MEV arises when miners or validators manipulate transaction ordering to extract additional value, often at the expense of other network participants. This not only affects user experience by introducing unpredictability and potential financial losses but also threatens the underlying principles of decentralization and trust. Given the growing complexity of blockchain applications, particularly with the increase of Decentralized Finance (DeFi) protocols, addressing MEV is crucial. This paper presents a comprehensive survey of MEV mitigation techniques as applied to both Ethereums L1 and various L2 solutions. We provide a novel categorization of mitigation strategies; we also describe the challenges, ranging from transaction sequencing and cryptographic methods to reconfiguring decentralized applications (DApps) to reduce front-running opportunities. We investigate their effectiveness, implementation challenges, and impact on network performance. By synthesizing current research, real-world applications, and emerging trends, this paper aims to provide a detailed roadmap for researchers, developers, and policymakers to understand and combat MEV in an evolving blockchain landscape.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Passivity based Stability Assessment for Four types of Droops for DC Microgrids</title>
<link>https://arxiv.org/abs/2407.19573</link>
<guid>https://arxiv.org/abs/2407.19573</guid>
<content:encoded><![CDATA[
<div> 关键词：DC微电网、Droop控制、稳定性评估、低通滤波器、系统集成

总结:

本文聚焦于DC微电网领域，特别是针对基于升压转换器的微电网中的Droop控制策略。研究了四种不同类型的Droop控制方法在提供功率共享方面的性能，并通过过阻尼的概念进行了稳定性评估。为了确保转换器的稳定性，文中引入了低通滤波器（LPF）作为反馈环节的一部分。此外，通过推导网络阻抗来确保整个系统的过阻尼状态，从而减少保守性。

文章还提出了一个实用的设计方法，用于为这四种类型的Droop控制器构建一个被动控制器，并通过时间域模拟验证了该设计的有效性。所使用的模拟对象是一个由恒定功率负载（CPL）供电的单个升压转换器构成的微电网。

EN标准50388-2为铁路系统提供了稳定性的参考标准，旨在确保从转换器到系统集成的整体稳定性。通过这些分析和验证，文章为DC微电网的稳定运行和高效管理提供了重要的理论依据和实践指导。 <div>
arXiv:2407.19573v1 Announce Type: new 
Abstract: DC microgrids are getting more and more applications due to simple converters, only voltage control and higher efficiencies compared to conventional AC grids. Droop control is a well know decentralized control strategy for power sharing among converter interfaced sources and loads in a DC microgrid. This work compares the stability assessment and control of four types of droops for boost converters using the concept of passivity. EN standard 50388-2 for railway systems provides a reference to ensure system stability in perspectives of converters and system integration. Low pass filter (LPF) in the feedback of the droop control is used to ensure converter passivity. Bus impedance is derived to ensure system passivity with less conservativeness. Analytical approach for design of passive controller for all four types of droops is verified through time domain simulations of a single boost converter based microgrid feeding a Constant Power Load (CPL).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Segmented Private Data Aggregation in the Multi-message Shuffle Model</title>
<link>https://arxiv.org/abs/2407.19639</link>
<guid>https://arxiv.org/abs/2407.19639</guid>
<content:encoded><![CDATA[
<div> 关键词：多消息混合模型、隐私保护、数据聚合、精度、通信效率

总结:
本文提出了一种新型的隐私保护数据聚合框架——分割私有数据聚合，该框架基于多消息混合模型，旨在提供用户自定义的隐私保护级别，同时增强聚合服务器的数据处理能力。通过将用户的贡献分为多个“遮蔽”消息，既保护了数据安全，又防止了隐私选择泄露的风险。为优化隐私、效能和通信之间的平衡，研究探讨了最佳的遮蔽消息数量配置，并进行了精确的隐私放大分析。

实验结果显示，与现有方法相比，新框架在估计误差上降低了约50%，显著提高了隐私保护水平和数据聚合的准确性，同时减少了通信开销。这一创新不仅解决了保守用户参与度低的问题，也激励了积极用户贡献更多信息，从而提高了整体数据集的利用价值。 <div>
arXiv:2407.19639v1 Announce Type: new 
Abstract: The shuffle model of differential privacy (DP) offers compelling privacy-utility trade-offs in decentralized settings (e.g., internet of things, mobile edge networks). Particularly, the multi-message shuffle model, where each user may contribute multiple messages, has shown that accuracy can approach that of the central model of DP. However, existing studies typically assume a uniform privacy protection level for all users, which may deter conservative users from participating and prevent liberal users from contributing more information, thereby reducing the overall data utility, such as the accuracy of aggregated statistics. In this work, we pioneer the study of segmented private data aggregation within the multi-message shuffle model of DP, introducing flexible privacy protection for users and enhanced utility for the aggregation server. Our framework not only protects users' data but also anonymizes their privacy level choices to prevent potential data leakage from these choices. To optimize the privacy-utility-communication trade-offs, we explore approximately optimal configurations for the number of blanket messages and conduct almost tight privacy amplification analyses within the shuffle model. Through extensive experiments, we demonstrate that our segmented multi-message shuffle framework achieves a reduction of about 50\% in estimation error compared to existing approaches, significantly enhancing both privacy and utility.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Performance Optimization of High-Conflict Transactions within the Hyperledger Fabric Blockchain</title>
<link>https://arxiv.org/abs/2407.19732</link>
<guid>https://arxiv.org/abs/2407.19732</guid>
<content:encoded><![CDATA[
<div> 关键词：Hyperledger Fabric、冲突交易、多版本并发控制（MVCC）、通过量、延迟

总结:
本文探讨了Hyperledger Fabric（HLF）平台在处理大量冲突性交易时面临的挑战，这些挑战导致了吞吐量和延迟性能下降。为了解决这些问题，文章提出了一种创新方法，将多版本并发控制（MVCC）验证阶段提前到交易流程中，以便更早地识别冲突交易。此方法引入了两种改进方案：Orderer Early MVCC（OEMVCC）和带有执行避免的OEMVCC（OEMVCC-EA）。实验结果表明，这两种方法在高冲突应用中显著提高了通过量和降低了延迟，提供了一种实用的高性能和可扩展性解决方案。 <div>
arXiv:2407.19732v1 Announce Type: new 
Abstract: Hyperledger Fabric (HLF) is a secure and robust blockchain (BC) platform that supports high-throughput and low-latency transactions. However, it encounters challenges in managing conflicting transactions that negatively affect throughput and latency. This paper proposes a novel solution to address these challenges and improve performance, especially in applications incorporating extensive volumes of highly conflicting transactions. Our solution involves reallocating the Multi-Version Concurrency Control (MVCC) of the validation phase to a preceding stage in the transaction flow to enable early detection of conflicting transactions. Specifically, we propose and evaluate two innovative modifications, called Orderer Early MVCC (OEMVCC) and OEMVCC with Execution Avoidance (OEMVCC-EA). Our experimental evaluation results demonstrate significant throughput and latency improvements, providing a practical solution for high-conflict applications that demand high performance and scalability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference</title>
<link>https://arxiv.org/abs/2407.19775</link>
<guid>https://arxiv.org/abs/2407.19775</guid>
<content:encoded><![CDATA[
<div> 关键词：Nesa、模型分片、区块链、分布式计算、安全措施

总结:
文章主要介绍了名为Nesa的模型分片框架，旨在解决大型AI模型在数据隐私、计算资源和可访问性方面带来的挑战。Nesa利用基于区块链的深度神经网络分片技术，将计算任务分散到多样化的节点网络上，通过个性化启发式算法和路由机制进行任务分配，以实现对近期大型模型的高效分布式训练和推理，即使在消费级硬件上也能够做到。

为了减少数据传输和内存需求，Nesa采用了动态块量化和混合矩阵分解等压缩技术。同时，系统还集成了硬件可信执行环境等安全措施，确保数据完整性和机密性不受损害。通过在自然语言处理和视觉任务上的评估，证实了这些压缩策略并未牺牲模型的准确性。

总的来说，Nesa框架为实现AI技术的民主化提供了可能，通过构建一个去中心化的网络，不仅提高了模型的可访问性，还保证了安全性与效率。 <div>
arXiv:2407.19775v1 Announce Type: new 
Abstract: The rapid growth of large-scale AI models, particularly large language models has brought significant challenges in data privacy, computational resources, and accessibility. Traditional centralized architectures often struggle to meet required data security and scalability needs which hinders the democratization of AI systems. Nesa introduces a model-agnostic sharding framework designed for decentralized AI inference. Our framework uses blockchain-based sequential deep neural network sharding to distribute computational tasks across a diverse network of nodes based on a personalised heuristic and routing mechanism. This enables efficient distributed training and inference for recent large-scale models even on consumer-grade hardware. We use compression techniques like dynamic blockwise quantization and mixed matrix decomposition to reduce data transfer and memory needs. We also integrate robust security measures, including hardware-based trusted execution environments to ensure data integrity and confidentiality. Evaluating our system across various natural language processing and vision tasks shows that these compression strategies do not compromise model accuracy. Our results highlight the potential to democratize access to cutting-edge AI technologies by enabling secure and efficient inference on a decentralized network.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Before and After Blockchain: Development and Principle of Distributed Fault Tolerance Consensus</title>
<link>https://arxiv.org/abs/2407.19863</link>
<guid>https://arxiv.org/abs/2407.19863</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式共识、拜占庭将军问题、区块链技术、Proof-of-X、拜占庭容错

<br /><br />
总结:
本文主要探讨了分布式共识的概念及其发展历史，特别是自2009年区块链技术问世以来的演变。分布式共识的核心在于允许网络中的节点达成一致状态，而无需中央控制。文章首先回顾了“拜占庭将军问题”对这一领域的影响，并介绍了区块链技术中使用的两种主要方法：Proof-of-X（PoX）和拜占庭容错（BFT）系统。PoX方法如工作量证明（Proof-of-Work）因其资源密集性和高能耗而较少用于区块链，而BFT方法则成为大多数许可区块链实现一致性选择的首选。

文章进一步详细讨论了在部分同步网络中的状态机复制（SMR）的故障容忍协议，以及异步模型下的共识算法，还提到了基于有向无环图（DAG）的新型共识机制。此外，文章还探讨了BFT共识与区块链技术之间的关系，分析了BFT协议设计的原理及核心组件，并讨论了未来BFT研究的驱动需求。通过这些分析，文章为理解分布式系统中的共识机制提供了全面视角，强调了BFT在确保去中心化网络中数据一致性方面的重要性，以及其在区块链技术发展中的关键作用。 <div>
arXiv:2407.19863v1 Announce Type: new 
Abstract: The concept of distributed consensus gained widespread attention following the publication of ``Byzantine Generals Problem'' by Leslie Lamport in the 1980s. This research topic has been active and extensively studied over the last four decades, particularly since the advent of blockchain technology in 2009. Blockchain technology employs Proof-of-X (PoX) or Byzantine-fault-tolerant (BFT) systems, where all participants follow a protocol to achieve a common state (i.e., consistency) eventually. However, because PoX consensus such as Proof-of-Work is is resource-intensive with high power consumption, most permissioned blockchains employ BFT to achieve consistency. In this article, we provide an introduction to the fundamental principles and history of distributed consensus. We then explore the well-known fault-tolerant state machine replication (SMR) in partially synchronous networks, as well as consensus protocols in asynchronous models and recently proposed DAG-based consensus. Additionally, we examine the relationship between BFT consensus and blockchain technology and discuss the following questions: What is the history and evolution of BFT? Why are BFT protocols designed in the way they are and what core components do they use? What is the connection between BFT and blockchain technology, and what are the driving needs for future BFT research?
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Prichain II: CloudGuardian Cloud Security Proposal with Blockchain</title>
<link>https://arxiv.org/abs/2407.19961</link>
<guid>https://arxiv.org/abs/2407.19961</guid>
<content:encoded><![CDATA[
<div> 关键词：云存储、数据安全、区块链技术、Ethereum网络、PostgreSQL数据库

总结:
本文主要探讨了在云环境下，随着云计算、数据存储和安全需求的不断增长，数据的隐私和所有权保护变得尤为重要。从2022年到2023年，云安全威胁增加了约48%，这凸显了迫切需要强大的安全解决方案。为了应对这些挑战，文章提出了一种创新方案，即结合Ethereum网络的区块链技术和位于云中的PostgreSQL数据库。

首先，区块链技术确保了交易的不可篡改性和透明性，为数据提供了一层坚实的保护。同时，PostgreSQL数据库因其高效性和可扩展性，为数据提供了可靠存储环境。通过在动态交通控制场景下进行严格测试，研究结果表明，该解决方案能够提供极高的安全性，得益于数据的去中心化特性。

此外，文章强调了区块链与云关系型数据库的集成不仅增强了信息安全性，还展示了其在实际应用中的可行性。这种双向对齐的方法显著提高了对网络攻击的防护能力，确保用户数据免受未经授权的访问和恶意修改。

综上所述，本文提出的解决方案不仅提升了云环境下的数据安全水平，也证明了区块链技术与传统数据库系统结合的潜力，为云计算领域的安全防护提供了新的思路和实践路径。 <div>
arXiv:2407.19961v1 Announce Type: new 
Abstract: With the advancement of cloud computing, data storage, and security have become crucial. The growing adoption of cloud services by companies, accompanied by increased threats from cybersecurity, highlights the importance of privacy and ownership of user data. Between 2022 and 2023, there has been an increase of around 48% in cloud security threats, emphasizing the urgent need for strong security solutions. To face these challenges, in this project, we propose integrating the Ethereum network's blockchain technology with a database located in the PostgreSQL cloud. The proposed solution aims to provide bidirectional data synchronization and strict control of access mechanisms. Blockchain technology ensures immutability and transparency of transactions, while PostgreSQL provides efficient and scalable storage. Through rigorous testing in an adaptive traffic control scenario, the results obtained indicate that this solution offers a significantly high level of security due to the decentralization of data, confirming that this solution is effective, and making it a powerful new option to improve security in cloud environments. In conclusion, the solution proposed in this project not only increases information security but also demonstrates the practical feasibility of integrating blockchain with cloud relational databases. This two-way alignment improves protection against cyberattacks and ensures that user data is protected from unauthorized access and malicious changes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain for Large Language Model Security and Safety: A Holistic Survey</title>
<link>https://arxiv.org/abs/2407.20181</link>
<guid>https://arxiv.org/abs/2407.20181</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、区块链、数据安全、攻击防御、研究综述

文章主要探讨了大型语言模型（LLMs）在商业和学术领域的兴起及其带来的新型攻击风险，以及区块链技术在此背景下作为数据保护手段的潜力。文章提出了区块链为大型语言模型（BC4LLM）的分类体系，详细定义了相关研究领域，并构建了研究框架，旨在全面评估区块链在保护LLMs免受漏洞侵害方面的应用，并探索其在新应用场景中的可能性。同时，文章指出了未来研究目标和面临的挑战。

总结:
本文首先指出大型语言模型（LLMs）的广泛应用导致了对其安全性需求的增加。随后，文章介绍了区块链技术作为一种新兴的数据保护手段，能够提供数据不可变性和可追溯性，从而帮助防御针对LLMs的攻击。接着，文章提出了一种BC4LLM的分类体系，对现有研究进行了系统梳理，并定义了不同研究领域的具体概念。此外，文章还构建了研究框架，为更深入的研究提供了结构化指导。最后，文章明确了未来研究的方向，包括进一步探索区块链在LLMs安全领域的应用潜力，以及解决当前面临的技术和实践挑战。 <div>
arXiv:2407.20181v1 Announce Type: new 
Abstract: With the advent of accessible interfaces for interacting with large language models, there has been an associated explosion in both their commercial and academic interest. Consequently, there has also been an sudden burst of novel attacks associated with large language models, jeopardizing user data on a massive scale. Situated at a comparable crossroads in its development, and equally prolific to LLMs in its rampant growth, blockchain has emerged in recent years as a disruptive technology with the potential to redefine how we approach data handling. In particular, and due to its strong guarantees about data immutability and irrefutability as well as inherent data provenance assurances, blockchain has attracted significant attention as a means to better defend against the array of attacks affecting LLMs and further improve the quality of their responses. In this survey, we holistically evaluate current research on how blockchains are being used to help protect against LLM vulnerabilities, as well as analyze how they may further be used in novel applications. To better serve these ends, we introduce a taxonomy of blockchain for large language models (BC4LLM) and also develop various definitions to precisely capture the nature of different bodies of research in these areas. Moreover, throughout the paper, we present frameworks to contextualize broader research efforts, and in order to motivate the field further, we identify future research goals as well as challenges present in the blockchain for large language model (BC4LLM) space.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy Amplification via Shuffling: Unified, Simplified, and Tightened</title>
<link>https://arxiv.org/abs/2304.05007</link>
<guid>https://arxiv.org/abs/2304.05007</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私、混合模型、隐私放大、总变异性减少、平行组成

总结:
本文提出了一种名为“总变异性减少”的全面框架，用于在单消息和多消息混合协议中进行隐私放大。该框架利用了本地消息的总变异性边界和毯子消息的概率比率边界两个新的参数化来确定不可区分性水平。理论结果表明，我们的框架提供了更紧的边界，特别是对于具有极端概率设计的本地随机化器，其中我们的边界恰好是紧的。此外，总变异性减少补充了混合模型中的并行组成，为统计查询（如范围查询、边缘查询和频繁项集挖掘）中常用的基于采样的随机化器提供了增强的隐私计数。实验发现，我们的数值放大边界超过了现有的边界，对于单消息协议保守高达30%的预算，对于多消息协议保守高达75%，并且对于并行组成保守高达75%-95%的预算。我们的边界还导致了一个非常高效的$\tilde{O}(n)$算法，在不到10秒的时间内为n=10^8用户实现了隐私的数值放大。

通过使用总变异性减少框架，文章解决了当前分析在分布式、隐私保护数据分析中关于隐私-效用平衡的挑战，提供了更紧、更通用的隐私放大边界。该框架不仅提高了对于特定类型随机化器的隐私保护效率，而且通过与并行组成的结合，进一步优化了隐私会计，使得在大规模数据集上进行隐私保护的数据分析成为可能。实验结果验证了理论分析的有效性和实用性，显示了在不同场景下显著提升的预算保守率。 <div>
arXiv:2304.05007v5 Announce Type: replace 
Abstract: The shuffle model of differential privacy provides promising privacy-utility balances in decentralized, privacy-preserving data analysis. However, the current analyses of privacy amplification via shuffling lack both tightness and generality. To address this issue, we propose the \emph{variation-ratio reduction} as a comprehensive framework for privacy amplification in both single-message and multi-message shuffle protocols. It leverages two new parameterizations: the total variation bounds of local messages and the probability ratio bounds of blanket messages, to determine indistinguishability levels. Our theoretical results demonstrate that our framework provides tighter bounds, especially for local randomizers with extremal probability design, where our bounds are exactly tight. Additionally, variation-ratio reduction complements parallel composition in the shuffle model, yielding enhanced privacy accounting for popular sampling-based randomizers employed in statistical queries (e.g., range queries, marginal queries, and frequent itemset mining). Empirical findings demonstrate that our numerical amplification bounds surpass existing ones, conserving up to $30\%$ of the budget for single-message protocols, $75\%$ for multi-message ones, and a striking $75\%$-$95\%$ for parallel composition. Our bounds also result in a remarkably efficient $\tilde{O}(n)$ algorithm that numerically amplifies privacy in less than $10$ seconds for $n=10^8$ users.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Security Analysis of Smart Contract Migration from Ethereum to Arbitrum</title>
<link>https://arxiv.org/abs/2307.14773</link>
<guid>https://arxiv.org/abs/2307.14773</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链平台迁移、安全风险、Arbitrum、Ethereum

总结:

本文主要探讨了将智能合约从以太坊（Ethereum）迁移到Arbitrum时所面临的安全风险。研究通过收集相关数据和分析智能合约迁移案例，深入探究了两个平台在跨链消息传输、区块属性、合约地址别名以及交易手续费等方面的差异。

关键发现包括：
1. **跨链消息传输**：Arbitrum与以太坊之间存在不同的消息传递机制，这可能导致在迁移过程中出现信息不一致或延迟的问题。
2. **区块属性**：两个平台的区块结构和特性不同，这可能影响智能合约的执行逻辑和效率。
3. **合约地址别名**：在迁移过程中，合约地址的别名处理不当可能会引发安全漏洞。
4. **交易费用**：Arbitrum与以太坊的Gas费用模型存在差异，这可能影响合约的经济性和安全性。
5. **公共区块链特性**：如数据获取的时效性问题、基于时间的逻辑错误、权限检查失败及分布式拒绝服务（DOS）攻击等安全风险。

研究提出了相应的规避方法，并为用户和开发者提供了安全迁移的指导，确保智能合约在迁移过程中的安全性。这是首次对从以太坊到Arbitrum的智能合约安全迁移进行深度分析的研究，对于促进跨平台智能合约迁移具有重要价值。 <div>
arXiv:2307.14773v3 Announce Type: replace 
Abstract: When migrating smart contracts from one blockchain platform to another, there are potential security risks. This is because different blockchain platforms have different environments and characteristics for executing smart contracts. The focus of this paper is to study the security risks associated with the migration of smart contracts from Ethereum to Arbitrum. We collected relevant data and analyzed smart contract migration cases to explore the differences between Ethereum and Arbitrum in areas such as Arbitrum cross-chain messaging, block properties, contract address alias, and gas fees. From the 36 types of smart contract migration cases we identified, we selected 4 typical types of cases and summarized their security risks. The research shows that smart contracts deployed on Ethereum may face certain potential security risks during migration to Arbitrum, mainly due to issues inherent in public blockchain characteristics, such as outdated off-chain data obtained by the inactive sequencer, logic errors based on time, the permission check failed, Denial of Service(DOS) attacks. To mitigate these security risks, we proposed avoidance methods and provided considerations for users and developers to ensure a secure migration process. It's worth noting that this study is the first to conduct an in-depth analysis of the secure migration of smart contracts from Ethereum to Arbitrum.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Democratization of Wealth Management: Hedged Mutual Fund Blockchain Protocol</title>
<link>https://arxiv.org/abs/2405.02302</link>
<guid>https://arxiv.org/abs/2405.02302</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、投资基金、传统金融、操作问题、智能合约

总结:

本文旨在将传统投资基金的最佳实践引入区块链领域，解决传统金融面临的一系列操作问题。通过四个关键创新点，文章详细阐述了如何利用区块链技术及传统财富管理策略，提升区块链投资基金的运作效率与安全性：

1. **定期更新基金价格**：借鉴传统基金的做法，实现基金价格的实时更新，为投资者提供透明、准确的价格信息。

2. **实施绩效收费机制**：类似于对冲基金的模式，引入绩效费用，确保基金管理人与投资者利益一致，促进长期稳定增长。

3. **引入保护机制**：通过设置“水位线”等投资者保护方案，确保在市场波动中投资者权益得到保障，增强信任度和吸引力。

4. **应对交易相关滑点成本**：提出策略以抵消赎回时可能产生的交易滑点成本，提高基金运营的效率与成本效益。

5. **优化智能合约设计**：通过提供详细的实施步骤、数学公式和指导性说明，克服区块链技术瓶颈，使智能合约更加高效、智能，从而加速区块链在传统金融领域的应用与普及。

综上所述，本文不仅揭示了区块链与传统金融结合的潜力，还提供了具体的实施方案，旨在推动区块链技术在财富管理领域的深入应用，同时解决传统基金面临的操作难题，促进金融行业的创新与发展。 <div>
arXiv:2405.02302v2 Announce Type: replace 
Abstract: We develop several innovations to bring the best practices of traditional investment funds to the blockchain landscape. Specifically, we illustrate how: 1) fund prices can be updated regularly like mutual funds; 2) performance fees can be charged like hedge funds; 3) mutually hedged blockchain investment funds can operate with investor protection schemes, such as high water marks; and 4) measures to offset trading related slippage costs when redemptions happen. Using our concepts - and blockchain technology - traditional funds can calculate performance fees in a simplified manner and alleviate several operational issues. Blockchain can solve many problems for traditional finance, while tried and tested wealth management techniques can benefit decentralization, speeding its adoption. We provide detailed steps - including mathematical formulations and instructive pointers - to implement these ideas and discuss how our designs overcome several blockchain bottlenecks, making smart contracts smarter. We provide numerical illustrations of several scenarios related to our mechanisms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fantastyc: Blockchain-based Federated Learning Made Secure and Practical</title>
<link>https://arxiv.org/abs/2406.03608</link>
<guid>https://arxiv.org/abs/2406.03608</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、区块链、完整性、机密性、可扩展性

总结:

本文提出了一种名为Fantastyc的解决方案，旨在解决当前联邦学习领域中尚未被同时满足的挑战，包括完整性、机密性、可扩展性。联邦学习作为一种分散化的框架，允许多个客户端在中央服务器的协调下共同训练机器学习模型，而无需共享本地数据。然而，这种框架的中心化特性构成了潜在的失败点，这在文献中得到了关注，并通过基于区块链的联邦学习方法进行了探讨。尽管区块链方法提供了全面去中心化的解决方案和可追溯性，它们仍然面临着关于完整性和保密性的实际部署挑战以及可扩展性问题。

Fantastyc解决方案的提出旨在克服这些局限性，通过集成区块链技术来确保数据的完整性和机密性，同时优化系统以提高可扩展性。这一创新的综合方法不仅提高了系统的安全性，还增强了其实用性，使其在实际应用中更具可行性。通过结合联邦学习的高效协同与区块链的分布式信任机制，Fantastyc为构建更安全、可靠且可扩展的机器学习生态系统提供了一种有前景的途径。 <div>
arXiv:2406.03608v2 Announce Type: replace 
Abstract: Federated Learning is a decentralized framework that enables multiple clients to collaboratively train a machine learning model under the orchestration of a central server without sharing their local data. The centrality of this framework represents a point of failure which is addressed in literature by blockchain-based federated learning approaches. While ensuring a fully-decentralized solution with traceability, such approaches still face several challenges about integrity, confidentiality and scalability to be practically deployed. In this paper, we propose Fantastyc, a solution designed to address these challenges that have been never met together in the state of the art.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future</title>
<link>https://arxiv.org/abs/2407.18358</link>
<guid>https://arxiv.org/abs/2407.18358</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、生成式人工智能、隐私保护、数据效率、模型性能

总结:
本文探讨了生成式人工智能在联邦学习中的应用潜力，旨在提升隐私保护、数据利用效率与模型性能。联邦学习作为分布式机器学习的一种方法，允许多个参与方在不共享原始数据的情况下协同训练模型，这为保护用户数据隐私提供了可能。引入生成式人工智能（如生成对抗网络GAN和变分自编码器VAE）后，研究发现可以通过生成与真实数据分布相匹配的合成数据来解决数据量不足的问题，从而增强模型的泛化能力。

此外，生成式AI在联邦学习中的应用还能够实现更个性化的解决方案，通过定制化模型来满足不同用户群体的需求。例如，通过生成特定领域的合成数据，可以为特定行业或特定用户群提供更加精准的服务。同时，生成的数据集还可以用于增强模型训练，提高模型性能，尤其是在数据稀疏或难以获取的真实数据集上。

总的来说，生成式人工智能与联邦学习的结合不仅能够促进数据隐私的保护，还能有效提升数据效率和模型性能，为构建更加个性化和高效的人工智能系统提供了新的路径。 <div>
arXiv:2407.18358v1 Announce Type: new 
Abstract: Federated learning has become a significant approach for training machine learning models using decentralized data without necessitating the sharing of this data. Recently, the incorporation of generative artificial intelligence (AI) methods has provided new possibilities for improving privacy, augmenting data, and customizing models. This research explores potential integrations of generative AI in federated learning, revealing various opportunities to enhance privacy, data efficiency, and model performance. It particularly emphasizes the importance of generative models like generative adversarial networks (GANs) and variational autoencoders (VAEs) in creating synthetic data that replicates the distribution of real data. Generating synthetic data helps federated learning address challenges related to limited data availability and supports robust model development. Additionally, we examine various applications of generative AI in federated learning that enable more personalized solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mini-Batch Gradient-Based MCMC for Decentralized Massive MIMO Detection</title>
<link>https://arxiv.org/abs/2407.18489</link>
<guid>https://arxiv.org/abs/2407.18489</guid>
<content:encoded><![CDATA[
<div> 关键词：MIMO、分散式基带处理、渐变式马尔可夫链蒙特卡洛方法、迷你批次随机梯度下降、性能增益

总结:
本文探讨了在大规模MIMO系统中采用分布式基带处理架构的可能性，以解决集中式处理所面临的计算复杂性和大量基带数据交换的问题。通过将天线阵列划分为多个处理单元，每个单元配备专用计算硬件进行并行处理，实现了计算负担的分散化。同时，结合渐变式马尔可夫链蒙特卡洛检测方法和迷你批次随机梯度下降算法，该研究提出了一种高效且性能优越的分布式检测器。仿真结果表明，与现有分布式检测器相比，新提出的检测器在多种场景下均表现出显著的性能提升。此外，复杂性分析显示，与传统的集中式检测器相比，提出的分布式策略在计算延迟和互联带宽方面具有明显优势。这一研究为大规模MIMO系统的实际应用提供了有效的解决方案，有望推动通信技术向更高性能、更高效的方向发展。 <div>
arXiv:2407.18489v1 Announce Type: new 
Abstract: Massive multiple-input multiple-output (MIMO) technology has significantly enhanced spectral and power efficiency in cellular communications and is expected to further evolve towards extra-large-scale MIMO. However, centralized processing for massive MIMO faces practical obstacles, including excessive computational complexity and a substantial volume of baseband data to be exchanged. To address these challenges, decentralized baseband processing has emerged as a promising solution. This approach involves partitioning the antenna array into clusters with dedicated computing hardware for parallel processing. In this paper, we investigate the gradient-based Markov chain Monte Carlo (MCMC) method -- an advanced MIMO detection technique known for its near-optimal performance in centralized implementation -- within the context of a decentralized baseband processing architecture. This decentralized design mitigates the computation burden at a single processing unit by utilizing computational resources in a distributed and parallel manner. Additionally, we integrate the mini-batch stochastic gradient descent method into the proposed decentralized detector, achieving remarkable performance with high efficiency. Simulation results demonstrate substantial performance gains of the proposed method over existing decentralized detectors across various scenarios. Moreover, complexity analysis reveals the advantages of the proposed decentralized strategy in terms of computation delay and interconnection bandwidth when compared to conventional centralized detectors.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Signalling and Control in Nonlinear Stochastic Systems: An Information State Approach with Applications</title>
<link>https://arxiv.org/abs/2407.18588</link>
<guid>https://arxiv.org/abs/2407.18588</guid>
<content:encoded><![CDATA[
<div> 关键词：信息理论优化、随机控制编码容量、非线性滤波、线性二次高斯系统、分离原理

<br /><br />
总结:

本文研究了离散时间非线性部分可观测随机系统的最优信号处理与控制问题。主要贡献如下：

1. **控制编码容量的定义与分析**：文章首先通过信息理论优化问题，定义并分析了控制编码容量$C_{FB}$，该容量衡量了在给定信道下，以最小化解码错误概率为条件，控制器和编码器策略能够传输的信息速率。

2. **随机策略与信息状态**：利用非线性滤波理论中的信息状态概念，分析了随机策略下的信号编码与解码过程。策略被表示为基于非均匀或任意分布的随机变量的实现，这些变量用于生成和恢复消息。

3. **线性二次高斯部分观测系统（LQG-POSS）的分析**：针对特定的LQG-POSS模型，文章展示了同时进行信号传递与控制的随机策略可以简化为仅依赖于有限维的充分统计量。这些统计量涉及两个卡尔曼滤波器，用于控制、估计和信号处理。

4. **分离原理与控制矩阵差分算子方程**：应用分散优化技术证明了分离原理，即信号处理和控制可以独立优化。进一步推导出控制部分的最优随机策略，其形式为控制矩阵差分算子方程（DRE）的解。

5. **结论**：综上所述，文章为非线性部分观测随机系统的信号处理与控制提供了理论基础与优化方法，特别是在LQG-POSS框架下，展示了如何通过信息理论工具解决复杂系统控制问题。 <div>
arXiv:2407.18588v1 Announce Type: new 
Abstract: We consider optimal signalling and control of discrete-time nonlinear partially observable stochastic systems in state space form. In the first part of the paper, we characterize the operational {\it control-coding capacity}, $C_{FB}$ in bits/second, by an information theoretic optimization problem of encoding signals or messages into randomized controller-encoder strategies, and reproducing the messages at the output of the system using a decoder or estimator with arbitrary small asymptotic error probability. Our analysis of $C_{FB}$ is based on realizations of randomized strategies (controller-encoders), in terms of information states of nonlinear filtering theory, and either uniform or arbitrary distributed random variables (RVs). In the second part of the paper, we analyze the linear-quadratic Gaussian partially observable stochastic system (LQG-POSS). We show that simultaneous signalling and control leads to randomized strategies described by finite-dimensional sufficient statistics, that involve two Kalman-filters, and consist of control, estimation and signalling strategies. We apply decentralized optimization techniques to prove a separation principle, and to derive the optimal control part of randomized strategies explicitly in terms of a control matrix difference Riccati equation (DRE).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulnerability Detection in Ethereum Smart Contracts via Machine Learning: A Qualitative Analysis</title>
<link>https://arxiv.org/abs/2407.18639</link>
<guid>https://arxiv.org/abs/2407.18639</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、安全漏洞检测、机器学习、区块链技术、风险评估

总结:
本文是对当前基于机器学习的以太坊智能合约安全漏洞检测方法的全面分析。文章首先概述了智能合约在区块链应用中的重要性以及它们面临的挑战，尤其是安全漏洞可能导致的经济损失。接下来，文章深入探讨了现有工具和方法的局限性，包括静态分析和机器学习两种主要策略的不足之处。这些局限性主要体现在覆盖范围有限、数据集构建问题等方面。

文章进一步提出了改进智能合约安全漏洞检测的方法和最佳实践，旨在提升检测的准确性和范围，同时提高效率。这些建议不仅解决了已知的问题，也为未来的研究和开发指明了方向。通过识别当前的挑战并提出创新解决方案，本文对智能合约的安全性、区块链技术的整体发展以及智能合约的可靠应用做出了贡献。

文章最后强调，通过增强安全漏洞检测能力，可以显著提升智能合约和整个区块链生态系统的技术安全性，为未来的区块链应用提供更可靠的基础。 <div>
arXiv:2407.18639v1 Announce Type: new 
Abstract: Smart contracts are central to a myriad of critical blockchain applications, from financial transactions to supply chain management. However, their adoption is hindered by security vulnerabilities that can result in significant financial losses. Most vulnerability detection tools and methods available nowadays leverage either static analysis methods or machine learning. Unfortunately, as valuable as they are, both approaches suffer from limitations that make them only partially effective. In this survey, we analyze the state of the art in machine-learning vulnerability detection for Ethereum smart contracts, by categorizing existing tools and methodologies, evaluating them, and highlighting their limitations. Our critical assessment unveils issues such as restricted vulnerability coverage and dataset construction flaws, providing us with new metrics to overcome the difficulties that restrain a sound comparison of existing solutions. Driven by our findings, we discuss best practices to enhance the accuracy, scope, and efficiency of vulnerability detection in smart contracts. Our guidelines address the known flaws while at the same time opening new avenues for research and development. By shedding light on current challenges and offering novel directions for improvement, we contribute to the advancement of secure smart contract development and blockchain technology as a whole.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Public Dataset For the ZKsync Rollup</title>
<link>https://arxiv.org/abs/2407.18699</link>
<guid>https://arxiv.org/abs/2407.18699</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链数据、ZKsync、数据集、分析代码、开放获取

总结:
本文报告了一项旨在解决区块链数据使用障碍的研究工作。面对公开但难以有效利用的区块链数据，特别是Layer 2（L2）生态系统中如ZKsync的数据，研究团队通过收集并整理了来自ZKsync Era归档节点的一年活动数据，形成了一个可自由获取的数据集。这一数据集的创建和可用性，旨在促进区块链领域的数据驱动型研究与探索。

文章详细介绍了数据集的构建过程，包括数据来源、处理方法和结构特点。同时，展示了几个基于该数据集的示例分析案例，这些案例不仅体现了数据集的丰富性和实用性，也为后续研究提供了方向。为了推动研究的透明度和可重复性，研究团队还公开分享了用于分析的数据处理代码，鼓励其他研究人员利用这些资源进行更深入的探索。

通过这一举措，研究团队不仅为区块链领域的数据研究者提供了宝贵的资源，还促进了社区内的知识共享和技术创新，有望加速区块链技术的发展和应用。 <div>
arXiv:2407.18699v1 Announce Type: new 
Abstract: Despite blockchain data being publicly available, practical challenges and high costs often hinder its effective use by researchers, thus limiting data-driven research and exploration in the blockchain space. This is especially true when it comes to Layer~2 (L2) ecosystems, and ZKsync, in particular. To address these issues, we have curated a dataset from 1 year of activity extracted from a ZKsync Era archive node and made it freely available to external parties. In this paper, we provide details on this dataset and how it was created, showcase a few example analyses that can be performed with it, and discuss some future research directions. We also publish and share the code used in our analysis on GitHub to promote reproducibility and to support further research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit</title>
<link>https://arxiv.org/abs/2402.04417</link>
<guid>https://arxiv.org/abs/2402.04417</guid>
<content:encoded><![CDATA[
<div> 关键词：多臂老虎机问题、区块链、协调机制、恶意参与者、最优策略

总结:
本文研究了在存在恶意参与者的分布式区块链环境中，多代理多臂老虎机问题的鲁棒性。多个参与者在完全去中心化的区块链上分布，其中一些可能是恶意的。奖励具有时间不变的随机分布，仅在满足一定条件后向诚实参与者揭示，以确保协调机制的安全性。目标是通过高效协调，最大化诚实参与者获得的累积奖励。

为了实现这一目标，文章首次将区块链技术与新型机制融入合作决策框架中，设计了适合诚实参与者的最优策略。该框架允许各种恶意行为，并维持了安全性和参与者隐私。具体措施包括选择验证者池，为验证者设计基于数字签名的共识机制，发明一种基于UCB算法的策略，通过安全多方计算减少参与者的信息需求，并设计链-参与者交互和激励机制鼓励参与。

文章首次证明了所提出算法的理论遗憾并声称其最优性。与现有工作侧重于通过计算实验展示区块链与学习问题（如联邦学习）集成的优化性不同，本文展示了在满足某些假设的情况下，诚实参与者的遗憾上限为$log{T}$。这一结果与没有恶意参与者的情况以及纯拜占庭攻击下（不破坏整个系统）的多代理多臂老虎机问题保持一致。 <div>
arXiv:2402.04417v2 Announce Type: replace 
Abstract: We study a robust, i.e. in presence of malicious participants, multi-agent multi-armed bandit problem where multiple participants are distributed on a fully decentralized blockchain, with the possibility of some being malicious. The rewards of arms are homogeneous among the honest participants, following time-invariant stochastic distributions, which are revealed to the participants only when certain conditions are met to ensure that the coordination mechanism is secure enough. The coordination mechanism's objective is to efficiently ensure the cumulative rewards gained by the honest participants are maximized. To this end, we are the first to incorporate advanced techniques from blockchains, as well as novel mechanisms, into such a cooperative decision making framework to design optimal strategies for honest participants. This framework allows various malicious behaviors and the maintenance of security and participant privacy. More specifically, we select a pool of validators who communicate to all participants, design a new consensus mechanism based on digital signatures for these validators, invent a UCB-based strategy that requires less information from participants through secure multi-party computation, and design the chain-participant interaction and an incentive mechanism to encourage participants' participation. Notably, we are the first to prove the theoretical regret of the proposed algorithm and claim its optimality. Unlike existing work that integrates blockchains with learning problems such as federated learning which mainly focuses on optimality via computational experiments, we demonstrate that the regret of honest participants is upper bounded by $\log{T}$ under certain assumptions. The regret bound is consistent with the multi-agent multi-armed bandit problem, both without malicious participants and with purely Byzantine attacks which do not affect the entire system.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Frosty: Bringing strong liveness guarantees to the Snow family of consensus protocols</title>
<link>https://arxiv.org/abs/2404.14250</link>
<guid>https://arxiv.org/abs/2404.14250</guid>
<content:encoded><![CDATA[
<div> 关键词：雪人协议、Avalanche区块链、正式一致性证明、活锁攻击、容错机制

总结:

本文聚焦于雪人协议（Snowman），它是Avalanche区块链中的共识算法，属于雪家族协议。雪人协议的主要优势在于其在普通情况下，即非严重拜占庭攻击条件下，每个共识决策的预期通信开销与处理器数量n无关，这为共识协议提供了一个关键特性，使其能够适应高达10,000或更多的独立验证器。然而，该协议仍存在两个主要问题：

1. **正式一致性证明**：提供雪人协议的一致性证明一直是一个挑战。
   
2. **活锁攻击**：当拜占庭对手控制超过$\sqrt{n}$数量级的处理器时，会引发活锁攻击，导致协议终止时间超过对数级别。

针对上述问题，文章提出以下解决方案：

- **一致性的证明**：通过简化方法提供了雪人协议的正式一致性证明。
  
- **活锁模块**：引入了活锁模块，当严重攻击发生时可以激活，以保证在这一特殊情况下协议的活锁性，同时确保协议在正常运行时不牺牲其低通信复杂度优势。

综上所述，本文旨在解决雪人协议面临的关键问题，通过提供一致性的正式证明和活锁模块的引入，增强了协议的安全性和鲁棒性，特别是针对拜占庭攻击的情况。 <div>
arXiv:2404.14250v4 Announce Type: replace 
Abstract: Snowman is the consensus protocol implemented by the Avalanche blockchain and is part of the Snow family of protocols, first introduced through the original Avalanche leaderless consensus protocol. A major advantage of Snowman is that each consensus decision only requires an expected constant communication overhead per processor in the `common' case that the protocol is not under substantial Byzantine attack, i.e. it provides a solution to the scalability problem which ensures that the expected communication overhead per processor is independent of the total number of processors $n$ during normal operation. This is the key property that would enable a consensus protocol to scale to 10,000 or more independent validators (i.e. processors). On the other hand, the two following concerns have remained:
  (1) Providing formal proofs of consistency for Snowman has presented a formidable challenge.
  (2) Liveness attacks exist in the case that a Byzantine adversary controls more than $O(\sqrt{n})$ processors, slowing termination to more than a logarithmic number of steps.
  In this paper, we address the two issues above. We consider a Byzantine adversary that controls at most $f<n/5$ processors. First, we provide a simple proof of consistency for Snowman. Then we supplement Snowman with a `liveness module' that can be triggered in the case that a substantial adversary launches a liveness attack, and which guarantees liveness in this event by temporarily forgoing the communication complexity advantages of Snowman, but without sacrificing these low communication complexity advantages during normal operation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SOK: Blockchain for Provenance</title>
<link>https://arxiv.org/abs/2407.17699</link>
<guid>https://arxiv.org/abs/2407.17699</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据证明、挑战、未来研究方向、设计考虑

总结:

本文聚焦于区块链技术在数据证明领域的应用，提出了三个关键的研究问题以全面探讨这一领域的问题与需求。首先，文章探讨了在非协作、单一来源环境中的挑战，强调了在确保数据完整性、可靠性和可信度方面的重要性。其次，它深入分析了在协作环境中，尤其是在供应链管理、科学合作和数字取证等不同领域中，数据证明可能遇到的问题和影响。最后，文章识别了组织间使用不同区块链进行通信和数据交换时所面临的复杂性。

文章进一步提供了针对基于区块链的数据证明系统的未来设计考虑，包括选择合适的区块链类型、构建查询机制、数据证明捕获方法以及考虑特定领域的具体需求。此外，还讨论了未来研究的方向和潜在的扩展领域，旨在推动区块链技术在数据证明领域的应用与发展。

通过这三个主要的研究问题，文章为理解区块链在数据证明领域的复杂性、挑战及未来的可能性提供了新的视角，旨在促进该领域的深入研究和技术创新。 <div>
arXiv:2407.17699v1 Announce Type: new 
Abstract: Provenance, which traces data from its creation to manipulation, is crucial for ensuring data integrity, reliability, and trustworthiness. It is valuable for single-user applications, collaboration within organizations, and across organizations. Blockchain technology has become a popular choice for implementing provenance due to its distributed, transparent, and immutable nature. Numerous studies on blockchain designs are specifically dedicated to provenance, and specialize in this area. Our goal is to provide a new perspective in blockchain based provenance field by identifying the challenges faced and suggesting future research directions. In this paper, we categorize the problem statement into three main research questions to investigate key issues comprehensively and propose a new outlook on the use of blockchains. The first focuses on challenges in non-collaborative, single-source environments, the second examines implications in collaborative environments and different domains such as supply chain, scientific collaboration and digital forensic, and the last one analyzes communication and data exchange challenges between organizations using different blockchains. The interconnected nature of these research questions ensures a thorough exploration of provenance requirements, leading to more effective and secure systems. After analyzing the requirements of provenance in different environments, we provide future design considerations for provenance-based blockchains, including blockchain type, query mechanisms, provenance capture methods, and domain-specific considerations. We also discuss future work and possible extensions in this field.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards the Blockchain Massive Adoption with Permissionless Storage</title>
<link>https://arxiv.org/abs/2407.17761</link>
<guid>https://arxiv.org/abs/2407.17761</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、成本问题、共识机制、安全性、大规模应用

总结:

本文主要探讨了区块链技术在大规模应用过程中面临的主要挑战——成本问题。随着区块链技术的成熟与普及，其高昂的使用成本成为阻碍其广泛采用的关键因素。文章指出，这种高成本与区块链的共识机制和安全策略紧密相关。为了解决这个问题，作者提出了创新性的解决方案：

1. **降低成本**：通过引入一种称为“有用工作量证明”（Useful Proof of Work）的新方法，将文件数据编码过程融入到Nakamoto共识算法中，以证明诚实数据的保存。这种方法不仅增强了安全性，还为存储需求者提供了支付存储资源的机会，从而间接降低了链上交易费用。

2. **保持去中心化**：基于上述理论，作者提出了一种新的去中心化存储网络作为区块链的安全引擎。该网络将存储用户的需求与区块链的安全需求相结合，实现了低成本的交易费用和对存储资源的有效利用，同时保证了区块链的去中心化特性。

3. **解决可扩展性问题**：为了满足日益增长的性能需求，作者提出了区块链分片（Sharding）方案，即通过将区块链分割成多个独立的分片，实现更高的事务处理能力（TPS），同时保持了区块链的去中心化特性。

这些解决方案旨在解决区块链大规模应用中的三大关键问题：降低使用成本、维持去中心化特性以及提升可扩展性。通过这些创新，本文为推动区块链技术的大规模应用提供了全面的策略和路径。 <div>
arXiv:2407.17761v1 Announce Type: new 
Abstract: Blockchain technology emerged with the advent of Bitcoin and rapidly developed over the past few decades, becoming widely accepted and known by the public. However, in the past decades, the massive adoption of blockchain technology has yet to come. Rather than the scalability issue, the blockchain application is challenged by its expensive usage cost. However, the high cost of blockchain usage is deeply connected with the blockchain consensus and security mechanism. The permissionless blockchain must maintain its high cost for security against the 51% Attack. Chain users indirectly cover the cost as coins are appointed for blockchain usage fees. This conflict prevents the massive adoption of blockchain. Thus, blockchain must be improved to solve those problems: 1. The cost of blockchain usage should be low enough. 2. The blockchain should remain decentralized. 3. The scalability of blockchain must meet the demand.
  In my thesis, new approaches are applied to solve the issues above. The key contribution is the discovery of the useful PoW. It extends the Nakamoto PoW with another usage of file data encoding during the same Nakamoto Consensus computation to prove honest data preservation. Based on this theory, a permissionless storage network is proposed as the new security engine for the blockchain. It bridges the high blockchain security cost to the storage users with real demands who are willing to pay for the storage resource. On the other hand, the chain users can benefit from the low transaction fee. Meanwhile, we also provide a scalability solution to shard the blockchain. It enables high TPS and keeps decentralization. The solutions in this thesis provide the answers to all the dependencies of the massive adoption.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Utilizing Blockchain and Smart Contracts for Enhanced Fraud Prevention and Minimization in Health Insurance through Multi-Signature Claim Processing</title>
<link>https://arxiv.org/abs/2407.17765</link>
<guid>https://arxiv.org/abs/2407.17765</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、保险理赔、欺诈预防、透明度

总结:

本文提出了一种基于区块链和智能合约的新型保险理赔处理机制，旨在通过引入所有相关方（患者、提供者和保险公司）的积极参与以及每一步操作的透明化来预防和减少保险欺诈。此机制采用多签名技术让各方在提交、审批和确认理赔过程中共同参与。每一项活动都将被智能合约记录在区块链上，确保所有行动的透明性和可追溯性，从而避免任何一方否认其行为或责任。区块链的不可篡改存储特性和强大的完整性保证了记录的操作不会被修改。

通过这一创新方法，可以显著降低欺诈行为，最终为保险公司和投保人带来利益。随着医疗系统和保险公司继续面临欺诈挑战，该提议的方法具有巨大的潜力，能够显著减少欺诈活动，为双方带来积极影响。 <div>
arXiv:2407.17765v1 Announce Type: new 
Abstract: Healthcare insurance provides financial support to access medical services for patients while ensuring timely and guaranteed payment for providers. Insurance fraud poses a significant challenge to insurance companies and policyholders, leading to increased costs and compromised healthcare treatment and service delivery. Most frauds, like phantom billing, upcoding, and unbundling, happen due to the lack of required entity participation. Also, claim activities are not transparent and accountable. Fraud can be prevented and minimized by involving every entity and making actions transparent and accountable. This paper proposes a blockchain-powered smart contract-based insurance claim processing mechanism to prevent and minimize fraud in response to this prevailing issue. All entities patients, providers, and insurance companies actively participate in the claim submission, approval, and acknowledgment process through a multi-signature technique. Also, every activity is captured and recorded in the blockchain using smart contracts to make every action transparent and accountable so that no entity can deny its actions and responsibilities. Blockchains' immutable storage property and strong integrity guarantee that recorded activities are not modified. As healthcare systems and insurance companies continue to deal with fraud challenges, this proposed approach holds the potential to significantly reduce fraudulent activities, ultimately benefiting both insurers and policyholders.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain Takeovers in Web 3.0: An Empirical Study on the TRON-Steem Incident</title>
<link>https://arxiv.org/abs/2407.17825</link>
<guid>https://arxiv.org/abs/2407.17825</guid>
<content:encoded><![CDATA[
<div> 关键词：Web 3.0、区块链网络接管、分散性、数据控制、价值交换

<br /><br />
总结:

本文深入分析了Web 3.0时代下区块链网络接管对分散性原则的威胁。研究以Tron-Steem接管事件为例，通过精细重建Steem区块链中的质押和选举快照，量化了事件前后分散度的变化。这揭示了区块链网络接管对Web 3.0愿景的重大挑战。同时，研究利用启发式方法识别异常投票者，并进行投票行为聚类分析，揭示了接管策略的内在机制。

研究建议采取预防措施，增强Web 3.0网络抵抗类似威胁的能力。这些见解有助于理解区块链网络接管对Web 3.0的挑战，推动分散技术与治理的发展，并加强Web 3.0用户权益保护。此研究为构建更安全、更分散的网络生态系统提供了重要参考。 <div>
arXiv:2407.17825v1 Announce Type: new 
Abstract: A fundamental goal of Web 3.0 is to establish a decentralized network and application ecosystem, thereby enabling users to retain control over their data while promoting value exchange. However, the recent Tron-Steem takeover incident poses a significant threat to this vision. In this paper, we present a thorough empirical analysis of the Tron-Steem takeover incident. By conducting a fine-grained reconstruction of the stake and election snapshots within the Steem blockchain, one of the most prominent social-oriented blockchains, we quantify the marked shifts in decentralization pre and post the takeover incident, highlighting the severe threat that blockchain network takeovers pose to the decentralization principle of Web 3.0. Moreover, by employing heuristic methods to identify anomalous voters and conducting clustering analyses on voter behaviors, we unveil the underlying mechanics of takeover strategies employed in the Tron-Steem incident and suggest potential mitigation strategies, which contribute to the enhanced resistance of Web 3.0 networks against similar threats in the future. We believe the insights gleaned from this research help illuminate the challenges imposed by blockchain network takeovers in the Web 3.0 era, suggest ways to foster the development of decentralized technologies and governance, as well as to enhance the protection of Web 3.0 user rights.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Lightweight Industrial Cohorted Federated Learning for Heterogeneous Assets</title>
<link>https://arxiv.org/abs/2407.17999</link>
<guid>https://arxiv.org/abs/2407.17999</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、工业应用、数据异质性、模型参数、自适应聚合算法

总结:

本文提出了一种针对工业环境的轻量级工业共聚联邦学习（LICFL）算法，旨在解决联邦学习中数据异质性导致的性能下降问题。LICFL算法通过利用模型参数进行客户分组，无需额外的边缘端计算和通信，从而在不增加资源消耗的情况下提高了联邦学习在工业数据场景中的适用性和效率。此外，文章还引入了适应性LICFL（ALICFL）算法，通过动态调整聚合策略来进一步提升全局模型性能并加速收敛速度。

研究通过实测数据实验验证了所提算法的有效性，并与现有方法进行了对比。实验结果表明，LICFL和ALICFL算法在处理工业环境中数据异质性方面表现出色，能够显著提升模型在不同设备上的性能一致性，并且具有较高的泛化能力，适用于实际工业应用场景。 <div>
arXiv:2407.17999v1 Announce Type: new 
Abstract: Federated Learning (FL) is the most widely adopted collaborative learning approach for training decentralized Machine Learning (ML) models by exchanging learning between clients without sharing the data and compromising privacy. However, since great data similarity or homogeneity is taken for granted in all FL tasks, FL is still not specifically designed for the industrial setting. Rarely this is the case in industrial data because there are differences in machine type, firmware version, operational conditions, environmental factors, and hence, data distribution. Albeit its popularity, it has been observed that FL performance degrades if the clients have heterogeneous data distributions. Therefore, we propose a Lightweight Industrial Cohorted FL (LICFL) algorithm that uses model parameters for cohorting without any additional on-edge (clientlevel) computations and communications than standard FL and mitigates the shortcomings from data heterogeneity in industrial applications. Our approach enhances client-level model performance by allowing them to collaborate with similar clients and train more specialized or personalized models. Also, we propose an adaptive aggregation algorithm that extends the LICFL to Adaptive LICFL (ALICFL) for further improving the global model performance and speeding up the convergence. Through numerical experiments on real-time data, we demonstrate the efficacy of the proposed algorithms and compare the performance with existing approaches.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Exploration Study on Developing Blockchain Systems the Practitioners Perspective</title>
<link>https://arxiv.org/abs/2407.18005</link>
<guid>https://arxiv.org/abs/2407.18005</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、软件开发、系统设计、学术研究、行业应用

总结:

本文通过两阶段的研究项目，旨在填补关于区块链软件（BBS）开发过程理解的空白。首先进行了一项系统文献综述，从58篇研究中提炼出构建BBS系统的23个任务流程。随后，对来自全球35个国家、覆盖六大洲的102名区块链从业者进行了问卷调查，以验证这些任务的重要性。研究结果发现，参与者对24个BBS任务的重要性的评价存在显著差异（p值<.001），仅两项任务（激励协议设计和粒度设计）未显示出显著性差异。

此研究是首个针对BBS开发过程深入理解的尝试，为研究人员和实践者提供了有关BBS系统开发挑战和建议的宝贵信息。它不仅揭示了BBS开发过程的关键步骤及其相对重要性，还强调了激励机制和粒度设计的特殊考虑。这一研究成果对于指导BBS的系统设计、实施与验证具有重要意义，有助于推动学术界与业界对BBS领域知识的深化与应用。 <div>
arXiv:2407.18005v1 Announce Type: new 
Abstract: Context: Blockchain-based software (BBS) exploits the concepts and technologies popularized by cryptocurrencies offering decentralized transaction ledgers with immutable content for security-critical and transaction critical systems. Recent research has explored the strategic benefits and technical limitations of BBS in various fields, including cybersecurity, healthcare, education, and financial technologies. Despite growing interest from academia and industry, there is a lack of empirical evidence, leading to an incomplete understanding of the processes, methods, and techniques necessary for systematic BBS development. Objectives: Existing research lacks a consolidated view, particularly empirically driven guidelines based on published evidence and development practices. This study aims to address the gap by consolidating empirical evidence and development practices to derive or leverage existing processes, patterns, and models for designing, implementing, and validating BBS systems. Method: Tied to this knowledge gap, we conducted a two-phase research project. First, a systematic literature review of 58 studies was performed to identify a development process comprising 23 tasks for BBS systems. Second, a survey of 102 blockchain practitioners from 35 countries across six continents was conducted to validate the BBS system development process. Results: Our results revealed a statistically significant difference (p-value <.001) in the importance ratings of 24 out of 26 BBS tasks by our participants. The only two tasks that were not statistically significant were incentive protocol design and granularity design. Conclusion: Our research is among the first to advance understanding on the aspect of development process for blockchain-based systems and helps researchers and practitioners in their quests on challenges and recommendations associated with the development of BBS systems
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On the Design of Ethereum Data Availability Sampling: A Comprehensive Simulation Study</title>
<link>https://arxiv.org/abs/2407.18085</link>
<guid>https://arxiv.org/abs/2407.18085</guid>
<content:encoded><![CDATA[
<div> 关键词：Data Availability Sampling（DAS）、区块链技术、分布式网络、模拟分析、系统性能

<br /><br />
总结:

本文深入探讨了数据可用性采样（DAS）和分片机制在去中心化系统中的应用，通过基于模拟的分析方法。DAS作为区块链技术和分布式网络的关键概念，文章对其进行了全面剖析，评估其对系统性能的影响。为了实现这一目标，作者开发了一款专为DAS设计的仿真器，以此来探究影响系统行为和效率的各种参数。

研究中包括了一系列实验，旨在验证理论假设并揭示DAS参数之间的相互作用。实验内容涉及行托管、每节点验证者数量以及恶意节点等不同策略。通过这些实验，研究团队得出了DAS协议的有效性结论，并据此提出了优化策略，旨在提升去中心化网络的整体性能。

此外，研究结果为未来的研究提供了指导，揭示了分布式系统内在复杂性的多维度理解。本研究不仅丰富了DAS的理论知识，还为分布式系统的构建、实施和优化提供了实际指导意义。 <div>
arXiv:2407.18085v1 Announce Type: new 
Abstract: This paper presents an in-depth exploration of Data Availability Sampling (DAS) and sharding mechanisms within decentralized systems through simulation-based analysis. DAS, a pivotal concept in blockchain technology and decentralized networks, is thoroughly examined to unravel its intricacies and assess its impact on system performance. Through the development of a simulator tailored explicitly for DAS, we embark on a comprehensive investigation into the parameters that influence system behavior and efficiency. A series of experiments are conducted within the simulated environment to validate theoretical formulations and dissect the interplay of DAS parameters. This includes an exploration of approaches such as custody by row, variations in validators per node, and malicious nodes. The outcomes of these experiments furnish insights into the efficacy of DAS protocols and pave the way for the formulation of optimization strategies geared towards enhancing decentralized network performance. Moreover, the findings serve as guidelines for future research endeavors, offering a nuanced understanding of the complexities inherent in decentralized systems. This study not only contributes to the theoretical understanding of DAS but also offers practical implications for the design, implementation, and optimization of decentralized systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review</title>
<link>https://arxiv.org/abs/2407.18096</link>
<guid>https://arxiv.org/abs/2407.18096</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、物联网、隐私保护、安全威胁、防御策略

<br /><br />
总结:
本文通过系统文献综述（SLR）方法，聚焦于2017年至2024年期间关于联邦学习（FL）在物联网（IoT）环境中的隐私威胁及其防御措施的研究。研究首先识别了FL在IoT环境中面临的三大主要隐私威胁：推理攻击、投毒攻击和窃听，并评估了差分隐私、安全多方计算等防御措施的有效性，这些措施旨在保护隐私同时保持FL功能的完整性。文章强调了为适应IoT环境需求而制定高效、强大的隐私保护策略的重要性。特别指出，需要针对重放、逃避和模型盗取攻击采取策略。此外，研究建议探索轻量级防御措施以及区块链等新兴技术，以增强FL在IoT中的隐私保护能力，从而开发能在不同网络条件下运行的FL模型。 <div>
arXiv:2407.18096v1 Announce Type: new 
Abstract: Federated Learning (FL) in the Internet of Things (IoT) environments can enhance machine learning by utilising decentralised data, but at the same time, it might introduce significant privacy and security concerns due to the constrained nature of IoT devices. This represents a research challenge that we aim to address in this paper. We systematically analysed recent literature to identify privacy threats in FL within IoT environments, and evaluate the defensive measures that can be employed to mitigate these threats. Using a Systematic Literature Review (SLR) approach, we searched five publication databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating relevant papers published between 2017 and April 2024, a period which spans from the introduction of FL until now. Guided by the PRISMA protocol, we selected 49 papers to focus our systematic review on. We analysed these papers, paying special attention to the privacy threats and defensive measures -- specifically within the context of IoT -- using inclusion and exclusion criteria tailored to highlight recent advances and critical insights. We identified various privacy threats, including inference attacks, poisoning attacks, and eavesdropping, along with defensive measures such as Differential Privacy and Secure Multi-Party Computation. These defences were evaluated for their effectiveness in protecting privacy without compromising the functional integrity of FL in IoT settings. Our review underscores the necessity for robust and efficient privacy-preserving strategies tailored for IoT environments. Notably, there is a need for strategies against replay, evasion, and model stealing attacks. Exploring lightweight defensive measures and emerging technologies such as blockchain may help improve the privacy of FL in IoT, leading to the creation of FL models that can operate under variable network conditions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Quantifying the Blockchain Trilemma: A Comparative Analysis of Algorand, Ethereum 2.0, and Beyond</title>
<link>https://arxiv.org/abs/2407.14335</link>
<guid>https://arxiv.org/abs/2407.14335</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、数字经济、元宇宙、证明权益（PoS）、区块链三难问题

总结:
本文探讨了区块链技术在数字经济和元宇宙领域的关键作用，特别是通过比较两种领先的权益证明（PoS）系统——Algorand 和 Ethereum 2.0。研究通过分析现有的指标体系来衡量去中心化程度，通过实际交易数据评估可扩展性，并通过识别潜在漏洞来评估安全性。研究发现，每种平台在解决“区块链三难问题”方面都有其独特的优势，并提出了通用方法来评估区块链的关键特性，这不仅适用于当前的系统，也对未来的区块链发展具有重要意义。数据和代码已作为开源资源在GitHub上提供，为研究人员和开发者提供了宝贵的资源，以进一步探索和优化区块链技术。 <div>
arXiv:2407.14335v1 Announce Type: cross 
Abstract: Blockchain technology is essential for the digital economy and metaverse, supporting applications from decentralized finance to virtual assets. However, its potential is constrained by the "Blockchain Trilemma," which necessitates balancing decentralization, security, and scalability. This study evaluates and compares two leading proof-of-stake (PoS) systems, Algorand and Ethereum 2.0, against these critical metrics. Our research interprets existing indices to measure decentralization, evaluates scalability through transactional data, and assesses security by identifying potential vulnerabilities. Utilizing real-world data, we analyze each platform's strategies in a structured manner to understand their effectiveness in addressing trilemma challenges. The findings highlight each platform's strengths and propose general methodologies for evaluating key blockchain characteristics applicable to other systems. This research advances the understanding of blockchain technologies and their implications for the future digital economy. Data and code are available on GitHub as open source.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>GeoFaaS: An Edge-to-Cloud FaaS Platform</title>
<link>https://arxiv.org/abs/2405.14413</link>
<guid>https://arxiv.org/abs/2405.14413</guid>
<content:encoded><![CDATA[
<div> 关键词：GeoFaaS、边缘计算、云计算、函数即服务（FaaS）、地理位置意识

<br /><br />
总结:本文提出了一种新型的边缘到云“函数即服务”(FaaS)平台——GeoFaaS。该平台利用实时客户端位置信息，将请求透明地执行在最近可用的FaaS节点上，以实现高效网络使用和降低延迟。当边缘资源过载时，GeoFaaS能够透明地将请求卸载到云端，确保一致的执行性能，无需用户干预。GeoFaaS具有模块化和分散化的架构，基于单节点FaaS系统tinyFaaS构建，可作为独立的边缘到云FaaS平台运行，同时也可以作为现有FaaS服务的路由层进行集成。为了评估这一方法的有效性，研究团队开发了一个开源概念验证原型，并通过实验研究了其性能和容错性。 <div>
arXiv:2405.14413v2 Announce Type: replace 
Abstract: The massive growth of mobile and IoT devices demands geographically distributed computing systems for optimal performance, privacy, and scalability. However, existing edge-to-cloud serverless platforms lack location awareness, resulting in inefficient network usage and increased latency.
  In this paper, we propose GeoFaaS, a novel edge-to-cloud Function-as-a-Service (FaaS) platform that leverages real-time client location information for transparent request execution on the nearest available FaaS node. If needed, GeoFaaS transparently offloads requests to the cloud when edge resources are overloaded, thus, ensuring consistent execution without user intervention. GeoFaaS has a modular and decentralized architecture: building on the single-node FaaS system tinyFaaS, GeoFaaS works as a stand-alone edge-to-cloud FaaS platform but can also integrate and act as a routing layer for existing FaaS services, e.g., in the cloud. To evaluate our approach, we implemented an open-source proof-of-concept prototype and studied performance and fault-tolerance behavior in experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Architectural Tactics to Improve the Environmental Sustainability of Microservices: A Rapid Review</title>
<link>https://arxiv.org/abs/2407.16706</link>
<guid>https://arxiv.org/abs/2407.16706</guid>
<content:encoded><![CDATA[
arXiv:2407.16706v1 Announce Type: new 
Abstract: Microservices are a popular architectural style adopted by the industry when it comes to deploying software that requires scalability, maintainability, and agile development. There is an increasing demand for improving the sustainability of microservice systems in the industry. This rapid review gathers 22 peer-reviewed studies and synthesizes architectural tactics that improve the environmental sustainability of microservices from them. We list 6 tactics that are presented in an actionable way and categorized according to their sustainability aspects and context. The sustainability aspects include energy efficiency, carbon efficiency, and resource efficiency, among which resource efficiency is the most researched one while energy efficiency and carbon efficiency are still in the early stage of study. The context categorization, including serverless platforms, decentralized networks, etc., helps to identify the tactics that we can use in a specific setting. Additionally, we present how the evidence of optimization after adopting these tactics is presented, like the measurement unit and statistical methods, and how experiments are generally set up so that this review is both instructive for our future study and our industrial practitioners' interest. We further study the insufficiencies of the current study and hope to provide insight for other researchers and the industry.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning</title>
<link>https://arxiv.org/abs/2407.16729</link>
<guid>https://arxiv.org/abs/2407.16729</guid>
<content:encoded><![CDATA[
arXiv:2407.16729v1 Announce Type: new 
Abstract: Generating human mobility trajectories is of great importance to solve the lack of large-scale trajectory data in numerous applications, which is caused by privacy concerns. However, existing mobility trajectory generation methods still require real-world human trajectories centrally collected as the training data, where there exists an inescapable risk of privacy leakage. To overcome this limitation, in this paper, we propose PateGail, a privacy-preserving imitation learning model to generate mobility trajectories, which utilizes the powerful generative adversary imitation learning model to simulate the decision-making process of humans. Further, in order to protect user privacy, we train this model collectively based on decentralized mobility data stored in user devices, where personal discriminators are trained locally to distinguish and reward the real and generated human trajectories. In the training process, only the generated trajectories and their rewards obtained based on personal discriminators are shared between the server and devices, whose privacy is further preserved by our proposed perturbation mechanisms with theoretical proof to satisfy differential privacy. Further, to better model the human decision-making process, we propose a novel aggregation mechanism of the rewards obtained from personal discriminators. We theoretically prove that under the reward obtained based on the aggregation mechanism, our proposed model maximizes the lower bound of the discounted total rewards of users. Extensive experiments show that the trajectories generated by our model are able to resemble real-world trajectories in terms of five key statistical metrics, outperforming state-of-the-art algorithms by over 48.03%. Furthermore, we demonstrate that the synthetic trajectories are able to efficiently support practical applications, including mobility prediction and location recommendation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain security for ransomware detection</title>
<link>https://arxiv.org/abs/2407.16862</link>
<guid>https://arxiv.org/abs/2407.16862</guid>
<content:encoded><![CDATA[
arXiv:2407.16862v1 Announce Type: new 
Abstract: Blockchain networks are critical for safeguarding digital transactions and assets, but they are increasingly targeted by ransomware attacks exploiting zero-day vulnerabilities. Traditional detection techniques struggle due to the complexity of these exploits and the lack of comprehensive datasets. The UGRansome dataset addresses this gap by offering detailed features for analysing ransomware and zero-day attacks, including timestamps, attack types, protocols, network flows, and financial impacts in bitcoins (BTC). This study uses the Lazy Predict library to automate machine learning (ML) on the UGRansome dataset. The study aims to enhance blockchain security through ransomware detection based on zero-day exploit recognition using the UGRansome dataset. Lazy Predict streamlines different ML model comparisons and identifies effective algorithms for threat detection. Key features such as timestamps, protocols, and financial data are used to predict anomalies as zero-day threats and to classify known signatures as ransomware. Results demonstrate that ML can significantly improve cybersecurity in blockchain environments. The DecisionTreeClassifier and ExtraTreeClassifier, with their high performance and low training times, are ideal candidates for deployment in real-time threat detection systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fostering Microservice Maintainability Assurance through a Comprehensive Framework</title>
<link>https://arxiv.org/abs/2407.16873</link>
<guid>https://arxiv.org/abs/2407.16873</guid>
<content:encoded><![CDATA[
arXiv:2407.16873v1 Announce Type: new 
Abstract: Cloud-native systems represent a significant leap in constructing scalable, large systems, employing microservice architecture as a key element in developing distributed systems through self-contained components. However, the decentralized nature of these systems, characterized by separate source codes and deployments, introduces challenges in assessing system qualities. Microservice-based systems, with their inherent complexity and the need for coordinated changes across multiple microservices, lack established best practices and guidelines, leading to difficulties in constructing and comprehending the holistic system view. This gap can result in performance degradation and increased maintenance costs, potentially requiring system refactoring. The main goal of this project is to offer maintainability assurance for microservice practitioners. It introduces an automated assessment framework tailored to microservice architecture, enhancing practitioners' understanding and analytical capabilities of the multiple system perspectives. The framework addresses various granularity levels, from artifacts to constructing holistic views of static and dynamic system characteristics. It integrates diverse perspectives, encompassing human-centric elements like architectural visualization and automated evaluations, including coupling detection, testing coverage measurement, and semantic clone identification. Validation studies involving practitioners demonstrate the framework's effectiveness in addressing diverse quality and maintainability issues, revealing insights not apparent when analyzing individual microservices in isolation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Profitable Manipulations of Cryptographic Self-Selection are Statistically Detectable</title>
<link>https://arxiv.org/abs/2407.16949</link>
<guid>https://arxiv.org/abs/2407.16949</guid>
<content:encoded><![CDATA[
arXiv:2407.16949v1 Announce Type: new 
Abstract: Cryptographic Self-Selection is a common primitive underlying leader-selection for Proof-of-Stake blockchain protocols. The concept was first popularized in Algorand [CM19], who also observed that the protocol might be manipulable. [FHWY22] provide a concrete manipulation that is strictly profitable for a staker of any size (and also prove upper bounds on the gains from manipulation).
  Separately, [YSZ23, BM24] initiate the study of undetectable profitable manipulations of consensus protocols with a focus on the seminal Selfish Mining strategy [ES14] for Bitcoin's Proof-of-Work longest-chain protocol. They design a Selfish Mining variant that, for sufficiently large miners, is strictly profitable yet also indistinguishable to an onlooker from routine latency (that is, a sufficiently large profit-maximizing miner could use their strategy to strictly profit over being honest in a way that still appears to the rest of the network as though everyone is honest but experiencing mildly higher latency. This avoids any risk of negatively impacting the value of the underlying cryptocurrency due to attack detection).
  We investigate the detectability of profitable manipulations of the canonical cryptographic self-selection leader selection protocol introduced in [CM19] and studied in [FHWY22], and establish that for any player with $\alpha < \frac{3-\sqrt{5}}{2} \approx 0.38$ fraction of the total stake, every strictly profitable manipulation is statistically detectable. Specifically, we consider an onlooker who sees only the random seed of each round (and does not need to see any other broadcasts by any other players). We show that the distribution of the sequence of random seeds when any player is profitably manipulating the protocol is inconsistent with any distribution that could arise by honest stakers being offline or timing out (for a natural stylized model of honest timeouts).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Bridging Trust into the Blockchain: A Systematic Review on On-Chain Identity</title>
<link>https://arxiv.org/abs/2407.17276</link>
<guid>https://arxiv.org/abs/2407.17276</guid>
<content:encoded><![CDATA[
arXiv:2407.17276v1 Announce Type: new 
Abstract: The ongoing regulation of blockchain-based services and applications requires the identification of users who are issuing transactions on the blockchain. This systematic review explores the current status, identifies research gaps, and outlines future research directions for establishing trusted and privacy-compliant identities on the blockchain (on-chain identity). A systematic search term was applied across various scientific databases, collecting 2232 potentially relevant research papers. These papers were narrowed down in two methodologically executed steps to 98 and finally to 13 relevant sources. The relevant articles were then systematically analyzed based on a set of screening questions. The results of the selected studies have provided insightful findings on the mechanisms of on-chain identities. On-chain identities are established using zero-knowledge proofs, public key infrastructure/certificates, and web of trust approaches. The technologies and architectures used by the authors are also highlighted. Trust has emerged as a key research gap, manifesting in two ways: firstly, a gap in how to trust the digital identity representation of a physical human; secondly, a gap in how to trust identity providers that issue identity confirmations on-chain. Potential future research avenues are suggested to help fill the current gaps in establishing trust and on-chain identities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Refined Bitcoin Security-Latency Under Network Delay</title>
<link>https://arxiv.org/abs/2212.01372</link>
<guid>https://arxiv.org/abs/2212.01372</guid>
<content:encoded><![CDATA[
arXiv:2212.01372v4 Announce Type: replace 
Abstract: We study security-latency bounds for Nakamoto consensus, i.e., how secure a block is after it becomes $k$-deep in the chain. We improve the state-of-the-art bounds by analyzing the race between adversarial and honest chains in three different phases. We find the probability distribution of the growth of the adversarial chains under models similar to those in [Guo, Ren; AFT 2022] when a target block becomes $k$-deep in the chain. We analyze certain properties of this race to model each phase with random walks that provide tighter bounds than the existing results. Combining all three phases provides novel upper and lower bounds for blockchains with small $\lambda\Delta$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Proof of Diligence: Cryptoeconomic Security for Rollups</title>
<link>https://arxiv.org/abs/2402.07241</link>
<guid>https://arxiv.org/abs/2402.07241</guid>
<content:encoded><![CDATA[
arXiv:2402.07241v2 Announce Type: replace 
Abstract: Layer 1 (L1) blockchains such as Ethereum are secured under an "honest supermajority of stake" assumption for a large pool of validators who verify each and every transaction on it. This high security comes at a scalability cost which not only effects the throughput of the blockchain but also results in high gas fees for executing transactions on chain. The most successful solution for this problem is provided by optimistic rollups, Layer 2 (L2) blockchains that execute transactions outside L1 but post the transaction data on L1.
  The security for such L2 chains is argued, informally, under the assumption that a set of nodes will check the transaction data posted on L1 and raise an alarm (a fraud proof) if faulty transactions are detected. However, all current deployments lack a proper incentive mechanism for ensuring that these nodes will do their job ``diligently'', and simply rely on a cursory incentive alignment argument for security.
  We solve this problem by introducing an incentivized watchtower network designed to serve as the first line of defense for rollups. Our main contribution is a ``Proof of Diligence'' protocol that requires watchtowers to continuously provide a proof that they have verified L2 assertions and get rewarded for the same. Proof of Diligence protocol includes a carefully-designed incentive mechanism that is provably secure when watchtowers are rational actors, under a mild rational independence assumption.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain in Healthcare: Implementing Hyperledger Fabric for Electronic Health Records at Frere Provincial Hospital</title>
<link>https://arxiv.org/abs/2407.15876</link>
<guid>https://arxiv.org/abs/2407.15876</guid>
<content:encoded><![CDATA[
arXiv:2407.15876v1 Announce Type: new 
Abstract: As healthcare systems worldwide continue to grapple with the challenges of interoperability, data security, and accessibility, integrating emerging technologies becomes imperative. This paper investigates the implementation of blockchain technology, specifically Hyperledger Fabric, for Electronic Health Records (EHR) management at Frere Hospital in the Eastern Cape province of South Africa. The paper examines the benefits and challenges of integrating blockchain into healthcare information systems. Hyperledger Fabric's modular architecture is harnessed to create a secure, transparent, and decentralized platform for storing, managing, and sharing EHRs among stakeholders. The study used a mixed-methods approach, integrating case studies and data collection methods through observation and informal questions, with the specific goal of understanding current record management methods and challenges. This method offers practical insights and validates the approach. The result demonstrates the role of blockchain in transforming healthcare, framed within a rigorous exploration and analysis. The findings of this study have broader implications for healthcare institutions seeking advanced solutions to address the persistent challenges in electronic health record management. Ultimately, the research underscores the transformative potential of blockchain technology in healthcare settings, fostering trust, security, and efficiency in the management of sensitive patient data.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach</title>
<link>https://arxiv.org/abs/2407.15879</link>
<guid>https://arxiv.org/abs/2407.15879</guid>
<content:encoded><![CDATA[
arXiv:2407.15879v1 Announce Type: new 
Abstract: The increasing security and privacy concerns in the Smart Grid sector have led to a significant demand for robust intrusion detection systems within critical smart grid infrastructure. To address the challenges posed by privacy preservation and decentralized power system zones with distinct data ownership, Federated Learning (FL) has emerged as a promising privacy-preserving solution which facilitates collaborative training of attack detection models without necessitating the sharing of raw data. However, FL presents several implementation limitations in the power system domain due to its heavy reliance on a centralized aggregator and the risks of privacy leakage during model update transmission. To overcome these technical bottlenecks, this paper introduces a novel decentralized federated anomaly detection scheme based on two main gossip protocols namely Random Walk and Epidemic. Our findings indicate that the Random Walk protocol exhibits superior performance compared to the Epidemic protocol, highlighting its efficacy in decentralized federated learning environments. Experimental validation of the proposed framework utilizing publicly available industrial control systems datasets demonstrates superior attack detection accuracy while safeguarding data confidentiality and mitigating the impact of communication latency and stragglers. Furthermore, our approach yields a notable 35% improvement in training time compared to conventional FL, underscoring the efficacy and robustness of our decentralized learning method.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Versioned Analysis of Software Quality Indicators and Self-admitted Technical Debt in Ethereum Smart Contracts with Ethstractor</title>
<link>https://arxiv.org/abs/2407.15967</link>
<guid>https://arxiv.org/abs/2407.15967</guid>
<content:encoded><![CDATA[
arXiv:2407.15967v1 Announce Type: new 
Abstract: The rise of decentralized applications (dApps) has made smart contracts imperative components of blockchain technology. As many smart contracts process financial transactions, their security is paramount. Moreover, the immutability of blockchains makes vulnerabilities in smart contracts particularly challenging because it requires deploying a new version of the contract at a different address, incurring substantial fees paid in Ether. This paper proposes Ethstractor, the first smart contract collection tool for gathering a dataset of versioned smart contracts. The collected dataset is then used to evaluate the reliability of code metrics as indicators of vulnerabilities in smart contracts. Our findings indicate that code metrics are ineffective in signalling the presence of vulnerabilities. Furthermore, we investigate whether vulnerabilities in newer versions of smart contracts are mitigated and identify that the number of vulnerabilities remains consistent over time. Finally, we examine the removal of self-admitted technical debt in contracts and uncover that most of the introduced debt has never been subsequently removed.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Addressing Trust Issues for Vehicle to Grid in Distributed Power Grids Using Blockchains</title>
<link>https://arxiv.org/abs/2407.16180</link>
<guid>https://arxiv.org/abs/2407.16180</guid>
<content:encoded><![CDATA[
arXiv:2407.16180v1 Announce Type: new 
Abstract: While blockchain offers inherent security, trust issues among stakeholders in vehicle-to-grid (V2G) applications remain unresolved due to a lack of regulatory frameworks and standardization. Additionally, a tailored decentralized privacy-preserved coordination scheme for blockchain in V2G networks is needed to ensure user privacy and efficient energy transactions. This paper proposes a V2G trading and coordination scheme tailored to the decentralized nature of blockchain as well as the interests of stakeholders utilizing smart charging points (SCPs) and Stackelberg game model. Case studies using real-world data from Southern University of Science and Technology demonstrate the efficacy of proposed scheme in reducing EV charging costs and the potential for supporting auxiliary grid services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Manifoldchain: Maximizing Blockchain Throughput via Bandwidth-Clustered Sharding</title>
<link>https://arxiv.org/abs/2407.16295</link>
<guid>https://arxiv.org/abs/2407.16295</guid>
<content:encoded><![CDATA[
arXiv:2407.16295v1 Announce Type: new 
Abstract: Bandwidth limitation is the major bottleneck that hinders scaling throughput of proof-of-work blockchains. To guarantee security, the mining rate of the blockchain is determined by the miners with the lowest bandwidth, resulting in an inefficient bandwidth utilization among fast miners. We propose Manifoldchain, an innovative blockchain sharding protocol that alleviates the impact of slow miners to maximize blockchain throughput. Manifoldchain utilizes a bandwidth-clustered shard formation mechanism that groups miners with similar bandwidths into the same shard. Consequently, this approach enables us to set an optimal mining rate for each shard based on its bandwidth, effectively reducing the waiting time caused by slow miners. Nevertheless, the adversary could corrupt miners with similar bandwidths, thereby concentrating hashing power and potentially creating an adversarial majority within a single shard. To counter this adversarial strategy, we introduce sharing mining, allowing the honest mining power of the entire network to participate in the secure ledger formation of each shard, thereby achieving the same level of security as an unsharded blockchain. Additionally, we introduce an asynchronous atomic commitment mechanism to ensure transaction atomicity across shards with various mining rates. Our theoretical analysis demonstrates that Manifoldchain scales linearly in throughput with the increase in shard numbers and inversely with network delay in each shard. We implement a full system prototype of Manifoldchain, comprehensively evaluated on both simulated and real-world testbeds. These experiments validate its vertical scalability with network bandwidth and horizontal scalability with network size, achieving a substantial improvement of 186% in throughput over baseline sharding protocols, for scenarios where bandwidths of miners range from 5Mbps to 60Mbps.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Real-Time Interactions Between Human Controllers and Remote Devices in Metaverse</title>
<link>https://arxiv.org/abs/2407.16591</link>
<guid>https://arxiv.org/abs/2407.16591</guid>
<content:encoded><![CDATA[
arXiv:2407.16591v1 Announce Type: new 
Abstract: Supporting real-time interactions between human controllers and remote devices remains a challenging goal in the Metaverse due to the stringent requirements on computing workload, communication throughput, and round-trip latency. In this paper, we establish a novel framework for real-time interactions through the virtual models in the Metaverse. Specifically, we jointly predict the motion of the human controller for 1) proactive rendering in the Metaverse and 2) generating control commands to the real-world remote device in advance. The virtual model is decoupled into two components for rendering and control, respectively. To dynamically adjust the prediction horizons for rendering and control, we develop a two-step human-in-the-loop continuous reinforcement learning approach and use an expert policy to improve the training efficiency. An experimental prototype is built to verify our algorithm with different communication latencies. Compared with the baseline policy without prediction, our proposed method can reduce 1) the Motion-To-Photon (MTP) latency between human motion and rendering feedback and 2) the root mean squared error (RMSE) between human motion and real-world remote devices significantly.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mobile Technology: A Panacea to Food Insecurity In Nigeria -- A Case Study of SELL HARVEST Application</title>
<link>https://arxiv.org/abs/2407.16614</link>
<guid>https://arxiv.org/abs/2407.16614</guid>
<content:encoded><![CDATA[
<div> 关键词：Sell Harvest、农业、技术、人工智能、数字农业

总结:
文章主要探讨了农业科技在解决全球贫困和饥饿问题上的潜力，特别是在尼日利亚这一农业产出占国内生产总值23%的国家。文中指出，尽管农业生产活动频繁，但尼日利亚仍未实现全民食物安全，主要原因是农业生产力低下与人口快速增长之间的矛盾。为了提升农业生产效率并促进食物安全，文章提出了一系列科技解决方案，包括室内垂直农业、自动化、机器人技术、现代温室实践、精准农业、人工智能以及区块链等。

此外，文章强调了手机在推广农业科技中的重要性，指出其高普及率使得数字农业成为可能。通过数字平台，消费者与农民可以更紧密地联系，实现最短供应链，从而减少农村地区的贫困和饥饿。最后，文章提出了一款名为“Sell Harvest”的移动应用提案，旨在通过数字化手段提高农业可持续性，确保食物安全。

综上所述，本文主要围绕农业技术的应用、手机在农业推广中的作用、以及一款名为“Sell Harvest”的创新移动应用展开讨论，旨在通过科技手段解决尼日利亚乃至全球的农业困境和食物安全问题。 <div>
arXiv:2407.16614v1 Announce Type: new 
Abstract: Over time, agriculture is the most consistent activity, and it evolves every day. It contributes to a vast majority of the Gross Domestic Product (GDP) of Nigeria but as ironic as it may be, there is still hunger in significant parts of the country due to low productivity in the agricultural sector and comparison to the geometric population growth. During the first half of 2022, agriculture contributed about 23% of the country's GDP while the industry and services sector had a share of the remaining 77%. This showed that with the high rate of agricultural activities, Nigeria has not achieved food security for the teeming population. and more productivity levels can be attained. Technology can/will assist Nigeria in overcoming global poverty and hunger quicker in both rural and urban areas. Today, there are many types of agricultural technologies available for farmers all over the world to increase productivity. Major technological advancements include indoor vertical farming, automation, robotics, livestock technology, modern greenhouse practices, precision agriculture, artificial intelligence, and blockchain. Mobile phones have one of the highest adoption rates of technologies developed within the last century. Digitalization will bring consumers and farmers closer together to access the shortest supply chain possible and reduce rural poverty and hunger. The paper will review the different agricultural technologies and propose a mobile solution, code Sell Harvest, to make farming more sustainable and secure food.
  Keywords: Sell Harvest, Agriculture, Technology, Artificial Intelligence, and Digital Farming.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Non-intrusive Enforcement of Decentralized Stability Protocol for IBRs in AC Microgrids</title>
<link>https://arxiv.org/abs/2310.09450</link>
<guid>https://arxiv.org/abs/2310.09450</guid>
<content:encoded><![CDATA[
arXiv:2310.09450v3 Announce Type: replace 
Abstract: This paper presents decentralized, passivity-based stability protocol for inverter-based resources (IBRs) in AC microgrids and a non-intrusive approach that enforces the protocol. By "non-intrusive" we mean that the approach does not require reprogramming IBRs' controllers to enforce the stability protocol. Implementing the approach only requires very minimal information of IBR dynamics, and sharing such information with the non-IBR-manufacturer parties does not cause any concerns on intellectual property privacy. Enforcing the protocol allows for plug-and-play operation of IBRs, while maintaining microgrid stability. The proposed method is tested by simulating two networked microgrids with tie lines and two IBRs modeled in the electromagnetic transient (EMT) time scale. Simulations show that oscillations with increasing amplitudes can occur, when two stable AC microgrids are networked. Simulations also suggest that the proposed approach can mitigate such a system-level symptom by changing less than 2 percent of energy produced by IBRs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Honeybee: Decentralized Peer Sampling with Verifiable Random Walks for Blockchain Data Sharding</title>
<link>https://arxiv.org/abs/2402.16201</link>
<guid>https://arxiv.org/abs/2402.16201</guid>
<content:encoded><![CDATA[
arXiv:2402.16201v2 Announce Type: replace 
Abstract: Data sharding$\unicode{x2013}$in which block data is sharded without sharding compute$\unicode{x2013}$is at the present the favored approach for scaling Ethereum and other popular blockchains. A key challenge toward implementing data sharding is verifying whether the entirety of a block's data is available in the network (across its shards). A central technique proposed to conduct this verification uses erasure-coded blocks and is called data availability sampling (DAS). While the high-level protocol details of DAS have been well discussed in the community, discussions around how such a protocol will be implemented at the peer-to-peer layer are lacking. We identify random sampling of nodes as a fundamental primitive necessary to carry out DAS and present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks. Honeybee is secure against attacks even in the presence of a large number of Byzantine nodes (e.g., 50% of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for DAS functions in both full nodes and light nodes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Personalized Federated Learning based on a Conditional Sparse-to-Sparser Scheme</title>
<link>https://arxiv.org/abs/2404.15943</link>
<guid>https://arxiv.org/abs/2404.15943</guid>
<content:encoded><![CDATA[
arXiv:2404.15943v3 Announce Type: replace 
Abstract: Decentralized Federated Learning (DFL) has become popular due to its robustness and avoidance of centralized coordination. In this paradigm, clients actively engage in training by exchanging models with their networked neighbors. However, DFL introduces increased costs in terms of training and communication. Existing methods focus on minimizing communication often overlooking training efficiency and data heterogeneity. To address this gap, we propose a novel \textit{sparse-to-sparser} training scheme: DA-DPFL. DA-DPFL initializes with a subset of model parameters, which progressively reduces during training via \textit{dynamic aggregation} and leads to substantial energy savings while retaining adequate information during critical learning periods.
  Our experiments showcase that DA-DPFL substantially outperforms DFL baselines in test accuracy, while achieving up to $5$ times reduction in energy costs. We provide a theoretical analysis of DA-DPFL's convergence by solidifying its applicability in decentralized and personalized learning. The code is available at:https://github.com/EricLoong/da-dpfl
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Electricity Consumption of Ethereum and Filecoin: Advances in Models and Estimates</title>
<link>https://arxiv.org/abs/2407.14519</link>
<guid>https://arxiv.org/abs/2407.14519</guid>
<content:encoded><![CDATA[
arXiv:2407.14519v1 Announce Type: new 
Abstract: The high electricity consumption of cryptocurrencies that rely on proof-of-work (PoW) consensus algorithms has raised serious environmental concerns due to its association with carbon emissions and strain on energy grids. There has been significant research into estimating the electricity consumption of PoW-based cryptocurrencies and developing alternatives to PoW.
  In this article, we introduce refined models to estimate the electricity consumption of two prominent alternatives: Ethereum, now utilizing proof-of-stake (PoS), and Filecoin, which employs proof-of-spacetime (PoSt). Ethereum stands as a leading blockchain platform for crafting decentralized applications, whereas Filecoin is recognized as the world's foremost decentralized data storage network.
  Prior studies for modeling electricity consumption have been criticized for methodological flaws and shortcomings, low-quality data, and unvalidated assumptions. We improve on this in several ways: we obtain more novel, validated data from the systems in question, extract information from existing data and research, and we improve transparency and reproducibility by clearly explaining and documenting the used methodology and explicitly stating unavoidable limitations and assumptions made. When comparing the current, most prominent models for Ethereum and Filecoin to our refined models, we find that given the wide error margins of both the refined models and the ones introduced in prior literature, the resulting average estimates are to a large extent in line with each other.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Alea-BFT: Practical Asynchronous Byzantine Fault Tolerance</title>
<link>https://arxiv.org/abs/2407.14538</link>
<guid>https://arxiv.org/abs/2407.14538</guid>
<content:encoded><![CDATA[
arXiv:2407.14538v1 Announce Type: new 
Abstract: Traditional Byzantine Fault Tolerance (BFT) state machine replication protocols assume a partial synchrony model, leading to a design where a leader replica drives the protocol and is replaced after a timeout. Recently, we witnessed a surge of asynchronous BFT protocols, which use randomization to remove the need for bounds on message delivery times, making them more resilient to adverse network conditions. However, existing research proposals still fall short of gaining practical adoption, plausibly because they are not able to combine good performance with a simple design that can be readily understood and adopted. In this paper, we present Alea-BFT, a simple and highly efficient asynchronous BFT protocol, which is gaining practical adoption, namely in Ethereum distributed validators. Alea-BFT brings the key design insight from classical protocols of concentrating part of the work on a single designated replica and incorporates this principle in a simple two-stage pipelined design, with an efficient broadcast led by the designated replica, followed by an inexpensive binary agreement. The evaluation of our research prototype implementation and two real-world integrations in cryptocurrency ecosystems shows excellent performance, improving on the fastest protocol (Dumbo-NG) in terms of latency and displaying good performance under faults.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Retrieval Augmented Generation Integrated Large Language Models in Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2407.14838</link>
<guid>https://arxiv.org/abs/2407.14838</guid>
<content:encoded><![CDATA[
arXiv:2407.14838v1 Announce Type: new 
Abstract: The rapid growth of Decentralized Finance (DeFi) has been accompanied by substantial financial losses due to smart contract vulnerabilities, underscoring the critical need for effective security auditing. With attacks becoming more frequent, the necessity and demand for auditing services has escalated. This especially creates a financial burden for independent developers and small businesses, who often have limited available funding for these services. Our study builds upon existing frameworks by integrating Retrieval-Augmented Generation (RAG) with large language models (LLMs), specifically employing GPT-4-1106 for its 128k token context window. We construct a vector store of 830 known vulnerable contracts, leveraging Pinecone for vector storage, OpenAI's text-embedding-ada-002 for embeddings, and LangChain to construct the RAG-LLM pipeline. Prompts were designed to provide a binary answer for vulnerability detection. We first test 52 smart contracts 40 times each against a provided vulnerability type, verifying the replicability and consistency of the RAG-LLM. Encouraging results were observed, with a 62.7% success rate in guided detection of vulnerabilities. Second, we challenge the model under a "blind" audit setup, without the vulnerability type provided in the prompt, wherein 219 contracts undergo 40 tests each. This setup evaluates the general vulnerability detection capabilities without hinted context assistance. Under these conditions, a 60.71% success rate was observed. While the results are promising, we still emphasize the need for human auditing at this time. We provide this study as a proof of concept for a cost-effective smart contract auditing process, moving towards democratic access to security.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Political Leanings in Web3 Betting: Decoding the Interplay of Political and Profitable Motives</title>
<link>https://arxiv.org/abs/2407.14844</link>
<guid>https://arxiv.org/abs/2407.14844</guid>
<content:encoded><![CDATA[
arXiv:2407.14844v1 Announce Type: new 
Abstract: Harnessing the transparent blockchain user behavior data, we construct the Political Betting Leaning Score (PBLS) to measure political leanings based on betting within Web3 prediction markets. Focusing on Polymarket and starting from the 2024 U.S. Presidential Election, we synthesize behaviors over 15,000 addresses across 4,500 events and 8,500 markets, capturing the intensity and direction of their political leanings by the PBLS. We validate the PBLS through internal consistency checks and external comparisons. We uncover relationships between our PBLS and betting behaviors through over 800 features capturing various behavioral aspects. A case study of the 2022 U.S. Senate election further demonstrates the ability of our measurement while decoding the dynamic interaction between political and profitable motives. Our findings contribute to understanding decision-making in decentralized markets, enhancing the analysis of behaviors within Web3 prediction environments. The insights of this study reveal the potential of blockchain in enabling innovative, multidisciplinary studies and could inform the development of more effective online prediction markets, improve the accuracy of forecast, and help the design and optimization of platform mechanisms. The data and code for the paper are accessible at the following link: https://github.com/anonymous.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AGORA: Open More and Trust Less in Binary Verification Service</title>
<link>https://arxiv.org/abs/2407.15062</link>
<guid>https://arxiv.org/abs/2407.15062</guid>
<content:encoded><![CDATA[
arXiv:2407.15062v1 Announce Type: new 
Abstract: Binary verification plays a pivotal role in software security, yet building a verification service that is both open and trustworthy poses a formidable challenge. In this paper, we introduce a novel binary verification service, AGORA, scrupulously designed to overcome the challenge. At the heart of this approach lies a strategic insight: certain tasks can be delegated to untrusted entities, while the corresponding validators are securely housed within the trusted computing base (TCB). AGORA can validate untrusted assertions generated for versatile policies. Through a novel blockchain-based bounty task manager, it also utilizes crowdsourcing to remove trust in theorem provers. These synergistic techniques successfully ameliorate the TCB size burden associated with two procedures: binary analysis and theorem proving. The design of AGORA allows untrusted parties to participate in these complex processes. Moreover, based on running the optimized TCB within trusted execution environments and recording the verification process on a blockchain, the public can audit the correctness of verification results. By implementing verification workflows for software-based fault isolation policy and side-channel mitigation, our evaluation demonstrates the efficacy of AGORA.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Secure Web Objects: Building Blocks for Metaverse Interoperability and Decentralization</title>
<link>https://arxiv.org/abs/2407.15221</link>
<guid>https://arxiv.org/abs/2407.15221</guid>
<content:encoded><![CDATA[
arXiv:2407.15221v1 Announce Type: new 
Abstract: This position paper explores how to support the Web's evolution through an underlying data-centric approach that better matches the data-orientedness of modern and emerging applications. We revisit the original vision of the Web as a hypermedia system that supports document composability and application interoperability via name-based data access. We propose the use of secure web objects (SWO), a data-oriented communication approach that can reduce complexity, centrality, and inefficiency, particularly for collaborative and local-first applications, such as the Metaverse and other collaborative applications. SWO are named, signed, application-defined objects that are secured independently of their containers or communications channels, an approach that leverages the results from over a decade-long data-centric networking research. This approach does not require intermediation by aggregators of identity, storage, and other services that are common today. We present a brief design overview, illustrated through prototypes for two editors of shared hypermedia documents: one for 3D and one for LaTeX. We also discuss our findings and suggest a roadmap for future research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Exploring the Design of Collaborative Applications via the Lens of NDN Workspace</title>
<link>https://arxiv.org/abs/2407.15234</link>
<guid>https://arxiv.org/abs/2407.15234</guid>
<content:encoded><![CDATA[
arXiv:2407.15234v1 Announce Type: new 
Abstract: Metaverse applications desire to communicate with semantically identified objects among a diverse set of cyberspace entities, such as cameras for collecting images from, sensors for sensing environment, and users collaborating with each other, all could be nearby or far away, in a timely and secure way. However, supporting the above function faces networking challenges. Today's metaverse implementations are, by and large, use secure transport connections to communicate with cloud servers instead of letting participating entities communicate directly. In this paper, we use the design and implementation of NDN Workspace, a web-based, multi-user collaborative app to showcase a new way to networking that supports many-to-many secure data exchanges among communicating entities directly. NDN Workspace users establish trust relations among each other, exchange URI-identified objects directly, and can collaborate through intermittent connectivity, all in the absence of cloud servers. Its data-centric design offers an exciting new approach to metaverse app development.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Sustainable broadcasting in Blockchain Network with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2407.15616</link>
<guid>https://arxiv.org/abs/2407.15616</guid>
<content:encoded><![CDATA[
arXiv:2407.15616v1 Announce Type: new 
Abstract: Recent estimates put the carbon footprint of Bitcoin and Ethereum at an average of 64 and 26 million tonnes of CO2 per year, respectively. To address this growing problem, several possible approaches have been proposed in the literature: creating alternative blockchain consensus mechanisms, applying redundancy reduction techniques, utilizing renewable energy sources, and employing energy-efficient devices, etc. In this paper, we follow the second avenue and propose an efficient approach based on reinforcement learning that improves the block broadcasting scheme in blockchain networks. The analysis and experimental results confirmed that the proposed improvement of the block propagation scheme could cleverly handle network dynamics and achieve better results than the default approach. Additionally, our technical integration of the simulator and developed RL environment can be used as a complete solution for further study of new schemes and protocols that use RL or other ML techniques.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dressed to Gamble: How Poker Drives the Dynamics of Wearables and Visits on Decentraland's Social Virtual World</title>
<link>https://arxiv.org/abs/2407.15625</link>
<guid>https://arxiv.org/abs/2407.15625</guid>
<content:encoded><![CDATA[
arXiv:2407.15625v1 Announce Type: new 
Abstract: Decentraland is a blockchain-based social virtual world touted to be a creative space owned by its community, unlike previous virtual worlds. Its users can create and publish wearables, virtual garments to customize avatars, which can be then sold or given away via the blockchain. Decentral Games (DG), a single project owning two prominent in-world casinos, has by far created the most wearables, with these being necessary to earn cryptocurrency in their flagship game ICE Poker. We thus present a comprehensive study that investigates how DG and ICE Poker influence the overall dynamics of Decentraland wearables and in-world visits. To this end, we analyzed 5.9 million wearable transfers made on the Polygon blockchain (and related sales) over a two-year period, and 677 million log events of in-world user positions in an overlapping 10-month period. We found that the influence of DG and Ice Poker is not only significant, but also substantial for transfers and sales monetary value of wearables, and very large for daily unique visitors and time spent in the virtual world. Despite several alternative in-world economic and artistic initiatives in Decentraland, some of which have attracted much attention from the general public, online poker appears to be the main driver of the analyzed dynamics. Our work thus contributes to the current understanding of user behavior in social virtual worlds and it is among the first to study the emerging phenomenon of blockchain-based online gambling in virtual spaces.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Preventing Out-of-Gas Exceptions by Typing</title>
<link>https://arxiv.org/abs/2407.15676</link>
<guid>https://arxiv.org/abs/2407.15676</guid>
<content:encoded><![CDATA[
arXiv:2407.15676v1 Announce Type: new 
Abstract: We continue the development of TinySol, a minimal object-oriented language based on Solidity, the standard smart-contract language used for the Ethereum platform. We first extend TinySol with exceptions and a gas mechanism, and equip it with a small-step operational semantics. Introducing the gas mechanism is fundamental for modelling real-life smart contracts in TinySol, since this is the way in which termination of Ethereum smart contracts is usually ensured. We then devise a type system for smart contracts guaranteeing that such programs never run out of gas at runtime. This is a desirable property for smart contracts, since a transaction that runs out of gas is aborted, but the price paid to run the code is not returned to the invoker.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cryptoeconomics and Tokenomics as Economics: A Survey with Opinions</title>
<link>https://arxiv.org/abs/2407.15715</link>
<guid>https://arxiv.org/abs/2407.15715</guid>
<content:encoded><![CDATA[
arXiv:2407.15715v1 Announce Type: new 
Abstract: This paper surveys products and studies on cryptoeconomics and tokenomics from an economic perspective, as these terms are still (i) ill-defined and (ii) disconnected from economic disciplines. We first suggest that they can be novel when integrated; we then conduct a literature review and case study following consensus-building for decentralization and token value for autonomy. Integration requires simultaneous consideration of strategic behavior, spamming, Sybil attacks, free-riding, marginal cost, marginal utility and stabilizers. This survey is the first systematization of knowledge on cryptoeconomics and tokenomics, aiming to bridge the contexts of economics and blockchain.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Entropic Optimal Transport for Distributed Distribution Comparison</title>
<link>https://arxiv.org/abs/2301.12065</link>
<guid>https://arxiv.org/abs/2301.12065</guid>
<content:encoded><![CDATA[
arXiv:2301.12065v2 Announce Type: replace 
Abstract: Distributed distribution comparison aims to measure the distance between the distributions whose data are scattered across different agents in a distributed system and cannot even be shared directly among the agents. In this study, we propose a novel decentralized entropic optimal transport (DEOT) method, which provides a communication-efficient and privacy-preserving solution to this problem with theoretical guarantees. In particular, we design a mini-batch randomized block-coordinate descent (MRBCD) scheme to optimize the DEOT distance in its dual form. The dual variables are scattered across different agents and updated locally and iteratively with limited communications among partial agents. The kernel matrix involved in the gradients of the dual variables is estimated by a decentralized kernel approximation method, in which each agent only needs to approximate and store a sub-kernel matrix by one-shot communication and without sharing raw data. Besides computing entropic Wasserstein distance, we show that the proposed MRBCD scheme and kernel approximation method also apply to entropic Gromov-Wasserstein distance. We analyze our method's communication complexity and, under mild assumptions, provide a theoretical bound for the approximation error caused by the convergence error, the estimated kernel, and the mismatch between the storage and communication protocols. In addition, we discuss the trade-off between the precision of the EOT distance and the strength of privacy protection when implementing our method. Experiments on synthetic data and real-world distributed domain adaptation tasks demonstrate the effectiveness of our method.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BAFFLE: A Baseline of Backpropagation-Free Federated Learning</title>
<link>https://arxiv.org/abs/2301.12195</link>
<guid>https://arxiv.org/abs/2301.12195</guid>
<content:encoded><![CDATA[
arXiv:2301.12195v3 Announce Type: replace 
Abstract: Federated learning (FL) is a general principle for decentralized clients to train a server model collectively without sharing local data. FL is a promising framework with practical applications, but its standard training paradigm requires the clients to backpropagate through the model to compute gradients. Since these clients are typically edge devices and not fully trusted, executing backpropagation on them incurs computational and storage overhead as well as white-box vulnerability. In light of this, we develop backpropagation-free federated learning, dubbed BAFFLE, in which backpropagation is replaced by multiple forward processes to estimate gradients. BAFFLE is 1) memory-efficient and easily fits uploading bandwidth; 2) compatible with inference-only hardware optimization and model quantization or pruning; and 3) well-suited to trusted execution environments, because the clients in BAFFLE only execute forward propagation and return a set of scalars to the server. Empirically we use BAFFLE to train deep models from scratch or to finetune pretrained models, achieving acceptable results. Code is available in https://github.com/FengHZ/BAFFLE.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>TrustRate: A Decentralized Platform for Hijack-Resistant Anonymous Reviews</title>
<link>https://arxiv.org/abs/2402.18386</link>
<guid>https://arxiv.org/abs/2402.18386</guid>
<content:encoded><![CDATA[
arXiv:2402.18386v3 Announce Type: replace 
Abstract: Reviews and ratings by users form a central component in several widely used products today (e.g., product reviews, ratings of online content, etc.), but today's platforms for managing such reviews are ad-hoc and vulnerable to various forms of tampering and hijack by fake reviews either by bots or motivated paid workers. We define a new metric called 'hijack-resistance' for such review platforms, and then present TrustRate, an end-to-end decentralized, hijack-resistant platform for authentic, anonymous, tamper-proof reviews. With a prototype implementation and evaluation at the scale of thousands of nodes, we demonstrate the efficacy and performance of our platform, towards a new paradigm for building products based on trusted reviews by end users without having to trust a single organization that manages the reviews.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Stochastic optimization with arbitrary recurrent data sampling</title>
<link>https://arxiv.org/abs/2401.07694</link>
<guid>https://arxiv.org/abs/2401.07694</guid>
<content:encoded><![CDATA[
arXiv:2401.07694v2 Announce Type: replace-cross 
Abstract: For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expected amount of time to visit a given data point either averaged (`target time') or supremized (`hitting time') over the current location. We demonstrate theoretically and empirically that convergence can be accelerated by selecting sampling algorithms that cover the data set most effectively. We discuss applications of our general framework to decentralized optimization and distributed non-negative matrix factorization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities</title>
<link>https://arxiv.org/abs/2406.11636</link>
<guid>https://arxiv.org/abs/2406.11636</guid>
<content:encoded><![CDATA[
arXiv:2406.11636v2 Announce Type: replace-cross 
Abstract: Segmentation models for brain lesions in MRI are commonly developed for a specific disease and trained on data with a predefined set of MRI modalities. Each such model cannot segment the disease using data with a different set of MRI modalities, nor can it segment any other type of disease. Moreover, this training paradigm does not allow a model to benefit from learning from heterogeneous databases that may contain scans and segmentation labels for different types of brain pathologies and diverse sets of MRI modalities. Additionally, the sensitivity of patient data often prevents centrally aggregating data, necessitating a decentralized approach. Is it feasible to use Federated Learning (FL) to train a single model on client databases that contain scans and labels of different brain pathologies and diverse sets of MRI modalities? We demonstrate promising results by combining appropriate, simple, and practical modifications to the model and training strategy: Designing a model with input channels that cover the whole set of modalities available across clients, training with random modality drop, and exploring the effects of feature normalization methods. Evaluation on 7 brain MRI databases with 5 different diseases shows that such FL framework can train a single model that is shown to be very promising in segmenting all disease types seen during training. Importantly, it is able to segment these diseases in new databases that contain sets of modalities different from those in training clients. These results demonstrate, for the first time, the feasibility and effectiveness of using Federated Learning to train a single 3D segmentation model on decentralised data with diverse brain diseases and MRI modalities, a necessary step towards leveraging heterogeneous real-world databases. Code will be made available at: https://github.com/FelixWag/FL-MultiDisease-MRI
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SecureVAX: A Blockchain-Enabled Secure Vaccine Passport System</title>
<link>https://arxiv.org/abs/2407.13852</link>
<guid>https://arxiv.org/abs/2407.13852</guid>
<content:encoded><![CDATA[
<div> 关键词：疫苗护照、区块链、智能合约、InterPlanetary File System (IPFS)、Ethereum。

总结:<br />
本文提出了一种基于区块链技术的新型疫苗护照系统，旨在解决现有系统的伪造、隐私和数据安全问题。该方案利用智能合约确保数据准确性和安全性，通过IPFS实现加密存储，防止个人信息泄露。原型在以太坊Sepolia测试网络上构建，评估了系统的性能和有效性。这一结合分布式存储与去中心化区块链的解决方案，旨在促进全球范围内疫苗接种管理的高效、安全和互操作性，支持全球范围内的全面疫苗接种计划。 <div>
arXiv:2407.13852v1 Announce Type: new 
Abstract: A vaccine passport serves as documentary proof, providing passport holders with greater freedom while roaming around during pandemics. It confirms vaccination against certain infectious diseases like COVID-19, Ebola, and flu. The key challenges faced by the digital vaccine passport system include passport forgery, unauthorized data access, and inaccurate information input by vaccination centers. Privacy concerns also need to be addressed to ensure that the user's personal identification information (PII) is not compromised. Additionally, it is necessary to track vaccine vials or doses to verify their authenticity, prevent misuse and illegal sales, as well as to restrict the illicit distribution of vaccines. To address these challenges, we propose a Blockchain-Enabled Secure Vaccine Passport System, leveraging the power of smart contracts. Our solution integrates off-chain and on-chain cryptographic computations, facilitating secure communication among various entities. We have utilized the InterPlanetary File System (IPFS) to store encrypted vaccine passports of citizens securely. Our prototype is built on the Ethereum platform, with smart contracts deployed on the Sepolia Test network, allowing for performance evaluation and validation of the system's effectiveness. By combining IPFS as a distributed data storage platform and Ethereum as a blockchain platform, our solution paves the way for secure, efficient, and globally interoperable vaccine passport management, supporting comprehensive vaccination initiatives worldwide.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-agent Coverage Control: From Discrete Assignments to Continuous Multi-agent Distribution Matching</title>
<link>https://arxiv.org/abs/2407.13890</link>
<guid>https://arxiv.org/abs/2407.13890</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent, spatial coverage, deployment strategies, discrete-task assignments, continuum task assignment

总结:<br />这篇论文探讨了多代理空间覆盖控制问题，这是一个广泛研究领域，涉及动态和静态部署、任务分配以及空间分布匹配。研究内容包括集中式或分散的本地交互方案，适用于有限资源和任务的离散描述，以及连续元素的混合或完全连续的情况。文章重点介绍了三种方法：<br />1) 静态覆盖通过并发区域划分和分配；<br />2) 将静态覆盖视为离散任务分配；<br />3) 大规模群体的连续任务分配。作者旨在揭示这些问题的共同特征，并引导读者关注相关的新研究方向。 <div>
arXiv:2407.13890v1 Announce Type: new 
Abstract: The multi-agent spatial coverage control problem encompasses a broad research domain, dealing with both dynamic and static deployment strategies, discrete-task assignments, and spatial distribution-matching deployment. Coverage control may involve the deployment of a finite number of agents or a continuum through centralized or decentralized, locally-interacting schemes. All these problems can be solved via a different taxonomy of deployment algorithms for multiple agents. Depending on the application scenario, these problems involve from purely discrete descriptions of tasks (finite loads) and agents (finite resources), to a mixture of discrete and continuous elements, to fully continuous descriptions of the same. Yet, it is possible to find common features that underline all the above formulations, which we aim to illustrate here. By doing so, we aim to point the reader to novel references related to these problems. The short article outline is the following: Static coverage via concurrent area partitioning and assignment; Static coverage as a discrete task assignment; and Continuum task assignment for large-scale swarms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Who Wins Ethereum Block Building Auctions and Why?</title>
<link>https://arxiv.org/abs/2407.13931</link>
<guid>https://arxiv.org/abs/2407.13931</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV-Boost、block auction、Ethereum、centralization、order flow

总结:
MEV-Boost块拍卖在以太坊中占据重要地位，贡献了约90%的区块。本文通过六个月的实证分析揭示了几个关键因素对区块建设者竞争力的影响。首先，多样化的订单流与市场占有率正相关；其次，独家供应商（如整合搜索者和有排他协议的外部提供者）的订单流对利润至关重要。顶级建设者的市场份额和利润率增加，受益于独家信号、非原子套利和Telegram流量等特征。这种现象形成了一种循环，即建设者需要差异化订单流才能盈利，而只有拥有较大份额时才可能获取。研究结果强调了维持以太坊去中心化和抗审查性的必要性，为改进拍卖设计提供了见解。 <div>
arXiv:2407.13931v1 Announce Type: new 
Abstract: The MEV-Boost block auction contributes approximately 90% of all Ethereum blocks. Between October 2023 and March 2024, only three builders produced 80% of them, highlighting the concentration of power within the block builder market. To foster competition and preserve Ethereum's decentralized ethos and censorship-resistance properties, understanding the dominant players' competitive edges is essential.
  In this paper, we identify features that play a significant role in builders' ability to win blocks and earn profits by conducting a comprehensive empirical analysis of MEV-Boost auctions over a six-month period. We reveal that block market share positively correlates with order flow diversity, while profitability correlates with access to order flow from Exclusive Providers, such as integrated searchers and external providers with exclusivity deals. Additionally, we show a positive correlation between market share and profit margin among the top ten builders, with features such as exclusive signal, non-atomic arbitrages, and Telegram bot flow strongly correlating with both metrics. This highlights a "chicken-and-egg" problem where builders need differentiated order flow to profit, but only receive such flow if they have a significant market share. Overall, this work provides an in-depth analysis of the key features driving the builder market towards centralization and offers valuable insights for designing further iterations of Ethereum block auctions, preserving Ethereum's censorship resistance properties.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A trustworthy blockchain-based energy trading scheme for V2G operations in distributed power grids via integrated scheduling and trading framework</title>
<link>https://arxiv.org/abs/2407.13988</link>
<guid>https://arxiv.org/abs/2407.13988</guid>
<content:encoded><![CDATA[
<div> 关键词：electric vehicles (EVs), vehicle-to-grid (V2G), blockchain, smart charging points (SCPs), fast-path practical Byzantine fault tolerance (PBFT).

总结:<br />
本文提出了一种集成的调度和交易框架，以应对电动汽车(V2G)对分布式电网的挑战。研究采用区块链技术，构建了基于智能充电桩(SCPs)的网络安全架构，利用快速路径实用拜占庭容错(fast-path PBFT)协议提高交易效率和可扩展性。通过博弈论定价策略和智能合约，实现电动汽车和运营商之间的自主决策，优化交易并提升经济效益。实验结果显示，该方法在SUSTech的实际数据上有效降低充电成本，并能支持辅助电网服务。区块链共识机制的改进在保证系统稳健的同时，显著提高了系统的扩展性。 <div>
arXiv:2407.13988v1 Announce Type: new 
Abstract: The rapid growth of electric vehicles (EVs) and the deployment of vehicle-to-grid (V2G) technology pose significant challenges for distributed power grids, particularly in fostering trust and ensuring effective coordination among stakeholders. In this paper, we developed an integrated scheduling and trading framework to conduct transparent and efficacious coordination in V2G operations. In blockchain implementation, we propose a cyber-physical blockchain architecture that enhances transaction efficiency and scalability by leveraging smart charging points (SCPs) for rapid transaction validation through a fast-path practical byzantine fault tolerance (fast-path PBFT) consensus mechanism. From the energy dispatching perspective, a game-theoretical pricing strategy is employed and smart contracts are utilized for autonomous decision-making between EVs and operators, aiming to optimize the trading process and maximize economic benefits. Numerical evaluation of blockchain consensus shows the effect of the fast-path PBFT consensus in improving systems scalability with a balanced trade-off in robustness. A case study, utilizing real-world data from the Southern University of Science and Technology (SUSTech), demonstrates significant reductions in EV charging costs and the framework potential to support auxiliary grid services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Theoretical Analysis on Block Time Distributions in Byzantine Fault-Tolerant Consensus Blockchains</title>
<link>https://arxiv.org/abs/2407.14299</link>
<guid>https://arxiv.org/abs/2407.14299</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine fault tolerance, proof-of-stake, block creation time, block propagation, block validation.

总结:<br />该论文研究了基于拜占庭容错共识的区块链网络，如Cosmos和Tezos，其特点在于证明权益机制。文章关注区块创建时间的波动性，提出数学模型分析传播验证过程。研究发现，节点间广播时间遵循Gumbel分布，且区块时间分布源于多Gumbel分布的卷积。作者还给出了适用于数据分析的近似公式，并通过实际数据验证了该模型的有效性，能够估计区块时间分布参数。这为理解此类区块链的时间行为提供了理论支持。 <div>
arXiv:2407.14299v1 Announce Type: new 
Abstract: Some blockchain networks employ a distributed consensus algorithm featuring Byzantine fault tolerance. Notably, certain public chains, such as Cosmos and Tezos, which operate on a proof-of-stake mechanism, have adopted this algorithm. While it is commonly assumed that these blockchains maintain a nearly constant block creation time, empirical analysis reveals fluctuations in this interval; this phenomenon has received limited attention. In this paper, we propose a mathematical model to account for the processes of block propagation and validation within Byzantine fault-tolerant consensus blockchains, aiming to theoretically analyze the probability distribution of block time. First, we propose stochastic processes governing the broadcasting communications among validator nodes. Consequently, we theoretically demonstrate that the probability distribution of broadcast time among validator nodes adheres to the Gumbel distribution. This finding indicates that the distribution of block time typically arises from convolving multiple Gumbel distributions. Additionally, we derive an approximate formula for the block time distribution suitable for data analysis purposes. By fitting this approximation to real-world block time data, we demonstrate the consistent estimation of block time distribution parameters.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Unravelling in Collaborative Learning</title>
<link>https://arxiv.org/abs/2407.14332</link>
<guid>https://arxiv.org/abs/2407.14332</guid>
<content:encoded><![CDATA[
<div> 关键词：collaborative learning, strategic agents, data quality, adverse selection, probabilistic verification

总结:<br />本文关注协作学习中的策略性行为，探讨了数据质量差异情况下，战略学习者组成的联盟可能遭遇“瓦解”现象。当数据质量信息不对称时，质量较差的参与者可能导致联盟收缩甚至消失。为解决这一问题，作者提出了一种基于概率验证的新方法，通过设计机制使优质和劣质数据都能公平参与，从而使得整体联盟成为纳什均衡，防止了“瓦解”现象的发生。这种方法无需外部转移，有效应对了信息不透明带来的挑战。 <div>
arXiv:2407.14332v1 Announce Type: new 
Abstract: Collaborative learning offers a promising avenue for leveraging decentralized data. However, collaboration in groups of strategic learners is not a given. In this work, we consider strategic agents who wish to train a model together but have sampling distributions of different quality. The collaboration is organized by a benevolent aggregator who gathers samples so as to maximize total welfare, but is unaware of data quality. This setting allows us to shed light on the deleterious effect of adverse selection in collaborative learning. More precisely, we demonstrate that when data quality indices are private, the coalition may undergo a phenomenon known as unravelling, wherein it shrinks up to the point that it becomes empty or solely comprised of the worst agent. We show how this issue can be addressed without making use of external transfers, by proposing a novel method inspired by probabilistic verification. This approach makes the grand coalition a Nash equilibrium with high probability despite information asymmetry, thereby breaking unravelling.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Stackelberg POMDP: A Reinforcement Learning Approach for Economic Design</title>
<link>https://arxiv.org/abs/2210.03852</link>
<guid>https://arxiv.org/abs/2210.03852</guid>
<content:encoded><![CDATA[
<div> 关键词：reinforcement learning, Stackelberg game, POMDP, no-regret learners, mechanism design

总结:<br />
本文提出了一种强化学习框架，将环境设计师（领导者）与参与者之间的互动建模为Stackelberg博弈。研究者构建了一个称为Stackelberg POMDP的决策过程模型，证明了在有限策略集下，Stackelberg博弈中的最优领导策略等于该POMDP的最优策略。针对跟随者采用无后悔学习者的假设，文章处理了复杂情境，如交替机制设计和有限交流。通过实验验证了训练框架的有效性，并扩展了关于粗相关均衡的收敛结果。这种方法有助于经济设计中智能规则制定。 <div>
arXiv:2210.03852v4 Announce Type: replace 
Abstract: We introduce a reinforcement learning framework for economic design where the interaction between the environment designer and the participants is modeled as a Stackelberg game. In this game, the designer (leader) sets up the rules of the economic system, while the participants (followers) respond strategically. We integrate algorithms for determining followers' response strategies into the leader's learning environment, providing a formulation of the leader's learning problem as a POMDP that we call the Stackelberg POMDP. We prove that the optimal leader's strategy in the Stackelberg game is the optimal policy in our Stackelberg POMDP under a limited set of possible policies, establishing a connection between solving POMDPs and Stackelberg games. We solve our POMDP under a limited set of policy options via the centralized training with decentralized execution framework. For the specific case of followers that are modeled as no-regret learners, we solve an array of increasingly complex settings, including problems of indirect mechanism design where there is turn-taking and limited communication by agents. We demonstrate the effectiveness of our training framework through ablation studies. We also give convergence results for no-regret learners to a Bayesian version of a coarse-correlated equilibrium, extending known results to correlated types.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Liquid Staking Tokens in Automated Market Makers</title>
<link>https://arxiv.org/abs/2403.10226</link>
<guid>https://arxiv.org/abs/2403.10226</guid>
<content:encoded><![CDATA[
<div> 关键词：liquid staking tokens (LSTs), automated market makers (AMMs), theoretical modeling, empirical analysis, Ethereum LSTs.

总结:<br />
本文研究了去中心化金融(DeFi)中的液态抵押代币(LSTs)在自动市场 maker(AMM)上的流动性。首先，理论模型探讨了哪种类型的AMM最适合LST流动性，并推导出交易费用需要提供足够补偿的公式，以应对LST价格波动导致的损失。文章关注两点：1)与将资金存入AMM外相比，持有LST的损失（"impermanent loss"）；2)相较于全额抵押，为LST提供流动性的相对盈利能力。实证分析发现，尽管交易费通常能弥补损失，但全押在某些情况下更赚钱，这引发了对当前LST在AMM中流动性分配可持续性的质疑。 <div>
arXiv:2403.10226v2 Announce Type: replace 
Abstract: This paper studies liquid staking tokens (LSTs) on automated market makers (AMMs), both theoretically and empirically. LSTs are tokenized representations of staked assets on proof-of-stake blockchains. First, we model LST-liquidity on AMMs theoretically, categorizing suitable AMM types for LST liquidity and deriving formulas for the necessary returns from trading fees to adequately compensate liquidity providers under the particular price trajectories of LSTs. For the latter, two relevant metrics are considered: (1) losses compared to holding the liquidity outside the AMM (loss-versus-holding, or "impermanent loss"), and (2) the relative profitability compared to fully staking the capital (loss-versus-staking) which is specifically tailored to the case of LST-liquidity. Next, we empirically measure these metrics for Ethereum LSTs across the most relevant AMM pools. We find that, while trading fees often compensate for impermanent loss, fully staking is more profitable for many pools, raising questions about the sustainability of the current LST liquidity allocation to AMMs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The need of a self for self-driving cars a theoretical model applying homeostasis to self driving</title>
<link>https://arxiv.org/abs/2407.12795</link>
<guid>https://arxiv.org/abs/2407.12795</guid>
<content:encoded><![CDATA[
<div> 关键词：self-driving cars, homeostatic architecture, inward sensors, outward sensors, blockchain technology

总结:<br />
本文探讨了一种新颖的自动驾驶汽车"自我"构建理念，基于家态架构。该架构强调通过内在传感器监测车辆状态（如金属部件、电池等），并利用外向传感器（如相机和LIDAR）评估对家态的影响，而非直接模仿人类视觉理解现实。虚拟环境被用于加速训练，车辆间通过区块链技术交流学习，避免重复错误。文章还提出了专为自动驾驶设计的语言，以支持精细的数据解读和响应。这种动态调整行为的方法促进了合作与持续优化。这一研究对于AI发展、应用及未来研究方向具有深远影响。 <div>
arXiv:2407.12795v1 Announce Type: new 
Abstract: This paper explores the concept of creating a "self" for self-driving cars through a homeostatic architecture designed to enhance their autonomy, safety, and efficiency. The proposed system integrates inward focused sensors to monitor the car's internal state, such as the condition of its metal bodywork, wheels, engine, and battery, establishing a baseline homeostatic state representing optimal functionality. Outward facing sensors, like cameras and LIDAR, are then interpreted via their impact on the car's homeostatic state by quantifying deviations from homeostasis. This contrasts with the approach of trying to make cars "see" reality in a similar way to humans and identify elements in their reality in the same way humans. Virtual environments would be leveraged to accelerate training. Additionally, cars are programmed to communicate and share experiences via blockchain technology, learning from each other's mistakes while maintaining individualized training models. A dedicated language for self-driving cars is proposed to enable nuanced interpretation and response to environmental data. This architecture allows self-driving cars to dynamically adjust their behavior based on internal and external feedback, promoting cooperation and continuous improvement. The study concludes by discussing the broader implications for AI development, potential real-world applications, and future research directions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Framework for testing Federated Learning algorithms using an edge-like environment</title>
<link>https://arxiv.org/abs/2407.12980</link>
<guid>https://arxiv.org/abs/2407.12980</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Edge Computing, Data Imbalance, Class Imbalance, Kubernetes.

总结:<br />Federated Learning (FL)是一种分布式机器学习方法，旨在保护数据隐私并提高边缘计算效率。然而，处理各客户端数据分布不均（数据不平衡或类别不平衡）是一个挑战。本文提出了一种框架，旨在简化和扩展评估FL算法的过程。该框架在基于容器编排平台Kubernetes的分布式边缘环境中进行了测试，为理解和优化FL性能提供了一种实用工具。 <div>
arXiv:2407.12980v1 Announce Type: new 
Abstract: Federated Learning (FL) is a machine learning paradigm in which many clients cooperatively train a single centralized model while keeping their data private and decentralized. FL is commonly used in edge computing, which involves placing computer workloads (both hardware and software) as close as possible to the edge, where the data is being created and where actions are occurring, enabling faster response times, greater data privacy, and reduced data transfer costs. However, due to the heterogeneous data distributions/contents of clients, it is non-trivial to accurately evaluate the contributions of local models in global centralized model aggregation. This is an example of a major challenge in FL, commonly known as data imbalance or class imbalance. In general, testing and assessing FL algorithms can be a very difficult and complex task due to the distributed nature of the systems. In this work, a framework is proposed and implemented to assess FL algorithms in a more easy and scalable way. This framework is evaluated over a distributed edge-like environment managed by a container orchestration platform (i.e. Kubernetes).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Automated Gateways: A Smart Contract-Powered Solution for Interoperability Across Blockchains</title>
<link>https://arxiv.org/abs/2407.13001</link>
<guid>https://arxiv.org/abs/2407.13001</guid>
<content:encoded><![CDATA[
<div> 关键词：Interoperability, Blockchain, Automated Gateways, Smart contracts, Cross-chain interactions.

总结:<br />本文探讨了区块链技术中的一个重要挑战——互操作性问题，阻碍了不同区块链网络间的数据和服务共享。作者提出了一种创新框架——自动门禁（Automated Gateways），它利用智能合约直接与区块链基础设施集成，提供内置的互操作性功能。通过精细访问控制机制，智能合约管理跨链交互的权限，简化服务在不同区块链之间的共享，同时保证交易的完整性和安全性。这个用户友好、自我管理权限且独立于外部平台的框架旨在促进区块链社区的更广泛应用。 <div>
arXiv:2407.13001v1 Announce Type: new 
Abstract: Interoperability is a significant challenge in blockchain technology, hindering seamless data and service sharing across diverse blockchain networks. This study introduces \textit {Automated Gateways} as a novel framework leveraging smart contracts to facilitate interoperability. Unlike existing solutions, which often require adopting new technologies or relying on external services, Automated Gateways framework is integrated directly with a blockchain's core infrastructure to enhance systems with built-in interoperability features. By implementing fine-grained access control mechanisms, smart contracts within this framework manage accessibility and authorization for cross-chain interactions and facilitate streamlining the selective sharing of services between blockchains. Our evaluation demonstrates the framework's capability to handle cross-chain interactions efficiently, significantly reduce operational complexities, and uphold transactional integrity and security across different blockchain networks. With its focus on user-friendliness, self-managed permissions, and independence from external platforms, this framework is designed to achieve broader adoption within the blockchain community.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Proof-of-Collaborative-Learning: A Multi-winner Federated Learning Consensus Algorithm</title>
<link>https://arxiv.org/abs/2407.13018</link>
<guid>https://arxiv.org/abs/2407.13018</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof-of-Work, Proof-of-Collaborative-Learning, federated learning, consensus mechanism, incentive mechanism

总结:
这篇文章提出了一种新的共识机制——Proof-of-Collaborative-Learning (PoCL)，它将区块链的计算能力转向联邦学习模型的训练。PoCL是一种多赢家机制，矿工们通过本地训练模型参与竞争，而文章设计了评估机制确保模型效率，并对可能的攻击进行了安全评估。此外，文章还介绍了一个公平的奖励分配系统，既激励获胜矿工，也保证了跨轮次的公平性。总的来说，PoCL旨在提高能源效率并重新定义区块链的激励结构，以适应分布式学习环境。 <div>
arXiv:2407.13018v1 Announce Type: new 
Abstract: Regardless of their variations, blockchains require a consensus mechanism to validate transactions, supervise added blocks, maintain network security, synchronize the network state, and distribute incentives. Proof-of-Work (PoW), one of the most influential implementations of consensus mechanisms, consumes an extraordinary amount of energy for a task that lacks direct productive output. In this paper, we propose Proof-of-Collaborative-Learning (PoCL), a multi-winner federated learning validated consensus mechanism that redirects the computation power of blockchains to train federated learning models. In addition, we present a novel evaluation mechanism to ensure the efficiency of the locally trained models of miners. We evaluated the security of our evaluation mechanism by introducing and conducting probable attacks. Moreover, we present a novel reward distribution mechanism to incentivize winning miners fairly, and demonstrate that our reward system is fair both within and across all rounds.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Identifying Smart Contract Security Issues in Code Snippets from Stack Overflow</title>
<link>https://arxiv.org/abs/2407.13271</link>
<guid>https://arxiv.org/abs/2407.13271</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contract, Stack Overflow (SO), code snippets, vulnerabilities, SOChecker.

总结:<br />本文研究了智能合约开发者在Stack Overflow上寻求问题解答时，对来自该平台的代码片段直接集成到智能合约可能带来的安全风险。大部分开发者（86.4%）在重用代码时忽视了安全性。目前的智能合约安全检测工具对不完整的代码片段效果不佳。为解决这个问题，作者提出了SOChecker，这是首个针对Stack Overflow智能合约相关代码片段的漏洞检测工具。SOChecker利用Llama2模型进行代码补全，然后应用符号执行方法检测漏洞。实验结果表明，SOChecker在897个代码片段测试集上的F1分数达到68.2%，远超GPT-3.5和GPT-4的20.9%和33.2%。研究强调了改进Q&amp;A网站代码片段安全性的必要性。 <div>
arXiv:2407.13271v1 Announce Type: new 
Abstract: Smart contract developers frequently seak solutions to developmental challenges on Q&amp;A platforms such as Stack Overflow (SO). Although community responses often provide viable solutions, the embedded code snippets can also contain hidden vulnerabilities. Integrating such code directly into smart contracts may make them susceptible to malicious attacks. We conducted an online survey and received 74 responses from smart contract developers. The results of this survey indicate that the majority (86.4%) of participants do not sufficiently consider security when reusing SO code snippets. Despite the existence of various tools designed to detect vulnerabilities in smart contracts, these tools are typically developed for analyzing fully-completed smart contracts and thus are ineffective for analyzing typical code snippets as found on SO. We introduce SOChecker, the first tool designed to identify potential vulnerabilities in incomplete SO smart contract code snippets. SOChecker first leverages a fine-tuned Llama2 model for code completion, followed by the application of symbolic execution methods for vulnerability detection. Our experimental results, derived from a dataset comprising 897 code snippets collected from smart contract-related SO posts, demonstrate that SOChecker achieves an F1 score of 68.2%, greatly surpassing GPT-3.5 and GPT-4 (20.9% and 33.2% F1 Scores respectively). Our findings underscore the need to improve the security of code snippets from Q&amp;A websites.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralised Governance for Autonomous Cyber-Physical Systems</title>
<link>https://arxiv.org/abs/2407.13566</link>
<guid>https://arxiv.org/abs/2407.13566</guid>
<content:encoded><![CDATA[
<div> 关键词：Cyber-Physical Systems (CPS), Decentralised Governance, Blockchain, Decentralised Autonomous Organisations (DAOs), Autonomous Cabin (no1s1).

总结:<br />
本文探讨了利用区块链技术实现Cyber-Physical Systems (CPS) 的去中心化治理的可能性。通过研究将计算集成到物理领域的Decentralised Autonomous Organisations (DAOs)，如自主小屋"no1s1"的例子，文章强调了区块链在管理自治物理系统中的作用。文章指出，这种自治不仅涉及技术挑战，还涉及到复杂的功能性和社会动态。作者提出，为了应对预期和突发问题，需要开发连续反馈回路和适应性治理框架。研究对基础设施研究和CPS工程领域有重要影响，为未来关于去中心化管理和物理空间自治的讨论提供了实践洞察和理论框架。 <div>
arXiv:2407.13566v1 Announce Type: new 
Abstract: This paper examines the potential for Cyber-Physical Systems (CPS) to be governed in a decentralised manner, whereby blockchain-based infrastructure facilitates the communication between digital and physical domains through self-governing and self-organising principles. Decentralised governance paradigms that integrate computation in physical domains (such as 'Decentralised Autonomous Organisations' (DAOs)) represent a novel approach to autono-mous governance and operations. These have been described as akin to cybernetic systems. Through the lens of a case study of an autonomous cabin called "no1s1" which demonstrates self-ownership via blockchain-based control and feedback loops, this research explores the potential for blockchain infrastructure to be utilised in the management of physical systems. By highlighting the considerations and challenges of decentralised governance in managing autonomous physical spaces, the study reveals that autonomy in the governance of autonomous CPS is not merely a technological feat but also involves a complex mesh of functional and social dynamics. These findings underscore the importance of developing continuous feedback loops and adaptive governance frameworks within decentralised CPS to address both expected and emergent challenges. This investigation contributes to the fields of infra-structure studies and Cyber-Physical Systems engineering. It also contributes to the discourse on decentralised governance and autonomous management of physical spaces by offering both practical insights and providing a framework for future research.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Resilient Consensus Sustained Collaboratively</title>
<link>https://arxiv.org/abs/2302.02325</link>
<guid>https://arxiv.org/abs/2302.02325</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Proof-of-Work (PoW), Proof-of-Stake (PoS), Malicious Fault-Tolerant (MFT), Power-of-Collaboration (PoC).

总结:<br />
本文关注区块链技术的发展，特别是对Proof-of-Work (PoW)共识协议的能源消耗问题。作者指出PoW的局限性在于其对大量计算的需求和由此产生的能源浪费。为解决这一问题，文章提出了一种新的Power-of-Collaboration (PoC) 协议，旨在增强现有的Proof-of-Stake (PoS) 和 Malicious Fault-Tolerant (MFT) 协议的安全性，防止长期攻击。PoC设计易于集成到现有区块链中，对吞吐量的影响较小。通过协作保障安全，同时兼顾效率。 <div>
arXiv:2302.02325v4 Announce Type: replace 
Abstract: The recent growth of blockchain technology has accelerated research on decentralized platforms. Initial blockchain platforms decide on what should be added to the ledger based on Proof-of-Work (PoW) consensus protocol. PoW requires its participants to perform large computations and leads to massive energy wastage. Recent blockchains aim to replace PoW through Proof-of-Stake (PoS) and Malicious Fault-Tolerant (MFT) consensus protocols. However, the safety of the ledger created by these protocols is at the mercy of the long-term safe-keeping of the private keys of participants. As a result, these blockchains face long-range attacks. To ameliorate this situation, we present the design of our novel Power-of-Collaboration (PoC) protocol, which guards existing PoS and MFT blockchains against long-range attacks. We show that PoC can be easily appended to existing blockchains and only marginally degrades their throughputs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Improving the Accuracy of Transaction-Based Ponzi Detection on Ethereum</title>
<link>https://arxiv.org/abs/2308.16391</link>
<guid>https://arxiv.org/abs/2308.16391</guid>
<content:encoded><![CDATA[
<div> 关键词：Ponzi scheme, Ethereum blockchain, smart contract, transaction-based approach, time-series features.

总结:
本文关注于以太坊区块链上的庞氏骗局检测。尽管合同代码为基础的方法准确性高，但不具鲁棒性，因为诈骗者可通过代码混淆或创新未被检测的利润分配逻辑来欺骗。相反，基于交易的方法更稳健，但现有模型精度较低。作者提出利用时间序列特征改进这种模型，这些特征能捕捉庞氏应用的生命周期行为，而过去的研究忽视了这一点。他们提出一套新的85个特征（22个已知账户和63个时间序列），使得现成的机器学习算法在F1分数上比现有工作高出30%。这一方法旨在提高基于交易的庞氏骗局检测的准确性，增强模型的鲁棒性。 <div>
arXiv:2308.16391v2 Announce Type: replace 
Abstract: The Ponzi scheme, an old-fashioned fraud, is now popular on the Ethereum blockchain, causing considerable financial losses to many crypto investors. A few Ponzi detection methods have been proposed in the literature, most of which detect a Ponzi scheme based on its smart contract source code. This contract-code-based approach, while achieving very high accuracy, is not robust because a Ponzi developer can fool a detection model by obfuscating the opcode or inventing a new profit distribution logic that cannot be detected. On the contrary, a transaction-based approach could improve the robustness of detection because transactions, unlike smart contracts, are harder to be manipulated. However, the current transaction-based detection models achieve fairly low accuracy. In this paper, we aim to improve the accuracy of the transaction-based models by employing time-series features, which turn out to be crucial in capturing the life-time behaviour a Ponzi application but were completely overlooked in previous works. We propose a new set of 85 features (22 known account-based and 63 new time-series features), which allows off-the-shelf machine learning algorithms to achieve up to 30% higher F1-scores compared to existing works.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Effective Illicit Account Detection on Large Cryptocurrency MultiGraphs</title>
<link>https://arxiv.org/abs/2309.02460</link>
<guid>https://arxiv.org/abs/2309.02460</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptocurrency, illicit accounts, directed multi-graphs, Edge2Seq, MGD

总结: 这篇论文介绍了一种名为DIAM的方法，用于检测数字货币交易网络中的非法账户。DIAM通过Edge2Seq模块捕捉交易模式，考虑边属性和方向顺序生成节点表示。接着，它利用MGD模块和自适应消息传递机制，针对多图拓扑检测正常与非法节点之间的差异。DIAM实现了端到端训练，结果在四个比特币和以太坊数据集上优于15种现有方法，如在包含2000万个节点和2亿多边的比特币数据集中，DIAM的F1分数达到96.55%，远超第二名的83.92%。代码已开源。 <div>
arXiv:2309.02460v3 Announce Type: replace 
Abstract: Cryptocurrencies are rapidly expanding and becoming vital in digital financial markets. However, the rise in cryptocurrency-related illicit activities has led to significant losses for users. To protect the security of these platforms, it is critical to identify illicit accounts effectively. Current detection methods mainly depend on feature engineering or are inadequate to leverage the complex information within cryptocurrency transaction networks, resulting in suboptimal performance. In this paper, we present DIAM, an effective method for detecting illicit accounts in cryptocurrency transaction networks modeled by directed multi-graphs with attributed edges. DIAM first features an Edge2Seq module that captures intrinsic transaction patterns from parallel edges by considering edge attributes and their directed sequences, to generate effective node representations. Then in DIAM, we design a multigraph Discrepancy (MGD) module with a tailored message passing mechanism to capture the discrepant features between normal and illicit nodes over the multigraph topology, assisted by an attention mechanism. DIAM integrates these techniques for end-to-end training to detect illicit accounts from legitimate ones. Extensive experiments, comparing against 15 existing solutions on 4 large cryptocurrency datasets of Bitcoin and Ethereum, demonstrate that DIAM consistently outperforms others in accurately identifying illicit accounts. For example, on a Bitcoin dataset with 20 million nodes and 203 million edges, DIAM attains an F1 score of 96.55%, markedly surpassing the runner-up's score of 83.92%. The code is available at https://github.com/TommyDzh/DIAM.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FBChain: A Blockchain-based Federated Learning Model with Efficiency and Secure Communication</title>
<link>https://arxiv.org/abs/2312.00035</link>
<guid>https://arxiv.org/abs/2312.00035</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-based Federated Learning (FBChain), parameter transmission, privacy, security, efficiency.

总结:<br />
这篇文章关注于联邦学习中参数传输过程中的隐私和安全问题，特别是"参数泄漏"和"通信效率低下"。作者提出了一种基于区块链的联邦学习模型（FBChain），通过利用区块链的不可篡改性存储全局模型和本地参数哈希值，确保数据隐私并通过比较本地参数的哈希值验证一致性，从而解决"参数泄漏"。同时，采用Proof of Weighted Link Speed (PoWLS) 共识算法，选择具有较高加权链速的节点进行模型聚合和打包区块，解决了"通信效率低"的问题。实验结果证明了FBChain的有效性和在提升模型通信效率方面的优势。 <div>
arXiv:2312.00035v2 Announce Type: replace 
Abstract: Privacy and security in the parameter transmission process of federated learning are currently among the most prominent concerns. However, there are two thorny problems caused by unprotected communication methods: "parameter-leakage" and "inefficient-communication". This article proposes Blockchain-based Federated Learning (FBChain) model for federated learning parameter communication to overcome the above two problems. First, we utilize the immutability of blockchain to store the global model and hash value of local model parameters in case of tampering during the communication process, protect data privacy by encrypting parameters, and verify data consistency by comparing the hash values of local parameters, thus addressing the "parameter-leakage" problem. Second, the Proof of Weighted Link Speed (PoWLS) consensus algorithm comprehensively selects nodes with the higher weighted link speed to aggregate global model and package blocks, thereby solving the "inefficient-communication" problem. Experimental results demonstrate the effectiveness of our proposed FBChain model and its ability to improve model communication efficiency in federated learning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>User Connection and Resource Allocation Optimization in Blockchain Empowered Metaverse over 6G Wireless Communications</title>
<link>https://arxiv.org/abs/2403.05116</link>
<guid>https://arxiv.org/abs/2403.05116</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Metaverse, non-fungible tokens (NFTs), resource allocation, trust-cost ratio (TCR)

总结:<br />
本文关注区块链、Metaverse和NFT融合带来的机遇与挑战，特别是资源管理和用户隐私。研究提出一种优化方法，通过用户任务卸载、连接参数调整和服务器计算频率分配，提升数据处理效率。资源分配阶段，引入信任成本比(TCR)，平衡延迟和能源消耗，确保用户参与度和信任。核心算法DASHF结合了多项技术，如Dinkelbach算法、交替优化、SDR和新颖的分数编程。文章难点在于将问题转化为二次约束二次规划(QCQP)解决。大量模拟验证了DASHF的有效性，为改进区块链-Metaverse应用，尤其是NFT相关系统提供了关键见解。 <div>
arXiv:2403.05116v2 Announce Type: replace 
Abstract: The convergence of blockchain, Metaverse, and non-fungible tokens (NFTs) brings transformative digital opportunities alongside challenges like privacy and resource management. Addressing these, we focus on optimizing user connectivity and resource allocation in an NFT-centric and blockchain-enabled Metaverse in this paper. Through user work-offloading, we optimize data tasks, user connection parameters, and server computing frequency division. In the resource allocation phase, we optimize communication-computation resource distributions, including bandwidth, transmit power, and computing frequency. We introduce the trust-cost ratio (TCR), a pivotal measure combining trust scores from users' resources and server history with delay and energy costs. This balance ensures sustained user engagement and trust. The DASHF algorithm, central to our approach, encapsulates the Dinkelbach algorithm, alternating optimization, semidefinite relaxation (SDR), the Hungarian method, and a novel fractional programming technique from a recent IEEE JSAC paper [2]. The most challenging part of DASHF is to rewrite an optimization problem as Quadratically Constrained Quadratic Programming (QCQP) via carefully designed transformations, in order to be solved by SDR and the Hungarian algorithm. Extensive simulations validate the DASHF algorithm's efficacy, revealing critical insights for enhancing blockchain-Metaverse applications, especially with NFTs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing</title>
<link>https://arxiv.org/abs/2407.12011</link>
<guid>https://arxiv.org/abs/2407.12011</guid>
<content:encoded><![CDATA[
<div> 关键词：human action representation, nuclear power plant, digital twin, partial computation offloading, multiuser game

总结:<br />该论文关注在核电厂数字孪生（DT）中准确表示复杂人类动作（HA），以及利用第六代网络（COIN）辅助的多接入边缘计算（MEC）降低延迟的挑战。研究采用两阶段方法：首先，构建概率图形模型（PGM）来捕捉HA及其与核设施资产孪生之间的交互；其次，将部分计算任务卸载问题建模为多人博弈，设计去中心化算法优化决策和资源分配。结果表明，该方法有效处理复杂HA并优化DT环境下NPP的资源管理。 <div>
arXiv:2407.12011v1 Announce Type: new 
Abstract: This paper addresses the challenge of representing complex human action (HA) in a nuclear power plant (NPP) digital twin (DT) and minimizing latency in partial computation offloading (PCO) in sixth-generation-enabled computing in the network (COIN) assisted multiaccess edge computing (MEC). Accurate HA representation in the DT-HA model is vital for modeling human interventions that are crucial for the safe and efficient operation of NPPs. In this context, DT-enabled COIN-assisted MEC harnesses DT (known as a cybertwin) capabilities to optimize resource allocation and reduce latency effectively. A two-stage approach is employed to address system complexity. First, a probabilistic graphical model (PGM) is introduced to capture HAs in the DT abstraction. In the PGM, HA and NPP asset-twin abstractions form coupled systems that evolve and interact through observable data and control input. Next, the underlying PCO problem is formulated as a multiuser game, where NPP assets can partially offload tasks to COIN and MEC. We propose a decentralized algorithm to optimize offloading decisions, offloading ratios, and resource allocation. The simulation results demonstrate the effectiveness of the proposed method in capturing complex HAs and optimal resource allocation in DT-enabled NPPs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Gaming and Blockchain: Hype and Reality</title>
<link>https://arxiv.org/abs/2407.12134</link>
<guid>https://arxiv.org/abs/2407.12134</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, gaming industry, Enjin, Axie Infinity, transaction cost

总结: 这篇文章探讨了区块链技术在游戏行业的应用潜力与挑战。它关注了Enjin和Axie Infinity等热门区块链游戏项目，分析了分布式账本技术如何可能革新游戏经济并赋予玩家对虚拟资产的控制。然而，文章也指出实际问题，如高能耗和用户接纳度，以及对区块链是否真正必需的质疑。通过对比交易成本和玩家反馈，作者评估了区块链整合游戏的长期前景。<br /><br />总结: 区块链<br />游戏行业<br />Enjin<br />Axie Infinity<br />交易成本 <div>
arXiv:2407.12134v1 Announce Type: new 
Abstract: This paper explores the adoption of blockchain technology in the gaming industry. While supporters affirm that distributed ledger technology has potential to revolutionize gaming economies and provide players with control over their virtual assets, there are practical challenges such as energy consumption and user adoption to be addressed, and detractors question whether blockchain integration is even necessary. This report characterises popular blockchain-based gaming projects like Enjin and Axie Infinity, then compares metrics such as transaction cost and player feedback to evaluate the longevity of blockchain-integrated gaming as a whole.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Latency Price of Threshold Cryptosystem in Blockchains</title>
<link>https://arxiv.org/abs/2407.12172</link>
<guid>https://arxiv.org/abs/2407.12172</guid>
<content:encoded><![CDATA[
<div> 关键词：threshold cryptography, blockchain, latency, Byzantine-fault tolerance (BFT), proof-of-stake.

总结:
本文主要探讨了阈值密码学与使用拜占庭容错(BFT)共识协议的区块链之间的交互，重点关注延迟问题。研究者提出了一种机制，消除了紧阈值区块链上运行阈值密码学协议的一次性消息延迟。然而，许多现实中的权益证明型区块链倾向于使用阶梯阈值，这导致额外的延迟不可避免。文章还介绍了一种乐观方法来减少这种延迟，并在Aptos区块链的分布式随机数生成方案中进行了实施。实验结果显示，该乐观方法将延迟 overhead 降低了71%。 <div>
arXiv:2407.12172v1 Announce Type: new 
Abstract: Threshold cryptography is essential for many blockchain protocols. For example, many protocols rely on threshold common coin to implement asynchronous consensus, leader elections, and provide support for randomized applications. Similarly, threshold signature schemes are frequently used for protocol efficiency and state certification, and threshold decryption and threshold time-lock puzzles are often necessary for privacy.
  In this paper, we study the interplay between threshold cryptography and a class of blockchains that use Byzantine-fault tolerant (BFT) consensus protocols with a focus on latency. More specifically, we focus on blockchain-native threshold cryptosystem, where the blockchain validators seek to run a threshold cryptographic protocol once for every block with the block contents as an input to the threshold cryptographic protocol. All existing approaches for blockchain-native threshold cryptosystems introduce a latency overhead of at least one message delay for running the threshold cryptographic protocol. In this paper, we first propose a mechanism to eliminate this overhead for blockchain-native threshold cryptosystems with tight thresholds, i.e., in threshold cryptographic protocols where the secrecy and reconstruction thresholds are the same. However, many real-world proof-of-stake-based blockchain-native threshold cryptosystems rely on ramp thresholds, where reconstruction thresholds are strictly greater than secrecy thresholds. For these blockchains, we formally demonstrate that the additional delay is unavoidable. We then introduce a mechanism to minimize this delay in the optimistic case. We implement our optimistic protocol for the proof-of-stake distributed randomness scheme on the Aptos blockchain. Our measurements from the Aptos mainnet show that the optimistic approach reduces latency overhead by 71%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>L2AI: lightweight three-factor authentication and authorization in IOMT blockchain-based environment</title>
<link>https://arxiv.org/abs/2407.12187</link>
<guid>https://arxiv.org/abs/2407.12187</guid>
<content:encoded><![CDATA[
<div> 关键词：Medical IoT, Multi-factor authentication, Anonymous user authentication, Blockchain, L2AI

总结: 这篇论文关注医疗物联网（Medical IoT）的安全问题，提出了一种轻量级的多因素和匿名用户认证方案。该方案利用L2AI（一个不安全但高效的安全通道）在区块链环境中访问实时数据。L2AI通过伪身份和动态索引增强用户匿名性，支持大规模系统下的高效注册过程。它结合了单向哈希函数、异或运算及模糊挖掘算法，确保用户生物信息验证。文章采用ROR模型和BAN逻辑进行安全证明，并使用Proverif工具进行了形式化验证。总之，L2AI旨在为医疗IoT提供一个兼顾安全与效率的解决方案。 <div>
arXiv:2407.12187v1 Announce Type: new 
Abstract: Medical Internet of Things (IoMT) is the next frontier in the digital revolution and is utilized in healthcare. In this context, IoT enables individuals to remotely manage their essential activities with minimal interaction. However, the limitations of network resources and the challenges of establishing a secure channel, as well as sharing and collecting sensitive information through an insecure public channel, pose security challenges for the medical IoT. This paper presents a lightweight multi-factor authentication and anonymous user authentication scheme to access real-time data in a blockchain-based environment. The scheme utilizes an insecure channel called L2AI. L2AI ensures security and efficiency while enhancing user anonymity through the use of pseudo-identity and dynamic indexing. The proposed method supports highly scalable systems with an efficient user registration process, allowing authenticated users to access both existing and newly added system entities without additional processes. Although the scheme is primarily designed for large systems, such as health infrastructure, it is also suitable for resource-constrained devices. The scheme relies on one-way cryptographic hashing functions and bitwise XOR operations. Additionally, a fuzzy mining algorithm is employed on the user side to verify the user's biometric information. L2AI adopts the "Real-Or-Random (ROR)" model for security proof and employs BAN logic for proof of authenticity. Formal security verification is conducted using the "Automatic Validation of Internet Security Protocols and Programs" (Proverif) tool, complemented by informal security analysis demonstrating the proper functionality of L2AI.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Comparing Federated Stochastic Gradient Descent and Federated Averaging for Predicting Hospital Length of Stay</title>
<link>https://arxiv.org/abs/2407.12741</link>
<guid>https://arxiv.org/abs/2407.12741</guid>
<content:encoded><![CDATA[
<div> 关键词：医院长度 of stay (LOS), 预测, 隐私规则, 联邦学习, 优化算法

总结:<br />
该研究关注医院长度 of stay (LOS) 的预测问题，强调了在遵守隐私规则的前提下进行准确预测的重要性。文章提出将问题建模为一个分布式图，通过节点（医院）上的局部模型训练，采用全局总变分最小化（GTVMin）。联邦学习方法，如联邦随机梯度下降（FedSGD）和联邦平均（FedAVG），被应用于协作训练，确保数据不离开医疗机构。结果显示，这种方法既能实现精确的LOS预测，又能保护患者隐私。 <div>
arXiv:2407.12741v1 Announce Type: new 
Abstract: Predicting hospital length of stay (LOS) reliably is an essential need for efficient resource allocation at hospitals. Traditional predictive modeling tools frequently have difficulty acquiring sufficient and diverse data because healthcare institutions have privacy rules in place. In our study, we modeled this problem as an empirical graph where nodes are the hospitals. This modeling approach facilitates collaborative model training by modeling decentralized data sources from different hospitals without extracting sensitive data outside of hospitals. A local model is trained on a node (hospital) by aiming the generalized total variation minimization (GTVMin). Moreover, we implemented and compared two different federated learning optimization algorithms named federated stochastic gradient descent (FedSGD) and federated averaging (FedAVG). Our results show that federated learning enables accurate prediction of hospital LOS while addressing privacy concerns without extracting data outside healthcare institutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>To Trade Or Not To Trade: Cascading Waterfall Round Robin Rebalancing Mechanism for Cryptocurrencies</title>
<link>https://arxiv.org/abs/2407.12150</link>
<guid>https://arxiv.org/abs/2407.12150</guid>
<content:encoded><![CDATA[
<div> 关键词：Cascading Waterfall Round Robin Mechanism, Portfolio Rebalancing, Gas Fee, Slippage, Hyper-volatile Crypto Market

总结:<br />
本文介绍了一种创新的交易策略，名为"Cascading Waterfall Round Robin Mechanism"（瀑布轮转机制），专为波动性大的加密市场设计。该算法在考虑交易成本（如gas费和滑点）的同时，根据资产级别的微观特征和市场的宏观因素决定买卖时机。在高波动性下，它倾向于在价格下跌时买入，价格上涨时卖出，以减少噪音并确保稳健交易。这种机制可应用于各类投资基金，不局限于区块链，适用于任何交易频率和再平衡周期。总的来说，这是一种在动荡市场中实现智能资产配置的方法。 <div>
arXiv:2407.12150v1 Announce Type: cross 
Abstract: We have designed an innovative portfolio rebalancing mechanism termed the Cascading Waterfall Round Robin Mechanism. This algorithmic approach recommends an ideal size and number of trades for each asset during the periodic rebalancing process, factoring in the gas fee and slippage. The essence of the model we have created gives indications regarding whether trades should be made on individual assets depending on the uncertainty in the micro - asset level characteristics - and macro - aggregate market factors - environments. In the hyper-volatile crypto market, our approach to daily rebalancing will benefit from volatility. Price movements will cause our algorithm to buy assets that drop in prices and sell as they soar. In fact, the buying and selling happen only when certain boundaries are crossed in order to weed out any market noise and ensure sound trade execution. We have provided several numerical examples to illustrate the steps - including the calculation of several intermediate variables - of our rebalancing mechanism. The Algorithm we have developed can be easily applied outside blockchain to investment funds across all asset classes at any trading frequency and rebalancing duration.
  Shakespeare As A Crypto Trader:
  To Trade Or Not To Trade, that is the Question,
  Whether an Optimizer can Yield the Answer,
  Against the Spikes and Crashes of Markets Gone Wild,
  To Quench One's Thirst before Liquidity Runs Dry,
  Or Wait till the Tide of Momentum turns Mild.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Bribe &amp; Fork: Cheap Bribing Attacks via Forking Threat</title>
<link>https://arxiv.org/abs/2402.01363</link>
<guid>https://arxiv.org/abs/2402.01363</guid>
<content:encoded><![CDATA[
<div> 关键词：Payment Channel Networks (PCNs), bribing attacks, blockchain miners, punishment mechanism, Bribe & Fork

总结:<br />
这篇文章关注的是Payment Channel Networks (PCNs) 的安全性，尤其是对抗贿赂攻击的能力。以往的研究认为贿赂矿工忽略交易的成本高昂，但作者揭示这一成本可能大幅降低至约125美元，增加了攻击发生的可能性。他们提出了Bribe & Fork 攻击策略，结合了对分叉威胁的利用，并开发了一个新的挖矿游戏模型来分析。通过分析实际区块链实施的历史数据，研究量化了成本减少的程度。这些发现揭示了PCNs潜在的脆弱性，强调了需要强化其安全解决方案的紧迫性。 <div>
arXiv:2402.01363v2 Announce Type: replace 
Abstract: In this work, we reexamine the vulnerability of Payment Channel Networks (PCNs) to bribing attacks, where an adversary incentivizes blockchain miners to deliberately ignore a specific transaction to undermine the punishment mechanism of PCNs. While previous studies have posited a prohibitive cost for such attacks, we show that this cost may be dramatically reduced (to approximately \$125), thereby increasing the likelihood of these attacks. To this end, we introduce Bribe & Fork, a modified bribing attack that leverages the threat of a so-called feather fork which we analyze with a novel formal model for the mining game with forking. We empirically analyze historical data of some real-world blockchain implementations to evaluate the scale of this cost reduction. Our findings shed more light on the potential vulnerability of PCNs and highlight the need for robust solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Sensor-based Multi-agent Coverage Control with Spatial Separation in Unstructured Environments</title>
<link>https://arxiv.org/abs/2403.01710</link>
<guid>https://arxiv.org/abs/2403.01710</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人系统、搜索与覆盖、Voronoi方法、主动感知、碰撞避免

总结:
本文提出了一种创新的多机器人系统搜索与覆盖算法，利用Voronoi图在复杂、密集环境中实现高效导航。该方法结合了GIS和实时点云数据，通过局部感知生成非凸环境下的安全Voronoi区域，采用空间分解和球面镜像技术。此外，文中引入了死锁感知的引导地图和基于梯度优化的中心Voronoi覆盖策略，以避免全局搜索和局部感知陷阱，提高任务成功率、覆盖率和执行时间。仿真结果验证了算法的有效性，优于现有方法。 <div>
arXiv:2403.01710v3 Announce Type: replace 
Abstract: Multi-robot systems have increasingly become instrumental in tackling search and coverage problems. However, the challenge of optimizing task efficiency without compromising task success still persists, particularly in expansive, unstructured environments with dense obstacles.
  This paper presents an innovative, decentralized Voronoi-based approach for search and coverage to reactively navigate these complexities while maintaining safety.
  This approach leverages the active sensing capabilities of multi-robot systems to supplement GIS (Geographic Information System), offering a more comprehensive and real-time understanding of the environment. Based on point cloud data, which is inherently non-convex and unstructured, this method efficiently generates collision-free Voronoi regions using only local sensing information through spatial decomposition and spherical mirroring techniques.
  Then, deadlock-aware guided map integrated with a gradient-optimized, centroid Voronoi-based coverage control policy, is constructed to improve efficiency by avoiding exhaustive searches and local sensing pitfalls.
  The effectiveness of our algorithm has been validated through extensive numerical simulations in high-fidelity environments, demonstrating significant improvements in both task success rate, coverage ratio, and task execution time compared with others.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Efficacy of Various Large Language Models in Generating Smart Contracts</title>
<link>https://arxiv.org/abs/2407.11019</link>
<guid>https://arxiv.org/abs/2407.11019</guid>
<content:encoded><![CDATA[
<div> 关键词：code-generating, Large Language Models, Solidity smart contracts, Ethereum Blockchain, security.

总结:<br />本文研究了大型语言模型在生成以太坊区块链上的不可变Solidity智能合约中的应用。先前的工作（陈马克等，2012）探讨了AI代码生成能力，但这项研究扩大了范围，关注安全性和效率至关重要的领域。研究发现，虽然LLMs普遍在实现代码安全性方面有困难，但在常见合同类型上表现出惊人效果。此外，论文还提出了一种通过新提示策略生成智能合约的创新方法。总的来说，研究证实了LLMs在智能合约领域的潜力与挑战并存。 <div>
arXiv:2407.11019v1 Announce Type: new 
Abstract: This study analyzes the application of code-generating Large Language Models in the creation of immutable Solidity smart contracts on the Ethereum Blockchain. Other works such as Evaluating Large Language Models Trained on Code, Mark Chen et. al (2012) have previously analyzed Artificial Intelligence code generation abilities. This paper aims to expand this to a larger scope to include programs where security and efficiency are of utmost priority such as smart contracts. The hypothesis leading into the study was that LLMs in general would have difficulty in rigorously implementing security details in the code, which was shown through our results, but surprisingly generally succeeded in many common types of contracts. We also discovered a novel way of generating smart contracts through new prompting strategies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator</title>
<link>https://arxiv.org/abs/2407.11078</link>
<guid>https://arxiv.org/abs/2407.11078</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Class-Incremental Learning (FCIL), catastrophic forgetting, generative models, privacy-preserving, feature-generator.

总结:<br />Federated Class-Incremental Learning (FCIL) 是一种新兴的分布式学习方法，尤其适用于数据隐私保护场景。然而，传统的联邦学习算法如FedAVG 在处理连续任务时易出现知识遗忘问题。为解决这一问题，本文提出了FedGTG（Federated Global Twin Generator），它利用隐私保护的生成模型在不访问客户端数据的情况下进行全局训练。FedGTG通过在服务器端训练数据生成器和特征生成器，生成各类别的合成信息，并在客户端使用特征方向控制损失来保持旧任务知识和学习新任务。实验结果表明，FedGTG在CIFAR-10、CIFAR-100和tiny-ImageNet等数据集上表现出更好的准确性和遗忘抑制能力，同时具有更好的预测置信度。 <div>
arXiv:2407.11078v1 Announce Type: new 
Abstract: Federated Class-Incremental Learning (FCIL) increasingly becomes important in the decentralized setting, where it enables multiple participants to collaboratively train a global model to perform well on a sequence of tasks without sharing their private data. In FCIL, conventional Federated Learning algorithms such as FedAVG often suffer from catastrophic forgetting, resulting in significant performance declines on earlier tasks. Recent works, based on generative models, produce synthetic images to help mitigate this issue across all classes, but these approaches' testing accuracy on previous classes is still much lower than recent classes, i.e., having better plasticity than stability. To overcome these issues, this paper presents Federated Global Twin Generator (FedGTG), an FCIL framework that exploits privacy-preserving generative-model training on the global side without accessing client data. Specifically, the server trains a data generator and a feature generator to create two types of information from all seen classes, and then it sends the synthetic data to the client side. The clients then use feature-direction-controlling losses to make the local models retain knowledge and learn new tasks well. We extensively analyze the robustness of FedGTG on natural images, as well as its ability to converge to flat local minima and achieve better-predicting confidence (calibration). Experimental results on CIFAR-10, CIFAR-100, and tiny-ImageNet demonstrate the improvements in accuracy and forgetting measures of FedGTG compared to previous frameworks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-MedChain: Multi-Party Multi-Blockchain Medical Supply Chain Management System</title>
<link>https://arxiv.org/abs/2407.11207</link>
<guid>https://arxiv.org/abs/2407.11207</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19, Medical supply chain, Multi-party, Multi-blockchain, Smart contracts.

总结:<br />
该文章关注于COVID-19疫情期间医疗供应链管理系统的挑战，提出了Multi-MedChain，一个三层的多党、多区块链（MPMB）框架。它利用智能合约解决现有系统的不足，如端到端追踪、透明度和协作访问控制。Multi-MedChain旨在提高医疗供应链的效率和安全性，特别强调了对药品等易腐产品的监管和合规报告。作者已经实施并评估了这个解决方案，证明其实用性，并将其公开提供。总的来说，Multi-MedChain是一个创新的框架，旨在应对公共卫生危机期间的供应链管理需求。 <div>
arXiv:2407.11207v1 Announce Type: new 
Abstract: The challenges of healthcare supply chain management systems during the COVID-19 pandemic highlighted the need for an innovative and robust medical supply chain. The healthcare supply chain involves various stakeholders who must share information securely and actively. Regulatory and compliance reporting is also another crucial requirement for perishable products (e.g., pharmaceuticals) within a medical supply chain management system. Here, we propose Multi-MedChain as a three-layer multi-party, multi-blockchain (MPMB) framework utilizing smart contracts as a practical solution to address challenges in existing medical supply chain management systems. Multi-MedChain is a scalable supply chain management system for the healthcare domain that addresses end-to-end traceability, transparency, and collaborative access control to restrict access to private data. We have implemented our proposed system and report on our evaluation to highlight the practicality of the solution. The proposed solution is made publicly available.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A2E: Attribute-based Anonymity-Enhanced Authentication for Accessing Driverless Taxi Service</title>
<link>https://arxiv.org/abs/2407.11320</link>
<guid>https://arxiv.org/abs/2407.11320</guid>
<content:encoded><![CDATA[
<div> 关键词：Driverless vehicle, Authentication scheme, Attribute-based anonymity, Redactable signature, Decentralized credential issuance.

总结:<br />
这篇文章关注无人驾驶出租车（DT）服务的安全与隐私问题。提出了一种新的Attribute-based Anonymity Enhanced (A2E) 认证方案。A2E通过基于可编辑签名的用户属性凭证实现属性可验证性，同时保证匿名性和不可链接性，防止身份关联。利用环签名和秘密共享的去中心化凭证发放机制，保护用户属性隐私，提供追踪性和非诬告性。此外，A2E在追踪恶意用户和更新凭证时具有低开销，保持了可扩展性和轻量级特性，有利于实际应用。文章对A2E的安全性和性能进行了深入分析和评估。 <div>
arXiv:2407.11320v1 Announce Type: new 
Abstract: Driverless vehicle as a taxi is gaining more attention due to its potential to enhance urban transportation efficiency. However, both unforeseen incidents led by unsupervised physical users' driverless taxi (DT) rides and personalized needs of users when riding in a DT necessitate the authentication of user identity and attributes. Moreover, safeguarding user identity privacy and quickly tracing malicious users if necessary to enhance the adoption of DTs remains a challenge. This paper proposes a novel Attribute-based Anonymity Enhanced (A2E) authentication scheme for users to access DT service. From the security aspect, A2E has attribute verifiability, which is achieved by designing a user attribute credential based on redactable signature. Meanwhile, this attribute credential also satisfies unlinkability and unforgeability. In addition, A2E has enhanced anonymity, which is achieved by designing a decentralized credential issuance mechanism utilizing ring signature and secret sharing, safeguarding user attributes from association with anonymous identities. Moreover, this mechanism provides traceability and non-frameability to users. From the performance aspect, A2E causes low overhead when tracing malicious users and updating credentials. Besides, both scalability and lightweight are satisfied, which contributes to A2E's practicability. We conduct security analysis and performance evaluation to the security and performance capabilities of A2E.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>End-user Comprehension of Transfer Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2407.11440</link>
<guid>https://arxiv.org/abs/2407.11440</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, USD Tether (USDT), ERC-20 smart contracts, transfer risks, user comprehension.

总结: 这篇文章研究了用户对以太坊智能合约（如USD Tether）转移风险的理解，并调查了前78个ERC-20智能合约中的风险。研究发现，尽管用户自评技术水平各异，但对升级和黑名单风险的认知存在误区，认为其严重程度高。用户更倾向于发现成功的交易结果而非潜在风险。约19.2%的顶级ERC-20合同存在研究中的风险，还发现了其他占25.6%的风险。结果强调了提供可解释的智能合约、易于理解的用户界面和有关风险信息的必要性。 <div>
arXiv:2407.11440v1 Announce Type: new 
Abstract: Smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that end-users understand the transfer risks in smart contracts. To address this, we investigate end-user comprehension of risks in the most popular Ethereum smart contract (i.e., USD Tether (USDT)) and their prevalence in the top ERC-20 smart contracts. We focus on five transfer risks with severe impact on transfer outcomes and user objectives, including users being blacklisted, contract being paused, and contract being arbitrarily upgraded. Firstly, we conducted a user study investigating end-user comprehension of smart contract transfer risks with 110 participants and USDT/MetaMask. Secondly, we performed manual and automated source code analysis of the next top (78) ERC-20 smart contracts (after USDT) to identify the prevalence of these risks. Results show that end-users do not comprehend real risks: most (up to 71.8% of) users believe contract upgrade and blacklisting are highly severe/surprising. More importantly, twice as many users find it easier to discover successful outcomes than risky outcomes using the USDT/MetaMask UI flow. These results hold regardless of the self-rated programming and Web3 proficiency of participants. Furthermore, our source code analysis demonstrates that the examined risks are prevalent in up to 19.2% of the top ERC-20 contracts. Additionally, we discovered (three) other risks with up to 25.6% prevalence in these contracts. This study informs the need to provide explainable smart contracts, understandable UI and relevant information for risky outcomes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dataset Dictionary Learning in a Wasserstein Space for Federated Domain Adaptation</title>
<link>https://arxiv.org/abs/2407.11647</link>
<guid>https://arxiv.org/abs/2407.11647</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Source Domain Adaptation (MSDA), Decentralized, Wasserstein barycenters, Data privacy, Robustness.

总结:<br />
本文提出了一种新的方法——Decentralized Dataset Dictionary Learning（去中心化数据字典学习），解决多源领域适应（Multi-Source Domain Adaptation，MSDA）中的隐私问题。通过运用Wasserstein barycenters，该方法能够在不泄露数据隐私的前提下，捕捉多个客户端之间分布的差异，实现有效的适应。实验结果表明，与现有去中心化MSDA技术相比，新方法在五个视觉领域适应基准上表现出优越性能，并且在处理客户端并行性时更加强健，同时保持相对鲁棒性。总的来说，该工作为保护隐私的去中心化多源领域适应提供了一种创新且有效的方法。 <div>
arXiv:2407.11647v1 Announce Type: new 
Abstract: Multi-Source Domain Adaptation (MSDA) is a challenging scenario where multiple related and heterogeneous source datasets must be adapted to an unlabeled target dataset. Conventional MSDA methods often overlook that data holders may have privacy concerns, hindering direct data sharing. In response, decentralized MSDA has emerged as a promising strategy to achieve adaptation without centralizing clients' data. Our work proposes a novel approach, Decentralized Dataset Dictionary Learning, to address this challenge. Our method leverages Wasserstein barycenters to model the distributional shift across multiple clients, enabling effective adaptation while preserving data privacy. Specifically, our algorithm expresses each client's underlying distribution as a Wasserstein barycenter of public atoms, weighted by private barycentric coordinates. Our approach ensures that the barycentric coordinates remain undisclosed throughout the adaptation process. Extensive experimentation across five visual domain adaptation benchmarks demonstrates the superiority of our strategy over existing decentralized MSDA techniques. Moreover, our method exhibits enhanced robustness to client parallelism while maintaining relative resilience compared to conventional decentralized MSDA methodologies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging</title>
<link>https://arxiv.org/abs/2407.11652</link>
<guid>https://arxiv.org/abs/2407.11652</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Cross-Client Variations, Adaptive Federated Learning, Medical Images, Synthetic Data.

总结:<br />Federated Learning (FL)在医疗领域具有巨大潜力，但面临跨客户端医学图像数据变化和标注不足的挑战。本文提出Cross-Client Variations Adaptive Federated Learning (CCVA-FL)，通过将图像转换到共同特征空间来减少差异。方法包括专家标注部分图像，选择数据复杂度最低的客户端作为目标，使用Scalable Diffusion Models with Transformers (DiT)生成合成医学图像，并进行图像翻译。CCVA-FL通过共享这些多样性的合成图像，成功改善了Vanilla Federated Averaging在处理数据分布不均时的表现，同时保护了隐私。实验结果表明，这种方法显著提升了模型性能。 <div>
arXiv:2407.11652v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a privacy-preserving approach to train models on decentralized data. Its potential in healthcare is significant, but challenges arise due to cross-client variations in medical image data, exacerbated by limited annotations. This paper introduces Cross-Client Variations Adaptive Federated Learning (CCVA-FL) to address these issues. CCVA-FL aims to minimize cross-client variations by transforming images into a common feature space. It involves expert annotation of a subset of images from each client, followed by the selection of a client with the least data complexity as the target. Synthetic medical images are then generated using Scalable Diffusion Models with Transformers (DiT) based on the target client's annotated images. These synthetic images, capturing diversity and representing the original data, are shared with other clients. Each client then translates its local images into the target image space using image-to-image translation. The translated images are subsequently used in a federated learning setting to develop a server model. Our results demonstrate that CCVA-FL outperforms Vanilla Federated Averaging by effectively addressing data distribution differences across clients without compromising privacy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Self-Duplicating Random Walks for Resilient Decentralized Learning on Graphs</title>
<link>https://arxiv.org/abs/2407.11762</link>
<guid>https://arxiv.org/abs/2407.11762</guid>
<content:encoded><![CDATA[
<div> 关键词：random walks (RWs), decentralized learning, graph, node failures, link failures.

总结:<br />
文章讨论了在图中多个随机游走执行计算任务时，如何在面临节点或链路故障的情况下维持所需的随机游走数量以确保系统鲁棒性。DECAFORK是一个去中心化的算法，通过估计返回时间分布来持续监控生存的随机游走，并在预测到可能的失败时进行复制。实验结果表明，DECAFORK在快速检测和应对故障方面表现出色。理论分析也支持该算法的有效性能。 <div>
arXiv:2407.11762v1 Announce Type: new 
Abstract: Consider the setting of multiple random walks (RWs) on a graph executing a certain computational task. For instance, in decentralized learning via RWs, a model is updated at each iteration based on the local data of the visited node and then passed to a randomly chosen neighbor. RWs can fail due to node or link failures. The goal is to maintain a desired number of RWs to ensure failure resilience. Achieving this is challenging due to the lack of a central entity to track which RWs have failed to replace them with new ones by forking (duplicating) surviving ones. Without duplications, the number of RWs will eventually go to zero, causing a catastrophic failure of the system. We propose a decentralized algorithm called DECAFORK that can maintain the number of RWs in the graph around a desired value even in the presence of arbitrary RW failures. Nodes continuously estimate the number of surviving RWs by estimating their return time distribution and fork the RWs when failures are likely to happen. We present extensive numerical simulations that show the performance of DECAFORK regarding fast detection and reaction to failures. We further present theoretical guarantees on the performance of this algorithm.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Proportional Dynamics in Linear Fisher Markets with Auto-bidding: Convergence, Incentives and Fairness</title>
<link>https://arxiv.org/abs/2407.11872</link>
<guid>https://arxiv.org/abs/2407.11872</guid>
<content:encoded><![CDATA[
<div> 关键词：proportional dynamics, Fisher markets, competitive equilibrium, auto-bidding, seller-side deviation game.

总结:<br />
这篇论文探讨了比例动态在Fisher市场中的扩展，将卖家带来的物品视为一个整体进行预算分配。这种新型动态依然能导向竞争均衡，与在线广告竞标市场的自动投标有所关联。然而，虽然买家倾向于遵循比例规则，但卖家有偏离的盈利动机。作者研究了卖家偏离游戏，发现存在独特的纯纳什均衡，尽管它不等于竞争均衡，但在市场竞争充分且非严重垄断的情况下，它能提供良好的公平性保障。 <div>
arXiv:2407.11872v1 Announce Type: new 
Abstract: Proportional dynamics, originated from peer-to-peer file sharing systems, models a decentralized price-learning process in Fisher markets. Previously, items in the dynamics operate independently of one another, and each is assumed to belong to a different seller. In this paper, we show how it can be generalized to the setting where each seller brings multiple items and buyers allocate budgets at the granularity of sellers rather than individual items. The generalized dynamics consistently converges to the competitive equilibrium, and interestingly relates to the auto-bidding paradigm currently popular in online advertising auction markets. In contrast to peer-to-peer networks, the proportional rule is not imposed as a protocol in auto-bidding markets. Regarding this incentive concern, we show that buyers have a strong tendency to follow the rule, but it is easy for sellers to profitably deviate (given buyers' commitment to the rule). Based on this observation, we further study the seller-side deviation game and show that it admits a unique pure Nash equilibrium. Though it is generally different from the competitive equilibrium, we show that it attains a good fairness guarantee as long as the market is competitive enough and not severely monopolized.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Code Documentation and Analysis to Secure Software Development</title>
<link>https://arxiv.org/abs/2407.11934</link>
<guid>https://arxiv.org/abs/2407.11934</guid>
<content:encoded><![CDATA[
<div> 关键词：Code Documentation and Analysis Tool (CoDAT), consistency, code comments, large language model, semantic consistency

总结:
CoDAT是一个代码文档和分析工具，专注于维护代码与注释之间的连贯性。它利用大型语言模型检查代码片段与描述的注释的语义一致性，同时标记过时或不一致的注释，帮助开发者改进代码实现。CoDAT集成在IntelliJ IDEA中，利用Code Insight daemon和自定义正则表达式检测代码块变化，其后端设计为分布式，支持代码一致性追踪和架构编译记录。<br /><br />总结: <div>
arXiv:2407.11934v1 Announce Type: new 
Abstract: We present the Code Documentation and Analysis Tool (CoDAT). CoDAT is a tool designed to maintain consistency between the various levels of code documentation, e.g. if a line in a code sketch is changed, the comment that documents the corresponding code is also changed. That is, comments are linked and updated so as to remain internally consistent and also consistent with the code. By flagging "out of date" comments, CoDAT alerts the developer to maintain up-to-date documentation.
  We use a large language model to check the semantic consistency between a fragment of code and the comments that describe it. Thus we also flag semantic inconsistency as well as out of date comments. This helps programers write code that correctly implements a code sketch, and so provides machine support for a step-wise refinement approach, starting with a code sketch and proceeding down to code through one or more refinement iterations.
  CoDAT is implemented in the Intellij IDEA IDE where we use the Code Insight daemon package alongside a custom regular expression algorithm to mark tagged comments whose corresponding code blocks have changed. CoDAT's backend is structurally decentralized to allow a distributed ledger framework for code consistency and architectural compilation tracking.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Retrieval-Augmented Mixture of LoRA Experts for Uploadable Machine Learning</title>
<link>https://arxiv.org/abs/2406.16989</link>
<guid>https://arxiv.org/abs/2406.16989</guid>
<content:encoded><![CDATA[
<div> 关键词：Low-Rank Adaptation (LoRA), Uploadable Machine Learning (UML), Huggingface, Modelscope, Retrieval-Augmented Mixture of LoRA Experts (RAMoLE).

总结:<br />本文主要探讨了低秩适应（LoRA）在大型语言模型（LLMs）微调中的应用，尤其是在Uploadable Machine Learning（UML）平台如Huggingface和Modelscope中的作用。LoRA通过模块化和插件式设计可以集成特定领域的LoRA，增强LLM的功能。然而，UML环境中的动态LoRA库更新和混合任务需求需要一个通用的选优机制。为此，作者提出了Retrieval-Augmented Mixture of LoRA Experts (RAMoLE)框架，它包括LoraRetriever、实时的MoLE协调机制和批量推理，以适应未知LoRA并为混合任务提供个性化服务。实验结果表明，RAMoLE在性能和可扩展性上优于现有方法。 <div>
arXiv:2406.16989v2 Announce Type: replace 
Abstract: Low-Rank Adaptation (LoRA) offers an efficient way to fine-tune large language models (LLMs). Its modular and plug-and-play nature allows the integration of various domain-specific LoRAs, enhancing LLM capabilities. Open-source platforms like Huggingface and Modelscope have introduced a new computational paradigm, Uploadable Machine Learning (UML). In UML, contributors use decentralized data to train specialized adapters, which are then uploaded to a central platform to improve LLMs. This platform uses these domain-specific adapters to handle mixed-task requests requiring personalized service. Previous research on LoRA composition either focuses on specific tasks or fixes the LoRA selection during training. However, in UML, the pool of LoRAs is dynamically updated with new uploads, requiring a generalizable selection mechanism for unseen LoRAs. Additionally, the mixed-task nature of downstream requests necessitates personalized services. To address these challenges, we propose Retrieval-Augmented Mixture of LoRA Experts (RAMoLE), a framework that adaptively retrieves and composes multiple LoRAs based on input prompts. RAMoLE has three main components: LoraRetriever for identifying and retrieving relevant LoRAs, an on-the-fly MoLE mechanism for coordinating the retrieved LoRAs, and efficient batch inference for handling heterogeneous requests. Experimental results show that RAMoLE consistently outperforms baselines, highlighting its effectiveness and scalability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning</title>
<link>https://arxiv.org/abs/2407.09658</link>
<guid>https://arxiv.org/abs/2407.09658</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Poisoning Attacks, Backdoor Attacks, Non-IID Data, Anomaly Detection.

总结:<br />
本文主要探讨了联邦学习中面临的一项挑战：非独立同分布（Non-IID）数据对后门攻击检测的影响。传统的基于异常检测的方法在数据多样性下效果减弱。为解决这个问题，作者提出了一种新的分布感知异常检测机制BoBa。BoBa分为两步：首先，利用数据分布对客户端进行聚类；其次，通过投票机制进行后门攻击检测。文章引入了一种新颖的数据分布推理方法，并采用重叠聚类增强检测鲁棒性。实验结果显示，BoBa在多种攻击策略和环境下能有效降低攻击成功率至0.001以下，同时保持较高的主任务精度。 <div>
arXiv:2407.09658v1 Announce Type: new 
Abstract: Federated learning, while being a promising approach for collaborative model training, is susceptible to poisoning attacks due to its decentralized nature. Backdoor attacks, in particular, have shown remarkable stealthiness, as they selectively compromise predictions for inputs containing triggers. Previous endeavors to detect and mitigate such attacks are based on the Independent and Identically Distributed (IID) data assumption where benign model updates exhibit high-level similarity in multiple feature spaces due to IID data. Thus, outliers are detected as backdoor attacks. Nevertheless, non-IID data presents substantial challenges in backdoor attack detection, as the data variety introduces variance among benign models, making outlier detection-based mechanisms less effective.
  We propose a novel distribution-aware anomaly detection mechanism, BoBa, to address this problem. In order to differentiate outliers arising from data variety versus backdoor attack, we propose to break down the problem into two steps: clustering clients utilizing their data distribution followed by a voting-based detection. Based on the intuition that clustering and subsequent backdoor detection can drastically benefit from knowing client data distributions, we propose a novel data distribution inference mechanism. To improve detection robustness, we introduce an overlapping clustering method, where each client is associated with multiple clusters, ensuring that the trustworthiness of a model update is assessed collectively by multiple clusters rather than a single cluster. Through extensive evaluations, we demonstrate that BoBa can reduce the attack success rate to lower than 0.001 while maintaining high main task accuracy across various attack strategies and experimental settings.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OpenTracer: A Dynamic Transaction Trace Analyzer for Smart Contract Invariant Generation and Beyond</title>
<link>https://arxiv.org/abs/2407.10039</link>
<guid>https://arxiv.org/abs/2407.10039</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart contracts, Blockchain, Transaction history, Invariant, OpenTracer.

总结:
OpenTracer是一个开源工具，专注于智能合约的动态分析，填补了当前市场在全面跟踪交易信息、提取用户所需数据（如不变量）方面的空白。该工具设计用于确保每个执行步骤的完整追踪，已成功分析了350,800个以太坊交易，从预设模板中推断出23种不同类型的不变量。OpenTracer为开发者和研究人员提供了宝贵资源，他们可以借此研究交易行为或验证新的不变量。工具代码可从https://github.com/jeffchen006/OpenTracer获取。 <div>
arXiv:2407.10039v1 Announce Type: new 
Abstract: Smart contracts, self-executing programs on the blockchain, facilitate reliable value exchanges without centralized oversight. Despite the recent focus on dynamic analysis of their transaction histories in both industry and academia, no open-source tool currently offers comprehensive tracking of complete transaction information to extract user-desired data such as invariant-related data. This paper introduces OpenTracer, designed to address this gap. OpenTracer guarantees comprehensive tracking of every execution step, providing complete transaction information. OpenTracer has been employed to analyze 350,800 Ethereum transactions, successfully inferring 23 different types of invariant from predefined templates. The tool is fully open-sourced, serving as a valuable resource for developers and researchers aiming to study transaction behaviors or extract and validate new invariants from transaction traces. The source code of OpenTracer is available at https://github.com/jeffchen006/OpenTracer.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Identity Chain</title>
<link>https://arxiv.org/abs/2407.10187</link>
<guid>https://arxiv.org/abs/2407.10187</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptocurrencies, privacy, accountability, IdentityChain, KYC

总结:
IdentityChain是一个结合了隐私和问责性的新型区块链框架，旨在解决首代加密货币的隐私与监管合规问题。它建立在公共区块链（如以太坊、Ton或Polygon）之上，作为KYC（了解你的客户）服务。该系统强调隐私保护，通过加密技术确保用户信息安全，防止利益冲突。同时，问责原则防止用户不当行为，实现隐私和监管的有效平衡，推动区块链技术的稳健发展和更广泛接纳。 <div>
arXiv:2407.10187v1 Announce Type: new 
Abstract: The first generation of cryptocurrencies introduced revolutionary concepts, yet faced challenges in privacy and regulatory compliance. While subsequent cryptocurrencies aimed to address privacy concerns (like Zcash and Monero), they often conflicted with regulatory frameworks, hindering broader adoption. In response, inspired by recent researches about privacy and accountability and incentive techniques in Blockchain, we propose IdentityChain as a novel framework that integrates privacy and accountability principles, leading to a robust system equipped with adaptable rules.
  IdentityChain is a KYC (Know Your Customer) service on top of a public Blockchain (e.g., Ethereum, Ton, Polygon). The goal is to maintain privacy while ensuring compliance with existing regulations. Privacy is one of the key characteristics of IdentityChain, it's crucial for preventing conflicts of interests further discussed how. Accountability is also one of the main characteristics of IdentityChain and prevents from misbehave of users. Privacy and accountability together wouldn't be possible unless advancements in cryptography.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Error Analysis of the Secret Key Generation Algorithm Using Analog Function Computation</title>
<link>https://arxiv.org/abs/2407.10276</link>
<guid>https://arxiv.org/abs/2407.10276</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Approach, Gaussian primes, Secret key generation, Distributed nodes, Fading channel.

总结:
本文提出了一种去中心化的无线通信安全方法，利用分布式节点之间的Gaussian素数生成加密密钥。系统模型包括预处理和后处理步骤以在网络中共享密钥。研究考虑了热噪声功率和信道估计误差等错误因素，并通过模拟评估了因子分解成功率。文章指出路径损耗引起的大型衰落对信息和功率损失有重大影响。研究还探讨了不同因子分解容忍值对成功率的影响，并对比了2用户和3用户场景下的性能。总的来说，该工作提供了在一个衰落信道下，去中心化密钥生成方法的稳健性和效率分析。 <div>
arXiv:2407.10276v1 Announce Type: new 
Abstract: This study introduces a decentralized approach to secure wireless communication using a cryptographic secret key generation algorithm among distributed nodes. The system model employs Gaussian prime numbers, ensuring the collaborative generation of a secret key. Pre-processing and post-processing functions enable to generate a secret key across the network. An error model evaluates aspects like thermal noise power and channel estimation errors, while simulations assess the success rate to factorize the norm of the secret key. It is observed that path loss-induced large scale fading emerges as a critical component impacting information and power loss. The robustness of the proposed model under fading channel conditions is evaluated with a success rate. Additionally, it is also observed that the tolerance value set in the factorization algorithms has a significant impact on the success rate. Furthermore, the success rate is compared in two scenarios, one with 2 users and another with 3 users, to provide a comprehensive evaluation of the system performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Feasibility of a Smart Contract "Kill Switch"</title>
<link>https://arxiv.org/abs/2407.10302</link>
<guid>https://arxiv.org/abs/2407.10302</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, smart contract, termination mechanisms, EU Data Act, regulatory compliance

总结:<br />
本文探讨了区块链技术的快速发展与监管需求之间的碰撞，重点关注智能合约的终止机制。研究覆盖了多个主流平台如以太坊、BNB智能链等，分析它们在实现消费者保护、错误纠正和符合欧盟数据法（GDPR）方面的策略。文章指出，区块链存在多样化的终止合同方法，从不可更改的带有内置终止条件的合约到可升级允许后期修改的合约。实施“智能合约终结开关”面临平衡监管与去中心化、技术可行性以及对系统安全和信任影响的挑战。总的来说，文章揭示了区块链在法律适应性与技术复杂性之间寻找平衡的努力。 <div>
arXiv:2407.10302v1 Announce Type: new 
Abstract: The advent of blockchain technology and its adoption across various sectors have raised critical discussions about the need for regulatory mechanisms to ensure consumer protection, maintain financial stability, and address privacy concerns without compromising the foundational principles of decentralization and immutability inherent in blockchain platforms. We examine the existing mechanisms for smart contract termination across several major blockchain platforms, including Ethereum, BNB Smart Chain, Cardano, Solana, Hyperledger Fabric, Corda, IOTA, Apotos, and Sui. We assess the compatibility of these mechanisms with the requirements of the EU Data Act, focusing on aspects such as consumer protection, error correction, and regulatory compliance. Our analysis reveals a diverse landscape of approaches, from immutable smart contracts with built-in termination conditions to upgradable smart contracts that allow for post-deployment modifications. We discuss the challenges associated with implementing the so-called smart contract "kill switches," such as the balance between enabling regulatory compliance and preserving the decentralized ethos, the technical feasibility of such mechanisms, and the implications for security and trust in the ecosystem.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Investigating shocking events in the Ethereum stablecoin ecosystem through temporal multilayer graph structure</title>
<link>https://arxiv.org/abs/2407.10614</link>
<guid>https://arxiv.org/abs/2407.10614</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、blockchain、cryptocurrency、crash event、temporal analysis

总结:<br />
本文探讨了Web3时代区块链技术驱动的加密货币市场，重点关注Ethereum上稳定币TerraUSD和LUNA的崩溃事件。研究利用复杂网络分析和多层时间图，揭示了在不同时间尺度下，稳定币之间的强关联以及崩溃前后系统结构的变化。作者发现崩溃前后的异常信号对图结构指标和用户行为有显著影响。这一跨链、时间序列的图分析方法对于理解加密货币市场动态具有重要意义，对于监管机构监控风险和保护用户具有实践价值。总的来说，该研究强调了在Web衍生数据领域进行时间序列分析的必要性，以及图形分析如何增强传统经济计量学研究。 <div>
arXiv:2407.10614v1 Announce Type: new 
Abstract: In the dynamic landscape of the Web, we are witnessing the emergence of the Web3 paradigm, which dictates that platforms should rely on blockchain technology and cryptocurrencies to sustain themselves and their profitability. Cryptocurrencies are characterised by high market volatility and susceptibility to substantial crashes, issues that require temporal analysis methodologies able to tackle the high temporal resolution, heterogeneity and scale of blockchain data. While existing research attempts to analyse crash events, fundamental questions persist regarding the optimal time scale for analysis, differentiation between long-term and short-term trends, and the identification and characterisation of shock events within these decentralised systems. This paper addresses these issues by examining cryptocurrencies traded on the Ethereum blockchain, with a spotlight on the crash of the stablecoin TerraUSD and the currency LUNA designed to stabilise it. Utilising complex network analysis and a multi-layer temporal graph allows the study of the correlations between the layers representing the currencies and system evolution across diverse time scales. The investigation sheds light on the strong interconnections among stablecoins pre-crash and the significant post-crash transformations. We identify anomalous signals before, during, and after the collapse, emphasising their impact on graph structure metrics and user movement across layers. This paper pioneers temporal, cross-chain graph analysis to explore a cryptocurrency collapse. It emphasises the importance of temporal analysis for studies on web-derived data and how graph-based analysis can enhance traditional econometric results. Overall, this research carries implications beyond its field, for example for regulatory agencies aiming to safeguard users from shocks and monitor investment risks for citizens and clients.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>MARTSIA: Safeguarding Data Confidentiality in Blockchain-Driven Process Execution</title>
<link>https://arxiv.org/abs/2407.10684</link>
<guid>https://arxiv.org/abs/2407.10684</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain, Multi-Authority Approach, Transaction Systems, Interoperating Applications, MARTSIA.

总结:<br />
文章提出了一种新型区块链技术解决方案，名为MARTSIA（Multi-Authority Approach to Transaction Systems for Interoperating Applications）。MARTSIA专注于解决公共区块链在保证透明性和可靠性的同时，如何保护数据隐私的问题。它通过用户自定义策略和证书声明的属性，实现消息部分的读取访问控制，仅授权用户能够解读加密数据，而所有区块链节点仍能验证其完整性。MARTSIA结合了区块链、多权威属性基础加密和分布式哈希表数据存储技术，旨在促进多方协作的可信与保密性。 <div>
arXiv:2407.10684v1 Announce Type: new 
Abstract: Blockchain technology streamlines multi-party collaborations in decentralized settings, especially where trust is limited. While public blockchains enhance transparency and reliability, they conflict with confidentiality. To address this, we introduce Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA). MARTSIA provides read-access control at the message-part level through user-defined policies and certifier-declared attributes, so that only authorized actors can interpret encrypted data while all blockchain nodes can verify its integrity. To this end, MARTSIA resorts to blockchain, Multi-Authority Attribute-Based Encryption and distributed hash-table data-stores.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Thinking Fast and Slow: Data-Driven Adaptive DeFi Borrow-Lending Protocol</title>
<link>https://arxiv.org/abs/2407.10890</link>
<guid>https://arxiv.org/abs/2407.10890</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized finance (DeFi), borrowing, lending platforms, over-collateralization, adaptive protocol.

总结:<br />本文提出了一种适应性、数据驱动的去中心化金融借贷协议。该协议包含两个关键组件：高频控制器和低频规划器。控制器通过学习算法快速调整利率，以应对市场动态，降低用户在市场不匹配时的机会成本；规划器分析用户行为，设定最优的超额抵押比率，平衡风险与长期收益。文章提供了理论保证，包括短期组件的收敛速度和抗扰动能力，以及长期协议的有效性。实证结果验证了这些优势。这一创新方法有助于提高DeFi市场的稳定性和效率。 <div>
arXiv:2407.10890v1 Announce Type: new 
Abstract: Decentralized finance (DeFi) borrowing and lending platforms are crucial to the decentralized economy, involving two main participants: lenders who provide assets for interest and borrowers who offer collateral exceeding their debt and pay interest. Collateral volatility necessitates over-collateralization to protect lenders and ensure competitive returns. Traditional DeFi platforms use a fixed interest rate curve based on the utilization rate (the fraction of available assets borrowed) and determine over-collateralization offline through simulations to manage risk. This method doesn't adapt well to dynamic market changes, such as price fluctuations and evolving user needs, often resulting in losses for lenders or borrowers. In this paper, we introduce an adaptive, data-driven protocol for DeFi borrowing and lending. Our approach includes a high-frequency controller that dynamically adjusts interest rates to maintain market stability and competitiveness with external markets. Unlike traditional protocols, which rely on user reactions and often adjust slowly, our controller uses a learning-based algorithm to quickly find optimal interest rates, reducing the opportunity cost for users during periods of misalignment with external rates. Additionally, we use a low-frequency planner that analyzes user behavior to set an optimal over-collateralization ratio, balancing risk reduction with profit maximization over the long term. This dual approach is essential for adaptive markets: the short-term component maintains market stability, preventing exploitation, while the long-term planner optimizes market parameters to enhance profitability and reduce risks. We provide theoretical guarantees on the convergence rates and adversarial robustness of the short-term component and the long-term effectiveness of our protocol. Empirical validation confirms our protocol's theoretical benefits.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain Governance: An Empirical Analysis of User Engagement on DAOs</title>
<link>https://arxiv.org/abs/2407.10945</link>
<guid>https://arxiv.org/abs/2407.10945</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain DAOs, voting, minimal quorum, Ethereum blockchain, voter activity

总结:<br />
本文研究了四个主要的区块链去中心化自治组织（DAO）——Aave、Compound、Lido和Uniswap的投票情况。作者通过直接从以太坊区块链收集数据，发现大多数投票中所需的最小投票人数（即“最小多数”）相当小。为了深入了解这些DAO的实际决策者，文章利用了Ethereum Name Service（ENS）、Sybil.org和Compound的数据，将投票者分为不同的类别。这项分析揭示了区块链治理中参与度和权力分布的特点。 <div>
arXiv:2407.10945v1 Announce Type: new 
Abstract: In this note, we examine voting on four major blockchain DAOs: Aave, Compound, Lido and Uniswap. Using data directly collected from the Ethereum blockchain, we examine voter activity.
  We find that in most votes, the "minimal quorum," i.e., the smallest number of active voters who could swing the vote is quite small.
  To understand who is actually driving these DAOs, we use data from the Ethereum Name Service (ENS), Sybil.org, and Compound, to divide voters into different categories.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Blockchain Risk Parity Line: Moving From The Efficient Frontier To The Final Frontier Of Investments</title>
<link>https://arxiv.org/abs/2407.09536</link>
<guid>https://arxiv.org/abs/2407.09536</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, risk parity, risk managed portfolios, sub-funds (Alpha, Beta, Gamma), decentralized ledger technology

总结:
本文探讨了如何利用区块链技术构建风险平衡的投资组合，通过创建三个子基金（Alpha、Beta和Gamma）实现不同的风险与回报特征。Alpha基金承担高风险，Beta基金跟随市场表现，而Gamma基金提供风险调整后的保值增值。文章详细介绍了如何运用数学方法设定资产权重，确保每个资产对整体风险的贡献相等，即风险平等（risk parity）。投资者可以根据自身风险承受能力选择不同组合，无论市场状况如何，都能实现风险分散。通过区块链，全球投资者都能参与并根据自己的财务目标实现财富增长，这标志着投资前沿理论在实践中的突破。 <div>
arXiv:2407.09536v1 Announce Type: cross 
Abstract: We engineer blockchain based risk managed portfolios by creating three funds with distinct risk and return profiles: 1) Alpha - high risk portfolio; 2) Beta - mimics the wider market; and 3) Gamma - represents the risk free rate adjusted to beat inflation. Each of the sub-funds (Alpha, Beta and Gamma) provides risk parity because the weight of each asset in the corresponding portfolio is set to be inversely proportional to the risk derived from investing in that asset. This can be equivalently stated as equal risk contributions from each asset towards the overall portfolio risk.
  We provide detailed mechanics of combining assets - including mathematical formulations - to obtain better risk managed portfolios. The descriptions are intended to show how a risk parity based efficient frontier portfolio management engine - that caters to different risk appetites of investors by letting each individual investor select their preferred risk-return combination - can be created seamlessly on blockchain.
  Any Investor - using decentralized ledger technology - can select their desired level of risk, or return, and allocate their wealth accordingly among the sub funds, which balance one another under different market conditions. This evolution of the risk parity principle - resulting in a mechanism that is geared to do well under all market cycles - brings more robust performance and can be termed as conceptual parity.
  We have given several numerical examples that illustrate the various scenarios that arise when combining Alpha, Beta and Gamma to obtain Parity.
  The final investment frontier is now possible - a modification to the efficient frontier, thus becoming more than a mere theoretical construct - on blockchain since anyone from anywhere can participate at anytime to obtain wealth appreciation based on their financial goals.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Mysticeti: Reaching the Limits of Latency with Uncertified DAGs</title>
<link>https://arxiv.org/abs/2310.14821</link>
<guid>https://arxiv.org/abs/2310.14821</guid>
<content:encoded><![CDATA[
<div> 关键词：DAG、Byzantine共识、Mysticeti-C、Mysticeti-FPC、资源效率。

总结:<br />
Mysticeti-C是一种基于有向无环图(DAG)的拜占庭共识协议，它实现了三项关键突破：首先，它将共识延迟降低到3轮消息，这是最低标准；其次，通过避免明确认证DAG块和采用新的提交规则，确保在崩溃失败下的最优延迟；最后，Mysticeti-FPC扩展了这一协议，提供更快的资产转移路径，减少签名和消息数量，进一步提升性能。该协议已被证明在拜占庭环境下安全且具有活性。在Sui区块链上的集成使得Mysticeti-C的共识提交延迟降低4倍，同时保持超过200k TPS的最高吞吐量，表现出卓越的低延迟和资源效率。 <div>
arXiv:2310.14821v4 Announce Type: replace 
Abstract: We introduce Mysticeti-C, the first DAG-based Byzantine consensus protocol to achieve the lower bounds of latency of 3 message rounds. Since Mysticeti-C is built over DAGs it also achieves high resource efficiency and censorship resistance. Mysticeti-C achieves this latency improvement by avoiding explicit certification of the DAG blocks and by proposing a novel commit rule such that every block can be committed without delays, resulting in optimal latency in the steady state and under crash failures. We further extend Mysticeti-C to Mysticeti-FPC, which incorporates a fast commit path that achieves even lower latency for transferring assets. Unlike prior fast commit path protocols, Mysticeti-FPC minimizes the number of signatures and messages by weaving the fast path transactions into the DAG. This frees up resources, which subsequently result in better performance. We prove the safety and liveness in a Byzantine context. We evaluate both Mysticeti protocols and compare them with state-of-the-art consensus and fast path protocols to demonstrate their low latency and resource efficiency, as well as their more graceful degradation under crash failures. Mysticeti-C is the first Byzantine consensus protocol to achieve WAN latency of 0.5s for consensus commit while simultaneously maintaining state-of-the-art throughput of over 200k TPS. Finally, we report on integrating Mysticeti-C as the consensus protocol into the Sui blockchain, resulting in over 4x latency reduction.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PILoRA: Prototype Guided Incremental LoRA for Federated Class-Incremental Learning</title>
<link>https://arxiv.org/abs/2401.02094</link>
<guid>https://arxiv.org/abs/2401.02094</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, catastrophic forgetting, data heterogeneity, prototype learning, Incremental LoRA

总结:<br />
本文提出了一种名为PILoRA的方法，针对动态增加新类别的联邦学习场景。该方法解决数据隐私和非独立同分布数据问题，通过原型学习获取更好的特征表示，并设计原型重权模块对抗分类器因数据异质性产生的偏差，无需重新训练分类器。此外，PILoRA将增量学习视为学习独立任务向量的过程，利用LoRA参数进行编码以缓解遗忘问题。实验结果表明，PILoRA在标准数据集上显著优于现有方法，对不同设置和数据异质性具有强大稳健性。代码可在[链接](https://github.com/Ghy0501/PILoRA)获取。 <div>
arXiv:2401.02094v2 Announce Type: replace 
Abstract: Existing federated learning methods have effectively dealt with decentralized learning in scenarios involving data privacy and non-IID data. However, in real-world situations, each client dynamically learns new classes, requiring the global model to classify all seen classes. To effectively mitigate catastrophic forgetting and data heterogeneity under low communication costs, we propose a simple and effective method named PILoRA. On the one hand, we adopt prototype learning to learn better feature representations and leverage the heuristic information between prototypes and class features to design a prototype re-weight module to solve the classifier bias caused by data heterogeneity without retraining the classifier. On the other hand, we view incremental learning as the process of learning distinct task vectors and encoding them within different LoRA parameters. Accordingly, we propose Incremental LoRA to mitigate catastrophic forgetting. Experimental results on standard datasets indicate that our method outperforms the state-of-the-art approaches significantly. More importantly, our method exhibits strong robustness and superiority in different settings and degrees of data heterogeneity. The code is available at \url{https://github.com/Ghy0501/PILoRA}.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Fundamental Limits of Throughput and Availability: Applications to prophet inequalities &amp; transaction fee mechanism design</title>
<link>https://arxiv.org/abs/2402.19292</link>
<guid>https://arxiv.org/abs/2402.19292</guid>
<content:encoded><![CDATA[
<div> 关键词：availability, throughput, independent demands, heterogeneous distributions, capacity.

总结:
该论文研究了有限资源下独立且异质需求的可用性和吞吐量的基本限制。可用性指需求低于资源容量的概率，而吞吐量是需求利用资源的期望比例。作者提出了一种浓度不等式生成器，为给定容量和单位以内需求的独立分布提供了可用性和吞吐量的下界。这些界限适用于整个需求分布，支持了单位需求的已有理论（Chawla等人，2023），并扩展至多单位需求。此外，这些结果对多单位先知不平等性的改进有潜在贡献（Hajiaghayi等人，2007），以及区块链中交易费机制设计的应用，有助于限制用户-矿工联盟的盈利可能性（Chung和Shi，2023）。总的来说，该工作提供了一个分析工具，用于理解和优化资源分配策略。 <div>
arXiv:2402.19292v3 Announce Type: replace 
Abstract: This paper studies the fundamental limits of availability and throughput for independent and heterogeneous demands of a limited resource. Availability is the probability that the demands are below the capacity of the resource. Throughput is the expected fraction of the resource that is utilized by the demands. We offer a concentration inequality generator that gives lower bounds on feasible availability and throughput pairs with a given capacity and independent but not necessarily identical distributions of up-to-unit demands. We show that availability and throughput cannot both be poor. These bounds are analogous to tail inequalities on sums of independent random variables, but hold throughout the support of the demand distribution. This analysis gives analytically tractable bounds supporting the unit-demand characterization of Chawla, Devanur, and Lykouris (2023) and generalizes to up-to-unit demands. Our bounds also provide an approach towards improved multi-unit prophet inequalities (Hajiaghayi, Kleinberg, and Sandholm, 2007). They have applications to transaction fee mechanism design (for blockchains) where high availability limits the probability of profitable user-miner coalitions (Chung and Shi, 2023).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Demystifying Invariant Effectiveness for Securing Smart Contracts</title>
<link>https://arxiv.org/abs/2404.14580</link>
<guid>https://arxiv.org/abs/2404.14580</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contract, security attacks, invariant guards, Trace2Inv, Ethereum blockchain.

总结:<br />
本文主要探讨了智能合约中安全攻击相关的交易通常表现出与历史良性交易不同的行为模式。作者研究了23种常见的合约不变式，这些不变式被部署在知名协议或由审计公司和专家推荐。Trace2Inv工具利用这些不变式模板，根据合约的历史交易数据动态生成定制化的验证规则。实验结果表明，最有效的单一不变式守护者可以阻止27次攻击中的18次，且气耗较低。即使面对有经验的攻击者尝试绕过，大多数不变式仍然有效。同时，结合多个守护者可以阻挡23次攻击，误报率低至0.32%。Trace2Inv在智能合约不变式挖掘和交易攻击检测方面表现出色，甚至发现两个未报告的攻击交易。 <div>
arXiv:2404.14580v2 Announce Type: replace 
Abstract: Smart contract transactions associated with security attacks often exhibit distinct behavioral patterns compared with historical benign transactions before the attacking events. While many runtime monitoring and guarding mechanisms have been proposed to validate invariants and stop anomalous transactions on the fly, the empirical effectiveness of the invariants used remains largely unexplored. In this paper, we studied 23 prevalent invariants of 8 categories, which are either deployed in high-profile protocols or endorsed by leading auditing firms and security experts. Using these well-established invariants as templates, we developed a tool Trace2Inv which dynamically generates new invariants customized for a given contract based on its historical transaction data.
  We evaluated Trace2Inv on 42 smart contracts that fell victim to 27 distinct exploits on the Ethereum blockchain. Our findings reveal that the most effective invariant guard alone can successfully block 18 of the 27 identified exploits with minimal gas overhead. Our analysis also shows that most of the invariants remain effective even when the experienced attackers attempt to bypass them. Additionally, we studied the possibility of combining multiple invariant guards, resulting in blocking up to 23 of the 27 benchmark exploits and achieving false positive rates as low as 0.32%. Trace2Inv outperforms current state-of-the-art works on smart contract invariant mining and transaction attack detection in terms of both practicality and accuracy. Though Trace2Inv is not primarily designed for transaction attack detection, it surprisingly found two previously unreported exploit transactions, earlier than any reported exploit transactions against the same victim contracts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SAMM: Sharded Automated Market Makers</title>
<link>https://arxiv.org/abs/2406.05568</link>
<guid>https://arxiv.org/abs/2406.05568</guid>
<content:encoded><![CDATA[
<div> 关键词：Automated Market Makers (AMMs), Decentralized Finance (DeFi), Blockchain, Parallel Execution, Shards.

总结:
本文介绍了一种新型的去中心化金融(DeFi)自动化市场 maker (SAMM)，旨在解决现有区块链平台上的AMM性能限制。SAMM通过将AMM划分为多个独立的子池（shards），允许并行执行交易，从而显著提升吞吐量。传统AMM的非交换性导致交易串行化，限制了效率。文章提出了一种创新的交易费用设计，激励用户仅使用最小的子池进行交易，以避免资源分散。系统通过子游戏完美纳什均衡(Subgame-Perfect Nash Equilibria)机制保证了液 <div>
arXiv:2406.05568v2 Announce Type: replace 
Abstract: \emph{Automated Market Makers} (\emph{AMMs}) are a cornerstone of decentralized finance (DeFi) blockchain-based platforms.
  They are smart contracts, enabling the direct exchange of virtual tokens by maintaining \emph{liquidity pools}.
  Traders exchange tokens with the contract, paying a fee; liquidity comes from \emph{liquidity providers}, paid by those fees.
  But despite growing demand, the performance of AMMs is limited.
  State-of-the-art blockchain platforms allow for parallel execution of transactions.
  However, we show that AMMs do not enjoy these gains, since their operations are not commutative so transactions using them must be serialized.
  We present \emph{SAMM}, an AMM comprising multiple independent \emph{shards}.
  All shards are smart contracts operating in the same chain, but they allow for parallel execution as each is independent.
  The challenge is that trading in a standard AMM is cheaper if its liquidity pool is larger.
  Therefore, we show that simply using multiple smaller AMMs results in traders splitting each trade among all AMMs, which worsens performance.
  SAMM addresses this issue with a novel design of the trading fees.
  Traders are incentivized to use only a single smallest shard.
  We show that all Subgame-Perfect Nash Equilibria (SPNE) fit the desired behavior: Liquidity providers balance the liquidity among all pools, so the system converges to the state where trades are evenly distributed.
  Evaluation in the Sui blockchain shows that SAMM's throughput is over fivefold that of traditional AMMs, approaching the system's limit.
  SAMM is a directly deployable open-source smart contract, allowing trading at scale for individuals and DeFi applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Byzantine-Robust Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2406.10416</link>
<guid>https://arxiv.org/abs/2406.10416</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized Federated Learning, Poisoning Attacks, Byzantine Robustness, BALANCE.

总结:<br />
本文主要探讨了联邦学习中的一个问题——去中心化联邦学习（DFL）对抗毒攻击的挑战。DFL通过去中心化的架构避免了服务器依赖性问题，但易受恶意客户端操纵。研究者提出了BALANCE算法，该算法利用每个客户端的本地模型作为相似性参考，判断接收到的模型是否为恶意。BALANCE在强凸和非凸设置下都保证了在攻击下的收敛理论。此外，其在有毒攻击下的收敛速度与无攻击状态下最先进的方法相当。实验结果显示，BALANCE相较于现有DFL方法表现更优，有效抵御毒攻击。 <div>
arXiv:2406.10416v4 Announce Type: replace 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train machine learning models without revealing their private training data. In conventional FL, the system follows the server-assisted architecture (server-assisted FL), where the training process is coordinated by a central server. However, the server-assisted FL framework suffers from poor scalability due to a communication bottleneck at the server, and trust dependency issues. To address challenges, decentralized federated learning (DFL) architecture has been proposed to allow clients to train models collaboratively in a serverless and peer-to-peer manner. However, due to its fully decentralized nature, DFL is highly vulnerable to poisoning attacks, where malicious clients could manipulate the system by sending carefully-crafted local models to their neighboring clients. To date, only a limited number of Byzantine-robust DFL methods have been proposed, most of which are either communication-inefficient or remain vulnerable to advanced poisoning attacks. In this paper, we propose a new algorithm called BALANCE (Byzantine-robust averaging through local similarity in decentralization) to defend against poisoning attacks in DFL. In BALANCE, each client leverages its own local model as a similarity reference to determine if the received model is malicious or benign. We establish the theoretical convergence guarantee for BALANCE under poisoning attacks in both strongly convex and non-convex settings. Furthermore, the convergence rate of BALANCE under poisoning attacks matches those of the state-of-the-art counterparts in Byzantine-free settings. Extensive experiments also demonstrate that BALANCE outperforms existing DFL methods and effectively defends against poisoning attacks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Collaborative Safety-Critical Control for Dynamically Coupled Networked Systems</title>
<link>https://arxiv.org/abs/2310.03289</link>
<guid>https://arxiv.org/abs/2310.03289</guid>
<content:encoded><![CDATA[
<div> 关键词：复杂动态、协作控制、控制屏障函数、网络系统、安全控制。

总结:<br />本文探讨了在现代系统中，随着节点间复杂动态耦合关系的增长，确保个体代理的节点级安全定义与局部邻域动态之间的关联。作者提出了协作控制屏障函数（CCBF），并给出了这些函数定义的安全集向前不变性的条件。通过CCBF，他们设计了一种新的去中心化算法，用于保证协作网络代理的安全控制，并提供了算法收敛于安全控制动作可行集的条件。研究以网络化的易感-感染-易感（SIS）模型为例，展示了这些理论的应用。 <div>
arXiv:2310.03289v3 Announce Type: replace-cross 
Abstract: As modern systems become ever more connected with complex dynamic coupling relationships, developing safe control methods becomes paramount. In this paper, we discuss the relationship of node-level safety definitions for individual agents with local neighborhood dynamics. We define a collaborative control barrier function (CCBF) and provide conditions under which sets defined by these functions will be forward invariant. We use collaborative node-level control barrier functions to construct a novel \edit{decentralized} algorithm for the safe control of collaborating network agents and provide conditions under which the algorithm is guaranteed to converge to a viable set of safe control actions for all agents. We illustrate these results on a networked susceptible-infected-susceptible (SIS) model.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Detect Llama -- Finding Vulnerabilities in Smart Contracts using Large Language Models</title>
<link>https://arxiv.org/abs/2407.08969</link>
<guid>https://arxiv.org/abs/2407.08969</guid>
<content:encoded><![CDATA[
<div> 关键词：OpenAI、GPT-4、fine-tune、smart contract vulnerability detection、F1 score

总结:
在本文中，研究者测试了使用开源模型超越OpenAI GPT-4在智能合约漏洞检测领域的可能性。他们对Meta的Code Llama模型（Detect Llama - Foundation和Detect Llama - Instruct）以及GPT-3.5 Turbo（GPT-3.5FT）进行微调，使用17,000个提示数据集进行训练。实验结果显示，GPT-3.5FT和Detect Llama - Foundation在二分类任务中的F1分数分别为0.776和0.68，优于GPT-4的0.66和GPT-4 Turbo的0.675。对于针对特定漏洞的识别，这两个模型同样表现出色，其整体和前两个最常见漏洞的F1分数均超过GPT-4和GPT-4 Turbo。因此，经过微调的模型在智能合约漏洞检测上展现出更强性能。 <div>
arXiv:2407.08969v1 Announce Type: new 
Abstract: In this paper, we test the hypothesis that although OpenAI's GPT-4 performs well generally, we can fine-tune open-source models to outperform GPT-4 in smart contract vulnerability detection. We fine-tune two models from Meta's Code Llama and a dataset of 17k prompts, Detect Llama - Foundation and Detect Llama - Instruct, and we also fine-tune OpenAI's GPT-3.5 Turbo model (GPT-3.5FT). We then evaluate these models, plus a random baseline, on a testset we develop against GPT-4, and GPT-4 Turbo's, detection of eight vulnerabilities from the dataset and the two top identified vulnerabilities - and their weighted F1 scores.
  We find that for binary classification (i.e., is this smart contract vulnerable?), our two best-performing models, GPT-3.5FT and Detect Llama - Foundation, achieve F1 scores of $0.776$ and $0.68$, outperforming both GPT-4 and GPT-4 Turbo, $0.66$ and $0.675$. For the evaluation against individual vulnerability identification, our top two models, GPT-3.5FT and Detect Llama - Foundation, both significantly outperformed GPT-4 and GPT-4 Turbo in both weighted F1 for all vulnerabilities ($0.61$ and $0.56$ respectively against GPT-4's $0.218$ and GPT-4 Turbo's $0.243$) and weighted F1 for the top two identified vulnerabilities ($0.719$ for GPT-3.5FT, $0.674$ for Detect Llama - Foundation against GPT-4's $0.363$ and GPT-4 Turbo's $0.429$).
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized multi-agent reinforcement learning algorithm using a cluster-synchronized laser network</title>
<link>https://arxiv.org/abs/2407.09124</link>
<guid>https://arxiv.org/abs/2407.09124</guid>
<content:encoded><![CDATA[
<div> 关键词：多Agent强化学习（MARL）、竞争性多臂_bandit（CMAB）、光子决策算法、激光耦合、分布式调整。

总结:<br />
本文提出了一种新颖的解决方案，将多Agent强化学习（MARL）应用于竞争性多臂Bandit问题。研究者利用光子技术，通过调控光耦合激光器的混沌振荡和集群同步，设计了一种分布式决策算法。这种算法在不共享信息的情况下促进了协作决策，实现了去中心化的强化学习，展示了物理过程与简单算法的有效结合，为无线网络和自动驾驶等领域提供了有前景的策略。 <div>
arXiv:2407.09124v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) studies crucial principles that are applicable to a variety of fields, including wireless networking and autonomous driving. We propose a photonic-based decision-making algorithm to address one of the most fundamental problems in MARL, called the competitive multi-armed bandit (CMAB) problem. Our numerical simulations demonstrate that chaotic oscillations and cluster synchronization of optically coupled lasers, along with our proposed decentralized coupling adjustment, efficiently balance exploration and exploitation while facilitating cooperative decision-making without explicitly sharing information among agents. Our study demonstrates how decentralized reinforcement learning can be achieved by exploiting complex physical processes controlled by simple algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization</title>
<link>https://arxiv.org/abs/2407.09324</link>
<guid>https://arxiv.org/abs/2407.09324</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized, Privacy, Information Theory, Deep Neural Networks.

总结:<br />Federated Learning (FL) 作为一种新兴的隐私保护方法，通过将数据保留在其源头以实现隐私核心化。本文与现有研究相悖，表明分布式优化的去中心化FL在理论上和实践上提供了比集中式模型更强的隐私保障。作者通过信息理论分析了FL的隐私损失，指出去中心化的关键区别在于迭代过程中本地梯度的差异和网络中各节点梯度的聚合，这使得攻击者难以推断个人信息。尽管在简单的模型中隐私泄露相似，但在深度神经网络等复杂模型中，去中心化FL的隐私风险较低。通过实证案例，证实了这些理论发现。 <div>
arXiv:2407.09324v1 Announce Type: new 
Abstract: Federated learning (FL) emerged as a paradigm designed to improve data privacy by enabling data to reside at its source, thus embedding privacy as a core consideration in FL architectures, whether centralized or decentralized. Contrasting with recent findings by Pasquini et al., which suggest that decentralized FL does not empirically offer any additional privacy or security benefits over centralized models, our study provides compelling evidence to the contrary. We demonstrate that decentralized FL, when deploying distributed optimization, provides enhanced privacy protection - both theoretically and empirically - compared to centralized approaches. The challenge of quantifying privacy loss through iterative processes has traditionally constrained the theoretical exploration of FL protocols. We overcome this by conducting a pioneering in-depth information-theoretical privacy analysis for both frameworks. Our analysis, considering both eavesdropping and passive adversary models, successfully establishes bounds on privacy leakage. We show information theoretically that the privacy loss in decentralized FL is upper bounded by the loss in centralized FL. Compared to the centralized case where local gradients of individual participants are directly revealed, a key distinction of optimization-based decentralized FL is that the relevant information includes differences of local gradients over successive iterations and the aggregated sum of different nodes' gradients over the network. This information complicates the adversary's attempt to infer private data. To bridge our theoretical insights with practical applications, we present detailed case studies involving logistic regression and deep neural networks. These examples demonstrate that while privacy leakage remains comparable in simpler models, complex models like deep neural networks exhibit lower privacy risks under decentralized FL.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Private Blockchain-based Procurement and Asset Management System with QR Code</title>
<link>https://arxiv.org/abs/2407.09353</link>
<guid>https://arxiv.org/abs/2407.09353</guid>
<content:encoded><![CDATA[
<div> 关键词：private blockchain, procurement process, distributed ledger, Proof-of-Authority, SHA3-512

总结:<br />
该研究介绍了一种旨在应用于供应办公室采购流程的新型区块链系统。通过集成私有区块链技术，系统利用分布式账本、对等网络、权威证明共识机制和SHA3-512加密算法，确保信息的安全与透明。极简原型模型被用于开发过程，提高了用户参与度，有助于早期发现并改进问题。相较于传统区块链，私有链提供了更高的隐私、安全和效率。SHA3-512作为加密算法，处理速度快且无长度扩展攻击风险。研究建议将这种技术应用于资产管理和采购记录，增强信任，降低数据篡改风险，推动供应链管理的创新与升级。 <div>
arXiv:2407.09353v1 Announce Type: new 
Abstract: The developed system aims to incorporate a private blockchain technology in the procurement process for the supply office. The procurement process includes the canvassing, purchasing, delivery and inspection of items, inventory, and disposal. The blockchain-based system includes a distributed ledger technology, peer-to-peer network, Proof-of-Authority consensus mechanism, and SHA3-512 cryptographic hash function algorithm. This will ensure trust and proper accountability to the custodian of the property while safeguarding sensitive information in the procurement records. The extreme prototyping model will be used as software development life cycle. It is mostly used for web-based applications and has an increased user involvement. The prototype version of the system allows the users get a better understanding of the system being developed. It also reduces the time and cost, has quicker user feedback, missing and difficult functions can be recognized, and confusing processes can be addressed on an early stage. The implementation of a private blockchain technology has an increased privacy, enhanced security, improved efficiency, and reduced complexity over traditional blockchain network. The use of SHA3-512 as cryptographic hash function algorithm is much faster than its predecessors when cryptography is handled by hardware components. Furthermore, it is not vulnerable to length extension attacks making it reliable in terms of security of data. The study recommends the use of private blockchain-based technology with the procurement and asset management system in the supply office. The procurement records will be protected against tampering using this technology. This will promote trust and confidence of the stakeholders. The implementation of blockchain technology in developing a system served as advancement and innovation in terms of securing data.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Thunderbolt: Causal Concurrent Consensus and Execution</title>
<link>https://arxiv.org/abs/2407.09409</link>
<guid>https://arxiv.org/abs/2407.09409</guid>
<content:encoded><![CDATA[
<div> 关键词：Directed acyclic graph (DAG), Thunderbolt, smart contracts, scalability, throughput.

总结:<br />本文介绍了一种名为Thunderbolt的新架构，它结合了DAG共识协议和Hyperledger的Execute-Order-Validate理念。Thunderbolt旨在为智能合约交易提供并行执行和并发处理，突破现有DAG协议的串行瓶颈。该架构在预执行阶段实现并行化，通过依赖性图动态调度交易以减少冲突导致的终止率。此外，还引入了恶意攻击防护机制，如shard重新配置。在SmallBank实验中，与Narwhal-Tusk的串行执行相比，Thunderbolt表现出50倍的速度提升，尤其是在64个副本时。 <div>
arXiv:2407.09409v1 Announce Type: new 
Abstract: In the realm of blockchain systems, smart contracts have gained widespread adoption owing to their programmability. Consequently, developing a system capable of facilitating high throughput and scalability is of paramount importance. Directed acyclic graph (DAG) consensus protocols have demonstrated notable enhancements in both throughput and latency, however, the serial execution is now becoming a bottleneck. Numerous approaches prove impractical for smart contracts by assuming that read/write sets are known in prior. This paper introduces Thunderbolt, a novel architecture based on DAG-based protocols, that aims to furnish a scalable and concurrent execution for smart contract transactions. Inspired by Hyperledger, Thunderbolt also expands Execute-Order-Validate architecture in which transactions are distributed into distinct replicas, with execution outcomes determined prior to ordering through the DAG-based protocol. Existing protocols adopt serial executions after the ordering to avoid non-determinism. However, Thunderbolt provides parallel pre-execution before the ordering as well as parallel verifications once any source of non-determinism is removed. Each replica validates the transaction results during the construction of the DAG other than after the ordering following the construction to improve the latency. In an effort to enhance smart contract execution, we implement an execution engine that constructs a dependency graph to dynamically assign transaction orders, thus mitigating abort rates due to execution conflicts. Additionally, we introduce a novel shard reconfiguration to withstand malicious attacks by relocating replicas from the current DAG to a new DAG, and rotating the shards among different replicas. Our comparison of the results on SmallBank with serial execution on Narwhal-Tusk revealed a remarkable 50 times speedup with 64 replicas.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>High-Speed Motion Planning for Aerial Swarms in Unknown and Cluttered Environments</title>
<link>https://arxiv.org/abs/2402.19033</link>
<guid>https://arxiv.org/abs/2402.19033</guid>
<content:encoded><![CDATA[
<div> 关键词：aerial swarm, motion planning, unknown environment, high-speed, decentralized

总结: 本文介绍了一种名为HDSM（High-Speed, Decentralized, and Synchronous Motion Planning）的创新方法，专为多无人机协作飞行设计。HDSM强调在未知环境中进行高效率、去中心化和同步路径规划，每个无人机仅需目标位置的全局信息。与现有四款最先进的方法相比，HDSM在成功率（100%到达目标）、飞行速度（提高97%）和飞行时间（减少50%）上表现出色。实验通过Crazyflie纳米无人机验证了HDSM的有效性和实用性，旨在提升多无人机任务执行的效率和安全性。<br /><br />总结: HDSM是一种用于多无人机的高速、去中心化路径规划框架，考虑未知环境；显著提升飞行效率与安全性；在实际硬件（Crazyflie）上验证成功。 <div>
arXiv:2402.19033v2 Announce Type: replace 
Abstract: Coordinated flight of multiple drones allows to achieve tasks faster such as search and rescue and infrastructure inspection. Thus, pushing the state-of-the-art of aerial swarms in navigation speed and robustness is of tremendous benefit. In particular, being able to account for unexplored/unknown environments when planning trajectories allows for safer flight. In this work, we propose the first high-speed, decentralized, and synchronous motion planning framework (HDSM) for an aerial swarm that explicitly takes into account the unknown/undiscovered parts of the environment. The proposed approach generates an optimized trajectory for each planning agent that avoids obstacles and other planning agents while moving and exploring the environment. The only global information that each agent has is the target location. The generated trajectory is high-speed, safe from unexplored spaces, and brings the agent closer to its goal. The proposed method outperforms four recent state-of-the-art methods in success rate (100% success in reaching the target location), flight speed (97% faster), and flight time (50% lower). Finally, the method is validated on a set of Crazyflie nano-drones as a proof of concept.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>It Takes Two: A Peer-Prediction Solution for Blockchain Verifier's Dilemma</title>
<link>https://arxiv.org/abs/2406.01794</link>
<guid>https://arxiv.org/abs/2406.01794</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Verifier's Dilemma, decentralized consensus, peer prediction, Bayesian truthful mechanisms.

总结:<br />
这篇论文关注区块链系统的安全性问题，特别是"Verifier's Dilemma"现象，即在几乎没有作弊者的情况下，确保验证者诚实执行验证的成本高昂，这可能威胁系统基础安全。作者提出利用peer prediction方法设计一种基于贝叶斯的真诚信实机制，旨在激励多个验证者在去中心化的环境中进行诚实验证，即使在验证过程中存在噪声也如此。这种机制理论上保证了真诚信实性，为增强区块链和其它分布式系统的安全性和稳健性提供了新框架。 <div>
arXiv:2406.01794v2 Announce Type: replace 
Abstract: The security of blockchain systems is fundamentally based on the decentralized consensus in which the majority of parties behave honestly, and the process of content verification is essential to keep the robustness of blockchain systems. However, the phenomenon that a secure blockchain system with few or no cheaters could not provide sufficient incentive for verifiers to honestly perform the costly verification, referred to as the Verifier's Dilemma, could severely undermine the fundamental security of blockchain systems. While existing works have attempted to insert deliberate errors to disincentivize lazy verification, the decentralized environment makes it impossible to judge the correctness of verification or detect malicious verifiers directly.
  In this paper, we initiate the research that leverages the peer prediction approach towards the design of Bayesian truthful mechanisms for the decentralized verification game among multiple verifiers, incentivizing all verifiers to perform honest verification without access to the ground truth even in the presence of noisy observations in the verification process. With theoretically guaranteed truthfulness of our mechanism for the verification game, our work provides a framework of verification mechanisms that enhances the security and robustness of the blockchain and potentially other decentralized systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Benchmarking GNNs Using Lightning Network Data</title>
<link>https://arxiv.org/abs/2407.07916</link>
<guid>https://arxiv.org/abs/2407.07916</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin Lightning Network, Layer 2 protocol, Channels, Graph Neural Networks (GNNs), Node properties.

总结:
比特币闪电网络（Bitcoin Lightning Network）是一种第二层协议，用于实现快速低成本的比特币交易。论文分析了该网络的图结构，利用机器学习中的图神经网络（GNNs）研究节点属性之间的统计关系。研究者设计任务来探索这些关系，并评估不同GNN模型的性能，发现它们在这些任务中有效，揭示了从图结构和邻居信息中获取的洞察。总的来说，这项工作展示了GNN在理解比特币 Lightning 网络中节点特征相互作用方面的潜力。 <div>
arXiv:2407.07916v1 Announce Type: new 
Abstract: The Bitcoin Lightning Network is a layer 2 protocol designed to facilitate fast and inexpensive Bitcoin transactions. It operates by establishing channels between users, where Bitcoin is locked and transactions are conducted off-chain until the channels are closed, with only the initial and final transactions recorded on the blockchain. Routing transactions through intermediary nodes is crucial for users without direct channels, allowing these routing nodes to collect fees for their services. Nodes announce their channels to the network, forming a graph with channels as edges. In this paper, we analyze the graph structure of the Lightning Network and investigate the statistical relationships between node properties using machine learning, particularly Graph Neural Networks (GNNs). We formulate a series of tasks to explore these relationships and provide benchmarks for GNN architectures, demonstrating how topological and neighbor information enhances performance. Our evaluation of several models reveals the effectiveness of GNNs in these tasks and highlights the insights gained from their application.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape</title>
<link>https://arxiv.org/abs/2407.07917</link>
<guid>https://arxiv.org/abs/2407.07917</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Backdoor Attacks, Triggers, Decentralized Nature, Robust Defenses

总结:<br />Federated Learning（FL）是一种分布式模型训练方法，旨在保护用户隐私。然而，它易受后门攻击，尤其是非合作式多触发攻击，这种攻击由独立的攻击者引入针对不同类别的独特触发器，利用FL的去中心化特性，使得检测困难。研究发现，即使单个后门被成功学习，不会影响主要任务，FL仍然面临严重威胁。这强调了对多样化的后门攻击防御的迫切需求。该研究通过实证分析，揭示了FL在现实场景中的脆弱性，提醒了未来研究关注更逼真的攻击设置，以及FL在构建抵御多类型后门威胁方面的重要性。相关代码可在指定链接获取。 <div>
arXiv:2407.07917v1 Announce Type: new 
Abstract: Despite the promise of Federated Learning (FL) for privacy-preserving model training on distributed data, it remains susceptible to backdoor attacks. These attacks manipulate models by embedding triggers (specific input patterns) in the training data, forcing misclassification as predefined classes during deployment. Traditional single-trigger attacks and recent work on cooperative multiple-trigger attacks, where clients collaborate, highlight limitations in attack realism due to coordination requirements. We investigate a more alarming scenario: non-cooperative multiple-trigger attacks. Here, independent adversaries introduce distinct triggers targeting unique classes. These parallel attacks exploit FL's decentralized nature, making detection difficult. Our experiments demonstrate the alarming vulnerability of FL to such attacks, where individual backdoors can be successfully learned without impacting the main task. This research emphasizes the critical need for robust defenses against diverse backdoor attacks in the evolving FL landscape. While our focus is on empirical analysis, we believe it can guide backdoor research toward more realistic settings, highlighting the crucial role of FL in building robust defenses against diverse backdoor threats. The code is available at \url{https://anonymous.4open.science/r/nba-980F/}.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Trustworthy AIoT-enabled Localization System via Federated Learning and Blockchain</title>
<link>https://arxiv.org/abs/2407.07921</link>
<guid>https://arxiv.org/abs/2407.07921</guid>
<content:encoded><![CDATA[
<div> 关键词：indoor localization, RF sensors, fingerprinting, federated learning, blockchain

总结:<br />
本文提出了一种新型的室内定位框架DFLoc，旨在解决使用RF传感器和机器学习进行智能建筑定位时遇到的安全与隐私问题。DFLoc利用区块链技术来分散依赖中央服务器的任务，如模型分发和聚合，以防止单点故障，确保系统的可靠性和精度。此外，它引入了更新的模型验证机制，以抵御恶意节点攻击。实验结果表明，DFLoc不仅能提供精确的三维位置预测，还比传统集中式联邦学习系统更能抵抗这些安全威胁。 <div>
arXiv:2407.07921v1 Announce Type: new 
Abstract: There is a significant demand for indoor localization technology in smart buildings, and the most promising solution in this field is using RF sensors and fingerprinting-based methods that employ machine learning models trained on crowd-sourced user data gathered from IoT devices. However, this raises security and privacy issues in practice. Some researchers propose to use federated learning to partially overcome privacy problems, but there still remain security concerns, e.g., single-point failure and malicious attacks. In this paper, we propose a framework named DFLoc to achieve precise 3D localization tasks while considering the following two security concerns. Particularly, we design a specialized blockchain to decentralize the framework by distributing the tasks such as model distribution and aggregation which are handled by a central server to all clients in most previous works, to address the issue of the single-point failure for a reliable and accurate indoor localization system. Moreover, we introduce an updated model verification mechanism within the blockchain to alleviate the concern of malicious node attacks. Experimental results substantiate the framework's capacity to deliver accurate 3D location predictions and its superior resistance to the impacts of single-point failure and malicious attacks when compared to conventional centralized federated learning systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulnerability Detection in Smart Contracts: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2407.07922</link>
<guid>https://arxiv.org/abs/2407.07922</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, machine learning, vulnerability detection, mitigation, systematic review

总结:
本文主要探讨了机器学习在智能合约安全领域的应用。研究通过系统性回顾88篇相关文献，发现古典机器学习方法如KNN、RF、DT、XG-Boost和SVM在检测智能合约漏洞方面优于静态工具。深度学习与传统方法结合的多模型策略显示出显著提高的精度和召回率。混合模型采用多种技术接近完美的检测准确性。文章强调了整合现有解决方案的重要性，揭示了研究空白，并为学术界、行业专家和对提升智能合约安全感兴趣的各方提供了未来研究方向的指引。 <div>
arXiv:2407.07922v1 Announce Type: new 
Abstract: In the growing field of blockchain technology, smart contracts exist as transformative digital agreements that execute transactions autonomously in decentralised networks. However, these contracts face challenges in the form of security vulnerabilities, posing significant financial and operational risks. While traditional methods to detect and mitigate vulnerabilities in smart contracts are limited due to a lack of comprehensiveness and effectiveness, integrating advanced machine learning technologies presents an attractive approach to increasing effective vulnerability countermeasures. We endeavour to fill an important gap in the existing literature by conducting a rigorous systematic review, exploring the intersection between machine learning and smart contracts. Specifically, the study examines the potential of machine learning techniques to improve the detection and mitigation of vulnerabilities in smart contracts. We analysed 88 articles published between 2018 and 2023 from the following databases: IEEE, ACM, ScienceDirect, Scopus, and Google Scholar. The findings reveal that classical machine learning techniques, including KNN, RF, DT, XG-Boost, and SVM, outperform static tools in vulnerability detection. Moreover, multi-model approaches integrating deep learning and classical machine learning show significant improvements in precision and recall, while hybrid models employing various techniques achieve near-perfect performance in vulnerability detection accuracy.
  By integrating state-of-the-art solutions, this work synthesises current methods, thoroughly investigates research gaps, and suggests directions for future studies. The insights gathered from this study are intended to serve as a seminal reference for academics, industry experts, and bodies interested in leveraging machine learning to enhance smart contract security.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities</title>
<link>https://arxiv.org/abs/2407.07966</link>
<guid>https://arxiv.org/abs/2407.07966</guid>
<content:encoded><![CDATA[
<div> 关键词：智能电网、安全、攻击策略、防御策略、机器学习

总结:<br />
本文对智能电网的安全进行了全面深入的研究，重点关注了系统架构、新型攻击手段和复杂协调攻击。文章探讨了各种防御策略，如游戏理论、图论、区块链和机器学习在对抗不断演变威胁中的应用，特别是详细分析了机器学习在识别和抵御攻击中的作用及其挑战。未来研究方向涉及现有技术的优化和新方法的探索，如大型语言模型（LLMs）以及对抗性机器学习的潜在威胁。总的来说，本文为智能电网安全领域的未来发展提供了有价值的见解和前瞻性思考。 <div>
arXiv:2407.07966v1 Announce Type: new 
Abstract: In this study, we conduct a comprehensive review of smart grid security, exploring system architectures, attack methodologies, defense strategies, and future research opportunities. We provide an in-depth analysis of various attack vectors, focusing on new attack surfaces introduced by advanced components in smart grids. The review particularly includes an extensive analysis of coordinated attacks that incorporate multiple attack strategies and exploit vulnerabilities across various smart grid components to increase their adverse impact, demonstrating the complexity and potential severity of these threats. Following this, we examine innovative detection and mitigation strategies, including game theory, graph theory, blockchain, and machine learning, discussing their advancements in counteracting evolving threats and associated research challenges. In particular, our review covers a thorough examination of widely used machine learning-based mitigation strategies, analyzing their applications and research challenges spanning across supervised, unsupervised, semi-supervised, ensemble, and reinforcement learning. Further, we outline future research directions and explore new techniques and concerns. We first discuss the research opportunities for existing and emerging strategies, and then explore the potential role of new techniques, such as large language models (LLMs), and the emerging threat of adversarial machine learning in the future of smart grid security.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Adaptive Aerospace Transportation of Unknown Loads Using A Team of Robots</title>
<link>https://arxiv.org/abs/2407.08084</link>
<guid>https://arxiv.org/abs/2407.08084</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized adaptive controller, aerospace robots, unknown objects, gravity environments, cooperative transportation

总结:<br />本文介绍了一种新颖的分布式自适应控制器设计，适用于不同类型的航空航天机器人，如多旋翼无人机和空间拖船。该控制器能够适应各种未知物体，并在不同重力条件下运行。研究通过实验验证了这一方法，包括使用全驱动六轴飞行器进行空中协同载物任务，以及空间拖船在太空环境中的操作。控制器展现出对运输过程中机器人损失等意外情况的适应能力，提高了任务执行的灵活性和可靠性。 <div>
arXiv:2407.08084v1 Announce Type: new 
Abstract: Transportation missions in aerospace are limited to the capability of each aerospace robot and the properties of the target transported object, such as mass, inertia, and grasping locations. We present a novel decentralized adaptive controller design for multiple robots that can be implemented in different kinds of aerospace robots. Our controller adapts to unknown objects in different gravity environments. We validate our method in an aerial scenario using multiple fully actuated hexarotors with grasping capabilities, and a space scenario using a group of space tugs. In both scenarios, the robots transport a payload cooperatively through desired three-dimensional trajectories. We show that our method can adapt to unexpected changes that include the loss of robots during the transportation mission.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>United We Stand: Decentralized Multi-Agent Planning With Attrition</title>
<link>https://arxiv.org/abs/2407.08254</link>
<guid>https://arxiv.org/abs/2407.08254</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized planning, Agent failures, Attritable MCTS (A-MCTS), Global reward function, Regret matching.

总结:<br />
本文提出了一种新型的分布式算法——Attritable MCTS (A-MCTS)，旨在解决大规模协作多代理系统中的信息采集任务。在频繁的代理失败情况下，当前方法存在无法收敛或资源利用效率低的问题。A-MCTS通过全局奖励函数评估每个代理的局部贡献，并采用后悔匹配进行协调，以实现及时且高效的适应性。实验结果表明，即使在高失败率环境中，A-MCTS也能显著提高全球效用和可扩展性，优于现有最佳方案。 <div>
arXiv:2407.08254v1 Announce Type: new 
Abstract: Decentralized planning is a key element of cooperative multi-agent systems for information gathering tasks. However, despite the high frequency of agent failures in realistic large deployment scenarios, current approaches perform poorly in the presence of failures, by not converging at all, and/or by making very inefficient use of resources (e.g. energy). In this work, we propose Attritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and efficient adaptation to changes in the set of active agents. It is based on the use of a global reward function for the estimation of each agent's local contribution, and regret matching for coordination. We evaluate its effectiveness in realistic data-harvesting problems under different scenarios. We show both theoretically and experimentally that A-MCTS enables efficient adaptation even under high failure rates. Results suggest that, in the presence of frequent failures, our solution improves substantially over the best existing approaches in terms of global utility and scalability.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Performance Evaluation of Hashing Algorithms on Commodity Hardware</title>
<link>https://arxiv.org/abs/2407.08284</link>
<guid>https://arxiv.org/abs/2407.08284</guid>
<content:encoded><![CDATA[
<div> 关键词：Blake3, SHA-256, SHA-512, hashing algorithms, performance evaluation.

总结:<br />
这篇文章主要关注了三种广泛应用于区块链网络的哈希算法：Blake3、SHA-256和SHA-512。研究者对这些算法进行了性能评估，重点关注了计算速率（hash rate）、内存使用和延迟等指标。实验在不同硬件平台上进行，包括桌面和虚拟机，还涉及了合成基准测试。结果表明，Blake3通常在吞吐量和延迟方面优于SHA-256和SHA-512。然而，其优势取决于硬件和输入数据大小。报告给出了根据应用需求（如性能和安全性）选择合适哈希算法的建议，并为未来算法优化提供了依据。 <div>
arXiv:2407.08284v1 Announce Type: new 
Abstract: Hashing functions, which are created to provide brief and erratic digests for the message entered, are the primary cryptographic primitives used in blockchain networks. Hashing is employed in blockchain networks to create linked block lists, which offer safe and secure distributed repository storage for critical information. Due to the unique nature of the hash search problem in blockchain networks, the most parallelization of calculations is possible. This technical report presents a performance evaluation of three popular hashing algorithms Blake3, SHA-256, and SHA-512. These hashing algorithms are widely used in various applications, such as digital signatures, message authentication, and password storage. It then discusses the performance metrics used to evaluate the algorithms, such as hash rate/throughput and memory usage. The evaluation is conducted on a range of hardware platforms, including desktop and VMs. The evaluation includes synthetic benchmarks. The results of the evaluation show that Blake3 generally outperforms both SHA-256 and SHA-512 in terms of throughput and latency. However, the performance advantage of Blake3 varies depending on the specific hardware platform and the size of the input data. The report concludes with recommendations for selecting the most suitable hashing algorithm for a given application, based on its performance requirements and security needs. The evaluation results can also inform future research and development efforts to improve the performance and security of hashing algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BriDe Arbitrager: Enhancing Arbitrage in Ethereum 2.0 via Bribery-enabled Delayed Block Production</title>
<link>https://arxiv.org/abs/2407.08537</link>
<guid>https://arxiv.org/abs/2407.08537</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum 2.0、Proof-of-Stake、BriDe Arbitrager、Bribery-driven attacks、Arbitrage

总结:<br />
Ethereum 2.0的PoS转变引发了新的挑战，BriDe Arbitrager应运而生。这个工具利用贿赂策略延迟区块生产，为恶意提议者提供更多时间发现套利机会，设计有适应性贿赂策略和延迟交易排序算法，以增加利润。通过智能合约和贿赂客户端实现自动化与公平，即使在Proposer Builder分离等机制下也能保持有效性。实验数据显示，BriDe Arbitrager每天可实现平均8.66 ETH（约16,442.23 USD）的利润，且不触发惩罚机制。 <div>
arXiv:2407.08537v1 Announce Type: new 
Abstract: The advent of Ethereum 2.0 has introduced significant changes, particularly the shift to Proof-of-Stake consensus. This change presents new opportunities and challenges for arbitrage. Amidst these changes, we introduce BriDe Arbitrager, a novel tool designed for Ethereum 2.0 that leverages Bribery-driven attacks to Delay block production and increase arbitrage gains. The main idea is to allow malicious proposers to delay block production by bribing validators/proposers, thereby gaining more time to identify arbitrage opportunities. Through analysing the bribery process, we design an adaptive bribery strategy. Additionally, we propose a Delayed Transaction Ordering Algorithm to leverage the delayed time to amplify arbitrage profits for malicious proposers. To ensure fairness and automate the bribery process, we design and implement a bribery smart contract and a bribery client. As a result, BriDe Arbitrager enables adversaries controlling a limited (< 1/4) fraction of the voting powers to delay block production via bribery and arbitrage more profit. Extensive experimental results based on Ethereum historical transactions demonstrate that BriDe Arbitrager yields an average of 8.66 ETH (16,442.23 USD) daily profits. Furthermore, our approach does not trigger any slashing mechanisms and remains effective even under Proposer Builder Separation and other potential mechanisms will be adopted by Ethereum.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Generalization Error Matters in Decentralized Learning Under Byzantine Attacks</title>
<link>https://arxiv.org/abs/2407.08632</link>
<guid>https://arxiv.org/abs/2407.08632</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Learning, Byzantine-resilient, Stochastic Gradient Descent (DSGD), Generalization Errors, Theoretical Analysis.

总结:<br />
本文关注的是去中心化学习中的一个重要问题，尤其是在存在恶意（Byzantine）节点的情况下。研究者首次对一类流行的抗拜占庭分布式随机梯度下降（DSGD）算法的泛化误差进行了理论分析。他们的发现令人惊讶，即使训练样本数量无限大，由于拜占庭节点的存在，泛化误差也无法完全消除。实验结果进一步验证了这一理论。这项工作填补了当前去中心化学习中关于模型泛化性能理解的空白，对于实际应用具有重要指导意义。 <div>
arXiv:2407.08632v1 Announce Type: new 
Abstract: Recently, decentralized learning has emerged as a popular peer-to-peer signal and information processing paradigm that enables model training across geographically distributed agents in a scalable manner, without the presence of any central server. When some of the agents are malicious (also termed as Byzantine), resilient decentralized learning algorithms are able to limit the impact of these Byzantine agents without knowing their number and identities, and have guaranteed optimization errors. However, analysis of the generalization errors, which are critical to implementations of the trained models, is still lacking. In this paper, we provide the first analysis of the generalization errors for a class of popular Byzantine-resilient decentralized stochastic gradient descent (DSGD) algorithms. Our theoretical results reveal that the generalization errors cannot be entirely eliminated because of the presence of the Byzantine agents, even if the number of training samples are infinitely large. Numerical experiments are conducted to confirm our theoretical results.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SpiralShard: Highly Concurrent and Secure Blockchain Sharding via Linked Cross-shard Endorsement</title>
<link>https://arxiv.org/abs/2407.08651</link>
<guid>https://arxiv.org/abs/2407.08651</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain sharding, SpiralShard, malicious nodes, Linked Cross-shard Endorsement (LCE), throughput gain.

总结:<br />
区块链分片技术（Blockchain sharding）旨在提升系统扩展性，但现有方案因依赖大量安全的分片而限制了并发。SpiralShard提出了一种创新方法，通过容忍部分恶意节点的较大分片（即“脏”分片），减小单个分片大小，从而增加并发处理。文章的核心贡献是Linked Cross-shard Endorsement (LCE)协议，确保在存在脏分片的情况下，通过其他分片的协作验证和最终确认，维持系统的安全性。实验基于Harmony平台进行，结果显示，与Harmony相比，SpiralShard在大型网络（4000+节点）下能实现约19倍的吞吐量提升。 <div>
arXiv:2407.08651v1 Announce Type: new 
Abstract: Blockchain sharding improves the scalability of blockchain systems by partitioning the whole blockchain state, nodes, and transaction workloads into different shards. However, existing blockchain sharding systems generally suffer from a small number of shards, resulting in limited concurrency. The main reason is that existing sharding systems require large shard sizes to ensure security. To enhance the concurrency of blockchain sharding securely, we propose SpiralShard. The intuition is to allow the existence of some shards with a larger fraction of malicious nodes (i.e., corrupted shards), thus reducing shard sizes. SpiralShard can configure more and smaller shards for higher concurrency at the same network size. To ensure security with the existence of corrupted shards, we propose the Linked Cross-shard Endorsement (LCE) protocol. According to our LCE protocol, the blocks of each shard are sequentially verified and endorsed by a group of shards before being finalized. As a result, a corrupted shard can eliminate forks with the help of the other shards. We implement SpiralShard based on Harmony and conduct extensive evaluations. Experimental results show that, compared with Harmony, SpiralShard achieves around 19x throughput gain under a large network size with 4,000+ nodes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Balancing Participation and Decentralization in Proof-of-Stake Cryptocurrencies</title>
<link>https://arxiv.org/abs/2407.08686</link>
<guid>https://arxiv.org/abs/2407.08686</guid>
<content:encoded><![CDATA[
<div> 关键词：proof-of-stake, blockchain, stake delegation, payment schemes, decentralization

总结: 本文主要探讨了基于权益证明（Proof-of-Stake, PoS）的区块链协议中，一种称为权益委托（stake delegation）的参与形式。权益委托允许代理将其权益委托给活跃的验证者，即池操作员，以促进交易验证过程。研究了作为激励机制的支付方案，这些方案根据参与者集体行为调整奖励，旨在保持系统的去中心化同时鼓励参与。文章分析了不同支付方案之间的权衡，特别是在费用支出与平衡安全、去中心化目标之间的关系。最后，作者提出了一种能在贝叶斯博弈理论框架下达到不同目标均衡的支付方案家族。 <div>
arXiv:2407.08686v1 Announce Type: new 
Abstract: Proof-of-stake blockchain protocols have emerged as a compelling paradigm for organizing distributed ledger systems. In proof-of-stake (PoS), a subset of stakeholders participate in validating a growing ledger of transactions. For the safety and liveness of the underlying system, it is desirable for the set of validators to include multiple independent entities as well as represent a non-negligible percentage of the total stake issued. In this paper, we study a secondary form of participation in the transaction validation process, which takes the form of stake delegation, whereby an agent delegates their stake to an active validator who acts as a stake pool operator. We study payment schemes that reward agents as a function of their collective actions regarding stake pool operation and delegation. Such payment schemes serve as a mechanism to incentivize participation in the validation process while maintaining decentralization. We observe natural trade-offs between these objectives and the total expenditure required to run the relevant payment schemes. Ultimately, we provide a family of payment schemes which can strike different balances between these competing objectives at equilibrium in a Bayesian game theoretic framework.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Clap: a Semantic-Preserving Optimizing eDSL for Plonkish Proof Systems</title>
<link>https://arxiv.org/abs/2405.12115</link>
<guid>https://arxiv.org/abs/2405.12115</guid>
<content:encoded><![CDATA[
<div> 关键词：Plonkish、Rust eDSL、Clap、零知识证明系统、自动优化。

总结:<br />
Plonkish是一种流行的电路格式，用于开发零知识证明系统，在区块链项目中占据重要地位。然而，这些项目依赖于手工优化的电路，测试和审计耗时且复杂。为此，研究人员提出了Clap，这是一种基于Rust的eDSL（领域特定语言），它提供了一种与证明系统无关的电路格式。Clap将转换Plonkish约束系统和生成器视为一种保持语义的编译问题，确保了变换的正确性和完整性，避免了因过度或不足约束导致的潜在错误。实验表明，Clap的自动优化功能优于手动优化，并能自动生成定制门。总的来说，Clap为零知识证明系统的电路设计提供了更高效、可扩展和形式化的方法。 <div>
arXiv:2405.12115v2 Announce Type: replace 
Abstract: Plonkish is a popular circuit format for developing zero-knowledge proof systems that powers a number of major projects in the blockchain space, responsible for holding billions of dollars and processing millions of transactions per day. These projects, including zero-knowledge rollups, rely on highly hand-optimized circuits whose correctness comes at the cost of time-consuming testing and auditing.
  In this paper, we present Clap, the first Rust eDSL with a proof system agnostic circuit format, facilitating extensibility, automatic optimizations, and formal assurances for the resultant constraint system. Clap casts the problem of producing Plonkish constraint systems and their witness generators as a semantic-preserving compilation problem. Soundness and completeness of the transformation guarantees the absence of subtle bugs caused by under- or over-constraining. Our experimental evaluation shows that its automatic optimizations achieve better performance compared to manual circuit optimization. The optimizer can also be used to automatically derive custom gates from circuit descriptions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Optimal Sharding for Scalable Blockchains with Deconstructed SMR</title>
<link>https://arxiv.org/abs/2406.08252</link>
<guid>https://arxiv.org/abs/2406.08252</guid>
<content:encoded><![CDATA[
<div> 关键词：Sharding, Blockchain, Scalability, Byzantine Faults, Arete

总结:<br />
这篇文章探讨了区块链扩容中的"大小-安全"困境，即每个分片需要足够大以保证安全，但这样限制了分片的效率和数量。作者提出了Arete协议，通过提高单个分片对拜占庭故障的容忍度来解决这一问题。Arete将区块链的状态机复制（SMR）过程分为交易传播、排序和执行三个步骤，其中只有一个排序分片负责排序，多个处理分片负责传播和执行区块，从而实现更高安全性。同时，Arete分离了安全性和可用性，允许暂时容忍临时的可用性违反，以创建更小、更优化的分片。此外，Arete的SMR重构还支持新的认证-排序-执行架构，实现交易处理的完全并行，显著提升性能。实验结果表明，Arete在AWS环境下优于现有最先进的分片协议。 <div>
arXiv:2406.08252v2 Announce Type: replace 
Abstract: Sharding is proposed to enhance blockchain scalability. However, a size-security dilemma where every shard must be large enough to ensure its security constrains the efficacy of individual shards and the degree of sharding itself. Most existing sharding solutions therefore rely on either weakening the adversary or making stronger assumptions on network links.
  This paper presents Arete, an optimally scalable blockchain sharding protocol designed to resolve the dilemma based on an observation that if individual shards can tolerate a higher fraction of (Byzantine) faults, we can securely create smaller shards in a larger quantity. The key idea of Arete, therefore, is to improve the security resilience/threshold of shards by dividing the blockchain's State Machine Replication (SMR) process itself. Similar to modern blockchains, Arete first decouples SMR in three steps: transaction dissemination, ordering, and execution. However, unlike other blockchains, for Arete, a single ordering shard performs the ordering task while multiple processing shards perform the dissemination and execution of blocks. As processing shards do not run consensus, each of those can tolerate up to half compromised nodes. Moreover, the SMR process in the ordering shard is lightweight as it only operates on the block digests. Second, Arete considers safety and liveness against Byzantine failures separately to improve the safety threshold further while tolerating temporary liveness violations in a controlled manner. Apart from the creation of more optimal-size shards, such a deconstructed SMR scheme also empowers us to devise a novel certify-order-execute architecture to fully parallelize transaction handling, thereby improving the performance of sharded blockchain systems. We implement Arete and evaluate it on a geo-distributed AWS environment, showing that Arete outperforms the state-of-the-art sharding protocol.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FedClust: Tackling Data Heterogeneity in Federated Learning through Weight-Driven Client Clustering</title>
<link>https://arxiv.org/abs/2407.07124</link>
<guid>https://arxiv.org/abs/2407.07124</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Clustering, Data Heterogeneity, Local Model Weights, Communication Cost

总结:<br />
这篇文章探讨了联邦学习（Federated Learning）中的一个重要挑战，即数据分布不均匀（Data Heterogeneity）。为解决这一问题，作者提出了FedClust方法，这是一种新颖的集群化联邦学习策略。FedClust通过分析客户端本地模型权重与数据分布的相关性，实现在一次训练中动态形成学习群组，无需等待长时间的集群稳定。实验结果表明，FedClust相较于现有方法在模型精度上提升高达45%，并且能以2.7倍的通信成本降低实现更快收敛。总结起来，FedClust通过有效利用局部模型权重，提高了集群化联邦学习的效率和准确性。 <div>
arXiv:2407.07124v1 Announce Type: new 
Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm that enables collaborative training of machine learning models over decentralized devices without exposing their local data. One of the major challenges in FL is the presence of uneven data distributions across client devices, violating the well-known assumption of independent-and-identically-distributed (IID) training samples in conventional machine learning. To address the performance degradation issue incurred by such data heterogeneity, clustered federated learning (CFL) shows its promise by grouping clients into separate learning clusters based on the similarity of their local data distributions. However, state-of-the-art CFL approaches require a large number of communication rounds to learn the distribution similarities during training until the formation of clusters is stabilized. Moreover, some of these algorithms heavily rely on a predefined number of clusters, thus limiting their flexibility and adaptability. In this paper, we propose {\em FedClust}, a novel approach for CFL that leverages the correlation between local model weights and the data distribution of clients. {\em FedClust} groups clients into clusters in a one-shot manner by measuring the similarity degrees among clients based on the strategically selected partial weights of locally trained models. We conduct extensive experiments on four benchmark datasets with different non-IID data settings. Experimental results demonstrate that {\em FedClust} achieves higher model accuracy up to $\sim$45\% as well as faster convergence with a significantly reduced communication cost up to 2.7$\times$ compared to its state-of-the-art counterparts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Support and Scandals in GameFi dApps: A Network Analysis of The Sandbox Transactions</title>
<link>https://arxiv.org/abs/2407.07138</link>
<guid>https://arxiv.org/abs/2407.07138</guid>
<content:encoded><![CDATA[
<div> 关键词：GameFi、The Sandbox、网络分析、交易数据、鲸鱼用户

总结:<br />The Sandbox是一个GameFi领域的关键应用，研究通过详细的网络分析对其进行了探索。利用弓形图模型，研究揭示了Sandbox内的交易动态和外部支持对网络活动的影响，发现其结构相对稳健，仅受短期事件影响有限。"鲸鱼"用户在影响网络趋势方面扮演重要角色，且他们的参与度随着时间演变。研究还指出GameFi生态系统与Web、AI社会的交织，以及其与传统网络行为的相似性。这些发现对发展公平、可持续的GameFi应用有启示，强调了在面对挑战和机遇时，理解用户行为和网络韧性的重要性。 <div>
arXiv:2407.07138v1 Announce Type: new 
Abstract: We explore the burgeoning field of GameFi through a detailed network analysis of The Sandbox, a prominent decentralized application (dApp) in this domain. Utilizing the bow-tie model, we map out transaction data within The Sandbox, providing a novel perspective on its operational dynamics. Our study investigates the varying impacts of external support, uncovering a surprising absence of enduring effects on network activity. We also investigate the network's response to several notable incidents, including the Ronin Hack and the United States Securities and Exchange Commission's hearing on cryptocurrencies, revealing a generally resilient structure with limited long-term disturbances. A critical aspect of our analysis focuses on the "whales," or major stakeholders in The Sandbox, where we uncover their pivotal role in influencing network trends, noting a significant shift in their engagement over time. This research sheds light on the intricate workings of GameFi ecosystems and contributes to the broader discourse on the intersection of the Web, AI, and society, particularly in understanding the resilience and dynamics of emerging digital economies. We particularly note the parallels of the long-tail behavior we see in web-based ecosystems appearing in this niche domain of GameFi. Our findings hold significant implications for the future development of equitable and sustainable GameFi dApps, offering insights into stakeholder behavior and network resilience in the face of external challenges and opportunities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Service Colonies: A Novel Architectural Style for Developing Software Systems with Autonomous and Cooperative Services</title>
<link>https://arxiv.org/abs/2407.07267</link>
<guid>https://arxiv.org/abs/2407.07267</guid>
<content:encoded><![CDATA[
<div> 关键词：服务殖民地、自主服务、系统功能、自我意识、分布式系统。

总结:<br />本文提出了"服务殖民地"这一新颖的软件架构理念。它由一系列自治服务组成，每个服务负责特定的系统功能，通过协作实现整体目标。服务之间具有高度的自我意识和自主决策能力，这使得整个系统更具备分布式、灵活、适应性强、模块化、健壮和容错的特点。这种设计旨在打造更加分散、高效和可靠的软件系统。 <div>
arXiv:2407.07267v1 Announce Type: new 
Abstract: This paper presents the concept of a service colony and its characteristics. A service colony is a novel architectural style for developing a software system as a group of autonomous software services co-operating to fulfill the objectives of the system. Each inhabitant service in the colony implements a specific system functionality, collaborates with the other services, and makes proactive decisions that impact its performance and interaction patterns with other inhabitants. By increasing the level of self-awareness and autonomy available to individual system components, the resulting system is increasingly more decentralized, distributed, flexible, adaptable, distributed, modular, robust, and fault-tolerant.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>TDML -- A Trustworthy Distributed Machine Learning Framework</title>
<link>https://arxiv.org/abs/2407.07339</link>
<guid>https://arxiv.org/abs/2407.07339</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、大规模模型、GPU需求、分布式机器学习、区块链技术。

总结:
近年来，深度学习发展迅速，大型生成模型如SORA和GPT等引领潮流。然而，这些模型对GPU资源的需求激增，尤其是在面临供应链问题和市场集中度提高的背景下。为解决这一挑战，分布式机器学习（DML）如联邦学习（FL）被提出，但优化实践复杂。本文提出了“可信分布式机器学习”（TDML）框架，利用区块链协调远程训练者、验证工作负载，确保隐私、透明度和在公共远程计算资源上的高效模型训练。实验验证了TDML在性能提升和恶意节点检测方面的有效性，表明它为大规模和安全的分布式机器学习提供了一种强大解决方案。 <div>
arXiv:2407.07339v1 Announce Type: new 
Abstract: Recent years have witnessed a surge in deep learning research, marked by the introduction of expansive generative models like OpenAI's SORA and GPT, Meta AI's LLAMA series, and Google's FLAN, BART, and Gemini models. However, the rapid advancement of large models (LM) has intensified the demand for computing resources, particularly GPUs, which are crucial for their parallel processing capabilities. This demand is exacerbated by limited GPU availability due to supply chain delays and monopolistic acquisition by major tech firms. Distributed Machine Learning (DML) methods, such as Federated Learning (FL), mitigate these challenges by partitioning data and models across multiple servers, though implementing optimizations like tensor and pipeline parallelism remains complex. Blockchain technology emerges as a promising solution, ensuring data integrity, scalability, and trust in distributed computing environments, but still lacks guidance on building practical DML systems. In this paper, we propose a \textit{trustworthy distributed machine learning} (TDML) framework that leverages blockchain to coordinate remote trainers and validate workloads, achieving privacy, transparency, and efficient model training across public remote computing resources. Experimental validation demonstrates TDML's efficacy in overcoming performance limitations and malicious node detection, positioning it as a robust solution for scalable and secure distributed machine learning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Searcher Competition in Block Building</title>
<link>https://arxiv.org/abs/2407.07474</link>
<guid>https://arxiv.org/abs/2407.07474</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、验证者、竞争性、核心概念、价值分配。

总结: <br />该研究论文探讨了以太坊等具有竞争性挖矿市场的区块链中，验证者从最大可提取价值（MEV）中获取的份额，重点关注搜索者竞争的影响。核心概念被提出作为分析工具，其预测独立于具体机制。论文揭示了验证者提取的价值与其与搜索者的竞争程度有关：在高度竞争下，验证者几乎肯定获得全部价值；而在低竞争情况下，搜索者可能占据大部分。对于被动提议者，研究发现存在一种独特的激励兼容机制，能使每个搜索者得到其对获胜区块边际贡献的价值。此外，作者通过实际数据验证了理论预测，即提交回滚次数与验证者从机会中获取的价值有正相关关系。 <div>
arXiv:2407.07474v1 Announce Type: new 
Abstract: We study the amount of maximal extractable value (MEV) captured by validators, as a function of searcher competition, in blockchains with competitive block building markets such as Ethereum. We argue that the core is a suitable solution concept in this context that makes robust predictions that are independent of implementation details or specific mechanisms chosen. We characterize how much value validators extract in the core and quantify the surplus share of validators as a function of searcher competition. Searchers can obtain at most the marginal value increase of the winning block relative to the best block that can be built without their bundles. Dually this gives a lower bound on the value extracted by the validator. If arbitrages are easy to find and many searchers find similar bundles, the validator gets paid all value almost surely, while searchers can capture most value if there is little searcher competition per arbitrage. For the case of passive block-proposers we study, moreover, mechanisms that implement core allocations in dominant strategies and find that for submodular value, there is a unique dominant-strategy incentive compatible core-selecting mechanism that gives each searcher exactly their marginal value contribution to the winning block. We validate our theoretical prediction empirically with aggregate bundle data and find a significant positive relation between the number of submitted backruns for the same opportunity and the median value captured by the proposer from the opportunity.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training</title>
<link>https://arxiv.org/abs/2407.07852</link>
<guid>https://arxiv.org/abs/2407.07852</guid>
<content:encoded><![CDATA[
<div> 关键词：OpenDiLoCo, 开源, 分布式训练, 大语言模型, Hivemind.

总结:
OpenDiLoCo是一个开源的分布式低通信(DiLoCo)训练方法实现，用于大规模语言模型。它基于Hivemind库，提供了可扩展的、去中心化的训练框架。研究者在多国跨洲环境下展示了该方法的有效性，保持了高达90-95%的计算利用率。文章还进行了算法效率、工作量扩展以及使用FP16进行全量归一化实验，证明其适应性。最后，OpenDiLoCo被扩展到比原工作大三倍的模型规模，验证了其对百亿参数模型的适用性。 <div>
arXiv:2407.07852v1 Announce Type: new 
Abstract: OpenDiLoCo is an open-source implementation and replication of the Distributed Low-Communication (DiLoCo) training method for large language models. We provide a reproducible implementation of the DiLoCo experiments, offering it within a scalable, decentralized training framework using the Hivemind library. We demonstrate its effectiveness by training a model across two continents and three countries, while maintaining 90-95% compute utilization. Additionally, we conduct ablations studies focusing on the algorithm's compute efficiency, scalability in the number of workers and show that its gradients can be all-reduced using FP16 without any performance degradation. Furthermore, we scale OpenDiLoCo to 3x the size of the original work, demonstrating its effectiveness for billion parameter models.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Federated Foundation Model for Cardiac CT Imaging</title>
<link>https://arxiv.org/abs/2407.07557</link>
<guid>https://arxiv.org/abs/2407.07557</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, partially labeled datasets, Transformer architectures, semi-supervised learning, cardiac CT imaging.

总结:<br />
该研究关注联邦学习中的部分标注数据挑战，特别是在心脏CT成像分析中。通过Transformer架构与传统的CNNs对比，提出了一种两阶段的半监督学习策略，利用大量未标注数据提升Transformer模型性能。这种方法不仅提高了预测精度和泛化能力，还允许在一个单一Transformer模型中同时学习所有部分标签。研究者展示了Transformer模型在特征提取方面优于基于UNet的模型，且仅需训练最后一层就能进行冠状动脉分割。研究成果以开源代码和权重的形式提供，为心脏CT成像领域的后续研究奠定了基础。 <div>
arXiv:2407.07557v1 Announce Type: cross 
Abstract: Federated learning (FL) is a renowned technique for utilizing decentralized data while preserving privacy. However, real-world applications often involve inherent challenges such as partially labeled datasets, where not all clients possess expert annotations of all labels of interest, leaving large portions of unlabeled data unused. In this study, we conduct the largest federated cardiac CT imaging analysis to date, focusing on partially labeled datasets ($n=8,124$) of Transcatheter Aortic Valve Implantation (TAVI) patients over eight hospital clients. Transformer architectures, which are the major building blocks of current foundation models, have shown superior performance when trained on larger cohorts than traditional CNNs. However, when trained on small task-specific labeled sample sizes, it is currently not feasible to exploit their underlying attention mechanism for improved performance. Therefore, we developed a two-stage semi-supervised learning strategy that distills knowledge from several task-specific CNNs (landmark detection and segmentation of calcification) into a single transformer model by utilizing large amounts of unlabeled data typically residing unused in hospitals to mitigate these issues. This method not only improves the predictive accuracy and generalizability of transformer-based architectures but also facilitates the simultaneous learning of all partial labels within a single transformer model across the federation. Additionally, we show that our transformer-based model extracts more meaningful features for further downstream tasks than the UNet-based one by only training the last layer to also solve segmentation of coronary arteries. We make the code and weights of the final model openly available, which can serve as a foundation model for further research in cardiac CT imaging.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Jolteon and Ditto: Network-Adaptive Efficient Consensus with Asynchronous Fallback</title>
<link>https://arxiv.org/abs/2106.10362</link>
<guid>https://arxiv.org/abs/2106.10362</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine、state machine replication (SMR)、trade-off、Ditto、communication cost

总结:<br />
本文提出了一种名为Ditto的拜占庭状态机复制协议，旨在打破现有的SMR协议在效率和鲁棒性之间的传统权衡。Ditto在正常情况下具有线性通信成本，而在异步或DDoS攻击期间仍能保证进步。研究者从HotStuff出发，设计了Jolteon，一种利用二次视图切换机制降低延迟的2链HotStuff版本。实验结果显示，Jolteon在系统规模增大时能比HotStuff减少200-300ms的提交延迟。此外，Ditto能够适应网络条件并在故障情况下提供优于Jolteon的性能，同时在无故障情况下优于当前最佳的异步协议VABA。这表明在实践中实现高效和鲁棒性的突破是切实可行的。 <div>
arXiv:2106.10362v4 Announce Type: replace 
Abstract: Existing committee-based Byzantine state machine replication (SMR) protocols, typically deployed in production blockchains, face a clear trade-off: (1) they either achieve linear communication cost in the happy path, but sacrifice liveness during periods of asynchrony, or (2) they are robust (progress with probability one) but pay quadratic communication cost. We believe this trade-off is unwarranted since existing linear protocols still have asymptotic quadratic cost in the worst case. We design Ditto, a Byzantine SMR protocol that enjoys the best of both worlds: optimal communication on and off the happy path (linear and quadratic, respectively) and progress guarantee under asynchrony and DDoS attacks. We achieve this by replacing the view-synchronization of partially synchronous protocols with an asynchronous fallback mechanism at no extra asymptotic cost. Specifically, we start from HotStuff, a state-of-the-art linear protocol, and gradually build Ditto. As a separate contribution and an intermediate step, we design a 2-chain version of HotStuff, Jolteon, which leverages a quadratic view-change mechanism to reduce the latency of the standard 3-chain HotStuff. We implement and experimentally evaluate all our systems. Notably, Jolteon's commit latency outperforms HotStuff by 200-300ms with varying system size. Additionally, Ditto adapts to the network and provides better performance than Jolteon under faulty conditions and better performance than VABA (a state-of-the-art asynchronous protocol) under faultless conditions. This proves our case that breaking the robustness-efficiency trade-off is in the realm of practicality.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Decentralized Market Mechanism for Energy Communities under Operating Envelopes</title>
<link>https://arxiv.org/abs/2402.17201</link>
<guid>https://arxiv.org/abs/2402.17201</guid>
<content:encoded><![CDATA[
<div> 关键词：operating envelopes, energy community, Stackelberg game, two-part pricing, social welfare

总结:<br />
本文提出了一种考虑运营限制（operating envelopes, OE）的能源社区市场机制，该机制利用两部分定价策略对社区成员进行动态收费/奖励。通过将社区运营商与其成员的行为建模为Stackelberg博弈，研究发现这种定价方案能在去中心化下达到纳什均衡，最大化社区的社会福利，同时确保社区运营符合OE。此外，机制遵循成本分摊原则，保证了社区成员的收益至少等于他们单独面对分销系统运营商（DSO）时的最大收益。社区电价随社区可再生能源总产量下降而递减。研究还探讨了NEM费率和OE对外部参数的影响，并通过数值模拟展示了社区福利、电价以及成员收益与DSO制度下的对比。 <div>
arXiv:2402.17201v2 Announce Type: replace 
Abstract: We propose an operating envelopes (OEs) aware energy community market mechanism that dynamically charges/rewards its members based on two-part pricing. The OEs are imposed exogenously by a regulated distribution system operator (DSO) on the energy community's revenue meter and is subject to a generalized net energy metering (NEM) tariff design. By formulating the interaction of the community operator and its members as a Stackelberg game, we show that the proposed two-part pricing achieves a Nash equilibrium and maximizes the community's social welfare in a decentralized fashion while ensuring that the community's operation abides by the OEs. The market mechanism conforms with the cost-causation principle and guarantees community members a surplus level no less than their maximum surplus when they autonomously face the DSO. The dynamic and uniform community price is a monotonically decreasing function of the community's aggregate renewable generation. We also analyze the impact of exogenous parameters such as NEM rates and OEs on the value of joining the community. Lastly, through numerical studies, we showcase the community's welfare, and pricing, and compare its members' surplus to customers under the DSO's regime.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FORAY: Towards Effective Attack Synthesis against Deep Logical Vulnerabilities in DeFi Protocols</title>
<link>https://arxiv.org/abs/2407.06348</link>
<guid>https://arxiv.org/abs/2407.06348</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain, Decentralized Finance (DeFi), smart contract, vulnerability detection, attack synthesis framework.

总结:<br />
区块链技术随着去中心化金融(DeFi)应用的兴起而迅速发展，但其价值巨大使其成为攻击目标。当前的智能合约漏洞检测工具在处理复杂的DeFi协议时面临挑战，因为它们涉及多个智能合约间的深层逻辑错误。为此，研究人员提出了Foray，一个针对DeFi深逻辑漏洞的有效攻击合成框架。Foray首先将低级智能合约提升到金融操作的高级别，通过设计领域特定语言(DSL)构建Token Flow Graph(TFG)。它采用策略性路径寻找生成攻击草图，而非随机枚举，提高效率。对于每个候选草图，Foray进行领域特定的符号编译，简化约束并适用于大规模问题。最后，通过现有求解器完成并转换为实际攻击。Foray有效地应对了DeFi中的复杂安全威胁。 <div>
arXiv:2407.06348v1 Announce Type: new 
Abstract: Blockchain adoption has surged with the rise of Decentralized Finance (DeFi) applications. However, the significant value of digital assets managed by DeFi protocols makes them prime targets for attacks. Current smart contract vulnerability detection tools struggle with DeFi protocols due to deep logical bugs arising from complex financial interactions between multiple smart contracts. These tools primarily analyze individual contracts and resort to brute-force methods for DeFi protocols crossing numerous smart contracts, leading to inefficiency. We introduce Foray, a highly effective attack synthesis framework against deep logical bugs in DeFi protocols. Foray proposes a novel attack sketch generation and completion framework. Specifically, instead of treating DeFis as regular programs, we design a domain-specific language (DSL) to lift the low-level smart contracts into their high-level financial operations. Based on our DSL, we first compile a given DeFi protocol into a token flow graph, our graphical representation of DeFi protocols. Then, we design an efficient sketch generation method to synthesize attack sketches for a certain attack goal (e.g., price manipulation, arbitrage, etc.). This algorithm strategically identifies candidate sketches by finding reachable paths in TFG, which is much more efficient than random enumeration. For each candidate sketch written in our DSL, Foray designs a domain-specific symbolic compilation to compile it into SMT constraints. Our compilation simplifies the constraints by removing redundant smart contract semantics. It maintains the usability of symbolic compilation, yet scales to problems orders of magnitude larger. Finally, the candidates are completed via existing solvers and are transformed into concrete attacks via direct syntax transformation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Toychain: A Simple Blockchain for Research in Swarm Robotics</title>
<link>https://arxiv.org/abs/2407.06630</link>
<guid>https://arxiv.org/abs/2407.06630</guid>
<content:encoded><![CDATA[
<div> 关键词：Toychain, Python, blockchain, robotics, smart contracts.

总结:
Toychain是一个由Python实现的轻量级区块链技术，专为机器人研究设计，易于部署和实用。它支持与ARGoS、Gazebo和ROS2等机器人软件工具集成，也可部署在具备Wi-Fi通信的实体机器人上。Toychain的核心功能是执行用Python编写的智能合约，通过广播交易更新分布式网络的状态，共识协议可以根据研究需求进行定制，目前支持Proof-of-Work和Proof-of-Authority。这个技术简化了在机器人领域应用区块链的过程。 <div>
arXiv:2407.06630v1 Announce Type: new 
Abstract: This technical report describes the implementation of Toychain: a simple, lightweight blockchain implemented in Python, designed for ease of deployment and practicality in robotics research. It can be integrated with various software and simulation tools used in robotics (we have integrated it with ARGoS, Gazebo, and ROS2), and also be deployed on real robots capable of Wi-Fi communications. The Toychain package supports the deployment of smart contracts written in Python (computer programs that can be executed by and synchronized across a distributed network). The nodes in the blockchain can execute smart contract functions by broadcasting transactions, which update the state of the blockchain upon agreement by all other nodes. The conditions for this agreement are established by a consensus protocol. The Toychain package allows for custom implementations of the consensus protocol, which can be useful for research or meeting specific application requirements. Currently, Proof-of-Work and Proof-of-Authority are implemented.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Cost of Executing Business Processes on Next-Generation Blockchains: The Case of Algorand</title>
<link>https://arxiv.org/abs/2407.06725</link>
<guid>https://arxiv.org/abs/2407.06725</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, process execution, Algorand, transaction fees, scalability

总结: 这篇文章探讨了区块链技术在业务流程执行中的应用，特别是关注了Algorand这种新型区块链系统。Algorand的特点在于低交易费用和快速最终性，但其成本结构与传统区块链（如以太坊）有显著差异。作者开发了一个BPMN Choreographies编译器，将流程转换为Algorand的智能合约语言TEAL，对比了在Algorand上执行流程的成本与传统云服务及先前研究。研究发现Algorand可以带来巨大的成本优势，但也提出了未来需要进一步探索和比较的多个挑战。 <div>
arXiv:2407.06725v1 Announce Type: new 
Abstract: Process (or workflow) execution on blockchain suffers from limited scalability; specifically, costs in the form of transactions fees are a major limitation for employing traditional public blockchain platforms in practice. Research, so far, has mainly focused on exploring first (Bitcoin) and second-generation (e.g., Ethereum) blockchains for business process enactment. However, since then, novel blockchain systems have been introduced - aimed at tackling many of the problems of previous-generation blockchains. We study such a system, Algorand, from a process execution perspective. Algorand promises low transaction fees and fast finality. However, Algorand's cost structure differs greatly from previous generation blockchains, rendering earlier cost models for blockchain-based process execution non-applicable. We discuss and contrast Algorand's novel cost structure with Ethereum's well-known cost model. To study the impact for process execution, we present a compiler for BPMN Choreographies, with an intermediary layer, which can support multi-platform output, and provide a translation to TEAL contracts, the smart contract language of Algorand. We compare the cost of executing processes on Algorand to previous work as well as traditional cloud computing. In short: they allow vast cost benefits. However, we note a multitude of future research challenges that remain in investigating and comparing such results.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems</title>
<link>https://arxiv.org/abs/2407.06862</link>
<guid>https://arxiv.org/abs/2407.06862</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized Architectures, Inter-Planetary File System (IPFS), Smart Contract, Weight Aggregation

总结:
本文探讨了一种基于去中心化架构的联邦学习（FL）系统，利用IPFS存储加密模型参数并通过智能合约管理协作过程，确保数据安全和可靠性。研究比较了两种聚合方法：经典平均和联邦proximal聚合。实验结果证实了该提案的可行性。通过智能合约的透明性和自动执行，这种设计提高了FL的信任度和效率。<br />总结: <div>
arXiv:2407.06862v1 Announce Type: new 
Abstract: In this paper, we present a study of a Federated Learning (FL) system, based on the use of decentralized architectures to ensure trust and increase reliability. The system is based on the idea that the FL collaborators upload the (ciphered) model parameters on the Inter-Planetary File System (IPFS) and interact with a dedicated smart contract to track their behavior. Thank to this smart contract, the phases of parameter updates are managed efficiently, thereby strengthening data security. We have carried out an experimental study that exploits two different methods of weight aggregation, i.e., a classic averaging scheme and a federated proximal aggregation. The results confirm the feasibility of the proposal.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DL-Chain: Scalable and Stable Blockchain Sharding with High Concurrency via Dual-Layer Consensus</title>
<link>https://arxiv.org/abs/2407.06882</link>
<guid>https://arxiv.org/abs/2407.06882</guid>
<content:encoded><![CDATA[
<div> 关键词：Sharding, Blockchain, Concurrency, Security, DL-Chain

总结:<br />
这篇文章主要探讨了区块链分片技术（Sharding）在提高交易并发性的同时面临的挑战，特别是如何在减小分片规模以增强并发性与确保系统安全之间找到平衡。作者提出了一种新型的区块链系统DL-Chain，它采用双层架构和共识机制，通过较小的提案分片（PSs）处理交易，较大的最终确认委员会（FCs）进行事务最终化。DL-Chain的关键创新在于通过PSs和FCs的合作保持系统的活跃性，避免了频繁的恢复过程，从而实现高并发性和稳定性能。此外，该系统优化FC设计，支持多个并存，允许每个PS中有较少的恶意节点，从而能配置更小的分片以提升并发性。实验结果表明，DL-Chain在吞吐量上比现有方案提高了10倍，并能在高达2,550个节点的情况下提供稳定的并发能力。 <div>
arXiv:2407.06882v1 Announce Type: new 
Abstract: Sharding enhances blockchain scalability by partitioning nodes into multiple groups for concurrent transaction processing. Configuring a large number of \emph{small shards} helps improve the transaction concurrency of a sharding system. However, it increases the fraction of malicious nodes within each shard, easily leading to shard corruption and jeopardizing system security. Some existing works have attempted to improve concurrency by reducing the shard size while maintaining security. However, they often require frequent and time-consuming recovery of corrupted shards, leading to severe system stagnation. Also, they usually require network-wide consensus to guarantee security, which limits scalability.
  To address these issues, we propose DL-Chain, a blockchain sharding system that can securely provide \emph{high concurrency with stable and scalable performance.} Our core idea is a \underline{D}ual-\underline{L}ayer architecture and consensus, which consists of numerous smaller proposer shards (PSs) for transaction processing and multiple larger finalizer committees (FCs) for transaction finalization. To avoid system stagnation and thus guarantee stable performance, we ensure PSs' liveness even if they are corrupted through the cooperation of PSs and FCs, thus eliminating the recovery process of corrupted PSs. To better trade-off security and scalability, we fine-tune the FCs to enable multiple FCs to coexist securely. As a result, DL-Chain allows a larger fraction of malicious nodes in each PS ($<1/2$) and thus can securely configure smaller shards for boosted stable and scalable concurrency. Evaluation results show that DL-Chain achieves up to 10 times improvement in throughput compared to existing solutions and provides stable concurrency with up to 2,550 nodes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SP-Chain: Boosting Intra-Shard and Cross-Shard Security and Performance in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2407.06953</link>
<guid>https://arxiv.org/abs/2407.06953</guid>
<content:encoded><![CDATA[
<div> 关键词：sharding, blockchain, SP-Chain, security, performance

总结:<br />
SP-Chain是一种新的区块链分片系统，旨在解决现有区块链在扩展性和安全性方面的挑战。它在保证高性能的同时，增强了对内部（intra-shard）和跨分片（cross-shard）交易的保护。论文的关键创新包括：<br />
1. 采用两阶段并发投票机制，提高系统吞吐量和降低交易确认延迟。
2. 设计高效无偏的领导者轮换方案，确保在恶意行为下仍保持性能。
3. 提出基于证明的跨分片交易处理机制，以低开销保障交易安全。
4. 实现于Harmony平台，通过大规模部署评估，结果显示在4000节点网络中，即使面对恶意行为，也能处理超过10000笔每秒的交易，确认时间为7.6秒。 <div>
arXiv:2407.06953v1 Announce Type: new 
Abstract: A promising way to overcome the scalability limitations of the current blockchain is to use sharding, which is to split the transaction processing among multiple, smaller groups of nodes. A well-performed blockchain sharding system requires both high performance and high security in both intra- and cross-shard perspectives. However, existing protocols either have issues on protecting security or trade off great performance for security. In this paper, we propose SP-Chain, a blockchain sharding system with enhanced Security and Performance for both intra- and cross-shard perspectives. For intra-shard aspect, we design a two-phase concurrent voting scheme to provide high system throughput and low transaction confirmation latency. Moreover, we propose an efficient unbiased leader rotation scheme to ensure high performance under malicious behavior. For cross-shard aspect, a proof-assisted efficient cross-shard transaction processing mechanism is proposed to guard the cross-shard transactions with low overhead. We implement SP-Chain based on Harmony, and evaluate its performance via large-scale deployment. Extensive evaluations suggest that SP-Chain can process more than 10,000 tx/sec under malicious behaviors with a confirmation latency of 7.6s in a network of 4,000 nodes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies</title>
<link>https://arxiv.org/abs/2407.07019</link>
<guid>https://arxiv.org/abs/2407.07019</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs), Health Insurance, Smart Contracts, Blockchain, Policy Automation.

总结:
本文探讨了使用大型语言模型（LLMs）生成自动化的健康保险流程代码，从文本政策中。研究重点是区块链智能合约，因其提供不可变性、可验证性、可扩展性和无需预先建立信任的环境。方法论涉及生成不同技术细节层次的内容：文本摘要、决策逻辑和带有单元测试的智能合约代码。评估表明LLMs在生成文本摘要方面表现良好，但任务（2）和（3）的结构化输出需要人工审阅，因为它们可能不完整、不准确或语法错误。尽管如此，实验展示了LLMs在将文本处理描述转化为智能合约方面的潜力，尤其是对于简单的场景。复杂场景仍面临挑战，需要进一步改进。总的来说，文章展示了LLMs在医疗保险自动化中的初步应用前景，但仍需结合人类专家的监督。 <div>
arXiv:2407.07019v1 Announce Type: new 
Abstract: We explore using Large Language Models (LLMs) to generate application code that automates health insurance processes from text-based policies. We target blockchain-based smart contracts as they offer immutability, verifiability, scalability, and a trustless setting: any number of parties can use the smart contracts, and they need not have previously established trust relationships with each other. Our methodology generates outputs at increasing levels of technical detail: (1) textual summaries, (2) declarative decision logic, and (3) smart contract code with unit tests. We ascertain LLMs are good at the task (1), and the structured output is useful to validate tasks (2) and (3). Declarative languages (task 2) are often used to formalize healthcare policies, but their execution on blockchain is non-trivial. Hence, task (3) attempts to directly automate the process using smart contracts. To assess the LLM output, we propose completeness, soundness, clarity, syntax, and functioning code as metrics. Our evaluation employs three health insurance policies (scenarios) with increasing difficulty from Medicare's official booklet. Our evaluation uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our findings confirm that LLMs perform quite well in generating textual summaries. Although outputs from tasks (2)-(3) are useful starting points, they require human oversight: in multiple cases, even "runnable" code will not yield sound results; the popularity of the target language affects the output quality; and more complex scenarios still seem a bridge too far. Nevertheless, our experiments demonstrate the promise of LLMs for translating textual process descriptions into smart contracts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Differentially Private Blockchain-Based Approach for Vertical Federated Learning</title>
<link>https://arxiv.org/abs/2407.07054</link>
<guid>https://arxiv.org/abs/2407.07054</guid>
<content:encoded><![CDATA[
<div> 关键词：Differentially Private Blockchain-Based Vertical Federated Learning (DP-BBVFL), privacy, embeddings, blockchain, medical data.

总结:<br />本文介绍了Differentially Private Blockchain-Based Vertical Federated Learning (DP-BBVFL)算法，一种结合了区块链技术和差分隐私的新型联邦学习方法。该算法通过智能合约透明地聚合客户端的特征表示（嵌入），同时保护存储在区块链上的原始数据隐私。DP-BBVFL首次展示了差分隐私与区块链在垂直联邦学习中的应用潜力。实验结果显示，尽管增加了训练时间，但该方法在医疗数据上实现了高精度，预示着分布式、可信任的机器学习应用的新纪元。<br />总结: <div>
arXiv:2407.07054v1 Announce Type: new 
Abstract: We present the Differentially Private Blockchain-Based Vertical Federal Learning (DP-BBVFL) algorithm that provides verifiability and privacy guarantees for decentralized applications. DP-BBVFL uses a smart contract to aggregate the feature representations, i.e., the embeddings, from clients transparently. We apply local differential privacy to provide privacy for embeddings stored on a blockchain, hence protecting the original data. We provide the first prototype application of differential privacy with blockchain for vertical federated learning. Our experiments with medical data show that DP-BBVFL achieves high accuracy with a tradeoff in training time due to on-chain aggregation. This innovative fusion of differential privacy and blockchain technology in DP-BBVFL could herald a new era of collaborative and trustworthy machine learning applications across several decentralized application domains.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Hyperion - A fast, versatile symbolic Gaussian Belief Propagation framework for Continuous-Time SLAM</title>
<link>https://arxiv.org/abs/2407.07074</link>
<guid>https://arxiv.org/abs/2407.07074</guid>
<content:encoded><![CDATA[
<div> 关键词：Continuous-Time SLAM, Centralized NLLS, SymForce, B- and Z-Spline, Gaussian Belief Propagation.

总结:<br />
本文介绍了一种新型的连续时间同时定位与建图(CTSLAM)方法，针对当前CTSLAM算法的计算需求高和集中式优化的问题。研究者提出了一种速度更快的SymForce（[Martiros等，RSS 2022]）B-和Z-Spline实现，比Sommer等人的方法[CVPR 2020]快2.43倍到110.31倍。此外，他们还开发了一个新的连续时间高斯信念传播框架Hyperion，旨在实现跨设备的分布式概率推断，适用于多传感器融合，如事件相机、滚筒式摄像头和惯性测量单元(IMU)。实验验证了新方法在运动跟踪和定位任务中的有效性，并通过实证研究进行了深入评估。 <div>
arXiv:2407.07074v1 Announce Type: new 
Abstract: Continuous-Time Simultaneous Localization And Mapping (CTSLAM) has become a promising approach for fusing asynchronous and multi-modal sensor suites. Unlike discrete-time SLAM, which estimates poses discretely, CTSLAM uses continuous-time motion parametrizations, facilitating the integration of a variety of sensors such as rolling-shutter cameras, event cameras and Inertial Measurement Units (IMUs). However, CTSLAM approaches remain computationally demanding and are conventionally posed as centralized Non-Linear Least Squares (NLLS) optimizations. Targeting these limitations, we not only present the fastest SymForce-based [Martiros et al., RSS 2022] B- and Z-Spline implementations achieving speedups between 2.43x and 110.31x over Sommer et al. [CVPR 2020] but also implement a novel continuous-time Gaussian Belief Propagation (GBP) framework, coined Hyperion, which targets decentralized probabilistic inference across agents. We demonstrate the efficacy of our method in motion tracking and localization settings, complemented by empirical ablation studies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Semantic Communication in Multi-team Dynamic Games: A Mean Field Perspective</title>
<link>https://arxiv.org/abs/2407.06528</link>
<guid>https://arxiv.org/abs/2407.06528</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent systems, networked control, mean-field games, noncooperative game, decentralized Nash equilibrium

总结:<br />本文研究了大规模多团队动态游戏中的协调通信与控制问题。每个团队由传感器和控制器组成，通过共享网络共同控制一个动态状态，同时考虑动作成本和传感/通信成本。由于无线通道的共享性质，团队的整体成本受其他团队策略影响，形成非合作博弈。通过扩展的mean-field游戏方法，文章计算了近似的分散式纳什均衡策略，考虑了平均流量和传感器信息价值。为解决传感器动作空间有限导致的非合同性问题，文章优化了代表团队的控制器和传感器策略。此外，文章证明了mean-field均衡解的ε-纳什性质，表明其对有限团队系统的性能。最后，大量的数值模拟验证了理论结果并揭示了更多洞察。 <div>
arXiv:2407.06528v1 Announce Type: cross 
Abstract: Coordinating communication and control is a key component in the stability and performance of networked multi-agent systems. While single user networked control systems have gained a lot of attention within this domain, in this work, we address the more challenging problem of large population multi-team dynamic games. In particular, each team constitutes two decision makers (namely, the sensor and the controller) who coordinate over a shared network to control a dynamically evolving state of interest under costs on both actuation and sensing/communication. Due to the shared nature of the wireless channel, the overall cost of each team depends on other teams' policies, thereby leading to a noncooperative game setup. Due to the presence of a large number of teams, we compute approximate decentralized Nash equilibrium policies for each team using the paradigm of (extended) mean-field games, which is governed by (1) the mean traffic flowing over the channel, and (2) the value of information at the sensor, which highlights the semantic nature of the ensuing communication. In the process, we compute optimal controller policies and approximately optimal sensor policies for each representative team of the mean-field system to alleviate the problem of general non-contractivity of the mean-field fixed point operator associated with the finite cardinality of the sensor action space. Consequently, we also prove the $\epsilon$--Nash property of the mean-field equilibrium solution which essentially characterizes how well the solution derived using mean-field analysis performs on the finite-team system. Finally, we provide extensive numerical simulations, which corroborate the theoretical findings and lead to additional insights on the properties of the results presented.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Straggler-Resilient Decentralized Learning via Adaptive Asynchronous Updates</title>
<link>https://arxiv.org/abs/2306.06559</link>
<guid>https://arxiv.org/abs/2306.06559</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Optimization, Machine Learning, Synchronization, Asynchronous Updates, Staleness.

总结:
本文关注大规模机器学习模型的分布式训练，提出了一种全新的全分布式算法DSGD-AAU。DSGD-AAU旨在解决传统同步更新方法中的“尾随”问题，通过自适应地调整每个工作节点与邻居通信的数量，实现异步更新，从而减少参数过时（staleness）的影响。研究者证明了DSGD-AAU具有线性加速的收敛速度，并通过大量实验验证了其有效性，为处理大规模数据训练提供了高效且健壮的解决方案。 <div>
arXiv:2306.06559v2 Announce Type: replace 
Abstract: With the increasing demand for large-scale training of machine learning models, fully decentralized optimization methods have recently been advocated as alternatives to the popular parameter server framework. In this paradigm, each worker maintains a local estimate of the optimal parameter vector, and iteratively updates it by waiting and averaging all estimates obtained from its neighbors, and then corrects it on the basis of its local dataset. However, the synchronization phase is sensitive to stragglers. An efficient way to mitigate this effect is to consider asynchronous updates, where each worker computes stochastic gradients and communicates with other workers at its own pace. Unfortunately, fully asynchronous updates suffer from staleness of stragglers' parameters. To address these limitations, we propose a fully decentralized algorithm DSGD-AAU with adaptive asynchronous updates via adaptively determining the number of neighbor workers for each worker to communicate with. We show that DSGD-AAU achieves a linear speedup for convergence and demonstrate its effectiveness via extensive experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Experimental Study of Decentralized Robot Network Coordination</title>
<link>https://arxiv.org/abs/2407.04832</link>
<guid>https://arxiv.org/abs/2407.04832</guid>
<content:encoded><![CDATA[
<div> 关键词：synchronization, desynchronization, robotics, decentralized algorithm, Roomba robots

总结:<br />该研究关注于机器人网络中的同步与解同步问题，这是机器人合作领域鲜少探讨的主题。作者改进了先前开发的算法，并通过实验证明其在多机器人系统（如Roomba机器人）中的应用。实验中，调整算法参数影响了同步和解同步的时间以及网络状态稳定性。测试了三种不同的方法，结果各异。这些改进的算法为未来机器人协作任务的成功执行提供了可能。未来的研究将有望在各种任务中应用这些算法，促进分布式机器人系统的协同工作。 <div>
arXiv:2407.04832v1 Announce Type: new 
Abstract: Synchronization and desynchronization in networks is a highly studied topic in many electrical systems, but there is a distinct lack of research on this topic with respect to robotics. Creating an effective decentralized synchronization algorithm for a robotic network would allow multiple robots to work together to achieve a task and would be able to adapt to the addition or loss of robots in real-time. The purpose of this study is to improve algorithms implemented developed by the authors for this purpose and experimentally evaluate these methods. The most effective algorithm for synchronization and desynchronization found in a former study were modified to improve testing and vary its methods of calculation. A multi-robot platform composed of multiple Roomba robots was used in the experimental study. Observation of data showed how adjusting parameters of the algorithms affected both the time to reach a desired state of synchronization or desynchronization and how the network maintained this state. Testing three different methods on each algorithm showed differing results. Future work in cooperative robotics will likely see success using these algorithms to accomplish a variety of tasks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-agent Off-policy Actor-Critic Reinforcement Learning for Partially Observable Environments</title>
<link>https://arxiv.org/abs/2407.04974</link>
<guid>https://arxiv.org/abs/2407.04974</guid>
<content:encoded><![CDATA[
<div> 关键词：social learning, multi-agent, off-policy actor-critic, partially observable environment, decentralized

总结:<br />该研究提出了一种基于社会学习的多智能体强化学习算法，用于在部分可观测环境中估计全局状态。算法适用于模型免费的多智能体系统，无需了解转换模型，且采用去中心化操作，允许智能体与其邻居交换信息。文章分析了通过社会学习估计与完全观察全局状态结果的差异有界性，并展示了其在实验中的有效性，优于现有方法。这种方法为处理复杂环境中的协作学习提供了新的解决方案。 <div>
arXiv:2407.04974v1 Announce Type: new 
Abstract: This study proposes the use of a social learning method to estimate a global state within a multi-agent off-policy actor-critic algorithm for reinforcement learning (RL) operating in a partially observable environment. We assume that the network of agents operates in a fully-decentralized manner, possessing the capability to exchange variables with their immediate neighbors. The proposed design methodology is supported by an analysis demonstrating that the difference between final outcomes, obtained when the global state is fully observed versus estimated through the social learning method, is $\varepsilon$-bounded when an appropriate number of iterations of social learning updates are implemented. Unlike many existing dec-POMDP-based RL approaches, the proposed algorithm is suitable for model-free multi-agent reinforcement learning as it does not require knowledge of a transition model. Furthermore, experimental results illustrate the efficacy of the algorithm and demonstrate its superiority over the current state-of-the-art methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A game theory analysis of decentralized epidemic management with opinion dynamics</title>
<link>https://arxiv.org/abs/2407.05020</link>
<guid>https://arxiv.org/abs/2407.05020</guid>
<content:encoded><![CDATA[
<div> 关键词：game model, decentralized control, epidemic, Generalized Nash equilibrium (GNE), Price of Anarchy (PoA)

总结:<br />
本文提出了一种静态博弈模型，用于评估全球流行病中去中心化控制或管理导致的效率损失。每个玩家代表一个地区，决策包括实施公共卫生措施和影响区域意见。文章主要贡献在于对这种具有实际意义的游戏进行了详尽的分析，通过构造辅助游戏证明了GNE的存在性和唯一性，计算了GNE和最优集中化解决方案（总成本）。研究结果允许作者量化去中心化带来的PoA，考虑或不考虑意见动态。总的来说，这项工作为理解和比较不同控制策略对疫情管理的影响提供了数学工具。 <div>
arXiv:2407.05020v1 Announce Type: new 
Abstract: In this paper, we introduce a static game that allows one to numerically assess the loss of efficiency induced by decentralized control or management of a global epidemic. Each player represents a region which is assumed to choose its control to implement a tradeoff between socio-economic aspects and health aspects; the control comprises both epidemic control physical measures and influence actions on the region opinion. The Generalized Nash equilibrium $(\mathrm{GNE})$ analysis of the proposed game model is conducted. The direct analysis of this game of practical interest is non-trivial but it turns out that one can construct an auxiliary game which allows one: to prove existence and uniqueness; to compute the GNE and the optimal centralized solution (sum-cost) of the game. These results allow us to assess numerically the loss (measured in terms of Price of Anarchy ($\mathrm{PoA}$)) induced by decentralization with or without taking into account the opinion dynamics.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Impact of Network Topology on Byzantine Resilience in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2407.05141</link>
<guid>https://arxiv.org/abs/2407.05141</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Decentralized FL, Byzantine nodes, Aggregation function, Network topology.

总结:<br />Federated Learning (FL)是一种分布式机器学习方法，尤其在去中心化形式（Decentralized FL）中，用户无需中心服务器即可协作训练。然而，这类系统面临的一个关键挑战是处理可能存在的“拜占庭节点”，即试图干扰学习过程的异常节点。以往的研究主要集中在客户端-服务器或全连接网络上的拜占庭鲁棒性，但尚未评估其在复杂网络结构中的表现。本文研究了当前最先进的拜占庭鲁棒聚合策略在大型非完全连接网络中的效果，发现这些策略在复杂大型网络中并不稳健。因此，作者呼吁开发针对网络拓扑的聚合方案，这对于大规模现实部署至关重要。这一发现强调了在去中心化FL中考虑网络结构的必要性，以确保系统的健壮性和可靠性。 <div>
arXiv:2407.05141v1 Announce Type: new 
Abstract: Federated learning (FL) enables a collaborative environment for training machine learning models without sharing training data between users. This is typically achieved by aggregating model gradients on a central server. Decentralized federated learning is a rising paradigm that enables users to collaboratively train machine learning models in a peer-to-peer manner, without the need for a central aggregation server. However, before applying decentralized FL in real-world use training environments, nodes that deviate from the FL process (Byzantine nodes) must be considered when selecting an aggregation function. Recent research has focused on Byzantine-robust aggregation for client-server or fully connected networks, but has not yet evaluated such aggregation schemes for complex topologies possible with decentralized FL. Thus, the need for empirical evidence of Byzantine robustness in differing network topologies is evident. This work investigates the effects of state-of-the-art Byzantine-robust aggregation methods in complex, large-scale network structures. We find that state-of-the-art Byzantine robust aggregation strategies are not resilient within large non-fully connected networks. As such, our findings point the field towards the development of topology-aware aggregation schemes, especially necessary within the context of large scale real-world deployment.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BFLN: A Blockchain-based Federated Learning Model for Non-IID Data</title>
<link>https://arxiv.org/abs/2407.05276</link>
<guid>https://arxiv.org/abs/2407.05276</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, imbalanced data distribution, blockchain technology, aggregation method, incentive algorithm

总结:<br />
这篇文章主要关注了联邦学习中数据分布不均衡的问题，提出了一种结合区块链和联邦学习的新型模型——BFLN（Blockchain-based Federated Learning Model for Non-IID Data）。BFLN通过引入新的聚合方法和激励算法，提升了非独立同分布数据下的联邦学习性能。实验结果显示，相比于现有最先进的模型，BFLN在训练准确性上有所提高，并为个性化联邦学习提供了可持续的激励机制。总的来说，BFLN旨在解决数据不平衡问题，提高联邦学习的效率和公平性。 <div>
arXiv:2407.05276v1 Announce Type: new 
Abstract: As the application of federated learning becomes increasingly widespread, the issue of imbalanced training data distribution has emerged as a significant challenge. Federated learning utilizes local data stored on different training clients for model training, rather than centralizing data on a server, thereby greatly enhancing the privacy and security of training data. However, the distribution of training data across different clients may be imbalanced, with different categories of data potentially residing on different clients. This presents a challenge to traditional federated learning, which assumes data distribution is independent and identically distributed (IID). This paper proposes a Blockchain-based Federated Learning Model for Non-IID Data (BFLN), which combines federated learning with blockchain technology. By introducing a new aggregation method and incentive algorithm, BFLN enhances the model performance of federated learning on non-IID data. Experiments on public datasets demonstrate that, compared to other state-of-the-art models, BFLN improves training accuracy and provides a sustainable incentive mechanism for personalized federated learning.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Vulnerability-Hunter: An Adaptive Feature Perception Attention Network for Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2407.05318</link>
<guid>https://arxiv.org/abs/2407.05318</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart Contract Vulnerability Detection, Graph Neural Networks, Feature Perception Module, Relationship Perception Attention Module, Performance Evaluation.

总结:<br />
该研究论文关注区块链系统的质量保证，特别是智能合约漏洞检测(ScVD)。现有的深度学习方法依赖图神经网络来理解代码语义，但其局限在于预定义规则的图采样和子图池化策略，这在处理智能合约代码的异构拓扑时可能不够灵活。为此，论文提出了一种新型的漏洞检测模型AFPNet，它包含特征感知模块和关系感知注意力模块。特征感知模块动态地扫描整个代码并自动提取关键代码片段，而关系感知注意力模块则利用注意力机制学习这些片段之间的依赖，以提高漏洞检测的准确性。实验结果显示，相比于现有最先进的方法，AFPNet在F1分数上提高了6.38%到14.02%，证明了其在动态提取有价值信息和优化SCVD方面的有效性。 <div>
arXiv:2407.05318v1 Announce Type: new 
Abstract: Smart Contract Vulnerability Detection (SCVD) is crucial to guarantee the quality of blockchain-based systems. Graph neural networks have been shown to be effective in learning semantic representations of smart contract code and are commonly adopted by existing deep learning-based SCVD. However, the current methods still have limitations in their utilization of graph sampling or subgraph pooling based on predefined rules for extracting crucial components from structure graphs of smart contract code. These predefined rule-based strategies, typically designed using static rules or heuristics, demonstrate limited adaptability to dynamically adjust extraction strategies according to the structure and content of the graph in heterogeneous topologies of smart contract code. Consequently, these strategies may not possess universal applicability to all smart contracts, potentially leading to false positives or omissions. To address these problems, we propose AFPNet, a novel vulnerability detection model equipped with a feature perception module that has dynamic weights for comprehensive scanning of the entire smart contract code and automatic extraction of crucial code snippets (the $P$ snippets with the largest weights). Subsequently, the relationship perception attention module employs an attention mechanism to learn dependencies among these code snippets and detect smart contract vulnerabilities. The efforts made by AFPNet consistently enable the capture of crucial code snippets and enhance the performance of SCVD optimization. We conduct an evaluation of AFPNet in the several large-scale datasets with vulnerability labels. The experimental results show that our AFPNet significantly outperforms the state-of-the-art approach by 6.38\%-14.02\% in term of F1-score. The results demonstrate the effectiveness of AFPNet in dynamically extracting valuable information and vulnerability detection.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Challenges and Best Practices in Corporate AI Governance:Lessons from the Biopharmaceutical Industry</title>
<link>https://arxiv.org/abs/2407.05339</link>
<guid>https://arxiv.org/abs/2407.05339</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、伦理原则、实践挑战、AstraZeneca、AI治理。

总结:<br />Astrazeneca是一家生物制药公司，正在探讨如何将伦理原则转化为有效的AI治理实践。文章指出，企业在实施AI治理时面临诸多挑战，如确定AI治理的范围、协调跨部门标准和衡量治理效果。Astrazeneca的经验包括依靠现有政策、实用术语、风险管理、员工教育和持续改进。这些实践对于其他组织设计和实施AI治理框架具有参考价值，鼓励企业注重风险管理，强化内部沟通与培训。 <div>
arXiv:2407.05339v1 Announce Type: new 
Abstract: While the use of artificial intelligence (AI) systems promises to bring significant economic and social benefits, it is also coupled with ethical, legal, and technical challenges. Business leaders thus face the question of how to best reap the benefits of automation whilst managing the associated risks. As a first step, many companies have committed themselves to various sets of ethics principles aimed at guiding the design and use of AI systems. So far so good. But how can well-intentioned ethical principles be translated into effective practice? And what challenges await companies that attempt to operationalize AI governance? In this article, we address these questions by drawing on our first-hand experience of shaping and driving the roll-out of AI governance within AstraZeneca, a biopharmaceutical company. The examples we discuss highlight challenges that any organization attempting to operationalize AI governance will have to face. These include questions concerning how to define the material scope of AI governance, how to harmonize standards across decentralized organizations, and how to measure the impact of specific AI governance initiatives. By showcasing how AstraZeneca managed these operational questions, we hope to provide project managers, CIOs, AI practitioners, and data privacy officers responsible for designing and implementing AI governance frameworks within other organizations with generalizable best practices. In essence, companies seeking to operationalize AI governance are encouraged to build on existing policies and governance structures, use pragmatic and action-oriented terminology, focus on risk management in development and procurement, and empower employees through continuous education and change management.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Blockchain Embedded Peer-to-Peer Access Control Framework for IoT Systems</title>
<link>https://arxiv.org/abs/2407.05506</link>
<guid>https://arxiv.org/abs/2407.05506</guid>
<content:encoded><![CDATA[
<div> 关键词：IoT系统、Blockchain、Access control、Decentralized、Pruned Blockchain-based Access Control (PBAC)

总结:<br />
这篇文章探讨了物联网(IoT)系统的访问控制问题，尤其是在涉及设备共享和数据访问的场景中。由于IoT设备分散在互联网边缘，传统的集中式访问控制面临挑战。为解决这一问题，作者提出了一种名为Pruned Blockchain-based Access Control (PBAC)的新协议。PBAC通过减少不必要的消息轮次，优化了验证和策略管理的效率。该协议包括两个关键部分：快捷方式（shortcut）和基于角色和设备层次结构的访问控制(R&amp;D-BAC)，以适应不同环境。此外，文中还详细讨论了实现PBAC所需的系统架构设计。实验结果显示，PBAC的快捷机制将访问时间减少了约43%，而R&amp;D-BAC比传统区块链基RBAC提高了两倍以上，显示了其显著的性能优势。 <div>
arXiv:2407.05506v1 Announce Type: new 
Abstract: We consider access control for IoT systems that involves shared accesses to the IoT devices as well as their data. Since IoT devices are dispersed all over the edge of the Internet, traditional centralized access control has problems. Blockchain based decentralized access control is thus the new solution trend. However, existing blockchain based access control methods do not focus on performance issues and may incur a high communication overhead.
  In this paper, we develop a Pruned Blockchain based Access Control (PBAC) protocol to cutdown the unnecessary message rounds and achieve high efficiency in access validations and policy management. The protocol includes a shortcut and a Role and Device Hierarchy-Based Access Control (R&amp;D-BAC) approaches for different environment settings. To realize the PBAC protocol, it is necessary to carefully engineer the system architecture, which is also discussed in the paper. Experiments demonstrate the efficacy of the PBAC protocol, specifically, the shortcut mechanism reduces access time by approximately 43%, and R&amp;D-BAC outperforms traditional blockchain based RBAC by more than two folds.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DFedSat: Communication-Efficient and Robust Decentralized Federated Learning for LEO Satellite Constellations</title>
<link>https://arxiv.org/abs/2407.05850</link>
<guid>https://arxiv.org/abs/2407.05850</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)卫星、人工智能、联邦学习、分布式学习、动态ISLs。

总结: 这篇论文关注低地球轨道（LEO）卫星在6G网络和空间-地面-空中集成系统中的应用。传统的集中式方法因卫星与地面站间连接不稳定而效率低下，因此提出了一种名为DFedSat的全分布式联邦学习框架。DFedSat通过在同轨道和异轨道卫星间设计自适应聚合机制，加速了模型训练，并引入补偿机制增强跨轨道链路的鲁棒性。论文还分析了非凸情况下DFedSat的亚线性收敛率。实验结果显示，DFedSat在收敛速度、通信效率和抗链路故障方面优于其他分布式学习基准。 <div>
arXiv:2407.05850v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellites play a crucial role in the development of 6G mobile networks and space-air-ground integrated systems. Recent advancements in space technology have empowered LEO satellites with the capability to run AI applications. However, centralized approaches, where ground stations (GSs) act as servers and satellites as clients, often encounter slow convergence and inefficiencies due to intermittent connectivity between satellites and GSs. In contrast, decentralized federated learning (DFL) offers a promising alternative by facilitating direct communication between satellites (clients) via inter-satellite links (ISLs). However, inter-plane ISLs connecting satellites from different orbital planes are dynamic due to Doppler shifts and pointing limitations. This could impact model propagation and lead to slower convergence. To mitigate these issues, we propose DFedSat, a fully decentralized federated learning framework tailored for LEO satellites. DFedSat accelerates the training process by employing two adaptive mechanisms for intra-plane and inter-plane model aggregation, respectively. Furthermore, a self-compensation mechanism is integrated to enhance the robustness of inter-plane ISLs against transmission failure. Additionally, we derive the sublinear convergence rate for the non-convex case of DFedSat. Extensive experimental results demonstrate DFedSat's superiority over other DFL baselines regarding convergence rate, communication efficiency, and resilience to unreliable links.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Redactable Blockchain Solutions for IoT: A Review of Mechanisms and Applications</title>
<link>https://arxiv.org/abs/2407.05948</link>
<guid>https://arxiv.org/abs/2407.05948</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Internet of Things (IoT), redaction, data security, data protection

总结:<br />
本文探讨了区块链技术与物联网（IoT）结合的最新趋势，特别是在处理数据隐私和保护问题上。关键词“可红删区块链”成为焦点，因为其在确保数据安全的同时，满足了法律对敏感信息删除的需求。研究深入分析了现有红删机制在IoT领域的应用，揭示了挑战和机遇，以及如何通过实施红删区块链来解决数据管理中的隐私顾虑。文章展示了实际的IoT案例，展示了这种技术在实践中的潜力和价值。 <div>
arXiv:2407.05948v1 Announce Type: new 
Abstract: The integration of blockchain technology with the Internet of Things (IoT) presents a promising solution to enhance data security, integrity, and trust within IoT ecosystems. However, the immutable nature of blockchain technology conflicts with data redaction requirements mandated by data protection laws. This paper provides a comprehensive review of the current state of redactable blockchains and redaction mechanisms, particularly focusing on their application within IoT contexts. Through an extensive review of existing literature, this paper identifies key challenges and opportunities in implementing redactable blockchains for IoT data management. Various redaction mechanisms are explored, and the paper examines IoT implementations and use cases where redactable blockchains are employed to address data protection concerns.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Towards Understanding the Bugs in Solidity Compiler</title>
<link>https://arxiv.org/abs/2407.05981</link>
<guid>https://arxiv.org/abs/2407.05981</guid>
<content:encoded><![CDATA[
<div> 关键词：Solidity编译器、bug、特性、测试用例、fuzzers。

总结:<br />
本文针对Solidity编译器的533个已知漏洞进行了深入研究，重点关注了这些bug的症状、根源和触发测试案例。研究发现七个关键见解，揭示了编译器在处理智能合约特定语言和优化过程中存在的挑战。同时，对三种Solidity编译器fuzzer的评估显示，它们在检测漏洞方面的效率较低，主要受限于未能充分考虑引发bug的有趣特性、相关编译标志以及测试或acles。这强调了改进现有工具以提高智能合约安全性的必要性。 <div>
arXiv:2407.05981v1 Announce Type: new 
Abstract: Solidity compiler plays a key role in enabling the development of smart contract applications on Ethereum by governing the syntax of a domain-specific language called Solidity and performing compilation and optimization of Solidity code. The correctness of Solidity compiler is critical in fostering transparency, efficiency, and trust in industries reliant on smart contracts. However, like other software systems, Solidity compiler is prone to bugs, which may produce incorrect bytecodes on blockchain platforms, resulting in severe security concerns. As a domain-specific compiler for smart contracts, Solidity compiler differs from other compilers in many perspectives, posing unique challenges to detect its bugs. To understand the bugs in Solidity compiler and benefit future research, in this paper, we present the first systematic study on 533 Solidity compiler bugs. We carefully examined their characteristics (including symptoms, root causes, and distribution), and their triggering test cases. Our study leads to seven bug-revealing takeaways for Solidity compiler. Moreover, to study the limitations of Solidity compiler fuzzers and bring our findings into practical scenarios, we evaluate three Solidity compiler fuzzers on our constructed benchmark. The results show that these fuzzers are inefficient in detecting Solidity compiler bugs. The inefficiency arises from their failure to consider the interesting bug-inducing features, bug-related compilation flags, and test oracles
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cellular Automata as a Network Topology</title>
<link>https://arxiv.org/abs/2407.05048</link>
<guid>https://arxiv.org/abs/2407.05048</guid>
<content:encoded><![CDATA[
<div> 关键词：cellular automata, network topologies, decentralized networks, load balancing, fault tolerance.

总结:<br />
本文探讨了将细胞自动机应用于网络拓扑建模的潜力，特别是在去中心化网络中。细胞自动机作为一种离散空间和时间的物理系统模型，可以模拟有限量值的物理量。研究旨在利用这种模型改善分布式系统的负载均衡、故障容错能力，以及信息传播的效率和规模扩展。通过细胞自动机，网络结构可能变得更加灵活和高效，为处理复杂通信问题提供新的途径。 <div>
arXiv:2407.05048v1 Announce Type: cross 
Abstract: Cellular automata represent physical systems where both space and time are discrete, and the associated physical quantities assume a limited set of values. While previous research has applied cellular automata in modeling chemical, biological, and physical systems, its potential for modeling topological systems, specifically network topologies, remains underexplored. This paper investigates the use of cellular automata to model decentralized network topologies, which could enhance load balancing, fault tolerance, scalability, and the propagation and dissemination of information in distributed systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Simple Opinion Dynamics for No-Regret Learning</title>
<link>https://arxiv.org/abs/2306.08670</link>
<guid>https://arxiv.org/abs/2306.08670</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent bandit, distributed GOSSIP model, memoryless protocols, consensus, adversarial rewards

总结: 这篇文章主要探讨了分布式GOSSIP模型下的多代理强化学习问题。研究者提出了基于已有意见动态算法的记忆less和时间无关的协议，实现了最优的双重世界行为：在 stationary reward设置中，这些简单协议具有常数累积后悔$R(T)/T = \widetilde{O}(1/T)$，同时能在$\widetilde{O}(\sqrt{n})$轮内达成对最高期望动作的一致。文章揭示了这些协议与零和乘法权重更新过程之间的新联系，从而建立了一般性框架来分析协议的全局性能。此外，这些协议在对抗性奖励环境下也表现出惊人的鲁棒性，即使在时间轮数与$n$的关系不紧密的情况下，也能实现$R(T)/T = \widetilde{O}(1/\sqrt{T})$的子线性后悔。 <div>
arXiv:2306.08670v4 Announce Type: replace 
Abstract: We study a cooperative multi-agent bandit setting in the distributed GOSSIP model: in every round, each of $n$ agents chooses an action from a common set, observes the action's corresponding reward, and subsequently exchanges information with a single randomly chosen neighbor, which may inform its choice in the next round. We introduce and analyze families of memoryless and time-independent protocols for this setting, inspired by opinion dynamics that are well-studied for other algorithmic tasks in the GOSSIP model. For stationary reward settings, we prove for the first time that these simple protocols exhibit best-of-both-worlds behavior, simultaneously obtaining constant cumulative regret scaling like $R(T)/T = \widetilde O(1/T)$, and also reaching consensus on the highest-mean action within $\widetilde O(\sqrt{n})$ rounds. We obtain these results by showing a new connection between the global evolution of these decentralized protocols and a class of zero-sum multiplicative weights update} processes. Using this connection, we establish a general framework for analyzing the population-level regret and other properties of our protocols. Finally, we show our protocols are also surprisingly robust to adversarial rewards, and in this regime we obtain sublinear regret scaling like $R(T)/T = \widetilde O(1/\sqrt{T})$ as long as the number of rounds does not grow too fast as a function of $n$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Kernel Ridge Regression Based on Data-Dependent Random Feature</title>
<link>https://arxiv.org/abs/2405.07791</link>
<guid>https://arxiv.org/abs/2405.07791</guid>
<content:encoded><![CDATA[
<div> 关键词：random feature（随机特征）、decentralized kernel ridge regression（分布式核岭回归）、node consistency（节点一致性）、decision functions（决策函数）、convergence（收敛性）。

总结:<br />该论文提出了一种新的分布式核岭回归算法，采用随机特征处理节点间数据差异。与现有方法相比，它不强制要求不同节点使用相同的随机特征，而是追求决策函数的一致性。这种适应性强的方法允许根据各节点数据自动生成不同的随机特征，从而提高了回归精度，平均提升了25.5%。算法具有良好的收敛性，并在六项真实世界的数据集上得到了验证。 <div>
arXiv:2405.07791v2 Announce Type: replace 
Abstract: Random feature (RF) has been widely used for node consistency in decentralized kernel ridge regression (KRR). Currently, the consistency is guaranteed by imposing constraints on coefficients of features, necessitating that the random features on different nodes are identical. However, in many applications, data on different nodes varies significantly on the number or distribution, which calls for adaptive and data-dependent methods that generate different RFs. To tackle the essential difficulty, we propose a new decentralized KRR algorithm that pursues consensus on decision functions, which allows great flexibility and well adapts data on nodes. The convergence is rigorously given and the effectiveness is numerically verified: by capturing the characteristics of the data on each node, while maintaining the same communication costs as other methods, we achieved an average regression accuracy improvement of 25.5\% across six real-world data sets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Correlations versus noise in the NFT market</title>
<link>https://arxiv.org/abs/2404.15495</link>
<guid>https://arxiv.org/abs/2404.15495</guid>
<content:encoded><![CDATA[
<div> 关键词：non-fungible token (NFT), market dynamics, correlation matrix, Marchenko-Pastur distribution, correlation strength.

总结:<br />
非同质化代币(NFT)市场利用区块链技术崭露头角，本文基于以太坊平台上大量token集合的资本化变化和交易量，研究其市场动态。通过多变量方法分析了集合之间的依赖性，发现NFT市场的相关性较弱，其相关矩阵的特征值谱接近马尔钦科-帕斯图分布，但仍存在一定程度的关联。对比皮尔逊系数和去趋势交叉相关系数构建的关联矩阵显示，NFT市场的全球关联主要源自高频波动。资本化变异性的最小生成树(MST)表现出幂律特性，而交易数量的MST则相对分散，显示出市场的复杂性和动态特性。 <div>
arXiv:2404.15495v2 Announce Type: replace-cross 
Abstract: The non-fungible token (NFT) market emerges as a recent trading innovation leveraging blockchain technology, mirroring the dynamics of the cryptocurrency market. The current study is based on the capitalization changes and transaction volumes across a large number of token collections on the Ethereum platform. In order to deepen the understanding of the market dynamics, the collection-collection dependencies are examined by using the multivariate formalism of detrended correlation coefficient and correlation matrix. It appears that correlation strength is lower here than that observed in previously studied markets. Consequently, the eigenvalue spectra of the correlation matrix more closely follow the Marchenko-Pastur distribution, still, some departures indicating the existence of correlations remain. The comparison of results obtained from the correlation matrix built from the Pearson coefficients and, independently, from the detrended cross-correlation coefficients suggests that the global correlations in the NFT market arise from higher frequency fluctuations. Corresponding minimal spanning trees (MSTs) for capitalization variability exhibit a scale-free character while, for the number of transactions, they are somewhat more decentralized.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ESBMC-Python: A Bounded Model Checker for Python Programs</title>
<link>https://arxiv.org/abs/2407.03472</link>
<guid>https://arxiv.org/abs/2407.03472</guid>
<content:encoded><![CDATA[
<div> 关键词：Python程序、类型注解、抽象语法树、Bounded Model Checking (BMC)、ESBMC-Python。

总结:<br />
本文介绍了一种新的Python程序验证工具，利用类型注解和前端处理，结合了Bounded Model Checking (BMC)技术。该工具首先将输入程序转换为带有类型信息的抽象语法树，随后将表达式和语句转化为中间表示，最后通过与SMT求解器交互，实现对代码的验证。实验结果表明，ESBMC-Python在专门设计的测试套件中表现出有效性，能正确评估成功和失败的测试，并发现Ethereum共识规范中的实际问题。 <div>
arXiv:2407.03472v1 Announce Type: new 
Abstract: This paper introduces a tool for verifying Python programs, which, using type annotation and front-end processing, can harness the capabilities of a bounded model-checking (BMC) pipeline. It transforms an input program into an abstract syntax tree to infer and add type information. Then, it translates Python expressions and statements into an intermediate representation. Finally, it converts this description into formulae evaluated with satisfiability modulo theories (SMT) solvers. The proposed approach was realized with the efficient SMT-based bounded model checker (ESBMC), which resulted in a tool called ESBMC-Python, the first BMC-based Python-code verifier. Experimental results, with a test suite specifically developed for this purpose, showed its effectiveness, where successful and failed tests were correctly evaluated. Moreover, it found a real problem in the Ethereum Consensus Specification.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Scalable Zero-Knowledge Proofs for Verifying Cryptographic Hashing in Blockchain Applications</title>
<link>https://arxiv.org/abs/2407.03511</link>
<guid>https://arxiv.org/abs/2407.03511</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明（ZKP）、SHA-256、Plonky2框架、PLONK协议、FRI承诺方案。

总结:<br />
本文提出了一种使用零知识证明（ZKP）验证SHA-256算法计算完整性的方法，基于Plonky2框架和FRI承诺方案。研究专注于提高效率和可扩展性，对随机数据和NEAR区块链的真实数据块进行了实验，证明了其在不同数据规模和类型下的性能稳定。生成的电路和证明保持在可管理的大小，适用于大型交易的现实世界数据块。该方法有助于构建安全可信的区块链系统，同时保证计算的保密性。未来还需研究其在其他加密算法和复杂场景的应用及性能。 <div>
arXiv:2407.03511v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKPs) have emerged as a promising solution to address the scalability challenges in modern blockchain systems. This study proposes a methodology for generating and verifying ZKPs to ensure the computational integrity of cryptographic hashing, specifically focusing on the SHA-256 algorithm. By leveraging the Plonky2 framework, which implements the PLONK protocol with FRI commitment scheme, we demonstrate the efficiency and scalability of our approach for both random data and real data blocks from the NEAR blockchain. The experimental results show consistent performance across different data sizes and types, with the time required for proof generation and verification remaining within acceptable limits. The generated circuits and proofs maintain manageable sizes, even for real-world data blocks with a large number of transactions. The proposed methodology contributes to the development of secure and trustworthy blockchain systems, where the integrity of computations can be verified without revealing the underlying data. Further research is needed to assess the applicability of the approach to other cryptographic primitives and to evaluate its performance in more complex real-world scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PEDDiM: Formal Definitions and Provably Secure Designs for Pre-Execution DoS Defense in Mempools</title>
<link>https://arxiv.org/abs/2407.03543</link>
<guid>https://arxiv.org/abs/2407.03543</guid>
<content:encoded><![CDATA[
<div> 关键词：mempool, secure blockchain, asymmetric eviction DoS attacks, secure transaction admission algorithm, \textsc{saferAd-PR}

总结:<br />
这篇论文关注区块链系统中的关键组件——mempool，它在处理待执行交易时面临asymmetric eviction DoS攻击的风险。作者提出了一种新型的防御策略，即\textsc{saferAd-PR}安全交易接纳算法。该算法设定了执行 eviction DoS 攻击的最低成本，确保了mempool的安全性。通过实际交易回放测试，\textsc{saferAd-PR}表现出低延迟和对各种攻击的强大防护能力，证明了其在保障区块链mempool安全方面的有效性与稳定性。 <div>
arXiv:2407.03543v1 Announce Type: new 
Abstract: The mempool plays a crucial role in blockchain systems as a buffer zone for pending transactions before they are executed and included in a block. However, existing works primarily focus on mitigating defenses against already identified real-world attacks. This paper introduces secure blockchain-mempool designs capable of defending against any form of asymmetric eviction DoS attacks. We establish formal security definitions for mempools under the eviction-based attack vector. Our proposed secure transaction admission algorithm, named \textsc{saferAd-PR}, ensures eviction-security by providing a provable lower bound on the cost of executing eviction DoS attacks. Through evaluation with real transaction trace replays, \textsc{saferAd-PR} demonstrates negligible latency and significantly high lower bounds against any eviction attack, highlighting its effectiveness and robustness in securing blockchain mempools.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SRAS: Self-governed Remote Attestation Scheme for Multi-party Collaboration</title>
<link>https://arxiv.org/abs/2407.03745</link>
<guid>https://arxiv.org/abs/2407.03745</guid>
<content:encoded><![CDATA[
<div> 关键词：Trusted Execution Environments (TEEs), Intel Software Guard Extensions (SGX), Remote Attestation, Multi-party Cloud Computing, Decentralized Verification.

总结:<br />本文提出了一种名为SRAS的开放自我治理远程验证方案，针对多党云计算中如何选择可信赖的第三方验证TEE（如Intel SGX）并保护数据隐私的问题。SRAS设计了一个Relying Party Enclave，形成虚拟可验证网络，能在本地代表其他参与者进行验证，无需泄露敏感信息。该方案实现了去中心化的统一可信验证平台，为云用户和开发者提供了开源原型，促进了相关技术的采纳。 <div>
arXiv:2407.03745v1 Announce Type: new 
Abstract: Trusted Execution Environments (TEEs), such as Intel Software Guard Extensions (SGX), ensure the confidentiality and integrity of user applications when using cloud computing resources. However, in the multi-party cloud computing scenario, how to select a Relying Party to verify the TEE of each party and avoid leaking sensitive data to each other remains an open question. In this paper, we propose SRAS, an open self-governed remote attestation scheme with attestation and verification functions for verifying the trustworthiness of TEEs and computing assets, achieving decentralized unified trusted attestation and verification platform for multi-party cloud users. In SRAS, we design a Relying Party enclave, which can form a virtual verifiable network, capable of local verification on behalf of other participants relying parties without leaking sensitive data to others. We provide an open-source prototype implementation of SRAS to facilitate the adoption of this technology by cloud users or developers.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>GriDB: Scaling Blockchain Database via Sharding and Off-Chain Cross-Shard Mechanism</title>
<link>https://arxiv.org/abs/2407.03750</link>
<guid>https://arxiv.org/abs/2407.03750</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain数据库、Scalability、Sharding、Cross-shard机制、Off-chain mechanism

总结:<br />
区块链数据库因其潜力而备受关注，但传统的非可扩展区块链限制了其性能。为解决这一问题，本文提出了一种名为GriDB的新型可扩展区块链数据库，通过设计一种新颖的离链跨 shard 机制，以提高跨 shard 数据服务的效率。GriDB借鉴了支付领域中离链处理的概念，选择不同 shard 的少量节点处理大规模数据交换，并通过生成简洁证明来抵抗拜占庭环境，共识机制只负责低成本的验证。文章还创新性地引入了几个新的认证数据结构（ADS），以满足数据库服务的额外要求，如完整性、正确性、新鲜性和可用性。此外，文中还探讨了负载均衡在区块链数据库中的重要性，并设计了一种离线且实时的方法，兼顾效率和可用性。总的来说，GriDB通过优化跨 shard 交互，为区块链数据库的可扩展性提供了新的解决方案。 <div>
arXiv:2407.03750v1 Announce Type: new 
Abstract: Blockchain databases have attracted widespread attention but suffer from poor scalability due to underlying non-scalable blockchains. While blockchain sharding is necessary for a scalable blockchain database, it poses a new challenge named on-chain cross-shard database services. Each cross-shard database service (e.g., cross-shard queries or inter-shard load balancing) involves massive cross-shard data exchanges, while the existing cross-shard mechanisms need to process each cross-shard data exchange via the consensus of all nodes in the related shards (i.e., on-chain) to resist a Byzantine environment of blockchain, which eliminates sharding benefits. To tackle the challenge, this paper presents GriDB, the first scalable blockchain database, by designing a novel off-chain cross-shard mechanism for efficient cross-shard database services. Borrowing the idea of off-chain payments, GriDB delegates massive cross-shard data exchange to a few nodes, each of which is randomly picked from a different shard. Considering the Byzantine environment, the untrusted delegates cooperate to generate succinct proof for cross-shard data exchanges, while the consensus is only responsible for the low-cost proof verification. However, different from payments, the database services' verification has more requirements (e.g., completeness, correctness, freshness, and availability); thus, we introduce several new authenticated data structures (ADS). Particularly, we utilize consensus to extend the threat model and reduce the complexity of traditional accumulator-based ADS for verifiable cross-shard queries with a rich set of relational operators. Moreover, we study the necessity of inter-shard load balancing for a scalable blockchain database and design an off-chain and live approach for both efficiency and availability during balancing.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Real-time Cyberattack Detection with Collaborative Learning for Blockchain Networks</title>
<link>https://arxiv.org/abs/2407.04011</link>
<guid>https://arxiv.org/abs/2407.04011</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链网络、攻击检测、协作学习、隐私保护、准确性。

总结:<br />
这篇文章关注区块链网络的安全问题，研究了常见的攻击手段如交易洪水和暴力破解。作者构建了一个包含正常和攻击流量数据的实验室区块链网络，用于生成实际攻击数据，训练和测试攻击检测模型。他们提出了一种实时的协作学习模型，允许网络中的节点在不泄露私有数据的情况下共享学习知识，从而提高整个系统的性能。实验结果显示，该模型能以高达97%的准确率检测区块链网络中的攻击，强调了隐私保护和高效检测的重要性。 <div>
arXiv:2407.04011v1 Announce Type: new 
Abstract: With the ever-increasing popularity of blockchain applications, securing blockchain networks plays a critical role in these cyber systems. In this paper, we first study cyberattacks (e.g., flooding of transactions, brute pass) in blockchain networks and then propose an efficient collaborative cyberattack detection model to protect blockchain networks. Specifically, we deploy a blockchain network in our laboratory to build a new dataset including both normal and attack traffic data. The main aim of this dataset is to generate actual attack data from different nodes in the blockchain network that can be used to train and test blockchain attack detection models. We then propose a real-time collaborative learning model that enables nodes in the network to share learning knowledge without disclosing their private data, thereby significantly enhancing system performance for the whole network. The extensive simulation and real-time experimental results show that our proposed detection model can detect attacks in the blockchain network with an accuracy of up to 97%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Pathfinder: Exploring Path Diversity for Assessing Internet Censorship Inconsistency</title>
<link>https://arxiv.org/abs/2407.04213</link>
<guid>https://arxiv.org/abs/2407.04213</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet censorship, ISP level, Routing paths, Incomplete/Flawed implementation, Decentralized censorship, Hosting platforms, Peering relationships, Inconsistent censorship.

总结:<br />
本文研究了互联网审查的多样性，关注国内ISP级别的部署差异。通过端到端测量框架，作者发现不同路由路径导致的审查不一致普遍存在，揭示了集中式审查的不完整和缺陷，以及分布式审查的广泛存在。此外，研究还指出，不同的托管平台由于与国内ISP的互联关系不同，会导致审查活动的不一致性。案例分析深入探讨了导致审查不一致的配置和原因。 <div>
arXiv:2407.04213v1 Announce Type: new 
Abstract: Internet censorship is typically enforced by authorities to achieve information control for a certain group of Internet users. So far existing censorship studies have primarily focused on country-level characterization because (1) in many cases, censorship is enabled by governments with nationwide policies and (2) it is usually hard to control how the probing packets are routed to trigger censorship in different networks inside a country. However, the deployment and implementation of censorship could be highly diverse at the ISP level. In this paper, we investigate Internet censorship from a different perspective by scrutinizing the diverse censorship deployment inside a country. Specifically, by leveraging an end-to-end measurement framework, we deploy multiple geo-distributed back-end control servers to explore various paths from one single vantage point. The generated traffic with the same domain but different control servers' IPs could be forced to traverse different transit networks, thereby being examined by different censorship devices if present. Through our large-scale experiments and in-depth investigation, we reveal that the diversity of Internet censorship caused by different routing paths inside a country is prevalent, implying that (1) the implementations of centralized censorship are commonly incomplete or flawed and (2) decentralized censorship is also common. Moreover, we identify that different hosting platforms also result in inconsistent censorship activities due to different peering relationships with the ISPs in a country. Finally, we present extensive case studies in detail to illustrate the configurations that lead to censorship inconsistency and explore the causes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Effective Targeted Testing of Smart Contracts</title>
<link>https://arxiv.org/abs/2407.04250</link>
<guid>https://arxiv.org/abs/2407.04250</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, symbolic execution, test data generation, targeted execution, CFG+

总结:
智能合约是一种部署在区块链网络上的自动执行代码，最初由以太坊在2014年提出。它们应用广泛，但固有的不可变性导致一旦出现错误无法修复，造成经济损失。文章关注测试数据生成与测试充分性的差距，提出了Griffin框架，采用目标导向的符号执行技术生成测试数据。它适用于多种场景，如验证静态分析警告和满足安全条件的反例。作者还改进了Solidity智能合约的控制流图（CFG+），并讨论了自定义启发式在合理时间内探索程序空间的方法。实验结果显示，Griffin能有效识别所需测试数据。 <div>
arXiv:2407.04250v1 Announce Type: new 
Abstract: Smart contracts are autonomous and immutable pieces of code that are deployed on blockchain networks and run by miners. They were first introduced by Ethereum in 2014 and have since been used for various applications such as security tokens, voting, gambling, non-fungible tokens, self-sovereign identities, stock taking, decentralized finances, decentralized exchanges, and atomic swaps. Since smart contracts are immutable, their bugs cannot be fixed, which may lead to significant monetary losses. While many researchers have focused on testing smart contracts, our recent work has highlighted a gap between test adequacy and test data generation, despite numerous efforts in both fields. Our framework, Griffin, tackles this deficiency by employing a targeted symbolic execution technique for generating test data. This tool can be used in diverse applications, such as killing the survived mutants in mutation testing, validating static analysis alarms, creating counter-examples for safety conditions, and reaching manually selected lines of code. This paper discusses how smart contracts differ from legacy software in targeted symbolic execution and how these differences can affect the tool structure, leading us to propose an enhanced version of the control-flow graph for Solidity smart contracts called CFG+. We also discuss how Griffin can utilize custom heuristics to explore the program space and find the test data that reaches a target line while considering a safety condition in a reasonable execution time. We conducted experiments involving an extensive set of smart contracts, target lines, and safety conditions based on real-world faults and test suites from related tools. The results of our evaluation demonstrate that Griffin can effectively identify the required test data within a reasonable timeframe.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Temporal fingerprints: Identity matching across fully encrypted domain</title>
<link>https://arxiv.org/abs/2407.04350</link>
<guid>https://arxiv.org/abs/2407.04350</guid>
<content:encoded><![CDATA[
<div> 关键词：temporal data, inter-event times, identity matching, Ethereum Blockchain, privacy preservation

总结:<br />
这篇文章探讨了技术进步如何促使人们在不同领域使用多个人格身份。研究发现，个体的时间行为，即事件之间的间隔分布，构成了独特的“时间指纹”，可用于跨域身份关联，即使在加密的数字交易平台（如以太坊区块链）上也能实现高精度匹配。这挑战了用户的隐私保护，因为仅仅知道一个人何时活跃就可能揭示其真实身份，即使缺乏交谈内容和联系人信息。因此，了解和保护这种时间数据的隐私成为当今数字时代的关键议题。 <div>
arXiv:2407.04350v1 Announce Type: new 
Abstract: Technological advancements have significantly transformed communication patterns, introducing a diverse array of online platforms, thereby prompting individuals to use multiple profiles for different domains and objectives. Enhancing the understanding of cross domain identity matching capabilities is essential, not only for practical applications such as commercial strategies and cybersecurity measures, but also for theoretical insights into the privacy implications of data disclosure. In this study, we demonstrate that individual temporal data, in the form of inter-event times distribution, constitutes an individual temporal fingerprint, allowing for matching profiles across different domains back to their associated real-world entity. We evaluate our methodology on encrypted digital trading platforms within the Ethereum Blockchain and present impressing results in matching identities across these privacy-preserving domains, while outperforming previously suggested models. Our findings indicate that simply knowing when an individual is active, even if information about who they talk to and what they discuss is lacking, poses risks to users' privacy, highlighting the inherent challenges in preserving privacy in today's digital landscape.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-based PKI within a Corporate Organization: Advantages and Challenges</title>
<link>https://arxiv.org/abs/2407.04536</link>
<guid>https://arxiv.org/abs/2407.04536</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, Public Key Infrastructure (PKI), decentralized, security, transparency

总结: <br />
本研究探讨了区块链技术在组织内部作为公共密钥基础设施（PKI）的潜在应用，与传统PKI系统进行了比较。文章关注点在于评估区块链技术的可行性，特别是在增强安全性和透明度方面的优势，如去中心化信任、防篡改证书管理和行为监控。同时，它还考虑了现行法律框架，如网络安全法(CRA)和NIS-2指令对这种新型PKI的影响。结论显示，区块链PKI在多个方面具有优势，尽管存在一些挑战，但仍显示出广阔的发展前景。 <div>
arXiv:2407.04536v1 Announce Type: new 
Abstract: This research investigates the potential use of a blockchain-based Public Key Infrastructure (PKI) within an organization and compares it to conventional PKI systems. The goal is to assess the advantages and disadvantages of both approaches in order to determine the feasibility of employing blockchain technology for a decentralized PKI. The study will also evaluate the impact of current legal frameworks, such as the Cyber Resilience Act (CRA) and NIS-2 Directive. The study will examine various implementations of blockchain PKIs based on factors such as security, performance, and platform. The results indicate that blockchain-based PKIs can overcome the limitations of conventional PKIs by decentralizing the trust anchor, providing greater security. Blockchain technology allows for the immutable and transparent management of certificates, making tampering significantly more challenging. Additionally, blockchain-based PKIs offer enhanced mechanisms for identifying and addressing certificate misconduct.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Joint Fronthaul Load Balancing and Computation Resource Allocation in Cell-Free User-Centric Massive MIMO Networks</title>
<link>https://arxiv.org/abs/2310.14911</link>
<guid>https://arxiv.org/abs/2310.14911</guid>
<content:encoded><![CDATA[
<div> 关键词：cell-free massive MIMO, open radio access network, user-centric clusters, fronthaul topology, computation resource allocation

总结:<br />
本文研究了一种可扩展的细胞自由大规模多输入多输出网络架构，该架构采用开放无线接入网络，包括用户设备(UEs)、无线单元(RUs)和分布式处理单元(DUs)。与现有文献主要关注无限制前传通信和计算能力下的用户速率不同，本文着重考虑了前传拓扑、有限容量和DU的计算约束。新提出的优化框架旨在解决前传负载平衡和计算资源分配问题。研究发现，RU的模数转换量化位数存在最优值，这影响系统性能。通过数值结果，文章揭示了这一优化问题的关键影响因素。 <div>
arXiv:2310.14911v2 Announce Type: replace 
Abstract: We consider scalable cell-free massive multiple-input multiple-output networks under an open radio access network paradigm comprising user equipments (UEs), radio units (RUs), and decentralized processing units (DUs). UEs are served by dynamically allocated user-centric clusters of RUs. The corresponding cluster processors (implementing the physical layer for each user) are hosted by the DUs as software-defined virtual network functions. Unlike the current literature, mainly focused on the characterization of the user rates under unrestricted fronthaul communication and computation, in this work we explicitly take into account the fronthaul topology, the limited fronthaul communication capacity, and computation constraints at the DUs. In particular, we systematically address the new problem of joint fronthaul load balancing and allocation of the computation resource. As a consequence of our new optimization framework, we present representative numerical results highlighting the existence of an optimal number of quantization bits in the analog-to-digital conversion at the RUs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain-empowered Federated Learning: Benefits, Challenges, and Solutions</title>
<link>https://arxiv.org/abs/2403.00873</link>
<guid>https://arxiv.org/abs/2403.00873</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Blockchain, Privacy, Security, Scalability.

总结:<br />Federated Learning (FL)是一种分布式机器学习方法，强调用户数据隐私保护。然而，它面临单点故障、激励不足和安全性问题。为解决这些问题，研究者将区块链技术与FL结合（Blockchain-empowered FL, BC-FL），以增强系统安全、公平性和扩展性。本文详尽回顾了BC-FL的最新研究，探讨了区块链如何融入FL，其带来的资源需求、优势与挑战，以及现有的解决方案。同时，对未来研究方向提出了见解。总的来说，BC-FL旨在优化FL系统的性能和隐私保护，但需要平衡网络、计算和存储资源的使用。 <div>
arXiv:2403.00873v2 Announce Type: replace 
Abstract: Federated learning (FL) is a distributed machine learning approach that protects user data privacy by training models locally on clients and aggregating them on a parameter server. While effective at preserving privacy, FL systems face limitations such as single points of failure, lack of incentives, and inadequate security. To address these challenges, blockchain technology is integrated into FL systems to provide stronger security, fairness, and scalability. However, blockchain-empowered FL (BC-FL) systems introduce additional demands on network, computing, and storage resources. This survey provides a comprehensive review of recent research on BC-FL systems, analyzing the benefits and challenges associated with blockchain integration. We explore why blockchain is applicable to FL, how it can be implemented, and the challenges and existing solutions for its integration. Additionally, we offer insights on future research directions for the BC-FL system.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection</title>
<link>https://arxiv.org/abs/2406.02318</link>
<guid>https://arxiv.org/abs/2406.02318</guid>
<content:encoded><![CDATA[
<div> 关键词：时间序列数据、联邦学习、异常检测、预训练语言模型、参数效率。

总结:<br />
本文提出了一种名为PeFAD的参数高效的联邦异常检测框架，旨在解决去中心化时间序列数据与集中式异常检测算法之间的差距。PeFAD利用预训练语言模型（PLM）作为客户端本地模型的基础，利用其跨模态知识转移能力。通过设计参数高效的联邦训练模块，降低通信成本和本地模型适应性，仅需微调少量参数并上传至服务器。文章还提出一种异常驱动的掩码选择策略来缓解训练中忽视异常的影响，并通过知识蒸馏处理合成的隐私保护数据集，解决客户端间的数据异质性问题。在四个真实数据集的实验中，PeFAD比现有最先进的方法性能提升高达28.74%。 <div>
arXiv:2406.02318v2 Announce Type: replace 
Abstract: With the proliferation of mobile sensing techniques, huge amounts of time series data are generated and accumulated in various domains, fueling plenty of real-world applications. In this setting, time series anomaly detection is practically important. It endeavors to identify deviant samples from the normal sample distribution in time series. Existing approaches generally assume that all the time series is available at a central location. However, we are witnessing the decentralized collection of time series due to the deployment of various edge devices. To bridge the gap between the decentralized time series data and the centralized anomaly detection algorithms, we propose a Parameter-efficient Federated Anomaly Detection framework named PeFAD with the increasing privacy concerns. PeFAD for the first time employs the pre-trained language model (PLM) as the body of the client's local model, which can benefit from its cross-modality knowledge transfer capability. To reduce the communication overhead and local model adaptation cost, we propose a parameter-efficient federated training module such that clients only need to fine-tune small-scale parameters and transmit them to the server for update. PeFAD utilizes a novel anomaly-driven mask selection strategy to mitigate the impact of neglected anomalies during training. A knowledge distillation operation on a synthetic privacy-preserving dataset that is shared by all the clients is also proposed to address the data heterogeneity issue across clients. We conduct extensive evaluations on four real datasets, where PeFAD outperforms existing state-of-the-art baselines by up to 28.74%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health</title>
<link>https://arxiv.org/abs/2406.07114</link>
<guid>https://arxiv.org/abs/2406.07114</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse, Healthcare, Technology, Machine Learning, Privacy

总结:<br />
本文探讨了Metaverse在医疗领域的潜力和应用。首先，介绍了Metaverse的基本概念和技术，特别是机器学习在其中的作用，指出其能提升医疗数据分析的深度。文章分析了Metaverse对医疗保健的积极影响，如改善患者护理、教育和研究。其次，讨论了区块链等新兴技术在未来医疗服务中的前景，以及如何处理隐私问题。总的来说，这篇研究为理解Metaverse在医疗行业的革命性作用提供了见解，强调了其可能带来的变革和挑战。 <div>
arXiv:2406.07114v2 Announce Type: replace 
Abstract: The concept of Metaverse has attracted a lot of attention in various fields and one of its important applications is health and treatment. The Metaverse has enormous potential to transform healthcare by changing patient care, medical education, and the way teaching/learning and research are done. The purpose of this research is to provide an introduction to the basic concepts and fundamental technologies of the Metaverse. This paper examines the pros and cons of the Metaverse in healthcare context and analyzes its potential from the technology and AI perspective. In particular, the role of machine learning methods is discussed; We will explain how machine learning algorithms can be applied to the Metaverse generated data to gain better insights in healthcare applications. Additionally, we examine the future visions of the Metaverse in health delivery, by examining emerging technologies such as blockchain and also addressing privacy concerns. The findings of this study contribute to a deeper understanding of the applications of Metaverse in healthcare and its potential to revolutionize the delivery of medical services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data</title>
<link>https://arxiv.org/abs/2406.10563</link>
<guid>https://arxiv.org/abs/2406.10563</guid>
<content:encoded><![CDATA[
<div> 关键词：healthcare, decentralized facilities, machine learning, data privacy, model confidentiality

总结:<br />文章探讨了在医疗保健领域，尤其是去中心化设施下，机器学习面临的两大挑战：数据隐私保护和模型异质性协作训练。为解决这些问题，作者提出了"Abstention-Aware Federated Voting (AAFV)"框架。AAFV结合了 abstention-aware voting 机制和差分隐私技术，允许本地模型在保持机密性的同时协作训练。通过阈值投票方法，筛选高置信度预测，提升学习效率并保护模型知识产权。实验结果验证了AAFV在糖尿病和院内患者死亡率预测任务中的有效性与隐私保护性能。 <div>
arXiv:2406.10563v2 Announce Type: replace 
Abstract: In the realm of healthcare where decentralized facilities are prevalent, machine learning faces two major challenges concerning the protection of data and models. The data-level challenge concerns the data privacy leakage when centralizing data with sensitive personal information. While the model-level challenge arises from the heterogeneity of local models, which need to be collaboratively trained while ensuring their confidentiality to address intellectual property concerns. To tackle these challenges, we propose a new framework termed Abstention-Aware Federated Voting (AAFV) that can collaboratively and confidentially train heterogeneous local models while simultaneously protecting the data privacy. This is achieved by integrating a novel abstention-aware voting mechanism and a differential privacy mechanism onto local models' predictions. In particular, the proposed abstention-aware voting mechanism exploits a threshold-based abstention method to select high-confidence votes from heterogeneous local models, which not only enhances the learning utility but also protects model confidentiality. Furthermore, we implement AAFV on two practical prediction tasks of diabetes and in-hospital patient mortality. The experiments demonstrate the effectiveness and confidentiality of AAFV in testing accuracy and privacy protection.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Learning Decentralized Linear Quadratic Regulators with $\sqrt{T}$ Regret</title>
<link>https://arxiv.org/abs/2210.08886</link>
<guid>https://arxiv.org/abs/2210.08886</guid>
<content:encoded><![CDATA[
<div> 关键词：online learning, decentralized LQR, system model, unknown, regret

总结:<br />
本文提出了一种在线学习算法，针对未知系统模型和单轨迹数据的动态调整，设计适应性的去中心化线性二次控制器。该算法利用了干扰反馈表示状态反馈控制器，结合在线凸优化和延迟反馈。研究结果表明，当系统稳定或已知稳定控制器时，算法在部分嵌套信息模式下的期望 regret 与时间步长 $T$ 成 $\sqrt{T}$ 规模增长。对于更普遍的信息模式，最优控制器未知，算法的 regret 相对于线性次优控制器。实验验证了理论分析。这种自适应控制策略在不断变化的环境中展示了其有效性。 <div>
arXiv:2210.08886v4 Announce Type: replace-cross 
Abstract: We propose an online learning algorithm that adaptively designs a decentralized linear quadratic regulator when the system model is unknown a priori and new data samples from a single system trajectory become progressively available. The algorithm uses a disturbance-feedback representation of state-feedback controllers coupled with online convex optimization with memory and delayed feedback. Under the assumption that the system is stable or given a known stabilizing controller, we show that our controller enjoys an expected regret that scales as $\sqrt{T}$ with the time horizon $T$ for the case of partially nested information pattern. For more general information patterns, the optimal controller is unknown even if the system model is known. In this case, the regret of our controller is shown with respect to a linear sub-optimal controller. We validate our theoretical findings using numerical experiments.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Accelerating Distributed Optimization: A Primal-Dual Perspective on Local Steps</title>
<link>https://arxiv.org/abs/2407.02689</link>
<guid>https://arxiv.org/abs/2407.02689</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式机器学习、通信复杂性、Primal-Dual方法、Accelerated GA-MSGD、Catalyst框架。

总结:<br />
本文探讨了分布式机器学习中高效训练的问题，特别是处理不同数据分布的多代理场景。作者提出了一种基本的Primal-Dual方法，即Accelerated Gradient Ascent Multiple Stochastic Gradient Descent (GA-MSGD)，它在处理拉格朗日函数时自然地融入了局部更新，无需跨代理通信。对于强凸目标，GA-MSGD即使在仅线性依赖于对偶变量的情况下也能实现通信轮次的线性收敛。这得益于对偶变量被限制在耦合矩阵的张成空间，使得对偶问题变得强烈凸。通过与Catalyst框架结合，该方法在各种设置下实现了近乎最优的通信复杂度，无需大批量处理。在随机分散问题中，它的性能接近确定性情况，优于现有算法。 <div>
arXiv:2407.02689v1 Announce Type: new 
Abstract: In distributed machine learning, efficient training across multiple agents with different data distributions poses significant challenges. Even with a centralized coordinator, current algorithms that achieve optimal communication complexity typically require either large minibatches or compromise on gradient complexity. In this work, we tackle both centralized and decentralized settings across strongly convex, convex, and nonconvex objectives. We first demonstrate that a basic primal-dual method, (Accelerated) Gradient Ascent Multiple Stochastic Gradient Descent (GA-MSGD), applied to the Lagrangian of distributed optimization inherently incorporates local updates, because the inner loops of running Stochastic Gradient Descent on the primal variable require no inter-agent communication. Notably, for strongly convex objectives, we show (Accelerated) GA-MSGD achieves linear convergence in communication rounds despite the Lagrangian being only linear in the dual variables. This is due to a unique structural property where the dual variable is confined to the span of the coupling matrix, rendering the dual problem strongly concave. When integrated with the Catalyst framework, our approach achieves nearly optimal communication complexity across various settings without the need for minibatches. Moreover, in stochastic decentralized problems, it attains communication complexities comparable to those in deterministic settings, improving over existing algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Balancing Patient Privacy and Health Data Security: The Role of Compliance in Protected Health Information (PHI) Sharing</title>
<link>https://arxiv.org/abs/2407.02766</link>
<guid>https://arxiv.org/abs/2407.02766</guid>
<content:encoded><![CDATA[
<div> 关键词：Protected Health Information (PHI)，Blockchain technology，Smart contracts，Patient consent management，HIPAA。

总结:<br />
本文探讨了区块链技术在保护医疗健康信息（PHI）方面的潜力。PHI的共享对于提升医疗服务质量和协调性至关重要，但必须遵循严格的隐私和安全政策，如HIPAA。作者提出了一种结合智能合约的区块链系统，旨在自动化部分知情同意流程，确保PHI的访问和分享符合患者意愿及法律要求，从而提高合规性和数据安全性。这一创新有助于实现高效、安全的医疗信息管理。 <div>
arXiv:2407.02766v1 Announce Type: new 
Abstract: Protected Health Information (PHI) sharing significantly enhances patient care quality and coordination, contributing to more accurate diagnoses, efficient treatment plans, and a comprehensive understanding of patient history. Compliance with strict privacy and security policies, such as those required by laws like HIPAA, is critical to protect PHI. Blockchain technology, which offers a decentralized and tamper-evident ledger system, hold promise in policy compliance. This system ensures the authenticity and integrity of PHI while facilitating patient consent management. In this work, we propose a blockchain technology that integrates smart contracts to partially automate consent-related processes and ensuring that PHI access and sharing follow patient preferences and legal requirements.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Hybrid Reactive Routing Protocol for Decentralized UAV Networks</title>
<link>https://arxiv.org/abs/2407.02929</link>
<guid>https://arxiv.org/abs/2407.02929</guid>
<content:encoded><![CDATA[
<div> 关键词：UAV网络、低SWaP、FW-UAVs、多跳通信、动态路由、管道机制。

总结:<br />
本文主要探讨了低SWaP和FW-UAVs构成的无线网络中，由于高机动性、快速变化的拓扑和频繁的路由中断所面临的挑战。为解决这些问题，作者提出了一种混合型的、基于需求的路由协议。该协议通过动态监控选定路线（称为“管道”）并提前切换到备用路线，以维持高服务质量的多跳通信。实验结果表明，与现有方案相比，这种管道机制能够提高吞吐量，减少路由发现次数、控制开销和流量中断，即使在高负载、密集节点和快速移动条件下也能保持优势。尽管对网络拓扑信息依赖有限，且算法复杂度较低，但作者的提议在不同网络和流量设置下仍表现出优于主动优化的链路状态路由的性能。同时，文中还对比了反应式和主动式路由策略的相对优劣。 <div>
arXiv:2407.02929v1 Announce Type: new 
Abstract: Wireless networks consisting of low SWaP, FW-UAVs are used in many applications, such as monitoring, search and surveillance of inaccessible areas. A decentralized and autonomous approach ensures robustness to failures; the UAVs explore and sense within the area and forward their information, in a multihop manner, to nearby aerial gateway nodes. However, the unpredictable nature of the events, relatively high speed of UAVs, and dynamic UAV trajectories cause the network topology to change significantly over time, resulting in frequent route breaks. A holistic routing approach is needed to support multiple traffic flows in these networks to provide mobility- and congestion-aware, high-quality routes when needed, with low control and computational overheads, using the information collected in a distributed manner. Existing routing schemes do not address all the mentioned issues.
  We present a hybrid reactive routing protocol for decentralized UAV networks. Our scheme searches routes on-demand, monitors a region around the selected route (the pipe), and proactively switches to an alternative route before the current route's quality degrades below a threshold. We empirically evaluate the impact of pipe width and node density on our ability to find alternate high-quality routes within the pipe and the overhead required to maintain the pipe. Compared to existing reactive routing schemes, our approach achieves higher throughput and reduces the number of route discoveries, overhead, and resulting flow interruptions at different traffic loads, node densities and speeds. Despite having limited network topology information, and low overhead and route computation complexity, our proposed scheme achieves superior throughput to proactive optimized link state routing scheme at different network and traffic settings. We also evaluate the relative performance of reactive and proactive routing schemes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Zero-X: A Blockchain-Enabled Open-Set Federated Learning Framework for Zero-Day Attack Detection in IoV</title>
<link>https://arxiv.org/abs/2407.02969</link>
<guid>https://arxiv.org/abs/2407.02969</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Vehicles (IoV), 5G/6G networks, zero-day attacks, Open-Set Recognition (OSR), federated learning (FL)

总结:<br />该论文关注互联网车辆（IoV）的安全问题，随着5G和即将来临的6G网络发展，网络安全威胁加剧，尤其是零日攻击。为此，作者提出Zero-X框架，结合深度神经网络与开放集识别（OSR），实现对未知漏洞的高效检测。创新之处在于利用区块链技术支持隐私保护的联邦学习，让汽车自主系统（CAVs）和安全运营中心（SOCs）在保护数据隐私的同时协作学习。实验结果表明，Zero-X框架在两个网络流量数据集上表现优秀，优于现有解决方案，具有高检测率和低误报率。 <div>
arXiv:2407.02969v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV) is a crucial technology for Intelligent Transportation Systems (ITS) that integrates vehicles with the Internet and other entities. The emergence of 5G and the forthcoming 6G networks presents an enormous potential to transform the IoV by enabling ultra-reliable, low-latency, and high-bandwidth communications. Nevertheless, as connectivity expands, cybersecurity threats have become a significant concern. The issue has been further exacerbated by the rising number of zero-day (0-day) attacks, which can exploit unknown vulnerabilities and bypass existing Intrusion Detection Systems (IDSs). In this paper, we propose Zero-X, an innovative security framework that effectively detects both 0-day and N-day attacks. The framework achieves this by combining deep neural networks with Open-Set Recognition (OSR). Our approach introduces a novel scheme that uses blockchain technology to facilitate trusted and decentralized federated learning (FL) of the ZeroX framework. This scheme also prioritizes privacy preservation, enabling both CAVs and Security Operation Centers (SOCs) to contribute their unique knowledge while protecting the privacy of their sensitive data. To the best of our knowledge, this is the first work to leverage OSR in combination with privacy-preserving FL to identify both 0-day and N-day attacks in the realm of IoV. The in-depth experiments on two recent network traffic datasets show that the proposed framework achieved a high detection rate while minimizing the false positive rate. Comparison with related work showed that the Zero-X framework outperforms existing solutions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Ultra-Lightweight Collaborative Mapping for Robot Swarms</title>
<link>https://arxiv.org/abs/2407.03136</link>
<guid>https://arxiv.org/abs/2407.03136</guid>
<content:encoded><![CDATA[
<div> 关键词：collaborative SLAM, lightweight, swarm robotics, onboard sensing, low-cost hardware

总结: 这篇文章介绍了一种创新的分布式、轻量级协作SLAM方法，旨在解决小规模和低成本机器人在自主定位与建图（SLAM）方面的挑战。该方法适用于各种机器人，包括微型昆虫尺寸设备，支持大规模群体协作，能有效协调数百个节点。实验表明，即使在仅重46克的厘米级无人机上实现，其性能接近高端解决方案，同时成本、内存和计算需求降低两个数量级。创新点包括：无基础设施的协作建图、优化的无线通信以支持大量节点以及分布式协调策略，降低延迟并提高精度。 <div>
arXiv:2407.03136v1 Announce Type: new 
Abstract: A key requirement in robotics is the ability to simultaneously self-localize and map a previously unknown environment, relying primarily on onboard sensing and computation. Achieving fully onboard accurate simultaneous localization and mapping (SLAM) is feasible for high-end robotic platforms, whereas small and inexpensive robots face challenges due to constrained hardware, therefore frequently resorting to external infrastructure for sensing and computation. The challenge is further exacerbated in swarms of robots, where coordination, scalability, and latency are crucial concerns. This work introduces a decentralized and lightweight collaborative SLAM approach that enables mapping on virtually any robot, even those equipped with low-cost hardware, including miniaturized insect-size devices. Moreover, the proposed solution supports large swarm formations with the capability to coordinate hundreds of agents. To substantiate our claims, we have successfully implemented collaborative SLAM on centimeter-size drones weighing only 46 grams. Remarkably, we achieve results comparable to high-end state-of-the-art solutions while reducing the cost, memory, and computation requirements by two orders of magnitude. Our approach is innovative in three main aspects. First, it enables onboard infrastructure-less collaborative mapping with a lightweight and cost-effective solution in terms of sensing and computation. Second, we optimize the data traffic within the swarm to support hundreds of cooperative agents using standard wireless protocols such as ultra-wideband (UWB), Bluetooth, or WiFi. Last, we implement a distributed swarm coordination policy to decrease mapping latency and enhance accuracy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2407.03144</link>
<guid>https://arxiv.org/abs/2407.03144</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Backdoor Attack, Imperceptible, Target-on-Demand, Venomancer.

总结:<br />
Federated Learning（FL）是一种分布式机器学习方法，旨在保护数据隐私。然而，它也面临后门攻击威胁。文章介绍了一种新的攻击手段Venomancer，它具有隐形和目标自定义的特点。隐形通过视觉损失函数实现，使毒数据与原始数据难以区分；目标自定义则通过条件对抗性训练允许攻击者选择任意目标类别。实验表明，Venomancer对抗现有防御机制如Norm Clipping、Weak DP、Krum和Multi-Krum表现出稳健性。代码可在https://anonymous.4open.science/r/Venomancer-3426获取。 <div>
arXiv:2407.03144v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning approach that maintains data privacy by training on decentralized data sources. Similar to centralized machine learning, FL is also susceptible to backdoor attacks. Most backdoor attacks in FL assume a predefined target class and require control over a large number of clients or knowledge of benign clients' information. Furthermore, they are not imperceptible and are easily detected by human inspection due to clear artifacts left on the poison data. To overcome these challenges, we propose Venomancer, an effective backdoor attack that is imperceptible and allows target-on-demand. Specifically, imperceptibility is achieved by using a visual loss function to make the poison data visually indistinguishable from the original data. Target-on-demand property allows the attacker to choose arbitrary target classes via conditional adversarial training. Additionally, experiments showed that the method is robust against state-of-the-art defenses such as Norm Clipping, Weak DP, Krum, and Multi-Krum. The source code is available at https://anonymous.4open.science/r/Venomancer-3426.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Cooperative Multi-Agent Deep Reinforcement Learning Methods for UAV-aided Mobile Edge Computing Networks</title>
<link>https://arxiv.org/abs/2407.03280</link>
<guid>https://arxiv.org/abs/2407.03280</guid>
<content:encoded><![CDATA[
<div> 关键词：无人飞行器、移动边缘计算、深度强化学习、协同多代理、任务卸载。

总结:<br />
本文提出了一种基于深度强化学习的协作多代理方法，应用于无人机辅助的移动边缘计算网络。该方法旨在优化无人机轨迹、资源分配和任务卸载策略，以提高地面物联网设备的服务性能。通过设计专用的演员神经网络生成消息动作和解决方案动作，实现无人机与设备的协调决策，即使面对任意数量的设备也能进行有效操作。文章还提出了一种可扩展的训练算法，适用于不同网络配置。实验结果显示，该协作多代理深度强化学习方法相较于传统方法表现出显著优势。 <div>
arXiv:2407.03280v1 Announce Type: new 
Abstract: This paper presents a cooperative multi-agent deep reinforcement learning (MADRL) approach for unmmaned aerial vehicle (UAV)-aided mobile edge computing (MEC) networks. An UAV with computing capability can provide task offlaoding services to ground internet-of-things devices (IDs). With partial observation of the entire network state, the UAV and the IDs individually determine their MEC strategies, i.e., UAV trajectory, resource allocation, and task offloading policy. This requires joint optimization of decision-making process and coordination strategies among the UAV and the IDs. To address this difficulty, the proposed cooperative MADRL approach computes two types of action variables, namely message action and solution action, each of which is generated by dedicated actor neural networks (NNs). As a result, each agent can automatically encapsulate its coordination messages to enhance the MEC performance in the decentralized manner. The proposed actor structure is designed based on graph attention networks such that operations are possible regardless of the number of IDs. A scalable training algorithm is also proposed to train a group of NNs for arbitrary network configurations. Numerical results demonstrate the superiority of the proposed cooperative MADRL approach over conventional methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits</title>
<link>https://arxiv.org/abs/2001.05452</link>
<guid>https://arxiv.org/abs/2001.05452</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent, Multi-Armed Bandit, Decentralized, Gossip Communication, Regret

总结: 本文探讨了一个多智能体马尔可夫链赌博（MAB）问题，其中N个智能体通过任意连接图进行协作，目标是减少个体累计后悔。研究者提出两种新算法，允许智能体仅交换臂ID而非样本，通过通信更新选择的臂集。文章表明，即使少量交流也能使每个智能体的后悔减少约N倍。通信对算法影响的二级效应也被分析，以理解后悔与通信之间的权衡。实验证明了这些结果的普遍性，且算法的性能界限是无沟通限制下的最优。总的来说，协作显著降低了所有智能体的后悔。 <div>
arXiv:2001.05452v4 Announce Type: replace 
Abstract: We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup consisting of $N$ agents, solving the same MAB instance to minimize individual cumulative regret. In our model, agents collaborate by exchanging messages through pairwise gossip style communications on an arbitrary connected graph. We develop two novel algorithms, where each agent only plays from a subset of all the arms. Agents use the communication medium to recommend only arm-IDs (not samples), and thus update the set of arms from which they play. We establish that, if agents communicate $\Omega(\log(T))$ times through any connected pairwise gossip mechanism, then every agent's regret is a factor of order $N$ smaller compared to the case of no collaborations. Furthermore, we show that the communication constraints only have a second order effect on the regret of our algorithm. We then analyze this second order term of the regret to derive bounds on the regret-communication tradeoffs. Finally, we empirically evaluate our algorithm and conclude that the insights are fundamental and not artifacts of our bounds. We also show a lower bound which gives that the regret scaling obtained by our algorithm cannot be improved even in the absence of any communication constraints. Our results thus demonstrate that even a minimal level of collaboration among agents greatly reduces regret for all agents.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2305.18784</link>
<guid>https://arxiv.org/abs/2305.18784</guid>
<content:encoded><![CDATA[
<div> 关键词：collaborative multi-agent bandits, decentralized algorithms, cumulative regret, group regret, lower bounds

总结:<br />本文关注协作多智能体_bandits的研究，探讨了由N个学习M个随机臂老虎机的代理组成的团队，目标是减少整体累积遗憾。研究者开发了去中心化的算法，适用于两种情景，并分析了算法性能，提供了每个代理和团队的累积遗憾上界。此外，文章还给出了团队遗憾的下界，证明了提议算法的近最优性。 <div>
arXiv:2305.18784v2 Announce Type: replace 
Abstract: The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Gradual Verification for Smart Contracts</title>
<link>https://arxiv.org/abs/2311.13351</link>
<guid>https://arxiv.org/abs/2311.13351</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchains, smart contracts, re-entrancy attacks, verification, Algorand.

总结:<br />
本文主要关注区块链中的智能合约安全问题，特别是针对外部合同交互时的漏洞，如著名的重入攻击(re-entrancy attacks)。作者提出了一种创新的方法——渐进式验证(gradual verification)，它结合了静态和动态验证技术，旨在提升智能合约的安全性、保证正确性和灵活性，同时优化资源使用。通过实现pyTEAL语言的Algorand智能合约验证原型，研究者展示了这种方法的有效性，有助于推动智能合约的稳健高效执行，从而保障区块链系统的安全性。 <div>
arXiv:2311.13351v2 Announce Type: replace 
Abstract: Blockchains facilitate secure resource transactions through smart contracts, yet these digital agreements are prone to vulnerabilities, particularly when interacting with external contracts, leading to substantial monetary losses. Traditional verification techniques fall short in providing comprehensive security assurances, especially against re-entrancy attacks, due to the unavailable implementations of external contracts. This paper introduces an incremental approach: gradual verification. We combine static and dynamic verification techniques to enhance security, guarantee soundness and flexibility, and optimize resource usage in smart contract interactions. By implementing a prototype for gradually verifying Algorand smart contracts via the pyTEAL language, we demonstrate the effectiveness of our approach, contributing to the safe and efficient execution of smart contracts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-Agent Probabilistic Ensembles with Trajectory Sampling for Connected Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2312.13910</link>
<guid>https://arxiv.org/abs/2312.13910</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Vehicles, Reinforcement Learning, Model-Based RL, Model-Free RL, Multi-Agent Probabilistic Ensembles with Trajectory Sampling

总结:
本文探讨了自动驾驶车辆（AVs）中的决策问题，特别关注了在连接的自动驾驶汽车（CAVs）中采用强化学习（RL）。文章指出，尽管模型自由的RL（MFRL）在数据驱动决策上表现出色，但在实际应用中可能面临数据需求大和学习不稳定的问题。相比之下，模型基于的RL（MBRL）虽然样本效率高，但长期性能可能不如最先进的MFRL算法。

研究者提出了一种多代理算法MA-PETS，它结合了概率ensemble神经网络（Probabilistic Ensemble，PE）和轨迹采样（Trajectory Sampling，TS）技术，以处理多个CAV之间的有限通信环境。MA-PETS通过利用邻居共享的数据，更好地捕捉环境不确定性，同时发展出基于模型预测控制的决策策略。文章还数学证明，通过在多代理学习中有效信息交流，可以降低多代理群体的后悔值。

实验结果表明，MA-PETS在样本效率上与MFRL相当，显示出其在复杂交通场景中的优势。总的来说，该研究提出了一种有效的多代理决策框架，兼顾了样本效率和不确定性处理，为连接的自动驾驶汽车的协同决策提供了新的解决方案。 <div>
arXiv:2312.13910v2 Announce Type: replace 
Abstract: Autonomous Vehicles (AVs) have attracted significant attention in recent years and Reinforcement Learning (RL) has shown remarkable performance in improving the autonomy of vehicles. In that regard, the widely adopted Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs (CAVs), contingent on the readiness of a significant amount of data samples for training. Nevertheless, it might be infeasible in practice and possibly lead to learning instability. In contrast, Model-Based RL (MBRL) manifests itself in sample-efficient learning, but the asymptotic performance of MBRL might lag behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs are limited to the decision-making of a single AV only, thus underscoring the performance due to the absence of communications. In this study, we try to address the decision-making problem of multiple CAVs with limited communications and propose a decentralized Multi-Agent Probabilistic Ensembles with Trajectory Sampling algorithm MA-PETS. In particular, in order to better capture the uncertainty of the unknown environment, MA-PETS leverages Probabilistic Ensemble (PE) neural networks to learn from communicated samples among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory Sampling (TS)-based model-predictive control for decision-making. On this basis, we derive the multi-agent group regret bound affected by the number of agents within the communication range and mathematically validate that incorporating effective information exchange among agents into the multi-agent learning scheme contributes to reducing the group regret bound in the worst case. Finally, we empirically demonstrate the superiority of MA-PETS in terms of the sample efficiency comparable to MFBL.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2406.17249</link>
<guid>https://arxiv.org/abs/2406.17249</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized, Metric-Semantic SLAM, Hierarchical Representation, Object-Based, Heterogeneous Robot Team

总结:<br />
本文提出了一种实时的分布式度量-语义同时定位和建图（SLAM）方法，适用于各种环境探索。该系统利用稀疏和轻量级的对象表示，支持异构机器人团队在室内、城市和森林环境中进行自主导航，无需GPS。通过层次化的度量-语义地图，包括高阶的对象模型和低阶的voxel地图，实现了跨不同传感器类型的机器人之间的位置识别。通信模块允许在通信链接可用时共享观察数据，构建合并地图。实验结果展示了出色的定位精度（约20厘米位置误差，0.2度方向误差），对象映射的F1分数超过0.9，以及每公里路径通信包大小仅2-3MB，即使有1000个地标。这项工作为多机器人协作的自主探索提供了有效解决方案。 <div>
arXiv:2406.17249v2 Announce Type: replace 
Abstract: This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) approach that leverages a sparse and lightweight object-based representation to enable a heterogeneous robot team to autonomously explore 3D environments featuring indoor, urban, and forested areas without relying on GPS. We use a hierarchical metric-semantic representation of the environment, including high-level sparse semantic maps of object models and low-level voxel maps. We leverage the informativeness and viewpoint invariance of the high-level semantic map to obtain an effective semantics-driven place-recognition algorithm for inter-robot loop closure detection across aerial and ground robots with different sensing modalities. A communication module is designed to track each robot's own observations and those of other robots whenever communication links are available. Such observations are then used to construct a merged map. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate and deploy our proposed framework on three types of aerial and ground robots. Extensive experimental results show an average inter-robot localization error of approximately 20 cm in position and 0.2 degrees in orientation, an object mapping F1 score consistently over 0.9, and a communication packet size of merely 2-3 megabytes per kilometer trajectory with as many as 1,000 landmarks. The project website can be found at https://xurobotics.github.io/slideslam/.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Commodification of Compute</title>
<link>https://arxiv.org/abs/2406.19261</link>
<guid>https://arxiv.org/abs/2406.19261</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、区块链技术、智能合约、全球计算交换（GCX）、资源优化。

总结:<br />
本文介绍了一种名为全球计算交换（GCX）的新型平台，它利用区块链技术和智能合约来解决计算资源分配中的效率问题和价格波动。GCX通过构建市场、应用、清算、风险管理、离链和区块链等多层结构，创建了一个安全、透明的市场，使用户能够买卖计算能力，实现资源的公平访问和优化使用。这个平台不仅提升了计算资源的利用率，还稳定了价格，促进了创新，并有望推动计算资源的民主化。总的来说，GCX是一个具有革新性的解决方案，预示着计算资源商品化的未来趋势。 <div>
arXiv:2406.19261v2 Announce Type: replace 
Abstract: The rapid advancements in artificial intelligence, big data analytics, and cloud computing have precipitated an unprecedented demand for computational resources. However, the current landscape of computational resource allocation is characterized by significant inefficiencies, including underutilization and price volatility. This paper addresses these challenges by introducing a novel global platform for the commodification of compute hours, termed the Global Compute Exchange (GCX) (Patent Pending). The GCX leverages blockchain technology and smart contracts to create a secure, transparent, and efficient marketplace for buying and selling computational power. The GCX is built in a layered fashion, comprising Market, App, Clearing, Risk Management, Exchange (Offchain), and Blockchain (Onchain) layers, each ensuring a robust and efficient operation. This platform aims to revolutionize the computational resource market by fostering a decentralized, efficient, and transparent ecosystem that ensures equitable access to computing power, stimulates innovation, and supports diverse user needs on a global scale. By transforming compute hours into a tradable commodity, the GCX seeks to optimize resource utilization, stabilize pricing, and democratize access to computational resources. This paper explores the technological infrastructure, market potential, and societal impact of the GCX, positioning it as a pioneering solution poised to drive the next wave of innovation in commodities and compute.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Multi-topic belief formation through bifurcations over signed social networks</title>
<link>https://arxiv.org/abs/2308.02755</link>
<guid>https://arxiv.org/abs/2308.02755</guid>
<content:encoded><![CDATA[
<div> 关键词：信念形成、多维、社会网络、认知不协调、动态模型

总结:<br />
本文提出并分析了一个连续时间多维度的信念形成模型，考虑了社会网络结构、个体自我评估、内在偏见以及认知不协调等社会心理学理论因素。模型通过描述意见形成过程中的转折点（即分岔）探讨了个体观点的形成。研究发现，社交网络效应的平衡决定了信念形成过程的性质，以及多稳态信念均衡和由此产生的信念振荡。该模型揭示了社会系统动态的新见解，并为设计工程网络中基于结构关系的去中心化决策提供了理论框架。 <div>
arXiv:2308.02755v2 Announce Type: replace-cross 
Abstract: We propose and analyze a nonlinear dynamic model of continuous-time multi-dimensional belief formation over signed social networks. Our model accounts for the effects of a structured belief system, self-appraisal, internal biases, and various sources of cognitive dissonance posited by recent theories in social psychology. We prove that agents become opinionated as a consequence of a bifurcation. We analyze how the balance of social network effects in the model controls the nature of the bifurcation and, therefore, the belief-forming limit-set solutions. Our analysis provides constructive conditions on how multi-stable network belief equilibria and belief oscillations emerging at a belief-forming bifurcation depend on the communication network graph and belief system network graph. Our model and analysis provide new theoretical insights on the dynamics of social systems and a new principled framework for designing decentralized decision-making on engineered networks in the presence of structured relationships among alternatives.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reusable Formal Verification of DAG-based Consensus Protocols</title>
<link>https://arxiv.org/abs/2407.02167</link>
<guid>https://arxiv.org/abs/2407.02167</guid>
<content:encoded><![CDATA[
<div> 关键词：DAG-based consensus, protocols, blockchain, safety proof, TLA+

总结:<br />
本文探讨了DAG（有向无环图）为基础的共识协议在区块链领域的应用，这些协议旨在降低能源消耗和增强安全性。作者提供了两个此类协议的安全性证明形式规范，强调了协议的不同实现变种，如传播、DAG构建和排序。使用TLA+语言对抽象模型进行了描述，包括492-732行的规格说明和2025-2294项义务的验证，整个过程在6-8分钟内完成。这一工作对于区块链技术的正确性和可靠性提供了重要保障。 <div>
arXiv:2407.02167v1 Announce Type: new 
Abstract: DAG-based consensus protocols are being adoption by blockchain companies to decrease energy footprints and improve security. A DAG-based consensus protocol collaboratively constructs a partial order of blocks of transactions and produces linearly ordered blocks. The ubiquity and strategic importance of blockchains call for formal proof of the correctness of key components, namely, consensus protocols. This paper presents a safety-proven formal specification of two DAG-based protocols. Our specification highlights several dissemination, DAG construction, and ordering variations that can be combined to express the two protocols. The formalization requires a refinement approach for modeling the consensus. In an abstract model, we first show the safety of DAG-based consensus on leader blocks and then further refine the specification to encompass all blocks for all processes. The TLA+ specification for a given protocol consists of 492-732 lines, and the proof system TLAPS verifies 2025-2294 obligations in 6-8 minutes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>RollupTheCrowd: Leveraging ZkRollups for a Scalable and Privacy-Preserving Reputation-based Crowdsourcing Platform</title>
<link>https://arxiv.org/abs/2407.02226</link>
<guid>https://arxiv.org/abs/2407.02226</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain, reputation, crowdsourcing, zkRollups, scalability

总结:<br />
这篇文章介绍了一种名为RollupTheCrowd的新型区块链框架，专注于解决现有区块链声誉系统在效率、隐私和可扩展性之间的平衡问题。通过结合zkRollups（零知识证明的rollup），该框架能够在保护用户隐私的同时，有效评估众包工作者的信誉，减轻了区块链上的交易压力，降低了约20倍的gas消耗。文章还提到，作者开发了一个概念验证原型，并通过实验展示了RollupTheCrowd的可行性和实际应用潜力。 <div>
arXiv:2407.02226v1 Announce Type: new 
Abstract: Current blockchain-based reputation solutions for crowdsourcing fail to tackle the challenge of ensuring both efficiency and privacy without compromising the scalability of the blockchain. Developing an effective, transparent, and privacy-preserving reputation model necessitates on-chain implementation using smart contracts. However, managing task evaluation and reputation updates alongside crowdsourcing transactions on-chain substantially strains system scalability and performance. This paper introduces RollupTheCrowd, a novel blockchain-powered crowdsourcing framework that leverages zkRollups to enhance system scalability while protecting user privacy. Our framework includes an effective and privacy-preserving reputation model that gauges workers' trustworthiness by assessing their crowdsourcing interactions. To alleviate the load on our blockchain, we employ an off-chain storage scheme, optimizing RollupTheCrowd's performance. Utilizing smart contracts and zero-knowledge proofs, our Rollup layer achieves a significant 20x reduction in gas consumption. To prove the feasibility of the proposed framework, we developed a proof-of-concept implementation using cutting-edge tools. The experimental results presented in this paper demonstrate the effectiveness and scalability of RollupTheCrowd, validating its potential for real-world application scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Intelligence Network (DIN)</title>
<link>https://arxiv.org/abs/2407.02461</link>
<guid>https://arxiv.org/abs/2407.02461</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Intelligence Network (DIN), 数据主权, 分散式学习, 公共区块链, 奖励机制

总结:<br />
Decentralized Intelligence Network (DIN)是一个创新框架，旨在解决数据碎片化和AI利用中的问题。它通过五个关键点实现：首先，个人数据存储支持数据主权；其次，基于公共区块链的联邦学习协议允许在保持数据私有性的同时进行模型参数共享；接着，通过无第三方的信任奖励机制激励参与，确保公平分配；此外，该系统防止任何一方控制数据访问或收益决定；最后，DIN创建了一个去中心化的生态系统，促进集体AI发展，保护用户数据权益并实现多方共赢。 <div>
arXiv:2407.02461v1 Announce Type: new 
Abstract: Decentralized Intelligence Network (DIN) addresses the significant challenges of data sovereignty and AI utilization caused by the fragmentation and siloing of data across providers and institutions. This comprehensive framework overcomes access barriers to scalable data sources previously hindered by silos by leveraging: 1) personal data stores as a prerequisite for data sovereignty; 2) a scalable federated learning protocol implemented on a public blockchain for decentralized AI training, where data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training, allowing participants to maintain control over their data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial algorithms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Efficient and Sybil Attack Resistant Voting Mechanism</title>
<link>https://arxiv.org/abs/2407.01844</link>
<guid>https://arxiv.org/abs/2407.01844</guid>
<content:encoded><![CDATA[
<div> 关键词：投票机制、Sybil攻击、Bayesian机制设计、风险中性、效率

总结: 这篇文章探讨了在无需身份验证的去中心化决策场景中，如何设计一种既能抵抗多重账户（Sybil攻击）又能实现最大集体利益的投票机制。研究者提出了一种基于Bayesian机制设计的解决方案，其核心在于：玩家通过财富存款表达偏好，投票结果影响个人收益分配；机制设计使得恶意投票者对整体效用的影响大于自身收益，从而保证系统在风险中性玩家和私有信息的假设下既防SA又高效。这一成果为构建更稳健的去中心化决策机制提供了新思路。 <div>
arXiv:2407.01844v1 Announce Type: cross 
Abstract: Voting mechanisms are widely accepted and used methods for decentralized decision-making. Ensuring the acceptance of the voting mechanism's outcome is a crucial characteristic of robust voting systems. Consider this scenario: A group of individuals wants to choose an option from a set of alternatives without requiring an identification or proof-of-personhood system. Moreover, they want to implement utilitarianism as their selection criteria. In such a case, players could submit votes multiple times using dummy accounts, commonly known as a Sybil attack (SA), which presents a challenge for decentralized organizations. Is there a voting mechanism that always prevents players from benefiting by casting votes multiple times (SA-proof) while also selecting the alternative that maximizes the added valuations of all players (efficient)? One-person-one-vote is neither SA-proof nor efficient. Coin voting is SA-proof but not efficient. Quadratic voting is efficient but not SA-proof. This study uses Bayesian mechanism design to propose a solution. The mechanism's structure is as follows: Players make wealth deposits to indicate the strength of their preference for each alternative. Each player then receives an amount based on their deposit and the voting outcome. The proposed mechanism relies on two main concepts: 1) Transfers are influenced by the outcome in a way that each player's optimal action depends only on individual preferences and the number of alternatives; 2) A player who votes through multiple accounts slightly reduces the expected utility of all players more than the individual benefit gained. This study demonstrates that if players are risk-neutral and each player has private information about their preferences and beliefs, then the mechanism is SA-proof and efficient. This research provides new insights into the design of more robust decentralized decision-making mechanisms.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Knowledge Connectivity Requirements for Solving BFT Consensus with Unknown Participants and Fault Threshold (Extended Version)</title>
<link>https://arxiv.org/abs/2405.06055</link>
<guid>https://arxiv.org/abs/2405.06055</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Fault Tolerant Consensus, Knowledge Connectivity Graph, Fault Threshold, BFT-CUP, BFT-CUPFT.

总结:<br />
本文主要关注拜占庭容错共识（BFT）在参与者知识受限的场景，即每个参与者仅知道部分参与者。首先，文章讨论了BFT-CUP问题，即在提供故障阈值给所有参与者的情况下达成共识。然而，研究者发现这不适用于BFT-CUPFT，即故障阈值未知的情况。为此，文章提出了一种新的知识连接图类型，确定了解决BFT-CUPFT所需的必要和充分条件。最后，作者设计了一个协议来处理这种故障未知的BFT共识场景，扩展了先前理论并解决了实际应用中的挑战。 <div>
arXiv:2405.06055v2 Announce Type: replace 
Abstract: Consensus stands as a fundamental building block for constructing reliable and fault-tolerant distributed services. The increasing demand for high-performance and scalable blockchain protocols has brought attention to solving consensus in scenarios where each participant joins the system knowing only a subset of participants. In such scenarios, the participants' initial knowledge about the existence of other participants can collectively be represented by a directed graph known as knowledge connectivity graph. The Byzantine Fault Tolerant Consensus with Unknown Participants (BFT-CUP) problem aims to solve consensus in those scenarios by identifying the necessary and sufficient conditions that the knowledge connectivity graphs must satisfy when a fault threshold is provided to all participants. This work extends BFT-CUP by eliminating the requirement to provide the fault threshold to the participants. We indeed address the problem of solving BFT consensus in settings where each participant initially knows a subset of participants, and although a fault threshold exists, no participant is provided with this information -- referred to as BFT Consensus with Unknown Participants and Fault Threshold (BFT-CUPFT). With this aim, we first demonstrate that the conditions for knowledge connectivity graphs identified by BFT-CUP are insufficient to solve BFT-CUPFT. Accordingly, we introduce a new type of knowledge connectivity graphs by determining the necessary and sufficient conditions they must satisfy to solve BFT-CUPFT. Furthermore, we design a protocol for solving BFT-CUPFT.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations</title>
<link>https://arxiv.org/abs/2407.00632</link>
<guid>https://arxiv.org/abs/2407.00632</guid>
<content:encoded><![CDATA[
<div> 关键词：视觉导航、多机器人协作、大型语言模型、通信触发、动态领导组织结构。

总结:<br />本文探讨了在复杂视觉导航任务中，如何利用大型语言模型（LLMs）实现多机器人有效协作。研究提出了一种框架，通过设计通信触发的动态领导组织结构，促进团队成员间的快速共识和减少交流次数，从而提高导航效率和探索效率。这种创新的通信机制使得框架在处理多目标导航时表现出冲突解决能力和对团队规模扩大的稳健性，为家庭服务机器人的协作导航提供了新思路。 <div>
arXiv:2407.00632v1 Announce Type: new 
Abstract: Visual navigation tasks are critical for household service robots. As these tasks become increasingly complex, effective communication and collaboration among multiple robots become imperative to ensure successful completion. In recent years, large language models (LLMs) have exhibited remarkable comprehension and planning abilities in the context of embodied agents. However, their application in household scenarios, specifically in the use of multiple agents collaborating to complete complex navigation tasks through communication, remains unexplored. Therefore, this paper proposes a framework for decentralized multi-agent navigation, leveraging LLM-enabled communication and collaboration. By designing the communication-triggered dynamic leadership organization structure, we achieve faster team consensus with fewer communication instances, leading to better navigation effectiveness and collaborative exploration efficiency. With the proposed novel communication scheme, our framework promises to be conflict-free and robust in multi-object navigation tasks, even when there is a surge in team size.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Opportunities for Shape-based Optimization of Link Traversal Queries</title>
<link>https://arxiv.org/abs/2407.00998</link>
<guid>https://arxiv.org/abs/2407.00998</guid>
<content:encoded><![CDATA[
<div> 关键词：web数据、Link Traversal Query Processing (LTQP)、RDF数据形状、source selection algorithm、decentralized query processing

总结:<br />
这篇文章主要探讨了在Web数据的去中心化环境中，如何利用RDF数据形状优化Link Traversal Query Processing (LTQP)的问题。作者提出了一种基于RDF数据形状映射的源选择算法，旨在解决LTQP中缺乏先验信息和大量HTTP请求的问题。初步实验表明，通过少量维护和服务器工作，该方法能显著减少查询执行时间（高达80%）和链接遍历数量（达97%）。这为非启发式查询规划研究提供了新的方向，展示了RDF数据形状的强大描述能力。未来的研究可能集中在更深入地挖掘这种潜力上。 <div>
arXiv:2407.00998v1 Announce Type: new 
Abstract: Data on the web is naturally unindexed and decentralized. Centralizing web data, especially personal data, raises ethical and legal concerns. Yet, compared to centralized query approaches, decentralization-friendly alternatives such as Link Traversal Query Processing (LTQP) are significantly less performant and understood. The two main difficulties of LTQP are the lack of apriori information about data sources and the high number of HTTP requests. Exploring decentralized-friendly ways to document unindexed networks of data sources could lead to solutions to alleviate those difficulties. RDF data shapes are widely used to validate linked data documents, therefore, it is worthwhile to investigate their potential for LTQP optimization. In our work, we built an early version of a source selection algorithm for LTQP using RDF data shape mappings with linked data documents and measured its performance in a realistic setup. In this article, we present our algorithm and early results, thus, opening opportunities for further research for shape-based optimization of link traversal queries. Our initial experiments show that with little maintenance and work from the server, our method can reduce up to 80% the execution time and 97% the number of links traversed during realistic queries. Given our early results and the descriptive power of RDF data shapes it would be worthwhile to investigate non-heuristic-based query planning using RDF shapes.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Energy-Aware Decentralized Learning with Intermittent Model Training</title>
<link>https://arxiv.org/abs/2407.01283</link>
<guid>https://arxiv.org/abs/2407.01283</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized learning, Energy consumption, SkipTrain, Synchronization rounds, Model accuracy.

总结:<br />
本文介绍了一种名为SkipTrain的新型去中心化学习（Decentralized learning）算法，其目标是减少能源消耗并提高模型准确性。SkipTrain通过有策略地跳过一些训练轮次，用同步轮替之，从而在不牺牲模型性能的前提下，节省了大量能量。与常规的D-PSGD算法相比，SkipTrain在256节点实验中显示出高达50%的节能效果和高达12%的模型精度提升。这种方法不仅降低了计算成本，还促进了模型间的更好融合。 <div>
arXiv:2407.01283v1 Announce Type: new 
Abstract: Decentralized learning (DL) offers a powerful framework where nodes collaboratively train models without sharing raw data and without the coordination of a central server. In the iterative rounds of DL, models are trained locally, shared with neighbors in the topology, and aggregated with other models received from neighbors. Sharing and merging models contribute to convergence towards a consensus model that generalizes better across the collective data captured at training time. In addition, the energy consumption while sharing and merging model parameters is negligible compared to the energy spent during the training phase. Leveraging this fact, we present SkipTrain, a novel DL algorithm, which minimizes energy consumption in decentralized learning by strategically skipping some training rounds and substituting them with synchronization rounds. These training-silent periods, besides saving energy, also allow models to better mix and finally produce models with superior accuracy than typical DL algorithms that train at every round. Our empirical evaluations with 256 nodes demonstrate that SkipTrain reduces energy consumption by 50% and increases model accuracy by up to 12% compared to D-PSGD, the conventional DL algorithm.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>C-MP: A decentralized adaptive-coordinated traffic signal control using the Max Pressure framework</title>
<link>https://arxiv.org/abs/2407.01421</link>
<guid>https://arxiv.org/abs/2407.01421</guid>
<content:encoded><![CDATA[
<div> 关键词：Coordinated Max Pressure (C-MP), adaptive traffic signals, decentralized decision-making, arterial network, stable region.

总结:<br />
本文提出了一种新颖的协调最大压力(Coordinated Max Pressure, C-MP)交通信号框架，旨在解决分布式决策下协调交通流的问题。C-MP利用车辆空间平均速度检测并优先处理沿走廊的自由行驶车队，通过调整上游车队的权重和下游车队的权重，确保交通流畅。文章证明了C-MP保持最大稳定性，并通过模拟分析展示了其在动脉网络中相较于基准MP控制策略具有更大的稳定区域。C-MP在无需预设交错时间和约束的情况下有效协调双向动脉交通，减少旅行时间和燃料消耗，实现交通流量的均衡。 <div>
arXiv:2407.01421v1 Announce Type: new 
Abstract: Coordinated traffic signals seek to provide uninterrupted flow through a series of closely spaced intersections, typically using pre-defined fixed signal timings and offsets. Adaptive traffic signals dynamically change signal timings based on observed traffic conditions in a way that might disrupt coordinated movements, particularly when these decisions are made independently at each intersection. To alleviate this issue, this paper introduces a novel Max Pressure-based traffic signal framework that can provide coordination even under decentralized decision-making. The proposed Coordinated Max Pressure (C-MP) algorithm uses the space mean speeds of vehicles to explicitly detect freely flowing platoons of vehicles and prioritizes their movement along a corridor. Specifically, upstream platoons are detected and their weight in the MP framework increased to provide priority, while downstream platoons are detected and their weight reduced to ensure smooth traffic flow across corridors. The study analytically proves that C-MP maintains the desirable maximum stability property, while micro-simulation analyses conducted on an arterial network demonstrate its ability to achieve a larger stable region compared to benchmark MP control policies. Simulation results also reveal that the proposed control algorithm can effectively coordinate traffic signals in both directions along an arterial without explicitly assigned offsets or constraints. The results also reveal C-MP's superiority to benchmark coordination strategies in reducing travel time, and fuel consumption both at the corridor level and the network level by balancing the negative impact imparted to vehicles in the minor direction.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Graph Neural Networks and Reinforcement Learning for Proactive Application Image Placement</title>
<link>https://arxiv.org/abs/2407.00007</link>
<guid>https://arxiv.org/abs/2407.00007</guid>
<content:encoded><![CDATA[
<div> 关键词：Edge computing, Cloud-Edge continuum, Service placement, Application placement, Reinforcement Learning.

总结:<br />
云计算向云边计算的转变为数据密集型和交互式应用带来了机遇与挑战。边缘计算作为下一代应用严格需求的关键支持，通过将计算任务移至用户附近，实现了低延迟和高带宽。然而，边缘计算的分布式、动态和异构特性使得服务部署成为一个难题。本文提出了一种结合图神经网络和强化学习（Actor-Critic）的前瞻性图像部署方法，旨在减少图像传输时间并优化应用部署。尽管在某些情况下可能导致执行时间稍长，但实验结果显示，该方法在整体应用部署上表现更优。 <div>
arXiv:2407.00007v1 Announce Type: new 
Abstract: The shift from Cloud Computing to a Cloud-Edge continuum presents new opportunities and challenges for data-intensive and interactive applications. Edge computing has garnered a lot of attention from both industry and academia in recent years, emerging as a key enabler for meeting the increasingly strict demands of Next Generation applications. In Edge computing the computations are placed closer to the end-users, to facilitate low-latency and high-bandwidth applications and services. However, the distributed, dynamic, and heterogeneous nature of Edge computing, presents a significant challenge for service placement. A critical aspect of Edge computing involves managing the placement of applications within the network system to minimize each application's runtime, considering the resources available on system devices and the capabilities of the system's network. The placement of application images must be proactively planned to minimize image tranfer time, and meet the strict demands of the applications. In this regard, this paper proposes an approach for proactive image placement that combines Graph Neural Networks and actor-critic Reinforcement Learning, which is evaluated empirically and compared against various solutions. The findings indicate that although the proposed approach may result in longer execution times in certain scenarios, it consistently achieves superior outcomes in terms of application placement.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A New Approach for Evaluating the Performance of Distributed Latency-Sensitive Services</title>
<link>https://arxiv.org/abs/2407.00015</link>
<guid>https://arxiv.org/abs/2407.00015</guid>
<content:encoded><![CDATA[
<div> 关键词：latency metrics, Service Level Agreement (SLA), distributed computing, immersive services, latency performance.

总结:<br />本文提出了一篇关于新型延迟度量标准（latency metrics）的研究论文，针对传统指标在评估现代服务和分布式计算环境中性能的局限性。研究者强调了现有指标无法充分捕捉两个关键性能方面：超过服务级别协议（SLA）阈值的频率以及恢复到可接受水平的时间。为解决这一问题，作者开发了五个创新的延迟度量，它们能够提供更深入的服务性能洞察。这些新指标尤其适用于对低延迟有严格要求的沉浸式服务。论文通过大规模实验验证了新指标的有效性和实用性，以促进服务性能优化。 <div>
arXiv:2407.00015v1 Announce Type: new 
Abstract: Conventional latency metrics are formulated based on a broad definition of traditional monolithic services, and hence lack the capacity to address the complexities inherent in modern services and distributed computing paradigms. Consequently, their effectiveness in identifying areas for improvement is restricted, falling short of providing a comprehensive evaluation of service performance within the context of contemporary services and computing paradigms. More specifically, these metrics do not offer insights into two critical aspects of service performance: the frequency of latency surpassing specified Service Level Agreement (SLA) thresholds and the time required for latency to return to an acceptable level once the threshold is exceeded. This limitation is quite significant in the frame of contemporary latency-sensitive services, and especially immersive services that require deterministic low latency that behaves in a consistent manner. Towards addressing this limitation, the authors of this work propose 5 novel latency metrics that when leveraged alongside the conventional latency metrics manage to provide advanced insights that can be potentially used to improve service performance. The validity and usefulness of the proposed metrics in the frame of providing advanced insights into service performance is evaluated using a large-scale experiment.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Preble: Efficient Distributed Prompt Scheduling for LLM Serving</title>
<link>https://arxiv.org/abs/2407.00023</link>
<guid>https://arxiv.org/abs/2407.00023</guid>
<content:encoded><![CDATA[
<div> 关键词：Preble、大型语言模型（LLMs）、分布式 serving 平台、prompt 分享、计算重用。

总结:
Preble 是一项创新，它提出了一种针对大型语言模型（LLMs）服务的分布式平台，专注于优化提示共享。文章研究了五个流行的工作负载，发现当前系统忽视了重复提示的注意力计算可以复用的潜力。为此，Preble 设计了一个分布式调度系统，兼顾计算重用和负载均衡。实验证明，与现有技术相比，Preble 在两到八GPU上分别提高了平均延迟1.5倍至14.5倍和p99值的2倍至10倍，显著提升了性能。 <div>
arXiv:2407.00023v1 Announce Type: new 
Abstract: Prompts to large language models (LLMs) have evolved beyond simple user questions. For LLMs to solve complex problems, today's practices include domain-specific instructions, illustration of tool usages, and long context, such as textbook chapters in prompts. As such, many parts of prompts are repetitive across requests, and their attention computation results can be reused. However, today's LLM serving systems treat every request in isolation, missing the opportunity of computation reuse.
  This paper proposes Preble, the first distributed LLM serving platform that targets and optimizes for prompt sharing. We perform a study on five popular LLM workloads. Based on our study results, we designed a distributed scheduling system that co-optimizes computation reuse and load balancing. Our evaluation of Preble on two to 8 GPUs with real workloads and request arrival patterns on two open-source LLM models shows that Preble outperforms the state-of-the-art average latency by 1.5X to 14.5X and p99 by 2X to 10X.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Inference Performance Optimization for LLMs on CPUs</title>
<link>https://arxiv.org/abs/2407.00029</link>
<guid>https://arxiv.org/abs/2407.00029</guid>
<content:encoded><![CDATA[
<div> 关键词：large language models (LLMs), distributed computing, resource-limited hardware, memory capacity, inference optimization.

总结:
本文介绍了一种针对大型语言模型（LLMs）的分布式推理优化解决方案，旨在缓解资源受限硬件设备上的内存限制和提高计算性能。该方法特别适用于部署在5代Intel Xeon Scalable处理器上。实验结果显示，使用72亿参数的LLM，通过优化后的方案，每输出一个令牌的时间降低到140毫秒，远低于人类阅读的平均速度（约200毫秒/令牌），显著提高了效率。这一成果表明分布式计算在有效利用CPU资源、扩展LLM应用中具有重要价值。 <div>
arXiv:2407.00029v1 Announce Type: new 
Abstract: Large language models (LLMs) hold tremendous potential for addressing numerous real-world challenges, yet they typically demand significant computational resources and memory. Deploying LLMs onto a resource-limited hardware device with restricted memory capacity presents considerable challenges. Distributed computing emerges as a prevalent strategy to mitigate single-node memory constraints and expedite LLM inference performance. To reduce the hardware limitation burden, we proposed an efficient distributed inference optimization solution for LLMs on CPUs. We conduct experiments with the proposed solution on 5th Gen Intel Xeon Scalable Processors, and the result shows the time per output token for the LLM with 72B parameter is 140 ms/token, much faster than the average human reading speed about 200ms per token.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On Orchestrating Parallel Broadcasts for Distributed Ledgers</title>
<link>https://arxiv.org/abs/2407.00030</link>
<guid>https://arxiv.org/abs/2407.00030</guid>
<content:encoded><![CDATA[
<div> 关键词：ticketing, atomic broadcasts, distributed system, managed ticketing, unmanaged ticketing

总结:<br />本文主要探讨了“票证”(ticketing)的概念在分布式系统中对原子广播的组织。文章研究了不同类型的票证制度，允许并行执行但防止慢节点影响整体进度。一种混合方案被提出，结合了管理和未管理的票证模式，旨在平衡适应性和鲁棒性。性能评估显示，无论是静态还是动态场景，资源异构的系统中，管理票证制度对吞吐量有优势，因为它能更好地适应。最后，实验表明，使用混合票证制度可以同时享受管理票证的适应性与未管理票证的活度保证。 <div>
arXiv:2407.00030v1 Announce Type: new 
Abstract: This paper introduces and develops the concept of ``ticketing'', through which atomic broadcasts are orchestrated by nodes in a distributed system. The paper studies different ticketing regimes that allow parallelism, yet prevent slow nodes from hampering overall progress. It introduces a hybrid scheme which combines managed and unmanaged ticketing regimes, striking a balance between adaptivity and resilience. The performance evaluation demonstrates how managed and unmanaged ticketing regimes benefit throughput in systems with heterogeneous resources both in static and dynamic scenarios, with the managed ticketing regime performing better among the two as it adapts better. Finally, it demonstrates how using the hybrid ticketing regime performance can enjoy both the adaptivity of the managed regime and the liveness guarantees of the unmanaged regime.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Systems in Fintech</title>
<link>https://arxiv.org/abs/2407.00034</link>
<guid>https://arxiv.org/abs/2407.00034</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统、金融技术（Fintech）、区块链、去中心化金融（DeFi）、分布式 ledger technology (DLT)

总结:<br />
分布式系统在Fintech中的作用日益凸显，推动了行业革新。本文分析了分布式系统的架构，如区块链、DeFi和DLT，它们在提升金融操作的安全性、可扩展性和效率方面展现出巨大潜力。文章深入探讨了这些技术如何影响金融服务、支付、资产管理等，并展望了未来分布式系统在Fintech领域的广阔前景。随着技术不断发展，分布式系统有望重塑金融行业的版图。 <div>
arXiv:2407.00034v1 Announce Type: new 
Abstract: The emergence of distributed systems has revolutionized the financial technology (Fintech) landscape, offering unprecedented opportunities for enhancing security, scalability, and efficiency in financial operations. This paper explores the role of distributed systems in Fintech, analyzing their architecture, benefits, challenges, and applications. It examines key distributed technologies such as blockchain, decentralized finance (DeFi), and distributed ledger technology (DLT), and their impact on various aspects of the financial industry, and future directions for distributed systems in Fintech.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Streamline Intelligent Crowd Monitoring with IoT Cloud Computing Middleware</title>
<link>https://arxiv.org/abs/2407.00045</link>
<guid>https://arxiv.org/abs/2407.00045</guid>
<content:encoded><![CDATA[
<div> 关键词：middleware, Raspberry Pi, wireless sensor networks (WSNs), MapReduce, fault tolerance

总结:<br />
本文介绍了一种新颖的中间件系统，它利用低成本、低功耗的设备如Raspberry Pi分析无线传感器网络（WSN）的数据。该系统针对室内环境，如历史建筑和博物馆，用于监控访客、识别兴趣点并作为疏散辅助工具。通过MapReduce算法收集和分布数据，结合故障容忍的领导选举算法，其性能与资源密集型方法相当，但使用简单硬件。在希腊一处历史建筑（哈茨迪亚基斯故居）进行了成功测试。与现有实现相比，这种设计的优势在于其经济、分布式且具有故障恢复能力。尤其在COVID-19大流行期间，这种中间件对于室内位置的监控具有重要意义，能有效追踪访客数量和整体建筑占用率。 <div>
arXiv:2407.00045v1 Announce Type: new 
Abstract: This article introduces a novel middleware that utilizes cost-effective, low-power computing devices like Raspberry Pi to analyze data from wireless sensor networks (WSNs). It is designed for indoor settings like historical buildings and museums, tracking visitors and identifying points of interest. It serves as an evacuation aid by monitoring occupancy and gauging the popularity of specific areas, subjects, or art exhibitions. The middleware employs a basic form of the MapReduce algorithm to gather WSN data and distribute it across available computer nodes. Data collected by RFID sensors on visitor badges is stored on mini-computers placed in exhibition rooms and then transmitted to a remote database after a preset time frame. Utilizing MapReduce for data analysis and a leader election algorithm for fault tolerance, this middleware showcases its viability through metrics, demonstrating applications like swift prototyping and accurate validation of findings. Despite using simpler hardware, its performance matches resource-intensive methods involving audiovisual and AI techniques. This design's innovation lies in its fault-tolerant, distributed setup using budget-friendly, low-power devices rather than resource-heavy hardware or methods. Successfully tested at a historical building in Greece (M. Hatzidakis' residence), it is tailored for indoor spaces. This paper compares its algorithmic application layer with other implementations, highlighting its technical strengths and advantages. Particularly relevant in the wake of the COVID-19 pandemic and general monitoring middleware for indoor locations, this middleware holds promise in tracking visitor counts and overall building occupancy.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Tracing Distributed Algorithms Using Replay Clocks</title>
<link>https://arxiv.org/abs/2407.00069</link>
<guid>https://arxiv.org/abs/2407.00069</guid>
<content:encoded><![CDATA[
<div> 关键词：replay clocks (RepCl), distributed computations, concurrent events, constraint violations, visualization.

总结:<br />
本文介绍了一种新的时钟基础设施——replay clocks (RepCl)，它旨在支持离线分析分布式计算。RepCl结合了向量时钟(VC)和混合逻辑时钟(HLC)的优势，提供高效重放功能，允许用户检查并发事件下的约束条件和潜在执行路径。文章强调了RepCl的低开销实现（最多4个整数表示64个进程）以及与同步时间的关系。通过模拟和NS-3网络模拟器，作者评估了RepCl的预期开销，并确定了其可行性的区域。此外，文中提出了一种基于RepCl的分布式计算追踪器，可实时分析系统的特性，同时考虑并发路径。这个可视化工具提供了逐进程和全局视图，便于深入理解计算过程。 <div>
arXiv:2407.00069v1 Announce Type: new 
Abstract: In this thesis, we introduce replay clocks (RepCl), a novel clock infrastructure that allows us to do offline analyses of distributed computations. The replay clock structure provides a methodology to replay a computation as it happened, with the ability to represent concurrent events effectively. It builds on the structures introduced by vector clocks (VC) and the Hybrid Logical Clock (HLC), combining their infrastructures to provide efficient replay. With such a clock, a user can replay a computation whilst considering multiple paths of executions, and check for constraint violations and properties that potential pathways could take in the presence of concurrent events. Specifically, if event e must occur before f then the replay clock must ensure that e is replayed before f. On the other hand, if e and f could occur in any order, replay should not force an order between them. We demonstrate that RepCl can be implemented with less than four integers for 64 processes for various system parameters if clocks are synchronized within 1ms. Furthermore, the overhead of RepCl (for computing timestamps and message size) is proportional to the size of the clock. Using simulations in a custom distributed system and NS-3, a state-of-the-art network simulator, we identify the expected overhead of RepCl. We also identify how a user can then identify feasibility region for RepCl, where unabridged replay is possible. Using the RepCl, we provide a tracer for distributed computations, that allows any computation using the RepCl to be replayed efficiently. The visualization allows users to analyze specific properties and constraints in an online fashion, with the ability to consider concurrent paths independently. The visualization provides per-process views and an overarching view of the whole computation based on the time recorded by the RepCl for each event.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized Task Offloading and Load-Balancing for Mobile Edge Computing in Dense Networks</title>
<link>https://arxiv.org/abs/2407.00080</link>
<guid>https://arxiv.org/abs/2407.00080</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized task offloading, load-balancing, dense network, edge servers, mean field multi-agent MAB game.

总结:
该研究关注于密集网络中众多设备和边缘服务器之间的任务卸载与负载均衡问题。由于网络信息未知和任务大小随机，优化这一问题颇具挑战。论文提出了一种结合了多智能体多臂赌博（MAB）游戏的平均场方法，通过调整服务器奖励实现目标用户分布，即使在分布式决策制定下也能达到平衡。数值结果证明了这种方法的有效性，并展示了其能导向目标负载分布。 <div>
arXiv:2407.00080v1 Announce Type: new 
Abstract: We study the problem of decentralized task offloading and load-balancing in a dense network with numerous devices and a set of edge servers. Solving this problem optimally is complicated due to the unknown network information and random task sizes. The shared network resources also influence the users' decisions and resource distribution. Our solution combines the mean field multi-agent multi-armed bandit (MAB) game with a load-balancing technique that adjusts the servers' rewards to achieve a target population profile despite the distributed user decision-making. Numerical results demonstrate the efficacy of our approach and the convergence to the target load distribution.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges</title>
<link>https://arxiv.org/abs/2407.00147</link>
<guid>https://arxiv.org/abs/2407.00147</guid>
<content:encoded><![CDATA[
<div> 关键词：数据挖掘、医院化、急诊部门、预测准确性、诊断错误。

总结: 这篇文章探讨了如何利用数据挖掘技术分析大型医院化数据，以预测患者在急诊部门出院后可能的早期住院。通过组合运用逻辑回归、朴素贝叶斯和关联规则分类器，研究者实现了对3天、7天和14天内住院的高精度预测。这种方法不仅准确，而且生成的可解释模型便于医生理解，规则可以直接转化为实践中的决策工具，帮助他们在患者出院前识别潜在的早期住院风险，从而改善诊断质量和患者安全。 <div>
arXiv:2407.00147v1 Announce Type: new 
Abstract: Hospitalizations that follow closely on the heels of one or more emergency department visits are often symptoms of missed opportunities to form a proper diagnosis. These diagnostic errors imply a failure to recognize the need for hospitalization and deliver appropriate care, and thus also bear important connotations for patient safety. In this paper, we show how data mining techniques can be applied to a large existing hospitalization data set to learn useful models that predict these upcoming hospitalizations with high accuracy. Specifically, we use an ensemble of logistics regression, na\"ive Bayes and association rule classifiers to successfully predict hospitalization within 3, 7 and 14 days of an emergency department discharge. Aside from high accuracy, one of the advantages of the techniques proposed here is that the resulting classifier is easily inspected and interpreted by humans so that the learned rules can be readily operationalized. These rules can then be easily distributed and applied directly by physicians in emergency department settings to predict the risk of early admission prior to discharging their emergency department patients.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Dual-view Aware Smart Contract Vulnerability Detection for Ethereum</title>
<link>https://arxiv.org/abs/2407.00336</link>
<guid>https://arxiv.org/abs/2407.00336</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、smart contracts、vulnerability detection、Dual-view Aware、DVDet。

总结:<br />
本文介绍了一种名为DVDet的双视图智能合约漏洞检测框架。该框架针对以太坊智能合约的源代码和字节码，通过转化为加权图和控制流序列，从两个视角捕捉潜在风险特征并整合分析，以提高合同漏洞检测的效率和准确性。实验结果显示，DVDet在检测智能合约漏洞方面表现出色，超越了其他方法，为区块链技术的安全性提供了有力支持。 <div>
arXiv:2407.00336v1 Announce Type: new 
Abstract: The wide application of Ethereum technology has brought technological innovation to traditional industries. As one of Ethereum's core applications, smart contracts utilize diverse contract codes to meet various functional needs and have gained widespread use. However, the non-tamperability of smart contracts, coupled with vulnerabilities caused by natural flaws or human errors, has brought unprecedented challenges to blockchain security. Therefore, in order to ensure the healthy development of blockchain technology and the stability of the blockchain community, it is particularly important to study the vulnerability detection techniques for smart contracts. In this paper, we propose a Dual-view Aware Smart Contract Vulnerability Detection Framework named DVDet. The framework initially converts the source code and bytecode of smart contracts into weighted graphs and control flow sequences, capturing potential risk features from these two perspectives and integrating them for analysis, ultimately achieving effective contract vulnerability detection. Comprehensive experiments on the Ethereum dataset show that our method outperforms others in detecting vulnerabilities.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>C-MASS: Combinatorial Mobility-Aware Sensor Scheduling for Collaborative Perception with Second-Order Topology Approximation</title>
<link>https://arxiv.org/abs/2407.00412</link>
<guid>https://arxiv.org/abs/2407.00412</guid>
<content:encoded><![CDATA[
<div> 关键词：Collaborative Perception, Sensor Scheduling, Combinatorial Mobility-Aware, Budgeted Maximum Coverage, Wireless Bandwidth.

总结:<br />该论文关注于协作感知(Collaborative Perception, CP)中如何有效利用有限的无线带宽。传统的传感器调度面临车辆移动带来的感知拓扑不确定性挑战。为此，作者提出了一种名为C-MASS的框架，通过组合单辆车和车对的数据来近似完整感知拓扑，减少通信开销。C-MASS采用一种混合贪婪算法解决带预算的最大覆盖问题，兼顾探索与利用，以应对移动性问题。实验结果表明，C-MASS在边缘辅助和分布式配置下接近最优，相较于基于距离和区域的贪心策略，性能提升明显。 <div>
arXiv:2407.00412v1 Announce Type: new 
Abstract: Collaborative Perception (CP) has been a promising solution to address occlusions in the traffic environment by sharing sensor data among collaborative vehicles (CoV) via vehicle-to-everything (V2X) network. With limited wireless bandwidth, CP necessitates task-oriented and receiver-aware sensor scheduling to prioritize important and complementary sensor data. However, due to vehicular mobility, it is challenging and costly to obtain the up-to-date perception topology, i.e., whether a combination of CoVs can jointly detect an object. In this paper, we propose a combinatorial mobility-aware sensor scheduling (C-MASS) framework for CP with minimal communication overhead. Specifically, detections are replayed with sensor data from individual CoVs and pairs of CoVs to maintain an empirical perception topology up to the second order, which approximately represents the complete perception topology. A hybrid greedy algorithm is then proposed to solve a variant of the budgeted maximum coverage problem with a worst-case performance guarantee. The C-MASS scheduling algorithm adapts the greedy algorithm by incorporating the topological uncertainty and the unexplored time of CoVs to balance exploration and exploitation, addressing the mobility challenge. Extensive numerical experiments demonstrate the near-optimality of the proposed C-MASS framework in both edge-assisted and distributed CP configurations. The weighted recall improvements over object-level CP are 5.8% and 4.2%, respectively. Compared to distance-based and area-based greedy heuristics, the gaps to the offline optimal solutions are reduced by up to 75% and 71%, respectively.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Data-Driven Control of Linear Parabolic Systems using Koopman Eigenstructure Assignment</title>
<link>https://arxiv.org/abs/2407.00432</link>
<guid>https://arxiv.org/abs/2407.00432</guid>
<content:encoded><![CDATA[
<div> 关键词：Koopman operator, data-driven, stabilization, parabolic PDEs, eigenstructure assignment.

总结:<br />
本文探讨了如何利用Koopman算子实现线性边界控制下抛物型PDE系统的数据驱动稳定化。研究的核心内容是解决Koopman特征向量赋值问题，即设计一个反馈控制器，使其能设定期望的有限组闭合环Koopman特征值和特征函数。这个控制器依赖于扩展的Krylov-DMD方法来处理抛物型系统，仅需有限数量的采样输出和输入数据。文章证明了在小的Krylov-DMD误差下，闭环系统是指数稳定的。最后，通过一个不稳定的扩散-反应系统的例子，验证了这种适用于分布式参数系统的新型数据驱动控制器设计技术。 <div>
arXiv:2407.00432v1 Announce Type: new 
Abstract: This paper considers the data-driven stabilization of linear boundary controlled parabolic PDEs by making use of the Koopman operator. For this, a Koopman eigenstructure assignment problem is solved, which amounts to determine a feedback of the Koopman open-loop eigenfunctionals assigning a desired finite set of closed-loop Koopman eigenvalues and eigenfunctionals to the closed-loop system. It is shown that the designed controller only needs a finite number of open-loop Koopman eigenvalues and modes of the state. They are determined by extending the classical Krylov-DMD to parabolic systems. For this, only a finite number of pointlike outputs and their temporal samples as well as temporal samples of the inputs are required resulting in a data-driven solution of the eigenstructure assignment problem. Exponential stability of the closed-loop system in the presence of small Krylov-DMD errors is verified. An unstable diffusion-reaction system demonstrates the new data-driven controller design technique for distributed-parameter systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Graph Neural Networks Gone Hogwild</title>
<link>https://arxiv.org/abs/2407.00494</link>
<guid>https://arxiv.org/abs/2407.00494</guid>
<content:encoded><![CDATA[
<div> 关键词：message passing GNNs, asynchronous inference, implicitly-defined GNNs, energy GNN, multi-agent systems.

总结:<br />
本文探讨了图神经网络（GNN）在异步推理时的性能问题，发现普通GNN架构在节点更新不同时会导致错误预测。为解决这一问题，作者提出了"隐式定义"的GNN类别，其中一种名为能量GNN的新架构特别受关注。这种架构基于异步优化的理论，如Bertsekas（1982）和Niu等人（2011）的工作，具有对部分异步" hogwild"推理的稳健性。实验表明，能量GNN在多智能体系统相关的合成任务上优于同类GNN，并在现实世界数据集上表现出竞争力。 <div>
arXiv:2407.00494v1 Announce Type: new 
Abstract: Message passing graph neural networks (GNNs) would appear to be powerful tools to learn distributed algorithms via gradient descent, but generate catastrophically incorrect predictions when nodes update asynchronously during inference. This failure under asynchrony effectively excludes these architectures from many potential applications, such as learning local communication policies between resource-constrained agents in, e.g., robotic swarms or sensor networks. In this work we explore why this failure occurs in common GNN architectures, and identify "implicitly-defined" GNNs as a class of architectures which is provably robust to partially asynchronous "hogwild" inference, adapting convergence guarantees from work in asynchronous and distributed optimization, e.g., Bertsekas (1982); Niu et al. (2011). We then propose a novel implicitly-defined GNN architecture, which we call an energy GNN. We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems, and achieves competitive performance on real-world datasets.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Blockchain based Decentralized Petition System</title>
<link>https://arxiv.org/abs/2407.00534</link>
<guid>https://arxiv.org/abs/2407.00534</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized online petition system, blockchain technology, transparency, voting platform, integrity

总结:
本文探讨了一种基于区块链技术的去中心化在线请愿系统，旨在克服现有系统在透明度、安全性和信任度上的不足。该系统通过区块链记录每个签名和行动，确保过程不可篡改，支持民主决策的民主化。文章还提出了一个基于区块链的去中心化投票应用，设计考虑了系统架构、透明计票机制以及消除中心权威的需求。研究着重于技术实现的细节，如算法和协议，目标是提升民主流程的公正性、安全性和防篡改能力。未来的研究将深入技术层面，以进一步优化这一创新平台。 <div>
arXiv:2407.00534v1 Announce Type: new 
Abstract: A decentralized online petition system enables individuals or groups to create, sign, and share petitions without a central authority. Using blockchain technology, these systems ensure the integrity and transparency of the petition process by recording every signature or action on the blockchain, making alterations or deletions impossible. This provides a permanent, tamper-proof record of the petition's progress. Such systems allow users to bypass traditional intermediaries like government or social media platforms, fostering more democratic and transparent decision-making.
  This paper reviews research on petition systems, highlighting the shortcomings of existing systems such as lack of accountability, vulnerability to hacking, and security issues. The proposed blockchain-based implementation aims to overcome these challenges. Decentralized voting systems have garnered interest recently due to their potential to provide secure and transparent voting platforms without intermediaries, addressing issues like voter fraud, manipulation, and trust in the electoral process.
  We propose a decentralized voting system web application using blockchain technology to ensure the integrity and security of the voting process. This system aims to provide a transparent, decentralized decision-making process that counts every vote while eliminating the need for centralized authorities. The paper presents an overview of the system architecture, design considerations, and implementation details, along with the potential benefits and limitations.
  Finally, we discuss future research directions, examining the technical aspects of the application, including underlying algorithms and protocols. Our research aims to enhance the integrity and accessibility of democratic processes, improve security, and ensure fairness, transparency, and tamper-proofness.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Challenging the Need for Packet Spraying in Large-Scale Distributed Training</title>
<link>https://arxiv.org/abs/2407.00550</link>
<guid>https://arxiv.org/abs/2407.00550</guid>
<content:encoded><![CDATA[
<div> 关键词：large-scale distributed training, network communication, packet spraying, singlepath transport, multipath transport.

总结:<br />该论文质疑了业界普遍接受的观点，即在大规模分布式训练中，多路径传输和包喷射对于提升性能至关重要。研究者发现，单路径传输（从网卡角度看）实际上可以接近理想的多路径传输效果。他们通过分析集体通信模式驱动的工作负载的四个关键特性得出这一结论：同时启动的流量、近似的等量流量、集体完成时间更重要以及流量可以在到达时分割。作者证明，应用层少量的流量分割使得单路径传输在最大拥塞方面与理想多路径传输和包喷射相当。初步评估支持这些发现，提出研发针对大规模分布式训练的下一代传输协议的新方向。 <div>
arXiv:2407.00550v1 Announce Type: new 
Abstract: Large-scale distributed training in production datacenters constitutes a challenging workload bottlenecked by network communication. In response, both major industry players (e.g., Ultra Ethernet Consortium) and parts of academia have surprisingly, and almost unanimously, agreed that packet spraying is necessary to improve the performance of large-scale distributed training workloads.
  In this paper, we challenge this prevailing belief and pose the question: How close can a singlepath transport approach an optimal multipath transport? We demonstrate that singlepath transport (from a NIC's perspective) is sufficient and can perform nearly as well as an ideal multipath transport with packet spraying, particularly in the context of distributed training in leaf-spine topologies. Our assertion is based on four key observations about workloads driven by collective communication patterns: (i) flows within a collective start almost simultaneously, (ii) flow sizes are nearly equal, (iii) the completion time of a collective is more crucial than individual flow completion times, and (iv) flows can be split upon arrival. We analytically prove that singlepath transport, using minimal flow splitting (at the application layer), is equivalent to an ideal multipath transport with packet spraying in terms of maximum congestion. Our preliminary evaluations support our claims. This paper suggests an alternative agenda for developing next-generation transport protocols tailored for large-scale distributed training.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Joint Task Allocation and Scheduling for Multi-Hop Distributed Computing</title>
<link>https://arxiv.org/abs/2407.00565</link>
<guid>https://arxiv.org/abs/2407.00565</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Things, Edge Computing, Distributed Computing, Master-Worker Paradigm, Multi-hop Routing

总结:<br />该论文探讨了物联网和边缘计算时代分布式计算的新框架，突破传统的一跳范围限制。研究提出将网络图转换为沉降树结构，通过联合优化任务分配和调度，实现跨多层节点的资源共享。论文提供了两种精确算法和三种启发式策略来解决这一问题。实验结果显示，新方法在有限资源、动态连通性和延迟敏感应用中表现出色，优于传统策略。总的来说，这项工作扩展了分布式计算的适用性，提升了计算效率。 <div>
arXiv:2407.00565v1 Announce Type: new 
Abstract: The rise of the Internet of Things and edge computing has shifted computing resources closer to end-users, benefiting numerous delay-sensitive, computation-intensive applications. To speed up computation, distributed computing is a promising technique that allows parallel execution of tasks across multiple compute nodes. However, current research predominantly revolves around the master-worker paradigm, limiting resource sharing within one-hop neighborhoods. This limitation can render distributed computing ineffective in scenarios with limited nearby resources or constrained/dynamic connectivity. In this paper, we address this limitation by introducing a new distributed computing framework that extends resource sharing beyond one-hop neighborhoods through exploring layered network structures and multi-hop routing. Our framework involves transforming the network graph into a sink tree and formulating a joint optimization problem based on the layered tree structure for task allocation and scheduling. To solve this problem, we propose two exact methods that find optimal solutions and three heuristic strategies to improve efficiency and scalability. The performances of these methods are analyzed and evaluated through theoretical analyses and comprehensive simulation studies. The results demonstrate their promising performances over the traditional distributed computing and computation offloading strategies.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DDRM: Distributed Drone Reputation Management for Trust and Reliability in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2407.00591</link>
<guid>https://arxiv.org/abs/2407.00591</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Drone Reputation Management (DDRM), Internet of Drone Things (IoDT), Ethereum blockchain, Service Review Authorization Token (SRAT), Drone Reputation Enhancement Token (DRET)

总结:<br />
分布式无人机信誉管理系统（DDRM）是一项针对互联网无人机事物（IoDT）生态的创新框架。它利用以太坊区块链构建一个可验证的透明评论机制，旨在提升无人机服务的信任度。DDRM采用双币系统，包括服务审查授权令牌（SRAT）用于权限管理，以及无人机声誉增强令牌（DRET）以奖励表现可靠的无人机。研究证明，DDRM能够抵御欺诈行为，有效提高无人机服务的效率和可靠性，为无人机服务民主化提供保障。 <div>
arXiv:2407.00591v1 Announce Type: new 
Abstract: This study introduces the Distributed Drone Reputation Management (DDRM) framework, designed to fortify trust and authenticity within the Internet of Drone Things (IoDT) ecosystem. As drones increasingly play a pivotal role across diverse sectors, integrating crowdsourced drone services within the IoDT has emerged as a vital avenue for democratizing access to these services. A critical challenge, however, lies in ensuring the authenticity and reliability of drone service reviews. Leveraging the Ethereum blockchain, DDRM addresses this challenge by instituting a verifiable and transparent review mechanism. The framework innovates with a dual-token system, comprising the Service Review Authorization Token (SRAT) for facilitating review authorization and the Drone Reputation Enhancement Token (DRET) for rewarding and recognizing drones demonstrating consistent reliability. Comprehensive analysis within this paper showcases DDRM's resilience against various reputation frauds and underscores its operational effectiveness, particularly in enhancing the efficiency and reliability of drone services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>BAZAM: A Blockchain-Assisted Zero-Trust Authentication in Multi-UAV Wireless Networks</title>
<link>https://arxiv.org/abs/2407.00630</link>
<guid>https://arxiv.org/abs/2407.00630</guid>
<content:encoded><![CDATA[
<div> 关键词：Unmanned Aerial Vehicles (UAVs), Zero-trust framework, Blockchain, Authentication scheme, Physical Unclonable Functions (PUFs).

总结:<br />本文主要探讨了无人驾驶航空器(UAVs)网络中的身份验证问题。针对传统身份认证的不足，如系统中心化、无法适应多样的UAV身份和访问需求，以及缺乏持续的身份合规检查，作者提出了一种基于区块链的零信任身份验证方案BAZAM。该方案利用物理不可克隆功能(PUFs)生成密钥，并借助加密技术验证UAV的注册和访问请求，同时通过区块链实现UAV身份信息的永久存储。文章详细分析了BAZAM的安全性和效率，并通过实验验证其有效性。 <div>
arXiv:2407.00630v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) are vulnerable to interception and attacks when operated remotely without a unified and efficient identity authentication. Meanwhile, the openness of wireless communication environments potentially leads to data leakage and system paralysis. However, conventional authentication schemes in the UAV network are system-centric, failing to adapt to the diversity of UAVs identities and access, resulting in changes in network environments and connection statuses. Additionally, UAVs are not subjected to periodic identity compliance checks once authenticated, leading to difficulties in controlling access anomalies. Therefore, in this work, we consider a zero-trust framework for UAV network authentication, aiming to achieve UAVs identity authentication through the principle of ``never trust and always verify''. We introduce a blockchain-assisted zero-trust authentication scheme, namely BAZAM, designed for multi-UAV wireless networks. In this scheme, UAVs follow a key generation approach using physical unclonable functions (PUFs), and cryptographic technique helps verify registration and access requests of UAVs. The blockchain is applied to store UAVs authentication information in immutable storage. Through thorough security analysis and extensive evaluation, we demonstrate the effectiveness and efficiency of the proposed BAZAM.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Field Knowledge as a Dual to Distributed Knowledge: A Characterization by Weighted Modal Logic</title>
<link>https://arxiv.org/abs/2407.00687</link>
<guid>https://arxiv.org/abs/2407.00687</guid>
<content:encoded><![CDATA[
<div> 关键词：group knowledge, distributed knowledge, field knowledge, epistemic logic, weighted models

总结:<br />本文探讨了群体知识概念，如相互知识、共同知识和分布式知识在认识逻辑中的应用。作者提出将认知能力纳入分布式知识的定义，并引入了场知识的概念，作为分布式知识的对立面。研究基于带有不同群体知识构造的识别模型（weighted models），发展了八种逻辑系统，并分析了它们的表达力。文章通过形式化的方法，提供了关于这些逻辑系统的完备的公理体系。 <div>
arXiv:2407.00687v1 Announce Type: new 
Abstract: The study of group knowledge concepts such as mutual, common, and distributed knowledge is well established within the discipline of epistemic logic. In this work, we incorporate epistemic abilities of agents to refine the formal definition of distributed knowledge and introduce a formal characterization of field knowledge. We propose that field knowledge serves as a dual to distributed knowledge. Our approach utilizes epistemic logics with various group knowledge constructs, interpreted through weighted models. We delve into the eight logics that stem from these considerations, explore their relative expressivity and develop sound and complete axiomatic systems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A posteriori error estimator for elliptic interface problems in the fictitious formulation</title>
<link>https://arxiv.org/abs/2407.00786</link>
<guid>https://arxiv.org/abs/2407.00786</guid>
<content:encoded><![CDATA[
<div> 关键词：a posteriori error estimator, elliptic interface problem, fictitious domain formulation, discontinuous Lagrange multiplier, adaptive algorithm.

总结:<br />
本文研究了一种针对椭圆界面问题的后验误差估计器，该问题采用虚域方法和分布拉格朗日乘子处理，且考虑了不连续拉格朗日乘子有限元素空间。理论部分探讨了常数系数和光滑系数跳跃情况下的误差估计，证明了其可靠性和效率。数值实验通过不同几何嵌入和大系数跳跃实例验证了理论结果，展示了适应性算法的有效性。计算结果显示，误差估计器在处理几何奇异性或系数跳跃时表现出最优收敛特性。 <div>
arXiv:2407.00786v1 Announce Type: new 
Abstract: A posteriori error estimator is derived for an elliptic interface problem in the fictitious domain formulation with distributed Lagrange multiplier considering a discontinuous Lagrange multiplier finite element space. A posteriori error estimation plays a pivotal role in assessing the accuracy and reliability of computational solutions across various domains of science and engineering. This study delves into the theoretical underpinnings and computational considerations of a residual-based estimator.
  Theoretically, the estimator is studied for cases with constant coefficients which jump across an interface as well as generalized scenarios with smooth coefficients that jump across an interface. Theoretical findings demonstrate the reliability and efficiency of the proposed estimators under all considered cases.
  Numerical experiments are conducted to validate the theoretical results, incorporating various immersed geometries and instances of high coefficients jumps at the interface. Leveraging an adaptive algorithm, the estimator identifies regions with singularities and applies refinement accordingly. Results substantiate the theoretical findings, highlighting the reliability and efficiency of the estimators. Furthermore, numerical solutions exhibit optimal convergence properties, demonstrating resilience against geometric singularities or coefficients jumps.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-Aware Spectrum Pricing and Power Control Optimization for LEO Satellite Internet-of-Things</title>
<link>https://arxiv.org/abs/2407.00814</link>
<guid>https://arxiv.org/abs/2407.00814</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)、satellite systems、IoT、federated learning (FL)、blockchain

总结:<br />该论文关注低地球轨道(LEO)卫星系统在物联网(IoT)中的应用，探讨了如何通过结合区块链技术和联邦学习(FL)来解决复杂谱资源管理问题。首先，提出了一种基于深度强化学习的本地算法，以优化卫星的定价和功率控制策略，以最大化收入。其次，构建了一个去中心化的FL系统，利用区块链技术实现数据隐私保护。通过声誉机制，确保模型聚合和区块生成的信任度。最后，实验结果显示，该方法既能有效提高LEO卫星系统的收益，又能保护用户隐私。总的来说，研究者提出了一个创新的框架，旨在提升LEO卫星IoT的运营效率和隐私保护。 <div>
arXiv:2407.00814v1 Announce Type: new 
Abstract: Low earth orbit (LEO) satellite systems play an important role in next generation communication networks due to their ability to provide extensive global coverage with guaranteed communications in remote areas and isolated areas where base stations cannot be cost-efficiently deployed. With the pervasive adoption of LEO satellite systems, especially in the LEO Internet-of-Things (IoT) scenarios, their spectrum resource management requirements have become more complex as a result of massive service requests and high bandwidth demand from terrestrial terminals. For instance, when leasing the spectrum to terrestrial users and controlling the uplink transmit power, satellites collect user data for machine learning purposes, which usually are sensitive information such as location, budget and quality of service (QoS) requirement. To facilitate model training in LEO IoT while preserving the privacy of data, blockchain-driven federated learning (FL) is widely used by leveraging on a fully decentralized architecture. In this paper, we propose a hybrid spectrum pricing and power control framework for LEO IoT by combining blockchain technology and FL. We first design a local deep reinforcement learning algorithm for LEO satellite systems to learn a revenue-maximizing pricing and power control scheme. Then the agents collaborate to form a FL system. We also propose a reputation-based blockchain which is used in the global model aggregation phase of FL. Based on the reputation mechanism, a node is selected for each global training round to perform model aggregation and block generation, which can further enhance the decentralization of the network and guarantee the trust. Simulation tests are conducted to evaluate the performances of the proposed scheme. Our results show the efficiency of finding the maximum revenue scheme for LEO satellite systems while preserving the privacy of each agent.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Privacy-First Crowdsourcing: Blockchain and Local Differential Privacy in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2407.00873</link>
<guid>https://arxiv.org/abs/2407.00873</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、无人机、数据集成、本地差分隐私、区块链。

总结:<br />
本文介绍了一种新的隐私保护框架，旨在将消费级无人机融入丛林火灾管理。该系统通过本地差分隐私技术确保数据提供者的隐私安全，利用区块链技术保证公平的数据交换和责任追踪。文章以原型实现验证了其在大规模数据收集场景中的可行性和扩展性。这一解决方案符合澳大利亚《1988年隐私法》等法规，为通过众包无人机服务提升丛林火灾检测与管理提供了实用途径。 <div>
arXiv:2407.00873v1 Announce Type: new 
Abstract: We introduce a privacy-preserving framework for integrating consumer-grade drones into bushfire management. This system creates a marketplace where bushfire management authorities obtain essential data from drone operators. Key features include local differential privacy to protect data providers and a blockchain-based solution ensuring fair data exchanges and accountability. The framework is validated through a proof-of-concept implementation, demonstrating its scalability and potential for various large-scale data collection scenarios. This approach addresses privacy concerns and compliance with regulations like Australia's Privacy Act 1988, offering a practical solution for enhancing bushfire detection and management through crowdsourced drone services.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Decentralized PKI Framework for Data Integrity in Spatial Crowdsourcing Drone Services</title>
<link>https://arxiv.org/abs/2407.00876</link>
<guid>https://arxiv.org/abs/2407.00876</guid>
<content:encoded><![CDATA[
<div> 关键词：Spatial Crowdsourcing, D2XChain, Blockchain-based PKI, Internet of Drone Things (IoDT), X.509 standard.

总结:<br />
本文主要关注的是无人机服务领域的网络安全，特别是针对空间众包无人机任务（如配送、监控和数据收集）中的通信安全。文章提出了D2XChain，一种基于区块链的公钥基础设施（PKI）框架，旨在解决传统PKI中集中式信任模型的单点故障问题。D2XChain通过去中心化CA（证书权威机构）实现了分布式操作，支持X.509标准，涵盖证书注册、验证、核查和撤销等关键操作。它增强了无人机通信的安全性和可靠性，尤其在私有以太坊测试环境中成功部署，为无人机服务，特别是关键任务下的可信运营提供了创新且实用的解决方案。 <div>
arXiv:2407.00876v1 Announce Type: new 
Abstract: In the domain of spatial crowdsourcing drone services, which includes tasks like delivery, surveillance, and data collection, secure communication is paramount. The Public Key Infrastructure (PKI) ensures this by providing a system for digital certificates that authenticate the identities of entities involved, securing data and command transmissions between drones and their operators. However, the centralized trust model of traditional PKI, dependent on Certificate Authorities (CAs), presents a vulnerability due to its single point of failure, risking security breaches. To counteract this, the paper presents D2XChain, a blockchain-based PKI framework designed for the Internet of Drone Things (IoDT). By decentralizing the CA infrastructure, D2XChain eliminates this single point of failure, thereby enhancing the security and reliability of drone communications. Fully compatible with the X.509 standard, it integrates seamlessly with existing PKI systems, supporting all key operations such as certificate registration, validation, verification, and revocation in a distributed manner. This innovative approach not only strengthens the defense of drone services against various security threats but also showcases its practical application through deployment on a private Ethereum testbed, representing a significant advancement in addressing the unique security challenges of drone-based services and ensuring their trustworthy operation in critical tasks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Ares II: Tracing the Flaws of a (Storage) God</title>
<link>https://arxiv.org/abs/2407.00881</link>
<guid>https://arxiv.org/abs/2407.00881</guid>
<content:encoded><![CDATA[
<div> 关键词：Ares, distributed shared memory, performance bottlenecks, optimizations, Ares II.

总结:<br />Ares是一个模块化的框架，旨在实现动态、可配置的分布式共享内存对象。最新版本通过版本化和数据条带技术支持大对象。研究者发现性能瓶颈并提出优化措施，包括piggyback机制、垃圾回收和批量重新配置，创建了优化版Ares II。该工作通过分布式追踪实验验证了Ares II的性能提升和存储效率改善，同时保持了正确性。 <div>
arXiv:2407.00881v1 Announce Type: new 
Abstract: Ares is a modular framework, designed to implement dynamic, reconfigurable, fault-tolerant, read/write and strongly consistent distributed shared memory objects. Recent enhancements of the framework have realized the efficient implementation of large objects, by introducing versioning and data striping techniques. In this work, we identify performance bottlenecks of the Ares's variants by utilizing distributed tracing, a popular technique for monitoring and profiling distributed systems. We then propose optimizations across all versions of Ares, aiming in overcoming the identified flaws, while preserving correctness. We refer to the optimized version of Ares as Ares II, which now features a piggyback mechanism, a garbage collection mechanism, and a batching reconfiguration technique for improving the performance and storage efficiency of the original Ares. We rigorously prove the correctness of Ares II, and we demonstrate the performance improvements by an experimental comparison (via distributed tracing) of the Ares II variants with their original counterparts.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SplitLoRA: A Split Parameter-Efficient Fine-Tuning Framework for Large Language Models</title>
<link>https://arxiv.org/abs/2407.00952</link>
<guid>https://arxiv.org/abs/2407.00952</guid>
<content:encoded><![CDATA[
<div> 关键词：large language models, federated learning, split learning, SplitLoRA, benchmark

总结:<br />该研究关注的是大型语言模型（LLMs）的联邦学习（FL）和分割学习（SL）应用。面对LLMs对大量数据和计算资源的需求，文章提出SplitLoRA，一个首开源的SL LLM fine-tuning框架。它结合了FL的并行训练优势和SL的模型分割，以降低计算和通信压力，提高效率。SplitLoRA作为SL LLM调优的基准，旨在推动相关研究。实验结果表明，SplitLoRA在达到相同准确度时所需时间远少于现有方法，显示出其出色的训练性能。项目页面链接为https://fduinc.github.io/splitlora/。 <div>
arXiv:2407.00952v1 Announce Type: new 
Abstract: The scalability of large language models (LLMs) in handling high-complexity models and large-scale datasets has led to tremendous successes in pivotal domains. While there is an urgent need to acquire more training data for LLMs, a concerning reality is the depletion of high-quality public datasets within a few years. In view of this, the federated learning (FL) LLM fine-tuning paradigm recently has been proposed to facilitate collaborative LLM fine-tuning on distributed private data, where multiple data owners collaboratively fine-tune a shared LLM without sharing raw data. However, the staggering model size of LLMs imposes heavy computing and communication burdens on clients, posing significant barriers to the democratization of the FL LLM fine-tuning paradigm. To address this issue, split learning (SL) has emerged as a promising solution by offloading the primary training workload to a server via model partitioning while exchanging activation/activation's gradients with smaller data sizes rather than the entire LLM. Unfortunately, research on the SL LLM fine-tuning paradigm is still in its nascent stage. To fill this gap, in this paper, we propose the first SL LLM fine-tuning framework, named SplitLoRA. SplitLoRA is built on the split federated learning (SFL) framework, amalgamating the advantages of parallel training from FL and model splitting from SL and thus greatly enhancing the training efficiency. It is worth noting that SplitLoRA is the inaugural open-source benchmark for SL LLM fine-tuning, providing a foundation for research efforts dedicated to advancing SL LLM fine-tuning. Extensive simulations validate that SplitLoRA achieves target accuracy in significantly less time than state-of-the-art LLM fine-tuning frameworks, demonstrating the superior training performance of SplitLoRA. The project page is available at https://fduinc.github.io/splitlora/.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Parallel Computing Architectures for Robotic Applications: A Comprehensive Review</title>
<link>https://arxiv.org/abs/2407.01011</link>
<guid>https://arxiv.org/abs/2407.01011</guid>
<content:encoded><![CDATA[
<div> 关键词：parallel computing, robotics, real-time processing, sensor integration, control algorithms

总结:
本文探讨了在现代机器人系统中，日益增长的复杂性和功能需求对计算性能提出了更高的要求。传统的串行计算已难以满足，因此并行计算，如多核CPU、GPU、FPGA和分布式系统，因其能同时处理多个任务而成为解决之道。这些架构在实时图像处理、传感器融合和路径规划等方面显著提升机器人系统的性能。文章通过实例分析展示了并行计算在机器人技术中的潜力，同时也指出了挑战，如硬件与软件协同、能耗问题等，并提出未来研究方向。并行计算为推动机器人技术进步提供了强大的工具。 <div>
arXiv:2407.01011v1 Announce Type: new 
Abstract: With the growing complexity and capability of contemporary robotic systems, the necessity of sophisticated computing solutions to efficiently handle tasks such as real-time processing, sensor integration, decision-making, and control algorithms is also increasing. Conventional serial computing frequently fails to meet these requirements, underscoring the necessity for high-performance computing alternatives. Parallel computing, the utilization of several processing elements simultaneously to solve computational problems, offers a possible answer. Various parallel computing designs, such as multi-core CPUs, GPUs, FPGAs, and distributed systems, provide substantial enhancements in processing capacity and efficiency. By utilizing these architectures, robotic systems can attain improved performance in functionalities such as real-time image processing, sensor fusion, and path planning. The transformative potential of parallel computing architectures in advancing robotic technology has been underscored, real-life case studies of these architectures in the robotics field have been discussed, and comparisons are presented. Challenges pertaining to these architectures have been explored, and possible solutions have been mentioned for further research and enhancement of the robotic applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>DistML.js: Installation-free Distributed Deep Learning Framework for Web Browsers</title>
<link>https://arxiv.org/abs/2407.01023</link>
<guid>https://arxiv.org/abs/2407.01023</guid>
<content:encoded><![CDATA[
<div> 关键词：DistML.js, web浏览器, 机器学习模型, 深度学习 API, WebGL

总结:<br />DistML.js是一个专为Web浏览器设计的机器学习库，支持本地训练和分布式学习。其API与PyTorch类似，便于原型开发，利用WebGL进行后台矩阵计算以实现高效运算。该库强调数据并行性，源代码开源。<br />DistML.js是用于浏览器的机器学习解决方案，易于使用，支持本地和服务器协作，通过WebGL加速计算，适合快速原型和实践深度学习项目。 <div>
arXiv:2407.01023v1 Announce Type: new 
Abstract: We present "DistML.js", a library designed for training and inference of machine learning models within web browsers. Not only does DistML.js facilitate model training on local devices, but it also supports distributed learning through communication with servers. Its design and define-by-run API for deep learning model construction resemble PyTorch, thereby reducing the learning curve for prototyping. Matrix computations involved in model training and inference are executed on the backend utilizing WebGL, enabling high-speed calculations. We provide a comprehensive explanation of DistML.js's design, API, and implementation, alongside practical applications including data parallelism in learning. The source code is publicly available at https://github.com/mil-tokyo/distmljs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Randomized linear solvers for computational architectures with straggling workers</title>
<link>https://arxiv.org/abs/2407.01098</link>
<guid>https://arxiv.org/abs/2407.01098</guid>
<content:encoded><![CDATA[
<div> 关键词：sparse system, iterative solution, partial matrix-vector product, random variable, convergence.

总结:<br />该论文探讨了在仅部分计算稀疏线性方程组系数矩阵的乘积时，迭代求解的问题。模型假设计算的元素数量及其行索引集是随机变量，且给定数量时行索引均匀分布。研究者提出了一种随机Richardson迭代法和Chebyshev半迭代法，并证明了它们在期望下的收敛条件。实验结果验证了理论和方法的有效性，尤其是在混合云架构的控制器-工作者分布式模型中，处理延迟（straggling workers）的情况。 <div>
arXiv:2407.01098v1 Announce Type: new 
Abstract: In this paper, we consider the iterative solution of sparse systems of linear algebraic equations under the condition that sparse matrix-vector products with the coefficient matrix are computed only partially. At the same time, non-computed entries are set to zeros. We assume that both the number of computed entries and their associated row index set are random variables, with the row index set sampled uniformly given the number of computed entries. This model of computations is prevalent to that realized in hybrid cloud computing architectures following the controller-worker distributed model under the influence of straggling workers. We propose a randomized Richardson iterative scheme and a randomized Chebyshev semi-iterative method within this model and prove the sufficient conditions for their convergence in expectation. Numerical experiments verify the presented theoretical results as well as the effectiveness of the proposed schemes on a few sparse matrix problems.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FedRC: A Rapid-Converged Hierarchical Federated Learning Framework in Street Scene Semantic Understanding</title>
<link>https://arxiv.org/abs/2407.01103</link>
<guid>https://arxiv.org/abs/2407.01103</guid>
<content:encoded><![CDATA[
<div> 关键词：Street Scene Semantic Understanding, Hierarchical Federated Learning, Convergence Rate, Data Heterogeneity, Gaussian Distributions.

总结:<br />
本文提出了一种新的联邦学习框架FedRC，针对城市间数据异质性问题，旨在加速街景语义理解（TriSU）任务的模型收敛。FedRC通过将单张RGB图像和RGB数据集建模为高斯分布，区分每个样本并考虑数据量和统计特性，而非仅凭数据量决策，从而提高了HFL在复杂任务中的性能。实验结果显示，FedRC比现有基准快38.7%、37.5%、35.5%和40.6%的mIoU、mPrecision、mRecall和mF1，且在CARLA模拟环境中表现出色，展示了顶级性能。 <div>
arXiv:2407.01103v1 Announce Type: new 
Abstract: Street Scene Semantic Understanding (denoted as TriSU) is a crucial but complex task for world-wide distributed autonomous driving (AD) vehicles (e.g., Tesla). Its inference model faces poor generalization issue due to inter-city domain-shift. Hierarchical Federated Learning (HFL) offers a potential solution for improving TriSU model generalization, but suffers from slow convergence rate because of vehicles' surrounding heterogeneity across cities. Going beyond existing HFL works that have deficient capabilities in complex tasks, we propose a rapid-converged heterogeneous HFL framework (FedRC) to address the inter-city data heterogeneity and accelerate HFL model convergence rate. In our proposed FedRC framework, both single RGB image and RGB dataset are modelled as Gaussian distributions in HFL aggregation weight design. This approach not only differentiates each RGB sample instead of typically equalizing them, but also considers both data volume and statistical properties rather than simply taking data quantity into consideration. Extensive experiments on the TriSU task using across-city datasets demonstrate that FedRC converges faster than the state-of-the-art benchmark by 38.7%, 37.5%, 35.5%, and 40.6% in terms of mIoU, mPrecision, mRecall, and mF1, respectively. Furthermore, qualitative evaluations in the CARLA simulation environment confirm that the proposed FedRC framework delivers top-tier performance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>SCIF: A Language for Compositional Smart Contract Security</title>
<link>https://arxiv.org/abs/2407.01204</link>
<guid>https://arxiv.org/abs/2407.01204</guid>
<content:encoded><![CDATA[
<div> 关键词：SCIF、智能合约、安全、信息流、Solidity。

总结:<br />
SCIF是一种用于构建安全智能合约的语言，特别强调在与不可信代码协作时的安全性。它基于安全信息流原理，扩展机制以防御重入攻击、混淆副官攻击和错误处理问题，即使面对不遵守规则的恶意合约也能保护系统。SCIF支持动态信任管理，允许复杂生态中部分信任的主体交互。该语言已实现为Solidity编译器，提供静态检查规则和运行时支持。通过实施多个具有深度安全考虑的应用，SCIF展示了其在构建复杂智能合约中的有效性和对潜在安全漏洞的精确诊断能力。 <div>
arXiv:2407.01204v1 Announce Type: new 
Abstract: Securing smart contracts remains a fundamental challenge. At its core, it is about building software that is secure in composition with untrusted code, a challenge that extends far beyond blockchains. We introduce SCIF, a language for building smart contracts that are compositionally secure. SCIF is based on the fundamentally compositional principle of secure information flow, but extends this core mechanism to include protection against reentrancy attacks, confused deputy attacks, and improper error handling, even in the presence of malicious contracts that do not follow SCIF's rules. SCIF supports a rich ecosystem of interacting principals with partial trust through its mechanisms for dynamic trust management. SCIF has been implemented as a compiler to Solidity. We describe the SCIF language, including its static checking rules and runtime. Finally, we implement several applications with intricate security reasoning, showing how SCIF supports building complex smart contracts securely and gives programmer accurate diagnostics about potential security bugs.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>On the Parameters of Codes for Data Access</title>
<link>https://arxiv.org/abs/2407.01229</link>
<guid>https://arxiv.org/abs/2407.01229</guid>
<content:encoded><![CDATA[
<div> 关键词：coded distributed storage systems, alphabet size, servers, service rate region, code constructions.

总结:<br />该论文关注编码分布式存储系统中的关键问题，研究了两个方面：<br />1) 在固定字母大小下，确定最小服务器数量以保证服务速率区域包含特定点；<br />2) 对于给定服务器数，找出最小字母大小以满足相同条件。论文提供了严格的上界和下界，以及基于编码理论、优化和项目几何的代码构造方法。<br />通过这些方法，作者深入探讨了系统性能与设计参数之间的关系。 <div>
arXiv:2407.01229v1 Announce Type: new 
Abstract: This paper studies two crucial problems in the context of coded distributed storage systems directly related to their performance: 1) for a fixed alphabet size, determine the minimum number of servers the system must have for its service rate region to contain a prescribed set of points; 2) for a given number of servers, determine the minimum alphabet size for which the service rate region of the system contains a prescribed set of points. The paper establishes rigorous upper and lower bounds, as well as code constructions based on techniques from coding theory, optimization, and projective geometry.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>An Operational Semantics for Yul</title>
<link>https://arxiv.org/abs/2407.01365</link>
<guid>https://arxiv.org/abs/2407.01365</guid>
<content:encoded><![CDATA[
<div> 关键词：Yul、Solidity、EVM bytecode、operational semantics、small-step semantics

总结:<br />
本文介绍了一种针对Yul（Solidity编译器产生的EVM字节码的中间语言）的大步和小步操作语义，采用与编程语言文献相符的数学表示法，便于语言证明并作为精确易理解的语言规范。作者对原有非正式规范进行了澄清，并证明了两种语义之间的等价性。此外，他们实现了一个小型步态解释器，支持优化并经过测试。这项工作有望推动在Yul上开发验证和符号执行技术，增强以太坊安全体系，并为未来的类型系统提供坚实的理论基础。 <div>
arXiv:2407.01365v1 Announce Type: new 
Abstract: We present a big-step and small-step operational semantics for Yul -- the intermediate language used by the Solidity compiler to produce EVM bytecode -- in a mathematical notation that is congruous with the literature of programming languages, lends itself to language proofs, and can serve as a precise, widely accessible specification for the language. Our two semantics stay faithful to the original, informal specification of the language but also clarify under-specified cases such as void function calls. Our presentation allows us to prove the equivalence between the two semantics. We also implement the small-step semantics in an interpreter for Yul which avails of optimisations that are provably correct. We have tested the interpreter using tests from the Solidity compiler and our own. We envisage that this work will enable the development of verification and symbolic execution technology directly in Yul, contributing to the Ethereum security ecosystem, as well as aid the development of a provably sound future type system.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Beyond Throughput and Compression Ratios: Towards High End-to-end Utility of Gradient Compression</title>
<link>https://arxiv.org/abs/2407.01378</link>
<guid>https://arxiv.org/abs/2407.01378</guid>
<content:encoded><![CDATA[
<div> 关键词：gradient compression, distributed machine learning, training systems, acceleration, accuracy.

总结:
本文主要关注大规模分布式机器学习训练系统中的瓶颈——梯度聚合。作者发现先前的梯度压缩方案存在计算开销大、与all-reduce不兼容以及评估指标不合适等问题。为解决这些问题，作者提出改进设计和评估技术，包括降低计算负担、适应all-reduce通信方式以及采用更合适的端到端评价标准（如16位基线）。初步结果显示，这些技巧提升了系统的性能，有助于更准确地评估梯度压缩方法的实际效益。 <div>
arXiv:2407.01378v1 Announce Type: new 
Abstract: Gradient aggregation has long been identified as a major bottleneck in today's large-scale distributed machine learning training systems. One promising solution to mitigate such bottlenecks is gradient compression, directly reducing communicated gradient data volume. However, in practice, many gradient compression schemes do not achieve acceleration of the training process while also preserving accuracy.
  In this work, we identify several common issues in previous gradient compression systems and evaluation methods. These issues include excessive computational overheads; incompatibility with all-reduce; and inappropriate evaluation metrics, such as not using an end-to-end metric or using a 32-bit baseline instead of a 16-bit baseline. We propose several general design and evaluation techniques to address these issues and provide guidelines for future work. Our preliminary evaluation shows that our techniques enhance the system's performance and provide a clearer understanding of the end-to-end utility of gradient compression methods.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Maximizing Blockchain Performance: Mitigating Conflicting Transactions through Parallelism and Dependency Management</title>
<link>https://arxiv.org/abs/2407.01426</link>
<guid>https://arxiv.org/abs/2407.01426</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchains, cryptocurrency, conflicting transactions, Hyperledger Fabric, transaction parallelism

总结: 本文主要关注区块链技术在加密货币领域的扩展应用，特别是解决"冲突交易"（conflicting transactions）问题。提出了一种新的区块链方案，结合了事务并行性和智能依赖管理器，旨在减少交易冲突，从而降低网络延迟、提高系统资源利用率和交易成功率。实验结果显示，该方案不仅有效解决了冲突交易问题，而且在与现有的Hyperledger Fabric网络比较中表现出色，实现了更高的交易吞吐量和更低的延迟。这一集成为改善现实世界中区块链网络的性能和稳定性提供了前景。<br /><br />总结: 关键词：区块链、冲突交易、Hyperledger Fabric、事务并行性、智能依赖管理。文章提出的新方案通过优化并行处理和依赖管理，显著提升了区块链网络的性能，特别是在交易成功率、吞吐量和延迟方面超越了现有系统，为实际应用中的区块链网络改进提供了解决方案。 <div>
arXiv:2407.01426v1 Announce Type: new 
Abstract: While blockchains initially gained popularity in the realm of cryptocurrencies, their widespread adoption is expanding beyond conventional applications, driven by the imperative need for enhanced data security. Despite providing a secure network, blockchains come with certain tradeoffs, including high latency, lower throughput, and an increased number of transaction failures. A pivotal issue contributing to these challenges is the improper management of "conflicting transactions", commonly referred to as "contention". When a number of pending transactions within a blockchain collide with each other, this results in a state of contention. This situation worsens network latency, leads to the wastage of system resources, and ultimately contributes to reduced throughput and higher transaction failures. In response to this issue, in this work, we present a novel blockchain scheme that integrates transaction parallelism and an intelligent dependency manager aiming to reduce the occurrence of conflicting transactions within blockchain networks. In terms of effectiveness and efficiency, experimental results show that our scheme not only mitigates the challenges posed by conflicting transactions, but also outperforms both existing parallel and non-parallel Hyperledger Fabric blockchain networks achieving higher transaction success rate, throughput, and latency. The integration of our scheme with Hyperledger Fabric appears to be a promising solution for improving the overall performance and stability of blockchain networks in real-world applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Reinforcement Learning-driven Data-intensive Workflow Scheduling for Volunteer Edge-Cloud</title>
<link>https://arxiv.org/abs/2407.01428</link>
<guid>https://arxiv.org/abs/2407.01428</guid>
<content:encoded><![CDATA[
<div> 关键词：Volunteer Edge-Cloud (VEC), Reinforcement Learning (RL), Data-intensive scientific workflows, Workflow scheduling, Resource allocation.

总结:<br />本文提出了一种基于强化学习（RL）的策略，旨在解决志愿边缘云（VEC）中数据密集型科学工作流任务调度的挑战。该方法考虑了工作流需求、VEC资源对工作流的偏好以及多样的VEC资源策略，通过将长期性能优化问题建模为马尔可夫决策过程，采用事件驱动的异步优势Actor-Critic RL算法求解。实验结果表明，相比于传统方法，该RL驱动的调度方案在满足工作流需求、优化VEC资源使用和满意度方面表现出色。 <div>
arXiv:2407.01428v1 Announce Type: new 
Abstract: In recent times, Volunteer Edge-Cloud (VEC) has gained traction as a cost-effective, community computing paradigm to support data-intensive scientific workflows. However, due to the highly distributed and heterogeneous nature of VEC resources, centralized workflow task scheduling remains a challenge. In this paper, we propose a Reinforcement Learning (RL)-driven data-intensive scientific workflow scheduling approach that takes into consideration: i) workflow requirements, ii) VEC resources' preference on workflows, and iii) diverse VEC resource policies, to ensure robust resource allocation. We formulate the long-term average performance optimization problem as a Markov Decision Process, which is solved using an event-based Asynchronous Advantage Actor-Critic RL approach. Our extensive simulations and testbed implementations demonstrate our approach's benefits over popular baseline strategies in terms of workflow requirement satisfaction, VEC preference satisfaction, and available VEC resource utilization.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources</title>
<link>https://arxiv.org/abs/2407.01445</link>
<guid>https://arxiv.org/abs/2407.01445</guid>
<content:encoded><![CDATA[
<div> 关键词：Contrastive Language-Image Pretraining (CLIP), Large-scale data, Resource limitation, FastCLIP, Optimization techniques.

总结:<br />该研究关注在资源受限情况下（如少于数百GPU）训练最先进的CLIP模型。FastCLIP是一个专为分布式设置设计和优化的框架，采用高效梯度降低策略减少通信开销。研究还探讨了内学习率调度、温度参数和模型参数更新规则对效率的影响。实验表明，FastCLIP在不同规模（32 GPU和3种数据集大小）上显著优于OpenCLIP基准，特别在资源有限的情况下。研究成果已开源。<br /> <div>
arXiv:2407.01445v1 Announce Type: new 
Abstract: Existing studies of training state-of-the-art Contrastive Language-Image Pretraining (CLIP) models on large-scale data involve hundreds of or even thousands of GPUs due to the requirement of a large batch size. However, such a large amount of resources is not accessible to most people. While advanced compositional optimization techniques for optimizing global contrastive losses have been demonstrated effective for removing the requirement of large batch size, their performance on large-scale data remains underexplored and not optimized. To bridge the gap, this paper explores several aspects of CLIP training with limited resources (e.g., up to tens of GPUs). First, we introduce FastCLIP, a general CLIP training framework built on advanced compositional optimization techniques while designed and optimized for the distributed setting. Our framework is equipped with an efficient gradient reduction strategy to reduce communication overhead. Second, to further boost training efficiency, we investigate three components of the framework from an optimization perspective: the schedule of the inner learning rate, the update rules of the temperature parameter and the model parameters, respectively. Experiments on different strategies for each component shed light on how to conduct CLIP training more efficiently. Finally, we benchmark the performance of FastCLIP and the state-of-the-art training baseline (OpenCLIP) on different compute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7 million, 9.1 million to 315 million image-text pairs to demonstrate the significant improvement of FastCLIP in the resource-limited setting. We release the code of FastCLIP at https://github.com/Optimization-AI/fast_clip .
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>How Clustering Affects the Convergence of Decentralized Optimization over Networks: A Monte-Carlo-based Approach</title>
<link>https://arxiv.org/abs/2407.01460</link>
<guid>https://arxiv.org/abs/2407.01460</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized algorithms, Convergence rate, Network topology, Clustering coefficient, Scale-free networks.

总结:
本文主要探讨了分布式优化算法在随机尺度自由网络（Scale-free, SF）和簇尺度自由网络（Clustered Scale-free, CSF）中的收敛速度，通过调整网络的聚类系数。研究发现，当其他网络属性如幂律度分布、链接数量和平均度保持不变时，低聚类系数的网络往往具有更快的收敛率。这一发现对于改进现有分布式机器学习系统的学习速率具有重要意义，因为可以通过调整网络结构来提升性能。作者还通过实际网络案例分析，进一步验证了这一结论。 <div>
arXiv:2407.01460v1 Announce Type: new 
Abstract: Decentralized algorithms have gained substantial interest owing to advancements in cloud computing, Internet of Things (IoT), intelligent transportation networks, and parallel processing over sensor networks. The convergence of such algorithms is directly related to specific properties of the underlying network topology. Specifically, the clustering coefficient is known to affect, for example, the controllability/observability and the epidemic growth over networks. In this work, we study the effects of the clustering coefficient on the convergence rate of networked optimization approaches. In this regard, we model the structure of large-scale distributed systems by random scale-free (SF) and clustered scale-free (CSF) networks and compare the convergence rate by tuning the network clustering coefficient. This is done by keeping other relevant network properties (such as power-law degree distribution, number of links, and average degree) unchanged. Monte-Carlo-based simulations are used to compare the convergence rate over many trials of SF graph topologies. Furthermore, to study the convergence rate over real case studies, we compare the clustering coefficient of some real-world networks with the eigenspectrum of the underlying network (as a measure of convergence rate). The results interestingly show higher convergence rate over low-clustered networks. This is significant as one can improve the learning rate of many existing decentralized machine-learning scenarios by tuning the network clustering.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Immutable in Principle, Upgradeable by Design: Exploratory Study of Smart Contract Upgradeability</title>
<link>https://arxiv.org/abs/2407.01493</link>
<guid>https://arxiv.org/abs/2407.01493</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, upgradeable, Ethereum blockchain, upgrade mechanisms, user engagement.

总结:<br />
升级可编程合约（upgradeable smart contracts）是Ethereum区块链上的一种创新，旨在解决固有不可变性与后期维护需求之间的矛盾。本文研究通过创建一个详细记录智能合约版本和演化路径的数据库，关注五个关键点：升级机制的使用频率、升级行为的发生率、升级后的修改性质、对用户参与的影响以及合同活动的变化。结果发现，只有约3%的智能合约具备升级功能，其中只有0.34%实际进行了升级，表明开发者对于改动持谨慎态度，可能源于升级过程的复杂性和维护稳定性偏好。升级主要集中在功能增强和漏洞修复，尤其是当源代码公开时。然而，升级与用户活跃度的关系复杂，暗示着影响智能合约使用的因素远不止其进化历程。 <div>
arXiv:2407.01493v1 Announce Type: new 
Abstract: Smart contracts, known for their immutable nature to ensure trust via automated enforcement, have evolved to require upgradeability due to unforeseen vulnerabilities and the need for feature enhancements post-deployment. This contradiction between immutability and the need for modifications has led to the development of upgradeable smart contracts. These contracts are immutable in principle yet upgradable by design, allowing updates without altering the underlying data or state, thus preserving the contract's intent while allowing improvements. This study aims to understand the application and implications of upgradeable smart contracts on the Ethereum blockchain. By introducing a dataset that catalogs the versions and evolutionary trajectories of smart contracts, the research explores key dimensions: the prevalence and adoption patterns of upgrade mechanisms, the likelihood and occurrences of contract upgrades, the nature of modifications post-upgrade, and their impact on user engagement and contract activity. Through empirical analysis, this study identifies upgradeable contracts and examines their upgrade history to uncover trends, preferences, and challenges associated with modifications. The evidence from analyzing over 44 million contracts shows that only 3% have upgradeable characteristics, with only 0.34% undergoing upgrades. This finding underscores a cautious approach by developers towards modifications, possibly due to the complexity of upgrade processes or a preference for maintaining stability. Furthermore, the study shows that upgrades are mainly aimed at feature enhancement and vulnerability mitigation, particularly when the contracts' source codes are accessible. However, the relationship between upgrades and user activity is complex, suggesting that additional factors significantly affect the use of smart contracts beyond their evolution.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>The Inverted 3-Sum Box: General Formulation and Quantum Information Theoretic Optimality</title>
<link>https://arxiv.org/abs/2407.01498</link>
<guid>https://arxiv.org/abs/2407.01498</guid>
<content:encoded><![CDATA[
<div> 关键词：$N$-sum box, quantum multiple access channel (QMAC), communication cost, quantum coding schemes, information theory.

总结:<br />
该论文探讨了在量子多路访问信道（QMAC）上计算$\mathbb{F}_d$线性函数的最优通信成本问题。研究焦点在于给定任意转移矩阵$V_k$时，确定所有可能的量子编码方案中，传输所需最小的量子比特数$\Delta_1, \Delta_2, \Delta_3$。对于三个发送者（$K=3$）的情况，作者给出了完整的结果，表明基于$N$-sum box协议的编码在所有情况下都达到信息论最优。文章还提供了特定参数下（如矩阵秩$r_1, r_2, r_3$）的最小总下载成本公式。对于$K\geq 4$的发送者情况，问题仍未解决。 <div>
arXiv:2407.01498v1 Announce Type: new 
Abstract: The $N$-sum box protocol specifies a class of $\mathbb{F}_d$ linear functions $f(W_1,\cdots,W_K)=V_1W_1+V_2W_2+\cdots+V_KW_K\in\mathbb{F}_d^{m\times 1}$ that can be computed at information theoretically optimal communication cost (minimum number of qudits $\Delta_1,\cdots,\Delta_K$ sent by the transmitters Alice$_1$, Alice$_2$,$\cdots$, Alice$_K$, respectively, to the receiver, Bob, per computation instance) over a noise-free quantum multiple access channel (QMAC), when the input data streams $W_k\in\mathbb{F}_d^{m_k\times 1}, k\in[K]$, originate at the distributed transmitters, who share quantum entanglement in advance but are not otherwise allowed to communicate with each other. In prior work this set of optimally computable functions is identified in terms of a strong self-orthogonality (SSO) condition on the transfer function of the $N$-sum box. In this work we consider an `inverted' scenario, where instead of a feasible $N$-sum box transfer function, we are given an arbitrary $\mathbb{F}_d$ linear function, i.e., arbitrary matrices $V_k\in\mathbb{F}_d^{m\times m_k}$ are specified, and the goal is to characterize the set of all feasible communication cost tuples $(\Delta_1,\cdots,\Delta_K)$, not just based on $N$-sum box protocols, but across all possible quantum coding schemes. As our main result, we fully solve this problem for $K=3$ transmitters ($K\geq 4$ settings remain open). Coding schemes based on the $N$-sum box protocol (along with elementary ideas such as treating qudits as classical dits, time-sharing and batch-processing) are shown to be information theoretically optimal in all cases. As an example, in the symmetric case where rk$(V_1)$=rk$(V_2)$=rk$(V_3) \triangleq r_1$, rk$([V_1, V_2])$=rk$([V_2, V_3])$=rk$([V_3, V_1])\triangleq r_2$, and rk$([V_1, V_2, V_3])\triangleq r_3$ (rk = rank), the minimum total-download cost is $\max \{1.5r_1 + 0.75(r_3 - r_2), r_3\}$.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Linear and Nonlinear MMSE Estimation in One-Bit Quantized Systems under a Gaussian Mixture Prior</title>
<link>https://arxiv.org/abs/2407.01305</link>
<guid>https://arxiv.org/abs/2407.01305</guid>
<content:encoded><![CDATA[
<div> 关键词：mean square error (MSE), conditional mean estimator (CME), one-bit quantization, Gaussian mixture model (GMM), additive white Gaussian noise (AWGN).

总结:<br />该论文研究了一比特量化系统中，对于由高斯混合模型（GMM）分布的信号和加性白高斯噪声（AWGN）干扰的信号，MSE-最优条件均值估计器（CME）的新理论。首先，论文提供了Busgang估计器的闭式解析表达式，这是量化系统中的线性最小均方误差（MMSE）估计算法。接着，文中揭示了CME在特殊情况下的线性性质，与高分辨率情况相反。论文还比较了Gaussian案例，发现信号与量化噪声存在相关性。此外，研究扩展到多观测场景，探讨了MSE-最优发送序列，并进行了大样本分析，给出了MSE及其极限的解析表达。这些结果对信号处理应用的分析和设计具有广泛影响。 <div>
arXiv:2407.01305v1 Announce Type: cross 
Abstract: We present new fundamental results for the mean square error (MSE)-optimal conditional mean estimator (CME) in one-bit quantized systems for a Gaussian mixture model (GMM) distributed signal of interest, possibly corrupted by additive white Gaussian noise (AWGN). We first derive novel closed-form analytic expressions for the Bussgang estimator, the well-known linear minimum mean square error (MMSE) estimator in quantized systems. Afterward, closed-form analytic expressions for the CME in special cases are presented, revealing that the optimal estimator is linear in the one-bit quantized observation, opposite to higher resolution cases. Through a comparison to the recently studied Gaussian case, we establish a novel MSE inequality and show that that the signal of interest is correlated with the auxiliary quantization noise. We extend our analysis to multiple observation scenarios, examining the MSE-optimal transmit sequence and conducting an asymptotic analysis, yielding analytic expressions for the MSE and its limit. These contributions have broad impact for the analysis and design of various signal processing applications.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Neural Distributed Source Coding</title>
<link>https://arxiv.org/abs/2106.02797</link>
<guid>https://arxiv.org/abs/2106.02797</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed source coding, Slepian-Wolf, Vector-Quantized Variational Autoencoder (VQ-VAE), Lossy compression, High dimensions.

总结:<br />本文介绍了一种新颖的分布式源编码（DSC）框架，它能够处理复杂的数据集和各种相关性结构，突破了传统方法的限制。该方法利用条件Vector-Quantized Variational Autoencoder (VQ-VAE)，即条件VQ-VAE，作为学习型编码器和解码器，实现了无须依赖特定源模型的高效编码。实验结果显示，这种神经网络驱动的DSC方法在处理高维数据时表现出色，能够在保持高质量（PSNR）的同时，适应各类复杂的关联。代码已在GitHub上开源，为实际应用中的分布式压缩提供了新的可能。 <div>
arXiv:2106.02797v4 Announce Type: replace 
Abstract: Distributed source coding (DSC) is the task of encoding an input in the absence of correlated side information that is only available to the decoder. Remarkably, Slepian and Wolf showed in 1973 that an encoder without access to the side information can asymptotically achieve the same compression rate as when the side information is available to it. While there is vast prior work on this topic, practical DSC has been limited to synthetic datasets and specific correlation structures. Here we present a framework for lossy DSC that is agnostic to the correlation structure and can scale to high dimensions. Rather than relying on hand-crafted source modeling, our method utilizes a conditional Vector-Quantized Variational Autoencoder (VQ-VAE) to learn the distributed encoder and decoder. We evaluate our method on multiple datasets and show that our method can handle complex correlations and achieves state-of-the-art PSNR. Our code is made available at https://github.com/acnagle/neural-dsc.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Directional Antenna Based Scheduling Protocol for IoT Networks</title>
<link>https://arxiv.org/abs/2305.02511</link>
<guid>https://arxiv.org/abs/2305.02511</guid>
<content:encoded><![CDATA[
<div> 关键词：IoT网络，MAC层，Scheduling协议，Directional Scheduling，6TiSCH-IoT。

总结:<br />
本文主要关注物联网(IoT)网络中的一 hop 调度和频道访问。现有的基于全方位天线的应用数据传输在性能上不如采用方向性天线的调度协议。为此，研究者提出了一种分布式一跳调度算法，称为Directional Scheduling协议，特别适用于受限的确定性6TiSCH-IoT网络。该算法通过定向传输实现了更高的空间重用，允许更多的物联网节点并发数据传输，减少了头阻塞现象。结果表明，这种策略能够显著提升6TiSCH-IoT网络的吞吐量和效率。 <div>
arXiv:2305.02511v2 Announce Type: replace 
Abstract: Scheduling and Channel Access at the MAC layer of the IoT network plays a pivotal role in enhancing the performance of IoT networks. State-of-the-art Omni-directional antenna based application data transmission has relatively less achievable throughput in comparison with directional antenna based scheduling protocols. To enhance the performance of the IoT networks, this paper propose a distributed one-hop scheduling algorithm called Directional Scheduling protocol for constrained deterministic 6TiSCH-IoT network. With this, in-creased number of IoT nodes can have concurrent application data transmission with efficient spatial reuse. This in-turn results in higher number of cell allocation to the one-hop IoT nodes during data transmission. The proposed algorithm makes use of through directional transmissions avoids head of line blocking.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration</title>
<link>https://arxiv.org/abs/2305.19476</link>
<guid>https://arxiv.org/abs/2305.19476</guid>
<content:encoded><![CDATA[
<div> 关键词：state entropy, reinforcement learning, value-conditional state entropy, exploration, high-value states.

总结:<br />本文介绍了一种新的强化学习探索策略，针对传统方法在有任务奖励的监督环境中遇到的问题。该策略关注价值条件下的状态熵（value-conditional state entropy），即分别估计每个状态的价值估计后计算的熵，以平均值为目标进行最大化。这种方法避免了低价值和高价值状态分布之间的不平衡，防止了低价值区域的探索偏向于高价值区域。实验结果表明，相比于单纯的 state entropy 基线，该策略在 MiniGrid、DeepMind Control Suite 和 Meta-World 等多个任务中显著加速了学习过程。源代码可在此处获取：[链接]。 <div>
arXiv:2305.19476v2 Announce Type: replace 
Abstract: A promising technique for exploration is to maximize the entropy of visited state distribution, i.e., state entropy, by encouraging uniform coverage of visited state space. While it has been effective for an unsupervised setup, it tends to struggle in a supervised setup with a task reward, where an agent prefers to visit high-value states to exploit the task reward. Such a preference can cause an imbalance between the distributions of high-value states and low-value states, which biases exploration towards low-value state regions as a result of the state entropy increasing when the distribution becomes more uniform. This issue is exacerbated when high-value states are narrowly distributed within the state space, making it difficult for the agent to complete the tasks. In this paper, we present a novel exploration technique that maximizes the value-conditional state entropy, which separately estimates the state entropies that are conditioned on the value estimates of each state, then maximizes their average. By only considering the visited states with similar value estimates for computing the intrinsic bonus, our method prevents the distribution of low-value states from affecting exploration around high-value states, and vice versa. We demonstrate that the proposed alternative to the state entropy baseline significantly accelerates various reinforcement learning algorithms across a variety of tasks within MiniGrid, DeepMind Control Suite, and Meta-World benchmarks. Source code is available at https://sites.google.com/view/rl-vcse.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Pilot Assignment for Distributed Massive-MIMO Networks</title>
<link>https://arxiv.org/abs/2309.15709</link>
<guid>https://arxiv.org/abs/2309.15709</guid>
<content:encoded><![CDATA[
<div> 关键词：pilot contamination, distributed massive MIMO, pilot assignment scheme, signaling overhead, fault-tolerance.

总结:<br />
本文主要关注大规模多输入多输出（massive MIMO）网络中的飞行员污染问题。提出了一种创新的分布式飞行员分配方案，旨在有效缓解该问题，同时减少信号开销并提高系统的容错性。通过大量数值模拟，研究结果显示，新方案在降低飞行员污染和提升网络吞吐量方面优于现有的中心化和分布式策略。总的来说，这项工作提供了一个有效的解决方案，优化了多用户环境下的通信性能。 <div>
arXiv:2309.15709v3 Announce Type: replace 
Abstract: Pilot contamination is a critical issue in distributed massive MIMO networks, where the reuse of pilot sequences due to limited availability of orthogonal pilots for channel estimation leads to performance degradation. In this work, we propose a novel distributed pilot assignment scheme to effectively mitigate the impact of pilot contamination. Our proposed scheme not only reduces signaling overhead, but it also enhances fault-tolerance. Extensive numerical simulations are conducted to evaluate the performance of the proposed scheme. Our results establish that the proposed scheme outperforms existing centralized and distributed schemes in terms of mitigating pilot contamination and significantly enhancing network throughput.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>CO-ASnet :A Smart Contract Architecture Design based on Blockchain Technology with Active Sensor Networks</title>
<link>https://arxiv.org/abs/2310.05070</link>
<guid>https://arxiv.org/abs/2310.05070</guid>
<content:encoded><![CDATA[
<div> 关键词：opinion leaders, blockchain, ICOs, influence, regulatory scheme

总结:<br />
这篇文章关注意见领袖在区块链金融中的影响力，特别是通过ICO进行资产影响的案例分析。研究发现，意见领袖能够利用社交媒体和社交网络中的金钱与流量影响代币资产价格，实现超额回报并降低资产实现成本。基于此现象，文章提出采用ChainLink Oracle与Active Sensor Networks（CO-ASnet）设计的去中心化监管方案，为token发行提供风险评估和预警措施。这一研究对区块链金融产品发展和治理具有参考价值，提示监管者和企业应探索其边界。 <div>
arXiv:2310.05070v2 Announce Type: replace 
Abstract: The influence of opinion leaders impacts different aspects of social finance. How to analyse the utility of opinion leaders' influence in realizing assets on the blockchain and adopt a compliant regulatory scheme is worth exploring and pondering. Taking Musk's call on social media to buy Dogecoin as an example, this paper uses an event study to empirically investigate the phenomenon in which opinion leaders use ICOs (initial coin offerings) to exert influence. The results show that opinion leaders can use ICOs to influence the price of token assets with money and data traffic in their social network. They can obtain excess returns and reduce the cost of realization so that the closed loop of influence realization will be accelerated. Based on this phenomenon and the results of its impact, we use the ChainLink Oracle with Active Sensor Networks(CO-ASnet) to design a safe and applicable decentralized regulatory scheme that can constructively provide risk assessment strategies and early warning measures for token issuance. The influence realization of opinion leaders in blockchain issuance is bound to receive widespread attention, and this paper will provide an exemplary reference for regulators and enterprises to explore the boundaries of blockchain financial product development and governance.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance</title>
<link>https://arxiv.org/abs/2310.11373</link>
<guid>https://arxiv.org/abs/2310.11373</guid>
<content:encoded><![CDATA[
<div> 关键词：Reticulum, sharding, blockchain, scalability, adversarial attacks.

总结:<br />Reticulum是一种创新的区块链分片协议，旨在提高交易吞吐量并抵御各种网络攻击。它采用两阶段架构，包括控制和处理分片。处理分片至少包含一个可信节点，而控制分片由多数可信节点组成。首先，交易在处理分片中进行投票，共识通过后确认。若未达成一致，控制分片介入，决定并解决争议。实验表明，Reticulum在高吞吐量和抗攻击性方面超越现有协议，为区块链网络提供强大且安全的扩展能力。 <div>
arXiv:2310.11373v4 Announce Type: replace 
Abstract: Sharding is essential for improving blockchain scalability. Existing protocols overlook diverse adversarial attacks, limiting transaction throughput. This paper presents Reticulum, a groundbreaking sharding protocol addressing this issue, boosting blockchain scalability.
  Reticulum employs a two-phase approach, adapting transaction throughput based on runtime adversarial attacks. It comprises "control" and "process" shards in two layers. Process shards contain at least one trustworthy node, while control shards have a majority of trusted nodes. In the first phase, transactions are written to blocks and voted on by nodes in process shards. Unanimously accepted blocks are confirmed. In the second phase, blocks without unanimous acceptance are voted on by control shards. Blocks are accepted if the majority votes in favor, eliminating first-phase opponents and silent voters. Reticulum uses unanimous voting in the first phase, involving fewer nodes, enabling more parallel process shards. Control shards finalize decisions and resolve disputes.
  Experiments confirm Reticulum's innovative design, providing high transaction throughput and robustness against various network attacks, outperforming existing sharding protocols for blockchain networks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>History Trees and Their Applications</title>
<link>https://arxiv.org/abs/2404.02673</link>
<guid>https://arxiv.org/abs/2404.02673</guid>
<content:encoded><![CDATA[
<div> 关键词：history trees, distributed communication networks, anonymous agents, dynamic networks, open problems

总结:<br />这篇论文介绍了历史树在分布式通信网络研究中的重要性。历史树作为一种结构，有助于理解匿名节点在接收到不同邻居信息后如何变得可区分。它在分析既匿名又动态变化的网络中，为设计最优确定算法提供了框架。文章还回顾了历史树的最新应用进展，并拓展了理论边界，提出了几个待解决的问题。通过比较传统结构和历史树，作者为读者提供了一个易于理解的历史树入门指南。 <div>
arXiv:2404.02673v3 Announce Type: replace 
Abstract: In the theoretical study of distributed communication networks, "history trees" are a discrete structure that naturally models the concept that anonymous agents become distinguishable upon receiving different sets of messages from neighboring agents. By conveniently organizing temporal information in a systematic manner, history trees have been instrumental in the development of optimal deterministic algorithms for networks that are both anonymous and dynamically evolving.
  This note provides an accessible introduction to history trees, drawing comparisons with more traditional structures found in existing literature and reviewing the latest advancements in the applications of history trees, especially within dynamic networks. Furthermore, it expands the theoretical framework of history trees in new directions, also highlighting several open problems for further investigation.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches</title>
<link>https://arxiv.org/abs/2404.02817</link>
<guid>https://arxiv.org/abs/2404.02817</guid>
<content:encoded><![CDATA[
<div> 关键词：Task and Motion Planning (TAMP), Optimization-based TAMP, Hybrid optimization, Locomotion, Manipulation.

总结:
本文是一篇关于优化型任务和运动规划（Optimization-based Task and Motion Planning，简称TAMP）的全面综述。TAMP旨在整合高阶任务规划与低阶运动规划，使机器人具备处理复杂、动态任务的能力，尤其适合解决涉及物理交互的高难度行走和操纵问题。文章重点讨论了TAMP的三个方面：(1) 规模表示，如动作描述语言和时序逻辑；(2) 解决策略，包括人工智能规划和轨迹优化；(3) 逻辑任务规划与模型基运动优化之间的动态互动。作者强调了高效的算法结构，如分级和分布式方法，并探讨了传统方法与基于学习的技术（如大型语言模型）的融合。最后，文章展望了TAMP的未来研究方向，包括算法改进和应用挑战。 <div>
arXiv:2404.02817v4 Announce Type: replace 
Abstract: Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO. A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches. Additionally, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations such as large language models. Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Static Application Security Testing (SAST) Tools for Smart Contracts: How Far Are We?</title>
<link>https://arxiv.org/abs/2404.18186</link>
<guid>https://arxiv.org/abs/2404.18186</guid>
<content:encoded><![CDATA[
<div> 关键词：smart contracts, static application security testing (SAST), vulnerability types, benchmark, evaluation.

总结:<br />
本文关注智能合约的安全性，随着攻击事件增多，静态应用安全测试(SAST)工具发展迅速。研究者提出了一种最新的、精细划分的45种漏洞类型分类，构建了一个涵盖40种类型的广泛基准，包括不同代码特性和应用场景。对8款SAST工具进行评估，结果显示这些工具漏检了约50%的基准漏洞，误报率高，精确度不足10%。结合工具可以降低漏检率，但会增加更多误报。许多非访问控制和重入性漏洞未被检测到。该研究为工具开发、改进、评估和选择提供了指导。 <div>
arXiv:2404.18186v3 Announce Type: replace 
Abstract: In recent years, the importance of smart contract security has been heightened by the increasing number of attacks against them. To address this issue, a multitude of static application security testing (SAST) tools have been proposed for detecting vulnerabilities in smart contracts. However, objectively comparing these tools to determine their effectiveness remains challenging. Existing studies often fall short due to the taxonomies and benchmarks only covering a coarse and potentially outdated set of vulnerability types, which leads to evaluations that are not entirely comprehensive and may display bias.
  In this paper, we fill this gap by proposing an up-to-date and fine-grained taxonomy that includes 45 unique vulnerability types for smart contracts. Taking it as a baseline, we develop an extensive benchmark that covers 40 distinct types and includes a diverse range of code characteristics, vulnerability patterns, and application scenarios. Based on them, we evaluated 8 SAST tools using this benchmark, which comprises 788 smart contract files and 10,394 vulnerabilities. Our results reveal that the existing SAST tools fail to detect around 50% of vulnerabilities in our benchmark and suffer from high false positives, with precision not surpassing 10%. We also discover that by combining the results of multiple tools, the false negative rate can be reduced effectively, at the expense of flagging 36.77 percentage points more functions. Nevertheless, many vulnerabilities, especially those beyond Access Control and Reentrancy vulnerabilities, remain undetected. We finally highlight the valuable insights from our study, hoping to provide guidance on tool development, enhancement, evaluation, and selection for developers, researchers, and practitioners.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>AB-Training: A Communication-Efficient Approach for Distributed Low-Rank Learning</title>
<link>https://arxiv.org/abs/2405.01067</link>
<guid>https://arxiv.org/abs/2405.01067</guid>
<content:encoded><![CDATA[
<div> 关键词：AB-training, communication bottlenecks, distributed neural network training, low-rank representations, independent training groups

总结: AB-training是一种新型的分布式神经网络训练方法，旨在解决通信瓶颈问题。它利用低秩表示和独立训练组显著减少通信开销，平均降低网络流量约70.31%。这种方法不仅加速大规模系统中的收敛，还在小规模下显示正则化效果，提高泛化能力同时保持或缩短训练时间。实验中，AB-training在VGG16和ResNet-50模型上表现出色，分别实现了44.14:1的压缩比和1.55%的性能提升。然而，文章指出大型批量效应在低秩设置中仍然存在，提示对大规模分布式训练优化更新机制的研究仍有待深入。 <div>
arXiv:2405.01067v2 Announce Type: replace 
Abstract: Communication bottlenecks severely hinder the scalability of distributed neural network training, particularly in high-performance computing (HPC) environments. We introduce AB-training, a novel data-parallel method that leverages low-rank representations and independent training groups to significantly reduce communication overhead. Our experiments demonstrate an average reduction in network traffic of approximately 70.31\% across various scaling scenarios, increasing the training potential of communication-constrained systems and accelerating convergence at scale. AB-training also exhibits a pronounced regularization effect at smaller scales, leading to improved generalization while maintaining or even reducing training time. We achieve a remarkable 44.14 : 1 compression ratio on VGG16 trained on CIFAR-10 with minimal accuracy loss, and outperform traditional data parallel training by 1.55\% on ResNet-50 trained on ImageNet-2012. While AB-training is promising, our findings also reveal that large batch effects persist even in low-rank regimes, underscoring the need for further research into optimized update mechanisms for massively distributed training.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Facilitating Feature and Topology Lightweighting: An Ethereum Transaction Graph Compression Method for Malicious Account Detection</title>
<link>https://arxiv.org/abs/2405.08278</link>
<guid>https://arxiv.org/abs/2405.08278</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、malicious accounts、transaction graph、feature engineering、TGC4Eth。

总结:<br />Ethereum作为全球主要的加密货币平台，其交易图谱庞大，恶意账户活动频繁。本文提出TGC4Eth方法，旨在通过特征选择和图结构压缩提升恶意账户检测的效率与鲁棒性。首先，TGC4Eth筛选交易特征，降低对重要性较低特征的依赖，对抗特征逃逸攻击；其次，通过聚焦和粗化过程压缩图谱结构，提高数据处理和模型推理效率。实验结果表明，TGC4Eth显著提高了现有检测模型的计算效率，保持了交易图的连通性，并且在面对特征逃逸攻击时表现出高稳定性。 <div>
arXiv:2405.08278v2 Announce Type: replace 
Abstract: Ethereum has become one of the primary global platforms for cryptocurrency, playing an important role in promoting the diversification of the financial ecosystem. However, the relative lag in regulation has led to a proliferation of malicious activities in Ethereum, posing a serious threat to fund security. Existing regulatory methods usually detect malicious accounts through feature engineering or large-scale transaction graph mining. However, due to the immense scale of transaction data and malicious attacks, these methods suffer from inefficiency and low robustness during data processing and anomaly detection. In this regard, we propose an Ethereum Transaction Graph Compression method named TGC4Eth, which assists malicious account detection by lightweighting both features and topology of the transaction graph. At the feature level, we select transaction features based on their low importance to improve the robustness of the subsequent detection models against feature evasion attacks; at the topology level, we employ focusing and coarsening processes to compress the structure of the transaction graph, thereby improving both data processing and inference efficiency of detection models. Extensive experiments demonstrate that TGC4Eth significantly improves the computational efficiency of existing detection models while preserving the connectivity of the transaction graph. Furthermore, TGC4Eth enables existing detection models to maintain stable performance and exhibit high robustness against feature evasion attacks.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Distributed Adaptive Control of Disturbed Interconnected Systems with High-Order Tuners</title>
<link>https://arxiv.org/abs/2405.15178</link>
<guid>https://arxiv.org/abs/2405.15178</guid>
<content:encoded><![CDATA[
<div> 关键词：network synchronization, distributed adaptive control, interconnected agents, consensus, communication limitations

总结:<br />
本文探讨了在通信受限的情况下，如何实现异质性子系统（包括领导者和跟随者）之间的网络同步，以达成共识。研究关注的是未知线性子系统的分布式自适应控制，存在输入-输出扰动。关键创新在于增强多 agent 系统内的通信，通过根据与领导者距离调整测量值，实现跟随。文章分析了不同类型的平衡网络（星形、循环、路径和随机）中第一至高阶调节器的效果，考虑了时间变系数。数值模拟展示了网络稀疏性对性能的影响，并指出增加节点数量并不总是减小误差。最后，经验证明，提出的改进高阶调节器优于其他方法，提供了深入的理论洞察和结论。 <div>
arXiv:2405.15178v2 Announce Type: replace 
Abstract: This paper addresses the challenge of network synchronization under limited communication, involving heterogeneous agents with different dynamics and various network topologies, to achieve consensus. We investigate the distributed adaptive control for interconnected unknown linear subsystems with a leader and followers, in the presence of input-output disturbance. We enhance the communication within multi-agent systems to achieve consensus under the leadership's guidance. While the measured variable is similar among the followers, the incoming measurements are weighted and constructed based on their proximity to the leader. We also explore the convergence rates across various balanced topologies (Star-like, Cyclic-like, Path, Random), featuring different numbers of agents, using three distributed algorithms, ranging from first- to high-order tuners to effectively address time-varying regressors. The mathematical foundation is rigorously presented from the network designs of the unknown agents following a leader, to the distributed methods. Moreover, we conduct several numerical simulations across various networks, agents and tuners to evaluate the effects of sparsity in the interaction between subsystems using the $L_2-$norm and $L_\infty-$norm. Some networks exhibit a trend where an increasing number of agents results in smaller errors, although this is not universally the case. Additionally, patterns observed at initial times may not reliably predict overall performance across different networks. Finally, we demonstrate that the proposed modified high-order tuner outperforms its counterparts, and we provide related insights along with our conclusions.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization</title>
<link>https://arxiv.org/abs/2406.07948</link>
<guid>https://arxiv.org/abs/2406.07948</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure Multi-party Computation, Decision Trees, Communication Optimization, Radix Sort Protocols, Training Framework

总结:<br />
本文介绍了一种名为 Ents 的高效三 party 训练框架，专注于优化决策树的多 party 训练过程中的通信效率。首先， Ents 提出基于安全排序协议的解决方案，有效处理连续属性数据集的分割，减少通信开销。其次，通过设计高效的份额转换协议，减少在大型环上进行大部分计算导致的通信负担。实验结果表明， Ents 相比现有框架在通信大小和轮数上分别提高了 5.5 倍到 9.3 倍和 3.9 倍到 5.3 倍，训练时间也缩短了 3.5 倍到 6.7 倍。在实际应用中， Ents 能在仅需三个小时的情况下，通过 WAN 环境对具有 245,000 多个样本的真实世界皮肤分割数据集进行安全训练，显示其实践可行性。 <div>
arXiv:2406.07948v3 Announce Type: replace 
Abstract: Multi-party training frameworks for decision trees based on secure multi-party computation enable multiple parties to train high-performance models on distributed private data with privacy preservation. The training process essentially involves frequent dataset splitting according to the splitting criterion (e.g. Gini impurity). However, existing multi-party training frameworks for decision trees demonstrate communication inefficiency due to the following issues: (1) They suffer from huge communication overhead in securely splitting a dataset with continuous attributes. (2) They suffer from huge communication overhead due to performing almost all the computations on a large ring to accommodate the secure computations for the splitting criterion.
  In this paper, we are motivated to present an efficient three-party training framework, namely Ents, for decision trees by communication optimization. For the first issue, we present a series of training protocols based on the secure radix sort protocols to efficiently and securely split a dataset with continuous attributes. For the second issue, we propose an efficient share conversion protocol to convert shares between a small ring and a large ring to reduce the communication overhead incurred by performing almost all the computations on a large ring. Experimental results from eight widely used datasets show that Ents outperforms state-of-the-art frameworks by $5.5\times \sim 9.3\times$ in communication sizes and $3.9\times \sim 5.3\times$ in communication rounds. In terms of training time, Ents yields an improvement of $3.5\times \sim 6.7\times$. To demonstrate its practicality, Ents requires less than three hours to securely train a decision tree on a widely used real-world dataset (Skin Segmentation) with more than 245,000 samples in the WAN setting.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>TemPrompt: Multi-Task Prompt Learning for Temporal Relation Extraction in RAG-based Crowdsourcing Systems</title>
<link>https://arxiv.org/abs/2406.14825</link>
<guid>https://arxiv.org/abs/2406.14825</guid>
<content:encoded><![CDATA[
<div> 关键词：Temporal Relation Extraction, Temporal Prompt Learning, Pre-trained Language Models, Contrastive Learning, Crowdsourcing Scenarios.

总结: 本文介绍了一种名为TemPrompt的多任务提示学习框架，用于解决时间关系抽取（TRE）任务中的数据限制和分布不均问题。该方法利用预训练语言模型（PLMs）的全球知识，通过任务导向的自动提示生成，结合prompt tuning和对比学习来提升性能。文章还提出利用时间事件推理辅助模型关注事件和时间线索。实验结果显示，TemPrompt在标准和少量样本条件下，相较于其他方法在大多数指标上表现更优，并通过案例研究验证了其在众包场景中的有效性。 <div>
arXiv:2406.14825v3 Announce Type: replace 
Abstract: Temporal relation extraction (TRE) aims to grasp the evolution of events or actions, and thus shape the workflow of associated tasks, so it holds promise in helping understand task requests initiated by requesters in crowdsourcing systems. However, existing methods still struggle with limited and unevenly distributed annotated data. Therefore, inspired by the abundant global knowledge stored within pre-trained language models (PLMs), we propose a multi-task prompt learning framework for TRE (TemPrompt), incorporating prompt tuning and contrastive learning to tackle these issues. To elicit more effective prompts for PLMs, we introduce a task-oriented prompt construction approach that thoroughly takes the myriad factors of TRE into consideration for automatic prompt generation. In addition, we present temporal event reasoning as a supplement to bolster the model's focus on events and temporal cues. The experimental results demonstrate that TemPrompt outperforms all compared baselines across the majority of metrics under both standard and few-shot settings. A case study is provided to validate its effectiveness in crowdsourcing scenarios.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>ammBoost: State Growth Control for AMMs</title>
<link>https://arxiv.org/abs/2406.17094</link>
<guid>https://arxiv.org/abs/2406.17094</guid>
<content:encoded><![CDATA[
<div> 关键词：Automated Market Makers (AMMs), Decentralized Finance (DeFi), Scalability issues, Sidechain architecture, ammBoost.

总结:<br />
本文探讨了去中心化金融(DeFi)应用中的自动市场 maker (AMM)面临的可扩展性问题，特别是高昂的链上存储开销。为解决这一问题，作者提出了一种新的侧链架构方案——ammBoost。ammBoost通过减少链上交易、提升吞吐量并支持区块链修剪，有效降低了交易成本和链增长。实验表明，ammBoost能将gas成本降低94.53%，链增长减少至少80%，并能处理比Uniswap实际流量高500倍的交易量。这一创新为AMM的高效运行提供了有力支持。 <div>
arXiv:2406.17094v2 Announce Type: replace 
Abstract: Automated market makers (AMMs) are a form of decentralized cryptocurrency exchanges and considered a prime example of Decentralized Finance (DeFi) applications. Their popularity and high trading activity have resulted in millions of on-chain transactions leading to serious scalability issues. In this paper, we address the on-chain storage overhead problem of AMMs by utilizing a new sidechain architecture as a layer 2 solution, building a system called ammBoost. Our system reduces the amount of on-chain transactions, boosts throughput, and supports blockchain pruning. We devise several techniques to enable layer 2 processing for AMMs while preserving correctness and security of the underlying AMM. We also build a proof-of-concept of ammBoost for a Uniswap-inspired use case to empirically evaluate its performance. Our experiments show that ammBoost decreases the gas cost by 94.53% and the chain growth by at least 80%, and that it can support up to 500x of the daily traffic volume observed for Uniswap in practice.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Protecting the 'Stop Using My Data' Right through Blockchain-assisted Evidence Generation</title>
<link>https://arxiv.org/abs/2406.17694</link>
<guid>https://arxiv.org/abs/2406.17694</guid>
<content:encoded><![CDATA[
<div> 关键词：个人数据、停止使用、证据生成、区块链、权利侵犯。

总结:<br />本文探讨了互联网平台如何在保护用户隐私的同时提供个性化服务。文章关注的核心问题是“停止使用我的数据”这一数据权利，它属于“被遗忘权”的重要方面。作者提出了一种创新的证据生成框架，利用区块链技术设计并实现了一个系统，以防止在数据收购后对这项权利的侵犯。该系统采用两阶段证据生成协议，其有效性由新提出的引理保证。通过在两个真实世界推荐系统数据集上的实验验证，证明了该方法的成功率超过99%。这个研究为数据保护提供了一种新的解决方案，确保用户的‘停止使用我的数据’请求得到尊重。 <div>
arXiv:2406.17694v2 Announce Type: replace 
Abstract: In order to provide personalized services to users, Internet-based platforms collect and utilize user-generated behavioral data. Although the 'stop using my data' right should be a fundamental data right, which allows individuals to request their personal data to be no longer utilized by online platforms, the existing preventive data protection measures (e.g., cryptographic data elimination, differential privacy) are unfortunately not applicable. This work aims to develop the first Evidence Generation Framework for deterring post-acquisition data right violations. We formulated the 'stop using my data' problem, which captures a vantage facet of the multi-faceted notion of 'right to be forgotten'. We designed and implemented the first blockchain-assisted system to generate evidence for deterring the violations of the 'stop using my data' right. Our system employs a novel two-stage evidence generation protocol whose efficacy is ensured by a newly proposed Lemma. To validate our framework, we conducted a case study on recommendation systems with systematic evaluation experiments using two real-world datasets: the measured success rate exceeds 99%.
]]></content:encoded>
<pubDate></pubDate>
</item>
<item>
<title>Federated Graph Semantic and Structural Learning</title>
<link>https://arxiv.org/abs/2406.18937</link>
<guid>https://arxiv.org/abs/2406.18937</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Graph Learning, Graph Neural Networks, Node-Level Semantics, Graph-Level Structure, Distillation

总结:<br />
该论文关注联邦图学习中的挑战，主要集中在非独立同分布问题上，目标是协作训练全球图神经网络。首先，论文发现节点级语义对本地模型性能至关重要，通过对比不同类别的节点进行正则化，提升区分度。其次，论文提出结构信息对于邻居节点具有相似性，但直接对齐可能因类别不一致而阻碍区分。为解决这个问题，作者将邻接关系转化为相似度分布，并利用全局模型向本地模型传授关系知识，保持局部模型的结构信息和识别能力。实验结果在三个图数据集上验证了该方法的有效性，优于现有方法。 <div>
arXiv:2406.18937v2 Announce Type: replace 
Abstract: Federated graph learning collaboratively learns a global graph neural network with distributed graphs, where the non-independent and identically distributed property is one of the major challenges. Most relative arts focus on traditional distributed tasks like images and voices, incapable of graph structures. This paper firstly reveals that local client distortion is brought by both node-level semantics and graph-level structure. First, for node-level semantics, we find that contrasting nodes from distinct classes is beneficial to provide a well-performing discrimination. We pull the local node towards the global node of the same class and push it away from the global node of different classes. Second, we postulate that a well-structural graph neural network possesses similarity for neighbors due to the inherent adjacency relationships. However, aligning each node with adjacent nodes hinders discrimination due to the potential class inconsistency. We transform the adjacency relationships into the similarity distribution and leverage the global model to distill the relation knowledge into the local model, which preserves the structural information and discriminability of the local model. Empirical results on three graph datasets manifest the superiority of the proposed method over its counterparts.
]]></content:encoded>
<pubDate></pubDate>
</item>
</channel>
</rss>